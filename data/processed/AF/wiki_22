{"id": "60343", "revid": "33744554", "url": "https://en.wikipedia.org/wiki?curid=60343", "title": "Sediment", "text": "Particulate solid matter deposited on a planetary surface\nSediment is a solid material made of loose particles that is transported to a new location where it is deposited. It occurs naturally and, through the processes of weathering and erosion, is broken down and subsequently transported by the action of wind, water, or ice or by the force of gravity acting on the particles. For example, sand and silt can be carried in suspension in river water and on reaching the sea bed deposited by sedimentation; if buried, they may eventually become sandstone and siltstone (sedimentary rocks) through lithification.\nSediments are most often transported by water (fluvial processes), but also wind (aeolian processes) and glaciers. Beach sands and river channel deposits are examples of fluvial transport and deposition, though sediment also often settles out of slow-moving or standing water in lakes and oceans. Desert sand dunes and loess are examples of aeolian transport and deposition. Glacial moraine deposits and till are ice-transported sediments.\nClassification.\nSediment can be classified based on its grain size, grain shape, and composition.\nGrain size.\nSediment size is measured on a log base 2 scale, called the \"Phi\" scale, which classifies particles by size from \"colloid\" to \"boulder\".\nShape.\nThe shape of particles can be defined in terms of three parameters. The \"form\" is the overall shape of the particle, with common descriptions being spherical, platy, or rodlike. The \"roundness\" is a measure of how sharp grain corners are. This varies from well-rounded grains with smooth corners and edges to poorly rounded grains with sharp corners and edges. Finally, \"surface texture\" describes small-scale features such as scratches, pits, or ridges on the surface of the grain.\nForm.\nForm (also called \"sphericity\") is determined by measuring the size of the particle on its major axes. William C. Krumbein proposed formulas for converting these numbers to a single measure of form, such as\nformula_1\nwhere formula_2, formula_3, and formula_4 are the long, intermediate, and short axis lengths of the particle. The form formula_5 varies from 1 for a perfectly spherical particle to very small values for a platelike or rodlike particle.\nAn alternate measure was proposed by Sneed and Folk:\nformula_6\nwhich, again, varies from 0 to 1 with increasing sphericity.\nRoundness.\nRoundness describes how sharp the edges and corners of particle are. Complex mathematical formulas have been devised for its precise measurement, but these are difficult to apply, and most geologists estimate roundness from comparison charts. Common descriptive terms range from very angular to angular to subangular to subrounded to rounded to very rounded, with increasing degree of roundness.\nSurface texture.\nSurface texture describes the small-scale features of a grain, such as pits, fractures, ridges, and scratches. These are most commonly evaluated on quartz grains, because these retain their surface markings for long periods of time. Surface texture varies from polished to frosted, and can reveal the history of transport of the grain; for example, frosted grains are particularly characteristic of aeolian sediments, transported by wind. Evaluation of these features often requires the use of a scanning electron microscope.\nComposition.\nComposition of sediment can be measured in terms of:\nThis leads to an ambiguity in which clay can be used as both a size-range and a composition (see clay minerals).\nSediment transport.\nSediment is transported based on the strength of the flow that carries it and its own size, volume, density, and shape. Stronger flows will increase the lift and drag on the particle, causing it to rise, while larger or denser particles will be more likely to fall through the flow.\nAeolian processes: wind.\nWind results in the transportation of fine sediment and the formation of sand dune fields and soils from airborne dust.\nGlacial processes.\nGlaciers carry a wide range of sediment sizes, and deposit it in moraines.\nMass balance.\nThe overall balance between sediment in transport and sediment being deposited on the bed is given by the Exner equation. This expression states that the rate of increase in bed elevation due to deposition is proportional to the amount of sediment that falls out of the flow. This equation is important in that changes in the power of the flow change the ability of the flow to carry sediment, and this is reflected in the patterns of erosion and deposition observed throughout a stream. This can be localized, and simply due to small obstacles; examples are scour holes behind boulders, where flow accelerates, and deposition on the inside of meander bends. Erosion and deposition can also be regional; erosion can occur due to dam removal and base level fall. Deposition can occur due to dam emplacement that causes the river to pool and deposit its entire load, or due to base level rise.\nShores and shallow seas.\nSeas, oceans, and lakes accumulate sediment over time. The sediment can consist of \"terrigenous\" material, which originates on land, but may be deposited in either terrestrial, marine, or lacustrine (lake) environments, or of sediments (often biological) originating in the body of water. Terrigenous material is often supplied by nearby rivers and streams or reworked marine sediment (e.g. sand). In the mid-ocean, the exoskeletons of dead organisms are primarily responsible for sediment accumulation.\nDeposited sediments are the source of sedimentary rocks, which can contain fossils of the inhabitants of the body of water that were, upon death, covered by accumulating sediment. Lake bed sediments that have not solidified into rock can be used to determine past climatic conditions.\nKey marine depositional environments.\nThe major areas for deposition of sediments in the marine environment include:\nOne other depositional environment which is a mixture of fluvial and marine is the turbidite system, which is a major source of sediment to the deep sedimentary and abyssal basins as well as the deep oceanic trenches.\nAny depression in a marine environment where sediments accumulate over time is known as a sediment trap.\nThe null point theory explains how sediment deposition undergoes a hydrodynamic sorting process within the marine environment leading to a seaward fining of sediment grain size.\nEnvironmental issues.\nErosion and agricultural sediment delivery to rivers.\nOne cause of high sediment loads is slash and burn and shifting cultivation of tropical forests. When the ground surface is stripped of vegetation and then seared of all living organisms, the upper soils are vulnerable to both wind and water erosion. In a number of regions of the earth, entire sectors of a country have become erodible. For example, on the Madagascar high central plateau, which constitutes approximately ten percent of that country's land area, most of the land area is devegetated, and gullies have eroded into the underlying soil to form distinctive gulleys called \"lavakas\". These are typically wide, long and deep. Some areas have as many as 150 lavakas/square kilometer, and lavakas may account for 84% of all sediments carried off by rivers. This siltation results in discoloration of rivers to a dark red brown color and leads to fish kills. In addition, sedimentation of river basins implies sediment management and siltation costs. The cost of removing an estimated 135 million m3 of accumulated sediments due to water erosion only is likely exceeding 2.3 billion euro (\u20ac) annually in the EU and UK, with large regional differences between countries.\nErosion is also an issue in areas of modern farming, where the removal of native vegetation for the cultivation and harvesting of a single type of crop has left the soil unsupported. Many of these regions are near rivers and drainages. Loss of soil due to erosion removes useful farmland, adds to sediment loads, and can help transport anthropogenic fertilizers into the river system, which leads to eutrophication.\nThe Sediment Delivery Ratio (SDR) is fraction of gross erosion (interill, rill, gully and stream erosion) that is expected to be delivered to the outlet of the river. The sediment transfer and deposition can be modelled with sediment distribution models such as WaTEM/SEDEM. In Europe, according to WaTEM/SEDEM model estimates the Sediment Delivery Ratio is about 15%.\nCoastal development and sedimentation near coral reefs.\nWatershed development near coral reefs is a primary cause of sediment-related coral stress. The stripping of natural vegetation in the watershed for development exposes soil to increased wind and rainfall and, as a result, can cause exposed sediment to become more susceptible to erosion and delivery to the marine environment during rainfall events. Sediment can negatively affect corals in many ways, such as by physically smothering them, abrading their surfaces, causing corals to expend energy during sediment removal, and causing algal blooms that can ultimately lead to less space on the seafloor where juvenile corals (polyps) can settle.\nWhen sediments are introduced into the coastal regions of the ocean, the proportion of land, marine, and organic-derived sediment that characterizes the seafloor near sources of sediment output is altered. In addition, because the source of sediment (i.e., land, ocean, or organically) is often correlated with how coarse or fine sediment grain sizes that characterize an area are on average, grain size distribution of sediment will shift according to the relative input of land (typically fine), marine (typically coarse), and organically-derived (variable with age) sediment. These alterations in marine sediment characterize the amount of sediment suspended in the water column at any given time and sediment-related coral stress.\nBiological considerations.\nIn July 2020, marine biologists reported that aerobic microorganisms (mainly), in \"quasi-suspended animation\", were found in organically-poor sediments, up to 101.5 million years old, 250 feet below the seafloor in the South Pacific Gyre (SPG) (\"the deadest spot in the ocean\"), and could be the longest-living life forms ever found.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60346", "revid": "9813438", "url": "https://en.wikipedia.org/wiki?curid=60346", "title": "LHA", "text": "LHA may refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "60347", "revid": "20695403", "url": "https://en.wikipedia.org/wiki?curid=60347", "title": "Chandrakirti", "text": "Buddhist philosopher\nChandrakirti (IAST: ; Sanskrit: \u091a\u0902\u0926\u094d\u0930\u0915\u0940\u0930\u094d\u0924\u093f; ; c.\u2009600\u00a0\u2013 c.\u2009650, meaning \"glory of the moon\" in Sanskrit) or \"Chandra\" was a Buddhist scholar of the Madhyamaka school who was based out of the monastery of Nalanda. He was a noted commentator on the works of Nagarjuna (c.\u2009150\u00a0\u2013 c.\u2009250 CE) and those of his main disciple, Aryadeva. He wrote two influential works on Madhyamaka, the \"Prasannapad\u0101\" and the \"Madhyamak\u0101vat\u0101ra\".\nChandrakirti does not seem to have been very influential during the 7th to 10th centuries, and his works were never translated into Chinese. However, by the 11th and 12th centuries, his work became influential in the north, especially in Kashmir and in Tibet. Over time, Chandrakirti became a major source for the study of Madhyamaka philosophy in Tibetan Buddhism. Chandrakirti's work was especially promoted by Tibetans like Rendawa Zh\u00f6nnu Lodr\u00f6 and his student Tsongkhapa as a way to counter the widespread influence of the Uttaratantra, and the shentong views associated with it.\nAs noted by Kevin A. Vose, Chandrakirti is seen by many Tibetan Buddhists as offering \"the most thorough and accurate vision of N\u0101g\u0101rjuna's emptiness, which, in turn, most fully represents the final truth of the Buddha's teaching.\" He is considered by Tibetans to be the main exponent of what they term the \"Pr\u0101sa\u1e45gika\" sub-school of madhyamaka. However, this doxographical categorization only arose in Tibet during the 12th century.\nLife.\nVery little is known about Chandrakirti's life, though Tibetan sources state that he was born in South India, became a Buddhist monk and was a student of Kamalabuddhi (who was the student of Buddhapalita). Tibetan sources like Bu ston and Taranatha state that Chandrakirti was active at Nalanda, where he is said to have become an abbot.\nAccording to Karen Lang:According to Bus ton and Taranatha, Candrakirti was born in south India and entered a monastery, where he mastered all the Buddhist scriptures. Taranatha adds that he was born in Samanta during the reign of King Sila, the son of Sriharsa. He took a special interest in Nagarjuna's treatises and studied them with the disciples of two rival interpreters, Bhavaviveka and Buddhapalita. He preferred Buddhapalita's interpretations of Madhyamaka teachings and defended them in a famous debate with the grammarian Candragomin, who supported the idealist position of the Vij\u00f1anavada (Doctrine of Consciousness) school.\nTibetan sources further add that during the latter period of his life, he returned to the South of India, where he stayed in the region of \"Ko\u1e45kuna\". During his time here, he is said to have worked to defeat and convert many non-Buddhists.\nDebate at Nalanda.\nBu ston and Taranatha both reference a debate that took place at Nalanda between Chandrakirti and the poet-lay scholar, Chandragomin. The debate started after Chandrakirti noticed Chandragomin delivering a lecture to a large crowd on the topics of P\u0101\u1e47inian grammar, s\u016btra, and tantra. Chandrakirti invited Chandragomin to come with him to Nalanda, where he could be enrolled into the sangha. However, due to a disagreement, a debate ensued between the two, with Chandrakirti arguing for the Madhyamaka position and Chandragomin taking on the Yogacara view. This debate was said to have attracted a large crowd. Over the course of the debate, Chandrakirti failed to defeat Chandragomin's position, and he began to suspect that someone was secretly teaching Chandragomin. Legend even states that Chandragomin was being tutored by the bodhisattva, Avalokite\u015bvara himself. Both Bu Ston and Taranatha record that the debate only ended after seven years, although neither writer specifies who the winner was.\nPhilosophy.\nChandrakirti was a philosopher of the madhyamaka school of Nagarjuna. This school held that all phenomena (\"dharmas\") were empty of intrinsic nature or self-existence (Sanskrit: \"svabh\u0101va\"). This includes all Buddhist phenomena including the Buddha, the four noble truths and nirvana. According to Chandrakirti, the apophatic method of madhyamaka is a thoroughgoing negation of all concepts, propositions (\"pratij\u00f1\u0101\") and views (\"d\u1e5b\u1e63\u1e6di\") which affirms neither existence nor non-existence. Due to this radical negation, madhyamaka is seen as a middle way which rejects all extreme views and positions.\nFor Chandrakirti, even though all phenomena lack svabh\u0101va, sentient beings impute svabh\u0101va in their experience due to their ignorance about the true nature of reality. Ultimately, all phenomena are merely conceptual constructs (\"praj\u00f1aptimatra\") which do not exist in themselves but are mentally imputed dependent designations (\"praj\u00f1\u0101ptirup\u0101d\u0101ya\").\nThubten Jinpa outlines what has been seen by commentators as the main philosophical ideas put forth by Chandrakirti as follows:(1) rejection of formal inference based on criteria grounded in objects facts of the world, relying instead on consequential reasoning that reveals logical contradictions and absurd consequences entailed by an opponent's positions, (2) rejection of the key tenets of the Buddhist epistemology initiated by Dignaga and developed further by Dharmakirti, (3) a radical understanding of the inaccessibility of ultimate truth through language and thought, (4) an understanding of conventional truth that appeals for its validity to everyday intuitions of the world instead of philosophical grounding, (5) a unique interpretation of Nagarjuna's statement about his having no thesis, and (6) the possible cessation of mind and mental factors in buddhahood.\nTwo Truths.\nLike all madhyamikas, Chandrakirti defends a theory of two truths with a strict anti-foundationalist character. According to Chandrakirti, all things (\"bh\u0101va\") have two natures, the conventional and the ultimate.\nThe conventional truth (\"sa\u1e41v\u1e5bti\" \"satya\") is the fact that, provisionally speaking, phenomena have a nature or existence (\"bh\u0101va\"). For example, a property of fire is heat and so on. This is the truth of the everyday world (\"lokasa\u1e41v\u1e5btisatya\") and the truth of conventional transaction (\"vyavah\u0101rasatya\"). However, these conventional properties are not intrinsic natures or \"svabh\u0101vas\" (even conventionally speaking), since for Chandra, even conventional truth is empty of intrinsic natures. This view differentiates Chandrakirti from other madhyamikas like Bh\u0101viveka which affirm the \"conventional existence\" of intrinsic natures.\nRegarding the ultimate truth (\"param\u0101rtha satya\"), when fire is analyzed to find its ultimate nature, no independent essence is found that makes fire hot, and thus fire (and all things, including the most basic concepts like time and causality) have no ultimate essence or nature. This is the ultimate truth i.e. emptiness (\"\u015b\u016bnyat\u0101\") or the lack of self-existence (\"ni\u1e25svabh\u0101va\"). It is this very lack of inherent nature in conventional truth that allows it to change and have causal efficacy (\"arthakriya\") and thus, to be a dependent arising (\"prat\u012btyasamutp\u0101da\").\nThe nature of conventional truth.\nThe conventional is the \"domain of mundane cognitive process, and is readily accessible for ordinary beings\" according to Sonam Thakchoe. The conventional truth can be contrasted with conventional falsehood based on erroneous cognitions. Correct cognition is differentiated from false cognitions by sense faculties that are not impaired. A related distinction which Chandrakirti makes is that between worldly conventions (\"lokasa\u1e43v\u1e5bti\"), which are epistemically reliable from the point of view of ordinary beings and conventions that do not reflect the world (\"alokasa\u1e43v\u1e5bti)\" and are thus deceptive even by worldly standards.\n\"Conventional\" \"(sa\u1e41v\u1e5bti)\" can also mean \"covering\" according to Chandrakirti and is also associated with delusion or ignorance (\"avidy\u0101\"). Furthermore, he also glosses the term as codependent (\"paraparasa\u1e43bhavana)\" and as being signified \"(sa\u1e41ket)\" or worldly convention \"(lokavyavah\u0101ra).\"\nThe conventional truth, especially as experienced by ordinary people (who reify reality), is a concealing and deluded kind of truth which may act as an obstacle to understanding the ultimate.\"\" From the ultimate point of view in fact, \"sa\u1e41v\u1e5btisatya\" is not really true. Indeed, Chandrakirti explains that conventional phenomena are illusory and unreal and can be compared to a mirage. The only difference is that conventional phenomena have some causal efficacy from the mundane point of view (for example, water can help a thirsty person, a mirage cannot)\".\"\nFurthermore, these conventional phenomena are to be differentiated from conventionally illusory entities, such as intrinsic natures or essences that are imputed on to things (which do not exist at all, even conventionally) and conventionally unreal entities (like the horns of a rabbit, which also do not exist at all)\".\" The main difference between these latter two unreal phenomena is that the conventionally unreal entities are understood to be unreal by ordinary people, whereas intrinsic nature is not understood to be unreal by ordinary persons. Instead, ordinary persons impute intrinsic nature on to conventional phenomena (such as water etc.) and perceive them as being intrinsically real (only noble beings realize that this is illusory). As such, intrinsic nature is a conceptual fiction in the minds of ordinary beings.\"\"\nIn spite of the unreality of the conventional, Chandrakirti states that the Buddha taught using language and conventional expressions as a way to guide people to the ultimate truth, which is beyond language and cannot be expressed through words.\nFor Chandrakirti, the way that ordinary beings experience the conventional is very different from the way that awakened saints or noble beings (\"\u0101ryas\") experience the conventional. Chandrakirti introduced the concept of \"mere convention\" (Tibetan: \"kun rdzob tsam\") to refer to how noble ones experience conventionality, which is quite different to what is held to be \"conventionally real\" or \"conventional true\" (\"kun rdzob bden pa\"). Ordinary beings grasp at and misconstrue phenomena as being intrinsically real, thus they experience conventional \"reality.\" Enlightened beings meanwhile, only experience a non-reified kind of appearance, which is perceived as being an unreal construct, like a reflected image.\nThe nature of the ultimate truth.\nChandrakirti defines ultimate reality as \"the nature of things found by particular exalted cognitive processes (yeshes) of those who perceive reality.\" He further defines it as follows:\u201cUltimate is the object, the nature of which is found by \"particular\" exalted cognitive processes of those who perceive reality. But it does not exist by virtue of its \"intrinsic objective reality\" (\"svar\u016bpat\u0101\" / \"bdag gi ngo bo nyid\").\"As such, the ultimate truth for Chandra is the nature of all conventional things that is found by a particular exalted perception which sees how things really are. However, as indicated by Chandra, this nature is also not truly real.\nAccording to Chandrakirti, the ultimate truth, emptiness, is seen as having two aspects: selflessness of persons (\"pudgalanair\u0101tmya\") and selflessness of phenomena (\"dharmanair\u0101tmya\"). Chandrakirti provides various arguments to show that persons, phenomena (dharmas) and emptiness itself are all unreal and empty.\nThe ultimate truth, the lack of self-nature in all phenomena, also refers to the fact that phenomena do not arise or cease at all. Even though conventional phenomena appear to arise and pass away through dependent arising, this appearance is in fact unreal and illusory. Thus, for Chandrakirti, the wisdom which realizes the ultimate truth is the realization that phenomena (dharmas) do not arise or come into being from themselves, from another thing, from both themselves and another thing, or without a cause. Just like Nagarjuna, Chandrakirti refutes all positions regarding the arising of phenomena, summing up his position as follows:Entities do not arise causelessly, and they do not arise through causes like God, for example. Nor do they arise out of themselves, nor from another, nor from both. They arise codependently.In this sense then, all phenomena are intrinsically unreal and like illusions, since they truly are not what they appear to be.\nAccording to Chandrakirti, this very ultimate truth (i.e. emptiness and non-arising), is also empty, in the sense that it is also dependent on the provisional truth of dependent imputation. Another way to state this is that only what lacks inherent nature is dependently originated and causally efficacious.\nChandrakirti explains the emptiness of emptiness as follows:The emptiness of intrinsic reality of things is itself called by the wise as \u2018emptiness,\u2019 and this emptiness also is considered to be empty of any intrinsic reality. The emptiness of that which is called \u2018emptiness\u2019 is accepted as \u2018the emptiness of emptiness\u2019 (\"\u015b\u016bnyat\u0101\u015b\u016bnyat\u0101\"). It is explained in this way for the purpose of controverting objectification of the emptiness as intrinsically real (\"bh\u0101va\").Thus, according to Chandrakirti's doctrine of \"the emptiness of emptiness\", the ultimate truth is not some absolute reality, existential ground or ontological foundation, but refers to a mere absence of nature, and thus to the illusory and unreal character of things.\nBecause of the unreality of the conventional and the ineffability of the ultimate, Chandrakirti holds that madhyamikas do not formally put forth any elaborate theory of the conventional truth apart from the ordinary worldly experience that is accepted by worldly convention or common consensus. According to Chandrakirti, theories which seek to explain the workings of the conventional truth (like the metaphysics of samkhya or yogacara) actually obscure and undermine our understanding of conventional truth, since it is at variance with direct experience. These theories also undermine our understanding of the ultimate truth (which is the very nature of our experience) since the ultimate cannot be understood conceptually and can only be accessed through the gateway of one's conventional direct experience.\n\"Pr\u0101sa\u1e45ga\" and reasoning.\nChandrakirti defended Buddhap\u0101lita and his madhyamaka method against the views of Bh\u0101viveka. According to Chandra, Madhyamikas should not use autonomous or independent inferences (\"svatantr\u0101num\u0101na\") when debating an opponent. This method had been developed by the Buddhist epistemologist Dign\u0101ga and had been adopted by madhyamikas like Bh\u0101viveka. Bh\u0101viveka had argued that to be able to accurately and effectively defend the madhyamaka view against its opponents, one needed to positively prove one's thesis by means of independent inferences (\"svatantr\u0101num\u0101na\") in formal syllogisms (\"prayoga\") which proved the madhyamika thesis in a self-contained manner independent of the views of non-madhyamika interlocutors. He therefore faulted Buddhap\u0101lita's analysis of madhyamaka as inadequate.\nChandrakirti critiqued Bh\u0101viveka on this point and argued that madhyamaka thinkers should instead only rely on \"pr\u0101sa\u1e45ga\" arguments (literally \"consequence\"), which mainly refers to reductio arguments that seek to show how an opponent's views lead to absurd or unwanted consequences. Furthermore, these reductio arguments only refute the opponents position on the opponent's own terms. They do not put forth a counter-position in return nor do they commit the madhyamika to the principles and conclusions used in the course of the argument. In this sense, the madhyamikas merely point out the absurdity of their opponents views without stating a position of their own, and merely indicate the truth indirectly.\nChandrakirti states:Whoever speaks in terms of independently valid logical arguments (inferences) reaps some fault. We do not rely on them, because the only fruit of our arguments is the annulment of someone else's thesis. Chandrakirti argues that the idea that one \"must\" use the syllogistic arguments commits one to the acceptance of inherent natures or some other form of foundationalism or essentialism. He also points out that Nagarjuna did not make use of such arguments and relied on \"pr\u0101sa\u1e45ga\". Chandrakirti sees figures like Bh\u0101viveka as not really being madhyamikas, instead he sees them as logicians which \"may take the side of the madhyamaka school out of a desire to parade the extent of his own dialectical skill.\" According to Chandrakirti, the philosophical practices of these logicians, motivated as they are by a desire for certainty and logic, becomes \"an enormous reservoir where faults pile up one after another.\" Thus, Chandrakirti does not see Bh\u0101viveka as being a madhyamika (unlike later Tibetan doxographers), but sees him as being a logician (\"t\u0101rkika\"), like other Buddhist thinkers such as Dignaga.\nAnother problem which Chandrakirti sees with the idea that a madhyamika must use independent syllogisms is that a madhyamika interlocutor and any essentialist or realist opponent do not share a basic set of premises required for syllogistic reasoning. This is because they do not have the same idea of what it means for something to \"exist\" and therefore they cannot even agree on a set of basic premises on which to develop an independent syllogism. The validity of any independent syllogism depends on the fact that the terminology it uses has the same meaning for both parties in the debate. However, this is impossible in a debate between a madhyamika and a realist according to Chandrakirti, since the very subject of debate is the nature of how the very objects of discussion are said to exist. Thus, a true madhyamika cannot put forth an independent syllogism which is not defective. Furthermore, if both parties use the same terminology but interpret them differently, they also lack a common understanding on which to ground a debate.\n\"Pr\u0101sa\u1e45ga\" arguments meanwhile, are mainly negative, and thus do not require the affirmation of any positive thesis or view, but merely deconstructs the arguments of one's opponent. As such, Chandrakirti thinks \"pr\u0101sa\u1e45ga\" arguments are more suited to the apophatic method of madhyamaka philosophy. Indeed, according to Chandrakirti, madhyamaka presents no positive view at all and he cites Nagarjuna's \"Vigrahavy\u0101vartan\u012b\" in which he states \"I have no thesis\" in this regard.\nChandrakirti also critiques the view of the non-madhyamika epistemologists like Dign\u0101ga for having failed to provide a sufficiently indisputable foundation for their premises and for having failed to respond to Nagarjuna's criticism of the foundations of pramana in the \"Vigrahavy\u0101vartan\u012b.\"\nThere is a further problem with the view of the logicians and this is that, for Chandrakirti, all cognitions involve ignorance from an ultimate point of view and thus no cognition is fully reliable. Because of this, meditation on emptiness does not rely on an object at all (even the idea or view of emptiness) and ultimate truth is thus said to be beyond the ordinary mind. However, there is a role for reasoning in Chandrakirti's thought. Reasoning is only useful for negating all views regarding existence and non-existence. Furthermore, reasoning must also negate itself, because it also relies on conceptual proliferation (\"prapa\u00f1ca\"), which is based on ignorance. Thus, for Chandrakirti, reasoning and conceptual thought cannot know the ultimate truth, because the ultimate is beyond all concepts and discursive proliferation (\"prapa\u00f1ca\"). However, reasoning \"can\" be used to understand the very limitations of reason and thought in explaining the ultimate and how any attempt at conceptually understanding the ultimate leads to contradictions. Reason can thus indirectly point to the ineffable ultimate truth (which can only be realized by another means, i.e. through wisdom, \"j\u00f1ana\") by revealing what it is not.\nBuddhahood.\nChandrakirti's view of Buddhahood is related to his apophatic views. For Chandrakirti, a Buddha's knowing of emptiness is not really knowing anything at all. Instead, a Buddha's knowledge of emptiness is a non-knowing in which there is neither an object nor a mind engaged in the act of knowing the object. Because of this, Chandrakirti holds that for a Buddha, all mind and mental factors (\"cittacaitta\") have ceased. Even though from the point of view of ordinary people, a Buddha seems to teach and engage in activities, from the point of view of a Buddha, no conscious decisions are being made and no cognition occurs. Yet, as Dunne notes, Chandrakirti thereby faces serious difficulties in explaining \"the improbable state of affairs\" by which a Buddha could teach and benefit sentient beings without any cognitive relation to the world.\nCritiques of Yog\u0101c\u0101ra.\nIn his \"Madhyamak\u0101vat\u0101ra,\" Chandrakirti also offered refutations of a number of Buddhist views such as those of the \"vij\u00f1\u0101nav\u0101da\" (\"consciousness doctrine\") or yog\u0101c\u0101ra school. Chandrakirti understood this tradition as positing a kind of subjective idealism. According to Chandrakirti, the yog\u0101c\u0101ra school fails to fully understand the empty nature of consciousness since they ontologically privilege consciousness over its objects. However, according to Chandrakirti, both are equally empty and neither have any ontological primacy or ultimate existence. Thus, for Chandrakirti, yog\u0101c\u0101ra fails to appreciate how everything, including consciousness, is conditioned and empty.\nChandrakirti also examines and refutes the basic theories of yog\u0101c\u0101ra, including the theory of the three natures and the theory of the storehouse consciousness. Chandrakirti cites the \"La\u1e45k\u0101vat\u0101ra S\u016btra\" in order to argue that the storehouse consciousness is a provisional teaching of indirect meaning (\"neyartha\"). He also critiques the yog\u0101c\u0101ra denial of an external object (\"b\u0101hy\u0101rtha, bahirartha\") of knowledge and the yog\u0101c\u0101ra theory of \u2018self-awareness\u2019 (\"svasamvedana, svasamvitti\").\nFurthermore, Chandrakirti interprets the various statements in the Mahayana sutras which seem to promote idealism in a different way than the yog\u0101c\u0101ra school. According to Chandrakirti, sutra teachings which state that \"all is mind\" and the like were taught by the Buddha as a way to counter the idea that our sufferings are caused by external forces and actors. According to Chandrakirti, to counter this wrong view and to help people understand that suffering mainly arises due to the way we understand our experience, the Buddha taught that all is mind (\"citta-matra\") or idea/impressions (\"vij\u00f1apti-matra\"). Chandrakirti argues that it is a mistake to take this literally as an ontological statement and to conclude that only consciousness exists.\nMajor works.\nChandra's major works are: \nLater Influence and Commentaries.\nOnly one Indian commentary on Chandrakirti exists, a 12th-century commentary to the \"Madhyamak\u0101vat\u0101ra\" by the Kashmiri pandit Jay\u0101nanda\".\" An earlier Indian author, Praj\u00f1akaramati (950\u20131030) repeadately cites the \"Madhyamak\u0101vat\u0101ra\" in his commentary on Shantideva's \"Bodhisattvacary\u0101vat\u0101ra\". The work of Atisha (982\u20131054), particularly his \"Introduction to the Two Truths\" (\"Satyadvay\u0101vat\u0101ra\")\",\" cites Chandrakirti and defends his view which rejects the applicability of valid cognition (\"pramana\") to ultimate truth.\nAnother late Indian author which seems to have held Chandrakirti's position is Maitr\u012bpad\u0101 (c. 1007\u20131085) and he is held to be one of the sources of the Kagyu school's Pr\u0101sa\u1e45gika lineage. Chandrakirti is also cited in some late Indian Buddhist tantric works, such as the \"Compendium of Good Sayings,\" indicating that he may have been influential among Indian tantric authors, especially among the Arya lineage of the \"Guhyasamaja tantra.\" The Arya lineage includes the works of tantric authors who go by the names Nagarjuna, Aryadeva and Chandrakirti (the last two can be dated to the 9th or 10th centuries) and who should not be confused with the earlier Madhyamaka philosophers. Later Tibetan authors also began to believe that the tantric figures and the Madhyamaka philosophers were the same persons.\nAnother critical Indian author who refers to the work of Chandrakirti (and responds to it) is the later Bh\u0101vaviveka or Bh\u0101vaviveka II (author of the \"Madhyamak\u0101rthasa\u1e43graha\" and the \"Madhyamakaratnaprad\u012bpa\"), not to be confused with the first Bh\u0101vaviveka (c. 500 \u2013 c. 578) who pre-dates Chandrakirti and authored the \"Madhyamakahrdaya\" and the \"Praj\u00f1\u0101prad\u012bpa\". According to Ruegg, this might be the same person as the tantric Bhavyak\u012brti (c. 1000).\nThe first Tibetan translation of Chandrakirti's \"Madhyamak\u0101vat\u0101ra\" and its auto-commentary was completed by Naktso Lotsawa, a student of Atisha. Another early Tibetan commentator on Chandrakirti was Patsab Nyima Drag (fl. 12th century), who also translator most of Chandra's major works. The logician Chapa Ch\u00f6kyi Seng\u00e9 (12th century) is known for discussing the views of Chandrakirti and composing refutations of them in his defense of the epistemological tradition of Dharmakirti. Chapa's student, Mabja Changchub Ts\u00f6ndr\u00fc (1109\u20131169) is also another important early figure who wrote on Chandrakirti. Mabja's work attempted to harmonize Dharmakirti's epistemology with Chandrakirti's Madhyamaka. Chandrakirti was categorized by Tibetans as part of the Uma Thelgyur ( Wylie: \"dbu ma thal 'gyur\") school, an approach to the interpretation of Madhyamaka philosophy typically back-translated into Sanskrit as or rendered in English as the \"Consequentialist\" or \"Dialecticist\" school.\nThe influence of these early commentators lead to the increased popularity of Chandrakirti in Tibet. Later important Tibetan Buddhist figures like Tsongkhapa, Wangchuk Dorje (the 9th Karmapa) and Jamgon Mipham also wrote commentaries on the \"Madhyamak\u0101vat\u0101ra.\"\nOther Chandrakirtis.\nThe Tibetan translation of \"Charyapada\" provided the name of its compiler as Munidatta, that its Sanskrit commentary is \"Cary\u0101g\u012btiko\u015bav\u1e5btti\", and that its lotsawa \"translator\" was Chandrakirti. This is a later Chandrakirti, who assisted in Tibetan translation in the Later Transmission of Buddhism to Tibet.\nThe author of the \"Tri\u015bara\u1e47asaptati\" (Seventy Verses on Taking Refuge) is also called Chandrakirti, but this does not seem to be the same person as the 7th century Chandrakirti. The same is the case with the author of the \"Madhyamak\u0101vat\u0101ra-praj\u00f1\u0101.\"\nThere is also another figure called Chandrakirti or Chandrakirtipada. This is the author of the \"Prad\u012bpoddyotana,\" a commentary on the \"Guhyasam\u0101ja Tantra.\" As such, he is sometimes called the \"tantric Chandrakirti\"\".\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60348", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=60348", "title": "Pkzip", "text": ""}
{"id": "60352", "revid": "1105348151", "url": "https://en.wikipedia.org/wiki?curid=60352", "title": "Countable sets", "text": ""}
{"id": "60353", "revid": "5862", "url": "https://en.wikipedia.org/wiki?curid=60353", "title": "BrainF", "text": ""}
{"id": "60355", "revid": "1575274", "url": "https://en.wikipedia.org/wiki?curid=60355", "title": "Amherst College", "text": "Private college in Amherst, Massachusetts, US\nAmherst College ( ) is a private liberal arts college in Amherst, Massachusetts, United States. Founded in 1821 as an attempt to relocate Williams College by its then-president Zephaniah Swift Moore, Amherst is the third oldest institution of higher education in Massachusetts. The institution was named after the town, which in turn had been named after Jeffery, Lord Amherst, Commander-in-Chief of British forces of North America during the French and Indian War. Originally established as a men's college, Amherst became coeducational in 1975.\nAmherst is an exclusively undergraduate four-year institution; 1,914 full-time students were enrolled in fall 2024. Admissions are highly selective. Students choose courses from 42 major programs in an open curriculum and are not required to study a core curriculum or fulfill any distribution requirements; students may also design their own interdisciplinary major.\nAmherst competes in the NCAA Division III as a member of the New England Small College Athletic Conference. Amherst has historically had close relationships and rivalries with Williams College and Wesleyan University, which form the Little Three colleges. The college is also a member of the Five College Consortium, which allows its students to attend classes at four other Pioneer Valley institutions: Mount Holyoke College, Smith College, Hampshire College, and the University of Massachusetts Amherst.\nHistory.\nFounding and 19th century.\nIn 1812, funds were raised in Amherst for a secondary school, Amherst Academy; it opened December 1814. The academy incorporated in 1816, and eventually counted among its students Emily Dickinson, Sylvester Graham, and Mary Lyon (founder of Mount Holyoke College). The institution was named after the town, which in turn had been named after Jeffery, Lord Amherst, a veteran from the Seven Years' War and later commanding general of the British forces in North America. On November 18, 1817, a project was adopted at the Academy to raise funds for the free instruction of \"indigent young men of promising talents and hopeful piety, who shall manifest a desire to obtain a liberal education with a sole view to the Christian ministry\". This required a substantial investment from benefactors.\nDuring the fundraising for the project, it became clear that without larger designs, it would be impossible to raise sufficient funds. This led the committee overseeing the project to conclude that a new institution should be created. On August 18, 1818, the Amherst Academy board of trustees accepted this conclusion and began building a new college.\nFounded in 1821, Amherst College developed from Amherst Academy, first established as a secondary school. The college was originally suggested as an alternative to Williams College, which was struggling to stay open. Although Williams survived, Amherst was formed and developed as a distinct institution.\nEstablishment.\nMoore, then President of Williams College, however, still believed that Williamstown was an unsuitable location for a college. When Amherst College was established, he was elected its first president on May 8, 1821. At its opening, Amherst had forty-seven students. Fifteen of these had followed Moore from Williams College. Those fifteen represented about one-third of the total students at Amherst, and about one-fifth of the whole number in the three classes to which they belonged in Williams College. President Moore died on June 29, 1823, and was replaced with a Williams College trustee, Heman Humphrey.\nWilliams alumni are fond of an apocryphal story ascribing the removal of books from the Williams College library to Amherst College. In 1995, Williams president Harry C. Payne declared the story false, but many still nurture the legend.\nIn 1826, Edward Jones became Amherst's first Black graduate.\nAmherst grew quickly, and for two years in the mid-1830s, it was the second largest college in the United States, behind Yale. In 1835, Amherst attempted to create a course of study parallel to the classical liberal arts education. This parallel course focused less on Greek and Latin, instead emphasizing contemporary English, French, and Spanish languages, chemistry, economics, etc. The parallel course did not take hold and replace the classical, however, until the next century.\nAmherst was founded as a non-sectarian institution \"for the classical education of indigent young men of piety and talents for the Christian ministry\" (Tyler, \"A History of Amherst College\"). One of the hallmarks of the new college was its Charity Fund, an early form of financial aid that paid the tuition of poorer students. Although officially non-denominational, Amherst was considered a religiously conservative institution with a strong connection to Calvinism; the Puritans still controlled much of Massachusetts life.\nAs a result, there was considerable debate in the Massachusetts government over whether the new college should receive an official charter from the state. A charter was not granted until February 21, 1825, as reflected on the Amherst seal. Religious conservatism persisted at Amherst until the mid-nineteenth century: students who consumed alcohol or played cards were subject to expulsion. A number of religious revivals were held at Amherst. Toward the end of the nineteenth century, however, the college began a transition toward secularism. This movement was considered to culminate in the 1949 demolition of the college church.\nDevelopment and academic reform.\nAcademic hoods in the United States are traditionally lined with the official colors of the school, in theory so watchers can tell where the hood wearer earned his or her degree. Amherst's hoods are purple (Williams' official color) with a white stripe or chevron, said to signify that Amherst was born of Williams. Amherst records one of the first uses of Latin honors of any American college, dating back to 1881. The college was an all-male school until the late 1960s, when a few female students from nearby schools in the Four-College Consortium (Amherst, Mount Holyoke, Smith, UMass) attended on an experimental basis. In October 1974, the faculty voted in favor of coeducation and in November 1974, the board of trustees voted to admit female students starting in the 1975\u20131976 school year. This was done while John William Ward served as president. In 1975, nine women who were already attending classes as part of an inter-college exchange program were admitted as transfer students. In June 1976, they became the first female graduates of the college.\nThe college established the Black Studies Department in 1969. In 1973, it launched the nation's first undergraduate neuroscience program. In 1983, it established a Department of Asian Languages and Literatures, which was later to become the Department of Asian Languages and Civilizations. \nIn 1984, on-campus fraternities were abolished. The former fraternity buildings, which were owned by the college, were converted into residence halls. The Department of Women's and Gender Studies, which later became the Department of Sexuality, Women's, and Gender Studies, was established in 1987, and the Department of Law, Jurisprudence, and Social Thought in 1993.\nIn March 2013, the faculty adopted an open-access policy. Eight years later, the college ended its practice of legacy admissions and increased financial aid to increase access to low and middle-income students and diversify the college.\nPresidents.\nThe following persons have served as president of Amherst College:\nTable notes:\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCampus.\nAmherst College is located in the town of Amherst in Western Massachusetts. \nAmherst College has a total of 34 residence halls, seven of which are strictly for first year students. Following their first year, sophomores, juniors, and seniors have the choice to live off campus and are offered options of Themed Houses including Arts House, Russian House, and French House, however this option is only available for two years of residence.\nFirst-year students are required to live on campus.\nThe college also owns the Emily Dickinson Museum, operated as a museum about the life and history of poet Emily Dickinson, and the Inn on Boltwood near to the main campus.\nSustainability.\nAmherst College is reducing its energy consumption through a computerized monitoring system for lighting and the use of an efficient cogeneration facility. The cogeneration facility features a gas turbine that generates electricity in addition to steam for heating the campus. Amherst also operates a composting program, in which a portion of the food waste from dining halls is sent to a farmer in Vermont.\nAcademics.\nAmherst College offers 41 fields of study (with 850+ courses) in the sciences, arts, humanities, mathematics and computer sciences, social sciences, foreign languages, classics, and several interdisciplinary fields (including premedical studies) and provides an unusually open curriculum. Students are not required to study a core curriculum or fulfill any distribution requirements and may even design their own unique interdisciplinary major. Freshmen may take advanced courses, and seniors may take introductory ones. Amherst College is accredited by the New England Commission of Higher Education.\nForty-five percent of Amherst students in the class of 2019 were double majors. Amherst College has been the first college to have undergraduate departments in the interdisciplinary fields of American Studies; Law, Jurisprudence and Social Thought; and Neuroscience and has helped to pioneer other interdisciplinary programs, including Asian Languages and Civilizations. Its most popular majors, by 2021 graduates, were:\nMathematics (40)\nEconometrics and Quantitative Economics (34)\nResearch and Experimental Psychology (31)\nPolitical Science and Government (25)\nHistory (22)\nBiology/Biological Sciences (21)\nNeuroscience (19)\nAmerican/U.S. Law/Legal Studies/Jurisprudence (19)\nThe Amherst library is named for long-time faculty member, poet Robert Frost. The student-faculty ratio is 7:1 and 84% of classes have fewer than 30 students.\nNotable faculty members include, among others, modern literature and poetry critic William H. Pritchard, Beowulf translator Howell Chickering, Jewish and Latino studies scholar Ilan Stavans, novelist and legal scholar Lawrence Douglas, physicist Arthur Zajonc, Pulitzer Prize-winning Nikita Khrushchev biographer William Taubman, African art specialist Rowland Abiodun, Natural Law expert Hadley Arkes, Mathematician Daniel Velleman, Biblical scholar Susan Niditch, law and society expert Austin Sarat, Asian American studies scholar and former Director of the Smithsonian Asian Pacific American Center Franklin Odo, and Pulitzer Prize-winning composer Lewis Spratlan, professor emeritus of the music faculty.\nReputation and rankings.\nSince the inception of the \"U.S. News &amp; World Report\" rankings in 1987, Amherst College has been ranked ten times as the first overall among 266 liberal arts colleges in the United States, and in 2022 ranked second, behind Williams. In 2023, Amherst College was ranked as the best liberal arts college and 8th best college or university overall in the United States by The WSJ/College Pulse 2024 Best College Rankings. In 2022, Amherst was ranked as the best liberal arts college in the country by \"The Wall Street Journal\". \"Forbes\" ranked Amherst College as the 24th best college or university in the United States for their 2024\u201325 rankings and the 16th best college or university in the United States in 2021.\n\"Kiplinger's Personal Finance\" places Amherst 11th in its 2016 ranking of best value liberal arts colleges in the United States.\nAmherst ranked 6th in the 2021 \"Washington Monthly\" liberal arts college rankings, which focus on contribution to the public good in three broad categories: social mobility, research, and promoting public service.\nAcademic freedom debate.\nThe writings of Amherst College political science Professor Hadley Arkes about homosexuality led to a dispute in 2013 over whether a college seeking to create a diverse, respectful academic community should speak out when a faculty member disparages community members or should instead remain silent as a way to protect academic freedom. The issue arose when a group of alumni petitioned the college trustees and President Biddy Martin to \"dissociate the institution\" from Arkes's \"divisive and destructive\" views, focusing particularly on his May 2013 comparison of homosexuality to bestiality, pedophilia and necrophilia. The alumni said, \"Amherst College cannot credibly maintain its professed commitment to be an inclusive community as long as it chooses to remain silent while a sitting professor disparages members of its community in media of worldwide circulation and accessibility.\"\nMartin disagreed, citing past debates over the college's position on the Vietnam War and apartheid in South Africa\u2014issues on which the college initially remained silent but eventually took a public position. In such times, she said, colleges should \"avoid taking institutional positions on controversial political matters, except in extraordinary circumstances\" and should simultaneously both \"protect their communities from discrimination and disrespect\" and \"cherish a diversity of viewpoints\".\nFive College Consortium.\nAmherst is a member of the Five Colleges consortium, which allows its students to attend classes at four other Pioneer Valley institutions. These include Mount Holyoke College, Smith College, Hampshire College, and the University of Massachusetts Amherst. In addition to the 850 courses available on campus, Amherst students have an additional 5,300 classes to consider through the Consortium (without paying additional tuition) and access to 8 million library volumes. The Five Colleges are geographically close to one another and are linked by buses that run between the campuses.\nThe Five Colleges share resources and develop common academic programs. Museums10 is a consortium of local art, history and science museums. The Five College Dance Department is one of the largest in the nation. The joint Astronomy department shares use of the Five College Radio Astronomy Observatory, which contributed to work that won the 1993 Nobel Prize in Physics.\nThe Five College Coastal and Marine Sciences Program offers an interdisciplinary curriculum to undergraduates in the Five Colleges.\nAdmissions.\n\"U.S. News &amp; World Report\" classifies Amherst as being \"most selective\" of liberal arts colleges in the United States; the Carnegie Foundation classifies Amherst as one of the \"more selective\" institutions whose first-year students' test scores places these institutions in roughly the top fifth of baccalaureate institutions. For the class first enrolled in fall 2021, Amherst received 13,999 applications and accepted 1,224 (an 8.7% acceptance rate). 514 students ultimately enrolled; 91% were in the top 10% of their high school classes, and the middle 50% scored between 1440 and 1540 on the SAT and between 32 and 35 on the ACT. 38 states and 23 countries were reflected among the first-year class, 55% received financial aid and 11% were first-generation college students. In addition, 16 transfer students enrolled.\nDespite its high cost of attendance \u2013 comprehensive tuition, room, and board fee for the 2022\u201323 academic year was $80,250 \u2013 Amherst College meets the full demonstrated need of every admitted student. Sixty percent of current students receive scholarship aid, and the average financial aid package award amounts to $62,071; college expenditures are approximately $109,000 per student each year.\nIn July 2007, Amherst announced that grants would replace loans in all financial aid packages beginning in the 2008\u201309 academic year. Amherst had already been the first school to eliminate loans for low-income students, and with this announcement it joined Princeton University, Cornell University and Davidson College, then the only colleges to eliminate loans from need-based financial aid packages. Increased rates of admission of highly qualified lower income students has resulted in greater equality of opportunity at Amherst than is usual at elite American colleges.\nIn the 2008\u20132009 academic year, Amherst College also extended its need-blind admission policy to international applicants. In 2021, it also eliminated preferences for students whose parents are alumni (\"legacies\").\nStudent life.\nAmherst's resources, faculty, and academic life allow the college to enroll students with a range of talents, interests, and commitments. Students represent 48 states, the District of Columbia, Puerto Rico, and sixty-six countries. The median family income of Amherst students is $158,200, with 51% of students coming from the top 10% highest-earning families and 24% from the bottom 60%. Ninety-eight percent of students live on campus. Ninety-eight percent of Amherst freshmen enrolled in Fall 2020 returned for their sophomore year; ninety-two percent of the most recent cohort graduated within six years. There are more than 200 student groups at Amherst. More than a third of the student body are members of a varsity athletics team.\nStudents pursue their interests through student-led organizations funded by a student fee and distributed by the student government, including a variety of cultural and religious groups, publications, fine and performing arts and political advocacy and service groups. Groups include a medieval sword-fighting club, a knitting club, and a club devoted to random acts of kindness, among others. Community service groups and opportunities (locally\u2014through the Center for Community Engagement, nationally, and internationally) have been a priority at Amherst and for former President Anthony Marx, who helped start a secondary school for black students in apartheid South Africa.\nOne of the longstanding traditions at the college involves the \"Sabrina\" statue. Even year and odd year classes battle for possession of the historic statue, often engaging in elaborate pranks in the process.\nSexual assault.\nIn 2012, President Biddy Martin began a community-wide review of the sexual misconduct and disciplinary policies at the college. This review was sparked by several factors, including an underground fraternity's T-shirt design that critics alleged was misogynist and an essay by Angie Epifano published in \"The Amherst Student\", wherein she accused the college of inappropriate handling of a case of sexual assault. In January 2013, a college committee published a report noting Amherst's rate of sexual assault as similar to other colleges and universities, and making recommendations to address the problem. In May 2014, the Amherst board of trustees banned students from joining any underground or off-campus fraternity.\nAfter a complaint was filed by Epifano and an anonymous former student in November 2013, the US Department of Education opened an investigation into the college's handling of sexual violence and potential violations of Title IX. In May 2014, the Department of Education announced a list of 55 colleges and universities (including Amherst) currently under investigation.\nA report from Amherst College stated that 2009 to 2011, Amherst reported 35 instances of \"forcible sex offenses\", a term that encompasses rape, attempted rape, and lesser forms of sexual contact.\nIn 2022, in response to the anonymous sharing of sexual assault experiences at Amherst College on the Instagram account https://, then President Biddy Martin announced the launch of a new comprehensive review of the issue of sexual misconduct and assault on campus. According to the 2023 NECHE Interim Crediting Report listening sessions and interviews were conducted, and a website for anonymous reporting of concerns was created. The NECHE interim report also suggested that the review was expected to be published in Spring 2023. However currently there has been no update or public disclosure of the 2022 review.\nMascot.\nIn the second decade of the 21st century, the original unofficial mascot of Amherst College, Lord Jeffery Amherst, became a cause of concern in the Amherst community. Many sought to separate the school from the problematic legacy of Lord Jeffery Amherst, in particular his advocacy of the use of biological warfare against Native Americans.\nIn May 2014, after a wild moose found its way onto the Amherst College campus and into the backyard of the house of the college president, students organized a Facebook campaign to change the mascot of the school to a moose. The page grew rapidly in popularity, receiving over 900 \"likes\" in under two weeks, and inspiring both a Twitter and Tumblr account for the newly proposed mascot. At the Commencement ceremony for the class of 2014, the moose mascot was mentioned by Biddy Martin in her address, and the Dining Hall served Moose Tracks ice cream in front of an ice sculpture of a moose.\nIn February 2015, discussion of a mascot change continued when the editorial board of the \"Amherst Student\", the college's official student-run newspaper, came out in favor of \"the moose-scot\". In November 2015 the student body and the faculty overwhelmingly voted to vacate the mascot. That same month, several hundred students who staged a sit-in protest against racism at the college library included among their demands a call for the college to cease use of the Lord Jeff mascot. The decision to drop the mascot was made official by the college's trustees on January 26, 2016.\nIn April 2017, Amherst announced that their official mascot would be the mammoth. Mammoths beat the other finalists \"Valley Hawks\", \"Purple and White\", \"Wolves\", and \"Fighting Poets\" in a ranked-choice election process. The mammoth is linked to Amherst due to the long-standing presence of a Columbian Mammoth skeleton on display in the Beneski Museum of Natural History on campus, which dated back to the 1920s excavation of the skeleton by Amherst professor Frederic Brewster Loomis in Melbourne, Florida.\nAthletics.\nAmherst participates in the NCAA's Division III, the Eastern College Athletic Conference, and the New England Small College Athletic Conference, which includes Bates, Bowdoin, Colby, Connecticut College, Hamilton, Middlebury, Trinity, Tufts, Wesleyan, and Williams. Amherst is also one of the \"Little Three\", along with Williams and Wesleyan. A Little Three champion is informally recognized by most teams based on the head-to-head records of the three schools, but three-way competitions are held in some of the sports.\nAmherst claims its athletics program as the oldest in the nation, pointing to its compulsory physical fitness regimen put in place in 1860 (the mandate that all students participate in sports or pursue physical education has been discontinued). Amherst and Williams played the first college baseball game July 2, 1859.\nAmherst's growing athletics program has been the subject of controversy in recent years due to dramatic contrasts between the racial and socioeconomic makeup of its student athletes and the rest of its student body, the clustering of athletes in particular academic departments, and a perceived \"divide\" on campus between varsity athletes and other students. Athletic skill plays a factor in the admissions decisions of between 28% and 35% of each incoming class.\nAmherst fields several club athletic teams, including ultimate, soccer, crew, rugby union, water polo, equestrian, mountain biking, fencing, sailing and skiing. Intramural sports include soccer, tennis, golf, basketball, volleyball and softball.\nThe sport of Ultimate was started and named at Amherst College in the mid-1960s by Jared Kass.\nAlumni.\nAlthough a relatively small college, Amherst has many accomplished alumni, including Nobel, Crafoord Prize and Lasker Award laureates, MacArthur Fellowship and Pulitzer Prize winners, National Medal of Science and National Book Award recipients, and Academy, Tony, Grammy and Emmy Award winners; a U.S. President, the current Sovereign Prince of Monaco, two Prime Ministers and one Foreign Minister of Greece, a President of Kenya, a President of El Salvador, a Chief Justice of the United States, three Speakers of the U.S. House of Representatives, a U.S. Poet Laureate, the legal architect of \"Brown v. Board of Education\" and the inventor of the blood bank; leaders in science, religion, politics, the Peace Corps, medicine, law, education, communications, and business; and acclaimed actors, architects, artists, astronauts, engineers, human rights activists, inventors, musicians, philanthropists, and writers.\nAmong its alumni, faculty and affiliates are six Nobel Prize laureates and twenty Rhodes Scholars. President Calvin Coolidge, Chief Justice Harlan F. Stone, and other notable writers, academics, politicians, entertainers, businesspeople, and activists have been graduates as well.\nThere are approximately 23,000 living alumni, of whom about 45% make a gift to Amherst each year\u2014one of the highest alumni participation rates of any college in the country.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60356", "revid": "46067550", "url": "https://en.wikipedia.org/wiki?curid=60356", "title": "Albany, California", "text": "City in California, United States\nAlbany ( ) is a city on the east shore of San Francisco Bay in northwestern Alameda County, California, United States. The population was 20,271 at the 2020 United States census.\nHistory.\nIn 1908, a group of local women protested the dumping of Berkeley garbage in their community. Armed with two shotguns and a twenty-two-caliber rifle, they confronted the drivers of the wagons near what is now the corner of San Pablo Avenue and Buchanan Street. The women told the drivers of the horse-drawn garbage wagons to go home, which they did quickly and without complaint. Shortly thereafter, the residents of the town voted to incorporate as the City of Ocean View.\nIn 1909, voters changed the name of the city, primarily to distinguish the city from the adjacent section of Berkeley which had previously been named Ocean View. On a vote of 38 to 6 the city was renamed in honor of Albany, New York, the birthplace of the city's first mayor, Frank Roberts.\nThe Albany Sauna is one of the oldest Finnish-style saunas open to the public in North America. Built in 1934 by Finnish-American Henry Walter Lundgren (a founding member of the Finnish Lodge in West Berkeley), the original furnace and rooms have been maintained.\nAlbany has a history of real estate discrimination, which made it difficult for non-white buyers to acquire property and build homes in Albany.\nGeography.\nAccording to the United States Census Bureau, the city has a total area of , of which is land and (67.28%) is water.\nThe principal shopping street in Albany is Solano Avenue, which cuts across the city from west to east. Another important street is San Pablo Avenue, which travels from north to south.\nAlbany is a small city located on the eastern shore of San Francisco Bay, bordering the city of Berkeley to the south and east, and the Contra Costa County cities of El Cerrito and Richmond to the north. Albany's northern and southern borders are defined by two creeks, Codornices Creek on the south and Cerrito Creek on the north. Cerrito Creek takes its name from \"El Cerrito de San Antonio\", now known as Albany Hill. The hill's unusual location near the bay shore makes it a prominent landmark in the East Bay. The rest of the city is relatively flat by Bay Area standards, except for a small area near the base of the Berkeley Hills.\nAlbany's waterfront has undergone significant man-made changes; the most prominent landform is now the Albany Bulb, a former garbage landfill jutting out into San Francisco Bay. The bulb was the site of a small art colony and shanty town until it was cleared to turn the area into part of the new Eastshore State Park.\nUniversity Village, a housing unit of the University of California Berkeley, is located in Albany.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\nThe 2020 United States census reported that Albany had a population of 20,271. The population density was . The racial makeup of Albany was 46.6% White, 3.5% African American, 0.4% Native American, 30.5% Asian, 0.1% Pacific Islander, 5.6% from other races, and 13.3% from two or more races. Hispanic or Latino of any race were 13.1% of the population.\nThe Census reported that 93.1% of the population lived in households, 6.8% lived in non-institutionalized group quarters, and 0.0% were institutionalized.\nThere were 7,493 households, out of which 38.4% included children under the age of 18, 52.4% were married-couple households, 6.7% were cohabiting couple households, 26.7% had a female householder with no partner present, and 14.2% had a male householder with no partner present. 22.9% of households were one person, and 11.3% were one person aged 65 or older. The average household size was 2.52. There were 5,126 families (68.4% of all households).\nThe age distribution was 21.6% under the age of 18, 11.7% aged 18 to 24, 28.6% aged 25 to 44, 23.0% aged 45 to 64, and 15.0% who were 65years of age or older. The median age was 36.3years. For every 100 females, there were 91.0 males.\nThere were 7,907 housing units at an average density of , of which 7,493 (94.8%) were occupied. Of these, 48.9% were owner-occupied, and 51.1% were occupied by renters.\nIn 2023, the US Census Bureau estimated that 26.1% of the population were foreign-born. Of all people aged 5 or older, 62.5% spoke only English at home, 7.9% spoke Spanish, 7.9% spoke other Indo-European languages, 21.3% spoke Asian or Pacific Islander languages, and 0.4% spoke other languages. Of those aged 25 or older, 97.4% were high school graduates and 76.4% had a bachelor's degree.\nThe median household income was $135,927, and the per capita income was $72,518. About 6.1% of families and 8.2% of the population were below the poverty line.\nThrough the early 1940's Albany \"remained closed to African Americans.\" The Black population of Albany in 1940 was 3 persons. Between 1950 and 1960, the Black population of Albany fell 95% from 1778 to 75.\nTransportation.\nAlbany is served by AC Transit, BART (North Berkeley, El Cerrito Plaza), and bus shuttles operated by Lawrence Berkeley National Laboratory. Interstate 80 runs along the bay shoreline, with access to local Albany via Buchanan street. San Pablo Avenue, managed by Caltrans, is the primary arterial roadway running from north to south through Albany, parallel to the San Francisco Bay. Other notable roadways in Albany include Solano Avenue, the city's primary commercial street, and Marin Avenue, both of which run from east to west. West of San Pablo Avenue, Marin Avenue continues on to Interstate 80 as Buchanan street.\nActive Transportation in Albany.\nThe Ohlone Greenway, a mixed use pedestrian and cycling facility, runs north and south through Albany from El Cerrito Plaza towards North Berkeley BART station. Many streets in Albany have been treated with fixtures that support the safety and comfort of pedestrians and cyclists, such as Curb extensions, Pedestrian islands, Raised crosswalks, and Bicycle boulevards with traffic diversion features. A local nonprofit, https:// has donated a number of bicycle parking racks around Albany, and frequently advises the city on its https:// As of April 2025, the city is in the process of updating its active transportation plan, which was last updated in 2019.\nEconomy.\nThe major retail and business areas in Albany are Solano Avenue, which is a pedestrian-oriented street lined with mainly small shops, restaurants, and services; San Pablo Avenue, which is more automobile-oriented; and an area near the Eastshore Freeway.\nIn 2006 voters approved of measure D which allows one medical cannabis dispensary in the town in addition to measure C to build a new emergency operations center with \"sustainable features\", an addition to the civic center of Albany.\nAlbany is the site of Golden Gate Fields, which was the only horse racing track in the Bay Area until it closed in June 2024.\nReal estate prices have been rising steeply in recent years. The median price of a single family home and condo in Census 2000, June 2007, November 2009, July 2011, August 2013 and August 2014 were $334,800, $687,500, $610,000, $590,000, $625,750 and $820,050 respectively.\nPolitics.\nAccording to the California Secretary of State, as of February 10, 2019, Albany has 11,344 registered voters. Of those, 7,489 (66%) are registered Democrats, 512 (4.5%) are registered Republicans, and 2,917 (25.7%) have declined to state a political party.\nIn 1966, Albany was home to a John Birch Society bookstore known as the American Opinion Library. On July 30, 1968, the John Birch society Truth About Civil Turmoil committee hosted an event at the Albany Veterans Memorial Building which included a speech by a former klansman, Delmar Dennis.\nOn March 26, 2024, the Albany City Council passed a resolution supporting an immediate ceasefire in Gaza.\nOn December 9, 2024, the city of Albany appointed their first ever Latino Mayor, Robin Lopez, who also happens to be a Doctoral Candidate at UC Berkeley in Environmental Science. The city of Albany conducts what is known as a rotating mayorship of elected council members. Previously, Robin Lopez served as the Vice Mayor of Albany, under past Mayor John Miki. Robin Lopez and John Miki campaigned together in 2022, when both were elected to city council. In that same year, a vacant council seat was filled by Jennifer Hansen-Romero.\nTop employers.\nAccording to Albany's 2013 Comprehensive Annual Financial Report, the top employers in the city were:\nEducation.\nPublic schools in Albany are operated by the Albany Unified School District, a special-purpose district whose borders match the city's. The school district operates three elementary schools (Marin Elementary School, Ocean View Elementary School and Cornell Elementary School), one middle school (Albany Middle School), one traditional high school (Albany High School), and one continuation high school (MacGregor High School), in addition to the Albany Children's Center. Albany High School is known as one of the best public schools of the San Francisco Bay Area for its academic excellence. The high school had a graduation rate of 92.1%, according to the 2009\u201310 School Accountability Report Card for the prior academic year.\nThere are two private high schools in Albany: \"Tilden Preparatory School\" (formerly School for Independent Learners) on Solano Avenue and St. Mary's College High School, whose campus straddles the border with Berkeley, CA.\nThe University of California, Berkeley owns a large student housing complex in Albany, University Village, which is primarily used for family housing.\nArts, culture, and recreation.\nThe Solano Avenue Stroll, an annual street festival held on Solano Avenue in Albany and Berkeley, attracts more than 250,000 visitors on the second Sunday of September. The event was started in 1975 by \"The Iris\" store owner and Solano Avenue Association founder Ira Klein as a \"thank you party\" from Solano Avenue business owners to customers. The Library of Congress designated the Solano Stroll as a \"National Local Legacy\" in 2001.\nAlbany has both the locale and the title for one of the best-known poems in language poetry, by former long-time Albany resident, poet Ron Silliman.\nAlbany is home to Golden Gate Fields, the only commercial racetrack in the Bay Area, as well as the Eastshore State Park which skirts the San Francisco Bay, and the Albany Bulb.\nAlbany has a school music program. High school music groups, both instrumental and choral, have performed at the CMEA, Reno Jazz, and other festivals. The Albany High School Jazz Band was also accepted at the Essentially Ellington festival at the Lincoln Center in 2010. Albany was one of 15 schools accepted into the festival.\nAlbany Strollers &amp; Rollers is a volunteer group dedicated to service and advocacy for bicycling and walking.\nFriends of Five Creeks is an all-volunteer group working hands-on for clean water and healthy watersheds.\nThe Albany Community Center was designed by architect Robert Marquis and opened in 1994. It houses the Albany Public Library on one side and the Community Center on the other, and is host to many different community events and cultural activities.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60357", "revid": "918295324", "url": "https://en.wikipedia.org/wiki?curid=60357", "title": "Evans Hall", "text": "Evans Hall is a common name for buildings on college and university campuses. Colleges which have (or had) an Evans Hall include:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "60358", "revid": "49402000", "url": "https://en.wikipedia.org/wiki?curid=60358", "title": "Internal rate of return", "text": "Method of calculating an investment's rate of return\nInternal rate of return (IRR) is a method of calculating an investment's rate of return. The term \"internal\" refers to the fact that the calculation excludes external factors, such as the risk-free rate, inflation, the cost of capital, or financial risk.\nThe method may be applied either ex-post or ex-ante. Applied ex-ante, the IRR is an estimate of a future annual rate of return. Applied ex-post, it measures the actual achieved investment return of a historical investment.\nIt is also called the discounted cash flow rate of return (DCFROR) or yield rate.\nDefinition (IRR).\nThe IRR of an investment or project is the \"annualized effective compounded return rate\" or rate of return that sets the net present value (NPV) of all cash flows (both positive and negative) from the investment equal to zero. Equivalently, it is the interest rate at which the net present value of the future cash flows is equal to the initial investment, and it is also the interest rate at which the total present value of costs (negative cash flows) equals the total present value of the benefits (positive cash flows).\nIRR represents the return on investment achieved when a project reaches its breakeven point, meaning that the project is only marginally justified as valuable. When NPV demonstrates a positive value, it indicates that the project is expected to generate value. Conversely, if NPV shows a negative value, the project is expected to lose value. In essence, IRR signifies the rate of return attained when the NPV of the project reaches a neutral state, precisely at the point where NPV breaks even.\nIRR accounts for the time preference of money and investments. A given return on investment received at a given time is worth more than the same return received at a later time, so the latter would yield a lower IRR than the former, if all other factors are equal. A fixed income investment in which money is deposited once, interest on this deposit is paid to the investor at a specified interest rate every time period, and the original deposit neither increases nor decreases, would have an IRR equal to the specified interest rate. An investment which has the same total returns as the preceding investment, but delays returns for one or more time periods, would have a lower IRR.\nUses.\nSavings and loans.\nIn the context of savings and loans, the IRR is also called the effective interest rate.\nProfitability of an investment.\nThe IRR is an indicator of the profitability, efficiency, quality, or yield of an investment. This is in contrast with the NPV, which is an indicator of the net value or magnitude added by making an investment.\nTo maximize the value of a business, an investment should be made only if its profitability, as measured by the internal rate of return, is greater than a minimum acceptable rate of return. If the estimated IRR of a project or investment - for example, the construction of a new factory - exceeds the firm's cost of capital invested in that project, the investment is profitable. If the estimated IRR is less than the cost of capital, the proposed project should not be undertaken.\nThe selection of investments may be subject to budget constraints. There may be mutually exclusive competing projects, or limits on a firm's ability to manage multiple projects. For these reasons, corporations use IRR in capital budgeting to compare the profitability of a set of alternative capital projects. For example, a corporation will compare an investment in a new plant versus an extension of an existing plant based on the IRR of each project. To maximize returns, the higher a project's IRR, the more desirable it is to undertake the project.\nThere are at least two different ways to measure the IRR for an investment: the project IRR and the equity IRR. The project IRR assumes that the cash flows directly benefit the project, whereas equity IRR considers the returns for the shareholders of the company after the debt has been serviced. \nEven though IRR is one of the most popular metrics used to test the viability of an investment and compare returns of alternative projects, looking at the IRR in isolation might not be the best approach for an investment decision. Certain assumptions made during IRR calculations are not always applicable to the investment. In particular, IRR assumes that the project will have either no interim cash flows or the interim cash flows are reinvested into the project which is not always the case. This discrepancy leads to overestimation of the rate of return which might be an incorrect representation of the value of the project.\nFixed income.\nIRR is used to evaluate investments in fixed income securities, using metrics such as the yield to maturity and yield to call.\nLiabilities.\nBoth IRR and net present value can be applied to liabilities as well as investments. For a liability, a lower IRR is preferable to a higher one.\nCapital management.\nCorporations use IRR to evaluate share issues and stock buyback programs. A share repurchase proceeds if returning capital to shareholders has a higher IRR than candidate capital investment projects or acquisition projects at current market prices. Funding new projects by raising new debt may also involve measuring the cost of the new debt in terms of the yield to maturity (internal rate of return).\nPrivate equity.\nIRR is also used for private equity, from the limited partners' perspective, as a measure of the general partner's performance as investment manager. This is because it is the general partner who controls the cash flows, including the limited partners' draw-downs of committed capital.\nCalculation.\nGiven a collection of pairs (time, cash flow) representing a project, the NPV is a function of the rate of return. The internal rate of return is a rate for which this function is zero, i.e. the internal rate of return is a solution to the equation NPV = 0 (assuming no arbitrage conditions exist).\nGiven the (period, cash flow) pairs (formula_1, formula_2) where formula_1 is a non-negative integer, the total number of periods formula_4, and the formula_5, (net present value); the internal rate of return is given by formula_6 in:\n formula_7\nThis rational polynomial can be converted to an ordinary polynomial having the same roots by substituting \"g\" (gain) for formula_8 and multiplying by formula_9 to yield the equivalent but simpler condition\n formula_10\nThe possible IRR's are the real values of \"r\" satisfying the first condition, and 1 less than the real roots of the second condition (that is, formula_11 for each root \"g\"). Note that in both formulas, formula_12 is the negation of the initial investment at the start of the project while formula_13 is the cash value of the project at the end, equivalently the cash withdrawn if the project were to be liquidated and paid out so as to reduce the value of the project to zero. In the second condition formula_12 is the leading coefficient of the ordinary polynomial in \"g\" while formula_13 is the constant term.\nThe period formula_1 is usually given in years, but the calculation may be made simpler if formula_6 is calculated using the period in which the majority of the problem is defined (e.g., using months if most of the cash flows occur at monthly intervals) and converted to a yearly period thereafter.\nAny fixed time can be used in place of the present (e.g., the end of one interval of an annuity); the value obtained is zero if and only if the NPV is zero.\nIn the case that the cash flows are random variables, such as in the case of a life annuity, the expected values are put into the above formula.\nOften, the value of formula_6 that satisfies the above equation cannot be found analytically. In this case, numerical methods or graphical methods must be used.\nExample.\nIf an investment may be given by the sequence of cash flows\nthen the IRR formula_6 is given by\n formula_20\nIn this case, the answer is 5.96% (in the calculation, that is, r = 0.0596).\nNumerical solution.\nSince the above is a manifestation of the general problem of finding the roots of the equation formula_21, there are many numerical methods that can be used to estimate formula_6. For example, using the secant method, formula_6 is given by\n formula_24\nwhere formula_25 is considered the formula_1th approximation of the IRR.\nThis formula_6 can be found to an arbitrary degree of accuracy. Different accounting packages may provide functions for different accuracy levels. For example, Microsoft Excel and Google Sheets have built-in functions to calculate IRR for both fixed and variable time-intervals; \"=IRR(...)\" and \"=XIRR(...)\".\nThe convergence behavior is as follows:\nHaving formula_35 when formula_36 or formula_37 when formula_38 may speed up convergence of formula_25 to formula_6.\nNumerical solution for single outflow and multiple inflows.\nOf particular interest is the case where the stream of payments consists of a single outflow, followed by multiple inflows occurring at equal periods. In the above notation, this corresponds to:\n formula_41\nIn this case the NPV of the payment stream is a convex, strictly decreasing function of interest rate. There is always a single unique solution for IRR.\nGiven two estimates formula_42 and formula_43 for IRR, the secant method equation (see above) with formula_44 always produces an improved estimate formula_45. This is sometimes referred to as the Hit and Trial (or Trial and Error) method. More accurate interpolation formulas can also be obtained: for instance the secant formula with correction\n formula_46\n(which is most accurate when formula_47) has been shown to be almost 10 times more accurate than the secant formula for a wide range of interest rates and initial guesses. For example, using the stream of payments {\u22124000, 1200, 1410, 1875, 1050} and initial guesses formula_48 and formula_49 the secant formula with correction gives an IRR estimate of 14.2% (0.7% error) as compared to IRR = 13.2% (7% error) from the secant method.\nIf applied iteratively, either the secant method or the improved formula always converges to the correct solution.\nBoth the secant method and the improved formula rely on initial guesses for IRR. The following initial guesses may be used:\nformula_50\nformula_51\nwhere\nformula_52\nformula_53\nHere, formula_54 refers to the NPV of the inflows only (that is, set formula_55 and compute NPV).\nExact dates of cash flows.\nA cash flow formula_2 may occur at any time formula_57 years after the beginning of the project. formula_57 may not be a whole number. The cash flow should still be discounted by a factor formula_59. And the formula is\n formula_60\nFor numerical solution we can use Newton's method\n formula_61\nwhere formula_62 is the derivative of formula_5 and given by\n formula_64\nAn initial value formula_42 can be given by\n formula_66\nProblems with use.\nComparison with NPV investment selection criterion.\nAs a tool applied to making an investment decision on whether a project adds value or not, comparing the IRR of a single project with the required rate of return, in isolation from any other projects, is equivalent to the NPV method. If the appropriate IRR (if such can be found correctly) is greater than the required rate of return, using the required rate of return to discount cash flows to their present value, the NPV of that project will be positive, and vice versa. However, using IRR to sort projects in order of preference does not result in the same order as using NPV.\nMaximizing NPV.\nOne possible investment objective is to maximize the total NPV of projects.\nWhen the objective is to maximize total value, the calculated IRR should not be used to choose between mutually exclusive projects. In cases where one project has a higher initial investment than a second mutually exclusive project, the first project may have a lower IRR (expected return), but a higher NPV (increase in shareholders' wealth) and should thus be accepted over the second project (assuming no capital constraints).\nWhen the objective is to maximize total value, IRR should not be used to compare projects of different duration. For example, the NPV added by a project with longer duration but lower IRR could be greater than that of a project of similar size, in terms of total net cash flows, but with shorter duration and higher IRR.\nPractitioner preference for IRR over NPV.\nDespite a strong academic preference for NPV, surveys indicate that executives prefer IRR over NPV. Apparently, managers prefer to compare investments of different sizes in terms of forecast investment performance, using IRR, rather than maximize value to the firm, in terms of NPV. This preference makes a difference when comparing mutually exclusive projects.\nMaximizing long-term return.\nMaximizing total value is not the only conceivable possible investment objective. An alternative objective would for example be to maximize long-term return. Such an objective would rationally lead to accepting first those new projects within the capital budget which have the highest IRR, because adding such projects would tend to maximize overall long-term return.\nExample.\nTo see this, consider two investors, Max Value and Max Return. Max Value wishes her net worth to grow as large as possible, and will invest every last cent available to achieve this, whereas Max Return wants to maximize his rate of return over the long term, and would prefer to choose projects with smaller capital outlay but higher returns. Max Value and Max Return can each raise \"up to\" 100,000 US dollars from their bank at an annual interest rate of 10 percent paid at the end of the year.\nInvestors Max Value and Max Return are presented with two possible projects to invest in, called Big-Is-Best and Small-Is-Beautiful. Big-Is-Best requires a capital investment of 100,000 US dollars today, and the lucky investor will be repaid 132,000 US dollars in a year's time. Small-Is-Beautiful only requires 10,000 US dollars capital to be invested today, and will repay the investor 13,750 US dollars in a year's time.\nSolution.\nThe cost of capital for both investors is 10 percent.\nBoth Big-Is-Best and Small-Is-Beautiful have positive NPVs:\nformula_67\nformula_68\nand the IRR of each is (of course) greater than the cost of capital:\nformula_69\nso the IRR of Big-Is-Best is 32 percent, and\nformula_70\nso the IRR of Small-Is-Beautiful is 37.5 percent.\nBoth investments would be acceptable to both investors, but the twist in the tale is that these are mutually exclusive projects for both investors, because their capital budget is limited to 100,000 US dollars. How will the investors choose rationally between the two?\nThe happy outcome is that Max Value chooses Big-Is-Best, which has the higher NPV of 20,000 US dollars, over Small-Is-Beautiful, which only has a modest NPV of 2,500, whereas Max Return chooses Small-Is-Beautiful, for its superior 37.5 percent return, over the attractive (but not as attractive) return of 32 percent offered on Big-Is-Best. So there is no squabbling over who gets which project, they are each happy to choose different projects.\nHow can this be rational for both investors? The answer lies in the fact that the investors do not have to invest the full 100,000 US dollars. Max Return is content to invest only 10,000 US dollars for now. After all, Max Return may rationalize the outcome by thinking that maybe tomorrow there will be new opportunities available to invest the remaining 90,000 US dollars the bank is willing to lend Max Return, at even higher IRRs. Even if only seven more projects come along which are identical to Small-Is-Beautiful, Max Return would be able to match the NPV of Big-Is-Best, on a total investment of only 80,000 US dollars, with 20,000 US dollars left in the budget to spare for truly unmissable opportunities. Max Value is also happy, because she has filled her capital budget straight away, and decides she can take the rest of the year off investing.\nMultiple IRRs.\nWhen the sign of the cash flows changes more than once, for example when positive cash flows are followed by negative ones and then by positive ones (+ + \u2212 \u2212 \u2212 +), the IRR may have multiple real values. In a series of cash flows like (\u221210, 21, \u221211), one initially invests money, so a high rate of return is best, but then receives more than one possesses, so then one owes money, so now a low rate of return is best. In this case, it is not even clear whether a high or a low IRR is better.\nThere may even be multiple real IRRs for a single project, like in the example 0% as well as 10%. Examples of this type of project are strip mines and nuclear power plants, where there is usually a large cash outflow at the end of the project.\nThe IRR satisfies a polynomial equation. Sturm's theorem can be used to determine if that equation has a unique real solution. In general the IRR equation cannot be solved analytically but only by iteration.\nWith multiple internal rates of return, the IRR approach can still be interpreted in a way that is consistent with the present value approach if the underlying investment stream is correctly identified as net investment or net borrowing.\nSee for a way of identifying the relevant IRR from a set of multiple IRR solutions.\nLimitations in the context of private equity.\nIn the context of survivorship bias which makes the high IRR of large private equity firms a poor representation of the average, according to Ludovic Phalippou,\n\"...a headline figure that is often shown prominently as a rate of return in presentations and documents is, in fact, an IRR. IRRs are not rates of return. Something large PE firms have in common is that their early investments did well. These early winners have set up those firms' since-inception IRR at an artificially sticky and high level. The mathematics of IRR means that their IRRs will stay at this level forever, as long as the firms avoid major disasters. In passing, this generates some stark injustice because it is easier to game IRRs on LBOs in Western countries than in any other PE investments. That means that the rest of the PE industry (e.g. emerging market growth capital) is sentenced to look relatively bad forever, for no reason other than the use of a game-able performance metric.\"\nAlso,\n\"Another problem with the presentation of pension fund performance is that for PE, time-weighted returns...are not the most pertinent measure of performance. Asking how much pension funds gave and got back in dollar terms from PE, i.e. MoM, would be more pertinent. I went through the largest 15 funds websites to collect information on their performance. Few of them post their PE fund returns online. In most cases, they post information on their past performance in PE, but nothing that enables any meaningful benchmarking. \"E.g.\", CalSTRS [a California public pension fund] provide only the net IRR for each fund they invest in. As IRR is often misleading and can never be aggregated or compared to stock-market returns, such information is basically useless for gauging performance.\"\nModified internal rate of return (MIRR).\nModified Internal Rate of Return (MIRR) considers cost of capital, and is intended to provide a better indication of a project's probable return. It applies a discount rate for borrowing cash, and the IRR is calculated for the investment cash flows. This applies in real life for example when a customer makes a deposit before a specific machine is built.\nWhen a project has multiple IRRs it may be more convenient to compute the IRR of the project with the benefits reinvested. Accordingly, MIRR is used, which has an assumed reinvestment rate, usually equal to the project's cost of capital.\nAverage internal rate of return (AIRR).\nMagni (2010) introduced a new approach, named AIRR approach, based on the intuitive notion of mean, that solves the problems of the IRR. However, the above-mentioned difficulties are only some of the many flaws incurred by the IRR. Magni (2013) provided a detailed list of 18 flaws of the IRR and showed how the AIRR approach does not incur the IRR problems.\nMathematics.\nMathematically, the value of the investment is assumed to undergo exponential growth or decay according to some rate of return (any value greater than \u2212100%), with discontinuities for cash flows, and the IRR of a series of cash flows is defined as any rate of return that results in a NPV of zero (or equivalently, a rate of return that results in the correct value of zero after the last cash flow).\nThus, internal rate(s) of return follow from the NPV as a function of the rate of return. This function is continuous. Towards a rate of return of \u2212100% the NPV approaches infinity with the sign of the last cash flow, and towards a rate of return of positive infinity the NPV approaches the first cash flow (the one at the present). Therefore, if the first and last cash flow have a different sign there exists an IRR. Examples of time series without an IRR:\nIn the case of a series of exclusively negative cash flows followed by a series of exclusively positive ones, the resulting function of the rate of return is continuous and monotonically decreasing from positive infinity (when the rate of return approaches \u2212100%) to the value of the first cash flow (when the rate of return approaches infinity), so there is a unique rate of return for which it is zero. Hence, the IRR is also unique (and equal). Although the NPV-function itself is not necessarily monotonically decreasing on its whole domain, it \"is\" at the IRR.\nSimilarly, in the case of a series of exclusively positive cash flows followed by a series of exclusively negative ones the IRR is also unique.\nFinally, by Descartes' rule of signs, the number of internal rates of return can never be more than the number of changes in sign of cash flow.\nThe reinvestment debate.\nIt is often stated that IRR assumes reinvestment of all cash flows until the very end of the project. This assertion has been a matter of debate in the literature.\nSources stating that there is such a hidden assumption have been cited below. Other sources have argued that there is no IRR reinvestment assumption.\nTo understand the source of this confusion let's consider an example with a 3-year bond of $1000 face value and coupon rate of 5% (or $50).\nAs can be seen, although the total return is different the IRR is still the same. Put in other words, IRR is neutral to reinvestments made at the same rate. No matter whether the cash is taken out early or reinvested at the same rate and taken out late - the rate is the same.\nTo understand why, we need to calculate the present value (PV) of our future cash flows, effectively reproducing IRR calculations manually:\nIn personal finance.\nThe IRR can be used to measure the money-weighted performance of financial investments such as an\nindividual investor's brokerage account. For this scenario, an \nequivalent, \nmore intuitive definition of the IRR is, \"The IRR is the annual interest rate of the fixed rate account (like a somewhat idealized savings account)\nwhich, when subjected to the same deposits and withdrawals as the actual investment, has the same ending balance as the actual investment.\" \nThis fixed rate account is also called the \"replicating fixed rate account\" for the investment. There are examples where \nthe replicating fixed rate account encounters negative balances despite the fact that the actual investment did not. \nIn those cases, the IRR calculation assumes that the same interest rate that is paid on positive balances is charged on \nnegative balances. It has been shown that this way of charging interest is the root cause of the IRR's multiple solutions \nproblem. If the model is modified so that, as is the case in real life, an externally supplied cost of borrowing \n(possibly varying over time) is charged on negative balances, the multiple solutions issue \ndisappears. The resulting rate is \ncalled the \"fixed rate equivalent\" (\"FREQ\").\nUnannualized internal rate of return.\nIn the context of investment performance measurement, there is sometimes ambiguity in terminology between the periodic rate of return, such as the IRR as defined above, and a holding period return. The term \"internal rate of return\" (\"IRR)\" or \"Since Inception Internal Rate of Return\" (\"SI-IRR)\" is in some contexts used to refer to the unannualized return over the period, particularly for periods of less than a year.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60359", "revid": "332930", "url": "https://en.wikipedia.org/wiki?curid=60359", "title": "Benthos", "text": "Community of organisms that live in the benthic zone\nBenthos (from grc \" ' ()\"\u00a0'the depths [of the sea]'), also known as benthon, is the community of organisms that live on, in, or near the bottom of a sea, river, lake, or stream, also known as the benthic zone. This community lives in or near marine or freshwater sedimentary environments, from tidal pools along the foreshore, out to the continental shelf, and then down to the abyssal depths.\nLight is an important energy source for shallow benthic systems. However, because light is absorbed before it can reach deep ocean water, the energy source for deep benthic ecosystems is often organic matter from higher up in the water column that drifts down to the depths. This dead and decaying matter sustains the benthic food chain; most organisms in the benthic zone are scavengers or detritivores.\nMany organisms adapted to deep-water pressure cannot survive in the upper parts of the water column. The pressure difference can be significant (approximately one atmosphere for every 10 metres of water depth).\nThe term \"benthos\", coined by Haeckel in 1891, comes from the Greek noun 'depth of the sea'. \"Benthos\" is used in freshwater biology to refer to organisms at the bottom of freshwater bodies of water, such as lakes, rivers, and streams. There is also a redundant synonym, \"benthon\".\nOverview.\nCompared to the relatively featureless pelagic zone, the benthic zone offers physically diverse habitats. There is a huge range in how much light and warmth is available, and in the depth of water or extent of intertidal immersion. The seafloor varies widely in the types of sediment it offers. Burrowing animals can find protection and food in soft, loose sediments such as mud, clay and sand. Sessile species such as oysters and barnacles can attach themselves securely to hard, rocky substrates. As adults they can remain at the same site, shaping depressions and crevices where mobile animals find refuge. This greater diversity in benthic habitats has resulted in a higher diversity of benthic species. The number of benthic animal species exceeds one million. This far exceeds the number of pelagic animal species (about 5000 larger zooplankton species, 22,000 pelagic fish species and 110 marine mammal species).\nBy size.\nMacrobenthos.\nMacrobenthos, prefix from grc \" makr\u00f3s\"\u00a0'long', comprises the larger, visible to the naked eye, benthic organisms greater than about 1\u00a0mm in size. In shallow waters, seagrass meadows, coral reefs and kelp forests provide particularly rich habitats for macrobenthos. Some examples are polychaete worms, bivalves, echinoderms, sea anemones, corals, sponges, sea squirts, turbellarians and larger crustaceans such as crabs, lobsters and cumaceans.\nMeiobenthos.\nMeiobenthos, prefix from grc \" me\u00eeon\"\u00a0'less', comprises tiny benthic organisms that are less than about 1\u00a0mm but greater than about 0.1\u00a0mm in size. Some examples are nematodes, foraminiferans, tardigrades, gastrotriches and smaller crustaceans such as copepods and ostracodes.\nMicrobenthos.\nMicrobenthos, prefix from the Greek \"mikr\u00f3s\" 'small', comprises microscopic benthic organisms that are less than about 0.1\u00a0mm in size. Some examples are bacteria, diatoms, ciliates, amoeba, flagellates.\nMarine microbenthos are microorganisms that live in the benthic zone of the ocean \u2013 that live near or on the seafloor, or within or on surface seafloor sediments. Microbenthos are found everywhere on or about the seafloor of continental shelves, as well as in deeper waters, with greater diversity in or on seafloor sediments. In photic zones benthic diatoms dominate as photosynthetic organisms. In intertidal zones changing tides strongly control opportunities for microbenthos.\nBoth foraminifera and diatoms have planktonic and benthic forms, that is, they can drift in the water column or live on sediment at the bottom of the ocean. Regardless of form, their shells sink to the seafloor after they die. These shells are widely used as climate proxies. The chemical composition of the shells are a consequence of the chemical composition of the ocean at the time the shells were formed. Past water temperatures can be also be inferred from the ratios of stable oxygen isotopes in the shells, since lighter isotopes evaporate more readily in warmer water leaving the heavier isotopes in the shells. Information about past climates can be inferred further from the abundance of forams and diatoms, since they tend to be more abundant in warm water.The sudden extinction event which killed the dinosaurs 66 million years ago also rendered extinct three-quarters of all other animal and plant species. However, deep-sea benthic forams flourished in the aftermath. In 2020 it was reported that researchers have examined the chemical composition of thousands of samples of these benthic forams and used their findings to build the most detailed climate record of Earth ever.\nSome endoliths have extremely long lives. In 2013 researchers reported evidence of endoliths in the ocean floor, perhaps millions of years old, with a generation time of 10,000 years. These are slowly metabolizing and not in a dormant state. Some Actinomycetota found in Siberia are estimated to be half a million years old.\nBy type.\nZoobenthos.\nZoobenthos, prefix from grc \" z\u00f4ion\"\u00a0'animal', animals belonging to the benthos. Examples include polychaete worms, starfish and anemones.\nPhytobenthos.\nPhytobenthos, prefix from grc \" phut\u00f3n\"\u00a0'plant', plants belonging to the benthos, mainly benthic diatoms and macroalgae (seaweed).\nBy location.\nEndobenthos.\nEndobenthos (or endobenthic), prefix from grc \" \u00e9ndon\"\u00a0'inner, internal', lives buried, or burrowing in the sediment, often in the oxygenated top layer, e.g., a sea pen or a sand dollar.\nEpibenthos.\nEpibenthos (or epibenthic), prefix from grc \" ep\u00ed\"\u00a0'on top of', lives on top of the sediments, e.g., sea cucumber or a sea snail.\nHyperbenthos.\nHyperbenthos (or hyperbenthic), prefix from grc \" hup\u00e9r\"\u00a0'over', lives just above the sediment, e.g., a rock cod.\nFood sources.\nThe main food sources for the benthos are phytoplankton and organic detrital matter. In coastal locations, organic run off from land provides an additional food source. Meiofauna and bacteria consume and recycle organic matter in the sediments, playing an important role in returning nitrate and phosphate to the pelagic.\nThe depth of water, temperature and salinity, and type of local substrate all affect what benthos is present. In coastal waters and other places where light reaches the bottom, benthic photosynthesizing diatoms can proliferate. Filter feeders, such as sponges and bivalves, dominate hard, sandy bottoms. Deposit feeders, such as polychaetes, populate softer bottoms. Fish, such as dragonets, as well as sea stars, snails, cephalopods, and crustaceans are important predators and scavengers.\nBenthic organisms, such as sea stars, oysters, clams, sea cucumbers, brittle stars and sea anemones, play an important role as a food source for fish, such as the California sheephead, and humans.\nEcological role.\nBenthos as bioindicators.\nBenthic macro-invertebrates play a critical role in aquatic ecosystems. These organisms can be used to indicate the presence, concentration, and effect of water pollutants in the aquatic environment. Some water contaminants\u2014such as nutrients, chemicals from surface runoff, and metals\u2014settle in the sediment of river beds, where many benthos reside. Benthos are highly sensitive to contamination, so their close proximity to high pollutant concentrations make these organisms ideal for studying water contamination.\nBenthos can be used as bioindicators of water pollution through ecological population assessments or through analyzing biomarkers. In ecological population assessments, a relative value of water pollution can be detected. Observing the number and diversity of macro-invertebrates in a waterbody can indicate the pollution level. In highly contaminated waters, a reduced number of organisms and only pollution-tolerant species will be found. In biomarker assessments, quantitative data can be collected on the amount of and direct effect of specific pollutants in a waterbody. The biochemical response of macro-invertebrates' internal tissues can be studied extensively in the laboratory. The concentration of a chemical can cause many changes, including changing feeding behaviors, inflammation, and genetic damage, effects that can be detected outside of the stream environment. Biomarker analysis is important for mitigating the negative impacts of water pollution because it can detect water pollution before it has a noticeable ecological effect on benthos populations.\nCarbon processing.\nOrganic matter produced in the sunlit layer of the ocean and delivered to the sediments is either consumed by organisms or buried. The organic matter consumed by organisms is used to synthesize biomass (i.e. growth) converted to carbon dioxide through respiration, or returned to the sediment as faeces. This cycle can occur many times before either all organic matter is used up or eventually buried. This process is known as the biological pump.\nIn the long-term or at steady-state, i.e., the biomass of benthic organisms does not change, the benthic community can be considered a black box diverting organic matter into either metabolites or the geosphere (burial). The macrobenthos also indirectly impacts carbon cycling on the seafloor through bioturbation.\nThreats.\nBenthos are negatively impacted by fishing, pollution and litter, deep-sea mining, oil and gas activities, tourism, shipping, invasive species, climate change (and its impacts such as ocean acidification, ocean warming and changes to ocean circulation) and construction such as coastal development, undersea cables, and wind farm construction.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60360", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=60360", "title": "Anapsid", "text": "Paraphyletic grouping of reptiles\nAn anapsid is an amniote whose skull lacks one or more skull openings (fenestra, or fossae) near the temples. Traditionally, the Anapsida are considered the most primitive subclass of amniotes, the ancestral stock from which Synapsida and Diapsida evolved, making anapsids paraphyletic. It is, however, doubtful that all anapsids lack temporal fenestra as a primitive trait, and that all the groups traditionally seen as anapsids truly lacked fenestra.\nAnapsids and the turtles.\nWhile \"anapsid reptiles\" or \"Anapsida\" were traditionally spoken of as if they were a monophyletic group, it has been suggested that several groups of reptiles that had anapsid skulls might be only distantly related. Scientists still debate the exact relationship between the basal (original) reptiles that first appeared in the late Carboniferous, the various Permian reptiles that had anapsid skulls, and the Testudines (turtles, tortoises, and terrapins). However, it was later suggested that the anapsid-like turtle skull is due to reversion rather than to anapsid descent. The majority of modern paleontologists believe that the Testudines are descended from diapsid reptiles that lost their temporal fenestrae. More recent morphological phylogenetic studies with this in mind placed turtles firmly within diapsids, most commonly within Archelosauria.\nPhylogenetic position of turtles.\nAll molecular studies have strongly upheld the placement of turtles within diapsids; some place turtles within Archosauria, or, more commonly, as a sister group to extant archosaurs. One molecular study, published in 2012, suggests that turtles are lepidosauromorph diapsids, most closely related to the lepidosaurs (lizards, snakes, and tuataras). However, in a later paper from the same authors, published in 2014, based on more extensive data, the archosauromorph hypothesis is supported.\nReanalysis of prior phylogenies suggests that they classified turtles as anapsids both because they assumed this classification (most of them were studying what sort of anapsid turtles are) and because they did not sample fossil and extant taxa broadly enough for constructing the cladogram. Testudines is suggested to have diverged from other diapsids between 200 and 279 million years ago, though the debate is far from settled. Although procolophonids managed to survive into the Triassic, most of the other reptiles with anapsid skulls, including the millerettids, nycteroleterids, and pareiasaurs, became extinct in the Late Permian period by the Permian-Triassic extinction event.\nDespite the molecular studies, there is evidence that contradicts their classification as diapsids. All known diapsids excrete uric acid as nitrogenous waste (uricotelic), and there is no known case of a diapsid reverting to the excretion of urea (ureotelism), even when they return to semi-aquatic lifestyles. Crocodilians, for example, are still uricotelic, although they are also partly ammonotelic, meaning they excrete some of their waste as ammonia. Ureotelism appears to be the ancestral condition among primitive amniotes, and it is retained by mammals, which likely inherited ureotelism from their synapsid and therapsid ancestors. Ureotelism therefore would suggest that turtles were more likely anapsids than diapsids. The only known uricotelic chelonian is the desert tortoise, which likely evolved it recently as adaptation to desert habitats. Some desert mammals are also uricotelic, so since practically all known mammals are ureotelic, uricotelic adaptation is a likely result of convergence among desert species. Therefore, turtles would have to be the only known case of a uricotelic reptile reverting to ureotelism.\nAnapsida in modern taxonomy.\nAnapsida is still sporadically recognized as a valid group, but is not favoured by current workers. Anapsids in the traditional meaning of the word are not a clade, but rather a paraphyletic group composed of all the early reptiles retaining the primitive skull morphology, grouped together by the absence of temporal openings. Gauthier, Kluge and Rowe (1988) attempted to redefine Anapsida so it would be monophyletic, defining it as the clade containing \"extant turtles and all other extinct taxa that are more closely related to them than they are to other reptiles\".\nThis definition explicitly includes turtles in Anapsida; because the phylogenetic placement of turtles within Amniota is very uncertain, it is unclear what taxa, other than turtles themselves, would be included in such defined Anapsida, and whether its content would be similar to the Anapsida of tradition. Indeed, Gauthier, Kluge and Rowe (1988) themselves included only turtles and Captorhinidae in their Anapsida, while excluding the majority of anapsids in the traditional sense of the word from it.\nTemporal openings in traditional anapsids.\nTsuji and M\u00fcller (2009) noted that the name Anapsida implies a morphology (lack of temporal openings) that is in fact absent in the skeletons of a number of taxa traditionally included in the group. A temporal opening in the skull roof behind each eye, similar to that present in the skulls of synapsids, has been discovered in the skulls of a number of members of Parareptilia (the group containing most of reptiles traditionally referred to as anapsids), including lanthanosuchoids, millerettids, bolosaurids, some nycteroleterids, some procolophonoids and at least some mesosaurs. The presence of temporal openings in the skulls of these taxa makes it uncertain whether the ancestral reptiles had an anapsid-like skull as traditionally assumed or a synapsid-like skull instead.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60361", "revid": "47012757", "url": "https://en.wikipedia.org/wiki?curid=60361", "title": "Illyria", "text": "In classical and late antiquity, Illyria (; , \"Illyr\u00eda\" or , \"Illyr\u00eds\"; , \"Illyricum\") was a region in the western part of the Balkan Peninsula inhabited by numerous tribes of people collectively known as the Illyrians.\nThe Ancient Greeks initially used the term Illyris to define approximately the area of northern and central Albania down to the Ao\u00f6s valley (modern Vjosa) and the Bay of Vlor\u00eb, including in most periods much of the lakeland area (Ohrid and Prespa). It corresponded to the region that neighboured Macedonia and Epirus. In Roman times the terms Illyria, Illyris, or Illyricum were extended from the territory that was roughly located in the area of the south-eastern Adriatic coast (modern Albania and Montenegro) and its hinterland, to a broader region stretching between the whole eastern Adriatic and the Danube.\nFrom about mid-1st century BC the term \"Illyricum\" was used by the Romans for the province of the Empire that stretched along the eastern Adriatic coast north of the Drin river, south of which the Roman province of Macedonia began including the southern part of the traditional region of Illyria. The southeastern part, to the north of Macedonia, was organized within the province of Moesia Superior. From about 69-79 AD the province of Illyricum was subsumed into the provinces of Dalmatia and Pannonia. In the Late Roman Empire the name was used for the praetorian prefecture of Illyricum.\nName.\nThe region took its name from its inhabitants, the Illyrians, a group of Balkan Indo-European speaking peoples that inhabited the western part of the Peninsula in ancient times.\nIllyrian kingdoms.\nThe earliest recorded Illyrian kingdom was that of the Enchele in the 8th century BC. The era in which we observe other Illyrian kingdoms begins approximately at 400 BC and ends at 167 BC. The Autariatae under Pleurias (337 BC) were considered to have been a kingdom. The Kingdom of the Ardiaei began at 230 BC and ended at 167 BC. The most notable Illyrian kingdoms and dynasties were those of Bardyllis of the Dardani and of Agron of the Ardiaei who created the last and best-known Illyrian kingdom. Agron ruled over the Ardiaei and had extended his rule to other tribes as well. As for the Dardanians, they always had separate domains from the rest of the Illyrians.\nThe Illyrian kingdoms were composed of small areas within the region of Illyria. Only the Romans ruled the entire region. The internal organization of the south Illyrian kingdoms points to imitation of their neighbouring Greek kingdoms and influence from the Greek and Hellenistic world in the growth of their urban centres. Polybius gives as an image of society within an Illyrian kingdom as peasant infantry fought under aristocrats which he calls in Greek \"Polydynastae\" (Greek: \u03a0\u03bf\u03bb\u03c5\u03b4\u03c5\u03bd\u03ac\u03c3\u03c4\u03b5\u03c2) where each one controlled a town within the kingdom. The monarchy was established on hereditary lines and Illyrian rulers used marriages as a means of alliance with other powers. Pliny (23\u201379 AD) writes that the people that formed the nucleus of the Illyrian kingdom were 'Illyrians proper' or Illyrii proprie dicti. They were the Taulantii, the Pleraei, the Endirudini, Sasaei, Grabaei and the Labeatae. These later joined to form the Docleatae.\nRoman Protectorate of Illyricum.\nAfter the Roman victory in the First Illyrian War, Illyrian Queen Teuta was forced to retreat to the Bay of Kotor, and in 228 BC the Romans imposed a protectorate on the islands of Issa and Corcyra, as well as on the cities of Epidamnos, Apollonia and Oricum. The protectorate area corresponded to the usage of the Roman concept of \"Illyricum\".\nDuring the Macedonian Wars, the territory of southern Illyria, which Rome had aimed to protect and control periodically for thirty years since the First Illyrian War, was involved in the conflict between Rome and Macedon. Macedon aimed to conquer, without success, the southern Illyrian ports because they would have been good bases for an attack upon Italy.\nThe Romans defeated Gentius, the last king of Illyria, at Scodra (in present-day Albania) in 168 BC and captured him, bringing him to Rome in 165 BC. Four client-republics were set up, which were in fact ruled by Rome. Later, the region was directly governed by Rome and organized as a province, with Scodra as its capital.\nRoman rule.\nIllyrian territories were organized during the Roman administration into the provinces of Illyricum, Macedonia, and Moesia Superior.\nThe Roman province of \"Illyricum\" roughly encompassed the territories of the last Illyrian kingdom. It stretched from the Drilon river in modern Albania to Istria (Croatia) in the west and to the Sava river (Bosnia and Herzegovina) in the north. Salona (near modern Split in Croatia) functioned as its capital.\nAfter subduing a troublesome revolt of Pannonians and Daesitiates, Roman administrators dissolved the province of Illyricum and divided its lands between the new provinces of Pannonia in the north and Dalmatia in the south. Although this division occurred in 10 AD, the term \"Illyria\" remained in use in Late Latin and throughout the medieval period. After the division of the Roman Empire, the bishops of Thessalonica appointed papal vicars for Illyricum. The first of these vicars is said to have been Bishop Acholius or Ascholius (died 383 or 384), the friend of St. Basil. In the 5th century, the bishops of Illyria withdrew from communion with Rome, without attaching themselves to Constantinople, and remained for a time independent, but in 515, forty Illyrian bishops renewed their loyalty to Rome by declaring allegiance to Pope Hormisdas. The patriarchs of Constantinople succeeded in bringing Illyria under their jurisdiction in the 8th century.\nJewish presence in Illyricum is attested during and after its incorporation into the Roman Empire. As Roman military and trade networks expanded into the region following the defeat of King Gentius, Jewish merchants, artisans, and possibly freed slaves settled in Dalmatian and Pannonian cities such as Salona, Narona, and Sirmium. These communities, often Greek-speaking and aligned with Jerusalem-based traditions, operated within Roman legal frameworks and sometimes held status as collegia. Although no literary corpus survives from Illyrian Jews, archaeological evidence, including menorahs and inscriptions, supports their presence. Some scholars suggest that these Jews formed part of broader Hellenistic Judaism diaspora patterns reaching as far as Tanais in the Crimea and Stobi in Macedonia.\nIn culture.\nWilliam Shakespeare chose a fictionalized Illyria as the setting for his play \"Twelfth Night\". (The modernized film spoof \"She's the Man\" is set in \"Illyria High School\" in California.) Shakespeare also mentioned the region in \"Henry VI, Part 2\".\nAn extensive history of Illyria by Charles du Fresne, sieur du Cange, was published by Joseph Keglevich in 1746.\nIllyria is the setting for Jean-Paul Sartre's \"Les Mains Sales.\"\nLloyd Alexander's \"The Illyrian Adventure\" is set in Illyria in 1872.\nJohn Hawkes' 1970 novel \"The Blood Oranges\" is set in a fictionalized Illyria.\nThere is a fictional Illyria with its inhabitants, winged fae, in the fantasy series \"A Court of Thorns and Roses\" by Sarah J. Maas.\nThe fighting game series 'Guilty Gear' created by Daisuke Ishiwatari, features a fictional Illyria in its world.\nThe television series \"Angel (1999 TV series)\" has a character named Illyria who is a main character for the back half of the final season, as well as a prominent figure in the comic spin-offs.\nThe character of Una \"Number One\" Chin-Riley in the television series \"\" is a member of a humanoid species called \"Illyrians\".\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "60363", "revid": "279219", "url": "https://en.wikipedia.org/wiki?curid=60363", "title": "Boleslaw III of Poland", "text": ""}
{"id": "60364", "revid": "48810645", "url": "https://en.wikipedia.org/wiki?curid=60364", "title": "Mostly Harmless", "text": "1992 comic science fiction novel by Douglas Adams\nMostly Harmless is a 1992 novel by Douglas Adams and the fifth book in the \"Hitchhiker's Guide to the Galaxy\" series. It is described on the cover of the first edition as \"The fifth book in the increasingly inaccurately named Hitch Hiker's Guide to the Galaxy trilogy\". It was the last \"Hitchhiker's\" book written by Adams and his final book released in his lifetime.\nPlot summary.\nArthur Dent plans to sightsee across the Galaxy with his girlfriend Fenchurch, but she disappears during a hyperspace jump, a result of being from an unstable sector of the Galaxy. Depressed, Arthur continues to travel the galaxy using samples of his bodily tissues/fluids to fund his travels, assured of his safety until he visits Stavromula Beta, having killed an incarnation of Agrajag at some point in the future at said planet. During one trip, he ends up stranded on the homely planet Lamuella, and decides to stay to become a sandwich maker for the local population.\nMeanwhile, Ford Prefect has returned to the offices of the Hitchhiker's Guide, and is annoyed to find out the original publishing company, Megadodo Publications, has been taken over by InfiniDim Enterprises, which are run by the Vogons. Fearing for his life, he escapes the building, along the way stealing the yet-unpublished, seemingly sentient Hitchhiker's Guide Mk. II. He goes into hiding after sending the Guide to himself, in the care of Arthur, for safekeeping.\nOn Lamuella, Arthur is surprised by the appearance of Trillian with a teenage daughter, Random Dent. Trillian explains that she wanted a child, and used the only human DNA she could find, thus claiming that Arthur is Random's father. She leaves Random with Arthur to allow her to better pursue her career as an intergalactic reporter. Random is frustrated with Arthur and life on Lamuella; when Ford's package to Arthur arrives, she takes it and discovers the Guide. The Guide helps her to escape the planet on Ford's ship after Ford arrives on the planet looking for Arthur. Discovering Random, the Guide, and Ford's ship missing, the two leave Lamuella on multidimensional Perfectly Normal Beasts and head for Earth, where they suspect Random is also heading to find Trillian. Ford expresses concern at the Guide's manipulation of events, noting its \"Unfiltered Perception\" and fearing its potency and ultimate objective.\nReporter Tricia McMillan is a version of Trillian living on an alternate Earth who never took Zaphod Beeblebrox's offer to travel in space. She is approached by an extraterrestrial species, the Grebulons, who have created a base of operations on the planet Rupert, a recently discovered tenth planet in the Solar System. However, due to damage to their ship in arriving, they have lost most of their computer core and their memories, with the only salvageable instructions being to observe something interesting with Earth. They ask Tricia's help to adapt astrology charts for Rupert in exchange for allowing her to interview them. She fulfills their request and conducts the interview, but the resulting footage looks so fake that she fears it will destroy her reputation if broadcast. She is called away from editing the footage to report on a spaceship landing in the middle of London.\nAs Tricia arrives at the scene, Random steps off the ship and begins to yell at her, mistaking Tricia for her mother. Arthur, Ford, and Trillian arrive and help Tricia to calm Random. They remove her from the chaos surrounding the spacecraft and take her to a bar. Trillian tries to warn the group that the Grebulons, having become bored with their mission, are about to destroy the Earth. Random disrupts the discussion by producing a laser gun she took from her ship. Arthur, still believing he cannot die, tries to calm Random, but a distraction causes her to fire the weapon, sending the bar into a panic. Arthur tends to a man hit by the blast, who drops a matchbook with the name of the bar - \"Stavro Mueller \u2013 Beta\" - and Arthur realises that this is the scene of Agrajag's final death. He sees Ford laughing wildly at this turn of events and experiences a \"tremendous feeling of peace\".\nThe Grebulons destroy the Earth, believing that their horoscopes will improve if it is removed from their astrological charts. It is revealed that the Vogons designed the Guide Mk. II to achieve their desired outcome by manipulating temporal events. As a result, every version of the Earth in all realities is obliterated, fulfilling the demolition order that was issued in the first novel. Its mission complete, the Guide collapses into nothingness.\nTitle.\nThe title derives from a joke early in the series, when Arthur Dent discovers that the entry for Earth in \"The Hitchhiker's Guide to the Galaxy\" consists, in its entirety, of the word \"Harmless\". His friend Ford Prefect, a contributor to the \"Guide\", assures him that the next edition will contain the article on Earth that Ford has spent the last 15 years researching\u2014somewhat cut due to space restrictions, but still an improvement. The revised article, he eventually admits, will simply read \"\"Mostly\" harmless\". Ford had written an extensive entry covering life and recreation on Earth, but the \"Guide\" editors cut it back to \"Harmless\". Later in the series, Ford is surprised to find that the entry on Earth has been updated to include all of his original material, prompting him to hitchhike across the galaxy and reunite with Arthur on the alternate Earth in \"So Long, and Thanks for All the Fish\".\nReception.\nUnlike the previous books in the series, \"Mostly Harmless\" received mixed reviews noting its darker tone. Nicholas Lezard in \"The Guardian\" wrote: \"I doubt there is a comedy sci-fi work bleaker than \"Mostly Harmless\". \"The Independent\" concluded \"Mostly Harmless\" has all the wit and inventiveness of vintage Douglas Adams, though its loose ends are not tied together as comprehensively as in previous \"Hitch-Hiker\" books\". David Edelman in the \"Baltimore Evening Sun\" wrote: \"Somewhere buried in the mess is a moral about learning how to feel at home in a chaotic universe. Unfortunately, Adams' skills at conveying serious messages are nowhere near on a level with his skill at conjuring up non sequiturs, and the idea gets buried\".\nIn an interview reprinted in \"The Salmon of Doubt\", Adams expressed dissatisfaction with the tone of this book, which he blamed on personal problems, saying \"for all sorts of personal reasons that I don't want to go into, I just had a thoroughly miserable year, and I was trying to write a book against that background. And, guess what, it was a rather bleak book!\"\nAdaptations.\nRadio.\nDirk Maggs adapted the book as the \"Quintessential Phase\" of the radio series, and it was broadcast in June 2005. The radio version has an entirely new, upbeat ending, appended to the existing story.\nIn the alternate ending, after the destruction of Earth, the description of the Babel fish from the earlier series is replayed with an additional section, which states that dolphins and Babel fish are acquainted, and that the dolphins' ability to travel through possibility space (first mentioned in \"The Hitchhiker's Guide to the Galaxy\" and elaborated on in \"So Long, and Thanks for All the Fish\") is shared by the Babel fish as well. During the ending, Ford explains that the dolphins got taught this skill from the Babel fish in exchange for knowing a good place to have parties. All the major characters are carrying Babel fish in their ears, which rescue them at the moment of Earth's destruction by transporting them to the Restaurant at the End of the Universe. It's also revealed that Fenchurch was transported here when she vanished and has been patiently waiting for Arthur to show up. The characters are reunited with Marvin, and it is revealed that beyond the Restaurant (and beyond the car park in which Marvin works) lies an endless series of blue lagoons\u00a0\u2014 the final destination of the dolphins. The series ends with Arthur asking Fenchurch, \"Will you come flying with me?\", and her reply, \"Always.\"\nThe version released on CD contains an even longer set of alternate endings, including one set after the events of the twelfth radio episode (with Arthur Dent and Lintilla), and on an alternate Earth where Arthur Dent and Fenchurch engage together in a stand-off against Mr. Prosser.\nAudiobook.\nThere have been four unabridged audiobook recordings of the novel. In 1992, Adams himself recorded an edition, later re-released by New Millennium Audio in the United States and available from BBC Audiobooks in the United Kingdom. In 2006, actor Martin Freeman, who had played Arthur Dent in the 2005 movie, recorded a new edition of the audiobook. This is the only book in the five novel series not to have also had a prior, abridged edition read by Stephen Moore.\nIn addition, the National Library Service for the Blind and Physically Handicapped released a version of the book, narrated by George Guidall-Shapiro, on 4-track cassette tape in 1993.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60367", "revid": "10288473", "url": "https://en.wikipedia.org/wiki?curid=60367", "title": "Front 242", "text": "Belgian electronic music group\nFront 242 were a Belgian electronic music group that came into prominence during the 1980s. Pioneering the style they called electronic body music, they influenced the electronic and industrial music genres.\nHistory.\nFormation.\nFront 242 were formed in 1981 in Aarschot, near Leuven, Belgium, by Daniel Bressanutti and Dirk Bergen, who wanted to create music and graphic design using emerging electronic tools. Prior to forming Front 242, Bressanutti worked on a music project called \"Prothese\" that had already produced several one-off tracks. The \"front\" part of the name comes from the idea of an organized popular uprising and the fact that the word can be translated in many languages while retaining the same meaning. The first single by the duo, \"Principles\", with b-side \"Body To Body,\" was released in 1981.\nPatrick Codenys and Jean-Luc De Meyer had separately formed a group called \"Underviewer\" at around the same time. The groups merged in 1982 after Underviewer had given their demo tapes to Bressanutti who was working at Hill's Music musical instrument shop in Brussels at the time. Bressanutti was sufficiently impressed to ask Codenys and De Meyer to join Front 242.\nRecordings by the band were initially created in Bressanutti's apartment studio, where the entire band and their equipment were packed into a room. The band incorporated as an artistic association in Belgium which allowed them to access government assistance and made it easier to afford better studio equipment.\nBressanutti, Codenys and De Meyer took turns on vocals at first, until they settled on De Meyer as the lead vocalist (early recordings with Bressanutti on vocals were subsequently released in 2004). De Meyer came to write most of the lyrics, although Valerie Jane Steele wrote several tracks including \"Don't Crash.\" Despite falling into specific roles, however, the band sought to project a more anonymous, mysterious image, replete with dark sunglasses and militaristic uniforms so that they could not be easily identified. Bressanutti took this concept of anonymity to the extreme, leaving the stage entirely to run live shows from the sound board behind the audience.\nThe band self-released their first album, \"Geography\", in 1982 and shortly after signed to the Belgian indie label consortium Les Disques du Cr\u00e9puscule who later re-released the album. Their next single, \"U-Men\", was released the same year as was the band's first music video, produced by Marcel Vanthilt and played on the program RoodVonk on VRT (Vlaamse Radio Televisie - Flemish Radio &amp; TV). The video proved a challenge, not only conceptually given the band's insistence on anonymity, but because of the small budget; ultimately the video was shot on location in Daniel's bedroom.\nIn 1983, the band brought on Richard Jonckheere (also known as Richard 23), whom they became familiar with through Richard's own \"noise concept\" as a percussionist and second vocalist to help boost the band's live presence. Not long after, Dirk Bergen left the band to manage the group and pursue a graphic design career. Also in 1983 the band released the EP \"Endless Riddance\".\nRising popularity.\nFront 242 became a popular musical group in Belgium, particularly for their \"infamous\" live performances that involved loud sound, aggressive stage presence, smoke, and bright flashing lights. The music press in Belgium was less receptive, sometimes interpreting their militaristic appearance, dark music, and samples from war especially given the backdrop of the cold war and terror incidents in as being pro-fascist, an interpretation the band firmly rejected.\nTheir second album, \"No Comment\", released in 1984, was the first to introduce the term electronic body music in association with their sound via the liner notes, which stated: \"Electronic body music composed and produced on eight tracks by Front 242.\" The band followed the release with a European tour.\nIt was around this time that Front 242 began collaborating with Luc van Acker, who was a familiar presence at Hill's Music. On one occasion, Luc brought his guitar and gear to the band's studio where samples of the session were used in composing the track \"No Shuffle.\" Luc was also known to take the stage with the band at times.\nFront 242 signed with the American label Wax Trax! in 1984. At the behest of Alain Jourgensen who was working with Wax Trax at the time, Front 242 were invited to be the support band for Ministry during their upcoming tour in the United States. This tour led to the creation of Revolting Cocks by Richard 23, Luc van Acker, and Alain Jourgensen.\nIn 1985 the band played the Seaside Festival and the first ever Pukkelpop Festival in Belgium. An incident between the band and security at Pukkelpop led to further negative press for the band. That year they also released the \"Politics of Pressure\" EP and a 12\" for \"No Shuffle.\"\nIn 1986, Front 242 turned down a contract with ZTT Records and instead signed with Red Rhino (RRE) in Europe\u2060a sub-label of Play It Again Samwho released \"Backcatalogue\" and \"Official Version\" in 1987. Trouser Press credited \"Official Version\" with helping Front 242 \"emerge from relative obscurity to become a significant cult force, selling records all over the world.\" In the fall of 1987, Front 242 supported Depeche Mode on the first European leg of their \"Music for the Masses\" tour.\nIn 1988, \"Front by Front\" was released, and in December of that same year, \"Headhunter\" (with a video by Anton Corbijn), became the band's first club hit, reaching number 13 on the US \"Billboard\" Dance/Club Play Songs chart.\n1990s.\n\"Tyranny (For You)\", released in 1991, became the band's highest-charting album, reaching No. 95 on the \"Billboard\" 200. \"Tyranny (For You)\" was the first album they released under contract with a major corporate label, Sony/Epic, after the widespread popularity of \"Front by Front\". Two further releases were extracted from \"Tyranny\" \u2014 \"Mixed by Fear\", which contained remixes of the track \"Gripped by Fear\", and the single \"Rhythm of Time\", which included a remix by The Orb.\nSony/Epic also acquired the rights to the band's back catalog from Wax Trax! and issued re-released versions of the albums with new cover art and bonus tracks taken from singles and EPs.\nIn 1992, Bressanutti returned to combining graphic arts with music, taking his lithographs on tour to three U.S. galleries. Bressanutti also composed a solo half-hour atmospheric recording called \"Art and Strategy\" (or The Art Corporation) to play during viewings of the lithographs, and released it in a limited edition of 1,000 CDs.\nFront 242's style shifted abruptly with each of their next two albums, released in rapid succession in 1993 on Epic's sub-label RRE (originally planned as a double-CD): \"06:21:03:11 UP EVIL\" and \"05:22:09:12 OFF\" (the numbers correspond to letters, spelling \"FUCK UP EVIL\" and \"EVIL OFF\"). The band describes the two albums as \"based on the duality of good and evil.\" However, strains were emerging, with the band members apparently having different artistic views. Despite these tensions, they performed on the main stage of the 1993 Lollapalooza tour.\nNeither of these albums had significant input from Richard 23, and \"05:22:09:12 OFF\" only included their lead vocalist, Jean-Luc De Meyer, on a remixed track originally from \"Up Evil\". On the other hand, a variety of new contributors were listed as members of Front 242 on these albums: Jean-Marc Pauly and Pierre Pauly (of the Belgian electronic group Parade Ground) on \"Up Evil\", and 99 Kowalski, John Dubs and Eran Westwood on \"Off\".\n99 Kowalski is the stage name of Kristin Kowalski, making a tradition out of Richard 23's idea of number-as-name. Kowalski, Dubs and Westwood were originally members of a New York City band called Spill who Bressanutti and Codenys had brought to Belgium to produce their debut album. After the recording sessions fell apart, they contributed to Front 242 on the \"Off\" release.\nAfter the release of \"06:21:03:11 Up Evil\" and \"05:22:09:12 Off\", there was no new material from Front 242 under any lineup. Instead, the band released a stream of live recordings and remixes. However, this period also saw a proliferation of side projects, an inordinate number of which involved De Meyer.\nEarlier, Richard 23 played in the Revolting Cocks, and De Meyer had a side project doing vocals for Bigod 20 for their single, \"The Bog\" in 1990. In 1995, De Meyer met Marc Heal of Cubanate at a Front Line Assembly concert, and the two of them collaborated along with Ged Denton and Jonathan Sharp, to record as Cyber-Tec Project for the new (and short-lived) Cyber-Tec record label.\nAfter the departure of Sharp and the demise of the Cyber-Tec label, the remaining group continued working under the name C-Tec. De Meyer also took over as vocalist for Birmingham 6 for their 1996 album \"Error of Judgment\". That year also saw the debut album \"Elemental\" from Cobalt 60, which De Meyer formed with Dominique Lallement and Frederic Sebastien of Reims, France, members of Kriegbereit. This was the start of a number of releases from Cobalt 60, which also did the soundtrack for the video game \"\". Meanwhile, Richard 23 recorded with the groups Holy Gang, and later, LaTchak.\nThe four core members of Front 242 regrouped in 1998 to compose radically reworked versions of many of their songs, which they then performed on their first tour in five years, appropriately called the Re:Boot tour. They acknowledged the influence of The Prodigy and their \"Fat of the Land\" album in crafting the new, more techno style of Re:Boot.\nThe new tour material was the subject of Front 242's new recording contract in the U.S. with Metropolis Records. Front 242 also indicated at this time that they were recording new material. However, they had little activity after 1998, making occasional appearances in Europe and Mexico, while Codenys recorded under the name Gaiden with Steve Stoll in 2001.\n2000s.\n2002 saw the beginning of a wave of new material from Bresanutti and Codenys, and then from Front 242. In August 2002 a DVD/CD two-disc set called \"Speed Tribe\" was released by Dance.com. The DVD was a collaboration with experimental documentary filmmakers Rod Chong and Sharon Matarazzo, who filmed the 2001 24 Hour Le Mans. In the video, the racecars, clouds, rain and spectators form an impressionistic visual backdrop for the music.\nSeveral months later, the first release from Male or Female, also known as Morf, a new project for Bresanutti and Codenys along with vocalist Elko Blijweert. In 2002 and 2003, Morf released an album, an E.P., a double album, and a DVD/CD two-disc combo, on the Belgian record label Alfa Matrix, and went on tour through the U.S.\nThen, 2002 and 2003 also saw the release of the new material from Front 242 in a decade: the EP \"Still &amp; Raw\" and the album \"Pulse\", released on XIIIBis Records in Europe and Metropolis in the U.S. These represented another iteration of Front 242's explicitly stated goal of reinventing itself. The style of the two new releases is more mellow than some of their past work, using more \"glitchy\" and \"bleepy\" sounds. As well, it uses the manipulated voice as a musical instrument. The new releases have a much more emotional style from De Meyer, which was presaged in his later recordings with C-Tec and particularly Cobalt 60 on its album \"Twelve\".\nFront 242 promised a new U.S. tour to perform new material from these releases. They have made occasional appearances in Latin America and Europe, even being rejoined by Dirk Bergen for a reunion concert in Aarschot (De Klinker club) in 2004 under the original lineup of Bresanutti, Bergen, Codenys and De Meyer. This performance was kept secret until two days before the show but when the scene magazine Side-Line and the band's label Alfa Matrix launched the news, tickets were quickly sold out.\nThe band has now also set itself to re-release its entire back catalogue both as a normal CD and as a limited edition consisting of a 2-CD set holding previously unreleased material. For this the band is working together with the Belgian label Alfa Matrix that already took care of releasing the albums of the Front 242 side-project Male Or Female. The first re-release is their debut album \"Geography\", this time newly remastered personally by Bresanutti to surprisingly powerful effect and including 3 extra tracks (two hidden ones) on the normal CD format.\nMeanwhile, their enthusiasm for side projects has continued, as Patrick Codenys started appearing with a new group called Red Sniper, Bresanutti started recording with a new group called Troissoeur, and Codenys and Richard 23 formed a quasi-DJ project called Coder23 which toured in late 2004 and early 2005 as the opening act for VNV Nation. De Meyer contributed vocals on two studio tracks for the Glis album \"Nemesis\" in 2005. The lyrical content of the two songs (\"The Irreparable\" and \"La B\u00e9atrice\") were based on the poems of Charles Baudelaire.\nFront 242 toured through twenty venues in North America in November 2005, their first tour as a full band since 2000. The band performed at the Roskilde Festival in 2006. The band's sold out two-day performance at the Ancienne Belgique in Brussels has been recorded for a future release via Alfa Matrix.\nIn December 2006, Front 242 announced from their MySpace page that they were writing music for a video game called \"Cipher Complex\" and provided a link to a teaser trailer with a short sample of one of their scores.\nIn 2007, De Meyer announced a new project: 32CRASH via the Alfa Matrix label. The band is preparing for an album release in October 2007 after the release of the EP \"Humanity\".\nIn August 2008, Front 242 played live at the Infest Festival in Bradford, England.\nIn October 2008, Front 242 performed for the first time in Finland, at the Alternative Party 2008 media arts festival.\n2008\u2013present.\nIn 2008, the band added two new members: Tim Kroker on percussion and Sylvain Guigon on live video projection and effects.\nOn 1 June 2008, the Alfa Matrix label announced that Front 242 would make an ultimate statement towards abusive audio compression by releasing the free two-track download, \"First Moment\". By 15 June the same year, the tracks were made available for free on Alfa Matrix's site in medium and high bit-rate MP3s, WAV, FLAC, and M4A formats. Contrary to what fans and some media speculated, the two-track download was not new studio material. Instead, \"First Moments\" consisted of two previously unreleased live tracks, \"U-Men\" and \"Im Rhythmus Bleiben\", in rather stunning sound quality. It is rumored that over 20,000 people downloaded the tracks within hours of being made available. The label later confirmed that over 25,000 people downloaded the free tracks.\nOn 4 June 2008, Alfa Matrix announced the release of \"Moments...\" The album was a live recording encompassing the best of Front 242's compositions. The album was shipped in several formats including limited CD box sets, vinyl in different colors including 300-copy limited editions, and as a one-disc CD release.\nOn 15 April 2016, Alfa Matrix released the remastered edition of P.U.L.S.E. The re-release featured the companion Still+Raw EP, in multicolored two-disc CD formats with the special collector box set limited to 1242 copies; this box set included the album in vinyl and CD formats, as well as a 1989 live recording, a laminated live pass, posters, and the Alfa Matrix Sounds from the Matrix 017 compilation.\nIn February 2020, Front 242 announced the \"Black To Square One\" US Tour with a planned 13 dates across the country which were to be preceded by a string of concerts in the EU. The US tour was rescheduled for 2021 and many of the European dates were postponed or cancelled due to the global COVID-19 pandemic. The rescheduled 16 date US tour was announced in May 2021 with the first show planned for 15 September 2021, in New York City.\nWhile Front 242 have not released new music since \"Pulse\" in 2003, on the \"Black To Square One\" US Tour they played three 'new' songs: \"Generator\", \"Fix It\", and \"Deeply Asleep.\" There is no information on whether these songs or a new studio album will see a release.\nIn March 2024 Front 242 announced the \"Black Out\" tour, stated to be their last, after which they will retire from live performance. The band performed their final three shows at Ancienne Belgique in Brussels, Brussels Capital, Belgium on January 23, 24 &amp; 25, 2025, which were streamed and are available on YouTube.\nInfluences and style.\nBressanutti cites Musique Concr\u00e8te, Avant Garde, and the experimental music of Karlheinz Stockhausen as early influences. De Meyer cited Joy Division as an early influence for their \"dramatic content.\" The electro-pop style of Fad Gadget also provided early inspiration for the band. While they were aware of, enjoyed, and learned from musical progenitors such as Klaus Schulze, Kraftwerk, and fellow countrymen Telex, the band did not see their styles as particularly influential. When asked in a 1989 interview about Front 242's being grouped with other industrial bands, Codenys replied that they \"were somewhere in between Throbbing Gristle, Kraftwerk, and bands like that, but... wanted to be exclusive, and to have nothing to do with any fashion.\"\nDespite the stated intention of remaining genre-neutral, Front 242 did latch onto a phrase to describe their style: \"electronic body music\" or EBM; a phrase that would expand into a genre in itself. The band was not the first to use \"electronic body music\" as a music descriptor. Kraftwerk used the phrase to describe their 1978 album \"Die Mensch Maschine\" (translated: The Man-Machine) and the German group Deutsch Amerikanische Freundschaft (DAF) used a similar term - \"k\u00f6rpermusik\" - to describe their music at the beginning of the 1980s. Despite not having coined the term originally, Front 242 was the first to explicitly claim EBM as a descriptor on the liner notes of their 1984 album \"No Comment\" and cemented their claim to the genre when given the lead track on the seminal Play It Again Sam compilation \"This Is Electronic Body Music\" in 1988.\nLegacy and cultural influence.\nIn the 1980s, Front 242 strived to project a visual mystery and anonymity to accompany their aggressive physical stage performances. The band's ethic is largely responsible for defining the rivethead style of industrial and EBM culture which included the wearing of military gear, such as flak jackets, camouflage, and combat boots, as well as hairstyles, sunglasses, accessories, tattoos, and piercings.\nDuring the 1991 Gulf War, US Navy ships continuously played a list of songs by Front 242 and other bands such as the Ramones, The Clash, and Ministry as a means of boosting morale and aggression during combat operations. The band were informed of this by military personnel who attended their 1993 tour.\nA broader public was exposed to Front 242's music in 1992 in the film \"Single White Female\", starring Bridget Fonda and Jennifer Jason Leigh. In the film, obsessed roommate Leigh ties Fonda to a chair but leaves her with the television remote control. In order to attract attention, Fonda tunes in to a music video channel and turns up the volume. The video playing at the time is Front 242's \"Rhythm Of Time\", from the album \"Tyranny (For You)\". Also in 1992, the television commercials for the film \"K2\" were set to the Front 242 song \"Moldavia\", from the same album.\nIn 1997, Billboard Encyclopedia featured Front 242 in their \"Top 500 Best Producers in Rock History.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60368", "revid": "30117227", "url": "https://en.wikipedia.org/wiki?curid=60368", "title": "Jean-Luc Godard", "text": "French and Swiss film director (1930\u20132022)\nJean-Luc Godard ( , ; ; 3 December 1930\u00a0\u2013 13 September 2022) was a French and Swiss film director, screenwriter, and film critic. He rose to prominence as a pioneer of the French New Wave film movement of the 1960s, alongside such filmmakers as Fran\u00e7ois Truffaut, Agn\u00e8s Varda, \u00c9ric Rohmer and Jacques Demy. He was arguably the most influential French filmmaker of the post-war era. According to AllMovie, his work \"revolutionized the motion picture form\" through its experimentation with narrative, continuity, sound, and camerawork.\nDuring his early career as a film critic for \"Cahiers du Cin\u00e9ma\", Godard criticized mainstream French cinema's \"Tradition of Quality\" and championed Hollywood directors like Alfred Hitchcock and Howard Hawks. In response, he and like-minded critics began to make their own films, challenging the conventions of traditional Hollywood in addition to French cinema. Godard first received global acclaim for \"Breathless\" (1960), a milestone in the New Wave movement. His work makes use of frequent homages and references to film history, and often expressed his political views; he was an avid reader of existentialism and Marxist philosophy, and in 1969 formed the Dziga Vertov Group with other radical filmmakers to promote political works. After the New Wave, his politics were less radical, and his later films came to be about human conflict and artistic representation \"from a humanist rather than Marxist perspective.\" He explained that \"As a critic, I thought of myself as a film-maker. Today I still think of myself as a critic, and in a sense I am, more than ever before. Instead of writing criticism, I make a film, but the critical dimension is subsumed.\"\nGodard was married three times, to actresses Anna Karina and Anne Wiazemsky, both of whom starred in several of his films, and later to his longtime partner Anne-Marie Mi\u00e9ville. His collaborations with Karina in \"Vivre sa vie\" (1962), \"Bande \u00e0 part\" (1964) and \"Pierrot le Fou\" (1965) were called \"arguably the most influential body of work in the history of cinema\" by \"Filmmaker\" magazine. In a 2002 \"Sight &amp; Sound\" poll, Godard ranked third in the critics' top ten directors of all time.\nHe is said to have \"generated one of the largest bodies of critical analysis of any filmmaker since the mid-twentieth century.\" His work has been central to narrative theory and has \"challenged both commercial narrative cinema norms and film criticism's vocabulary.\" In 2010, Godard was awarded an Academy Honorary Award. He was known for his aphorisms, such as \"All you need to make a movie is a girl and a gun\" and \"A film consists of a beginning, a middle and an end, though not necessarily in that order.\" Some critics have claimed that Godard's films contain prevailing themes of misogyny and sexism towards women. Feminist film theorist Laura Mulvey, has agreed that \"While trying to decode a deep-seated, but interesting, misogyny, I came to think that Godard's cinema knows its own entrapment...for feminist curiosity, it is still a goldmine.\"\nEarly life.\nJean-Luc Godard was born on 3 December 1930 in the 7th arrondissement of Paris, the son of Odile (\"n\u00e9e\" Monod) and Paul Godard, a Swiss physician. His wealthy parents came from Protestant families of Franco\u2013Swiss descent, and his mother was the daughter of Julien Monod, a founder of the Banque Paribas. She was the great-granddaughter of theologian Adolphe Monod. Other relatives on his mother's side include composer Jacques-Louis Monod, naturalist Th\u00e9odore Monod and pastor Fr\u00e9d\u00e9ric Monod. Four years after Jean-Luc's birth, his father moved the family to Switzerland. At the outbreak of the Second World War, Godard was in France, and returned to Switzerland with difficulty. He spent most of the war in Switzerland, although his family made clandestine trips to his grandfather's estate on the French side of Lake Geneva. Godard attended school in Nyon, Switzerland.\nNot a frequent film-goer, he attributed his introduction to cinema to a reading of Andr\u00e9 Malraux's essay \"Outline of a Psychology of Cinema\" and the \"La Revue du cin\u00e9ma\", which was relaunched in 1946. In 1946, he went to study at the Lyc\u00e9e Buffon in Paris and, through family connections, mixed with members of its cultural elite. He lodged with the writer Jean Schlumberger. Having failed his baccalaur\u00e9at exam in 1948, he returned to Switzerland. He studied in Lausanne and lived with his parents, whose marriage was breaking up. He spent time in Geneva also with a group that included another film fanatic, Roland Tolmatchoff, and the extreme rightist philosopher Jean Parvulesco. His elder sister Rachel encouraged him to paint, which he did, in an abstract style. After time spent at a boarding school in Thonon to prepare for the retest, which he passed, he returned to Paris in 1949. He registered for a certificate in anthropology at the University of Paris (Sorbonne), but did not attend class.\nEarly career (1950\u20131959).\nFilm criticism.\nIn Paris, in the Latin Quarter just prior to 1950, \"cin\u00e9-clubs\" (film societies) were gaining prominence. Godard began attending these clubs\u2014the Cin\u00e9math\u00e8que Fran\u00e7aise, Cin\u00e9-Club du Quartier Latin (CCQL), Work and Culture cin\u00e9 club, and others\u2014which became his regular haunts. The Cin\u00e9math\u00e8que was founded by Henri Langlois and Georges Franju in 1936; Work and Culture was a workers' education group for which Andr\u00e9 Bazin had organized wartime film screenings and discussions and which had become a model for the film clubs that had risen throughout France after the Liberation; CCQL, founded in about 1947 or 1948, was animated and intellectually led by Maurice Sch\u00e9rer. At these clubs he met fellow film enthusiasts including Claude Chabrol and Fran\u00e7ois Truffaut. Godard was part of a generation for whom cinema took on a special importance. He said: \"In the 1950s cinema was as important as bread\u2014but it isn't the case anymore. We thought cinema would assert itself as an instrument of knowledge, a microscope... a telescope... At the Cin\u00e9math\u00e8que I discovered a world which nobody had spoken to me about. They'd told us about Goethe, but not Dreyer. ... We watched silent films in the era of talkies. We dreamed about film. We were like Christians in the catacombs.\"\nHis foray into films began in the field of criticism. Along with Maurice Sch\u00e9rer (writing under the to-be-famous pseudonym \u00c9ric Rohmer) and Jacques Rivette, he founded the short-lived film journal \"La Gazette du cin\u00e9ma\", which saw the publication of five issues in 1950. When Bazin co-founded the influential critical magazine \"Cahiers du Cin\u00e9ma\" in 1951 (a seminal publication on cinema and its main observers and participants), Godard was the first of the younger critics from the CCQL/Cin\u00e9math\u00e8que group to be published. The January 1952 issue featured his review of an American melodrama directed by Rudolph Mat\u00e9, \"No Sad Songs for Me\". His \"Defence and Illustration of Classical D\u00e9coupage\" published in September 1952, in which he attacks an earlier article by Bazin and defends the use of the shot\u2013reverse shot technique, is one of his earliest important contributions to cinema criticism. Praising Otto Preminger and \"the greatest American artist\u2014Howard Hawks\", Godard raises their harsh melodramas above the more \"formalistic and overtly artful films of Welles, De Sica, and Wyler which Bazin endorsed\". At this point Godard's activities did not include making films. Rather, he watched films, and wrote about them, and helped others make films, notably Rohmer, with whom he worked on \"Pr\u00e9sentation ou Charlotte et son steak\".\nFilmmaking.\nHaving left Paris in the fall of 1952, Godard returned to Switzerland and went to live with his mother in Lausanne. He became friendly with his mother's lover, Jean-Pierre Laubscher, who was a labourer on the Grande Dixence Dam. Through Laubscher he secured work himself as a construction worker at the Plaz Fleuri work site at the dam. He saw the possibility of making a documentary film about the dam; when his initial contract ended, to prolong his time at the dam, he moved to the post of telephone switchboard operator. While on duty, in April 1954, he put through a call to Laubscher which relayed the fact that Odile Monod, Godard's mother, had died in a scooter accident. Thanks to Swiss friends who lent him a 35 mm movie camera, he was able to shoot on 35mm film. He rewrote the commentary that Laubscher had written, and gave his film a rhyming title \"Op\u00e9ration b\u00e9ton\" (\"Operation Concrete\"). The company that administered the dam bought the film and used it for publicity purposes.\nAs he continued to work for \"Cahiers\", he made \"Une femme coquette\" (1955), a 10-minute short, in Geneva; and in January 1956 he returned to Paris. A plan for a feature film of Goethe's \"Elective Affinities\" proved too ambitious and came to nothing. Truffaut enlisted his help to work on an idea he had for a film based on the true-crime story of a petty criminal, Michel Portail, who had shot a motorcycle policeman and whose girlfriend had turned him in to the police, but Truffaut failed to interest any producers. Another project with Truffaut, a comedy about a country girl arriving in Paris, was also abandoned. He worked with Rohmer on a planned series of short films centering on the lives of two young women, Charlotte and V\u00e9ronique; and in the autumn of 1957, Pierre Braunberger produced the first film in the series, \"All the Boys Are Called Patrick\", directed by Godard from Rohmer's script. \"A Story of Water\" (1958) was created largely out of unused footage shot by Truffaut. In 1958, Godard, with a cast that included Jean-Paul Belmondo and Anne Colette, made his last short before gaining international prominence as a filmmaker, \"Charlotte et son Jules\", an homage to Jean Cocteau. The film was shot in Godard's hotel room on the rue de Rennes and apparently reflected something of the 'romantic austerity' of Godard's own life at this time. His Swiss friend Roland Tolmatchoff noted: \"In Paris he had a big Bogart poster on the wall and nothing else.\" In December 1958, Godard reported from the Festival of Short Films in Tours and praised the work of, and became friends with Jacques Demy, Jacques Rozier and Agn\u00e8s Varda\u2014he already knew Alain Resnais whose entry he praised\u2014but Godard now wanted to make a feature film. He travelled to the 1959 Cannes Film Festival and asked Truffaut to let him use the story on which they had collaborated in 1956, about car thief Michel Portail. He sought money from producer Georges de Beauregard, whom he had met previously while working briefly in the publicity department of Twentieth Century Fox's Paris office, and who was also at the Festival. Beauregard could offer his expertise, but was in debt from two productions based on Pierre Loti stories; hence, financing came instead from a film distributor, Ren\u00e9 Pigni\u00e8res.\nNew Wave (1960\u20131967).\n\"Breathless\".\nGodard's \"Breathless\" (\"\u00c0 bout de souffle\", 1960), starring Jean-Paul Belmondo and Jean Seberg, distinctly expressed the French New Wave's style, and incorporated quotations from several elements of popular culture\u2014specifically American film noir. It was based on a story suggested by Fran\u00e7ois Truffaut. The film employed various techniques such as the innovative use of jump cuts (which were traditionally considered amateurish), character asides and breaking the eyeline match in continuity editing. Another unique aspect of \"Breathless\" was the spontaneous writing of the script on the day of shooting\u2014a technique that the actors found unsettling\u2014which contributed to the spontaneous, documentary-like ambiance of the film.\nFrom the beginning of his career, Godard included more film references in his movies than any of his New Wave colleagues. In \"Breathless\", his citations include a movie poster showing Humphrey Bogart (from his last film, \"The Harder They Fall\"), whose expression Belmondo tries reverently to imitate\u2014visual quotations from the films of Ingmar Bergman, Samuel Fuller, Fritz Lang and others; and an onscreen dedication to Monogram Pictures, an American B-movie studio. Quotations from, and references to, literature include William Faulkner, Dylan Thomas, Louis Aragon, Rainer Maria Rilke, Fran\u00e7oise Sagan and Maurice Sachs. The film also contains citations to composers (J. S. Bach, Mozart) and painters (Picasso, Paul Klee and Auguste Renoir).\nGodard wanted to hire Seberg, who was living in Paris with her husband Fran\u00e7ois Moreuil, a lawyer, to play the American woman. Seberg had become famous in 1956 when Otto Preminger had chosen her to play Joan of Arc in his \"Saint Joan\", and had then cast her in his 1958 adaptation of \"Bonjour Tristesse\". Her performance in this film had not been generally regarded as a success\u2014\"The New York Times\"'s critic called her a \"misplaced amateur\"\u2014but Truffaut and Godard disagreed. In the role of Michel Poiccard, Godard cast Belmondo, an actor he had already called, in \"Arts\" in 1958, \"the Michel Simon and the Jules Berry of tomorrow.\" The cameraman was Raoul Coutard, choice of the producer Beauregard. Godard wanted \"Breathless\" to be shot like a documentary, with a lightweight handheld camera and a minimum of added lighting; Coutard had experience as a documentary cameraman while working for the French army's information service during the French-Indochina War. Tracking shots were filmed by Coutard from a wheelchair pushed by Godard. Though Godard had prepared a traditional screenplay, he dispensed with it and wrote the dialogue day by day as the production went ahead. The film's importance was recognized immediately, and in January 1960 Godard won the Jean Vigo Prize, awarded \"to encourage an auteur of the future\". One reviewer mentioned Alexandre Astruc's prophecy of the age of the \"cam\u00e9ra-stylo\", the camera that a new generation would use with the efficacy with which a writer uses his pen\u2014\"here is in fact the first work authentically written with a \"cam\u00e9ra-stylo\"\". Richard Brody writes: \"After \"Breathless\", anything artistic appeared possible in the cinema. The film moved at the speed of the mind and seemed, unlike anything that preceded it, a live recording of one person thinking in real time.\" Phillip Lopate wrote that \"It seemed a new kind of storytelling, with its saucy jump cuts, digressions, quotes, in jokes and addresses to the viewer.\"\nEarly work with Anna Karina.\nIn 1960 Godard shot \"Le petit soldat\" (\"The Little Soldier\"). The cast included Godard's future wife Anna Karina. At this time Karina had virtually no experience as an actress. Godard used her awkwardness as an element of her performance. Godard and Karina were a couple by the end of the shoot. She appeared again, along with Belmondo, in Godard's first color film, \"A Woman Is a Woman\" (1961), their first project to be released. The film was intended as an homage to the American musical. Adjustments that Godard made to the original version of the story gave it autobiographical resonances, \"specifically in regard to his relationship with Anna Karina.\" The film revealed \"the confinement within the four walls of domestic life\" and \"the emotional and artistic fault lines that threatened their relationship\".\n\"Vivre sa vie\".\nGodard's next film, \"Vivre sa vie\" (\"My Life to Live\", 1962), was one of his most popular among critics. Karina starred as Nana, an errant mother and aspiring actress whose financially strained circumstances lead her to the life of a streetwalker. It is an episodic account of her rationalizations to prove she is free, even though she is tethered at the end of her pimp's short leash. In one scene, within a caf\u00e9, she spreads her arms out and announces she is free to raise or lower them as she wishes.\nThe film was a popular success and led to Columbia Pictures giving him a deal where he would be provided with $100,000 to make a movie, with complete artistic control.\n\"Le petit soldat\" and \"Les Carabiniers\".\n\"Le petit soldat\" was not released until 1963, the first of three films he released that year. It dealt with the Algerian War of Independence and was banned by the French government for the next two years due to its political nature. The 'little soldier' Bruno Forestier was played by Michel Subor. Forestier was a character close to Godard himself, an image-maker and intellectual, 'more or less my spokesman, but not totally' Godard told an interviewer.\nThe film begins on 13 May 1958, the date of the attempted putsch in Algeria, and ends later the same month. In the film, Bruno Forestier, a photojournalist who has links with a right-wing paramilitary group working for the French government, is ordered to murder a professor accused of aiding the Algerian resistance. He is in love with Veronica Dreyer, a young woman who has worked with the Algerian fighters. He is captured by Algerian militants and tortured. His organization captures and tortures her. In making \"Le petit soldat\", Godard took the unusual step of writing dialogue every day and calling the lines to the actors during filming \u2013 a technique made possible by filming without direct sound and dubbing dialogue in post-production.\nHis following film was \"Les Carabiniers\", based on a story by Roberto Rossellini, one of Godard's influences. The film follows two peasants who join the army of a king, only to find futility in the whole thing as the king reveals the deception of war-administrating leaders.\n\"Contempt\".\nHis final film of 1963, and the most commercially successful of his career, was \"Le M\u00e9pris\" (\"Contempt\"), starring Michel Piccoli and one of France's biggest female stars, Brigitte Bardot. The film follows Paul (Piccoli), a screenwriter who is commissioned by Prokosch (Jack Palance), an arrogant American movie producer, to rewrite the script for an adaptation of Homer's \"Odyssey\", directed by Austrian director Fritz Lang (playing himself). Lang's 'high culture' interpretation of the story is lost on Prokosch, whose character is a firm indictment of the commercial motion picture hierarchy.\nAnouchka Films.\nIn 1964, Godard and Karina formed a production company, Anouchka Films. He directed \"Bande \u00e0 part\" (\"Band of Outsiders\"), also starring Karina and described by Godard as \"\"Alice in Wonderland\" meets Franz Kafka.\" It follows two young men, looking to score on a heist, who both fall in love with Karina, and quotes from several gangster film conventions. While promoting the film, Godard wrote that according to D. W. Griffith, all one needs to make a film is \"a girl and a gun.\"\n\" Une femme mari\u00e9e\" (\"A Married Woman\", 1964) followed \"Band of Outsiders\". It was a slow, deliberate, toned-down black-and-white picture without a real story. The film was shot in four weeks and was \"an explicitly and stringently modernist film\". It showed Godard's \"engagement with the most advanced thinking of the day, as expressed in the work of Claude L\u00e9vi-Strauss and Roland Barthes\" and its fragmentation and abstraction reflected also \"his loss of faith in the familiar Hollywood styles.\"\nIn 1965, Godard directed \"Alphaville\", a futuristic blend of science fiction, film noir and satire. Eddie Constantine starred as Lemmy Caution, a detective who is sent into a city controlled by a giant computer named Alpha 60. His mission is to make contact with Professor von Braun (Howard Vernon), a famous scientist who has fallen mysteriously silent, and is believed to be suppressed by the computer. His next film was \"Pierrot le Fou\" (1965). Gilles Jacob, an author, critic and president of the Cannes Film Festival, called it both a \"retrospective\" and recapitulation. He solicited the participation of Belmondo, by then a famous actor, to guarantee the necessary amount of funding for the expensive film. Godard said the film was \"connected with the violence and loneliness that lie so close to happiness today. It's very much a film about France.\" The film featured American director Samuel Fuller as himself.\n\"Masculin F\u00e9minin\" (1966), based on two Guy de Maupassant stories, \"La Femme de Paul\" and \"Le Signe\", was a study of contemporary French youth and their involvement with cultural politics. An intertitle refers to the characters as \"The children of Marx and Coca-Cola.\" Although Godard's cinema is sometimes thought to depict a wholly masculine point of view, Phillip John Usher has demonstrated how the film, by the way it connects images and disparate events, seems to blur gender lines.\nGodard followed with \"Made in U.S.A\" (1966), the source material for which was Richard Stark's \"The Jugger\". A classic New Wave crime thriller, it was inspired by American Noir films. Karina stars as the anti-hero searching for her murdered lover and the film includes a cameo by Marianne Faithfull. A year later came \"Two or Three Things I Know About Her\" (1967), in which Marina Vlady portrays a woman leading a double life as housewife and prostitute, considered to be \"among the greatest achievements in filmmaking.\"\n\"La Chinoise\" (1967) saw Godard at his most politically forthright so far. The film focused on a group of students and engaged with the ideas coming out of the student activist groups in contemporary France. Released just before the May 1968 events, the film is thought by some to have foreshadowed the student rebellions that took place.\n\"Week End\".\nThat same year, Godard made a more colourful and political film, \"Week End\". It follows a Parisian couple as they leave on a weekend trip across the French countryside to collect an inheritance. What ensues is a confrontation with the tragic flaws of the over-consuming bourgeoisie. The film contains an eight-minute tracking shot of the couple stuck in an unremitting traffic jam as they leave the city, cited as a technique Godard used to deconstruct bourgeois trends. Startlingly, a few shots contain extra footage from, as it were, before the beginning of the take (while the actors are preparing) and after the end of the take (while the actors are coming out of character). \"Week End\"'s enigmatic and audacious end title sequence, which reads \"End of Cinema\", appropriately marked an end to the narrative and cinematic period in Godard's filmmaking career.\nPolitical period (1968\u20131979).\nGodard was known for his \"highly political voice\", and regularly featured political content in his films. One of his earliest features, \"Le petit soldat\", which dealt with the Algerian War of Independence, was notable for its attempt to present the complexity of the dispute; the film was perceived as equivocating and as drawing a \"moral equivalence\" between the French forces and the National Liberation Front. Along these lines, \"Les Carabiniers\" presents a fictional war that is initially romanticized in the way its characters approach their service, but becomes a stiff anti-war metonym. In addition to the international conflicts to which Godard sought an artistic response, he was also very concerned with the social problems in France. The earliest and best example of this is Karina's potent portrayal of a prostitute in \"Vivre sa vie\". In 1960s Paris, the political milieu was not overwhelmed by one specific movement. There was, however, a distinct post-war climate shaped by various international conflicts such as colonialism in North Africa and Southeast Asia. Godard's Marxist disposition did not become abundantly explicit until \"La Chinoise\" and \"Week End\", but is evident in several films\u2014namely \"Pierrot\" and \"Une femme mari\u00e9e\".\nGodard was accused by some of harbouring anti-Semitic views: in 2010, in the lead-up to the presentation of Godard's honorary Oscar, a prominent article in \"The New York Times\" by Michael Cieply drew attention to the idea, which had been circulating through the press in previous weeks, that Godard might be an anti-Semite, and thus undeserving of the accolade. Cieply makes reference to Richard Brody's book \"Everything is Cinema: The Working Life of Jean-Luc Godard\", and alluded to a previous, longer article published by the \"Jewish Journal\" as lying near the origin of the debate. The article also draws upon Brody's book, for example in the following quotation, which Godard made on television in 1981: \"Moses is my principal enemy...Moses, when he received the commandments, he saw images and translated them. Then he brought the texts, he didn't show what he had seen. That's why the Jewish people are accursed.\"\nImmediately after Cieply's article was published, Brody made a clear point of criticising the \"extremely selective and narrow use\" of passages in his book, and noted that Godard's work approached the Holocaust with \"the greatest moral seriousness\". Indeed, his documentaries feature images from the Holocaust in a context suggesting he considers Nazism and the Holocaust as the nadir of human history. Godard's views become more complex regarding the State of Israel. In 1970, Godard travelled to the Middle East to make a pro-Palestinian film he did not complete and whose footage eventually became part of the 1976 film \"Ici et ailleurs\". In this film, Godard seems to view the Palestinians' cause as one of many worldwide Leftist revolutionary movements. Elsewhere, Godard explicitly identified himself as an anti-Zionist but denied the accusations of anti-Semitism.\nVietnam War.\nGodard produced several pieces that directly address the Vietnam War. Furthermore, there are two scenes in \"Pierrot le fou\" that tackle the issue. The first is a scene that takes place in the initial car ride between Ferdinand (Belmondo) and Marianne (Karina). Over the car radio, the two hear the message \"garrison massacred by the Viet Cong who lost 115 men\". Marianne responds with an extended musing on the way the radio dehumanises the Northern Vietnamese combatants. The war is present throughout the film in mentions, allusions, and depictions in newsreel footage, and the film's style was affected by Godard's political anger at the war, upsetting his ability to draw from earlier cinematic styles.\nNotably, he also participated in \"Loin du Vietnam\" (1967). An anti-war project, it consists of seven sketches directed by Godard (who used stock footage from \"La Chinoise\"), Claude Lelouch, Joris Ivens, William Klein, Chris Marker, Alain Resnais, and Agn\u00e8s Varda.\nBertolt Brecht.\nGodard's engagement with German poet and playwright Bertolt Brecht stems primarily from his attempt to transpose Brecht's theory of epic theatre and its prospect of alienating the viewer (\"Verfremdungseffekt\") through a radical separation of the elements of the medium (theatre in Brecht's case, but in Godard's, film). Brecht's influence is keenly felt through much of Godard's work, particularly before 1980, when Godard used cinematic expression for specific political ends.\nFor example, \"Breathless\"'s elliptical editing, which denies the viewer a fluid narrative typical of mainstream cinema, forces the viewers to take on more critical roles, connecting the pieces themselves and coming away with more investment in the work's content. In many of his most political pieces, specifically \"Week-end\", \"Pierrot le Fou\", and \"La Chinoise\", characters address the audience with thoughts, feelings, and instructions.\nMarxism.\nA Marxist reading is possible with most if not all of Godard's early work. Godard's direct interaction with Marxism does not become explicitly apparent, however, until \"Week-end\", where the name Karl Marx is cited in conjunction with figures such as Jesus Christ. A constant refrain throughout Godard's cinematic period is that of the bourgeoisie's consumerism, the commodification of daily life and activity, and man's alienation\u2014all central features of Marx's critique of capitalism.\nIn an essay on Godard, philosopher and aesthetics scholar Jacques Ranci\u00e8re states, \"When in \"Pierrot le fou\", 1965, a film without a clear political message, Belmondo played on the word 'scandal' and the 'freedom' that the Scandal girdle supposedly offered women, the context of a Marxist critique of commodification, of pop art derision at consumerism, and of a feminist denunciation of women's false 'liberation', was enough to foster a dialectical reading of the joke and the whole story.\" The way Godard treated politics in his cinematic period was in the context of a joke, a piece of art, or a relationship, presented to be used as tools of reference, romanticising the Marxist rhetoric, rather than being solely tools of education.\n\"Une femme mari\u00e9e\" is also structured around Marx's concept of commodity fetishism. Godard once said that it is \"a film in which individuals are considered as things, in which chases in a taxi alternate with ethological interviews, in which the spectacle of life is intermingled with its analysis\". He was very conscious of the way he wished to portray the human being. His efforts are overtly characteristic of Marx, who in his \"Economic and Philosophical Manuscripts of 1844\" gives one of his most nuanced elaborations, analysing how the worker is alienated from his product, the object of his productive activity. Georges Sadoul, in his short rumination on the film, describes it as a \"sociological study of the alienation of the modern woman\".\nRevolutionary period (1968\u20131979).\nThe period which spans from May 1968 into the 1970s has been given various labels\u2014from his \"militant\" period, to his \"radical\" period, along with terms as specific as \"Maoist\" and as vague as \"political\". In any case, the period saw Godard employ consistent revolutionary rhetoric in his films and in his public statements.\nInspired by the May 68 upheaval, Godard, alongside Fran\u00e7ois Truffaut, led protests that shut down the 1968 Cannes Film Festival in solidarity with the students and workers. Godard stated there was not a single film showing at the festival that represented their causes. \"Not one, whether by Milos, myself, Roman or Fran\u00e7ois. There are none. We're behind the times.\"\nFilms.\nAmid the upheavals of the late 1960s, Godard became passionate about \"making political films politically.\" Though many of his films from 1968 to 1972 are feature-length films, they are low-budget and challenge the notion of what a film can be. In addition to abandoning mainstream filmmaking, Godard also tried to escape the cult of personality that had formed around him. He worked anonymously in collaboration with other filmmakers, most notably Jean-Pierre Gorin, with whom he formed the Dziga-Vertov cinema collective. During this period Godard made films in England, Italy, Czechoslovakia, Palestine, and the U.S., as well as France. He and Gorin toured with their work, attempting to create discussion, mainly on college campuses. This period came to a climax with the big-budget production \"Tout Va Bien\", which starred Yves Montand and Jane Fonda. Owing to a motorcycle accident that severely incapacitated Godard, Gorin ended up directing this most celebrated of their work together almost single-handedly. As a companion piece to \"Tout va bien\", the pair made \"Letter to Jane\", a 50-minute \"examination of a still\" showing Jane Fonda visiting North Vietnam during the Vietnam War. The film is a deconstruction of Western imperialist ideology. This was the last film that Godard and Gorin made together.\nIn 1978 Godard was commissioned by the Mozambican government to make a short film. During this time his experience with Kodak film led him to criticise the film stock as \"inherently racist\" since it did not reflect the variety, nuance or complexity in dark brown or dark skin. This was because Kodak Shirley cards were only made for Caucasian subjects, a problem that was not rectified until 1995.\nSonimage.\nIn 1972, Godard and his life partner, Swiss filmmaker, Anne-Marie Mi\u00e9ville started the alternative video production and distribution company Sonimage, based in Grenoble. Under Sonimage, Godard produced \"Comment ca va\", \"Num\u00e9ro Deux\" (1975) and \"Sauve qui peut (la vie)\" (1980). In 1976, Godard and Mi\u00e9ville, his future wife, collaborated on a series of innovative video works for European broadcast television, titled \"Six fois deux/Sur et sous la communication\" (1976) and \"France/tour/d\u00e9tour/deux/enfants\" (1978). From the time that Godard returned to mainstream filmmaking in 1980, Anne-Marie Mi\u00e9ville remained an important collaborator.\nJean-Pierre Gorin.\nAfter the events of May 1968, when the city of Paris saw a total upheaval in response to the \"authoritarian de Gaulle\", and Godard's professional objective was reconsidered, he began to collaborate with like-minded individuals in the filmmaking arena. His most notable collaborator was Jean-Pierre Gorin, a Maoist student of Louis Althusser, Michel Foucault, and Jacques Lacan, who later became a professor of Film Studies at the University of California at San Diego, with a passion for cinema that attracted Godard's attention.\nBetween 1968 and 1973, Godard and Gorin collaborated to make a total of five films with strong Maoist messages. The most prominent film from the collaboration was \"Tout Va Bien\" (1972). The film starred Jane Fonda, who was, at the time, the wife of French filmmaker Roger Vadim. Fonda was at the height of her acting career, having won an Academy Award for her performance in \"Klute\" (1971), and had gained notoriety as a left-wing anti-war activist. The male lead was the legendary French singer and actor Yves Montand, who had appeared in prestigious films by Georges Clouzot, Alain R\u00e9snais, Sacha Guitry, Vincente Minelli, George Cukor, and Costa-Gavras.\nDziga Vertov Group.\nThe small group of Maoists that Godard had brought together, which included Gorin, adopted the name Dziga Vertov Group. Godard had a specific interest in Dziga Vertov, a Soviet filmmaker\u2014who was known for a series of radical documentaries titled \"Kino Pravda\" (literally, \"film truth\") and the late silent-era feature film \"Man with a Movie Camera\" (1929). Vertov was also a contemporary of both Soviet montage theorists, notably Sergei Eisenstein, and Russian constructivist and avant-garde artists such as Alexander Rodchenko and Vladimir Tatlin. Part of Godard's political shift after May 1968 was toward a proactive participation in the class struggle and he drew inspiration from filmmakers associated with the Russian Revolution.\nTowards the end of this period of his life, Godard began to feel disappointed with his Maoist ideals and was abandoned by his wife at the time, Anne Wiazemsky. In this context, according to biographer Antoine de Baecque, Godard attempted suicide on two occasions.\nReturn to commercial films and \"Histoire(s) du cin\u00e9ma\" (1980\u20132000).\nGodard returned to somewhat more traditional fiction with \"Sauve qui peut (la vie)\" (1980), the first of a series of more mainstream films marked by autobiographical currents: it was followed by \"Passion\", \"Lettre \u00e0 Freddy Buache\" (both 1982), \"Pr\u00e9nom Carmen\" (1983), and \"Grandeur et d\u00e9cadence d'un petit commerce de cin\u00e9ma\" (1986). There was, though, another flurry of controversy with \"Je vous salue, Marie\" (1985), which was condemned by the Roman Catholic Church for alleged heresy, and also with \"King Lear\" (1987), a postmodern production of the play by William Shakespeare. Also completed in 1987 was a segment in the film \"Aria\" which was based loosely from the plot of Armide; it is set in a gym and uses several arias by Jean-Baptiste Lully from his famous \"Armide\".\nHis later films were marked by great formal beauty and frequently a sense of requiem: \"Nouvelle Vague\" (\"New Wave\", 1990), the autobiographical \"JLG/JLG, autoportrait de d\u00e9cembre\" (\"JLG/JLG: Self-Portrait in December\", 1995), and \"For Ever Mozart\" (1996). \"Allemagne ann\u00e9e 90 neuf z\u00e9ro\" (\"Germany Year 90 Nine Zero\", 1991) which is a quasi-sequel to \"Alphaville\", but done with an elegiac tone and focus on the inevitable decay of age. He won the Medaglia d'oro della Presidenza del Senato for the film. In 1990, Godard was presented with a special award from the National Society of Film Critics. Between 1988 and 1998, he produced the multi-part series \"Histoire(s) du cin\u00e9ma\", a monumental project which combined all the innovations of his video work with a passionate engagement in the issues of twentieth-century history and the history of film itself.\nLate period films (2001\u20132022).\nIn 2001, \"\u00c9loge de l'amour\" (\"In Praise of Love\") was released. The film is notable for its use of both film and video\u2014the first half captured in 35\u00a0mm black and white, the latter half shot in color on DV\u2014and subsequently transferred to film for editing. The film is also noted for containing themes of ageing, love, separation, and rediscovery as it follows the young artist Edgar in his contemplation of a new work on the four stages of love. In \"Notre musique\" (2004), Godard turned his focus to war, specifically, the war in Sarajevo, but with attention to all war, including the American Civil War, the war between the U.S. and Native Americans, and the Israeli\u2013Palestinian conflict. The film is structured into three Dantean kingdoms: Hell, Purgatory, and Paradise. Godard's fascination with paradox is constant in the film. It opens with a long, ponderous montage of war images that occasionally lapses into the comic; Paradise is shown as a lush wooded beach patrolled by U.S. Marines.\nGodard's film \"Film Socialisme\" (2010) premiered in the Un Certain Regard section at the 2010 Cannes Film Festival. It was released theatrically in France in May 2010. Godard was rumoured to be considering directing a film adaptation of Daniel Mendelsohn's \"\", an award-winning book about the Holocaust. In 2013, Godard released the short \"Les trois d\u00e9sastres\" (\"The Three Disasters\") as part of the omnibus film \"3X3D\" with filmmakers Peter Greenaway and Edgar Pera. \"3X3D\" premiered at the 2013 Cannes Film Festival. His 2014 film \"Goodbye to Language\", shot in 3-D, revolves around a couple who cannot communicate with each other until their pet dog acts as an interpreter for them. The film makes reference to a wide range of influences such as paintings by Nicolas de Sta\u00ebl and the writing of William Faulkner, as well as the work of mathematician Laurent Schwartz and dramatist Bertolt Brecht\u2014one of Godard's most important influences. It was selected to compete for the Palme d'Or in the main competition section at the 2014 Cannes Film Festival, where it won the Jury Prize. Godard's non-traditional script for the film was described as a collage of handwritten text and images, and an \"artwork\" itself.\nIn 2015 J. Hoberman reported that Godard was working on a new film. Initially titled \"Tentative de bleu\", in December 2016 Wild Bunch co-chief Vincent Maraval stated that Godard had been shooting \"Le livre d'image\" (\"The Image Book\") for almost two years \"in various Arab countries, including Tunisia\" and that it is an examination of the modern Arab World.\"Godard presented the film at several international festivals, where it received a Special Palme d'Or at the 2018 Cannes Film Festival.\n\"Le livre d'image\" was first shown in May 2018 at the Cannes Film Festival, and later released more widely in November 2018. On 4 December 2019, an art installation piece created by Godard opened at the Fondazione Prada in Milan. Titled \"Le Studio d'Orph\u00e9e\", the installation is a recreated workspace and includes editing equipment, furniture, and other materials used by Godard in post-production.\nIn 2020, Godard told \"Les Inrockuptibles\" that his new film would be about a Yellow vest protestor, and indicated that along with archival footage \"there will also be a shoot. I don't know if I will find what are called actors...I would like to film the people we see on news channels but by plunging them into a situation where documentary and fiction come together.\" In March 2021 he said that he was working on two new films during a virtual interview at the International Film Festival of Kerala. Godard stated \"I'm finishing my movie life \u2014 yes, my moviemaker life \u2014 by doing two scripts...After, I will say, 'Goodbye, cinema.'\"\nIn July 2021, cinematographer and long time collaborator Fabrice Aragno said that work on the films was going slowly and Godard was more focused on \"books, on the ideas of the film, and less in the making.\" Godard suggested making a film like Chris Marker's \"La Jet\u00e9e\" to \"come back to his origin.\" Much of the film would be shot on 35mm, 16mm and 8mm film, but the expense of celluloid film stock and the COVID-19 pandemic stalled production. Aragno expected to shoot test footage that fall. He added that the second film was for the Arte channel in France. The first of the two films, a 20-minute short titled \"\", premiered at the 2023 Cannes Film Festival, in collaboration with St. Laurent. The second and final posthumous short, \"Scenarios\", left unfinished at the time of Godard's death, was finished by Aragno and Jean-Paul Battagia and will have its world premiere at the 2024 Cannes Film Festival.\nAragno said that he did not think that either film would be Godard's last film, adding \"I say this often that \"\u00c9loge de l'amour\" was the beginning of his last gesture. These five, or six or seven films are connected to each other in a way, they're not just full stops. It's not just one painting.\"\nPersonal life and death.\nGodard was married to two of his leading women: Anna Karina (1961\u20131965) and Anne Wiazemsky (1967\u20131979). Beginning in 1970, he collaborated personally and professionally with Anne-Marie Mi\u00e9ville. Godard lived with Mi\u00e9ville in Rolle, Switzerland, from 1978 onwards, and was described by his former wife Karina as a \"recluse\". Godard married Mi\u00e9ville in the 2010s, according to Patrick Jeanneret, an adviser to Godard.\nHis relationship with Karina in particular produced some of his most critically acclaimed films, and their relationship was widely publicised: \"The Independent\" described them as \"one of the most celebrated pairings of the 1960s\". \"Filmmaker\" magazine called their collaborations \"arguably the most influential body of work in the history of cinema.\"\nAccording to Karina, their relationship was tumultuous. Later in life, Karina said they no longer spoke to each other.\nThrough his father, he was the cousin of Pedro Pablo Kuczynski, former President of Peru.\nIn 2017, Michel Hazanavicius directed a film about Godard, \"Redoubtable\", based on the memoir \"One Year After\" (; 2015) by Wiazemsky. It centers on his life in the late 1960s, when he and Wiazemsky made films together. The film premiered at the Cannes Film Festival in 2017. Godard said that the film was a \"stupid, stupid idea\".\nAgnes Varda's 2017 documentary \"Faces Places\" culminates with Varda and co-director JR knocking on Godard's front door in Rolle for an interview. Godard agreed to the meeting but he \"stands them up\". His nephew and assistant Paul Grivas directed the 2018 documentary \"Film Catastrophe\", which included behind-the-scenes footage, shot on the \"Costa Concordia\" cruise ship by Grivas during the making of \"Film Socialism\", of Godard working with actors and directing the film. Godard participated in the 2022 documentary \"See You Friday, Robinson\". Director Mitra Farahani initiated an email exchange between Godard and Iranian filmmaker Ebrahim Golestan, with emailed text letters from Golestan and \"videos, images, and aphorism\" responses from Godard.\nAt the age of 91, Godard died on 13 September 2022, at his home in Rolle. His death was reported as an assisted suicide procedure, which is legal in Switzerland. Godard's legal advisor said that he had \"multiple disabling pathologies\", but a family member said that \"He was not sick, he was simply exhausted\". Mi\u00e9ville was by his side when he died. His body was cremated and there was no funeral service.\nLegacy.\nGodard has been recognised as one of the most influential filmmakers of the 20th century and one of the leaders of the French New Wave.\nFilm critic Pauline Kael suggests that what made young people so drawn to Godard was the disturbing quality of this work.\nIn 1969, film critic Roger Ebert wrote about Godard's importance in cinema:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Godard is a director of the very first rank; no other director in the 1960s has had more influence on the development of the feature-length film. Like Joyce in fiction or Beckett in theater, he is a pioneer whose present work is not acceptable to present audiences. But his influence on other directors is gradually creating and educating an audience that will, perhaps in the next generation, be able to look back at his films and see that this is where their cinema began.In 2001, Ebert recalled his early days as a critic, writing \"As much as we talked about Tarantino after \"Pulp Fiction\", we talked about Godard in those days.\" Tarantino named his production company A Band Apart, a reference to Godard's 1964 film. Tarantino says that \"To me Godard did to movies what Bob Dylan did to music. They both revolutionized their forms.\"\nGodard's works and innovations have received praise from notable directors such as Michelangelo Antonioni, Satyajit Ray, and George Lucas. Fritz Lang agreed to take part in Godard's film \"Le M\u00e9pris\" due to his admiration of Godard as a director. Akira Kurosawa listed \"Breathless\" as one of his 100 favourite films. Ingmar Bergman strongly disliked Godard, stating: \"I've never gotten anything out of his movies. They have felt constructed, faux intellectual and completely dead. Cinematographically uninteresting and infinitely boring. He's made his films for the critics. One of the movies, \"Masculin F\u00e9minin\" (1966), was shot here in Sweden. It was mind-numbingly boring.\" Orson Welles admired Godard as a director but criticized him as a thinker, telling Peter Bogdanovich: \"He is the definitive \"influence\" if not really the first great film artist of this last decade, and his gifts as a director are enormous. I just can't take him very seriously as a \"thinker\"\u2014and that's where we seem to differ, because \"he\" does.\"\nDavid Thomson reached a similar conclusion, writing that \"Godard's greatness rests in his grasping of the idea that films are made of moving images, of moments from films, of images projected in front of audiences\" but that \"He knows only cinema: on politics and real life he is childish and pretentious.\" Still, Thomson calls Godard's early films \"a magnificent critical explanation of American movies\" and \"one of the inescapable bodies of work\" and deserving of retrospectives. Thomson included \"Pierrot le Fou\" on his \" Sight &amp; Sound\" list. Political activist, critic and filmmaker Tariq Ali listed Godard's film \"Tout Va Bien\" as one of his ten favorite films of all time in the 2012 \"Sight and Sound\" critics' poll. American film critic Armond White listed Godard's film \"Nouvelle Vague\" as one of his top ten favorite films in the same poll. Susan Sontag called \"Vivre sa vie\" \"one of the most extraordinary, beautiful and original works of art I know of.\" Four of Godard's films are included on the 2022 edition of the \"Sight and Sound\" list of 100 Greatest Films: \"Breathless\" (38), \"Le M\u00e9pris\" (54), \"Histoire(s) du cin\u00e9ma\" (78) and \"Pierrot le Fou\" (85).\nThe 60th New York Film Festival paid tribute to Godard, who died earlier that year. \"The Onion\" paid homage to him with the headline \"Jean-Luc Godard Dies At End of Life In Uncharacteristically Linear Narrative Choice.\"\nSelected filmography.\nFeature films\nThe list excludes multi-director anthology films to which Godard contributed shorts.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDocumentary\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nShort films\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDiscography.\nGodard had a lasting friendship with Manfred Eicher, founder and head of the German music label ECM Records. The label released the soundtracks of Godard's \"Nouvelle Vague\" (ECM NewSeries 1600\u201301) and \"Histoire(s) du cin\u00e9ma\" (ECM NewSeries 1706). This collaboration expanded over the years, leading to Godard's granting ECM permission to use stills from his films for album covers, while Eicher took over the musical direction of Godard films such as \"Allemagne 90 neuf z\u00e9ro\", \"H\u00e9las Pour Moi\", \"JLG\", and \"For Ever Mozart\". Tracks from ECM records have been used in his films; for example, the soundtrack for \"In Praise of Love\" uses Ketil Bj\u00f8rnstad and David Darling's album \"Epigraphs\" extensively. Godard also released on the label a collection of shorts he made with Anne-Marie Mi\u00e9ville called \"Four Short Films\" (ECM 5001).\nAmong the ECM album covers with Godard's film stills are these:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "60369", "revid": "43252809", "url": "https://en.wikipedia.org/wiki?curid=60369", "title": "Mayoneise", "text": ""}
{"id": "60372", "revid": "1308806671", "url": "https://en.wikipedia.org/wiki?curid=60372", "title": "Calamine (mineral)", "text": "Zinc ore group\nCalamine is a historic name for an ore of zinc. The name \"calamine\" was derived from \"lapis calaminaris\", a Latin correption of Greek \"cadmia (\u03ba\u03b1\u03b4\u03bc\u03af\u03b1)\", the old name for zinc ores in general. The name of the Belgian town of Kelmis, \"La Calamine\" in French, which was home to a zinc mine, comes from this. In the 18th and 19th centuries, large ore mines could be found near the German village of Breinigerberg.\nDuring the early 19th century it was discovered that what had been thought to be one ore was actually two distinct minerals:\nAlthough chemically and crystallographically quite distinct, the two minerals exhibit similar massive or botryoidal external form and are not readily distinguished without detailed chemical or physical analysis. The first person to separate the minerals was the British chemist and mineralogist James Smithson in 1803. In the mining industry the term calamine has been historically used to refer to both minerals indiscriminately.\nIn mineralogy calamine is no longer considered a valid term. It has been replaced by smithsonite and hemimorphite in order to distinguish it from the pinkish mixture of zinc oxide (ZnO) and iron(III) oxide (Fe2O3) known as calamine lotion.\nEarly history.\nIn the 16th century demand for latten (brass) in England came from the needs of wool-carding, for which brass-wire combs were preferred, and battery pieces (brassware formed by hammering sheet brass in a battery mill). The only known method for producing the alloy was by heating copper and calamine together in the cementation process and in 1568 a royal charter was granted to the Society of the Mineral and Battery Works to search for the mineral and produce brass, to reduce dependence on imported metal from Germany. Factories to exploit the process were established at Isleworth and Rotherhithe. By the late 17th century enough was known of metallic zinc to make brass solder directly by combining copper and spelter (zinc ingots). In 1738 a patent was granted to William Champion, a Bristol brass founder, for the large-scale reduction of calamine to produce spelter. There were many calamine mines in Shipham, not far from William Champion's brass works.\nIn 1684 a paper presented to the Royal Society described the medicinal and veterinary properties of the compound when in finely powdered form. Since then no mechanism of action for the powder has been identified, and as of 1992[ [update]] the only medical effect of the powdered mineral appears to be its ability to absorb moisture secreted from irritated and weeping skin.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60373", "revid": "36540065", "url": "https://en.wikipedia.org/wiki?curid=60373", "title": "8-bit clean", "text": "Computer system that correctly handles 8-bit character encodings\nIn computer networking, a system is 8-bit clean if it processes 8-bit character encodings without altering the high bit or treating any byte as an in-band control code. This property can describe both a communications protocol and the software and devices that implement such protocols. Although many early email systems only supported 7-bit data, the vast majority of modern email systems are 8-bit clean.\nHistory.\nUntil the early 1990s, many programs and data transmission channels were character-oriented and treated some characters like end-of-text (ETX) as control characters. Others assumed a stream of seven-bit characters, with values between 0 and 127; for example, the ASCII standard used only seven bits per character, avoiding an eight-bit representation in order to save on data transmission costs. On computers and data links using 8-bit bytes, this left the top bit of each byte free for use as a parity bit, flag bit, or metadata control bit. Seven-bit systems and data links are unable to directly handle more complex character codes which are commonplace in non-English-speaking countries with larger alphabets.\nBinary files consisting of 8-bit octets cannot be transmitted through 7-bit data channels directly. To work around this, binary-to-text encodings have been devised which use only 7-bit ASCII characters. Some of these encodings are uuencoding, Ascii85, SREC, BinHex, kermit and MIME's Base64. EBCDIC-based systems cannot handle all characters used in UUencoded data. However, the base64 encoding does not have this problem.\nSMTP and NNTP.\nHistorically, various media were used to transfer messages, some of which only supported 7-bit data, so an 8-bit message had high chances to be garbled during transmission in the 20th century. Some implementations ignored the formal discouraging of 8-bit data and allowed bytes with the high bit set to pass through. Such implementations are said to be 8-bit clean. In general, a communications protocol is said to be 8-bit clean if it correctly passes through the high bit of each byte in the communication process.\nMany early communications protocol standards, such as (for SMTP), (for NNTP) and , were designed to work over such \"7-bit\" communication links. They specifically require the use of ASCII \"transmitted as an 8-bit byte with the high-order bit cleared to zero\", and some of these explicitly restrict all data to 7-bit characters.\nFor the first few decades of email networks (1971 to the early 1990s), most email messages were plain text in the 7-bit US-ASCII character set.\nThe RFC 788 definition of SMTP, like its predecessor RFC 780, limits Internet Mail to lines (1000 characters or less) of 7-bit US-ASCII characters.\nLater, the format of email messages was redefined in order to support messages that are not entirely US-ASCII text (text messages in character sets other than US-ASCII, and non-text messages, such as audio and images). The header field Content-Transfer-Encoding=binary requires an 8-bit clean transport.\nRFC 3977 specifies that \"NNTP operates over any reliable bi-directional 8-bit-wide data stream channel\" and changes the character set for commands to UTF-8. However, RFC 5536 still limits the character set to ASCII, including RFC 2047 and RFC 2231 MIME encoding of non-ASCII data.\nThe Internet community generally adds features by \"extension\", allowing communication in both directions between upgraded machines and not-yet-upgraded machines, rather than declaring formerly standards-compliant legacy software to be broken and requiring that all software worldwide be upgraded to the latest standard. The recommended way to take advantage of 8-bit clean links between machines is to use the ESMTP () 8BITMIME extension for message bodies and the SMTP SMTPUTF8 extension for message headers. Despite this, some mail transfer agents, notably Exim and qmail, relay mail to servers that do not advertise 8BITMIME without performing the conversion to 7-bit MIME (typically quoted-printable, \"Q-P conversion\") required by . This \"just-send-8\" attitude does not, in fact, cause problems in practice because virtually all modern email servers are 8-bit clean.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60374", "revid": "2214", "url": "https://en.wikipedia.org/wiki?curid=60374", "title": "Eight-bit clean", "text": ""}
{"id": "60376", "revid": "279219", "url": "https://en.wikipedia.org/wiki?curid=60376", "title": "8x86", "text": ""}
{"id": "60377", "revid": "22651524", "url": "https://en.wikipedia.org/wiki?curid=60377", "title": "90\u201390 rule", "text": ""}
{"id": "60378", "revid": "1461430", "url": "https://en.wikipedia.org/wiki?curid=60378", "title": "IBM 709/90 9PAC", "text": "9PAC is a common abbreviation for 709 PACkage. It was a report generator developed in 1959 for the IBM 709 and used on its successor, the IBM 7090. It was developed by SHARE, an early IBM users' group, and based on the File Maintenance and Report Generator System developed by General Electric for the IBM 702, led by Harry Tellier.\nCharles Bachman worked on its design in 1957, and although his company's order for the 709 was cancelled, he later included some of its general concepts into the more generalized idea of navigational databases.\nEngineers at companies such as Union Carbide, Northwest Power Company, Philips Petroleum, Dow Chemical, and Chrysler cooperated on the project.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60379", "revid": "1319029557", "url": "https://en.wikipedia.org/wiki?curid=60379", "title": "Aioli", "text": "West Mediterranean sauce of garlic and oil\nAioli, allioli, or a\u00efoli () is a cold sauce consisting of an emulsion of garlic and olive oil; it is found in the cuisines of the northwest Mediterranean.\nThe names mean 'garlic and oil' in Catalan and Proven\u00e7al. It is found in the cuisines of the Mediterranean coasts of Spain (Catalonia, the Valencian Community, the Balearic Islands, Murcia, and eastern Andalusia) and France (Provence, Languedoc, Roussillon).\nSome versions of the sauce are closer to a garlic mayonnaise, incorporating egg yolks and lemon juice, whereas other versions lack egg yolk and contain more garlic. The latter gives the sauce a pastier texture, making it more laborious to produce as the emulsion is harder to stabilise. There are many variations, such as adding lemon juice or other seasonings. In France, it may include mustard.\nIn Malta, the term arjoli or ajjoli is used for a different preparation made with galletti (a type of cracker), tomato, onion, garlic, and herbs.\nLike mayonnaise, aioli is an emulsion or suspension of small globules of oil and oil-soluble compounds in water and water-soluble compounds. Traditionally, aioli should not include egg, but nowadays, egg or egg yolk is the usual emulsifier.\nSince about 1990, it has become common in the United States to call all flavored mayonnaises \"aioli\". Purists insist that flavored mayonnaise can contain garlic, but true aioli contains garlic and no other seasoning (except salt).\nEtymology.\nIn the form \"aioli\", the word is a compound of Proven\u00e7al 'garlic' and 'oil'.\nThe English spelling comes from the French , which is an adaptation of an Occitan term. The spelling in Occitan may be , following the classical norm, or , following the Mistralian norm. In Catalan it is spelled (). The most common term in Spanish is , an adaptation from Catalan, although it is also called , , or . It is also spelled in Galician.\nBasic recipe.\nGarlic is crushed in a mortar and pestle and emulsified with salt and olive oil.\nToday, aioli is often made in a food processor or blender, but some traditionalists object that this does not give the same result.\nServing.\nIn Occitan cuisine, \"aioli\" is typically served with seafood, fish soup, and croutons. An example is a dish called \"merlu\u00e7a amb alh\u00f2li\". In the Occitan Alps it is served with potatoes boiled with salt and bay laurel.\nIn Proven\u00e7al cuisine, \"aioli\" or, more formally, \"le grand a\u00efoli\", \"aioli garni\", or \"a\u00efoli monstre\" is a dish consisting of various boiled vegetables (usually carrots, potatoes, artichokes, and green beans), poached fish (normally soaked salt cod), snails, canned tuna, other seafood, and boiled eggs, all served with \"aioli\". This dish is often served during the festivities on the feast days of the patron saint of Proven\u00e7al villages and towns. It is traditional to serve it with snails for Christmas Eve and with cod on Ash Wednesday. A\u00efoli is so strongly associated with Provence that when the poet Fr\u00e9d\u00e9ric Mistral started a regionalist Proven\u00e7al-language newspaper in 1891, he called it \"L'Ai\u00f2li\".\nThe Proven\u00e7al cuisine fish soup bourride is generally served with \"aioli\".\nIn Spain, particularly in Catalan cuisine and Valencian cuisine, \"allioli\" is often served with arr\u00f2s negre, arr\u00f2s a banda, fideu\u00e0, with grilled snails (\"cargols a la llauna\"), grilled meat, lamb, rabbit, vegetables, boiled cod (\"bacall\u00e0 a la catalana, bacall\u00e0 amb patates\") and comes in other varieties such as \"allioli de codony\" (allioli with boiled quince, not the preserve) or allioli with boiled pear. Other commonly used vegetables are beets, fennel, celery, zucchini, cauliflower, chickpeas, and raw tomato.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60380", "revid": "711150", "url": "https://en.wikipedia.org/wiki?curid=60380", "title": "Equals (computing)", "text": ""}
{"id": "60381", "revid": "251228", "url": "https://en.wikipedia.org/wiki?curid=60381", "title": "Commercial at (computing)", "text": ""}
{"id": "60382", "revid": "1310273", "url": "https://en.wikipedia.org/wiki?curid=60382", "title": "A Sharp", "text": ""}
{"id": "60383", "revid": "218586", "url": "https://en.wikipedia.org/wiki?curid=60383", "title": "A-0 System", "text": "Programming language\nThe A-0 system (\"Arithmetic Language version 0\") was an early compiler-related tool developed for electronic computers, written by Grace Murray Hopper in 1951 and 1952 originally for the UNIVAC I. The A-0 functioned more as a loader or linker than the modern notion of a compiler. A program was specified as a sequence of subroutines and its arguments. The subroutines were identified by a numeric code and the arguments to the subroutines were written directly after each subroutine code. The A-0 system converted the specification into machine code that could be fed into the computer a second time to execute the said program.\nThe A-0 system was followed by the A-1, A-2, A-3 (released as ARITH-MATIC), AT-3 (released as MATH-MATIC), and B-0 (released as FLOW-MATIC).\nThe A-2 system was developed at the UNIVAC division of Remington Rand in 1953 and released to customers by the end of that year. Customers were provided the source code for A-2 and invited to send their improvements back to UNIVAC. Thus, A-2 could be considered an example of the result of an early philosophy similar to free and open-source software."}
{"id": "60384", "revid": "218586", "url": "https://en.wikipedia.org/wiki?curid=60384", "title": "A0", "text": "A0, A-0, A0, or a0 may refer to:\nSee also.\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles associated with the same title formed as a letter\u2013number combination."}
{"id": "60385", "revid": "41790710", "url": "https://en.wikipedia.org/wiki?curid=60385", "title": "AO", "text": "AO, aO, Ao, or ao may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "60386", "revid": "8570870", "url": "https://en.wikipedia.org/wiki?curid=60386", "title": "A-O", "text": ""}
{"id": "60388", "revid": "269022", "url": "https://en.wikipedia.org/wiki?curid=60388", "title": "A1 security", "text": ""}
{"id": "60389", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=60389", "title": "Orange Book", "text": "Orange Book may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "60390", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=60390", "title": "A20 handler", "text": ""}
{"id": "60391", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=60391", "title": "A-3", "text": ""}
{"id": "60392", "revid": "49006237", "url": "https://en.wikipedia.org/wiki?curid=60392", "title": "Sind Province (1936\u20131955)", "text": "Province of British India (1936\u20131947) and Pakistan (1947-1955)\nSind, sometimes spelled Scinde, was a province of Pakistan from 1947 till its amalgamation into West Pakistan in 1955; and prior, a province of British India from being granted provincial status in 1936 till Pakistan's independence in 1947. Karachi was the capital of the province till 1948, succeeded by Hyderabad.\nUnder the British, it encompassed the current territorial limits excluding the princely state of Khairpur. In 1948, Karachi was separated from the province to form the Federal Capital Territory and serve as the federal capital of Pakistan; this resulted in the provincial capital being shifted to Hyderabad. The province was dissolved alongside Baluchistan, the North-West Frontier Province, West Punjab, and a number of Pakistani princely states to form a unified province of West Pakistan in 1955, upon implementation of the One Unit Scheme.\nAdministrative divisions.\nOn 1 April 1936 Sind division was separated from Bombay Presidency and established as a province.\nAt that time the Province's Administration division are listed below: \nGeography.\nThe province was bordered by Karachi (within the Federal Capital Territory after 1948) and the princely states of Las Bela and Kalat on the west. To the north were the provinces of Baluchistan and West Punjab. The province bordered the princely state of Bahawalpur on the northeast and it enclosed on three sides the princely state of Khairpur. The Indian states of Rajasthan and Gujarat were beyond its borders to the east and south. On the southwest lay the Arabian Sea, with the Sind's coastline consisting entirely of river deltas, including the Indus River Delta up to Sind's border with the city of Karachi, now the capital of present-day Sindh.\nHistory.\nSindh was first settled by the Indus Valley Civilization and Mohenjo-Daro, as early as 1750 BC. It had Greek influence during its history after the expansion of the Macedonian Empire, and developed trade with surrounding regions. Several Sunni Muslim and Rajput kingdoms were set up there, beginning with the Rai dynasty and ending with the Arghuns. The Mughal Empire conquered Sindh under the rule of Akbar in the year 1591. Soon after the coming of European companies, in particular the East India Company, the Mughal hold on the area loosened, and in 1843 Sindh became part of the British India and its Bombay Presidency on 1 October 1848. Later it became Sindh province on 1 April 1936 under All India Act of 1935. \n1936\u20131947.\nOn 1 April 1936, Sind was separated from the Bombay Presidency and given the status of a province, with Karachi as the provincial capital.\n1947\u20131955.\nFollowing a resolution in the Sindh Legislative Assembly about joining Pakistan, with the independence and Partition of India in August 1947 Sindh became part of Pakistan.\nIn 1948, Karachi city (2,103 km2 area) separated from Sind to form the Federal Capital Territory of Pakistan. Apart from the city, the remaining areas of Karachi district remained part of Sind and a new district of Thatta was formed from these areas.\nOn 11 December 1954, the Sindh Legislative Assembly voted by 100 to 4 in favour of the One Unit policy announced by Prime Minister Chaudhry Mohammad Ali, and Sindh was merged into the new province of West Pakistan on 14 October 1955.\nGovernment.\nThe offices of Governor of Sindh and Premier (later Chief Minister) of Sindh were established in 1936 when Sindh became a province. This system continued until 1955 when Sindh was dissolved.\nDemographics.\nBy the time of independence in 1947 Sindh had a Muslim majority for centuries but there were significant minorities of Hindus throughout the province. In 1947 due to communal tensions and partition two million Muslim muhajir migrated to Pakistan while most Sindhi Hindus fled to India.\nThe Muslims from India were mostly Urdu speaking.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60393", "revid": "24198", "url": "https://en.wikipedia.org/wiki?curid=60393", "title": "ARITH-MATIC", "text": "ARITH-MATIC is an extension of Grace Hopper's A-2 programming language, developed around 1955. ARITH-MATIC was originally known as A-3, but was renamed by the marketing department of Remington Rand UNIVAC.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60394", "revid": "4052843", "url": "https://en.wikipedia.org/wiki?curid=60394", "title": "A3D", "text": ""}
{"id": "60399", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=60399", "title": "AAP", "text": "Aap or AAP may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "60400", "revid": "47290012", "url": "https://en.wikipedia.org/wiki?curid=60400", "title": "Association of American Publishers", "text": "American book-publishing trade association\nThe Association of American Publishers (AAP) is the national trade association of the American book publishing industry. AAP lobbies for book, journal and education publishers in the United States. AAP members include most of the major commercial publishers in the United States, as well as smaller and nonprofit publishers, university presses, and scholarly societies.\nPatricia Schroeder, a former United States representative, served as the association's CEO from 1997 until 2009, taking over the role from Nicholas A. Veliotes. On May 1, 2009, another former United States representative, Tom Allen, took over as president and CEO. In January 2017, Maria Pallante, a former United States Register of Copyrights, became the president and CEO of the organization.\nActivities.\nThe association's core programs deal primarily with advocacy related to: intellectual property; new technology and digital issues of concern to publishers; the freedom to read, censorship and libel; the freedom to publish; funding for education and libraries; postal rates and regulations; tax and trade policy; and international copyright enforcement.\nAAP tracks publisher revenue on a monthly and annual basis with its StatShot programs. The association has also awarded books, journals, and electronic content through its annual PROSE Awards since 1976.\nIn August 2019, AAP sued Audible for its Captions feature, through which machine-generated text could be displayed alongside audio narration. The lawsuit was settled in February 2020, with Audible agreeing not to implement the Captions feature without obtaining express permission.\nControversies.\nThe AAP initially supported the arrest of Dmitry Sklyarov.\nAAP was criticized after it contracted Eric Dezenhall's crisis management firm to promote its position regarding the open access movement. Schroeder told \"The Washington Post\" \u201cthe association hired Dezenhall when members realized they needed help. \u2018We thought we were angels for a long time and we didn't need PR firms.\u2019\u201d\nIn 2020, AAP released press statements to support four of its members in the case of \"Hachette v. Internet Archive\" (IA). President Maria Pallante said of the case, \"As the complaint outlines, by illegally copying and distributing online a stunning number of literary works each day, IA displays an abandon shared only by the world\u2019s most egregious pirate sites.\" This action was opposed by the Electronic Frontier Foundation, Public Knowledge, and the Association of Research Libraries.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60401", "revid": "3606755", "url": "https://en.wikipedia.org/wiki?curid=60401", "title": "AAP DTD", "text": "In computing, AAP DTD (variously known as AAP Electronic Manuscript Standard, AAP standard, AAP/EPSIG standard, and ANSI/NISO Z39.59) is a set of three SGML Document Type Definitions (book, journal, and article) for scientific documents, defined by the Association of American Publishers. It was ratified as a U.S. standard under the name ANSI/NISO Z39.59 in 1988, and evolved into the international ISO 12083 standard in 1993. It was supplanted as a U.S. standard by ANSI/ISO 12083 in 1995.\nDevelopment and standard ratifications.\nFrom 1983 to 1987, the Association of American Publishers (AAP), a coalition of book and journal publishers in North America, sponsored the Electronic Manuscript Project, the earliest effort to develop a commercial SGML application. The project sought to create an SGML standard for book, journal, and article creation. With the technical work led by Aspen Systems, over thirty information-processing organizations contributed to the project, including the US Library of Congress, the American Society of Indexers, the IEEE, the American Chemical Society, the American Institute of Physics, and the American Mathematical Society.\nTwo preliminary works with restricted distribution were produced in 1985, the draft AAP DTD and author guidelines.\nThe Electronic Publishing Special Interest Group (EPSIG) was founded to take over responsibility for the work from AAP. The consortium, sponsored by the Online Computer Library Center, recommended that the DTDs developed by the Electronic Manuscript Project should become an American standard. With the support of the AAP and the Graphic Communications Association, the AAP DTDs were ratified in 1988 as the American National Standards Institute's \"Electronic Manuscript Preparation and Markup\" (ANSI/NISO Z39.59) standard. Unlike the DTDs that ANSI/NISO Z39.59 specifies for books, serials and articles, the markup recommended for mathematics and tables is not part of the standard. As the standard is based on ASCII character encoding, it includes a large set of entity definitions for special characters.\nThe AAP and EPSIG continued their collaboration and published a revised version of the specification in 1989.\nThe AAP and the European Physical Society further collaborated on a standard method for marking up mathematical notation and tables in scientific documents. Building on this work, Eric van Herwijnen, then head of the text processing section at CERN, edited the specification for adoption by the International Organization for Standardization as ISO 12083, which was first published in 1993, revised in 1994 and last reconfirmed in 2016. ISO 12083 specifies four DTDs: Article, Book, Serial, and Math.\nIn 1995 ANSI/NISO Z39.59:1988 was superseded by ISO 12083, which was adopted as U.S. standard ANSI/NISO/ISO 12083-1995 (R2009) Electronic Manuscript Preparation and Markup. This U.S. standard was withdrawn in 2016.\nUsage.\nThe AAP DTDs counted the academic publishing house Elsevier among their earliest users and found significant acceptance in the emerging CD-ROM publishing industry.\nAAP DTD also informed other SGML applications, such as CERN's SGMLguid, the Elsevier Science Article DTD, and EWS MAJOUR, a DTD developed between 1989 and 1991 in an effort led by the publishing houses Elsevier, Wolters Kluwer, and Springer.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60406", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=60406", "title": "8052", "text": ""}
{"id": "60407", "revid": "49523", "url": "https://en.wikipedia.org/wiki?curid=60407", "title": "Apple Address Resolution Protocol", "text": ""}
{"id": "60408", "revid": "37005538", "url": "https://en.wikipedia.org/wiki?curid=60408", "title": "HCL Notes", "text": "Collaborative software platform\n \nHCL Notes (formerly Lotus Notes then IBM Notes) is a proprietary collaborative software platform for Unix (AIX), IBM i, Windows, Linux, and macOS, sold by HCLTech. The client application is called Notes while the server component is branded HCL Domino.\nHCL Notes provides business collaboration functions, such as email, calendars, to-do lists, contact management, discussion forums, file sharing, websites, instant messaging, blogs, document libraries, user directories, and custom applications. It can also be used with other HCL Domino applications and databases. IBM Notes 9 Social Edition removed integration with the office software package IBM Lotus Symphony, which had been integrated with the Lotus Notes client in versions 8.x.\nLotus Development Corporation originally developed \"Lotus Notes\" in 1989. IBM bought Lotus in 1995 and it became known as the Lotus Development division of IBM. On December 6, 2018, IBM announced that it was selling a number of software products to HCLSoftware for $1.8bn, including Notes and Domino. This acquisition was completed in July 2019.\nHistory.\nLotus Notes's chief inspiration was \"PLATO Notes\", created by David R. Woolley at the University of Illinois in 1973. In today's terminology, PLATO Notes supported user-created discussion groups, and it was part of the foundation for an online community which thrived for more than 20 years on the PLATO system. Ray Ozzie worked with PLATO while attending the University of Illinois in the 1970s. When PC network technology began to emerge, Ozzie made a deal with Lotus Development founder Mitch Kapor that resulted in the formation of Iris Associates in 1984 to develop products that would combine the capabilities of PCs with the collaborative tools pioneered in PLATO. The agreement put control of product development under Ozzie and Iris, and sales and marketing under Lotus.\nLotus beta tested Notes for so long that it was considered vaporware before its December 1989 release. The company was unsure at first of how or whether to market the product, as Lotus traditionally sold products through retail while Notes's corporate customers would buy from the company and require support. An example was Price Waterhouse, which bought 10,000 copies\u2014the largest single sale of PC software\u2014before the official release. In 1994, after the release and marketplace success of Notes R3, Lotus purchased Iris.\nIn 1995 IBM purchased Lotus for $3.2 billion, primarily to acquire Notes. By then large companies bought the software in volume for tens of thousands of employees. In 2008, IBM released XPages technology, based on Jakarta Faces (formerly JavaServer Faces). This allows Domino applications to be better surfaced to browser clients, though the UX and business logic must be completely rewritten. Previously, Domino applications could be accessed through browsers, but required extensive web specific modifications to get full functionality in browsers. XPages also gave the application new capabilities that are not possible with the classic Notes client. The IBM Domino 9 Social Edition included the Notes Browser Plugin, which would surface Notes applications via minified version of the rich desktop client contained in a browser tab.\nBranding.\nPrior to release 4.5, the \"Lotus Notes\" branding encompassed both the client and server applications. In 1996, Lotus released an HTTP server add-on for the Notes 4 server called \"Domino\". This add-on allowed Notes documents to be rendered as web pages in real time. Later that year, the Domino web server was integrated into release 4.5 of the core Notes server and the entire server program was re-branded, taking on the name \"Domino\". Only the client program officially retained the \"Lotus Notes\" name.\nIn November 2012, IBM announced it would be dropping the Lotus brand and moving forward with the IBM brand only to identify products, including Notes and Domino. On October 9, 2018, IBM announced the availability of the latest version of the client and server software.\nIn 2019, Domino and Notes became enterprise software products managed under HCLSoftware.\nDesign.\nHCL Domino is a client-server cross-platform software application runtime environment.\nDomino provides email, calendars, instant messaging (with further HCLSoftware voice- and video-conferencing and web-collaboration), discussions/forums, blogs, and an inbuilt personnel/user directory. In addition to these standard applications, an organization may use the Domino Designer development environment and other tools to develop further integrated applications such as request approval / workflow and document management.\nThe Domino product consists of several components:\nDomino competes with products from other companies such as Microsoft, Google, Zimbra and others. Because of the application development abilities, HCL Domino is often compared to products like Microsoft SharePoint. The database in Domino can be replicated between servers and between server and client, thereby allowing clients offline capabilities.\nDomino, a business application as well as a messaging server, is compatible with both Notes and web-browsers. Notes (and since IBM Domino 9, the HCAA) may be used to access any Domino application, such as discussion forums, document libraries, and numerous other applications. Notes resembles a web-browser in that it may run any compatible application that the user has permission for.\nDomino provides applications that can be used to:\nThe standard storage mechanism in Domino is a document-database format, the \"Notes Storage Facility\" (.nsf). The .nsf file will normally contain both an application design and its associated data. Domino can also access relational databases, either through another server called HCL Enterprise Integrator for Domino, through ODBC calls or through the use of XPages.\nAs Domino is an application runtime environment, email and calendars operate as applications within Notes, which HCL provides with the product. A Domino application-developer can change or completely replace that application. HCL has released the base templates as open source as well.\nApplications can be developed for Domino in several programming languages, including:\nThe client supports a formula language and JavaScript. Applications can be built to run either in the Notes application runtime environment or via web server for use in a web browser, although the interface must be developed separately unless XPages is used.\nUse.\nNotes can be used for email, as a calendar, PIM, instant messaging, Web browsing, and other applications. Notes can access both local- and server-based applications and data.\nNotes can function as an IMAP and POP email client with non-Domino mail servers. The system can retrieve recipient addresses from any LDAP server, including Active Directory, and includes a web browser, although it can be configured by a Domino Developer to launch a different web browser instead.\nFeatures include group calendars and schedules, SMTP/MIME-based email, NNTP-based news support, and automatic HTML conversion of all documents by the Domino HTTP task.\nNotes can be used with Sametime instant-messaging to allow to see other users online and chat with one or more of them at the same time. Beginning with Release 6.5, this function has been freely available. Presence awareness is available in email and other HCL Domino applications for users in organizations that use both Notes and Sametime.\nSince version 7, Notes has provided a Web services interface. Domino can be a Web server for HTML files; authentication of access to Domino databases or HTML files uses the Domino user directory and external systems such as Microsoft Active Directory.\nA design client, Domino Designer, can allow the development of database applications consisting of forms (which allow users to create documents) and views (which display selected document fields in columns).\nIn addition to its role as a groupware system (email, calendaring, shared documents and discussions), HCL Notes and Domino can also construct \"workflow\"-type applications, particularly those which require approval processes and routing of data.\nSince Release 5, server clustering has had the ability to provide geographic redundancy for servers.\nNotes System Diagnostic (NSD) gathers information about the running of a Notes workstation or of a Domino server.\nOn October 10, 2018, IBM released IBM Domino v10.0 and IBM Notes 10.0 as the latest release. In December, 2019, HCL released HCL Domino v11 and HCL Notes v11.\nOverview.\nClient/server.\nNotes and Domino are client/server database environments. The server software is called Domino and the client software is Notes. Domino software can run on Windows, Unix, AIX, and IBM mid-range systems and can scale to tens of thousands of users per server. There are different supported versions of the Domino server that are supported on the various levels of server operating systems. Usually the latest server operating system is only officially supported by a version of HCL Domino that is released at about the same time as that OS.\nDomino has security capabilities on a variety of levels. The authorizations can be granular, down to the field level in specific records all the way up to 10 different parameters that can be set up at a database level, with intermediate options in between. Users can also assign access for other users to their personal calendar and email on a more generic reader, editor, edit with delete and manage my calendar levels. All of the security in Notes and Domino is independent of the server OS or Active Directory. Optionally, the Notes client can be configured to have the user use their Active Directory identity.\nData replication.\nThe first release of Lotus Notes included a generalized replication facility. The generalized nature of this feature set it apart from predecessors like Usenet and continued to differentiate Lotus Notes.\nDomino servers and Notes clients identify NSF files by their Replica IDs, and keep replicated files synchronized by bi-directionally exchanging data, metadata, and application logic and design. There are options available to define what meta-data replicates, or specifically exclude certain meta data from replicating. Replication between two servers, or between a client and a server, can occur over a network or a point-to-point modem connection. Replication between servers may occur at intervals according to a defined schedule, in near-real-time when triggered by data changes in server clusters, or when triggered by an administrator or program.\nCreation of a local replica of an NSF file on the hard disk of an HCL Notes client enables the user to fully use Notes and Domino databases while working off-line. The client synchronizes any changes when client and server next connect. Local replicas are also sometimes maintained for use while connected to the network in order to reduce network latency. Replication between a Notes client and Domino server can run automatically according to a schedule, or manually in response to a user or programmatic request. Since Notes 6, local replicas maintain all security features programmed into the applications. Earlier releases of Notes did not always do so. Early releases also did not offer a way to encrypt NSF files, raising concerns that local replicas might expose too much confidential data on laptops or insecure home office computers, but more recent releases offer encryption, and as of the default setting for newly created local replicas.\nSecurity.\nLotus Notes was the first widely adopted software product to use public key cryptography for client\u2013server and server\u2013server authentication and for encryption of data. Until US laws regulating encryption were changed in 2000, IBM and Lotus were prohibited from exporting versions of Notes that supported symmetric encryption keys that were longer than 40 bits. In 1997, Lotus negotiated an agreement with the NSA that allowed export of a version that supported stronger keys with 64 bits, but 24 of the bits were encrypted with a special key and included in the message to provide a \"workload reduction factor\" for the NSA. This strengthened the protection for users of Notes outside the US against private-sector industrial espionage, but not against spying by the US government. This implementation was widely announced, but with some justification many people did consider it to be a backdoor. Some governments objected to being put at a disadvantage to the NSA, and as a result Lotus continued to support the 40-bit version for export to those countries.\nNotes and Domino also uses a code-signature framework that controls the security context, runtime, and rights of custom code developed and introduced into the environment. Notes 5 introduced an execution control list (ECL) at the client level. The ECL allows or denies the execution of custom code based on the signature attached to it, preventing code from untrusted (and possibly malignant) sources from running. Notes and Domino 6 allowed client ECLs to be managed centrally by server administrators through the implementation of policies. Since release 4.5, the code signatures listed in properly configured ECLs prevent code from being executed by external sources, to avoid virus propagation through Notes/Domino environments. Administrators can centrally control whether each mailbox user can add exceptions to, and thus override, the ECL.\nDatabase security.\nAccess control lists (ACLs) control a user of server's level of access to that database. Only a user with Manager access can create or modify the ACL. Default entries in the ACL can be set when the Manager creates the database.\nRoles, rather than user id, can determine access level.\nProgramming.\nNotes and Domino is a cross-platform, distributed document-oriented NoSQL database and messaging framework and rapid application development environment that includes pre-built applications like email, calendar, etc. This sets it apart from its major commercial competitors, such as Microsoft Exchange or Novell GroupWise, which are purpose-built applications for mail and calendaring that offer APIs for extensibility.\nDomino databases are built using the Domino Designer client, available only for Microsoft Windows; standard user clients are available for Windows, Linux, and macOS. A key feature of Notes is that many replicas of the same database can exist at the same time on different servers and clients, across dissimilar platforms; the same storage architecture is used for both client and server replicas. Originally, replication in Notes happened at document (i.e., record) level. With release of Notes 4 in 1996, replication was changed so that it now occurs at field level.\nA database is a Notes Storage Facility (.nsf) file, containing basic units of storage known as a \"note\". Every note has a UniqueID that is shared by all its replicas. Every replica also has a UniqueID that uniquely identifies it within any cluster of servers, a domain of servers, or even across domains belonging to many organizations that are all hosting replicas of the same database. Each note also stores its creation and modification dates, and one or more Items.\nThere are several classes of notes, including design notes and document notes. Design notes are created and modified with the Domino Designer client, and represent programmable elements, such as the GUI layout of forms for displaying and editing data, or formulas and scripts for manipulating data. Document notes represent user data, and are created and modified with the Notes client, via a web browser, via mail routing and delivery, or via programmed code.\nDocument notes can have parent-child relationships, but Notes should not be considered a hierarchical database in the classic sense of information management systems. Notes databases are also not relational, although there is a SQL driver that can be used with Notes, and it does have some features that can be used to develop applications that mimic relational features. Notes does not support atomic transactions, and its file locking is rudimentary. Notes is a document-oriented database (document-based, schema-less, loosely structured) with support for rich content and powerful indexing facilities. This structure closely mimics paper-based work flows that Notes is typically used to automate.\nItems represent the content of a note. Every item has a name, a type, and may have some flags set. A note can have more than one item with the same name. Item types include Number, Number List, Text, Text List, Date-Time, Date-Time List, and Rich Text. Flags are used for managing attributes associated with the item, such as read or write security. Items in design notes represent the programmed elements of a database. For example, the layout of an entry form is stored in the rich text Body item within a form design note. This means that the design of the database can replicate to users' desktops just like the data itself, making it extremely easy to deploy updated applications.\nItems in document notes represent user-entered or computed data. An item named \"Form\" in a document note can be used to bind a document to a form design note, which directs the Notes client to merge the content of the document note items with the GUI information and code represented in the given form design note for display and editing purposes. However, other methods can be used to override this binding of a document to a form note. The resulting loose binding of documents to design information is one of the cornerstones of the power of Notes. Traditional database developers used to working with rigidly enforced schemas, in contrast, may consider the power of this feature as a double-edged sword.\nNotes application development uses several programming languages. Formula and LotusScript are the two original ones. LotusScript is similar to, and may even be considered a specialized implementation of, Visual Basic, but with the addition of many native classes that model the Notes environment, whereas Formula is similar to Lotus 1-2-3 formula language but is unique to Notes.\nJava was integrated into IBM Notes beginning with Release 4.5. With Release 5, Java support was greatly enhanced and expanded, and JavaScript was added. While LotusScript remains a primary tool in developing applications for the Lotus Notes client, Java and JavaScript are the primary tools for server-based processing, developing applications for browser access, and allowing browsers to emulate the functionality of the IBM Notes client. With XPages, the IBM Notes client can now natively process Java and JavaScript code, although applications development usually requires at least some code specific to only IBM Notes or only a browser.\nAs of version 6, Lotus established an XML programming interface in addition to the options already available. The Domino XML Language (DXL) provides XML representations of all data and design resources in the Notes model, allowing any XML processing tool to create and modify IBM Notes and Domino data.\nSince Release 8.5, XPages were also integrated into IBM Notes.\nExternal to the Notes application, HCL provides toolkits in C, C++, and Java to connect to the Domino database and perform a wide variety of tasks. The C toolkit is the most mature, and the C++ toolkit is an objectized version of the C toolkit, lacking many functions the C toolkit provides. The Java toolkit is the least mature of the three and can be used for basic application needs.\nDatabase.\nHCL Notes includes a database management system but Notes files are different from relational or object databases because they are document-centric. Document-oriented databases such as Notes allow multiple values in items (fields), do not require a schema, come with built-in document-level access control, and store rich text data. IBM Domino 7 to 8.5.x supports the use of IBM Db2 database as an alternative store for IBM Notes databases. This NSFDB2 feature, however, is now in maintenance mode with no further development planned. An IBM Notes database can be mapped to a relational database using tools like DECS, [LEI], JDBCSql for Domino or NotesSQL.\nConfiguration.\nThe HCL Domino server or the Domino client store their configuration in their own databases / application files (*.nsf). No relevant configuration settings are saved in the Windows Registry if the operating system is Windows. Some other configuration options (primary the start configuration) is stored in the notes.ini (there are currently over 2000 known options available).\nUse as an email client.\nNotes is commonly deployed as an end-user email client in larger organizations.\nWhen an organization employs an HCL Domino server, it usually also deploys the supplied Notes client for accessing the Notes application for email and calendaring but also to use document management and workflow applications. As Notes is a runtime environment, and the email and calendaring functions in Notes are simply an application provided by HCL, the administrators are free to develop alternate email and calendaring applications. It is also possible to alter, amend or extend the HCL supplied email and calendaring application.\nThe Domino server also supports POP3 and IMAP mail clients, and through an extension product (HCL mail support for Microsoft Outlook) supports native access for Microsoft Outlook clients.\nHCL also provides iNotes (in Notes 6.5 renamed to \"Domino Web Access\" but in version 8.0 reverted to iNotes), to allow the use of email and calendaring features through web browsers on Windows, Mac and Linux, such as Internet Explorer and Firefox. There are several spam filtering programs available (including IBM Lotus Protector), and a rules engine allowing user-defined mail processing to be performed by the server.\nComparison with other email clients.\nNotes was designed as a collaborative application platform where email was just one of numerous applications that ran in the Notes client software. The Notes client was also designed to run on multiple platforms including Windows, OS/2, classic Mac OS, SCO Open Desktop UNIX, and Linux. These two factors have resulted in the user interface containing some differences from applications that only run on Windows. Furthermore, these differences have often remained in the product to retain backward compatibility with earlier releases, instead of conforming to updated Windows UI standards. The following are some of these differences.\nLotus Notes 7 and older versions had more differences, which were removed from subsequent releases:\nLotus Notes 8.0 (released in 2007) became the first version to employ a dedicated user-experience team, resulting in changes in the IBM Notes client experience in the primary and new notes user interface. This new interface runs in the open source Eclipse Framework, which is a project started by IBM, opening up more application development opportunities through the use of Eclipse plug-ins. The new interface provides many new user interface features and the ability to include user-selected applications/applets in small panes in the interface. Lotus Notes 8.0 also included a new email interface / design to match the new Lotus Notes 8.0 eclipse based interface. Eclipse is a Java framework and allows IBM to port Notes to other platforms rapidly. An issue with Eclipse and therefore Notes 8.0 is the applications start-up and user-interaction speed. Lotus Notes 8.5 sped up the application and the increase in general specification of PCs means this is less of an issue.\nIBM Notes 9 continued the evolution of the user interface to more closely align with modern application interfaces found in many commercial packaged or web-based software. Currently, the software still does not have an auto-correct option - or even ability - to reverse accidental use of caps lock.\nDomino is now running on the Eclipse platform and offers many new development environments and tools such as XPages.\nFor lower spec PCs, a new version of the old interface is still provided albeit as it is the old interface many of the new features are not available and the email user interface reverts to the Notes 7.x style.\nThis new user experience builds on Notes 6.5 (released in 2003), which upgraded the email client, previously regarded by many as the product's Achilles heel. Features added at that time included:\nReception.\nPublications such as \"The Guardian\" in 2006 have criticized earlier versions of Lotus Notes for having an \"unintuitive [user] interface\" and cite widespread dissatisfaction with the usability of the client software. \"The Guardian\" indicated that Notes has not necessarily suffered as a result of this dissatisfaction due to the fact that \"the people who choose [enterprise software] tend not to be the ones who use it.\"\nEarlier versions of Notes have also been criticized for violating an important usability best practice that suggests a consistent UI is often better than custom alternative. Software written for a particular operating system should follow that particular OS's user interface style guide. Not following those style guides can confuse users. A notable example is F5 keyboard shortcut, which is used to refresh window contents in Microsoft Windows. Pressing F5 in Lotus Notes before release 8.0 caused it to lock screen. Since this was a major point of criticism this was changed in release 8.0. Old versions did not support proportional scrollbars (which give the user an idea of how long the document is, relative to the portion being viewed). Proportional scroll bars were only introduced in Notes 8.\nOlder versions of Notes also suffered from similar user interaction choices, many of which were also corrected in subsequent releases. One example that was corrected in Release 8.5: In earlier versions the out-of-office agent needed to be manually enabled when leaving and disabled when coming back, even if start and end date have been set. As of Release 8.5 the out-of-office notification now automatically shuts off without a need for a manual disable.\nUnlike some other e-mail client software programs, IBM Notes developers made a choice to not allow individual users to determine whether a return receipt is sent when they open an e-mail; rather, that option is configured at the server level. IBM developers believe \"Allowing individual cancellation of return receipt violates the intent of a return receipt function within an organization\". So, depending on system settings, users will have no choice in return receipts going back to spammers or other senders of unwanted e-mail. This has led tech sites to publish ways to get around this feature of Notes. For IBM Notes 9.0 and IBM iNotes 9.0, the IBM Domino server's .INI file can now contain an entry to control return receipt in a manner that's more aligned with community expectations (IBM Notes 9 Product Documentation).\nWhen Notes crashes, some processes may continue running and prevent the application from being restarted until they are killed.\nRelated software.\nRelated IBM Lotus products.\nOver the 30-year history of IBM Notes, Lotus Development Corporation and later IBM have developed many other software products that are based on, or integrated with IBM Notes. The most prominent of these is the IBM Lotus Domino server software, which was originally known as the Lotus Notes Server and gained a separate name with the release of version 4.5. The server platform also became the foundation for products such as IBM Lotus Quickr for Domino, for document management, and IBM Sametime for instant messaging, audio and video communication, and web conferencing, and with Release 8.5, IBM Connections.\nIn early releases of IBM Notes, there was considerable emphasis on client-side integration with the IBM Lotus SmartSuite environment. With Microsoft's increasing predominance in office productivity software, the desktop integration focus switched for a time to Microsoft Office. With the release of version 8.0 in 2007, based on the Eclipse framework, IBM again added integration with its own office-productivity suite, the OpenOffice.org-derived IBM Lotus Symphony. IBM Lotus Expeditor is a framework for developing Eclipse-based applications.\nOther IBM products and technologies have also been built to integrate with IBM Notes. For mobile-device synchronization, this previously included the client-side IBM Lotus Easysync Pro product (no longer in development) and IBM Notes Traveler, a newer no-charge server-side add-on for mail, calendar and contact sync. A recent addition to IBM's portfolio are two IBM Lotus Protector products for mail security and encryption, which have been built to integrate with IBM Notes.\nRelated software from other vendors.\nWith a long market history and large installed base, Notes and Domino have spawned a large third-party software ecosystem. Such products can be divided into four broad, and somewhat overlapping classes:\nRelease history.\n21st century.\nIBM donated parts of the IBM Notes and Domino code to OpenOffice.org on September 12, 2007, and since 2008 has been regularly donating code to OpenNTF.org.\nDespite repeated predictions of the decline or impending demise of IBM Notes and Domino, such as \"Forbes\" magazine's 1998 \"The decline and fall of Lotus\", the installed base of Lotus Notes has increased from an estimated 42 million seats in September 1998 to approximately 140 million cumulative licenses sold through 2008. Once IBM Workplace was discontinued in 2006, speculation about dropping Notes was rendered moot. Moreover, IBM introduced \"iNotes\" for iPhone two years later.\nIBM contributed some of the code it had developed for the integration of the OpenOffice.org suite into Notes 8 to the project. IBM also packaged its version of OpenOffice.org for free distribution as IBM Lotus Symphony.\nIBM Notes and Domino 9 Social Edition shipped on March 21, 2013. Changes include significantly updated user interface, near-parity of IBM Notes and IBM iNotes functionality, the IBM Notes Browser Plugin, new XPages controls added to IBM Domino, refreshed IBM Domino Designer user interface, added support for To Dos on Android mobile devices, and further server functions as detailed in the Announcement Letter.\nIn late 2016, IBM announced that there would not be a Notes 9.0.2 release, but 9.0.1 would be supported until at least 2021. In the same presentation, IBM also stated that their internal users had been migrated away from Notes and onto the IBM Verse client.\nOn October 25, 2017, IBM announced a plan to deliver a Domino V10 family update sometime in 2018. The new version will be built in partnership with HCLTech. IBM's development and support team responsible for these products are moving to HCL, however, the marketing, and sales continue to be IBM-led. Product strategy is shared between IBM and HCL. As part of the announcement, IBM indicated that there is no formal end to product support planned.\nOn October 9, 2018, IBM announced IBM Domino 10.0 and IBM Notes 10.0 in Frankfurt, Germany, and made them available to download on October 10, 2018.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60409", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=60409", "title": "Microsoft's .NET", "text": ""}
{"id": "60411", "revid": "28903366", "url": "https://en.wikipedia.org/wiki?curid=60411", "title": "Steller's sea cow", "text": "Extinct species of marine mammal\n&lt;templatestyles src=\"Template:Taxobox/core/styles.css\" /&gt;\nSteller's sea cow (Hydrodamalis gigas) is an extinct sirenian described by Georg Wilhelm Steller in 1741. At that time, it was found only around the Commander Islands in the Bering Sea between Alaska and Russia; its range extended across the North Pacific during the Pleistocene epoch, and likely contracted to such an extreme degree due to the glacial cycle. It is possible that indigenous populations interacted with the animal before Europeans. Steller first encountered it on Vitus Bering's Great Northern Expedition when the crew became shipwrecked on Bering Island. Much of what is known about its behavior comes from Steller's observations on the island, documented in his posthumous publication \"On the Beasts of the Sea\". Within 27 years of its discovery by Europeans, the slow-moving and easily caught mammal was hunted into extinction for its meat, fat, and hide.\nSome 18th-century adults would have reached weights of and lengths up to . It was a member of the family Dugongidae, of which the long dugong (\"Dugong dugon\") is the sole living member. It had a thicker layer of blubber than other members of the order, an adaptation to the cold waters of its environment. Its tail was forked, like that of whales or dugongs. Lacking true teeth, it had an array of white bristles on its upper lip and two keratinous plates within its mouth for chewing. It fed mainly on kelp, and communicated with sighs and snorting sounds. Steller believed it was a monogamous and social animal living in small family groups and raising its young, similar to modern sirenians.\nDescription.\nSteller's sea cows are reported to have grown to long as adults, much larger than extant sirenians. In 1987, a rather complete skeleton was found on Bering Island measuring . In 2017, another such skeleton was found on Bering Island measuring , and in life probably about . Georg Steller's writings contain two contradictory estimates of weight: . The true value is estimated to fall between these figures, at about . This size made the sea cow one of the largest mammals of the Holocene epoch, along with baleen whales and some few toothed whales, and was likely an adaptation to reduce its surface-area to volume ratio and conserve heat.\nUnlike other sirenians, Steller's sea cow was positively buoyant, meaning that it was unable to submerge completely. It had a very thick outer skin, , to prevent injury from sharp rocks and ice and possibly to prevent unsubmerged skin from drying out. The sea cow's blubber was thick, another adaptation to the frigid climate of the Bering Sea. Its skin was brownish-black, with white patches on some individuals. It was smooth along its back and rough on its sides, with crater-like depressions most likely caused by parasites. This rough texture led to the animal being nicknamed the \"bark animal\". Hair on its body was sparse, but the insides of the sea cow's flippers were covered in bristles. The fore limbs were roughly long, and the tail fluke was forked.\nThe sea cow's head was small and short in comparison to its huge body. The animal's upper lip was large and broad, extending so far beyond the lower jaw that the mouth appeared to be located underneath the skull. Unlike other sirenians, Steller's sea cow was toothless and instead had a dense array of interlacing white bristles on its upper lip. The bristles were about in length and were used to tear seaweed stalks and hold food. The sea cow also had two keratinous plates, called ceratodontes, located on its palate and mandible, used for chewing. According to Steller, these plates (or \"masticatory pads\") were held together by interdental papillae, a part of the gums, and had many small holes containing nerves and arteries.\nAs with all sirenians, the sea cow's snout pointed downwards, which allowed it to better grasp kelp. The sea cow's nostrils were roughly long and wide. In addition to those within its mouth, the sea cow also had stiff bristles long protruding from its muzzle. Steller's sea cow had small eyes located halfway between its nostrils and ears with black irises, livid eyeballs, and canthi which were not externally visible. The animal had no eyelashes, but like other diving creatures such as sea otters, Steller's sea cow had a nictitating membrane, which covered its eyes to prevent injury while feeding. The tongue was small and remained in the back of the mouth, unable to reach the masticatory (chewing) pads.\nThe sea cow's spine is believed to have had seven cervical (neck), 17 thoracic, three lumbar, and 34 caudal (tail) vertebrae. Its ribs were large, with five of 17 pairs making contact with the sternum; it had no clavicles. As in all sirenians, the scapula of Steller's sea cow was fan-shaped, being larger on the posterior side and narrower towards the neck. The anterior border of the scapula was nearly straight, whereas those of modern sirenians are curved. Like other sirenians, the bones of Steller's sea cow were pachyosteosclerotic, meaning they were both bulky (pachyostotic) and dense (osteosclerotic). In all collected skeletons of the sea cow, the manus is missing; since \"Dusisiren\"\u2014the sister taxon of \"Hydrodamalis\"\u2014had reduced phalanges (finger bones), Steller's sea cow possibly did not have a manus at all.\nThe sea cow's heart was in weight; its stomach measured long and wide. The full length of its intestinal tract was about , equaling more than 20 times the animal's length. The sea cow had no gallbladder, but did have a wide common bile duct. Its anus was in width, with its feces resembling those of horses. The male's penis was long. Genetic evidence indicates convergent evolution with other marine mammals of genes related to metabolic and immune function, including leptin associated with energy homeostasis and reproductive regulation.\nEcology and behavior.\nWhether Steller's sea cow had any natural predators is unknown. It may have been hunted by killer whales and sharks, though its buoyancy may have made it difficult for killer whales to drown, and the rocky kelp forests in which the sea cow lived may have deterred sharks. According to Steller, the adults guarded the young from predators.\nSteller described an ectoparasite on the sea cows that was similar to the whale louse (\"Cyamus ovalis\"), but the parasite remains unidentified due to the host's extinction and loss of all original specimens collected by Steller. It was first formally described as \"Sirenocyamus rhytinae\" in 1846 by Johann Friedrich von Brandt, although it has since been placed into the genus \"Cyamus\" as \"Cyamus rhytinae\". It was the only species of cyamid amphipod to be reported inhabiting a sirenian. Steller also identified an endoparasite in the sea cows, which was likely an ascarid nematode.\nLike other sirenians, Steller's sea cow was an obligate herbivore and spent most of the day feeding, only lifting its head every 4\u20135 minutes for breathing. Kelp was its main food source, making it an algivore. The sea cow likely fed on several species of kelp, which have been identified as \"Agarum\" spp., \"Alaria praelonga\", \"Halosaccion glandiforme\", \"Laminaria saccharina\", \"Nereocyctis luetkeana\", and \"Thalassiophyllum clathrus\". Steller's sea cow only fed directly on the soft parts of the kelp, which caused the tougher stem and holdfast to wash up on the shore in heaps. The sea cow may have also fed on seagrass, but the plant was not common enough to support a viable population and could not have been the sea cow's primary food source. Further, the available seagrasses in the sea cow's range (\"Phyllospadix\" spp. and \"Zostera marina\") may have grown too deep underwater or been too tough for the animal to consume. Since the sea cow floated, it likely fed on canopy kelp, as it is believed to have only had access to food no deeper than below the tide. Kelp releases a chemical deterrent to protect it from grazing, but canopy kelp releases a lower concentration of the chemical, allowing the sea cow to graze safely. Steller noted that the sea cow grew thin during the frigid winters, indicating a period of fasting due to low kelp growth. Fossils of Pleistocene Aleutian Island sea cow populations were larger than those from the Commander Islands, indicating that the growth of Commander Island sea cows may have been stunted due to a less favorable habitat and less food than the warmer Aleutian Islands.\nSteller described the sea cow as being highly social (gregarious). It lived in small family groups and helped injured members, and was also apparently monogamous. Steller's sea cow may have exhibited parental care, and the young were kept at the front of the herd for protection against predators. Steller reported that as a female was being captured, a group of other sea cows attacked the hunting boat by ramming and rocking it, and after the hunt, her mate followed the boat to shore, even after the captured animal had died. Mating season occurred in early spring and gestation took a little over a year, with calves likely delivered in autumn, as Steller observed a greater number of calves in autumn than at any other time of the year. Since female sea cows had only one set of mammary glands, they likely had one calf at a time.\nThe sea cow used its fore limbs for swimming, feeding, walking in shallow water, defending itself, and holding on to its partner during copulation. According to Steller, the fore limbs were also used to anchor the sea cow down to prevent it from being swept away by the strong nearshore waves. While grazing, the sea cow progressed slowly by moving its tail (fluke) from side to side; more rapid movement was achieved by strong vertical beating of the tail. They often slept on their backs after feeding. According to Steller, the sea cow was nearly mute and made only heavy breathing sounds, raspy snorting similar to a horse, and sighs.\nDespite their large size, as with many other marine megafauna in the region, Steller's sea cows may have been prey for the local transient orcas (\"Orcinus orca\"); it is likely that they experienced predation, as Steller observed that foraging sea cows with calves would always keep their calves between themselves and the shore, and orcas would have been the most likely candidate for causing this behavior. In addition, early indigenous peoples of the North Pacific may have depended on the sea cow for food, and it is possible that this dependency may have extirpated the sea cow from portions of the North Pacific aside from the Commander Islands. Steller's sea cows may have also had a mutualistic (or possibly even parasitic) relationship with local seabird species; Steller often observed birds perching on the exposed backs of the sea cows, feeding on the parasitic \"Cyamus rhytinae\"; this unique relationship that disappeared with the sea cows may have been a food source for many birds, and is similar to the recorded interactions between oxpeckers (\"Buphagus\") and extant African megafauna.\nTaxonomy.\nPhylogeny.\nSteller's sea cow was a member of the genus \"Hydrodamalis\", a group of large sirenians, whose sister taxon was \"Dusisiren\". Like those of Steller's sea cow, the ancestors of \"Dusisiren\" lived in tropical mangroves before adapting to the cold climates of the North Pacific. \"Hydrodamalis\" and \"Dusisiren\" are classified together in the subfamily Hydrodamalinae, which diverged from other sirenians around 4 to 8 mya. Steller's sea cow is a member of the family Dugongidae, the sole surviving member of which, and thus Steller's sea cow's closest living relative is the dugong (\"Dugong dugon\").\nSteller's sea cow was a direct descendant of the Cuesta sea cow (\"H. cuestae\"), an extinct tropical sea cow that lived off the coast of western North America, particularly California. The Cuesta sea cow is thought to have become extinct due to the onset of the Quaternary glaciation and the subsequent cooling of the oceans. Many populations died out, but the lineage of Steller's sea cow was able to adapt to the colder temperatures. The Takikawa sea cow (\"H. spissa\") of Japan is thought of by some researchers to be a taxonomic synonym of the Cuesta sea cow, but based on a comparison of endocasts, the Takikawa and Steller's sea cows are more derived than the Cuesta sea cow. This has led some to believe that the Takikawa sea cow is its own species. The evolution of the genus \"Hydrodamalis\" was characterized by increased size, and a loss of teeth and phalanges, as a response to the onset of the Quaternary glaciation.\nBased on a 2015 study by Mark Springer:\nResearch history.\nSteller's sea cow was discovered in 1741 by Georg Wilhelm Steller, and was named after him. Steller researched the wildlife of Bering Island while he was shipwrecked there for about a year; the animals on the island included relict populations of sea cows, sea otters, Steller sea lions, and northern fur seals. As the crew hunted the animals to survive, Steller described them in detail. Steller's account was included in his posthumous publication \"De bestiis marinis\", or \"The Beasts of the Sea\", which was published in 1751 by the Russian Academy of Sciences in Saint Petersburg. Zoologist Eberhard von Zimmermann formally described Steller's sea cow in 1780 as \"Manati gigas\". Biologist Anders Jahan Retzius in 1794 put the sea cow in the new genus \"Hydrodamalis\", with the specific name of \"stelleri\", in honor of Steller. In 1811, naturalist Johann Karl Wilhelm Illiger reclassified Steller's sea cow into the genus \"Rytina\", which many writers at the time adopted. The name \"Hydrodamalis gigas\", the correct \"combinatio nova\" if a separate genus is recognised, was first used in 1895 by Theodore Sherman Palmer.\nFor decades after its discovery, no skeletal remains of a Steller's sea cow were known. This may have been due to rising and falling sea levels over the course of the Quaternary period, which could have left many sea cow bones hidden. The first bones of a Steller's sea cow were unearthed in about 1840, over 70 years after it was presumed to have become extinct. The first partial sea cow skull was discovered in 1844 by Ilya Voznesensky while on the Commander Islands, and the first skeleton was discovered in 1855 on northern Bering Island. These specimens were sent to Saint Petersburg in 1857, and another nearly complete skeleton arrived in Moscow around 1860. Until recently, all the full skeletons were found during the 19th century, being the most productive period in terms of unearthed skeletal remains, from 1878 to 1883. During this time, 12 of the 22 skeletons having known dates of collection were discovered. Some authors did not believe possible the recovery of further significant skeletal material from the Commander Islands after this period, but a skeleton was found in 1983, and two zoologists collected about 90 bones in 1991. Only two to four skeletons of the sea cow exhibited in various museums of the world originate from a single individual. It is known that Adolf Erik Nordenski\u00f6ld, Benedykt Dybowski, and Leonhard Hess Stejneger unearthed many skeletal remains from different individuals in the late 1800s, from which composite skeletons were assembled. As of 2006, 27 nearly complete skeletons and 62 complete skulls have been found, but most of them are assemblages of bones from two to 16 different individuals.\nIllustrations.\nThe Pallas Picture is the only known drawing of Steller's sea cow believed to be from a complete specimen. It was published by Peter Simon Pallas in his 1840 work . Pallas did not specify a source; Stejneger suggested it may have been one of the original illustrations produced by Friedrich Plenisner, a member of Vitus Bering's crew as a painter and surveyor who drew a figure of a female sea cow on Steller's request. Most of Plenisner's depictions were lost during transit from Siberia to Saint Petersburg.\nAnother drawing of Steller's sea cow similar to the Pallas Picture appeared on a 1744 map drawn by Sven Waxell and Sofron Chitrow. The picture may have also been based upon a specimen, and was published in 1893 by Pekarski. The map depicted Vitus Bering's route during the Great Northern Expedition, and featured illustrations of Steller's sea cow and Steller's sea lion in the upper-left corner. The drawing contains some inaccurate features such as the inclusion of eyelids and fingers, leading to doubt that it was drawn from a specimen.\nJohann Friedrich von Brandt, director of the Russian Academy of Sciences, had the \"Ideal Image\" drawn in 1846 based upon the Pallas Picture, and then the \"Ideal Picture\" in 1868 based upon collected skeletons. Two other possible drawings of Steller's sea cow were found in 1891 in Waxell's manuscript diary. There was a map depicting a sea cow, as well as a Steller sea lion and a northern fur seal. The sea cow was depicted with large eyes, a large head, claw-like hands, exaggerated folds on the body, and a tail fluke in perspective lying horizontally rather than vertically. The drawing may have been a distorted depiction of a juvenile, as the figure bears a resemblance to a manatee calf. Another similar image was found by Alexander von Middendorff in 1867 in the library of the Russian Academy of Sciences, and is probably a copy of the Tsarskoye Selo Picture.\nRange.\nThe range of Steller's sea cow at the time of its discovery was apparently restricted to the shallow seas around the Commander Islands, which include Bering and Copper Islands. The Commander Islands remained uninhabited until 1825, when the Russian-American Company relocated Aleuts from Attu Island and Atka Island there.\nThe first fossils discovered outside the Commander Islands were found in interglacial Pleistocene deposits in Amchitka, and further fossils dating to the late Pleistocene were found in Monterey Bay, California, and Honshu, Japan. This suggests that the sea cow had a far more extensive range in prehistoric times, but the possibility that these fossils belong to other \"Hydrodamalis\" species cannot be excluded. The southernmost find is a Middle Pleistocene rib bone from the B\u014ds\u014d Peninsula of Japan. The remains of three individuals were found preserved in the South Bight Formation of Amchitka; as late Pleistocene interglacial deposits are rare in the Aleutians, the discovery suggests that sea cows were abundant during that era. According to Steller, the sea cow often resided in the shallow, sandy shorelines and in the mouths of freshwater rivers. Genetic evidence suggests that Steller's sea cow, as well as the modern dugong, suffered a population bottleneck (a significant reduction in population) bottoming roughly 400,000 years ago.\nBone fragments and accounts by native Aleut people suggest that sea cows also historically inhabited the Near Islands, possibly with viable populations that were in contact with humans in the western Aleutian Islands prior to Steller's discovery in 1741. A sea cow rib discovered in 1998 on Kiska Island was dated to around 1,000 years old, and is now in the possession of the Burke Museum in Seattle; the dating may be skewed due to the marine reservoir effect, which causes radiocarbon-dated marine specimens to appear several hundred years older than they are. (Marine reservoir effect is caused by the large reserves of C14 in the ocean, and it is more likely that the animal died between 1710 and 1785. A 2004 study reported that sea cow bones discovered on Adak Island were around 1,700 years old, and sea cow bones discovered on Buldir Island were found to be around 1,600 years old. It is possible that these bones were from cetaceans and were misclassified. Rib bones of a Steller's sea cow have also been found on St. Lawrence Island, from a specimen that is thought to have lived between 800 and 920 CE.\nInteractions with humans.\nExtinction.\nGenetic evidence suggests the Steller's sea cows around the Commander Islands were the last of a much more ubiquitous population dispersed across the North Pacific coastal zones. They had the same genetic diversity as the last and rather inbred population of woolly mammoths on Wrangel Island. During glacial periods and reduction in sea levels and temperatures, suitable habitat substantially regressed, fragmenting the population. By the time sea levels stabilized around 5,000 years ago, the population had already plummeted. Together, these indicate that even without human influence, the Steller's sea cow would have still been a dead clade walking, with the vast majority of the population having already gone extinct from natural climatic and sea level shifts, with the tiny remaining population at major risk from a genetic extinction vortex.\nThe presence of Steller's sea cows in the Aleutian Islands may have caused the Aleut people to migrate westward to hunt them. This possibly led to the sea cow's extirpation in that area, assuming it had not already happened yet, but the archaeological evidence is inconclusive. One factor potentially leading to extinction of Steller's sea cow, specifically off the coast of St. Lawrence Island, was the Siberian Yupik people who have inhabited St. Lawrence island for 2,000 years. They may have hunted the sea cows into extinction, as the natives have a dietary culture heavily dependent upon marine mammals. The onset of the Medieval Warm Period, which reduced the availability of kelp, may have also been the cause for their local extinction in that area. It has also been argued that the decline of Steller's sea cow may have been an indirect effect of the harvesting of sea otters by the area's aboriginal people. With the otter population reduced, the sea urchin population would have increased, in turn reducing the stock of kelp, its principal food. In historic times, though, aboriginal hunting had depleted sea otter populations only in localized areas, and as the sea cow would have been easy prey for aboriginal hunters, accessible populations may have been exterminated with or without simultaneous otter hunting. In any event, the range of the sea cow was limited to coastal areas off uninhabited islands by the time Bering arrived, and the animal was already endangered.\nWhen Europeans discovered them, there may have been only 2,000 individuals left. This small population was quickly wiped out by fur traders, seal hunters, and others who followed Vitus Bering's route past its habitat to Alaska. It was also hunted to collect its valuable subcutaneous fat. The animal was hunted and used by Ivan Krassilnikov in 1754 and Ivan Korovin 1762, but Dimitri Bragin, in 1772, and others later, did not see it. Brandt thus concluded that by 1768, twenty-seven years after it had been discovered by Europeans, the species was extinct. In 1887, Stejneger estimated that there had been fewer than 1,500 individuals remaining at the time of Steller's discovery, and argued there was already an immediate danger of the sea cow's extinction.\nThe first attempt to hunt the animal by Steller and the other crew members was unsuccessful due to its strength and thick hide. They had attempted to impale it and haul it to shore using a large hook and heavy cable, but the crew could not pierce its skin. In a second attempt a month later, a harpooner speared an animal, and men on shore hauled it in while others repeatedly stabbed it with bayonets. It was dragged into shallow waters, and the crew waited until the tide receded and it was beached to butcher it. After this, they were hunted with relative ease, the challenge being in hauling the animal back to shore. This bounty inspired maritime fur traders to detour to the Commander Islands and restock their food supplies during North Pacific expeditions.\nImpact of extinction.\nWhile not a keystone species, Steller's sea cows likely influenced the community composition of the kelp forests they inhabited, and also boosted their productivity and resilience to environmental stressors by allowing more light into kelp forests and more kelp to grow, and enhancing the recruitment and dispersal of kelp through their feeding behavior. In the modern day, the flow of nutrients from kelp forests to adjacent ecosystems is regulated by the seasons, with seasonal storms and currents being the primary factor. The Steller's sea cow may have allowed this flow to continue year-round, thus allowing for more productivity in adjacent habitats. The disturbance caused by the Steller's sea cow may have facilitated the dispersal of kelp, most notably \"Nereocystis\" species, to other habitats, allowing recruitment and colonization of new areas, and facilitating genetic exchange. Their presence may have also allowed sea otters and large marine invertebrates to coexist, indicating a commonly-documented decline in marine invertebrate populations driven by sea otters (an example being in populations of the black leather chiton) may be due to lost ecosystem functions associated with the Steller's sea cow. This indicates that due to the sea cow's extinction, the ecosystem dynamics and resilience of North Pacific kelp forests may have already been compromised well before more well-known modern stressors like overharvesting and climate change.\nLater reported sightings.\nSea cow sightings have been reported after Brandt's official 1768 date of extinction. Lucien Turner, an American ethnologist and naturalist, said the natives of Attu Island reported that the sea cows survived into the 1800s, and were sometimes hunted.\nIn 1963, the official journal of the Academy of Sciences of the USSR published an article announcing a possible sighting. The previous year, the whaling ship \"Buran\" had reported a group of large marine mammals grazing on seaweed in shallow water off Kamchatka, in the Gulf of Anadyr. The crew reported seeing six of these animals ranging from , with trunks and split lips. There have also been alleged sightings by local fishermen in the northern Kuril Islands, and around the Kamchatka and Chukchi peninsulas.\nUses.\nSteller's sea cow was described as being \"tasty\" by Steller; the meat was said to have a taste similar to corned beef, though it was tougher, redder, and needed to be cooked longer. The meat was abundant on the animal, and slow to spoil, perhaps due to the high amount of salt in the animal's diet effectively curing it. The fat could be used for cooking and as an odorless lamp oil. The crew of the St. Peter drank the fat in cups and Steller described it as having a taste like almond oil. The thick, sweet milk of female sea cows could be drunk or made into butter, and the thick, leathery hide could be used to make clothing, such as shoes and belts, and large skin boats sometimes called baidarkas or umiaks.\nTowards the end of the 19th century, bones and fossils from the extinct animal were valuable and often sold to museums at high prices. Most were collected during this time, limiting trade after 1900. Some are still sold commercially, as the highly dense cortical bone is well-suited for making items such as knife handles and decorative carvings. Because the sea cow is extinct, native artisan products made in Alaska from this \"mermaid ivory\" are legal to sell in the United States and do not fall under the jurisdiction of the Marine Mammal Protection Act (MMPA) or the Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES), which restrict the trade of marine mammal products. Although the distribution is legal, the sale of unfossilized bones is generally prohibited and trade in products made of the bones is regulated because some of the material is unlikely to be authentic and probably comes from arctic cetaceans.\nThe ethnographer Elizabeth Porfirevna Orlova, from the Russian Museum of Ethnography, was working on the Commander Island Aleuts from August to September 1961. Her research includes notes about a game of accuracy, called \"kakan\" (\"stones\") played with the bones of the Steller's sea cow. Kakan was usually played at home between adults during bad weather, at least during Orlova's fieldwork.\nIn literature, media, and folklore.\nIn the story \"The White Seal\" from \"The Jungle Book\" by Rudyard Kipling, which takes place in the Bering Sea, Kotick the rare white seal consults Sea Cow during his journey to find a new home.\n\"Tales of a Sea Cow\" is a 2012 docufiction film by Icelandic-French artist Etienne de France about a fictional 2006 discovery of Steller's sea cows off the coast of Greenland. The film has been exhibited in art museums and universities in Europe.\nSteller's sea cows appear in two books of poetry: \"Nach der Natur\" (1995) by Winfried Georg Sebald, and \"Species Evanescens\" (2009) by Russian poet Andrei Bronnikov. Bronnikov's book depicts the events of the Great Northern Expedition through the eyes of Steller; Sebald's book looks at the conflict between man and nature, including the extinction of Steller's sea cow.\nThe 2023 novel \"Beasts of the Sea\" (\"Elolliset\") by Finnish author and literary scholar Iida Turpeinen uses Steller's sea cow and its demise as a central theme. It features multiple characters at different times in history that were involved with the animal, beginning from Steller's expedition and telling how the complete skeleton was conserved and ended up in the Helsinki museum of natural history.\nScottish poet John Glenday published the poem \"The Kelp Eaters\" in his 2003 volume, Grain, describing the beauty and loving nature of the sea cows and their harpooning by the narrator and his companions. The poem carries the epigraph \"From \"Journal of a Voyage with Bering 1741-1742\" By Georg Wilhelm Steller\".\nGenetic research and potential revival.\nIn 2021, the nuclear genome of the species was sequenced from skeletal remains. The reconstructed genome showed that the species was already declining due to low genetic diversity caused by climate change and hunting by Paleolithic humans prior to its discovery by Steller, similar to the final populations of woolly mammoths on Wrangel Island. A year later, in late 2022, a group of Russian scientists funded by Sergi Bachin began research to potentially revive the species and reintroduce it to the Bering Sea. Arctic Sirenia plans to revive the species through genome editing of the dugong, but an artificial womb is necessary to conceive a living sea cow due to the lack of an appropriate living surrogate species. Ben Lamm of Colossal Biosciences has also stated that he and his company want to revive the species after they complete their first four projects (woolly mammoth, dodo, thylacine, and northern white rhinoceros) and have an artificial animal womb developed.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60413", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=60413", "title": "Susa", "text": "Ancient city in Iran\nSusa ( ) was an ancient city in the lower Zagros Mountains about east of the Tigris, between the Karkheh and Dez Rivers in Iran. One of the most important cities of the Ancient Near East, Susa served as the capital of Elam and the winter capital of the Achaemenid Empire, and remained a strategic centre during the Parthian and Sasanian periods.\nThe site currently consists of three archaeological mounds, covering an area of around . The city of Shush is located on the site of ancient Susa.\nName.\nThe name Susa is of Elamite origin and has appeared in many languages:\nLiterary references.\nSusa was one of the most important cities of the Ancient Near East. In historic literature, Susa appears in the very earliest Sumerian records: for example, it is described as one of the places obedient to Inanna, patron deity of Uruk, in \"Enmerkar and the Lord of Aratta\".\nBiblical texts.\nSusa is mentioned in the Ketuvim of the Hebrew Bible by the name Shushan, mainly in the Book of Esther, but also once each in the books of Ezra (Ezra 4:9), Nehemiah (Nehemiah 1:1) and Daniel (Daniel 8:2). According to these texts, Nehemiah lived in Susa during the Babylonian captivity of the 6th century BC (Daniel mentions it in a prophetic vision), while Esther became queen there, married to King Ahasuerus, and saved the Jews from genocide. A tomb presumed to be that of Daniel is located in the area, known as \"Shush-Daniel\". However, a large portion of the current structure is actually a much later construction dated to the late nineteenth century, c.\u20091871.\nPseudepigrapha.\nSusa is further mentioned in the \"Book of Jubilees\" (8:21 &amp; 9:2) as one of the places within the inheritance of Shem and his eldest son Elam; and in 8:1, \"Susan\" is also named as the son (or daughter, in some translations) of Elam.\nExcavation history.\nThe site was examined in 1836 by Henry Rawlinson and then by A. H. Layard.\nIn 1851, some modest excavation was done by William Loftus, accompanied by Fenwick Williams, who identified it as Susa. Among his finds was a jar containing around 110 coins, the earliest of which was dated to 697-98 AD.\nIn 1885 and 1886 Marcel-Auguste Dieulafoy and Jane Dieulafoy began the first French excavations, discovering glazed bricks, column bases, and capitals from the palace of the Achaemenid kings. However, they failed to identify mudbrick walls, which were then destroyed in the course of excavation. Almost all of the excavations at Susa, post-1885, were organized and authorized by the French government.\nIn two treaties in 1894 and 1899, the French gained a monopoly on all archaeological excavations in Iran indefinitely. Jacques de Morgan, after visiting the site in 1891, conducted major excavations from 1897 until 1911. The excavations that were conducted in Susa brought many artistic and historical artifacts back to France. These artifacts filled multiple halls in the Museum of the Louvre throughout the late 1890s and early 1900s. De Morgan's most important work was the excavation of the Grande Tranch\u00e9e in the Acropole mound, where he found the stele of Naram-Sin, a collection of Babylonian kudurrus (boundary stones), the stele bearing the Code of Hammurabi, an ornamented bronze table of snakes, the bronze statue of Queen Napir-Asu, and thousands of inscribed bricks. His finds showed Susa to be the most important center of Elamite civilization, which was effectively discovered by the French mission at Susa.\nExcavation efforts continued under Roland De Mecquenem until 1914, at the beginning of World War I. French work at Susa resumed after the war, led by De Mecquenem, continuing until World War II in 1940. To supplement the original publications of De Mecquenem the archives of his excavation have now been put online thanks to a grant from the Shelby White Levy Program.\nRoman Ghirshman took over direction of the French efforts in 1946, after the end of the war. Together with his wife Tania Ghirshman, he continued there until 1967. The Ghirshmans concentrated on excavating a single part of the site, the hectare sized Ville Royale, taking it all the way down to bare earth. The pottery found at the various levels enabled a stratigraphy to be developed for Susa.\nFrom 1969 until 1979 excavations were conducted under Jean Perrot.\nIn 2019 the Susa salvage project was launched to counter the construction of a transportation underpass in the vicinity of the site.\nHistory.\nEarly settlement.\nIn urban history, Susa is one of the oldest-known settlements of the region. Based on calibrated carbon-14 dating, the foundation of a settlement there occurred as early as 4200\u00a0BC. In the region around Susa were a number of towns (with their own platforms) and villages that maintained a trading relationship with the city, especially those along the Zagro frontier.\nThe founding of Susa corresponded with the abandonment of nearby villages. Potts suggests that the settlement may have been founded to try to reestablish the previously destroyed settlement at Chogha Mish, about 25\u00a0km to the west. Previously, Chogha Mish was a very large settlement, and it featured a similar massive platform that was later built at Susa.\nAnother important settlement in the area is Chogha Bonut, which was discovered in 1976.\nSusa I period (4200\u20133800 BC).\nShortly after Susa was first settled over 6000\u00a0years ago, its inhabitants erected a monumental platform that rose over the flat surrounding landscape. The exceptional nature of the site is still recognizable today in the artistry of the ceramic vessels that were placed as offerings in a thousand or more graves near the base of the temple platform.\nSusa's earliest settlement is known as the \"Susa I\" period (c. 4200\u20133900 BC). Two settlements named by archaeologists the \"Acropolis\" (7 ha) and the \"Apadana\" (6.3 ha), would later merge to form Susa proper (18 ha). The \"Apadana\" was enclosed by 6 metre thick walls of rammed earth (this particular place is named Apadana because it also contains a late Achaemenid structure of this type).\nNearly two thousand pots of \"Susa I\" style were recovered from the cemetery, most of them now in the Louvre. The vessels found attest to the artistic and technical achievements of their makers, and they hold clues about the organization of the society that commissioned them.\nPainted ceramic vessels from Susa in the earliest first style are a late, regional version of the Mesopotamian Ubaid ceramic tradition that spread across the Near East during the fifth millennium BC. Susa I style was very much a product of the past and of influences from contemporary ceramic industries in the mountains of western Iran. The recurrence in close association of vessels of three types\u2014a drinking goblet or beaker, a serving dish, and a small jar\u2014implies the consumption of three types of food, apparently thought to be as necessary for life in the afterworld as it is in this one. Ceramics of these shapes, which were painted, constitute a large proportion of the vessels from the cemetery. Others are coarse cooking-type jars and bowls with simple bands painted on them and were probably the grave goods of the sites of humbler citizens as well as adolescents and, perhaps, children. The pottery is carefully made by hand. Although a slow wheel may have been employed, the asymmetry of the vessels and the irregularity of the drawing of encircling lines and bands indicate that most of the work was done freehand.\nMetallurgy.\nCopper metallurgy is also attested during this period, which was contemporary with metalwork at some highland Iranian sites such as Tepe Sialk.\nAs many as 40 copper axes have been found at the Susa cemetery, as well as 10 round discs probably used as mirrors. Many awls and spatulas were also found.\n \"Metal finds from the burials in Susa are the major metal assemblage from the end of the 5th millennium BCE. Strata 27 to 25 contained the earliest burials with a large number of axes, made from unalloyed copper and copper with elevated As [Arsenic] levels.\"\nThe cemetery of Chega Sofla, from the same timeframe, provides a lot of similar material, with many sophisticated metal objects. Chega Sofla is located in the same geographical area.\nSusa II and Uruk influence (3800\u20133100 BC).\nSusa came within the Uruk cultural sphere during the Uruk period. An imitation of the entire state apparatus of Uruk, proto-writing, cylinder seals with Sumerian motifs, and monumental architecture is found at Susa. The comparative periodization of Susa and Uruk at this time remains disputed among scholars with some research indicating that Early Uruk period corresponds to Susa II period.\nThe nature and extent of Uruk influence in Susa is also disputed. Daniel T. Potts argues that the influence from the highland Iranian Khuzestan area in Susa was more significant at the early period, and also continued later on. Thus, Susa combined the influence of two cultures, from the highland area and from the alluvial plains. Potts also stresses that Susa did not simply borrow the writing and numerical systems of Uruk wholesale, but were adopted only partially and selectively as needed.\nUruk was far larger than Susa at the time, raising questions about its influence. Some scholars believe that Susa was part of the greater Uruk culture. Holly Pittman, an art historian at the University of Pennsylvania in Philadelphia says, \"the Susanians are participating entirely in an Uruk way of life. They are not culturally distinct; the material culture of Susa is a regional variation of that on the Mesopotamian plain\". \nOthers emphasize Susa's relative independence. They deny that Susa was a colony of Uruk: it maintained some independence for a long time, according to Potts. An architectural link has also been suggested between Susa, Tal-i Malyan, and Godin Tepe at this time, in support of the idea of the parallel development of the Proto-Cuneiform and proto-elamite scripts. Gilbert Stein, director of the University of Chicago's Oriental Institute, notes that \"An expansion once thought to have lasted less than 200 years now apparently went on for 700 years. It is hard to think of any colonial system lasting that long. The spread of Uruk material is not evidence of Uruk domination; it could be local choice\".\nSusa III, or \"Proto-Elamite\", period (3100\u20132700 BC).\nSusa III (3100\u20132700\u00a0BC) is also known as the 'Proto-Elamite' period. At this time, Banesh period pottery is predominant. This is also when the Proto-Elamite tablets first appear in the record. Subsequently, Susa became the centre of Elam civilization.\nAmbiguous reference to Elam () appear also in this period in Sumerian records. Susa enters recorded history in the Early Dynastic period of Sumer. A battle between Kish and Susa is recorded in 2700\u00a0BC, when En-me-barage-si is said to have \"made the land of Elam submit\".\nElamites.\nIn the Sumerian period, Susa was the capital of a state called Susiana (\u0160u\u0161an), which occupied approximately the same territory of modern Kh\u016bzest\u0101n Province centered on the Karun River. Control of Susiana shifted between Elam, Sumer, and Akkad.\nDuring the Elamite monarchy, many riches and materials were brought to Susa from the plundering of other cities. This was mainly due to the fact of Susa's location on Iran's South Eastern region, closer to the city of Babylon and cities in Mesopotamia.\nThe use of the Elamite language as an administrative language was first attested in texts of ancient Ansan, Tall-e Mal-yan, dated 1000 BC. Previous to the era of Elamites, the Akkadian language was responsible for most or all of the text used in ancient documents. Susiana was incorporated by Sargon the Great into his Akkadian Empire in approximately 2330\u00a0BC.\nThe main goddess of the city was Nanaya, who had a significant temple in Susa.\nOld Elamite period (c. 2700\u20131500 BC).\nThe Old Elamite period began around 2700 BC. Historical records mention the conquest of Elam by Enmebaragesi, the Sumerian king of Kish in Mesopotamia. Three dynasties ruled during this period. Twelve kings of each of the first two dynasties, those of Awan (or \"Avan\"; c. 2400\u20132100 BC) and Simashki (c. 2100\u20131970 BC), are known from a list from Susa dating to the Old Babylonian period. Two Elamite dynasties said to have exercised brief control over parts of Sumer in very early times include Awan and Hamazi; and likewise, several of the stronger Sumerian rulers, such as Eannatum of Lagash and Lugal-anne-mundu of Adab, are recorded as temporarily dominating Elam.\nKutik-Inshushinak.\nSusa was the capital of an Akkadian province until ca. 2100\u00a0BC, when its governor, Kutik-Inshushinak, rebelled and made it an independent state and a literary center. Also, he was the last from the Awan dynasty according to the Susa kinglist. He unified the neighbouring territories and became the king of Elam. He encouraged the use of the Linear Elamite script, that remains undeciphered.\nThe city was subsequently conquered by the neo-Sumerian Third Dynasty of Ur and held until Ur finally collapsed at the hands of the Elamites under Kindattu in ca. 2004\u00a0BC. At this time, Susa was ruled by Elam again and became its capital under the Shimashki dynasty.\nIndus-Susa relations (2400\u20132100 BC).\nNumerous artifacts of Indus Valley civilization origin have been found in Susa from this period, especially seals and etched carnelian beads, pointing to Indus-Mesopotamia relations during this period.\nMiddle Elamite period (c. 1500\u20131100 BC).\nAround 1500 BC, the Middle Elamite period began with the rise of the Anshanite dynasties. Their rule was characterized by an \"Elamisation\" of Susa, and the kings took the title \"king of Anshan and Susa\". While, previously, the Akkadian language was frequently used in inscriptions, the succeeding kings, such as the Igihalkid dynasty of c. 1400\u00a0BC, tried to use Elamite. Thus, Elamite language and culture grew in importance in Susiana.\nThis was also the period when the Elamite pantheon was being imposed in Susiana. This policy reached its height with the construction of the political and religious complex at Chogha Zanbil, south-east of Susa.\nIn ca. 1175\u00a0BC, the Elamites under Shutruk-Nahhunte plundered the original stele bearing the \"Code of Hammurabi\" and took it to Susa. Archeologists found it in 1901. Nebuchadnezzar I of the Babylonian empire plundered Susa around fifty years later.\nNeo-Elamite period (c. 1100\u2013540 BC).\nNeo-Assyrians.\nIn 647\u00a0BC, Neo-Assyrian king Ashurbanipal leveled the city during a war in which the people of Susa participated on the other side. A tablet unearthed in 1854 by Austen Henry Layard in Nineveh reveals Ashurbanipal as an \"avenger\", seeking retribution for the humiliations that the Elamites had inflicted on the Mesopotamians over the centuries:\n\"Susa, the great holy city, abode of their gods, seat of their mysteries, I conquered. I entered its palaces, I opened their treasuries where silver and gold, goods and wealth were amassed. . . .I destroyed the ziggurat of Susa. I smashed its shining copper horns. I reduced the temples of Elam to naught; their gods and goddesses I scattered to the winds. The tombs of their ancient and recent kings I devastated, I exposed to the sun, and I carried away their bones toward the land of Ashur. I devastated the provinces of Elam and, on their lands, I sowed salt.\"\nAssyrian rule of Susa began in 647 BC and lasted till Median capture of Susa in 617 BC.\nAchaemenid Period.\nSusa underwent a major political and ethnocultural transition when it became part of the Persian Achaemenid empire between 540 and 539\u00a0BC when it was captured by Cyrus the Great during his conquest of Elam (Susiana), of which Susa was the capital. The Nabonidus Chronicle records that, prior to the battle(s), Nabonidus had ordered cult statues from outlying Babylonian cities to be brought into the capital, suggesting that the conflict over Susa had begun possibly in the winter of 540\u00a0BC.\nIt is probable that Cyrus negotiated with the Babylonian generals to obtain a compromise on their part and therefore avoid an armed confrontation. Nabonidus was staying in the city at the time and soon fled to the capital, Babylon, which he had not visited in years.\nCyrus' conquest of Susa and the rest of Babylonia commenced a fundamental shift, bringing Susa under Persian control for the first time. Strabo stated that Cyrus made Susa an imperial capital though there was no new construction in that period so this is in dispute.\nUnder Cyrus' son Cambyses II, Susa became a center of political power as one of four capitals of the Achaemenid Persian empire, while reducing the significance of Pasargadae as the capital of Persis. Following Cambyses' brief rule, Darius the Great began a major building program in Susa and Persepolis, which included building a large palace. During this time he describes his new capital in an inscription:\n\"This palace which I built at Susa, from afar its ornamentation was brought. Downward the earth was dug, until I reached rock in the earth. When the excavation had been made, then rubble was packed down, some 40\u00a0cubits in depth, another part 20\u00a0cubits in depth. On that rubble the palace was constructed.\"\nThe city forms the setting of \"The Persians\" (472\u00a0BC), an Athenian tragedy by the ancient Greek playwright Aeschylus that is the oldest surviving play in the history of theatre.\nEvents mentioned in the Old Testament book of Esther are said to have occurred in Susa during the Achaemenid period. The King Ahasuerus mentioned in that book may refer to Xerxes I (486-465\u00a0BC).\nSeleucid period.\nAlexander the Great invaded the Achaemenid empire and the satrap of Susa surrendered to him. Susa lost much of its importance afterwards. In 324\u00a0BC, Alexander met Nearchus here, who explored the Persian Gulf as he returned from the Indus River by sea. In that same year Alexander celebrated in Susa with a mass wedding between the Persians and Macedonians.\nThe city retained its importance under the Seleucids for approximately one century after Alexander, however Susa lost its position of imperial capital to Seleucia on the Tigris to become the regional capital of the satrapy of Susiana. Nevertheless, Susa retained its economic importance to the empire with its vast assortment of merchants conducting trade in Susa, using Charax Spasinou as its port.\nThe city was named Seleucia on the Eulaeus or Seleucia ad Eulaeum.\nSeleucus I Nicator minted coins there in substantial quantities. Susa is rich in Greek inscriptions, perhaps indicating a significant number of Greeks living in the city. Especially in the royal city large, well-equipped peristyle houses have been excavated.\nParthian period.\nAround 147\u00a0BC Susa and the adjacent Elymais broke free from the Seleucid Empire. The city was at least temporarily ruled by the rulers of the Elymais with Kamnaskires II Nikephoros minting coins there. The city may again have briefly returned to Seleucid rule, but starting with Phraates II (about 138\u2013127 BC) to Gotarzes II (about 40\u201351 AD) almost all rulers of the Parthian Empire coined coins in the city, indicating that it was firmly in the hands of the Parthians at least during this period. The city however retained a considerable amount of independence and retained its Greek city-state organization well into the ensuing Parthian period. From second half of the first century it was probably partly governed by rulers of Elymais again, but it became Parthian once again in 215.\nSusa was a frequent place of refuge for Parthian and later, the Persian Sassanid kings, as the Romans sacked Ctesiphon five different times between 116 and 297\u00a0AD. Susa was briefly captured in 116\u00a0AD by the Roman emperor Trajan during the course of his Parthian campaign. Never again would the Roman Empire advance so far to the east.\nSassanid period.\nSusa was conquered and destroyed in 224\u00a0AD by the Sassanid Ardashir I, but rebuilt immediately thereafter, and perhaps even temporarily a royal residence. According to a later tradition, Shapur I is said to have spent his twilight years in the city, although this tradition is uncertain and perhaps refers more to Shapur II.\nUnder the Sassanids, following the founding of Gundeshapur Susa slowly lost its importance. Archaeologically, the Sassanid city is less dense compared to the Parthian period, but there were still significant buildings, with the settlement extending over 400 hectares.\nSusa was also still very significant economically and a trading center, especially in gold trading. Coins also continued to be minted in the city. The city had a Christian community in a separate district with a Nestorian bishop, whose last representative is attested to in 1265. Archaeologically a stucco panel with the image of a Christian saint has been found.\nDuring the reign of Shapur II after Christianity became the state religion of the Roman Empire in 312, and the identification of Christians as possible collaborators with the enemy Christians living in the Sasanian Empire were persecuted from 339 onwards. Shapur II also imposed a double tax on the Christians during his war campaign against the Romans. Following a rebellion of Christians living in Susa, the king destroyed the city in 339 using 300 elephants. He later had the city rebuilt and resettled with prisoners of war and weavers, which is believed to have been after his victory over the Romans in Amida in 359. The weaver produced silk brocade. He renamed it \"Eran-Khwarrah-Shapur\" (\"Iran's glory [built by] Shapur\").\nIslamic period.\nDuring the Muslim conquest of Persia an Arab army invaded Khuzistan under the command of Abu Musa al-Ash'ari. After taking most of the smaller fortified towns the army captured Tustar in 642 before proceeding to besiege Susa. A place of military importance, it also held the tomb of the Jewish prophet Daniel.\nTwo stories are given in the Muslim sources of how the city fell. In the first, a Persian priest proclaimed from the walls that only a \"dajjal\" was fated to capture the city. A \"dajjal\" is an Islamic term for an \"Al-Masih ad-Dajjal\", a false messiah, compatible to the Antichrist in Christianity. In everyday use, it also means \"deceiver\" or \"imposter\". Siyah, a Persian general who had defected to Muslim side, claimed that by converting to Islam he had turned his back on Zoroastrianism and was thus a \"dajjal\". Abu Musa agreed to Siyah's plan. Soon after as the sun came up one morning, the sentries on the walls saw a man in a Persian officer's uniform covered in blood lying on the ground before the main gate. Thinking it he had been left out overnight after a conflict the previous day, they opened the gate and some came out to collect him. As they approached, Siyah jumped up and killed them. Before the other sentries had time to react, Siyah and a small group of Muslim soldiers hidden nearby charged through the open gate. They held the gate open long enough for Muslim reinforcements to arrive and passing through the gate to take the city.\nIn the other story, once again the Muslims were taunted from the city wall that only an \"Al-Masih ad-Dajjal\" could capture the city, and since there were none in the besieging army then they may as well give up and go home. One of the Muslim commanders was so angry and frustrated at this taunt that he went up to one of the city gates and kicked it. Instantly the chains snapped, the locks broke and it fell open.\nFollowing their entry into the city, the Muslims killed all of the Persian nobles.\nOnce the city was taken, as Daniel () was not mentioned in the Qur'an, the initial reaction of the Muslim was to destroy the cult by confiscating the treasure that had stored at the tomb since the time of the Achaemenids. They then broke open the silver coffin and carried off the mummified corpse, removing from the corpse a signet ring, which carried an image of a man between two lions. However, upon hearing what had happened, the caliph Umar ordered the ring to be returned and the body reburied under the riverbed. In time, Daniel became a Muslim cult figure and they as well as Christians began making pilgrimages to the site, despite several other places claiming to be the site of Daniel's grave.\nFollowing the capture of Susa, the Muslims moved on to besiege Gundeshapur.\nSusa recovered following its capture and remained a regional center of more than 400 hectares in size. A mosque was built, but also Nestorian bishops are still testifie. In addition, there was a Jewish community with its own synagogue.\nThe city continued to be a manufacturing center of luxury fabrics during this period. Archaeologically, the Islamic period is characterized mainly by its rich ceramics. Beth Huzaye (East Syrian Ecclesiastical Province) had a significant Christian population during the first millennium, and was a diocese of the Church of the East between the 5th and 13th centuries, in the metropolitan province of Beth Huzaye (Elam).\nIn 1218, the city was razed by invading Mongols and was never able to regain its previous importance. The city further degraded in the 15th century when the majority of its population moved to Dezful.\nToday.\nToday the ancient center of Susa is unoccupied, with the population living in the adjacent modern Iranian town of Shush to the west and north of the historic ruins. Shush is the administrative capital of Shush County in Iran's Khuzestan province. It had a population of 64,960 in 2005.\nWorld Heritage listing.\nIn July 2015, it was inscribed on the list of World Heritage Sites by UNESCO.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\nExcavation reports.\nAlthough numerous excavation reports have been published so far, many excavations are not or only partially published. Above all, the found architecture was often presented only in short preliminary reports and plans.\nExternal links.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "60415", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=60415", "title": "Bandwidt", "text": ""}
{"id": "60416", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=60416", "title": "Bell Labsq", "text": ""}
{"id": "60417", "revid": "17417424", "url": "https://en.wikipedia.org/wiki?curid=60417", "title": "Battle of Maldon", "text": "Battle near Maldon, Essex, in 991\nThe Battle of Maldon took place on 10 or 11 August 991 AD near Maldon beside the River Blackwater in Essex, England, during the reign of \u00c6thelred the Unready. Earl Byrhtnoth and his thegns led the English against a Viking invasion. The battle ended in an Anglo-Saxon defeat. After the battle Archbishop Sigeric of Canterbury and the aldermen of the south-western provinces advised King \u00c6thelred to buy off the Vikings rather than continue the armed struggle. The result was a payment of Danegeld of 10,000 Roman pounds (3,300\u00a0kg) of silver (approx \u00a31.8M at 2022 prices).\nAn account of the battle, embellished with many speeches attributed to the warriors and with other details, is related in an Old English poem which is usually named \"The Battle of Maldon\". A modern embroidery created for the millennium celebration in 1991 and, in part, depicting the battle, can be seen at the Maeldune Centre in Maldon.\nOne manuscript of the \"Anglo-Saxon Chronicle\" states that a certain Olaf, possibly the Norwegian Olaf Tryggvason, led the Viking forces, these estimated to have been between 2,000 and 4,000 fighting men. A source from the 12th-century , written by the monks at Ely, suggests that Byrhtnoth had only a few men to command: \"he was neither shaken by the small number of his men, nor fearful of the multitude of the enemy\". Not all sources indicate such a disparity in numbers.\nThe poem \"The Battle of Maldon\".\n\"The Battle of Maldon\" is the name conventionally given to a surviving 325-line fragment of Old English poetry. Linguistic study has led to the conjecture that initially the complete poem was transmitted orally, then in a lost manuscript in the East Saxon dialect and now survives as a fragment in the West Saxon form, possibly that of a scribe active at the Monastery of Worcester late in the 11th century. It is fortuitous that this was attached at an early date to a very notable manuscript, Asser's \"Life of King Alfred\", which undoubtedly assisted in its survival. The manuscript, by now detached, was burned in the Cotton library fire at Ashburnham House in 1731. The keeper of the collection, John Elphinstone (or his assistant, David Casley), had transcribed the 325 lines of the poem in 1724, but the front and back pages were already missing from the manuscript (possibly around 50 lines each): an earlier catalogue described it as ('mutilated at head and heel'). As a result, vital clues about the purpose of the poem and perhaps its date have been lost.\nAt the time of battle, English royal policy of responding to Viking incursions was split. Some favoured paying off the Viking invaders with land and wealth, while others favoured fighting to the last man. The poem suggests that Byrhtnoth held this latter attitude, hence his moving speeches of patriotism.\nThe Vikings sailed up the Blackwater (then called the Panta), and Byrhtnoth called out his levy. The poem begins with him ordering his men to stand and to hold weapons. His troops, except for personal household guards, were local farmers and villagers of the Essex Fyrd militia. He ordered them to \"send steed away and stride forwards\": they arrived on horses but fought on foot. The Vikings sailed up to a small island in the river. At low tide, the river leaves a land bridge from this island to the shore; the description seems to have matched the Northey Island causeway at that time. This would place the site of the battle about two miles southeast of Maldon. Olaf addressed the Saxons, promising to sail away if he was paid with gold and armour from the lord. Byrhtnoth replied, \"We will pay you with spear tips and sword blades.\"\nWith the ebb of the tide, Olaf's forces began an assault across the small land bridge. Three Anglo-Saxon warriors, Wulfstan, \u00c6lfhere and Maccus blocked the bridge, successfully engaging any Vikings who pressed forward (lines 72\u201383). The Viking commander requested that Byrhtnoth allow his troops onto the shore for formal battle. Byrhtnoth, (line 89b), let the enemy force cross to the mainland. Battle was joined, but an Englishman called Godr\u012bc fled riding Byrhtnoth's horse. Godr\u012bc's brothers Godwine and Godw\u012bg followed him. Then many English fled, recognizing the horse and thinking that its rider was Byrhtnoth fleeing. To add insult to injury, it is stated that Godric had often been given horses by Byrhtnoth, a detail that, especially during the time period, would have had Godric marked as a coward and a traitor, something that could have easily been described as worse than death. The Vikings overcame the Saxons after losing many men, killing Byrhtnoth. After the battle Byrhtnoth's body was found with its head missing, but his gold-hilted sword was still with his body.\nThere is some discussion about the meaning of \"\". Although literally meaning \"over-heart\" or \"having too much heart\", it could mean either \"pride\" or \"excess of courage\" (compare the Danish or German , which mean both \"hubris\" and \"recklessness\"). One argument is that the poem was written to celebrate Byrhtnoth's actions and goad others into heroic action, and Byrhtnoth's action stands proudly in a long tradition of heroic literature. Another viewpoint, most notably held by J. R. R. Tolkien, is that the poem is an elegy on a terrible loss and that the monastic author pinpoints the cause of the defeat in the commander's sin of pride, a viewpoint bolstered by the fact that is, in every other attested instance, used to describe Satan's pride. There is a memorial window, representing Byrhtnoth's dying prayer, in St Mary's church at Maldon.\nIt is believed by many scholars that the poem, while based upon actual events and people, was created to be less of a historical account and more of a means of enshrining and lifting up the memories of the men who fought and lost their lives on the battlefield protecting their homeland, especially in the case of the English commander of the battle, Byrhtnoth. He (Byrhtnoth) seems to embody many of the virtues that are uplifted in the Anglo-Saxon world, and is compared often by many scholars to the character Beowulf.\nNorse invaders and Norse raiders differed in purpose. The forces engaged by the Anglo-Saxon were raiding, or (in Old Norse) \"\", to gather loot, rather than to occupy land for settlement. Therefore, if Byrhtnoth's forces had kept the Vikings off by guarding the causeway or by paying them off, Olaf would likely have sailed farther up the river or along the coast, and raided elsewhere. As a man with troops and weapons, it might be that Byrhtnoth had to allow the Vikings ashore to protect others. The poem may, therefore, represent the work of what has been termed the \"monastic party\" in Ethelred's court, which advocated a military response, rather than tribute, to all Norse attacks.\nOther sources.\nThe death of Byrhtnoth, an ealdorman of Essex, was recorded in four versions of the \"Anglo-Saxon Chronicle\". Its Cotton Tiberius manuscript (Version B) says for the year 991:\n&lt;templatestyles src=\"Verse translation/styles.css\" /&gt;\n&lt;templatestyles src=\"Screen reader-only/styles.css\" /&gt;Translation:\n\"The Life of Oswald\", written in Ramsey around the same time as the battle, portrays Byrhtnoth as a great religious warrior, with references to Biblical prophetic era figures.\nIn 1170, the \"Liber Eliensis\" retold and embroidered the story and made the battle two fights, with the second being a fortnight long against overwhelming odds. These texts show, to some degree, the growth of a local hero cultus.\nChronology.\nThe Winchester (or Parker) version of the \"Anglo-Saxon Chronicle\" (Version A), has the most detailed account of the battle, but places it under the heading for the year 993. As all the other versions of the \"Chronicle\" place it in 991, this is believed to be either a transcription error, or because the battle was inserted later when its importance had become apparent. The widely accepted precise date is taken from notices for the death of Byrhtnoth in three abbey calendars; those of Ely, Winchester and Ramsey. The date in the Ely calendar is 10 August, whereas Winchester and Ramsey give 11 August. However, Byrhtnoth's close connections with Ely imply that 10 August is more likely to be the accurate date.\nTopography.\nIt is clear from the \"Anglo-Saxon Chronicles\" that Maldon in Essex is the site of the battle, because of its proximity to Ipswich and because Byrhtnoth was an Ealdorman of Essex. More precise details come from \"The Battle of Maldon\" narrative, which describes how the Vikings established themselves on an island, separated from the mainland by a tidal inlet which could be crossed by a \"bridge\" or \"ford\" at low tide. The poem describes how the Vikings and Saxons negotiated by calling across the water while waiting for the tide to go out. Northey Island seems to fit this description. An investigation in 1973 suggested that the channel between Northey Island and the mainland would have been about 120 yards (110 metres) rather than 240 yards (220 metres) today. The causeway which crosses the channel today may not have existed in its present form in the 10th century, but there was certainly some form of crossing present. Other sites have been suggested, one being Osea Island which can be reached by a causeway, but is too far from the mainland to shout across. A bridge a mile inland from Maldon, now called Heybridge, has also been suggested, but the river is not tidal at that point.\nManuscript sources.\nIn the Cotton library, the \"Battle of Maldon\" text had been in Otho A xii. The Elphinstone transcription is in the Bodleian Library, where it is pp.\u00a07\u201312 of MS Rawlinson B. 203.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60422", "revid": "27062869", "url": "https://en.wikipedia.org/wiki?curid=60422", "title": "Battle of Badon", "text": "6th-century battle in Sub-Roman Britain\nThe Battle of Badon, also known as the Battle of Mons Badonicus, was purportedly fought between Britons and Anglo-Saxons in Post-Roman Britain during the late 5th or early 6th century. It was credited as a major victory for the Britons, stopping the westward encroachment of the Anglo-Saxon kingdoms for a period.\nThe earliest known references to the battle, by the British cleric Gildas, date to the 6th century. It is chiefly known today for the supposed involvement of the man who would later be remembered as the legendary King Arthur; although it is not agreed that Arthur was a historical person, his name first appears in the 9th-century \"Historia Brittonum\", where he is mentioned as having participated in the battle alongside the Brittonic kings as a war commander, though is not described as a king himself. Because of the limited number of sources, there is no certainty about the date, location, or details of the fighting apart from the result being a victory for the Britons.\nAlmost all scholars agree that this battle did take place. Gildas, who wrote within living memory of the battle (he claims to have been born in the same year it was fought), does not mention Arthur or the names of other British leaders who took part. He also omits the names of the Saxon leaders. Gildas also does not describe it as an actual open battle, but rather as a siege. It remains unclear whether the Saxons were besieging the Britons or the Britons were besieging the Saxons.\nHistorical accounts.\nGildas.\nThe earliest mention of the Battle of Badon appears in Gildas' \"De Excidio et Conquestu Britanniae\" (\"On the Ruin and Conquest of Britain\"), written in the early to mid-6th century. In it, the Anglo-Saxons are said to have \"dipped [their] red and savage tongue in the western ocean\" before Ambrosius Aurelianus organized a British resistance with the survivors of the initial Saxon onslaught. Gildas describes the period that followed Ambrosius' initial success:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;From that time, the citizens were sometimes victorious, sometimes the enemy, in order that the Lord, according to His wont, might try in this nation the Israel of today, whether it loves Him or not. This continued up to the year of the siege of Badon Hill (\"obsessionis Badonici montis\"), and of almost the last great slaughter inflicted upon the rascally crew. And this commences, a fact I know, as the forty-fourth year, with one month now elapsed; it is also the year of my birth.\n\"De Excidio Britanniae\" describes the battle as such an \"unexpected recovery of the [island]\" that it caused kings, nobles, priests, and commoners to \"live orderly according to their several vocations.\" Afterwards, the long peace degenerated into civil wars and the iniquity of Maelgwn Gwynedd.\nThat Arthur had gone unmentioned by Gildas, ostensibly the source closest to his own time, was noticed at least as early as a 12th-century hagiography of Gildas which claims that Gildas had praised Arthur extensively but then excised him completely after Arthur killed the saint's brother, Hueil mab Caw. Modern writers have suggested the details of the battle may have been so well known that Gildas expected his audience to be familiar with them.\nBede.\nThe battle is next mentioned in an 8th-century text of Bede's \"Ecclesiastical History of the English People\" (\"Historia Ecclesiastica Gentis Anglorum\"), which describes the \"siege of Mount Badon, when they made no small slaughter of those invaders,\" as occurring 44 years after the first Anglo-Saxon settlement of Britain. Bede refers to Ambrosius Aurelianus as the leader of the Britons at that battle, whose parents had perished 'in the storm' and who were 'of the royal race'. Since Bede places that arrival just before, during or just after the joint reign in Rome of Marcian and Valentinian III in AD 449\u2013456, he must have considered Badon to have taken place between 493 and 500. Bede then puts off discussion of the battle \u2013 \"But more of this hereafter\" \u2013 only to seemingly never return to it.\nBede does later include an extended account of Saint Germanus of Auxerre's victory over the Saxons and Picts in a mountain valley (traditionally placed at Mold in Flintshire in northeast Wales), which he credits with curbing the threat of invasion for a generation. However, as the victory is described as having been accomplished bloodlessly, it was presumably a different occasion from Badon. Accepted at face value, Saint Germanus' involvement would also place the battle around AD 430, although Bede's chronology shows no knowledge of this.\nNennius and the Welsh Annals.\nThe earliest surviving text specifically mentioning Arthur in connection with the battle is the early 9th-century \"Historia Brittonum\" (\"The History of the Britons\"), attributed to the Welsh monk Nennius, in which the soldier (Latin \"m\u012bles\") Arthur is identified as the leader of the victorious British force at Badon:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The twelfth battle was on Mount Badon in which there fell in one day 960 men from one charge by Arthur; and no one struck them down except Arthur himself.\nThe Battle of Badon is next mentioned in the \"Annales Cambriae\" (\"Annals of Wales\"), assumed to have been written during the mid- to late-10th century. The entry states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Battle of Badon, in which Arthur carried the Cross of our Lord Jesus Christ for three days and three nights upon his shoulders [or shield] and the Britons were the victors.\nGeoffrey of Monmouth.\nGeoffrey of Monmouth's c. 1136 \"Historia Regum Britanniae\" (\"The History of the Kings of Britain\") was massively popular and survives in many copies from soon after its composition. Going into (and fabricating) much greater detail, Geoffrey closely identifies Badon with Bath, including having Merlin foretell that Badon's baths would lose their hot water and turn poisonous. He also mixes in aspects of other accounts: the battle begins as a Saxon siege and then becomes a normal engagement once Arthur's men arrive; Arthur bears the image of the Virgin both on his shield and shoulder. Arthur charges and kills 470, ten more than the number of Britons ambushed by Hengist near Salisbury.\nElements of the Welsh legends are added: in addition to the shield \"Pridwen\", Arthur gains his sword, \"Caliburnus\" (Excalibur), and his spear, \"Ron\". Geoffrey also makes the defence of the city from the Saxon sneak attack a holy cause, having Dubricius offer absolution of all sins for those who fall in battle.\nScholarship.\nThere is considerable scholarly debate as to the exact date and location of the battle, though most agree that it took place in southern England sometime around the turn of the sixth century.\nDate.\nDates proposed by scholars for the battle include 493, 501 and 516. Daniel McCarthy and D\u00e1ibh\u00ed \u00d3 Cr\u00f3in\u00edn have posited that Gildas' 44 years and one month is not a reference to the simple chronology but a position within the 84-year Easter cycle used for computus at the time by the Britons and the Irish church. The tables in question begin in January 438, which would place their revised date of the battle in February 482.\nAndrew Breeze, in a 2020 book, argues that the Battle of Badon or \"Braydon, Wiltshire\" took place in 493, deducing that Gildas was writing \"De Excidio\" in 536, in the middle of the extreme weather events of 535\u2013536, because he cited a \"certain thick mist and black night\" which \"sits upon the whole island\" of Britain, but not the subsequent famine in the year 537. Breeze concluded that Badon was fought \"(...) in southern Britain, was fought in 493 and had nothing to do with Arthur.\"\nLocation.\nThough academics have never reached any consensus, Mount Badon\u2019s location has traditionally been sited in the hills around Bath, most notably at Bathampton Down. Tim and Annette Burkitt have proposed Caer Badden (; now Bath, Somerset), some 20 miles northeast of the Roman mines at Charterhouse, on the basis of the \"Welsh Annals\" as well as archaeological and toponymic evidence.\nSusan Hirst, Geoffrey Ashe and Michael Wood argue for the site of Liddington Castle on the hill above Badbury (Old English: \"Baddan byrig\") in Wiltshire west of Swindon. This site, an Iron Age hill fort with signs of sub-Roman occupation, commands The Ridgeway, which connects the River Thames with the River Avon and River Severn beyond. From a very different etymological approach, Andrew Breeze also put forward a site near Swindon: arguing that \"Badon\" must be etymologically Brythonic rather than English (thus eliminating Bath from consideration as its name is entirely Germanic) and that Gildas's toponym (\"Badonici Montis\") is a corruption of \"Bradonici Montis\", Breeze posits Ringsbury Camp near Braydon northwest of Swindon as the site of the battle.\nThe similarly named Badbury Rings in Dorset have also been argued to be the location of the battle. David Cooper agrees that this is the most likely site and has provided the most comprehensive analysis of the battle available to date.\nA number of scholars have suggested locations outside southern England. William Forbes Skene believed the battle to have occurred at a substantial hillfort on Bowden Hill near Linlithgow on the basis of it overlooking one of Britain's many River Avons, specifically the Avon in Falkirk. Thomas Green proposed a site near Baumber in Lincolnshire (recorded as \"Badeburg\" in the Domesday Book) on the basis of archaeological evidence for a major early Saxon presence in the region and the similarity of the phrase \"in regione Linnuis\", used for a site in Nennius' list of Arthur's battles, to the Roman name for Lincoln (\"Lindum Colonia\") and the subsequent early English Kingdom of Lindsey. Archaeologist Keith Fitzpatrick-Matthews described Green's proposal as \"so far removed from the mainstream yet based on sound reasoning that it deserves serious consideration.\" Bernard Mees proposes on linguistic grounds that the sources for the \"Historia Brittonum\" were of northern origin, and that of hillforts containing the element \"Bad\", Arbury Camp in Northamptonshire is a possibility.\nPossible Saxon commander.\nSome authors have speculated that \u00c6lle of Sussex may have led the Saxon forces at this battle. Others reject the idea out of hand. In book 9 of his work \"Historia regum Britanniae\", Geoffrey of Monmouth mentions a certain Cheldric as a Saxon war leader who fought at Bath during the same period, so other scholars suggest that (due to similarities of names) Cerdic of Wessex was the Saxon leader during the battle.\nSecond Badon.\nThe A Text of the \"Annales Cambriae\" includes the entry: \"The first celebration of Easter among the Saxons. The second battle of Badon. Morgan dies.\" The date for this action is given by Phillimore as AD 665, but the Saxons' first Easter is placed by the B Text in its entry 634 years after the birth of Christ and \"the second Badon\" is not mentioned.\nRomance depiction.\nThe 13th-century Vulgate Cycle, a French prose romance retelling of the Arthurian legend, replaced the Battle of Badon with the Battle of Clarence (spelling variants: \"Clarance\", \"Clarans\", \"Clarenche\", \"Clarens\"). In the first round of fighting, a coalition of British kings is defeated by the Saxons (or the Saracens in some subsequent versions, including that by Thomas Malory). In the second phase, Arthur joins the battle and enemy forces are destroyed, driving invaders into the sea.\nLocal lore.\nApart from the professional scholarship, various communities throughout Wales and England have their own traditions maintaining that their area was the site of the battle. These include (besides Badbury Rings and Bathampton Down), the mountain of Mynydd Baedan near Maesteg in South Wales, and Bowden Hill in Wiltshire.\nModern depictions.\nKing Arthur leads the Knights of the Round Table into battle against the Saxons led by Hengist in the \"Prince Valiant\" comic strip series episodes 1430 (5 July 1964) and following. The battle is mentioned in the 1975 comedy film \"Monty Python and the Holy Grail\" as one of the many questionable feats of Sir Robin, who in the film's bardic narration is said to have \"personally wet himself at the Battle of Badon Hill\". The battle is featured prominently in 1997's \"\" by Bernard Cornwell, in the book's second part, \"Mynydd Baddon\", in which the armies of Angle and Saxon kings Aelle and Cerdic, aided by Celtic traitors led by Lancelot, are defeated in an epic battle by an uneasy alliance of various British and Irish kingdoms. The author combines various medieval accounts of the battle, such as it beginning as an Anglo-Saxon siege of a hilltop (here initially desperately defended by Guinevere, who is depicted as a brilliant strategist and rallying figure) and having Arthur's cavalry appear with the sign of the cross on their shields (here a requisite demanded by the Christian king Tewdric for him to also join the battle), to create a more grounded and realistic depiction than the ones from his medieval sources. The 2004 film \"King Arthur\" ends in a climactic battle scene occurring along Hadrian's Wall as the mostly Romano-British forces of Arthur defeat those of the Saxon kings Cerdic and Cynric, at a heavy cost to Arthur.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60424", "revid": "33352166", "url": "https://en.wikipedia.org/wiki?curid=60424", "title": "Hallucigenia", "text": "Genus of Cambrian animals\nHallucigenia is a genus of lobopodian known from Cambrian-aged fossils in Burgess Shale-type deposits in Canada (Burgess Shale) and China, and from isolated spines around the world. The generic name reflects the type species' unusual appearance and eccentric history of study; when it was erected as a genus, \"H. sparsa\" was reconstructed as an enigmatic animal upside down and back to front. Lobopodians are a grade of Paleozoic panarthropods from which the velvet worms, water bears, and arthropods arose.\nDescription.\n\"Hallucigenia\" is a long tubular animal with up to ten pairs of slender legs (lobopods). The first 2 or 3 leg pairs are slender and featureless, while the remaining 7 or 8 pairs each terminate with 1 or 2 claws. Above the trunk region are 7 pairs of rigid conical sclerites (spines) corresponding to the 3rd\u20139th leg pairs. The trunk is either featureless (\"H. sparsa\") or divided by heteronomous annulations (\"H. fortis\" and \"H. hongmeia\"). The \"head\" and \"tail\" end of the animal are difficult to identify; one end extends some distance beyond the legs and often droops down as if to reach the substrate. Some specimens display traces of a simple gut.\nResearch in the mid-2010s clarified that the longer end is a head with anteroventral mouth and at least a pair of simple eyes. The shape of head differs between species \u2013 elongated in \"H. sparsa\", rounded in \"H. fortis\", while those of \"H. hongmeia\" remain unknown. At least in \"H. sparsa\", the head possesses radial teeth and pharyngeal teeth within the front of the gut.\n\"Hallucigenia\"'s spines are made up of one to four nested elements. The spine surface of \"H. sparsa\" is covered in an ornament of minute triangular \"scales\", while the spine surface of \"Hallucigenia hongmeia\" is a net-like texture of microscopic circular openings, which can be interpreted as the remains of Papillae.\nHistory of study.\n\"Hallucigenia sparsa\" was originally described by Charles Walcott as a species of the polychaete worm \"Canadia\". In his 1977 redescription of the organism, Simon Conway Morris recognized the animal as something quite distinct, for which he proposed the name \"Hallucigenia\" because of the \"bizarre and dream-like appearance of the animal.\" No specimen was available that showed both rows of legs, so Conway Morris reconstructed the animal walking on its spines, with its single row of legs interpreted as tentacles on the animal's back. A dark stain at one end of the animal was interpreted as a featureless head. Only the forward tentacles could easily reach to the \"head\", meaning that a mouth on the head would have to be fed by passing food along the line of tentacles. Conway Morris suggested that a hollow tube within each of the tentacles might be a \"mouth\". This raised questions, such as how it would walk on the stiff legs, but it was accepted (with reservations) as the best available interpretation.\nAn alternative interpretation considered \"Hallucigenia\" to be an appendage of a larger, unknown animal. There had been precedent for this, as \"Anomalocaris\" had been originally identified as three separate creatures before being identified as a single huge (for its time) to creature.\nIn 1991, Lars Ramskold and Hou Xianguang, working with additional specimens of a \"hallucigenid\", \"Microdictyon\", from the lower Cambrian Maotianshan shales of China, reinterpreted \"Hallucigenia\" as a lobopodian, a legged worm-like taxon which were still thought to be exclusively related to onychophoran (velvet worm), carnivorous animals that resemble a caterpillar and shoot a sticky substance from their papillae to ensnare their prey, at that time. They inverted it, interpreting the tentacles, which they believe to be paired, as walking structures and the spines as protective. Further preparation of fossil specimens showed that \"second legs\" were buried at an angle to the plane along which the rock had split, and could be revealed by removing the overlying sediment. Ramskold and Hou also believe that the blob-like \"head\" is actually a stain that appears in many specimens, not a preserved portion of the anatomy. This stain may be an artifact of decomposition.\nAffinity.\nSince the revisions around 1990s, \"Hallucigenia\" is unquestionably a lobopodian panarthropod, although the relationship with other panarthropods remains controversial. \"Hallucigenia\" has long been interpreted as a stem-group onychophoran (velvet worms) \u2013 a position that has found support from multiple phylogenetic analysis. A key character demonstrating this affinity is the cone-in-cone construction of \"Hallucigenia\" claws, a feature shared only with modern onychophorans. On the other hand, some analysis rather support the position of \"Hallucigenia\" as a basal panarthropod outside of onychophoran stem-group. Under this scenario, the cone-in-cone structure shared between \"Hallucigenia\" and onychophorans represent panarthropod plesiomorphy. \"Hallucigenia\" also exhibits certain characters inherited from the ancestral ecdysozoan, but lost in the modern onychophorans \u2013 in particular its distinctive foregut armature.\nBelow is a cladogram for \"Hallucigenia\" according to Yang \"et al.\", 2015:\nMany studies show that the Hallucigenia genus may be paraphyletic.\nDiversity.\nIn 2002, Desmond Collins informally suggested that new \"Hallucigenia\" fossils from the Burgess Shale showed male and female forms, one with \"a rigid trunk, robust neck and a globular head\" and the other thinner, and with a small head.\nThree species of \"Hallucigenia\" have been described. The first specimen, \"Hallucigenia\" \"sparsa\", was discovered in Canada. Two other species, \"H. fortis\" and \"H. hongmeia\", are represented by the Maotianshan Shales' fossils of Chengjiang.\nDistribution.\n\"Hallucigenia\" was first described from the Burgess Shale in southeastern British Columbia, Canada. 109 specimens of \"Hallucigenia\" are known from the Greater Phyllopod bed, where they comprise 0.3% of the community. \"Hallucigenia\" also forms a minor component of Chinese lagerst\u00e4tten. Isolated hallucigeniid spines, however, are widely distributed in a range of Cambrian deposits, preserved both as carbonaceous and mineralized fossils.\nIn popular culture.\nThe bizarre appearance of \"Hallucigenia\" has inspired a number of science fiction creators when designing otherworldly or primordial creatures. Some examples include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60425", "revid": "4383153", "url": "https://en.wikipedia.org/wiki?curid=60425", "title": "Endosymbiosis", "text": ""}
{"id": "60426", "revid": "2051880", "url": "https://en.wikipedia.org/wiki?curid=60426", "title": "Symbiogenesis", "text": "Evolutionary theory\nSymbiogenesis (endosymbiotic theory, or serial endosymbiotic theory) is the leading evolutionary theory of the origin of eukaryotic cells from prokaryotic organisms. The theory holds that mitochondria, plastids such as chloroplasts, and possibly other organelles of eukaryotic cells are descended from formerly free-living prokaryotes (more closely related to the Bacteria than to the Archaea) taken one inside the other in endosymbiosis. Mitochondria appear to be phylogenetically related to Rickettsiales bacteria, while chloroplasts are thought to be related to cyanobacteria. \nThe idea that chloroplasts were originally independent organisms that merged into a symbiotic relationship with other one-celled organisms dates back to the 19th century, when it was espoused by researchers such as Andreas Schimper. The endosymbiotic theory was articulated in 1905 and 1910 by the Russian botanist Konstantin Mereschkowski, and advanced and substantiated with microbiological evidence by Lynn Margulis in 1967. \nAmong the many lines of evidence supporting symbiogenesis are that mitochondria and plastids contain their own chromosomes and reproduce by splitting in two, parallel but separate from the sexual reproduction of the rest of the cell; that the chromosomes of some mitochondria and plastids are single circular DNA molecules similar to the circular chromosomes of bacteria; that the transport proteins called porins are found in the outer membranes of mitochondria and chloroplasts, and also bacterial cell membranes; and that cardiolipin is found only in the inner mitochondrial membrane and bacterial cell membranes.\nHistory.\nThe Russian botanist Konstantin Mereschkowski first outlined the theory of symbiogenesis (from Greek: \u03c3\u03cd\u03bd \"syn\" \"together\", \u03b2\u03af\u03bf\u03c2 \"bios\" \"life\", and \u03b3\u03ad\u03bd\u03b5\u03c3\u03b9\u03c2 \"genesis\" \"origin, birth\") in his 1905 work, \"The nature and origins of chromatophores in the plant kingdom\", and then elaborated it in his 1910 \"The Theory of Two Plasms as the Basis of Symbiogenesis, a New Study of the Origins of Organisms\". Mereschkowski proposed that complex life-forms had originated by two episodes of symbiogenesis, the incorporation of symbiotic bacteria to form successively nuclei and chloroplasts. Mereschkowski knew of the work of botanist Andreas Schimper. In 1883, Schimper had observed that the division of chloroplasts in green plants closely resembled that of free-living cyanobacteria. Schimper had tentatively proposed (in a footnote) that green plants had arisen from a symbiotic union of two organisms. In 1918 the French scientist Paul Jules Portier published \"Les Symbiotes\", in which he claimed that the mitochondria originated from a symbiosis process. Ivan Wallin advocated the idea of an endosymbiotic origin of mitochondria in the 1920s.\nThe Russian botanist Boris Kozo-Polyansky became the first to explain the theory in terms of Darwinian evolution. In his 1924 book \"A New Principle of Biology. Essay on the Theory of Symbiogenesis\", he wrote, \"The theory of symbiogenesis is a theory of selection relying on the phenomenon of symbiosis.\" \nThese theories did not gain traction until more detailed electron-microscopic comparisons between cyanobacteria and chloroplasts were made, such as by Hans Ris in 1961 and 1962. These, combined with the discovery that plastids and mitochondria contain their own DNA, led to a resurrection of the idea of symbiogenesis in the 1960s.\nLynn Margulis advanced and substantiated the theory with microbiological evidence in a 1967 paper, \"On the origin of mitosing cells.\" In her 1981 work \"Symbiosis in Cell Evolution\" she argued that eukaryotic cells originated as communities of interacting entities, including endosymbiotic spirochaetes that developed into eukaryotic flagella and cilia. This last idea has not received much acceptance, because flagella lack DNA and do not show ultrastructural similarities to bacteria or to archaea (see also: Evolution of flagella and Prokaryotic cytoskeleton). According to Margulis and Dorion Sagan, \"Life did not take over the globe by combat, but by networking\" (i.e., by cooperation). Christian de Duve proposed that the peroxisomes may have been the first endosymbionts, allowing cells to withstand growing amounts of free molecular oxygen in the Earth's atmosphere. However, it now appears that peroxisomes may be formed \"de novo\", contradicting the idea that they have a symbiotic origin. The fundamental theory of symbiogenesis as the origin of mitochondria and chloroplasts is now widely accepted.\nSymbiogenesis revolutionized the history of evolution by proposing a mechanism for evolutionary development not encompassed in the original Darwininan vision. Symbiogenesis demonstrated that major evolutionary advancements, particularly the origin of eukaryotic cells, may have resulted from symbiotic mergers rather than from gradual mutations and individual competition, i.e., classical natural selection. Accordingly, symbiogenic theory suggests that endosymbiosis may be a powerful force in generating evolutionary novelty, beyond that which can be explained by natural selection alone.\nFrom endosymbionts to organelles.\nBiologists usually distinguish organelles from endosymbionts \u2013 whole organisms living inside other organisms \u2013 by their reduced genome sizes. As an endosymbiont evolves into an organelle, most of its genes are transferred to the host cell genome. The host cell and organelle therefore need to develop a transport mechanism that enables the return of the protein products needed by the organelle but now manufactured by the cell. \nFree-living ancestors.\nAlphaproteobacteria were formerly thought to be the free-living organisms most closely related to mitochondria. Later research indicates that mitochondria are most closely related to Pelagibacterales bacteria, in particular, those in the SAR11 clade. \nNitrogen-fixing filamentous cyanobacteria are the free-living organisms most closely related to plastids.\nBoth cyanobacteria and alphaproteobacteria maintain a large (&gt;6Mb) genome encoding thousands of proteins. Plastids and mitochondria exhibit a dramatic reduction in genome size when compared with their bacterial relatives. Chloroplast genomes in photosynthetic organisms are normally 120\u2013200kb encoding 20\u2013200 proteins and mitochondrial genomes in humans are approximately 16kb and encode 37 genes, 13 of which are proteins. Using the example of the freshwater amoeboid, however, \"Paulinella chromatophora\", which contains chromatophores found to be evolved from cyanobacteria, Keeling and Archibald argue that this is not the only possible criterion; another is that the host cell has assumed control of the regulation of the former endosymbiont's division, thereby synchronizing it with the cell's own division. Nowack and her colleagues gene sequenced the chromatophore (1.02Mb) and found that only 867 proteins were encoded by these photosynthetic cells. Comparisons with their closest free living cyanobacteria of the genus \"Synechococcus\" (having a genome size 3Mb, with 3300 genes) revealed that chromatophores had undergone a drastic genome shrinkage. Chromatophores contained genes that were accountable for photosynthesis but were deficient in genes that could carry out other biosynthetic functions; this observation suggests that these endosymbiotic cells are highly dependent on their hosts for their survival and growth mechanisms. Thus, these chromatophores were found to be non-functional for organelle-specific purposes when compared with mitochondria and plastids. This distinction could have promoted the early evolution of photosynthetic organelles.\nThe loss of genetic autonomy, that is, the loss of many genes from endosymbionts, occurred very early in evolutionary time. Taking into account the entire original endosymbiont genome, there are three main possible fates for genes over evolutionary time. The first is the loss of functionally redundant genes, in which genes that are already represented in the nucleus are eventually lost. The second is the transfer of genes to the nucleus, while the third is that genes remain in the organelle that was once an organism. The loss of autonomy and integration of the endosymbiont with its host can be primarily attributed to nuclear gene transfer. As organelle genomes have been greatly reduced over evolutionary time, nuclear genes have expanded and become more complex. As a result, many plastid and mitochondrial processes are driven by nuclear encoded gene products. In addition, many nuclear genes originating from endosymbionts have acquired novel functions unrelated to their organelles.\nGene transfer mechanisms.\nThe mechanisms of gene transfer are not fully known; however, multiple hypotheses exist to explain this phenomenon. The possible mechanisms include the Complementary DNA (cDNA) hypothesis and the bulk flow hypothesis. \nThe cDNA hypothesis involves the use of messenger RNA (mRNAs) to transport genes from organelles to the nucleus where they are converted to cDNA and incorporated into the genome. The cDNA hypothesis is based on studies of the genomes of flowering plants. Protein coding RNAs in mitochondria are spliced and edited using organelle-specific splice and editing sites. Nuclear copies of some mitochondrial genes, however, do not contain organelle-specific splice sites, suggesting a processed mRNA intermediate. The cDNA hypothesis has since been revised as edited mitochondrial cDNAs are unlikely to recombine with the nuclear genome and are more likely to recombine with their native mitochondrial genome. If the edited mitochondrial sequence recombines with the mitochondrial genome, mitochondrial splice sites would no longer exist in the mitochondrial genome. Any subsequent nuclear gene transfer would therefore also lack mitochondrial splice sites.\nThe bulk flow hypothesis is the alternative to the cDNA hypothesis, stating that escaped DNA, rather than mRNA, is the mechanism of gene transfer. According to this hypothesis, disturbances to organelles, including autophagy (normal cell destruction), gametogenesis (the formation of gametes), and cell stress release DNA which is imported into the nucleus and incorporated into the nuclear DNA using non-homologous end joining (repair of double stranded breaks). For example, in the initial stages of endosymbiosis, due to a lack of major gene transfer, the host cell had little to no control over the endosymbiont. The endosymbiont underwent cell division independently of the host cell, resulting in many \"copies\" of the endosymbiont within the host cell. Some of the endosymbionts lysed (burst), and high levels of DNA were incorporated into the nucleus. A similar mechanism is thought to occur in tobacco plants, which show a high rate of gene transfer and whose cells contain multiple chloroplasts. In addition, the bulk flow hypothesis is also supported by the presence of non-random clusters of organelle genes, suggesting the simultaneous movement of multiple genes.\nFord Doolittle proposed that (whatever the mechanism) gene transfer behaves like a ratchet, resulting in unidirectional transfer of genes from the organelle to the nuclear genome. When genetic material from an organelle is incorporated into the nuclear genome, either the organelle or nuclear copy of the gene may be lost from the population. If the organelle copy is lost and this is fixed, or lost through genetic drift, a gene is successfully transferred to the nucleus. If the nuclear copy is lost, horizontal gene transfer can occur again, and the cell can 'try again' to have successful transfer of genes to the nucleus. In this ratchet-like way, genes from an organelle would be expected to accumulate in the nuclear genome over evolutionary time.\nEndosymbiosis of protomitochondria.\nEndosymbiotic theory for the origin of mitochondria suggests that the proto-eukaryote engulfed a protomitochondrion, and this endosymbiont became an organelle, a major step in eukaryogenesis, the creation of the eukaryotes.\nMitochondria.\nMitochondria are organelles that synthesize the energy-carrying molecule ATP for the cell by metabolizing carbon-based macromolecules. The presence of DNA in mitochondria and proteins, derived from mtDNA, suggest that this organelle may have been a prokaryote prior to its integration into the proto-eukaryote. Mitochondria are regarded as organelles rather than endosymbionts because mitochondria and the host cells share some parts of their genome, undergo division simultaneously, and provide each other with means to produce energy. The endomembrane system and nuclear membrane were hypothesized to have derived from the protomitochondria.\nNuclear membrane.\nThe presence of a nucleus is one major difference between eukaryotes and prokaryotes. Some conserved nuclear proteins between eukaryotes and prokaryotes suggest that these two types had a common ancestor. Another theory behind nucleation is that early nuclear membrane proteins caused the cell membrane to fold and form a sphere with pores like the nuclear envelope.\nAs a way of forming a nuclear membrane, endosymbiosis could be expected to use less energy than if the cell was to develop a metabolic process to fold the cell membrane for the purpose. Digesting engulfed cells without energy-producing mitochondria would have been challenging for the host cell. On this view, membrane-bound bubbles or vesicles leaving the protomitochondria may have formed the nuclear envelope.\nThe process of symbiogenesis by which the early eukaryotic cell integrated the proto-mitochondrion likely included protection of the archaeal host genome from the release of reactive oxygen species. These would have been formed during oxidative phosphorylation and ATP production by the proto-mitochondrion. The nuclear membrane may have evolved as an adaptive innovation for protecting against nuclear genome DNA damage caused by reactive oxygen species. Substantial transfer of genes from the ancestral proto-mitochondrial genome to the nuclear genome likely occurred during early eukaryotic evolution. The greater protection of the nuclear genome against reactive oxygen species afforded by the nuclear membrane may explain the adaptive benefit of this gene transfer.\nEndomembrane system.\nModern eukaryotic cells use the endomembrane system to transport products and wastes in, within, and out of cells. The membrane of nuclear envelope and endomembrane vesicles are composed of similar membrane proteins. These vesicles also share similar membrane proteins with the organelle they originated from or are traveling towards. This suggests that what formed the nuclear membrane also formed the endomembrane system. Prokaryotes do not have a complex internal membrane network like eukaryotes, but they could produce extracellular vesicles from their outer membrane. After the early prokaryote was consumed by a proto-eukaryote, the prokaryote would have continued to produce vesicles that accumulated within the cell. Interaction of internal components of vesicles may have led to the endoplasmic reticulum and the Golgi apparatus, both being parts of the endomembrane system.\nCytoplasm.\nThe syntrophy hypothesis, proposed by L\u00f3pez-Garc\u00eda and Moreira in 1998, suggested that eukaryotes arose by combining the metabolic capabilities of an archaean, a fermenting deltaproteobacterium, and a methanotrophic alphaproteobacterium which became the mitochondrion. In 2020, the same team updated their syntrophy proposal to cover an promethearchaeon that produced hydrogen with deltaproteobacterium that oxidised sulphur. A third organism, an alphaproteobacterium able to respire both aerobically and anaerobically, and to oxidise sulphur, developed into the mitochondrion; it may possibly also have been able to photosynthesise.\nDate.\nThe question of when the transition from prokaryotic to eukaryotic form occurred and when the first crown group eukaryotes appeared on earth is unresolved. The oldest known body fossils that can be positively assigned to the Eukaryota are acanthomorphic acritarchs from the 1.631 Gya Deonar Formation of India. These fossils can still be identified as derived post-nuclear eukaryotes with a sophisticated, morphology-generating cytoskeleton sustained by mitochondria. This fossil evidence indicates that endosymbiotic acquisition of alphaproteobacteria must have occurred before 1.6 Gya. Molecular clocks have also been used to estimate the last eukaryotic common ancestor, however these methods have large inherent uncertainty and give a wide range of dates. Reasonable results include the estimate of c. 1.8 Gya. A 2.3 Gya estimate also seems reasonable, and has the added attraction of coinciding with one of the most pronounced biogeochemical perturbations in Earth history, the early Palaeoproterozoic Great Oxygenation Event. The marked increase in atmospheric oxygen concentrations at that time has been suggested as a contributing cause of eukaryogenesis, inducing the evolution of oxygen-detoxifying mitochondria. Alternatively, the Great Oxidation Event might be a consequence of eukaryogenesis, and its impact on the export and burial of organic carbon.\nOrganellar genomes.\nPlastomes and mitogenomes.\nSome endosymbiont genes remain in the organelles. Plastids and mitochondria retain genes encoding rRNAs, tRNAs, proteins involved in redox reactions, and proteins required for transcription, translation, and replication. There are many hypotheses to explain why organelles retain a small portion of their genome; however no one hypothesis will apply to all organisms, and the topic is still quite controversial. The hydrophobicity hypothesis states that highly hydrophobic (water hating) proteins (such as the membrane bound proteins involved in redox reactions) are not easily transported through the cytosol and therefore these proteins must be encoded in their respective organelles. The code disparity hypothesis states that the limit on transfer is due to differing genetic codes and RNA editing between the organelle and the nucleus. The redox control hypothesis states that genes encoding redox reaction proteins are retained in order to effectively couple the need for repair and the synthesis of these proteins. For example, if one of the photosystems is lost from the plastid, the intermediate electron carriers may lose or gain too many electrons, signalling the need for repair of a photosystem. The time delay involved in signalling the nucleus and transporting a cytosolic protein to the organelle results in the production of damaging reactive oxygen species. The final hypothesis states that the assembly of membrane proteins, particularly those involved in redox reactions, requires coordinated synthesis and assembly of subunits; however, translation and protein transport coordination is more difficult to control in the cytoplasm.\nNon-photosynthetic plastid genomes.\nThe majority of the genes in the mitochondria and plastids are related to the expression (transcription, translation and replication) of genes encoding proteins involved in either photosynthesis (in plastids) or cellular respiration (in mitochondria). One might predict that the loss of photosynthesis or cellular respiration would allow for the complete loss of the plastid genome or the mitochondrial genome respectively. While there are numerous examples of mitochondrial descendants (mitosomes and hydrogenosomes) that have lost their entire organellar genome, non-photosynthetic plastids tend to retain a small genome. There are two main hypotheses to explain this occurrence:\nThe essential tRNA hypothesis notes that there have been no documented functional plastid-to-nucleus gene transfers of genes encoding RNA products (tRNAs and rRNAs). As a result, plastids must make their own functional RNAs or import nuclear counterparts. The genes encoding tRNA-Glu and tRNA-fmet, however, appear to be indispensable. The plastid is responsible for haem biosynthesis, which requires plastid encoded tRNA-Glu (from the gene trnE) as a precursor molecule. Like other genes encoding RNAs, trnE cannot be transferred to the nucleus. In addition, it is unlikely trnE could be replaced by a cytosolic tRNA-Glu as trnE is highly conserved; single base changes in trnE have resulted in the loss of haem synthesis. The gene for tRNA-formylmethionine (tRNA-fmet) is also encoded in the plastid genome and is required for translation initiation in both plastids and mitochondria. A plastid is required to continue expressing the gene for tRNA-fmet so long as the mitochondrion is translating proteins.\nThe limited window hypothesis offers a more general explanation for the retention of genes in non-photosynthetic plastids. According to this hypothesis, genes are transferred to the nucleus following the disturbance of organelles. Disturbance was common in the early stages of endosymbiosis, however, once the host cell gained control of organelle division, eukaryotes could evolve to have only one plastid per cell. Having only one plastid severely limits gene transfer as the lysis of the single plastid would likely result in cell death. Consistent with this hypothesis, organisms with multiple plastids show an 80-fold increase in plastid-to-nucleus gene transfer compared with organisms with single plastids.\nEvidence.\nThere are many lines of evidence that mitochondria and plastids including chloroplasts arose from bacteria.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nComparison of chloroplasts and cyanobacteria showing their similarities. Both chloroplasts and cyanobacteria have a double membrane, DNA, ribosomes, and chlorophyll-containing thylakoids. \nSecondary endosymbiosis.\nPrimary endosymbiosis involves the engulfment of a cell by another free living organism. Secondary endosymbiosis occurs when the product of primary endosymbiosis is itself engulfed and retained by another free living eukaryote. Secondary endosymbiosis has occurred several times and has given rise to extremely diverse groups of algae and other eukaryotes. Some organisms can take opportunistic advantage of a similar process, where they engulf an alga and use the products of its photosynthesis, but once the prey item dies (or is lost) the host returns to a free living state. Obligate secondary endosymbionts become dependent on their organelles and are unable to survive in their absence. A secondary endosymbiosis event involving an ancestral red alga and a heterotrophic eukaryote resulted in the evolution and diversification of several other photosynthetic lineages including Cryptophyta, Haptophyta, Stramenopiles (or Heterokontophyta), and Alveolata. \nA possible secondary endosymbiosis has been observed in process in the heterotrophic protist \"Hatena\". This organism behaves like a predator until it ingests a green alga, which loses its flagella and cytoskeleton but continues to live as a symbiont. \"Hatena\" meanwhile, now a host, switches to photosynthetic nutrition, gains the ability to move towards light, and loses its feeding apparatus.\nDespite the diversity of organisms containing plastids, the morphology, biochemistry, genomic organisation, and molecular phylogeny of plastid RNAs and proteins suggest a single origin of all extant plastids \u2013 although this theory was still being debated in 2008.\nNitroplasts.\nA unicellular marine alga, \"Braarudosphaera bigelowii\" (a coccolithophore, which is a eukaryote), has been found with a cyanobacterium as an endosymbiont. The cyanobacterium forms a nitrogen-fixing structure, dubbed the nitroplast. It divides evenly when the host cell undergoes mitosis, and many of its proteins derive from the host alga, implying that the endosymbiont has proceeded far along the path towards becoming an organelle. The cyanobacterium is named \"Candidatus\" Atelocyanobacterium thalassa, and is abbreviated UCYN-A. The alga is the first eukaryote known to have the ability to fix nitrogen.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "60429", "revid": "50883526", "url": "https://en.wikipedia.org/wiki?curid=60429", "title": "Archie (search engine)", "text": "FTP search engine\nArchie is a tool for indexing FTP archives, allowing users to more easily identify specific files. It is considered the first Internet search engine. The original implementation was written in 1990 by Alan Emtage, then a postgraduate student at McGill University in Montreal, Canada.\nArchie was superseded by other, more sophisticated search engines, including Jughead and Veronica, which were search engines for the Gopher protocol. These were in turn superseded by World Wide Web search engines like AltaVista and directories like Yahoo! in 1995. Work on Archie ceased in the late 1990s. A legacy Archie server was maintained for historic purposes in Poland at Interdisciplinary Centre for Mathematical and Computational Modelling in the University of Warsaw until 2023.\nWith assistance from the University of Warsaw, a new Archie server was created and opened for public access at The Serial Port, a web-based computer museum, on 11 May 2024.\nOrigin.\nArchie first appeared in 1986, while Emtage was the systems manager at the McGill University School of Computer Science. His predecessor had attempted to persuade the institution to connect to the Internet, but due to the expensive cost \u2014 roughly $35,000 per year for a sluggish link to Boston \u2014 it had been challenging to persuade the appropriate parties that the investment was worthwhile.\nThe name derives from the word \"archive\" without the 'v'. Emtage has said that contrary to popular belief, there was no association with the Archie Comics. Despite this, other early Internet search technologies such as Jughead and Veronica were named after characters from the comics. Anarchie, one of the earliest graphical FTP clients, was named for its ability to perform Archie searches.\nFunction.\nThe earliest versions of Archie would simply search a list of public anonymous File Transfer Protocol (FTP) sites using the Telnet protocol and create index files available via FTP. To view the contents of a file, it had first to be downloaded. The indexes are updated on a regular basis (contacting each roughly once a month, so as not to waste too many resources of the remote servers) by requesting a listing. These listings were stored in local files to be searched using the Unix &lt;templatestyles src=\"Kbd/styles.css\"&gt;&lt;/templatestyles&gt;grep command.\nThe developers populated the engine's servers with databases of anonymous FTP host directories. This was used to find specific file titles since the list was plugged in to a searchable database of FTP sites. Archie did not recognize natural language requests nor index the content inside the files. Therefore, users had to know the title of the file they wanted. The ability to index the content inside the files was later introduced by Gopher.\nDevelopment.\nEmtage and Heelan wrote a script allowing people to log in and search collected information using the Telnet protocol at the host \"archie.mcgill.ca\" [132.206.2.3]. Later, more efficient front- and back-ends were developed, and the system spread from a local tool to a network-wide resource and a popular service available from multiple sites around the Internet. The collected data would be exchanged between the neighbouring Archie servers. The servers could be accessed in multiple ways: using a local client (such as \"archie\" or \"xarchie\"); telnetting to a server directly; sending queries by electronic mail; and later via a World Wide Web interface. At the peak of its popularity, the Archie search engine accounted for 50% of Montreal Internet traffic.\nIn 1992, Emtage, along with J. Peter Deutsch and some financial help from McGill University, formed Bunyip Information Systems with a licensed commercial version of the Archie search engine used by millions of people worldwide. Heelan followed them into Bunyip soon after, where he together with Bibi Ali and Sandro Mazzucato significantly updated the Archie database and indexed web pages. Work on the search engine ceased in the late 1990s, and the company dissolved in 2003.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60430", "revid": "50978187", "url": "https://en.wikipedia.org/wiki?curid=60430", "title": "Archie Comics", "text": "American comic book publisher\nArchie Comic Publications, Inc. (often referred to simply as Archie Comics) is an American comic book publisher headquartered in the village of Pelham, New York. The company's many titles feature the fictional teenagers Archie Andrews, Jughead Jones, Betty Cooper, Veronica Lodge, Reggie Mantle, Sabrina Spellman, Josie and the Pussycats and Katy Keene. The company is also known for its long-running \"Sonic the Hedgehog\" comic series, which it published from 1992 until 2016.\nThe company began in 1939 as M.L.J. Magazines, Inc., which primarily published superhero comics. The initial Archie characters were created in 1941 by publisher John L. Goldwater and artist Bob Montana, in collaboration with writer Vic Bloom. They first appeared in \"Pep Comics\" #22 (cover-dated Dec. 1941). With the creation of Archie, publisher John Goldwater hoped to appeal to fans of the Andy Hardy films starring Mickey Rooney.\n\"Archie Comics\" was also the title of the company's longest-running publication, the first issue appearing with a cover date of Winter 1942. Starting with issue #70, the title was shortened to simply \"Archie.\" The flagship series was relaunched from issue #1 in July 2015 with a new look and design suited for a new generation of readers, although after #32 it reverted to its historic numbering with #699. Archie Comics characters and concepts have also appeared in numerous films, television programs, cartoons, and video games.\nHistory.\nIndependent era.\nM.L.J. Magazines.\n1939\u20131946: early years.\nMaurice Coyne, Louis Silberkleit, and John L. Goldwater formed M.L.J. Magazines, Inc., and started publishing in September 1939. The company name was derived from the initials of the partners' first names.\nCoyne served as M.L.J.'s bookkeeper and CFO. Coyne and Silberkleit had been partners in Columbia Publications, a pulp company that published its last issue in 1960. Silberkleit had a college degree from St. John's University, was a licensed and registered pharmacist, and had a law degree from New York Law School. His efforts were focused on the business, printing, separating, distribution and financial ends of the company. John Goldwater served as editor-in-chief. Goldwater was one of the founders of the Comics Magazine Association of America, and he served as its president for 25 years. (The Comics Magazine Association of America is best known to comic fans for its Comics Code Authority.) Goldwater was also a national commissioner of the Anti-Defamation League.\nM.L.J.'s first comic book, published in September 1939 (with a November cover date), was \"Blue Ribbon Comics\" with the first half full color and the last half in red and white tints. The first issue featured Rang-a-Tang the Wonder Dog. In November 1939 (with a January 1940 cover date), \"Pep Comics\" debuted with the Shield, the first US patriotic comic book hero, created by writer and managing editor Harry Shorten and designed by artist Irv Novick. \"Top Notch Comics\" was launched in December 1941. Until March 1944, the cover feature of \"Pep\" was the Shield when Archie took over the cover. The Shield was a forerunner for Joe Simon's and Jack Kirby's Captain America, being published 13 months earlier.\nArchie Comics.\n1946\u20131990s.\nThe Andy Hardy movies were an inspiration for Goldwater to have a comic book about a relatable normal person. Teenaged Archibald \"Archie\" Andrews debuted with Betty Cooper and Jughead Jones in \"Pep Comics\" #22 (Dec. 1941), in a story by writer Vic Bloom and artist Bob Montana. Archie soon became M.L.J. Magazines' headliner, which led to the company changing its name to Archie Comic Publications in 1946. Siberkleit and Coyne discontinued Columbia Publications. In the late 1950s, Archie Publishing launched its \"Archie Adventure Series\" line with a new version of the Shield and two new characters.\nThe February 1962 issue of Harvey Kurtzman's \"Help!\" magazine featured his parody of the Archie characters in its \"Goodman Beaver\" story, \"Goodman Goes Playboy\", which was illustrated by frequent collaborator Will Elder. \"Help!\" publisher Jim Warren received a letter on December 6, 1961, accusing \"Help!\" of copyright infringement and demanding removal of the offending issue from newsstands. Warren was unable to recall the magazine, but he agreed to settle out of court rather than risk an expensive lawsuit. Warren paid Archie Comics $1,000, and ran a note of apology in a subsequent issue of \"Help!\" The story was reprinted in the book collection \"Executive Comic Book\" in 1962, with the artwork modified by Elder to obscure the appearance of the Archie characters. Archie Comics found their appearance still too close to its copyrighted properties, and threatened another lawsuit. Kurtzman and Elder settled out of court by handing over the copyright to the story. Archie Comics held onto the copyright and refused to allow the story to be republished. A request from Denis Kitchen in 1983 to include the story in his \"Goodman Beaver\" reprint collection was turned down. After \"The Comics Journal\" co-owner Gary Groth discovered that Archie Comics had allowed the copyright on \"Goodman Goes Playboy\" to expire, he had the story reprinted in \"The Comics Journal\" #262 (September 2004), and made it available as a PDF on the magazine's website.\nIn the mid-1960s, during the period fans and historians call the Silver Age of Comic Books, Archie switched its superheroes to a new imprint, \"Mighty Comics Group,\" with the MLJ heroes done in the campy humor of the Batman TV show. This imprint ended in 1967.\nIn the early 1970s, Archie Enterprises Inc. went public. Just over 10 years later, Louis Silberkleit's son Michael and John Goldwater's son Richard returned Archie Comic Publications to private ownership. Michael Silberkleit served as chairman and co-publisher, while Richard Goldwater served as president and co-publisher. Coyne retired in the 1970s as CFO.\nIn the 1970s and 1980s, Spire Christian Comics, a line of comic books by Fleming H. Revell, obtained license to feature the Archie characters in several of its titles, including \"Archie's Sonshine,\" \"Archie's Roller Coaster,\" \"Archie's Family Album,\" and \"Archie's Parables.\" These comics used Archie and his friends to tell stories with strong Christian themes and morals, sometimes incorporating Bible scripture. In at least one instance, the regular characters meet a Christ-like figure on the beach, and listen as he gently preaches Christian values.\nArchie launched a short-lived fantasy and horror imprint, Red Circle Comics, in the 1970s. The company revived that imprint in the 1980s for its brief line of superhero comics. Later in the 1980s, Archie planned to publish superheroes again with the Spectrum Comics imprint, featuring a number of high-profile talents, but it cancelled this attempt before publishing a single issue.\nHaving licensed Archie's MLJ Superheroes in 1991, DC Comics launched its imprint Impact Comics with these heroes.\nIn 1992, Archie partnered with Sega to create a four-part \"Sonic the Hedgehog\" comic book miniseries based on the video game series of the same name. This was continued with a full series launch in 1993, which incorporated elements from the 1993 animated series by DiC Entertainment. The series ran for over 20 years, becoming the longest-running comic series based on a video game by 2008.\n2000s.\nOn April 4, 2003, Dad's Garage Theatre Company in Atlanta was scheduled to debut a new play by Roberto Aguirre-Sacasa, \"Archie's Weird Fantasy,\" which depicted Riverdale's most famous resident coming out of the closet and moving to New York. The day before the play was scheduled to open, Archie Comics issued a cease and desist order, threatening litigation if the play proceeded as written. Dad's Garage artistic director Sean Daniels said, \"The play was to depict Archie and his pals from Riverdale growing up, coming out and facing censorship. Archie Comics thought if Archie was portrayed as being gay, that would dilute and tarnish his image.\" It opened a few days later as \"Weird Comic Book Fantasy\" with the character names changed. In 2014, Aguirre-Sacasa would become Archie's Chief Creative Officer.\nBill Yoshida learned comic book lettering from Ben Oda and was hired in 1965 by Archie Comics, where he averaged 75 pages a week for 40 years for an approximate total of 156,000 pages.\nArchie Comics sued music duo The Veronicas for trademark infringement in 2005 over the band's name, which Archie Comics alleges was taken from the comic book character. Archie Comics and Sire Records (The Veronicas's record label) reached a settlement involving co-promotion.\nIn 2007, Archie Comics launched a \"new look\" series of stories, featuring Archie characters drawn in an updated, less cartoony style similar to the characters' first appearance. There are a total of seven storylines and each one was published as a four-part storyline in a digest series. Also each \"new look\" story was based on a Riverdale High novel, a series of twelve novels; seven that are published, five that are not. They were published in the 1990s.\nIn 2008, Archie Publications once again licensed DC Comics its MLJ Super heroes for a DC Universe integrated line, Red Circle.\n2010\u2013present.\nFollowing Richard Goldwater's death in 2007 and Michael Silberkleit's in 2008, Silberkleit's widow Nancy and Goldwater's half-brother Jonathan became co-CEOs in 2009. Nancy Silberkleit, a former elementary-school art teacher, was given responsibility for scholastic and theater projects, and Jon Goldwater, a former rock/pop music manager, was responsible for running the company's day-to-day publishing and entertainment efforts. The company sued Silberkleit in July 2011, and Goldwater filed another lawsuit against her in January 2012, alleging she was making bad business decisions and alienating staff; she in turn sued him for defamation. As of February 2012, New York Supreme Court Judge Shirley Kornreich, in Manhattan, had fined Silberkleit $500 for violating the court's autumn order temporarily barring her from the company's headquarters, and said the court might appoint a temporary receiver to protect the company's assets. As of May\u00a02016[ [update]], these legal proceedings had been resolved.\nBeginning in 2010, the company partnered with Random House Publisher Services for its bookstore distribution which included trade paperbacks, original graphic novels and additional book formats. Archie Comics saw its graphic novel and collected edition output increase from 11 book titles that year to 33 in 2012, and 40 in 2013. The company's sales also increased by 410% for books and 1,000% for e-books since 2010.\nBeginning in July 2010, the first issue of \"Life with Archie\" was launched. The series featured two different storylines exploring two possible futures \u2014 a world where Archie marries Betty and a world where he marries Veronica. The series also incorporated more contemporary themes including death, marriage woes, same-sex marriage, cancer, financial problems and gun control.\nKevin Keller, Archie Comics' first gay character, debuted in \"Veronica\" #202 in September 2010. The character was created out of a conversation between Goldwater and longtime Archie Comics writer-artist Dan Parent during the company's first creative summit, about bringing more diversity to Riverdale. The issue sold out at the distributor level, prompting Archie Comics for the first time to issue a second edition of a comic. In June 2011, Keller was featured in his own four-part miniseries. A bimonthly Kevin Keller series launched with writer-artist Parent in early 2012 received a GLAAD award for Outstanding Comic Book the following year.\nIn March 2011, a copy of \"Archie Comics\" #1, first published in 1942, was sold at auction for $167,300, a record for a non-superhero comic book.\nIn April 2011, Archie Comics became the first mainstream comic-book publisher to make its entire line available digitally on the same day as the print release. At the New York Comic Con in October 2011, Archie Comics announced that its superheroes would return as an all-digital line under the Red Circle imprint, a subscription model with back-issue archive access. The imprint started in 2012 with a new \"New Crusaders\" series.\nIn October 2013, Archie Comics launched its first horror title, \"Afterlife with Archie,\" depicting Archie and the gang dealing with a zombie apocalypse that begins in their hometown of Riverdale. Written by Roberto Aguirre-Sacasa and drawn by artist Francesco Francavilla, \"Afterlife with Archie\" was also the first Archie Comics title to be sold exclusively to comic shops and to carry a rating of \"Teen+\". The series adapted the Archie characters into a world with adult themes and horror tropes including zombies, the occult, demons, and Cthulhu.\nThe success of \"Afterlife with Archie\" led to a second horror series, \"Chilling Adventures of Sabrina,\" which launched in October 2014 from Aguirre-Sacasa and artist Robert Hack. \"Chilling Adventures of Sabrina\" takes place in the 1960s in the neighboring town of Greendale, and follows a 16-year-old Sabrina Spellman as she struggles to balance her responsibilities as a witch-in-training, with her feeling for her boyfriend, Harvey Kinkle.\nOn April 9, 2014, Archie Comics announced that the adult version of Archie Andrews featured in the \"Life with Archie\" series would die in issue #36 (July 2014), which would also be the second-to-last issue. Goldwater said Archie's final fate would be the same in both of the possible parallel futures covered by the series. This version of Archie was killed saving Senator Kevin Keller from an assassination attempt.\nIn July 2014, Archie Comics announced that its superhero imprint Red Circle Comics would be rebranded as Dark Circle Comics in 2015. The new imprint focuses on self-contained stories featuring the superheroes from the Red Circle library while exploring the crime, horror, and adventure genres. The first wave included the superheroes the Black Hood, the Fox, and the Shield. Dark Circle Comics debuted with \"The Black Hood\" #1 (Feb. 2015) by writer Duane Swierczynski and artist Michael Gaydos in February 2015. The mature-readers title introduced policer officer Gregory Hettinger, the new Black Hood, who struggles with an addiction to painkillers as a result of a shooting outside a school in Philadelphia. The launch continued with \"The Fox\" (April 2015), picking up where Red Circle's \"The Fox\" series had left. The series was co-written by Dean Haspiel and Mark Waid with art by Haspiel. \"The Shield\" #1 (Oct. 2015) from co-writers Chuck Wendig and Adam Christopher and artist Drew Johnson debuted a new, female Shield named Victoria Adams. \"The Hangman\" #1 (Nov. 2015) introduced a supernatural horror series from writer Frank Tieri and artist Felix Ruiz about mob hit-man Mike Minetta making a deal with the devil to become the new Hangman after the previous person to wear the mantle ascended to Heaven.\nArchie Comics launched a $350,000 Kickstarter in May 2015 campaign to help the publisher get three additional series out to the public sooner than otherwise: \"Life with Kevin\", focusing on Kevin Keller, and new \"Jughead\" and \"Betty and Veronica\" series. Five days later, Archie Comics cancelled the campaign after critical response. The company stated that the three titles would still be published at a later time.\nIn March 2015, Archie Comics announced that its two delayed horror series would return under a new imprint, Archie Horror, with \"Chilling Adventures of Sabrina\" #2 and \"Afterlife with Archie\" #8 being released in April and May.\nIn December 2014, Archie Comics announced that its flagship series \"Archie\" would relaunch with a new first issue in July 2015. The new series would be a modern take on the Archie characters by writer Mark Waid and artist Fiona Staples, featuring serialized storylines. After the first three issues, Annie Wu drew an issue, followed by new regular artist Veronica Fish. The new title received IGN's \"Best New Comic Series of 2015\" award.\nThe first title in the company's \"New Riverdale\" universe, \"Archie\" was released with a July 2015 cover date and came in at #7 for comic book sales for the month. The next title, \"Jughead\", was released in October. In April 2015, Archie Comics announced \"Betty and Veronica\" which debuted in July 2016. Also announced was \"Life with Kevin\", a digital-first mini-series that debuted in June 2016. \"Josie and the Pussycats\" and \"Reggie and Me\" followed in September and December 2016.\nRoberto Aguirre-Sacasa, playwright, screenwriter and comic book writer, was appointed Archie Comics chief creative officer in March 2014. Archie characters landed a live-action TV series, \"Riverdale\", at Fox with a script deal plus penalty in October 2014. Warner Bros Television and Berlanti Productions were producing. However, the show was not selected for broadcast until January 29, 2016, when it was picked up by the CW.\nIn February 2017, Marvel had licensed Archie Comics to publish Marvel Digests collections for the newsstand market starting in November 2017. With three TV series at various stages, Archie Comics expanded its film and television operations in February 2019 to a division, Archie Comics Studios, with the hire of two executives, Siobhan Bachman, senior vice-president of film and television, and Matthew Lottman, head of development &amp; production.\nAs of August 2025, Phil Lord and Christopher Miller, the filmmaking duo behind \u201cSpider-Verse,\u201d \u201cThe Lego Movie\u201d and \u201c21 Jump Street,\u201d are bringing Archie Comics to the big screen with their production company Lord Miller, through their first-look deal with Universal Pictures.\nCorporate affairs.\nThe company's headquarters is in a property in the Sanborn Map Building in Pelham, New York. It was in a facility of Mamaroneck, New York, with warehouse facilities and of office space until May 2015, when it moved to its current location. Due to changes in the comics industry with digitization, the company needed more office space and less warehouse space.\nAccording to the publisher, the http:// receives 40\u00a0million hits a month.\nCharacters.\nArchie and Riverdale.\n\"Archie\" is set in the fictional small town of Riverdale.\nThe \"New York Times\" postulated that \"the cartoonist Bob Montana inked the original likenesses of Archie and his pals and plopped them in an idyllic Midwestern community named Riverdale because Mr. Goldwater, a New Yorker, had fond memories of time spent in Hiawatha, Kansas.\" However, others have noted resemblance between Riverdale and Haverhill, Massachusetts, where Bob Montana attended Haverhill High School.\nSuperheroes.\nInitially, MLJ started out publishing humor and adventure strips in anthology comic books as was the standard, but quickly added superheroes in their first title's second issue, \"Blue Ribbon Comics\" #2, with Bob Phantom. In January 1940, \"Pep Comics\" debuted featuring the Shield, America's first patriotic comic book hero, by writer and managing editor Harry Shorten and artist Irv Novick. MLJ's Golden Age heroes also included the Black Hood, who also appeared in pulp magazines and a radio show; and the Wizard, who shared a title with the Shield.\nLater revivals of the MLJ superheroes occurred under a number of imprints: Archie Adventure Series, Mighty Comics, Red Circle Comics and one aborted attempt, Spectrum Comics. Archies Publications then licensed them out to DC Comics in the 1990s for Impact Comics universe imprint then again in 2008 for a DC Universe integrated Red Circle line.\nArchie's Silver Age relaunch of its superheroes under the Archie Adventure Series imprint and then the Mighty Comics imprint began with a new version of the Shield and two new characters: the Jaguar and the Fly. In the mid-1960s with the Silver Age of Comics, Archie switched the heroes to a new imprint, \"Mighty Comics Group\", with the revival of all the MLJ heroes done as Marvel parodies with \"the campy humor of the Batman TV show.\" This imprint shift soon brought the company its first super hero team book similar to Marvel's Avengers with the Mighty Crusaders. This imprint ended in 1967.\nWith the conversion of Archie's Red Circle Comics from horror to superheroes in the 1980s, the Mighty Crusaders, Black Hood, the Comet, the Fly and two versions of the Shield had their own titles.\nArchie planned to publish superheroes again in the late 1980s with an imprint called Spectrum Comics, featuring a number of high-profile talents, including Steve Englehart, Jim Valentino, Marv Wolfman, Michael Bair, Kelley Jones, and Rob Liefeld. Planned Spectrum titles included \"The Fly\", \"The Fox\", \"Hangman\", \"Jaguar\", \"Mister Justice\", and \"The Shield\". Ultimately, Archie cancelled Spectrum Comics before publishing a single issue.\nIn 2012, Archie Comics relaunched its superhero imprint, Red Circle Comics, as an all-digital line under a subscription model with back issues archive access starting with New Crusader.\nIn 2015, Archie Comics rebranded its superhero imprint under the new title Dark Circle Comics. It was launched in February with The Black Hood followed by the launch of \"The Fox\" in April, while \"The Shield\" and \"The Hangman\" followed in September and November.\nHonors and awards.\nThe United States Postal Service included Archie in a set of five 44-cent commemorative postage stamps on the theme \"Sunday Funnies\", issued July 16, 2010. The Archie stamp featured Veronica, Archie, and Betty sharing a chocolate milkshake. The other stamps depicted characters from the comic strips \"Beetle Bailey\", \"Calvin and Hobbes\", \"Garfield\", and \"Dennis the Menace\".\nArchie characters in other media.\nTelevision.\nAnimation.\nIn 1968, CBS began airing episodes of \"The Archie Show\", a cartoon series produced by Filmation. Although it lasted only for a single season, it aired in reruns for the next decade, and was followed by several spin-off programs, which used segments from this original Archie show and new material. In 1970, Sabrina, the Teenage Witch got her own animated series, also produced by Filmation. In 1970, another Archie property received the Saturday morning cartoon treatment: \"Josie and the Pussycats\". Unlike Archie and Sabrina, Josie's show was produced by Hanna-Barbera Productions, the company behind such animated hits as \"Yogi Bear\", \"The Flintstones\", \"The Jetsons\", and \"Scooby-Doo, Where Are You?\". The show was followed by a spin-off, \"Josie and the Pussycats in Outer Space,\" in 1972. \"The Archie Show\", \"Sabrina the Teenage Witch\", \"Josie and the Pussycats\", and several of the spin-off shows including \"Josie and the Pussycats in Outer Space\" are currently available on DVD in complete-series boxed sets.\nIn 1974, Filmation produced \"The U.S. of Archie\", in which the gang recreated several events from American history, which lasted 16 episodes.\nIn 1987, DIC Entertainment produced an NBC Saturday morning cartoon, \"The New Archies\". This children's television cartoon re-imagined the teenage students of Riverdale High School as pre-teens in junior high. Fourteen episodes of the show were produced, which aired during the show's only season in 1987 and were repeated in 1989. A short-lived Archie Comics series was produced bearing the same title and set in the same universe as the animated series. Reruns of the series ran on The Family Channel's Saturday morning lineup from 1991 to 1993, and on Toon Disney from 1998 to 2002. The cast was basically the same, but Dilton Doiley was replaced as the \"intellectual\" character by an African American named Eugene. Eugene's girlfriend Amani was another addition to the cast. Archie also gained a dog named Red.\nIn 1999, another animated program featuring Archie and his friends was produced by DIC Entertainment. \"Archie's Weird Mysteries\" featured core Archie characters solving mysteries occurring in their hometown of Riverdale. The show ran on the PAX network for only a single 40-episode season, and continues to air sporadically in reruns on various other networks. The complete series was released on DVD in 2012. As a companion to the Archie series, DIC also produced ', \"Sabrina's Secret Life\" and '; the cartoons featured Sabrina and her aunts at a younger age than they were in the comic books. Tie-in comic book titles were produced for all of these series.\nIn 2012, it was announced that MoonScoop would produce a new Sabrina the Teenage Witch series titled \"\". It ran for a single 26-episode season on Hub Network from October 2013 until June 2014.\nIn 2013, MoonScoop announced that it would produce a new Archie animated series titled \"It's Archie\", featuring Archie and friends in junior high. The first season was set to feature 52 11-minute episodes, however the series never aired.\nIn 2021, a television series, titled \"Superhero Kindergarten\", was produced by Genius Brands. The series is based on the comic series of the same name written by Stan Lee.\nLive action.\n1976 special and \"Archie: To Riverdale and Back Again\".\nIn the mid-1970s, two live-action specials of Archie and the Archie characters were aired on U.S. television. \"Archie,\" which aired on December 19, 1976, was a one-hour pilot episode as part of the ABC Saturday Comedy Special, and \"The Archie Situation Comedy Musical Variety Show,\" a TV movie, which aired on August 5, 1978. Both specials featured the same actors cast in their respective roles. In 1990, NBC aired \"\" (titled \"Archie: Return to Riverdale\" on video), a TV movie featuring Christopher Rich as a 30-something Archie Andrews who returns to his hometown for a high school reunion, and reunites with Betty, Veronica, and several other original comic book characters.\n\"Sabrina the Teenage Witch\".\nIn 1996, cable network Showtime aired \"Sabrina the Teenage Witch\", a live-action TV movie starring Melissa Joan Hart as Sabrina. The film served as the pilot for a TV series, also starring Hart, which began airing in the fall of 1996 on ABC. The sitcom was relatively faithful to the comic book series (despite major revisions to the character's backstory that were later retconned into the comic books), and enjoyed a lengthy run until 2003. It is now available in its entirety on DVD, as is the original TV movie.\n\"Riverdale\".\nBy October 2014, Greg Berlanti was developing a drama series for Fox titled \"Riverdale\" with Berlanti and Sarah Schechter as executive producers through Berlanti Productions, and Roberto Aguirre-Sacasa writing the series. It would feature Archie, Betty, Veronica, Jughead, Cheryl, Toni, Sweetpea, Fangs, Reggie, Kevin, Josie &amp; the Pussycats, and all of the parents. In July 2015, the pilot was moved to The CW. In addition to the series offering a bold, subversive take on the gang, Aguirre-Sacasa has described \"Riverdale\" as \"Archie meets \"Twin Peaks\"\". The pilot was ordered by the network in January 2016 with filming set to begin in the spring. Archie is portrayed by actor KJ Apa.\n\"Chilling Adventures of Sabrina\".\nIn September 2017, it was reported that a live-action television series was being developed for The CW by Warner Bros. Television and Berlanti Productions, with a planned release in the 2018\u20132019 television season. Based on the comic series, featuring the Archie Comics character Sabrina the Teenage Witch, the series would be a companion series to \"Riverdale\". Lee Toland Krieger will direct the pilot, which will be written by Roberto Aguirre-Sacasa. Both are executive producers along with Greg Berlanti, Sarah Schechter, and Jon Goldwater. In December 2017, the project had moved to Netflix under a yet-to-be-announced new title. Two seasons, comprising ten episodes each, have been ordered by the streaming service. Filming for first season will begin on March 19, 2018. It is expected to film back-to-back with the second season.\nIn January 2018, it was announced that Kiernan Shipka has signed on to play the lead role of Sabrina Spellman, and CW president Mark Pedowitz noted that, \"at the moment, there is no discussion about crossing over\" with \"Riverdale\". Throughout February and mid-March 2018, the remaining starring cast members were cast, including Jaz Sinclair as Rosalind Walker, Michelle Gomez as Mary Wardell / Madam Satan, Chance Perdomo as Ambrose Spellman, Lucy Davis as Hilda Spellman, Miranda Otto as Zelda Spellman, Richard Coyle as Father Blackwood, Ross Lynch as Harvey Kinkle, and Tati Gabrielle as Prudence. Salem Saberhagen does not appear.\n\"Katy Keene\".\nIn August 2018, Aguirre-Sacasa revealed that another \"Riverdale\" spin-off was in development at The CW. He said that the series would be \"very different from \"Riverdale\"\" and that it would be produced \"in [the 2018\u201319] development cycle.\" By January 2019, The CW issued a pilot order for the series stating that the plot will: \"[follow] the lives and loves of four iconic Archie Comics characters \u2014 including fashion legend-to-be Katy Keene \u2014 as they chase their twenty-something dreams in New York City. This musical dramedy chronicles the origins and struggles of four aspiring artists trying to make it on Broadway, on the runway and in the recording studio.\" In February of the same year, it was announced that Ashleigh Murray, who portrays Josie McCoy in \"Riverdale\", had been cast in a lead role for \"Katy Keene\", leading to her exit from the former. By August 2019, Michael Grassi announced that there is a crossover between \"Riverdale\" and \"Katy Keene\" being developed. The crossover episode aired on February 5, 2020.\n\"Afterlife With Archie\".\nOn August 20, 2025, Jeff Snider reports that a new live action series based on Afterlife With Archie is in development by Disney+.\nFilm.\nIn 1994, a planned live-action \"Archie\" movie to be released by Universal Studios in 1995 was announced. In 1996, it was said that the script was being finalized and the film was scheduled for release in 1997. In 1997 it was still reported that Universal was developing the film's script.\nIn 2001, Universal Studios and Metro-Goldwyn-Mayer released \"Josie and the Pussycats\", based on the comic of the same name.\nIn 2003, Miramax announced that they were working on a Betty and Veronica movie, but the project was cancelled.\nIn 2013, it was announced that Warner Bros. would produce a live-action \"Archie\" film, directed by Jason Moore and written by Roberto Aguirre-Sacasa.\nAn Indian feature film adaptation of \"The Archies\", directed by Zoya Akhtar, was in production for Netflix, with release planned for late 2023.\nOn August 20, 2025, it was announced that Universal was developing a live-action Archie movie with Phil Lord and Christopher Miller producing and Tom King penning the screenplay.\nBroadway.\nIn 2015, Archie Comics announced that they would be bringing Archie, Betty, Veronica, Jughead and the rest of the Riverdale gang to Broadway with an all-new musical. Adam McKay is set to write the book for the show while Funny or Die will serve as a presenting partner. CEO Jon Goldwater and CCO Roberto Aguirre-Sacasa will oversee production. Triptyk Studios packaged the partnership and Tara Smith, B. Swibel and Adam Westbrook will oversee development of the musical for the company. At this time no creative team for the musical has been announced.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "60433", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=60433", "title": "Nuclear bunker buster", "text": "Earth-penetrating nuclear weapon\nA nuclear bunker buster, also known as an earth-penetrating weapon (EPW), is the nuclear equivalent of the conventional bunker buster. The non-nuclear component of the weapon is designed to penetrate soil, rock, or concrete to deliver a nuclear warhead to an underground target. These weapons would be used to destroy hardened, underground military bunkers or other below-ground facilities. An underground explosion releases a larger fraction of its energy into the ground, compared to a surface burst or air burst explosion at or above the surface, and so can destroy an underground target using a lower explosive yield. This in turn could lead to a reduced amount of radioactive fallout. However, it is unlikely that the explosion would be completely contained underground. As a result, significant amounts of rock and soil would be rendered radioactive and lofted as dust or vapor into the atmosphere, generating significant fallout.\nBase principle.\nWhile conventional bunker busters use several methods to penetrate concrete structures, these are for the purpose of destroying the structure directly, and are generally limited in how much of a bunker (or system of bunkers) they can destroy by depth and their relatively low explosive force (compared to nuclear weapons).\nThe primary difference between conventional and nuclear bunker busters is that, while the conventional version is meant for one target, the nuclear version can destroy an entire underground bunker system.\nThe main principles in modern bunker design are largely centered around survivability in nuclear war. As a result of this both American and Soviet sites reached a state of \"super hardening\", involving defenses against the effects of a nuclear weapon such as spring- or counterweight-mounted (in the case of the R-36) control capsules and thick concrete walls ( for the Minuteman ICBM launch control capsule) heavily reinforced with rebar. These systems were designed to survive a near miss of 20 megatons.\nLiquid-fueled missiles such as those historically used by Russia are more fragile and easily damaged than solid-fueled missiles such as those used by the United States. The complex fuel storage facilities and equipment needed to fuel missiles for launch and de-fuel them for frequent maintenance add additional weaknesses and vulnerabilities. Therefore, a similar degree of silo \"hardening\" does not automatically equate to a similar level of missile \"survivability\".\nMajor advancements in the accuracy and precision of nuclear and conventional weapons subsequent to the invention of the missile silo itself have also rendered many \"hardening\" technologies useless. With modern weapons capable of striking within several feet of their intended targets, a modern \"near miss\" can be much more effective than a \"hit\" decades ago. A weapon need only cover the silo door with sufficient debris to prevent its immediate opening to render the missile inside useless for its intended mission of rapid strike or counter-strike deployment.\nA nuclear bunker buster negates most of the countermeasures involved in the protection of underground bunkers by penetrating the defenses prior to detonating. A relatively low yield may be able to produce seismic forces beyond those of an air burst or even ground burst of a weapon with twice its yield. Additionally, the weapon has the ability to impart more severe horizontal shock waves than many bunker systems are designed to combat by detonating at or near the bunker's depth, rather than above it.\nGeologic factors also play a major role in weapon effectiveness and facility survivability. Locating facilities in hard rock may appear to reduce the effectiveness of bunker-buster type weapons by decreasing penetration, but the hard rock also transmits shock forces to a far higher degree than softer soil types. The difficulties of drilling into and constructing facilities within hard rock also increase construction time and expense, as well as making it more likely construction will be discovered and new sites targeted by foreign militaries.\nMethods of operation.\nPenetration by explosive force.\nConcrete structure design has not changed significantly in the last 70 years. The majority of protected concrete structures in the US military are derived from standards set forth in \"Fundamentals of Protective Design\", published in 1946 (US Army Corps of Engineers). Various augmentations, such as glass, fibers, and rebar, have made concrete less vulnerable, but far from impenetrable.\nWhen explosive force is applied to concrete, three major fracture regions are usually formed: the initial crater, a crushed aggregate surrounding the crater, and \"scabbing\" on the surface opposite the crater. Scabbing, also known as spalling, is the violent separation of a mass of material from the opposite face of a plate or slab subjected to an impact or impulsive loading, without necessarily requiring that the barrier itself be penetrated.\nWhile soil is a less dense material, it also does not transmit shock waves as well as concrete. So while a penetrator may actually travel further through soil, its effect may be lessened due to its inability to transmit shock to the target.\nHardened penetrator.\nFurther thinking on the subject envisions a hardened penetrator using kinetic energy to defeat the target's defenses and subsequently deliver a nuclear explosive to the buried target.\nThe primary difficulty facing the designers of such a penetrator is the tremendous heat applied to the penetrator when striking the shielding at high speed. This has partially been solved by using metals such as tungsten (the metal with the highest melting point), and altering the shape of the projectile (such as an ogive).\nAltering the shape of the projectile to incorporate an ogive shape has yielded substantial improvement in penetration ability. Rocket sled testing at Eglin Air Force Base has demonstrated penetrations of in concrete when traveling at . The reason for this is liquefaction of the concrete in the target, which tends to flow over the projectile. Variation in the speed of the penetrator can either cause it to be vaporized on impact (in the case of traveling too fast), or to not penetrate far enough (in the case of traveling too slowly). An approximation for the penetration depth is obtained with an impact depth formula derived by Sir Isaac Newton.\nCombination penetrator-explosive munitions.\nAnother school of thought on nuclear bunker busters is using a light penetrator to travel through shielding, and detonate a nuclear charge there. Such an explosion would generate powerful shock waves, which would be transmitted very effectively through the solid material comprising the shielding (see \"scabbing\" above).\nPolicy and criticism of fallout.\nThe main criticisms of nuclear bunker busters regard fallout and nuclear proliferation. The purpose of an earth-penetrating nuclear bunker buster is to reduce the required yield needed to ensure the destruction of the target by coupling the explosion to the ground, yielding a shock wave similar to an earthquake. For example, the United States retired the B-53 warhead, with a yield of nine megatons, because the B-61 Mod 11 could attack similar targets with much lower yield (400 kilotons), due to the latter's superior ground penetration. By burying itself into the ground before detonation, a much higher proportion of the explosion energy is transferred to seismic shock when compared to the surface burst produced from the B-53's laydown delivery. Moreover, the globally dispersed fallout of an underground B-61 Mod 11 would likely be less than that of a surface burst B-53. Supporters note that this is one of the reasons nuclear bunker busters should be developed. Critics claim that developing new nuclear weapons sends a proliferating message to non-nuclear powers, undermining non-proliferation efforts.\nCritics also worry that the existence of lower-yield nuclear weapons for relatively limited tactical purposes will lower the threshold for their actual use, thus blurring the sharp line between conventional weapons intended for use and weapons of mass destruction intended only for hypothetical deterrence, and increasing the risk of escalation to higher-yield nuclear weapons.\nLocal fallout from any nuclear detonation is increased with proximity to the ground. While a megaton-class yield surface burst will inevitably throw up many tons of (newly) radioactive debris, which falls back to the earth as fallout, critics contend that despite their relatively minuscule explosive yield, nuclear bunker busters create more local fallout per kiloton yield. Also, because of the subsurface detonation, radioactive debris may contaminate the local groundwater.\nThe Union of Concerned Scientists advocacy group points out that at the Nevada Test Site, the depth required to contain fallout from an average-yield underground nuclear test was over , depending upon the weapon's yield. They contend that it is improbable that penetrators could be made to burrow so deeply. With yields between 0.3 and 340 kilotons, they argue, it is unlikely the blast would be completely contained.\nCritics further state that the testing of new nuclear weapons would be prohibited by the proposed Comprehensive Test Ban Treaty. Although Congress refused to ratify the CTBT in 1999, and therefore this treaty has no legal force in the US, the US has adhered to the spirit of the treaty by maintaining a moratorium on nuclear testing since 1992.\nProponents, however, contend that lower explosive yield devices and subsurface bursts would produce little to no climatic effects in the event of a nuclear war, in contrast to multi-megaton air and surface bursts (that is, if the nuclear winter hypothesis proves accurate). Lower fuzing heights, which would result from partially buried warheads, would limit or completely obstruct the range of the burning thermal rays of a nuclear detonation, therefore limiting the target, and its surroundings, to a fire hazard by reducing the range of thermal radiation with fuzing for subsurface bursts.235 Professors Altfeld and Cimbala have suggested that belief in the possibility of nuclear winter has actually made nuclear war more likely, contrary to the views of Carl Sagan and others, because it has inspired the development of more accurate, and lower explosive yield, nuclear weapons.242\nTargets and the development of bunker busters.\nAs early as 1944, the Barnes Wallis Tallboy bomb and subsequent Grand Slam weapons were designed to penetrate deeply fortified structures through sheer explosive power. These were not designed to directly penetrate defences, though they could do this (for example, the Valentin submarine pens had ferrous concrete roofs thick which were penetrated by two Grand Slams on 27 March 1945), but rather to penetrate under the target and explode leaving a camouflet (cavern) which would undermine foundations of structures above, causing it to collapse, thus negating any possible hardening. The destruction of targets such as the V3 battery at Mimoyecques was the first operational use of the Tallboy. One bored through a hillside and exploded in the Saumur rail tunnel about below, completely blocking it, and showing that these weapons could destroy any hardened or deeply excavated installation. Modern targeting techniques allied with multiple strikes could perform a similar task.\nDevelopment continued, with weapons such as the nuclear B61, and conventional thermobaric weapons and GBU-28. One of the more effective housings, the GBU-28 used its large mass () and casing (constructed from barrels of surplus 203\u00a0mm howitzers) to penetrate of concrete, and more than of earth. The B61 Mod 11, which first entered military service after the Cold war had ended, in January 1997, was specifically developed to allow for bunker penetration, and is speculated to have the ability to destroy hardened targets a few hundred feet beneath the earth.\nWhile penetrations of were sufficient for some shallow targets, both the Soviet Union and the United States were creating bunkers buried under huge volumes of soil or reinforced concrete in order to withstand the multi-megaton thermonuclear weapons developed in the 1950s and 1960s. Bunker penetration weapons were initially designed within this Cold War context. One likely Soviet Union/Russian target, Mount Yamantau, was regarded in the 1990s by Maryland Republican congressman, Roscoe Bartlett, as capable of surviving \"half a dozen\" repeated nuclear strikes of an unspecified yield, one after the other in a \"direct hole\".\nThe Russian continuity of government facility at Kosvinsky Mountain, finished in early 1996, was designed to resist US earth-penetrating warheads and serves a similar role as the American Cheyenne Mountain Complex. The timing of the Kosvinsky completion date is regarded as one explanation for US interest in a new nuclear bunker buster and the declaration of the deployment of the B-61 Mod 11 in 1997. Kosvinsky is protected by about of granite.\nThe weapon was revisited after the Cold War during the 2001 US invasion of Afghanistan, and again during the 2003 invasion of Iraq. During the campaign in Tora Bora in particular, the United States believed that \"vast underground complexes,\" deeply buried, were protecting opposing forces. Such complexes were not found. While a nuclear penetrator (the \"Robust Nuclear Earth Penetrator\", or \"RNEP\") was never built, the US DOE was allotted budget to develop it, and tests were conducted by the US Air Force Research Laboratory. The RNEP was to use the 1.2\u00a0megaton B83 physics package.\nThe Bush administration removed its request for funding of the weapon in October 2005. Additionally, then US Senator Pete Domenici announced funding for the nuclear bunker-buster has been dropped from the US Department of Energy's 2006 budget at the department's request.\nWhile the project for the RNEP seems to be in fact canceled, Jane's Information Group speculated in 2005 that work might continue under another name.\nA more recent development (c. 2012) is the GBU-57 Massive Ordnance Penetrator, a conventional gravity bomb. The USAF's B-2 Spirit bombers can each carry two such weapons.\nNotable US nuclear bunker busters.\nNote that with the exception of strictly earth penetrating weapons, others were designed with air burst capability and some were depth charges as well.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60436", "revid": "49523", "url": "https://en.wikipedia.org/wiki?curid=60436", "title": "AARP probe packets", "text": ""}
{"id": "60437", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=60437", "title": "Pashtu language", "text": ""}
{"id": "60438", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=60438", "title": "Pakhto language", "text": ""}
{"id": "60439", "revid": "49523", "url": "https://en.wikipedia.org/wiki?curid=60439", "title": "AARP probe packet", "text": ""}
{"id": "60440", "revid": "49523", "url": "https://en.wikipedia.org/wiki?curid=60440", "title": "AppleTalk Address Resolution Protocol probe packet", "text": ""}
{"id": "60441", "revid": "49523", "url": "https://en.wikipedia.org/wiki?curid=60441", "title": "Apple Address Resolution Protocol probe packet", "text": ""}
{"id": "60442", "revid": "49523", "url": "https://en.wikipedia.org/wiki?curid=60442", "title": "Apple Address Resolution Protocol probe packets", "text": ""}
{"id": "60443", "revid": "49523", "url": "https://en.wikipedia.org/wiki?curid=60443", "title": "AppleTalk Address Resolution Protocol probe packets", "text": ""}
{"id": "60444", "revid": "2214", "url": "https://en.wikipedia.org/wiki?curid=60444", "title": "AAUI", "text": ""}
{"id": "60445", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=60445", "title": "Apple Attachment Unit Interface", "text": "Apple version of the standard Ethernet connection\nApple Attachment Unit Interface (AAUI) is a mechanical re-design by Apple of the standard Attachment Unit Interface (AUI) used to connect computer equipment to Ethernet. The AUI was popular in the era before the dominance of 10BASE-T networking that started in the early 1990s; the AAUI was an attempt to make the connector much smaller and more user friendly, though the proprietary nature of the interface was also criticized.\nFriendlyNet.\nAAUI is part of a system of Ethernet peripherals intended to make connecting over Ethernet easier. At the time of the introduction of AAUI, Ethernet systems usually were 10BASE2, also known as thinnet. Apple's system is called FriendlyNet. A FriendlyNet 10BASE2 system does not use BNC T-connectors or separate terminators. Instead of a single BNC connector that is inserted into a T-connector placed inline, the FriendlyNet transceiver has two BNC connectors, one on each side, to which the cables are attached. The transceiver automatically terminates the network if a cable is missing from either side. Additionally, Apple 10BASE2 cables terminate the network when no device is attached to them. Thus the number of mistakes that could be made hooking up a thinnet network is reduced considerably. Since any of these mistakes can disable the network segment, this presents a significant improvement.\nFriendlyNet equipment was expensive. Because of this, Apple's computers, billed as having built-in Ethernet, were expensive to connect to Ethernet, perhaps adding as much as a tenth to the total price of the computer system. Additionally, AAUI held no advantage for any system other than 10BASE2, and thus as 10BASE-T became ubiquitous it became impossible to justify the cost of an external transceiver. Apple eventually abandoned the system and sold off the name.\nMacintosh Quadra, Centris, PowerBook 500, Duo Dock II (for PowerBook Duo) and early Power Macintoshes have AAUI ports, which require external transceivers. By the time AAUI was nearing the end of its life, the cost of an AAUI transceiver became a burden for consumers. Later models include both AAUI and modular connector ports for directly connecting 10BASE-T; either can be used, but not both at the same time. AAUI connectors are also present on some Processor Direct Slot Ethernet adapter cards used in Macintosh LC and Performa machines. AAUI had disappeared by the late 1990s, when new Apple machines, starting with the beige Power Macintosh G3 series, include only the modular connector ports.\nThird-party vendors.\nMany third parties also created AAUI transceivers. Most made simplifications to the connectors and cables, presumably to reduce costs. Most third parties, as well as any non-Apple equipment, would use standard 10BASE2 cabling, including T-connectors and manual termination. Additionally, Apple's 10BASE2 cables were not appropriate for all uses since they only came in fixed lengths and the ends were not detachable, making it difficult to wire them through walls. Unfortunately, when mixing and matching Apple and non-Apple 10BASE2 devices, there were many seemingly natural configurations of cables and connectors which would cause the network to become unreliable or unusable in the area, reducing the value of the complex and proprietary Apple 10BASE2 wiring system.\nConnector and signals.\nAUI uses a DA-15 connector and a sliding clip to mechanically secure the connection. AAUI replaces these with a small 14-position, 0.05-inch-spaced ribbon contact connector. This connector may have been chosen to avoid confusion with the monitor port on early Macintoshes, which also uses a DA-15. The connector locks into position using two clips or hooks on the sides of the connector outside of the shell which automatically clicks on when plugged in, and can be removed by pulling back on a sliding sheath over the body of the connector, disengaging the hooks. Third-party AAUI devices often omit this sheath, requiring the user to directly squeeze small tabs on the sides of the plug housing to detach the hooks.\nAAUI signals have the same description, function, and electrical requirements as the Attachment Unit Interface (AUI) signals of the same name, as detailed in IEEE 802.3-1990 CSMA/CD Standard, section 7, with the exception that most hosts provide only 5 volts of power rather than the 12 volts required for most AUI transceivers. An adapter containing a power supply to provide the required 12 volts was available from Apple to permit connection of standard AUI transceivers to an AAUI port. This facilitated direct connection to 10BASE-F (fibre optic) and 10BASE5 (ThickNet) Ethernet networks, for which AAUI transceivers were not available.\nSee also.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "60446", "revid": "46866511", "url": "https://en.wikipedia.org/wiki?curid=60446", "title": "Abbreviated Test Language for All Systems", "text": "Computer programming language\nAbbreviated Test Language for All Systems (ATLAS) is a specialized programming language for use with automatic test equipment (ATE). It is a compiled high-level computer language and can be used on any computer whose supporting software can translate it into the appropriate low-level instructions.\nHistory.\nATLAS Test Language.\nThe original language was developed by Aeronautical Radio, Incorporated (ARINC) and standardized under ANSI/IEEE-Std-416 and released on 22 December 1983. Its purpose was to serve as a standard programming language for testing and maintenance of electronic systems for military and commercial aerospace applications. The language was designed to be platform-independent.\nThe ATLAS language is oriented toward the Unit Under Test (UUT) and is independent of the test equipment used. This allows interchangeability of test procedures developed by different organizations, and thus reduces costly duplication of test programming effort.\nThe first ATLAS specification developed by the international committee was published in 1968. The basic document has been revised several times.\nAn ATLAS implementation typically consists of an online compiler (OLC), test executive (TEX or Test Exec), and file manager and media exchange (FMX) packages. ATLAS is run in TEX mode on test stations while testing electronic equipment.\nSyntax and Structure.\nThe structure of an ATLAS program is very similar to FORTRAN. Standard ATLAS program structure consists of two elements: preamble structure and procedural structure. The language makes extensive use of variables and statement syntax. An ATLAS statement consists of these fields:\n F STATNO VERB,variable field$\nSample ATLAS Statements:\n 000250 DECLARE,DECIMAL,'A1'(4)$\n 000300 FILL, 'A1', 'NUM',\n (1) 1, 5,\n (2) 20, 87,\n (3) 15, 12,\n (4) $30, 18\nComments may be included with a 'C' in the FLAG field.\nThese ATLAS statements apply a voltage to a pin (stimulus) and verify the presence and characteristics of a voltage at a pin:\n 010200 APPLY, AC SIGNAL, VOLTAGE-PP 7.5V, FREQ 3\u00a0kHz, CNX HI=P1-$1 \n 010300 VERIFY, (VOLTAGE-AV INTO 'VAVG'), AC SIGNAL, VOLTAGE-PP RANGE 64V TO 1V, SAMPLE-WIDTH 10MSEC, \n SYNC-VOLTAGE 2 MAX 5, SYNC-NEG-SLOPE, MAX-TIME 0.5, GO-TO-STEP 400 IF GO, LL 0.5 UL 50, \n CNX HI=P2-4 LO=P2-5, SYNC HI=P2-8 LO=P2-$5 \nApplications.\nATLAS has been used in the U.S. Air Force primarily on test stations for testing the avionic components of the EF-111A Raven, F-15 Eagle, F-16 Fighting Falcon, C-5 Galaxy, C-17 Globemaster III, and B-1 Lancer. The U.S. Navy uses ATLAS-based programs for testing avionics systems of the P-3C Orion, UH-1Y Venom, AH-1Z Viper, SH-60 Seahawk, E-2C Hawkeye, F-14 Tomcat, F/A-18 Hornet, S-3 Viking, A-6 Intruder, EA-6B Prowler, AV8B Harrier, and V-22 Osprey. The U.S. Navy and Marine Corps used a version called Super Atlas for its AN/USM-484 hybrid test set (HTS) test benches. The AN/USM-247 VAST (Versatile Avionics Shop Test) was used by the Navy onboard aircraft carrier and shore stations. It has been used in testing the F-14, S-3, E-2, A-7 Corsair II, A-6, etc. VAST is considered by many to be the grandfather of modern avionics test equipment.\nIn the years that followed the cold war, ATLAS found uses on many dual-use aircraft for the U.S. and NATO, as well as commercial business, regional, and general aviation aircraft. ATLAS test program sets (TPS) allow porting older programs to new hardware, providing some protection against hardware obsolescence. Although a standard, many adaptations, customizations, and flavors exist that impede full portability. Because most ATLAS toolsets are custom, on custom hardware, with a custom software load for the platform, it is not as prone to some types of issues that plague other languages that are more prevalent in the industry; the down side is that training is not available to the general public, so it also requires an extensive investment in personnel.\nATLAS generally can be configured to run \"stand-alone\", or \"stand-alone\u00a0\u2013 monitored only\" which can help limit many of the tampering and other concerns with mainstream commercial software. Other languages, such as BASIC, C/C++, Python, and Perl, are also used on commercial and military programs for testing of systems; ATLAS typically requires another computer system to either optically scan test results, or read a tape, disk, or locked memory stick/data key from a test station and then perform statistical analysis on test results for a variety of uses.\nSubsets.\nSubsets include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60447", "revid": "1306352", "url": "https://en.wikipedia.org/wiki?curid=60447", "title": "ATLAS", "text": ""}
{"id": "60448", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=60448", "title": "Alanis Morrissette", "text": ""}
{"id": "60449", "revid": "279219", "url": "https://en.wikipedia.org/wiki?curid=60449", "title": "ABC (programming)", "text": ""}
{"id": "60451", "revid": "668752", "url": "https://en.wikipedia.org/wiki?curid=60451", "title": "ABCL/1", "text": ""}
{"id": "60452", "revid": "5517884", "url": "https://en.wikipedia.org/wiki?curid=60452", "title": "Object-Based Concurrent Language", "text": ""}
{"id": "60453", "revid": "668752", "url": "https://en.wikipedia.org/wiki?curid=60453", "title": "ABCL/c+", "text": ""}
{"id": "60454", "revid": "5517884", "url": "https://en.wikipedia.org/wiki?curid=60454", "title": "ABCL/c", "text": ""}
{"id": "60455", "revid": "41219559", "url": "https://en.wikipedia.org/wiki?curid=60455", "title": "Line-of-sight propagation", "text": "Characteristic of electromagnetic radiation\nLine-of-sight propagation is a characteristic of electromagnetic radiation or acoustic wave propagation which means waves can only travel in a direct visual path from the source to the receiver without obstacles. Electromagnetic transmission includes light emissions traveling in a straight line. The rays or waves may be diffracted, refracted, reflected, or absorbed by the atmosphere and obstructions with material and generally cannot travel over the horizon or behind obstacles.\nIn contrast to line-of-sight propagation, at low frequency (below approximately 3\u00a0MHz) due to diffraction, radio waves can travel as ground waves, which follow the contour of the Earth. This enables AM radio stations to transmit beyond the horizon. Additionally, frequencies in the shortwave bands between approximately 1 and 30\u00a0MHz, can be refracted back to Earth by the ionosphere, called skywave or \"skip\" propagation, thus giving radio transmissions in this range a potentially global reach.\nHowever, at frequencies above 30\u00a0MHz (VHF and higher) and in lower levels of the atmosphere, neither of these effects are significant. Thus, any obstruction between the transmitting antenna (transmitter) and the receiving antenna (receiver) will block the signal, just like the light that the eye may sense. Therefore, since the ability to visually see a transmitting antenna (disregarding the limitations of the eye's resolution) roughly corresponds to the ability to receive a radio signal from it, the propagation characteristic at these frequencies is called \"line-of-sight\". The farthest possible point of propagation is referred to as the \"radio horizon\".\nIn practice, the propagation characteristics of these radio waves vary substantially depending on the exact frequency and the strength of the transmitted signal (a function of both the transmitter and the antenna characteristics). Broadcast FM radio, at comparatively low frequencies of around 100\u00a0MHz, are less affected by the presence of buildings and forests.\nImpairments to line-of-sight propagation.\nLow-powered microwave transmitters can be foiled by tree branches, or even heavy rain or snow. The presence of objects not in the direct line-of-sight can cause diffraction effects that disrupt radio transmissions. For the best propagation, a volume known as the first Fresnel zone should be free of obstructions.\nReflected radiation from the surface of the surrounding ground or salt water can also either cancel out or enhance the direct signal. This effect can be reduced by raising either or both antennas further from the ground: The reduction in loss achieved is known as \"height gain\".\nSee also Non-line-of-sight propagation for more on impairments in propagation.\nIt is important to take into account the curvature of the Earth for calculation of line-of-sight paths from maps, when a direct visual fix cannot be made. Designs for microwave formerly used &lt;templatestyles src=\"Fraction/styles.css\" /&gt;4\u20443\u00a0Earth radius to compute clearances along the path.\nMobile telephones.\nAlthough the frequencies used by mobile phones (cell phones) are in the line-of-sight range, they still function in cities. This is made possible by a combination of the following effects:\nThe combination of all these effects makes the mobile phone propagation environment highly complex, with multipath effects and extensive Rayleigh fading. For mobile phone services, these problems are tackled using:\nA Faraday cage is composed of a conductor that completely surrounds an area on all sides, top, and bottom. Electromagnetic radiation is blocked where the wavelength is longer than any gaps. For example, mobile telephone signals are blocked in windowless metal enclosures that approximate a Faraday cage, such as elevator cabins, and parts of trains, cars, and ships. The same problem can affect signals in buildings with extensive steel reinforcement.\nRadio horizon.\nThe \"radio horizon\" is the locus of points at which direct rays from an antenna are tangential to the surface of the Earth. If the Earth were a perfect sphere without an atmosphere, the radio horizon would be a circle.\nThe radio horizon of the transmitting and receiving antennas can be added together to increase the effective communication range. \nRadio wave propagation is affected by atmospheric conditions, ionospheric absorption, and the presence of obstructions, for example mountains or trees. \nSimple formulas that include the effect of the atmosphere give the range as:\nformula_1\nformula_2\nThe simple formulas give a best-case approximation of the maximum propagation distance, but are not sufficient to estimate the quality of service at any location.\nEarth bulge.\nIn telecommunications, Earth bulge refers to the effect of earth's curvature on radio propagation. It is a consequence of a circular segment of earth profile that blocks off long-distance communications. Since the vacuum line of sight passes at varying heights over the Earth, the propagating radio wave encounters slightly different propagation conditions over the path.\nVacuum distance to horizon.\nAssuming a perfect sphere with no terrain irregularity, the distance to the horizon from a high altitude transmitter (i.e., line of sight) can readily be calculated.\nLet \"R\" be the radius of the Earth and \"h\" be the altitude of a telecommunication station. The line of sight distance \"d\" of this station is given by the Pythagorean theorem;\n formula_3\nThe altitude of the station \"h\" is much smaller than the radius of the Earth \"R.\" Therefore, formula_4 can be neglected compared with formula_5. \nThus:\n formula_6\nIf the height \"h\" is given in metres, and distance \"d\" in kilometres,\n formula_7\nIf the height \"h\" is given in feet, and the distance \"d\" in statute miles,\n formula_8\nIn the case, when there are two stations involve, e.g. a transmit station on ground with a station height \"h\" and a receive station in the air with a station height \"H\", the line of sight distance can be calculated as follows:\n formula_9\nAtmospheric refraction.\nThe usual effect of the declining pressure of the atmosphere with height (vertical pressure variation) is to bend (refract) radio waves down towards the surface of the Earth. This results in an effective Earth radius, increased by a factor around &lt;templatestyles src=\"Fraction/styles.css\" /&gt;4\u20443. This \"k\"-factor can change from its average value depending on weather.\nRefracted distance to horizon.\nThe previous vacuum distance analysis does not consider the effect of atmosphere on the propagation path of RF signals. In fact, RF signals do not propagate in straight lines: Because of the refractive effects of atmospheric layers, the propagation paths are somewhat curved. Thus, the maximum service range of the station is not equal to the line of sight vacuum distance. Usually, a factor \"k\" is used in the equation above, modified to be\n formula_10\n\"k\"\u00a0&gt;\u00a01 means geometrically reduced bulge and a longer service range. On the other hand, \"k\"\u00a0&lt;\u00a01 means a shorter service range.\nUnder normal weather conditions, \"k\" is usually chosen to be &lt;templatestyles src=\"Fraction/styles.css\" /&gt;4\u20443. That means that the maximum service range increases by\u00a015%.\n formula_11\nfor \"h\" in metres and \"d\" in kilometres; or\n formula_12\nfor \"h\" in feet and \"d\" in miles.\nBut in stormy weather, \"k\" may decrease to cause fading in transmission. (In extreme cases \"k\" can be less than\u00a01.) That is equivalent to a hypothetical decrease in Earth radius and an increase of Earth bulge.\nFor example, in normal weather conditions, the service range of a station at an altitude of 1500 m with respect to receivers at sea level can be found as,\n formula_13\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60456", "revid": "668752", "url": "https://en.wikipedia.org/wiki?curid=60456", "title": "ABCL/R", "text": ""}
{"id": "60457", "revid": "668752", "url": "https://en.wikipedia.org/wiki?curid=60457", "title": "ABCL/R2", "text": ""}
{"id": "60458", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=60458", "title": "Franz Kafka/Metamorphosis", "text": ""}
{"id": "60459", "revid": "33582079", "url": "https://en.wikipedia.org/wiki?curid=60459", "title": "Abductive reasoning", "text": "Inference seeking the simplest and most likely explanation\n \nAbductive reasoning (also called abduction, abductive inference, or retroduction) is a form of logical inference that seeks the simplest and most likely conclusion from a set of observations. It was formulated and advanced by the American philosopher and logician Charles Sanders Peirce beginning in the latter half of the 19th century.\nAbductive reasoning, unlike deductive reasoning, yields a plausible conclusion but does not definitively verify it. Abductive conclusions do not eliminate uncertainty or doubt, which is expressed in terms such as \"best available\" or \"most likely\". While inductive reasoning draws general conclusions that apply to many situations, abductive conclusions are confined to the particular observations in question.\nIn the 1990s, as computing power grew, the fields of law, computer science, and artificial intelligence research spurred renewed interest in the subject of abduction.\nDiagnostic expert systems frequently employ abduction.\nDeduction, induction, and abduction.\nDeduction.\nDeductive reasoning allows deriving formula_1 from formula_2 only where formula_1 is a formal logical consequence of formula_2. In other words, deduction derives the consequences of the assumed. Given the truth of the assumptions, a valid deduction guarantees the truth of the conclusion. For example, given that \"all men are mortal\" (formula_5) and \"Socrates is a man\" (formula_6), it follows that \"Socrates is mortal\" (formula_1).\nInduction.\nInductive reasoning is the process of inferring some \"general\" principle formula_1 from a body of knowledge formula_2, where formula_1 does not necessarily follow from formula_2. formula_2 might give us very good reason to accept formula_1 but does not ensure formula_1. For example, if it is given that 95% percent of the elephants are gray, and Louise is an elephant, one can \"induce\" that Louise is gray. Still, this is not necessarily the case: 5 percent of the time this conclusion will be wrong.\nHowever, an inference being derived from statistical data is not sufficient to classify it as inductive. For example, if all swans that a person has observed so far are white, they may instead \"abduce\" the possibility that all swans are white. They have good reason to believe the conclusion from the premise because it is the \"best explanation\" for their observations, and the truth of the conclusion is still not guaranteed. (Indeed, it turns out that some swans are black.)\nAbduction.\nAbductive reasoning allows inferring formula_2 as an explanation of formula_1. As a result of this inference, abduction allows the precondition formula_2 to be abducted from the consequence formula_1. Deductive reasoning and abductive reasoning differ in which end, left or right, of the proposition \"formula_2 entails formula_1\" serves as the conclusion. For example, a couple leaving their house in the morning and seeing that their lawn is wet might abduce that it rained while they were asleep. This serves as a hypothesis that \"best explains\" their observation. Given the many possible explanations for the lawn getting wet, their abduction does not establish certainty that it rained overnight, but it is still useful and can serve to orient them in their surroundings. Despite many possible explanations for any physical process we observe, we tend to abduce a single explanation (or a few) for this process, in the expectation that we can better orient ourselves in our surroundings and disregard some possibilities. Properly used, abductive reasoning can be a useful source of priors in Bayesian statistics.\nOne can understand abductive reasoning as inference to the best explanation, although the terms \"abduction\" and \"inference to the best explanation\" are not always used equivalently.\nFormalizations of abduction.\nLogic-based abduction.\nIn logic, explanation is accomplished through the use of a logical theory formula_21 representing a domain and a set of observations formula_22. Abduction is the process of deriving a set of explanations of formula_22 according to formula_21 and picking out one of those explanations. For formula_25 to be an explanation of formula_22 according to formula_21, it should satisfy two conditions:\nIn formal logic, formula_22 and formula_25 are assumed to be sets of literals. The two conditions for formula_25 being an explanation of formula_22 according to theory formula_21 are formalized as:\nformula_38\nformula_39 is consistent.\nAmong the possible explanations formula_25 satisfying these two conditions, some other condition of minimality is usually imposed to avoid irrelevant facts (not contributing to the entailment of formula_22) being included in the explanations. Abduction is then the process that picks out some member of formula_25. Criteria for picking out a member representing \"the best\" explanation include the simplicity, the prior probability, or the explanatory power of the explanation.\nA proof-theoretical abduction method for first-order classical logic based on the sequent calculus and a dual one, based on semantic tableaux (analytic tableaux) have been proposed. The methods are sound and complete and work for full first-order logic, without requiring any preliminary reduction of formulae into normal forms. These methods have also been extended to modal logic.\nAbductive logic programming is a computational framework that extends normal logic programming with abduction. It separates the theory formula_21 into two components, one of which is a normal logic program, used to generate formula_25 by means of backward reasoning, the other of which is a set of integrity constraints, used to filter the set of candidate explanations.\nSet-cover abduction.\nA different formalization of abduction is based on inverting the function that calculates the visible effects of the hypotheses. Formally, we are given a set of hypotheses formula_45 and a set of manifestations formula_46; they are related by the domain knowledge, represented by a function formula_47 that takes as an argument a set of hypotheses and gives as a result the corresponding set of manifestations. In other words, for every subset of the hypotheses formula_48, their effects are known to be formula_49.\nAbduction is performed by finding a set formula_48 such that formula_51. In other words, abduction is performed by finding a set of hypotheses formula_52 such that their effects formula_49 include all observations formula_46.\nA common assumption is that the effects of the hypotheses are independent, that is, for every formula_48, it holds that formula_56. If this condition is met, abduction can be seen as a form of set covering.\nAbductive validation.\nAbductive validation is the process of validating a given hypothesis through abductive reasoning. This can also be called reasoning through successive approximation. Under this principle, an explanation is valid if it is the best possible explanation of a set of known data. The best possible explanation is often defined in terms of simplicity and elegance (see Occam's razor). Abductive validation is common practice in hypothesis formation in science; moreover, Peirce claims that it is a ubiquitous aspect of thought:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Looking out my window this lovely spring morning, I see an azalea in full bloom. No, no! I don't see that; though that is the only way I can describe what I see. That is a proposition, a sentence, a fact; but what I perceive is not proposition, sentence, fact, but only an image, which I make intelligible in part by means of a statement of fact. This statement is abstract; but what I see is concrete. I perform an abduction when I so much as express in a sentence anything I see. The truth is that the whole fabric of our knowledge is one matted felt of pure hypothesis confirmed and refined by induction. Not the smallest advance can be made in knowledge beyond the stage of vacant staring, without making an abduction at every step.\nIt was Peirce's own maxim that \"Facts cannot be explained by a hypothesis more extraordinary than these facts themselves; and of various hypotheses the least extraordinary must be adopted.\" After obtaining possible hypotheses that may explain the facts, abductive validation is a method for identifying the most likely hypothesis that should be adopted.\nSubjective logic abduction.\nSubjective logic generalises probabilistic logic by including degrees of epistemic uncertainty in the input arguments, i.e. instead of probabilities, the analyst can express arguments as subjective opinions. Abduction in subjective logic is thus a generalization of probabilistic abduction described above. The input arguments in subjective logic are subjective opinions which can be binomial when the opinion applies to a binary variable or multinomial when it applies to an \"n\"-ary variable. A subjective opinion thus applies to a state variable formula_57 which takes its values from a domain formula_58 (i.e. a state space of exhaustive and mutually disjoint state values formula_59), and is denoted by the tuple formula_60, where formula_61 is the belief mass distribution over formula_58, formula_63 is the epistemic uncertainty mass, and formula_64 is the base rate distribution over formula_58. These parameters satisfy formula_66 and formula_67 as well as formula_68.\nAssume the domains formula_58 and formula_70 with respective variables formula_57 and formula_72, the set of conditional opinions formula_73 (i.e. one conditional opinion for each value formula_74), and the base rate distribution formula_75. Based on these parameters, the subjective Bayes' theorem denoted with the operator formula_76 produces the set of inverted conditionals formula_77 (i.e. one inverted conditional for each value formula_59) expressed by:\nformula_79. The equality between the different expressions for subjective abduction is given below:\nformula_80\", and the operator itself is denoted as \"formula_81\". The operator for the subjective Bayes' theorem is denoted \"formula_82\", and subjective deduction is denoted \"formula_83\".\nThe advantage of using subjective logic abduction compared to probabilistic abduction is that both aleatoric and epistemic uncertainty about the input argument probabilities can be explicitly expressed and taken into account during the analysis. It is thus possible to perform abductive analysis in the presence of uncertain arguments, which naturally results in degrees of uncertainty in the output conclusions.\nHistory.\nThe idea that the simplest, most easily verifiable solution should be preferred over its more complicated counterparts is a very old one. To this point, George P\u00f3lya, in his treatise on problem-solving, makes reference to the following Latin truism: \"simplex sigillum veri\" (simplicity is the seal of truth).\nIntroduction and development by Peirce.\nOverview.\nThe American philosopher Charles Sanders Peirce introduced abduction into modern logic. Over the years he called such inference \"hypothesis\", \"abduction\", \"presumption\", and \"retroduction\". He considered it a topic in logic as a normative field in philosophy, not in purely formal or mathematical logic, and eventually as a topic also in economics of research.\nAs two stages of the development, extension, etc., of a hypothesis in scientific inquiry, abduction and also induction are often collapsed into one overarching concept\u2014the hypothesis. That is why, in the scientific method known from Galileo and Bacon, the abductive stage of hypothesis formation is conceptualized simply as induction. Thus, in the twentieth century this collapse was reinforced by Karl Popper's explication of the hypothetico-deductive model, where the hypothesis is considered to be just \"a guess\" (in the spirit of Peirce). However, when the formation of a hypothesis is considered the result of a process it becomes clear that this \"guess\" has already been tried and made more robust in thought as a necessary stage of its acquiring the status of hypothesis. Indeed, many abductions are rejected or heavily modified by subsequent abductions before they ever reach this stage.\nBefore 1900, Peirce treated abduction as the use of a known rule to explain an observation. For instance: it is a known rule that, if it rains, grass gets wet; so, to explain the fact that the grass on this lawn is wet, one \"abduces\" that it has rained. Abduction can lead to false conclusions if other rules that might explain the observation are not taken into account\u2014e.g. the grass could be wet from dew. This remains the common use of the term \"abduction\" in the social sciences and in artificial intelligence.\nPeirce consistently characterized it as the kind of inference that originates a hypothesis by concluding in an explanation, though an unassured one, for some very curious or surprising (anomalous) observation stated in a premise. As early as 1865 he wrote that all conceptions of cause and force are reached through hypothetical inference; in the 1900s he wrote that all explanatory content of theories is reached through abduction. In other respects Peirce revised his view of abduction over the years.\nIn later years his view came to be:\nWriting in 1910, Peirce admits that \"in almost everything I printed before the beginning of this century I more or less mixed up hypothesis and induction\" and he traces the confusion of these two types of reasoning to logicians' too \"narrow and formalistic a conception of inference, as necessarily having formulated judgments from its premises.\"\nHe started out in the 1860s treating hypothetical inference in a number of ways which he eventually peeled away as inessential or, in some cases, mistaken:\n\"The Natural Classification of Arguments\" (1867).\nIn 1867, Peirce's \"On the Natural Classification of Arguments\", hypothetical inference always deals with a cluster of characters (call them \"P\u2032, P\u2032\u2032, P\u2032\u2032\u2032,\" etc.) known to occur at least whenever a certain character (\"M\") occurs. Note that categorical syllogisms have elements traditionally called middles, predicates, and subjects. For example: All \"men\" [middle] are \"mortal\" [predicate]; \"Socrates\" [subject] is a \"man\" [middle]; ergo \"Socrates\" [subject] is \"mortal\" [predicate]\". Below, 'M' stands for a middle; 'P' for a predicate; 'S' for a subject. Peirce held that all deduction can be put into the form of the categorical syllogism Barbara (AAA-1).\n\"Deduction, Induction, and Hypothesis\" (1878).\nIn 1878, in \"Deduction, Induction, and Hypothesis\", there is no longer a need for multiple characters or predicates in order for an inference to be hypothetical, although it is still helpful. Moreover, Peirce no longer poses hypothetical inference as concluding in a \"probable\" hypothesis. In the forms themselves, it is understood but not explicit that induction involves random selection and that hypothetical inference involves response to a \"very curious circumstance\". The forms instead emphasize the modes of inference as rearrangements of one another's propositions (without the bracketed hints shown below).\n\"A Theory of Probable Inference\" (1883).\nPeirce long treated abduction in terms of induction from characters or traits (weighed, not counted like objects), explicitly so in his influential 1883 \"A theory of probable inference\", in which he returns to involving probability in the hypothetical conclusion. Like \"Deduction, Induction, and Hypothesis\" in 1878, it was widely read (see the historical books on statistics by Stephen Stigler), unlike his later amendments of his conception of abduction. Today abduction remains most commonly understood as induction from characters and extension of a known rule to cover unexplained circumstances.\nSherlock Holmes used this method of reasoning in the stories of Arthur Conan Doyle, although Holmes refers to it as \"deductive reasoning\".\n\"Minute Logic\" (1902) and after.\nIn 1902 Peirce wrote that he now regarded the syllogistical forms and the doctrine of extension and comprehension (i.e., objects and characters as referenced by terms), as being less fundamental than he had earlier thought. In 1903 he offered the following form for abduction: \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The surprising fact, C, is observed; \nBut if A were true, C would be a matter of course,\nHence, there is reason to suspect that A is true.\nThe hypothesis is framed, but not asserted, in a premise, then asserted as rationally suspectable in the conclusion. Thus, as in the earlier categorical syllogistic form, the conclusion is formulated from some premise(s). But all the same the hypothesis consists more clearly than ever in a new or outside idea beyond what is known or observed. Induction in a sense goes beyond observations already reported in the premises, but it merely amplifies ideas already known to represent occurrences, or tests an idea supplied by hypothesis; either way it requires previous abductions in order to get such ideas in the first place. Induction seeks facts to test a hypothesis; abduction seeks a hypothesis to account for facts.\nNote that the hypothesis (\"A\") could be of a rule. It need not even be a rule strictly necessitating the surprising observation (\"C\"), which needs to follow only as a \"matter of course\"; or the \"course\" itself could amount to some known rule, merely alluded to, and also not necessarily a rule of strict necessity. In the same year, Peirce wrote that reaching a hypothesis may involve placing a surprising observation under either a newly hypothesized rule or a hypothesized combination of a known rule with a peculiar state of facts, so that the phenomenon would be not surprising but instead either necessarily implied or at least likely.\nPeirce did not remain quite convinced about any such form as the categorical syllogistic form or the 1903 form. In 1911, he wrote, \"I do not, at present, feel quite convinced that any logical form can be assigned that will cover all 'Retroductions'. For what I mean by a Retroduction is simply a conjecture which arises in the mind.\"\nPragmatism.\nIn 1901 Peirce wrote, \"There would be no logic in imposing rules, and saying that they ought to be followed, until it is made out that the purpose of hypothesis requires them.\" In 1903 Peirce called pragmatism \"the logic of abduction\" and said that the pragmatic maxim gives the necessary and sufficient logical rule to abduction in general. The pragmatic maxim is:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Consider what effects, that might conceivably have practical bearings, we conceive the object of our conception to have. Then, our conception of these effects is the whole of our conception of the object.\nIt is a method for fruitful clarification of conceptions by equating the meaning of a conception with the conceivable practical implications of its object's conceived effects. Peirce held that that is precisely tailored to abduction's purpose in inquiry, the forming of an idea that could conceivably shape informed conduct. In various writings in the 1900s he said that the conduct of abduction (or retroduction) is governed by considerations of economy, belonging in particular to the economics of research. He regarded economics as a normative science whose analytic portion might be part of logical methodeutic (that is, theory of inquiry).\nThree levels of logic about abduction.\nPeirce came over the years to divide (philosophical) logic into three departments: \nPeirce had, from the start, seen the modes of inference as being coordinated together in scientific inquiry and, by the 1900s, held that hypothetical inference in particular is inadequately treated at the level of critique of arguments. To increase the assurance of a hypothetical conclusion, one needs to deduce implications about evidence to be found, predictions which induction can test through observation so as to evaluate the hypothesis. That is Peirce's outline of the scientific method of inquiry, as covered in his inquiry methodology, which includes pragmatism or, as he later called it, pragmaticism, the clarification of ideas in terms of their conceivable implications regarding informed practice.\nClassification of signs.\nAs early as 1866, Peirce held that:\n1. Hypothesis (abductive inference) is inference through an \"icon\" (also called a \"likeness\"). \n2. Induction is inference through an \"index\" (a sign by factual connection); a sample is an index of the totality from which it is drawn. \n3. Deduction is inference through a \"symbol\" (a sign by interpretive habit irrespective of resemblance or connection to its object).\nIn 1902, Peirce wrote that, in abduction: \"It is recognized that the phenomena are \"like\", i.e. constitute an Icon of, a replica of a general conception, or Symbol.\"\nCritique of arguments.\nAt the critical level Peirce examined the forms of abductive arguments (as discussed above), and came to hold that the hypothesis should economize explanation for plausibility in terms of the feasible and natural. In 1908 Peirce described this plausibility in some detail. It involves not likeliness based on observations (which is instead the inductive evaluation of a hypothesis), but instead optimal simplicity in the sense of the \"facile and natural\", as by Galileo's natural light of reason and as distinct from \"logical simplicity\" (Peirce does not dismiss logical simplicity entirely but sees it in a subordinate role; taken to its logical extreme it would favor adding no explanation to the observation at all). Even a well-prepared mind guesses oftener wrong than right, but our guesses succeed better than random luck at reaching the truth or at least advancing the inquiry, and that indicates to Peirce that they are based in instinctive attunement to nature, an affinity between the mind's processes and the processes of the real, which would account for why appealingly \"natural\" guesses are the ones that oftenest (or least seldom) succeed; to which Peirce added the argument that such guesses are to be preferred since, without \"a natural bent like nature's\", people would have no hope of understanding nature. In 1910 Peirce made a three-way distinction between probability, verisimilitude, and plausibility, and defined plausibility with a normative \"ought\": \"By plausibility, I mean the degree to which a theory ought to recommend itself to our belief independently of any kind of evidence other than our instinct urging us to regard it favorably.\" For Peirce, plausibility does not depend on observed frequencies or probabilities, or on verisimilitude, or even on testability, which is not a question of the critique of the hypothetical inference \"as\" an inference, but rather a question of the hypothesis's relation to the inquiry process.\nThe phrase \"inference to the best explanation\" (not used by Peirce but often applied to hypothetical inference) is not always understood as referring to the most simple and natural hypotheses (such as those with the fewest assumptions). However, in other senses of \"best\", such as \"standing up best to tests\", it is hard to know which is the best explanation to form, since one has not tested it yet. Still, for Peirce, any justification of an abductive inference as \"good\" is not completed upon its formation as an argument (unlike with induction and deduction) and instead depends also on its methodological role and promise (such as its testability) in advancing inquiry.\nMethodology of inquiry.\nAt the methodeutical level Peirce held that a hypothesis is judged and selected for testing because it offers, via its trial, to expedite and economize the inquiry process itself toward new truths, first of all by being testable and also by further economies, in terms of cost, value, and relationships among guesses (hypotheses). Here, considerations such as probability, absent from the treatment of abduction at the critical level, come into play. For examples:\nUberty.\nPeirce indicated that abductive reasoning is driven by the need for \"economy in research\"\u2014the expected fact-based productivity of hypotheses, prior to deductive and inductive processes of verification. A key concept proposed by him in this regard is \"uberty\"\u2014the expected fertility and pragmatic value of reasoning. This concept seems to be gaining support via association to the Free Energy Principle.\nGilbert Harman (1965).\nGilbert Harman was a professor of philosophy at Princeton University. Harman's 1965 account of the role of \"inference to the best explanation\" \u2013 inferring the existence of that which we need for the best explanation of observable phenomena \u2013 has been very influential.\nStephen Jay Gould (1995).\nStephen Jay Gould, in answering the Omphalos hypothesis, claimed that only hypotheses that can be proved incorrect lie within the domain of science and only these hypotheses are good explanations of facts worth inferring to. &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"[W]hat is so desperately wrong with Omphalos? Only this really (and perhaps paradoxically): that we can devise no way to find out whether it is wrong\u2014or for that matter, right. Omphalos is the classic example of an utterly untestable notion, for the world will look exactly the same in all its intricate detail whether fossils and strata are prochronic [signs of a fictitious past] or products of an\nextended history. . . . Science is a procedure for testing and rejecting hypotheses, not a compendium of certain knowledge. Claims that can be proved incorrect lie within its domain. . . . But theories that cannot be tested in principle are not part of science. . . . [W]e reject Omphalos as useless, not wrong.\"\nApplications.\nArtificial intelligence.\nApplications in artificial intelligence include fault diagnosis, belief revision, and automated planning. The most direct application of abduction is that of automatically detecting faults in systems: given a theory relating faults with their effects and a set of observed effects, abduction can be used to derive sets of faults that are likely to be the cause of the problem.\nMedicine.\nIn medicine, abduction can be seen as a component of clinical evaluation and judgment. The Internist-I diagnostic system, the first AI system that covered the field of Internal Medicine, used abductive reasoning to converge on the most likely causes of a set of patient symptoms that it acquired through an interactive dialog with an expert user.\nAutomated planning.\nAbduction can also be used to model automated planning. Given a logical theory relating action occurrences with their effects (for example, a formula of the event calculus), the problem of finding a plan for reaching a state can be modeled as the problem of abducting a set of literals implying that the final state is the goal state.\nIntelligence analysis.\nIn intelligence analysis, analysis of competing hypotheses and Bayesian networks, probabilistic abductive reasoning is used extensively. Similarly in medical diagnosis and legal reasoning, the same methods are being used, although there have been many examples of errors, especially caused by the base rate fallacy and the prosecutor's fallacy.\nBelief revision.\nBelief revision, the process of adapting beliefs in view of new information, is another field in which abduction has been applied. The main problem of belief revision is that the new information may be inconsistent with the prior web of beliefs, while the result of the incorporation cannot be inconsistent. The process of updating the web of beliefs can be done by the use of abduction: once an explanation for the observation has been found, integrating it does not generate inconsistency.\nIn 1992 Peter G\u00e4rdenfors presented a paper which contained a brief survey of the area of belief revision and its relation to updating of logical databases, and explores the relationship between belief revision and nonmonotonic logic.\nThis use of abduction is not straightforward, as adding propositional formulae to other propositional formulae can only make inconsistencies worse. Instead, abduction is done at the level of the ordering of preference of the possible worlds. Preference models use fuzzy logic or utility models.\nPhilosophy of science.\nIn the philosophy of science, abduction has been the key inference method to support scientific realism, and much of the debate about scientific realism is focused on whether abduction is an acceptable method of inference.\nHistorical linguistics.\nIn historical linguistics, abduction during language acquisition is often taken to be an essential part of processes of language change such as reanalysis and analogy.\nApplied linguistics.\nIn applied linguistics research, abductive reasoning is starting to be used as an alternative explanation to inductive reasoning, in recognition of anticipated outcomes of qualitative inquiry playing a role in shaping the direction of analysis. It is defined as \"The use of an unclear premise based on observations, pursuing theories to try to explain it\" (Rose et al., 2020, p.\u00a0258)\nAnthropology.\nIn anthropology, Alfred Gell in his influential book \"Art and Agency\" defined abduction (after Eco) as \"a case of synthetic inference 'where we find some very curious circumstances, which would be explained by the supposition that it was a case of some general rule, and thereupon adopt that supposition'\". Gell criticizes existing \"anthropological\" studies of art for being too preoccupied with aesthetic value and not preoccupied enough with the central anthropological concern of uncovering \"social relationships\", specifically the social contexts in which artworks are produced, circulated, and received. Abduction is used as the mechanism for getting from art to agency. That is, abduction can explain how works of art inspire a \"sensus communis:\" the commonly held views shared by members that characterize a given society.\nThe question Gell asks in the book is, \"how does it initially 'speak' to people?\" He answers by saying that \"No reasonable person could suppose that art-like relations between people and things do not involve at least some form of semiosis.\" However, he rejects any intimation that semiosis can be thought of as a language because then he would have to admit to some pre-established existence of the \"sensus communis\" that he wants to claim only emerges afterwards out of art. Abduction is the answer to this conundrum because the tentative nature of the abduction concept (Peirce likened it to guessing) means that not only can it operate outside of any pre-existing framework, but moreover, it can actually intimate the existence of a framework. As Gell reasons in his analysis, the physical existence of the artwork prompts the viewer to perform an abduction that imbues the artwork with intentionality. A statue of a goddess, for example, in some senses actually becomes the goddess in the mind of the beholder; and represents not only the form of the deity but also her intentions (which are adduced from the feeling of her very presence). Therefore, through abduction, Gell claims that art can have the kind of agency that plants the seeds that grow into cultural myths. The power of agency is the power to motivate actions and inspire ultimately the shared understanding that characterizes any given society.\nComputer programming.\nIn formal methods, logic is used to specify and prove properties of computer programs. Abduction has been used in mechanized reasoning tools to increase the level of automation of the proof activity.\nA technique known as bi-abduction, which mixes abduction and the frame problem, was used to scale reasoning techniques for memory properties to millions of lines of code; logic-based abduction was used to infer pre-conditions for individual functions in a program, relieving the human of the need to do so. It led to a program-proof startup company, which was acquired by Facebook, and the Infer program analysis tool, which led to thousands of bugs being prevented in industrial codebases.\nIn addition to inference of function preconditions, abduction has been used to automate inference of invariants for program loops, inference of specifications of unknown code, and in synthesis of the programs themselves.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "60460", "revid": "41833184", "url": "https://en.wikipedia.org/wiki?curid=60460", "title": "20,000 Leagues Under the Sea", "text": ""}
{"id": "60467", "revid": "1306352", "url": "https://en.wikipedia.org/wiki?curid=60467", "title": "Abnormal end", "text": ""}
{"id": "60470", "revid": "4788526", "url": "https://en.wikipedia.org/wiki?curid=60470", "title": "ABI", "text": "Abi or ABI may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "60471", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=60471", "title": "Application binary interface", "text": "Interface to software defined in terms of in-process, machine code access\nAn application binary interface (ABI) is an interface exposed by software that is defined for in-process machine code access. Often, the exposing software is a library, and the consumer is a program.\nAn ABI is at a relatively low level of abstraction. Interface compatibility depends on the target hardware and the software build toolchain. In contrast, an application programming interface (API) defines access in source code, which is a relatively high-level, hardware-independent, and human-readable format. An API defines an interface at the source code level, before compilation, whereas an ABI defines an interface to compiled code.\nAPI compatibility is generally the concern for system design and of the toolchain. However, a programmer may have to deal with an ABI directly when writing a program in multiple languages or when using multiple compilers for the same language.\nA complete ABI enables a program that supports an ABI to run without modification on multiple operating systems that provide the ABI. The target system must provide any required libraries (that implement the ABI), and there may be other prerequisites.\nDescription.\nInterface aspects covered by an ABI include:\nABIs include the Intel Binary Compatibility Standard (iBCS) and the System V Release 4 ABIs for various instruction sets.\nEmbedded ABI.\nAn embedded ABI (EABI), used on an embedded operating system, specifies aspects such as file formats, data types, register usage, stack frame organization, and function parameter passing of an embedded software program.\nEach compiler and assembler that supports an EABI creates object code that is compatible with code generated by other such compilers and assemblers. This allows developers to link libraries generated by one compiler with object code generated by another.\nTypically, an EABI is optimized for performance for the limited resources of the target embedded system. Therefore, an EABI may omit abstractions between kernel and user space typically found in desktop operating systems. For example, dynamic linking may be avoided to allow smaller executables and faster loading, fixed register usage allows more compact stacks and kernel calls, and running the application in privileged mode allows direct access to custom hardware operation without the indirection of calling a device driver. The choice of EABI can affect performance.\nWidely used EABIs include the PowerPC, Arm, and MIPS EABIs. Specific software implementations like the C library may impose additional limitations to form more concrete ABIs; one example is the GNU OABI and EABI for ARM, both of which are subsets of the ARM EABI.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60473", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=60473", "title": "Application Binary Interface", "text": ""}
{"id": "60474", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=60474", "title": "Asynchronous Balanced Mode", "text": ""}
{"id": "60475", "revid": "39544904", "url": "https://en.wikipedia.org/wiki?curid=60475", "title": "ABNF", "text": ""}
{"id": "60476", "revid": "48535834", "url": "https://en.wikipedia.org/wiki?curid=60476", "title": "Augmented Backus\u2013Naur form", "text": "Metalanguage based on Backus\u2013Naur Form (BNF)\nIn computer science, augmented Backus\u2013Naur form (ABNF) is a metalanguage based on Backus\u2013Naur form (BNF) but consisting of its own syntax and derivation rules. The motive principle for ABNF is to describe a formal system of a language to be used as a bidirectional communications protocol. It is defined by https:// (\"STD 68\", type case sic), which as of \u00a02010[ [update]] was , and it often serves as the definition language for IETF communication protocols.\n supersedes . updates it, adding a syntax for specifying case-sensitive string literals.\nOverview.\n tright\" style=\"width:282px;\"&gt;\nABNF syntax diagram of ABNF rules\nAn ABNF specification is a set of derivation rules, written as\nwhere rule is a case-insensitive nonterminal, the definition consists of sequences of symbols that define the rule, a comment for documentation, and ending with a carriage return and line feed.\nRule names are case-insensitive: codice_1, codice_2, codice_3, and codice_4 all refer to the same rule. Rule names consist of a letter followed by letters, numbers, and hyphens.\nAngle brackets (codice_5, codice_6) are not required around rule names (as they are in BNF). However, they may be used to delimit a rule name when used in prose to discern a rule name.\nExample.\nThe (U.S.) postal address example given in the augmented Backus\u2013Naur form (ABNF) page may be specified as follows:\npostal-address = name-part street zip-part\nname-part = *(personal-part SP) last-name [SP suffix] CRLF\nname-part =/ personal-part CRLF\npersonal-part = first-name / (initial \".\")\nfirst-name = *ALPHA\ninitial = ALPHA\nlast-name = *ALPHA\nsuffix = (\"Jr.\" / \"Sr.\" / 1*(\"I\" / \"V\" / \"X\"))\nstreet = [apt SP] house-num SP street-name CRLF\napt = 1*4DIGIT\nhouse-num = 1*8(DIGIT / ALPHA)\nstreet-name = 1*VCHAR\nzip-part = town-name \",\" SP state 1*2SP zip-code CRLF\ntown-name = 1*(ALPHA / SP)\nstate = 2ALPHA\nzip-code = 5DIGIT [\"-\" 4DIGIT]\nTerminal values.\nTerminals are specified by one or more numeric characters.\nNumeric characters may be specified as the percent sign codice_7, followed by the base (codice_8 = binary, codice_9 = decimal, and codice_10 = hexadecimal), followed by the value, or concatenation of values (indicated by codice_11). For example, a carriage return is specified by codice_12 in decimal or codice_13 in hexadecimal. A carriage return followed by a line feed may be specified with concatenation as codice_14.\nLiteral text is specified through the use of a string enclosed in quotation marks (codice_15). These strings are case-insensitive, and the character set used is (US-)ASCII. Therefore, the string codice_16 will match \u201cabc\u201d, \u201cAbc\u201d, \u201caBc\u201d, \u201cabC\u201d, \u201cABc\u201d, \u201cAbC\u201d, \u201caBC\u201d, and \u201cABC\u201d. https:// added a syntax for case-sensitive strings: codice_17 will only match \"aBc\". Prior to that, a case-sensitive string could only be specified by listing the individual characters: to match \u201caBc\u201d, the definition would be codice_18. A string can also be explicitly specified as case-insensitive with a codice_19 prefix.\nOperators.\nWhite space.\nWhite space is used to separate elements of a definition; for space to be recognized as a delimiter, it must be explicitly included. The explicit reference for a single whitespace character is codice_20 (linear white space), and codice_21 is for zero or more whitespace characters with newlines permitted. The codice_21 definition in RFC5234 is controversial because at least one whitespace character is needed to form a delimiter between two fields.\nDefinitions are left-aligned. When multiple lines are required (for readability), continuation lines are indented by whitespace.\nComment.\ncodice_23\nA semicolon (codice_24) starts a comment that continues to the end of the line.\nConcatenation.\ncodice_25\nA rule may be defined by listing a sequence of rule names.\nTo match the string \u201caba\u201d, the following rules could be used:\nAlternative.\ncodice_26\nA rule may be defined by a list of alternative rules separated by a solidus (codice_27).\nTo accept the rule \"fu\" or the rule \"bar\", the following rule could be constructed:\nIncremental alternatives.\ncodice_28\nAdditional alternatives may be added to a rule through the use of codice_29 between the rule name and the definition.\nThe rule\nis therefore equivalent to \nValue range.\ncodice_30\nA range of numeric values may be specified through the use of a hyphen (codice_31).\nThe rule\nis equivalent to\nSequence group.\ncodice_32\nElements may be placed in parentheses to group rules in a definition.\nTo match \"a b d\" or \"a c d\", the following rule could be constructed:\nTo match \u201ca b\u201d or \u201cc d\u201d, the following rules could be constructed:\nVariable repetition.\ncodice_33\nTo indicate repetition of an element, the form codice_34 is used. The optional codice_35 gives the minimal number of elements to be included (with the default of 0). The optional codice_36 gives the maximal number of elements to be included (with the default of infinity).\nUse codice_37 for zero or more elements, codice_38 for zero or one element, codice_39 for one or more elements, and codice_40 for two or three elements, cf. regular expressions codice_41, codice_42, codice_43 and codice_44.\nSpecific repetition.\ncodice_45\nTo indicate an explicit number of elements, the form codice_46 is used and is equivalent to codice_47.\nUse codice_48 to get two numeric digits, and codice_49 to get three numeric digits. (codice_50 is defined below under \"Core rules\". Also see \"zip-code\" in the example below.)\nOptional sequence.\ncodice_51\nTo indicate an optional element, the following constructions are equivalent:\nOperator precedence.\nThe following operators have the given precedence from tightest binding to loosest binding:\nUse of the alternative operator with concatenation may be confusing, and it is recommended that grouping be used to make explicit concatenation groups.\nCore rules.\n tright\" style=\"width:282px;\"&gt;\nABNF syntax diagram of core rules\nThe core rules are defined in the ABNF standard.\nNote that in the core rules diagram the CHAR2 charset is inlined in char-val and CHAR3 is inlined in prose-val in the RFC spec. They are named here for clarity in the main syntax diagram.\nABNF representation of itself.\nABNF's syntax itself may be represented with a ABNF like the following:\nrulelist = 1*( rule / (*WSP c-nl) )\nrule = rulename defined-as elements c-nl\n ; continues if next line starts\n ; with white space\nrulename = ALPHA *(ALPHA / DIGIT / \"-\")\ndefined-as = *c-wsp (\"=\" / \"=/\") *c-wsp\n ; basic rules definition and\n ; incremental alternatives\nelements = alternation *WSP\nc-wsp = WSP / (c-nl WSP)\nc-nl = comment / CRLF\n ; comment or newline\ncomment = \";\" *(WSP / VCHAR) CRLF\nalternation = concatenation\n *(*c-wsp \"/\" *c-wsp concatenation)\nconcatenation = repetition *(1*c-wsp repetition)\nrepetition = [repeat] element\nrepeat = 1*DIGIT / (*DIGIT \"*\" *DIGIT)\nelement = rulename / group / option /\n char-val / num-val / prose-val\ngroup = \"(\" *c-wsp alternation *c-wsp \")\"\noption = \"[\" *c-wsp alternation *c-wsp \"]\"\nchar-val = DQUOTE *(%x20-21 / %x23-7E) DQUOTE\n ; quoted string of SP and VCHAR\n ; without DQUOTE\nnum-val = \"%\" (bin-val / dec-val / hex-val)\nbin-val = \"b\" 1*BIT\n [ 1*(\".\" 1*BIT) / (\"-\" 1*BIT) ]\n ; series of concatenated bit values\n ; or single ONEOF range\ndec-val = \"d\" 1*DIGIT\n [ 1*(\".\" 1*DIGIT) / (\"-\" 1*DIGIT) ]\nhex-val = \"x\" 1*HEXDIG\n [ 1*(\".\" 1*HEXDIG) / (\"-\" 1*HEXDIG) ]\nprose-val = \"&lt;\" *(%x20-3D / %x3F-7E) \"&gt;\"\n ; bracketed string of SP and VCHAR\n ; without angles\n ; prose description, to be used as\n ; last resort\nThe core rules have to be adapted to their environment's encoding. Here are the core rules of ABNF in 7-bit ASCII encoding:\nALPHA = %x41-5A / %x61-7A ; A-Z / a-z\nBIT = \"0\" / \"1\"\nCHAR = %x01-7F\n ; any 7-bit US-ASCII character,\n ; excluding NUL\nCR = %x0D\n ; carriage return\nCRLF = CR LF\n ; Internet standard newline\nCTL = %x00-1F / %x7F\n ; controls\nDIGIT = %x30-39\n ; 0-9\nDQUOTE = %x22\n ; \" (Double Quote)\nHEXDIG = DIGIT / \"A\" / \"B\" / \"C\" / \"D\" / \"E\" / \"F\"\nHTAB = %x09\n ; horizontal tab\nLF = %x0A\n ; linefeed\nLWSP = *(WSP / CRLF WSP)\n ; Use of this linear-white-space rule\n ; permits lines containing only white\n ; space that are no longer legal in\n ; mail headers and have caused\n ; interoperability problems in other\n ; contexts.\n ; Do not use when defining mail\n ; headers and use with caution in\n ; other contexts.\nOCTET = %x00-FF\n ; 8 bits of data\nSP = %x20\nVCHAR = %x21-7E\n ; visible (printing) characters\nWSP = SP / HTAB\n ; white space\nPitfalls.\nhttp:// adds a warning in conjunction to the definition of LWSP as follows: \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Use of this linear-white-space rule permits lines containing only white space that are no longer legal in mail headers and have caused interoperability problems in other contexts. Do not use when defining mail headers and use with caution in other contexts.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60477", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=60477", "title": "Asynchronous balanced mode", "text": ""}
{"id": "60478", "revid": "43709170", "url": "https://en.wikipedia.org/wiki?curid=60478", "title": "Abort (computing)", "text": "Unscheduled termination of a process\nIn a computer or data transmission system, to abort means to , usually in a controlled manner, a processing activity because it is impossible or undesirable for the activity to proceed or in conjunction with an error. Such an action may be accompanied by information on the aborted process.\nIn addition to being a verb, abort also has two noun senses. In the most general case, the event of aborting can be referred to as an abort. Sometimes the event of aborting can be given a special name, as in the case of an abort involving a Unix kernel where it is known as a kernel panic. Specifically in the context of data transmission, an abort is a function invoked by a sending station to cause the recipient to discard or ignore all bit sequences transmitted by the sender since the preceding flag sequence.\nIn the C programming language, codice_1 is a standard library function that terminates the current application and returns an error code to the host environment.\nTypes of aborts.\nAborts are typically logged, especially in critical systems, to facilitate troubleshooting and improve future runs.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60479", "revid": "29615425", "url": "https://en.wikipedia.org/wiki?curid=60479", "title": "Augmented Backus-Naur Form", "text": ""}
{"id": "60481", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=60481", "title": "Alternating bit protocol", "text": "Type of data link layer protocol about transmission fidelity\nAlternating bit protocol (ABP) is a simple network protocol operating at the data link layer (OSI layer 2) that retransmits lost or corrupted messages using FIFO semantics. It can be seen as a special case of a sliding window protocol where a simple timer restricts the order of messages to ensure receivers send messages in turn while using a window of 1 bit.\nDesign.\nMessages are sent from transmitter A to receiver B. Assume that the channel from A to B is initialized and that there are no messages in transit. Each message from A to B contains a data part and a one-bit sequence number, i.e., a value that is 0 or 1. B has two acknowledge codes that it can send to A: ACK0 and ACK1.\nWhen A sends a message, it resends it continuously, with the same sequence number, until it receives an acknowledgment from B that contains the same sequence number. When that happens, A complements (flips) the sequence number and starts transmitting the next message.\nWhen B receives a message that is not corrupted and has sequence number 0, it starts sending ACK0 and keeps doing so until it receives a valid message with number 1. Then it starts sending ACK1, etc.\nThis means that A may still receive ACK0 when it is already transmitting messages with sequence number one. (And vice versa.) It treats such messages as negative-acknowledge codes (NAKs). The simplest behaviour is to ignore them all and continue transmitting.\nThe protocol may be initialized by sending bogus messages and acks with sequence number 1. The first message with sequence number 0 is a real message.\nBounded Retransmission Protocol.\nBounded Retransmission Protocol (BRP) is a variant of the alternating bit protocol introduced by Philips. The service it delivers is to transfer in a reliable manner, if possible, large files (sequence of data of arbitrary length) from a sender to a receiver. Unlike ABP, BRP deals with sequence numbers of datum in the file and interrupts transfer after fixed number of retransmissions for a datum.\nHistory.\nDonald Davies' team at the National Physical Laboratory introduced the concept of an alternating bit protocol in 1968 for the NPL network. An ABP was used by the ARPANET and by the European Informatics Network.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60482", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=60482", "title": "Alternating Bit Protocol", "text": ""}
{"id": "60483", "revid": "6056090", "url": "https://en.wikipedia.org/wiki?curid=60483", "title": "ABR", "text": "Abr or ABR may refer to:\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "60484", "revid": "2214", "url": "https://en.wikipedia.org/wiki?curid=60484", "title": "Automatic baud dectection", "text": ""}
{"id": "60485", "revid": "2214", "url": "https://en.wikipedia.org/wiki?curid=60485", "title": "Autobaud", "text": ""}
{"id": "60486", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=60486", "title": "Automatic baud rate detection", "text": "Determining speed and configuration of a serial connecgion by examining the first character\nAutomatic baud rate detection (ABR, autobaud) refers to the process by which a receiving device (such as a modem) determines the speed, code level, start bit, and stop bits of incoming data by examining the first character, usually a preselected sign-on character (syncword) on a UART connection. ABR allows the receiving device to accept data from a variety of transmitting devices operating at different speeds without needing to establish data rates in advance.\nProcess.\nDuring the autobaud process, the baud rate of received character stream is determined by examining the received pattern and its timing, and the length of a start bit. These types of baud rate detection mechanisms are supported by many hardware chips including processors such as STM32 MPC8280, MPC8360, and so on. \nWhen start bit length is used to determine the baud rate, it requires the character to be odd since UART sends LSB bit first\u00a0\u2013 this particular bit order scheme is referred to as little-endian. Often ASCII symbols 'a' or 'A' (0x61 or 0x41) are used. For example, the MPC8270 SCC tries to detect the length of the UART start bit for autobaud.\nMany protocols begin each frame with a preamble of alternating 1 and 0 bits that can be used for automatic baud rate detection. For example, the TI PGA460 uses a ASCII \"U\" ( or ) sync byte for automatic baud rate detection as well as frame synchronization, and so does the LIN header (Local Interconnect Network#Header).\nFor example, the UART-based FlexWire protocol begins each frame with a \"U\" () sync byte. FlexWire receivers use the sync byte to precisely set their UART bit-clock frequency without a high-precision oscillator. For example, the Ethernet preamble contains 56 bits of alternating 1 and 0 bits for synchronizing bit clocks.\nSupport.\nMost modems currently on the market support autobaud. Before receiving any input data, most modems use a default baud rate of 9600 for output. For example, the following modems have been verified for autobaud and default output baud rate 9600: \nThe baud rate of modems are adjusted automatically after receiving input data by the autobaud process.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "60487", "revid": "5320876", "url": "https://en.wikipedia.org/wiki?curid=60487", "title": "Abscissa and ordinate", "text": "Horizontal and vertical axes/coordinate numbers of a 2D coordinate system or graph\nIn mathematics, the abscissa (; plural \"abscissae\" or \"abscissas\") and the ordinate are respectively the first and second coordinate of a point in a Cartesian coordinate system:\n abscissa formula_1-axis (horizontal) coordinate\n ordinate formula_2-axis (vertical) coordinate\nTogether they form an ordered pair which defines the location of a point in two-dimensional rectangular space.\nMore technically, the abscissa of a point is the signed measure of its projection on the primary axis. Its absolute value is the distance between the projection and the origin of the axis, and its sign is given by the location on the projection relative to the origin (before: negative; after: positive). Similarly, the ordinate of a point is the signed measure of its projection on the secondary axis. In three dimensions, the third direction is sometimes referred to as the \"applicate\".\nEtymology.\nThough the word \"abscissa\" (from la \" linea abscissa\"\u00a0'a line cut off') has been used at least since \"De Practica Geometrie\" (1220) by Fibonacci (Leonardo of Pisa), its use in its modern sense may be due to Venetian mathematician Stefano degli Angeli in his work \"Miscellaneum Hyperbolicum, et Parabolicum\" (1659). Historically, the term was used in the more general sense of a 'distance'.\nIn his 1892 work \" (\"Lectures on history of mathematics\"\"), volume 2, German historian of mathematics Moritz Cantor writes:\nAt the same time it was presumably by [Stefano degli Angeli] that a word was introduced into the mathematical vocabulary for which especially in analytic geometry the future proved to have much in store. [\u2026] We know of no earlier use of the word \"abscissa\" in Latin original texts. Maybe the word appears in translations of the Apollonian conics, where [in] Book I, Chapter 20 there is mention of \"\u1f00\u03c0\u03bf\u03c4\u03b5\u03bc\u03bd\u03bf\u03bc\u03ad\u03bd\u03b1\u03b9\u03c2,\" for which there would hardly be a more appropriate Latin word than .\nThe use of the word \"ordinate\" is related to the Latin phrase \"linea ordinata appliicata\" 'line applied parallel'.\nIn parametric equations.\nIn a somewhat obsolete variant usage, the abscissa of a point may also refer to any number that describes the point's location along some path, e.g. the parameter of a parametric equation. Used in this way, the abscissa can be thought of as a coordinate-geometry analog to the independent variable in a mathematical model or experiment (with any ordinates filling a role analogous to dependent variables).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60489", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=60489", "title": "Abstract class", "text": ""}
{"id": "60490", "revid": "16272435", "url": "https://en.wikipedia.org/wiki?curid=60490", "title": "Abstract interpretation", "text": "Approach to static program analysis\nIn computer science, abstract interpretation is a theory of sound approximation of the semantics of computer programs, based on monotonic functions over ordered sets, especially lattices. It can be viewed as a partial execution of a computer program which gains information about its semantics (e.g., control-flow, data-flow) without performing all the calculations.\nIts main concrete application is formal static analysis, the automatic extraction of information about the possible executions of computer programs; such analyses have two main usages:\nAbstract interpretation was formalized by the French computer scientist working couple Patrick Cousot and Radhia Cousot in the late 1970s.\nIntuition.\nThis section illustrates abstract interpretation by means of real-world, non-computing examples.\nConsider the people in a conference room. Assume a unique identifier for each person in the room, like a social security number in the United States. To prove that someone is not present, all one needs to do is see if their social security number is not on the list. Since two different people cannot have the same number, it is possible to prove or disprove the presence of a participant simply by looking up their number.\nHowever it is possible that only the names of attendees were registered. If the name of a person is not found in the list, we may safely conclude that that person was not present; but if it is, we cannot conclude definitely without further inquiries, due to the possibility of homonyms (for example, two people named John Smith). Note that this imprecise information will still be adequate for most purposes, because homonyms are rare in practice. However, in all rigor, we cannot say for sure that somebody was present in the room; all we can say is that they were \"possibly\" here. If the person we are looking up is a criminal, we will issue an \"alarm\"; but there is of course the possibility of issuing a \"false alarm\". Similar phenomena will occur in the analysis of programs.\nIf we are only interested in some specific information, say, \"was there a person of age formula_1 in the room?\", keeping a list of all names and dates of births is unnecessary. We may safely and without loss of precision restrict ourselves to keeping a list of the participants' ages. If this is already too much to handle, we might keep only the age of the youngest, formula_2 and oldest person, formula_3. If the question is about an age strictly lower than formula_2 or strictly higher than formula_3, then we may safely respond that no such participant was present. Otherwise, we may only be able to say that we do not know.\nIn the case of computing, concrete, precise information is in general not computable within finite time and memory (see Rice's theorem and the halting problem). Abstraction is used to allow for generalized answers to questions (for example, answering \"maybe\" to a yes/no question, meaning \"yes or no\", when we (an algorithm of abstract interpretation) cannot compute the precise answer with certainty); this simplifies the problems, making them amenable to automatic solutions. One crucial requirement is to add enough vagueness so as to make problems manageable while still retaining enough precision for answering the important questions (such as \"might the program crash?\").\nAbstract interpretation of computer programs.\nGiven a programming or specification language, abstract interpretation consists of giving several semantics linked by relations of abstraction. A semantics is a mathematical characterization of a possible behavior of the program. The most precise semantics, describing very closely the actual execution of the program, are called the \"concrete semantics\". For instance, the concrete semantics of an imperative programming language may associate to each program the set of execution traces it may produce \u2013 an execution trace being a sequence of possible consecutive states of the execution of the program; a state typically consists of the value of the program counter and the memory locations (globals, stack and heap). More abstract semantics are then derived; for instance, one may consider only the set of reachable states in the executions (which amounts to considering the last states in finite traces).\nThe goal of static analysis is to derive a computable semantic interpretation at some point. For instance, one may choose to represent the state of a program manipulating integer variables by forgetting the actual values of the variables and only keeping their signs (+, \u2212 or 0). For some elementary operations, such as multiplication, such an abstraction does not lose any precision: to get the sign of a product, it is sufficient to know the sign of the operands. For some other operations, the abstraction may lose precision: for instance, it is impossible to know the sign of a sum whose operands are respectively positive and negative.\nSometimes a loss of precision is necessary to make the semantics decidable (see Rice's theorem and the halting problem). In general, there is a compromise to be made between the precision of the analysis and its decidability (computability), or tractability (computational cost).\nIn practice the abstractions that are defined are tailored to both the program properties one desires to analyze, and to the set of target programs. The first large scale automated analysis of computer programs with abstract interpretation was motivated by the accident that resulted in the destruction of the first flight of the Ariane 5 rocket in 1996.\nFormalization.\nLet formula_6 be an ordered set, called \"concrete set\", and let formula_7 be another ordered set, called \"abstract set\". These two sets are related to each other by defining total functions that map elements from one to the other.\nA function formula_8 is called an \"abstraction function\" if it maps an element formula_9 in the concrete set formula_6 to an element formula_11 in the abstract set formula_7. That is, element formula_11 in formula_7 is the \"abstraction\" of formula_9 in formula_6.\nA function formula_17 is called a \"concretization function\" if it maps an element formula_18 in the abstract set formula_7 to an element formula_20 in the concrete set formula_6. That is, element formula_20 in formula_6 is a \"concretization\" of formula_18 in formula_7.\nLet formula_26, formula_27, formula_28, and formula_29 be ordered sets. The concrete semantics formula_30 is a monotonic function from formula_26 to formula_27. A function formula_33 from formula_28 to formula_29 is said to be a \"valid abstraction\" of formula_30 if, for all formula_18 in formula_28, we have formula_39.\nProgram semantics are generally described using fixed points in the presence of loops or recursive procedures. Suppose that formula_6 is a complete lattice and let formula_30 be a monotonic function from formula_6 into formula_6. Then, any formula_18 such that formula_45 is an abstraction of the least fixed-point of formula_30, which exists, according to the Knaster\u2013Tarski theorem.\nThe difficulty is now to obtain such an formula_18. If formula_7 is of finite height, or at least verifies the ascending chain condition (all ascending sequences are ultimately stationary), then such an formula_18 may be obtained as the stationary limit of the ascending sequence formula_50 defined by induction as follows: formula_51 (the least element of formula_7) and formula_53.\nIn other cases, it is still possible to obtain such an formula_18 through a (pair-)widening operator, defined as a binary operator formula_55 which satisfies the following conditions:\nIn some cases, it is possible to define abstractions using Galois connections formula_64 where formula_8 is from formula_6 to formula_7 and formula_17 is from formula_7 to formula_6. This supposes the existence of best abstractions, which is not necessarily the case. For instance, if we abstract sets of couples formula_71 of real numbers by enclosing convex polyhedra, there is no optimal abstraction to the disc defined by formula_72.\nExamples of abstract domains.\nNumerical abstract domains.\nOne can assign to each variable formula_9 available at a given program point an interval formula_74. A state assigning the value formula_75 to variable formula_9 will be a concretization of these intervals if, for all formula_9, we have formula_78. From the intervals formula_74 and formula_80 for variables formula_9 and formula_57, respectively, one can easily obtain intervals for formula_83 (namely, formula_84) and for formula_85 (namely, formula_86); note that these are \"exact\" abstractions, since the set of possible outcomes for, say, formula_87, is precisely the interval formula_84. More complex formulas can be derived for multiplication, division, etc., yielding so-called interval arithmetics.\nLet us now consider the following very simple program:\nWith reasonable arithmetic types, the result for &lt;samp style=\"padding-left:0.4em; padding-right:0.4em; color:var( --color-subtle, #666666); \" &gt;z&lt;/samp&gt; should be zero. But if we do interval arithmetic starting from &lt;samp style=\"padding-left:0.4em; padding-right:0.4em; color:var( --color-subtle, #666666); \" &gt;x&lt;/samp&gt; in [0, 1], one gets &lt;samp style=\"padding-left:0.4em; padding-right:0.4em; color:var( --color-subtle, #666666); \" &gt;z&lt;/samp&gt; in [\u22121, +1]. While each of the operations taken individually was exactly abstracted, their composition isn't.\nThe problem is evident: we did not keep track of the equality relationship between &lt;samp style=\"padding-left:0.4em; padding-right:0.4em; color:var( --color-subtle, #666666); \" &gt;x&lt;/samp&gt; and &lt;samp style=\"padding-left:0.4em; padding-right:0.4em; color:var( --color-subtle, #666666); \" &gt;y&lt;/samp&gt;; actually, this domain of intervals does not take into account any relationships between variables, and is thus a \"non-relational domain\". Non-relational domains tend to be fast and simple to implement, but imprecise.\nSome examples of \"relational\" numerical abstract domains are:\nand combinations thereof (such as the reduced product, cf. right picture).\nWhen one chooses an abstract domain, one typically has to strike a balance between keeping fine-grained relationships, and high computational costs.\nMachine word abstract domains.\nWhile high-level languages such as Python or Haskell use unbounded integers by default, lower-level programming languages such as C or assembly language typically operate on finitely-sized machine words, which are more suitably modeled using the integers modulo formula_89 (where \"n\" is the bit width of a machine word). There are several abstract domains suitable for various analyses of such variables.\nThe \"bitfield domain\" treats each bit in a machine word separately, i.e., a word of width \"n\" is treated as an array of \"n\" abstract values. The abstract values are taken from the set formula_90, and the abstraction and concretization functions are given by: formula_91, formula_92, formula_93, formula_94, formula_95, formula_96, formula_97. Bitwise operations on these abstract values are identical with the corresponding logical operations in some three-valued logics:\nFurther domains include the \"signed interval domain\" and the \"unsigned interval domain\". All three of these domains support forwards and backwards abstract operators for common operations such as addition, shifts, xor, and multiplication. These domains can be combined using the reduced product.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60491", "revid": "612852", "url": "https://en.wikipedia.org/wiki?curid=60491", "title": "Abstraction (computer science)", "text": "Software that provides access that hides details\nIn software, an abstraction provides access while hiding details that otherwise might make access more challenging. It focuses attention on details of greater importance. Examples include the abstract data type which separates use from the representation of data and functions that form a call tree that is more general at the base and more specific towards the leaves.\nRationale.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThe essence of abstraction is preserving information that is relevant in a given context, and forgetting information that is irrelevant in that context.\n\u2013 John V. Guttag\nComputing mostly operates independently of the concrete world. The hardware implements a model of computation that is interchangeable with others. The software is structured in architectures to enable humans to create the enormous systems by concentrating on a few issues at a time. These architectures are made of specific choices of abstractions. Greenspun's tenth rule is an aphorism on how such an architecture is both inevitable and complex.\nLanguage abstraction is a central form of abstraction in computing: new artificial languages are developed to express specific aspects of a system. \"Modeling languages\" help in planning. \"Computer languages\" can be processed with a computer. An example of this abstraction process is the generational development of programming language from the first-generation programming language (machine language) to the second-generation programming language (assembly language) and the third-generation programming language (high-level programming language). Each stage can be used as a stepping stone for the next stage. The language abstraction continues for example in scripting languages and domain-specific languages.\nWithin a programming language, some features let the programmer create new abstractions. These include subroutines, modules, polymorphism, and software components. Some other abstractions such as software design patterns and architectural styles remain invisible to a translator and operate only in the design of a system.\nSome abstractions try to limit the range of concepts a programmer needs to be aware of, by completely hiding the abstractions they are built on. The software engineer and writer Joel Spolsky has criticized these efforts by claiming that all abstractions are \"leaky\" \u2013 that they can never completely hide the details below; however, this does not negate the usefulness of abstraction.\nSome abstractions are designed to inter-operate with other abstractions \u2013 for example, a programming language may contain a foreign function interface for making calls to the lower-level language.\nAbstraction features.\nProgramming languages.\nDifferent programming languages provide different types of abstraction, depending on the intended applications for the language. For example:\nSpecification methods.\nAnalysts have developed various methods to formally specify software systems. Some known methods include:\nSpecification languages.\nSpecification languages generally rely on abstractions of one kind or another, since specifications are typically defined earlier in a project, (and at a more abstract level) than an eventual implementation. The Unified Modeling Language (UML) specification language, for example, allows the definition of \"abstract\" classes, which in a waterfall project, remain abstract during the architecture and specification phase of the project.\nControl abstraction.\nProgramming languages offer control abstraction as one of the main purposes of their use. Computer machines understand operations at the very low level such as moving some bits from one location of the memory to another location and producing the sum of two sequences of bits. Programming languages allow this to be done in the higher level. For example, consider this statement written in a Pascal-like fashion:\ncodice_4\nTo a human, this seems a fairly simple and obvious calculation (\"one plus two is three, times five is fifteen\"). However, the low-level steps necessary to carry out this evaluation, and return the value \"15\", and then assign that value to the variable \"a\", are actually quite subtle and complex. The values need to be converted to binary representation (often a much more complicated task than one would think) and the calculations decomposed (by the compiler or interpreter) into assembly instructions (again, which are much less intuitive to the programmer: operations such as shifting a binary register left, or adding the binary complement of the contents of one register to another, are simply not how humans think about the abstract arithmetical operations of addition or multiplication). Finally, assigning the resulting value of \"15\" to the variable labeled \"a\", so that \"a\" can be used later, involves additional 'behind-the-scenes' steps of looking up a variable's label and the resultant location in physical or virtual memory, storing the binary representation of \"15\" to that memory location, etc.\nWithout control abstraction, a programmer would need to specify \"all\" the register/binary-level steps each time they simply wanted to add or multiply a couple of numbers and assign the result to a variable. Such duplication of effort has two serious negative consequences:\nStructured programming.\nStructured programming involves the splitting of complex program tasks into smaller pieces with clear flow-control and interfaces between components, with a reduction of the complexity potential for side-effects.\nIn a simple program, this may aim to ensure that loops have single or obvious exit points and (where possible) to have single exit points from functions and procedures.\nIn a larger system, it may involve breaking down complex tasks into many different modules. Consider a system which handles payroll on ships and at shore offices:\nThese layers produce the effect of isolating the implementation details of one component and its assorted internal methods from the others. Object-oriented programming embraces and extends this concept.\nData abstraction.\nData abstraction enforces a clear separation between the \"abstract\" properties of a data type and the \"concrete\" details of its implementation. The abstract properties are those that are visible to client code that makes use of the data type\u2014the \"interface\" to the data type\u2014while the concrete implementation is kept entirely private, and indeed can change, for example to incorporate efficiency improvements over time. The idea is that such changes are not supposed to have any impact on client code, since they involve no difference in the abstract behaviour.\nFor example, one could define an abstract data type called \"lookup table\" which uniquely associates \"keys\" with \"values\", and in which values may be retrieved by specifying their corresponding keys. Such a lookup table may be implemented in various ways: as a hash table, a binary search tree, or even a simple linear list of (key:value) pairs. As far as client code is concerned, the abstract properties of the type are the same in each case.\nOf course, this all relies on getting the details of the interface right in the first place, since any changes there can have major impacts on client code. As one way to look at this: the interface forms a \"contract\" on agreed behaviour between the data type and client code; anything not spelled out in the contract is subject to change without notice.\nManual data abstraction.\nWhile much of data abstraction occurs through computer science and automation, there are times when this process is done manually and without programming intervention. One way this can be understood is through data abstraction within the process of conducting a systematic review of the literature. In this methodology, data is abstracted by one or several abstractors when conducting a meta-analysis, with errors reduced through dual data abstraction followed by independent checking, known as adjudication.\nAbstraction in object-oriented programming.\nIn object-oriented programming theory, \"abstraction\" involves the facility to define objects that represent abstract \"actors\" that can perform work, report on and change their state, and \"communicate\" with other objects in the system. The term encapsulation refers to the hiding of state details, but extending the concept of \"data type\" from earlier programming languages to associate \"behavior\" most strongly with the data, and standardizing the way that different data types interact, is the beginning of \"abstraction\". When abstraction proceeds into the operations defined, enabling objects of different types to be substituted, it is called polymorphism. When it proceeds in the opposite direction, inside the types or classes, structuring them to simplify a complex set of relationships, it is called delegation or inheritance.\nVarious object-oriented programming languages offer similar facilities for abstraction, all to support a general strategy of polymorphism in object-oriented programming, which includes the substitution of one data type for another in the same or similar role. Although not as generally supported, a configuration or image or package may predetermine a great many of these bindings at compile time, link time, or load time. This would leave only a minimum of such bindings to change at run-time.\nCommon Lisp Object System or Self, for example, feature less of a class-instance distinction and more use of delegation for polymorphism. Individual objects and functions are abstracted more flexibly to better fit with a shared functional heritage from Lisp.\nC++ exemplifies another extreme: it relies heavily on templates and overloading and other static bindings at compile-time, which in turn has certain flexibility problems.\nAlthough these examples offer alternate strategies for achieving the same abstraction, they do not fundamentally alter the need to support abstract nouns in code \u2013 all programming relies on an ability to abstract verbs as functions, nouns as data structures, and either as processes.\nConsider for example a sample Java fragment to represent some common farm \"animals\" to a level of abstraction suitable to model simple aspects of their hunger and feeding. It defines an codice_5 class to represent both the state of the animal and its functions:\npublic class Animal extends LivingThing\n private Location loc;\n private double energyReserves;\n public boolean isHungry() {\n return energyReserves &lt; 2.5;\n public void eat(Food food) {\n // Consume food\n energyReserves += food.getCalories();\n public void moveTo(Location location) {\n // Move to new location\n this.loc = location;\nWith the above definition, one could create objects of type &lt;samp style=\"padding-left:0.4em; padding-right:0.4em; color:var( --color-subtle, #666666); \" &gt;Animal&lt;/samp&gt; and call their methods like this:\nthePig = new Animal();\ntheCow = new Animal();\nif (thePig.isHungry()) {\n thePig.eat(tableScraps);\nif (theCow.isHungry()) {\n theCow.eat(grass);\ntheCow.moveTo(theBarn);\nIn the above example, the class \"codice_5\" is an abstraction used in place of an actual animal, \"codice_7\" is a further abstraction (in this case a generalisation) of \"codice_5\".\nIf one requires a more differentiated hierarchy of animals \u2013 to differentiate, say, those who provide milk from those who provide nothing except meat at the end of their lives \u2013 that is an intermediary level of abstraction, probably DairyAnimal (cows, goats) who would eat foods suitable to giving good milk, and MeatAnimal (pigs, steers) who would eat foods to give the best meat-quality.\nSuch an abstraction could remove the need for the application coder to specify the type of food, so they could concentrate instead on the feeding schedule. The two classes could be related using inheritance or stand alone, and the programmer could define varying degrees of polymorphism between the two types. These facilities tend to vary drastically between languages, but in general each can achieve anything that is possible with any of the others. A great many operation overloads, data type by data type, can have the same effect at compile-time as any degree of inheritance or other means to achieve polymorphism. The class notation is simply a coder's convenience.\nObject-oriented design.\nDecisions regarding what to abstract and what to keep under the control of the coder become the major concern of object-oriented design and domain analysis\u2014actually determining the relevant relationships in the real world is the concern of object-oriented analysis or legacy analysis.\nIn general, to determine appropriate abstraction, one must make many small decisions about scope (domain analysis), determine what other systems one must cooperate with (legacy analysis), then perform a detailed object-oriented analysis which is expressed within project time and budget constraints as an object-oriented design. In our simple example, the domain is the barnyard, the live pigs and cows and their eating habits are the legacy constraints, the detailed analysis is that coders must have the flexibility to feed the animals what is available and thus there is no reason to code the type of food into the class itself, and the design is a single simple Animal class of which pigs and cows are instances with the same functions. A decision to differentiate DairyAnimal would change the detailed analysis but the domain and legacy analysis would be unchanged\u2014thus it is entirely under the control of the programmer, and it is called an abstraction in object-oriented programming as distinct from abstraction in domain or legacy analysis.\nConsiderations.\nWhen discussing formal semantics of programming languages, formal methods or abstract interpretation, \"abstraction\" refers to the act of considering a less detailed, but safe, definition of the observed program behaviors. For instance, one may observe only the final result of program executions instead of considering all the intermediate steps of executions. Abstraction is defined to a \"concrete\" (more precise) model of execution.\nAbstraction may be \"exact\" or \"faithful\" with respect to a property if one can answer a question about the property equally well on the concrete or abstract model. For instance, if one wishes to know what the result of the evaluation of a mathematical expression involving only integers +, -, \u00d7, is worth modulo \"n\", then one needs only perform all operations modulo \"n\" (a familiar form of this abstraction is casting out nines).\nAbstractions, however, though not necessarily \"exact\", should be \"sound\". That is, it should be possible to get sound answers from them\u2014even though the abstraction may simply yield a result of undecidability. For instance, students in a class may be abstracted by their minimal and maximal ages; if one asks whether a certain person belongs to that class, one may simply compare that person's age with the minimal and maximal ages; if his age lies outside the range, one may safely answer that the person does not belong to the class; if it does not, one may only answer \"I don't know\".\nThe level of abstraction included in a programming language can influence its overall usability. The Cognitive dimensions framework includes the concept of \"abstraction gradient\" in a formalism. This framework allows the designer of a programming language to study the trade-offs between abstraction and other characteristics of the design, and how changes in abstraction influence the language usability.\nAbstractions can prove useful when dealing with computer programs, because non-trivial properties of computer programs are essentially undecidable (see Rice's theorem). As a consequence, automatic methods for deriving information on the behavior of computer programs either have to drop termination (on some occasions, they may fail, crash or never yield out a result), soundness (they may provide false information), or precision (they may answer \"I don't know\" to some questions).\nAbstraction is the core concept of abstract interpretation. Model checking generally takes place on abstract versions of the studied systems.\nLevels of abstraction.\nComputer science commonly presents \"levels\" (or, less commonly, \"layers\") of abstraction, wherein each level represents a different model of the same information and processes, but with varying amounts of detail. Each level uses a system of expression involving a unique set of objects and compositions that apply only to a particular domain.\nEach relatively abstract, \"higher\" level builds on a relatively concrete, \"lower\" level, which tends to provide an increasingly \"granular\" representation. For example, gates build on electronic circuits, binary on gates, machine language on binary, programming language on machine language, applications and operating systems on programming languages. Each level is embodied, but not determined, by the level beneath it, making it a language of description that is somewhat self-contained.\nDatabase systems.\nSince many users of database systems lack in-depth familiarity with computer data-structures, database developers often hide complexity through the following levels:\n\"Physical level\" \u2013 The lowest level of abstraction describes \"how\" a system actually stores data. The physical level describes complex low-level data structures in detail.\n\"Logical level\" \u2013 The next higher level of abstraction describes \"what\" data the database stores, and what relationships exist among those data. The logical level thus describes an entire database in terms of a small number of relatively simple structures. Although implementation of the simple structures at the logical level may involve complex physical level structures, the user of the logical level does not need to be aware of this complexity. This is referred to as physical data independence. Database administrators, who must decide what information to keep in a database, use the logical level of abstraction.\n\"View level\" \u2013 The highest level of abstraction describes only part of the entire database. Even though the logical level uses simpler structures, complexity remains because of the variety of information stored in a large database. Many users of a database system do not need all this information; instead, they need to access only a part of the database. The view level of abstraction exists to simplify their interaction with the system. The system may provide many views for the same database.\nLayered architecture.\nThe ability to provide a design of different levels of abstraction can\nSystems design and business process design can both use this. Some design processes specifically generate designs that contain various levels of abstraction.\nLayered architecture partitions the concerns of the application into stacked groups (layers).\nIt is a technique used in designing computer software, hardware, and communications in which system or network components are isolated in layers so that changes can be made in one layer without affecting the others.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "60492", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=60492", "title": "Abstract machine", "text": "Theoretical computer used for defining a model of computation\nIn computer science, an abstract machine is a theoretical model that allows for a detailed and precise analysis of how a computer system functions. It is similar to a mathematical function in that it receives inputs and produces outputs based on predefined rules. Abstract machines vary from literal machines in that they are expected to perform correctly and independently of hardware. Abstract machines are \"machines\" because they allow step-by-step execution of programs; they are \"abstract\" because they ignore many aspects of actual (hardware) machines. A typical abstract machine consists of a definition in terms of input, output, and the set of allowable operations used to turn the former into the latter. They can be used for purely theoretical reasons as well as models for real-world computer systems. In the theory of computation, abstract machines are often used in thought experiments regarding computability or to analyse the complexity of algorithms. This use of abstract machines is fundamental to the field of computational complexity theory, such as with finite state machines, Mealy machines, push-down automata, and Turing machines.\nClassification.\nAbstract machines are typically categorized into two types based on the quantity of operations they can execute simultaneously at any given moment: deterministic abstract machines and non-deterministic abstract machines. A deterministic abstract machine is a system in which a particular beginning state or condition always yields the same outputs. There is no randomness or variation in how inputs are transformed into outputs. In contrast, a non-deterministic abstract machine can provide various outputs for the same input on different executions. Unlike a deterministic algorithm, which gives the same result for the same input regardless of the number of iterations, a non-deterministic algorithm takes various paths to arrive to different outputs. Non-deterministic algorithms are helpful for obtaining approximate answers when deriving a precise solution using a deterministic approach is difficult or costly.\nTuring machines, for example, are some of the most fundamental abstract machines in computer science. These machines conduct operations on a tape (a string of symbols) of any length. Their instructions provide for both modifying the symbols and changing the symbol that the machine\u2019s pointer is currently at. For example, a rudimentary Turing machine could have a single command, \"convert symbol to 1 then move right\", and this machine would only produce a string of 1s. This basic Turing machine is deterministic; however, nondeterministic Turing machines that can execute several actions given the same input may also be built.\nImplementation.\nAny implementation of an abstract machine in the case of physical implementation (in hardware) uses some kind of physical device (mechanical or electronic) to execute the instructions of a programming language. An abstract machine, however, can also be implemented in software or firmware at levels between the abstract machine and underlying physical device. \nProgramming language implementation.\nAn abstract machine is, intuitively, just an abstraction of the idea of a physical computer. For actual execution, algorithms must be properly formalised using the constructs offered by a programming language. This implies that the algorithms to be executed must be expressed using programming language instructions. The syntax of a programming language enables the construction of programs using a finite set of constructs known as instructions. Most abstract machines share a program store and a state, which often includes a stack and registers. In digital computers, the stack is simply a memory unit with an address register that can count only positive integers (after an initial value is loaded into it). The address register for the stack is known as a stack pointer because its value always refers to the top item on the stack. The program consists of a series of instructions, with a stack pointer indicating the next instruction to be performed. When the instruction is completed, a stack pointer is advanced. This fundamental control mechanism of an abstract machine is also known as its execution loop. Thus, an abstract machine for a programming language is any collection of data structures and algorithms capable of storing and running programs written in the programming language. It bridges the gap between the high level of a programming language and the low level of an actual machine by providing an intermediate language step for compilation. An abstract machine's instructions are adapted to the unique operations necessary to implement operations of a certain source language or set of source languages.\nImperative languages.\nIn the late 1950s, the Association for Computing Machinery (ACM) and other allied organisations developed many proposals for Universal Computer Oriented Language (UNCOL), such as Conway's machine. The UNCOL concept is good, but it has not been widely used due to the poor performance of the generated code. In many areas of computing, its performance will continue to be an issue despite the development of the Java Virtual Machine in the late 1990s. Algol Object Code (1964), P4-machine (1976), UCSD P-machine (1977), and Forth (1970) are some successful abstract machines of this kind.\nObject-oriented languages.\nAbstract machines for object-oriented programming languages are often stack-based and have special access instructions for object fields and methods. In these machines, memory management is often implicit performed by a garbage collector (memory recovery feature built into programming languages). Smalltalk-80 (1980), Self (1989), and Java (1994) are examples of this implementation. \nString processing languages.\nA string processing language is a computer language that focuses on processing strings rather than numbers. There have been string processing languages in the form of command shells, programming tools, macro processors, and scripting languages for decades. Using a suitable abstract machine has two benefits: increased execution speed and enhanced portability. Snobol4 and ML/I are two notable instances of early string processing languages that use an abstract machine to gain machine independence.\nFunctional programming languages.\nThe early abstract machines for functional languages, including the SECD machine (1964) and Cardelli's Functional Abstract Machine (1983), defined strict evaluation, also known as eager or call-by-value evaluation, in which function arguments are evaluated before the call and precisely once. Recently, the majority of research has been on lazy (or call-by-need) evaluation, such as the G-machine (1984), Krivine machine (1985), and Three Instruction Machine (1986), in which function arguments are evaluated only if necessary and at most once. One reason is because effective implementation of strict evaluation is now well-understood, therefore the necessity for an abstract machine has diminished.\nLogical languages.\nPredicate calculus (first order logic) is the foundation of logic programming languages. The most well-known logic programming language is Prolog. The rules in Prolog are written in a uniform format known as universally quantified 'Horn clauses', which means to begin the calculation that attempts to discover a proof of the objective. The Warren Abstract Machine WAM (1983), which has become the de facto standard in Prolog program compilation, has been the focus of most study. It provides special purpose instructions such as data unification instructions and control flow instructions to support backtracking (searching algorithm).\nStructure.\nA generic abstract machine is made up of a memory and an interpreter. The memory is used to store data and programs, while the interpreter is the component that executes the instructions included in programs. \nThe interpreter must carry out the operations that are unique to the language it is interpreting. However, given the variety of languages, it is conceivable to identify categories of operations and an \"execution mechanism\" shared by all interpreters. The interpreter's operations and accompanying data structures are divided into the following categories:\nProcessing primitive data.\nAn abstract machine must contain operations for manipulating primitive data types such as strings and integers. For example, integers are nearly universally considered a basic data type for both physical abstract machines and the abstract machines used by many programming languages. The machine carries out the arithmetic operations necessary, such as addition and multiplication, within a single time step.\nSequence control.\nOperations and structures for \"sequence control\" allow controlling the execution flow of program instructions. When certain conditions are met, it is necessary to change the typical sequential execution of a program. Therefore, the interpreter employs data structures (such as those used to store the address of the next instruction to execute) that are modified by operations distinct from those used for data manipulation (for example, operations to update the address of the next instruction to execute).\nControlling data transfers.\nData transfer operations are used to control how operands and data are transported from memory to the interpreter and vice versa. These operations deal with the store and the retrieval order of operands from the store.\nMemory management.\nMemory management is concerned with the operations performed in memory to allocate data and applications. In the abstract machine, data and programmes can be held indefinitely, or in the case of programming languages, memory can be allocated or deallocated using a more complex mechanism.\nHierarchies.\nAbstract machine hierarchies are often employed, in which each machine uses the functionality of the level immediately below and adds additional functionality of its own to meet the level immediately above. A hardware computer, constructed with physical electronic devices, can be added at the most basic level. Above this level, the abstract microprogrammed machine level may be introduced. The abstract machine supplied by the operating system, which is implemented by a program written in machine language, is located immediately above (or directly above the hardware if the firmware level is not there). On the one hand, the operating system extends the capability of the physical machine by providing higher-level primitives that are not available on the physical machine (for example, primitives that act on files). The host machine is formed by the abstract machine given by the operating system, on which a high-level programming language is implemented using an intermediary machine, such as the Java Virtual machine and its byte code language. The level given by the abstract machine for the high-level language (for example, Java) is not usually the final level of hierarchy. At this point, one or more applications that deliver additional services together may be introduced. A \"web machine\" level, for example, can be added to implement the functionalities necessary to handle Web communications (communications protocols or HTML code presentation). The \"Web Service\" level is located above this, and it provides the functionalities necessary to make web services communicate, both in terms of interaction protocols and the behaviour of the processes involved. At this level, entirely new languages that specify the behaviour of so-called \"business processes\" based on Web services may be developed (an example is the Business Process Execution Language). Finally, a specialised application can be found at the highest level (for example, E-commerce) which has very specific and limited functionality.\nJan van Leeuwen, ed. \"Handbook of Theoretical Computer Science. Volume A: Algorithms and Complexity\", The MIT PRESS/Elsevier, 1990. (volume A). QA 76.H279 1990\""}
{"id": "60493", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=60493", "title": "Abstraction (philosophy)", "text": ""}
{"id": "60494", "revid": "62", "url": "https://en.wikipedia.org/wiki?curid=60494", "title": "Extict", "text": ""}
{"id": "60495", "revid": "44342819", "url": "https://en.wikipedia.org/wiki?curid=60495", "title": "Extinct", "text": ""}
{"id": "60496", "revid": "4373810", "url": "https://en.wikipedia.org/wiki?curid=60496", "title": "194 BC", "text": "Calendar year\n \nYear 194 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Africanus and Longus (or, less frequently, year 560 \"Ab urbe condita\"). The denomination 194 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nKorea.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60497", "revid": "49862160", "url": "https://en.wikipedia.org/wiki?curid=60497", "title": "200 BC", "text": "Calendar year\nYear 200 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Maximus and Cotta (or, less frequently, year 554 \"Ab urbe condita\"). The denomination 200 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy topic.\nAstronomy.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60498", "revid": "48371088", "url": "https://en.wikipedia.org/wiki?curid=60498", "title": "201 BC", "text": "Calendar year\n \nYear 201 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Lentulus and Paetus (or, less frequently, year 553 \"Ab urbe condita\"). The denomination 201 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nChina.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60499", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=60499", "title": "204 BC", "text": "Calendar year\n \nYear 204 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Cethegus and Tuditanus (or, less frequently, year 550 \"Ab urbe condita\"). The denomination 204 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nChina.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60500", "revid": "45595768", "url": "https://en.wikipedia.org/wiki?curid=60500", "title": "203 BC", "text": "Calendar year\n \nYear 203 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Caepio and Geminus (or, less frequently, year 551 \"Ab urbe condita\"). The denomination 203 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nChina.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60501", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=60501", "title": "199 BC", "text": "Calendar year\n \nYear 199 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Lentulus and Tappulus (or, less frequently, year 555 \"Ab urbe condita\"). The denomination 199 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nRoman Republic.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60502", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=60502", "title": "1599 BC", "text": ""}
{"id": "60503", "revid": "33839581", "url": "https://en.wikipedia.org/wiki?curid=60503", "title": "206 BC", "text": "Calendar year\n \nYear 206 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Philo and Metellus (or, less frequently, year 548 \"Ab urbe condita\"). The denomination 206 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nChina.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60504", "revid": "27417341", "url": "https://en.wikipedia.org/wiki?curid=60504", "title": "205 BC", "text": "Calendar year\n \nYear 205 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Scipio and Dives (or, less frequently, year 549 \"Ab urbe condita\"). The denomination 205 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nNorthern Asia.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60505", "revid": "125972", "url": "https://en.wikipedia.org/wiki?curid=60505", "title": "207 BC", "text": "Calendar year\n \nYear 207 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Nero and Salinator (or, less frequently, year 547 \"Ab urbe condita\"). The denomination 207 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nChina.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60506", "revid": "25082147", "url": "https://en.wikipedia.org/wiki?curid=60506", "title": "208 BC", "text": "Calendar year\n \nYear 208 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Marcellus and Crispinus (or, less frequently, year 546 \"Ab urbe condita\"). The denomination 208 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nChina.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60507", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=60507", "title": "209 BC", "text": "Calendar year\n \nYear 209 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Verrucosus and Flaccus (or, less frequently, year 545 \"Ab urbe condita\"). The denomination 209 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nCentral Asia.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60508", "revid": "51067389", "url": "https://en.wikipedia.org/wiki?curid=60508", "title": "Pinball", "text": "Arcade entertainment machine\nPinball games are a family of games in which a ball is propelled into a specially designed table where it bounces off various obstacles, scoring points either en-route or when it comes to rest. Historically the board was studded with nails called 'pins' and had hollows or pockets which scored points if the ball came to rest in them. Today, pinball is most commonly an arcade game in which the ball is fired into a specially designed cabinet known as a pinball machine, hitting various lights, bumpers, ramps, and other targets depending on its design.\nThe game's object is generally to score as many points as possible by hitting these targets and making various shots with flippers before the ball is lost. Most pinball machines use one ball per turn, except during special multi-ball phases, and the game ends when the ball(s) from the last turn are lost. The biggest pinball machine manufacturers historically include Bally Manufacturing, Gottlieb, Williams Electronics and Stern Pinball.\nCurrently active pinball machine manufacturers include Stern Pinball, Jersey Jack Pinball, American Pinball, Chicago Gaming Company, Pinball Brothers, Dutch Pinball, Spooky Pinball and Multimorphic, Inc., as well as several smaller boutique manufacturers.\nHistory.\nThe history of pinball machines varies by the source. These machines definitely arrived in recognizable form prior to World War II. The opinions on the relevance of the earlier prototypes varies depending on the definition of the pinball machine, for example:\nPre-modern: Development of outdoor and tabletop ball games.\nThe origins of pinball are intertwined with the history of many other games. Games played outdoors by rolling balls or stones on a grass course, such as bocce or bowls, eventually evolved into various local ground billiards games played by hitting the balls with sticks and propelling them at targets, often around obstacles. Croquet, golf and pall-mall eventually derived from ground billiards variants.\nThe evolution of outdoor games finally led to indoor versions that could be played on a table, such as billiards, or on the floor of a pub, like bowling and shuffleboard. The tabletop versions of these games became the ancestors of modern pinball.\nLate 18th century: Spring launcher invented.\nIn France, during the long 1643\u20131715 reign of Louis XIV, billiard tables were narrowed, with wooden pins or skittles at one end of the table, and players would shoot balls with a stick or cue from the other end, in a game inspired as much by bowling as billiards. Pins took too long to reset when knocked down, so they were eventually fixed to the table, and holes in the table's bed became the targets. Players could ricochet balls off the pins to achieve the more challenging scorable holes. A standardized version of the game eventually became known as bagatelle.\nSomewhere between the 1750s and 1770s, the bagatelle variant \"\", or Japanese billiards in English, was invented in Western Europe, despite its misnomer. Also called \"Stosspudel\", it used thin metal pins and replaced the cue at the player's end of the table with a coiled spring and a plunger. The player shot balls up the inclined playfield toward the scoring targets using this plunger, a device that remains in use in pinball to this day, and the game was also directly ancestral to pachinko.\n1869: Spring launchers become mainstream.\nIn 1869, British inventor Montague Redgrave settled in the United States and manufactured bagatelle tables in Cincinnati, Ohio. In 1871 Redgrave was granted U.S. Patent #115,357 for his \"Improvements in Bagatelle\", another name for the spring launcher that was first introduced in \"\". The game also shrank in size to fit atop a bar or counter. The balls became marbles and the wickets became small metal pins. Redgrave's popularization of the spring launcher and innovations in game design (playfield bells) are acknowledged as the birth of pinball in its modern form. The Redgrave \"Bagatelle\" was produced until 1927.\n1931: Coin operation introduced.\nBy the 1930s, manufacturers were producing coin-operated versions of bagatelles, now known as \"marble games\" or \"pin games\". The table was under glass and used Montague Redgrave's plunger device to propel the ball into the upper playfield. In January of 1931 \"Whiffle\" was introduced in Youngstown, Ohio. The \"Whiffle\" is referred to as the birth of pinball by the IPDB. Later, that same year, David Gottlieb's \"Baffle Ball\" became the first major hit of the coin-operated era. Selling for $17.50, the game dispensed five, seven, or ten balls for a penny. At its peak, Gottlieb produced 400 \"Baffle Ball\" machines per day and establishing the company as the first major manufacturer of pinball machines.\nIn 1932, Gottlieb distributor Raymond Moloney found it hard to obtain more Baffle Ball units to sell. In his frustration he founded Lion Manufacturing to produce a game of his design, \"Ballyhoo\", named after a popular magazine. The game became a smash hit. Its larger playfield and ten pockets made it more challenging than \"Baffle Ball\", selling 50,000 units in 7 months. Moloney eventually changed the name of his company to Bally to reflect the success of this game. These early machines were relatively small, mechanically simple and designed to sit on a counter or bar top. 1932 also saw the earliest version of flippers used on a pinball machine with the Hercules Novelty Company's \"Double-Shuffle.\" Rock-Ola also experimented with player-controlled pinball; their 1932 \"Juggle Ball\" had a rod that players could use to manipulate the ball's direction.\n1933: Electrification and active bumpers introduced.\nThe 1930s saw major advances in pinball design with the introduction of electrification. Pacific Amusements in Los Angeles, California produced \"Contact\" in 1933, which had an electrically powered solenoid to propel the ball out of a bonus hole in the middle of the playfield. Another solenoid rang a bell to reward the player. \"Contact\"'s designer, Harry Williams, eventually formed his own company, Williams Manufacturing, in 1944. Other manufacturers quickly followed suit with similar features. Electric lights soon became standard on all pinball games, to attract players.\nBy the end of 1932, approximately 150 companies manufactured pinball machines, most of them in Chicago, Illinois. Chicago has been the center of pinball manufacturing ever since. Competition was strong, and by 1934, only 14 companies remained.\nDuring World War II, all major manufacturers of coin-operated games turned to manufacturing for the war effort. Some, like Williams, bought old games from operators and refurbished them, adding new artwork with a patriotic theme. At the end of the war, a generation of Americans looked for amusement in bars and malt shops, and pinball saw another golden age. Improvements such as the tilt-sensing mechanism and the awarding of free games (replays) appeared.\n1947: Flippers widely introduced.\nGottlieb's \"Humpty Dumpty\", introduced in 1947, was the first game to add electromechanical player-controlled flippers to keep the ball in play longer. The low-power flippers required three pairs around the playfield to get the ball to the top.\n\"Triple Action\" was the first game to feature just two flippers at the bottom of the playfield. Unlike in modern machines, the flippers faced outwards. These flippers were made more powerful by the addition of a DC (direct current) power supply. These innovations were some of many by designer Steve Kordek.\nThe first game to feature the familiar dual-inward-facing-flipper design was Gottlieb's \"Just 21\" released in January 1950. However, the flippers were rather far apart to allow for a turret ball shooter at the bottom center of the playfield. Another 1950 Gottlieb game, \"Spot Bowler\", was the first with inward-facing flippers placed close together.\nThe post-war era was dominated by Gottlieb. Game designers Wayne Neyens and Ed Krynski, with artist Leroy Parker, produced games that collectors consider some of the best classic pinball machines.\n1970s: Solid-state electronics and digital displays introduced.\nThe introduction of microprocessors brought pinball into the realm of electronic gaming. The electromechanical relays and scoring reels that drove games in the 1950s and 1960s were replaced in the 1970s with circuit boards and digital displays.\nIn late 1973 the pinball industry, including Ross Schier of Bally, was skeptical about the use of microprocessors in pinball machines. Despite this, Dave Nutting Associates began to work under contract from Bally on the possibility in the last few weeks of 1973.\nCyan Engineering under Atari began work on an electronic pinball project around February 1974.\nThe first advert suggesting use of a microprocessor in a pinball machine was published by Intel in March 1974.\nIn May or June 1974 Atari had an event for employees and their families where a converted Bally \"El Toro\" (1972) machine was on display which had been attempted to run on a microprocessor, but didn\u2019t function properly. By the summer of 1974 this machine was working as intended, and left beside a company cafeteria where it was played. This also used an Intellec-4 which was in cart beside it. Later in 1974 five Bally \"Delta Queen\"\u2019s (1974) were similarly converted and the first one was shown in October/ November 1974 at the MOA trade show, with a fully working version shown at a conference in April 1975.\nDave Nutting Associates acquired a development kit for the Intel 4040 microprocessor and used a Bally \"Flicker\" (1974) pinball machine to experiment with. The circuit board used inside this machine was dubbed the \u201cBally brain\u201d. A clock was reversed engineered for use as a 6 segment scoring display. The game was programmed using about 500 lines of assembly code. On September 26, 1974, they demonstrated this table to Bally running using a microprocessor, the implementation of which was subsequently patented. Bally began to develop their own version of this, converting an EM \"Boomerang\" (1975) which lead to them filing a patent in November 1975, 6 months later than the one filed by David Nutting. Bally later acquired Dave Nutting Associates and by the time they were granted in 1978 and 1980 held both patents. Universal Research Laboratories manufactured circuit boards for Bally pinball machines, and then reverse engineered these for Stern (who bought Universal Research Laboratories in October 1977), who were then sued by Bally. Stern agreed a license with Bally for this technology, and by September 1981 had paid $700,000 in royalties. Bally took legal action against Williams and Gottlieb in 1980 for breeching these patents. As defendants Williams and Gottlieb eventually won the case due to the judge ruling that the invention was \u201cobvious\u201d.\nThe first working pinball machine using a microprocessor is \"Flicker\". Bally soon followed that up with a solid-state version of \"Bow and Arrow\" in the same year with a microprocessor board that was also used in eight other machines through 1978, which included \"Eight Ball\", the machine that held the sales record from 1977 to 1993.\nThe first commercial solid-state (SS) pinball is considered by some to be Mirco Games' \"The Spirit of '76\" (1976), which sold in very limited quantities. At almost the same time Allied Leisure released \"Rock On\" which Roger Sharpe considers to be a hybrid EM/SS game, and the 4 player version \"Dyn O'Mite\" (including and named after Jimmie Walker's catchphrase) had been shown to distributors in April 1976. The first mainstream solid-state game was Bally's \"Freedom\" in December 1976 with Williams' \"Hot Tip\" following 9 months later; all of these games used a Motorola 6800. This new technology led to a boom for Williams and Bally, who attracted more players with games featuring more complex rules, digital sound effects, and speech. Atari released \"The Atarians\" at a similar time to Bally's \"Freedom\", but remained a very minor player in the pinball market, exiting it shortly after.\nThe video game boom of the 1980s signaled the end of the boom for pinball. Arcades replaced rows of pinball machines with video games like 1978's \"Space Invaders\", 1979's \"Asteroids\", 1980's \"Pac-Man\", and 1981's \"Galaga\". These earned significantly greater profits than the pinball machines of the day while simultaneously requiring less maintenance. Bally, Williams, and Gottlieb continued to make pinball machines while also manufacturing video games in much higher numbers.\nMany of the larger companies were acquired by, or merged with, other companies. Chicago Coin was purchased by the Stern family in 1977, who brought the company into the digital era as Stern Enterprises, which closed its doors in the mid-1980s. Bally exited the pinball business in 1988 and sold their assets to Williams, who subsequently used the Bally trademark from then on for about half of their pinball releases.\nWhile the video game craze of the late 1970s and early 1980s dealt a severe blow to pinball revenue, it sparked the industry's creative talents. All companies involved tried to take advantage of the new solid-state technology to improve player appeal of pinball and win back former players from video games. Some of this creativity resulted in landmark designs and features still present today. Some of these include speech, such as Williams' \"Gorgar\"; ramps for the ball to travel around, such as Williams' \"Space Shuttle\"; \"multiball\", used on Williams' \"Firepower\"; multi-level games like Gottlieb's \"Black Hole\" and Williams' \"Black Knight\"; and blinking chase lights, as used on Bally's \"Xenon\". Although these novel features did not win back players as the manufacturers had hoped, they changed players' perception of pinball for decades.\n1980s and 1990s: Pinball in the digital age.\nDuring the 1980s, pinball manufacturers navigated technology changes while going through changes of ownership and mergers: Gottlieb was sold to Premier Technologies, and Bally merged with Williams. The video game crash of 1983 made the manufacturers refocus on their pinball sales. A trend started of pinball becoming increasingly elaborate to use more computing resources, following video games.\nGames in the latter half of the 1980s such as \"High Speed\" started incorporating full soundtracks, elaborate light shows and backbox animations - a radical change from the previous decade's electromechanical games. Although pinball continued to compete with video games in arcades, pinball held a premium niche, since the video games of the time could not reproduce an accurate pinball experience.\nBy the first years of the 1990s, pinball had made a strong comeback and saw new sales highs. Some new manufacturers entered the field, such as Capcom Pinball and Alvin G. and Company, founded by Alvin Gottlieb, son of David Gottlieb. Gary Stern, the son of Williams co-founder Sam Stern, founded Data East Pinball with funding from Data East Japan.\nThe games from Williams now dominated the industry, with complicated mechanical devices and more elaborate display and sound systems attracting new players to the game. Licensing popular movies and icons of the day became a staple for pinball, with Bally/Williams' \"The Addams Family\" from 1992 hitting a modern sales record of 20,270 machines. In 1994, Williams commemorated this benchmark with a limited edition of 1,000 \"Addams Family Gold\" pinball machines, featuring gold-colored trim and updated software with new game features. Other notable popular licenses included ' and '. Expanding markets in Europe and Asia helped fuel the revival of interest. Pat Lawlor was a designer, working for Williams until their exit from the industry in 1999. About a year later, Lawlor returned to the industry, starting his own company, working in conjunction with Stern Pinball to produce new games.\nThe end of the 1990s saw another downturn in the industry, with Gottlieb, Capcom, and Alvin G. closing by the end of 1996. Data East's pinball division was acquired by Sega and became Sega Pinball in 1994. By 1997, there were two companies left: Sega Pinball and Williams. In 1999, Sega sold their pinball division to Gary Stern, President of Sega Pinball at the time, who called his company Stern Pinball.\nBy this time, Williams games rarely sold more than 4,000 units. In 1999, Williams attempted to revive sales with the Pinball 2000 line of games, merging a video display into the pinball playfield. The reception was initially good with \"Revenge from Mars\" selling well over 6,000 machines, but short of the 10,000-plus production runs for releases just six years earlier. The next Pinball 2000 game, \"Star Wars Episode I\", sold only a little over 3,500 machines.\nWilliams exited the pinball business on October 25, 1999 to focus on making gaming equipment for casinos, which was more profitable. They licensed the rights to reproduce Bally/Williams parts to Illinois Pinball and reproduce full-sized machines to The Pinball Factory. Stern Pinball remained the only manufacturer of original pinball machines until 2013, when Jersey Jack Pinball started shipping \"The Wizard of Oz\". Most members of the design teams for Stern Pinball are former employees of Williams.\nAmid the 1990s closures, virtual pinball simulations, marketed on computers and home consoles, had become high enough in quality for serious players to take notice: these video versions of pinball such as \"Epic Pinball\", \"Full Tilt! Pinball\" and the Pro Pinball series found marketplace success and lasting fan interest, starting a new trend for realistic pinball simulation. This market existed largely independently from the physical pinball manufacturers, and relied upon original designs instead of licenses until the 2000s.\n2000s and beyond: Revival.\nAfter most pinball manufacturers' closure in the 1990s, smaller independent manufacturers started appearing in the early 2000s.\nIn November 2005, The Pinball Factory (TPF) in Melbourne, Australia, announced that they would be producing a new \"Crocodile Hunter\"-themed pinball machine under the Bally label. With the death of Steve Irwin, it was announced that the future of this game was uncertain. In 2006, TPF announced that they would be reproducing two popular 1990s era Williams machines, \"Medieval Madness\" and \"Cactus Canyon\". TPF, however, was unable to make good on its promises to produce new machines, and in October 2010 transferred its Williams Electronics Games licenses as well as its pinball spare parts manufacturing and distribution business to Planetary Pinball Supply Inc, a California distributor of pinball replacement parts.\nIn 2006, Illinois pinball company PinBall Manufacturing Inc. produced 178 reproductions of Capcom's \"Big Bang Bar\" for the European and US markets.\nIn 2010, MarsaPlay in Spain manufactured a remake of Inder's original \"Canasta\" titled \"New Canasta\", which was the first game to include a liquid-crystal display (LCD) screen in the backbox.\nIn 2013, Jersey Jack Pinball released \"The Wizard of Oz\" pinball machine, based on the 1939 film. It is the first pinball machine manufactured in the US with a large color display (LCD) in the backbox, the first widebody pinball machine since 1994 and the first new US pinball machine not made by Stern Pinball since 2001. This game was followed by several additional pinball machines, incorporating both existing media properties and original themes.\nIn 2013, the Chicago Gaming Company announced the creation of a remake of \"Medieval Madness\". This was later followed by three additional remakes of earlier machines. They announced their first original title, \"Pulp Fiction\", based on the film \"Pulp Fiction\", in 2023.\nIn 2014, the new pinball manufacturer Spooky Pinball released their first game, \"America's Most Haunted\". This was followed by a few more themed, original, and contracted titles.\nIn 2015, the new British pinball manufacturer Heighway Pinball released the racing themed pinball machine \"Full Throttle\". The game has an LCD screen for scores, info, and animations located in the playfield surface at player's eye view. The game was designed with modularity in mind so that the playfield and artwork could be swapped out for future game titles. Heighway Pinball's second title, \"Alien\", was released in 2017 and was based on the \"Alien\" and \"Aliens\" films. Due to internal company issues, Heighway Pinball ceased manufacturing operations and closed its doors in April 2018. The company assets were obtained by the Scandinavian company named Pinball Brothers, and in 2020, they officially announced the remake of the \"Alien\" pinball machine. Pinball Brothers released additional game titles, including \"Queen\" revealed in 2021 (based on the rock band Queen, and \"ABBA\" in 2024 (based on the Swedish rock band ABBA).\nIn 2016, Dutch Pinball, based in the Netherlands, released their first game \"The Big Lebowski\", based on the 1998 film, \"The Big Lebowski\". \nIn 2017, Multimorphic began shipping its pinball machine platform after several years of development. It is a modular design where different games can be swapped into the cabinet. It also has a large interactive display as the playfield surface, which differs from all prior pinball machines traditionally made of plywood and embedded with translucent plastic inserts for lighting. Multimorphic released several more unlicensed titles, and in 2022, released their first licensed game: \n\"Weird Al's Museum of Natural Hilarity\" (based on parody music artist \"Weird Al\" Yankovic). This was followed by additional licensed titles: \"The Princess Bride\" in 2024 (based on the movie of the same name), and \"Portal\" in 2025 (based on the Valve video game series of the same name).\nIn 2017, American Pinball released its first production game, \"Houdini\", followed by \"Oktoberfest\" (2018), \"Hot Wheels\" (2020), \"Legends of Valhalla\" (2020), \"Galactic Tank Force\" (2023), and \"Barry O's BBQ Challenge\" (2024). \"Barry O's BBQ Challenge\" was a tribute to and the final game designed by pinball designer Barry Oursler, who passed in 2022.\nIn 2023, Barrels of Fun released its first production game, Jim Henson's \"Labyrinth\". Barrels of Fun followed with \"Dune\" in 2025, based on the 2021 Dune film and the .\nIn 2024, Turner Pinball began production on their first game named \"Ninja Eclipse\", and in 2025 revealed their second game named \"Merlin's Arcade\".\nIn 2024, Pedretti Gaming released a remake of \"\", and incorporated an LCD display into the backbox, as well as a number of other technological updates to the original game.\nRelation to gambling.\nPinball machines, like many other mechanical games, were sometimes used as gambling devices. Some pinball machines, such as Bally's \"bingos\", featured a grid on the backglass scoring area with spaces corresponding to targets or holes on the playfield. Free games could be won if the player could get the balls to land in a winning pattern; however, doing this was nearly random, and a common use for such machines was for gambling. Other machines allowed players to win and accumulate large numbers of \"free games\" which could then be cashed out for money with the location owner.\nLater, this type of feature was discontinued to legitimize the machines, and to avoid legal problems in areas where awarding free games was considered illegal, some games, called Add-A-Ball, did away with the free game feature, instead giving players extra balls to play, between 5 and 25 in most cases. These extra balls were indicated via lighted graphics in the backglass or by a ball count wheel, but in some areas that was disallowed, and some games were shipped with a sticker to cover the counters.\nPinball was banned beginning in the early 1940s until 1976 in New York City. New York mayor Fiorello La Guardia was responsible for the ban, believing that it robbed school children of their hard-earned nickels and dimes. La Guardia spearheaded major raids throughout the city, collecting thousands of machines. The mayor participated with police in destroying machines with sledgehammers before dumping the remnants into the city's rivers.\nThe ban ended when Roger Sharpe, a star witness for the AMOA \u2013 Amusement and Music Operators Association, testified in April 1976 before a committee in a Manhattan courtroom that pinball games had become games of skill and were not games of chance, which are more closely associated with gambling. He began to play one of two games set up in the courtroom, and \u2013 in a move he compares to Babe Ruth's home run in the 1932 World Series \u2013 called out precisely what he was going to shoot for, and then proceeded to do so. Astonished committee members reportedly voted to remove the ban, which was followed in other cities. Sharpe reportedly acknowledges, in a self-deprecating manner, his courtroom shot was by sheer luck although there was admittedly skill involved in what he did.\nLike New York, Los Angeles banned pinball machines in 1939. The ban was overturned by the Supreme Court of California in 1974 because (1) if pinball machines were games of chance, the ordinance was preempted by state law governing games of chance in general, and (2) if they were games of skill, the ordinance was unconstitutional as a denial of the equal protection of the laws. Although it was rarely enforced, Chicago's ban on pinball lasted three decades and ended in 1977. Philadelphia and Salt Lake City also had similar bans. Regardless of these events, some towns in the United States still have such bans on their books; the town of Kokomo, Indiana lifted its ordinance banning pinball in December 2016,and although the law is no longer enforced, South Carolina still bans minors under 18 from playing pinball machines (SC-63-19-2430).\nComponents.\nCabinet.\nThe cabinet of a pinball machine is the (traditionally wooden) frame usually shaped like a box, with the playfield laid inside.\nBackbox/head.\nThe 'backbox', 'head', or 'lightbox' is the vertical box atop the cabinet opposite the player's position. It usually consists of a wooden box with colorful graphics on the side and a large 'backglass' in the front. The backglass usually has very stylized graphics related to the game.\nBackglass.\nThe \"backglass\" is a vertical graphic panel mounted on the front of the backbox. The backglass contains the name of the machine, graphics, and score displays (lights, mechanical wheels, an LED display, or a dot-matrix display depending on the era). Some backglasses include a mechanical device tied to gameplay, such as \"NBA Fastbreak\", which featured a miniature basketball and hoop. For older games, the backglass image is screen printed in layers on the reverse side of a piece of glass; in more recent games, the image is imprinted into a translite.\nPlayfield.\nThe \"playfield\" is a planar surface inclined upward, usually at six and a half degrees, away from the player, and includes multiple targets and scoring objectives. Some operators intentionally extend threaded levelers on the rear legs and/or shorten or remove the levelers on the front legs to create additional incline in the playfield, making the ball move faster and harder to play.\nPlunger.\nThe \"plunger\" is a spring-loaded rod with a small handle, used to propel the ball into the playfield. The player can control the amount of force used for launching by pulling the plunger a certain distance (thus changing the spring compression). This is often used for a \"skill shot\", in which a player attempts to launch a ball so that it exactly hits a specified target. Once the ball is in motion in the main area of the playfield, the plunger is not used again until another ball must be brought onto the playfield. An electronically controlled launcher is sometimes substituted for the plunger in modern machines.\nThe shape of the ball launch button that replaces the plunger may be modified to fit the aesthetics of a particular game's theme, such as being made to look like the trigger of a gun in a game with a military or action-hero theme.\nFlippers.\nThe \"flippers\" are one or more mechanically or electromechanically (solenoid) controlled levers, roughly in length, used for redirecting the ball up the playfield. They are the main control that the player has over the ball, usually by corresponding pushbuttons on the cabinet's sides. They can primarily be switched fully on, sometimes with two different strengths for thrusting the flipper up and for holding it in position. Careful timing of this limited positional control allows the player to direct the ball in a range of directions with various levels of velocity and spin. With the flippers, the player attempts to move the ball to hit various types of scoring targets, and to keep the ball from disappearing off the bottom of the playfield.\nThe very first pinball games appeared in the early 1930s and did not have flippers. After launching the ball simply proceeded down the playfield, directed by static nails (or \"pins\") to one of several scoring areas. These pins gave the game its name. In 1947, the first mechanical flippers appeared on Gottlieb's \"Humpty Dumpty\" and by the early 1950s, the two-flipper configuration at the bottom above the center drain had become standard.\nSome pinball models have a third or fourth flipper. A few later machines have flippers that the machine's software could operate independently of the flipper button. During \"Thing Flips\" on \"The Addams Family\" pinball machine, the upper-left flipper automatically triggers a brief moment after the ball passes an optical sensor just above the flipper. Very few machines came with curve-shaped banana flippers.\nThe introduction of flippers ushered in the \"golden age\" of pinball, where the fierce competition between the various pinball manufacturers led to constant innovation in the field. Various types of stationary and moving targets were added, spinning scoring reels replaced games featuring static scores lit from behind. Multiplayer scores were added soon after, and then bells and other noise-makers, all of which began to make pinball less a game and more of an experience. The flippers have loaned pinball its common name in many languages, where the game is known mainly as \"flipper\".\nBumpers.\n\"Bumpers\" are round knobs that, when hit, will actively push the ball away. There is also an earlier variety of bumper (known as a \"dead bumper\" or \"passive bumper\") that does not propel the ball away; most bumpers on machines built since the 1960s are active bumpers, variously called \"pop bumpers\", \"thumper bumpers\", \"jet bumpers\", or \"turbo bumpers\". Most recent games include a set of pop bumpers, usually three, sometimes more or fewer depending on the designer's goals. Bumpers predate flippers, and active bumpers served to add interest and complexity to older games.\nPop bumpers are operated by a switch connected to a ring surrounding the bottom circumference of the bumper that is suspended several millimeters above the playfield surface. When the ball rolls over this ring and forces one side of it down, a switch is closed that activates the bumper's solenoid. This pulls down a tapered ring surrounding the central post of the bumper that pushes downward and outward on the ball, propelling it away.\nKickers and slingshots.\n\"Kickers\" and \"slingshots\" are rubber pads that propel the ball away upon impact, like bumpers, but are usually a horizontal side of a wall. Every recent pinball machine includes slingshots to the upper left and upper right of the lowest set of flippers; older games used more experimental arrangements. They operate similarly to pop bumpers, with a switch on each side of a solenoid-operated lever arm in a typical arrangement. The switches are closed by ball contact with the rubber on the kicker's face, which activates the solenoid.\nEarly pinball machines typically had full solenoid current passing through trigger switches for all types of solenoids, from kickers to pop bumpers to the flippers themselves. This caused arcing across switch contacts and rapid contact fouling and failure. As electronics were gradually implemented in pinball design, solenoids began to be switched by power transistors under software control to lower switch voltage and current, vastly extend switch service lifetime, and add flexibility to game design.\nThe smaller, lower-powered solenoids were first to be transistorized, followed later by the higher-current solenoids as the price, performance, and reliability of power transistors improved over the years.\nHoles and saucers.\nInitially, holes and saucers worked by using tubes behind the playing field, with a pin at the top to hold the ball for later drops. Another version of the tube uses two spinning wheels to transfer the ball from hole to hole. Newer versions use an electronic track with a carriage or an electromagnet to pull the ball between holes.\nRamps.\nRamps are inclined planes with a gentle enough slope that the ball may travel along it. The player attempts to direct the ball with enough force to make it to the top of the ramp and down the other side. If the player succeeds, a \"ramp shot\" has been made. Ramps frequently end so that the ball goes to a flipper so one can make several ramp shots in a row. The number of ramp shots scored in a game is often tallied, and reaching certain numbers may lead to various game features. At other times, the ramps will go to smaller \"mini-playfields\" (small playfields, usually raised above the main game surface, with special goals or scoring).\nFeatures.\nPinball games have become increasingly complex. Multiple play modes, multi-level playfields, and even progression through a rudimentary \"plot\" have become common features in recent games. Pinball scoring objectives often require a series of targets to be hit in a particular order. Recent pinball games are distinguished by their requiring strategy and planning for maximum scoring. Players seeking the highest scores are advised to study a game's placard (usually found in the lower-left corner of the playfield) to learn the specific patterns required for advanced features and scoring.\nCommon features in modern pinball games include the following:\nIn the 1990s, game designers often put hidden, recurring images or references in their games, which became known as easter eggs. For example, Williams' designers hid cows in the video displays of the games, and Pat Lawlor placed a red button in the artwork of games he developed. The methods used to find the hidden items usually involved pressing the flipper buttons in a certain order or during specific events. Designers also included hidden messages or in-jokes; one example of this is the phrase \"DOHO\" sometimes seen quickly displayed on the dot matrix displays, a reference to \"Do\"ris \"Ho\", the wife of then-Williams display artist Scott \"Matrix\" Slomiany. DOHO was popularly thought to be an acronym for \"D\"ocumented \"O\"ccurrence of a \"H\"idden \"O\"bject until its true meaning was revealed in a \"PinGame Journal\" article on the subject. The game \"\" went so far as to embed a hidden \"Breakout\"-like game, available only after a complex sequence of events had been accomplished during the game.\nScoring points.\nContact with or manipulation of scoring elements (such as targets or ramps) scores points for the player. Electrical switches embedded in the scoring elements detect contact and relay this information to the scoring mechanism. Older pinball machines used an electromechanical system for scoring wherein a pulse from a switch would cause a complex mechanism composed of relays to ratchet up the score. In later games these tasks have been taken over by semiconductor chips and displays are made on electronic segmented or dot-matrix displays (DMD). The first DMD on a pinball machine was used by \"Checkpoint\" and features also video mode minigames.\nMarsaPlay in Spain manufactured a remake of Inder's original \"Canasta\" titled \"New Canasta\", with an LCD screen in the backbox in 2010.\" The Wizard of Oz\" is the first US pinball machine that used a LCD in the back box. It is used for scoring and mini-games and to display full color videos. Other display innovations on pinball machines include pinball video game hybrids like \"Baby Pac-Man\" in 1982 and \"Granny and the Gators\" in 1984 and the use of a small color video monitor for scoring and minigames in the backbox of the pinball machine \"Dakar\" from manufacturer Mr. Game in 1988 and CGA color monitors in Pinball 2000 in 1999 that uses a Pepper's ghost technique to reflect the monitor in the head of the as well as modifications by the use of ColorDMD that is used to replace the standard mono color DMDs.\nPinball scoring can be peculiar and varies greatly from machine to machine. During the 1930s and the 1940s, lights mounted behind the painted backglasses were used for scoring purposes, making the scoring somewhat arbitrary. Frequently the lights represented scores in the hundreds of thousands. During the 1950s and 1960s when the scoring mechanism was limited to mechanical wheels, high scores were frequently only in the hundreds \"or\" thousands. In an effort to keep with the traditional high scores attained with the painted backglass games, the first pinball machines to use mechanical wheels for scoring, such as \"Army Navy\", allowed the score to reach into the millions by adding a number of permanent zeros to the end of the score.\nThe average score changed again in the 1970s with the advent of electronic displays. Average scores soon began to commonly increase back into tens or hundreds of thousands. Since then, there has been a trend of scoring inflation, with modern machines often requiring scores of over a billion points to win a free game. At the peak of this trend, Williams \"\" and \"Jack-Bot\" have been played into ten billions and Williams \"Johnny Mnemonic\" and Bally/Midway \"Attack from Mars\", have been played into one hundred billion.\nThe 1997 Bally game \"NBA Fastbreak\" which, true to its theme, awards points in terms of a real basketball score: Each successful shot can give from one to three points. Getting a hundred points by the end of a game is considered respectable, which makes it one of the \"lowest\" scoring pinball machines of all time. The inflated scores are the source of one of the Spanish-language names of pinball machines, (\"million machine\").\nSpecial scores.\nPinball designers also entice players with the chance to win a free game or credit. Ways to get a free game might include the following:\nWhen a free game is won, Williams and Bally/Midway machines typically makes a single loud bang, most often with a solenoid that strikes a piece of metal, or the side of the cabinet, with a rod, known as a \"knocker\", or less commonly with loudspeakers. \"Knocking\" is the act of winning a free game when the knocker makes the loud and distinctive noise.\nPlaying techniques.\nThe primary skill of pinball involves application of the proper timing and technique to the operation of the flippers, nudging the playfield when appropriate without tilting, and choosing targets for scores or features. A placard is often placed in a lower corner of the playfield with pricing information and details about game-specific rules and scoring techniques.\nNudging.\nPlayers can influence the movement of the ball by moving or bumping the pinball machine, a technique known as \"nudging\" or \"shaking\".\nThere are tilt mechanisms which guard against excessive manipulation of this sort. The mechanisms generally include:\nWhen any of these sensors is activated, the game registers a \"tilt\" and the lights go out, solenoids for the flippers no longer work, and other playfield systems become inoperative so that the ball can do nothing other than roll down the playfield directly to the drain. A tilt will usually result in forfeiting the end-of-ball bonus points that would have been earned by the player during that ball; the game is automatically over if it is the last ball and the player has no extra ball. Older games would immediately end the ball in play on a tilt.\nModern games give tilt warnings before sacrificing the ball in play. The number of tilt warnings can be adjusted by the operator of the machine. Until recently most games also had a \"slam tilt\" switch which guarded against kicking or slamming the coin mechanism, or for overly aggressive behavior with the machine, which could give a false indication that a coin had been inserted, thereby giving a free game or credit. This feature was taken out by default in Stern SAM System games, but can be added as an option; some other manufacturers omit it entirely. A slam tilt will typically end the current game for all players.\nTrapping.\nPlayers can hold a ball in place with the flipper, giving them more control over where they want to place the ball when they shoot it forward. This is known as \"trapping.\"\nManufacturing process.\nThe assembly of a pinball machine is a complex process and involves several manual steps.\nThe wiring for the game's electronic system is a major effort. A color-coded flexible wiring harness is typically soldered to many lamps, switches and solenoids, and connected with plugs to the main electronic circuit boards in modern machines. Technicians are guided by a set of instructions and templates to ensure all wires (that can have a total length of almost half a mile) are installed properly.\nThe main construction on one hand involves the mounting of mechanical components onto the wooden playfield, such as hammering in anchored metal railing that keeps the balls from exiting the playfield and attachment of plastic parts with nuts and screws. On the other hand, electrical components are installed, like bumpers, slingshots, and sockets for lamps and flashing lights. All of the wiring is fastened to the playfield and big components like speakers, mains transformers or shaker motors are bolted into the bottom of the cabinet. The player-accessible parts like the spring plunger, buttons and the coin door with its mechanics are attached directly to the cabinet.\nAfter successful testing, the playfield is set on hinges into the cabinet. The cabinet of computerized games contains very few parts. On older electromechanical games, the entire floor of the lower box was used to mount custom relays and special scoring switches, making them much heavier. To protect the top of the playfield, tempered glass is slid into side rails and secured with a metal locking bar.\nThe backbox is installed with hinges on modern machines or screws on older games. It contains the scoring displays and electronic circuit boards and is historically covered with a removable, painted, partially transparent, backglass which defined the game's appeal as much as the playfield design and the cabinet art. Since a damaged backglass is hard to restore, newer games use (sometimes optional) plastic translites behind a clear glass.\nOther steps include installation of removable boards with speaker and dot-matrix displays and/or hinged wooden boards with lights and displays. The cabinet and backbox are covered with artwork that was historically sprayed on with stencils and later is applied as full-size decal stickers.\nSolenoids.\nFlipper solenoids contain two coil windings in one package; a short, heavy gage 'power' winding to give the flipper its initial thrust up, and a long, light gage 'hold' winding that uses lower power (and creates far less heat) and essentially just holds the flipper up allowing the player to capture the ball in the inlane for more precise aiming. As the flipper nears the end of its upward travel, a switch under the flipper disconnects the power-winding and leaves only the second sustain winding to hold the flipper up in place. If this switch fails 'open' the flipper will be too weak to be usable, since only the weak winding is available. If it fails 'closed' the coil will overheat and destroy itself, since both windings will hold the flipper at the top of its stroke.\nSolenoids also control pop-bumpers, kickbacks, drop target resets, and many other features on the machine. These solenoid coils contain a single coil winding. The plunger size and wire gage &amp; length are matched to the strength required for each coil to do its work, so some types are repeated throughout the game, some are not.\nAll solenoids and coils used on microprocessor games include a special reverse-biased diode to eliminate a high-voltage pulse of reverse EMF (electromotive force). Without this diode, when the solenoid is de-energized, the magnetic field that was built up in the coil collapses and generates a brief, high-voltage pulse backward into the wiring, capable of destroying the solid-state components used to control the solenoid. Proper wiring polarity must be retained during coil replacement or this diode will act as a dead short, immediately destroying electronic switches. Older electromechanical AC game solenoids do not require this diode, since they were controlled with mechanical switches. However, electromechanical games running on DC do require diodes to protect the rectifier.\nAll but very old games use low DC voltages to power the solenoids and electronics (or relays). Some microprocessor games use high voltages (potentially hazardous) for the score displays. Very early games used low-voltage AC power for solenoids, requiring fewer components, but AC is less efficient for powering solenoids, causing heavier wiring and slower performance. For locations that suffer from low AC wall outlet voltage, additional taps may be provided on the AC transformer in electromechanical games to permit raising the game's DC voltage levels, thus strengthening the solenoids. Microprocessor games have electronic power supplies that automatically compensate for inaccurate AC supply voltages.\nHistorically, pinball machines have employed a central fixed I/O board connected to the primary CPU controlled by a custom microcontroller platform running an in-house operating system. For a variety of reasons that include thermal flow, reliability, vibration reduction and serviceability, I/O electronics have been located in the upper backbox of the game, requiring significant custom wiring harnesses to connect the central I/O board to the playfield devices.\nA typical pinball machine I/O mix includes 16 to 24 outputs for driving solenoids, motors, electromagnets and other mechanical devices in the game. These devices can draw up to 500 W momentarily and operate at voltages up to 50 Vdc. There is also individually controlled lighting that consists of 64 to 96 individually addressable lights. Recently developed games have switched from incandescent bulbs to LEDs. And there is general illumination lighting that comprises two or more higher-power light strings connected and controlled in parallel for providing broad illumination to the playfield and backbox artwork. Additionally, 12 to 24 high-impulse lighting outputs, traditionally incandescent but now LED, provide flash effects within the game. Traditionally, these were often controlled by solenoid-level drivers.\nA game typically includes 64 to 96 TTL-level inputs from a variety of sensors such as mechanical leaf switches, optical sensors and electromagnetic sensors. Occasionally extra signal conditioning is necessary to adapt custom sensors, such as eddy sensors, to the system TTL inputs.\nRecently, some pinball manufacturers have replaced some of the discrete control wiring with standard communication buses. In one case, the pinball control system might include a custom embedded network node bus, a custom embedded Linux-based software stack, and a 48-V embedded power distribution system.\nCustom machines.\nSome hobbyists and small companies modify existing pinball machines or create their own custom pinball machines. Some want, for example, a game with a specific subject or theme that cannot be bought in this form or was never built at all. Some custom games are built by using the programmable P-ROC controller board. Modifications include the use of ColorDMD that is used to replace the standard mono color dot-matrix displays or the addition of features, e.g. figures or other toys.\nA few notable examples of custom pinball machines include a \"Ghostbusters\" theme machine, a \"Matrix\" style game, Bill Paxton Pinball, \"Sonic\", \"Star Fox\", \"Predator\", and Iron man machines.\nData East was one of the few regular pinball companies that manufactured custom pinball games (e.g. for Aaron Spelling, Michael Jordan and the movie \"Richie Rich\"), though these were basically mods of existing or soon to be released pinball machines (e.g. \"Lethal Weapon 3\" or \"The Who's Tommy Pinball Wizard\").\nCompetitions.\nTwo Pinball World Championships were held in the Washington, D.C. area in 1972 and 1973 under the auspices of the World Pinball Association which also published a newsletter carrying results of regional tournaments.\nIn 1974, students at Jersey City State College wanted to make pinball playing a varsity school sport, like football was, so they started a Pinball Club Team to compete against clubs at other schools. They asked two other schools to participate. St. Peter's College took up the challenge, while the other school did not.\nMany pinball leagues have formed, with varying levels of competitiveness, formality and structure. These leagues exist everywhere from the Free State Pinball Association (FSPA) in the Washington, D.C. area to the Tokyo Pinball Organization (TPO) in Japan. In the late 1990s, game manufacturers added messages to some games encouraging players to join a local league, providing website addresses for prospective league players to investigate.\nCompetitive pinball has become increasingly popular in recent years, with the relaunch of both the Professional and Amateur Pinball Association (PAPA) and the International Flipper Pinball Association (IFPA).\nTwo different systems for ranking pinball players exist. The World Pinball Player Rankings (WPPR) was created by the IFPA. The WPPR formula takes into account the quantity and quality of the players in the field, and awards points based on that calculation for the nearly 200 IFPA endorsed events worldwide. PAPA manages a ranking system known as the PAPA Advanced Rating System (PARS), which uses the Glicko Rating System to mathematically analyze the results of more than 100,000 competitive matches. Since 2008 the IFPA has held a World Championship tournament, inviting the top-ranked WPPR players to compete; the 2019 title holder was Johannes Ostermeier of Germany.\nPAPA also designates the winner of the A Division in the annual PAPA World Pinball Championships as the World Pinball Champion. Current Junior (16 and under) and Senior (50 and over) World Champions are Joshua Henderson and Paul McGlone, respectively. Samuel Ogden has become one of the most memorable champions in the PAPA tournaments, winning four straight competitions from 2004 to 2008 in the 50 and over category.\nIn 2018, the IFPA and Stern Pinball created the Stern Pro Circuit. The top 32 qualifiers in this series are invited to the Stern Pro Circuit Final for an invitation-only, no-entry-fee-required event where all contestants who qualify win prize money.\nThe popularity of competitive pinball continues to increase with widely adopted tournament rules, standard competition formats and guides for new players.\nVideo game simulations.\nSimulating a pinball machine has also been a popular theme of video games. Chicago Coin's \"TV Pingame\" (1973) was a digital version of pinball that had a vertical playfield with a paddle at the bottom, controlled by a dial, with the screen filled with simple squares to represent obstacles, bumpers and pockets. This inspired a number of clones, including \"TV Flipper\" (1973) by Midway Manufacturing, Exidy's \"TV Pinball\" (1974), and \"Pin Pong\" (1974) by Atari, Inc. The latter replaced the dial controls with button controls.\nOther early pinball video games include Toru Iwatani's \"Gee Bee\" (1978), \"Bomb Bee\" (1979), and \"Cutie Q\" (1979), Tehkan's arcade game \"Pinball Action\" (1985), the Atari 2600 game \"Video Pinball\" (1981), and \"David's Midnight Magic\" (1982). Bill Budge's \"Pinball Construction Set\", released for the Apple II in 1983, allowed the user to create their own simulated pinball machine and play it.\nMost early simulations were top-down 2D. As processor and graphics capabilities have improved, more accurate ball physics and 3D pinball simulations have become possible. Tilting has also been simulated, which can be activated using one or more keys (sometimes the space bar) for \"moving\" the machine. Flipper button computer peripherals were also released, allowing pinball fans to add an accurate feel to their game play instead of using the keyboard or mouse. Modern pinball video games are often based around established franchises such as \"Metroid Prime Pinball\", \"Mario Pinball Land\", \"Pok\u00e9mon Pinball\", \"Kirby's Pinball Land\", and \"Sonic Spinball\".\nPopular pinball simulations of the 1990s include \"Pinball Dreams\", \"Pro Pinball\" and \"3D Pinball: Space Cadet\" that was included in Windows 2000 and Windows XP. More recent examples include \"Pinball FX\" (2007), \"Pinball FX 2\", \"Pinball FX 3\" and \"Pinball FX\" (2023).\nThere have been released for all major home video game and computer systems, tablet computers and smart phones. Pinball video game engines and editors for creation and recreation of pinball machines include for instance \"Visual Pinball\", \"Future Pinball\" and \"Unit3D Pinball\".\nA BBC News article described virtual pinball games e.g. \"Zen Pinball\" and \"The Pinball Arcade\" as a way to preserve pinball culture and bring it to new audiences. Another example of preserving historic pinball machines is \"Zaccaria Pinball\" that includes digital recreations of classic Zaccaria pinball machines.\nIn 2022 Flutter released an online pinball game. That same year Google released an Easter Egg pinball game on iOS.\nIn popular culture.\nPerhaps the most famous media about pinball is the rock opera album \"Tommy\" (1969) by The Who, which centers on the title character, a \"deaf, dumb, and blind kid\", who becomes a \"Pinball Wizard\" and who later uses pinball as a symbol and tool for his messianic mission. The album was subsequently made into a movie and stage musical. The movie features a Gottlieb \"Kings and Queens\" machine and Gottlieb \"Buckaroo\" machine. \"Wizard\" has since moved into popular usage as a term for an expert pinball player.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60509", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=60509", "title": "195 BC", "text": "Calendar year\n \nYear 195 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Flaccus and Cato (or, less frequently, year 559 \"Ab urbe condita\"). The denomination 195 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nKorea.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60510", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=60510", "title": "198 BC", "text": "Calendar year\n \nYear 198 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Catus and Flamininus (or, less frequently, year 556 \"Ab urbe condita\"). The denomination 198 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nChina.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60511", "revid": "51029144", "url": "https://en.wikipedia.org/wiki?curid=60511", "title": "Parrot virtual machine", "text": "Software to run programming languages\nParrot is a discontinued register-based process virtual machine designed to run dynamic languages efficiently. It is possible to compile Parrot assembly language and Parrot intermediate representation (PIR, an intermediate language) to Parrot bytecode and execute it. Parrot is free and open-source software.\nParrot was started by the Perl community and developed with help from the open-source and free software communities. As a result, it was focused on license compatibility with Perl (Artistic License 2.0), platform compatibility across a broad array of systems, processor architecture compatibility across most modern processors, speed of execution, small size (around 700k depending on platform), and the flexibility to handle the varying demands made by Raku and other modern dynamic languages.\nVersion 1.0, with a stable application programming interface (API) for development, was released on March 17, 2009. The last version is release 8.1.0 \"Andean Parakeet\". Parrot was officially discontinued in August 2021, after being supplanted by MoarVM in its main use (Raku) and never becoming a mainstream VM for any of its other supported languages.\nHistory.\nThe name \"Parrot\" came from an April Fool's joke which announced a hypothetical language, named \"Parrot\", that would unify Python and Perl. The name was later adopted by the Parrot project (initially a part of the Raku development effort) which aimed to support Raku, Python, and other programming languages.\nThe Parrot Foundation was dissolved in 2014. The Foundation was created in 2008 to hold the copyright and trademarks of the Parrot project, to help drive development of language implementations and the core codebase, to provide a base for growing the Parrot community, and to reach out to other language communities.\nHistorical design decisions are documented in the form of Parrot Design Documents, or PDDs, in the Parrot repository.\nUntil late 2005, Dan Sugalski was the lead designer and chief architect of Parrot. Chip Salzenberg, a longtime Perl, Linux kernel, and C++ hacker, took over until mid-2006, when he became the lead developer. Allison Randal, the lead developer of Punie and chief architect of Parrot's compiler tools, was the chief architect until mid-October 2010 when she stepped down and chose Christoph Otto as the new chief architect.\nLanguages.\nThe goal of the Parrot virtual machine was to host client languages and allow inter-operation between them. Several hurdles exist in accomplishing this goal, in particular the difficulty of mapping high-level concepts, data, and data structures between languages.\nStatic and dynamic languages.\nThe differing properties of statically and dynamically typed languages motivated the design of Parrot. Current popular virtual machines such as the Java virtual machine and the Common Language Runtime (for the .NET platform) have been designed for statically typed languages, while the languages targeted by Parrot are dynamically typed.\nVirtual machines such as the Java virtual machine and the current Perl 5 virtual machine are also stack-based. Parrot developers chose a register-based design, reasoning that it more closely resembles a hardware design, allowing the vast literature on compiler optimization to be used in generating bytecode for the Parrot virtual machine that could run at speeds closer to machine code. Other register-based virtual machines inspired parts of Parrot's design, including LLVM, the Lua VM and Inferno's Dis.\nFunctional concepts.\nParrot has rich support for several features of functional programming including closures and continuations, both of which can be particularly difficult to implement correctly and portably, especially in conjunction with exception handling and threading. The biggest advantage is the dynamic extendability of objects with methods, which allows for \"polymorphic containers\" (PMCs) and associated opcodes. Implementing solutions to these problems at the virtual machine level obviates the need to solve them in the individual client languages.\nCompiler tools.\nParrot provides a suite of compiler-writing tools which includes the Parser Grammar Engine (PGE), a hybrid parser-generator that can express a recursive descent parser as well as an operator-precedence parser, allowing free transition between the two in a single grammar. The PGE feeds into the Tree Grammar Engine (TGE) which further transforms the parse-tree generated by PGE for optimization and ultimately for code generation.\nImplementations.\nThe most complete language implementations targeting the Parrot VM were Raku (known at the time as Rakudo Perl 6), Lua and Winxed. Projects to implement many other languages were started, including PHP, Python, and Ruby; along with esoteric and demonstration languages such as Befunge and the \"\" tutorial language. None of these projects were successful in becoming the primary implementation of their respective languages.\nInternals.\nThere are three forms of program code for Parrot:\nExamples.\nRegisters.\nParrot is register-based like most hardware CPUs, and unlike most virtual machines, which are stack-based. Parrot provides four types of registers:\nParrot provides an arbitrary number of registers; this number is fixed at compile time per subroutine.\nArithmetic operations.\nIn PASM\n set I1, 4\n inc I1 # I1 is now 5\n add I1, 2 # I1 is now 7\n set N1, 42.0\n dec N1 # N1 is now 41.0\n sub N1, 2.0 # N1 is now 39.0\n print I1\n print ', '\n print N1\n print \"\\n\"\n end\nIn PIR\n .sub 'main' :main\n $I1 = 4\n inc $I1 # $I1 is now 5\n $I1 += 2 # $I1 is now 7\n $N1 = 42.0\n dec $N1 # $N1 is now 41.0\n $N1 -= 2.0 # $N1 now 39.0\n print $I1\n print ', '\n print $N1\n print \"\\n\"\n .end\nmod_parrot.\nmod_parrot is an optional module for the Apache web server. It embeds a Parrot virtual machine interpreter into the Apache server and provides access to the Apache API to allow handlers to be written in Parrot assembly language, or any high-level language targeted to Parrot.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60512", "revid": "125972", "url": "https://en.wikipedia.org/wiki?curid=60512", "title": "197 BC", "text": "Calendar year\n \nYear 197 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Cethegus and Rufus (or, less frequently, year 557 \"Ab urbe condita\"). The denomination 197 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nChina.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60513", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=60513", "title": "196 BC", "text": "Calendar year\n \nYear 196 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Purpureo and Marcellus (or, less frequently, year 558 \"Ab urbe condita\"). The denomination 196 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nChina.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60514", "revid": "125972", "url": "https://en.wikipedia.org/wiki?curid=60514", "title": "193 BC", "text": "Calendar year\n \nYear 193 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Merula and Thermus (or, less frequently, year 561 \"Ab urbe condita\"). The denomination 193 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming a year.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nEgypt.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60515", "revid": "125972", "url": "https://en.wikipedia.org/wiki?curid=60515", "title": "192 BC", "text": "Calendar year\n \nYear 192 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Flamininus and Ahenobarbus (or, less frequently, year 562 \"Ab urbe condita\"). The denomination 192 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nGreece.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60516", "revid": "917887370", "url": "https://en.wikipedia.org/wiki?curid=60516", "title": "191 BC", "text": "Calendar year\n \nYear 191 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Nasica and Glabrio (or, less frequently, year 563 \"Ab urbe condita\"). The denomination 191 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nChina.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60518", "revid": "44263707", "url": "https://en.wikipedia.org/wiki?curid=60518", "title": "190 BC", "text": "Calendar year\n \nYear 190 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Asiaticus and Laelius (or, less frequently, year 564 \"Ab urbe condita\"). The denomination 190 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy topic.\nArt.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60520", "revid": "46115515", "url": "https://en.wikipedia.org/wiki?curid=60520", "title": "Boxer Rebellion", "text": "1899\u20131901 anti-foreign uprising in China\nThe Boxer Rebellion, also known as the Boxer Uprising, Boxer Movement, or Yihetuan Movement (), was an anti-foreign, anti-imperialist, and anti-Christian uprising in North China between 1899 and 1901, towards the end of the Qing dynasty, by the Society of Righteous and Harmonious Fists. Its members were known as the \"Boxers\" in English, owing to many of them practicing Chinese martial arts, which at the time were referred to as \"Chinese boxing\". It was defeated by the Eight-Nation Alliance of foreign powers.\nFollowing the First Sino-Japanese War, villagers in North China feared the expansion of foreign spheres of influence and resented Christian missionaries who ignored local customs and used their power to protect their followers in court. In 1898, North China experienced natural disasters, including the Yellow River flooding and droughts, which Boxers blamed on foreign and Christian influence. Beginning in 1899, the movement spread across Shandong and the North China Plain, destroying foreign property such as railroads, and attacking or murdering Chinese Christians and missionaries. The events came to a head in June 1900, when Boxer fighters, convinced they were invulnerable to foreign weapons, converged on Beijing with the slogan \"Support the Qing government and exterminate the foreigners\".\nDiplomats, missionaries, soldiers, and some Chinese Christians took refuge in the Legation Quarter, which the Boxers besieged. The Eight-Nation Alliance\u2014comprising American, Austro-Hungarian, British, French, German, Italian, Japanese, and Russian troops\u2014invaded China to lift the siege and on 17 June stormed the Dagu Fort at Tianjin. Empress Dowager Cixi, who had initially been hesitant, supported the Boxers and on 21 June issued an imperial decree that was a de facto declaration of war on the invading powers. Chinese officialdom was split between those supporting the Boxers and those favouring conciliation, led by Prince Qing. The supreme commander of the Chinese forces, the Manchu general Ronglu, later claimed he acted to protect the foreigners. Officials in the southern provinces ignored the imperial order to fight against foreigners.\nThe Eight-Nation Alliance, after initially being turned back by the Imperial Chinese military and Boxer militia, brought 20,000 armed troops to China. They defeated the Imperial Army in Tianjin and arrived in Beijing on 14 August, relieving the 55-day Siege of the International Legations. Plunder and looting of the capital and the surrounding countryside ensued, along with summary execution of those suspected of being Boxers in retribution. The Boxer Protocol of 7 September 1901 provided for the execution of government officials who had supported the Boxers, for foreign troops to be stationed in Beijing, and for 450\u00a0million taels of silver\u2014more than the government's annual tax revenue\u2014to be paid as indemnity over the course of the next 39 years to the eight invading nations. The Qing dynasty's handling of the Boxer Rebellion further weakened both their credibility and control over China, and led to the Late Qing reforms, and to a greater extent the Xinhai Revolution.\nBackground.\nOrigin of the Boxers.\nThe Righteous and Harmonious Fists arose in the inland sections of the northern coastal province of Shandong, a region which had long been plagued by social unrest, religious sects, and martial societies. American Christian missionaries were probably the first people who referred to the well-trained, athletic young men as the \"Boxers\", because of the martial arts which they practised and the weapons training which they underwent. Their primary practice was a type of spiritual possession which involved the whirling of swords, violent prostrations, and incantations to deities.\nThe opportunities to fight against Western encroachment were especially attractive to unemployed village men, many of whom were teenagers. The tradition of possession and invulnerability went back several hundred years but took on special meaning against the powerful new weapons of the West. The Boxers, armed with rifles and swords, claimed supernatural invulnerability against cannons, rifle shots, and knife attacks. The Boxer groups popularly claimed that millions of soldiers would descend out of heaven to assist them in purifying China of foreign oppression. Members demonstrated their claimed invulnerability to new initiates by firing guns loaded with blank rounds at one another.\nIn 1895, despite ambivalence toward their heterodox practices, Yuxian, a Manchu who was the then prefect of Cao Prefecture and would later become provincial governor, cooperated with the Big Swords Society, whose original purpose was to fight bandits. The German Catholic missionaries of the Society of the Divine Word had built up their presence in the area, partially by taking in a significant portion of converts who were \"in need of protection from the law\". On one occasion in 1895, a large bandit gang defeated by the Big Swords Society claimed to be Catholics to avoid prosecution. \"The line between Christians and bandits became increasingly indistinct\", remarks historian Paul Cohen.\nSome missionaries such as Georg Maria Stenz also used their privileges to intervene in lawsuits. The Big Swords responded by attacking Catholic properties and burning them. As a result of diplomatic pressure in the capital, Yuxian executed several Big Sword leaders but did not punish anyone else. More martial secret societies started emerging after this.\nThe early years saw a variety of village activities, not a broad movement with a united purpose. Martial folk-religious societies such as the Baguadao ('Eight Trigrams') prepared the way for the Boxers. Like the Red Boxing school or the Plum Flower tradition, the Boxers of Shandong were more concerned with traditional social and moral values, such as filial piety, than with foreign influences. One leader, Zhu Hongdeng (Red Lantern Zhu), started as a wandering healer, specialising in skin ulcers, and gained wide respect by refusing payment for his treatments. Zhu claimed descent from Ming dynasty emperors, since his surname was the surname of the Ming imperial family. He announced that his goal was to \"Revive the Qing and destroy the foreigners\" ( ).\nThe enemy was seen as foreign influence. They decided the \"primary devils\" were the Christian missionaries while the \"secondary devils\" were the Chinese converts to Christianity, which both had either to repent, be driven out or killed.\nCauses.\nThe movement had multiple causes, both domestic and international. Escalating tensions caused Chinese to turn against \"foreign devils\" who engaged in the Scramble for China in the late 19th century. The Western success at controlling China, growing anti-imperialist sentiment, and extreme weather conditions sparked the movement. A drought followed by floods in Shandong province in 1897\u201398 forced farmers to flee to cities and seek food.\nA major source of discontent in northern China was missionary activity. The Boxers opposed German missionaries in Shandong and in the German concession in Qingdao. The Treaty of Tientsin and the Convention of Peking, signed in 1860 after the Second Opium War, had granted foreign missionaries the freedom to preach anywhere in China and to buy land on which to build churches. There was strong public indignation over the dispossession of Chinese temples that were replaced by Catholic churches which were viewed as deliberately anti-feng shui. A further cause of discontent among Chinese people were the destruction of Chinese burial sites to make way for German railroads and telegraph lines. In response to Chinese protests against German railroads, Germans shot the protestors.\nEconomic conditions in Shandong also contributed to rebellion. Northern Shandong's economy focused significantly on cotton production and was hampered by the importation of foreign cotton. Traffic along the Grand Canal was also decreasing, further eroding the economy. The area had also experienced periods of drought and flood.\nA major precipitating incident was anger at the German Catholic Priest Georg Stenz, who had allegedly serially raped Chinese women in Juye County, Shandong. In an attack known as the Juye Incident, Chinese rebels attempted to kill Stenz in his missionary quarters, but failed to find him and killed two other missionaries. The German Navy's East Asia Squadron dispatched to occupy Jiaozhou Bay on the southern coast of the Shandong peninsula.\nIn December 1897, Wilhelm declared his intent to seize territory in China, which triggered a \"scramble for concessions\" by which Britain, France, Russia and Japan also secured their own sphere of influence in China. Germany gained exclusive control of developmental loans, mining, and railway ownership in Shandong province. Russia gained influence of all territory north of the Great Wall, plus the previous tax exemption for trade in Mongolia and Xinjiang, economic powers similar to Germany's over Fengtian, Jilin and Heilongjiang. France gained influence of Yunnan, most of Guangxi and Guangdong, Japan over Fujian. Britain gained influence of the whole Yangtze valley (defined as all provinces adjoining the Yangtze, as well as Henan and Zhejiang), parts of Guangdong and Guangxi provinces and part of Tibet. Only Italy's request for Zhejiang was declined by the Chinese government. These do not include the lease and concession territories where the foreign powers had full authority. The Russian government militarily occupied their zone, imposed their law and schools, seized mining and logging privileges, settled their citizens, and even established their municipal administration on several cities.\nIn October 1898, a group of Boxers attacked the Christian community of Liyuantun village where a temple to the Jade Emperor had been converted into a Catholic church. Disputes had surrounded the church since 1869, when the temple had been granted to the Christian residents of the village. This incident marked the first time the Boxers used the slogan \"Support the Qing, destroy the foreigners\" () that later characterised them.\nThe Boxers called themselves the \"Militia United in Righteousness\" for the first time in October 1899, at the Battle of Senluo Temple, a clash between Boxers and Qing government troops. By using the word \"Militia\" rather than \"Boxers\", they distanced themselves from forbidden martial arts sects and tried to give their movement the legitimacy of a group that defended orthodoxy.\nViolence toward missionaries and Christians drew sharp responses from diplomats protecting their nationals, including Western seizure of harbors and forts and the moving in of troops in preparation for all-out war, as well as taking control of more land by force or by coerced long-term leases from the Qing. In 1899, the French minister in Beijing helped the missionaries to obtain an edict granting official status to every order in the Roman Catholic hierarchy, enabling local priests to support their people in legal or family disputes and bypass the local officials. After the German government took over Shandong, many Chinese feared that the foreign missionaries and possibly all Christian activities were imperialist attempts at \"carving the melon\", i.e., to colonise China piece by piece. A Chinese official expressed the animosity towards foreigners succinctly, \"Take away your missionaries and your opium and you will be welcome.\"\nIn 1899, the Boxer Rebellion developed into a mass movement. The previous year, the Hundred Days' Reform, in which progressive Chinese reformers persuaded the Guangxu Emperor to engage in modernizing efforts, was suppressed by Empress Dowager Cixi and Yuan Shikai. The Qing political elite struggled with the question of how to retain its power. The Qing government came to view the Boxers as a means to help oppose foreign powers. The national crisis was widely perceived as caused by \"foreign aggression\" inside, even though afterwards a majority of Chinese were grateful for the actions of the alliance. The Qing government was corrupt, common people often faced extortions from government officials and the government offered no protection from the violent actions of the Boxers.\nQing forces.\nThe military of the Qing dynasty had been dealt a severe blow by the First Sino-Japanese War and this had prompted military reform that was still in its early stages when the Boxer rebellion occurred and they were expected to fight. The bulk of the fighting was conducted by the forces already around Zhili with troops from other provinces only arriving after the main fighting had ended.\nThe failure of the Qing forces to withstand the Allied forces was not surprising given the limited time for reform and the fact that the best troops of China were not committed to the fight, remaining instead in Huguang and Shandong. The officer corps was particularly deficient; many lacked basic knowledge of strategy and tactics, and even those with training had not actively commanded troops in the field. In addition, the regular soldiers were noted for their poor marksmanship and inaccuracy, while cavalry was ill-organised and was not used to its full extent. Tactically, the Chinese still retained their belief in the superiority of defence, often withdrawing as soon as they were flanked, a tendency attributable to their lack of combat experience and training as well as a lack of initiative from commanders who would rather retreat than counterattack. However, accusations of cowardice were minimal; this was a marked improvement from the Sino-Japanese War of 1894\u20131895, as Chinese troops did not flee en masse as before. If led by courageous officers, the troops would often fight to the death as occurred under Nie Shicheng and Ma Yukun.\nOn the other hand, Chinese artillery was well-regarded, and caused far more casualties than the infantry at Tientsin, proving themselves superior to Allied artillery in counter-battery fire. The infantry, for their part, were commended for their good usage of cover and concealment in addition to their tenacity in resistance.\nThe Boxers also targeted Jewish groups in the region destroying their reputation and leading to Britain temporarily vacating their civilian workers from the front lines. \nBoxer War.\nIntensifying crisis.\nIn January 1900, with a majority of conservatives in the imperial court, Cixi changed her position on the Boxers and issued edicts in their defence, causing protests from foreign powers. Cixi urged provincial authorities to support the Boxers, although few did so. In the spring of 1900, the Boxer movement spread rapidly north from Shandong into the countryside near Beijing. Boxers burned Christian churches, killed Chinese Christians and intimidated Chinese officials who stood in their way. American Minister Edwin H. Conger cabled Washington, \"the whole country is swarming with hungry, discontented, hopeless idlers\".\nOn 30 May the diplomats, led by British Minister Claude Maxwell MacDonald, requested that foreign soldiers come to Beijing to defend the legations. The Chinese government reluctantly acquiesced, and the next day a multinational force of 435 navy troops from eight countries debarked from warships and travelled by train from the Taku Forts to Beijing. They set up defensive perimeters around their respective missions.\nOn 5 June 1900, the railway line to Tianjin was cut by Boxers in the countryside, and Beijing was isolated. On 11 June, at Yongdingmen, the secretary of the Japanese legation, Sugiyama Akira, was attacked and killed by the forces of General Dong Fuxiang, who were guarding the southern part of the Beijing walled city. Armed with Mauser rifles but wearing traditional uniforms, Dong's troops had threatened the foreign legations in the fall of 1898 soon after arriving in Beijing, so much that United States Marines had been called to Beijing to guard the legations.\nWilhelm was so alarmed by the Chinese Muslim troops that he requested Ottoman caliph Abdul Hamid II to find a way to stop the Muslim troops from fighting. Abdul Hamid agreed to the Kaiser's request and sent Enver Pasha (not to be confused with the later Young Turk leader) to China in 1901, but the rebellion was over by that time.\nOn 11 June, the first Boxer was seen in the Peking Legation Quarter. The German Minister Clemens von Ketteler and German soldiers captured a Boxer boy and inexplicably executed him. In response, thousands of Boxers burst into the walled city of Beijing that afternoon and burned many of the Christian churches and cathedrals in the city, burning some victims alive. American and British missionaries took refuge in the Methodist Mission, and an attack there was repulsed by US Marines. The soldiers at the British Embassy and German legations shot and killed several Boxers. The Kansu Braves and Boxers, along with other Chinese, then attacked and killed Chinese Christians around the legations in revenge for foreign attacks on Chinese.\nSeymour Expedition.\nAs the situation grew more violent, the Eight Powers authorities at Dagu dispatched a second multinational force to Beijing on 10 June 1900. This force of 2,000 sailors and marines was under the command of Vice Admiral Edward Hobart Seymour, the largest contingent being British. The force moved by train from Dagu to Tianjin with the agreement of the Chinese government, but the railway had been severed between Tianjin and Beijing. Seymour resolved to continue forward by rail to the break and repair the railway, or progress on foot from there, if necessary, as it was only 120\u00a0km from Tianjin to Beijing. The court then replaced Prince Qing at the Zongli Yamen with Manchu Prince Duan, a member of the imperial Aisin Gioro clan (foreigners called him a \"Blood Royal\"), who was anti-foreigner and pro-Boxer. He soon ordered the Imperial army to attack the foreign forces. Confused by conflicting orders from Beijing, General Nie Shicheng let Seymour's army pass by in their trains.\nAfter leaving Tianjin, the force quickly reached Langfang, but the railway was destroyed there. Seymour's engineers tried to repair the line, but the force found itself surrounded, as the railway in both behind directions was destroyed. They were attacked from all sides by Chinese irregulars and imperial troops. Five thousand of Dong Fuxiang's Gansu Braves and an unknown number of Boxers won a costly but major victory over Seymour's troops at the Battle of Langfang on 18 June. The Seymour force could not locate the Chinese artillery, which was raining shells upon their positions. Chinese troops employed mining, engineering, flooding, and simultaneous attacks. The Chinese also employed pincer movements, ambushes, and sniping with some success.\nOn 18 June, Seymour learned of attacks on the Legation Quarter in Beijing, and decided to continue advancing, this time along the Beihe River, toward Tongzhou, from Beijing. By 19 June, the force was halted by progressively stiffening resistance and started to retreat southward along the river with over 200 wounded. The force was now very low on food, ammunition, and medical supplies. They happened upon The Great Hsi-Ku Arsenal, a hidden Qing munitions cache of which the Eight Powers had had no knowledge until then.\nThere they dug in and awaited rescue. A Chinese servant slipped through the Boxer and Imperial lines, reached Tianjin, and informed the Eight Powers of Seymour's predicament. His force was surrounded by Imperial troops and Boxers, attacked nearly around the clock, and at the point of being overrun. The Eight Powers sent a relief column from Tianjin of 1,800 men (900 Russian troops from Port Arthur, 500 British seamen, and other assorted troops). On 25 June the relief column reached Seymour. The Seymour force destroyed the Arsenal: they spiked the captured field guns and set fire to any munitions that they could not take (an estimated \u00a33\u00a0million worth). The Seymour force and the relief column marched back to Tientsin, unopposed, on 26 June. Seymour's casualties during the expedition were 62 killed and 228 wounded.\nConflict within the Qing imperial court.\nMeanwhile, in Beijing, on 16 June, Empress Dowager Cixi summoned the imperial court for a mass audience and addressed the choice between using the Boxers to evict the foreigners from the city, and seeking a diplomatic solution. In response to a high official who doubted the efficacy of the Boxers, Cixi replied that both sides of the debate at the imperial court realised that popular support for the Boxers in the countryside was almost universal and that suppression would be both difficult and unpopular, especially when foreign troops were on the march.\nSiege of the Beijing legations.\nOn 15 June, Qing imperial forces deployed electric naval mines in the Beihe River to prevent the Eight-Nation Alliance from sending ships to attack. With a difficult military situation in Tianjin and a total breakdown of communications between Tianjin and Beijing, the allied nations took steps to reinforce their military presence significantly. On 17 June, Allied forces under Russian Admiral Yevgeni Alekseyev took the Dagu Forts commanding the approaches to Tianjin, and from there brought increasing numbers of troops on shore. When Cixi received an ultimatum that same day demanding that China surrender total control over all its military and financial affairs to foreigners, she defiantly stated before the entire Grand Council, \"Now they [the Powers] have started the aggression, and the extinction of our nation is imminent. If we just fold our arms and yield to them, I would have no face to see our ancestors after death. If we must perish, why don't we fight to the death?\" It was at this point that Cixi began to blockade the legations with the armies of the Peking Field Force, which began the siege. Cixi stated that \"I have always been of the opinion, that the allied armies had been permitted to escape too easily in 1860. Only a united effort was then necessary to have given China the victory. Today, at last, the opportunity for revenge has come\", and said that millions of Chinese would join the cause of fighting the foreigners since the Manchus had provided \"great benefits\" on China. On receipt of the news of the attack on the Dagu Forts on 19 June, Empress Dowager Cixi immediately sent an order to the legations that the diplomats and other foreigners depart Beijing under escort of the Chinese army within 24 hours.\nThe next morning, diplomats from the besieged legations met to discuss the Empress's offer. The majority quickly agreed that they could not trust the Chinese army. Fearing that they would be killed, they agreed to refuse the Empress's demand. The German Imperial Envoy, Baron Clemens von Ketteler, was infuriated with the actions of the Chinese army troops and determined to take his complaints to the royal court. Against the advice of the fellow foreigners, the baron left the legations with a single aide and a team of porters to carry his sedan chair. On his way to the palace, von Ketteler was killed on the streets of Beijing by a Manchu captain. His aide managed to escape the attack and carried word of the baron's death back to the diplomatic compound. At this news, the other diplomats feared they also would be murdered if they left the legation quarter and they chose to continue to defy the Chinese order to depart Beijing. The legations were hurriedly fortified. Most of the foreign civilians, which included a large number of missionaries and businessmen, took refuge in the British legation, the largest of the diplomatic compounds. Chinese Christians were primarily housed in the adjacent palace (Fu) of Prince Su, who was forced to abandon his property by the foreign soldiers.\nOn 21 June, Cixi issued an imperial decree stating that hostilities had begun and ordering the regular Chinese army to join the Boxers in their attacks on the invading troops. This was a declaration of war, but the Allies also made no formal declaration of war. Regional governors in the south, who commanded substantial modernised armies, such as Li Hongzhang at Guangzhou, Yuan Shikai in Shandong, Zhang Zhidong at Wuhan, and Liu Kunyi at Nanjing, formed the Mutual Defense Pact of the Southeastern Provinces. They refused to recognise the imperial court's declaration of war, which they declared a (illegitimate order) and withheld knowledge of it from the public in the south. Yuan Shikai used his own forces to suppress Boxers in Shandong, and Zhang entered into negotiations with the foreigners in Shanghai to keep his army out of the conflict. The neutrality of these provincial and regional governors left the majority of Chinese military forces out of the conflict. The republican revolutionary Sun Yat-sen even took the opportunity to submit a proposal to Li Hongzhang to declare an independent democratic republic, although nothing came of the suggestion.\nThe legations of the United Kingdom, France, Germany, Italy, Austria-Hungary, Spain, Belgium, the Netherlands, the United States, Russia and Japan were located in the Beijing Legation Quarter south of the Forbidden City. The Chinese army and Boxer irregulars besieged the Legation Quarter from 20 June to 14 August 1900. A total of 473 foreign civilians, 409 soldiers, marines and sailors from eight countries, and about 3,000 Chinese Christians took refuge there. Under the command of the British minister to China, Claude Maxwell MacDonald, the legation staff and military guards defended the compound with small arms, three machine guns, and one old muzzle-loaded cannon, which was nicknamed the \"International Gun\" because the barrel was British, the carriage Italian, the shells Russian and the crew American. Chinese Christians in the legations led the foreigners to the cannon and it proved important in the defence. Also under siege in Beijing was the Northern Cathedral (\"Beitang\") of the Catholic Church. The cathedral was defended by 43 French and Italian soldiers, 33 Catholic foreign priests and nuns, and about 3,200 Chinese Catholics. The defenders suffered heavy casualties from lack of food and from mines which the Chinese exploded in tunnels dug beneath the compound. The number of Chinese soldiers and Boxers besieging the Legation Quarter and the Beitang is unknown. Zaiyi's bannermen in the Tiger and Divine Corps led attacks against the Catholic cathedral church.\nOn 22 and 23 June, Chinese soldiers and Boxers set fire to areas north and west of the British Legation, using it as a \"frightening tactic\" to attack the defenders. The nearby Hanlin Academy, a complex of courtyards and buildings that housed \"the quintessence of Chinese scholarship ... the oldest and richest library in the world\", caught fire. Each side blamed the other for the destruction of the invaluable books it contained.\nAfter the failure to burn out the foreigners, the Chinese army adopted an anaconda-like strategy. The Chinese built barricades surrounding the Legation Quarter and advanced, brick by brick, on the foreign lines, forcing the foreign legation guards to retreat a few feet at a time. This tactic was especially used in the Fu, defended by Japanese and Italian sailors and soldiers, and inhabited by most of the Chinese Christians. Fusillades of bullets, artillery and firecrackers were directed against the Legations almost every night\u2014but did little damage. Sniper fire took its toll among the foreign defenders. Despite their numerical advantage, the Chinese did not attempt a direct assault on the Legation Quarter although in the words of one of the besieged, \"it would have been easy by a strong, swift movement on the part of the numerous Chinese troops to have annihilated the whole body of foreigners\u00a0... in an hour\". American missionary Francis Dunlap Gamewell and his crew of \"fighting parsons\" fortified the Legation Quarter, but impressed Chinese Christians to do most of the physical labour of building defences.\nThe Germans and the Americans occupied perhaps the most crucial of all defensive positions: the Tartar Wall. Holding the top of the tall and wide wall was vital. The German barricades faced east on top of the wall and west were the west-facing American positions. The Chinese advanced toward both positions by building barricades even closer. \"The men all feel they are in a trap\", said the US commander Capt. John Twiggs Myers, \"and simply await the hour of execution\". On 30 June, the Chinese forced the Germans off the Wall, leaving the American Marines alone in its defence. In June 1900, one American described the scene of 20,000 Boxers storming the walls:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Their yells were deafening, while the roar of gongs, drums, and horns sounded like thunder\u00a0... They waved their swords and stamped on the ground with their feet. They wore red turbans, sashes, and garters over blue cloth\u00a0... They were now only twenty yards from our gate. Three or four volleys from the Lebel rifles of our marines left more than fifty dead on the ground.\nAt the same time, a Chinese barricade was advanced to within a few feet of the American positions, and it became clear that the Americans had to abandon the wall or force the Chinese to retreat. At 2\u00a0am on 3 July 56 British, Russian and American marines and sailors, under the command of Myers, launched an assault against the Chinese barricade on the wall. The attack caught the Chinese sleeping, killed about 20 of them, and expelled the rest of them from the barricades. The Chinese did not attempt to advance their positions on the Tartar Wall for the remainder of the siege.\nSir Claude MacDonald said 13 July was the \"most harassing day\" of the siege. The Japanese and Italians in the Fu were driven back to their last defence line. The Chinese detonated a mine beneath the French Legation pushing the French and Austrians out of most of the French Legation. On 16 July, the most capable British officer was killed and the journalist George Ernest Morrison was wounded. American Minister Edwin H. Conger established contact with the Chinese government and on 17 July, and an armistice was declared by the Chinese.\nInfighting among officials and commanders.\nGeneral Ronglu concluded that it was futile to fight all of the powers simultaneously and declined to press home the siege. Zaiyi wanted artillery for Dong's troops to destroy the legations. Ronglu blocked the transfer of artillery to Zaiyi and Dong, preventing them from attacking. Ronglu forced Dong Fuxiang and his troops to pull back from completing the siege and destroying the legations, thereby saving the foreigners and making diplomatic concessions. Ronglu and Prince Qing sent food to the legations and used their bannermen to attack the Gansu Braves of Dong Fuxiang and the Boxers who were besieging the foreigners. They issued edicts ordering the foreigners to be protected, but the Gansu warriors ignored it, and fought against bannermen who tried to force them away from the legations. The Boxers also took commands from Dong Fuxiang. Ronglu also deliberately hid an Imperial Decree from Nie Shicheng. The Decree ordered him to stop fighting the Boxers because of the foreign invasion, and also because the population was suffering. Due to Ronglu's actions, Nie continued to fight the Boxers and killed many of them even as the foreign troops were making their way into China. Ronglu also ordered Nie to protect foreigners and save the railway from the Boxers. Because parts of the railway were saved under Ronglu's orders, the foreign invasion army was able to transport itself into China quickly. Nie committed thousands of troops against the Boxers instead of against the foreigners, but was already outnumbered by the Allies by 4,000 men. He was blamed for attacking the Boxers, and decided to sacrifice his life at Tietsin by walking into the range of Allied guns.\nXu Jingcheng, who had served as the envoy to many of the same states under siege in the Legation Quarter, argued that \"the evasion of extraterritorial rights and the killing of foreign diplomats are unprecedented in China and abroad\". Xu and five other officials urged Empress Dowager Cixi to order the repression of Boxers, the execution of their leaders, and a diplomatic settlement with foreign armies. The Empress Dowager was outraged, and sentenced Xu and the five others to death for \"willfully and absurdly petitioning the imperial court\" and \"building subversive thought\". They were executed on 28 July 1900 and their severed heads placed on display at Caishikou Execution Grounds in Beijing.\nReflecting this vacillation, some Chinese soldiers were quite liberally firing at foreigners under siege from its very onset. Cixi did not personally order imperial troops to conduct a siege, and on the contrary had ordered them to protect the foreigners in the legations. Prince Duan led the Boxers to loot his enemies within the imperial court and the foreigners, although imperial authorities expelled Boxers after they were let into the city and went on a looting rampage against both the foreign and the Qing imperial forces. Older Boxers were sent outside Beijing to halt the approaching foreign armies, while younger men were absorbed into the Muslim Gansu army.\nWith conflicting allegiances and priorities motivating the various forces inside Beijing, the situation in the city became increasingly confused. The foreign legations continued to be surrounded by both Qing imperial and Gansu forces. While Dong's Gansu army, now swollen by the addition of the Boxers, wished to press the siege, Ronglu's imperial forces seem to have largely attempted to follow Cixi's decree and protect the legations. However, to satisfy the conservatives in the imperial court, Ronglu's men also fired on the legations and let off firecrackers to give the impression that they, too, were attacking the foreigners. Inside the legations and out of communication with the outside world, the foreigners simply fired on any targets that presented themselves, including messengers from the imperial court, civilians and besiegers of all persuasions. Dong Fuxiang was denied artillery held by Ronglu which stopped him from levelling the legations, and when he complained to Empress Dowager Cixi on 23 June, she dismissively said that \"Your tail is becoming too heavy to wag.\" The Alliance discovered large amounts of unused Chinese Krupp guns and shells after the siege was lifted.\nGaselee Expedition.\nForeign navies started building up their presence along the northern China coast from the end of April 1900. Several international forces were sent to the capital, with varying success, and the Chinese forces were ultimately defeated by the Alliance. Independently, the Netherlands dispatched three cruisers in July to protect its citizens in Shanghai.\nBritish Lieutenant-General Alfred Gaselee acted as the commanding officer of the Eight-Nation Alliance, which eventually numbered 55,000. Japanese forces, led by Fukushima Yasumasa and Yamaguchi Motomi and numbering over 20,840 men, made up the majority of the expeditionary force. French forces in the campaign, led by general Henri-Nicolas Frey, consisted mostly of inexperienced Vietnamese and Cambodian conscripts from French Indochina. The \"First Chinese Regiment\" (Weihaiwei Regiment) which was praised for its performance, consisted of Chinese collaborators serving in the British military. Notable events included the seizure of the Dagu Forts commanding the approaches to Tianjin and the boarding and capture of four Chinese destroyers by British Commander Roger Keyes. Among the foreigners besieged in Tianjin was a young American mining engineer named Herbert Hoover, who would go on to become the 31st President of the United States.\nThe international force captured Tianjin on 14 July. The international force suffered its heaviest casualties of the Boxer Rebellion in the Battle of Tientsin. With Tianjin as a base, the international force marched from Tianjin to Beijing (about ), with 20,000 allied troops. On 4 August, there were approximately 70,000 Qing imperial troops and anywhere from 50,000 to 100,000 Boxers along the way. The allies only encountered minor resistance, fighting battles at Beicang and Yangcun. At Yangcun, Russian general Nikolai Linevich led the 14th Infantry Regiment of the US and British troops in the assault. The weather was a major obstacle. Conditions were extremely humid with temperatures sometimes reaching . These high temperatures and insects plagued the Allies. Soldiers became dehydrated and horses died. Chinese villagers killed Allied troops who searched for wells.\nThe heat killed Allied soldiers, who foamed at the mouth. The tactics along the way were gruesome on either side. Allied soldiers beheaded already dead Chinese corpses, bayoneted or beheaded live Chinese civilians, and raped Chinese girls and women. Cossacks were reported to have killed Chinese civilians almost automatically and Japanese kicked a Chinese soldier to death. The Chinese responded to the Alliance's atrocities with similar acts of violence and cruelty, especially towards captured Russians. Lieutenant Smedley Butler saw the remains of two Japanese soldiers nailed to a wall, who had their tongues cut off and their eyes gouged. Lieutenant Butler was wounded during the expedition in the leg and chest, later receiving the Brevet Medal in recognition for his actions.\nThe international force reached Beijing on 14 August. Following Beiyang army's defeat in the First Sino-Japanese War, the Chinese government had invested heavily in modernising the imperial army, which was equipped with modern Mauser repeater rifles and Krupp artillery. Three modernised divisions consisting of Manchu bannermen protected the Beijing Metropolitan region. Two of them were under the command of the anti-Boxer Prince Qing and Ronglu, while the anti-foreign Prince Duan commanded the ten-thousand-strong Hushenying, or \"Tiger Spirit Division\", which had joined the Gansu Braves and Boxers in attacking the foreigners. It was a Hushenying captain who had assassinated the German diplomat, Ketteler. The Tenacious Army under Nie Shicheng received Western style training under German and Russian officers in addition to their modernised weapons and uniforms. They effectively resisted the Alliance at the Battle of Tientsin before retreating and astounded the Alliance forces with the accuracy of their artillery during the siege of the Tianjin concessions (the artillery shells failed to explode upon impact due to corrupt manufacturing). The Gansu Braves under Dong Fuxiang, which some sources described as \"ill disciplined\", were armed with modern weapons but were not trained according to Western drill and wore traditional Chinese uniforms. They led the defeat of the Alliance at Langfang in the Seymour Expedition and were the most ferocious in besieging the Legations in Beijing. The British won the race among the international forces to be the first to reach the besieged Legation Quarter. The US was able to play a role due to the presence of US ships and troops stationed in Manila since the US conquest of the Philippines during the Spanish\u2013American War and the subsequent Philippine\u2013American War. The US military refers to this as the China Relief Expedition. United States Marines scaling the walls of Beijing is an iconic image of the Boxer Rebellion.\nThe British Army reached the legation quarter on the afternoon of 14 August and relieved the Legation Quarter. The Beitang was relieved on 16 August, first by Japanese soldiers and then, officially, by the French.\nQing court flight to Xi'an.\nAs the foreign armies reached Beijing, the Qing court fled to Xi'an, with Cixi disguised as a Buddhist nun. The journey was made all the more arduous by the lack of preparation, but the Empress Dowager insisted this was not a retreat, rather a \"tour of inspection\". After weeks of travel, the party arrived in Xi'an, beyond protective mountain passes where the foreigners could not reach, deep in Chinese Muslim territory and protected by the Gansu Braves. The foreigners had no orders to pursue Cixi, so they decided to stay put.\nRussian invasion of Manchuria.\nThe Russian Empire and the Qing dynasty had maintained a long peace, starting with the Treaty of Nerchinsk in 1689, but Russian forces took advantage of Chinese defeats to impose the Aigun Treaty of 1858 and the Treaty of Peking of 1860 which ceded formerly Chinese territory in Manchuria to Russia, much of which is held by Russia to the present day (Primorye). The Russians aimed for control over the Amur River for navigation, and the all-weather ports of Dairen and Port Arthur in the Liaodong peninsula. The rise of Japan as an Asian power provoked Russia's anxiety, especially in light of expanding Japanese influence in Korea. Following Japan's victory in the First Sino-Japanese War of 1895, the Triple Intervention of Russia, Germany and France forced Japan to return the territory won in Liaodong, leading to a de facto Sino-Russian alliance.\nLocal Chinese in Manchuria were incensed at these Russian advances and began to harass Russians and Russian institutions, such as the Chinese Eastern Railway, which was guarded by Russian troops under Pavel Mishchenko. In June 1900, the Chinese bombarded the town of Blagoveshchensk on the Russian side of the Amur. The Russian government, at the insistence of war minister Aleksey Kuropatkin, used the pretext of Boxer activity to move some 200,000 troops led by Paul von Rennenkampf into the area to crush the Boxers. The Chinese used arson to destroy a bridge carrying a railway and a barracks on 27 July. The Boxer attacks on Chinese Eastern Railway and burned the Yantai mines.\nMassacre of missionaries and Chinese Christians.\nA total of 136 Protestant missionaries, 53 children, 47 Catholic priests and nuns, 30,000 Chinese Catholics, 2,000 Chinese Protestants, and 200\u2013400 of the 700 Russian Orthodox Christians in Beijing are estimated to have been killed during the uprising. The Protestant dead were collectively termed the China Martyrs of 1900.\nOrthodox, Protestant, and Catholic missionaries and their Chinese parishioners were massacred throughout northern China, some by Boxers and others by government troops and authorities. After the declaration of war on Western powers in June 1900, Yuxian, who had been named governor of Shanxi in March of that year, implemented a brutal anti-foreign and anti-Christian policy. On 9 July, reports circulated that he had executed forty-four foreigners (including women and children) from missionary families whom he had invited to the provincial capital Taiyuan under the promise to protect them. Although the purported eyewitness accounts have recently been questioned as improbable, this event became a notorious symbol of Chinese anger, known as the Taiyuan massacre.\nThe England-based Baptist Missionary Society opened its mission in Shanxi in 1877. In 1900, all its missionaries there were killed, along with all 120 converts. By the summer's end, more foreigners and as many as 2,000 Chinese Christians had been put to death in the province. Journalist and historical writer Nat Brandt has called the massacre of Christians in Shanxi \"the greatest single tragedy in the history of Christian evangelicalism\".\nSome 222 Russian\u2013Chinese martyrs, including Chi Sung as St. Metrophanes, were locally canonised as New Martyrs on 22 April 1902, after Archimandrite Innocent (Fugurovsky), head of the Russian Orthodox Mission in China, solicited the Most Holy Synod to perpetuate their memory. This was the first local canonisation for more than two centuries.\nAftermath.\nAllied occupation and atrocities.\nThe Eight Nation Alliance occupied Zhili province while Russia occupied Manchuria, but the rest of China was not occupied due to the actions of several Han governors who formed the Mutual Protection of Southeast China that refused to obey the declaration of war and kept their armies and provinces out of the war. Zhang Zhidong told Everard Fraser, the Hankou-based British consul general, that he despised Manchus so that the Eight Nation Alliance would not occupy provinces under the Mutual Defense Pact.\nBeijing, Tianjin and Zhili province were occupied for more than one year by the international expeditionary force under the command of German Field Marshal Alfred von Waldersee, who had initially been appointed commander of the Eight-Nation Alliance during the rebellion but did not arrive in China until after most of the fighting had ended. The Americans and British paid General Yuan Shikai and his army (the Right Division) to help the Eight Nation Alliance suppress the Boxers. Yuan Shikai's forces killed tens of thousands of people in their anti-Boxer campaign in Zhili province and Shandong after the Alliance captured Beijing. The majority of the hundreds of thousands of people living in inner Beijing during the Qing were Manchus and Mongol bannermen from the Eight Banners after they were moved there in 1644, when Han Chinese were expelled. Sawara Tokusuke, a Japanese journalist, wrote in \"Miscellaneous Notes about the Boxers\" about the rapes of Manchu and Mongol banner girls. He alleged that soldiers of the Eight-Nation Alliance raped a large number of women in Peking, including all seven daughters of Viceroy Yulu of the Hitara clan. Likewise, a daughter and a wife of Mongol banner noble Chongqi of the Alute clan were allegedly gang-raped by soldiers of the Eight-Nation Alliance. Chongqi killed himself on 26 August 1900, and some other relatives, including his son, Baochu, did likewise shortly afterward.\nDuring attacks on suspected Boxer areas from September 1900 to March 1901, European and American forces engaged in tactics which included public decapitations of Chinese with suspected Boxer sympathies, systematic looting, routine shooting of farm animals and crop destruction, destruction of religious buildings and public buildings, burning of religious texts, and widespread rape of Chinese women and girls.\nContemporary British and American observers levelled their greatest criticism at German, Russian, and Japanese troops for their ruthlessness and willingness to execute Chinese of all ages and backgrounds, sometimes burning villages and killing their entire populations. The German force arrived too late to take part in the fighting but undertook punitive expeditions to villages in the countryside. According to missionary Arthur Henderson Smith, in addition to burning and looting, Germans \"cut off the heads of many Chinese within their jurisdiction, many of them for absolutely trivial offenses\". US Army Lieutenant C.\u00a0D. Rhodes reported that German and French soldiers set fire to buildings where innocent peasants were sheltering and would shoot and bayonet peasants who fled the burning buildings. According to Australian soldiers, Germans extorted ransom payments from villages in exchange for not torching their homes and crops. British journalist George Lynch wrote that German and Italian soldiers engaged in a practice of raping Chinese women and girls before burning their villages. According to Lynch, German soldiers would attempt to cover up these atrocities by throwing rape victims into wells as staged suicides. Lynch said, \"There are things that I must not write, and that may not be printed in England, which would seem to show that this Western civilisation of ours is merely a veneer over savagery\".\nOn 27 July, during departure ceremonies for the German relief force, Kaiser Wilhelm II included an impromptu but intemperate reference to the Hun invaders of continental Europe:\nOne newspaper called the aftermath of the siege a \"carnival of ancient loot\", and others called it \"an orgy of looting\" by soldiers, civilians and missionaries. These characterisations called to mind the sacking of the Summer Palace in 1860. Each nationality accused the others of being the worst looters. An American diplomat, Herbert G. Squiers, filled several railway carriages with loot and artefacts. The British Legation held loot auctions every afternoon and proclaimed, \"Looting on the part of British troops was carried out in the most orderly manner.\" However, one British officer noted, \"It is one of the unwritten laws of war that a city which does not surrender at the last and is taken by storm is looted.\" For the rest of 1900 and 1901, the British held loot auctions every day except Sunday in front of the main-gate to the British Legation. Many foreigners, including Claude Maxwell MacDonald and Lady Ethel MacDonald and George Ernest Morrison of \"The Times\", were active bidders among the crowd. Many of these looted items ended up in Europe. The Catholic Beitang or North Cathedral was a \"salesroom for stolen property\". The American general Adna Chaffee banned looting by American soldiers, but the ban was ineffectual. According to Chaffee, \"it is safe to say that where one real Boxer has been killed, fifty harmless coolies or laborers, including not a few women and children, have been slain\".\nA few Western missionaries took an active part in calling for retribution. To provide restitution to missionaries and Chinese Christian families whose property had been destroyed, William Scott Ament, a missionary of American Board of Commissioners for Foreign Missions, guided American troops through villages to punish those he suspected of being Boxers and confiscate their property. When Mark Twain read of this expedition, he wrote a scathing essay, \"To the Person Sitting in Darkness\", that attacked the \"Reverend bandits of the American Board\", especially targeting Ament, one of the most respected missionaries in China. The controversy was front-page news during much of 1901. Ament's counterpart on the distaff side was British missionary Georgina Smith, who presided over a neighbourhood in Beijing as judge and jury.\nWhile one historical account reported that Japanese troops were astonished by other Alliance troops raping civilians, others noted that Japanese troops were \"looting and burning without mercy\", and that Chinese \"women and girls by hundreds have committed suicide to escape a worse fate at the hands of Russian and Japanese brutes\". Roger Keyes, who commanded the British destroyer \"Fame\" and accompanied the Gaselee Expedition, noted that the Japanese had brought their own \"regimental wives\" (prostitutes) to the front to keep their soldiers from raping Chinese civilians.\n\"The Daily Telegraph\" journalist E. J. Dillon stated that he witnessed the mutilated corpses of Chinese women who were raped and killed by the Alliance troops. The French commander dismissed the rapes, attributing them to \"gallantry of the French soldier\". According to U.S. Captain Grote Hutcheson, French forces burned each village they encountered during a 99-mile march and planted the French flag in the ruins.\nMany bannermen supported the Boxers, and shared their anti-foreign sentiment. Bannermen had been devastated in the First Sino-Japanese War in 1895 and Banner armies were destroyed while resisting the invasion. In the words of historian Pamela Crossley, their living conditions went \"from desperate poverty to true misery\". When thousands of Manchus fled south from Aigun during the fighting in 1900, their cattle and horses were stolen by Russian Cossacks who then burned their villages and homes to ashes. Manchu Banner armies were destroyed while resisting the invasion, many annihilated by Russians. Manchu Shoufu killed himself during the battle of Peking and the Manchu Lao She's father was killed by Western soldiers in the battle as the Manchu banner armies of the Center Division of the Guards Army, Tiger Spirit Division and Peking Field Force in the Metropolitan banners were slaughtered by the western soldiers. The Inner-city Legation Quarters and Catholic cathedral (Church of the Saviour, Beijing) were both attacked by Manchu bannermen. Manchu bannermen were slaughtered by the Eight Nation Alliance all over Manchuria and Beijing because most of the Manchu bannermen supported the Boxers.The clan system of the Manchus in Aigun was obliterated by the despoliation of the area at the hands of the Russian invaders. There were 1,266 households including 900 Daurs and 4,500 Manchus in Sixty-Four Villages East of the River and Blagoveshchensk until the Blagoveshchensk massacre and Sixty-Four Villages East of the River massacre committed by Russian Cossack soldiers. Many Manchu villages were burned by Cossacks in the massacre according to Victor Zatsepine.\nManchu royals, officials and officers like Yuxian, Qixiu, Zaixun, Prince Zhuang and Captain Enhai were executed or forced to commit suicide by the Eight Nation Alliance. Manchu official Gangyi's execution was demanded, but he had already died. Japanese soldiers arrested Qixiu before he was executed. Zaixun, Prince Zhuang was forced to commit suicide on 21 February 1901. They executed Yuxian on 22 February 1901. On 31 December 1900 German soldiers beheaded the Manchu captain Enhai for killing Clemens von Ketteler.\nIndemnity.\nAfter the capture of Peking by the foreign armies, some of Cixi's advisers advocated that the war be carried on, arguing that China could have defeated the foreigners as it was disloyal and traitorous people within China who allowed Beijing and Tianjin to be captured by the Allies, and that the interior of China was impenetrable. They also recommended that Dong Fuxiang continue fighting. The Empress Dowager Cixi was practical however, and decided that the terms were generous enough for her to acquiesce when she was assured of her continued reign after the war and that China would not be forced to cede any territory.\nOn 7 September 1901, the Qing imperial court agreed to sign the Boxer Protocol, also known as Peace Agreement between the Eight-Nation Alliance and China. The protocol ordered the execution of 10 high-ranking officials linked to the outbreak and other officials who were found guilty for the slaughter of foreigners in China. Alfons Mumm, Ernest Satow, and Komura Jutaro signed on behalf of Germany, Britain, and Japan, respectively.\nChina was fined war reparations of 450,000,000 taels of fine silver (&lt;templatestyles src=\"Template:Tooltip/styles.css\" /&gt;) for the loss that it caused. The reparation was to be paid by 1940, within 39 years, and would be 982,238,150 taels with interest (4 per cent per year) included. The existing tariff increased from 3.18 to 5 per cent, and formerly duty-free merchandise was newly taxed, to help meet these indemnity demands. The sum of reparations was estimated by the Chinese population size (roughly 450\u00a0million in 1900) at one tael per person. Chinese customs income and salt taxes guaranteed the reparation. China paid 668,661,220 taels of silver from 1901 to 1939\u00a0\u2013 equivalent in 2010 to &lt;templatestyles src=\"Template:Tooltip/styles.css\" /&gt;US$61\u00a0billion on a purchasing-power-parity basis.\nA large portion of the reparations paid to the United States was diverted to pay for the education of Chinese students in US universities under the Boxer Indemnity Scholarship Program. To prepare the students chosen for this program, an institute was established to teach the English language and to serve as a preparatory school. When the first of these students returned to China, they undertook the teaching of subsequent students; from this institute was born Tsinghua University.\nThe US China Inland Mission lost more members than any other missionary agency: 58 adults and 21 children were killed. However, in 1901, when the allied nations were demanding compensation from the Chinese government, Hudson Taylor refused to accept payment for loss of property or life, to demonstrate the meekness and gentleness of Christ to the Chinese.\nThe Belgian Catholic vicar apostolic of Ordos wanted foreign troops garrisoned in Inner Mongolia, but the Governor refused. Bermyn petitioned the Manchu Enming to send troops to Hetao where Prince Duan's Mongol troops and General Dong Fuxiang's Muslim troops allegedly threatened Catholics. It turned out that Bermyn had created the incident as a hoax. Western Catholic missionaries forced Mongols to give up their land to Han Chinese Catholics as part of the Boxer indemnities according to Mongol historian Shirnut Sodbilig. Mongols had participated in attacks against Catholic missions in the Boxer rebellion.\nThe Qing government did not capitulate to all the foreign demands. The Manchu governor Yuxian was executed, but the imperial court refused to execute the Han Chinese General Dong Fuxiang, although he had also encouraged the killing of foreigners during the rebellion. Empress Dowager Cixi intervened when the Alliance demanded him executed and Dong was only cashiered and sent back home. Instead, Dong lived a life of luxury and power in \"exile\" in his home province of Gansu. Upon Dong's death in 1908, all honours which had been stripped from him were restored and he was given a full military burial. The indemnity was never fully paid and was lifted during World War II.\nLong-term consequences.\nThe occupation of Beijing by foreign powers and the failure of the rebellion further eroded support for the Qing state. Support for reforms decreased, while support for revolution increased. In the ten years after the Boxer Rebellion, uprisings in China increased, particularly in the south. Support grew for the \"Tongmenghui\", an alliance of anti-Qing groups which later became the Kuomintang.\nCixi was returned to Beijing, the foreign powers believing that maintaining the Qing government was the best way to control China. The Qing state made further efforts to reform. It abolished the imperial examinations in 1905 and sought to gradually introduce consultative assemblies. Along with the formation of new military and police organisations, the reforms also simplified central bureaucracy and made a start at revamping taxation policies. These efforts failed to maintain the Qing dynasty, which was overthrown in the 1911 Xinhai Revolution.\nIn October 1900, Russia occupied the provinces of Manchuria, a move that threatened Anglo-American hopes of maintaining the country's openness to commerce under the Open Door Policy.\nThe historian Walter LaFeber has argued that President William McKinley's decision to send 5,000 American troops to quell the rebellion marks \"the origins of modern presidential war powers\":\nArthur M. Schlesinger Jr., concurred and wrote:\nAnalysis of the Boxers.\nFrom the beginning, views differed as to whether the Boxers were better seen as anti-imperialist, patriotic and proto-nationalist, or as backward, irrational, and futile opponents of what was inevitable change. The historian Joseph W. Esherick comments that \"confusion about the Boxer Uprising is not simply a matter of popular misconceptions\" since \"there is no major incident in China's modern history on which the range of professional interpretation is as great\".\nThe Boxers drew condemnation from those who wanted to modernise China according to a Western model of civilisation. Sun Yat-sen, considered the founding father of modern China, at the time worked to overthrow the Qing but believed that government spread rumours that \"caused confusion among the populace\" and stirred up the Boxer Movement. He delivered \"scathing criticism\" of the Boxers' \"anti-foreignism and obscurantism\". Sun praised the Boxers for their \"spirit of resistance\" but called them \"bandits\". Students studying in Japan were ambivalent. Some stated that while the uprising originated from the ignorant and stubborn people, their beliefs were brave and righteous and could be transformed into a force for independence. After the fall of the Qing dynasty in 1911, nationalistic Chinese became more sympathetic to the Boxers. In 1918, Sun praised their fighting spirit and said that the Boxers were courageous and fearless in fighting to the death against the Alliance armies, specifically the Battle of Yangcun. Chinese liberals such as Hu Shih, who called on China to modernise, still condemned the Boxers for their irrationality and barbarity. The leader of the New Culture Movement, Chen Duxiu, forgave the \"barbarism of the Boxer\u00a0... given the crime foreigners committed in China\", and contended that it was those \"subservient to the foreigners\" that truly \"deserved our resentment\".\nIn other countries, views of the Boxers were complex and contentious. Mark Twain said that \"the Boxer is a patriot. He loves his country better than he does the countries of other people. I wish him success.\" The Russian writer Leo Tolstoy also praised the Boxers and accused Nicholas II of Russia and Wilhelm II of Germany of being chiefly responsible for the lootings, rapes, murders, and \"Christian brutality\" of the Russian and Western troops. The Russian revolutionary Vladimir Lenin mocked the Russian government's claim that it was protecting Christian civilisation: \"Poor Imperial Government! So Christianly unselfish, and yet so unjustly maligned! Several years ago it unselfishly seized Port Arthur, and now it is unselfishly seizing Manchuria; it has unselfishly flooded the frontier provinces of China with hordes of contractors, engineers, and officers, who, by their conduct, have roused to indignation even the Chinese, known for their docility.\" The Russian newspaper \"Amurskii Krai\" criticised the killing of innocent civilians and charged that restraint would have been more becoming of a \"civilized Christian nation\", asking: \"What shall we tell civilized people? We shall have to say to them: 'Do not consider us as brothers anymore. We are mean and terrible people; we have killed those who hid at our place, who sought our protection.'\" Lenin saw the Boxers as an avant-garde Proletarian force fighting against imperialism.\nSome American churchmen spoke out in support of the Boxers. In 1912, the evangelist George F. Pentecost said that the Boxer uprising was a:\nThe Indian Bengali Rabindranath Tagore attacked the European colonialists. A number of Indian soldiers in the British Indian Army sympathised with the cause of the Boxers, and in 1994 the Indian military returned a bell looted by British soldiers in the Temple of Heaven to China.\nThe events also left a longer impact. Historian Robert Bickers noted that the Boxer Rebellion served as an equivalent to the Indian Rebellion of 1857 for the British government, and agitated the Yellow Peril among the British public. He adds that later events like the Northern Expedition during the 1920s, and even the activities of the Red Guards during the 1960s, were perceived as standing in the shadow of the Boxers.\nHistory textbooks in Taiwan and Hong Kong often present the Boxer as irrational, but the central government textbooks in mainland China have described the Boxer movement as an anti-imperialist, patriotic peasant movement that failed by the lack of leadership from the modern working class\u2014and the international army as an invading force. In recent decades, however, large-scale projects of village interviews and explorations of archival sources have led historians in China to take a more nuanced view. Some non-Chinese scholars, such as Joseph Esherick, have seen the movement as anti-imperialist, but others hold that the concept \"nationalistic\" is anachronistic because the Chinese nation had not been formed, and the Boxers were more concerned with regional issues. Paul Cohen's recent study includes a survey of \"the Boxers as myth\", which shows how their memory was used in changing ways in 20th-century China from the New Culture Movement to the Cultural Revolution.\nIn recent years, the Boxer question has been debated in the People's Republic of China. In 1998, the critical scholar Wang Yi argued that the Boxers had features in common with the extremism of the Cultural Revolution. Both events had the external goal of \"liquidating all harmful pests\" and the domestic goal of \"eliminating bad elements of all descriptions\" and that the relation was rooted in \"cultural obscurantism\". Wang explained to his readers the changes in attitudes towards the Boxers from the condemnation of the May Fourth Movement to the approval expressed by Mao Zedong during the Cultural Revolution. In 2006, Yuan Weishi, a professor of philosophy at Zhongshan University in Guangzhou, wrote that the Boxers by their \"criminal actions brought unspeakable suffering to the nation and its people! These are all facts that everybody knows, and it is a national shame that the Chinese people cannot forget.\" Yuan charged that history textbooks had been lacking in neutrality by presenting the Boxer Uprising as a \"magnificent feat of patriotism\" and not the view that most Boxer rebels were violent. In response, some labelled Yuan Weishi a \"traitor\" (Hanjian).\nTerminology.\nThe name \"Boxer Rebellion\", concludes Joseph W. Esherick, a contemporary historian, is truly a \"misnomer\", for the Boxers \"never rebelled against the Manchu rulers of China and their Qing dynasty\" and the \"most common Boxer slogan, throughout the history of the movement, was 'support the Qing, destroy the Foreign,' where 'foreign' clearly meant the foreign religion, Christianity, and its Chinese converts as much as the foreigners themselves\". He adds that only after the movement was suppressed by the Allied Intervention did the foreign powers and influential Chinese officials both realise that the Qing would have to remain as the government of China to maintain order and collect taxes to pay the indemnity. Therefore, to save face for the Empress Dowager and the members of the imperial court, all argued that the Boxers were rebels and that the only support which the Boxers received from the imperial court came from a few Manchu princes. Esherick concludes that the origin of the term \"rebellion\" was \"purely political and opportunistic\", but it has had a remarkable staying power, particularly in popular accounts.\nOn 6 June 1900, \"The Times\" of London used the term \"rebellion\" in quotation marks, presumably to indicate its view that the rising was actually instigated by Empress Dowager Cixi. The historian Lanxin Xiang refers to the uprising as the \"so called 'Boxer Rebellion'\", and he also states that \"while peasant rebellion was nothing new in Chinese history, a war against the world's most powerful states was.\" Other recent Western works refer to the uprising as the \"Boxer Movement\", the \"Boxer War\" or the Yihetuan Movement, while Chinese studies refer to it as the \"Yihetuan Movement\" (). In his discussion of the general and legal implications of the terminology involved, the German scholar Thoralf Klein notes that all of the terms, including the Chinese terms, are \"posthumous interpretations of the conflict\". He argues that each term, whether it be \"uprising\", \"rebellion\" or \"movement\" implies a different definition of the conflict. Even the term \"Boxer War\", which has frequently been used by scholars in the West, raises questions. Neither side made a formal declaration of war. The imperial edicts on June 21 said that hostilities had begun and directed the regular Chinese army to join the Boxers against the Allied armies. This was a de facto declaration of war. The Allied troops behaved like soldiers who were mounting a punitive expedition in colonial style, rather than soldiers who were waging a declared war with legal constraints. The Allies took advantage of the fact that China had not signed \"The Laws and Customs of War on Land\", a key document signed at the 1899 Hague Peace Conference. They argued that China had violated provisions that they themselves ignored.\nThere is also a difference in terms referring to the combatants. The first reports which came from China in 1898 referred to the village activists as the \"Yihequan\", (Wade\u2013Giles: I Ho Ch'uan). The earliest use of the term \"Boxer\" is contained in a letter which was written in Shandong in September 1899 by missionary Grace Newton. The context of the letter makes it clear that when it was written, \"Boxer\" was already a well-known term, probably coined by Arthur Henderson Smith or Henry Porter, two missionaries who were also residing in Shandong. Smith wrote in his 1902 book that the name:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u00a0... literally denotes the \"Fists\" () of Righteousness (or Public) () Harmony (), in apparent allusion to the strength of the united force which was to be put forth. As the Chinese phrase \"fists and feet\" signifies boxing and wrestling, there appeared to be no more suitable term for the adherents of the sect than \"Boxers\", a designation first used by one or two missionary correspondents of foreign journals in China, and later universally accepted on account of the difficulty of coining a better one.\nMedia portrayal.\nBy 1900, many new forms of media had matured, including illustrated newspapers and magazines, postcards, broadsides, and advertisements, all of which presented images of the Boxers and the invading armies. The rebellion was covered in the foreign illustrated press by artists and photographers. Paintings and prints were also published including Japanese woodblocks. In the following decades, the Boxers were a constant subject of comment. A sampling includes:\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "60521", "revid": "5808430", "url": "https://en.wikipedia.org/wiki?curid=60521", "title": "HMS Scorpion (1863)", "text": "Ironclad turret ship\nHMS \"Scorpion\" was an ironclad turret ship built by John Laird Sons &amp; Company, at Birkenhead, England. She was one of two sister ships secretly ordered from the Laird shipyard in 1862 by the Confederate States of America.\nHer true ownership was concealed by the fiction that she was being built as the Egyptian warship \"El Tousson\". She was to have been named CSS \"North Carolina\" upon delivery to the Confederacy. Her sister was built under the false name \"El Monassir\" and was to have been renamed CSS \"Mississippi\". In October 1863, a few months after their launch and before they could be completed, the UK Government seized the two ironclads.\nIn 1864 the Admiralty bought them and commissioned them into the Royal Navy: \"El Tousson\" as HMS \"Scorpion\" and \"El Monassir\" as . \"Scorpion\" had a long Royal Navy career, until she was lost in the North Atlantic in 1903.\nDesign and description.\n\"North Carolina\" and her sister were intended, together with other warships, to break the Federal blockade of Confederate coastal cities and to hold some Northern cities for ransom. The ships had a length between perpendiculars of , a beam of , and a draught of at deep load. They displaced . The hull was divided by 12 watertight bulkheads and the ships had a double bottom beneath the engine and boiler rooms. Their crew consisted of 152 officers and ratings.\nThe \"Scorpion\"-class ships had two horizontal direct-acting steam engines, built by Lairds, each driving a single propeller shaft, using steam provided by four tubular boilers. The engines produced a total of which gave the ships a maximum speed of . The ships carried of coal, enough to steam at . They were barque-rigged with three masts. The funnel was made semi-retractable to reduce wind resistance while under sail.\nNo ordnance had been ordered by the Confederates before the ships were seized in 1863, but in British service they mounted a pair of 9-inch rifled muzzle-loading guns in each turret. The guns could fire both solid shot and explosive shells. According to Parkes, going from full depression to full elevation supposedly took one hour in smooth water and with an even keel!\nThe \"Scorpion\"-class ships had a complete waterline belt of wrought iron that was thick amidships and thinned to at the bow and at the stern. It completely covered the hull from the upper deck to below the waterline. The armour protection of the turrets was quite elaborate. The inside of the turret was lined with of iron boiler plate to which T-shaped beams were bolted. The space between the beams was filled with of teak. This was covered by an iron lattice thick that was covered in turn by of teak. The iron plates were bolted to the outside using bolts that ran through to the interior iron \"skin\". The area around the gun ports was reinforced by 4.5-inch plates to give a total thickness of 10 inches. The turret roof consisted of T-shaped beams covered by iron plates.\nConstruction and career.\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;\nIn early 1864, the Admiralty purchased both for the Royal Navy and named them \"Scorpion\" and . Commissioned in July 1865, \"Scorpion\" was assigned to the Channel Fleet until 1869, with time out for a refit that reduced her sailing rig from a bark to a schooner. In late 1869, she moved to Bermuda for coast and harbour defence service. \"Scorpion\" remained there for over three decades before being removed from the effective list. \"Scorpion\" was sunk as a target in 1901 but raised the next year and sold in February 1903. She was lost at sea while under tow to the U.S., where she was to be scrapped.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60522", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=60522", "title": "SONAR", "text": ""}
{"id": "60523", "revid": "31696229", "url": "https://en.wikipedia.org/wiki?curid=60523", "title": "1954 FIFA World Cup", "text": "Association football tournament in Switzerland\nInternational football competition\nThe 1954 FIFA World Cup was the 5th edition of the FIFA World Cup, the quadrennial international football tournament for senior men's national teams of the nations affiliated to FIFA. It was held in Switzerland from 16 June to 4 July. Switzerland was selected as the host country in July 1946. At the tournament, several all-time records for goalscoring were set, including the highest average number of goals scored per game. The tournament was won by West Germany, who defeated tournament favourites Hungary 3\u20132 in the final for their first World Cup title. Uruguay, the defending champions, were eliminated by Hungary and would lose to Austria in the third-place match.\nThe highest scoring match of a men\u2019s World Cup happened in the quarter-finals of this tournament, when Austria defeated hosts Switzerland 7\u20135. The 12 goals of that match have never been surpassed in a men\u2019s World Cup since \u2014 the 2019 Women's World Cup saw the USA beat Thailand 13\u20130.\nHost selection.\nSwitzerland was awarded the tournament unopposed at a meeting in Luxembourg City on 22 July 1946, the same day Brazil was selected to host the 1950 World Cup.\nQualification.\nThe hosts (Switzerland) and the defending champions (Uruguay) qualified automatically. Of the remaining 14 places, 11 were allocated to Europe (including Egypt, Turkey, and Israel), two to the Americas, and one to Asia.\nScotland, Turkey, and South Korea made their World Cup debuts at this tournament (Turkey and Scotland had qualified for the 1950 competition but both withdrew). South Korea became the first independent Asian country to participate in a World Cup tournament. Austria appeared following a hiatus from 1934. Several teams, such as Hungary and Czechoslovakia were back into the tournament after missing out the 1950 World Cup.\nGerman teams as well as Japan were allowed to qualify again, after having been banned from the 1950 FIFA World Cup. West Germany qualified against fellow Germans from the Saarland (which then was a French protectorate), while East Germany did not enter, having cancelled international football matches after the East German uprising of 1953. Argentina declined to participate for the third successive World Cup.\nList of qualified teams.\nThe following 16 teams qualified for the final tournament.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nSummary.\nFormat.\nGroup stage.\nThe 1954 tournament used a unique format. The sixteen qualifying teams were divided into four groups of four teams each. Each group contained two seeded teams and two unseeded teams. Only four matches were scheduled for each group, each pitting a seeded team against an unseeded team. This contrasts with the usual round-robin in which every team plays every other team: six matches in each group. Another oddity was that extra time, which in most tournaments is not employed at the group stage, was played in the group games if the score was level after 90 minutes, with the result being a draw if the scores were still level after 120 minutes.\nTwo points were awarded for a win and one for a draw. The two teams with the most points from each group progressed to the knockout stage. In the case of a tie between two teams for second place, the two tied teams competed in a play-off to decide which team would progress to the next stage, with extra time and drawing of lots if necessary. Had all four teams in a group been tied on points, there would have been two further play-offs \u2013 one play-off between the two seeded teams, and the other between the two unseeded teams, again with extra time and drawing of lots if necessary \u2013 with the winner of each play-off progressing to the quarter-finals.\nTwo of the four groups ended up requiring play-offs \u2013 one between Switzerland and Italy, and the other between Turkey and West Germany. In each match, the unseeded team (Switzerland and West Germany) repeated an earlier victory against the seeded team (Italy and Turkey) to progress. The fact that two group matches were played twice, while other group opponents never faced each other at all, attracted criticism; newly elected FIFA President Seeldrayers declared that this group format would be abandoned in future world cups.\nQuarter-finals.\nFor each of the first two quarter-finals, one team progressing from group 1 was drawn against one team progressing from group 2. For the remaining two quarter-finals, this procedure was repeated for groups 3 and 4. Before the tournament, it was stated that in the event of a quarter-final being tied after 90 minutes, 30 minutes of extra time would be played, followed by drawing of lots if necessary. Later, it was stated that a quarter-final could be replayed in this situation. The draw was scheduled to be held on Sunday 20 June, though in fact it was delayed into the early morning of Monday 21 June.\nSemi-finals.\nFor the semi-finals, a further draw was held, with each semi-final featuring one team from groups 1\u20132 against one team from groups 3\u20134. In the event of a semi-final being tied after extra time, it would be replayed once, followed by drawing of lots if necessary.\nThe draw for the semi-finals, held on Sunday 27 June, was delayed by a complaint from the Hungarian team concerning the manner in which their quarter-final against Brazil had been played.\nFinal.\nThe final would be replayed if scores were level after extra-time. If the replay was also tied, the winner would be decided by the tournament organising committee, or by drawing of lots.\nSeeding.\nBefore qualification was complete, the eight seeded teams were determined by FIFA. They were Austria, Brazil, England, France, Hungary, Italy, Spain, and Uruguay.\nThese seedings were thrown into disarray when, in an unexpected result, Turkey eliminated Spain in qualification. FIFA resolved this situation by giving Turkey the seeding that had previously been allocated to Spain.\nNotable results.\nThe Germany national football team, then limited to the area of West Germany only, had been reinstated as full FIFA members only in late 1950, had played only 18 games since, and were unseeded. When meeting the seeded Turkish side at Wankdorf stadium in Berne, the Turks scored early, but the Germans convincingly won the encounter, which would turn out as the first of two within six days.\nThe South Koreans, the other unseeded team, lost 7\u20130 and 9\u20130 against the seeded sides of Hungary and Turkey. West Germany, being denied the chance to play such an easy opponent, had to face the seeded team of Hungary, a favourite to win the World Cup. Sepp Herberger, the West German coach, did not want his A-squad to suffer a possible defeat against a strong opponent while trying to qualify for a rather meaningless first place, and gambled by going the easier route into the play-offs and sending in a reserve side which lost 8\u20133 in Basel. A benefit was that the Hungarians did not get to know the best German players in case both teams would meet again - which they did, in the Final, along with referee William Ling. Now two teams were tied for second place on 2 points, and with no tie breaking procedures in effect, even though West Germany had beaten Turkey head-to-head, they had to play-off against each other, a match-up that West Germany easily won for the second time within six days, this time in Z\u00fcrich. \nHungary's team captain Ferenc Pusk\u00e1s, considered by many as the best player in the world in that time, was injured by West German defender Werner Liebrich, and had to miss Hungary's next two matches. Pusk\u00e1s played for Hungary in the final, despite still being in a questionable condition.\nIn the quarter-finals, the favourites Hungary beat Brazil 4\u20132 in one of the most violent matches in football history, which became infamous as the Battle of Berne. Meanwhile, the World Cup holders Uruguay sent England out of the tournament, also by 4\u20132. West Germany dispatched Yugoslavia 2\u20130, and Austria beat the host nation Switzerland in the game that saw the most goals in any World Cup match, 7\u20135.\nIn the first semi-final, West Germany beat Austria 6\u20131.\nThe other semi-final, one of the most exciting games of the tournament, saw Hungary go into the second half leading Uruguay 1\u20130, only for the game to be taken to extra time with a score after 90 minutes of 2\u20132. The deadlock was broken by S\u00e1ndor Kocsis with two late goals to take Hungary through to the final, with Uruguay finally losing their unbeaten record in World Cup Final matches. Uruguay then went on to be beaten for a second time as Austria secured third place.\nFinal: \"The Miracle of Bern\".\nThe Wankdorf Stadion in Berne saw 60,000 people cram inside to watch the final between West Germany and Hungary, a rematch of a first-round game, which Hungary had won 8\u20133 against the reserves of the German team. The Golden Team of the Hungarians were favourites, as they were unbeaten for a record of 32 consecutive matches, but they had had two tough knockout matches. It started raining on match day\u2013in Germany this was dubbed \"Fritz-Walter-Wetter\" (\"Fritz Walter's weather\") because the West German team captain Fritz Walter was said to play his best in the rain, a result of having contracted malaria during the war. Adi Dassler of \"Adidas\" provided the West German team with a new kind of shoes, with exchangeable studs that were replaced during halftime. \nHungary's Ferenc Pusk\u00e1s played again in the final, even though he was not fully fit. Despite this he put his team ahead after only six minutes and with Zolt\u00e1n Czibor adding another two minutes later it seemed that the pre-tournament favourites would take the title. However, with a quick goal from Max Morlock in the 10th minute and an equaliser by Helmut Rahn in the 19th, the tide began to turn.\nThe second half saw telling misses by the Hungarian team. Barely six minutes before the end of the match, the popular German radio reporter Herbert Zimmermann delivered the most famous line in the German commentary, recommending that \"Rahn should shoot from deep\", which he did. The second goal from Rahn gave West Germany a 3\u20132 lead while the Hungarian reporter Gy\u00f6rgy Szepesi burst into tears. Later, Zimmermann called Pusk\u00e1s offside before he kicked the ball into Toni Turek's net with 2 minutes left. While referee William Ling pointed to the centre spot, linesman Griffiths signalled offside. After a one-minute consultation, Ling disallowed the claimed equaliser.\nThe West Germans were handed the Jules Rimet Trophy as World Cup winners, while the crowd sang along to the tune of the national anthem of Germany\u2013there was disquiet in the stadium as the Germans fans decided to sing the (too) well known anthem's first stanza \"Deutschland \u00fcber alles\", instead of the uncontroversial third \"Unity and Justice and Freedom\" which was supposed to be sung at official events according to a 1952 decree. In Germany the success is known as the \"Miracle of Bern\" (\"Das Wunder Von Bern\"), and was memorialised in a 2003 film of the same name. For the Hungarians, the defeat was a disaster, and remains controversial due to apparent refereeing errors and claims of doping.\nOne controversy concerns the 2\u20132 equaliser. Hungarian goalie Gyula Grosics jumped to catch Fritz Walter's corner shot, but Hans Sch\u00e4fer obstructed him (in plain sight of TV cameras), allowing the ball to reach Rahn, who then scored. Another controversy concerns allegations of doping. Though teammates steadfastly denied this rumour, German historian Guido Knopp claimed in a 2004 documentary for German public channel ZDF that the players were injected with shots of vitamin C at half-time, using a needle earlier taken from a Soviet sports doctor. This would explain both the better condition of the West German team in the second half and the wave of jaundice among their players following the tournament. A Leipzig University study in 2010 posited that the West German players had been injected with the banned substance methamphetamine.\nMost controversial was the offside ruling for Pusk\u00e1s's intended 87th-minute equaliser. The camera filming the official footage was in a bad position to judge the situation, but eyewitnesses claimed that the referee was wrong, including West German substitute player Alfred Pfaff. In 2004, North German regional public channel NDR aired unofficial footage appearing to show that Pusk\u00e1s was onside.\nRecords.\nThe following all-time records were set or equalled at this tournament, and have not been surpassed:\nAll matches in one tournament\nTeam records for one tournament\nRecords for a single game\nOther landmarks.\nFor the first time there was television coverage, and special coins were issued to mark the event.\nThe 11 goals scored by Kocsis of Hungary not only led the World Cup but bettered the previous record (set by Brazilian Ademir in the previous tournament) by three goals. Kocsis' mark was broken by Just Fontaine's 13 goals in 1958. Despite not winning the 1954 tournament, their fourth-place finish and their two previous World Cup titles made Uruguay the most successful World Cup nation for eight years, until Brazil won their second title in 1962. Hungary's 9\u20130 win against Korea during the group stages remains the biggest margin of victory in FIFA World Cup history, later equalled by Yugoslavia over Zaire (9\u20130) in 1974 and Hungary over El Salvador (10\u20131) in 1982.\nWest Germany also became the first team to win the World Cup after having lost a match at the finals, losing 8\u20133 after pitting the backups against Hungary in the group stage with the intention of getting an additional play-off game. This feat was repeated by West Germany in 1974 (beaten 1\u20130 by East Germans), Argentina in 1978 and Spain in 2010, who all lost group matches 1\u20130 (coincidentally, all three teams won against the Netherlands in the final), as well as by Argentina in 2022, who lost their first group match 2\u20131 against Saudi Arabia but would also defeat the Netherlands (although this time, it was in the quarter-finals).\nWest Germany's 1954 victory remains the only time that a team has won the World Cup without playing any team from outside its own continent; South Korea was in the same group, but with both team unseeded, they were not matched against each other. Instead, West Germany had to play Turkey twice, which is geographically more in Asia than in Europe, but qualified from Europe's qualification zone and has always been affiliated with UEFA. Turkey had also been one of the few non-German speaking countries that had played West Germany after being reinstated as FIFA member in late 1950; and like most, did it twice, Switzerland even four times. Thus, West Germany's coach and players had limited international experience in 1954, and no intercontinental game before the 1958 FIFA World Cup.\nWest Germany's victory in the final is considered one of the greatest upsets of all time and one of the finest achievements in German sporting history. The West German team was made up of amateur \"contract\" players from several regional leagues, as German sports did not have a nationwide league nor professional play before 1963, while the Hungarians were \"de jure\" amateurs, like in all the communist countries at that time, but playing football as professionals, mainly for Budapesti Honv\u00e9d FC and later for major clubs like Real Madrid and Barcelona in Spain, and were ranked best in the world. This is the only time a team has won the World Cup with amateur footballers.\nVenues.\nSix venues in six cities (1 venue in each city) hosted the tournament's 26 matches. The most used stadium was the St. Jakob Stadium in Basel, which hosted 6 matches. The venues in Bern, Zurich and Lausanne each hosted 5 matches, the venue in Geneva hosted 4 matches, and the venue in Lugano only hosted 1 match.\nSquads.\nThe 16 finalists named squads of 22 for the finals, though South Korea only named 20 players in their squad. Unlike recent tournaments, there were no requirements for teams to name three goalkeepers; most teams did, but 6 did not. Some teams also chose to leave some of their named squad at home, only bringing them to Switzerland if necessary.\nMatch officials.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nGroup stage.\nAll times listed are local time (CET, ).\nKnockout stage.\nBracket.\n&lt;section begin=\"Bracket\" /&gt;&lt;section end=\"Bracket\" /&gt;\nGoalscorers.\nWith 11 goals, S\u00e1ndor Kocsis was the top scorer in the tournament. In total, 140 goals were scored by 63 players, with four of them credited as own goals.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFIFA retrospective ranking.\nIn 1986, FIFA published a report that ranked all teams in each World Cup up to and including 1986, based on progress in the competition, overall results and quality of the opposition. The rankings for the 1954 tournament were as follows:\nIn film.\nThe final scene of Rainer Werner Fassbinder's film \"The Marriage of Maria Braun\" takes place during the finals of the 1954 World Cup; in the scene's background, the sports announcer is celebrating West Germany's victory and shouting \"Deutschland ist wieder was!\" (Germany is something again); the film uses this as the symbol of Germany's recovery from the ravages of the Second World War.\nS\u00f6nke Wortmann's 2003 German box-office hit \"The Miracle of Bern\" (in German: \"Das Wunder von Bern\") re-tells the story of the German team's route to victory through the eyes of a young boy who admires the key player of the final, Helmut Rahn.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60524", "revid": "1320129369", "url": "https://en.wikipedia.org/wiki?curid=60524", "title": "General semantics", "text": "School of thought on cognition and problem-solving\nGeneral semantics is a school of thought that incorporates philosophic and scientific aspects. Although it does not stand on its own as a separate school of philosophy, a separate science, or an academic discipline, it describes itself as a scientifically empirical approach to cognition and problem solving. It has been described by nonproponents as a self-help system, and it has been criticized as having pseudoscientific aspects, but it has also been favorably viewed by various scientists as a useful set of analytical tools albeit not its own science.\nGeneral semantics is concerned with how phenomena (observable events) translate to perceptions, how they are further modified by the names and labels we apply to them, and how we might gain a measure of control over our own cognitive, emotional, and behavioral responses. Proponents characterize general semantics as an antidote to certain kinds of delusional thought patterns in which incomplete and possibly warped mental constructs are projected onto the world and treated as reality itself. Accurate map\u2013territory relations are a central theme.\nAfter partial launches under the names \"human engineering\" and \"humanology\", Polish-American originator Alfred Korzybski (1879\u20131950) fully launched the program as \"general semantics\" in 1933 with the publication of \"Science and Sanity: An Introduction to Non-Aristotelian Systems and General Semantics\".\nIn \"Science and Sanity\", general semantics is presented as both a theoretical and a practical system whose adoption can reliably alter human behavior in the direction of greater sanity. In the 1947 preface to the third edition of \"Science and Sanity\", Korzybski wrote: \"We \"need not\" blind ourselves with the old dogma that 'human nature cannot be changed', for we find that it \"can be changed\".\" While Korzybski considered his program to be empirically based and to strictly follow the scientific method, general semantics has been described as veering into the domain of pseudoscience.\nStarting around 1940, university English professor S.\u00a0I. Hayakawa (1906\u20131992), speech professor Wendell Johnson, speech professor Irving J. Lee, and others assembled elements of general semantics into a package suitable for incorporation into mainstream communications curricula. The Institute of General Semantics, which Korzybski and co-workers founded in 1938, continues today. General semantics as a movement has waned considerably since the 1950s, although many of its ideas live on in other movements, such as media literacy, neuro-linguistic programming and rational emotive behavior therapy.\nOverview.\n\"Identification\" and \"the silent level\".\nIn the 1946 \"Silent and Verbal Levels\" diagram, the arrows and boxes denote ordered stages in human neuro-evaluative processing that happens in an instant. Although newer knowledge in biology has more sharply defined what the text in these 1946 boxes labels \"electro-colloidal\", the diagram remains, as Korzybski wrote in his last published paper in 1950, \"satisfactory for our purpose of explaining briefly the most general and important points\". General semantics postulates that most people \"identify,\" or fail to differentiate the serial stages or \"levels\" within their own neuro-evaluative processing. \"Most people,\" Korzybski wrote, \"\"identify in value\" levels I, II, III, and IV and react \"as if\" our verbalizations about the first three levels were 'it.' Whatever we may say something 'is' obviously \"is not\" the 'something' on the silent levels.\" \nBy making it a 'mental' habit to find and keep one's bearings among the ordered stages, general semantics training seeks to sharpen internal orientation much as a GPS device may sharpen external orientation. Once trained, general semanticists affirm, a person will act, respond, and make decisions more appropriate to any given set of happenings. Although producing saliva constitutes an appropriate response when lemon juice drips onto the tongue, a person has inappropriately identified when an imagined lemon or the word \"l\u2013e\u2013m\u2013o\u2013n\" triggers a salivation response.\n\"Once we differentiate, differentiation becomes the denial of identity,\" Korzybski wrote in \"Science and Sanity\". \"Once we discriminate among the objective and verbal levels, we learn 'silence' on the unspeakable objective levels, and so introduce a most beneficial neurological 'delay'\u2014engage the cortex to perform its natural function.\" British-American philosopher Max Black, an influential critic of general semantics, called this neurological delay the \"central aim\" of general semantics training, \"so that in responding to verbal or nonverbal stimuli, we are aware of what it is that we are doing\".\nAbstracting and consciousness of abstracting.\nIdentification prevents what general semantics seeks to promote: the additional cortical processing experienced as a delay. Korzybski called his remedy for identification \"consciousness of abstracting.\" The term \"abstracting\" occurs ubiquitously in \"Science and Sanity.\" Korzybski's use of the term is somewhat unusual and requires study to understand his meaning. He discussed the problem of identification in terms of \"confusions of orders of abstractions\" and \"lack of consciousness of abstracting\". To be conscious of abstracting is to differentiate among the \"levels\" described above; levels II\u2013IV being abstractions of level I (whatever level I \"is\"\u2014all we really get are abstractions). The techniques Korzybski prescribed to help a person develop consciousness of abstracting he called \"extensional devices\".\nExtensional devices.\nSatisfactory accounts of general semantics extensional devices can be found easily. This article seeks to explain briefly only the \"indexing\" devices. Suppose you teach in a school or university. Students enter your classroom on the first day of a new term, and, if you identify these new students to a memory association retrieved by your brain, you under-engage your powers of observation and your cortex. Indexing makes explicit a differentiating of studentsthis term from studentsprior terms. You survey the new students, and indexing explicitly differentiates student1 from student2 from student3, etc. Suppose you recognize one student\u2014call her Anna\u2014from a prior course in which Anna either excelled or did poorly. Again, you escape identification by your indexed awareness that Annathis term, this course is different from Annathat term, that course. Not identifying, you both expand and sharpen your apprehension of \"students\" with an awareness rooted in fresh silent-level observations.\nLanguage as a core concern.\nAutoassociative memory in the memory-prediction model describes neural operations in mammalian brains generally. A special circumstance for humans arises with the introduction of language components, both as fresh stimuli and as stored representations. Language considerations figure prominently in general semantics, and three language and communications specialists who embraced general semantics, university professors and authors Hayakawa, Wendell Johnson and Neil Postman, played major roles in framing general semantics, especially for non-readers of \"Science and Sanity\".\nCriticism.\nKorzybski wrote in the preface to the third edition of \"Science and Sanity\" (1947) that general semantics \"turned out to be an empirical natural science\". But the type of existence, if any, of universals and abstract objects is an issue of serious debate within metaphysical philosophy. So Black summed up general semantics as \"some hypothetical neurology fortified with dogmatic metaphysics\". And in 1952, two years after Korzybski died, American skeptic Martin Gardner wrote, \"[Korzybski's] work moves into the realm of cultism and pseudo-science.\"\nFormer Institute of General Semantics executive director Steve Stockdale has compared GS to yoga. \"First, I'd say that there is little if any benefit to be gained by just \"knowing\" something about general semantics. The benefits come from maintaining an awareness of the principles and attitudes that are derived from GS and applying them as they are needed. You can sort of compare general semantics to yoga in that respect... knowing about yoga is okay, but to benefit from yoga you have to \"do\" yoga.\" Similarly, Kenneth Burke explains Korzybski's kind of semantics contrasting it, in \"A Grammar of Motives\", with a kind of Burkean poetry by saying \"\"Semantics\" is essentially scientist, an approach to language in terms of knowledge, whereas poetic forms are kinds of action\".\nHistory.\nEarly attempts at validation.\nThe First American Congress for General Semantics convened in March 1935 at the Central Washington College of Education in Ellensburg, Washington. In introductory remarks to the participants, Korzybski said: General semantics formulates a new experimental branch of natural science, underlying an empirical theory of human evaluations and orientations and involving a definite neurological mechanism, present in all humans. It discovers direct neurological methods for the stimulation of the activities of the human cerebral cortex and the direct introduction of beneficial neurological 'inhibition'... He added that general semantics \"will be judged by experimentation\". One paper presented at the congress reported dramatic score improvements for college sophomores on standardized intelligence tests after six weeks of training by methods prescribed in Chapter 29 of \"Science and Sanity.\"\nInterpretation as semantics.\nGeneral semantics accumulated only a few early experimental validations. In 1938, economist and writer Stuart Chase praised and popularized Korzybski in \"The Tyranny of Words\". Chase called Korzybski \"a pioneer\" and described \"Science and Sanity\" as \"formulating a genuine science of communication. The term which is coming into use to cover such studies is 'semantics,' matters having to do with signification or meaning.\" Because Korzybski, in \"Science and Sanity\", had articulated his program using \"semantic\" as a standalone qualifier on hundreds of pages in constructions like \"semantic factors,\" \"semantic disturbances,\" and especially \"semantic reactions,\" to label the general semantics program \"semantics\" amounted to only a convenient shorthand.\nHayakawa read \"The Tyranny of Words,\" then \"Science and Sanity\", and in 1939 he attended a Korzybski-led workshop conducted at the newly organized Institute of General Semantics in Chicago. In the introduction to his own \"Language in Action\", a 1941 Book of the Month Club selection, Hayakawa wrote, \"[Korzybski's] principles have in one way or another influenced almost every page of this book...\" But, Hayakawa followed Chase's lead in interpreting general semantics as making communication its defining concern. When Hayakawa co-founded the Society for General Semantics and its publication \"ETC: A Review of General Semantics\" in 1943\u2014he would continue to edit \"ETC.\" until 1970\u2014Korzybski and his followers at the Institute of General Semantics began to complain that Hayakawa had wrongly coopted general semantics. In 1985, Hayakawa gave this defense to an interviewer: \"I wanted to treat general semantics as a subject, in the same sense that there's a scientific concept known as gravitation, which is independent of Isaac Newton. So after a while, you don't talk about Newton anymore; you talk about gravitation. You talk about semantics and not Korzybskian semantics.\"\nLowered sights.\nThe regimen in the Institute's seminars, greatly expanded as team-taught seminar-workshops starting in 1944, continued to develop following the prescriptions laid down in Chapter XXIX of \"Science and Sanity.\" The structural differential, patented by Korzybski in the 1920s, remained among the chief training aids to help students reach \"the silent level,\" a prerequisite for achieving \"neurological delay\". Innovations in the seminar-workshops included a new \"neuro-relaxation\" component, led by dancer and Institute editorial secretary Charlotte Schuchardt (1909\u20132002).\nBut although many people were introduced to general semantics\u2014perhaps the majority through Hayakawa's more limited 'semantics'\u2014superficial lip service seemed more common than the deep internalization that Korzybski and his co-workers at the Institute aimed for. Marjorie Kendig (1892\u20131981), probably Korzybski's closest co-worker, director of the Institute after his death, and editor of his posthumously published \"Collected Writings: 1920\u20131950\", wrote in 1968:I would guess that I have known about 30 individuals who have in some degree adequately, by my standards, mastered this highly general, very simple, very difficult system of orientation and method of evaluating\u2014reversing as it must all our cultural conditioning, neurological canalization, etc...\nTo me the \"great error\" Korzybski made\u2014and I carried on, financial necessity\u2014and for which we pay the price today in many criticisms, consisted in not restricting ourselves to training very thoroughly \"a very few people\" who would be competent to utilize the discipline in various fields and to train others. We should have done this before encouraging anyone to popularize or spread the word (horrid phrase) in societies for general semantics, by talking \"about\" general semantics instead of learning, using, etc. the methodology to \"change\" our essential epistemological assumptions, premises, etc. (unconscious or conscious), i.e. the \"un\"-learning basic to learning to learn.\nYes, large numbers of people do enjoy making a philosophy of general semantics. This saves them the pain of rigorous training so simple and general and limited that it seems obvious when \"said\", yet so difficult.\nSuccessors at the Institute of General Semantics continued for many years along the founders' path. Stuart Mayper (1916\u20131997), who studied under Karl Popper, introduced Popper's principle of falsifiability into the seminar-workshops he led at the Institute starting in 1977. More modest pronouncements gradually replaced Korzybski's claims that general semantics can change human nature and introduce an era of universal human agreement. In 2000, Robert Pula (1928\u20132004), whose roles at the Institute over three decades included Institute director, editor-in-chief of the Institute's \"General Semantics Bulletin\", and leader of the seminar-workshops, characterized Korzybski's legacy as a \"contribution toward the improvement of human evaluating, to the amelioration of human woe...\"\nHayakawa died in 1992. The Society for General Semantics merged into the Institute of General Semantics in 2003. In 2007, Martin Levinson, president of the Institute's Board of Trustees, teamed with Paul D. Johnston, executive director of the Society at the date of the merger, to teach general semantics with a light-hearted \"Practical Fairy Tales for Everyday Living\".\nOther institutions supporting or promoting general semantics in the 21st century include the New York Society for General Semantics, the European Society for General Semantics, the Australian General Semantics Society, and the Balvant Parekh Centre for General Semantics and Other Human Sciences (Baroda, India).\nConnections to other disciplines.\nThe influence of Ludwig Wittgenstein and the Vienna Circle, and of early operationalists and pragmatists such as Charles Sanders Peirce, is particularly clear in the foundational ideas of general semantics. Korzybski himself acknowledged many of these influences.\nThe concept of \"silence on the objective level\"\u2014attributed to Korzybski and his insistence on consciousness of abstracting\u2014are parallel to some of the central ideas in Buddhism. Although Korzybski never acknowledged any influence from this quarter, later Zen-popularizer Alan Watts was influenced by ideas from general semantics.\nGeneral semantics has survived most profoundly in the cognitive therapies that emerged in the 1950s and 1960s. Albert Ellis (1913\u20132007), who developed rational emotive behavior therapy, acknowledged influence from general semantics and delivered the Alfred Korzybski Memorial Lecture in 1991. The Bruges (Belgium) center for solution-focused brief therapy operates under the name Korzybski Institute Training and Research Center. George Kelly, creator of personal construct psychology, was influenced by general semantics. Fritz Perls and Paul Goodman, founders of Gestalt therapy are said to have been influenced by Korzybski Wendell Johnson wrote \"People in Quandaries: The Semantics of Personal Adjustment\" in 1946, which stands as the first attempt to form a therapy from general semantics.\nRay Solomonoff (1926\u20132009) was influenced by Korzybski. Solomonoff was the inventor of algorithmic probability, and founder of algorithmic information theory ( Kolmogorov complexity).\nAnother scientist influenced by Korzybski (verbal testimony) is Paul Vitanyi (born 1944), a scientist in the theory of computation.\nDuring the 1940s, 1950s, and 1960s, general semantics entered the idiom of science fiction. Notable examples include the works of A. E. van Vogt, \"The World of Null-A\" and its sequels. General semantics appear also in Robert A. Heinlein's work, especially \"Gulf\". Bernard Wolfe drew on general semantics in his 1952 science fiction novel \"Limbo\". Frank Herbert's novels \"Dune\" and \"Whipping Star\" are also indebted to general semantics. The ideas of general semantics became a sufficiently important part of the shared intellectual toolkit of genre science fiction to merit parody by Damon Knight and others; they have since shown a tendency to reappear in the work of more recent writers such as Samuel R. Delany, Suzette Haden Elgin and Robert Anton Wilson. In 2008, John Wright extended van Vogt's Null-A series with Null-A Continuum. William Burroughs references Korzybski's time binding principle in his essay The Electronic Revolution, and elsewhere. Henry Beam Piper explicitly mentioned general semantics in \"Murder in the Gunroom\", and its principles, such as awareness of the limitations of knowledge, are apparent in his later work. A fictional rendition of the \"Institute of General Semantics\" appears in the 1965 French science fiction film, Alphaville, directed by Jean-Luc Godard.\nNeil Postman, founder of New York University's media ecology program in 1971, edited \"ETC: A Review of General Semantics\" from 1976 to 1986. Postman's student Lance Strate, a co-founder of the Media Ecology Association, served as executive director of the Institute of General Semantics from 2007 to 2010.\nWith Charles Weingartner, Neil Postman included General Semantics within the introductory background analysis in \"Teaching as a Subversive Activity\" (Delacorte, 1969). In particular, they argued that General Semantics fitted with what Postman and Weingartner referred to as the \"Whorf-Sapir hypothesis\", the claim that the particular language used to describe experience shapes how we perceive and understand that experience; that is, language shapes the way people think. (The \"Whorf-Sapir hypothesis\" is also known as Linguistic relativity.)\nSee also.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nRelated books\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nRelated books.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nRelated academic articles.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;"}
{"id": "60525", "revid": "1601135", "url": "https://en.wikipedia.org/wiki?curid=60525", "title": "List of Intel processors", "text": "This generational list of Intel processors attempts to present all of Intel's processors from the 4-bit 4004 (1971) to the present high-end offerings. Concise technical data is given for each product.\nLatest.\nCore Ultra (Series 2).\nReleased on October 24, 2024. It follows on from Meteor Lake which saw Intel move from monolithic silicon to a disaggregated MCM design. Meteor Lake was limited to a mobile release while Arrow Lake includes desktop processors and mobile processors. \nDesktop \u2013 Core Ultra 200S Series (codenamed \"Arrow Lake\").\nSocket LGA 1851\nMobile \u2013 Arrow Lake-U.\nArrow Lake-U uses refreshed Meteor Lake silicon fabricated on the Intel 3 node.\n13th and 14th generation Core.\nDesktop \u2013 Raptor Lake-S Refresh (codenamed \"Raptor Lake\") (14th Gen).\nAn iterative refresh of Raptor Lake-S desktop processors, called the 14th generation of Intel Core, was launched on October 17, 2023.\nSocket LGA 1700\nCPUs in bold below feature ECC memory support when paired with a motherboard based on the W680 chipset according to each respective Intel Ark product page.\n&lt;templatestyles src=\"Template:Sort under/styles.css\" /&gt;\nMobile \u2013 Raptor Lake-HX Refresh (codenamed \"Raptor Lake\") (14th Gen).\nAn iterative refresh of Raptor Lake-HX mobile processors, called the 14th generation of Intel Core, was launched on Jan 9, 2024 \nMobile \u2013 Meteor Lake-H (14th gen).\n155H, 165H, and 185H support P-core Turbo Boost 3.0 running at the same frequency as Turbo Boost 2.0.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nMobile \u2013 Meteor Lake-U (14th gen).\nThe integrated GPU is branded as \"Intel Graphics\" but still use the same GPU microarchitecture as \"Intel Arc Graphics\" on the H series models.\nAll models support DDR5 memory except 134U and 164U.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nDesktop (codenamed \"Raptor Lake\") (13th Gen).\n&lt;templatestyles src=\"Template:Sort under/styles.css\" /&gt;\nMobile (codenamed \"Raptor Lake\") (13th Gen).\n&lt;templatestyles src=\"Template:Sort under/styles.css\" /&gt;\nRaptor Lake-U Refresh.\nThese Raptor Lake\u2013based processors are branded as \"Core Series 1\" vs. the Meteor Lake\u2013based ones which are branded \"Core Ultra Series 1.\"\nRaptor Lake-U Re-refresh.\nThese Raptor Lake\u2013based processors are branded as \"Core Series 2\", Unlike Arrow Lake's \"Core Ultra Series 2\".\n12th generation Core.\nDesktop (codenamed \"Alder Lake\").\n&lt;templatestyles src=\"Template:Sort under/styles.css\" /&gt;\nAll processors.\nAll processors are listed in chronological order.\nThe 4-bit processors.\nIntel 4004.\nFirst commercially available microprocessor (single-chip IC processor)\nMCS-4 family:\nMicrocontrollers.\nThey are ICs with CPU, RAM, ROM (or PROM or EPROM), I/O Ports, Timers &amp; Interrupts\nIntel 8048.\nMCS-48 family:\nIntel 8051.\nMCS-51 family:\nIntel 80151.\nMCS-151 family:\nIntel 80251.\nMCS-251 family:\nThe bit-slice processor.\n3000 family.\nIntroduced in the third quarter of 1974, these bit-slicing components used bipolar Schottky transistors. Each component implemented two bits of a processor function; packages could be interconnected to build a processor with any desired word length.\nMembers of the 3000 family:\nBus width 2\"n\" bits data/address (depending on number \"n\" of slices used)\n32-bit processors: P6/Pentium M microarchitecture.\nCeleron (Pentium II\u2013based).\nPentium II Xeon \"(chronological entry)\"\nCeleron (Pentium III Coppermine-based).\nXScale \"(chronological entry \u2013 non-x86 architecture)\"\nPentium 4 (not 4EE, 4E, 4F), Itanium, P4-based Xeon, Itanium 2 \"(chronological entries)\"\n32-bit processors: NetBurst microarchitecture.\nPentium 4.\nItanium \"(chronological entry \u2013 new non-x86 architecture)\"\nXeon (32-bit NetBurst).\nItanium 2 \"(chronological entry \u2013 new non-x86 architecture)\"\n64-bit processors: Intel 64 \u2013 Nehalem microarchitecture.\nCore i7 (1st generation).\nWestmere\n64-bit processors: Intel 64 \u2013 Broadwell microarchitecture.\nOther Broadwell CPUs.\nNot listed (yet) are several Broadwell-based CPU models:\nNote: this list does not say that all processors that match these patterns are Broadwell-based or fit into this scheme. The model numbers may have suffixes that are not shown here.\n64-bit processors: Intel 64 \u2013 Skylake microarchitecture.\nOther Skylake processors.\nMany Skylake-based processors are not yet listed in this section: mobile i3/i5/i7 processors (U, H, and M suffixes), embedded i3/i5/i7 processors (E suffix), certain i7-67nn/i7-68nn/i7-69nn.\nSkylake-based \"Core X-series\" processors (certain i7-78nn and i9-79nn models) can be found under current models.\nIntel Xeon Phi.\nManycore processors, originating from the cancelled Larrabee processor.\nIntel Quark.\nA product line of SoCs and microcontrollers, targetting much lower size and power consumption than Intel Atom. \nC&amp;T F8680.\nThe F8680 was an 80186-class SoC originally developed by Chips and Technologies, Inc. \u2212 after Intel acquired C&amp;T in 1997, Intel continued shipments of this SoC until 2000.\nIntel 805xx product codes.\nIntel discontinued the use of part numbers such as 80486 in the marketing of mainstream x86-architecture processors with the introduction of the Pentium brand in 1993. However, numerical codes, in the 805xx range, continued to be assigned to these processors for internal and part numbering uses. The following is a list of such product codes in numerical order:\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60526", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=60526", "title": "Boxer rebellion", "text": ""}
{"id": "60527", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=60527", "title": "Universities", "text": ""}
{"id": "60528", "revid": "43944218", "url": "https://en.wikipedia.org/wiki?curid=60528", "title": "List of colleges and universities in California", "text": "This is a list of colleges and universities in California.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60529", "revid": "21878292", "url": "https://en.wikipedia.org/wiki?curid=60529", "title": "USS Wasp", "text": "USS \"Wasp\" may refer to the following ships of the Continental and United States navies: \n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n List of ships with the same or similar names\nThis article includes a with the same or similar names. If an [ internal link] for a specific ship led you here, you may wish to change the link to point directly to the intended ship article, if one exists."}
{"id": "60530", "revid": "51035277", "url": "https://en.wikipedia.org/wiki?curid=60530", "title": "List of professional sports teams in California", "text": "There are many professional sports teams based in California, participating in sports such as baseball, American football, soccer, basketball, ice hockey, lacrosse, and ultimate.\n\"based in Anaheim\" \n*Expansion team in 1993\n*Previously known as the Mighty Ducks of Anaheim \n*Play at Honda Center \n*No previous arenas \n*Stanley Cup Championships: 2007\n\"based in Los Angeles\" \n*Expansion team in 1967\n*No previous monikers\n*Play at Crypto.com Arena \n*Previously played at Long Beach Arena , Los Angeles Memorial Sports Arena , The Forum \n*Stanley Cup Championships: 2012, 2014\n\"based in San Jose\" \n*Expansion team in 1991\n*No previous monikers\n*Play at SAP Center at San Jose \n*Previously played at Cow Palace \n*Stanley Cup Championships: None\n\"based in Anaheim\" \n*Expansion team in 1961\n*Previously known as the Los Angeles Angels , California Angels , Anaheim Angels , and Los Angeles Angels of Anaheim \n*Play at Angel Stadium of Anaheim \n*Previously played at Wrigley Field and Dodger Stadium \n*World Series Championships: 2002\n\"based in Los Angeles\" \n*Relocated from Brooklyn in 1958\n*Previously known as the Brooklyn Dodgers and others \n*Play at Dodger Stadium \n*Previously played at Ebbets Field , Los Angeles Memorial Coliseum , and others \n*World Series Championships: 1959, 1963, 1965, 1981, 1988, 2020, 2024, 2025\n\"based in San Diego\" \n*Expansion team in 1969\n*No previous monikers\n*Play at Petco Park \n*Previously played at San Diego Stadium \n*World Series Championships: None\n\"based in San Francisco\" \n*Relocated from New York City in 1958\n*Previously known as the New York Gothams and New York Giants \n*Play at Oracle Park \n*Previously played at the New York Polo Grounds , Seals Stadium , Candlestick Park , and others \n*World Series Championships: 2010, 2012, 2014\n\"based in West Sacramento\" \n*Relocated from Oakland in 2025\n*Previously known as the Oakland Athletics \n*Previously known as the Kansas City Athletics \n*Previously known as the Philadelphia Athletics \n*Play at Sutter Health Park \n*Previously played at the Oakland Coliseum , Municipal Stadium , Shibe Park , Columbia Park \n*World Series Championships: 1972, 1973, 1974, 1989\n\"play in Inglewood; headquarters in Costa Mesa\" \n*Expansion team in 1960, played in San Diego from 1961 to 2016\n*Previously known as the San Diego Chargers \n*Play at SoFi Stadium \n*Previously played at Los Angeles Memorial Coliseum , Balboa Stadium , San Diego Stadium , and Dignity Health Sports Park \n*Championships: 1963\n\"play in Inglewood; headquarters in Agoura Hills\" \n*Expansion team in 1936, played in Cleveland from 1936 to 1945 and St. Louis from 1995 to 2015\n*Previously known as the Cleveland Rams and St. Louis Rams \n*Play at SoFi Stadium \n*Previously played at Cleveland Stadium , League Park , Shaw Stadium , Los Angeles Memorial Coliseum , Anaheim Stadium , Busch Memorial Stadium , and Edward Jones Dome \n*Championships: 1951, 2021\u00a0(LVI)\n\"based in Santa Clara (stadium and HQ)\" \n*Expansion team in 1946 (AAFC), joined NFL in 1950\n*No previous moniker\n*Play at Levi's Stadium \n*Previously played at Kezar Stadium and Candlestick Park \n*Championships: 1981\u00a0(XVI), 1984\u00a0(XIX), 1988\u00a0(XXIII), 1989\u00a0(XXIV), 1994\u00a0(XXIX)\n\"based in San Francisco\" \n*Relocated from Philadelphia in 1962\n*Previously known as the Philadelphia Warriors and San Francisco Warriors \n*Play at Chase Center .\n*Previously played at Cow Palace , San Francisco Civic Auditorium , USF War Memorial Gymnasium , HP Pavilion at San Jose , Oracle Arena , and others \n*NBA Championships: 1975, 2015, 2017, 2018, 2022\n\"based in Los Angeles\" \n*Relocated from Buffalo in 1978 to San Diego, then relocated to Los Angeles in 1984\n*Previously known as the Buffalo Braves and San Diego Clippers \n*Play at Intuit Dome \n*Previously played at Buffalo Memorial Auditorium , San Diego Sports Arena , Los Angeles Memorial Sports Arena , Honda Center and Crypto.com Arena \n*NBA Championships: None\n\"based in Los Angeles\" \n*Relocated from Minnesota in 1960\n*Previously known as the Detroit Gems and Minneapolis Lakers \n*Play at Crypto.com Arena \n*Previously played at Minneapolis Auditorium , Los Angeles Memorial Sports Arena , The Forum \n*NBA Championships: 1972, 1980, 1982, 1985, 1987, 1988, 2000, 2001, 2002, 2009, 2010, 2020\n\"based in Sacramento\" \n*Relocated from Kansas City in 1985\n*Previously known as the Rochester Royals , Cincinnati Royals, Kansas City-Omaha Kings , Kansas City Kings \n*Play at the Golden 1 Center \n*Previously played at Kansas City Municipal Auditorium Omaha Civic Auditorium , Kemper Arena , ARCO Arena I , Sleep Train Arena (and others) \n*NBA Championships: None\n\"based in Carson\" \n*Original team in league's 1996 inaugural season\n*No previous monikers\n*Play at Dignity Health Sports Park \"(Dignity Health Sports Park was formerly known as The Home Depot Center)\"\n*Previously played at Rose Bowl plus Titan Stadium \n*Championships: MLS Cup 6 (2002, 2005, 2011, 2012, 2014, 2024) Supporters' Shield (1998, 2002, 2010, 2011), Lamar Hunt U.S. Open Cup (2001, 2005), CONCACAF Champions Cup (2000)\n\"based in Los Angeles\" \n*Expansion team in 2018\n*No previous monikers\n*Play at BMO Stadium \n*No previous stadiums\n*Championships: MLS Cup (2022); Supporters' Shield (2019, 2022), Lamar Hunt U.S. Open Cup (2024)\n\"based in San Jose\" \n*Original team in league's 1996 inaugural season\n*Previously known as the San Jose Clash \n*Franchise on hiatus in the 2006 and 2007 seasons; the original ownership relocated the team to Houston after the 2005 season as the Houston Dynamo, but MLS kept the name and history of the original franchise in San Jose for a new ownership group\n*Play at PayPal Park , plus other venues for select games\n*Previously played at Spartan Stadium , Buck Shaw Stadium , and other venues for select games\n*Championships: MLS Cup (2001, 2003), Supporters' Shield (2005, 2012)\n\"based in San Diego\" \n*Expansion team to begin play in 2025\n*No previous monikers\n*Play at Snapdragon Stadium \n*Championships: None\n\"based in San Francisco\" \n*Expansion team in 2025\n*No previous monikers\n*Play at Chase Center \n*No previous stadiums\n*Championships: None\n\"based in Los Angeles\" \n*Inaugural WNBA team in 1997\n*No previous monikers\n*Play at Crypto.com Arena \n*Previously played at The Forum \n*Championships: 2001, 2002, 2016\n\"based in Los Angeles\" \n*Expansion team in 2022\n*No previous monikers\n*Play at BMO Stadium , plus Titan Stadium for NWSL Challenge Cup home matches\n*No previous stadiums\n*Championships: None\n\"based in San Diego\" \n*Expansion team in 2022\n*No previous monikers\n*Play at Snapdragon Stadium \n*Previously played at Torero Stadium \n*Championships: None\n\"based in San Jose\" \n*Expansion team in 2024\n*No previous monikers\n*Play at PayPal Park \n*No previous stadiums\n*Championships: None\nOther professional sports teams.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60531", "revid": "15881234", "url": "https://en.wikipedia.org/wiki?curid=60531", "title": "Anna Leonowens", "text": "British educator (1831\u20131915)\nAnna Harriette Leonowens (born Ann Hariett Emma Edwards; 5 November 1831 \u2013 19 January 1915) was an Anglo-Indian or Indian-born British travel writer, educator, and social activist.\nShe became well known with the publication of her memoirs, beginning with \"The English Governess at the Siamese Court\" (1870), which chronicled her experiences in Siam (modern Thailand), as teacher to the children of the Siamese King Mongkut. Leonowens's own account was fictionalised in Margaret Landon's best-selling novel \"Anna and the King of Siam\" (1944) as well as adaptations for other media such as Rodgers and Hammerstein's 1951 musical \"The King and I\".\nDuring the course of her life, Leonowens also lived in Western Australia, Singapore and Penang, the United States, Canada and Germany. In later life, she was a lecturer of Indology and a suffragist. Among other achievements, she co-founded the Nova Scotia College of Art and Design.\nEarly life and family.\nAnna was born in Ahmednagar in the Bombay Presidency of Company-ruled India, on 5 November 1831, three months after the death of her father, Sergeant Thomas Edwards. While she was christened Ann Hariett Emma Edwards, Leonowens later changed \"Ann\" to \"Anna\" and \"Hariett\" to \"Harriette\" and ceased using her third given name (\"Emma\").\nAnna Leonowens's mother, Mary Ann Glascott, married Edwards, a non-commissioned officer in the East India Company's Corps of Sappers and Miners, on 15 March 1829 in St James's Church, Tannah, Bombay Presidency, British India. Edwards was from London and a former cabinetmaker.\nLeonowens's maternal grandfather, William Vawdrey (or Vaudrey) Glascott, was an English-born commissioned officer of the 4th Regiment, Bombay Native Infantry, in the Bombay Army. Glascott arrived in India in 1810, and was apparently married in 1815, although his wife's name is not known. According to biographer Susan Morgan, the only viable explanation for the complete and deliberate lack of information regarding Glascott's wife in official British records is that she \"was not European\". Morgan suggests that she was \"most likely ... Anglo-Indian (of mixed race) born in India.\" Anna's mother, Mary Anne Glascott, was born in 1815 or 1816.\nFor most of her adult life, Anna Leonowens had no contact with her family and took pains to disguise her origins by claiming that she had been born with the surname \"Crawford\" in Caernarfon, Wales, and giving her father's rank as captain. By doing so, she protected not only herself but her children, who would have had greater opportunities if their possibly mixed-race heritage remained unknown. Investigations uncovered no record of her birth at Caernarfon, although the town had long claimed her as one of its most famous natives.\nA few months after Anna's birth, her mother married Patrick Donohoe, an Irish Catholic corporal of the Royal Engineers. The family relocated repeatedly within Western India, following Donohoe's regiment. In 1841, they settled in Deesa, Gujarat. Anna attended the Bombay Education Society's girls school in Byculla (now a neighbourhood of Mumbai) that admitted \"mixed-race\" children whose military fathers were either dead or absent. Leonowens later said she had attended a British boarding school and had arrived in India, which she described as a \"strange land\" to her, at the age of 15. Anna's relationship with her stepfather Donohoe was not a happy one, and she later accused him of putting pressure on her to marry a much older man as her sister had done. In 1847, Donohoe was seconded as assistant supervisor of public works in Aden, Yemen. It is unclear whether the rest of the family went with him or stayed in India.\nOn 24 April 1845, Anna's 15-year-old sister, Eliza Julia Edwards, married James Millard, a sergeant-major with the 4th Troop Artillery, Indian Army in Deesa. Anna served as a witness to this marriage. Their daughter, Eliza Sarah Millard, born in 1848 in India, married on 7 October 1864 in Surat, Gujarat, India. Her husband was Edward John Pratt, a 38-year-old British civil servant. One of their sons, William Henry Pratt, born 23 November 1887 upon their return to London, was better known by his stage name of Boris Karloff; Anna was thus his great-aunt. Anna Edwards never approved of her sister's marriage, and her self-imposed separation from the family was so complete that, a decade later, when Eliza contacted her during her stay in Siam, she replied by threatening suicide if she persisted.\nLeonowens claimed that she had gone on a three-year tour through Egypt and the Middle East with the orientalist Reverend George Percy Badger and his wife. However, recent biographies consider this episode to be fictitious. Anna may have met Badger in India and listened to or read reports about his travels.\nMarriage, Western Australia and widowhood.\nAnna Edwards married Thomas Leon Owens on Christmas Day 1849 in the Anglican church of Pune. In the marriage certificate, Owens merged his second and last names to 'LeonOwens'. Owens, an Irish Protestant from Enniscorthy, County Wexford, had come to India with the 28th Regiment of Foot in 1843. From a private, he rose to the position of paymaster's clerk (rather than the army officer suggested by Anna's memoir) in 1844, serving first in Pune, and from December 1845 until 1847 in Deesa. Biographer Alfred Habegger characterises him as \"well read and articulate, strongly opinionated, historically informed, and almost a gentleman\". Anna Edwards, who was seven years his junior, fell in love with him. However, her mother and stepfather objected to the relationship due to Owens' poor prospects for gainful employment and since he had been temporarily downgraded from sergeant to private for an unspecified offence. According to Leonowens', her stepfather had violently opposed the marriage; however, Patrick Donohoe signed the marriage certificate. The couple had four children together before Thomas Leonowens' death in 1859, and two died in infancy. Leonowens' first daughter, Selina, was born in December 1850 and died at seventeen months.\nIn 1852, the young couple, accompanied by Anna's uncle, W.\u2009V. Glasscott, sailed to Australia via Singapore, where they boarded the barque . While on board, Anna gave birth to a son named Thomas. On 8 March 1853, the \"Alibi\" was almost wrecked on a reef as it approached the Western Australian coast. Ten days later, Anna, Thomas, their newborn son and Glasscott arrived in Perth. Glasscott and Thomas Leonowens quickly found employment as clerks in the colonial administration. Later in 1853, Glasscott accepted a position as government commissariat storekeeper at Lynton, a small and remote settlement that was the site of Lynton Convict Depot. Glasscott became involved in frequent disagreements with the abrasive resident magistrate, William Burges. Within three years, Glasscott had returned to India and taken up a career in teaching before dying suddenly in 1856.\nAnna Leonowens, using her middle name of Harriett, tried to establish a school for young ladies. In March 1854, the infant Thomas died at the age of 13 months, and, later that year, a daughter, Avis Annie, was born. In 1855, Thomas Leonowens was appointed to Glasscott's former position with the commissariat at Lynton, and the family moved there. At Lynton, Anna Leonowens gave birth to a son, Louis. During late 1856, Thomas Leonowens also served briefly as magistrate's clerk under William Burges. Like Glasscott, Thomas clashed with Burges but survived until the Convict Depot was closed in 1857, and he was transferred to a more senior position with the Commissariat in Perth.\nThe Leonowens family left Australia abruptly in April 1857, sailing to Singapore, and then moving to Penang, where Thomas found work as a hotel keeper. In or before the first week of May 1859, Thomas Leonowens died of \"apoplexy\" and was buried (7 May 1859) in the Protestant Cemetery in Penang. His death left Anna Leonowens an impoverished widow. She returned to Singapore, where she created a new identity as a Welsh-born lady and widow of a British army major. To support her daughter Avis and son Louis, Leonowens again took up teaching and opened a school for the children of British officers in Singapore. While the enterprise was not a financial success, it established her reputation as an educator.\nTeacher at the Siamese court.\nIn 1862, Leonowens accepted an offer made by the consul in Singapore, Tan Kim Ching, to teach the wives and children of Mongkut, King of Siam. The king wished to give his 39 wives and concubines and 82 children a modern Western education on scientific secular lines, which earlier missionaries' wives had not provided. Leonowens sent her daughter Avis to school in England, and took her son Louis with her to Bangkok. She succeeded Dan Beach Bradley, an American missionary, as teacher to the Siamese court.\nLeonowens served at court until 1867, a period of nearly six years, first as a teacher and later as language secretary for the King. Although her position carried great respect and even a degree of political influence, she did not find the terms and conditions of her employment to her satisfaction. And, despite her position at the king's court, she was never invited into the social circle of the British merchants and traders of the area.\nIn 1868, Leonowens was on leave for her health in England and had been negotiating a return to the court on better terms when Mongkut fell ill and died. The King mentioned Leonowens and her son in his will, though they did not receive a legacy. The new monarch, fifteen-year-old Chulalongkorn, who succeeded his father, wrote Leonowens a warm letter of thanks for her services. He did not invite her to resume her post, but they corresponded amicably for many years. At the age of 27, Louis Leonowens returned to Siam and was granted a commission of Captain in the Royal Cavalry. Chulalongkorn made reforms for which his former tutor claimed some of the credit, including the abolition of the practice of prostration before the royal person. However, many of those same reforms were goals that had been established by his father.\nLiterary career.\nBy 1869, Leonowens was in New York City, where she briefly opened a school for girls in the West New Brighton section of Staten Island, and she began contributing travel articles to a Boston journal, \"The Atlantic Monthly\", including \"The Favorite of the Harem\", reviewed by \"The New York Times\" as \"an Eastern love story, having apparently a strong basis of truth\". She expanded her articles into two volumes of memoirs, beginning with \"The English Governess at the Siamese Court\" (1870), which earned her immediate fame but also brought charges of sensationalism. In her writing, she casts a critical eye over court life; the account is not always a flattering one, and has become the subject of controversy in Thailand, and she has also been accused of exaggerating her influence with the king.\nThere have also been claims of fabrication: the likelihood of the argument over slavery, for example, when King Mongkut was for 27 years a Buddhist monk and later abbot, before ascending to the throne. It is thought that his religious training and vocation would never have permitted the views expressed by Leonowens's cruel, eccentric and self-indulgent monarch. Even the title of her memoir is inaccurate, as she was neither English nor did she work as a governess: Her task was to teach English, not to educate and care for the royal children comprehensively. Leonowens claimed to have spoken Thai fluently, but the examples of that language presented in her books are unintelligible, even if one allows for clumsy transcription.\nLeonowens was a feminist, and in her writings she tended to focus on what she saw as the subjugated status of Siamese women, including those sequestered within the \"Nang Harm\", or royal harem. She emphasised that although Mongkut had been a forward-looking ruler, he had desired to preserve customs such as prostration and sexual slavery that seemed unenlightened and degrading. The sequel, \"Romance of the Harem\" (1873), incorporates tales based on palace gossip, including the king's alleged torture and execution of one of his concubines, Tuptim. The story lacks independent corroboration and is dismissed as out of character for the king by some critics. A great-granddaughter, Princess Vudhichalerm Vudhijaya (b. 21 May 1934), stated in a 2001 interview, \"King Mongkut was in the monk's hood for 27 years before he was king. He would never have ordered an execution. It is not the Buddhist way.\" She added that the same Tuptim was her grandmother and had married Chulalongkorn as one of his minor wives. Moreover, there were no dungeons below the Grand Palace or anywhere else in Bangkok as the high ground-water level would not allow this. Nor are there any accounts of a public burning by other foreigners staying in Siam during the same period as Leonowens.\nWhile in the United States, Leonowens also earned much-needed money through popular lecture tours. At venues such as the house of Mrs. Sylvanus Reed in Fifty-third Street, New York City, in the regular members' course at Association Hall, or under the auspices of bodies such as the Long Island Historical Society, she lectured on subjects including \"Christian Missions to Pagan Lands\" and \"The Empire of Siam, and the City of the Veiled Women\". \"The New York Times\" reported: \"Mrs. Leonowens' purpose is to awaken an interest, and enlist sympathies, in behalf of missionary labors, particularly in their relation to the destiny of Asiatic women.\" She joined the literary circles of New York and Boston and made the acquaintance of local lights on the lecture circuit, such as Oliver Wendell Holmes, Henry Wadsworth Longfellow and Harriet Beecher Stowe, author of \"Uncle Tom's Cabin\", a book whose anti-slavery message Leonowens had brought to the attention of the royal household. She said the book influenced Chulalongkorn's reform of slavery in Siam, a process he had begun in 1868, and which would end with its total abolition in 1915. Meanwhile, Louis had accumulated debts in the U.S. by 1874 and fled the country. He became estranged from his mother and did not see her for 19 years. In the summer of 1878, she taught Sanskrit at Amherst College.\nCanada and Germany.\nIn 1878, Leonowens's daughter Avis Annie Crawford Connybeare married Thomas Fyshe, a Scottish banker and the cashier (general manager) of the Bank of Nova Scotia in Halifax, where she resided for nineteen years as she continued to travel the world. This marriage ended the family's money worries. Leonowens resumed her teaching career and taught daily from 9\u00a0am to 12 noon for an autumn half at the Berkeley School of New York at 252 Madison Avenue, Manhattan, beginning on 5 October 1880; this was a new preparatory school for colleges and schools of science and her presence was advertised in the press. On behalf of \"The Youth's Companion\" magazine, Leonowens visited Russia in 1881, shortly after the assassination of Tsar Alexander II, and other European countries, and continued to publish travel articles and books. This established her position as an orientalist scholar.\nHaving returned to Halifax, she again became involved in women's education and worked as a suffragist. She initiated a reading circle and a Shakespeare club, and she was one of the founders of the Local Council of Women of Halifax and the Victoria School of Art and Design (now the Nova Scotia College of Art and Design). From 1888 to 1893, Anna Leonowens lived with her daughter Avis and her grandchildren in Kassel, Germany. \nOn her way back to Canada, she met her son Louis again, after nineteen years of separation. He had returned to Siam in 1881, having had become an officer in the Siamese royal cavalry and a teak trader. From his marriage to Caroline Knox \u2014 a daughter of Sir Thomas George Knox, the British consul-general in Bangkok, and his Thai wife, Prang Yen\u2014 he had two children, aged two and five years. After the death of his wife, he entrusted them to his mother, who took them with her to Canada, while Louis returned to Siam.\nAnna Leonowens met Chulalongkorn again when both visited London in 1897, thirty years after she had left Siam. During this audience, the king took the opportunity to express his thanks in person, but he also voiced his dismay at the inaccuracies in Leonowens's books. According to Leonowens's granddaughter Anna Fyshe, who had accompanied her, the king asked, \"Why did you write such a wicked book about my father King Mongkut? You know that you have made him utterly ridiculous\". In response, according to Fyshe, Leonowens insisted that she had written \"the whole truth\" and that Mongkut had indeed been \"a ridiculous and a cruel, wicked man\". With her granddaughter Anna, Leonowens stayed in Leipzig, Germany, until 1901. She studied Sanskrit and classical Indian literature with the renowned Indology professor Ernst Windisch of Leipzig University, while her granddaughter studied piano at the Royal Conservatory of Music.\nIn 1901 she moved to Montreal, Quebec, where she lectured Sanskrit at McGill University. She delivered her last lecture at the age of 78. Anna Leonowens died on 19 January 1915, at 83 years of age. She was interred in Mount Royal Cemetery in Montreal. The headstone identifies her as the \"Beloved Wife of Major Thomas Lorne Leonowens\", despite her husband never having risen beyond the rank of paymaster sergeant.\nIn popular culture.\nMargaret Landon's novel \"Anna and the King of Siam\" (1944) provides a fictionalised look at Anna Leonowens's years at the royal court and develops the abolitionist theme that resonated with her American readership. In 1946, Talbot Jennings and Sally Benson adapted it into the screenplay for a dramatic film of the same name, starring Irene Dunne and Rex Harrison. In response, Thai authors Seni and Kukrit Pramoj wrote their own account in 1948 and sent it to American politician and diplomat Abbot Low Moffat (1901\u20131996), who drew on it for his biography \"Mongkut, the King of Siam\" (1961). Moffat donated the Pramoj brothers' manuscript to the Library of Congress in 1961.\nLandon had, however, created the iconic image of Leonowens, and \"in the mid-20th century she came to personify the eccentric Victorian female traveler\". The novel was adapted as a hit musical by Rodgers and Hammerstein, \"The King and I\" (1951), starring Gertrude Lawrence and Yul Brynner, which ran 1,246 performances on Broadway and was also a hit in London and on tour. In 1956, a film version was released, with Deborah Kerr starring in the role of Leonowens and Brynner reprising his role as the king. Brynner starred in many revivals until his death in 1985.\nThe humorous depiction of Mongkut as a polka-dancing despot, as well as the king's and Anna's apparent romantic feelings for each other, is condemned as disrespectful in Thailand, where the Rodgers and Hammerstein film and musical were banned by the government. The 1946 film version of \"Anna and the King of Siam\", starring Rex Harrison as Mongkut and Irene Dunne as Anna, was allowed to be shown in Thailand, although it was banned in newly independent India as an inaccurate insult by Westerners to an Eastern king. In 1950, the Thai government did not permit the film to be shown for the second time in Thailand. The books \"Romance in the Harem\" and \"An English Governess at the Siamese Court\" were not banned in Thailand. There were even Thai translations of these books by Ob Chaivasu, a Thai humor writer.\nDuring a visit to the United States in 1960, the monarch of Thailand, King Bhumibol (a great-grandson of Mongkut), and his entourage explained that from what they could gather from the reviews of the musical, the characterisation of Mongkut seemed \"90 percent exaggerated. My great-grandfather was really quite a mild and nice man.\" Years later, during her 1985 visit to New York, Bhumibol's wife, Queen Sirikit, went to see the Broadway musical at the invitation of Yul Brynner. The then ambassador of Thailand to the U.S. gave another reason for Thailand's disapproval of \"The King and I\": its ethno-centric attitude and its barely hidden insult to the whole Siamese nation by portraying its people as childish and inferior to the Westerners.\nIn 1972, Twentieth Century Fox produced a non-musical American TV series for CBS, \"Anna and the King\", with Samantha Eggar taking the part of Leonowens and Brynner reprising his role as the king. Margaret Landon charged the makers with \"inaccurate and mutilated portrayals\" of her literary property and sued unsuccessfully for copyright infringement. The series was not a success and was cancelled after only 13 episodes. In 1999 an animated film using the songs of the musical was released by Warner Bros. Animation. In the same year, Jodie Foster and Chow Yun-fat starred in a new feature-length cinematic adaptation of Leonowens's books, also titled \"Anna and the King\". One Thai critic complained that the filmmakers had made Mongkut \"appear like a cowboy\"; this version was also banned by censors in Thailand.\nLeonowens appears as a character in Paul Marlowe's novel \"Knights of the Sea\", in which she travels from Halifax to Baddeck in 1887 to take part in a campaign to promote women's suffrage during a by-election.\nLater research.\nLeonowens kept the actual facts of her early life a closely guarded secret throughout her life, and never disclosed them to anybody, including her family. They were uncovered by researchers long after her death; their scrutiny began with her writings, especially following the popularity of the musical's 1956 film adaptation. D. G. E. Hall, writing in his 1955 book \"A History of South-East Asia\", commented that Leonowens \"was gifted with more imagination than insight\", and from 1957 to 1961 A. B. Griswold published several articles and a monograph sharply criticizing her depictions of King Mongkut and Siam, writing that \"she would seize on a lurid story that appealed to her... remove it from its context and transpose it to Bangkok in the 1860's; and... re-write it with a wealth of circumstantial detail\". Moffat noted in his biography of King Mongkut that Leonowens \"carelessly leaves proof of her transposed plagiarism\".\nThe fact that Leonowens's claimed birth in Caernarfon was fabricated was first uncovered by W. S. Bristowe, an arachnologist and frequent visitor to Thailand, who was researching a biography of her son Louis. Bristowe failed to locate Louis's certificate of birth in London (as claimed by Anna), prompting further research that led to him identifying her origins in India. His findings were published in the 1976 book \"Louis and the King of Siam\", and later writers have expanded on this line of research, including Leslie Smith Dow in \"Anna Leonowens: A Life Beyond The King and I\" (1991) and Susan Kepner in her 1996 paper \"Anna (and Margaret) and the King of Siam\". More recent full-length scholarly biographies by Susan Morgan (\"Bombay Anna\", 2008) and Alfred Habegger (\"Masked: The Life of Anna Leonowens, Schoolmistress at the Court of Siam\", 2014) brought widespread attention to Leonowens's actual life story.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "60532", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=60532", "title": "Toxins", "text": ""}
{"id": "60533", "revid": "1743697", "url": "https://en.wikipedia.org/wiki?curid=60533", "title": "CSS Scorpion", "text": "Squib-class torpedo boat procured late in 1864 by the Confederate States Navy\nCSS \"Scorpion\" was a \"Squib\"-class torpedo boat that served in the Confederate States Navy during the American Civil War. Armed with a single spar torpedo, she originally served guard duty on the James River after being built in late 1864. Along with the rest of the James River Squadron, \"Scorpion\" moved downriver on January 23, 1865, and participated in the Battle of Trent's Reach. After performing depth soundings near Union obstructions, \"Scorpion\" moved to get a lantern from the ironclad CSS \"Virginia II\", but ran into a hawser and then ran aground. At 07:10 on the morning of January 24, Union fire struck the abandoned tender CSS \"Drewry\", which then exploded. The force of the explosion swept \"Scorpion\" out of control downriver. An attempt to rescue her that night failed, and she was captured by Union forces.\nConstruction and characteristics.\nDuring the American Civil War, the Union blockade was slowly destroying the economy of the rebelling Confederate States of America. The first use of torpedo boats in attempting to break the blockade came in October 1863. The attack damaged a Union vessel, and the partial success led the Confederates to build additional torpedo boats. Multiple designs were used, including a group known as the \"Squib\"-class built at Richmond, Virginia. Lieutenant Hunter Davidson playing a significant role in the design.\nCSS \"Scorpion\", one of the \"Squib\"-class, was constructed in late 1864, and was long, had a beam of , and a depth of hold of . Tonnage for the class is unknown. The \"Squib\"-class ships were powered by two oscillating condensing engines, which had a diameter cylinder and a stroke, as well a single boiler. According to a Union engineer, she could go at \"a fair speed for a boat of her kind\". Her crew of five or six operated steer gear that was located towards the front of the vessel. Her armament was a single spar torpedo mounted to a spar shaft that measured or long. The spar could be raised or lowered by the ship's crew using a chain and tackle system. Thin plates of iron served as armor on the ships's sides.\nService history.\nAfter construction, \"Scorpion\" entered Confederate service with the James River Squadron. Under the command of Lieutenant Edward Lakin, she performed guard duty in the James River. Beginning on January 23, 1865, the James River Squadron began an offensive against the Union supply depot at City Point, Virginia. To reduce the chance of collisions in the narrow river, the wooden vessels of the fleet were lashed to the ironclads. Overall, the Confederates had 11 ships present: three ironclads, three gunboats, three torpedo boats, and two tenders. \"Scorpion\" was towed by the tender CSS \"Torpedo\", which was in turn lashed to the ironclad CSS \"Virginia II\". Moving during the night, the Confederate vessels passed a Union shore position known as Fort Brady, which fired upon them. At around 09:00, the Confederate vessels reached Union obstructions in the river at Trent's Reach.\n\"Scorpion\" was then sent forward to perform depth sounding, with a pilot from \"Virginia II\" aboard. The pilot claimed that the channel was not open, but Charles Read, who commanded all of the torpedo boats in the James River Squadron, found that a passage could be made; the pilot may have become unnerved by Union shore fire. The ironclad CSS \"Fredericksburg\" then managed to clear the obstructions at around 01:30 on January 24. Read later took \"Scorpion\" to look for the gunboat CSS \"Hampton\", but after not finding her, took the ship to \"Virginia II\" to get a lantern for lighting the passage. \"Virginia II\" had run aground, and the same fate had befallen the ironclad CSS \"Richmond\" as well. The tender CSS \"Drewry\" then ran aground trying to free \"Richmond\". Moving towards \"Virginia II\", \"Scorpion\" ran into a hawser strung between the former ship and the gunboat CSS \"Beaufort\", losing her torpedo and spar in the process. Not long afterwards, she ran aground. The torpedo boat CSS \"Hornet\" then ran aground trying to free \"Scorpion\". The Confederate vessels that were not aground withdrew upriver before daylight. At 06:55, the crew of \"Drewry\" was taken onto \"Richmond\", and at 07:10, Union fire caused \"Drewry\" to explode. The force of the explosion knocked \"Scorpion\" downriver out of control; two men on board were killed and four others swept overboard. After dark on January 24, Read tried to take \"Beaufort\" downriver to rescue \"Scorpion\", but as \"Beaufort\" could not be controlled due to a strong wind, and a smaller vessel was sent to \"Scorpion\". \"Scorpion\" was found to have taken on water, and after the Union illuminated the area with a Drummond light, the efforts to rescue the vessel were abandoned. She was later captured by Union forces, and may have been burned.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60534", "revid": "7852030", "url": "https://en.wikipedia.org/wiki?curid=60534", "title": "Shilling", "text": "Name for a coin or unit of currency\nThe shilling is a historical coin, and the name of a unit of modern currencies formerly used in the United Kingdom, Australia, New Zealand, other British Commonwealth countries and Ireland, where they were generally equivalent to 12 pence or one-twentieth of a pound before being phased out during the 1960s and 1970s.\nCurrently the shilling is used as a currency in five east African countries: Kenya, Tanzania, Uganda, Somalia, and the \"de facto\" country of Somaliland. The East African Community additionally plans to introduce an East African shilling.\nHistory.\nThe word \"shilling\" comes from Anglo-Saxon phrase \"Scilling\", a monetary term meaning literally \"twentieth of a pound\", from the Proto-Germanic root skiljan\u0105 meaning literally \"to separate, split, divide\", from (s)kelH- meaning \"to cut, split.\" The word \"Scilling\" is mentioned in the earliest recorded Germanic law codes, the Law of \u00c6thelberht (c.\u2009600).\nIn origin, the word \"schilling\" designated the \"solidus\" of Late Antiquity, the gold coin that replaced the aureus in the 4th century. The Anglo-Saxon \"scillingas\" of the 7th century were still small gold coins.\nIn 796, Charlemagne passed a monetary reform, based on the Carolingian silver pound (about 406.5 grams). The \"schilling\" was one-twentieth of a pound or about 20.3 grams of silver. One \"schilling\" had 12 \"denarii\" or \"deniers\" (\"pennies\"). There were, however, no silver \"schilling\" coins in the Carolingian period, and gold \"schillings\" (equivalent to twelve silver \"pfennigs\") were very rare.\nIn the 12th century, larger silver coins of multiple \"pfennig\" weight were minted, known as \"denarii grossi\" or \"groschen\" (groats). These heavier coins were valued at between 4 and 20 of the silver \"denarii\". In the late medieval period, states of the Holy Roman Empire began minting similar silver coins of multiple \"pfennig\" weight, some of them denominated as \"schilling\".\nIn the 16th century, numerous different types of \"schilling\" were minted in Europe. The English shilling was a successor of the testoon coin first minted during the reign of Edward VI in 1551, which consisted of 92.5% \"sterling\" silver.\nBy the 17th century, further devaluation resulted in \"schillings\" in the Holy Roman Empire being minted in billon (majority base metal content) instead of silver, with 48 \"schillings\" to one \"Reichsthaler\". The English (later British) shilling continued to be minted as a silver coin until 1946, although the silver content was debased from 1920 onwards.\nBritish Isles.\nKingdom of England.\nA shilling was a coin used in England from the reign of Henry VII (or Edward VI around 1550). The shilling continued in use after the Acts of Union of 1707 created a new United Kingdom from the Kingdoms of England and Scotland, and under Article 16 of the Articles of Union, a common currency for the new United Kingdom was created.\nKingdom of Scotland.\nThe term \"shilling\" () was in use in Scotland from early medieval times.\nGreat Britain, then the United Kingdom of Great Britain and Ireland.\nThe common currency for Great Britain, created in 1707 by Article 16 of the Articles of Union between England and Scotland, continued in use until decimalisation in 1971. During the Great Recoinage of 1816 (following the Acts of Union 1800 that united the Kingdoms of Great Britain and Ireland), the mint was instructed to coin one troy pound (weighing 5760 grains or 373\u00a0g) of sterling silver (0.925 fine) into 66 shillings, or its equivalent in other denominations. This set the weight of the shilling at 87.2727 grains or 5.655\u00a0grams from 1816 until 1990, when it was demonetised in favour of a new smaller 5p coin of the same value.\nAt decimalisation in 1971, the shilling coin was superseded by the new five-pence piece, which initially was of identical size and weight and had the same value. Shillings remained in circulation until the five pence coin was reduced in size in 1991.\nThree coins denominated in multiple shillings were also in circulation at this time. They were:\nIrish shillings.\nBetween 1701 and the unification of the currencies in 1825, the Irish shilling was valued at 13 pence and known as the \"black hog\", as opposed to the 12-pence English shillings which were known as \"white hogs\".\nIn the Irish Free State and Republic of Ireland, the shilling coin was issued as (the Irish language equivalent). It was worth 1/20 of an Irish pound, and was interchangeable at the same value to the British coin, which continued to be used in Northern Ireland. The coin featured a bull on the reverse side. The first minting, from 1928 until 1941, contained 75% silver, more than the equivalent British coin. The pre-decimal Irish shilling coin (which was retained for some time after decimalisation) was withdrawn from circulation on 1 January 1993, when a smaller five-pence coin was introduced.\nAbbreviation and slang.\nOne abbreviation for shilling is s (for , see \u00a3sd). Often it was expressed by a solidus symbol (/) (which may have begun as a substitute for ) thus '1/9' means \"one shilling and ninepence\". A price expressed as a number of shillings with no additional pence was often written as the number, a solidus and a dash: thus for example ten shillings was written '10/-'. Two shillings and sixpence (half a crown, or an eighth of a \u00a3) was written as '2/6', rarely as '2s6d' ('d' being the abbreviation for , a penny). The shilling itself was equal to twelve pence. In the traditional pounds, shillings and pence system, there were 20 shillings per pound and 12 pence per shilling, making 240 pence in a pound.\nSlang terms for the old shilling coins include \"bob\" and \"hog\". While the derivation of \"bob\" is uncertain, John Camden Hotten in his 1864 \"Slang Dictionary\" says the original version was \"bobstick\" and speculates that it may be connected with Sir Robert Walpole.\nBritish Empire and Commonwealth.\nAustralian shillings.\nAustralian shillings, twenty of which made up one Australian pound, were first issued in 1910, with the Australian coat of arms on the reverse and King Edward VII on the face. The coat of arms design was retained through the reign of King George V until a new ram's head design was introduced for the coins of King George VI. This design continued until the last year of issue in 1963. In 1966, Australia's currency was decimalised and the shilling was replaced by a ten\u00a0cent coin (Australian), where 10 shillings made up one Australian dollar.\nThe slang term for a shilling coin in Australia was \"deener\". The slang term for a shilling as currency unit was \"bob\", the same as in the United Kingdom.\nAfter 1966, shillings continued to circulate, as they were replaced by ten-cent coins of the same size and weight.\nNew Zealand shilling.\nNew Zealand shillings, twenty of which made up one New Zealand pound, were first issued in 1933 and featured the image of a Maori warrior carrying a taiaha \"in a warlike attitude\" on the reverse. In 1967, New Zealand's currency was decimalised and the shilling was replaced by a ten-cent coin of the same size and weight. Ten-cent coins minted through the remainder of the 1960s included the legend \"ONE SHILLING\" on the reverse. Smaller ten-cent coins were introduced in 2006.\nMaltese shillings.\nThe shilling (, pl. \"xelini\") was used in Malta, prior to decimalisation in 1972, and had a face value of five Maltese cents.\nCeylonese shillings.\nIn British Ceylon, a shilling (, ) was equivalent to eight fanams. With the replacement of the rixdollar by the rupee in 1852, a shilling was deemed to be equivalent to half a rupee. On the decimalisation of the currency in 1969, a shilling was deemed to be equivalent to 50 Ceylon cents. The term continued to be used colloquially until the late 20th century.\nEast African shillings.\nThe East African shilling was in use in the British colonies and protectorates of British Somaliland, Kenya, Tanganyika, Uganda and Zanzibar from 1920, when it replaced the rupee, until after those countries became independent, and in Tanzania after that country was formed by the merger of Tanganyika and Zanzibar in 1964. Upon independence in 1960, the East African shilling in the British Somaliland and the Somali somalo in the Trust Territory of Somalia were replaced by the Somali shilling.\nIn 1966, the East African Monetary Union broke up, and the member countries replaced their currencies with the Kenyan shilling, the Ugandan shilling and the Tanzanian shilling, respectively. Though all these currencies have different values at present, there were plans to reintroduce the East African shilling as a new common currency by 2009, although this has not come about.\nNorth America.\nIn the thirteen British colonies that became the United States in 1776, British money was often in circulation. Each colony issued its own paper money, with pounds, shillings, and pence used as the standard units of account. Some coins were minted in the colonies, such as the pine tree shilling in the Massachusetts Bay Colony. After the United States adopted the dollar as its unit of currency and accepted the gold standard, one British shilling was worth 24 US cents. Due to ongoing shortages of US coins in some regions, shillings continued to circulate well into the nineteenth century. Shillings are described as the standard monetary unit throughout the autobiography of Solomon Northup (1853) and mentioned several times in the Horatio Alger Jr. story \"Ragged Dick\" (1868). Prices in an 1859 advertisement in a Chicago newspaper were given in dollars and shillings.\nIn British North America, \u00a3sd currencies were in use both during the French period (New France livre) and after the British conquest (Canadian pound). Between the 1760s and 1840s in Lower Canada, both French and British-based pounds coexisted as units of account, the French livre being close in value to the British shilling. A variety of coinage circulated. By 1858, a decimal Canadian dollar came into use in the Province of Canada. Other parts of British North America decimalized shortly afterwards and Canadian Confederation in 1867 passed control of currency to the federal government.\nSomali shilling.\nThe Somali shilling is the official currency of Somalia. It is subdivided into 100 \"cents\" (English), \"senti\" (Somali, also \u0633\u0646\u062a) or \"centesimi\" (Italian).\nThe Somali shilling has been the currency of parts of Somalia since 1921, when the East African shilling was introduced to the former British Somaliland protectorate. Following independence in 1960, the somalo of Italian Somaliland and the East African shilling (which were equal in value) were replaced at par in 1962 by the Somali shilling. Names used for the denominations were cent, centesimo (plural: centesimi) and \u0633\u0646\u062a (plurals: \u0633\u0646\u062a\u064a\u0645\u0627\u062a and \u0633\u0646\u062a\u064a\u0645\u0627) together with shilling, scellino (plural: scellini) and \u0634\u0644\u0646.\nThat same year, the \"Banca Nazionale Somala\" issued notes for 5, 10, 20 and 100 scellini/shillings. In 1975, the \"Bankiga Qaranka Soomaaliyeed\" (Somali National Bank) introduced notes for 5, 10, 20 and 100 shilin/shillings. These were followed in 1978 by notes of the same denominations issued by the \"Bankiga Dhexe Ee Soomaaliya\" (Central Bank of Somalia). 50 shilin/shillings notes were introduced in 1983, followed by 500 shilin/shillings in 1989 and 1000 shilin/shillings in 1990. Also in 1990 there was an attempt to reform the currency at 100 to 1, with new banknotes of 20 and 50 new shilin prepared for the redenomination.\nFollowing the breakdown in central authority that accompanied the civil war, which began in the early 1990s, the value of the Somali shilling was disrupted. The Central Bank of Somalia, the nation's monetary authority, also shut down operations. Rival producers of the local currency, including autonomous regional entities such as the Somaliland territory, subsequently emerged.\nSomalia's newly established Transitional Federal Government revived the defunct Central Bank of Somalia in the late 2000s. In terms of financial management, the monetary authority is in the process of assuming the task of both formulating and implementing monetary policy. Owing to a lack of confidence in the Somali shilling, the US dollar is widely accepted as a medium of exchange alongside the Somali shilling. Dollarization notwithstanding, the large issuance of the Somali shilling has increasingly fueled price hikes, especially for low value transactions. This inflationary environment, however, is expected to come to an end as soon as the Central Bank assumes full control of monetary policy and replaces the presently circulating currency introduced by the private sector.\nSomaliland shilling.\nThe Somaliland shilling is the official currency of Somaliland, a self-declared republic that is internationally recognised as an autonomous region of Somalia. The currency is not recognised as legal tender by the international community, and it currently has no official exchange rate. It is regulated by the Bank of Somaliland, Somaliland's central bank. Although the authorities in Somaliland have attempted to bar usage of the Somali shilling, Somalia's official currency is still in circulation in some regions.\nOther.\nElsewhere in the former British Empire, forms of the word \"shilling\" remain in informal use.\nIn Vanuatu and Solomon Islands, \"selen\" is used in Bislama and Pijin to mean \"money\"; in Malaysia, \"syiling\" (pronounced like \"shilling\") means \"coin\". In Egypt and Jordan the \"shillin\" () is equal to 1/20 (five \"qirshes\" \u2014 , ) of the Egyptian pound or the Jordanian dinar. In Belize, the term \"shilling\" is commonly used to refer to twenty-five cents.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60535", "revid": "37052726", "url": "https://en.wikipedia.org/wiki?curid=60535", "title": "Samuel Delany", "text": ""}
{"id": "60536", "revid": "4967956", "url": "https://en.wikipedia.org/wiki?curid=60536", "title": "Geography of California", "text": " \nCalifornia is a U.S. state on the western coast of North America. Covering an area of , California is among the most geographically diverse states. The Sierra Nevada, the fertile farmlands of the Central Valley, and the arid Mojave Desert of the south are some of the geographic features of this U.S. state. It is home to some of the world's most exceptional trees: the tallest (coast redwood), most massive (Giant Sequoia), and oldest (bristlecone pine). It is also home to both the highest (Mount Whitney) and lowest (Death Valley) points in the 48 contiguous states.\nThe state is generally divided into Northern and Southern California, although the boundary between the two is not well defined. San Francisco is decidedly a Northern California city and Los Angeles is a Southern California one but areas in between do not often share their confidence in geographic identity. The US Geological Survey defines the geographic center of California about 7.1 miles (11.4\u00a0km) driving distance from the United States Forest Service office in the community of North Fork. Earth scientists typically divide the state into eleven geomorphic provinces with clearly defined boundaries. They are, from north to south, the Klamath Mountains, the Cascade Range, the Modoc Plateau, the Basin and Range, the Coast Ranges, the Central Valley, the Sierra Nevada, the Transverse Ranges, the Mojave Desert, the Peninsular Ranges, and the Colorado Desert.\nState boundaries.\nThe boundaries of California were defined by Spanish claims of Mexico, as part of the province of Alta California. The northern boundary of Spanish claims was set at 42 degrees latitude by the Adams\u2013Onis Treaty of 1819. The states of Nevada and Utah, also originally part of Alta California, also use that line for their northern boundaries. The southern boundary, between California and Mexico, was established by the Treaty of Guadalupe Hidalgo that ended the Mexican\u2013American War in 1848. The line is about north of the former Alta California southern boundary. The eastern boundary consists of two straight lines: a north\u2013south line from the northern border to the middle of Lake Tahoe, and a second line angling southeast to the Colorado River. From that point, south-southwest of Davis Dam on Lake Mohave, the southeast boundary follows the Colorado River to the international border west of Yuma, Arizona. The eastern and south-eastern boundaries were decided upon during the debates of the California Constitutional Convention in 1849.\nNorthern California.\nNorthern California usually refers to the state's northernmost 48 counties.\nThe main population centers of Northern California include San Francisco Bay Area (which includes the cities of San Francisco, Oakland, and the largest city of the region, San Jose), and Sacramento (the state capital) as well as its metropolitan area. It also contains redwood forests, along with the Sierra Nevada including Yosemite Valley and Lake Tahoe, Mount Shasta (the second-highest peak in the Cascade Range after Mount Rainier in Washington), and the northern half of the Central Valley, one of the world's most productive agricultural regions. The climate can be generally characterized by its marine to warm Mediterranean climates along the coast, to a somewhat continental Mediterranean climate in the valley to alpine climate zones in the high mountains. Apart from the San Francisco Bay Area and Sacramento metropolitan areas (and some other cities in the Central Valley), it is a region of relatively low population density. Northern California's economy is noted for being the de facto world leader in industries such as high technology (both software and semiconductor), as well as being known for clean power, biomedical, government, and finance.\nKlamath Mountains.\nThe Klamath Mountains are a range in northwest California and southwest Oregon, the highest peak being Mount Eddy in Trinity County, California, at . The range has a varied geology, with substantial areas of serpentine and marble. The climate is characterized by moderately cold winters with heavy snowfall and warm, very dry summers with limited rainfall. As a consequence of the geology, the mountains have a unique flora, including several endemic or near-endemic species, such as Lawson's Cypress (Chamaecyparis lawsoniana) and Foxtail Pine (Pinus balfouriana). Brewer's Spruce \"(Picea breweriana)\" and Kalmiopsis \"(Kalmiopsis leachiana)\" are relict species, remaining since the last ice age.\nCascade Range.\nThe Cascade Range is a mountainous region stretching from the Fraser River in British Columbia, Canada down to south of Lassen Peak, California. The Cascades (as they are called for short) are part of the Pacific Ring of Fire, the ring of volcanoes around the Pacific Ocean. All of the known historic eruptions in the contiguous United States have been from either Cascade volcanoes or near Mono Lake. Lassen Peak was the last Cascade volcano to erupt in California, from 1914 to 1921. Lassen is the most southerly active volcano of the Cascade chain.\nThis region is located in the northeastern section of the state bordering Oregon and Nevada, mostly north of the Central Valley and the Sierra Nevada mountain range. The area is centered on Mount Shasta, near the Trinity Alps. Mount Shasta is a dormant volcano, but there is some evidence that it erupted in the 18th century.\nModoc Plateau.\nIn the northeast corner of the state lies the Modoc Plateau, an expanse of lava flows that formed a million years ago and now lie at an altitude of . The plateau has many cinder cones, juniper flats, pine forests, and seasonal lakes. The plateau lies between the Cascade Range to the west and the Warner Mountains to the east. The Lost River watershed drains the north part of the plateau, while southern watersheds either collect in basin reservoirs or flow into Big Sage Reservoir and thence to the Pit River.\nNine percent of the plateau is protected as reserves or wilderness areas, such as the Modoc National Wildlife Refuge. The plateau supports large herds of mule deer (\"Odocoileus hemionus\"), Rocky Mountain Elk (\"Cervus canadensis\"), and pronghorn (\"Antilocapra americana\"). Herds of wild horses and livestock grazing have altered the original high desert ecosystem of the plateau.\nBasin and Range.\nTo the east of the Sierra is the Basin and Range geological province, which extends into Nevada. The Basin and Range is a series of mountains and valleys (specifically horsts and grabens), caused by the extension of the Earth's crust. One notable feature of the Basin and Range is Mono Lake, which is the oldest lake in North America. The Basin and Range also contains the Owens Valley, the deepest valley in North America (more than 10,000 feet (3\u00a0km) deep, as measured from the top of Mount Whitney).\nIn the eastern part of the state, below the Sierra Nevada, there is a series of dry lake beds that were filled with water during the last ice age (fed by ice melt from alpine glaciers but never directly affected by glaciation; see pluvial). Many of these lakes have extensive evaporite deposits that contain a variety of different salts. In fact, the salt sediments of many of these lake beds have been mined for many years for various salts, most notably borax (this is most famously true for Owens Lake and Death Valley).\nIn this province reside the White Mountains, which are home to the oldest living organism in the world, the bristlecone pine\nCoast Ranges.\nTo the west of the Central Valley lies the Coast Ranges, including the Diablo Range, just east of San Francisco, and the Santa Cruz Mountains, to the south of San Francisco. The Coast Ranges north of San Francisco become increasingly foggy and rainy. These mountains are noted for their coast redwoods, the tallest trees on earth, which live within the range of the coastal fog.\nCentral Valley.\nCalifornia's geography is largely defined by its central feature\u2014the Central Valley, a huge, fertile valley between the coastal mountain ranges and the Sierra Nevada. The northern part of the Central Valley is called the Sacramento Valley, after its main river, and the southern part is called the San Joaquin Valley , after its main river. The whole Central Valley is watered by mountain-fed rivers (notably the San Joaquin, Kings, and Sacramento) that drain to the San Francisco Bay system. The rivers are sufficiently large and deep that several inland cities, notably Stockton, and Sacramento are seaports.\nThe southern tip of the valley has interior drainage and thus is not technically part of the valley at all. Tulare Lake, with an area of , once filled much of the area. In modern times, it is usually a dry lake and partially covered with agricultural fields. The lake reappears during unusually high levels of rainfall or snow melt such as the winter of 2022 and early spring of 2023.\nSierra Nevada.\nIn the east of the state lies the Sierra Nevada, which runs north\u2013south for . The highest peak in the contiguous United States, Mount Whitney at 14,505 feet (4.42\u00a0km), lies within the Sierra Nevada. The topography of the Sierra is shaped by uplift and glacial action.\nThe Sierra has 200\u2013250 sunny days each year, warm summers, fierce winters, and varied terrain, a rare combination of rugged variety and pleasant weather. The famous Yosemite Valley lies in the Central Sierra. The large, deep freshwater Lake Tahoe lies to the North of Yosemite. The Sierra is also home to the Giant Sequoia, the most massive trees on Earth.\nThe most famous hiking and horse-packing trail in the Sierra is the John Muir Trail, which goes from the top of Mt. Whitney to Yosemite valley. This is part of the Pacific Crest Trail that goes from Mexico to Canada. The three major national parks in this province are Yosemite National Park, Kings Canyon National Park, and Sequoia National Park.\nSouthern California.\nThe term Southern California usually refers to the ten southernmost counties which closely match the lower one-third of California's span of latitude. This definition coincides neatly with the county lines at 35\u00b0 47\u2032 28\u2033 north latitude, which form the northern borders of San Luis Obispo, Kern, and San Bernardino counties. Geographically, Southern California is separated from the north by the Transverse Ranges and the Sierra Nevada range, creating a significant biological barrier. Historically, this barrier also limited human movement and commerce.\nSouthern California consists of a heavily developed urban environment, home to some of the largest urban areas in the state, along with vast areas that have been left undeveloped. With over 22 million people, roughly 60% of California's population resides in Southern California. It is the second-largest urbanized region in the United States, second only to the Washington/Philadelphia/New York/Boston Northeastern Megalopolis. Where these cities are dense, with major downtown populations and significant rail and transit systems, much of Southern California is famous for its large, spread-out, suburban communities and use of automobiles and highways. The dominant areas are Los Angeles, Orange County, San Diego, and Riverside-San Bernardino, each of which is the center of its respective metropolitan area, composed of numerous smaller cities and communities. The urban area is also host to an international metropolitan region in the form of San Diego\u2013Tijuana, created by the urban area spilling over into Baja California.\nSouthern California is noted for industries including the film industry, residential construction, entertainment industry, and military aerospace. Other industries include software, automotive, ports, finance, tourism, biomedical, and regional logistics.\nTransverse Ranges.\nSouthern California is separated from the rest of the state by the east\u2013west trending Transverse Ranges. The Transverse Ranges include a series of east\u2013west trending mountain ranges that extend from Point Conception, at the western tip of Santa Barbara County, eastward (and a bit south) to the east end of the San Jacinto Mountains in western Riverside County.\nThe Santa Ynez Mountains make up the westernmost ranges, extending from Point Conception to the Ventura River just west-northwest of Ojai in Ventura County. Pine Mountain Ridge, Nordhoff Ridge\u2013Topatopa Mountains, Rincon Peak\u2013Red Mountain, Sulphur Mountain, Santa Paula Ridge, South Mountain\u2013Oat Mountain\u2013Santa Susana Mountains, Simi Hills, Conejo Mountains\u2013Santa Monica Mountains are all part of the Western Transverse Ranges in Ventura and western Los Angeles counties. The Transverse Ranges also include the Tehachapi Mountains, which separate the Central Valley from the Mojave Desert.\nThe Liebre Mountains occupy the northwest corner of Los Angeles County, and represent a northwestern extension of the San Gabriel Mountains, both on the Pacific plate side of the San Andreas Fault. The fault divides the San Gabriel Mountains from the San Bernardino Mountains further to the east in San Bernardino County.\nUrban Southern California occupies the valleys between the Santa Susana Mountains, Santa Monica Mountains and San Gabriel Mountains, which range from the Pacific Coast, eastward over , to the San Bernardino Mountains, north of San Bernardino. The highest point of the range is Mount San Gorgonio at . The San Gabriel Mountains have Mount Wilson observatory, where the redshift was discovered in the 1920s.\nIt is possible to surf in the Pacific Ocean and ski on a mountain during the same winter day in Southern California.\nMojave Desert.\nThere are harsh deserts in the Southeast of California. These deserts are caused by a combination of the cold offshore current, which limits evaporation, and the rain shadow of the mountains. The prevailing winds blow from the ocean inland. When the air passes over the mountains, adiabatic cooling causes most water in the air to rain on the mountains. When the air returns to sea level on the other side of the mountains, it recompresses, warms and dries, parching the deserts. When the wind blows from inland, the resulting hot dry katabatic winds are called the Santa Ana Winds.\nThe Mojave Desert is bounded by the peninsular Tehachapi Mountains on the Northwest, together with the San Gabriel and the San Bernardino Mountains on the Southwest. These Western boundaries are quite distinct, forming the dominant pie-slice shaped Antelope Valley in Southern California. The outlines of this valley are caused by the two largest faults in California: the San Andreas and the Garlock. The Mojave Desert extends Eastward into the State of Nevada. The Mojave Desert receives less than 6\u00a0inches (150\u00a0mm) of rain a year and is generally between 3,000 and 6,000 feet (1,000 and 2,000 m) of elevation. Areas such as the Antelope Valley desert which is a high desert received snow each year, in the past it could snow 2\u20133 times a year; however, recently snow level has declined significantly to once a year or less. Most of the towns and cities in the California portion of the Mojave are relatively small, except for Palmdale and Lancaster. However, some are quite famous like Barstow, a popular stop on the famous U.S. Route\u00a066. The Mojave Desert also contains the lowest, hottest place in the Americas: Death Valley, where temperature normally approaches 120\u00a0\u00b0F (49\u00a0\u00b0C), in late July and early August.\nPeninsular Ranges.\nThe southernmost mountains of California are the Peninsular Ranges, which are east of San Diego and continue into Baja California (Mexico) in the Sierra San Pedro Martir. The Peninsular Ranges contain the Laguna Mountains, the San Jacinto Mountains, the Santa Rosa Mountains, the Santa Ana Mountains and the Palomar Mountain Range, notable for its famous Palomar observatory. San Jacinto Peak's eastern shoulder has a cable tram that runs from the desert floor to nearly the top of the mountain where riders can set off hiking or go cross-country skiing.\nColorado Desert.\nTo the east of the peninsular ranges lie the Colorado and Sonoran Deserts, which extend into Arizona and Mexico.\nThe ground elevation is generally lower and in some areas was compressed downward, therefore the eastern Coachella and Imperial Valleys north of the U.S.-Mexican border are below sea level. The lowest community in the U.S. is Calipatria, California, at below sea level.\nOne feature of the desert is the Salton Sea, an inland lake that was formed in 1905 when a swollen Colorado River breached a canal near the U.S.-Mexico border and flowed into the Salton Sink (Salton Basin) for almost two years. Today, the Salton Sea, a new version of historic Lake Cahuilla, remains as California's largest lake.\nPacific Ocean.\nThe Pacific Ocean lies to the west of California. Owing to the long length of the state, Sea temperatures generally range from 50\u00a0\u00b0F (10\u00a0\u00b0C) in the northernmost parts during winter to 70\u00a0\u00b0F (21\u00a0\u00b0C) in the south coast during summer. The lower seasonal temperature variance compared to the waters of the East Coast is because of up-welling deep waters with dissolved nutrients. Therefore, sea life in and around California has examples of both Arctic and tropical, biotopes, leaning more towards the latter in the south coast and vice versa. The sea off California is remarkably fertile, a murky green filled with a massive variety of fish, rather than the clear dead blue of most tropical seas. Before 1930, there was an extremely valuable sardine (herring) fishery off Monterey, but this was depleted, an event later famous as the background to John Steinbeck's \"Cannery Row\".\nCalifornia's coastline is about 840 miles long, the third longest coastline in the United States after Alaska and Florida.\nGeology.\nFaults, volcanoes, and tsunamis.\nEarthquakes occur due to faults that run the length of the Pacific coast, the largest being the San Andreas Fault. Major historical earthquakes include, with the magnitudes listed:\nCoastal cities are vulnerable to tsunamis from locally generated earthquakes as well as those elsewhere in the Pacific Ring of Fire. The Great Chilean earthquake tsunami (1960) killed one person and caused $500,000 to $1,000,000 of damage in Los Angeles, damaged harbors in many coastal cities, and flooded streets in Crescent City. Waves from the Alaskan Good Friday earthquake of 1964 killed twelve people in Crescent City and caused damage as far south as Los Angeles. USGS has released the UCERF California earthquake forecast which models earthquake occurrence in California.\nCalifornia is also home to several volcanoes, including Lassen Peak, which erupted in 1914 and 1921, and Mount Shasta.\nTectonics.\nCalifornia, when only partially explored by the Spanish, was once thought to be an island, as when the southern Baja California peninsula is approached from the Gulf of California the land appears to the west. It is expected, through the motions of plate tectonics that the sea floor spreading now acting in the Gulf of California (also known as the Sea of Cortez) will eventually extend through Southern California and along the San Andreas fault to below San Francisco, finally forming a long island in less than 150 million years. (For comparison, this is also the approximate age of the Atlantic Ocean.) Predictions suggest that this island will eventually collide with Alaska after an additional 100 million years.\nClimate.\nCalifornia's climate varies widely, from arid to subarctic, depending on latitude, elevation, and proximity to the coast. Coastal and Southern parts of the state have a Subtropical Mediterranean climate, with somewhat rainy winters and dry summers. The influence of the ocean generally moderates temperature extremes, creating warmer winters and substantially cooler summers, especially along the coastal areas.\nThe state is subject to coastal storms during the winter. Eastern California is subject to summertime thunderstorms caused by the North American monsoon. Dry weather during the rest of the year produces conditions favorable to wildfires. California hurricanes occur less frequently than their counterparts on the Atlantic Ocean. Higher elevations experience snowstorms in the winter months.\nFloods are occasionally caused by heavy rain, storms, and snowmelt. Steep slopes and unstable soil make certain locations vulnerable to landslides in wet weather or during earthquakes.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60538", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=60538", "title": "BART", "text": ""}
{"id": "60540", "revid": "302229", "url": "https://en.wikipedia.org/wiki?curid=60540", "title": "Leslie Groves", "text": "American military officer (1896\u20131970)\nLeslie Richard Groves Jr. (17 August 1896 \u2013 13 July 1970) was a United States Army Corps of Engineers officer who oversaw the construction of the Pentagon and directed the Manhattan Project, a top secret research project that developed the atomic bomb during World War II.\nThe son of a U.S. Army chaplain, Groves lived at various Army posts during his childhood. In 1918, he graduated fourth in his class at the United States Military Academy at West Point and was commissioned into the United States Army Corps of Engineers. In 1929, he went to Nicaragua as part of an expedition to conduct a survey for the Inter-Oceanic Nicaragua Canal. Following the 1931 Nicaraguan earthquake, Groves took over Managua's water supply system, for which he was awarded the Nicaraguan Presidential Medal of Merit. He attended the Command and General Staff School at Fort Leavenworth, Kansas, in 1935 and 1936, and the Army War College in 1938 and 1939, after which he was posted to the War Department General Staff. Groves developed \"a reputation as a doer, a driver, and a stickler for duty\". In 1940 he became special assistant for construction to the Quartermaster General, tasked with inspecting construction sites and checking on their progress. In August 1941, he was appointed to create the gigantic office complex for the War Department's 40,000 staff that would ultimately become the Pentagon.\nIn September 1942, Groves took charge of the Manhattan Project. He was involved in most aspects of the atomic bomb's development: he participated in the selection of sites for research and production at Oak Ridge, Tennessee; Los Alamos, New Mexico; and Hanford, Washington. He directed the enormous construction effort, made critical decisions on the various methods of isotope separation, acquired raw materials, directed the collection of military intelligence on the German nuclear energy project and helped select the cities in Japan that were chosen as targets. Groves wrapped the Manhattan Project in security, but spies working within the project were able to pass some of its most important secrets to the Soviet Union.\nAfter the war, Groves remained in charge of the Manhattan Project until responsibility for nuclear weapons production was handed over to the United States Atomic Energy Commission in 1947. He then headed the Armed Forces Special Weapons Project, which had been created to control the military aspects of nuclear weapons. He was given a dressing down by the Chief of Staff of the Army, General of the Army Dwight D. Eisenhower, on the basis of various complaints, and told that he would never be appointed Chief of Engineers. Three days later, Groves announced his intention to leave the Army. He was promoted to lieutenant general just before his retirement on 29 February 1948 in recognition of his leadership of the bomb program. By a special act of Congress, his date of rank was backdated to 16 July 1945, the date of the Trinity nuclear test. He went on to become a vice president at Sperry Rand.\nEarly life.\nLeslie Richard Groves Jr. was born in Albany, New York, on 17 August 1896, the third son of four children of a pastor, Leslie Richard Groves Sr., and his wife Gwen n\u00e9e Griffith. He was half Welsh and half English, with some French Huguenot ancestors who came to the United States in the 17th century. Leslie Groves Sr. resigned as pastor of the Sixth Presbyterian church in Albany in December 1896 to become a United States Army chaplain. He was posted to the 14th Infantry at Vancouver Barracks in Washington state in 1897.\nFollowing the outbreak of the Spanish\u2013American War in 1898, Chaplain Groves was sent to Cuba with the 8th Infantry. On returning to Vancouver Barracks, he was ordered to rejoin the 14th Infantry in the Philippines. Service in the Philippine\u2013American War and the Boxer Rebellion followed. The 14th Infantry returned to the United States in 1901 and moved to Fort Snelling, Minnesota. The family relocated there from Vancouver, then moved to Fort Hancock, New Jersey, and returned to Vancouver in 1905. Chaplain Groves was hospitalized with tuberculosis at Fort Bayard in 1905. He decided to settle in southern California and bought a house in Altadena. His next posting was to Fort Apache, Arizona. The family spent their summers there and returned to Altadena where the children attended school.\nIn 1911, Chaplain Groves was ordered to return to the 14th Infantry, which was now stationed at Fort William Henry Harrison, Montana. At Fort Harrison, the younger Groves met Grace (Boo) Wilson, the daughter of Colonel Richard Hulbert Wilson, a career Army officer who had served with Chaplain Groves during the 8th Infantry's posting to Cuba. In 1913, the 14th Infantry moved once more, this time to Fort Lawton in Seattle, Washington.\nGroves entered Queen Anne High School in 1913, and graduated in 1914. While completing high school, he enrolled in courses at the University of Washington, in anticipation of attempting to gain an appointment to the United States Military Academy. He earned a nomination from the President, Woodrow Wilson, which allowed him to compete for a vacancy, but did not score a high enough mark on the examination to be admitted. Charles W. Bell from California's 9th congressional district nominated Groves as an alternate, but the principal nominee accepted. Instead, Groves enrolled at the Massachusetts Institute of Technology (MIT) and planned to re-take the West Point entrance exam. In 1916, Groves tested again, attained a passing score, and was accepted. He later said \"Entering West Point fulfilled my greatest ambition. I had been brought up in the Army, and in the main had lived on Army posts all my life.\"\nGroves's class entered West Point on 15 June 1916. His nickname at West Point was \"Greasy.\" The United States declaration of war on Germany in April 1917 led to their program of instruction being shortened as the War Emergency Course (WEC), which graduated on 1 November 1918, a year and a half ahead of schedule. Groves finished fourth in his class, which earned him a commission as a second lieutenant in the Corps of Engineers, the first choice of most high ranking cadets.\nAt MIT he had played tennis informally, but at West Point he could not skate for ice hockey, did not like basketball, and was not good enough for baseball or track. So football was his only sport. He said that \"I was the number two center but was on the bench most of the time as in those days you didn't have substitutes and normally the number one played the whole game. I was not very heavy, and today would be considered too light to play at all\".\nBetween the wars.\nAfter the traditional month's leave following graduation from West Point, Groves reported to Camp A. A. Humphreys, Virginia, in December 1918, where he was promoted to first lieutenant on 1 May 1919. He was sent to France in June on an educational tour of the European battlefields of World War I. After returning from Europe, Groves became a student officer at the Engineer School at Camp Humphreys in September 1919. On graduation he was posted to the 7th Engineers at Fort Benning, Georgia, as a company commander.\nHe returned to Camp Humphreys in February 1921 for the Engineer Basic Officers' Course. On graduation in August 1921, he was posted to the 4th Engineers, stationed at Camp Lewis, Washington. He was then posted to Fort Worden in command of a survey detachment. This was close to Seattle, so he was able to pursue his courtship of Grace Wilson, who had become a kindergarten teacher. They were married in St. Clement's Episcopal Church in Seattle on 10 February 1922. Their marriage produced two children: a son, Richard Hulbert, born in 1923, and a daughter, Gwen, born in 1928.\nIn November 1922, Groves received his first overseas posting, as a company commander with the 3rd Engineers at the Schofield Barracks in Hawaii. He earned a commendation for his work there, constructing a trail from Kahuku to Pupukea. In November 1925 he was posted to Galveston, Texas, as an assistant to the District Engineer, Major Julian Schley. Groves's duties included opening the channel at Port Isabel and supervising dredging operations in Galveston Bay. In 1927 he became commander of Company D, 1st Engineers, at Fort DuPont, Delaware.\nDuring the he was sent to Fort Ethan Allen, Vermont, to assist with a detachment of the 1st Engineers. After a pontoon bridge they constructed was swamped and swept away by the flood waters, Groves was accused of negligence. A month later Groves and several of his men were seriously injured, one fatally, when a block of TNT prematurely detonated. Groves's superior wrote a critical report on him, but the Chief of Engineers, Major General Edgar Jadwin, interceded, attributing blame to Groves's superiors instead. Groves was returned to Fort DuPont.\nIn 1929, Groves departed for Nicaragua in charge of a company of the 1st Engineers as part of an expedition whose purpose was to conduct a survey for the Inter-Oceanic Nicaragua Canal. Following the 1931 Nicaragua earthquake, Groves took over responsibility for Managua's water supply system, for which he was awarded the Nicaraguan Presidential Medal of Merit. Groves was promoted to captain on 20 October 1934. He attended the Command and General Staff School at Fort Leavenworth, Kansas, in 1935 and 1936, after which he was posted to Kansas City, Missouri, as assistant to the commander of the Missouri River Division. In 1938 and 1939 he attended the Army War College. On 1 July 1939, he was posted to the War Department General Staff in Washington, D.C.\nWorld War II.\nConstruction Division.\nGroves was promoted to major on 1 July 1940. Three weeks later, he became special assistant for construction to the Quartermaster General, Major General Edmund B. Gregory. The two men had known each other a long time, as Groves's father was a close friend of Gregory's. At this point, the US Army was about to embark on a national mobilization, and it was the task of the Construction Division of the Quartermaster Corps to prepare the necessary accommodations and training facilities for the vast army that would be created. The enormous construction program had been dogged by bottlenecks, shortages, delays, spiralling costs, and poor living conditions at the construction sites. Newspapers began publishing accounts charging the Construction Division with incompetence, ineptitude, and inefficiency. Groves, who \"had a reputation as a doer, a driver, and a stickler for duty\", was one of a number of engineer officers brought in to turn the project around. He was tasked with inspecting construction sites and checking on their progress.\nOn 12 November 1940, Gregory asked Groves to take over command of the Fixed Fee Branch of the Construction Division as soon as his promotion to colonel came through. Groves assumed his new rank and duties on 14 November 1940. Groves later recalled:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;During the first week that I was on duty there, I could not walk out of my office down the corridor to Hartman's office without being literally assailed by the officers or civilian engineers with liaison responsibility for various camps. It is no exaggeration to state that during this period decisions involving up to $5,000,000 [$ with inflation] were made at the rate of about one every 100 feet of corridor walked.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nFirst, General Groves is the biggest S.O.B. I have ever worked for. He is most demanding. He is most critical. He is always a driver, never a praiser. He is abrasive and sarcastic. He disregards all normal organizational channels. He is extremely intelligent. He has the guts to make difficult, timely decisions. He is the most egotistical man I know. He knows he is right and so sticks by his decision. He abounds with energy and expects everyone to work as hard or even harder than he does. Although he gave me great responsibility and adequate authority to carry out his mission-type orders, he constantly meddled with my subordinates. However, to compensate for that he had a small staff, which meant that we were not subject to the usual staff-type heckling. He ruthlessly protected the overall project from other government agency interference, which made my task easier. He seldom accepted other agency cooperation and then only on his own terms. During the war and since I have had the opportunity to meet many of our most outstanding leaders in the Army, Navy and Air Force as well as many of our outstanding scientific, engineering and industrial leaders. And in summary, if I had to do my part of the atomic bomb project over again and had the privilege of picking my boss I would pick General Groves.\nKenneth D. Nichols\nGroves instituted a series of reforms. He installed phone lines for the Supervising Construction Quartermasters, demanded weekly reports on progress, ordered that reimbursement vouchers be processed within a week, and sent expediters to sites reporting shortages. He ordered his contractors to hire whatever special equipment they needed and to pay premium prices if necessary to guarantee quick delivery. Instead of allowing construction of camps to proceed in whatever order the contractors saw fit, Groves laid down priorities for completion of camp facilities, so that the troops could begin moving in even while construction was still under way.\nBy mid-December, the worst of the crisis was over. Over half a million men had been mobilized and essential accommodations and facilities for two million men were 95 per cent complete. Between 1 July 1940 and 10 December 1941, the Construction Division let contracts worth $1,676,293,000 ($ with inflation), of which $1,347,991,000 ($ with inflation), or about 80 per cent, were fixed-fee contracts.\nOn 19 August 1941, Groves was summoned to a meeting with the head of the Construction Division, Brigadier General Brehon B. Somervell. In attendance were Captain Clarence Renshaw, one of Groves's assistants; Major Hugh J. Casey, the chief of the Construction Division's Design and Engineering Section; and George Bergstrom, a former president of the American Institute of Architects. Casey and Bergstrom had designed an enormous office complex to house the War Department's 40,000 staff together in one building, a five-story, five-sided structure, which would ultimately become the Pentagon.\nThe Pentagon had a total square footage of \u00a0\u2013 twice that of the Empire State Building\u00a0\u2013 making it the largest office building in the world. The estimated cost was $35 million ($ with inflation), and Somervell wanted of floor space available by 1 March 1942. Bergstrom became the architect-engineer with Renshaw in charge of construction, reporting directly to Groves. At its peak the project employed 13,000 persons. By the end of April, the first occupants were moving in and of space was ready by the end of May. In the end, the project cost some $63 million ($ with inflation).\nGroves steadily overcame one crisis after another, dealing with strikes, shortages, competing priorities and engineers who were not up to their tasks. He worked six days a week in his office in Washington, D.C. During the week he would determine which project was in the greatest need of personal attention and pay it a visit on Sunday. Groves later recalled that he was \"hoping to get to a war theater so I could find a little peace.\"\nManhattan Project.\nThe Manhattan Engineer District (MED) was formally established by the Chief of Engineers, Major General Eugene Reybold on 16 August 1942. The name was chosen by Groves and MED's district engineer, Colonel James C. Marshall. Like other engineer districts, it was named after the city where its headquarters was located, at 270 Broadway. Unlike the others, it had no geographic boundaries, only a mission: to develop an atomic bomb. Marshall had the authority of a division engineer head and reported directly to Reybold.\nAlthough Reybold was satisfied with the progress being made, Vannevar Bush was less so. He felt that aggressive leadership was required, and suggested the appointment of a prestigious officer as overall project director. Somervell, now Chief of Army Service Forces, recommended Groves. Somervell met Groves outside the hearing room where Groves had been testifying before a United States Congress committee on military housing and informed him that \"The Secretary of War has selected you for a very important assignment, and the President has approved the selection\u00a0... If you do the job right, it will win the war.\" Groves could not hide his disappointment at not receiving a combat assignment: \"Oh, that thing,\" he replied (having heard of the Manhattan Project).\nGroves met with Major General Wilhelm D. Styer in his office at the Pentagon to discuss the details. They agreed that in order to avoid suspicion, Groves would continue to supervise the Pentagon project. He would be promoted to brigadier general, as it was felt that the title \"general\" would hold more sway with the academic scientists working on the Manhattan Project. Groves therefore waited until his promotion came through on 23 September 1942 before assuming his new command so the scientists (in academia the prerogatives of rank were more important than in the Army) would think of him as a general rather than a promoted colonel. His orders placed him directly under Somervell rather than Reybold, with Marshall now answerable to Groves.\nGroves was given authority to sign contracts for the project from 1 September 1942. The Under Secretary of War, Robert P. Patterson, retrospectively delegated his authority from the President under the War Powers Act of 1941 in a memorandum to Groves dated 17 April 1944. Groves delegated the authority to Kenneth Nichols, except for contracts of $5 million or more that required his authority. The written authority was only given in 1944 when Nichols was about to sign a contract with Du Pont, and it was found that Nichols's original authority to sign project contracts for Marshall was based on a verbal authority from Styer, and Nichols only had the low delegated authority of a divisional engineer.\nGroves soon decided to establish his project headquarters on the fifth floor of the New War Department Building, now known as the Harry S Truman Building, in Washington, D.C., where Marshall had maintained a liaison office. In August 1943, the MED headquarters moved to Oak Ridge, Tennessee, but the name of the district did not change.\nConstruction accounted for roughly 90 percent of the Manhattan Project's total cost. The day after Groves took over, he and Marshall took a train to Tennessee to inspect the site that Marshall had chosen for the proposed production plant at Oak Ridge. Groves was suitably impressed with the site, and steps were taken to condemn the land. Protests, legal appeals, and congressional inquiries were to no avail. By mid-November U.S. Marshals were tacking notices to vacate on farmhouse doors, and construction contractors were moving in.\nMeanwhile, Groves had met with J. Robert Oppenheimer, a physicist at the University of California, Berkeley, and discussed the creation of a laboratory where the bomb could be designed and tested. Groves was impressed with the breadth of Oppenheimer's knowledge. He had a long conversation on a train after a meeting in Chicago on October 15, when Groves invited Oppenheimer to join Marshall and Nichols on the 20th Century Limited train returning to New York. After dinner on the train they discussed the project while squeezed into Nichols's one-person roomette, and when Oppenheimer left the train at Buffalo, Nichols had no doubt that he should direct the new lab. Groves saw that Oppenheimer thoroughly understood the issues involved in setting up a laboratory in a remote area. These were features that Groves found lacking in other scientists, and he knew that broad knowledge would be vital in an interdisciplinary project that would involve not just physics, but chemistry, metallurgy, ordnance, and engineering.\nIn October 1942 Groves and Oppenheimer inspected sites in New Mexico, where they selected a suitable location for the laboratory at Los Alamos. Unlike Oak Ridge, the ranch school at Los Alamos, along with of surrounding forest and grazing land, was soon acquired. Groves also detected in Oppenheimer something that many others did not, an \"overweening ambition\" which Groves reckoned would supply the drive necessary to push the project to a successful conclusion. Groves became convinced that Oppenheimer was the best and only man to run the laboratory.\nFew agreed with him in 1942. Oppenheimer had little administrative experience and, unlike other potential candidates, no Nobel Prize. There was also concern about whether Oppenheimer was a security risk, as many of his associates were communists, including his brother Frank Oppenheimer, his wife Katherine Oppenheimer, and his girlfriend Jean Tatlock. Oppenheimer's Communist Party connections soon came to light, but Groves personally waived the security requirements and issued Oppenheimer a clearance on 20 July 1943. Groves's faith in Oppenheimer was ultimately justified. Oppenheimer's inspirational leadership fostered practical approaches to designing and building bombs. Asked years later why Groves chose him, Oppenheimer replied that the general \"had a fatal weakness for good men.\" Isidor Rabi considered the appointment \"a real stroke of genius on the part of General Groves, who was not generally considered to be a genius\u00a0...\"\nGroves made critical decisions on prioritizing the various methods of isotope separation and acquiring raw materials needed by the scientists and engineers. By the time he assumed command of the project, it was evident that the AA-3 priority rating that Marshall had obtained was insufficient. The top ratings were AA-1 through AA-4 in descending order, although there was also a special AAA rating reserved for emergencies. Ratings AA-1 and AA-2 were for essential weapons and equipment, so Colonel Lucius D. Clay, the deputy chief of staff at Services and Supply for requirements and resources, felt that the highest rating he could assign was AA-3, although he was willing to provide an AAA rating on request for critical materials to remove bottlenecks. Groves went to Donald M. Nelson, the chairman of the War Production Board and, after threatening to take the matter to the President, obtained a AAA priority for the Manhattan project. It was agreed that the AA-3 priority would still be used where possible.\nThe Combined Development Trust was established by the governments of the United Kingdom, United States and Canada in June 1944, with Groves as its chairman, to procure uranium and thorium ores on international markets. In 1944, the trust purchased of uranium oxide ore from companies operating mines in the Belgian Congo. In order to avoid briefing the Treasury Secretary, Henry Morgenthau Jr., on the project, a special account not subject to the usual auditing and controls was used to hold Trust monies. Between 1944 and the time he resigned from the Trust in 1947, Groves deposited a total of $37.5 million into the Trust's account.\nWorried by the heavy losses occurring during the Battle of the Bulge, in late December 1944, President Franklin D. Roosevelt requested atomic bombs be dropped on Germany during his only meeting with Groves during the war. Groves informed him the first workable bomb was six months away.\nIn 1943, the Manhattan District became responsible for collecting military intelligence on Axis atomic research. Groves created Operation Alsos, special intelligence teams that would follow in the wake of the advancing armies, rounding up enemy scientists and collecting what technical information and technology they could. Alsos teams ultimately operated in Italy, France and Germany. The security system resembled that of other engineer districts. The Manhattan District organized its own counterintelligence which gradually grew in size and scope, but strict security measures failed to prevent the Soviets from conducting a successful espionage program that stole some of its most important secrets.\nGroves met with General Henry H. Arnold, the Chief of U.S. Army Air Forces, in March 1944 to discuss the delivery of the finished bombs to their targets. Groves was hoping that the Boeing B-29 Superfortress would be able to carry the finished bombs. The 509th Composite Group was duly activated on 17 December 1944 at Wendover Army Air Field, Utah, under the command of Colonel Paul W. Tibbets. A joint Manhattan District \u2013 USAAF targeting committee was established to determine which cities in Japan should be targets. It recommended Kokura, Hiroshima, Niigata, and Kyoto.\nAt this point, Secretary of War Henry L. Stimson intervened, announcing that he would be making the targeting decision, and that he would not authorize the bombing of Kyoto. Groves attempted to get him to change his mind several times and Stimson refused every time. Kyoto had been the capital of Japan for centuries, and was of great cultural and religious significance. In the end, Groves asked Arnold to remove Kyoto not just from the list of nuclear targets, but from targets for conventional bombing as well. Nagasaki was substituted for Kyoto as a target.\nGroves was promoted to temporary major general on 9 March 1944. After the atomic bombing of Hiroshima and Nagasaki became public knowledge, he was awarded the Distinguished Service Medal. His citation read:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nGroves had previously been nominated for the Distinguished Service Medal for his work on the Pentagon, but to avoid drawing attention to the Manhattan Project, it had not been awarded at the time. After the war, the Decorations Board decided to change it to a Legion of Merit. In recognition of his work on the project, the Belgian government made him a Commander of the Order of the Crown and the British government made him an honorary Companion of the Order of the Bath.\nAfter the war.\nResponsibility for nuclear power and nuclear weapons was transferred from the Manhattan District to the Atomic Energy Commission on 1 January 1947. On 29 January 1947, the Secretary of War, Robert P. Patterson, and the Secretary of the Navy, James V. Forrestal, issued a joint directive creating the Armed Forces Special Weapons Project (AFSWP) to control the military aspects of nuclear weapons. Groves was appointed its chief on 28 February 1947. In April, AFSWP moved from the New War Department Building to the fifth floor of the Pentagon. Groves had already made a start on the new mission by creating Sandia Base in 1946.\nThe Chief of Staff of the United States Army, General of the Army Dwight D. Eisenhower, met with Groves on 30 January 1948 to evaluate his performance. Eisenhower recounted a long list of complaints about Groves pertaining to his rudeness, arrogance, insensitivity, contempt for the rules, and maneuvering for promotion out of turn. Eisenhower made it clear that Groves would never become Chief of Engineers.\nGroves realized that in the rapidly shrinking postwar military he would not be given any assignment similar in importance to the one he had held in the Manhattan Project, as such posts would go to combat commanders returning from overseas, and he decided to leave the Army. In recognition of his leadership of the Manhattan Project, he received an honorary promotion to lieutenant general by special Act of Congress, effective 24 January 1948, just before his retirement on 29 February 1948. His date of rank was backdated to 16 July 1945, the date of the Trinity nuclear test.\nLater life.\nGroves went on to become a vice president at Sperry Rand, an equipment and electronics firm, and moved to Darien, Connecticut, in 1948, and retired at age 65 in 1961. He also served as president of the West Point alumni organization, the \"Association of Graduates\". He presented General of the Army Douglas MacArthur the Sylvanus Thayer Award in 1962, which was the occasion of MacArthur's famous speech to the U.S. Military Academy Corps of Cadets. In retirement, Groves wrote an account of the Manhattan Project entitled \"Now It Can Be Told\", originally published in 1962. In 1964, he moved back to Washington, D.C.\nGroves suffered a heart attack caused by chronic calcification of the aortic valve on 13 July 1970. He was rushed to Walter Reed Army Medical Center in Washington, D.C., where he died that night at age 73. A funeral service was held in the chapel at Fort Myer, Virginia, after which Groves was interred in Arlington National Cemetery next to his brother Allen, who had died of pneumonia in 1916.\nLegacy.\nGroves is memorialized at a namesake park along the Columbia River, near the Hanford Site in Richland, Washington. At the United States Military Academy, the LTG Leslie R. Groves Award is awarded to the cadet with the highest GPA in major classes associated with nuclear engineering. \nThe 1980 BBC series, \"Oppenheimer\", featured Manning Redwood as Groves. The same year, he was played by Richard Herd in the American television movie, \"\". In the 1989 film \"Fat Man and Little Boy\", he was portrayed by Paul Newman, and in the made-for-TV movie of the same year, \"Day One\", by Brian Dennehy. In 1995, Groves was portrayed by Richard Masur in the Japanese-Canadian made-for-television movie \"Hiroshima\". He was portrayed by Eric Owens in the 2007 Lyric Opera of Chicago's work \"Doctor Atomic\". The opera follows Oppenheimer, Groves, Edward Teller and others in the days preceding the Trinity test. Groves is played by Matt Damon in Christopher Nolan's 2023 film \"Oppenheimer\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "60541", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=60541", "title": "Hannelore Kohl", "text": "Wife of Helmut Kohl\nJohanna Klara Eleonore \"Hannelore\" Kohl (n\u00e9e Renner; 7 March 1933 \u2013 5 July 2001) was the first wife of German Chancellor Helmut Kohl. She met him for the first time at a school party in Ludwigshafen, Allied-occupied Germany in 1948, when she was 15 years old, and they became engaged in 1953. They were married from 1960 until her death in 2001, a span which included his entire political career. They were the parents of Walter Kohl and Peter Kohl.\nAs the first lady of Rhineland-Palatinate (1969\u20131976) and later as the wife of the Chancellor (1982\u20131998) she undertook official duties, and was engaged in philanthropic work. According to their sons she was an important adviser for her husband during his chancellorship, especially concerning the German reunification and in international relations. Her fluency in foreign languages aided her husband in personal diplomacy.\nLife and work.\nJohanna Klara Eleonore Renner was born and christened in Berlin. Her father Wilhelm Renner who joined the Nazi Party (NSDAP) in 1933, became an engineer, business executive, at Hugo Schneider AG and also headed the employment office that developed the anti-tank weapon . Later, she chose \"Hannelore\" to be used as her first name.\nIn the days following Germany's defeat in World War II, at the age of 12, Hannelore Kohl was \"one of the girls battered and defiled by Stalin's soldiers\", multiple times raped by multiple Soviet soldiers and then thrown out of a window. In addition to psychological trauma, the attacks left her with a fractured vertebra and back pain for the rest of her life. In order to help others with similar injuries, in 1983 she founded the , a foundation that helps those with trauma-induced injuries to the central nervous system, and became its president.\nHannelore Kohl had trained as an interpreter of English and French, which she spoke fluently. She had to end her studies in 1952, when her father died, and worked for some years as a foreign-language secretary. She later utilized her fluency in English and French in personal diplomacy alongside her husband, who spoke no foreign languages.\nOn 5 July 2001, Kohl was found dead at age 68 in her Ludwigshafen home. She had apparently died by suicide with an overdose of sleeping pills, after years of suffering from what she had claimed to be a very rare and painful photoallergy induced by an earlier penicillin treatment that had forced her to avoid practically all sunlight for years. Hannelore's biographer, Heribert Schwan, cited \"medical experts to support his theory that the bizarre light allergy of her later years may have been a psychosomatic reaction to the suppressed traumas of the war.\" In 2005, the was renamed in her honor.\nKohl's collection of German-style cooking recipes, (\"Culinary Journey through German Regions\"), was published in 1996.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60542", "revid": "50599207", "url": "https://en.wikipedia.org/wiki?curid=60542", "title": "Adams State University", "text": "Public university in Alamosa, Colorado, U.S.\nAdams State University is a public university in Alamosa, Colorado, United States. The university's Adams State Grizzlies athletic teams compete in the Rocky Mountain Athletic Conference.\nHistory.\nAdams State was founded in 1921 as a teacher's college. Billy Adams, a Colorado legislator who would later become a three-term governor of Colorado, worked for three decades before obtaining the authorization to found Adams State Normal School in 1921, to provide higher education opportunities for teachers from remote and rural areas of Colorado, such as the San Luis Valley, and see them work in those same areas. In 1926, Harriet Dalzell Hester became the university's first graduate. She became the school's first librarian and an Alamosa County school superintendent. The school adopted the name Adams State College in 1946, corresponding with the expansion of its undergraduate and graduate programs.\nIn 2012, the institution's name changed again, to Adams State University.\nThe university gained some national attention in 2016 when its online classes came under scrutiny. The university's accreditor, the Higher Learning Commission, placed the university on probation. In 2018, the probation was lifted and the university's status was restored to \"Accredited\".\nThe university also came into the national spotlight when it placed president Beverlee McClure on leave after employees lodged complaints about her \"caustic behavior\". Cheryl D. Lovell was named the interim president and appointed to serve a 12-month term beginning July 1, 2018.\nAcademics.\nAdams State offers bachelor's degrees in 16 different academic programs, with nearly 60 emphases, 5 teacher licensure programs, and 10 pre-professional programs, in addition to 7 master's degrees and 1 doctoral degree. Students can also earn an associate of art or science degree at Adams State.\nCampus.\nAdams State University's campus is located in the heart of the San Luis Valley. All of the university's academic and residential buildings are located on its contiguous campus.\nAcademic buildings.\nThe main administration building and oldest building on campus is Richardson Hall, named after the school's first president, Ira Richardson. The home of the math and science curriculum, Porter Hall, is named for alumnus William A. Porter, the creator of E-Trade and a major benefactor of the school. McDaniel Hall, named for donor and emeritus faculty member John McDaniel, is the main venue for English, psychology, history, sociology, and teacher education classes.\nCampus edifices for the performing arts include the Adams State University Theater (erected in 2001), the Music Building (which underwent major renovations in 2011) and the Leon Memorial Concert Hall.\nAthletic facilities.\nThere are two gyms and an indoor pool. The Rex Activity Center for student recreation includes weights, exercise bikes, rock climbing wall, and racquet ball courts. Plachy Hall includes the gym and indoor pool and field house as part of the Athletics Department.\nThe Rex Stadium has undergone major renovation including the addition of the Residence at the Rex. The new complex includes suites for game viewing. The new residence hall provides one of the most impressive views, with a view of Mount Blanca (one of the 14ers of Colorado) to the east and overlooking the track and football field to the west. A new $750,000 video-tron screen displays action and replays at one end of the field.\nResidences.\nThere are currently six on-campus apartment complexes (Houtchens, McCurry, Moffat, Petteys, Savage and Residence at the Rex) that include private bedrooms for two to three students, a kitchen/living room and private bath, in addition to three traditional dormitory halls (Conour, Coronado and Girault). Most entering freshmen are housed in Coronado and Girault Halls. The main cafeteria, La Mesa Dining Hall, in the Student Union Building is newly renovated.\nAthletics.\nThe Adams State Grizzlies compete in the Rocky Mountain Athletic Conference (RMAC) at the NCAA Division II level. Grizzly teams compete in men's baseball, basketball, cross country, football, lacrosse, soccer, swimming, track and field, and wrestling; and women's\u00a0 basketball, cross country, golf, lacrosse, soccer, softball, swimming, track and field, and volleyball.\nThe Grizzlies have won 222 RMAC team championships and 64 team National Championships. Individually, Adams State has produced 268 national champions and 1,937 All-Americans.\nThe school's sports teams are now called the Grizzlies and were formerly known as the Indians.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60543", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=60543", "title": "Pope Theodore I", "text": "Head of the Catholic Church from 642 to 649\nPope Theodore I (; died 14 May 649) was the bishop of Rome from 24 November 642 to his death on 14 May 649. His pontificate was dominated by the struggle with Monothelitism.\nEarly career.\nAccording to the \"Liber Pontificalis\", Theodore was a Greek man from Jerusalem whose father, Theodore, had been a bishop in the city; he is the only pope to have been a native of that city. He was among the many Syrian clergy who fled to Rome following the Muslim conquest of the Levant. He was made a cardinal deacon possibly around 640 and a full cardinal by Pope John IV.\nPontificate.\nTheodore I's election was supported by the exarch of Ravenna, who governed Italy in the name of the emperor in Constantinople. He was installed on 24 November 642, succeeding John IV. \nThe main focus of his pontificate was the continued struggle against the heretical Monothelites. He refused to recognize Paul II as the patriarch of Constantinople because Paul's predecessor, Pyrrhus I, had not been correctly replaced. He pressed Emperor Constans II to withdraw the \"Ecthesis\" of Heraclius. While his efforts made little impression on Constantinople, it increased the opposition to the teaching in the West; Pyrrhus even briefly recanted Monothelitism in 645, but was excommunicated in 648. Paul was excommunicated in 649. In response, Paul destroyed the Roman altar in the palace of Placidia and exiled or imprisoned the papal apocrisiarius. He also sought to end the issue with the emperor by promulgating the Type of Constans, ordering that the \"Ecthesis\" be taken down and seeking to end discussion on the doctrine.\nTheodore planned the Lateran Council of 649 to condemn the \"Ecthesis\", but died before he could convene it. His successor, Martin I, did so instead. Theodore was buried in Old St. Peter's Basilica. His feast day in the Eastern Orthodox Church is on 18 May.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60545", "revid": "18779361", "url": "https://en.wikipedia.org/wiki?curid=60545", "title": "NewtonScript", "text": "Prototype-based programming language for the Apple Newton platform\nNewtonScript is a prototype-based programming language created to write programs for the Newton platform. It is heavily influenced by the Self programming language, but modified to be more suited to needs of mobile and embedded devices.\nHistory.\nOn August 3, 1993, Apple unveiled the Apple Newton MessagePad. The device had 640 KB RAM, 4 MB ROM, and a 20\u00a0MHz ARM 610 microprocessor.\nThe main intention behind Newton project, was to develop a device capable of replacing a computer while being portable. With limited battery and memory, the developers were looking for programming language capable of meeting these challenges.\nThe developers looked at the C++ programming language but realized that it lacked flexibility. They started focusing on prototype based languages and were impressed with Smalltalk and Self. Concurrently Apple was developing another dynamic programming language called Dylan, which was a strong candidate for the Newton platform.\nHowever, both Self and Dylan were dropped out of consideration, as they were both in nascent stage for proper integration.\nInstead, a team headed by Walter R. Smith developed a new language called NewtonScript. It was influenced by dynamic language like Smalltalk and prototype model based like Self.\nFeatures.\nAlthough NewtonScript was heavily influenced by Self, there were some differences in both the languages.\nDifferences arose due to three perceived problems with Self.\nThe syntax was also modified to allow a more text-based programming style, as opposed to Self's widespread use of a GUI environment for programming. This allowed Newton programs to be developed on a computer running the Toolkit, where the programs would be compiled and then downloaded to a Newton device for running.\nOne of the advantages of NewtonScript's prototype based inheritance was reduced memory usage, a key consideration in the 128\u00a0KB Newton. The prototype of a GUI object could actually be stored in ROM, so there was no need to copy default data or functions into working memory.\nUnlike class-based languages, where creation of an object involves memory being allocated to all of its attributes, NewtonScripts' use of prototype inheritance allowed it to allocated memory to few fields like _proto and _parent instead of creating whole new object. Here, _proto and _parent signifies whether the object is using prototype or parent inheritance.\nAn example to illustrate above concept, a developer might create a new button instance. If the button uses the default font, accessing its font \"slot\" (i.e., property or member variable) will return a value that is actually stored in ROM; the button instance in RAM does not have a value in its own font slot, so the prototype inheritance chain is followed until a value is found. If the developer then changes the button's font, setting its font slot to a new value will override the prototype; this override value is stored in RAM. NewtonScript's \"differential inheritance\" therefore made efficient use of the Newton's expensive flash RAM by storing the bulk of the default data and code in the PDA's cheaper and much larger ROM.\nInfluences.\nWith the cancellation of the Newton project by Apple in 1998, all further mainstream developments on NewtonScript were stopped. However, the features used in NewtonScript would continue to inspire other programming models and languages.\nThe prototype-based object model of Self and NewtonScript was used in JavaScript, the most popular and visible language to use the concept so far.\nNewtonScript is also one of the conceptual ancestors (together with Smalltalk, Self, Act1, Lisp and Lua) of a general-purpose programming language called Io which implements the same differential inheritance model, which was used in NewtonScript to conserve memory.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60546", "revid": "166386", "url": "https://en.wikipedia.org/wiki?curid=60546", "title": "Unique factorization domain", "text": "Type of integral domain\nIn mathematics, a unique factorization domain (UFD) (also sometimes called a factorial ring following the terminology of Bourbaki) is a ring in which a statement analogous to the fundamental theorem of arithmetic holds. Specifically, a UFD is an integral domain (a nontrivial commutative ring in which the product of any two non-zero elements is non-zero) in which every non-zero non-unit element can be written as a product of irreducible elements, uniquely up to order and units.\nImportant examples of UFDs are the integers and polynomial rings in one or more variables with coefficients coming from the integers or from a field.\nUnique factorization domains appear in the following chain of class inclusions:\n rngs \u2283 rings \u2283 commutative\u00a0rings \u2283 integral\u00a0domains \u2283 integrally\u00a0closed\u00a0domains \u2283 GCD\u00a0domains \u2283 unique\u00a0factorization\u00a0domains \u2283 principal\u00a0ideal\u00a0domains \u2283 Euclidean\u00a0domains \u2283 fields \u2283 algebraically\u00a0closed fields\nDefinition.\nFormally, a unique factorization domain is defined to be an integral domain \"R\" in which every non-zero element \"x\" of \"R\" which is not a unit can be written as a finite product of irreducible elements \"p\"\"i\" of \"R\":\n \"x\" = \"p\"1 \"p\"2 \u22c5\u22c5\u22c5 \"p\"\"n\" with \"n\" \u2265 1\nand this representation is unique in the following sense:\nIf \"q\"1, ..., \"q\"\"m\" are irreducible elements of \"R\" such that\n \"x\" = \"q\"1 \"q\"2 \u22c5\u22c5\u22c5 \"q\"\"m\" with \"m\" \u2265 1,\nthen \"m\" = \"n\", and there exists a bijective map \"\u03c6\" : {1, ..., \"n\"} \u2192 {1, ..., \"m\"} such that \"p\"\"i\" is associated to \"q\"\"\u03c6\"(\"i\") for \"i\" \u2208 {1, ..., \"n\"}.\nExamples.\nMost rings familiar from elementary mathematics are UFDs:\nProperties.\nSome concepts defined for integers can be generalized to UFDs:\nEquivalent conditions for a ring to be a UFD.\nA Noetherian integral domain is a UFD if and only if every height 1 prime ideal is principal (a proof is given at the end). Also, a Dedekind domain is a UFD if and only if its ideal class group is trivial. In this case, it is in fact a principal ideal domain.\nIn general, for an integral domain \"A\", the following conditions are equivalent:\nIn practice, (2) and (3) are the most useful conditions to check. For example, it follows immediately from (2) that a PID is a UFD, since every prime ideal is generated by a prime element in a PID.\nFor another example, consider a Noetherian integral domain in which every height one prime ideal is principal. Since every prime ideal has finite height, it contains a height one prime ideal (induction on height) that is principal. By (2), the ring is a UFD.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "60547", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=60547", "title": "UFD", "text": "UFD may refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "60548", "revid": "4152300", "url": "https://en.wikipedia.org/wiki?curid=60548", "title": "Planetarium", "text": "Theatre that presents educational and entertaining shows about astronomy\nA planetarium (pl.: planetariums or planetaria) is a theatre built primarily for presenting educational and entertaining shows about astronomy and the night sky, or for training in celestial navigation.\nA dominant feature of most planetariums is the large dome-shaped projection screen onto which scenes of stars, planets, and other celestial objects can be made to appear and move realistically to simulate their motion. The projection can be created in various ways, such as a star ball, slide projector, video, fulldome projector systems, and lasers. Typical systems can be set to simulate the sky at any point in time, past or present, and often to depict the night sky as it would appear from any point of latitude on Earth.\nPlanetaria range in size from the 37 meter dome in St. Petersburg, Russia (called \"Planetarium No 1\") to three-meter inflatable portable domes where attendees sit on the floor. The largest planetarium in the Western Hemisphere is the Jennifer Chalsty Planetarium at Liberty Science Center in New Jersey, its dome measuring 27 meters in diameter. The Birla Planetarium, Kolkata in India is the largest by seating capacity, having 630 seats. In North America, the Hayden Planetarium at the American Museum of Natural History in New York City has the greatest number of seats, at 423.\nThe term \"planetarium\" is sometimes used generically to describe other devices which illustrate the Solar System, such as a computer simulation or an orrery. \"Planetarium software\" refers to a software application that renders a three-dimensional image of the sky onto a two-dimensional computer screen, or in a virtual reality headset for a 3D representation. The term \"planetarian\" is used to describe a member of the professional staff of a planetarium.\nHistory.\nEarly.\nThe ancient Greek polymath Archimedes is attributed with creating a primitive planetarium device that could predict the movements of the Sun and the Moon and the planets. The discovery of the Antikythera mechanism proved that such devices already existed during antiquity, though likely after Archimedes' lifetime. Campanus of Novara described a planetary equatorium in his \"Theorica Planetarum\", and included instructions on how to build one. The Globe of Gottorf built around 1650 had constellations painted on the inside. These devices would today usually be referred to as orreries (named for the Earl of Orrery). In fact, many planetariums today have projection orreries, which project onto the dome the Solar System (including the Sun and planets up to Saturn) in their regular orbital paths.\nIn 1229, following the conclusion of the Fifth Crusade, Holy Roman Emperor Frederick II of Hohenstaufen brought back a tent with scattered holes representing stars or planets. The device was operated internally with a spinnable table that rotated the tent.\nThe small size of typical 18th century orreries limited their impact, and towards the end of that century a number of educators attempted to create a larger sized version. The efforts of Adam Walker (1730\u20131821) and his sons are noteworthy in their attempts to fuse theatrical illusions with education. Walker's Eidouranion was the heart of his public lectures or theatrical presentations. Walker's son describes this \"Elaborate Machine\" as \"twenty feet high, and twenty-seven in diameter: it stands vertically before the spectators, and its globes are so large, that they are distinctly seen in the most distant parts of the Theatre. Every Planet and Satellite seems suspended in space, without any support; performing their annual and diurnal revolutions without any apparent cause\". Other lecturers promoted their own devices: R E Lloyd advertised his Dioastrodoxon, or Grand Transparent Orrery, and by 1825 William Kitchener was offering his Ouranologia, which was in diameter. These devices most probably sacrificed astronomical accuracy for crowd-pleasing spectacle and sensational and awe-provoking imagery.\nThe oldest still-working planetarium can be found in the Frisian city of Franeker. It was built by Eise Eisinga (1744\u20131828) in the living room of his house. It took Eisinga seven years to build his planetarium, which was completed in 1781.\n20th century.\nIn 1905 Oskar von Miller (1855\u20131934) of the \"Deutsches Museum\" in Munich commissioned updated versions of a geared orrery and planetarium from M Sendtner, and later worked with Franz Meyer, chief engineer at the Carl Zeiss optical works in Jena, on the largest mechanical planetarium ever constructed, capable of displaying both heliocentric and geocentric motion. This was displayed at the Deutsches Museum in 1924, construction work having been interrupted by the war. The planets travelled along overhead rails, powered by electric motors: the orbit of Saturn was 11.25 m in diameter. 180 stars were projected onto the wall by electric bulbs.\nWhile this was being constructed, von Miller was also working at the Zeiss factory with German astronomer Max Wolf, director of the Landessternwarte Heidelberg-K\u00f6nigstuhl observatory of the University of Heidelberg, on a new and novel design, inspired by Wallace W. Atwood's work at the Chicago Academy of Sciences and by the ideas of Walther Bauersfeld and Rudolf Straubel at Zeiss. The result was a planetarium design which would generate all the necessary movements of the stars and planets inside the optical projector, and would be mounted centrally in a room, projecting images onto the white surface of a hemisphere. In August 1923, the first (Model I) Zeiss planetarium projected images of the night sky onto the white plaster lining of a 16 m hemispherical concrete dome, erected on the roof of the Zeiss works. The first official public showing was at the Deutsches Museum in Munich on October 21, 1923.\nZeiss Planetarium became popular, and attracted a lot of attention. Next Zeiss planetariums were opened in Rome (1928, in Aula Ottagona, part of the Baths of Diocletian), Chicago (1930), Osaka (1937, in the Osaka City Electricity Science Museum).\nAfter World War II.\nWhen Germany was divided into East and West Germany after the war, the Zeiss firm was also split. Part remained in its traditional headquarters at Jena, in East Germany, and part migrated to West Germany. The designer of the first planetariums for Zeiss, Walther Bauersfeld, also migrated to West Germany with the other members of the Zeiss management team. There he remained on the Zeiss West management team until his death in 1959.\nThe West German firm resumed making large planetariums in 1954, and the East German firm started making small planetariums a few years later. Meanwhile, the lack of planetarium manufacturers had led to several attempts at construction of unique models, such as one built by the California Academy of Sciences in Golden Gate Park, San Francisco, which operated 1952\u20132003. The Korkosz brothers built a large projector for the Boston Museum of Science, which was unique in being the first (and for a very long time only) planetarium to project the planet Uranus. Most planetariums ignore Uranus as being at best marginally visible to the naked eye.\nA great boost to the popularity of the planetarium worldwide was provided by the Space Race of the 1950s and 60s when fears that the United States might miss out on the opportunities of the new frontier in space stimulated a massive program to install over 1,200 planetariums in U.S. high schools.\nArmand Spitz recognized that there was a viable market for small inexpensive planetaria. His first model, the Spitz A, was designed to project stars from a dodecahedron, thus reducing machining expenses in creating a globe. Planets were not mechanized, but could be shifted by hand. Several models followed with various upgraded capabilities, until the A3P, which projected well over a thousand stars, had motorized motions for latitude change, daily motion, and annual motion for Sun, Moon (including phases), and planets. This model was installed in hundreds of high schools, colleges, and even small museums from 1964 to the 1980s.\nJapan entered the planetarium manufacturing business in the 1960s, with Goto and Minolta both successfully marketing a number of different models. Goto was particularly successful when the Japanese Ministry of Education put one of their smallest models, the E-3 or E-5 (the numbers refer to the metric diameter of the dome) in every elementary school in Japan.\nPhillip Stern, as former lecturer at New York City's Hayden Planetarium, had the idea of creating a small planetarium which could be programmed. His Apollo model was introduced in 1967 with a plastic program board, recorded lecture, and film strip. Unable to pay for this himself, Stern became the head of the planetarium division of Viewlex, a mid-size audio-visual firm on Long Island. About thirty canned programs were created for various grade levels and the public, while operators could create their own or run the planetarium live. Purchasers of the Apollo were given their choice of two canned shows, and could purchase more. A few hundred were sold, but in the late 1970s Viewlex went bankrupt for reasons unrelated to the planetarium business.\nDuring the 1970s, the OmniMax movie system (now known as IMAX Dome) was conceived to operate on planetarium screens. More recently, some planetariums have re-branded themselves as \"dome theaters\", with broader offerings including wide-screen or \"wraparound\" films, fulldome video, and laser shows that combine music with laser-drawn patterns.\nLearning Technologies Inc. in Massachusetts offered the first easily portable planetarium in 1977. Philip Sadler designed this patented system which projected stars, constellation figures from many mythologies, celestial coordinate systems, and much else, from removable cylinders (Viewlex and others followed with their own portable versions).\nWhen Germany reunified in 1989, the two Zeiss firms did likewise, and expanded their offerings to cover many different size domes.\nComputerized planetaria.\nIn 1983, Evans &amp; Sutherland installed the first digital planetarium projector displaying computer graphics (Hansen planetarium, Salt Lake City, Utah)\u2014the Digistar I projector used a vector graphics system to display starfields as well as line art. This gives the operator great flexibility in showing not only the modern night sky as visible from Earth, but as visible from points far distant in space and time. The newest generations of planetarium projectors, beginning with Digistar 3, offer fulldome video technology. This allows for the projection of any image.\nTechnology.\nDomes.\nPlanetarium domes range in size from 3 to 35 m in diameter, accommodating from 1 to 500 people. They can be permanent or portable, depending on the application. \nThe realism of the viewing experience in a planetarium depends significantly on the dynamic range of the image, i.e., the contrast between dark and light. This can be a challenge in any domed projection environment, because a bright image projected on one side of the dome will tend to reflect light across to the opposite side, \"lifting\" the black level there and so making the whole image look less realistic. Since traditional planetarium shows consisted mainly of small points of light (i.e., stars) on a black background, this was not a significant issue, but it became an issue as digital projection systems started to fill large portions of the dome with bright objects (e.g., large images of the sun in context). For this reason, modern planetarium domes are often not painted white but rather a mid grey colour, reducing reflection to perhaps 35-50%. This increases the perceived level of contrast.\nA major challenge in dome construction is to make seams as invisible as possible. Painting a dome after installation is a major task, and if done properly, the seams can be made almost to disappear.\nTraditionally, planetarium domes were mounted horizontally, matching the natural horizon of the real night sky. However, because that configuration requires highly inclined chairs for comfortable viewing \"straight up\", increasingly domes are being built tilted from the horizontal by between 5 and 30 degrees to provide greater comfort. Tilted domes tend to create a favoured \"sweet spot\" for optimum viewing, centrally about a third of the way up the dome from the lowest point. Tilted domes generally have seating arranged stadium-style in straight, tiered rows; horizontal domes usually have seats in circular rows, arranged in concentric (facing center) or epicentric (facing front) arrays.\nPlanetaria occasionally include controls such as buttons or joysticks in the arm rests of seats to allow audience feedback that influences the show in real time.\nOften around the edge of the dome (the \"cove\") are:\nTraditionally, planetariums needed many incandescent lamps around the cove of the dome to help audience entry and exit, to simulate sunrise and sunset, and to provide working light for dome cleaning. More recently, solid-state LED lighting has become available that significantly decreases power consumption and reduces the maintenance requirement as lamps no longer have to be changed on a regular basis.\nThe world's largest mechanical planetarium is located in Monico, Wisconsin. Called the \"Kovac Planetarium,\" it is 22 feet in diameter and weighs two tons. The globe is made of wood and is driven with a variable speed motor controller. This is the largest mechanical planetarium in the world, larger than the \"Atwood Globe\" in Chicago (15 feet in diameter) and one third the size of the Hayden.\nSome new planetariums now feature a glass floor, which allows spectators to stand near the center of a sphere surrounded by projected images in all directions, giving the impression of floating in outer space. For example, a small planetarium at AHHAA in Tartu, Estonia features such an installation, with special projectors for images below the feet of the audience, as well as above their heads.\nTraditional electromechanical/optical projectors.\nTraditional planetarium projection apparatus use a hollow ball with a light inside, and a pinhole for each star, hence the name \"star ball\". With some of the brightest stars (e.g. Sirius, Canopus, Vega), the hole must be so big to let enough light through that there must be a small lens in the hole to focus the light to a sharp point on the dome. In later and modern planetarium star balls, the individual bright stars often have individual projectors, shaped like small hand-held torches, with focusing lenses for individual bright stars. Contact breakers prevent the projectors from projecting below the \"horizon\".\nThe star ball is usually mounted so it can rotate as a whole to simulate the Earth's daily rotation, and to change the simulated latitude on Earth. There is also usually a means of rotating to produce the effect of precession of the equinoxes. Often, one such ball is attached at its south ecliptic pole. In that case, the view cannot go so far south that any of the resulting blank area at the south is projected on the dome. Some star projectors have two balls at opposite ends of the projector like a dumbbell. In that case all stars can be shown and the view can go to either pole or anywhere between. But care must be taken that the projection fields of the two balls match where they meet or overlap.\nSmaller planetarium projectors include a set of fixed stars, Sun, Moon, and planets, and various nebulae. Larger projectors also include comets and a far greater selection of stars. Additional projectors can be added to show twilight around the outside of the screen (complete with city or country scenes) as well as the Milky Way. Others add coordinate lines and constellations, photographic slides, laser displays, and other images.\nEach planet is projected by a sharply focused spotlight that makes a spot of light on the dome. Planet projectors must have gearing to move their positioning and thereby simulate the planets' movements. These can be of these types:-\nDespite offering a good viewer experience, traditional star ball projectors suffer several inherent limitations. From a practical point of view, the low light levels require several minutes for the audience to \"dark adapt\" its eyesight. \"Star ball\" projection is limited in education terms by its inability to move beyond an Earth-bound view of the night sky. Finally, in most traditional projectors the various overlaid projection systems are incapable of proper occultation. This means that a planet image projected on top of a star field (for example) will still show the stars shining through the planet image, degrading the quality of the viewing experience. For related reasons, some planetariums show stars below the horizon projecting on the walls below the dome or on the floor, or (with a bright star or a planet) shining in the eyes of someone in the audience.\nHowever, the new breed of Optical-Mechanical projectors using fiber-optic technology to display the stars show a much more realistic view of the sky.\nDigital projectors.\nAn increasing number of planetariums are using digital technology to replace the entire system of interlinked projectors traditionally employed around a star ball to address some of their limitations. Digital planetarium manufacturers claim reduced maintenance costs and increased reliability from such systems compared with traditional \"star balls\" on the grounds that they employ few moving parts and do not generally require synchronisation of movement across the dome between several separate systems. Some planetariums mix both traditional opto-mechanical projection and digital technologies on the same dome.\nIn a fully digital planetarium, the dome image is generated by a computer and then projected onto the dome using a variety of technologies including cathode-ray tube, LCD, DLP, or laser projectors. Sometimes a single projector mounted near the centre of the dome is employed with a fisheye lens to spread the light over the whole dome surface, while in other configurations several projectors around the horizon of the dome are arranged to blend together seamlessly.\nDigital projection systems all work by creating the image of the night sky as a large array of pixels. Generally speaking, the more pixels a system can display, the better the viewing experience. While the first generation of digital projectors were unable to generate enough pixels to match the image quality of the best traditional \"star ball\" projectors, high-end systems now offer a resolution that approaches the limit of human visual acuity.\nLCD projectors have fundamental limits on their ability to project true black as well as light, which has tended to limit their use in planetaria. LCOS and modified LCOS projectors have improved on LCD contrast ratios while also eliminating the \"screen door\" effect of small gaps between LCD pixels. \"Dark chip\" DLP projectors improve on the standard DLP design and can offer relatively inexpensive solution with bright images, but the black level requires physical baffling of the projectors. As the technology matures and reduces in price, laser projection looks promising for dome projection as it offers bright images, large dynamic range and a very wide color space.\nShow content.\nWorldwide, most planetariums provide shows to the general public. Traditionally, shows for these audiences with themes such as \"What's in the sky tonight?\", or shows which pick up on topical issues such as a religious festival (often the Christmas star) linked to the night sky, have been popular. Live format is preferred by many venues as a live speaker or presenter can answer questions raised by the audience.\nSince the early 1990s, fully featured 3-D digital planetariums have added an extra degree of freedom to a presenter giving a show because they allow simulation of the view from any point in space, not only the Earth-bound view which we are most familiar with. This new virtual reality capability to travel through the universe provides important educational benefits because it vividly conveys that space has depth, helping audiences to leave behind the ancient misconception that the stars are stuck on the inside of a giant celestial sphere and instead to understand the true layout of the Solar System and beyond. For example, a planetarium can now 'fly' the audience towards one of the familiar constellations such as Orion, revealing that the stars which appear to make up a co-ordinated shape from an Earth-bound viewpoint are at vastly different distances from Earth and so not connected, except in human imagination and mythology. For especially visual or spatially aware people, this experience can be more educationally beneficial than other demonstrations.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60549", "revid": "50428975", "url": "https://en.wikipedia.org/wiki?curid=60549", "title": "Orrery", "text": "Mechanical model of the Solar System\nAn orrery is a mechanical model of the Solar System that illustrates or predicts the relative positions and motions of the planets and moons, usually according to the heliocentric model. It may also represent the relative sizes of these bodies; however, since accurate scaling is often not practical due to the actual large ratio differences, it may use a scaled-down approximation. The Greeks had working planetaria, but the first modern example was produced c.\u20091712 by John Rowley. He named it \"orrery\" for his patron Charles Boyle, 4th Earl of Orrery (in County Cork, Ireland). The plaque on it reads \"Orrery invented by Graham 1700 improved by Rowley and presented by him to John [sic] Earl of Orrery after whom it was named at the suggestion of Richard Steele.\"\nOrreries are typically driven by a clockwork mechanism with a globe representing the Sun at the centre, and with a planet at the end of each of a series of arms.\nHistory.\nAncient.\nThe Antikythera mechanism, discovered in 1901 in a wreck off the Greek island of Antikythera in the Mediterranean Sea, exhibited the diurnal motions of the Sun, Moon, and the five planets known to the ancient Greeks. It has been dated between 205 to 87\u00a0BC. The mechanism is considered one of the first orreries. It was geocentric and used as a mechanical calculator to calculate astronomical positions.\nCicero, the Roman philosopher and politician writing in the first century BC, has references describing planetary mechanical models. According to him, the Greek polymaths Thales and Posidonius both constructed a device modeling celestial motion.\nEarly Modern.\nIn 1348, Giovanni Dondi built the first known clock driven mechanism of the system. It displays the ecliptic position of the Moon, Sun, Mercury, Venus, Mars, Jupiter and Saturn according to the complicated geocentric Ptolemaic planetary theories. The clock itself is lost, but Dondi left a complete description of its astronomic gear trains.\nAs late as 1650, P. Schirleus built a geocentric planetarium with the Sun as a planet, and with Mercury and Venus revolving around the Sun as its moons.\nAt the court of William IV, Landgrave of Hesse-Kassel two complicated astronomic clocks were built in 1561 and 1563\u20131568. These use four sides to show the ecliptical positions of the Sun, Mercury, Venus, Mars, Jupiter, Saturn, the Moon, Sun and Dragon (Nodes of the Moon) according to Ptolemy, a calendar, the sunrise and sunset, and an automated celestial sphere with an animated Sun symbol which, for the first time on a celestial globe, shows the real position of the Sun, including the equation of time. The clocks are now on display in Kassel at the Astronomisch-Physikalisches Kabinett and in Dresden at the Mathematisch-Physikalischer Salon.\nIn \"De revolutionibus orbium coelestium\", published in Nuremberg in 1543, Nicolaus Copernicus challenged the Western teaching of a geocentric universe in which the Sun revolved daily around the Earth. He observed that some Greek philosophers such as Aristarchus of Samos had proposed a heliocentric universe. This simplified the apparent epicyclic motions of the planets, making it feasible to represent the planets' paths as simple circles. This could be modeled by the use of gears. Tycho Brahe's improved instruments made precise observations of the skies (1576\u20131601), and from these Johannes Kepler (1621) deduced that planets orbited the Sun in ellipses. In 1687 Isaac Newton explained the cause of elliptic motion in his theory of gravitation.\nModern.\nThere is an orrery built by clock makers George Graham and Thomas Tompion dated c.\u20091710 in the History of Science Museum, Oxford. Graham gave the first model, or its design, to the celebrated instrument maker John Rowley of London to make a copy for Prince Eugene of Savoy. Rowley was commissioned to make another copy for his patron Charles Boyle, 4th Earl of Orrery, from which the device took its name in English. This model was presented to Charles' son John, later the 5th Earl of Cork and 5th Earl of Orrery. Independently, Christiaan Huygens published in 1703 details of a heliocentric planetary machine which he had built while living in Paris between 1665 and 1681. He calculated the gear trains needed to represent a year of 365.242 days, and used that to produce the cycles of the principal planets.\nJoseph Wright's painting \"A Philosopher giving a Lecture on the Orrery\" (c.\u20091766), which hangs in the Derby Museum and Art Gallery, depicts a group listening to a lecture by a natural philosopher. The Sun in a brass orrery provides the only light in the room. The orrery depicted in the painting has rings, which give it an appearance similar to that of an armillary sphere. The demonstration was thereby able to depict eclipses.\nTo put this in chronological context, in 1762 John Harrison's marine chronometer first enabled accurate measurement of longitude. In 1766, astronomer Johann Daniel Titius first demonstrated that the mean distance of each planet from the Sun could be represented by the following progression:\nformula_1\nThat is, 0.4, 0.7, 1.0, 1.6, 2.8,\u00a0... The numbers refer to astronomical units, the mean distance between Sun and Earth, which is 1.496 \u00d7 108 km (93 \u00d7 106 miles). The Derby Orrery does not show mean distance, but demonstrated the relative planetary movements.\nThe Eisinga Planetarium was built from 1774 to 1781 by Eise Eisinga in his home in Franeker, in the Netherlands. It displays the planets across the width of a room's ceiling, and has been in operation almost continually since it was created. This orrery is a planetarium in both senses of the word: a complex machine showing planetary orbits, and a theatre for depicting the planets' movement. Eisinga house was bought by the Dutch Royal family who gave him a pension.\nIn 1764, Benjamin Martin devised a new type of planetary model, in which the planets were carried on brass arms leading from a series of concentric or coaxial tubes. With this construction it was difficult to make the planets revolve, and to get the moons to turn around the planets. Martin suggested that the conventional orrery should consist of three parts: the planetarium where the planets revolved around the Sun, the tellurion (also \"tellurian\" or \"tellurium\") which showed the inclined axis of the Earth and how it revolved around the Sun, and the lunarium which showed the eccentric rotations of the Moon around the Earth. In one orrery, these three motions could be mounted on a common table, separately using the central spindle as a prime mover.\nWorkings.\nAll orreries are \"planetariums\". The term \"orrery\" has only existed since 1714. A \"grand orrery\" is one that includes the outer planets known at the time of its construction. The word planetarium has shifted meaning, and now usually refers to hemispherical theatres in which images of the night sky are projected onto an overhead surface. Orreries can range widely in size from hand-held to room-sized. An orrery is used to demonstrate the motion of the planets, while a mechanical device used to predict eclipses and transits is called an astrarium.\nAn orrery should properly include the Sun, the Earth and the Moon (plus optionally other planets). A model that only includes the Earth, the Moon, and the Sun is called a tellurion or tellurium, and one which only includes the Earth and the Moon is a lunarium. A jovilabe is a model of Jupiter and its moons.\n&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nA planetarium will show the orbital period of each planet and the \"rotation rate\", as shown in the table above. A tellurion will show the Earth with the Moon revolving around the Sun. It will use the angle of \"inclination of the equator\" from the table above to show how it rotates around its own axis. It will show the Earth's Moon, rotating around the Earth. A lunarium is designed to show the complex motions of the Moon as it revolves around the Earth.\nOrreries are usually not built to scale. Human orreries, where humans move about as the planets, have also been constructed, but most are temporary. There is a permanent human orrery at Armagh Observatory in Northern Ireland, which has the six ancient planets, Ceres, and comets Halley and Encke. Uranus and beyond are also shown, but in a fairly limited way. Another is at Sky's the Limit Observatory and Nature Center in Twentynine Palms, California; it is a true to scale (20 billion to one), true to position (accurate to within four days) human orrery. The first four planets are relatively close to one another, but the next four require a certain amount of hiking in order to visit them. A census of all permanent human orreries has been initiated by the French group F-HOU with a new effort to study their impact for education in schools. A map of known human orreries is available.\nA normal mechanical clock could be used to produce an extremely simple orrery to demonstrate the principle, with the Sun in the centre, Earth on the minute hand and Jupiter on the hour hand; Earth would make 12 revolutions around the Sun for every 1 revolution of Jupiter. As Jupiter's actual year is 11.86 Earth years long, the model would lose accuracy rapidly.\nProjection.\nMany planetariums have a projection orrery, which projects onto the dome of the planetarium a Sun with either dots or small images of the planets. These usually are limited to the planets from Mercury to Saturn, although some include Uranus. The light sources for the planets are projected onto mirrors which are geared to a motor which drives the images on the dome. Typically the Earth will circle the Sun in one minute, while the other planets will complete an orbit in time periods proportional to their actual motion. Thus Venus, which takes 224.7 days to orbit the Sun, will take 37 seconds to complete an orbit on an orrery, and Jupiter will take 11 minutes, 52 seconds.\nSome planetariums have taken advantage of this to use orreries to simulate planets and their moons. Thus Mercury orbits the Sun in 0.24 of an Earth year, while Phobos and Deimos orbit Mars in a similar 4:1 time ratio. Planetarium operators wishing to show this have placed a red cap on the Sun (to make it resemble Mars) and turned off all the planets but Mercury and Earth. Similar approximations can be used to show Pluto and its five moons.\nNotable examples.\nShoemaker John Fulton of Fenwick, Ayrshire, built three between 1823 and 1833. The last is in Glasgow's Kelvingrove Art Gallery and Museum.\nThe Eisinga Planetarium built by a wool carder named Eise Eisinga in his own living room, in the small city of Franeker in Friesland, is in fact an orrery. It was constructed between 1774 and 1781. The base of the model faces down from the ceiling of the room, with most of the mechanical works in the space above the ceiling. It is driven by a pendulum clock, which has 9 weights or ponds. The planets move around the model in real time.\nAn innovative concept is to have people play the role of the moving planets and other Solar System objects. Such a model, called a human orrery, has been laid out at the Armagh Observatory.\nIn 2024, the LEGO Group commercially produced an orrery of the Sun, Earth, and Moon. The model is assembled exclusively from LEGO elements and reproduces solar and lunar orbits, as well Earth's rotation about a tilted axis.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60550", "revid": "1811786", "url": "https://en.wikipedia.org/wiki?curid=60550", "title": "SS Caroline", "text": ""}
{"id": "60551", "revid": "1811786", "url": "https://en.wikipedia.org/wiki?curid=60551", "title": "Caroline Incident", "text": ""}
{"id": "60552", "revid": "318795", "url": "https://en.wikipedia.org/wiki?curid=60552", "title": "Anticipatory self-defense", "text": ""}
{"id": "60553", "revid": "1811786", "url": "https://en.wikipedia.org/wiki?curid=60553", "title": "Anticipatory self-defence", "text": ""}
{"id": "60554", "revid": "49452401", "url": "https://en.wikipedia.org/wiki?curid=60554", "title": "Bamburgh", "text": "Village in Northumberland, England\nBamburgh ( ) is a village and civil parish on the coast of Northumberland, England. It had a population of 454 in 2001, decreasing to 414 at the 2011 census.\nBamburgh was the centre of an independent north Northumbrian territory between 867 and 954. Bamburgh Castle was built by the Normans on the site of an Anglo-Saxon fort. The Victorian era heroine Grace Darling is buried there.\nThe extensive beach by the village was awarded the Blue Flag rural beach award in 2005. The Bamburgh Dunes, a Site of Special Scientific Interest, stand behind the beach. Bamburgh is popular with holidaymakers and is within the Northumberland Coast Area of Outstanding Natural Beauty.\nHistory.\nThe site now occupied by Bamburgh Castle was previously home to a fort of the Celtic Britons known as \"Din Guarie\" and may have been the capital of the kingdom of Bernicia, the realm of the Gododdin people, from the realm's foundation in c. 420 until 547, the year of the first written reference to the castle. In that year, the citadel was captured by the Anglo-Saxon ruler Ida of Bernicia (Beornice) and became Ida's seat. The Anglo-Saxons called the place \"Bebbanburh\", meaning \"Queen Bebba's stronghold\"; this was later corrupted into the modern \"Bamburgh\". Aidan of Lindisfarne came to this area from the monastery of Iona in 635 on behalf of King Oswald of Northumbria.\nFollowing the defeat of Northumbrian forces by the Viking Great Heathen Army, at York in 867, the Kingdom of Northumbria disintegrated. Southern Northumbria became the Viking-ruled Kingdom of York, while north remained under Anglo-Saxon control under the high reeves of Bamburgh. The territory finally became part of the Kingdom of England in 954.\nThe late medieval village began to develop near the castle. During the dissolution of the monasteries the property of the friars, including the castle, was seized on behalf of Henry VIII.\nLate medieval British author Thomas Malory identified Bamburgh Castle with Joyous Gard, the mythical castle home of Sir Lancelot in Arthurian legend.\nLionel Lukin's first purpose-built lifeboat was stationed here in 1786. The Royal National Lifeboat Institution re-established a lifeboat station here in 1882 but it closed in 1897.\nSt Aidan's Church.\nAccording to Bede, St Aidan built a wooden church outside the castle wall in AD 635, and he died here in AD 652. A wooden beam preserved inside the church is traditionally said to be the one on which he rested as he died. The present church dates from the late 12th century, though some pre-conquest stonework survives in the north aisle. The chancel, said to be the second-longest in the country (), was added in 1230; it contains an 1895 reredos in Caen stone by W.S. Hicks, depicting northern saints of the 7th and 8th centuries. There is an effigy of local heroine Grace Darling in the north aisle. This formed part of the original monument to Grace Darling but was removed due to weathering of the stonework. Her memorial is sited in the churchyard in such a position that passing ships can see it.\nThe property has been Grade I listed since December 1969. The listing summary includes this description:\"Parish church. C12, C13 and C14. Restored 1830 and later C19. Squared stone and ashlar; chancel and north transept have stone slate roofs; other roofs not visible. West tower, nave, aisles, transepts and chancel\".\nAfter the dissolution of the monasteries in the mid-1500s, the monks were forced to leave and St Aidan's became the parish church for the village. Over the subsequent centuries there were major repairs and restorations. \nThe church's crypt holds the remains of 110 individuals who died in the 7th and 8th centuries; they had initially been buried in the castle's Bowl Hole graveyard. The remains were found during a project between 1998 and 2007. In 2016, they were moved into the crypt. Since November 2019, the crypt can be viewed by visitors through a small gate.\nGovernance.\nAn electoral ward of the same name exists. This ward includes Belford and also stretches south to Ellingham with a total population taken at the 2011 census of 4,846.\nIn popular culture.\nBamburgh Castle, under its Saxon name Bebbanburg, is the ancestral home of Uhtred, the main character in Bernard Cornwell's historical 13-novel series \"The Saxon Stories\", published 2004\u20132020, which was made into the BBC and Netflix five-season series \"The Last Kingdom\" 2015\u20132022.\nBamburgh is also featured in the open-world video game series \"Forza Horizon 4\" released in October 2018.\nAdditionally, Bamburgh is featured in the Realtime Strategy video game \"Ancestors Legacy\" released in 2018.\nSee also.\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60555", "revid": "31454441", "url": "https://en.wikipedia.org/wiki?curid=60555", "title": "Grace Darling", "text": "British lighthouse keeper's daughter (1815\u20131842)\nGrace Horsley Darling (also known as \"Amazing Grace\"; 24 November 1815 \u2013 20 October 1842) was an English lighthouse keeper's daughter. Her participation in the rescue of survivors from the shipwrecked \"Forfarshire\" in 1838 brought her national fame. The paddlesteamer ran aground on the Farne Islands off the coast of Northumberland in northeast England; eight members of the crew and one passenger, Sarah Dawson, were saved.\nEarly life.\nGrace Darling was born on 24 November 1815 at her grandfather's house in Northumberland. She was the seventh of nine children (four brothers and four sisters) born to William and Thomasin Darling, and when only a few weeks old, she was taken to live on Brownsman Island, one of the Farne Islands, in a small cottage attached to the lighthouse. Her father ran the lighthouse (built in 1795) for Trinity House, and earned a salary of \u00a370 per year () with a bonus of \u00a310 for satisfactory service. The accommodation was basic, and the lighthouse was not located in a good place to guide shipping to safety, so in 1826, the family moved to the newly constructed lighthouse on Longstone Island.\nLongstone Lighthouse had better accommodation, but the island itself was slightly less hospitable, so William would row back to Brownsman to gather vegetables from their former garden and to feed the animals. The family spent most of their time on the ground floor of the lighthouse, which consisted of a large room, heated by a wooden stove. The room was their living room, dining room, and kitchen in one, and had a spiral staircase leading to three bedrooms above and the light at the top of the tower.\nShipwreck.\nIn the early hours of 7 September 1838, Darling, looking from an upstairs window, spotted the wreck and survivors of the \"Forfarshire\" on Big Harcar, a nearby low, rocky island. The \"Forfarshire\" had foundered on the rocks and broken in half; one of the halves had sunk during the night.\nDarling and her father, William, determined that the weather was too rough for the lifeboat to put out from Seahouses (then North Sunderland), so they took a rowing boat (a , four-man Northumberland coble) across to the survivors, taking a long route that kept to the lee side of the islands, a distance of nearly a mile (about ). Darling kept the coble steady in the water, while her father helped four men and the lone surviving woman, Sarah Dawson, into the boat. Although she survived the sinking, Mrs. Dawson had lost her two young children (James, 7, and Matilda, 5) during the night. William and three of the rescued men then rowed the boat back to the lighthouse. Darling then remained at the lighthouse while William and three of the rescued crew members rowed back and recovered four more survivors.\nMeanwhile, the lifeboat had set out from Seahouses, but arrived at Big Harcar rock after Darling and her father had completed their rescue operation; all they found were the bodies of Mrs Dawson's children and of a clergyman. Returning to North Sunderland was too dangerous, so they rowed to the lighthouse to take shelter. Darling's brother, William Brooks Darling, was one of the seven fishermen in the lifeboat. The weather deteriorated to the extent that everyone was obliged to remain at the lighthouse for three days before returning to shore.\nThe \"Forfarshire\" had been carrying 62 people. The vessel broke in two almost immediately upon hitting the rocks. Those rescued by Darling and her father were from the bow section of the vessel, which had been held by the rocks for some time before sinking. All that remained at daybreak was the portside paddlebox casing. Nine other passengers and crew had managed to float off a lifeboat from the stern section before it, too, sank, and were picked up in the night by a passing Montrose sloop, and brought into South Shields that same night.\nAs news of her role in the rescue reached the public, her combination of bravery and simple virtue set her out as exemplary, and led to an uneasy role as the nation's heroine. Grace and her father were awarded the Silver Medal for Bravery by the Royal National Institution for the Preservation of Life from Shipwreck, later named the Royal National Lifeboat Institution (RNLI). Subscriptions and donations totaling over \u00a3700 (equivalent to about \u00a3 in 2023) were raised for her, including \u00a350 from Queen Victoria; more than a dozen portrait painters sailed to her island home to capture her likeness, and hundreds of gifts, letters, and even marriage proposals were delivered to her. Her unexpected wealth and fame were such that the Duke of Northumberland took on a role as her self-appointed guardian and founder of a trust, established to look after the donations offered to her. His personal gifts to her family were a timepiece and a silver teapot.\nDeath.\nIn 1842, Darling fell ill with tuberculosis while visiting the mainland. According to letters at Northumberland Archives, Grace stayed with the Shields family in Wooler during late August and early September in an attempt to improve her health. A later letter shows that she moved to Alnwick with her mother in early October 1842. She then convalesced with her cousins, the MacFarlanes, in their house in Narrowgate, Alnwick. When the Duchess of Northumberland heard of her situation, she arranged for Darling to be moved to better accommodation close to Alnwick Castle. The Duchess tended to her in person, as well as providing her with the services of the ducal family physician. \nHowever, Darling's condition declined and she was conveyed to the place of her birth in Bamburgh, where she died, aged 26, of consumption in October 1842. She is buried in the churchyard of St Aidan's Church, Bamburgh. The Monument to Grace Darling was completed in 1842. It represents a sleeping effigy of her holding an oar, and lies to the north of her grave at the western edge of the churchyard so it would be visible to passing seafarers. The original effigy, which was sculpted by Charles Raymond Smith son of James Smith, was moved into the church in 1895 due to weathering.\nWithin the St Aidan's Church there is also a stained-glass window dedicated to the memory of Grace Darling.\nLegacy.\nDarling's achievement was celebrated in her lifetime; she received a large financial reward in addition to the plaudits of the nation. A number of fictionalised depictions propagated the Grace Darling legend, such as \"Grace Darling, or the Maid of the Isles\" by Jerrold Vernon (1839), which gave birth to the legend of \"the girl with windswept hair\". Her deed was committed to verse by William Wordsworth in his poem \"Grace Darling\" (1843). In 1882 a four-act drama, \"Humanity, or a Passage in the Life of Grace Darling\", premiered at the Theatre Royal, Leicester and immediately transferred to the vast Standard Theatre in London's Shoreditch. The play by Leonard Rae and Hugh Marston included a realistic representation of the sea rescue. In 1884, rose breeder Henry Bennett named the tea rose 'Grace Darling' after her. A lifeboat with her name was presented to Holy Island. One of a series of Victorian paintings by William Bell Scott at Wallington Hall in Northumberland depicts her rescue efforts. The McManus Galleries in Dundee includes three paintings by Thomas Musgrave Joy that celebrate Grace Darling's deeds with the \"Forfarshire\".\nAt Bamburgh, a museum is dedicated to her achievements and the seafaring life of the area. From 1990 to 2020 an RNLI \"Mersey\"-class lifeboat at Seahouses bore the name \"Grace Darling\". Singer/songwriter Dave Cousins of Strawbs wrote \"Grace Darling\" (on the album \"Ghosts\") in tribute and as a love song. The folk singing group The Limeliters, accompanied by a children's chorus, sang a different \"Grace Darling\" (featuring the refrain \"Help, help, came a desperate yelp!\") in their 1962 album, recorded live in concert, \"Through Children's Eyes\". In 2017, Duke Special set Michael Longley's poem \"Grace Darling\" to music and recorded it on the album \"Hallow\". The Grace Darling Hotel, one of the oldest extant hotels in Melbourne, Victoria, opened in 1854.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60556", "revid": "44127043", "url": "https://en.wikipedia.org/wiki?curid=60556", "title": "William Armstrong, 1st Baron Armstrong", "text": "English inventor, scientist, engineer and industrialist (1810-1900)\nWilliam George Armstrong, 1st Baron Armstrong, (26 November 1810 \u2013 27 December 1900) was an English engineer and industrialist who founded the Armstrong Whitworth manufacturing concern on Tyneside. He was also an eminent scientist, inventor and philanthropist. In collaboration with the architect Richard Norman Shaw, he built Cragside in Northumberland, the first house in the world to be lit by hydroelectricity. He is regarded as the inventor of modern artillery.\nArmstrong was knighted in 1859 after giving his gun patents to the government. In 1887, during Queen Victoria's golden jubilee year, he was raised to the peerage as Baron Armstrong, of Cragside.\nEarly life.\nArmstrong was born in Newcastle upon Tyne at 9 Pleasant Row, Shieldfield. Although the house in which he was born no longer exists, an inscribed granite tablet marks the site where it stood. At that time, the area \u2013 next to the https:// \u2013 was rural. His father, also called William, was a corn merchant on the Newcastle quayside, who rose through the ranks of Newcastle society to become mayor of the town in 1850. An elder sister, Anne, born in 1802, was named after his mother, the daughter of Addison Potter.\nArmstrong was educated at the Royal Grammar School, Newcastle upon Tyne, until he was sixteen, when he was sent to Bishop Auckland Grammar School. While there, he often visited the nearby engineering works of William Ramshaw. During his visits, he met his future wife, Ramshaw's daughter Margaret, six years his senior.\nArmstrong's father was set on his following a career in the law, and so he was articled to Armorer Donkin, a solicitor friend of his father. He spent five years in London studying law and returned to Newcastle in 1833. He became a partner in Donkin's business in 1835, and the firm became Donkin, Stable and Armstrong. He married Margaret Ramshaw in 1835, and they built a house in Jesmond Dene, on the eastern edge of Newcastle. Armstrong worked for eleven years as a solicitor, but during his spare time, he showed great interest in engineering and developed the \"Armstrong Hydroelectric Machine\" between 1840 and 1842. In 1837, he laid the foundations for the engineering and environmental consultancy which is today known as Wardell Armstrong.\nChange of career.\nArmstrong was a very keen angler, and while fishing on the River Dee at Dentdale in the Pennines, he saw a waterwheel in action, supplying power to a marble quarry. It struck Armstrong that much of the available power was being wasted. When he returned to Newcastle, he designed a rotary engine powered by water, and this was built in the High Bridge works of his friend Henry Watson. Little interest was shown in the engine. Armstrong subsequently developed a piston engine instead of a rotary one and decided that it might be suitable for driving a hydraulic crane. In 1846 his work as an amateur scientist was recognized when he was elected a Fellow of the Royal Society.\nIn 1845 a scheme was set in motion to provide piped water from distant reservoirs to the households of Newcastle. Armstrong was involved in this scheme and he proposed to Newcastle Corporation that the excess water pressure in the lower part of town could be used to power a quayside crane specially adapted by himself. He claimed that his hydraulic crane could unload ships faster and more cheaply than conventional cranes. The Corporation agreed to his suggestion, and the experiment proved so successful that three more hydraulic cranes were installed on the Quayside.\nThe success of his hydraulic crane led Armstrong to consider setting up a business to manufacture cranes and other hydraulic equipment. He therefore resigned from his legal practice. Donkin, his legal colleague, supported him in his career move, providing financial backing for the new venture. In 1847 the firm of W. G. Armstrong &amp; Company bought of land alongside the river at Elswick, near Newcastle, and began to build a factory there. The new company received orders for hydraulic cranes from Edinburgh and Northern Railways and from Liverpool Docks, as well as for hydraulic machinery for dock gates in Grimsby. The company soon began to expand. In 1850 the company produced 45 cranes and two years later, 75. It averaged 100 cranes per year for the rest of the century. In 1850 over 300 men were employed at the works, but by 1863 this had risen to 3,800. The company soon branched out into bridge building, one of the first orders being for the Inverness Bridge, completed in 1855.\nHydraulic accumulator.\nArmstrong was responsible for developing the hydraulic accumulator. Where water pressure was not available on site for the use of hydraulic cranes, Armstrong often built high water towers to provide a supply of water at pressure \u2013 for instance, the Grimsby Dock Tower. However, when supplying cranes for use at New Holland on the Humber Estuary, he was unable to do this because the foundations consisted of sand. After much careful thought he produced the weighted accumulator, a cast-iron cylinder fitted with a plunger supporting a very heavy weight. The plunger would slowly be raised, drawing in water, until the downward force of the weight was sufficient to force the water below it into pipes at great pressure. The accumulator was a very significant, if unspectacular, invention, which found many applications in the following years.\nArmaments.\nIn 1854, during the Crimean War, Armstrong read about the difficulties the British Army experienced in manoeuvring its heavy field guns. He decided to design a lighter, more mobile field gun, with greater range and accuracy. He built a breech-loading gun with a strong, rifled barrel made from wrought iron wrapped around a steel inner lining, designed to fire a shell rather than a ball. In 1855 he had a five-pounder ready for inspection by a government committee. The gun proved successful in trials, but the committee thought a higher calibre gun was needed, so Armstrong built an 18-pounder on the same design.\nAfter trials, this gun was declared to be superior to all its rivals. Armstrong surrendered the patent for the gun to the British government, rather than profit from its design. As a result he was created a Knight Bachelor and in 1859 was presented to Queen Victoria. Armstrong became employed as Engineer of Rifled Ordnance to the War Department. In order to avoid a conflict of interests if his own company were to manufacture armaments, Armstrong created a separate company, called Elswick Ordnance Company, in which he had no financial involvement. The new company agreed to manufacture armaments for the British government and no other. Under his new position, Armstrong worked to bring the old Woolwich Arsenal up to date so that it could build guns designed at Elswick.\nHowever, just when it looked as if the new gun was about to become a great success, a great deal of opposition to the gun arose, both inside the army and from rival arms manufacturers, particularly Joseph Whitworth of Manchester. Stories were publicised that the new gun was too difficult to use, that it was too expensive, that it was dangerous to use, that it frequently needed repair and so on. All of this smacked of a concerted campaign against Armstrong. Armstrong was able to refute all of these claims in front of various government committees, but he found the constant criticism very wearying and depressing. In 1862 the government decided to stop ordering the new gun and return to muzzle loaders. Also, because of a drop in demand, future orders for guns would be supplied from Woolwich, leaving Elswick without new business. Compensation was eventually agreed with the government for the loss of business to the company, which went on legitimately to sell its products to foreign powers. Speculation that guns were sold to both sides in the American Civil War was unfounded.\nWarships.\nIn 1864 the two companies, W. G. Armstrong &amp; Company and Elswick Ordnance Company merged to form Sir W. G. Armstrong &amp; Company. Armstrong had resigned from his employment with the War Office, so there was no longer a conflict of interest. The company turned its attention to naval guns. In 1867 Armstrong reached an agreement with Charles Mitchell, a shipbuilder in Low Walker, whereby Mitchells would build warships and Elswick would provide the guns. The first ship, in 1868 was HMS \"Staunch\", a gunboat.\nIn 1876, because the 18th-century bridge at Newcastle restricted access by ships to the Elswick works, Armstrong's company paid for a new Swing Bridge to be built, so that warships could have their guns fitted at Elswick. In 1882 Armstrong's company merged with Mitchell's to form Sir William Armstrong, Mitchell and Co. Ltd. and in 1884 a shipyard opened at Elswick to specialise in warship production. The first vessels produced were the torpedo cruisers \"Panther\" and \"Leopard\" for the Austro-Hungarian Navy. The first battleship produced at Elswick was HMS \"Victoria\", launched in 1887. The ship was originally to be named \"Renown\", but the name was changed in honour of the Queen's Golden Jubilee. Armstrong drove the first and last rivets. The ship was ill-fated, as she was involved in a collision with HMS \"Camperdown\" just six years later in 1893 and sank with the loss of 358 men, including Vice-Admiral Sir George Tryon. An important customer of the Elswick yard was Japan, which took several cruisers, some of which defeated the Russian fleet at the Battle of Tsushima in 1905. It was claimed that every Japanese gun used in the battle had been provided by Elswick. Elswick was the only factory in the world that could build a battleship and arm it completely.\nThe Elswick works continued to prosper, and by 1870 stretched for three-quarters of a mile along the riverside. The population of Elswick, which had been 3,539 in 1851, had increased to 27,800 by 1871. In 1894, Elswick built and installed the steam-driven pumping engines, hydraulic accumulators and hydraulic pumping engines to operate London's Tower Bridge. In 1897 the company merged with the company of Armstrong's old rival, Joseph Whitworth, and became Sir W. G. Armstrong, Whitworth &amp; Co Ltd. Whitworth was by this time dead.\nArmstrong gathered many excellent engineers at Elswick. Notable among them were Andrew Noble and George Wightwick Rendel, whose design of gun-mountings and hydraulic control of gun-turrets were adopted worldwide. Rendel introduced the cruiser as a naval vessel. There was great rivalry and dislike between Noble and Rendel, which became open after Armstrong's death.\nCragside.\nFrom 1863 onwards, although Armstrong remained the head of his company, he became less involved in its day-to-day running. He appointed several very able men to senior positions and they continued his work. When he married, he acquired a house called Jesmond Dean (sic), which is now demolished, and not to be confused with the nearby Jesmond Dene House. Armstrong's house was to the west of Jesmond Dene, Newcastle, and thus not far from his birthplace, and he began to landscape and improve land that he bought within the Dene. In 1860 he paid local architect John Dobson to design a Banqueting Hall overlooking the Dene, which still survives, though it is now roofless. His house close to Newcastle was convenient for his practice as a solicitor and his work as an industrialist, but when he had more spare time he longed for a house in the country.\nHe had often visited Rothbury as a child, when he was afflicted by a severe cough, and he had fond memories of the area. In 1863 he bought some land in a steep-sided, narrow valley where the Debdon Burn flows towards the River Coquet near Rothbury. He had the land cleared and supervised the building of a house perched on a ledge of rock, overlooking the burn. He also supervised a programme of planting trees and mosses so as to cover the rocky hillside with vegetation.\nHis new house was called Cragside, and over the years Armstrong added to the Cragside estate. Eventually the estate was and had seven million trees planted, together with five artificial lakes and of carriage drives, and his demonstration centre at Cragend Farm Hydraulic Silo. The lakes were used to generate hydro-electricity, and the house was the first in the world to be lit by hydro-electricity, using incandescent lamps provided by the inventor Joseph Swan.\nAs Armstrong spent less and less time at the Elswick works, he spent more and more time at Cragside, and it became his main home. In 1869 he commissioned the celebrated architect Richard Norman Shaw to enlarge and improve the house, and this was done over a period of 15\u00a0years. In 1883 Armstrong gave Jesmond Dene, together with its banqueting hall to the city of Newcastle. He retained his house next to the Dene. Armstrong entertained several eminent guests at Cragside, including the Shah of Persia, the King of Siam, the prime minister of China and the Prince and Princess of Wales.\nLater life.\nIn 1873 he served as High Sheriff of Northumberland. He was President of the North of England Institute of Mining and Mechanical Engineers from 1872 to 1875. He was elected as the president of the Institution of Civil Engineers in December 1881 and served in that capacity for the next year. He was conferred with Honorary Membership of the Institution of Engineers and Shipbuilders in Scotland in 1884. In 1886, he was persuaded to stand as a Unionist Liberal candidate for Newcastle, but was unsuccessful, coming third in the election. That same year he was presented with the Freedom of the City of Newcastle. In 1887 he was raised to the peerage as Baron Armstrong, of Cragside in the County of Northumberland. His last great project, begun in 1894, was the purchase and restoration of the huge Bamburgh Castle on the Northumberland coast, which remains in the hands of the Armstrong family. His wife, Margaret, died in September 1893, at their house in Jesmond. Armstrong died at Cragside on 27 December 1900, aged ninety. He was buried in Rothbury churchyard, alongside his wife. The couple had no children, and Armstrong's heir was his great-nephew William Watson-Armstrong. He was succeeded as chairman of the company by his one-time prot\u00e9g\u00e9, Andrew Noble.\nSuch was Armstrong's fame as a gun-maker that he is thought to be a possible model for George Bernard Shaw's arms magnate in \"Major Barbara\". The title character in Iain Pears' historical-mystery novel \"Stone's Fall\" also has similarities to Armstrong.\nHis attitude to armaments.\nThere is no evidence that Armstrong agonised over his decision to go into armament production. He once said: \"If I thought that war would be fomented, or the interests of humanity suffer, by what I have done, I would greatly regret it. I have no such apprehension.\" He also said: \"It is our province, as engineers to make the forces of matter obedient to the will of man; those who use the means we supply must be responsible for their legitimate application.\"\nViews on renewable energy.\nArmstrong advocated the use of renewable energy. Stating that coal \"was used wastefully and extravagantly in all its applications\", he predicted in 1863 that Britain would cease to produce coal within two centuries. As well as advocating the use of hydroelectricity, he also supported solar power, stating that the amount of solar energy received by an area of in the tropics would \"exert the amazing power of 4,000 horses acting for nearly nine hours every day\".\nThe benefactor.\nArmstrong donated the long wooded gorge of Jesmond Dene to the people of the city of Newcastle upon Tyne in 1883, as well as Armstrong Bridge and Armstrong Park nearby. He was involved in the foundation in 1871 of the College of Physical Science \u2013 a forerunner of the University of Newcastle, renamed Armstrong College in 1906. He was President of the Literary and Philosophical Society of Newcastle upon Tyne from 1860 until his death, as well as twice president of the Institution of Mechanical Engineers. Armstrong gave \u00a311,500 towards the building of Newcastle's Hancock Natural History Museum, which was completed in 1882. This sum is equivalent to over \u00a3555,000 in 2010. Lord Armstrong's generosity extended beyond his death. In 1901 his heir, William Watson-Armstrong gave \u00a3100,000 (equivalent to \u00a3 in 2023), for the building of the new Royal Victoria Infirmary in Newcastle upon Tyne. Its original 1753 building at Forth Banks near the River Tyne was inadequate and impossible to expand. In 1903 the barony of Armstrong was revived in favour of William Watson-Armstrong.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60557", "revid": "25866927", "url": "https://en.wikipedia.org/wiki?curid=60557", "title": "Emmeline Pankhurst", "text": "British suffragette (1858\u20131928)\nEmmeline Pankhurst (; n\u00e9e Goulden; 15 July 1858 \u2013 14 June 1928) was a British political activist who organised the British suffragette movement and helped women to win in 1918 the right to vote in Great Britain and Ireland. In 1999, \"Time\" named her as one of the , stating that \"she shaped an idea of objects for our time\" and \"shook society into a new pattern from which there could be no going back\". She was widely criticised for her militant tactics, and historians disagree about their effectiveness, but her work is recognised as a crucial element in achieving women's suffrage in the United Kingdom.\nBorn in the Moss Side district of Manchester to politically active parents, Pankhurst was 16 when she was introduced to the women's suffrage movement. She founded and became involved with the Women's Franchise League, which advocated suffrage for both married and unmarried women. When that organisation broke apart, she tried to join the left-leaning Independent Labour Party through her friendship with socialist Keir Hardie but was initially refused membership by the local branch on account of her sex. While working as a Poor Law Guardian, she was shocked at the harsh conditions she encountered in Manchester's workhouses.\nIn 1903, Pankhurst founded the Women's Social and Political Union (WSPU), an all-women suffrage advocacy organisation dedicated to \"deeds, not words\". The group identified as independent from\u00a0\u2013 and often in opposition to\u00a0\u2013 political parties. It became known for physical confrontations: its members smashed windows and assaulted police officers. Pankhurst, her daughters, and other WSPU activists received repeated prison sentences, where they staged hunger strikes to secure better conditions, and were often force-fed. As Pankhurst's eldest daughter Christabel took leadership of the WSPU, antagonism between the group and the government grew. Eventually, the group adopted bombings and arson as a tactic, and more moderate organisations spoke out against the Pankhurst family. In 1913, several prominent individuals left the WSPU, among them Pankhurst's younger daughters, Adela and Sylvia. Emmeline was so furious that she \"gave [Adela] a ticket, \u00a320, and a letter of introduction to a suffragette in Australia, and firmly insisted that she emigrate\". Adela complied and the family rift was never healed. Sylvia became a socialist.\nWith the advent of the First World War, Emmeline and Christabel called an immediate halt to the militant terrorism in support of the British government's stand against the \"German Peril\". Emmeline organised and led a massive procession called the Women's Right to Serve demonstration to illustrate women's contribution to the war effort. Emmeline and Christabel urged women to aid industrial production and encouraged young men to fight.\nIn 1918, the Representation of the People Act granted votes to all men over the age of 21 and women over the age of 30. This discrepancy was intended to ensure that men did not become minority voters as a consequence of the huge number of deaths suffered during the First World War.\nShe transformed the WSPU machinery into the Women's Party, which was dedicated to promoting women's equality in public life. In her later years, she became concerned with what she perceived as the menace posed by Bolshevism and joined the Conservative Party. She was selected as the Conservative candidate for Whitechapel and St Georges in 1927. She died on 14 June 1928, only weeks before the Conservative government's Representation of the People (Equal Franchise) Act 1928 extended the vote to all women over 21 years of age on 2 July 1928. She was commemorated two years later with a statue in Victoria Tower Gardens, next to the Houses of Parliament.\nEarly life.\nEmmeline Goulden was born on Sloan Street in the Moss Side district of Manchester on 15 July 1858. Although her birth certificate says otherwise, she believed and later claimed her birthday was a day earlier, on Bastille Day (14 July). Most biographies, including those written by her daughters, repeat this claim. Feeling a kinship with the female revolutionaries who stormed the Bastille, she said in 1908: \"I have always thought that the fact that I was born on that day had some kind of influence over my life.\" The family into which she was born had been steeped in political agitation for generations; her mother, Sophia, was a Manx woman from the Isle of Man who was descended from men who were charged with social unrest and slander.\nIn 1881, the Isle of Man became the first place in the British Isles to grant women the right to vote in Manx national elections (the Isle does not return members to the UK Parliament). Her father, Robert Goulden, was a self-made man\u00a0\u2013 working his way from errand boy to manufacturer\u00a0\u2013 from a humble Manchester family with its own background of political activity. Robert's mother, a fustian cutter, worked with the Anti-Corn Law League, and his father was press-ganged into the Royal Navy and present at the Peterloo massacre, when cavalry charged and broke up a crowd demanding parliamentary reform.\nThe Gouldens' first son died at the age of three, but they had 10 other children; Emmeline was the eldest of five daughters. Soon after her birth, the family moved to Seedley, where her father had co-founded a small business. He was also active in local politics, serving for several years on the Salford town council. He was an enthusiastic supporter of dramatic organisations including the Manchester Athenaeum and the Dramatic Reading Society. He owned a theatre in Salford for several years, where he played the leads in several Shakespeare plays. Goulden absorbed an appreciation of drama and theatrics from her father, which she used later in social activism. The Gouldens included their children in social activism. As part of the movement to end U.S. slavery, Robert welcomed American abolitionist Henry Ward Beecher when he visited Manchester. Sophia used the novel \"Uncle Tom's Cabin\", written by Beecher's sister Harriet Beecher Stowe, as a regular source of bedtime stories for her sons and daughters. In her 1914 autobiography \"My Own Story\", Goulden recalls visiting a bazaar at a young age to collect money for newly freed slaves in the U.S.\nEmmeline began to read books when she was very young, with one source claiming that she was reading as early as the age of three. She read the \"Odyssey\" at the age of nine and enjoyed the works of John Bunyan, especially his 1678 story \"The Pilgrim's Progress\". Another of her favourite books was Thomas Carlyle's three-volume treatise \"\", and she later said the work \"remained all [her] life a source of inspiration\". Despite her avid consumption of books, however, she was not given the educational advantages enjoyed by her brothers. Their parents believed that the girls needed most to learn the art of \"making home attractive\" and other skills desired by potential husbands. The Gouldens deliberated carefully about future plans for their sons' education, but they expected their daughters to marry young and avoid paid work. Although they supported women's suffrage and the general advancement of women in society, the Gouldens believed their daughters incapable of the goals of their male peers. Feigning sleep one evening as her father came into her bedroom, Goulden heard him pause and say to himself, \"What a pity she wasn't born a lad.\"\nIt was through her parents' interest in women's suffrage that Goulden was first introduced to the subject. Her mother received and read the \"Women's Suffrage Journal\", and Goulden grew fond of its editor Lydia Becker. At the age of 14, she returned home from school one day to find her mother on her way to a public meeting about women's voting rights. After learning that Becker would be speaking, she insisted on attending. Goulden was enthralled by Becker's address and later wrote, \"I left the meeting a conscious and confirmed suffragist.\" A year later, she arrived in Paris to attend the \"\u00c9cole Normale de Neuilly\". The school provided its female pupils with classes in chemistry and bookkeeping, in addition to traditionally feminine arts such as embroidery. Her roommate was No\u00e9mie, the daughter of Victor Henri Rochefort, who had been imprisoned in New Caledonia for his support of the Paris Commune. The girls shared tales of their parents' political exploits and remained good friends for years. Goulden was so fond of No\u00e9mie and the school that she returned with her sister Mary Jane as a parlour boarder after graduating. No\u00e9mie had married a Swiss painter and quickly found a suitable French husband for her English friend. When Robert refused to provide a dowry for his daughter, the man withdrew his offer of marriage and Goulden returned, miserable, to Manchester.\nMarriage and family.\nIn the autumn of 1878, at the age of 20, Goulden met and began a relationship with Richard Pankhurst, a barrister who had advocated women's suffrage \u2013 and other causes, including freedom of speech and education reform \u2013 for years. Richard, 44 years old when they met, had earlier resolved to remain a bachelor to better serve the public. Their mutual affection was powerful, but the couple's happiness was diminished by the death of his mother the following year. Sophia Jane Goulden chastised her daughter for \"throwing herself\" at Richard and advised her without success to exhibit more aloofness. Emmeline suggested to Richard that they avoid the legal formalities of marriage by entering into a free union; he objected on the grounds that she would be excluded from political life as an unmarried woman. He noted that his colleague Elizabeth Wolstenholme Elmy had faced social condemnation before she formalised her marriage to Ben Elmy. Emmeline Goulden agreed, and they had their wedding in St Luke's Church, Pendleton on 18 December 1879.\nDuring the 1880s, living at the Goulden cottage with her parents in Seedley, then at 1 Drayton Terrace Chester Rd Old Trafford (1881 census Stretford) opposite Richard's parents' home, Emmeline Pankhurst tended to her husband and children, but still devoted time to political activities. Although she gave birth to five children in ten years, both she and Richard believed that she should not be \"a household machine\". Thus a butler was hired to help with the children as Pankhurst involved herself with the Women's Suffrage Society. Their daughter Christabel was born on 22 September 1880, less than a year after the wedding. Pankhurst gave birth to another daughter, Estelle Sylvia, in 1882, and their son Henry Francis Robert, nicknamed Frank, in 1884. Soon afterwards Richard Pankhurst left the Liberal Party. He began expressing more radical socialist views and argued a case in court against several wealthy businessmen. These actions roused Robert Goulden's ire and the mood in the house became tense. In 1885, the Pankhursts moved to Chorlton-on-Medlock, and their daughter Adela was born. They moved to London the following year, where Richard ran unsuccessfully for election as a Member of Parliament and Pankhurst opened a small fabric shop called Emerson and Company, together with her sister Mary Jane.\nIn 1888, Pankhurst's son Frank developed diphtheria. He died on 11 September. Overwhelmed with grief, Pankhurst commissioned two portraits of the dead boy but was unable to look at them and hid them in a bedroom cupboard. The family concluded that a faulty drainage system at the back of their house had caused their son's illness. Pankhurst blamed the poor conditions of the neighbourhood, and the family moved to a more affluent middle class district at Russell Square. She was soon pregnant once more and declared that the child was \"Frank coming again\". She gave birth to a son on 7 July 1889 and named him Henry Francis in honour of his deceased brother.\nPankhurst made their Russell Square home into a centre for political intellectuals and activists, including, \"Socialists, Protesters, Anarchists, Suffragists, Free Thinkers, Radicals and Humanitarians of all schools.\" She took pleasure in decorating the house \u2013 especially with furnishings from Asia \u2013 and clothing the family in tasteful apparel. Her daughter Sylvia later wrote: \"Beauty and appropriateness in her dress and household appointments seemed to her at all times an indispensable setting to public work.\"\nThe Pankhursts hosted a variety of guests including Indian MP Dadabhai Naoroji, socialist activists Herbert Burrows and Annie Besant, and French anarchist Louise Michel.\nWomen's Franchise League.\nIn 1888, Britain's first nationwide coalition of groups advocating women's right to vote, the National Society for Women's Suffrage (NSWS), split after a majority of members decided to accept organisations affiliated with political parties. Angry at this decision, some of the group's leaders, including Lydia Becker and Millicent Fawcett, stormed out of the meeting and created an alternative organisation committed to the \"old rules,\" called the Great College Street Society after the location of its headquarters. Pankhurst aligned herself with the \"new rules\" group, which became known as the Parliament Street Society (PSS). Some members of the PSS favoured a piecemeal approach to gaining the vote. Because it was often assumed that married women did not need the vote since their husbands \"voted for them,\" some PSS members felt that the vote for single women and widows was a practical step along the path to full suffrage. When the reluctance within the PSS to advocate on behalf of married women became clear, Pankhurst and her husband helped organise another new group dedicated to voting rights for all women \u2013 married and unmarried.\nThe inaugural meeting of the Women's Franchise League (WFL) was held on 25 July 1889, at the Pankhurst home in Russell Square. Early members of the WFL included Josephine Butler, leader of the Ladies National Association for the Repeal of the Contagious Diseases Acts; the Pankhursts' friend Elizabeth Clarke Wolstenholme-Elmy; and Harriot Eaton Stanton Blatch, daughter of US suffragist Elizabeth Cady Stanton.\nThe WFL was considered a radical organisation, since in addition to women's suffrage it supported equal rights for women in the areas of divorce and inheritance. It also advocated trade unionism and sought alliances with socialist organisations. The more conservative group that emerged from the NSWS split spoke out against what they called the \"extreme left\" wing of the movement. The WFL reacted by ridiculing the \"Spinster Suffrage party\" and insisting that a wider assault on social inequity was required. The group's radicalism caused some members to leave; both Blatch and Elmy resigned from the WFL. The group fell apart one year later.\nIndependent Labour Party.\nPankhurst's shop never succeeded and he had trouble attracting business in London. With the family's finances in jeopardy, Richard travelled regularly to northwest England, where most of his clients were. In 1893 the Pankhursts closed the store and returned to Manchester. They stayed for several months in the seaside town of Southport, then moved briefly to the village of Disley and finally settled into a house in Manchester's Victoria Park. The girls were enrolled in Manchester Girls' High School, where they felt confined by the large student population and strictly regimented schedule.\nPankhurst began to work with several political organisations, distinguishing herself for the first time as an activist in her own right and gaining respect in the community. One biographer describes this period as her \"emergence from Richard's shadow.\" In addition to her work on behalf of women's suffrage, she became active with the Women's Liberal Federation (WLF), an auxiliary of the Liberal Party. She quickly grew disenchanted with the group's moderate positions, however, especially its unwillingness to support Irish Home Rule and the aristocratic leadership of Archibald Primrose.\nIn 1888 Pankhurst had met and befriended Keir Hardie, a socialist from Scotland. He was elected to parliament in 1891 and two years later helped to create the Independent Labour Party (ILP). Excited about the range of issues which the ILP pledged to confront, Pankhurst resigned from the WFL and applied to join the ILP. The local branch refused her admission on the grounds of her sex, but she eventually joined the ILP nationally. Christabel later wrote of her mother's enthusiasm for the party and its organising efforts: \"In this movement she hoped there might be the means of righting every political and social wrong.\"\nOne of her first activities with the ILP found Pankhurst distributing food to poor men and women through the Committee for the Relief of the Unemployed. In December 1894 she was elected to the position of Poor Law Guardian in Chorlton-on-Medlock. She was appalled by the conditions she witnessed first-hand in the Manchester workhouse:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The first time I went into the place I was horrified to see little girls seven and eight years old on their knees scrubbing the cold stones of the long corridors\u00a0... bronchitis was epidemic among them most of the time\u00a0... I found that there were pregnant women in that workhouse, scrubbing floors, doing the hardest kind of work, almost until their babies came into the world\u00a0... Of course the babies are very badly protected\u00a0... These poor, unprotected mothers and their babies I am sure were potent factors in my education as a militant.Pankhurst immediately began to change these conditions, and established herself as a successful voice of reform on the Board of Guardians. Her chief opponent was a passionate man named Mainwaring, known for his rudeness. Recognising that his loud anger was hurting his chances of persuading those aligned with Pankhurst, he kept a note nearby during meetings: \"Keep your temper!\"\nAfter helping her husband with another unsuccessful parliamentary campaign, Pankhurst faced legal troubles in 1896 when she and two men violated a court order against ILP meetings at Boggart Hole Clough. With Richard's volunteering his time as legal counsel, they refused to pay fines, and the two men spent a month in prison. The punishment was never ordered for Pankhurst, however, possibly because the magistrate feared public backlash against the imprisonment of a woman so respected in the community. Asked by an ILP reporter if she were prepared to spend time in prison, Pankhurst replied: \"Oh, yes, quite. It wouldn't be so very dreadful, you know, and it would be a valuable experience.\" Although ILP meetings were eventually permitted, the episode was a strain on Pankhurst's health and caused loss of income for their family.\nRichard's death.\nDuring the struggle at Boggart Hole Clough, Richard Pankhurst began to experience severe stomach pains. He had developed a gastric ulcer, and his health deteriorated in 1897. The family moved briefly to Mobberley, with the hope that country air would help his condition. He soon felt well again, and the family returned to Manchester in the autumn. In the summer of 1898, he suffered a sudden relapse. Emmeline Pankhurst had taken their oldest daughter Christabel to Corsier, Switzerland, to visit her old friend No\u00e9mie. A telegram arrived from Richard, reading: \"I am not well. Please come home, my love.\" Leaving Christabel with No\u00e9mie, Pankhurst returned immediately to England. On 5 July, while on a train from London to Manchester, she noticed a newspaper announcing the death of Richard Pankhurst.\nThe loss of her husband left Pankhurst with new responsibilities and a significant amount of debt. She moved the family to a smaller house at 62 Nelson Street, resigned from the Board of Guardians, and was given a paid position as Registrar of Births and Deaths in Chorlton. This work gave her more insight into the conditions of women in the region. She wrote in her autobiography: \"They used to tell me their stories, dreadful stories some of them, and all of them pathetic with that patient and uncomplaining pathos of poverty.\" Her observations of the differences between the lives of men and women, for example in relation to illegitimacy, reinforced her conviction that women needed the right to vote before their conditions could improve. In 1900 she was elected to the Manchester School Board and saw new examples of women suffering unequal treatment and limited opportunities. During this time she also re-opened her store, with the hope that it would provide additional income for the family.\nThe individual identities of the Pankhurst children began to emerge around the time of their father's death. Before long they were all involved in the struggle for women's suffrage. Christabel enjoyed a privileged status among the daughters, as Sylvia noted in 1931: \"She was our mother's favourite; we all knew it, and I, for one, never resented the fact.\" Christabel did not share her mother's fervour for political work, however, until she befriended the suffrage activists Esther Roper and Eva Gore-Booth. She soon became involved with the suffrage movement and joined her mother at speaking events. Sylvia took lessons from a respected local artist and soon received a scholarship to the Manchester School of Art. She went on to study art in Florence and Venice. The younger children, Adela and Harry, had difficulty finding a path for their studies. Adela was sent to a local boarding school, where she was cut off from her friends and contracted head lice. Harry also had difficulty at school; he suffered from measles and vision problems.\nWomen's Social and Political Union/WSPU.\nBy 1903, Pankhurst believed that years of moderate speeches and promises about women's suffrage from members of parliament (MPs) had yielded no progress. Although suffrage bills in 1870, 1886, and 1897 had shown promise, each was defeated. She doubted that political parties, with their many agenda items, would ever make women's suffrage a priority. She even broke with the ILP when it refused to focus on Votes for Women. It was necessary to abandon the patient tactics of existing advocacy groups, she believed, in favour of more militant actions. Thus on 10 October 1903 Pankhurst and several colleagues founded the Women's Social and Political Union (WSPU), an organisation open only to women and focused on direct action to win the vote. \"Deeds,\" she wrote later, \"not words, was to be our permanent motto.\" The WSPU confined its membership to women \u2013 men could not become members.\nThe group's early militancy took non-violent forms. In addition to making speeches and gathering petition signatures, the WSPU organised rallies and published a newsletter called \"Votes for Women.\" The group also convened a series of \"Women's Parliaments\" for example, in Caxton Hall, to coincide with official government sessions. When a bill for women's suffrage was filibustered on 12 May 1905, Pankhurst and other WSPU members began a loud protest outside the Parliament building. Police immediately forced them away from the building, where they regrouped and demanded passage of the bill. Although the bill was never resurrected, Pankhurst considered it a successful demonstration of militancy's power to capture attention. Pankhurst declared in 1906: \"We are at last recognized as a political party; we are now in the swim of politics, and are a political force.\"\nBefore long, all three of her daughters became active with the WSPU. Christabel was arrested after spitting at a policeman during a meeting of the Liberal Party in October 1905; Adela and Sylvia were arrested a year later during a protest outside Parliament. Pankhurst was arrested for the first time in February 1908, when she tried to enter Parliament to deliver a protest resolution to Prime Minister H. H. Asquith. She was charged with obstruction and sentenced to six weeks in prison. She spoke out against the conditions of her confinement, including vermin, meagre food, and the \"civilised torture of solitary confinement and absolute silence\" to which she and others were ordered. Pankhurst saw imprisonment as a means to publicise the urgency of women's suffrage; in June 1909 she struck a police officer twice in the face to ensure she would be arrested. Pankhurst was arrested seven times before women's suffrage was approved. During her trial on 21 October 1908 she told the court: \"We are here not because we are law-breakers; we are here in our efforts to become law-makers.\"\nThe exclusive focus of the WSPU on votes for women was another hallmark of its militancy. While other organisations agreed to work with individual political parties, the WSPU insisted on separating itself from \u2013 and in many cases opposing \u2013 parties which did not make women's suffrage a priority. The group protested against all candidates belonging to the party of the ruling government since it refused to pass women's suffrage legislation. This brought them into immediate conflict with Liberal Party organisers, particularly since many Liberal candidates supported women's suffrage. (One early target of WSPU opposition was future Prime Minister Winston Churchill; his opponent attributed Churchill's defeat in part to \"those ladies who are sometimes laughed at.\")\nMembers of the WSPU were sometimes heckled and derided for spoiling elections for Liberal candidates. On 18 January 1908, Pankhurst and her associate Nellie Martel were attacked by an all-male crowd of Liberal supporters who blamed the WSPU for costing them a recent by-election to the Conservative candidate. The men threw clay, rotten eggs, and stones packed in snow; the women were beaten and Pankhurst's ankle was severely bruised. Similar tensions later formed with Labour. Until party leaders made the vote for women a priority, however, the WSPU vowed to continue its militant activism. Pankhurst and others in the union saw party politics as distracting to the goal of women's suffrage and criticised other organisations for putting party loyalty ahead of women's votes.\nAs the WSPU gained recognition and notoriety for its actions, Pankhurst resisted efforts to democratise the organisation itself. In 1907 a small group of members led by Teresa Billington-Greig called for more involvement from the rank-and-file suffragettes at the union's annual meetings. In response, Pankhurst announced at a WSPU meeting that elements of the organisation's constitution relating to decision-making were void and cancelled the annual meetings. She also insisted that a small committee chosen by the members in attendance be allowed to co-ordinate WSPU activities. Pankhurst and her daughter Christabel were chosen (along with Mabel Tuke and Emmeline Pethick Lawrence) as members of the new committee. Frustrated, several members including Billington-Greig and Charlotte Despard quit to form their own organisation, the Women's Freedom League. In her 1914 autobiography Pankhurst dismissed criticism of the WSPU's leadership structure:\nif at any time a member, or a group of members, loses faith in our policy; if any one begins to suggest that some other policy ought to be substituted, or if she tries to confuse the issue by adding other policies, she ceases at once to be a member. Autocratic? Quite so. But, you may object, a suffrage organisation ought to be democratic. Well the members of the W.S.P.U. do not agree with you. We do not believe in the effectiveness of the ordinary suffrage organisation. The W.S.P.U. is not hampered by a complexity of rules. We have no constitution and by-laws; nothing to be amended or tinkered with or quarrelled over at an annual meeting\u00a0... The W.S.P.U. is simply a suffrage army in the field.\nTactical intensification.\nOn 21 June 1908, 500,000 activists rallied in Hyde Park to demand votes for women. This day is the beginning of \"Women' s Sunday\". It was organised by the WSPN, the massive demonstration for women's suffrage saw thousands march in seven processions all over London, gathering for a day of peaceful protest. Asquith and leading MPs responded with indifference. Angered by this intransigence and abusive police activity, some WSPU members increased the severity of their actions. Soon after the rally, twelve women gathered in Parliament Square and tried to deliver speeches for women's suffrage. Police officers seized several of the speakers and pushed them into a crowd of opponents who had gathered nearby. Frustrated, two WSPU members \u2013 Edith New and Mary Leigh \u2013 went to 10 Downing Street and hurled rocks at the windows of the Prime Minister's home. They insisted their act was independent of the WSPU command, but Pankhurst expressed her approval of the action. When a magistrate sentenced New and Leigh to two months' imprisonment, Pankhurst reminded the court of how various male political agitators had broken windows to win legal and civil rights throughout Britain's history.\nIn 1909 the hunger strike was added to the WSPU's repertoire of resistance. On 24 June Marion Wallace Dunlop was arrested for writing an excerpt from the Bill of Rights (1688 or 1689) on a wall in the House of Commons. Angered by the conditions of the jail, Dunlop went on a hunger strike. When it proved effective, fourteen women imprisoned for smashing windows began to fast. WSPU members soon became known around the country for holding prolonged hunger strikes to protest their incarceration. Prison authorities frequently force-fed the women, using tubes inserted through the nose or mouth. The painful techniques (which, in the case of mouth-feeding, required the use of steel gags to force the mouth open) brought condemnation from suffragists and medical professionals.\nThese tactics caused some tension between the WSPU and more moderate organisations, which had coalesced into the National Union of Women's Suffrage Societies (NUWSS). That group's leader, Millicent Fawcett, originally hailed WSPU members for their courage and dedication to the cause. By 1912, however, she declared that hunger strikes were mere publicity stunts and that militant activists were \"the chief obstacles in the way of the success of the suffrage movement in the House of Commons.\" The NUWSS refused to join a march of women's suffrage groups after demanding without success that the WSPU end its support of property destruction. Fawcett's sister Elizabeth Garrett Anderson later resigned from the WSPU for similar reasons.\nPress coverage was mixed; many journalists noted that crowds of women responded positively to speeches by Pankhurst, while others condemned her radical approach to the issue. \"The Daily News\" urged her to endorse a more moderate approach, and other press outlets condemned the breaking of windows by WSPU members. In 1906 \"Daily Mail\" journalist Charles Hands referred to militant women using the diminutive term \"suffragette\" (rather than the standard \"suffragist\"). Pankhurst and her allies seized the term as their own and used it to differentiate themselves from moderate groups.\nThe last half of the century's first decade was a time of sorrow, loneliness, and constant work for Pankhurst. In 1907 she sold her home in Manchester and began an itinerant lifestyle, moving from place to place as she spoke and marched for women's suffrage. She stayed with friends and in hotels, carrying her few possessions in suitcases. Although she was energized by the struggle\u2014and found joy in giving energy to others\u2014her constant travelling meant separation from her children, especially Christabel, who had become the national coordinator of the WSPU. In 1909, as Pankhurst planned a speaking tour of the United States, Henry was paralyzed after his spinal cord became inflamed. She hesitated to leave the country while he was ill, but she needed money to pay for his treatment and the tour promised to be lucrative. On her return from a successful tour, she sat by Henry's bedside as he died on 5 January 1910. Five days later she buried him beside his brother Frank in Highgate Cemetery, then spoke before 5,000 people in Manchester. Liberal Party supporters who had come to heckle her remained quiet as she addressed the crowd.\nConciliation, force-feeding attempt, and arson.\nAfter the Liberal losses in the 1910 elections, ILP member and journalist Henry Brailsford helped organise a Conciliation Committee for Women's Suffrage, which gathered 54 MPs from various parties. The group's Conciliation Bill looked to be a narrowly defined but still significant possibility to achieve the vote for some women. Thus, the WSPU agreed to suspend its support for window-breaking and hunger strikes while it was being negotiated. When it became clear that the bill would not pass, Pankhurst declared: \"If the Bill, in spite of our efforts, is killed by the Government, then\u00a0... I have to say there is an end to the truce.\" When it was defeated, Pankhurst led a protest march of 300 women to Parliament Square on 18 November. They were met with aggressive police response, directed by Home Secretary Winston Churchill: officers punched the marchers, twisted arms, and pulled on women's breasts. Although Pankhurst was allowed to enter Parliament, Prime Minister Asquith refused to meet her. The incident became known as Black Friday. Her sister Mary Jane, who had attended the protest, too, was arrested for the third time, a few days later. She was sentenced to a month of imprisonment. On Christmas Day she died at the home of their brother Herbert Goulden, two days after her release.\nAs subsequent Conciliation Bills were introduced, WSPU leaders advocated a halt to militant tactics. Aileen Preston was appointed as Pankhurst's driver in April 1911, to drive her around the country to help spread the suffrage message.\nIn March 1912, the second bill was in jeopardy and Pankhurst joined a fresh outbreak of window-smashing. Extensive property damage led police to raid the WSPU offices. Pankhurst and Emmeline Pethick-Lawrence were tried at the Old Bailey and convicted of conspiracy to commit property damage. Christabel, who by 1912 was the chief coordinator for the organisation, was also wanted by police. She fled to Paris, where she directed WSPU strategy in exile. Inside Holloway Prison, Emmeline Pankhurst staged her first hunger strike to improve conditions for other suffragettes in nearby cells; she was quickly joined by Pethick-Lawrence and other WSPU members. She described in her autobiography the trauma caused by force-feeding during the strike: \"Holloway became a place of horror and torment. Sickening scenes of violence took place almost every hour of the day, as the doctors went from cell to cell performing their hideous office.\" When prison officials tried to enter her cell, Pankhurst raised a clay jug over her head and announced: \"If any of you dares so much as to take one step inside this cell I shall defend myself.\"\nPankhurst was spared further force-feeding attempts after this incident, but she continued to violate the law and \u2013 when imprisoned \u2013 starve herself in protest. During the following two years she was arrested numerous times but was frequently released after several days because of her ill health. Later, the Asquith government enacted the Cat and Mouse Act, which allowed similar releases for other suffragettes facing ill-health due to hunger strikes. Prison officials recognised the potential public relations disaster that would erupt if the popular WSPU leader were force-fed or allowed to suffer extensively in jail. Still, police officers arrested her during talks and as she marched. She tried to evade police harassment by wearing disguises and eventually the WSPU established a jujutsu-trained female bodyguard squad to physically protect her against the police. She and other escorts were targeted by police, resulting in violent scuffles as officers tried to detain Pankhurst.\nIn 1912, WSPU members adopted arson as another tactic to win the vote. After Prime Minister Asquith had visited the Theatre Royal in Dublin, suffragette activists Gladys Evans, Lizzie Baker, Mary Leigh, and Mabel Capper attempted to cause an explosion using gunpowder and benzine, which resulted in minimal damage. During the same evening, Mary Leigh threw an axe at the carriage containing John Redmond (leader of the Irish Parliamentary Party), the Lord Mayor, and Asquith.\nOver the next two years women set fire to a refreshments building in Regent's Park, an orchid house at Kew Gardens, pillar boxes, and a railway carriage. Emily Davison threw herself under the King's horse Anmer at the Epsom Derby in 1913. Her funeral drew 55,000 attendees along the streets and at the funeral. This gave significant publicity to the movement. Although Pankhurst confirmed that these women had not been commanded by her or Christabel, they both assured the public that they supported the arsonist suffragettes. There were similar incidents around the country. One WSPU member, for example, put a small hatchet into the Prime Minister's carriage inscribed with the words: \"Votes for Women,\" and other suffragettes used acid to burn the same slogan into golf courses used by MPs. In 1914, Mary Richardson slashed the Velasquez painting \"Rokeby Venus\" to protest against Pankhurst's imprisonment.\nDefection and dismissal.\nThe WSPU's approval of property destruction led to the departure of several important members. The first were Emmeline Pethick-Lawrence and her husband Frederick. They had long been integral members of the group's leadership but found themselves in conflict with Christabel about the wisdom of such volatile tactics. After returning from a vacation in Canada they found that Pankhurst had expelled them from the WSPU. The pair found the decision appalling, but to avoid a schism in the movement they continued to praise Pankhurst and the organisation in public. Around the same time, Emmeline's daughter Adela left the group. She disapproved of WSPU endorsement of property destruction and felt that a heavier emphasis on socialism was necessary. Adela's relationship with her family \u2013 especially Christabel \u2013 was also strained as a result.\nThe deepest rift in the Pankhurst family came in November 1913 when Sylvia spoke at a meeting of socialists and trade unionists in support of trade union organiser Jim Larkin. She had been working with the East London Federation of Suffragettes (ELFS), a local branch of the WSPU which had a close relationship with socialists and organised labour. The close connection to labour groups and Sylvia's appearance on stage with Frederick Pethick-Lawrence \u2013 who also addressed the crowd \u2013 convinced Christabel that her sister was organising a group that might challenge the WSPU in the suffrage movement. The dispute became public, and members of groups including the WSPU, ILP, and ELFS braced themselves for a showdown. After being dismissed from the WSPU, Sylvia felt \"bruised, as one does, when fighting the foe without, one is struck by the friend within.\"\nIn January Sylvia was summoned to Paris, where Emmeline and Christabel were waiting. Their mother had just returned from another tour of the US, and Sylvia had just been released from prison. All three women were exhausted and stressed, which added considerably to the tension. In her 1931 book \"The Suffrage Movement\" Sylvia describes Christabel as an unreasonable figure, haranguing her for refusing to toe the WSPU line:\nShe turned to me. \"You have your own ideas. We do not want that; we want all our women to take their instructions and walk in step like an army!\" Too tired, too ill to argue, I made no reply. I was oppressed by a sense of tragedy, grieved by her ruthlessness. Her glorification of autocracy seemed to me remote indeed from the struggle we were waging, the grim fight even now proceeding in the cells. I thought of many others who had been thrust aside for some minor difference.\nWith their mother's blessing, Christabel ordered Sylvia's group to dissociate from the WSPU. Pankhurst tried to persuade the ELFS to remove the word \"suffragettes\" from its name, since it was inextricably linked to the WSPU. When Sylvia refused, her mother switched to fierce anger in a letter:\nYou are unreasonable, always have been &amp; I fear always will be. I suppose you were made so!\u00a0... Had you chosen a name which we could approve we could have done much to launch you &amp; advertise your society by name. Now you must take your own way of doing so. I am sorry but you make your own difficulties by an incapacity to look at situations from other people's point of view as well as your own. Perhaps in time you will learn the lessons that we all have to learn in life.\nAdela, unemployed and unsure of her future, had become a worry for Pankhurst as well. She decided that Adela should move to Australia, and paid for her relocation. They never saw one another again.\nThe Women's Party.\nIn November 1917 the WSPU's weekly newspaper announced that the WSPU was to become the Women's Party. Twelve months later on Tuesday 19 November at the Queen's Hall in London Emmeline Pankhurst said that her daughter Christabel would be their candidate at the forthcoming General Election, the first at which women could stand as candidates. They didn't say which constituency they would fight but a few days later Westbury in Wiltshire was identified. Emmeline lobbied Prime Minister David Lloyd George to ensure Christabel would have coalition backing. However, as these discussions were taking place the Pankhurst's switched their attention to Smethwick in Staffordshire. The Coalition had already settled on a local candidate, Major Samuel Nock Thompson, but Bonar Law, the Conservative leader, was persuaded to ask Thompson to withdraw. Significantly, Christabel was not issued with a formal letter of support from the two leaders, the Coalition Coupon. Christabel then had a straight fight with the Labour candidate John Davison and lost by 775 votes. The Women's Party fought no other elections and closed soon after.\nFirst World War.\nWhen the First World War began in August 1914, Emmeline and Christabel considered that the threat posed by Germany was a danger to all humanity, and that the British government needed the support of all men. They persuaded the WSPU to halt all militant suffrage activities until fighting on the European mainland ended. It was no time for dissent or agitation; Christabel wrote later: \"This was national militancy. As Suffragists we could not be pacifists at any price.\" A truce with the government was established, all WSPU prisoners were released, and Christabel returned to London. Emmeline and Christabel set the WSPU into motion on behalf of the war effort. In her first speech after returning to Britain, Christabel warned of the \"German Peril\". She urged the gathered women to follow the example of their French sisters, who \u2013 while the men fought \u2013 \"are able to keep the country going, to get in the harvest, to carry on the industries\".\nSylvia and Adela, meanwhile, did not share their mother's enthusiasm for the war. As committed pacifists, they rejected the WSPU's support for the government. Sylvia's socialist perspective convinced her that the war was another example of capitalist oligarchs exploiting poor soldiers and workers. Adela, however, spoke against the war in Australia and made public her opposition to conscription. In a short letter, Emmeline told Sylvia: \"I am ashamed to know where you and Adela stand.\" She had a similar impatience for dissent within the WSPU; when long-time member Mary Leigh asked a question during a meeting in October 1915, Pankhurst replied: \"That woman is a pro German and should leave the hall.\u00a0... I denounce you as a pro German and wish to forget that such a person ever existed.\" Some WSPU members were outraged by this sudden rigid devotion to the government, the leadership's perceived abandonment of efforts to win the vote for women, and questions about how funds collected on behalf of suffrage were being managed with regard to the organisation's new focus. Two groups split from the WSPU: The Suffragettes of the Women's Social and Political Union (SWSPU) and the Independent Women's Social and Political Union (IWSPU), each dedicated to maintaining pressure toward women's suffrage.\nPankhurst put the same energy and determination she had previously applied to women's suffrage into patriotic advocacy of the war effort. She organised rallies, toured constantly delivering speeches, and lobbied the government to help women enter the work force while men were overseas fighting. Another issue which concerned her greatly at the time was the plight of so-called war babies, children born to single mothers whose fathers were on the front lines. Pankhurst established an adoption home at Campden Hill designed to employ the Montessori method of childhood education. Some women criticised Pankhurst for offering relief to parents of children born out of wedlock, but she declared indignantly that the welfare of children\u2013whose suffering she had seen firsthand as a Poor Law Guardian\u2013was her only concern. Due to lack of funds, however, the home was soon turned over to Princess Alice. Pankhurst herself adopted four children, whom she renamed Kathleen King, Flora Mary Gordon (later Mary Hodgson), Joan Pembridge and Elizabeth Tudor. They lived in London, where\u2013for the first time in many years\u2013she had a permanent home, at Holland Park. Asked how, at the age of 57 and with no steady income, she could take on the burden of bringing up four more children, Pankhurst replied: \"My dear, I wonder I didn't take forty.\" The historian, Brian Harrison, interviewed Mary Hodgson, about Pankhurst, in July 1976 as part of the Suffrage Interviews project, titled \"Oral evidence on the suffragette and suffragist movements: the Brian Harrison interviews.\" She talks about Pankhurst's approach to motherhood and education, their time in Bermuda and Canada, and Pankhurst's death and funeral.\nRussian delegation.\nPankhurst visited North America in 1916 together with the former Secretary of State for Serbia, \u010cedomilj Mijatovi\u0107, whose nation had been at the centre of fighting at the start of the war. They toured the United States and Canada, raising money and urging the US government to support Britain and its Canadian and other allies. Two years later, after the US entered the war, Pankhurst returned to the United States, encouraging suffragettes there \u2013 who had not suspended their militancy \u2013 to support the war effort by sidelining activities related to the vote. She also spoke about her fears of communist insurgency, which she considered a grave threat to Russian democracy.\nBy June 1917 the Russian Revolution had strengthened the Bolsheviks, who urged an end to the war. Pankhurst's translated autobiography had been read widely in Russia, and she saw an opportunity to put pressure on the Russian people. She hoped to convince them not to accept Germany's conditions for peace, which she saw as a potential defeat for Britain and Russia. UK Prime Minister David Lloyd George agreed to sponsor her trip to Russia, which she took in June. She told one crowd: \"I came to Petrograd with a prayer from the English nation to the Russian nation, that you may continue the war on which depends the face of civilisation and freedom.\" Press response was divided between left and right wings; the former depicted her as a tool of capitalism, while the latter praised her devout patriotism.\nIn August she met with Alexander Kerensky, the Russian Prime Minister. Although she had been active with the socialist-leaning ILP in years past, Pankhurst had begun to see leftist politics as disagreeable, an attitude which intensified while she was in Russia. The meeting was uncomfortable for both parties; he felt that she was unable to appreciate the class-based conflict driving Russian policy at the time. He concluded by telling her that English women had nothing to teach women in Russia. She later told the \"New York Times\" that Kerensky was the \"biggest fraud of modern times\" and that his government could \"destroy civilisation.\"\nAccomplishment of suffrage (1918).\nWhen she returned from Russia, Pankhurst was delighted to find that women's right to vote was finally on its way to becoming a reality. The 1918 Representation of the People Act removed property restrictions on men's suffrage and granted the vote to women over the age of 30 (with several restrictions). As suffragists and suffragettes celebrated and prepared for its imminent passage, a new schism erupted: should women's political organisations join forces with those established by men? Many socialists and moderates supported unity of the sexes in politics, but Emmeline and Christabel Pankhurst saw the best hope in remaining separate. They reinvented the WSPU as the Women's Party, still open only to women. Women, they said, \"can best serve the nation by keeping clear of men's party political machinery and traditions, which, by universal consent, leave so much to be desired.\" The party favoured equal marriage laws, equal pay for equal work, and equal job opportunities for women. These were matters for the post-war era, however. While the fighting continued the Women's Party demanded no compromise in the defeat of Germany; the removal from government of anyone with family ties to Germany or pacifist attitudes; and shorter work hours to forestall labour strikes. This last plank in the party's platform was meant to discourage potential interest in Bolshevism, about which Pankhurst was increasingly anxious.\nPost-war activities.\nIn the years after the 1918 Armistice, Pankhurst continued to promote her nationalist vision of British unity. She maintained a focus on women's empowerment, but her days of fighting with government officialdom were over. She defended the presence and reach of the British Empire: \"Some talk about the Empire and Imperialism as if it were something to decry and something to be ashamed of. [I]t is a great thing to be the inheritors of an Empire like ours\u00a0... great in territory, great in potential wealth.\u00a0... If we can only realise and use that potential wealth we can destroy thereby poverty, we can remove and destroy ignorance.\" For years she travelled around England and North America, rallying support for the British Empire and warning audiences about the dangers of Bolshevism. After the war she lived in Bermuda and America for a couple of years.\nEmmeline Pankhurst also became active in political campaigning again when a bill was passed allowing women to run for the House of Commons. Many Women's Party members urged Pankhurst to stand for election, but she insisted that Christabel was a better choice. She campaigned tirelessly for her daughter, lobbying Prime Minister Lloyd George for his support and at one point delivering a passionate speech in the rain. Christabel lost by a very slim margin to the Labour Party candidate, and the recount showed a difference of 775 votes. One biographer called it \"the bitterest disappointment of Emmeline's life.\" The Women's Party withered from existence soon afterward.\nAs a result of her many trips to North America, Pankhurst became fond of Canada, stating in an interview that \"there seems to be more equality between men and women [there] than in any other country I know.\" In 1922 she applied for Canadian \"permission to land\" (a prerequisite to status as a \"British Subject with Canadian Domicile\") and rented a house in Toronto, where she moved with her four adopted children. She became active with the Canadian National Council for Combating Venereal Diseases (CNCCVD), which worked against the sexual double standard which Pankhurst considered particularly harmful to women. In many of her public lectures across Canada, she also promoted eugenic feminist notions of \"race betterment\" and often gave speeches together with Emily Murphy, a prominent proponent of compulsory sterilization for the \"feeble-minded.\" During a tour of Bathurst, the mayor showed her a new building which would become the Home for Fallen Women. Pankhurst replied: \"Ah! Where is your Home for Fallen Men?\" Before long, however, she grew tired of long Canadian winters, and she ran out of money. She returned to England in late 1925.\nBack in London Emmeline was visited by Sylvia, who had not seen her mother in years. Their politics were by now very different, and Sylvia was living, unmarried, with an Italian anarchist. Sylvia described a moment of familial affection when they met, followed by a sad distance between them. Emmeline's adopted daughter Mary, however, remembered the meeting differently. According to her version, Emmeline set her teacup down and walked silently out of the room, leaving Sylvia in tears. Christabel, meanwhile, had become a convert to Adventism and devoted much of her time to the church. The British press sometimes made light of the varied paths followed by the once indivisible family.\nIn 1926 Pankhurst joined the Conservative Party and two years later ran as a candidate for Parliament in Whitechapel and St George's. Her transformation from a fiery supporter of the ILP and window-smashing radical to an official Conservative Party member surprised many people. She replied succinctly: \"My war experience and my experience on the other side of the Atlantic have changed my views considerably.\" Her biographers insist that the move was more complex; she was devoted to a programme of women's empowerment and anti-communism. Both the Liberal and Labour parties bore grudges for her work against them in the WSPU, and the Conservative Party had a victorious record after the war and a significant majority. Pankhurst may have joined the Conservative Party as much to secure the vote for women as from ideological affinity.\nIllness and death.\nPankhurst's campaign for Parliament was preempted by her ill health and a final scandal involving Sylvia. The years of touring, lectures, imprisonment and hunger strikes had taken their toll; fatigue and illness became a regular part of Pankhurst's life. Even more painful, however, was the news in April 1928 that Sylvia had given birth out of wedlock. She had named the child Richard Keir Pethick Pankhurst, in memory of her father, her ILP comrade, and her colleagues from the WSPU respectively. Emmeline was further shocked to see a report from a newspaper in the US that declared that \"Miss Pankhurst\" \u2013 a title usually reserved for Christabel \u2013 boasted of her child being a triumph of \"eugenics\", since both parents were healthy and intelligent. In the article, Sylvia also spoke of her belief that \"marriage without legal union\" was the most sensible option for liberated women. These offences against the social dignity which Pankhurst had always valued devastated the elderly woman; to make matters worse, many people believed the \"Miss Pankhurst\" in newspaper headlines referred to Christabel. After hearing the news, Emmeline spent an entire day crying; her campaign for Parliament ended with the scandal.\nAs her health deteriorated, Pankhurst moved into a nursing home in Hampstead. She requested that she be treated by the doctor who attended to her during her hunger strikes. His use of the stomach pump had helped her feel better while in prison; her nurses were sure that the shock of such treatment would severely wound her, but Christabel felt obliged to carry out her mother's request. Before the procedure could be carried out, however, she fell into a critical condition from which none expected her to recover. On Thursday, 14 June 1928, Pankhurst died at the age of 69.\nShe was interred in Brompton Cemetery in London. Her pallbearers were the former WSPU suffragettes Georgiana Brackenbury, Marie Brackenbury, Marion Wallace Dunlop, Harriet Kerr, Mildred Mansel, Kitty Marshall, Marie Naylor, Ada Wright and Barbara Wylie.\nLegacy.\nNews of Emmeline Pankhurst's death was announced around the country, and extensively in North America. Her funeral service on 18 June 1928 was filled with her former WSPU colleagues and those who had worked beside her in various capacities. The \"Daily Mail\" described the procession as \"like a dead general in the midst of a mourning army\". Women wore WSPU sashes and ribbons, and the organisation's flag was carried alongside the Union Flag. Christabel and Sylvia appeared together at the service, the latter with her child. Adela did not attend. Press coverage around the world recognised her tireless work on behalf of women's right to vote \u2013 even if they did not agree on the value of her contributions. The \"New York Herald Tribune\" called her \"the most remarkable political and social agitator of the early part of the twentieth century and the supreme protagonist of the campaign for the electoral enfranchisement of women.\"\nShortly after the funeral, one of Pankhurst's bodyguards from her WSPU days, Catherine Marshall, began raising funds for a memorial statue. In spring 1930 her efforts bore fruit, and on 6 March her statue in Victoria Tower Gardens, next to and gesturing towards the Houses of Parliament, was unveiled. A crowd of radicals, former suffragettes, and national dignitaries gathered as former Prime Minister Stanley Baldwin presented the memorial to the public. In his address, Baldwin declared: \"I say with no fear of contradiction, that whatever view posterity may take, Mrs. Pankhurst has won for herself a niche in the Temple of Fame which will last for all time.\" Sylvia was the only Pankhurst daughter in attendance; Christabel, touring North America, sent a telegram which was read aloud. While planning the agenda for the day, Marshall had intentionally excluded Sylvia, who in her opinion had hastened Pankhurst's death. Historic England listed the statue as Grade II on 5 February 1970.\nA proposal to move the statue of Pankhurst away from the Houses of Parliament to the private Regent's University London in Regent's Park was submitted to Westminster City Council planning department in July 2018 by former Conservative MP Sir Neil Thorne. This proposal was withdrawn in September 2018 after widespread anger and a public campaign against it. The planning application received 896 comments, 887 of them objections. A 38 Degrees petition against the removal of the statue attracted 180,839 signatures. The Curator's Office at the Palace of Westminster commissioned a report into the plan to remove the statue. Published on 22 August 2018, it concluded 'The Memorial to Emmeline and Christabel Pankhurst is of high significance, which is not fully recognised through its listing at Grade II. An application has been made to Historic England to upgrade the memorial to Grade II*. This is based on it having 'more than special interest', in terms of its unique history, its artistic quality and the importance of its setting next to the Houses of Parliament. This proposal to move the memorial from Victoria Tower Gardens to Regent's Park would cause substantial harm to the significance of the memorial, as well has harm to the Westminster Abbey and Parliament Square Conservation Area...The proposal to move the memorial, therefore, should not be granted planning permission or listed building consent.\nDuring the twentieth century Emmeline Pankhurst's value to the movement for women's suffrage was debated passionately, and no consensus was achieved. Her daughters Sylvia and Christabel weighed in with books, scornful and laudatory respectively, about their time in the struggle. Sylvia's 1931 book \"The Suffrage Movement\" describes her mother's political shift at the start of the First World War as the beginning of a betrayal of her family (especially her father) and the movement. It set the tone for much of the socialist and activist history written about the WSPU and particularly solidified Emmeline Pankhurst's reputation as an unreasonable autocrat. Christabel's \"Unshackled: The Story of How We Won the Vote,\" released in 1959, paints her mother as generous and selfless to a fault, offering herself completely to the most noble causes. It provided a sympathetic counterpart to Sylvia's attacks and continued the polarised discussion; detached and objective assessment has rarely been a part of Pankhurst scholarship.\nRecent biographies show that historians differ about whether Emmeline Pankhurst's militancy helped or hurt the movement; however, there is general agreement that the WSPU raised public awareness of the movement in ways that proved essential. Baldwin compared her to Martin Luther and Jean-Jacques Rousseau: individuals who were not the sum total of the movements in which they took part, but who nevertheless played crucial roles in struggles of social and political reform. In the case of Pankhurst, this reform took place in both intentional and unintentional ways. By defying the roles of wife and mother as the docile companion, Pankhurst helped to pave the way for many future feminists, though some would later decry her support for empire and endorsement of the idea of \"race betterment.\"\nIn 1987 one of her homes in Manchester was opened as the Pankhurst Centre, an all-women gathering space and museum. In 2002, Pankhurst was placed at number 27 in the BBC's poll of the 100 Greatest Britons. In 2006, a blue plaque for Pankhurst and her daughter, Christabel was placed by English Heritage at 50 Clarendon Road, Notting Hill, London W11 3AD, Royal Borough of Kensington and Chelsea, where they had lived.\nIn January 2016, following a public vote, it was announced that \"Rise up, Women\", a statue of Emmeline Pankhurst by Hazel Reeves, would be unveiled in Manchester in 2019, making her the first woman to be honoured with a statue in the city since Queen Victoria more than 100 years ago. The statue was unveiled on 14 December 2018, one hundred years after British women were first able to vote in the 1918 United Kingdom general election. Her name and image and those of 58 other women's suffrage supporters including her daughters are etched on the plinth of the statue of Millicent Fawcett in Parliament Square, London that was unveiled in 2018. One of the 'houses' at Wellacre Academy in Manchester is named after her.\nHelen Pankhurst, the great-granddaughter of Emmeline Pankhurst and the granddaughter of Sylvia Pankhurst, works for women's rights. Along with her daughter, she founded Olympic Suffragettes, which campaigns on a number of women's rights issues.\nPankhurst has appeared in several works of popular culture. In the 1974 BBC television miniseries \"Shoulder to Shoulder\", Pankhurst is played by Si\u00e2n Phillips. In the 2015 film \"Suffragette\", Pankhurst is played by Meryl Streep. Pankhurst is commemorated in the song \"Emily\" in the Manic Street Preachers album \"Lifeblood\" (2004).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "60558", "revid": "51042751", "url": "https://en.wikipedia.org/wiki?curid=60558", "title": "ARM architecture family", "text": "Family of computer architectures\nARM (stylised in lowercase as arm, formerly an acronym for Advanced RISC Machines and originally Acorn RISC Machine) is a family of RISC instruction set architectures for computer processors. Arm Holdings develops the instruction set architecture and licenses them to other companies, who build the physical devices that use the instruction set. It also designs and licenses cores that implement these instruction set architectures.\nDue to their low costs, low power consumption, and low heat generation, ARM processors are useful for light, portable, battery-powered devices, including smartphones, laptops, and tablet computers, as well as embedded systems. However, ARM processors are also used for desktops and servers, including Fugaku, the world's fastest supercomputer from 2020 to 2022. With over 230 billion ARM chips produced, since at least 2003, and with its dominance increasing every year[ [update]], ARM is the most widely used family of instruction set architectures.\nThere have been several generations of the ARM design. The original ARM1 used a 32-bit internal structure but had a 26-bit address space that limited it to 64\u00a0MB of main memory. This limitation was removed in the ARMv3 series, which has a 32-bit address space, and several additional generations up to ARMv7 remained 32-bit. Released in 2011, the ARMv8-A architecture added support for a 64-bit address space and 64-bit arithmetic with its new 32-bit fixed-length instruction set. Arm Holdings has also released a series of additional instruction sets for different roles: the \"Thumb\" extensions add both 32- and 16-bit instructions for improved code density, while Jazelle added instructions for directly handling Java bytecode. More recent changes include the addition of simultaneous multithreading (SMT) for improved performance or fault tolerance.\nHistory.\nBBC Micro.\nAcorn Computers' first widely successful design was the BBC Micro, introduced in December 1981. This was a relatively conventional machine based on the MOS Technology 6502 CPU but ran at roughly double the performance of competing designs like the Apple II due to its use of faster dynamic random-access memory (DRAM). Typical DRAM of the era ran at about 2\u00a0MHz; Acorn arranged a deal with Hitachi for a supply of faster 4\u00a0MHz parts.\nMachines of the era generally shared memory between the processor and the framebuffer, which allowed the processor to quickly update the contents of the screen without having to perform separate input/output (I/O). As the timing of the video display is exacting, the video hardware had to have priority access to that memory. Due to a quirk of the 6502's design, the CPU left the memory untouched for half of the time. Thus by running the CPU at 1\u00a0MHz, the video system could read data during those down times, taking up the total 2\u00a0MHz bandwidth of the RAM. In the BBC Micro, the use of 4\u00a0MHz RAM allowed the same technique to be used, but running at twice the speed. This allowed it to outperform any similar machine on the market.\nAcorn Business Computer.\n1981 was also the year that the IBM Personal Computer was introduced. Using the recently introduced Intel 8088, a 16-bit CPU compared to the 6502's 8-bit design, it offered higher overall performance. Its introduction changed the desktop computer market radically: what had been largely a hobby and gaming market emerging over the prior five years began to change to a must-have business tool where the earlier 8-bit designs simply could not compete. Even newer 32-bit designs were also coming to market, such as the Motorola 68000 and National Semiconductor NS32016.\nAcorn began considering how to compete in this market and produced a new paper design named the Acorn Business Computer. They set themselves the goal of producing a machine with ten times the performance of the BBC Micro, but at the same price. This would outperform and underprice the PC. At the same time, the recent introduction of the Apple Lisa brought the graphical user interface (GUI) concept to a wider audience and suggested the future belonged to machines with a GUI. The Lisa, however, cost $9,995, as it was packed with support chips, large amounts of memory, and a hard disk drive, all very expensive then.\nThe engineers then began studying all of the CPU designs available. Their conclusion about the existing 16-bit designs was that they were a lot more expensive and were still \"a bit crap\", offering only slightly higher performance than their BBC Micro design. They also almost always demanded a large number of support chips to operate even at that level, which drove up the cost of the computer as a whole. These systems would simply not hit the design goal. They also considered the new 32-bit designs, but these cost even more and had the same issues with support chips. According to Sophie Wilson, all the processors tested at that time performed about the same, with about a 4\u00a0Mbit/s bandwidth.\nTwo key events led Acorn down the path to ARM. One was the publication of a series of reports from the University of California, Berkeley, which suggested that a simple chip design could nevertheless have extremely high performance, much higher than the latest 32-bit designs on the market. The second was a visit by Steve Furber and Sophie Wilson to the Western Design Center, a company run by Bill Mensch and his sister Kathryn, which had become the logical successor to the MOS team and was offering new versions like the WDC 65C02. The Acorn team saw high school students producing chip layouts on Apple II machines, which suggested that anyone could do it. In contrast, a visit to another design firm working on modern 32-bit CPU revealed a team with over a dozen members who were already on revision H of their design and yet it still contained bugs. This cemented their late 1983 decision to begin their own CPU design, the Acorn RISC Machine.\nDesign concepts.\nThe original Berkeley RISC designs were in some sense teaching systems, not designed specifically for outright performance. To the RISC's basic register-heavy and load/store concepts, ARM added a number of the well-received design notes of the 6502. Primary among them was the ability to quickly service interrupts, which allowed the machines to offer reasonable input/output performance with no added external hardware. To offer interrupts with similar performance as the 6502, the ARM design limited its physical address space to 64\u00a0MB of total addressable space, requiring 26 bits of address. As instructions were 4 bytes (32 bits) long, and required to be aligned on 4-byte boundaries, the lower 2 bits of an instruction address were always zero. This meant the program counter (PC) only needed to be 24 bits, allowing it to be stored along with the eight bit processor flags in a single 32-bit register. That meant that upon receiving an interrupt, the entire machine state could be saved in a single operation, whereas had the PC been a full 32-bit value, it would require separate operations to store the PC and the status flags. This decision halved the interrupt overhead.\nAnother change, and among the most important in terms of practical real-world performance, was the modification of the instruction set to take advantage of page mode DRAM. Recently introduced, page mode allowed subsequent accesses of memory to run twice as fast if they were roughly in the same location, or \"page\", in the DRAM chip. Berkeley's design did not consider page mode and treated all memory equally. The ARM design added special vector-like memory access instructions, the \"S-cycles\", that could be used to fill or save multiple registers in a single page using page mode. This doubled memory performance when they could be used, and was especially important for graphics performance.\nThe Berkeley RISC designs used register windows to reduce the number of register saves and restores performed in procedure calls; the ARM design did not adopt this.\nWilson developed the instruction set, writing a simulation of the processor in BBC\u00a0BASIC that ran on a BBC Micro with a second 6502 processor. This convinced Acorn engineers they were on the right track. Wilson approached Acorn's CEO, Hermann Hauser, and requested more resources. Hauser gave his approval and assembled a small team to design the actual processor based on Wilson's instruction set architecture. The official Acorn RISC Machine project started in October 1983.\nARM1.\nAcorn chose VLSI Technology as the \"silicon partner\", as they were a source of ROMs and custom chips for Acorn. Acorn provided the design and VLSI provided the layout and production. The first samples of ARM silicon worked properly when first received and tested on 26 April 1985. Known as ARM1, these versions ran at 6\u00a0MHz.\nThe first ARM application was as a second processor for the BBC Micro, where it helped in developing simulation software to finish development of the support chips (VIDC, IOC, MEMC), and sped up the CAD software used in ARM2 development. Wilson subsequently rewrote BBC BASIC in ARM assembly language. The in-depth knowledge gained from designing the instruction set enabled the code to be very dense, making ARM BBC BASIC an extremely good test for any ARM emulator.\nARM Evaluations Systems featuring ARM1 CPUs and supplied as a second processors for BBC Micro and Master machines, were made available from July 1986 under the Acorn OEM Products brand to developers and researchers.\nThe A500 Second Processor, an additional ARM1 based BBC Micro and Master second processor, featured the ARM support chipset (VIDC, IOC, MEMC), was capable of producing video output and operating near independently of the host BBC Micro.\nARM2.\nThe result of the simulations on the ARM1 boards led to the late 1986 introduction of the ARM2 design running at 8\u00a0MHz, and the early 1987 speed-bumped version at 10 to 12\u00a0MHz. A significant change in the underlying architecture was the addition of a Booth multiplier, whereas formerly multiplication had to be carried out in software. Further, a new Fast Interrupt reQuest mode, FIQ for short, allowed registers 8 to 14 to be replaced as part of the interrupt itself. This meant FIQ requests did not have to save out their registers, further speeding interrupts.\nThe first use of the ARM2 was in internal Acorn A500 development machines, and the Acorn Archimedes personal computer models A305, A310, and A440, launched on the 6th June 1987.\nAccording to the Dhrystone benchmark, the ARM2 was roughly seven times the performance of a typical 7\u00a0MHz 68000-based system like the Amiga or Macintosh SE. It was twice as fast as an Intel 80386 running at 16\u00a0MHz, and about the same speed as a multi-processor VAX-11/784 superminicomputer. The only systems that beat it were the Sun SPARC and MIPS R2000 RISC-based workstations. Further, as the CPU was designed for high-speed I/O, it dispensed with many of the support chips seen in these machines; notably, it lacked any dedicated direct memory access (DMA) controller which was often found on workstations. The graphics system was also simplified based on the same set of underlying assumptions about memory and timing. The result was a dramatically simplified design, offering performance on par with expensive workstations but at a price point similar to contemporary desktops.\nThe ARM2 featured a 32-bit data bus, 26-bit address space and 27\u00a032-bit registers, of which 16 are accessible at any one time (including the PC). The ARM2 had a transistor count of just 30,000, compared to Motorola's six-year-older 68000 model with around 68,000. Much of this simplicity came from the lack of microcode, which represents about one-quarter to one-third of the 68000's transistors, and the lack of (like most CPUs of the day) a cache. This simplicity enabled the ARM2 to have a low power consumption and simpler thermal packaging by having fewer powered transistors. Nevertheless, ARM2 offered better performance than the contemporary 1987 IBM PS/2 Model 50, which initially utilised an Intel 80286, offering 1.8 MIPS @ 10\u00a0MHz, and later in 1987, the 2 MIPS of the PS/2 70, with its Intel 386 DX @ 16\u00a0MHz.\nA successor, ARM3, was produced with a 4 KB cache, which further improved performance. The address bus was extended to 32\u00a0bits in the ARM6, but program code still had to lie within the first 64 MB of memory in 26-bit compatibility mode, due to the reserved bits for the status flags.\nAdvanced RISC Machines Ltd. \u2013 ARM6.\nIn the late 1980s, Apple Computer and VLSI Technology started working with Acorn on newer versions of the ARM core. In 1990, Acorn spun off the design team into a new company named Advanced RISC Machines Ltd., which became ARM Ltd. when its parent company, Arm Holdings plc, floated on the London Stock Exchange and Nasdaq in 1998. The new Apple\u2013ARM work would eventually evolve into the ARM6, first released in early 1992. Apple used the ARM6-based ARM610 as the basis for their Apple Newton PDA.\nEarly licensees.\nIn 1994, Acorn used the ARM610 as the main central processing unit (CPU) in their RiscPC computers. DEC licensed the ARMv4 architecture and produced the StrongARM. At 233\u00a0MHz, this CPU drew only one watt (newer versions draw far less). This work was later passed to Intel as part of a lawsuit settlement, and Intel took the opportunity to supplement their i960 line with the StrongARM. Intel later developed its own high performance implementation named XScale, which it has since sold to Marvell. Transistor count of the ARM core remained essentially the same throughout these changes; ARM2 had 30,000\u00a0transistors, while ARM6 grew only to 35,000.\nMarket share.\nIn 2005, about 98% of all mobile phones sold used at least one ARM processor. In 2010, producers of chips based on ARM architectures reported shipments of 6.1\u00a0billion ARM-based processors, representing 95% of smartphones, 35% of digital televisions and set-top boxes, and 10% of mobile computers. In 2011, the 32-bit ARM architecture was the most widely used architecture in mobile devices and the most popular 32-bit one in embedded systems. In 2013, 10 billion were produced and \"ARM-based chips are found in nearly 60 percent of the world's mobile devices\".\nLicensing.\nCore licence.\nArm Holdings's primary business is selling IP cores, which licensees use to create microcontrollers (MCUs), CPUs, and systems-on-chips based on those cores. The original design manufacturer combines the ARM core with other parts to produce a complete device, typically one that can be built in existing semiconductor fabrication plants (fabs) at low cost and still deliver substantial performance. The most successful implementation has been the ARM7TDMI with hundreds of millions sold. Atmel has been a precursor design center in the ARM7TDMI-based embedded system.\nThe ARM architectures used in smartphones, PDAs and other mobile devices range from ARMv5 to ARMv8-A.\nIn 2009, some manufacturers introduced netbooks based on ARM architecture CPUs, in direct competition with netbooks based on Intel Atom.\nArm Holdings offers a variety of licensing terms, varying in cost and deliverables. Arm Holdings provides to all licensees an integratable hardware description of the ARM core as well as complete software development toolset (compiler, debugger, software development kit), and the right to sell manufactured silicon containing the ARM CPU.\nSoC packages integrating ARM's core designs include Nvidia Tegra's first three generations, CSR plc's Quatro family, ST-Ericsson's Nova and NovaThor, Silicon Labs's Precision32 MCU, Texas Instruments's OMAP products, Samsung's Hummingbird and Exynos products, Apple's A4, A5, and A5X, and NXP's i.MX.\nFabless licensees, who wish to integrate an ARM core into their own chip design, are usually only interested in acquiring a ready-to-manufacture verified semiconductor intellectual property core. For these customers, Arm Holdings delivers a gate netlist description of the chosen ARM core, along with an abstracted simulation model and test programs to aid design integration and verification. More ambitious customers, including integrated device manufacturers (IDM) and foundry operators, choose to acquire the processor IP in synthesizable RTL (Verilog) form. With the synthesizable RTL, the customer has the ability to perform architectural level optimisations and extensions. This allows the designer to achieve exotic design goals not otherwise possible with an unmodified netlist (high clock speed, very low power consumption, instruction set extensions, etc.). While Arm Holdings does not grant the licensee the right to resell the ARM architecture itself, licensees may freely sell manufactured products such as chip devices, evaluation boards and complete systems. Merchant foundries can be a special case; not only are they allowed to sell finished silicon containing ARM cores, they generally hold the right to re-manufacture ARM cores for other customers.\nArm Holdings prices its IP based on perceived value. Lower performing ARM cores typically have lower licence costs than higher performing cores. In implementation terms, a synthesisable core costs more than a hard macro (blackbox) core. Complicating price matters, a merchant foundry that holds an ARM licence, such as Samsung or Fujitsu, can offer fab customers reduced licensing costs. In exchange for acquiring the ARM core through the foundry's in-house design services, the customer can reduce or eliminate payment of ARM's upfront licence fee.\nCompared to dedicated semiconductor foundries (such as TSMC and UMC) without in-house design services, Fujitsu/Samsung charge two- to three-times more per manufactured wafer. For low to mid volume applications, a design service foundry offers lower overall pricing (through subsidisation of the licence fee). For high volume mass-produced parts, the long term cost reduction achievable through lower wafer pricing reduces the impact of ARM's NRE (non-recurring engineering) costs, making the dedicated foundry a better choice.\nCompanies that have developed chips with cores designed by Arm include Amazon.com's Annapurna Labs subsidiary, Analog Devices, Apple, AppliedMicro (now: MACOM Technology Solutions), Atmel, Broadcom, Cavium, Cypress Semiconductor, Freescale Semiconductor (now NXP Semiconductors), Huawei, Intel, Maxim Integrated, Nvidia, NXP, Qualcomm, Renesas, Samsung Electronics, ST Microelectronics, Texas Instruments, and Xilinx.\nBuilt on ARM Cortex Technology licence.\nIn February 2016, ARM announced the Built on ARM Cortex Technology licence, often shortened to Built on Cortex (BoC) licence. This licence allows companies to partner with ARM and make modifications to ARM Cortex designs. These design modifications will not be shared with other companies. These semi-custom core designs also have brand freedom, for example Kryo 280.\nCompanies that are current licensees of Built on ARM Cortex Technology include Qualcomm.\nArchitectural licence.\nCompanies can also obtain an ARM \"architectural licence\" for designing their own CPU cores using the ARM instruction sets. These cores must comply fully with the ARM architecture. Companies that have designed cores that implement an ARM architecture include Apple, AppliedMicro (now: Ampere Computing), Broadcom, Cavium (now: Marvell), Digital Equipment Corporation, Intel, Nvidia, Qualcomm, Samsung Electronics, Fujitsu, and NUVIA Inc. (acquired by Qualcomm in 2021).\nARM Flexible Access.\nOn 16 July 2019, ARM announced ARM Flexible Access. ARM Flexible Access provides unlimited access to included ARM intellectual property (IP) for development. Per product licence fees are required once a customer reaches foundry tapeout or prototyping.\n75% of ARM's most recent IP over the last two years are included in ARM Flexible Access. As of October 2019:\nCores.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nArm provides a list of vendors who implement ARM cores in their design (application specific standard products (ASSP), microprocessor and microcontrollers).\nExample applications of ARM cores.\nARM cores are used in a number of products, particularly PDAs and smartphones. Some computing examples are Microsoft's first generation Surface, Surface 2 and Pocket PC devices (following 2002), Apple's iPads, and Asus's Eee Pad Transformer tablet computers, and several Chromebook laptops. Others include Apple's iPhone smartphones and iPod portable media players, Canon PowerShot digital cameras, Nintendo Switch hybrid, the Wii security processor and 3DS handheld game consoles, and TomTom turn-by-turn navigation systems.\nIn 2005, Arm took part in the development of Manchester University's computer SpiNNaker, which used ARM cores to simulate the human brain.\nARM chips are also used in Raspberry Pi, BeagleBoard, BeagleBone, PandaBoard, and other single-board computers, because they are very small, inexpensive, and consume very little power.\n32-bit architecture.\nThe 32-bit ARM architecture (ARM32), such as ARMv7-A (implementing AArch32; see section on Armv8-A for more on it), was the most widely used architecture in mobile devices as of 2011[ [update]].\nSince 1995, various versions of the \"ARM Architecture Reference Manual\" (see ) have been the primary source of documentation on the ARM processor architecture and instruction set, distinguishing interfaces that all ARM processors are required to support (such as instruction semantics) from implementation details that may vary. The architecture has evolved over time, and version seven of the architecture, ARMv7, defines three architecture \"profiles\":\nAlthough the architecture profiles were first defined for ARMv7, ARM subsequently defined the ARMv6-M architecture (used by the Cortex M0/M0+/M1) as a subset of the ARMv7-M profile with fewer instructions.\nArchitecture versions.\n26-bit addressing - obsolete as of June 2000\nMultiply and multiply-accumulate instructions; coprocessor support - obsolete as of June 2000\nAtomic load-and-store instructions - obsolete as of June 2000\n32-bit addressing - obsolete as of July 2005\n; ARMv3G\nNo 26-bit addressing support - obsolete as of July 2005\n; ARMv3M\nLong and signed multiplies - obsolete as of July 2005\nHalfword load and store instructions; sign-extending byte and halfword load instructions; 26-bit addressing support removed\n;ARMv4xM\nARMv4, but without long multiply - obsolete as of July 2005\n; ARMv4T\nARMv4 plus version 1 of Thumb instruction set\n; ARMv4TxM\nARMv4T, but without long multiply - obsolete as of July 2005\nCount leading zeros instruction - obsolete as of July 2005\n; ARMv5xM\nARMv5, but without long multiply - obsolete as of July 2005\n; ARMv5T\nARMv5 plus version 2 of Thumb\n; ARMv5TxM\nARMv5T, but without long multiply - obsolete as of July 2005\n; ARMv5TE\nARMv5T plus enhanced DSP instructions\n; ARMv5TExP\nARMv5TE, but without , , , , and enhanced DSP instructions\n; ARMv5TEJ\nARMv5TE plus Jazelle\nFull ARMv5TEJ; byte reversal instructions; exclusive-access load and store instructions; byte and halfword sign-extend and zero-extend instructions; SIMD media instructions; unaligned access support\n; ARMv6K\nARMv6 plus instructions to support multiprocessor systems\n; ARMv6T2\nARMv6 plus Thumb-2 instruction set\n; ARMv7-A, ARMv7-R\nOptional signed and unsigned divide; memory and synchronization barrier instructions; preload instruction hint instruction\n; ARMv7-M\nThumb-2 only\nIntroduces two \"Execution states\", AArch32 and AArch64, the former of which supports the 32-bit ARM instruction set, called A32, and the Thumb-2 instruction set, called T32, and the latter of which supports a new instruction set with 32 64-bit registers, called A64.\n; ARMv8-A AArch32, ARMv8-R AArch32\nLoad-acquire and store-release instructions, crypto instructions, data barrier instruction extensions, Send Event Locally instruction\n; ARMv8-M\nVariant Thumb-2 only\nCPU modes.\nExcept in the M-profile, the 32-bit ARM architecture specifies several CPU modes, depending on the implemented architecture features. At any moment in time, the CPU can be in only one mode, but it can switch modes due to external events (interrupts) or programmatically.\nInstruction set.\nThe original (and subsequent) ARM implementation was hardwired without microcode, like the much simpler 8-bit 6502 processor used in prior Acorn microcomputers.\nThe 32-bit ARM architecture (and the 64-bit architecture for the most part) includes the following RISC features:\nTo compensate for the simpler design, compared with processors like the Intel 80286 and Motorola 68020, some additional design features were used:\nArithmetic instructions.\nARM includes integer arithmetic operations for add, subtract, and multiply; some versions of the architecture also support divide operations.\nARM supports 32-bit \u00d7 32-bit multiplies with either a 32-bit result or 64-bit result, though Cortex-M0 / M0+ / M1 cores do not support 64-bit results. Some ARM cores also support 16-bit \u00d7 16-bit and 32-bit \u00d7 16-bit multiplies.\nThe divide instructions are only included in the following ARM architectures:\nRegisters.\nRegisters R0 through R7 are the same across all CPU modes; they are never banked.\nRegisters R8 through R12 are the same across all CPU modes except FIQ mode. FIQ mode has its own distinct R8 through R12 registers.\nR13 and R14 are banked across all privileged CPU modes except system mode. That is, each mode that can be entered because of an exception has its own R13 and R14. These registers generally contain the stack pointer and the return address from function calls, respectively.\nAliases:\nThe Current Program Status Register (CPSR) has the following 32\u00a0bits.\nConditional execution.\nAlmost every ARM instruction has a conditional execution feature called predication, which is implemented with a 4-bit condition code selector (the predicate). To allow for unconditional execution, one of the four-bit codes causes the instruction to be always executed. Most other CPU architectures only have condition codes on branch instructions.\nThough the predicate takes up four of the 32\u00a0bits in an instruction code, and thus cuts down significantly on the encoding bits available for displacements in memory access instructions, it avoids branch instructions when generating code for small codice_1 statements. Apart from eliminating the branch instructions themselves, this preserves the fetch/decode/execute pipeline at the cost of only one cycle per skipped instruction.\nAn algorithm that provides a good example of conditional execution is the subtraction-based Euclidean algorithm for computing the greatest common divisor. In the C programming language, the algorithm can be written as:\nint gcd(int a, int b) {\n while (a != b) // We enter the loop when a &lt; b or a &gt; b, but not when a == b\n if (a &gt; b) // When a &gt; b we do this\n a -= b;\n else // When a &lt; b we do that (no \"if (a &lt; b)\" needed since a != b is checked in while condition)\n b -= a;\n return a;\nThe same algorithm can be rewritten in a way closer to target ARM instructions as:\nloop:\n // Compare a and b\n GT = a &gt; b;\n LT = a &lt; b;\n NE = a != b;\n // Perform operations based on flag results\n if (GT) a -= b; // Subtract *only* if greater-than\n if (LT) b -= a; // Subtract *only* if less-than\n if (NE) goto loop; // Loop *only* if compared values were not equal\n return a;\nand coded in assembly language as:\nloop: CMP r0, r1 ; set condition \"NE\" if (a \u2260 b),\n ; \"GT\" if (a &gt; b),\n ; or \"LT\" if (a &lt; b)\n SUBGT r0, r0, r1 ; if \"GT\" (Greater Than), then a = a \u2212 b\n SUBLT r1, r1, r0 ; if \"LT\" (Less Than), then b = b \u2212 a\n BNE loop ; if \"NE\" (Not Equal), then loop\n B lr ; return\nwhich avoids the branches around the codice_2 and codice_3 clauses. If codice_4 and codice_5 are equal then neither of the codice_6 instructions will be executed, eliminating the need for a conditional branch to implement the codice_7 check at the top of the loop, for example had codice_8 (less than or equal) been used.\nOne of the ways that Thumb code provides a more dense encoding is to remove the four-bit selector from non-branch instructions.\nOther features.\nAnother feature of the instruction set is the ability to fold shifts and rotates into the \"data processing\" (arithmetic, logical, and register-register move) instructions, so that, for example, the statement in C language:\na += (j \u00ab 2);\ncould be rendered as a one-word, one-cycle instruction:\nADD Ra, Ra, Rj, LSL #2\nThis results in the typical ARM program being denser than expected with fewer memory accesses; thus the pipeline is used more efficiently.\nThe ARM processor also has features rarely seen in other RISC architectures, such as PC-relative addressing (indeed, on the 32-bit ARM the PC is one of its 16\u00a0registers) and pre- and post-increment addressing modes.\nThe ARM instruction set has increased over time. Some early ARM processors (before ARM7TDMI), for example, have no instruction to store a two-byte quantity.\nPipelines and other implementation issues.\nThe ARM7 and earlier implementations have a three-stage pipeline; the stages being fetch, decode, and execute. Higher-performance designs, such as the ARM9, have deeper pipelines: Cortex-A8 has thirteen stages. Additional implementation changes for higher performance include a faster adder and more extensive branch prediction logic. The difference between the ARM7DI and ARM7DMI cores, for example, was an improved multiplier; hence the added \"M\".\nCoprocessors.\nThe ARM architecture (pre-Armv8) provides a non-intrusive way of extending the instruction set using \"coprocessors\" that can be addressed using MCR, MRC, MRRC, MCRR, and similar instructions. The coprocessor space is divided logically into 16\u00a0coprocessors with numbers from 0 to 15, coprocessor\u00a015 (cp15) being reserved for some typical control functions like managing the caches and MMU operation on processors that have one.\nIn ARM-based machines, peripheral devices are usually attached to the processor by mapping their physical registers into ARM memory space, into the coprocessor space, or by connecting to another device (a bus) that in turn attaches to the processor. Coprocessor accesses have lower latency, so some peripherals\u2014for example, an XScale interrupt controller\u2014are accessible in both ways: through memory and through coprocessors.\nIn other cases, chip designers only integrate hardware using the coprocessor mechanism. For example, an image processing engine might be a small ARM7TDMI core combined with a coprocessor that has specialised operations to support a specific set of HDTV transcoding primitives.\nDebugging.\nAll modern ARM processors include hardware debugging facilities, allowing software debuggers to perform operations such as halting, stepping, and breakpointing of code starting from reset. These facilities are built using JTAG support, though some newer cores optionally support ARM's own two-wire \"SWD\" protocol. In ARM7TDMI cores, the \"D\" represented JTAG debug support, and the \"I\" represented presence of an \"EmbeddedICE\" debug module. For ARM7 and ARM9 core generations, EmbeddedICE over JTAG was a de facto debug standard, though not architecturally guaranteed.\nThe ARMv7 architecture defines basic debug facilities at an architectural level. These include breakpoints, watchpoints and instruction execution in a \"Debug Mode\"; similar facilities were also available with EmbeddedICE. Both \"halt mode\" and \"monitor\" mode debugging are supported. The actual transport mechanism used to access the debug facilities is not architecturally specified, but implementations generally include JTAG support.\nThere is a separate ARM \"CoreSight\" debug architecture, which is not architecturally required by ARMv7 processors.\nDebug Access Port.\nThe Debug Access Port (DAP) is an implementation of an ARM Debug Interface.\nThere are two different supported implementations, the Serial Wire JTAG Debug Port (SWJ-DP) and the Serial Wire Debug Port (SW-DP).\nCMSIS-DAP is a standard interface that describes how various debugging software on a host PC can communicate over USB to firmware running on a hardware debugger, which in turn talks over SWD or JTAG to a CoreSight-enabled ARM Cortex CPU.\nDSP enhancement instructions.\nTo improve the ARM architecture for digital signal processing and multimedia applications, DSP instructions were added to the instruction set. These are signified by an \"E\" in the name of the ARMv5TE and ARMv5TEJ architectures. E-variants also imply T, D, M, and I.\nThe new instructions are common in digital signal processor (DSP) architectures. They include variations on signed multiply\u2013accumulate, saturated add and subtract, and count leading zeros.\nFirst introduced in 1999, this extension of the core instruction set contrasted with ARM's earlier DSP coprocessor known as Piccolo, which employed a distinct, incompatible instruction set whose execution involved a separate program counter. Piccolo instructions employed a distinct register file of sixteen 32-bit registers, with some instructions combining registers for use as 48-bit accumulators and other instructions addressing 16-bit half-registers. Some instructions were able to operate on two such 16-bit values in parallel. Communication with the Piccolo register file involved \"load to Piccolo\" and \"store from Piccolo\" coprocessor instructions via two buffers of eight 32-bit entries. Described as reminiscent of other approaches, notably Hitachi's SH-DSP and Motorola's 68356, Piccolo did not employ dedicated local memory and relied on the bandwidth of the ARM core for DSP operand retrieval, impacting concurrent performance. Piccolo's distinct instruction set also proved not to be a \"good compiler target\".\nSIMD extensions for multimedia.\nIntroduced in the ARMv6 architecture, this was a precursor to Advanced SIMD, also named Neon.\nJazelle.\nJazelle DBX (Direct Bytecode eXecution) is a technique that allows Java bytecode to be executed directly in the ARM architecture as a third execution state (and instruction set) alongside the existing ARM and Thumb-mode. Support for this state is signified by the \"J\" in the ARMv5TEJ architecture, and in ARM9EJ-S and ARM7EJ-S core names. Support for this state is required starting in ARMv6 (except for the ARMv7-M profile), though newer cores only include a trivial implementation that provides no hardware acceleration.\nThumb.\nTo improve compiled code density, processors since the ARM7TDMI (released in 1994) have featured the \"Thumb\" compressed instruction set, which have their own state. (The \"T\" in \"TDMI\" indicates the Thumb feature.) When in this state, the processor executes the Thumb instruction set, a compact 16-bit encoding for a subset of the ARM instruction set. Most of the Thumb instructions are directly mapped to normal ARM instructions. The space saving comes from making some of the instruction operands implicit and limiting the number of possibilities compared to the ARM instructions executed in the ARM instruction set state.\nIn Thumb, the 16-bit opcodes have less functionality. For example, only branches can be conditional, and many opcodes are restricted to accessing only half of all of the CPU's general-purpose registers. The shorter opcodes give improved code density overall, even though some operations require extra instructions. In situations where the memory port or bus width is constrained to less than 32\u00a0bits, the shorter Thumb opcodes allow increased performance compared with 32-bit ARM code, as less program code may need to be loaded into the processor over the constrained memory bandwidth.\nUnlike processor architectures with variable length (16- or 32-bit) instructions, such as the Cray-1 and Hitachi SuperH, the ARM and Thumb instruction sets exist independently of each other. Embedded hardware, such as the Game Boy Advance, typically have a small amount of RAM accessible with a full 32-bit datapath; the majority is accessed via a 16-bit or narrower secondary datapath. In this situation, it usually makes sense to compile Thumb code and hand-optimise a few of the most CPU-intensive sections using full 32-bit ARM instructions, placing these wider instructions into the 32-bit bus accessible memory.\nThe first processor with a Thumb instruction decoder was the ARM7TDMI. All processors supporting 32-bit instruction sets, starting with ARM9, and including XScale, have included a Thumb instruction decoder. It includes instructions adopted from the Hitachi SuperH (1992), which was licensed by ARM. ARM's smallest processor families (Cortex M0 and M1) implement only the 16-bit Thumb instruction set for maximum performance in lowest cost applications. ARM processors that don't support 32-bit addressing also omit Thumb.\nThumb-2.\n\"Thumb-2\" technology was introduced in the \"ARM1156\u00a0core\", announced in 2003. Thumb-2 extends the limited 16-bit instruction set of Thumb with additional 32-bit instructions to give the instruction set more breadth, thus producing a variable-length instruction set. A stated aim for Thumb-2 was to achieve code density similar to Thumb with performance similar to the ARM instruction set on 32-bit memory.\nThumb-2 extends the Thumb instruction set with bit-field manipulation, table branches and conditional execution. At the same time, the ARM instruction set was extended to maintain equivalent functionality in both instruction sets. A new \"Unified Assembly Language\" (UAL) supports generation of either Thumb or ARM instructions from the same source code; versions of Thumb seen on ARMv7 processors are essentially as capable as ARM code (including the ability to write interrupt handlers). This requires a bit of care, and use of a new \"IT\" (if-then) instruction, which permits up to four successive instructions to execute based on a tested condition, or on its inverse. When compiling into ARM code, this is ignored, but when compiling into Thumb it generates an actual instruction. For example:\nCMP r0, r1\nITE EQ ; ARM: no code ... Thumb: IT instruction\nMOVEQ r0, r2 ; ARM: conditional; Thumb: condition via ITE 'T' (then)\nMOVNE r0, r3 ; ARM: conditional; Thumb: condition via ITE 'E' (else)\nAll ARMv7 chips support the Thumb instruction set. All chips in the Cortex-A series that support ARMv7, all Cortex-R series, and all ARM11 series support both \"ARM instruction set state\" and \"Thumb instruction set state\", while chips in the Cortex-M series support only the Thumb instruction set.\nThumb Execution Environment (ThumbEE).\n\"ThumbEE\" (erroneously called \"Thumb-2EE\" in some ARM documentation), which was marketed as Jazelle RCT (Runtime Compilation Target), was announced in 2005 and deprecated in 2011. It first appeared in the \"Cortex-A8\" processor. ThumbEE is a fourth instruction set state, making small changes to the Thumb-2 extended instruction set. These changes make the instruction set particularly suited to code generated at runtime (e.g. by JIT compilation) in managed \"Execution Environments\". ThumbEE is a target for languages such as Java, C#, Perl, and Python, and allows JIT compilers to output smaller compiled code without reducing performance.\nNew features provided by ThumbEE include automatic null pointer checks on every load and store instruction, an instruction to perform an array bounds check, and special instructions that call a handler. In addition, because it utilises Thumb-2 technology, ThumbEE provides access to registers r8\u2013r15 (where the Jazelle/DBX Java VM state is held). Handlers are small sections of frequently called code, commonly used to implement high level languages, such as allocating memory for a new object. These changes come from repurposing a handful of opcodes, and knowing the core is in the new ThumbEE state.\nOn 23 November 2011, Arm deprecated any use of the ThumbEE instruction set, and Armv8 removes support for ThumbEE.\nFloating-point (VFP).\n\"VFP\" (Vector Floating Point) technology is a floating-point unit (FPU) coprocessor extension to the ARM architecture (implemented differently in Armv8 \u2013 coprocessors not defined there). It provides low-cost single-precision and double-precision floating-point computation fully compliant with the \"ANSI/IEEE Std 754-1985 Standard for Binary Floating-Point Arithmetic\". VFP provides floating-point computation suitable for a wide spectrum of applications such as PDAs, smartphones, voice compression and decompression, three-dimensional graphics and digital audio, printers, set-top boxes, and automotive applications. The VFP architecture was intended to support execution of short \"vector mode\" instructions but these operated on each vector element sequentially and thus did not offer the performance of true single instruction, multiple data (SIMD) vector parallelism. This vector mode was therefore removed shortly after its introduction, to be replaced with the much more powerful Advanced SIMD, also named Neon.\nSome devices such as the ARM Cortex-A8 have a cut-down \"VFPLite\" module instead of a full VFP module, and require roughly ten times more clock cycles per float operation. Pre-Armv8 architecture implemented floating-point/SIMD with the coprocessor interface. Other floating-point and/or SIMD units found in ARM-based processors using the coprocessor interface include FPA, FPE, iwMMXt, some of which were implemented in software by trapping but could have been implemented in hardware. They provide some of the same functionality as VFP but are not opcode-compatible with it. FPA10 also provides extended precision, but implements correct rounding (required by IEEE\u00a0754) only in single precision.\nIn Debian Linux and derivatives such as Ubuntu and Linux Mint, armhf (ARM hard float) refers to the ARMv7 architecture including the additional VFP3-D16 floating-point hardware extension (and Thumb-2) above. Software packages and cross-compiler tools use the armhf vs. arm/armel suffixes to differentiate.\nAdvanced SIMD (Neon).\nThe \"Advanced SIMD\" extension (also known as \"Neon\" or \"MPE\" Media Processing Engine) is a combined 64- and 128-bit SIMD instruction set that provides standardised acceleration for media and signal processing applications. Neon is included in all Cortex-A8 devices, but is optional in Cortex-A9 devices. Neon can execute MP3 audio decoding on CPUs running at 10\u00a0MHz, and can run the GSM adaptive multi-rate (AMR) speech codec at 13\u00a0MHz. It features a comprehensive instruction set, separate register files, and independent execution hardware. Neon supports 8-, 16-, 32-, and 64-bit integer and single-precision (32-bit) floating-point data and SIMD operations for handling audio and video processing as well as graphics and gaming processing. In Neon, the SIMD supports up to 16\u00a0operations at the same time. The Neon hardware shares the same floating-point registers as used in VFP. Devices such as the ARM Cortex-A8 and Cortex-A9 support 128-bit vectors, but will execute with 64\u00a0bits at a time, whereas some more powerful CPUs such as Cortex-A15 can execute 128\u00a0bits at a time.\nA quirk of Neon in Armv7 devices is that it flushes all subnormal numbers to zero, and as a result the GCC compiler will not use it unless , which allows losing denormals, is turned on. \"Enhanced\" Neon defined since Armv8 does not have this quirk, but as of GCC 8.2 the same flag is still required to enable Neon instructions. On the other hand, GCC does consider Neon safe on AArch64 for Armv8.\nProjectNe10 is ARM's first open-source project (from its inception; while they acquired an older project, now named Mbed TLS). The Ne10 library is a set of common, useful functions written in both Neon and C (for compatibility). The library was created to allow developers to use Neon optimisations without learning Neon, but it also serves as a set of highly optimised Neon intrinsic and assembly code examples for common DSP, arithmetic, and image processing routines. The source code is available on GitHub.\nARM Helium technology.\nHelium is the M-Profile Vector Extension (MVE). It adds more than 150 scalar and vector instructions.\nSecurity extensions.\nTrustZone (for Cortex-A profile).\nThe Security Extensions, marketed as TrustZone Technology, is in ARMv6KZ and later application profile architectures. It provides a low-cost alternative to adding another dedicated security core to an SoC, by providing two virtual processors backed by hardware based access control. This lets the application core switch between two states, referred to as \"worlds\" (to reduce confusion with other names for capability domains), to prevent information leaking from the more trusted world (the \"Secure world\") to the less trusted world (the \"Normal world\"). This world switch is generally orthogonal to all other capabilities of the processor, thus each world can operate independently of the other while using the same core. Memory and peripherals are then made aware of the operating world of the core and may use this to provide access control to secrets and code on the device.\nTypically, a rich operating system is run in the less trusted world, with smaller security-specialised code in the more trusted world, aiming to reduce the attack surface. Typical applications include DRM functionality for controlling the use of media on ARM-based devices, and preventing any unapproved use of the device.\nIn practice, since the specific implementation details of proprietary TrustZone implementations have not been publicly disclosed for review, it is unclear what level of assurance is provided for a given threat model, but they are not immune from attack.\nOpen Virtualization is an open source implementation of the trusted world architecture for TrustZone.\nAMD has licensed and incorporated TrustZone technology into its Secure Processor Technology. AMD's APUs include a Cortex-A5 processor for handling secure processing, which is enabled in some, but not all products. In fact, the Cortex-A5 TrustZone core had been included in earlier AMD products, but was not enabled due to time constraints.\nSamsung Knox uses TrustZone for purposes such as detecting modifications to the kernel, storing certificates and attestating keys.\nTrustZone for Armv8-M (for Cortex-M profile).\nThe Security Extension, marketed as TrustZone for Armv8-M Technology, was introduced in the Armv8-M architecture. While containing similar concepts to TrustZone for Armv8-A, it has a different architectural design, as world switching is performed using branch instructions instead of using exceptions. It also supports safe interleaved interrupt handling from either world regardless of the current security state. Together these features provide low latency calls to the secure world and responsive interrupt handling. ARM provides a reference stack of secure world code in the form of Trusted Firmware for M and PSA Certified.\nNo-execute page protection.\nAs of ARMv6, the ARM architecture supports no-execute page protection, which is referred to as \"XN\", for \"eXecute Never\".\nLarge Physical Address Extension (LPAE).\nThe Large Physical Address Extension (LPAE), which extends the physical address size from 32 bits to 40 bits, was added to the Armv7-A architecture in 2011.\nThe physical address size may be even larger in processors based on the 64-bit (Armv8-A) architecture. For example, it is 44 bits in Cortex-A75 and Cortex-A65AE.\nArmv8-R and Armv8-M.\nThe Armv8-R and Armv8-M architectures, announced after the Armv8-A architecture, share some features with Armv8-A. However, Armv8-M does not include any 64-bit AArch64 instructions, and Armv8-R originally did not include any AArch64 instructions; those instructions were added to Armv8-R later.\nArmv8.1-M.\nThe Armv8.1-M architecture, announced in February 2019, is an enhancement of the Armv8-M architecture. It brings new features including:\n64/32-bit architecture.\nArmv8.\nArmv8-A.\nAnnounced in October 2011, Armv8-A (often called ARMv8 while the Armv8-R is also available) represents a fundamental change to the ARM architecture. It supports two \"Execution states\": a 64-bit state named \"AArch64\" and a 32-bit state named \"AArch32\". In the AArch64 state, a new 64-bit \"A64\" instruction set is supported; in the AArch32 state, two instruction sets are supported: the original 32-bit instruction set, named \"A32\", and the 32-bit Thumb-2 instruction set, named \"T32\". AArch32 provides user-space compatibility with Armv7-A. The processor state can change on an Exception level change; this allows 32-bit applications to be executed in AArch32 state under a 64-bit OS whose kernel executes in AArch64 state, and allows a 32-bit OS to run in AArch32 state under the control of a 64-bit hypervisor running in AArch64 state. ARM announced their Cortex-A53 and Cortex-A57 cores on 30 October 2012. Apple was the first to release an Armv8-A compatible core in a consumer product (Apple A7 in iPhone 5S). AppliedMicro, using an FPGA, was the first to demo Armv8-A. The first Armv8-A SoC from Samsung is the Exynos 5433 used in the Galaxy Note 4, which features two clusters of four Cortex-A57 and Cortex-A53 cores in a big.LITTLE configuration; but it will run only in AArch32 mode.\nTo both AArch32 and AArch64, Armv8-A makes VFPv3/v4 and advanced SIMD (Neon) standard. It also adds cryptography instructions supporting AES, SHA-1/SHA-256 and finite field arithmetic. AArch64 was introduced in Armv8-A and its subsequent revision. AArch64 is not included in the 32-bit Armv8-R and Armv8-M architectures.\nAn ARMv8-A processor can support one or both of AArch32 and AArch64; it may support AArch32 and AArch64 at lower Exception levels and only AArch64 at higher Exception levels. For example, the ARM Cortex-A32 supports only AArch32, the ARM Cortex-A34 supports only AArch64, and the ARM Cortex-A72 supports both AArch64 and AArch32. An ARMv9-A processor must support AArch64 at all Exception levels, and may support AArch32 at EL0.\nArmv8-R.\nOptional AArch64 support was added to the Armv8-R profile, with the first ARM core implementing it being the Cortex-R82. It adds the A64 instruction set.\nArmv9.\nArmv9-A.\nAnnounced in March 2021, the updated architecture places a focus on secure execution and compartmentalisation. The first ARMv9-A processors were released later that year, including the Cortex-A510, Cortex-A710 and Cortex-X2.\nArm SystemReady.\nArm SystemReady is a compliance program that helps ensure the interoperability of an operating system on Arm-based hardware from datacenter servers to industrial edge and IoT devices. The key building blocks of the program are the specifications for minimum hardware and firmware requirements that the operating systems and hypervisors can rely upon. These specifications are:\nThese specifications are co-developed by Arm and its partners in the System Architecture Advisory Committee (SystemArchAC).\nArchitecture Compliance Suite (ACS) is the test tools that help to check the compliance of these specifications. The Arm SystemReady Requirements Specification documents the requirements of the certifications.\nThis program was introduced by Arm in 2020 at the first DevSummit event. Its predecessor Arm ServerReady was introduced in 2018 at the Arm TechCon event. This program currently includes two bands:\nPSA Certified.\nPSA Certified, formerly named Platform Security Architecture, is an architecture-agnostic security framework and evaluation scheme. It is intended to help secure Internet of things (IoT) devices built on system-on-a-chip (SoC) processors. It was introduced to increase security where a full trusted execution environment is too large or complex.\nThe architecture was introduced by Arm in 2017 at the annual TechCon event. Although the scheme is architecture agnostic, it was first implemented on Arm Cortex-M processor cores intended for microcontroller use. PSA Certified includes freely available threat models and security analyses that demonstrate the process for deciding on security features in common IoT products. It also provides freely downloadable application programming interface (API) packages, architectural specifications, open-source firmware implementations, and related test suites.\nFollowing the development of the architecture security framework in 2017, the PSA Certified assurance scheme launched two years later at Embedded World in 2019. PSA Certified offers a multi-level security evaluation scheme for chip vendors, OS providers and IoT device makers. The Embedded World presentation introduced chip vendors to Level 1 Certification. A draft of Level 2 protection was presented at the same time. Level 2 certification became a usable standard in February 2020.\nThe certification was created by PSA Joint Stakeholders to enable a security-by-design approach for a diverse set of IoT products. PSA Certified specifications are implementation and architecture agnostic, as a result they can be applied to any chip, software or device. The certification also removes industry fragmentation for IoT product manufacturers and developers.\nOperating system support.\n32-bit operating systems.\nHistorical operating systems.\nThe first 32-bit ARM-based personal computer, the Acorn Archimedes, was originally intended to run an ambitious operating system called ARX. The machines shipped with RISC OS, which was also used on later ARM-based systems from Acorn and other vendors. Some early Acorn machines were also able to run a Unix port called RISC iX. (Neither is to be confused with RISC/os, a contemporary Unix variant for the MIPS architecture.)\nEmbedded operating systems.\nThe 32-bit ARM architecture is supported by a large number of embedded and real-time operating systems, including:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nMobile device operating systems.\nAs of March 2024, the 32-bit ARM architecture used to be the primary hardware environment for most mobile device operating systems such as the following but many of these platforms such as Android and Apple iOS have evolved to the 64-bit ARM architecture:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFormerly, but now discontinued:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDesktop and server operating systems.\nThe 32-bit ARM architecture is supported by RISC OS and by multiple Unix-like operating systems including:\nPorting to 32- or 64-bit ARM operating systems.\nWindows applications recompiled for ARM and linked with Winelib, from the Wine project, can run on 32-bit or 64-bit ARM in Linux, FreeBSD, or other compatible operating systems. x86 binaries, e.g. when not specially compiled for ARM, have been demonstrated on ARM using QEMU with Wine (on Linux and more), but do not work at full speed or same capability as with Winelib.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nQuick-reference cards.\nOpcodes.\n "}
