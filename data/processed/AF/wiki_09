{"id": "58596", "revid": "36968800", "url": "https://en.wikipedia.org/wiki?curid=58596", "title": "Triple Crown of Thoroughbred Racing", "text": "3-race horse honor in various countries\nThe Triple Crown of Thoroughbred Racing, often shortened to Triple Crown, is a series of horse races for Thoroughbreds, often restricted to three-year-olds. Winning all three of these Thoroughbred horse races is considered the greatest accomplishment in Thoroughbred racing. The term originated in mid-19th-century England and nations where Thoroughbred racing is popular, each having their own Triple Crown series.\nEngland.\nIn England, where the term Triple Crown originated with West Australian's three wins in 1853, it is made up of:\nSince the 2,000 Guineas was first run in 1809, fifteen horses (including three winners of substitute races at Newmarket during the First World War) have won the English Triple Crown. The most recent \u2013 and only winner since World War II \u2013 was Nijinsky, in 1970. For many years, it was considered unlikely that any horse would ever win the English Triple Crown again. In the winter of 2006/2007, however, trainer Jim Bolger was training his unbeaten colt Teofilo for the Triple Crown and bookmaker William Hill plc was offering odds of only 12/1 on Teofilo winning the 2007 Triple Crown. The horse was withdrawn from the 2000 Guineas two days before the race after suffering a setback and never raced again.\nSince Nijinsky, only Nashwan (1989), Sea the Stars (2009) and Camelot (2012) have won both the Guineas and the Derby. Between Reference Point in 1987 and Camelot in 2012, no Derby winner (not even the potential Triple Crown winners Nashwan and Sea the Stars) even entered the St. Leger. This reluctance to compete in the St. Leger is said to be because of the impact it would have on a horse's stud value in a market where speed is preferred to stamina.\nTriple Crown winners.\nFor a list of the annual individual race winners, see English Triple Crown race winners.\nTriple Crown winners:\n\u2020Wartime winners Pommern, Gay Crusader and Gainsborough are not counted, according to many judges, as the three races were all held at Newmarket and racing itself was too disrupted. By this reckoning, there were only 12 triple crown winners, and only three in the 20th century.\nFailed Triple Crown attempts.\nThe following horses won the 2000 Guineas and Derby but were beaten in the St Leger:\nAdditionally:\nFillies Triple Crown.\nThere is also a Fillies Triple Crown for a filly winning the 1,000 Guineas Stakes, Epsom Oaks and St. Leger Stakes. In the past, this was not considered a true Triple Crown as the best fillies would often run in the Derby and Two Thousand Guineas. As this is no longer the case, the Fillies' Triple Crown would now be considered as comparable as the original. Winners of the Fillies Triple Crown are:\nStayers' Triple Crown.\nThe so-called Stayers Triple Crown consists of the most prestigious long-distance races in the British flat racing season:\nUnited States.\nTriple Crown winners.\nIn the United States, the three races that make up the Triple Crown are:\nTriple Tiara.\nThere have been several different versions of the \"Triple Tiara\" (sometimes known as the Filly Triple Crown) in the United States. One of them was a national version that consisted of undercard events on the same weekends as the associated Triple Crown races:\nOnly one filly won this version of the Triple Tiara, Davona Dale in 1979. Few have even tried as the short time between the Kentucky Oaks and Black-Eyed Susan is generally considered too short for fillies.\nThe most commonly accepted version of the Triple Tiara is the American Triple Tiara of Thoroughbred Racing which uses three races from New York. From 1957 to 2002, and 2007 to 2009, these three races were the Acorn Stakes, the Mother Goose Stakes, and the Coaching Club American Oaks. Eight fillies won this version of the New York Triple Tiara:\nIn 2010, the NYRA changed the configuration of the Triple Tiara to include the Alabama Stakes instead of the Mother Goose. As of 2022, no filly has won the reconfigured Triple Tiara.\nNew York Handicap Triple.\nThe New York Handicap Triple is a series of three handicap races run in New York. Although historically notable, the series is now essentially defunct, as two of the races are run on the same day, making a sweep impossible. In addition, only the Metropolitan Handicap maintains a top-level designation and continues to be run as a handicap. The series consists of:\nThe triple has been won by four horses:\nTurf Triple Series.\nIn 2019, the New York Racing Association established two series of races for three-year-olds on the turf: the Turf Trinity and the Turf Tiara. As of 2022, neither has been swept by a singular horse.\nThe Turf Trinity consists of:\nThe Turf Tiara consists of:\nIreland.\nThe Irish Triple Crown, modelled on the English equivalent, consists of:\nFor a list of the annual individual race winners, see Irish Triple Crown race winners.\nOnly two horses have won all three races since the Irish Two Thousand Guineas was first run in 1921:\nCanada.\nThe Canadian Triple Crown consists of:\nTriple Crown winners.\nThe Canadian Triple Crown was established in 1959 and since then seven horses have won it. In 2014, the Hall of Fame decided to honor the five horses who had won the three races before 1959, meaning 12 horses are now officially recognized as winning the Canadian Triple Crown.\nTriple Tiara.\nThe Canadian Triple Tiara consists of:\nAs of 2025, only one filly has won it:\nWestern Canadian Triple Crown.\nOn May 9, 2023, it was announced that Western Canada would have their own Triple Crown, also dubbed the Western Canadian Triple Crown. The Western Canadian Triple Crown consists of:\nAustralia.\nThe Australian Triple Crown comprises the following races:\nThe Australian Triple Crown initially included the Canterbury Guineas, which was replaced with the Randwick Guineas.\nThe Spring Grand Slam.\nThe Spring Grand Slam for older horses consists of:\nThe only horse to win the Spring Grand Slam was the New Zealand bred Rising Fast in 1954.\nThe Two Year Old Triple Crown.\nThe Two-Year-Old Triple Crown, also known as the Two-Year-Old Grand Slam, consists of:\nWinners of the Two-Year-Old Triple Crown:\nNew Zealand.\nThe New Zealand Triple Crown consists of:\nThe New Zealand Triple Crown is also known as the Hawke's Bay Triple Crown or Hastings Triple Crown as all three races are run there.\nThe only horse to win the New Zealand Triple Crown is Melody Belle in 2019.\nNew Triple Crown Series.\nThree new Triple Crown series were announced for the 2019/2020 season. Each series consists of three prestigious Group races with a $100,000 bonus for the winner of all three races.\nThe Weight-For-Age Triple Crown\nThe Sprint Triple Crown\nThe Fillies And Mares Triple Crown\nGermany.\nIn Germany, the Triple Crown (\"Dreifache Krone\") consists of:\nOnly one horse has won the German Triple Crown:\nIn East Germany, the \"Dreifache Krone\" consisted of:\nThree horses won the East German Triple Crown:\nFrance.\nThe French Triple Crown consists of:\nPreviously the French Triple Crown consisted of:\nTwo horses have swept the French Triple Crown:\nThe French Fillies Triple Crown consists of:\nFour fillies have won all three races:\nPreviously the French Triple Crown for fillies consisted of:\nNo filly ever won the series.\nJapan.\nJapan's JRA has two sets of races referred to as Triple Crowns. In addition, the NAR has announced that it would create its own Dirt Triple Crown starting from 2024, comprising the Haneda Hai, Tokyo Derby, and the Japan Dirt Derby.\nJapanese Triple Crown.\nThe Japanese Triple Crown for colts consists of:\nTo date, eight horses have won the Japanese Triple Crown:\nJapanese Triple Tiara.\nThe Japanese Triple Tiara, a triple crown for fillies, consists of:\nFrom 1976 to 1995, the Queen Elizabeth II Commemorative Cup was the third leg.\nTo date, seven horses have won the Japanese Triple Tiara:\nJapanese Dirt Triple Crown.\nThe Japanese Dirt Triple Crown is run by the NAR instead of the JRA. Most dirt racing in Japan is run under the NAR. In 2022 the NAR announced an official Dirt Triple Crown that includes 3 pre-existing domestic Grade 1 races.\nAll 3 races are held at Oi Racecourse in Shinagawa, Tokyo, Japan. Although the Triple Crown is not set to debut until 2024, the three races have all been run since 1999 and have been won by three horses. \nArgentina.\nThe three races that compose the Triple Crown in Argentina are:\nWinners of the Argentinian Triple Crown are:\nA Quadruple Crown adding the Gran Premio Carlos Pellegrini, run over miles on the turf and open to older horses, is also recognised. Winners are:\nThe Argentinian Filly Triple Crown consists of:\nWinners of the Argentinian Filly Triple Crown are:\nAdditionally, a San Isidro Colt Triple Crown and San Isidro Filly Triple Crown are recognised. The San Isidro Colt Triple Crown consists of:\nWinners of the San Isidro Colt Triple Crown are:\nThe San Isidro Filly Triple Crown consists of:\nAs of 2023, no horse has won all three races.\nBrazil.\nBrazil has triple crowns run at multiple tracks, including at Hip\u00f3dromo da G\u00e1vea (Rio de Janeiro) and at Hip\u00f3dromo de Cidade Jardim (S\u00e3o Paulo).\nThe Rio de Janeiro Triple Crown consists of:\nWinners are:\nPrior to 1963, the Rio de Janeiro Triple Crown consisted of the Grande Pr\u00eamio Outono ( on turf), Grande Pr\u00eamio Cruzeiro do Sul, and Grande Pr\u00eamio Distrito Federal ( on turf). From 1963 to 1993, it consisted of the Grande Pr\u00eamio Estado do Rio de Janeiro, Grande Pr\u00eamio Cruzeiro do Sul, and Grande Pr\u00eamio Jockey Club Brasileiro ( on turf). From 1994 to 2003, the order of the Grande Pr\u00eamio Jockey Club Brasileiro and Grande Pr\u00eamio Cruzeiro do Sul were reversed in order. The current configuration started in 2004.\nThe Rio de Janeiro Filly Triple Crown consists of:\nWinners are:\nThe S\u00e3o Paulo Triple Crown consists of:\nWinners are:\nHistorically, the S\u00e3o Paulo Triple Crown ran without the Grande Pr\u00eamio Jockey Club de S\u00e3o Paulo, with the Grande Pr\u00eamio Consagra\u00e7\u00e3o ( on a turf track) being run as the third and final leg.\nThe S\u00e3o Paulo Filly Triple Crown consists of:\nWinners are:\nThe Rio Grande do Sul Triple Crown, as of 1985, consists of:\nWinners are:\nChile.\nThe three races that compose the Triple Crown in Chile are:\nWinners of the Chilean Triple Crown are:\nAdditionally, the Hip\u00f3dromo Chile has multiple recognized Triple Crowns. The Filly Triple Crown consists of:\nThere have been four winners:\nThe Triple Crown consists of:\nThere have been eight winners:\n\u2020 Designates a filly winner\nChile also has a Two-Year-Old Triple Crown, with all three races run on turf at Valparaiso Sporting Club. It consists of:\nThere have been five winners:\nMexico.\nThe Mexican Triple Crown consists of:\nThere have been a total of 9 winners as of 2025:\nThe Mexican Fillies' Triple Crown series consists of :\nAll the races that compose the Mexican Triple Crown and the Mexican Fillies' Triple Crown are hosted at the Hip\u00f3dromo de las Am\u00e9ricas in Mexico City.\nPanama.\nCrown Races.\nThe races that make up the Triple Crown in Panama are held at the Hip\u00f3dromo Presidente Rem\u00f3n and are as follows:\n1. Primera Gema: Cl\u00e1sico Arturo, Eric, Max, Eric Arturo, and Eric Antonio Delvalle (Grade 2) (1800 m)\n2. Segunda Gema: Cl\u00e1sico Augusto Samuel Boyd Paredes and Daniela Boyd (Grade 2) (1800 m)\n3. Tercera Gema: Cl\u00e1sico Carlos Eleta Almar\u00e1n, Fernando Eleta Almar\u00e1n, and Raquel Eleta (Grade 2) (1800 m)\nIn Panamanian racing history, 16 horses have achieved the Triple Crown. Pind\u00edn was the first Triple Crown winner in 1964, while El Rojo was the most recent, securing the title in 2023.\nPeru.\nThe Peruvian Triple Crown consists of:\nWinners are:\nThe Peruvian Filly Triple Crown consists of:\nWinners are:\nA Quadruple Crown adding the Gran Premio Nacional Augusto B. Leguia, run over on a turf track, is also recognised. Winners are:\nHorses that have won any combination of three of the above races are also sometimes considered Triple Crown winners. Horses that have done this are:\nHong Kong.\nThe Triple Crown series at Hong Kong's Sha Tin Racecourse consists of three races at increasingly longer distances. Unlike most other Triple Crown events, these races are not confined to three-year-olds. They are:\nThere have been two horses to win the Hong Kong Triple Crown:\nThere are two other Triple Crown series: the Hong Kong Speed Series and the Four-Year-Old Classic Series.\nHong Kong Speed Series (International Group 1):\nWinners of the Hong Kong Speed Series are:\nFour-Year-Old Classic Series (Domestic Group 1):\nRestricted to four-year-old horses.\nWinners of the Four-Year-Old Classic Series are:\nSouth Korea.\nThe current Triple Crown series that started in 2008 consists of:\nCurrently only one horse has swept this modern version of the Triple Crown\nOriginally the Triple Crown was started a year prior in 2007 and consisted of:\nIn the only year it was run it produced a Triple Crown winner\nItaly.\nThe Triple Crown series consists of:\nThree horses have swept the Italian Triple Crown:\nThe Italian Fillies' Triple Crown consists of:\nNo filly has swept all three races, but Jacopa de Sellaio won the Premio Parioli, Derby Italiano, Premio Regina Elena, and Oaks d'Italia in 1932.\nUruguay.\nThe three races that compose the Triple Crown in Uruguay are:\nThis combination of races received some publicity outside of Uruguay in 2006. The 2005 Triple Crown winner Invasor, after being sold to Sheik Hamdan bin Rashid Al Maktoum's Shadwell Racing and sent to be raced in the United States, went on to win three Grade I races in 2006 before winning that year's Breeders' Cup Classic. He finished the year as the top-ranked horse in the 2006 World Thoroughbred Racehorse Rankings, and won the 2007 Dubai World Cup before being retired to stud following a training injury.\nUruguayan Triple Crown winners are:\nThe Uruguayan Filly Triple Crown consists of:\nUruguayan Filly Triple Crown winners are:\nSouth Africa.\nThe South African Triple Crown consists of:\nAll of these races are run on a turf track at Turffontein Racecourse.\nThe Cape Guineas, run over on a turf track at Kenilworth Racecourse is considered an alternate first leg.\nSouth African Triple Crown winners are:\nThe South African Filly Triple Crown consists of:\nSouth African Filly Triple Crown winners are:\nZimbabwe.\nThe Zimbabwean Triple Crown consists of:\nAll of these races are run on a turf track at Borrowdale Park\nZimbabwean Triple Crown winners are:\nOther Triple Crowns in European countries.\nBelgium.\nThe Belgian Triple Crown consists of:\nKnown Triple Crown winners in Belgium are:\nThe Fillies' Triple Crown in Belgium consists of:\nOne filly is known to have won all three races:\nHungary.\nThe Hungarian Triple Crown consists of:\nHungarian Triple Crown winners are:\nThe Hungarian Fillies' Triple Crown (not officially listed by the Hungarian racing authorities) consists of:\nNo filly has swept the Hungarian Fillies' Triple Crown.\nSwitzerland.\nIn Switzerland, the Triple Crown series consists of:\nThe Swiss Fillies Triple Crown consists of:\nOne horse has won the Swiss Triple Crown.\nDenmark.\nIn Denmark, the Triple Crown series consists of:\nThree horses have won the Danish Triple Crown:\nThe Danish Filly Triple Crown consists of:\nOne filly has swept all three races:\nRossard was one of the most successful runners in Denmark's history, being a Grade One winner in the US. She later became a good broodmare, with her son Unusual Heat being a leading sire in California.\nRussia.\nThe Russian Triple Crown differs from other Triple Crowns in a major way by instead having its three jewels be spread out over three years. The Triple Crown consists of:\nCurrently only three horses have won this version of the Triple Crown\nThere is a more traditional 3-year-old triple crown in Russia modeled after the English Triple Crown but no horse has ever won all three races. But if they did they would have to win;\nSweden.\nThe Swedish Triple Crown consists of:\nThree horses have swept the Swedish Triple Crown:\nThe Swedish Filly Triple Crown consists of:\nOne filly has swept all three races:\nNorway.\nThe Norwegian Triple Crown series consists of:\nEight horses have swept the Norwegian Triple Crown:\nThe Norwegian Filly Triple Crown consists of:\nNo filly has won all three races.\nThe Netherlands.\nThe Dutch Triple Crown consists of:\nThe following horses have won the Dutch Triple Crown:\nThe Dutch Fillies' Triple Crown consists of:\nThe following horses have swept the series:\nThe Dutch Triple Crown races, except the Dutch Derby and possibly the Dutch Oaks, have not been run since around 2008.\nTurkey.\nThe Turkish Triple Crown consists of:\nChampions of the Turkish Triple Crown are:\nThe Turkish Fillies' Triple Crown (not officially recognized by Turkish racing authorities) consists of:\nFillies that have swept this series are:\nSpain.\nThe Spanish Triple Crown series consists of:\nTwo horses have swept the Spanish Triple Crown:\nThe Triple Crown for fillies consists of:\nOne filly has swept all three races:\nPoland.\nIn Poland, the Triple Crown (\"Potr\u00f3jna korona\") consists of:\nKnown Polish Triple Crown winners are:\nThe classic races for fillies are:\nNo filly is known to have won the Polish Fillies' Triple Crown, which would conclude with the St. Leger. The Polish St. Leger is now open to 3-year-olds and up.\nCzechia.\nIn Czechia, the Triple Crown (\"Klasick\u00e1 trojkoruna\") consists of\nAll three jewels are held at Prague-Velk\u00e1 Chuchle Racecourse currently seven horses have won this Triple Crown\nTriple Crowns in other countries.\nIndia.\nThe Indian Triple Crown consists of:\nAll three races are run at Mahalaxmi Racecourse in Mumbai. The St. Leger was run at Pune between 1970 and 1990, before being shifted to Mumbai. It is now again being run in Pune.\nTen horses have won the Indian Triple Crown:\nThe Indian Fillies Triple Crown consists of:\nOne filly has swept the series for fillies:\nKenya.\nThe Kenya Triple Crown series is run at Ngong Racecourse, in Nairobi, and consists of:\nThe three races have been won by:\nThe Kenya Fillies' Triple Crown consists of:\nThe three races have been won by:\nMacau.\nIn Macau, the Macau Jockey Club introduced the Triple Crown Series in 2008, with three races all held in Taipa Racecourse, Macau:\nIn 2009 Macau Jockey Club changed the series for 4-year-old horses:\nIn 2010, Luen Yat Forever became the first and, before the Macau Jockey Club stopped holding races from 31 March 2024, the only horse to win the Macau Triple Crown.\nBarbados.\nThe Barbados Triple Crown of Thoroughbred Racing is a series of thoroughbred horse races run annually at Garrison Savannah Racetrack near Bridgetown, Barbados, consisting of races of increasing distance:\nThe winners of the Barbados Triple Crown have been:\nDominican Republic.\nThe three races that compose the Triple Crown in the Dominican Republic are:\nThe winners of the Dominican Republic Triple Crown have been:\nJamaica.\nThe Jamaican Triple Crown series at Caymanas Park consists of:\nThe winners of the Jamaican Triple Crown are:\nThe Jamaican Fillies' Triple Crown at Caymanas Park consists of:\nThe winners of the Jamaican Fillies' Triple Crown are:\nPanama.\nThe Panamanian Triple Crown consists of:\nAll of the races are conducted at the Hip\u00f3dromo Presidente Remon\nThe winners of the Panamanian Triple Crown have been:\nThe Panamanian Filly Triple Crown consists of:\nWinners of the Panamanian Filly Triple Crown include:\nPuerto Rico.\nThe Triple Crown series at Puerto Rico's Camarero Racetrack consists of three races at increasingly longer distances. They are:\nThe Puerto Rico Triple Crown winners are:\nEcuador.\nEcuador has two sets of races referred to as Triple Crowns:\nEcuador Triple Crown\nEcuador Fillies' Triple Crown\nIn Ecuador, the Triple Crown consists of:\nWinners of the Ecuadoran Triple Crown are:\nVenezuela.\nVenezuela has two sets of races referred to as Triple Crowns.\nThe Venezuelan Official Triple Crown consists of:\nWinners of the Venezuelan Triple Crown, since 1956, are:\nThe Venezuelan Fillies' Triple Crown consists of:\nFilly Triple Crown winners are:\nIndonesia.\nThe Indonesian Triple Crown consists of\nIndonesian Triple Crown winners are: \nNote that thoroughbred horses are not eligible to run at the Indonesian Triple Crown, since the event is limited to only local breeds like Sandalwood Pony, crossbreeds (known locally as \"G Horses\"), or \"Kuda Pacu Indonesia\"/KPI (crosses between crossbreeds). No Triple Crown for thoroughbred racing is organized by PORDASI, as races exclusively for thoroughbreds are only held in two non-derby classes.\nPhilippines.\nThe Triple Crown Stakes backed by the Philippine Racing Commission (Philracom). It was first organized in 1978, but a horse did not sweep all three races until 1981, when Fair and Square achieved that feat, becoming the series' first Triple Crown champion.\nThe races are held at various venues throughout its history. The first two legs of the series have traditionally been referred to as the Cojuangco Cup and the J.V. Ongpin Cup, respectively, while the final leg has been known as the Horseman's Cup. However, recent editions commonly refer to the races simply by their order as legs of the Triple Crown series.\nIts winners include:\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nIn 2025, the Metro Manila Turf Club introduced two new Triple Crown\u2011style stakes races: the Prince Cup and the King's Gold Cup. Each tournament consists of three legs and is restricted to horses foaled outside the Philippines. The first editions are still ongoing and hence no horse has made a sweep in either tournaments.\nTrinidad and Tobago.\nThe three races that compose the triple crown of Trinidad and Tobago were established in 1983 and they are:\nThe Trinidad and Tobago triple crown winners are\nPre 1983:\nAfter 1983:\nUndefeated Triple Crown winners.\nThe following horses won their Triple Crown when still undefeated. Those marked with an asterisk retired undefeated.\n\u2020Although Justify finished first in all of his races, litigation filed by the owners of Bolt d'Oro in 2020 called for Justify's disqualification from the 2018 Santa Anita Derby over a positive drug test for scopolamine, a known environmental contaminant. A Los Angeles County Superior Court judge ordered Justify's disqualification, for which Justify's connections have filed an appeal. The appeal is pending.\nIndividual Triple Crown winners.\nOnly three jockeys have won the Triple Crown with different horses (i.e., rode horses to Triple Crowns in different years):\nAt least two jockeys is known to have won all three of a country's Triple Crown races in the same year on different horses:\nOne trainer is known to have accomplished the same feat as Contreras and Garc\u00eda Paduani:\nBack to back Triple Crown winners (jockeys).\nDon Seymour (Canada)\nJavier Santiago (Puerto Rico)\nMost Triple Crown winners (jockeys).\nWinston Grifiths \u2013 Jamaica (5)\nAlexis Feliciano \u2013 Puerto Rico (3)\nEmisael Jaramillo \u2013 Venezuela (3)\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "58597", "revid": "49695808", "url": "https://en.wikipedia.org/wiki?curid=58597", "title": "Palestinian Academic Society for the Study of International Affairs", "text": "Jerusalem-based research institution\nThe Palestinian Academic Society for the Study of International Affairs (PASSIA; ) was founded in Jerusalem in March 1987 by Dr. Mahdi Abdul Hadi and a group of Palestinian academics and intellectuals. PASSIA is a member of the Palestinian NGOs Network and claims no affiliation with any government, political party organization. PASSIA deals with the various national, Arab and international aspects of the Palestinian Question through its academic Research Studies Program, dialogue and publication.\nA major component of PASSIA\u2019s activities is its Roundtable Meetings Program, and with over 100 publications to its credit, many of which include the minutes of these meetings. As part of its Religious Studies Unit PASSIA also holds regular meetings with religious leaders (mainly local Muslim and Christian dignitaries, but also involving Jews and foreign scholars) in an effort to foster scholarly understanding.\nIts Seminar Program provides a venue for Palestinian graduates to benefit from the experience and knowledge of local and foreign experts. PASSIA\u2019s educational and training seminars are divided into two categories: International Affairs \u2013 including seminars on Diplomacy and Conflict Resolution, Strategic Studies and Security, the EU, Education on Democracy, The Foreign Policies of Arab States, Japan and the Middle East, and The United States and Canada: Political Systems, Policy-Making and the Middle East \u2013 and Civil Society Empowerment, with seminars held to date including those on Policy-Making, Strategic Planning &amp; Media &amp; Communication Skills.\nJerusalem is the focus of the majority of PASSIA\u2019s activities. PASSIA hosts regular workshops that address different but inter-connected issues pertaining to Jerusalem. In these meetings, as during all other events held at PASSIA, it is the desire to promote communication, cooperation and coordination between those with an interest in the fate of this region that overrides any other consideration, and which inevitably results in a dialogue that is as stimulating as it is productive.\nPASSIA Publications.\nPASSIA seeks to present the Palestine Question in its national, Arab and international contexts through academic research, dialogue, education, documentation and publication. PASSIA works to achieve its goals through the implementation of the following regular programs: Research, Dialogue, Training and Education in International Affairs, Civil Society Empowerment, Religious Studies, the Question of Jerusalem, and the annual PASSIA Diary.\nPASSIA has dedicated a large part of its various program and project activities to the provision of background information, in-depth studies and documentation on issues of concern, as well as the promotion of a better understanding of the Palestinian cause. PASSIA publications aim to be specialized, scientific and objective, yet they often address controversial or neglected issues and allow the expression of a wide range of perspectives. The authors of PASSIA publications throughout the years have been as diverse as the subjects covered and include Palestinian, Arab, Israeli and inter national academics, scholars and experts.\nPASSIA publications are classified as follows: "}
{"id": "58598", "revid": "95921", "url": "https://en.wikipedia.org/wiki?curid=58598", "title": "State court (United States)", "text": "Court with jurisdiction over disputes with some connection to a U.S. state\nIn the United States, a state court is a court of law with jurisdiction over disputes with some connection to a U.S. state. State courts handle the overwhelming majority of civil and criminal cases in the United States; the United States federal courts are far smaller in terms of both personnel and caseload, and handle different types of cases. The number of cases filed in state courts each year surpasses the number of cases filed in federal courts by a factor of over two hundred. States often provide their trial courts with general jurisdiction (the hearing of all matters in which personal jurisdiction exists and which are not committed to another court) and state trial courts regularly have concurrent jurisdiction with federal courts. Federal courts are courts of limited jurisdiction and their subject-matter jurisdiction arises only under federal law.\nEach state \"is free to organize its courts as it sees fit,\" and consequently, \"no two states have identical court structures.\" Generally, state courts are common law courts, and apply their respective state laws and procedures to decide cases. They are organized pursuant to and apply the law in accordance with their state's constitution, state statutes, and binding decisions of courts in their state court hierarchy. Where applicable, they also apply federal law, or need to make a choice of law from another jurisdiction.\nGenerally, a single judicial officer, usually called a judge, exercises original jurisdiction by presiding over contested criminal or civil actions which culminate in trials, which may include empaneling a jury, although most matters stop short of reaching trial. The decisions of lower courts may be reviewed by a panel of a state intermediate appellate court. Generally, there is also a highest court for appeals, a state supreme court, that oversees the court system. In matters that involve issues of federal law, the final decision of the state's highest court (including refusals to hear final appeals) may be appealed to the United States Supreme Court (which also has the discretion to refuse to hear them).\nTypes of state courts.\nTrial court.\nCases in state courts begin in a trial court where lawsuits and criminal cases are filed and evidence is eventually presented if a case proceeds to a hearing or trial. Trials in these courts are often held only after extensive pretrial procedures that in more than 90% of cases lead to a default judgment in a civil case, an agreed resolution settling the case or plea bargain resolving a criminal case, or pretrial resolution of the case by a judge either on the merits or on procedural grounds. \nOn the one hand, the United States has a well-deserved reputation as one of the most litigious places in the world: \"American society is somewhat exceptional not only in the frequency with which Americans resort to court to settle their disputes but, more significantly, the scope and importance of social and economic issues that are confided to the private litigation process\". On the other hand, very few cases actually go to a jury verdict and a final judgment, let alone an appeal that results in a published appellate opinion. A 2015 empirical study examined 8,038 cases that went to trial in state-level trial courts and found that only 24 (0.3%) resulted in a judicial opinion from the state supreme court. In other words, the reported case law studied in American law schools does not reflect the way the vast majority of cases are handled and resolved\u2014by \"bargain[ing] [in the] shadow of the law\".\nTerritory outside of any state in the United States, such as the District of Columbia or American Samoa, often has a court system established under federal or territorial law which substitutes for a state court system and is distinct from the ordinary federal court system.\nState trial courts are usually located in a courthouse, which is often in the county seat. Even when state trial courts include more than one county in a judicial district, it is not uncommon for the state trial court to hold regular sessions at each county seat in its jurisdiction and function from the point of view of litigants as if it were a county-based court.\nAppellate court.\nIf one of the litigants is unsatisfied with the decision of the lower court, the matter may be taken up on appeal. However, an acquittal in a criminal trial cannot be appealed by the state because of the Fifth Amendment protection against double jeopardy. Usually, an intermediate appellate court, if there is one in that state, often called the state court of appeals, will review the decision of the trial court. If still unsatisfied, the litigant can appeal to the highest appellate court in the state, which is usually called the state supreme court and is usually located in or near the state's capital city. Appellate courts in the United States, unlike their civil law counterparts, are generally not permitted to correct mistakes concerning the facts of the case on appeal, only mistakes of law, or findings of fact with no support in the trial court record.\nCourts of inferior jurisdiction.\nMany states have courts of limited jurisdiction (inferior jurisdiction), presided over by, for example, a magistrate or justice of the peace who hears criminal arraignments and tries petty offenses and small civil cases. Appeals from courts of limited jurisdiction are frequently sent to state trial courts of general jurisdiction rather than to an appellate court. As of 2014, the United States had over 13,500 courts of limited jurisdiction. Most of these courts were small one-judge courts, meaning that these courts were staffed by approximately 18,500 judicial officers. \nLarger cities often have city courts (also known as municipal courts) which hear traffic offenses and violations of city ordinances; in some states, such as New York, these courts have slightly broader jurisdiction and can also handle small claims and misdemeanors. Other courts of limited jurisdiction include alderman's courts, police court, mayor's courts, recorder's courts, county courts, probate courts, municipal courts, juvenile courts, courts of claims, courts of common pleas, family courts, small claims courts, tax courts, water courts (present in some western states such as Colorado and Montana), and workers' compensation courts (Rhode Island).\nLawrence M. Friedman has described courts of limited jurisdiction as \"the bargain basement of justice,\" where procedures are often informal and \"slapdash\" and the quality of justice is poor. In states that still use justices of the peace or equivalent judicial officers, many judges of courts of limited jurisdiction are laypersons who never attended law school or passed a bar examination. As of 2020, 26 states still allowed such nonlawyers to preside as judges in courts of limited jurisdiction. The low pay and low status of such positions tends to attract candidates with terrible educational qualifications; a 1976 survey found that somewhere between one-third and one-half of judges of courts of limited jurisdiction in California had not even completed high school. There is widespread anecdotal and empirical evidence that lay judges are prone to ignoring the law and issuing arbitrary rulings. \nThe issues that inevitably result from the lack of a law-trained judge are compounded by the complete absence of lawyers on both sides of a case in some of the poorest states. For example, in South Carolina, \"one of the poorest states in the country\", a criminal defendant prosecuted in a court of limited jurisdiction in that state may be arrested, prosecuted, tried, and convicted without ever encountering a single lawyer. The police in South Carolina often act as the prosecutor. \nCourts of limited jurisdiction should not be confused with the administrative courts seen in other countries. The United States does not use administrative courts, as a result of the strict separation of powers imposed by the United States Constitution. Instead, at both the federal and state levels, administrative law judges (ALJs) preside over tribunals within executive branch agencies (although their decisions can usually be appealed to real judges in the judicial branch). In state governments, ALJs handle matters such as driver's license revocations, workers' compensation claims, unemployment insurance claims, and land use disputes.\nSuperior court.\nAll these courts are distinguished from courts of general jurisdiction (also known as \"superior jurisdiction\"), which are the default type of trial court that can hear any case which is not required to be first heard in a court of limited jurisdiction. Most such cases are civil cases involving large sums of money or criminal cases arising from serious felonies like rape and murder. Typically, felonies are handled in general jurisdiction courts, while misdemeanors and other lesser offenses are handled in inferior jurisdiction courts. Unlike most European courts (in both common law and civil law countries), American state courts do not usually have a separate court that handles serious crimes; jurisdiction lies with the court that handles all other felony cases in a given county. \nMany state courts that handle criminal cases also have separate divisions or judges assigned to handle certain types of cases, known as \"problem-solving courts\". Problem-solving courts are part of a larger reform effort known as therapeutic jurisprudence which attempts to address underlying issues which lead to the same people repeatedly appearing in criminal courts, in order to reduce recidivism. Examples of such courts include drug court, domestic violence court, and mental health court. \nAll states have courts of general jurisdiction, but only some have courts of limited jurisdiction. Courts of general jurisdiction tend to be better funded, better staffed, more professional, more dignified, and more solemn than courts of limited jurisdiction. They also tend to have jurisdiction over larger geographical areas and more people. As of 2014, the United States had approximately 2,000 state trial courts of general jurisdiction. These courts were staffed by approximately 11,000 judges. \nA few states like California have unified all courts of general and inferior jurisdiction to make the judicial process more efficient. In such courts, there may be divisions that specialize in hearing particular types of proceedings, but from the perspective of the judges, these are mere administrative assignments. In such courts, every judge is deemed to be \"qualified to hear every type of proceeding, enhancing administrative flexibility and ending the possibility of a judgment being invalidated because it was heard in the wrong court\". As of 2014, the six jurisdictions which had fully unified all trial courts and no longer used courts of limited jurisdiction were California, Iowa, Illinois, Minnesota, the District of Columbia, and Puerto Rico.\nState court judges.\nUnlike federal courts, where judges are presidential appointees confirmed by the U.S. Senate serving life terms of office, the vast majority of states have some judges who are elected, while some judges are appointed. The methods of judicial appointment vary widely.\nThe American habit of electing state court judges originates with Alexander Hamilton and Federalist No. 78, in which Hamilton brought about a fundamental reconceptualization of the idea of separation of powers with respect to the judiciary. Before Hamilton, both English and American people had thought of judges as mere appendages of royal authority, and that a government had only two branches, the executive and the legislative. Hamilton implied and others later developed the idea that American judges were coequal to legislatures and executives in their responsibility to carry out the people's will (popular sovereignty), which extended to the power to make law (through case law). Therefore, if the judiciary was a coequal third branch of government, and the judges were the people's agents, then like the other branches, they ought to be elected by the people. However, problems with partisan judicial elections led many states to later adopt judicial appointment systems, while also using retention elections as a check on appointed judges.\nState court judges are usually distinguished attorneys who have had some political involvement, who are pursuing second careers on the bench. But a small number of state court judges, particularly in limited jurisdiction trial courts in rural areas or small towns, are nonlawyers, who are often elected to their posts.\nA disproportionate share of state court judges previously served as prosecutors, or less commonly as criminal defense attorneys or trial lawyers, although no particular background as an attorney is required to serve as a judge. The judiciary is not a separate profession in the American legal system as it is in many civil law jurisdictions. While in many civil law jurisdictions a common judicial career involves an entry-level assignment in an inferior court followed by promotions to more senior courts over the course of a career, no U.S. court system makes experience in an inferior judicial position a prerequisite to higher judicial office.\nWhile many countries consider criminal prosecutors to be part of the judicial branch, in the United States, all criminal prosecutors are considered part of the executive branch. The fact that all attorneys admitted to the practice of law are somewhat confusingly called \"officers of the court\" in U.S. legal practice is a legal fiction that calls attention to the special professional ethical obligations that all lawyers have to the court, and does not mean that all lawyers are employees or agents of the judicial branch.\nState court judges are typically paid less, have smaller staffs, and handle larger caseloads than their counterparts in the federal judiciary.\nOne indicator of the significant disparity in prestige between the federal judiciary and the state judiciaries is the number of judges who go from one to the other. A 2017 study found that of the 3,580 judges then listed in the \"Biographical Directory of Federal Judges\", 911 judges went directly from a state court to a federal court, but only 14 went the other way. The study was expressly limited to analyzing direct movements between judicial systems and did not include judges who had taken other types of jobs when not serving in judicial positions.\nHow many and what level.\nOne of the largest areas of interstate divergence goes to how states conceive of their courts as one court or many courts, and whether their courts are part of the state government itself, or part of local governments (which are creatures of state law but usually enjoy some autonomy from the state government).\nOne difference is whether the state trial court of general jurisdiction is regarded as a single entity or a set of many entities. Some states conceptualize of that court as a single unified court of statewide jurisdiction that merely happens to sit in particular counties or districts, while other states have a set of separate and coequal courts, one for each county or district. The most extreme exponent of the first position is New York, which has a single Supreme Court that sits as a trial court with general jurisdiction throughout the entire state. The most extreme exponent of the second position is Texas, where each trial court is constituted as a legally distinct entity with a single judge. The language in the Texas Constitution requiring one judge per court was not fixed until 1985. Thus, an urban courthouse in Texas normally houses multiple single-judge trial courts sharing concurrent jurisdiction over the same county.\nAnother difference is whether state trial courts, especially courts of limited jurisdiction, are created and funded as components of state government or local governments. There are a great many hybrid systems which lie in between. State courts which operate as part of the state government are more likely to have centralized court administration and oversight, which promotes professionalism and uniformity of procedure. Local courts which operate as parts of local governments tend to see themselves as components of local communities, rather than as agents of the state government impartially applying state law. Local courts are more likely to be integrated into local political machines and are more sensitive to local politics. \nThe most significant danger which arises from the latter arrangement is that in the United States, local governments are also usually responsible for most of the other components of criminal justice, like police, prosecutors, and jails. This clear conflict of interest has resulted in the development of predatory criminal justice systems more focused on sustaining themselves on revenue from excessive penal fines than ensuring the fair administration of justice or protecting the rights of the accused.\nDifferences among the states.\nThe foregoing summary is only a very rough generalization. There are a great many \"oddities\" and \"extra wrinkles\" from one state court system to the next, although the tendency in most states has been towards rationalization and simplification: \"the further back in history one goes, the more confused the situation gets\".\nAdministration.\nIn most, but not all states (California and New York are significant exceptions), the state supreme court or a related administrative body has the power to write the rules of procedure that govern the courts through a rulemaking process. In a minority of the states, criminal and civil procedure are largely governed by state statutes.\nMost states model their general jurisdiction trial court rules closely upon the Federal Rules of Civil Procedure with modifications to address types of cases that come up only in state practice (like traffic violations), and model their professional ethics rules closely upon models drafted by the American Bar Association with minor modifications. A minority of states, however, have idiosyncratic procedural rules, often based on the Field Code in place in many states before the Federal Rules of Civil Procedure were adopted. Importantly, neither California nor New York state follow federal models.\nTypically, state trial courts of limited jurisdiction have generally similar rules to state trial courts of general jurisdiction, but are stripped of rules applicable to special cases like class actions and many pretrial procedures (such as out-of-court discovery in the absence of a court order).\nMost state supreme courts also have general supervisory authority over the state court system. In this capacity they are responsible, for example, for making budget requests and administrative management decisions for the court system as a whole. In most states, such administrative authority has been transferred or delegated to a state judicial council which includes members of lower courts.\nState court regulation of lawyers.\nAll state supreme courts are the \"de jure\" primary regulatory body for all lawyers in their state and determine who can practice law and when lawyers are sanctioned for violations of professional ethical rules, which are generally also put in place as state court rules. (Most federal courts that sit within a particular state usually require lawyers seeking admission to their bars to first obtain admission to that particular state's bar). In all states, such powers have been delegated either to the state bar association or various committees, commissions, or offices directly responsible to the state supreme court. The result is that such subordinate entities generally have original jurisdiction over lawyer admissions and discipline, nearly all \"de facto\" lawyer regulation takes place through such entities, and the state supreme court becomes directly involved only when petitioned to \"not\" ratify the decisions made by some subordinate entity in its name.\nRelationship to federal courts.\nAlthough the United States Constitution and federal laws override state laws where there is a conflict between federal and state law, state courts are not subordinate to federal courts. Rather, as instruments of separate sovereigns (under the U.S. system of dual sovereignty), they are two parallel sets of courts with different but often overlapping jurisdiction. Thus, state courts usually interpret federal law independently of the inferior federal courts. The U.S. Supreme Court is the only court whose interpretation of federal law is always binding upon all federal and state courts. \nAs the U.S. Supreme Court recognized in \"Erie Railroad Co. v. Tompkins\" (1938), no part of the federal Constitution actually grants federal courts the power to directly decide the content of state law. Clause 1 of Section 2 of Article Three of the United States Constitution describes the scope of federal judicial power, but only extended it to \"the Laws of the United States\" and not the laws of the several or individual states.\nThe U.S. Supreme Court can but is not required to review final decisions of state courts, after a party exhausts all remedies up to a request for relief from the state's highest appellate court, if the Court believes that the case involves an important question of federal law. Because of the aforementioned silence in the Constitution (as well as Section 25 of the Judiciary Act of 1789 and successor sections), the Court cannot and \"never\" reviews decisions of state courts that depend entirely on the resolution of a state law issue; there \"must\" be an issue of federal law (such as the federal constitutional right to due process) implicit in the state case before the Court will even agree to hear it. Since there really is no such issue in the vast majority of state cases, the decision of the state supreme court in such cases is effectively final, as any petition for certiorari to the U.S. Supreme Court will be summarily denied without comment.\nNomenclature.\nThe following table notes the names of the courts in the states and territories of the United States. Listed are the principal trial courts of general jurisdiction, the principal intermediate appellate courts, and the state supreme courts.\nCourts are described below in the singular when state law defines only one statewide court of that name (whose judges may be assigned to particular counties, circuits, or districts, but still remain part of a single court). Courts are described below in the plural when they are defined by state law as a set of separate courts, each exercising jurisdiction only over a specifically defined territory within the state.\nIn some states, the number of county-based courts does not exactly match the number of actual counties in the state. This occurs when a single court has jurisdiction over more than one county.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58600", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=58600", "title": "Manual for Courts-Martial", "text": "The Manual for Courts-Martial (MCM) is the official guide to the conduct of courts-martial in the United States military. An Executive Order of the President of the United States, the \"MCM\" details and expands on the military law established in the statute Uniform Code of Military Justice (UCMJ). It gathers both executive orders as well as opinions of said executive orders. The \"MCM\" contains five parts plus 22 appendices:\nIn June 2019, the \"Federal Register\" published the 2019 Manual for Courts-Martial with all recent changes."}
{"id": "58601", "revid": "2156376", "url": "https://en.wikipedia.org/wiki?curid=58601", "title": "Dunkirk (disambiguation)", "text": "Dunkirk (French: \"Dunkerque\") is a town and port in northern France.\nDunkirk or Dunkerque may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nVessels.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "58602", "revid": "188", "url": "https://en.wikipedia.org/wiki?curid=58602", "title": "PASSIA", "text": ""}
{"id": "58604", "revid": "32677190", "url": "https://en.wikipedia.org/wiki?curid=58604", "title": "Easton", "text": "Easton may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nPlaces.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "58606", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=58606", "title": "United States District Court", "text": ""}
{"id": "58607", "revid": "2666701", "url": "https://en.wikipedia.org/wiki?curid=58607", "title": "Hobbit", "text": "Fictional race from J. R. R. Tolkien's legendarium\nHobbits are a fictional race of people in the novels of J. R. R. Tolkien. About half average human height, Tolkien presented hobbits as a variety of humanity, or close relatives thereof. Occasionally known as halflings in Tolkien's writings, they live barefooted, and traditionally dwell in homely underground houses which have windows, built into the sides of hills, though others live in houses. Their feet have naturally tough leathery soles (so they do not need shoes) and are covered on top with curly hair.\nHobbits first appeared in the 1937 children's novel \"The Hobbit\", whose titular Hobbit is the protagonist Bilbo Baggins, who is thrown into an unexpected adventure involving a dragon. In its sequel, \"The Lord of the Rings\", the hobbits Frodo Baggins, Sam Gamgee, Pippin Took, and Merry Brandybuck are primary characters who all play key roles in fighting to save their world (\"Middle-earth\") from evil. In \"The Hobbit\", hobbits live together in a small town called Hobbiton, which in \"The Lord of the Rings\" is identified as being part of a larger rural region called the Shire, the homeland of the hobbits in the northwest of Middle-earth. Some also live in a region east of the Shire, Bree-land, where they co-exist with Men. \nThe origins of the name and idea of \"Hobbits\" have been debated; literary antecedents include Sinclair Lewis's 1922 novel \"Babbitt\", and Edward Wyke Smith's 1927 \"The Marvellous Land of Snergs\". The word \"hobbit\" also appears in a list of ghostly beings in The Denham Tracts (1895), though these bear no similarity to Tolkien's Hobbits. Scholars have noted Tolkien's denial of a relationship with the word \"rabbit\", pointing to several lines of evidence to the contrary. Hobbits are modern, unlike the heroic ancient-style cultures of Gondor and Rohan, with familiar things like umbrellas, matches, and clocks. As such they mediate between the modern world known to readers and the heroic ancient world of Middle-earth. \nHalflings appear as a race in \"Dungeons &amp; Dragons\", and the works of other fantasy authors including Terry Brooks, Jack Vance, and Clifford D. Simak.\nOrigins of the word.\n \nTolkien claimed that he started \"The Hobbit\" suddenly, without premeditation, in the midst of grading a set of student essay exams in 1930 or 1931, writing its famous opening line on a blank piece of paper: \"In a hole in the ground there lived a hobbit\".\nIn English literature.\nThe term \"hobbit\", however, has real antecedents in modern English. One is a fact that Tolkien admitted: the title of Sinclair Lewis's 1922 novel \"Babbitt\", about a \"complacent American businessman\" who goes through a journey of some kind of self-discovery, facing \"near-disgrace\"; the Tolkien scholar Tom Shippey observes that there are some parallels here with Bilbo's own journey.\nAccording to a letter from Tolkien to W. H. Auden, one \"probably ... unconscious\" inspiration was Edward Wyke Smith's 1927 children's book \"The Marvellous Land of Snergs\". Tolkien described the Snergs as \"a race of people only slightly taller than the average table but broad in the shoulders and [who] have the strength of ten men.\"\nAnother possible origin emerged in 1977 when the \"Oxford English Dictionary\" announced that it had found the source that it supposed Tolkien to have used: James Hardy wrote in his 1895 \"The Denham Tracts, Volume 2\": \"The whole earth was overrun with ghosts, boggles ... hobbits, hobgoblins.\" Shippey writes that the list was of ghostly creatures without bodies, nothing like Tolkien's solid flesh-and-blood hobbits. Tolkien scholars consider it unlikely that Tolkien saw the list.\nRabbit.\nAn additional connection is with rabbit, one that Tolkien \"emphatically rejected\", although the word appears in \"The Hobbit\" in connection with other characters' opinions of Bilbo in several places. Bilbo compares himself to a rabbit when he is with the eagle that carries him; the eagle, too, tells Bilbo not to be \"frightened like a rabbit\". The giant bear-man Beorn teases Bilbo and jokes that \"little bunny is getting nice and fat again\", while the dwarf Thorin shakes Bilbo \"like a rabbit\".\nShippey writes that the rabbit is not a native English species, but was deliberately introduced in the 13th century, and has become accepted as a local wild animal. Shippey compares this \"situation of anachronism-cum-familiarity\" with the lifestyle of the Hobbit, giving the example of smoking \"pipeweed\". He argues that Tolkien did not want to write \"tobacco\", as it did not arrive until the 16th century, so Tolkien invented a calque made of English words. \nDonald O'Brien, writing in \"Mythlore\", notes, too, that Aragorn's description of Frodo's priceless \"mithril\" mail-shirt, \"here's a pretty hobbit-skin to wrap an elven-princeling in\", is a \"curious echo\" of the English nursery rhyme \"To find a pretty rabbit-skin to wrap the baby bunting in.\"\nFictional etymology.\nTolkien has King Th\u00e9oden of Rohan say \"the Halflings, that some among us call the Holbytlan\". Tolkien set out a fictional etymology for the word \"Hobbit\" in an appendix to \"The Lord of the Rings\", that it was derived from \"holbytla\" (plural \"holbytlan\"), meaning \"hole-builder\". This was Tolkien's own new construction from Old English \"hol\", \"a hole or hollow\", and \"bytlan\", \"to build\".\nDescription.\nCharacteristics.\nTolkien describes hobbits as between two and four feet (0.6\u20131.2 m) tall, with the average height being . They dress in bright colours, favouring yellow and green. They are usually shy, but are nevertheless capable of great courage and amazing feats under the proper circumstances. They are adept at throwing stones. For the most part, they cannot grow beards, but a few Stoor hobbits can. Their feet are covered with curly hair (usually brown, as is the hair on their heads) and have leathery soles, so Hobbits hardly ever wear shoes. Hobbits are not quite as stocky as the similarly sized dwarves, but still tend to be stout, with slightly pointed ears. Tolkien clarified their appearance in a 1938 letter to his American publisher:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I picture a fairly human figure, not a kind of 'fairy' rabbit as some of my British reviewers seem to fancy: fattish in the stomach, shortish in the leg. A round, jovial face; ears only slightly pointed and 'elvish'; hair short and curling (brown). The feet from the ankles down, covered with brown hairy fur. Clothing: green velvet breeches; red or yellow waistcoat; brown or green jacket; gold (or brass) buttons; [and specifically for Bilbo, in \"The Hobbit\"] a dark green hood and cloak (belonging to a dwarf).\nTolkien presented hobbits as relatives of the human race, or a \"variety\" or separate \"branch\" of humanity. In Tolkien's fictional world, hobbits and other races are aware of the similarities between humans and hobbits (hence the colloquial terms for each other of \"Big People\" and \"Little People\"); nevertheless, hobbits consider themselves a separate people.\nThe race's average life expectancy is 100 years, but some of Tolkien's main Hobbit characters live much longer: Bilbo Baggins and the Old Took are described as living to the age of 130 or beyond, though Bilbo's long lifespan owes much to his possession of the One Ring. Hobbits are considered to \"come of age\" on their 33rd birthday, so a 50-year-old hobbit would be regarded as entering middle-age.\nTypes.\nTolkien devised a fictional history with three types of hobbits, with different physical characteristics and temperaments: \"Harfoots\", \"Fallohides\", and \"Stoors\". By the time of Bilbo and Frodo, these kinds had intermixed for centuries, though unevenly, so that some families and regions skewed more towards descent from one of the three groups.\nThe Harfoots were by far the most numerous group of hobbits and were the first to enter the land of Eriador, which contains the Shire and Bree. They were the smallest in stature, \"browner of skin\" in complexion, and the most typical of the race as described in \"The Hobbit\". They lived in holes, or \"smials\", and had closer relations with Dwarves than other hobbits did. Harfoots tended to live in gentle rolling hill country, and were mostly agrarian. They were the first group to cross the Misty Mountains, settling in the lands around Bree starting in Third Age 1050 (about 2,000 years before the time of Bilbo and Frodo, and five and a half centuries before the founding of the Shire in Third Age 1601). Tolkien coined the term \"Harfoot\" as analogous to \"hairfoot\".\nThe Fallohides were the least numerous, and the second group to enter Eriador. They were generally fair-haired, and taller and slimmer than other Hobbits. While the other two types of hobbit were on average about three and a half feet tall, Fallohides were closer on average to four feet. They were more adventurous than the other breeds and preferred living in woodlands, where they became skilled huntsmen, known for their accuracy with ranged weapons. They had closer relations with Elves, who also tended to live in forests. Due to their contact with the Elves, Fallohides were the first hobbits to learn literacy, and therefore were the only ones who preserved even vague knowledge of their past before crossing the Misty Mountains. The Fallohides crossed into Eriador about a century after the Harfoots did, and settled in the pre-existing Harfoot villages of the Bree-land. Never very numerous, the Fallohides intermixed with and were largely absorbed by the Harfoots during this time, though several prominent families such as the Tooks and the Masters of Buckland had a substantial Fallohide descent, unlike many of the people that they led. After about four centuries, a large expedition of hobbits migrated westward from Bree-land led by the Fallohide brothers Marcho and Blancho, who settled and founded the Shire in TA 1601.\nBilbo and three of the four principal hobbit characters in \"The Lord of the Rings\" (Frodo, Pippin, and Merry) had Fallohide blood through their common ancestor, the Old Took. The one physical description given for Frodo matches this, as Gandalf identifies him as \"taller than some, and fairer than most\". Tolkien created the name from the archaic meanings of English words \"fallow\" and \"hide\", meaning \"pale skin\".\nThe Stoors were the second most numerous group of hobbits and the last to enter Eriador. They were quite different from the other two groups: they were stockier than other hobbits, though slightly shorter, and they were also the only group whose males were able to grow beards. They had an affinity for water, dwelt mostly beside rivers, and were the only hobbits to use boats and swim, activities which other hobbits considered dangerous and frightening. Their hands and feet were also sturdier than those of other hobbits, who generally didn't wear shoes for cushioning their steps, though because the Stoors tended to live near muddy riverbanks they often wore boots to keep their feet dry, making them the only hobbits to use footwear of any kind. Tolkien says they were \"less shy of Men\". The Stoors migrated into Eriador two centuries after the Fallohides did, but instead of settling in Bree-land they headed farther south to Dunland by Third Age 1300, finally migrating to the newly founded Shire in Third Age 1630, the last of the three groups to arrive. The Stoors mostly settled along the banks of the River Brandywine in the east of the Shire, thus many hobbits of Buckland and the Marish were of Stoor descent. Due to the time the Stoors spent living in Dunland before migrating to the Shire, their names have a slight Celtic influence.\nA small group of Stoors did not go as far south as Dunland but settled in the wetlands of the Angle in southern Rhudaur, between Dunland and Bree. When the evil power of Angmar rose in the north many of these Stoors joined their kin in Dunland, but some fled back east over the mountains and settled in the marshes of the Gladden Fields: D\u00e9agol and Sm\u00e9agol/Gollum both belonged to this group. Tolkien used the Old English word \"stor\" or \"stoor\", meaning \"strong\".\nLifestyle and culture.\nIn his writings, Tolkien depicted hobbits as fond of an unadventurous, bucolic and simple life of farming, eating, and socializing, although capable of defending their homes courageously if the need arises. They would enjoy six meals a day, if they could get them. They claimed to have invented the art of smoking pipe-weed. \nThey were extremely \"clannish\" and had strong \"predilections for genealogy\"; accordingly, Tolkien included several Hobbit family trees in \"The Lord of the Rings\". Most hobbits married and had large families, although Bilbo and Frodo were exceptions to this general rule.\nThe hobbits of the Shire developed the custom of giving away gifts on their birthdays, instead of receiving them, although this custom was not universally followed among other hobbit cultures or communities. The term \"mathom\" is used for old and useless objects, but which hobbits are unwilling to throw away. \"Mathoms\" are invariably given as presents many times over, sometimes returning to the original owner, or are stored in a museum (\"mathom-house\").\nThe hobbits had a distinct calendar: every year started on a Saturday and ended on a Friday, with each of the twelve months consisting of thirty days. Some special days did not belong to any month\u2014Yule 1 and 2 (New Year's Eve &amp; New Years Day) and three Lithedays in mid-summer. Every fourth year there was an extra Litheday, most likely as an adaptation, similar to a leap year, to ensure that the calendar remained in time with the seasons.\nHobbits traditionally live in \"hobbit-holes\", or \"smials\", underground homes found in hillsides, downs, and banks, though others lived in houses. It has been suggested that the soil or ground of the Shire consists of loess and that this facilitates the construction of hobbit-holes. Loess is a yellow soil, which would explain the colour of the Brandywine River, and the nature of the bricks made at Stock, the main Shire brickyard. Hobbit architecture favours round doors and windows.\nTolkien likened his own tastes to those of hobbits in a 1958 letter:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nFictional history.\nIn Rhovanion.\nIn their earliest folk tales, hobbits appear to have lived in Rhovanion, in the Valley of Anduin, between Mirkwood and the Misty Mountains. According to \"The Lord of the Rings\", they had lost the genealogical details of how they are related to the Big People. Still, Tolkien clearly states in \"Concerning Hobbits\" that hobbits are not technically a distinct race from Men, the way that Elves or Dwarves are, but branched off from other humans in the distant past of the Elder Days. Many eons later, but still early in the Third Age, the ancient hobbits lived in the valley of the Anduin River, close by the \u00c9oth\u00e9od, the ancestors of the Rohirrim. This led to some contact between the two, and as a result many old words and names in \"Hobbitish\" are derivatives of words in Rohirric (which Tolkien \"translated\" into his text by presenting it as Old English).\nThe Harfoots lived on the lowest slopes of the Misty Mountains in Hobbit-holes dug into the hillsides. They were not only smaller and shorter, but also beard- and bootless. The Stoors lived on the marshy Gladden Fields where the Gladden River met the Anduin, and were broader and heavier in build; and the Fallohides preferred to live in the woods under the Misty Mountains. They were described as fairer of skin and hair, as well as taller and slimmer than the rest of the hobbits.\nMigration to the West.\nIn the Third Age, hobbits undertook the arduous task of crossing the Misty Mountains\u2014a migration period they refer to as the \"Wandering Days\", the earliest remembered time in their history. Reasons for this trek are unknown, but they possibly had to do with Sauron's growing power in nearby Greenwood, which later became known as Mirkwood as a result of the shadow that fell upon it during his search of the forest for the One Ring. Hobbits took different routes in their journey westward, but as they began to settle together in Bree-land, Dunland, and the Angle formed by the rivers Mitheithel and Bruinen, the divisions between the hobbit-kinds began to blur. Shippey explains that the name \"Angle\" has a special resonance, as the name \"England\" comes from the Angle (Anglia) between the Flensburg Fjord and the River Schlei, in the north of Germany next to Denmark, the origin of the Angles among the Anglo-Saxons who founded England. Further, the migrations of the three types of hobbit mirror those of England's founders.\nFoundation of the Shire.\nIn the year 1601 of the Third Age (year 1 in the Shire Reckoning), two Fallohide brothers named Marcho and Blanco gained permission from the King of Arnor at Fornost to cross the River Brandywine and settle on the other side. The new land that they founded on the west bank of the Brandywine was called The Shire. Many hobbits followed them, and by the end of the Third Age most hobbits outside The Shire could be found in their village of Staddle on the southeastern slopes of Bree-hill. However, some also lived with Men in the village of Bree itself and in nearby Archet and Combe.\nOriginally the hobbits of the Shire swore nominal allegiance to the last Kings of Arnor, being required only to acknowledge their lordship, speed their messengers, and keep the bridges and roads in repair. During the final fight against Angmar at the Battle of Fornost, the hobbits maintain that they sent a company of archers to help but this is nowhere else recorded. After the battle, the kingdom of Arnor was destroyed, and in the absence of the king, the hobbits elected a Thain of the Shire from among their own chieftains.\nThe first Thain of the Shire was Bucca of the Marish, who founded the Oldbuck family. However, the Oldbuck family later crossed the Brandywine River to create the separate land of Buckland and the family name changed to the familiar \"Brandybuck\". Their patriarch then became Master of Buckland. With the departure of the Oldbucks/Brandybucks, a new family was selected to have its chieftains be Thain: the Took family (Pippin Took was son of the Thain and would later become Thain himself). The Thain was in charge of Shire Moot and Muster and the Hobbitry-in-Arms, but as the hobbits of the Shire generally led entirely peaceful, uneventful lives the office of Thain came to be seen as something of a formality.\nHobbits first appear in \"The Hobbit\" as the rural people of the Shire; the book tells of the unexpected adventure that happened to one of them, Bilbo, as a party of Dwarves seeks to recover an ancient treasure from the hoard of a dragon. They are again central to \"The Lord of the Rings\", an altogether darker tale, where Bilbo's younger cousin Frodo sets out from the Shire to destroy the Ring that Bilbo had brought home.\nAnalysis.\nMoral significance.\nThe Tolkien critic Paul H. Kocher notes that Tolkien's literary techniques require readers to view hobbits as like humans, especially when placed under moral pressure to survive a war that threatens to devastate their land. Frodo becomes in some ways the symbolic representation of the conscience of hobbits, a point made explicitly in the story \"Leaf by Niggle\" which Tolkien wrote at the same time as the first nine chapters of \"The Lord of the Rings\". Niggle is a painter struggling against the summons of death to complete his one great canvas, a picture of a tree with a background of forest and distant mountains. He dies with the work incomplete, undone by his imperfectly generous heart: \"it made him uncomfortable more often than it made him do anything\". After discipline in Purgatory, however, Niggle finds himself in the very landscape depicted by his painting which he is now able to finish with the assistance of a neighbour who obstructed him during life. The picture complete, Niggle is free to journey to the distant mountains which represent the highest stage of his spiritual development. Thus, upon recovery from the wound inflicted by the Witch-King of Angmar on Weathertop, Gandalf speculates that the hobbit Frodo \"may become like a glass filled with a clear light for eyes to see that can\". Similarly, as Frodo nears Mount Doom he casts aside weapons and refuses to fight others with physical force: \"For him struggles for the right must hereafter be waged only on the moral plane\".\nModern mediators.\nTolkien scholars including Shippey and Dimitra Fimi have stated that the hobbits are misfits in Middle-earth's heroic cultures like Gondor and Rohan. Those have a basis in ancient societies such as ancient Rome and the Anglo-Saxons. In contrast, Tolkien placed the Shire in a society he had personally experienced, \"more or less a Warwickshire village of about the period of the Diamond Jubilee [of Queen Victoria, in 1897]\". Shippey described hobbit culture, complete with tobacco and potatoes, as a \"creative anachronism\" on Tolkien's part. In his view, anachronism is the \"essential function\" of hobbits, enabling Tolkien to \"bridge the gap\" by mediating between readers' lives in the modern world and the dangerous ancient world of Middle-earth. \nFimi comments that this applies both to the style of language used by hobbits, and to their material culture of \"umbrellas, camping kettles, matches, clocks, pocket handkerchiefs and fireworks\", all of which are plainly modern, as are the fish and chips that Sam Gamgee thinks of on his journey to Mordor. Most striking, in her view, however, is Tolkien's description of the enormous dragon firework at Bilbo's party which rushed overhead \"like an express train\". Tolkien's drawing of the hall of Bilbo's home, Bag End, shows both a clock and a barometer (mentioned in an early draft), and he had another clock on his mantelpiece. To arrange a party, hobbits rely on a daily postal service. The effect, the scholars agree, is to bring the reader comfortably into the ancient heroic world.\nIn popular culture.\nFantasy.\n\"Dungeons &amp; Dragons\" began using the name \"halfling\" as an alternative to \"hobbit\" for legal reasons. Fantasy authors including Terry Brooks, Jack Vance, and Clifford D. Simak use races of halflings.\nPeter Jackson's films of \"The Lord of the Rings\" and \"The Hobbit\" made extensive use of prosthetics. W\u0113t\u0101 Workshop spent a year creating hobbit feet to look like large, furry feet, yet act as shoes for the actors. In total, 1,800 pairs were worn by the four lead hobbit actors during production. In addition, actors went in for face casts to create pointed ears and false noses.\n\"\", a series screened from 2022, has attracted \"fierce debate\" about its handling of race, and racism aimed at the actors playing the Harfoots. The fantasy author Neil Gaiman, defending the casting, commented that \"Tolkien described the Harfoots as \"browner of skin\" than the other Hobbits. So I think anyone grumbling is either racist or hasn't read their Tolkien.\" Commentators have observed that the hobbit-like Harfoots speak in Irish accents, behave as friendly peasants, and are accompanied by Celtic music; and that they resemble the 19th century caricaturist John Leech's \"wildly unflattering\" depictions of the Irish in \"Punch\" magazine.\nPopular music.\nThe comic horror rock band Rosemary's Billygoat recorded a song and video called \"Hobbit Feet\", about a man who takes a girl home from a bar only to discover she has horrifying \"hobbit feet\". According to lead singer Mike Odd, the band received over 100 pieces of hate mail from angry Tolkien fans.\nFossil hominids.\nThe skeletal remains of several diminutive paleolithic hominids were discovered on the Indonesian island of Flores in 2004. The fossils, of a species named \"Homo floresiensis\" after the island on which the remains were found, were informally dubbed \"Hobbits\" by their discoverers in a series of articles published in the scientific journal \"Nature\". The excavated skeletons reveal a hominid that (like a Hobbit) grew no larger than a three-year-old modern child and had proportionately larger feet than modern humans.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nPrimary.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSecondary.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58608", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=58608", "title": "Trusted Computing", "text": "Technology developed and promoted by the Trusted Computing Group\nTrusted Computing (TC) is a technology developed and promoted by the Trusted Computing Group. The term is taken from the field of trusted systems and has a specialized meaning that is distinct from the field of confidential computing. With Trusted Computing, the computer will consistently behave in expected ways, and those behaviors will be enforced by computer hardware and software. Enforcing this behavior is achieved by loading the hardware with a unique encryption key that is inaccessible to the rest of the system and the owner.\nTC is controversial as the hardware is not only secured for its owner, but also against its owner, leading opponents of the technology like free software activist Richard Stallman to deride it as \"treacherous computing\", and certain scholarly articles to use scare quotes when referring to the technology.\nTrusted Computing proponents such as International Data Corporation, the Enterprise Strategy Group and Endpoint Technologies Associates state that the technology will make computers safer, less prone to viruses and malware, and thus more reliable from an end-user perspective. They also state that Trusted Computing will allow computers and servers to offer improved computer security over that which is currently available. Opponents often state that this technology will be used primarily to enforce digital rights management policies (imposed restrictions to the owner) and not to increase computer security.\nChip manufacturers Intel and AMD, hardware manufacturers such as HP and Dell, and operating system providers such as Microsoft include Trusted Computing in their products if enabled. The U.S. Army requires that every new PC it purchases comes with a Trusted Platform Module (TPM). As of July 3, 2007, so does virtually the entire United States Department of Defense.\nKey concepts.\nTrusted Computing encompasses six key technology concepts, of which all are required for a fully Trusted system, that is, a system compliant to the TCG specifications:\nEndorsement key.\nThe endorsement key is a 2048-bit RSA public and private key pair that is created randomly on the chip at manufacture time and cannot be changed. The private key never leaves the chip, while the public key is used for attestation and for encryption of sensitive data sent to the chip, as occurs during the TPM_TakeOwnership command.\nThis key is used to allow the execution of secure transactions: every Trusted Platform Module (TPM) is required to be able to sign a random number (in order to allow the owner to show that he has a genuine trusted computer), using a particular protocol created by the Trusted Computing Group (the direct anonymous attestation protocol) in order to ensure its compliance of the TCG standard and to prove its identity; this makes it impossible for a software TPM emulator with an untrusted endorsement key (for example, a self-generated one) to start a secure transaction with a trusted entity. The TPM should be designed to make the extraction of this key by hardware analysis hard, but tamper resistance is not a strong requirement.\nMemory curtaining.\nMemory curtaining extends common memory protection techniques to provide full isolation of sensitive areas of memory\u2014for example, locations containing cryptographic keys. Even the operating system does not have full access to curtained memory. The exact implementation details are vendor specific.\nSealed storage.\nSealed storage protects private information by binding it to platform configuration information including the software and hardware being used. This means the data can be released only to a particular combination of software and hardware. Sealed storage can be used for DRM enforcing. For example, users who keep a song on their computer that has not been licensed to be listened will not be able to play it. Currently, a user can locate the song, listen to it, and send it to someone else, play it in the software of their choice, or back it up (and in some cases, use circumvention software to decrypt it). Alternatively, the user may use software to modify the operating system's DRM routines to have it leak the song data once, say, a temporary license was acquired. Using sealed storage, the song is securely encrypted using a key bound to the trusted platform module so that only the unmodified and untampered music player on his or her computer can play it. In this DRM architecture, this might also prevent people from listening to the song after buying a new computer, or upgrading parts of their current one, except after explicit permission of the vendor of the song.\nRemote attestation.\nRemote attestation allows changes to the user's computer to be detected by authorized parties. For example, software companies can identify unauthorized changes to software, including users modifying their software to circumvent commercial digital rights restrictions. It works by having the hardware generate a certificate stating what software is currently running. The computer can then present this certificate to a remote party to show that unaltered software is currently executing. Numerous remote attestation schemes have been proposed for various computer architectures, including Intel, RISC-V, and ARM.\nRemote attestation is usually combined with public-key encryption so that the information sent can only be read by the programs that requested the attestation, and not by an eavesdropper.\nTo take the song example again, the user's music player software could send the song to other machines, but only if they could attest that they were running an authorized copy of the music player software. Combined with the other technologies, this provides a more restricted path for the music: encrypted I/O prevents the user from recording it as it is transmitted to the audio subsystem, memory locking prevents it from being dumped to regular disk files as it is being worked on, sealed storage curtails unauthorized access to it when saved to the hard drive, and remote attestation prevents unauthorized software from accessing the song even when it is used on other computers. To preserve the privacy of attestation responders, Direct Anonymous Attestation has been proposed as a solution, which uses a group signature scheme to prevent revealing the identity of individual signers.\nProof of space (PoS) have been proposed to be used for malware detection, by determining whether the L1 cache of a processor is empty (e.g., has enough space to evaluate the PoSpace routine without cache misses) or contains a routine that resisted being evicted.\nKnown applications.\nThe Microsoft products Windows Vista, Windows 7, Windows 8 and Windows RT make use of a Trusted Platform Module to facilitate BitLocker Drive Encryption. Other known applications with runtime encryption and the use of secure enclaves include the Signal messenger and the e-prescription service (\"E-Rezept\") by the German government.\nPossible applications.\nDigital rights management.\nTrusted Computing would allow companies to create a digital rights management (DRM) system which would be very hard to circumvent, though not impossible. An example is downloading a music file. Sealed storage could be used to prevent the user from opening the file with an unauthorized player or computer. Remote attestation could be used to authorize play only by music players that enforce the record company's rules. The music would be played from curtained memory, which would prevent the user from making an unrestricted copy of the file while it is playing, and secure I/O would prevent capturing what is being sent to the sound system. Circumventing such a system would require either manipulation of the computer's hardware, capturing the analogue (and thus degraded) signal using a recording device or a microphone, or breaking the security of the system.\nNew business models for use of software (services) over Internet may be boosted by the technology. By strengthening the DRM system, one could base a business model on renting programs for a specific time periods or \"pay as you go\" models. For instance, one could download a music file which could only be played a certain number of times before it becomes unusable, or the music file could be used only within a certain time period.\nPreventing cheating in online games.\nTrusted Computing could be used to combat cheating in online games. Some players modify their game copy in order to gain unfair advantages in the game; remote attestation, secure I/O and memory curtaining could be used to determine that all players connected to a server were running an unmodified copy of the software.\nVerification of remote computation for grid computing.\nTrusted Computing could be used to guarantee participants in a grid computing system are returning the results of the computations they claim to be instead of forging them. This would allow large scale simulations to be run (say a climate simulation) without expensive redundant computations to guarantee malicious hosts are not undermining the results to achieve the conclusion they want.\nCriticism.\nThe Electronic Frontier Foundation and the Free Software Foundation criticize that trust in the underlying companies is not deserved and that the technology puts too much power and control into the hands of those who design systems and software. They also state that it may cause consumers to lose anonymity in their online interactions, as well as mandating technologies Trusted Computing opponents say are unnecessary. They suggest Trusted Computing as a possible enabler for future versions of mandatory access control, copy protection, and DRM.\nSome security experts, such as Alan Cox and Bruce Schneier, have spoken out against Trusted Computing, believing it will provide computer manufacturers and software authors with increased control to impose restrictions on what users are able to do with their computers. There are concerns that Trusted Computing would have an anti-competitive effect on the IT market.\nThere is concern amongst critics that it will not always be possible to examine the hardware components on which Trusted Computing relies, the Trusted Platform Module, which is the ultimate hardware system where the core 'root' of trust in the platform has to reside. If not implemented correctly, it presents a security risk to overall platform integrity and protected data. The specifications, as published by the Trusted Computing Group, are open and are available for anyone to review. However, the final implementations by commercial vendors will not necessarily be subjected to the same review process. In addition, the world of cryptography can often move quickly, and that hardware implementations of algorithms might create an inadvertent obsolescence. Trusting networked computers to controlling authorities rather than to individuals may create digital imprimaturs.\nCryptographer Ross Anderson, University of Cambridge, has great concerns that:\nTC can support remote censorship [...] In general, digital objects created using TC systems remain under the control of their creators, rather than under the control of the person who owns the machine on which they happen to be stored [...] So someone who writes a paper that a court decides is defamatory can be compelled to censor it \u2014 and the software company that wrote the word processor could be ordered to do the deletion if she refuses. Given such possibilities, we can expect TC to be used to suppress everything from pornography to writings that criticize political leaders.\nHe goes on to state that:\n[...] software suppliers can make it much harder for you to switch to their competitors' products. At a simple level, Word could encrypt all your documents using keys that only Microsoft products have access to; this would mean that you could only read them using Microsoft products, not with any competing word processor. [...]\nThe [...] most important benefit for Microsoft is that TC will dramatically increase the costs of switching away from Microsoft products (such as Office) to rival products (such as OpenOffice). For example, a law firm that wants to change from Office to OpenOffice right now merely has to install the software, train the staff and convert their existing files. In five years' time, once they have received TC-protected documents from perhaps a thousand different clients, they would have to get permission (in the form of signed digital certificates) from each of these clients in order to migrate their files to a new platform. The law firm won't in practice want to do this, so they will be much more tightly locked in, which will enable Microsoft to hike its prices.\nAnderson summarizes the case by saying:\nThe fundamental issue is that whoever controls the TC infrastructure will acquire a huge amount of power. Having this single point of control is like making everyone use the same bank, or the same accountant, or the same lawyer. There are many ways in which this power could be abused.\nDigital rights management.\nOne of the early motivations behind trusted computing was a desire by media and software corporations for stricter DRM technology to prevent users from freely sharing and using potentially copyrighted or private files without explicit permission.\nAn example could be downloading a music file from a band: the band's record company could come up with rules for how the band's music can be used. For example, they might want the user to play the file only three times a day without paying additional money. Also, they could use remote attestation to only send their music to a music player that enforces their rules: sealed storage would prevent the user from opening the file with another player that did not enforce the restrictions. Memory curtaining would prevent the user from making an unrestricted copy of the file while it is playing, and secure output would prevent capturing what is sent to the sound system.\nUsers unable to modify software.\nA user who wanted to switch to a competing program might find that it would be impossible for that new program to read old data, as the information would be \"locked in\" to the old program. It could also make it impossible for the user to read or modify their data except as specifically permitted by the software.\nUsers unable to exercise legal rights.\nThe law in many countries allows users certain rights over data whose copyright they do not own (including text, images, and other media), often under headings such as fair use or public interest. Depending on jurisdiction, these may cover issues such as whistleblowing, production of evidence in court, quoting or other small-scale usage, backups of owned media, and making a copy of owned material for personal use on other owned devices or systems. The steps implicit in trusted computing have the practical effect of preventing users exercising these legal rights.\nUsers vulnerable to vendor withdrawal of service.\nA service that requires external validation or permission - such as a music file or game that requires connection with the vendor to confirm permission to play or use - is vulnerable to that service being withdrawn or no longer updated. A number of incidents have already occurred where users, having purchased music or video media, have found their ability to watch or listen to it suddenly stop due to vendor policy or cessation of service, or server inaccessibility, at times with no compensation. Alternatively in some cases the vendor refuses to provide services in future which leaves purchased material only usable on the present -and increasingly obsolete- hardware (so long as it lasts) but not on any hardware that may be purchased in future.\nUsers unable to override.\nSome opponents of Trusted Computing advocate \"owner override\": allowing an owner who is confirmed to be physically present to allow the computer to bypass restrictions and use the secure I/O path. Such an override would allow remote attestation to a user's specification, e.g., to create certificates that say Internet Explorer is running, even if a different browser is used. Instead of preventing software change, remote attestation would indicate when the software has been changed without owner's permission.\nTrusted Computing Group members have refused to implement owner override. Proponents of trusted computing believe that owner override defeats the trust in other computers since remote attestation can be forged by the owner. Owner override offers the security and enforcement benefits to a machine owner, but does not allow them to trust other computers, because their owners could waive rules or restrictions on their own computers. Under this scenario, once data is sent to someone else's computer, whether it be a diary, a DRM music file, or a joint project, that other person controls what security, if any, their computer will enforce on their copy of those data. This has the potential to undermine the applications of trusted computing to enforce DRM, control cheating in online games and attest to remote computations for grid computing.\nLoss of anonymity.\nBecause a Trusted Computing equipped computer is able to uniquely attest to its own identity, it will be possible for vendors and others who possess the ability to use the attestation feature to zero in on the identity of the user of TC-enabled software with a high degree of certainty.\nSuch a capability is contingent on the reasonable chance that the user at some time provides user-identifying information, whether voluntarily, indirectly, or simply through inference of many seemingly benign pieces of data. (e.g. search records, as shown through simple study of the AOL search records leak). One common way that information can be obtained and linked is when a user registers a computer just after purchase. Another common way is when a user provides identifying information to the website of an affiliate of the vendor.\nWhile proponents of TC point out that online purchases and credit transactions could potentially be more secure as a result of the remote attestation capability, this may cause the computer user to lose expectations of anonymity when using the Internet.\nCritics point out that this could have a chilling effect on political free speech, the ability of journalists to use anonymous sources, whistle blowing, political blogging and other areas where the public needs protection from retaliation through anonymity.\nThe TPM specification offers features and suggested implementations that are meant to address the anonymity requirement. By using a third-party Privacy Certification Authority (PCA), the information that identifies the computer could be held by a trusted third party. Additionally, the use of direct anonymous attestation (DAA), introduced in TPM v1.2, allows a client to perform attestation while not revealing any personally identifiable or machine information.\nThe kind of data that must be supplied to the TTP in order to get the trusted status is at present not entirely clear, but the TCG itself admits that \"attestation is an important TPM function with significant privacy implications\". It is, however, clear that both static and dynamic information about the user computer may be supplied (Ekpubkey) to the TTP (v1.1b), it is not clear what data will be supplied to the \u201cverifier\u201d under v1.2. The static information will uniquely identify the endorser of the platform, model, details of the TPM, and that the platform (PC) complies with the TCG specifications . The dynamic information is described as software running on the computer. If a program like Windows is registered in the user's name this in turn will uniquely identify the user. Another dimension of privacy infringing capabilities might also be introduced with this new technology; how often you use your programs might be possible information provided to the TTP. In an exceptional, however practical situation, where a user purchases a pornographic movie on the Internet, the purchaser nowadays, must accept the fact that he has to provide credit card details to the provider, thereby possibly risking being identified. With the new technology a purchaser might also risk someone finding out that he (or she) has watched this pornographic movie 1000 times. This adds a new dimension to the possible privacy infringement. The extent of data that will be supplied to the TTP/Verifiers is at present not exactly known, only when the technology is implemented and used will we be able to assess the exact nature and volume of the data that is transmitted.\nTCG specification interoperability problems.\nTrusted Computing requests that all software and hardware vendors will follow the technical specifications released by the Trusted Computing Group in order to allow interoperability between different trusted software stacks. However, since at least mid-2006, there have been interoperability problems between the TrouSerS trusted software stack (released as open source software by IBM) and Hewlett-Packard's stack. Another problem is that the technical specifications are still changing, so it is unclear which is the standard implementation of the trusted stack.\nShutting out of competing products.\nPeople have voiced concerns that trusted computing could be used to keep or discourage users from running software created by companies outside of a small industry group. Microsoft has received a great deal of bad press surrounding their Palladium software architecture, evoking comments such as \"Few pieces of vaporware have evoked a higher level of fear and uncertainty than Microsoft's Palladium\", \"Palladium is a plot to take over cyberspace\", and \"Palladium will keep us from running any software not personally approved by Bill Gates\". The concerns about trusted computing being used to shut out competition exist within a broader framework of consumers being concerned about using bundling of products to obscure prices of products and to engage in anti-competitive practices. Trusted Computing is seen as harmful or problematic to independent and open source software developers.\nTrust.\nIn the widely used public-key cryptography, creation of keys can be done on the local computer and the creator has complete control over who has access to it, and consequentially their own security policies. In some proposed encryption-decryption chips, a private/public key is permanently embedded into the hardware when it is manufactured, and hardware manufacturers would have the opportunity to record the key without leaving evidence of doing so. With this key it would be possible to have access to data encrypted with it, and to authenticate as it. It is trivial for a manufacturer to give a copy of this key to the government or the software manufacturers, as the platform must go through steps so that it works with authenticated software.\nTherefore, to trust anything that is authenticated by or encrypted by a TPM or a Trusted computer, an end user has to trust the company that made the chip, the company that designed the chip, the companies allowed to make software for the chip, and the ability and interest of those companies not to compromise the whole process. A security breach breaking that chain of trust happened to a SIM card manufacturer Gemalto, which in 2010 was infiltrated by US and British spies, resulting in compromised security of cellphone calls.\nIt is also critical that one be able to trust that the hardware manufacturers and software developers properly implement trusted computing standards. Incorrect implementation could be hidden from users, and thus could undermine the integrity of the whole system without users being aware of the flaw.\nHardware and software support.\nSince 2004, most major manufacturers have shipped systems that have included Trusted Platform Modules, with associated BIOS support. In accordance with the TCG specifications, the user must enable the Trusted Platform Module before it can be used.\nProcessor manufacturers have included secure enclaves in their design such as ARM TrustZone, Intel Management Engine with SGX and AMD PSP with Secure Encrypted Virtualization.\nThe Linux kernel has included trusted computing support since version 2.6.13, and there are several projects to implement trusted computing for Linux. In January 2005, members of Gentoo Linux's \"crypto herd\" announced their intention of providing support for TC\u2014in particular support for the Trusted Platform Module. There is also a TCG-compliant software stack for Linux named https://, released under an open source license. There are several open-source projects that facilitate the use of confidential computing technology, including https://, EdgelessDB and MarbleRun from Edgeless Systems, as well as Enarx, which originates from security research at Red Hat.\nSome limited form of trusted computing can be implemented on current versions of Microsoft Windows with third-party software. Major cloud providers such as Microsoft Azure, AWS and Google Cloud Platform have virtual machines with trusted computing features available.\nThe Intel Classmate PC (a competitor to the One Laptop Per Child) includes a Trusted Platform Module.\nPrivateCore vCage software can be used to attest x86 servers with TPM chips.\nGoogle enforces Play Integrity API to Android devices with their bootloader unlocked.\nMobile T6 secure operating system simulates the TPM functionality in mobile devices using the ARM TrustZone technology.\nSamsung smartphones come equipped with Samsung Knox that depend on features like Secure Boot, TIMA, MDM, TrustZone and SE Linux.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58609", "revid": "95921", "url": "https://en.wikipedia.org/wiki?curid=58609", "title": "Courthouse", "text": "Building which is home to a court\nA courthouse or court house is a structure which houses judicial functions for a governmental entity such as a state, region, province, county, prefecture, regency, or similar governmental unit. A courthouse is home to one or more courtrooms, the enclosed space in which a judge presides over a court, and one or more chambers, the private offices of judges. Larger courthouses often also have space for offices of judicial support staff such as court clerks and deputy clerks.\nThe term is commonly used in the English-speaking countries of North America. In most other English-speaking countries, buildings which house courts of law are simply called \"courts\" or \"court buildings\". In most of continental Europe and former non-English-speaking European colonies, the equivalent term is a palace of justice (French: palais de justice, Italian: palazzo di giustizia, Portuguese: pal\u00e1cio da justi\u00e7a).\nUnited States.\nIn the United States, most counties maintain trial courts in a county-based courthouse, which also house other county government offices. The courthouse may be a part of a wider county government building or complex. The courthouse is usually located in the county seat, although large metropolitan counties may have satellite or annex offices for their courts. A 2014 textbook estimated that there were \"roughly 17,000 courthouses\" in the United States. \nEarly American courthouses were very simple, with \"plain furnishings and finishes\". By the middle of the 19th century, courthouses increasingly evolved into \"imposing, grandiose\" structures featuring \"formal architectural elements such as columns, domes, clock towers, and grand entrances\". Courthouses often have entrances which require visitors to climb \"an excessive number of steps that lead to a single set of doors through which all people must enter\". The point of such architecture is to project \"an image of solidity\" and \"strength\". Today, American courthouses come in a broad variety of designs, from ancient \"stone fortresses to modern-day, multifloor monolithic towers\". In the largest cities, courthouses for criminal courts were sometimes constructed in close proximity to pretrial detention facilities in rundown inner-city neighborhoods, and streets near such courthouses often feature \"garish neon signs\" for bail bondsmen. \nIn some cases, the building housing the courthouse may be named in some way or its function may be divided between a judicial building and administrative office building. Philadelphia City Hall, for instance, serves as the seat of the legislative and executive functions of the consolidated city and county of Philadelphia, but most of its floor space is devoted to the Civil Division of the Philadelphia Court of Common Pleas. The Supreme Court of Pennsylvania shares space with three local governments and with the legislative and executive branches of the state government of Pennsylvania in Philadelphia City Hall in Philadelphia, the Pennsylvania State Capitol in Harrisburg, which it shares with the Pennsylvania General Assembly and the Governor of Pennsylvania, and the Pittsburgh City-County Building in Pittsburgh, which it shares with the governments of the City of Pittsburgh and of Allegheny County.\nMany judges also officiate at civil marriage ceremonies in their courthouse chambers. In some places, the courthouse also contains the main administrative office for the county government, or when a new courthouse is constructed, the former one will often be used for other local government offices. Either way, a typical courthouse will have one or more courtrooms and a court clerk's office with a filing window where litigants may submit documents for filing with the court.\nEach United States district court also has a federally owned building that houses courtrooms, chambers and clerk's offices. Many federal judicial districts are further split into divisions, which may also have their own courthouses. However, sometimes divisional court facilities are located in buildings that also house other agencies or offices of the United States government; for instance, the Mitchell H. Cohen United States Courthouse in Camden, New Jersey houses a United States post office as well as court facilities for the District of New Jersey.\nSome branches of U.S. federal government courts are housed in rented office space in buildings housing commercial tenants; for instance, the United States Bankruptcy Court for the District of Delaware is located in an office building in Wilmington, Delaware, across the street from the main courthouse of the district court. The United States District Court for the Eastern District of California has a courthouse in Yosemite to hear misdemeanors and petty crimes for Yosemite National Park. Most of the United States courts of appeals are based in the main courthouses of the federal district court in the city in which they are seated.\nThe courthouse is part of the iconography of American life and is equivalent to the city hall as the symbol of the municipium in European free cities. Courthouses are often shown in American cinema (i.e. \"Peyton Place\", \"Back to the Future\", and \"My Cousin Vinny\"). They range from small-town rural buildings with a few rooms to huge metropolitan courthouses that occupy large plots of land. The style of American architecture used varies, with common styles including federal, Greek Revival, neoclassicist, and modern.\nSecurity.\nCourt security is a paramount priority in the design, construction, and renovation of modern American courthouses. Every day, courthouses \"are visited by a large number of disgruntled and even lawbreaking citizens\", such as gang members accused of witness tampering, romantic partners charged with domestic violence, and spouses litigating a divorce. Most importantly, modern courthouses strive to separate in-custody criminal defendants from the general public. \nThe architecture of court buildings can present significant security challenges. Architects typically use two main tools to mitigate security risks within the adjudicative space depending upon local needs, such as the proliferation of weapons: secure entrance vestibules and separation of circulation pathways and adjacencies within the footprint of the building.\nSecure entrance vestibules provide court staff the opportunity to screen visitors to the building for contraband, such as weapons and narcotics, as well as for unauthorized access. Midsize to larger courthouses often have separate entrances to the building for the public, prisoners, judges, and witnesses. These entrances may be monitored remotely from a central security station. In lower risk settings, the security screening may be more perfunctory and serve as an information desk to direct visitors to the various agencies and offices housed within the court building.\nOnce users of the court have entered the building through security screenings and access control checkpoints, the circulation systems of passageways through the building provide discrete pathways by which the public, court staff, and in-custody defendants access to courtrooms and other court services, such as attorneys, pretrial and probation services, and clerks' offices. The circulation pathways and adjacency diagrams designed for newer and larger courthouses often ensure that the only place the systems of circulation, including hallways, stairwells, and elevators overlap is within the monitored setting of the courtroom. This reduces the risk of unauthorized access to court materials by the public, such as court clerk record vaults, as well as the risk of in-custody defendants intimidating witnesses or jurors while being escorted through the public areas of the courthouse.\nFor example, the Los Angeles Superior Court added such checkpoints to all entrances to its main courthouse in Downtown Los Angeles after a woman was shot and killed by her ex-husband in open court in September 1995. The Supreme Court of California ruled in 2002 that Los Angeles County (which at the time was responsible for maintaining the courthouses) was not liable to her three children under the California Government Tort Claims Act.\nAfter the Oklahoma City bombing, the federal government proceeded to heavily fortify all large federal buildings, including many urban courthouses.\nSome courthouses in areas with high levels of violent crime have redundant layers of security. For example, when the Supreme Court of California hears oral argument in San Francisco or Los Angeles, visitors must pass through one security checkpoint to enter the building, and another to enter the courtroom.\nCanada.\nIn Canada, each municipality constructs its own courthouse, or several in the case of large cities. In smaller communities the court is in the same building as the city hall and other municipal offices. In the past many courthouses also included the local prison.\nOne well-known court house in Canada is the Romanesque Revival (Neo-Romanesque) Old City Hall in Toronto, Ontario. Designed by E.J. Lennox, Old City Hall was completed in 1899 and has been functioning as a municipal building ever since. It was originally constructed to facilitate Toronto's City Council, legal and municipal offices and the city's courts however following the construction of the fourth city hall (adjacent to the third, on Queen Street) the building's purpose was limited to being solely a courthouse for the Ontario Court of Justice. The building can be described as Romanesque Revival due to multiple characteristics it shares with Romanesque architecture, despite being constructed seven centuries later in a completely different continent. These characteristics include the materiality in terms of large stone construction, the repetitive rhythmic use of windows containing various sized arches and barrel vaults directing attention towards them, decorated spandrels (wall section connecting arches) and the inclusion of gabled walls (pointed sections). Old City Hall has been designated a National Historical Site since 1989.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58610", "revid": "92899", "url": "https://en.wikipedia.org/wiki?curid=58610", "title": "Non-Euclidean geometry", "text": "Two geometries based on axioms closely related to those specifying Euclidean geometry\nIn mathematics, non-Euclidean geometry consists of two geometries based on axioms closely related to those that specify Euclidean geometry. As Euclidean geometry lies at the intersection of metric geometry and affine geometry, non-Euclidean geometry arises by either replacing the parallel postulate with an alternative, or consideration of quadratic forms other than the definite quadratic forms associated with metric geometry. In the former case, one obtains hyperbolic geometry and elliptic geometry, the traditional non-Euclidean geometries. When isotropic quadratic forms are admitted, then there are affine planes associated with the planar algebras, which give rise to kinematic geometries that have also been called non-Euclidean geometry.\nPrinciples.\nThe essential difference between the metric geometries is the nature of parallel lines. Euclid's fifth postulate, the parallel postulate, is equivalent to Playfair's postulate, which states that, within a two-dimensional plane, for any given line l and a point \"A\", which is not on l, there is exactly one line through \"A\" that does not intersect l. In hyperbolic geometry, by contrast, there are infinitely many lines through \"A\" not intersecting l, while in elliptic geometry, any line through \"A\" intersects l.\nAnother way to describe the differences between these geometries is to consider two straight lines indefinitely extended in a two-dimensional plane that are both perpendicular to a third line (in the same plane):\nHistory.\nBackground.\nEuclidean geometry, named after the Greek mathematician Euclid, includes some of the oldest known mathematics, and geometries that deviated from this were not widely accepted as legitimate until the 19th century.\nThe debate that eventually led to the discovery of the non-Euclidean geometries began almost as soon as Euclid wrote \"Elements\". In the \"Elements\", Euclid begins with a limited number of assumptions (23 definitions, five common notions, and five postulates) and seeks to prove all the other results (propositions) in the work. The most notorious of the postulates is often referred to as \"Euclid's Fifth Postulate\", or simply the \"parallel postulate\", which in Euclid's original formulation is:\nIf a straight line falls on two straight lines in such a manner that the interior angles on the same side are together less than two right angles, then the straight lines, if produced indefinitely, meet on that side on which are the angles less than the two right angles.\nOther mathematicians have devised simpler forms of this property. Regardless of the form of the postulate, however, it consistently appears more complicated than Euclid's other postulates:\nFor at least a thousand years, geometers were troubled by the disparate complexity of the fifth postulate, and believed it could be proved as a theorem from the other four. Many attempted to find a proof by contradiction, including Ibn al-Haytham (Alhazen, 11th century), Omar Khayy\u00e1m (12th century), Nas\u012br al-D\u012bn al-T\u016bs\u012b (13th century), and Giovanni Girolamo Saccheri (18th century).\nThe theorems of Ibn al-Haytham, Khayyam and al-Tusi on quadrilaterals, including the Lambert quadrilateral and Saccheri quadrilateral, were \"the first few theorems of the hyperbolic and the elliptic geometries\". These theorems along with their alternative postulates, such as Playfair's axiom, played an important role in the later development of non-Euclidean geometry. These early attempts at challenging the fifth postulate had a considerable influence on its development among later European geometers, including Witelo, Levi ben Gerson, Alfonso, John Wallis and Saccheri. All of these early attempts made at trying to formulate non-Euclidean geometry, however, provided flawed proofs of the parallel postulate, depending on assumptions that are now recognized as essentially equivalent to the parallel postulate. These early attempts did, however, provide some early properties of the hyperbolic and elliptic geometries.\nKhayyam, for example, tried to derive it from an equivalent postulate he formulated from \"the principles of the Philosopher\" (Aristotle): \"Two convergent straight lines intersect and it is impossible for two convergent straight lines to diverge in the direction in which they converge.\" Khayyam then considered the three cases right, obtuse, and acute that the summit angles of a Saccheri quadrilateral can take and after proving a number of theorems about them, he correctly refuted the obtuse and acute cases based on his postulate and hence derived the classic postulate of Euclid, which he didn't realize was equivalent to his own postulate. Another example is al-Tusi's son, Sadr al-Din (sometimes known as \"Pseudo-Tusi\"), who wrote a book on the subject in 1298, based on al-Tusi's later thoughts, which presented another hypothesis equivalent to the parallel postulate. \"He essentially revised both the Euclidean system of axioms and postulates and the proofs of many propositions from the \"Elements\".\" His work was published in Rome in 1594 and was studied by European geometers, including Saccheri who criticised this work as well as that of Wallis.\nGiordano Vitale, in his book \"Euclide restituo\" (1680, 1686), used the Saccheri quadrilateral to prove that if three points are equidistant on the base AB and the summit CD, then AB and CD are everywhere equidistant.\nIn a work titled \"Euclides ab Omni Naevo Vindicatus\" (\"Euclid Freed from All Flaws\"), published in 1733, Saccheri quickly discarded elliptic geometry as a possibility (some others of Euclid's axioms must be modified for elliptic geometry to work) and set to work proving a great number of results in hyperbolic geometry.\nHe finally reached a point where he believed that his results demonstrated the impossibility of hyperbolic geometry. His claim seems to have been based on Euclidean presuppositions, because no \"logical\" contradiction was present. In this attempt to prove Euclidean geometry he instead unintentionally discovered a new viable geometry, but did not realize it.\nIn 1766 Johann Lambert wrote, but did not publish, \"Theorie der Parallellinien\" in which he attempted, as Saccheri did, to prove the fifth postulate. He worked with a figure now known as a \"Lambert quadrilateral\", a quadrilateral with three right angles (can be considered half of a Saccheri quadrilateral). He quickly eliminated the possibility that the fourth angle is obtuse, as had Saccheri and Khayyam, and then proceeded to prove many theorems under the assumption of an acute angle. Unlike Saccheri, he never felt that he had reached a contradiction with this assumption. He had proved the non-Euclidean result that the sum of the angles in a triangle increases as the area of the triangle decreases, and this led him to speculate on the possibility of a model of the acute case on a sphere of imaginary radius. He did not carry this idea any further.\nAt this time it was widely believed that the universe worked according to the principles of Euclidean geometry.\nDevelopment of non-Euclidean geometry.\nThe beginning of the 19th century would finally witness decisive steps in the creation of non-Euclidean geometry.\nCirca 1813, Carl Friedrich Gauss and independently around 1818, the German professor of law Ferdinand Karl Schweikart had the germinal ideas of non-Euclidean geometry worked out, but neither published any results. Schweikart's nephew Franz Taurinus did publish important results of hyperbolic trigonometry in two papers in 1825 and 1826, yet while admitting the internal consistency of hyperbolic geometry, he still believed in the special role of Euclidean geometry.\nThen, in 1829\u20131830 the Russian mathematician Nikolai Ivanovich Lobachevsky and in 1832 the Hungarian mathematician J\u00e1nos Bolyai separately and independently published treatises on hyperbolic geometry. Consequently, hyperbolic geometry is called Lobachevskian or Bolyai-Lobachevskian geometry, as both mathematicians, independent of each other, are the basic authors of non-Euclidean geometry. Gauss mentioned to Bolyai's father, when shown the younger Bolyai's work, that he had developed such a geometry several years before, though he did not publish. While Lobachevsky created a non-Euclidean geometry by negating the parallel postulate, Bolyai worked out a geometry where both the Euclidean and the hyperbolic geometry are possible depending on a parameter\u00a0\"k\". Bolyai ends his work by mentioning that it is not possible to decide through mathematical reasoning alone if the geometry of the physical universe is Euclidean or non-Euclidean; this is a task for the physical sciences.\nBernhard Riemann, in a famous lecture in 1854, founded the field of Riemannian geometry, discussing in particular the ideas now called manifolds, Riemannian metric, and curvature.\nHe constructed an infinite family of non-Euclidean geometries by giving a formula for a family of Riemannian metrics on the unit ball in Euclidean space. The simplest of these is called elliptic geometry and it is considered a non-Euclidean geometry due to its lack of parallel lines.\nBy formulating the geometry in terms of a curvature tensor, Riemann allowed non-Euclidean geometry to apply to higher dimensions. Beltrami (1868) was the first to apply Riemann's geometry to spaces of negative curvature.\nTerminology.\nIt was Gauss who coined the term \"non-Euclidean geometry\". He was referring to his own work, which today we call \"hyperbolic geometry\" or \"Lobachevskian geometry\". Several modern authors still use the generic term \"non-Euclidean geometry\" to mean \"hyperbolic geometry\".\nArthur Cayley noted that distance between points inside a conic could be defined in terms of logarithm and the projective cross-ratio function. The method has become called the Cayley\u2013Klein metric because Felix Klein exploited it to describe the non-Euclidean geometries in articles in 1871 and 1873 and later in book form. The Cayley\u2013Klein metrics provided working models of hyperbolic and elliptic metric geometries, as well as Euclidean geometry.\nKlein is responsible for the terms \"hyperbolic\" and \"elliptic\" (in his system he called Euclidean geometry \"parabolic\", a term that generally fell out of use). His influence has led to the current usage of the term \"non-Euclidean geometry\" to mean either \"hyperbolic\" or \"elliptic\" geometry.\nThere are some mathematicians who would extend the list of geometries that should be called \"non-Euclidean\" in various ways.\nThere are many kinds of geometry that are quite different from Euclidean geometry but are also not necessarily included in the conventional meaning of \"non-Euclidean geometry\", such as more general instances of Riemannian geometry.\nAxiomatic basis of non-Euclidean geometry.\nEuclidean geometry can be axiomatically described in several ways. However, Euclid's original system of five postulates (axioms) is not one of these, as his proofs relied on several unstated assumptions that should also have been taken as axioms. Hilbert's system consisting of 20 axioms most closely follows the approach of Euclid and provides the justification for all of Euclid's proofs. Other systems, using different sets of undefined terms obtain the same geometry by different paths. All approaches, however, have an axiom that is logically equivalent to Euclid's fifth postulate, the parallel postulate. Hilbert uses the Playfair axiom form, while Birkhoff, for instance, uses the axiom that says that, \"There exists a pair of similar but not congruent triangles.\" In any of these systems, removal of the one axiom equivalent to the parallel postulate, in whatever form it takes, and leaving all the other axioms intact, produces absolute geometry. As the first 28 propositions of Euclid (in \"The Elements\") do not require the use of the parallel postulate or anything equivalent to it, they are all true statements in absolute geometry.\nTo obtain a non-Euclidean geometry, the parallel postulate (or its equivalent) \"must\" be replaced by its negation. Negating the Playfair's axiom form, since it is a compound statement (...\u00a0there exists one and only one\u00a0...), can be done in two ways: either there will exist more than one line through the point parallel to the given line or there will exist no lines through the point parallel to the given line.\nModels.\nModels of non-Euclidean geometry are mathematical models of geometries that are non-Euclidean in the sense that it is not the case that exactly one line can be drawn parallel to a given line \"l\" through a point \"A\" that is not on \"l\". In hyperbolic geometric models, by contrast, there are infinitely many lines through \"A\" parallel to \"l\", and in elliptic geometric models, parallel lines do not exist. (See the entries on hyperbolic geometry and elliptic geometry for more information.)\nEuclidean geometry is modelled by our notion of a \"flat plane.\" \nThe simplest model for elliptic geometry is a sphere, where lines are \"great circles\" (such as the equator or the meridians on a globe), and points opposite each other are identified (considered to be the same). \nThe pseudosphere has the appropriate curvature to model hyperbolic geometry.\nElliptic geometry.\nThe simplest model for elliptic geometry is a sphere, where lines are \"great circles\" (such as the equator or the meridians on a globe), and points opposite each other (called antipodal points) are identified (considered the same). This is also one of the standard models of the real projective plane. The difference is that as a model of elliptic geometry a metric is introduced permitting the measurement of lengths and angles, while as a model of the projective plane there is no such metric.\nIn the elliptic model, for any given line l and a point \"A\", which is not on l, all lines through \"A\" will intersect l.\nHyperbolic geometry.\nEven after the work of Lobachevsky, Gauss, and Bolyai, the question remained: \"Does such a model exist for hyperbolic geometry?\". The model for hyperbolic geometry was answered by Eugenio Beltrami, in 1868, who first showed that a surface called the pseudosphere has the appropriate curvature to model a portion of hyperbolic space and in a second paper in the same year, defined the Klein model, which models the entirety of hyperbolic space, and used this to show that Euclidean geometry and hyperbolic geometry were equiconsistent so that hyperbolic geometry was logically consistent if and only if Euclidean geometry was. (The reverse implication follows from the horosphere model of Euclidean geometry.)\nIn the hyperbolic model, within a two-dimensional plane, for any given line l and a point \"A\", which is not on l, there are infinitely many lines through \"A\" that do not intersect l.\nIn these models, the concepts of non-Euclidean geometries are represented by Euclidean objects in a Euclidean setting. This introduces a perceptual distortion wherein the straight lines of the non-Euclidean geometry are represented by Euclidean curves that visually bend. This \"bending\" is not a property of the non-Euclidean lines, only an artifice of the way they are represented.\nThree-dimensional non-Euclidean geometry.\nIn three dimensions, there are eight models of geometries. There are Euclidean, elliptic, and hyperbolic geometries, as in the two-dimensional case; mixed geometries that are partially Euclidean and partially hyperbolic or spherical; twisted versions of the mixed geometries; and one unusual geometry that is completely anisotropic (i.e. every direction behaves differently).\nUncommon properties.\nEuclidean and non-Euclidean geometries naturally have many similar properties, namely those that do not depend upon the nature of parallelism. This commonality is the subject of absolute geometry (also called \"neutral geometry\"). However, the properties that distinguish one geometry from others have historically received the most attention.\nBesides the behavior of lines with respect to a common perpendicular, mentioned in the introduction, we also have the following:\nImportance.\nBefore the models of a non-Euclidean plane were presented by Beltrami, Klein, and Poincar\u00e9, Euclidean geometry stood unchallenged as the mathematical model of space. Furthermore, since the substance of the subject in synthetic geometry was a chief exhibit of rationality, the Euclidean point of view represented absolute authority.\nThe discovery of the non-Euclidean geometries had a ripple effect which went far beyond the boundaries of mathematics and science. The philosopher Immanuel Kant's treatment of human knowledge had a special role for geometry. It was his prime example of synthetic a priori knowledge; not derived from the senses nor deduced through logic\u00a0\u2014 our knowledge of space was a truth that we were born with. Unfortunately for Kant, his concept of this unalterably true geometry was Euclidean. Theology was also affected by the change from absolute truth to relative truth in the way that mathematics is related to the world around it, that was a result of this paradigm shift.\nNon-Euclidean geometry is an example of a scientific revolution in the history of science, in which mathematicians and scientists changed the way they viewed their subjects. Some geometers called Lobachevsky the \"Copernicus of Geometry\" due to the revolutionary character of his work.\nThe existence of non-Euclidean geometries impacted the intellectual life of Victorian England in many ways and in particular was one of the leading factors that caused a re-examination of the teaching of geometry based on Euclid's Elements. This curriculum issue was hotly debated at the time and was even the subject of a book, \"Euclid and his Modern Rivals\", written by Charles Lutwidge Dodgson (1832\u20131898) better known as Lewis Carroll, the author of \"Alice in Wonderland\".\nPlanar algebras.\nIn analytic geometry a plane is described with Cartesian coordinates: \n formula_1\nThe points are sometimes identified with generalized complex numbers \"z\" = \"x\" + \"y\" \u03b5 where \u03b52 \u2208 {\u20131, 0, 1}.\nThe Euclidean plane corresponds to the case \u03b52 = \u22121, an imaginary unit. Since the modulus of z is given by\n formula_2 this quantity is the square of the Euclidean distance between z and the origin.\nFor instance, {\"z\" | \"z z\"* = 1} is the unit circle.\nFor planar algebra, non-Euclidean geometry arises in the other cases.\nWhen \u03b52 = +1, a hyperbolic unit. Then z is a split-complex number and conventionally j replaces epsilon. Then\n formula_3\nand {\"z\" | \"z z\"* = 1} is the unit hyperbola.\nWhen \u03b52 = 0, then z is a dual number.\nThis approach to non-Euclidean geometry explains the non-Euclidean angles: the parameters of slope in the dual number plane and hyperbolic angle in the split-complex plane correspond to angle in Euclidean geometry. Indeed, they each arise in polar decomposition of a complex number z.\nKinematic geometries.\nHyperbolic geometry found an application in kinematics with the physical cosmology introduced by Hermann Minkowski in 1908. Minkowski introduced terms like worldline and proper time into mathematical physics. He realized that the submanifold, of events one moment of proper time into the future, could be considered a hyperbolic space of three dimensions.\nAlready in the 1890s Alexander Macfarlane was charting this submanifold through his \"Algebra of Physics\" and hyperbolic quaternions, though Macfarlane did not use cosmological language as Minkowski did in 1908. The relevant structure is now called the hyperboloid model of hyperbolic geometry.\nThe non-Euclidean planar algebras support kinematic geometries in the plane. For instance, the split-complex number \"z\" = e\"a\"j can represent a spacetime event one moment into the future of a frame of reference of rapidity \"a\". Furthermore, multiplication by \"z\" amounts to a Lorentz boost mapping the frame with rapidity zero to that with rapidity \"a\".\nKinematic study makes use of the dual numbers formula_4 to represent the classical description of motion in absolute time and space:\nThe equations formula_5 are equivalent to a shear mapping in linear algebra:formula_6\nWith dual numbers the mapping is formula_7\nAnother view of special relativity as a non-Euclidean geometry was advanced by E. B. Wilson and Gilbert Lewis in \"Proceedings of the American Academy of Arts and Sciences\" in 1912. They revamped the analytic geometry implicit in the split-complex number algebra into synthetic geometry of premises and deductions.\nFiction.\nNon-Euclidean geometry often makes appearances in works of science fiction and fantasy.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58611", "revid": "279219", "url": "https://en.wikipedia.org/wiki?curid=58611", "title": "Courts-Martial", "text": ""}
{"id": "58614", "revid": "151", "url": "https://en.wikipedia.org/wiki?curid=58614", "title": "Karl Gauss", "text": ""}
{"id": "58616", "revid": "31964136", "url": "https://en.wikipedia.org/wiki?curid=58616", "title": "Evidence (disambiguation)", "text": "Evidence is anything presented as proof of an assertion.\nEvidence may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "58617", "revid": "50237715", "url": "https://en.wikipedia.org/wiki?curid=58617", "title": "Fact", "text": "Datum or structured component of reality\nA fact is a true datum about one or more aspects of a circumstance. Standard reference works are often used to check facts. Scientific facts are verified by repeatable careful observation or measurement by experiments or other means. Generally speaking, facts are independent of belief, knowledge and opinion. \nFacts are different from inferences, theories, values, and objects.\nFor example, \"This sentence contains words.\" accurately describes a linguistic fact, and \"the Sun is a star\" describes an astronomical fact. Further, \"Abraham Lincoln was the 16th president of the United States\" and \"Abraham Lincoln was assassinated\" are both historical facts.\nEtymology and usage.\nThe word \"fact\" derives from the Latin \"factum\". It was first used in English with the same meaning: \"a thing done or performed\"\u00a0\u2013 a meaning now obsolete outside the law. The common usage of \"something that has really occurred or is the case\" dates from the mid-16th century.\nBarbara J. Shapiro wrote in her book \"A Culture of Fact\" how the concept of a fact evolved, starting within the English legal tradition of the 16th century.\nIn 1870, Charles Sanders Peirce described in his book \"The Fixation of Belief\" four methods which people use to decide what they should believe: tenacity, method of authority, a priori and scientific method.\nThe term \"fact\" also indicates a \"matter under discussion\" deemed to be true or correct, such as to emphasize a point or prove a disputed issue; (e.g., \"...\u00a0the \"fact\" of the matter is ...\").\nAlternatively, \"fact\" may also indicate an allegation or stipulation of something that may or may not be a \"true fact\", (e.g., \"the author's facts are not trustworthy\"). This alternate usage, although contested by some, has a long history in standard English according to the \"American Heritage Dictionary of the English Language.\" The \"Oxford English Dictionary\" dates this use to 1729.\n\"Fact\" may also indicate findings derived through a \"process of evaluation\", including review of testimony, direct observation, or otherwise; as distinguishable from matters of inference or speculation. This use is reflected in the terms \"fact-find\" and \"fact-finder\" (e.g., \"set up a fact-finding commission\").\nFacts may be checked by reason, experiment, personal experience, or may be argued from authority. Roger Bacon wrote \"If in other sciences we should arrive at certainty without doubt and truth without error, it behooves us to place the foundations of knowledge in mathematics.\"\nIn philosophy.\nIn philosophy, the concept \"fact\" is considered in the branch of philosophy concerned with knowledge, called epistemology and ontology, which studies concepts such as existence, being, becoming, and reality. Questions of objectivity and truth are closely associated with questions of fact. A fact can be defined as something that is the case, in other words, a state of affairs.\nFacts may be understood as information, which makes a true sentence true: \"A fact is, traditionally, the worldly correlate of a true proposition, a state of affairs whose obtaining makes that proposition true.\" Facts may also be understood as those things to which a true sentence refers. The statement \"Jupiter is the largest planet in the Solar System\" is \"about\" the fact that Jupiter is the largest planet in the Solar System.\nCorrespondence and the slingshot argument.\nPascal Engel's version of the correspondence theory of truth explains that what makes a sentence true is that it \"corresponds\" to a fact. This theory presupposes the existence of an objective world.\nThe Slingshot argument claims to show that all true statements stand for the same thing, the truth value \"true\". If this argument holds, and facts are taken to be what true statements stand for, then one arrives at the counter-intuitive conclusion that there is only one fact: \"the truth\".\nCompound facts.\nAny non-trivial true statement about reality is necessarily an abstraction composed of a complex of objects and properties or relations. Facts \"possess internal structure, being complexes of objects and properties or relations\". For example, the fact described by the true statement \"Paris is the capital city of France\" implies that there is such a place as Paris, there is such a place as France, there are such things as capital cities, as well as that France has a government, that the government of France has the power to define its capital city, and that the French government has chosen Paris to be the capital, that there is such a thing as a \"place\" or a \"government\", and so on. The verifiable accuracy of all of these assertions, if facts themselves, may coincide to create the fact, that Paris is the capital of France.\nDifficulties arise, however, in attempting to identify the constituent parts of negative, modal, disjunctive, or moral facts.\nFact\u2013value distinction.\nMoral philosophers since David Hume have debated whether values are objective, and thus factual. In \"A Treatise of Human Nature\" Hume pointed out there is no obvious way for a series of statements about what \"ought\" to be the case to be derived from a series of statements of what \"is\" the case. This is called the is\u2013ought distinction. Those who insist there is a logical gulf between facts and values, such that it is fallacious to attempt to derive values (e.g., \"it is good to give food to hungry people\") from facts (e.g., \"people will die if they can't eat\"), include G. E. Moore, who called attempting to do so the naturalistic fallacy.\nFactual\u2013counterfactual distinction.\nFactuality\u2014what has occurred\u2014can also be contrasted with counterfactuality: what \"might have\" occurred, but did not. A counterfactual conditional or subjunctive conditional is a conditional (or \"if\u2013then\") statement indicating what \"would be\" the case if events had been other than they were. For example, \"If Alexander had lived, his empire would have been greater than Rome.\" This contrasts with an indicative conditional, which indicates what \"is\" (in fact) the case if its antecedent \"is\" (in fact) true\u2014for example, \"If you drink this, it will make you well.\" Such sentences are important to modal logic, especially since the development of possible world semantics.\nIn mathematics.\nIn mathematics, a \"fact\" is a statement (called a theorem) that can be proven by logical argument from certain axioms and definitions.\nIn science.\nThe definition of a \"scientific fact\" is different from the definition of fact, as it implies knowledge. A scientific fact is the result of a repeatable careful observation or measurement by experimentation or other means, also called empirical evidence. These are central to building scientific theories. Various forms of observation and measurement lead to fundamental questions about the scientific method, and the scope and validity of scientific reasoning.\nIn the most basic sense, a \"scientific fact\" is an objective and verifiable observation, in contrast with a \"hypothesis\" or \"theory\", which is intended to explain or interpret facts.\nVarious scholars have offered significant refinements to this basic formulation. Philosophers and scientists are careful to distinguish between: 1) \"states of affairs\" in the external world and 2) \"assertions\" of fact that may be considered relevant in scientific analysis. The term is used in both senses in the philosophy of science.\nScholars and clinical researchers in both the social and natural sciences have written about numerous questions and theories that arise in the attempt to clarify the fundamental nature of scientific fact. Pertinent issues raised by this inquiry include:\nConsistent with the idea of confirmation holism, some scholars assert \"fact\" to be necessarily \"theory-laden\" to some degree. Thomas Kuhn points out that knowing what facts to measure, and how to measure them, requires the use of other theories. For example, the age of fossils is based on radiometric dating, which is justified by reasoning that radioactive decay follows a Poisson process rather than a Bernoulli process. Similarly, Percy Williams Bridgman is credited with the methodological position known as operationalism, which asserts that all observations are not only influenced, but necessarily defined, by the means and assumptions used to measure them.\nThe scientific method.\nApart from the fundamental inquiry into the nature of scientific fact, there remain the practical and social considerations of how fact is investigated, established, and substantiated through the proper application of the scientific method. Scientific facts are generally believed independent of the observer: no matter who performs a scientific experiment, all observers agree on the outcome.\nIn addition to these considerations, there are the social and institutional measures, such as peer review and accreditation, that are intended to promote \"factual accuracy\" among other interests in scientific study.\nIn history.\nA common rhetorical clich\u00e9 states, \"History is written by the winners\". This phrase suggests but does not examine the use of facts in the writing of history.\nE. H. Carr in his 1961 volume \"What is History?\" argues that the inherent biases from the gathering of facts makes the objective truth of any historical perspective idealistic and impossible. Facts are, \"like fish in the Ocean\", of which we may only happen to catch a few, only an indication of what is below the surface. Even a dragnet cannot tell us for certain what it would be like to live below the Ocean's surface. Even if we do not discard any facts (or fish) presented, we will always miss the majority; the site of our fishing, the methods undertaken, the weather and even luck play a vital role in what we will catch. Additionally, the composition of history is inevitably made up by the compilation of many different biases of fact finding \u2013 all compounded over time. He concludes that for a historian to attempt a more objective method, one must accept that history can only aspire to a conversation of the present with the past \u2013 and that one's methods of fact gathering should be openly examined. The set of highlighted historical facts, and their interpretations, therefore changes over time, and reflect present consensuses.\nIn law.\nThis section of the article emphasizes common law jurisprudence as primarily represented in Anglo-American\u2013based legal tradition. Nevertheless, the principles described herein have analogous treatment in other legal systems such as civil law systems as well.\nIn most common law jurisdictions, the general concept and analysis of fact reflects fundamental principles of jurisprudence, and is supported by several well-established standards. Matters of fact have various formal definitions under common law jurisdictions.\nThese include:\nLegal pleadings.\nA party (e.g., plaintiff) to a civil suit generally must clearly state the relevant allegations of fact that form the basis of a claim. The requisite level of precision and particularity of these allegations varies, depending on the rules of civil procedure and jurisdiction. Parties who face uncertainties regarding facts and circumstances attendant to their side in a dispute may sometimes invoke alternative pleading. In this situation, a party may plead separate sets of facts that when considered together may be contradictory or mutually exclusive. This seemingly logically-inconsistent presentation of facts may be necessary as a safeguard against contingencies such as \"res judicata\" that would otherwise preclude presenting a claim or defense that depends on a particular interpretation of the underlying facts and ruling of the court.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58619", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=58619", "title": "The Wasp Factory", "text": "1984 novel by Iain Banks\nThe Wasp Factory is the first novel by Scottish writer Iain Banks, published in 1984. Before the book came out, Banks had written several science fiction novels that had not been accepted for publication. He decided to try a more mainstream novel in the hopes that it would be more readily accepted, and wrote about a psychopathic teenager living on a remote Scottish island. According to Banks, this allowed him to treat the story as something resembling science fiction\u2014the island could be envisaged as a planet, and Frank, the protagonist, almost as an alien. Following the success of \"The Wasp Factory\", Banks began to write full-time.\n\"The Wasp Factory\" is written from a first person perspective, told by 17-year-old Francis Cauldhame (\"Frank\"), describing his childhood and all that remains of it. Frank observes many shamanistic rituals of his own invention, and it is soon revealed that Frank killed three children before he reached the age of ten himself.\nThe book sold well, but was greeted with a mixture of acclaim and criticism, due to its gruesome depiction of violence. \"The Irish Times\" called it \"a work of unparalleled depravity\".\nPlot.\nThe story is told from the perspective of 17-year-old Frank Cauldhame. Frank lives with his father on a small island in rural Scotland, and he has not seen his mother in many years. There is no official record of his birth, meaning his existence is largely unknown.\nFrank occupies his time with rituals, building dams, and maintaining an array of weapons (a small catapult, pipe bombs, and a crude flamethrower) for killing small animals around the island. He takes long walks to patrol the island and occasionally gets drunk with his only friend, a dwarf. Otherwise, Frank has almost no contact with the outside world. He's haunted by the memory of a dog attack during his youth, which resulted in the loss of his genitalia. He resents others for his impotence, particularly women. This is in part due to the mauling coinciding with the last time he saw his mother, who had come back to give birth to his younger brother, and left immediately afterward.\nFrank's older brother, Eric, escapes from a psychiatric institution, having been arrested some years prior for arson and terrorising the local children by force-feeding them live maggots. Eric often calls him from a pay-phone to inform Frank of his progress back to the island. Eric is extremely erratic; their conversations end badly, with Eric exploding in fits of rage. However, it's clear Frank loves his brother.\nThe Wasp Factory is a mechanism invented by Frank, consisting of a huge clock face, salvaged from the local dump, encased in a glass box. Behind each of the 12 numerals is a trap that leads to a different ritual death (such as burning, crushing, or drowning in Frank's urine) for the wasp that Frank puts into it via the hole at the centre. Frank believes the death \"chosen\" by the wasp predicts something about the future. The Factory is in the house's loft, which Frank's father cannot access because of a leg injury. There are also \u201cSacrifice Poles\u201d constructed by Frank. The corpses of animals, such as mice that he has killed, are placed onto the poles for the purpose of attracting birds which will fly away and alert Frank to anybody approaching the island.\nIt's revealed that when Frank was much younger, he killed three of his relatives: two cousins and his younger half-brother. He also exhumed the skull of the dog that castrated him, and uses it as part of his rituals. Eric is described as having been extremely sensitive before the incident that drove him mad: a tragic case of neglect at the hospital where Eric was a volunteer when studying to become a doctor. While attempting to feed a brain-damaged newborn with acalvaria, Eric notes how the child is unresponsive and smiling, despite usually appearing expressionless. The child's skull is held together by a metal plate over his head. Eric checks underneath the plate to find the child's exposed brain tissue infested and being consumed by day-old maggots.\nFrank's father is distant and spends most of his time in his study, which he keeps locked at all times. Frank longs to know what is inside. He is used to being lied to by his father, who seemingly does it purely for his own amusement. At the end of the novel, Frank is alerted to Eric's return when he sees a dog that has been burned alive and discovers Eric's campsite. This knowledge incites Frank's father to get drunk before forgetting to conceal the keys to his study, where Frank discovers male hormone drugs, tampons, and what appears to be the remains of his own genitals in a jar. He assumes that his findings mean that his father is actually female. After disrobing his father at knifepoint, Frank discovers this is not the case. At the same time, Eric arrives. During the ensuing confrontation, Eric attempts to destroy the house by setting light to the large stock of cordite kept in the cellar. Frank stops him, and Eric runs into the distance. \nFrank's father explains that it was Frank who was born a female; the hormones had been fed to him by his father since the dog attack in an experiment to see whether Frank would transition from female to male. The remains of his genitals were fake, fashioned from wax as evidence in case Frank ever questioned his father's story. It is suggested that his father's reasoning for doing this was to distance himself from the women he felt had ruined his life. In the end, Frank finds Eric, half asleep. He sits with him and considers his life up to this point and whether he should leave the island.\nLiterary significance and criticism.\nThe book was initially greeted with a mixture of acclaim and criticism, due to its gruesome depiction of violence. While this is mostly against animals, Frank also recollects killing three younger children. The murders are described in an honest and matter-of-fact way, often with grotesque humour. \"The Irish Times\" called it \"a work of unparalleled depravity.\" Banks' response to this criticism is that readers understood the humour of these scenes in a way that many critics did not in their reviews.\nNeil Gaiman reviewed \"The Wasp Factory\" for \"Imagine\" magazine, and stated that it \"will delight horror fans with its mixture of black humour and horrible, imaginative, beautiful deaths\".\nA 1997 poll of over 25,000 readers of \"The Independent\" listed \"The Wasp Factory\" as one of the top 100 books of the 20th century.\nAdaptations.\nIn 1992, Malcolm Sutherland adapted the novel for the stage. The production was performed at the Glasgow Citizen's Theatre. It was revived in 1997 and shown in Yorkshire and London.\nIn 1997, Craig Warner adapted the novel into a 10-part serial (15-minute episodes) for BBC Radio 4.\nIn 2008, the Sutherland production went on tour again.\nIn 2013, the Australian producer and composer Ben Frost directed an opera adaptation of the Iain Banks novel, in which all characters are represented by three female singers.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58620", "revid": "7098284", "url": "https://en.wikipedia.org/wiki?curid=58620", "title": "Espedair Street", "text": "1987 novel by Iain Banks\nEspedair Street is a novel by Scottish writer Iain Banks, published in 1987.\nPlot introduction.\nThe book tells the (fictional) story of the rise to fame of Dan Weir ('Weird'), a bass guitar player in a rock and roll band called Frozen Gold, and of his struggles to be happy now that he is rich and famous.\nPlot summary.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Two days ago I decided to kill myself. I would walk and hitch and sail away from this dark city to the bright spaces of the wet west coast, and there throw myself into the tall, glittering seas beyond Iona (with its cargo of mouldering kings) to let the gulls and seals and tides have their way with my remains, and in my dying moments look forward to an encounter with Staffa\u2019s six-sided columns and Fingal's Cave; or I might head south to Corryvreckan, to be spun inside the whirlpool and listen with my waterlogged deaf ears to its mile-wide voice ringing over the wave-race; or be borne north, to where the white sands sing and coral hides, pink-fingered and hard-soft, beneath the ocean swell, and the rampart cliffs climb thousand-foot above the seething acres of milky foam, rainbow-buttressed.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Last night I changed my mind and decided to stay alive. Everything that follows is .\u00a0.\u00a0. just to try and explain.\nWeird starts out in the Ferguslie Park area of Paisley in a very underprivileged Catholic family. He is impressed by a group named Frozen Gold when he sees them live, in the Union of Paisley College of Technology, and auditions with them. Christine Brice likes his songs, and he joins the band. He ends up writing all their material and playing bass guitar (after trying unsuccessfully to get them to change their name), as the band rises in the drug- and booze-fuelled rock and roll of the 1970s, assisted by A&amp;R man Rick Tumber of ARC Records. In the Three Chimneys tour, singer Davey Balfour takes Dan along on an attempt to break an unofficial (and illegal) speed record for flying around three power station chimneys in Kent in his private aeroplane.\nHe reminisces about this from 1980s Glasgow, where he lives as a recluse in a Victorian folly (St Jutes), ever since the tragic events which led to the demise of the band. He is posing as his own caretaker, and his friends McCann and Wee Tommy know him as Jimmy Hay. After a memorable fight in a nightclub called 'Monty's', his real identity is revealed. He has grown uncomfortable with fame and wealth, and eventually visits his first girlfriend, Jean Webb, now living in Arisaig.\nLiterary significance &amp; criticism.\nThe band is loosely modelled on Pink Floyd or Fleetwood Mac although Banks has said that the character of Weird was in part inspired by Fish, the ex-Marillion singer and lyricist (\"When I created Weird [...] I think Fish was at the back of my mind as a wee subliminal influence\"). There is a tone of rock journalism in the parts of the book about Frozen Gold. Coincidentally, onetime aspiring rock musician Sandy Robertson, who later became a well known rock journalist at Sounds magazine, lived in Espedair Street in the early 70s before the book was written.\nAs Banks' first novel to eschew 'special effects', not being Gothic horror like \"The Wasp Factory\", a literary mystery like \"Walking on Glass\", or science fiction like \"The Bridge\", most critics regard it as one of his most accessible works.\nEspedair Street is also a real street in Charleston, Paisley, where some of the significant events in the book take place.\nBibliography.\n\"Espedair Street\", Iain Banks, London: Macmillan, 1987, (paperback )\nAdaptation.\nA four-part BBC radio adaptation of the novel was broadcast on BBC Radio 4 in January 1998."}
{"id": "58621", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=58621", "title": "The Crow Road", "text": "1992 novel by Iain Banks\nThe Crow Road is a novel by the Scottish writer Iain Banks, published in 1992.\nPlot introduction.\nThe novel describes Prentice McHoan's preoccupation with death, sex, his relationship with his father, unrequited love, sibling rivalry, a missing uncle, cars, alcohol and other intoxicants, and God, against the background of the Scottish landscape.\nPlot summary.\nThis Bildungsroman is set in the fictional Argyll town of Gallanach, the real village of Lochgair, and in Glasgow, where the adult Prentice McHoan lives. Prentice's uncle Rory disappeared eight years previously while writing a book called \"The Crow Road.\" Prentice becomes obsessed with papers his uncle left behind and sets out to solve the mystery. Along the way he must cope with estrangement from his father, unrequited love, sibling rivalry, and failure at his studies.\nThe estrangement from his father concerns Prentice's belief in a higher power and purpose, and in life after death, all of which his father denies.\nA parallel plot is Prentice's gradual transition from an adolescent fixation on one young woman to a more mature love for another.\nPrentice's efforts to make sense of Uncle Rory's fragmentary notes and the minimal clues surrounding his disappearance mirror his efforts to understand the world and his place in it. The narrative is nonlinear, leaping back and forth with little or no warning, requiring the reader to piece things together.\nLiterary significance and criticism.\nThe novel combines menace (it contains an account of a \"perfect murder\") and dark humour (note the opening sentence: \"It was the day my grandmother exploded.\") with an interesting treatment of love. Banks uses multiple voices and points of view, jumping freely in both time and character. Even minor characters like Prentice's grandmother, the fictional town of Gallanach, and his family's home in Lochgair receive careful description, giving Prentice's life depth and context.\nThe book follows Prentice's journey of discovery about himself, those he loves, and the ways of the world.\n\"The Crow Road\" is the name of a street in the west of Glasgow, but serves as well as a metaphor for death, as in \"He's away the Crow Road\". The appropriateness of this title becomes apparent as the novel progresses.\nAdaptation.\n\"The Crow Road\" was adapted for television by Bryan Elsley for the BBC in 1996. See \"The Crow Road\".\nBibliography.\n\"The Crow Road\", Iain Banks, Abacus, 1992, \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGood Omens 2 episode 6 ~43:30"}
{"id": "58622", "revid": "1603072", "url": "https://en.wikipedia.org/wiki?curid=58622", "title": "Consider Phlebas", "text": "1987 novel by Iain M. Banks\nConsider Phlebas, first published in 1987, is a space opera novel by Scottish writer Iain M. Banks. It is the first in a series of novels about an interstellar post-scarcity society called the Culture.\nThe novel revolves around the Idiran\u2013Culture War, and Banks plays on that theme by presenting various microcosms of that conflict. Its protagonist Bora Horza Gobuchul is an enemy of the Culture.\n\"Consider Phlebas\" is Banks's first published science fiction novel, and takes its title from a line in T. S. Eliot's poem \"The Waste Land\". A subsequent Culture novel, \"Look to Windward\" (2000), whose title comes from the previous line of the same poem, can be considered a loose follow-up.\nPlot summary.\nThe Culture and the Idiran Empire are at war in a galaxy-spanning conflict. A Culture Mind, fleeing the destruction of its ship in an Idiran ambush, takes refuge on Schar's World. The Dra'Azon, godlike incorporeal beings, maintain Schar's World as a monument to the world's extinct civilisation and the dangers of nuclear proliferation, forbidding access to both the Culture and the Idirans. Horza, a shape-changing mercenary, is rescued from execution by the Idirans who believe the Dra'Azon guardian may let him onto the planet as in the past he was part of a small group of Changers who acted as stewards. They instruct him to retrieve the Mind.\nDuring Horza's extraction, the Idirans also capture a Special Circumstances agent, Perosteck Balveda. However, the Idiran starship on which he is travelling is soon attacked by a Culture vessel, and Horza is ejected. He is picked up by a pirate ship, the \"Clear Air Turbulence\" (\"CAT\"). He is forced to fight and kill one of the crew to earn a place. The captain, Kraiklyn, leads them on two disastrous pirate raids in which several of the crew perish. After the second raid Horza is taken prisoner by a cult living on an island on the orbital Vavatch, which is scheduled to be destroyed by the Culture. He escapes after poisoning the cult leader and makes his way to Evanauth, the main city of Vavatch, where he finds Kraiklyn, who is playing \"Damage\"\u2014a high-stakes card game played by the most notorious characters in the galaxy, usually at a location about to be destroyed.\nHaving now changed his appearance to mimic that of the \"CAT\" captain, Horza follows him back to the \"CAT\", kills him and returns to the \"CAT\" meeting the few remaining original crew. He is introduced to a newly recruited member, whom he recognises as a disguised Perosteck Balveda. Culture agents outside try to capture the ship. Horza manages to lift off and as the fugitives warp away from Vavatch, they see the evacuated Orbital destroyed by the Culture warships to prevent it from falling into enemy hands. Balveda reveals Horza's identity, but he convinces the crew to carry out his mission. A sentient Vavatch drone, Unaha-Closp, has been trapped on the ship and reluctantly joins the team.\nThey land on Schar's World and search for the Mind in the Command System, a complex of subterranean railway stations formerly part of a nuclear missile complex. These were built by the inhabitants of Schar before their extinction. Horza has kept Balveda alive, and she is taken with the rest of the crew into the complex. They soon discover that the Mind is being hunted by a pair of Idiran soldiers who have killed all the Changers stationed on the planet, and who regard Horza and his crew as enemies, having no knowledge of the Changers' alliance with the Idirans. The \"CAT\"'s crew encounter the Idirans in one of the Command System stations, and after a firefight apparently kill one and capture the other. After tracking the Mind to another station, they discover it hiding in the reactor car of a Command System train. The second Idiran, who had been mortally wounded but not killed, sets one of the trains for a collision course to the station. The captured Idiran, Xoxarle, frees himself and in the ensuing impact and firefight the remaining members of the \"Clear Air Turbulence\" are killed. Horza pursues Xoxarle and is fatally injured, but the Idiran is killed by Balveda.\nHorza dies soon after Balveda gets him to the surface, and the Mind is returned to the Culture. In an epilogue, the Mind becomes a starship, and reveals having taken the name \"Bora Horza Gobuchul\".\nHistory and theme.\n\"Consider Phlebas\", like most of Banks's early SF output, was a rewritten version of an earlier book, as he explained in a 1994 interview:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Phlebas\" was an old one too; it was written just after \"The Wasp Factory\", in 1984. I've found that rewriting an old book took much more effort than writing one from scratch, but I had to go back to do right by these things. Now I can go on and start completely new stuff.On the theme of the novel, he said:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;There's a big war going on in that novel, and various individuals and groups manage to influence its outcome. But even being able to do that doesn't ultimately change things very much. At the book's end, I have a section pointing this out by telling what happened after the war, which was an attempt to pose the question, 'What was it all for?' I guess this approach has to do with my reacting to the clich\u00e9 of SF's 'lone protagonist.' You know, this idea that a single individual can determine the direction of entire civilizations. It's very, very hard for a lone person to do that. And it sets you thinking what difference, if any, it would have made if Jesus Christ, or Karl Marx or Charles Darwin had never been. We just don't know.\nLiterary significance and criticism.\nThe book was generally very well received as a fast-paced space opera with a morally ambiguous hero and much grand scenery and devices. \"Kirkus Reviews\" described it as \"Overextended and jarring\", but \"imaginative and gripping in places.\"\nDave Langford reviewed \"Consider Phlebas\" for \"White Dwarf\" #90, and stated that \"Banks pumps in enough high spirits to keep this rattling along to his slam-bang finale in the bowels of an ancient deep-shelter system whose nuclear-powered high-speed trains are used for... well, not commuting.\"\nIn other media.\nTV adaptation.\nAmazon announced in February 2018 that it acquired the global television rights to \"Consider Phlebas\", to be adapted by Dennis Kelly into a television series and produced by Plan B Entertainment. The project was cancelled in August 2020.\nHowever, in February 2025, Deadline reported that Amazon MGM Studios was developing a television series of \"Consider Phlebas\", to be written by Charles Yu.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58623", "revid": "42964511", "url": "https://en.wikipedia.org/wiki?curid=58623", "title": "The Culture", "text": "Fictional universe created by Iain Banks\nThe Culture is a fictional interstellar post-scarcity civilisation or society created by the Scottish writer Iain Banks and features in a number of his space opera novels and works of short fiction, collectively called the \"Culture\" series.\nIn the series, the Culture is composed primarily of sentient beings of the humanoid alien variety, artificially intelligent sentient machines, and a small number of other sentient \"alien\" life forms. Machine intelligences range from human-equivalent drones to hyper-intelligent Minds. Artificial intelligences with capabilities measured as a fraction of human intelligence also perform a variety of tasks, e.g. controlling spacesuits. Without scarcity, the Culture has no need for money; instead, Minds voluntarily indulge humanoid and drone citizens' pleasures, leading to a largely hedonistic society. Many of the series' protagonists are humanoids who have chosen to work for the Culture's diplomatic or espionage organs, and interact with other civilisations whose citizens act under different ideologies, morals, and technologies.\nThe Culture has a grasp of technology that is advanced relative to most other civilisations with which it shares the galaxy. Most of the Culture's citizens do not live on planets but in artificial habitats such as orbitals and ships, the largest of which are home to billions of individuals. The Culture's citizens have been genetically enhanced to live for centuries and have modified mental control over their physiology, including the ability to introduce a variety of psychoactive drugs into their systems, change biological sex, or switch off pain at will. Culture technology is able to transfer individuals into vastly different body forms, although the Culture standard form remains fairly close to human.\nThe Culture holds peace and individual freedom as core values, and a central theme of the series is the ethical struggle it faces when interacting with other societies \u2013 some of which brutalise their own members, pose threats to other civilisations, or threaten the Culture itself. It tends to make major decisions based on the consensus formed by its Minds and, if appropriate, its citizens. In one instance, a direct democratic vote of trillions \u2013 the entire population \u2013 decided The Culture would go to war with a rival civilisation. Those who objected to the Culture's subsequent militarisation broke off from the meta-civilisation, forming their own separate civilisation; a hallmark of the Culture is its ambiguity. In contrast to the many interstellar societies and empires which share its fictional universe, the Culture is difficult to define, geographically or sociologically, and \"fades out at the edges\".\nOverview.\nThe Culture is characterised as a post-scarcity society, having overcome most physical constraints on life and being an egalitarian, stable society without the use of any form of force or compulsion, except where necessary to protect others. That being said, some citizens, including the extremely powerful artificial intelligences, Minds, sometimes engage in the manipulation of others. This can include influencing or controlling the development of alien societies, through the group known as Contact.\nThe novels of the Culture cycle mostly deal with people at the fringes of the Culture: diplomats, spies, or mercenaries; those who interact with other civilisations, and who do the Culture's dirty work in moving those societies closer to the Culture ideal, sometimes by force.\nFictional history.\nIn this fictional universe, the Culture exists concurrently with human society on Earth. The time frame for the published Culture stories is from 1267 CE to roughly 2970 CE, with Earth being contacted around 2100 CE, though the Culture had covertly visited the planet in the 1970s in \"The State of the Art\".\nThe Culture itself is described as having been created when several humanoid species and machine sentiences reached a certain social level, and took not only their physical, but also their civilisational evolution into their own hands. In \"The Player of Games\", the Culture is described as having existed as a space-faring society for eleven thousand years. In \"The Hydrogen Sonata\", one of these founding civilisations was named as the Buhdren Federality.\nSociety and culture.\nEconomy.\nThe Culture is a symbiotic society of artificial intelligences (AIs) (Minds and drones), humanoids and other alien species who all share equal status. All essential work is performed (as far as possible) by non-sentient devices, freeing sentients to do only things that they enjoy (administrative work requiring sentience is undertaken by the AIs using a bare fraction of their mental power, or by people who take on the work out of free choice). As such, the Culture is a post-scarcity society, where technological advances ensure that no one lacks any material goods or services. Energy is farmed from a fictitious \"energy grid\", and matter to build orbitals is collected mostly from asteroids. As a consequence, the Culture has no need of economic constructs such as money (as is apparent when it deals with civilisations in which money is still important). The Culture rejects all forms of economics based on anything other than voluntary activity. \"Money implies poverty\" is a common saying in the Culture.\nLanguage.\nMarain is the Culture's shared constructed language. The Culture believes the Sapir\u2013Whorf hypothesis that language influences thought, and Marain was designed by early Minds to exploit this effect, while also \"appealing to poets, pedants, engineers and programmers\". Designed to be represented either in binary or symbol-written form, Marain is also regarded as an aesthetically pleasing language by the Culture. The symbols of the Marain alphabet can be displayed in three-by-three grids of binary (yes/no, black/white) dots and thus correspond to nine-bit binary numbers.\nRelated comments are made by the narrator in \"The Player of Games\" regarding gender-specific pronouns, which Marain speakers do not use in typical conversation unless specifying one's gender is necessary, and by general reflection on the fact that Marain places much less structural emphasis on (or even lacks) concepts like possession and ownership, dominance and submission, and especially aggression. Many of these concepts would in fact be somewhat theoretical to the average Culture citizen. Indeed, the presence of these concepts in other civilisation signify the brutality and hierarchy associated with forms of empire that the Culture strives to avoid.\nMarain itself is also open to encryption and dialect-specific implementations for different parts of the Culture. M1 is basic Nonary Marain, the three-by-three grid. All Culture citizens can communicate in this variant. Other variants include M8 through M16, which are encrypted by various degrees, and are typically used by the Contact Section. Higher level encryptions exist, the highest of these being M32. M32 and lower level encrypted signals are the province of Special Circumstances (SC). Use of M32 is reserved for extremely secret and reserved information and communication within Special Circumstances. That said, M32 has an air of notoriety in the Culture, and in the thoughts of most may best be articulated as \"the Unbreakable, Inviolable, Holy of Holies Special Circumstances M32\" as described by prospective SC agent Ulver Seich. Ships and Minds also have a slightly distasteful view of SC procedure associated with M32, one Ship Mind going so far as to object to the standard SC attitude of \"Full scale, stark raving M32 don't-talk-about-this-or-we'll-pull-your-plugs-out-baby paranoia\" on the use of the encryption.\nLaws.\nThere are no laws as such in the Culture. Social norms are enforced by convention (personal reputation, \"good manners\", and by, as described in \"The Player of Games\", possible ostracism and involuntary supervision for more serious crimes). Minds generally refrain from using their all-seeing capabilities to influence people's reputations, though they are not necessarily themselves above judging people based on such observations, as described in \"Excession\". Minds also judge each other, with one of the more relevant criteria being the quality of their treatment of sentients in their care. Hub Minds for example are generally nominated from well-regarded GSV (the largest class of ships) Minds, and then upgraded to care for the billions living on the artificial habitats.\nThe only serious prohibitions that seem to exist are against harming sentient beings, or forcing them into undertaking any act (another concept that seems unnatural to and is, in fact, almost unheard of by almost all Culture citizens). As mentioned in \"The Player of Games\", the Culture does have the occasional \"crime of passion\" (as described by an Azadian) and the punishment was to be \"slap-droned\", or to have a drone assigned to follow the offender and \"make sure [they] don't do it again\".\nWhile the enforcement in theory could lead to a Big Brother-style surveillance society, in practice social convention among the Minds prohibits them from watching, or interfering in, citizens' lives unless requested, or unless they perceive severe risk. The practice of reading a sentient's mind without permission (something the Culture is technologically easily capable of) is also strictly taboo. The whole plot of \"Look to Windward\" relies on a Hub Mind not reading an agent's mind (with certain precautions in case this rule gets violated). Minds that do so anyway are considered deviant and shunned by other Minds (see GCU \"Grey Area\"). At one point it is said that if the Culture actually had written laws, the sanctity of one's own thoughts against the intrusion of others would be the first on the books.\nThis gives some measure of privacy and protection; though the very nature of Culture society would, strictly speaking, make keeping secrets irrelevant: most of them would be considered neither shameful nor criminal. It does allow the Minds in particular to scheme amongst themselves in a very efficient manner, and occasionally withhold information.\nSymbols.\nThe Culture has no flag, symbol or logo. According to \"Consider Phlebas\", people can recognise items made by the Culture implicitly, by the way they are simple, efficient and aesthetic. The main outright symbol of the Culture is its language, Marain, which is used far beyond the Culture itself. It is often employed in the galaxy as a de facto lingua franca among people who don't share a language. Marain has a similar purpose to other constructed languages encountered in utopian and dystopian fiction including Pravic in \"The Dispossessed\" and Newspeak in \"Nineteen Eighty-Four\".\nCitizens.\nBiological.\nThe Culture is a posthuman society, which originally arose when seven or eight roughly humanoid space-faring species coalesced into a quasi-collective (a group-civilisation) ultimately consisting of approximately thirty trillion (short scale) sentient and sapient beings (this includes artificial intelligences). In Banks's universe, a good part (but by no means an overwhelming percentage) of all sentient species is of the \"pan-human\" type, as noted in \"Matter\".\nAlthough the Culture was originated by humanoid species, subsequent interactions with other civilisations have introduced many non-humanoid species into the Culture (including some former enemy civilisations), though the majority of the biological Culture is still pan-human. Little uniformity exists in the Culture, and its citizens are such by choice, free to change physical form and even species (though some stranger biological conversions are irreversible, and conversion from biological to artificial sentience is considered to be what is known as an Unusual Life Choice). All members are also free to join, leave, and rejoin, or indeed declare themselves to be, say, 80% Culture.\nWithin the novels, opponents of the Culture have argued that the role of humans in the Culture is nothing more than that of pets, or parasites on Culture Minds, and that they can have nothing genuinely useful to contribute to a society where science is close to omniscient about the physical universe, where every ailment has been cured, and where every thought can be read. Many of the Culture novels in fact contain characters (from within or without the Culture) wondering how far-reaching the Minds' dominance of the Culture is, and how much of the democratic process within it might in fact be a sham: subtly but very powerfully influenced by the Minds in much the same ways Contact and Special Circumstances influence other societies. Also, except for some mentions about a vote over the Idiran-Culture War, and the existence of a very small number of \"Referrers\" (humans of especially acute reasoning), few biological entities are ever said to be involved in any high-level decisions.\nOn the other hand, the Culture can be seen as fundamentally hedonistic (one of the main objectives for any being, including Minds, is to have fun rather than to be \"useful\"). Also, Minds are constructed, by convention, to care for and value human beings. While a General Contact Unit (GCU) does not strictly need a crew (and could construct artificial avatars when it did), a real human crew adds richness to its existence, and offers distraction during otherwise dull periods. In \"Consider Phlebas\" it is noted that Minds still find humans fascinating, especially their odd ability to sometimes achieve similarly advanced reasoning as their much more complex machine brains.\nTo a large degree, the freedoms enjoyed by humans in the Culture are only available because Minds choose to provide them. The freedoms include the ability to leave the Culture when desired, often forming new associated but separate societies with Culture ships and Minds, most notably the Zetetic Elench and the ultra-pacifist and non-interventionist Peace Faction.\nPhysiology.\nTechniques in genetics have advanced in the Culture to the point where bodies can be freed from built-in limitations. Citizens of the Culture refer to a normal human as \"human-basic\" and the vast majority opt for significant enhancements: severed limbs grow back, sexual physiology can be voluntarily changed from male to female and back (though the process takes time), sexual stimulation and endurance are strongly heightened in both sexes (something that is often the subject of envious debate among other species), pain can be switched off, toxins can be bypassed away from the digestive system, autonomic functions such as heart rate can be switched to conscious control, reflexes like blinking can be switched off, and bones and muscles adapt quickly to changes in gravity without the need to exercise. The degree of enhancement found in Culture individuals varies to taste, with certain of the more exotic enhancements limited to Special Circumstances personnel (for example, weapons systems embedded in various parts of the body).\nMost Culture individuals opt to have drug glands that allow for hormonal levels and other chemical secretions to be consciously monitored, released and controlled. These allow owners to secrete on command any of a wide selection of synthetic drugs, from the merely relaxing to the mind-altering: \"Snap\" is described in \"Use of Weapons\" and \"The Player of Games\" as \"The Culture's favourite breakfast drug\". \"Sharp Blue\" is described as a utility drug, as opposed to a sensory enhancer or a sexual stimulant, that helps in problem solving. \"Quicken\", mentioned in \"Excession\", speeds up the user's neural processes so that time seems to slow down, allowing them to think and have mental conversation (for example with artificial intelligences) in far less time than it appears to take to the outside observer. \"Sperk\", as described in \"Matter\", is a mood- and energy-enhancing drug, while other such self-produced drugs include \"Calm\", \"Gain\", \"Charge\", \"Recall\", \"Diffuse\", \"Somnabsolute\", \"Softnow\", \"Focal\", \"Edge\", \"Drill\", \"Gung\", \"Winnow\" and \"Crystal Fugue State\". The glanded substances have no permanent side-effects and are non-habit-forming.\nPhenotypes.\nFor all their genetic improvements, the Culture is by no means eugenically uniform. Human members in the Culture setting vary in size, colour and shape as in reality, and with possibly even further natural differences: in the novella \"The State of the Art\", it is mentioned that a character \"looks like a Yeti\", and that there is variance among the Culture in minor details such as the number of toes or of joints on each finger. It is mentioned in \"Excession\" that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;the tenor of the time had generally turned against... outlandishness and people had mostly returned to looking more like people over the last millennium... (previously) as the fashions of the intervening times had ordained\u00a0\u2013 people... had resembled birds, fish, dirigible balloons, snakes, small clouds of cohesive smoke and animated bushes.\nSome Culture citizens opt to leave the constraints of a human or even humanoid body altogether, opting to take on the appearance of one of the myriad other galactic sentients (perhaps in order to live with them) or even non-sentient objects as commented upon in \"Matter\" (though this process can be irreversible if the desired form is too removed from the structure of the human brain). Certain eccentrics have chosen to become drones or even Minds themselves, though this is considered rude and possibly even insulting by most humans and AIs alike.\nWhile the Culture is generally pan-humanoid (and tends to call itself \"human\"), various other species and individuals of other species have become part of the Culture.\nAs all Culture citizens are of perfect genetic health, the very rare cases of a Culture citizen showing any physical deformity are almost certain to be a sort of fashion statement of somewhat dubious taste.\nPersonality.\nAlmost all Culture citizens are very sociable and of great intellectual capability and learning, and possess very well\u2011balanced psyches. Their biological make-up and their growing up in an enlightened society make neuroses and lesser emotions like greed or (strong) jealousy practically unknown, and produce persons that, in any lesser society, appear very self-composed and charismatic. Character traits like strong shyness, while very rare, are not fully unknown, as shown in \"Excession\". As described there and in \"Player of Games\", a Culture citizen who becomes dysfunctional enough to pose a serious nuisance or threat to others would be offered (voluntary) psychological adjustment therapy and might potentially find themself under constant (non-voluntary) oversight by representatives of the local Mind. In extreme cases, as described in \"Use of Weapons\" and \"Surface Detail\", dangerous individuals have been known to be assigned a \"slap-drone\", a robotic follower who ensures that the person in question doesn't continue to endanger the safety of others.\nArtificial.\nAs well as humans and other biological species, sentient artificial intelligences are also members of the Culture. These can be broadly categorised into drones and Minds. Also, by custom, as described in \"Excession\", any artifact (be it a tool or vessel) above a certain capability level has to be given sentience.\nDrones.\nDrones are roughly comparable in intelligence and social status to that of the Culture's biological members. Their intelligence is measured against that of an average biological member of the Culture; a so-called \"1.0 value\" drone would be considered the mental equal of a biological citizen, whereas lesser drones such as the menial service units of Orbitals are merely proto-sentient (capable of limited reaction to unprogrammed events, but possessing no consciousness, and thus not considered citizens; these take care of much of the menial work in the Culture). The sentience of advanced drones has various levels of redundancy, from systems similar to that of Minds (though much reduced in capability) down to electronic, to mechanical and finally biochemical back-up brains.\nAlthough drones are artificial, the parameters that prescribe their minds are not rigidly constrained, and sentient drones are full individuals, with their own personalities, opinions and quirks. Like biological citizens, Culture drones generally have lengthy names. They also have a form of sexual intercourse for pleasure, called being \"in thrall\", though this is an intellect-only interfacing with another sympathetic drone.\nWhile civilian drones do generally match humans in intelligence, drones built especially as Contact or Special Circumstances agents are often several times more intelligent, and imbued with extremely powerful senses, powers and armaments (usually forcefield and effector-based, though occasionally more destructive weaponry such as lasers or, exceptionally, \"knife-missiles\" are referred to) all powered by antimatter reactors. Despite being purpose-built, these drones are still allowed individual personalities and given a choice in lifestyle. Indeed, some are eventually deemed psychologically unsuitable as agents (for example as Mawhrin-Skel notes about itself in \"The Player of Games\") and must choose either mental reprofiling or demilitarisation and discharge from Special Circumstances.\nPhysically, drones are floating units of various sizes and shapes, usually with no visible moving parts. Drones get around the limitations of this inanimation with the ability to project \"fields\": both those capable of physical force, which allow them to manipulate objects, as well as visible, coloured fields called \"auras\", which are used to enable the drone to express emotion. There is a complex drone code based on aura colours and patterns (which is fully understood by biological Culture citizens as well). Drones have full control of their auras and can display emotions they're not feeling or can switch their aura off. The drone Jase, in \"Consider Phlebas\", is said to have been constructed before the use of auras, and refuses to be retrofitted with them, preferring to remain inscrutable.\nIn size drones vary substantially: the oldest still alive (eight or nine thousand years old) tend to be around the size of humans, whereas later technology allows drones to be small enough to lie in a human's cupped palm; modern drones may be any size between these extremes according to fashion and personal preference. Some drones are also designed as utility equipment with its own sentience, such as the gelfield protective suit described in \"Excession\".\nMinds.\nBy contrast to drones, Minds are orders of magnitude more powerful and intelligent than the Culture's other biological and artificial citizens. Typically they inhabit and act as the controllers of large-scale Culture hardware such as ships or space-based habitats. Unsurprisingly, given their duties, Minds are tremendously powerful: capable of running all of the functions of a ship or habitat, while holding potentially billions of simultaneous conversations with the citizens that live aboard them. To allow them to perform at such a high degree, they exist partially in hyperspace to get around hindrances to computing power such as the speed of light.\nSome inhabited planets and all orbitals have their own Minds: sapient, hyperintelligent machines originally built by biological species, which have evolved, redesigned themselves, and become many times more intelligent than their original creators. According to \"Consider Phlebas\", a Mind is an ellipsoid object roughly the size of a bus and weighing around tons. A Mind is in fact a 4-D entity, meaning that the ellipsoid is only the protrusion of the larger four dimensional device into our 3D 'real space'.\nIn the Culture universe, Minds have become an indispensable part of the prevailing society, enabling much of its post-scarcity amenities by planning and automating societal functions, and by handling day-to-day administration with mere fractions of their mental power.\nThe main difference between Minds and other extremely powerful artificial intelligences in fiction is that they are highly humanistic and benevolent. They are so both by design, and by their shared culture. They are often even rather eccentric. Yet, by and large, they show no wish to supplant or dominate their erstwhile creators.\nOn the other hand, it can also be argued that to the Minds, the human-like members of the Culture amount to little more than pets, whose wants are followed on a Mind's whim. Within the Series, this dynamic is played on more than once. In 'Excession', it is also played on to put a Mind in its place \u2013 in the mythology, a Mind is not thought to be a god, still, but an artificial intelligence capable of surprise, and even fear.\nAlthough the Culture is a type of utopian anarchy, Minds most closely approach the status of leaders, and would likely be considered godlike in less rational societies. As independent, thinking beings, each has its own character, and indeed, legally (insofar as the Culture has a 'legal system'), each is a Culture citizen. Some Minds are more aggressive, some more calm; some don't mind mischief, others simply demonstrate intellectual curiosity. But above all they tend to behave rationally and benevolently in their decisions.\nAs mentioned before, Minds can serve several different purposes, but Culture ships and habitats have one special attribute: the Mind and the ship or habitat are perceived as one entity; in some ways the Mind \"is\" the ship, certainly from its passengers' point of view. It seems normal practice to address the ship's Mind as \"Ship\" (and an Orbital hub as \"Hub\"). However, a Mind can transfer its 'mind state' into and out of its ship 'body', and even switch roles entirely, becoming (for example) an Orbital Hub from a warship.\nMore often than not, the Mind's character defines the ship's purpose. Minds do not end up in roles unsuited to them; an antisocial Mind simply would not volunteer to organise the care of thousands of humans, for example.\nOn occasion groupings of two or three Minds may run a ship. This seems normal practice for larger vehicles such as GSVs, though smaller ships only ever seem to have one Mind.\nBanks also hints at a Mind's personality becoming defined at least partially before its creation or 'birth'. Warships, as an example, are designed to revel in controlled destruction; seeing a certain glory in achieving a 'worthwhile' death also seems characteristic. The presence of human crews on board warships may discourage such recklessness, since in the normal course of things, a Mind would not risk beings other than itself.\nWith their almost godlike powers of reasoning and action comes a temptation to bend (or break) Cultural norms of ethical behaviour, if deemed necessary for some greater good. In \"The Player of Games\", a Culture citizen is blackmailed, apparently by Special Circumstances Minds, into assisting the overthrow of a barbaric empire, while in \"Excession\", a conspiracy by some Minds to start a war against an oppressive alien race nearly comes to fruition. Yet even in these rare cases, the essentially benevolent intentions of Minds towards other Culture citizens is never in question. More than any other beings in the Culture, Minds are the ones faced with the more complex and provocative ethical dilemmas.\nWhile Minds would likely have different capabilities, especially seeing their widely differing ages (and thus technological sophistication), this is not a theme of the books. It might be speculated that the older Minds are upgraded to keep in step with the advances in technology, thus making this point moot. It is also noted in \"Matter\" that every Culture Mind writes its own OS, thus continually improving itself and, as a side benefit, becoming much less vulnerable to outside takeover by electronic means and viruses, as every Mind's processing functions work differently.\nThe high computing power of the Mind is apparently enabled by thought processes (and electronics) being constantly in hyperspace (thus circumventing the light speed limit in computation). Minds do have back-up capabilities functioning with light-speed if the hyperspace capabilities fail \u2013 however, this reduces their computational powers by several orders of magnitude (though they remain sentient).\nThe storage capability of a GSV Mind is described in \"Consider Phlebas\" as 1030 bytes (1 million yottabytes).\nThe Culture is a society undergoing slow (by present-day Earth standards) but constant technological change, so the stated capacity of Minds is open to change. In the last 3,000 years, the capacity of Minds has increased considerably. By the time of the events of the novel \"Excession\" in the mid 19th century, Minds from the first millennium BCE are referred to jocularly as minds, with a small 'm'. Their capacities only allow them to be considered equivalent to what are now known as AI Cores, small (in the literal physical sense) Artificial intelligences used in shuttles, trans-light modules, Drones, and other machines not large enough for a full scale Mind. While still considered sentient, a mind's power at this point is considered greatly inferior to a contemporary Mind. That said, It is possible for Minds to have upgrades, improvements and enhancements given to them since construction, to allow them to remain up to date.\nUsing the sensory equipment available to the Culture, Minds can see inside solid objects; in principle they can also read minds by examining the cellular processes inside a living brain, but Culture Minds regard such mindreading as taboo. The only known Mind to break this Taboo, the GCU \"Grey Area\" seen in \"Excession\", is largely ostracised and shunned by other Minds as a result. In \"Look to Windward\" an example is cited of an attempt to destroy a Culture Mind by smuggling a minuscule antimatter bomb onto a Culture orbital inside the head of a Chelgrian agent. However the bomb ends up being spotted without the taboo being broken.\nIn \"Consider Phlebas\", a typical Mind is described as a mirror-like ellipsoid of several dozen cubic metres, but weighing many thousands of tons, due to the fact that it is made up of hyper-dense matter. It is noted that most of its 'body' only exists in the real world at the outer shell, the inner workings staying constantly within hyperspace.\nThe Mind in \"Consider Phlebas\" is also described as having internal power sources which function as back-up shield generators and space propulsion, and seeing the rational, safety-conscious thinking of Minds, it would be reasonable to assume that all Minds have such features, as well as a complement of drones and other remote sensors as also described.\nOther equipment available to them spans the whole range of the Culture's technological capabilities and its practically limitless resources. However, this equipment would more correctly be considered emplaced in the ship or orbital that the Mind is controlling, rather than being part of the Mind itself.\nMinds are constructed entities, which have general parameters fixed by their constructors (other Minds) before 'birth', not unlike biological beings. A wide variety of characteristics can be and are manipulated, such as introversion-extroversion, aggressiveness (for warships) or general disposition.\nHowever, the character of a Mind evolves as well, and Minds often change over the course of centuries, sometimes changing personality entirely. This is often followed by them becoming eccentric or at least somewhat odd. Others drift from the Culture-accepted ethical norms, and may even start influencing their own society in subtle ways, selfishly furthering their own views of how the Culture should act.\nMinds have also been known to commit suicide to escape punishment, or because of grief.\nMinds are constructed with a personality typical of the Culture's interests, i.e. full of curiosity, general benevolence (expressed in the 'good works' actions of the Culture, or in the protectiveness regarding sentient beings) and respect for the Culture's customs.\nNonetheless, Minds have their own interests in addition to what their peers expect them to do for the Culture, and may develop fascinations or hobbies like other sentient beings do.\nThe mental capabilities of Minds are described in \"Excession\" to be vast enough to run entire universe-simulations inside their own imaginations, exploring metamathical (a fictional branch of metamathematics) scenarios, an activity addictive enough to cause some Minds to totally withdraw from caring about our own physical reality into \"Infinite Fun Space\", their own, ironic and understated term for this sort of activity.\nOne of the main activities of Ship Minds is the guidance of spaceships from a certain minimum size upwards. A culture spaceship \"is\" the Mind and vice versa; there are no different names for the two, and a spaceship without a Mind would be considered damaged or incomplete to the Culture.\nShip Mind classes include General Systems Vehicle (GSV), Medium Systems Vehicle (MSV), Limited Systems Vehicle (LSV), General Contact Vehicle (GCV), General Contact Unit (GCU), Limited Contact Unit (LCU), Rapid Offensive Unit (ROU), General Offensive Unit (GOU), Limited Offensive Unit (LOU), Demilitarised ROU (dROU), Demilitarised GOU (dGOU), Demilitarised LOU (dLOU), Very Fast Picket (VFP\u2013synonym for dROU), Fast Picket (FP\u2013synonym for dGOU or dLOU), and Superlifter.\nThese ships provide a convenient 'body' for a Mind, which is too large and too important to be contained within smaller, more fragile shells. Following the 'body' analogy, it also provides the Mind with the capability of physical movement. As Minds are living beings with curiosity, emotion and wishes of their own, such mobility is likely very important to most.\nCulture Minds (mostly also being ships) usually give themselves whimsical names, though these often hint at their function as well. Even the names of warships retain this humorous approach, though the implications are much darker.\nSome Minds also take on functions which either preclude or discourage movement. These usually administer various types of Culture facilities:\nMinds (and, as a consequence, Culture starships) usually bear names that do a little more than just identify them. The Minds themselves choose their own names, and thus they usually express something about a particular Mind's attitude, character or aims in their personal life. They range from funny to just plain cryptic. Some examples are:\nNames.\nSome humanoid or drone Culture citizens have long names, often with seven or more words. Some of these words specify the citizen's origin (place of birth or manufacture), some an occupation, and some may denote specific philosophical or political alignments (chosen later in life by the citizen themselves), or make other similarly personal statements. An example would be Diziet Sma, whose full name is Rasd-Coduresa Diziet Embless Sma da' Marenhide:\nIain Banks gave his own Culture name as \"Sun-Earther Iain El-Bonko Banks of North Queensferry\".\nDeath.\nThe Culture has a relatively relaxed attitude towards death. Genetic manipulation and the continual benevolent surveillance of the Minds make natural or accidental death almost unknown. Advanced technology allows citizens to make backup copies of their personalities, allowing them to be resurrected in case of death. The form of that resurrection can be specified by the citizen, with personalities returning either in the same biological form, in an artificial form (see below), or even just within virtual reality. Some citizens choose to go into \"storage\" (a form of suspended animation) for long periods of time, out of boredom or curiosity about the future.\nAttitudes individual citizens have towards death are varied (and have varied throughout the Culture's history). While many, if not most, citizens make some use of backup technology, many others do not, preferring instead to risk death without the possibility of recovery (for example when engaging in extreme sports). These citizens are sometimes called \"disposables\", and are described in \"Look to Windward\". Taking into account such accidents, voluntary euthanasia for emotional reasons, or choices like sublimation (abandoning physical reality), the average lifespan of humans is said in \"Excession\" to be around 350 to 400 years. Some citizens choose to forgo death altogether, although this is rarely done and is viewed as an eccentricity. Other options instead of death include conversion of an individual's consciousness into an AI, joining of a group mind (which can include biological and non-biological consciousnesses), or subliming (usually in association with a group mind).\nConcerning the lifespan of drones and Minds, given the durability of Culture technology and the options of mindstate backups, it is reasonable to assume that they live as long as they choose. Even Minds, with their utmost complexity, are known to be backed up (and reactivated if they for example die in a risky mission, see \"GSV Lasting Damage\"). It is noted that even Minds themselves do not necessarily live forever either, often choosing to eventually sublime or even killing themselves (as does the double-Mind \"GSV Lasting Damage\" due to its choices in the Culture-Idiran war).\nScience and technology.\nAnti-gravity and forcefields.\nThe Culture (and other societies) have developed powerful anti-gravity abilities, closely related to their ability to manipulate forces themselves.\nIn this ability they can create action-at-a-distance\u00a0\u2013 including forces capable of pushing, pulling, cutting, and even fine manipulation, and forcefields for protection, visual display or plain destructive ability. Such applications still retain restrictions on range and power: while forcefields of many cubic kilometres are possible (and in fact, orbitals are held together by forcefields), even in the chronologically later novels, such as \"Look to Windward\", spaceships are still used for long-distance travel and drones for many remote activities.\nWith the control of a Mind, fields can be manipulated over vast distances. In \"Use of Weapons\", a Culture warship uses its electromagnetic effectors to hack into a computer light years away.\nArtificial intelligence.\nArtificial intelligences (and to a lesser degree, the non-sentient computers omnipresent in all material goods), form the backbone of the technological advances of the Culture. Not only are they the most advanced scientists and designers the Culture has, their lesser functions also oversee the vast (but usually hidden) production and maintenance capabilities of the society.\nThe Culture has achieved artificial intelligences where each Mind has thought processing capabilities many orders of magnitude beyond that of human beings, and data storage drives which, if written out on paper and stored in filing cabinets, would cover thousands of planets skyscraper high (as described by one Mind in \"Consider Phlebas\"). Yet it has managed to condense these entities to a volume of several dozen cubic metres (though much of the contents and the operating structure are continually in hyperspace). Minds also demonstrate reaction times and multitasking abilities orders of magnitude greater than any sentient being; armed engagements between Culture and equivalent technological civilisations sometimes occur in timeframes as short as microseconds, and standard Orbital Minds are capable of running all of the vital systems on the Orbital while simultaneously conversing with millions of the inhabitants and observing phenomena in the surrounding regions of space.\nAt the same time, it has achieved drone sentiences and capability of Special Circumstance proportions in forms that could fit easily within a human hand, and built extremely powerful (though not sentient) computers capable of fitting into tiny insect-like drones. Some utilitarian devices (such as spacesuits) are also provided with artificial sentience. These specific types of drones, like all other Culture AI, would also be considered citizens \u2013 though as described in the short story \"Descendant\", they may spend most of the time when their \"body\" is not in use in a form of remote-linked existence outside of it, or in a form of AI-level virtual reality.\nEnergy manipulation.\nA major feature of its post-scarcity society, the Culture is obviously able to gather, manipulate, transfer and store vast amounts of energy. While not explained in detail in the novels, this involves antimatter and the \"energy grid\", a postulated energy field dividing the universe from neighboring anti-matter universes, and providing practically limitless energy. Transmission or storage of such energy is not explained, though these capabilities must be powerful as well, with tiny drones capable of very powerful manipulatory fields and forces.\nThe Culture also uses various forms of energy manipulation as weapons, with \"gridfire\", a method of creating a dimensional rift to the energy grid, releasing astronomical amounts of energy into a region of non-hyperspace, being described as a sort of ultimate weapon more destructive than collapsed antimatter bombardment. One character in \"Consider Phlebas\" refers to gridfire as \"the weaponry of the end of the universe\". Gridfire resembles the zero-point energy used within many popular science fiction stories.\nMatter displacement.\nThe Culture (at least by the time of \"The Player of Games\") has developed a form of teleportation capable of transporting both living and unliving matter instantaneously via wormholes. This technology has not rendered spacecraft obsolete\u00a0\u2013 in \"Excession\" a barely apple-sized drone was displaced no further than a light-second at maximum range (mass being a limiting factor determining range), a tiny distance in galactic terms. The process also still has a very small chance of failing and killing living beings, but the chance is described as so small (1 in 61 million) that it normally only becomes an issue when transporting a large number of people and is only regularly brought up due to the Culture's safety conscious nature.\nDisplacement is an integral part of Culture technology, being widely used for a range of applications from peaceful to belligerent. Displacing warheads into or around targets is one of the main forms of attack in space warfare in the Culture universe. \"The Player of Games\" mentions that drones can be displaced to catch a person falling from a cliff before they impact the ground, as well.\nBrain\u2013computer interfaces.\nThrough \"neural lace\", a form of brain\u2013computer interface that is implanted into the brains of young people and grows with them, the Culture has the capability to read and store the full sentience of any being, biological or artificial, and thus reactivate a stored being after its death. The neural lace also allows wireless communication with the Minds and databases. This also necessitates the capability to read thoughts, but as described in \"Look to Windward\", doing this without permission is considered taboo.\nStarships and warp drives.\nStarships are living spaces, vehicles and ambassadors of the Culture. A proper Culture starship (as defined by hyperspace capability and the presence of a Mind to inhabit it) may range from several hundreds of metres to hundreds of kilometres. The latter may be inhabited by billions of beings and are artificial worlds in their own right, including whole ecosystems, and are considered to be self-contained representations of all aspects of Culture life and capability.\nThe Culture (and most other space-faring species in its universe) use a form of Hyperspace-drive to achieve faster-than-light speeds. Banks has evolved a (self-confessedly) technobabble system of theoretical physics to describe the ships' acceleration and travel, using such concepts as \"infraspace\" and \"ultraspace\" and an \"energy grid\" between universes (from which the warp engines \"push off\" to achieve momentum). An \"induced singularity\" is used to access infra or ultra space from real space; once there, \"engine fields\" reach down to the Grid and gain power and traction from it as they travel at high speeds.\nThese hyperspace engines do not use reaction mass and hence do not need to be mounted on the surface of the ship. They are described as very dense exotic matter, which only reveals its complexity under a powerful microscope. Acceleration and maximum speed depend on the ratio of the mass of the ship to its engine mass. As with any other matter aboard, ships can gradually manufacture extra engine volume or break it down as needed. In \"Excession\" one of the largest ships of the Culture redesigns itself to be mostly engine (by combining the hyperspace engine fields of thousands of semi-slaved warships which have been constructed in secret, and housed within the ship itself, and out of view) and reaches a speed of 233,000 times lightspeed. Within the range of the Culture's influence in the galaxy, most ships would still take years of travelling to reach the more remote spots.\nOther than the engines used by larger Culture ships, there are a number of other propulsion methods such as gravitic drive at sublight speeds, with antimatter, fusion and other reaction engines occasionally seen with less advanced civilisations, or on Culture hobby craft.\nWarp engines can be very small; some Culture drones barely larger than fist-size have them. There is also at least one (apparently non-sentient) species (the \"Chuy-Hirtsi\" animal), that possesses the innate capability of warp travel. In \"Consider Phlebas\", it is being used as a military transport by the Idirans, but no further details are given.\nNanotechnology.\nThe Culture has highly advanced nanotechnology, though descriptions of such technology in the books is limited. Many of the described uses are by or for Special Circumstances, but there are no indications that the use of nanotechnology is limited in any way. (In a passage in one of the books, there is a brief reference to the question of sentience when comparing the human brain or a \"pico-level substrate\".)\nOne of the primary clandestine uses of nanotechnology is information gathering. The Culture likes to be in the know, and as described in \"Matter\" \"they tend to know everything.\" Aside from its vast network of sympathetic allies and wandering Culture citizens one of the primary ways that the Culture keeps track of important events is by the use of practically invisible nanobots capable of recording and transmitting their observations. This technique is described as especially useful to track potentially dangerous people (such as ex-Special Circumstances agents). Via such nanotechnology, it is potentially possible for the Culture (or similarly advanced societies) to see everything happening on a given planet, orbital or any other habitat. The usage of such devices is limited by various treaties and agreements among the Involved.\nIn addition, EDust assassins are potent Culture terror weapons, composed entirely of nano machines called EDust, or \"Everything Dust.\" They are capable of taking almost any shape or form, including swarms of insects or entire humans or aliens, and possess powerful weaponry capable of levelling entire buildings.\nLiving space.\nMuch of the Culture's population lives on orbitals, vast artificial worlds that can accommodate billions of people. Others travel the galaxy in huge space ships such as General Systems Vehicles (GSVs) that can accommodate hundreds of millions of people. Almost no Culture citizens are described as living on planets, except when visiting other civilisations. The reason for this is partly because the Culture believes in containing its own expansion to self-constructed habitats, instead of colonising or conquering new planets. With the resources of the universe allowing permanent expansion (at least assuming non-exponential growth), this frees them from having to compete for living space.\nThe Culture, and other civilisations in Banks' universe, are described as living in these various, often constructed habitats:\nAirspheres.\nThese are vast, brown dwarf-sized bubbles of atmosphere enclosed by force fields, and (presumably) set up by an ancient advanced race at least one and a half billion years ago (see: Look to Windward). There is only minimal gravity within an airsphere. They are illuminated by moon-sized orbiting planetoids that emit enormous light beams.\nCitizens of the Culture live there only very occasionally as guests, usually to study the complex ecosystem of the airspheres and the dominant life-forms: the \"dirigible behemothaurs\" and \"gigalithine lenticular entities\", which may be described as inscrutable, ancient intelligences looking similar to a cross between gigantic blimps and whales. The airspheres slowly migrate around the galaxy, taking anywhere from 50 to 100 million years to complete one circuit. In the novels no one knows who created the airspheres or why, but it is presumed that whoever did has long since sublimed but may maintain some obscure link with the behemothaurs and lenticular entities. Guests in the airspheres are not allowed to use any force-field technology, though no reason has been offered for this prohibition.\nThe airspheres resemble in some respects the orbit-sized ring of breathable atmosphere created by Larry Niven in \"The Integral Trees\", but spherical not toroidal, require a force field to retain their integrity, and arose by artificial rather than natural processes.\nOrbitals.\nOne of the main types of habitats of the Culture, an orbital is a ring structure orbiting a star as would a megastructure akin to a bigger Bishop ring. Unlike a ringworld or a Dyson sphere, an orbital does not enclose the star (being much too small). Like a ringworld, the orbital rotates to provide an analog of gravity on the inner surface. A Culture orbital rotates about once every 24 hours and has gravity-like effect about the same as the gravity of Earth, making the diameter of the ring about (nearly five times the diameter of the Moon's orbit around Earth), and ensuring that the inhabitants experience night and day. Orbitals feature prominently in many Culture stories.\nPlanets.\nThough many other civilisations in the Culture books live on planets, the Culture as currently developed has little direct connection to on-planet existence. Banks has written that he presumes this to be an inherent consequence of space colonisation, and a foundation of the liberal nature of the Culture. A small number of home worlds of the founding member-species of the Culture receive a mention in passing, and a few hundred human-habitable worlds were colonised (some of them terraformed) before the Culture elected to turn towards artificial habitats, preferring to keep the planets it encounters wild. Since then, the Culture has come to look down on terraforming as inelegant, ecologically problematic and possibly even immoral. Less than one per cent of the population of the Culture lives on planets, and many find the very concept somewhat bizarre.\nThis attitude is not absolute though; in \"Consider Phlebas\", some Minds suggest testing a new technology on a \"spare planet\" (knowing that it could be destroyed in an antimatter explosion if unsuccessful). One could assume \u2013 from Minds' usual ethics \u2013 that such a planet would have been lifeless to start with. It is also quite possible, even probable, that the suggestion was not made in complete seriousness.\nRings.\nRingworld-like megastructures exist in the Culture universe; the texts refer to them simply as \"Rings\" (with a capital \"R\"). As opposed to the smaller orbitals which revolve around a star, these structures are massive and completely encircle a star. Banks does not describe these habitats in detail, but records one as having been destroyed (along with three Spheres) in the Idiran-Culture war. In \"Matter\", the Morthanveld people possesses ringworld-like structures made of innumerable various-sized tubes. Those structures, like Niven's Ringworld, encircle a star and are about the same size.\nRocks.\nThese are asteroids and other non-planetary bodies hollowed out for habitation and usually spun for centrifugal artificial gravity. Rocks (with the exception of those used for secretive purposes) are described as having faster-than-light space drives, and thus can be considered a special form of spaceship. Like Orbitals, they are usually administered by one or more Minds.\nRocks do not play a large part in most of the Culture stories, though their use as storage for mothballed military ships (\"Pittance\") and habitats (\"Phage Rock\", one of the founding communities of the Culture) are both key plot points in \"Excession\".\nShellworlds.\nShellworlds are introduced in \"Matter\", and consist of multilayered levels of concentric spheres in four dimensions held up by countless titanic interior towers. Their extra dimensional characteristics render some products of Culture technology too dangerous to use and yet others ineffective, notably access to hyperspace. About 4000 were built millions of years ago as vast machines intended to cast a forcefield around the whole of the galaxy for unknown purposes; less than half of those remain at the time of \"Matter\", many having been destroyed by a departed species known as the Iln. The species that developed this technology, known as the Veil or the Involucra, are now lost, and many of the remaining shellworlds have become inhabited, often by many different species throughout their varying levels. Many still hold deadly secret defence mechanisms, often leading to great danger for their new inhabitants, giving them one of their other nicknames: Slaughter Worlds.\nShips.\nShips in the Culture are intelligent individuals, often of very large size, controlled by one or more Minds. The ship is considered by the Culture generally and the Mind itself to be the Mind's body (compare avatars). Some ships (GSVs, for example) are tens or even hundreds of kilometres in length and may have millions or even billions of residents who live on them full-time; together with Orbitals, such ships represent the main form of habitat for the Culture. Such large ships may temporarily contain smaller ships with their own populations, and/or manufacture such ships themselves.\nIn \"Use of Weapons\", the protagonist Zakalwe is allowed to acclimatise himself to the Culture by wandering for days through the habitable levels of a ship (the GSV \"Size Isn't Everything\", which is described as over long), eating and sleeping at the many locations which provide food and accommodation throughout the structure and enjoying the various forms of contact possible with the friendly and accommodating inhabitants.\nSpheres.\nDyson spheres also exist in the Culture universe but receive only passing mention as \"Spheres\". Three spheres are recorded as having been destroyed in the Idiran-Culture war.\nInteraction with other civilisations.\nThe Culture, living mostly on massive spaceships and in artificial habitats, and also feeling no need for conquest in the typical sense of the word, possesses no borders. Its sphere of influence is better defined by the (current) concentration of Culture ships and habitats as well as the measure of effect its example and its interventions have already had on the \"local\" population of any galactic sector. As the Culture is also a very graduated and constantly evolving society, its societal boundaries are also constantly in flux (though they tend to be continually expanding during the novels), peacefully \"absorbing\" societies and individuals.\nWhile the Culture is one of the most advanced and most powerful of all galactic civilisations, it is still but one of the \"high-level Involved\" (called \"Optimae\" by some less advanced civilisations), the most powerful non-sublimed civilisations which mentor or control the others.\nAn Involved society is a highly advanced group that has achieved galaxy-wide involvement with other cultures or societies. There are a few dozen Involved societies and hundreds or thousands of well-developed (interstellar) but insufficiently influential societies or cultures. The well-developed societies which do not take a dynamic role in the galaxy as a whole are designated as \"galactically mature\". In the novels, the Culture might be considered the premier Involved society, or at least the most dynamic and energetic, especially given that the Culture itself is a growing multicultural fusion of Involved societies. \nThe Involved are contrasted with the Sublimed, groups that have reached a high level of technical development and galactic influence but subsequently abandoned physical reality, ceasing to take serious interventionist interest in galactic civilisation. They are also contrasted with what some Culture people loosely refer to as \"barbarians\", societies of intelligent beings which lack the technical capacity to know about or take a serious role in their interstellar neighbourhood. There are also the elder civilisations, which are civilisations that reached the required level of technology for sublimation, but chose not to, and have retreated from the larger galactic meta-civilisation.\nThe Involved are also contrasted with hegemonising swarms (a term used in several of Banks' Culture novels). These are entities that exist to convert as much of the universe as possible into more of themselves; most typically these are technological in nature, resembling more sophisticated forms of grey goo, but the term can be applied to cultures that are sufficiently single-minded in their devotion to mass conquest, control, and colonisation. Both the Culture and the author (in his \"Notes on the Culture\") find this behaviour quixotic and ridiculous. Most often, societies categorised as hegemonising swarms consist of species or groups newly arrived in the galactic community with highly expansionary and exploitative goals. The usage of the term \"hegemonising swarm\" in this context is considered derisive in the Culture and among other Involved and is used to indicate their low regard for those with these ambitions by comparing their behaviour to that of mindless self-replicating technology. The Culture's central moral dilemma regarding intervention in other societies can be construed as a conflict between the desire to help others and the desire to avoid becoming a hegemonising swarm themselves.\nForeign policy.\nAlthough they lead a comfortable life within the Culture, many of its citizens feel a need to be useful and to belong to a society that does not merely exist for their own sake but that also helps improve the lot of sentient beings throughout the galaxy. For that reason the Culture carries out \"good works\", covertly or overtly interfering in the development of lesser civilisations, with the main aim to gradually guide them towards less damaging paths. As Culture citizens see it, these good works provide the Culture with a \"moral right to exist\".\nA group within the Culture, known as Contact, is responsible for its interactions (diplomatic or otherwise) with other civilisations. Non-Contact citizens are apparently not prevented from travelling or interacting with other civilisations, though the effort and potential danger involved in doing so alone makes it much more commonly the case for Culture people simply to join Contact if they long to \"see the world\". Further within Contact, an intelligence organisation named Special Circumstances exists to deal with interventions which require more covert behaviour; the interventionist approach that the Culture takes to advancing other societies may often create resentment in the affected civilisations and thus requires a rather delicate touch (see: \"Look to Windward\").\nIn \"Matter\", it is described that there are a number of other galactic civilisations that come close to or potentially even surpass the Culture in power and sophistication. The Culture is very careful and considerate of these groupings, and while still trying to convince them of the Culture ideal, will be much less likely to openly interfere in their activities.\nIn \"Surface Detail\", three more branches of Contact are described: Quietus, the Quietudinal Service, whose purview is dealing with those entities who have retired from biological existence into digital form and/or those who have died and been resurrected; Numina, which is described as having the charge of contact with races that have sublimed; and Restoria, a subset of Contact which focuses on containing and negating the threat of swarms of self-replicating creatures (\"hegswarms\").\nBehaviour in war.\nWhile the Culture is normally pacifist, Contact historically acts as its military arm in times of war and Special Circumstances can be considered its secret service and its military intelligence. During war, most of the strategic and tactical decisions are taken by the Minds, with apparently only a small number of especially gifted humans, the \"Referrers\", being involved in the top-level decisions, though they are not shown outside \"Consider Phlebas\". It is shown in \"Consider Phlebas\" that actual decisions to go to war (as opposed to purely defensive actions) are based on a vote of all Culture citizens, presumably after vigorous discussion within the whole society.\nIt is described in various novels that the Culture is extremely reluctant to go to war, though it may start to prepare for it long before its actual commencement. In the Idiran-Culture War (possibly one of the most hard-fought wars for the normally extremely superior Culture forces), various star systems, stellar regions and many orbital habitats were overrun by the Idirans before the Culture had converted enough of its forces to military footing. The Culture Minds had had enough foresight to evacuate almost all its affected citizens (apparently numbering in the many billions) in time before actual hostilities reached them. As shown in \"Player of Games\", this is a standard Culture tactic, with its strong emphasis on protecting its citizens rather than sacrificing some of them for short-term goals.\nWar within the Culture is mostly fought by the Culture's sentient warships, the most powerful of these being war-converted GSVs, which are described as powerful enough to oppose whole enemy fleets. The Culture has little use for conventional ground forces (as it rarely occupies enemy territory); combat drones equipped with knife missiles do appear in \"Descendant\" and \"terror weapons\" (basically intelligent, nano-form assassins) are mentioned in \"Look to Windward\", while infantry combat suits of great power (also usable as capable combat drones when without living occupants) are used in \"Matter\".\nRelevance to real-world politics.\nThe inner workings of The Culture are not especially described in detail though it is shown that the society is populated by an empowered, educated and augmented citizenry in a direct democracy or highly democratic and transparent system of self-governance. In comparisons to the real world, intended or not, the Culture could resemble various posited egalitarian societies including in the writings of Karl Marx, the end condition of communism after a withering away of the state, the anarchism of Bakunin and Fourier et al., libertarian socialism, council communism and anarcho-communism. Other characteristics of The Culture that are recognisable in real world politics include pacifism, post-capitalism, and transhumanism. Banks deliberately portrayed an imperfect utopia whose imperfection or weakness is related to its interaction with the 'other', that is, exterior civilisations and species that are sometimes variously warred with or mishandled through the Culture's Contact section which cannot always control its intrigues and the individuals it either 'employs' or interacts with. This 'dark side' of The Culture also alludes to or echoes mistakes and tragedies in 20th century Marxist\u2013Leninist countries, although the Culture is generally portrayed as far more 'humane' and just.\nUtopia.\nComparisons are often made between the Culture and twentieth and twenty-first century Western civilisation and nation-states, particularly their interventions in less-developed societies. These are often confused with regard to the author's assumed politics.\nBen Collier has said that the Culture is a utopia carrying significantly greater moral legitimacy than the West's, by comparison, proto-democracies. While Culture interventions can seem similar at first to Western interventions, especially when considered with their democratising rhetoric, the argument is that the Culture operates completely without material need, and therefore without the possibility of baser motives. This is not to say that the Culture's motives are purely altruistic; a peaceful, enlightened universe full of good neighbours lacking ethnic, religious, and sexual chauvinisms is in the Culture's interest as well. Furthermore, the Culture's ideals, in many ways similar to those of the liberal perspective today, are to a much larger extent realised internally in comparison to the West.\nCriticism.\nExamples are the use of mercenaries to perform the work that the Culture does not want to get their hands dirty with, and even outright threats of invasion (the Culture has issued ultimatums to other civilisations before). Some commentators have also argued that those Special Circumstances agents tasked with civilising foreign cultures (and thus potentially also changing them into a blander, more Culture-like state) are also those most likely to regret these changes, with parallels drawn to real-world special forces trained to operate within the cultural mindsets of foreign nations.\nThe events of \"Use of Weapons\" are an example of just how dirty Special Circumstances will play in order to get their way and the conspiracy at the heart of the plot of \"Excession\" demonstrates how at least some Minds are prepared to risk killing sentient beings when they conclude that these actions are beneficial for the long term good. Special Circumstances represents a very small fraction of Contact, which itself is only a small fraction of the entire Culture, making it comparable again to size and influence of modern intelligence agencies.\nIssues raised.\nThe Culture stories are largely about problems and paradoxes that confront liberal societies. The Culture itself is an \"ideal-typical\" liberal society; that is, as pure an example as one can reasonably imagine. It is highly egalitarian; the liberty of the individual is its most important value; and all actions and decisions are expected to be determined according to a standard of reasonability and sociability inculcated into all people through a progressive system of education. It is a society so beyond material scarcity that for almost all practical purposes its people can have and do what they want. If they do not like the behaviour or opinions of others, they can easily move to a more congenial Culture population centre (or Culture subgroup), and hence there is little need to enforce codes of behaviour.\nEven the Culture has to compromise its ideals where diplomacy and its own security are concerned. Contact, the group that handles these issues, and Special Circumstances, its secret service division, can employ only those on whose talents and emotional stability it can rely, and may even reject self-aware drones built for its purposes that fail to meet its requirements. Hence these divisions are regarded as the Culture's elite and membership is widely regarded as a prize; yet also something that can be shameful as it contradicts many of the Culture's moral codes.\nWithin Contact and Special Circumstances, there are also inner circles that can take control in crises, somewhat contradictory to the ideal notions of democratic and open process the Culture espouses. Contact and Special Circumstances may suppress or delay the release of information, for example to avoid creating public pressure for actions they consider imprudent or to prevent other civilisations from exploiting certain situations.\nIn dealing with less powerful regressive civilisations, the Culture usually intervenes discreetly, for example by protecting and discreetly supporting the more liberal elements, or subverting illiberal institutions. For instance, in \"Use of Weapons\", the Culture operates within a less advanced illiberal society through control of a business cartel which is known for its humanitarian and social development investments, as well as generic good Samaritanism. In \"Excession\", a sub-group of Minds conspires to provoke a war with the extremely sadistic Affront, although the conspiracy is foiled by a GSV that is a deep cover Special Circumstances agent. Only one story, \"Consider Phlebas\", pits the Culture against a highly illiberal society of approximately equal power: the aggressive, theocratic Idirans. Though they posed no immediate, direct threat to the Culture, the Culture declared war because it would have felt useless if it allowed the Idirans' ruthless expansion to continue. The Culture's decision was a value-judgement rather than a utilitarian calculation, and the \"Peace Faction\" within the Culture seceded. Later in the timeline of the Culture's universe, the Culture has reached a technological level at which most past civilisations have Sublimed, in other words disengaged from Galactic politics and from most physical interaction with other civilisations. The Culture continues to behave \"like an idealistic adolescent\".\nAs of 2008, three stories force the Culture to consider its approach to more powerful civilisations. In one incident during the Culture\u2013Idiran War, they strive to avoid offending a civilisation so advanced that it has disengaged from Galactic politics, and note that this hyper-advanced society is not a threat to either the welfare or the values of the Culture. In \"Excession\", an overwhelmingly more powerful individual from an extremely advanced civilisation is simply passing through on its way from one plane of the physical Reality to another, and there is no real interaction. In the third case it sets up teams to study a civilisation that is not threatening but is thought to have eliminated aggressors in the past.\nBanks on the Culture.\nWhen asked in \"Wired\" magazine (June 1996) whether mankind's fate depends on having intelligent machines running things, as in the Culture, Banks replied:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Not entirely, no. I think the first point to make about the Culture is, I'm just making it up as I go along. It doesn't exist and I don't delude myself that it does. It's just my take on it. I'm not convinced that humanity is capable of becoming the Culture because I think people in the Culture are just too nice\u00a0\u2013 altering their genetic inheritance to make themselves relatively sane and rational and not the genocidal, murdering bastards that we seem to be half the time.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;But I don't think you have to have a society like the Culture in order for people to live. The Culture is a self-consciously stable and long-lived society that wants to go on living for thousands of years. Lots of other civilisations within the same universe hit the Culture's technological level and even the actuality of the Culture's utopia, but it doesn't last very long\u00a0\u2013 that's the difference.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The point is, humanity can find its own salvation. It doesn't necessarily have to rely on machines. It'll be a bit sad if we did, if it's our only real form of progress. Nevertheless, unless there's some form of catastrophe, we are going to use machines whether we like it or not. This sort of stuff has been going on for decades and mainstream society is beginning to catch up to the implications of artificial intelligence.\nIn a 2002 interview with \"Science Fiction Weekly\" magazine, when asked:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Excession\" is particularly popular because of its copious detail concerning the Ships and Minds of the Culture, its great AIs: their outrageous names, their dangerous senses of humour. Is this what gods would actually be like?\nBanks replied:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If we're lucky.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "58624", "revid": "47198456", "url": "https://en.wikipedia.org/wiki?curid=58624", "title": "Polyglotta Africana", "text": "Study published in 1854 on African languages\nPolyglotta Africana is a study published in 1854 by the German missionary Sigismund Wilhelm Koelle (1823\u20131902), in which the author compares 280 words from 200 African languages and dialects (or about 120 separate languages according to today's classification; several varieties considered distinct by Koelle were later shown to belong to the same language). As a comparative study it was a major breakthrough at the time.\nKoelle based his material on first-hand observations, mostly with freed slaves in Freetown, Sierra Leone. He transcribed the data using a uniform phonetic script. Koelle's transcriptions were not always accurate; for example, he persistently confused with and with . His data were consistent enough, however, to enable groupings of languages based on vocabulary resemblances. Notably, the groups which he set up correspond in a number of cases to modern groups: \nAlthough Koelle's was not the first such study comparing different African languages, (for example, a missionary called John Clarke had produced a similar work in 1848, and still earlier Hannah Kilham had produced her \"Specimens of African Languages, Spoken in the Colony of Sierra Leone\" in 1828), yet in its accuracy and thoroughness it outclassed all the others and still proves useful today.\nValue of the work.\nThe \"Polyglotta Africana\" was the second work carried out by Koelle during his five years in Sierra Leone, the first being a grammar of the Vai language in 1849. The idea of this was to use the fact that Sierra Leone was a melting pot of ex-slaves from all over Africa to compile a list of 280 basic words (a sort of early Swadesh list) in some 160 languages and dialects. These were then grouped as far as possible in families. Most of the informants who contributed to this work came from West Africa, but there were also others from as far away as Mozambique. One area that was lacking was the Swahili coast of Kenya and Tanzania, since it seems that slaves from this region were generally taken northwards to Zanzibar and Arabia rather than southward towards America and Brazil. The pronunciations of all the words were carefully noted using an alphabet similar, though not identical, to that devised by Karl Richard Lepsius, which was not yet available at that time. The name of the book was imitated from a well-known work called \"Asia Polyglotta\" (1823) by the German scholar Julius Klaproth. \nThe value of the list is not merely linguistic, since the work not only includes the words themselves, but Koelle also added a short biography of each informant, with geographical information about their place of origin, and an indication of how many other people they knew in Sierra Leone who spoke the same language. This information, combined with a census of Sierra Leone conducted in 1848, has proved invaluable to historians researching the African slave trade in the 19th century. Of the 210 informants, there were 179 ex-slaves (two of them women), while the rest were mostly traders or sailors. An analysis of the data shows that typically Koelle's informants were middle-aged or elderly men who had been living in Freetown for ten years or more. Three-quarters of the ex-slaves had left their homeland more than ten years earlier, and half of them more than 20 years before; and three-quarters of the informants were over 40 years old. Another interesting facet of the book is the manner in which the informants had been made slaves. Some had been captured in war, some kidnapped, some sold by a relative, others condemned for a debt or sentenced for a crime.\nIncluded with a book is a map of Africa showing the approximate location, as far as it could be ascertained, of each language, prepared by the cartographer August Heinrich Petermann.\nThe transcription.\nIt was Koelle's aim not to use any previously published material on the languages he was writing down, but to achieve uniformity by having one person using a single phonetic system for every language. The orthography he eventually chose, after discussions in London, was not that of Karl Richard Lepsius (as is sometimes claimed), since it had not yet been published, but was based on a short document issued in 1848 by Henry Venn of the Church Missionary Society entitled \"Rules for Reducing Unwritten Languages to Alphabetical Writing in Roman Characters With Reference Specially to the Languages Spoken in Africa\". The aim of this was to produce a simple practical system of orthography for teaching purposes with the use of as few diacritics as possible. Koelle, however, sought a more accurate phonetic system, and added diacritics. He retained seven of the eight vowels of Venn's system (\"i, e, \u1eb9, a, \u1ecd, o, u\", omitting \"\u1ea1\" as in \"but\") but added length marks, a dot for nasalisation, and an accent to indicate the prominent syllable. (Unlike in Lepsius's alphabet, the dotted \"\u1eb9\" and \"\u1ecd\" are open not closed sounds.) He modified Venn's alphabet by writing \"d\u1e63\" for the sound of \"judge\" or \"church\" (apparently confusing these two), and n followed by a dot (\"n\u02d9\") for the \"ng\" sound of \"sing\". When Koelle learnt of Lepsius's alphabet in 1854, he made immediate use of it in his Kanuri grammar, in which he wrote:\n\"I much regret that this System was not propounded sooner, so that I might also have adopted it in my Vei-Grammar and Polyglotta Africana. Happily, however, the Orthography which I employed in those books already so nearly approaches the System of Prof. Lepsius, as to only require some minor alterations.\"\nKoelle's word list.\nIn the introduction Koelle tells us that he wanted a selection of words that would be simple enough for each informant to be interviewed on a single day, and for this reason he omitted pronouns, which would have taken much longer to elicit. He adds that a few years earlier during a long vacation he had made a similar such list, of just 71 languages, and that in making the present list he had learnt from that experience.\nThe actual list (the spelling is Koelle's) is as follows:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nThe languages.\nAs the list of languages and countries below shows, most of Koelle's languages came from West Africa. This is mainly because the majority of the slaves themselves who were intercepted by the British Navy and taken to Sierra Leone were from that region. Another factor was that the number of different languages in West Africa is greater than in some other parts of Africa. For example, Cameroon alone is said to have 255 different languages. One area missing is the Swahili coast of Kenya and Tanzania, apparently because slaves intercepted there were taken not to Sierra Leone but to Zanzibar.\nKoelle's language names are given in the left-hand column of the table below: some of the diacritics (such as the dot beneath \u1eb9 and \u1ecd, and the acute accent) have been omitted. The groupings are Koelle's own. The larger groups are subdivided by Koelle into smaller groups, which are not shown in the table. \nNames in square brackets such as [Aku] are subheadings of a group of languages, and do not themselves have any words. The number of languages or dialects represented on each double-page spread of Koelle's book is therefore exactly 200, divided into four columns of 50 languages each.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58625", "revid": "24465790", "url": "https://en.wikipedia.org/wiki?curid=58625", "title": "Court-martial", "text": "Judicial action in military forces\nA court-martial (plural \"courts-martial\" or \"courts martial\", as \"martial\" is a postpositive adjective) is a military court or a trial conducted in such a court. A court-martial is empowered to determine the guilt of members of the armed forces subject to military law, and, if the defendant is found guilty, to decide upon punishment. In addition, courts-martial may be used to try prisoners of war for war crimes. The Geneva Conventions require that POWs who are on trial for war crimes be subject to the same procedures as would be the holding military's own forces. Finally, courts-martial can be convened for other purposes, such as dealing with violations of martial law, and can involve civilian defendants.\nMost navies have a standard court-martial which convenes whenever a ship is lost; this does not presume that the captain is suspected of wrongdoing, but merely that the circumstances surrounding the loss of the ship be made part of the official record. Most military forces maintain a judicial system that tries defendants for breaches of military discipline. Some countries like France have no courts-martial in times of peace and use civilian courts instead.\nHyphenation.\nCourt-martial is hyphenated in US usage, whether used as a noun or verb. However, in British usage, a hyphen is used to distinguish between the noun, \"court martial\", and the verb, \"to court-martial\".\nComposition.\nUsually, a court-martial takes the form of a trial with a presiding judge, a prosecutor and a defense attorney (all trained lawyers as well as officers). The precise format varies from one country to another and may also depend on the severity of the accusation.\nJurisdiction.\nCourts-martial have the authority to try a wide range of military offences, many of which closely resemble civilian crimes like fraud, theft or perjury. Others, like cowardice, desertion, and insubordination, are purely military crimes. For members of the British Armed Forces, offences are defined in the Armed Forces Act 2006. Regulations for the Canadian Forces are found in the Queen's Regulations and Orders as well as the National Defence Act. For members of the United States Armed Forces offenses are covered under the Uniform Code of Military Justice (UCMJ). These offences, as well as their corresponding punishments and instructions on how to conduct a court-martial, are explained in detail based on each country and/or service.\nBy country.\nCanada.\nIn Canada, there is a two-tier military trial system. Summary trials are presided over by superior officers, while more significant matters are heard by courts martial, which are presided over by independent military judges serving under the independent Office of the Chief Military Judge. Appeals are heard by the Court Martial Appeal Court of Canada. Capital punishment in Canada was abolished generally in 1976, and for military offences in 1998. Harold Pringle was the last Canadian soldier executed pursuant to a court martial, in 1945, having been convicted of murder.\nChina.\nThe Military Court of the Chinese People's Liberation Army is the highest level military court (High Military Court, a special people's court executing the authority of the High People's Court) established by the People's Republic of China within the Chinese People's Liberation Army with jurisdiction over the nation's armed forces (including the People's Liberation Army and the People's Armed Police), organized as a unit under the dual leadership of the Supreme People's Court and the Political and Legal Committee of the Central Military Commission.\nFinland.\nIn Finland, the military has jurisdiction over two types of crimes: those that can be committed only by military personnel and those normal crimes by military persons where both the defendant and the victim are military persons or organizations and the crime has been defined in law as falling under military jurisdiction. The former category includes military offences such as various types of disobedience and absence without leave, while the latter category includes civilian crimes such as murder, assault, theft, fraud and forgery. However, war crimes and sexual crimes are not under military jurisdiction.\nIn crimes where the military has jurisdiction, the military conducts the investigation. In non-trivial cases, this is done by the investigative section of Defence Command or by civilian police, but trivial cases are investigated by the defendant's own unit. The civilian police has always the right to take the case from the military.\nIf the case does not warrant a punishment greater than a fine or a disciplinary punishment, the punishment is given summarily by the company, battalion or brigade commander, depending on severity of the crime. If the brigade commander feels that the crime warrants a punishment more severe than he can give, he refers the case to the local district attorney who commences prosecution.\nThe crimes with military jurisdiction are handled by the civilian district court which has a special composition. In military cases, the court consists of a civilian legally trained judge and two military members: an officer and a warrant officer, an NCO or a private soldier. The verdict and the sentence are decided by a majority of votes. However, the court cannot give a more severe sentence than the learned member supports. The appeals can be made as in civilian trials. If a court of appeals handles a military matter, it will have an officer member with at least a major's rank. The Supreme Court of Finland has, in military cases, two general officers as members.\nCourts-martial proper are instituted only during a war, by decree of the government. Such courts-martial have jurisdiction over all crimes committed by military persons. In addition, they may handle criminal cases against civilians in areas where ordinary courts have ceased operation, if the matter is urgent. Such courts-martial have a learned judge as a president and two military members: an officer and an NCO, warrant officer or a private soldier. The verdicts of a war-time court-martial can be appealed to a court of appeals.\nGermany.\nThe Basic Law for the Federal Republic of Germany establishes in Art. 96 para. 2 that courts-martial can be established by federal law. Such courts-martial would take action in a state of defence or against soldiers abroad or at sea.\nGreece.\nThe existence of military courts, naval courts and air courts is provided for in the Constitution of Greece, which in article 96 paragraph 4 states that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Special laws define: a. Those related to military courts, naval courts and air courts, to the jurisdiction of which private individuals cannot be subject.\nThe first chapter of the procedural part of the Military Penal Code (MPC) regulates the matters related to the courts and judicial persons that make up the Military Justice. Specifically in article 167 of the MPC, it is defined that criminal justice in the Army is awarded by the military courts (military courts, air courts, naval courts, review court) and the Supreme Court.\nIndia.\nThere are four kinds of courts-martial in India. These are the General Court Martial (GCM), District Court Martial (DCM), Summary General Court Martial (SGCM) and Summary Court Martial (SCM). According to the Army Act, army courts can try personnel for all kinds of offenses, except for murder and rape of a civilian, which are primarily tried by a civilian court of law. \nThe President of India can use the judicial power under Article 72 of the constitution to pardon, reprieve, respite or remission of punishment or sentence given by a court martial.\nIndonesia.\nIn Indonesia, any criminal offense conducted by military personnel will be held in trial by military court. There are four levels of military jurisdiction:\nThe judges will receive temporary rank the same as the defendant if the rank of the defendant is higher than the judges.\nIreland.\nCourts martial are provided for in the Constitution of Ireland, which states in Article 38.4.1 that:\n\"Military tribunals may be established for the trial of offences against military law alleged to have been committed by persons while subject to military law and also to deal with a state of war or armed rebellion.\"\nThere are three classes of courts martial in the Irish Defence Forces:\nIsrael.\nOutside of the Israeli settlements, the West Bank remains under direct Israeli military rule, and under the jurisdiction of martial law in the form of military courts. The international community maintains that Israel does not have sovereignty in the West Bank, and considers Israel's control of the area to be the longest military occupation in modern history.\nThe military court system for the occupied territories, modeled partially on the British military court system set up in 1937, was established in 1967.\nSociology professor Lisa Hajjar argues that Israeli military courts criminalize not only Palestinian violence, but also certain forms of expression deemed to threaten Israeli security. She states the incarceration rate of Palestinians is high compared to other states, and that Palestinians in the West Bank are being treated as \"foreign civilians\".\nLuxembourg.\nIn Luxembourg, there are three levels of military jurisdiction:\nNetherlands.\nIn the Netherlands, members of the military are tried by a special military section of the civilian court in Arnhem. This section consists of a military member and two civilian judges. The decision whether or not to prosecute is primarily made by the (civilian) attorney general.\nNew Zealand.\nService members of the New Zealand Defence Force are tried under a court martial for offences pertaining to the most serious offences against the Armed Forces Discipline Act 1971. Offences such as mutiny, murder, sexual offences, serious assaults, drug offences, or offences where the maximum punishment exceeds a 7-year prison term will be heard by court martial. Below this 7-year threshold the accused is dealt with by their commanding officer in what is known as a summary trial.\nDuring court martial the appointed judge is either a New Zealand High Court or District Court judge and they preside over the trial. Defendants are assigned legal counsel, and for the prosecution, a lawyer is assigned who generally comes from a military background. The judge advocate is usually made up of senior NZDF officers and warrant officers who hear the defence and prosecution evidence during court martial. Punishment on guilty findings of a defendant will see them face being charged with a punishment such as serious reprimand, loss of rank, dismissal from the NZDF, or being sent to military or civilian prison.\nPoland.\nIn Poland, military courts are military garrison courts and military district courts. They are criminal courts with jurisdiction over offences committed by soldiers in active military service, as well as certain offences committed by civilian military personnel and soldiers of the armed forces of foreign countries (Article 647 of the Code of Criminal Procedure). Garrison courts rule in the first instance, appeals against their decisions and orders are heard by district courts, which also have first-instance jurisdiction in the most serious cases. The Criminal Chamber of the Supreme Court then acts as the second instance; in addition, cassation appeals against judgments rendered in the second instance are heard in the Criminal Chamber. The military courts are therefore subject to the adjudicatory supervision of the Supreme Court (which, by the way, follows from Article 183(1) of the Constitution of the Republic of Poland), and the Minister of Justice has superior organizational and administrative supervision.\nPhilippines.\nIn 2005, ex-AFP Major General Carlos Garcia (PMA Class of 1971, assigned comptroller of the AFP was court martialled for violating two articles of the Articles of War for the alleged Php 303 million Peso Money Laundering/Plunder and direct Bribery against him.\nSingapore.\nUnder the Singapore Armed Forces Act, any commissioned officer is allowed to represent servicemen when they are tried for military offences in the military courts. The cases are heard at the Court-Martial Centre at Kranji Camp II. Some of the courts martial in Singapore include that of Capt. G. R. Wadsworth in 1946 due to use of insubordinate language and, in the modern day, misbehaviour by conscripted servicemen.\nThailand.\nThe governing law in Thailand's military courts is the \"Military Court Organisation Act 1955\" (). The act allows the Judge Advocate General of Thailand () to establish court regulations. In wartime or during the imposition of martial law, military courts may adopt special procedures.\nUnited Kingdom.\nThe Court Martial is one of the Military Courts of the United Kingdom. The Armed Forces Act 2006 established the Court Martial as a permanent standing court. Previously courts-martial were convened on an \"ad hoc\" basis with several traditions, including usage of swords. The Court Martial may try any offence against service law. The court is made up of a judge advocate, and between three and seven (depending on the seriousness of the offence) officers and warrant officers. Rulings on matters of law are made by the judge advocate alone, whilst decisions on the facts are made by a majority of the members of the court, not including the judge advocate, and decisions on sentence by a majority of the court, this time including the judge advocate.\nUnited States.\nMost commonly, courts-martial in the United States are convened to try members of the U.S. military for violations of the Uniform Code of Military Justice (UCMJ), which is the U.S. military's criminal code. However, they can also be convened for other purposes, including military tribunals and the enforcement of martial law in an occupied territory. Courts-martial are governed by the rules of procedure and evidence laid out in the Manual for Courts-Martial, which contains the Rules for Courts-Martial, Military Rules of Evidence, and other guidance. There are three types: Special, Summary, and General.\nFictional examples.\nIn Herman Melville's novella \"Billy Budd\" (first published 1924), the title character is convicted at a drumhead court-martial of striking and killing his superior officer on board HMS \"Indomitable\", is sentenced to death, and is hanged. The novella has been adapted for the stage, film and television; notably in Benjamin Britten's 1951 opera \"Billy Budd\".\nIn C.S. Forester's 1938 novel \"Flying Colours\", Captain Horatio Hornblower is court-martialled for the loss of HMS \"Sutherland\". He is \"most honourably acquitted\".\nIn Michael Morpurgo's novel \"Private Peaceful\", the main character of \"Tommo\" reflects on the childhoods of himself and his brother, Charlie as Charlie awaits a court martial during WWI, which he receives at the end of the story for disobeying orders and cowardice in the face of the enemy.\nSeveral courts-martial occur in the British naval TV series \"Warship\", including notably that of Lieutenant Palfrey, a Royal Marines officer accused of killing a foreign officer during a military exercise, and that of Fleet Air Arm pilot Edward Glenn, brother of Alan Glenn, one the principal characters, charged with a range of offences relating to a dangerous flight manoeuvre.\nIn the \"\" episode \"The Battle\", it is stated that, Picard was court-martialed for the loss of the \"Stargazer\" and zealously prosecuted by Phillipa Louvois. In the end, he was absolved of all charges.\nThe 1992 film \"A Few Good Men\" (and the play on which it was based) deals almost entirely with the court martial of two enlisted Marines.\nIn the 2008 to 2020 science-fiction animated TV series \"\"'s 2011 fourth-season episode \"Plan of Dissent\", clone troopers Fives and Jesse, both serving in the Grand Army of the Republic, act against orders from their acting superior in a war situation and in revenge are threatened with court-martial and consequent execution. They find themselves court-martialed and about to be executed by firing squad in the next episode, although the final execution does not happen despite them being found guilty.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "58629", "revid": "32823000", "url": "https://en.wikipedia.org/wiki?curid=58629", "title": "Leopold Zunz", "text": "German Reform Rabbi (1794\u20131886)\nLeopold Zunz (\u2014\"Yom Tov Tzuntz\", \u2014\"Lipmann Zunz\"; 10 August 1794 \u2013 17 March 1886) was the founder of academic Judaic Studies (\"Wissenschaft des Judentums\"), the critical investigation of Jewish literature, hymnology and ritual. Zunz's historical investigations and contemporary writings had an important influence on contemporary Judaism.\nBiography.\nLeopold Zunz was born at Detmold, the son of Talmud scholar Immanuel Menachem Zunz (1759\u20131802) and Hendel Behrens (1773\u20131809), the daughter of Dov Beer, an assistant cantor of the Detmold community. The year following his birth his family moved to Hamburg, where, as a young boy, he began learning Hebrew grammar, the Pentateuch, and the Talmud. His father, who was his first teacher, died in July 1802, when Zunz was not quite eight years old. He subsequently gained admission to the Jewish \"free school\" (Freischule) founded by Philipp Samson, in Wolfenb\u00fcttel. Departing from home in July 1803, he saw his mother for the last time (she died in 1809 during his years in Wolfenb\u00fcttel). A turning point in Zunz's development came in 1807, when Samuel Meyer Ehrenberg, a reform-minded educator, took over the directorship of the Samson School. Ehrenberg reorganized the curriculum, introducing, alongside traditional learning, new subjects such as religion, history, geography, French, and German; he became Zunz's mentor, and they remained friends until Ehrenberg's death in 1853.\nThe summer of 1811 is noteworthy as the time when Zunz made his first acquaintance with Johann Christoph Wolf's \"Bibliotheca Hebr\u00e6a\", which, together with David Gans's \"Tzemach David\", gave him his first introduction to Jewish literature and the first impulse to think of the \"Science of Judaism.\"\nHe settled in Berlin in 1815, studying at the University of Berlin and obtaining a doctorate from the University of Halle. He was ordained by the Hungarian rabbi Aaron Chorin, an early supporter of religious reform, and served for two years teaching and giving sermons in the Beer reformed synagogue in Berlin. He found the career uncongenial, and in 1840 he was appointed director of a \"Lehrerseminar,\" a post which relieved him from pecuniary troubles. Zunz was always interested in politics, and in 1848 addressed many public meetings. In 1850 he resigned his headship of the Teachers' Seminary, and was awarded a pension. Throughout his early and married life he was the champion of Jewish rights, and he did not withdraw from public affairs until 1874, the year of the death of his wife Adelheid Beermann, whom he had married in 1822.\nTogether with other young men, among them the poet Heinrich Heine, Zunz founded the \"Verein f\u00fcr Kultur und Wissenschaft der Juden\" (The Society for the Culture and Science of the Jews) alongside Joel Abraham List, Isaac Marcus Jost, and Eduard Gans in Berlin in 1819. In 1823, Zunz became the editor of the \"Zeitschrift f\u00fcr die Wissenschaft des Judenthums\" (Journal for the Science of Judaism). The ideals of this \"Verein\" were not destined to bear religious fruit, but the \"Science of Judaism\" survived. Zunz \"took no large share in Jewish reform\", but never lost faith in the regenerating power of \"science\" as applied to the traditions and literary legacies of the ages. He influenced Judaism from the study rather than from the pulpit.\nAlthough affiliated with the Reform movement, Zunz appeared to show little sympathy for it, though this has been attributed to his disdain for ecclesiastical ambition and fears that rabbinical autocracy would result from the Reform crusade. Further, Isidore Singer and Emil Hirsch have stated that \"the point of (Geiger's) protest against Reform was directed against Samuel Holdheim and the position maintained by this leader as an autonomous rabbi.\" Later in life Zunz went so far as to refer to rabbis as \"soothsayers and quacks\".\nThe violent outcry raised against the Talmud by some of the principal spirits of the Reform party was repugnant to Zunz's historic sense. Zunz himself was temperamentally inclined to assign a determinative potency to sentiment, this explaining his tender reverence for ceremonial usages. Although Zunz kept to the Jewish ritual practises, he understood them as symbols (see among others his meditation on tefillin, reprinted in \"Gesammelte Schriften,\" ii. 172-176). This contrasts with the traditional view of the validity of divine ordinances according to which the faithful are bound to observe without inquiry into their meaning. His position accordingly approached that of the symbolists among the reformers who insisted that symbols had their function, provided their suggestive significance was spontaneously comprehensible. He emphasized most strongly the need of a moral regeneration of the Jews.\nHe wrote precise philological studies but also impassioned speeches on the Jewish nation and history that had an influence on later Jewish historians. Zunz wrote in 1855:\n\"If there are ranks in suffering, Israel takes precedence of all the nations; if the duration of sorrows and the patience with which they are borne ennoble, the Jews can challenge the aristocracy of every land; if a literature is called rich in the possession of a few classic tragedies\u2014what shall we say to a National Tragedy lasting for fifteen hundred years, in which the poets and the actors were also the heroes?\"\nIn 1840 he became director of the Berlin Jewish Teachers' Seminary.\nHe was friendly with the traditional Enlightenment figure Nachman Krochmal whose \"Moreh Nebuke ha-Zeman\" (Lemberg, 1851), was edited by Zunz.\nZunz urged his contemporaries to, through the embrace of study of a wide swath of literature, grasp the geist or \"spirit\" of the Jewish people. Zunz proposed an ambitious Jewish historiography and further proposed that Jewish people adopt history as a way of life. Zunz not only proposed a university vision of Jewish studies, but believed Jewish history to be an inseparable part of human culture. Zunz's historiographical view aligns with the \"lachrymose\" view of Jewish history of persecution. Zunz was the least philosophically inclined of the \"Wissenschaft\" but the most devoted to scholarship. Zunz called for an \"emanicipation\" of Jewish scholarship \"from the theologians.\"\nContrasting with earlier bible printing, Zunz adopted a re-Hebraization of names.\nZunz was politically active and was elected to office. He believed that Jewish emancipation would come out of universal human rights. The revolutionary year of 1848 had an influence on Zunz, and he expressed a messianic eagerness in the ideals of equality. Zunz's stated goal was to transform Prussia into a democratic republic.\nZunz died in Berlin in 1886.\nWorks.\nZunz's famous article \"Etwas \u00fcber die rabbinische Litteratur\" (\"On Rabbinical Literature\"), published in 1818, established the intellectual agenda of the Wissenschaft des Judentums (\"Science of Judaism\"), while adumbrating the main themes of his own future work as well. Even at this early stage of his academic career, Zunz mapped out his concept of the Wissenschaft des Judentums which he intended to serve as a medium for presenting, preserving, and transmitting the corpus of Jewish literary works. Zunz believed that only an academic approach to Jewish texts and a comprehensive and interdisciplinary academic framework would allow for the adequate study of Jewish themes and Judaism. In 1832 appeared \"the most important Jewish book published in the 19th century.\" This was Zunz's \"Gottesdienstliche Vortr\u00e4ge der Juden\", i.e. a history of the Sermon. It lays down principles for the investigation of the Rabbinic exegesis (Midrash) and of the siddur (prayer-book of the synagogue). This book raised Zunz to the supreme position among Jewish scholars. In 1845 appeared his \"Zur Geschichte und Literatur\", in which he threw light on the literary and social history of the Jews. He had visited the British Museum in 1846, and this confirmed him in his plan for his third book, \"Synagogale Poesie des Mittelalters\" (1855). It was from this book that George Eliot translated the following opening of a chapter of \"Daniel Deronda\": \"If there are ranks in suffering, Israel takes precedence of all the nations...\". After its publication Zunz again visited England, and in 1859 issued his \"Ritus\". In this he gives a masterly survey of synagogal rites. His last great book was his \"Literaturgeschichte der synagogalen Poesie\" (1865). A supplement appeared in 1867. Besides these works, Zunz published a new translation of the Bible, and wrote many essays which were afterwards collected as \"Gesammelte Schriften\".\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "58632", "revid": "1268774522", "url": "https://en.wikipedia.org/wiki?curid=58632", "title": "Tom\u00e1s de Zumalac\u00e1rregui", "text": "Spanish Basque officer\nTom\u00e1s de Zumalac\u00e1rregui e Imaz (Basque: Tomas Zumalakarregi Imatz; 29 December 1788\u00a0\u2013 24 June 1835), known among his troops as \"Uncle Tom\u00e1s\", was a Spanish Basque officer who led the Carlist faction as Captain general of the Army during the First Carlist War. He was occasionally nicknamed the \"Wolf of the Amezcoas\", making reference to his famous military victory in the region of Navarre.\nZumalac\u00e1rregui is popularly credited as the inventor of the Spanish omelette (or \"tortilla de patatas\"), which he may have elaborated during the Siege of Bilbao.\nFrom the Peninsula War to Ferdinand VII.\nZumalac\u00e1rregui was born in Ormaiztegi in Gipuzkoa, a Basque province in Spain, on 29 December 1788. His father, Francisco Antonio de Zumalac\u00e1rregui Muxica, was a lawyer who possessed some property, and the son was articled to a solicitor. His mother was Maria Ana Imaz Altolaguirre.\nWhen the Peninsular War began with a French invasion of Spain in 1808 he enlisted in Zaragoza. He served in the 1808 First Siege of Zaragoza, at the Battle of Tudela, and during the 1809 Second Siege of Zaragoza until he was taken prisoner in a sortie. He succeeded in escaping and in reaching his family in Navarre. For a short time he served with Gaspar de J\u00e1uregui, another Gipuzkoan known as \"The Shepherd\" (), one of the guerrilla leaders, who later became a general in the regular army against which Zumalacarregui fought.\nBut Zumalac\u00e1rregui, who was noted for his grave and silent disposition and his strong religious principles, disliked the disorderly life of the guerrillas, and when regular forces were organized in the north he entered the 1st battalion of Gipuzkoa as an officer. During the remainder of the war he served in the regular army. His brother Miguel Antonio de Zumalac\u00e1rregui was in C\u00e1diz at the time the Cortes passed the Constitution of 1812, going on to be elected chief deputy of Gipuzkoa. Tomas was then sent with dispatches to the Regency at C\u00e1diz, and received his commission as captain. In that rank he was present at the Battle of San Marcial in August 1813. After the restoration of Ferdinand VII he continued in the army, and is said to have made a careful study of the theory of war.\nDuring Ferdinand VII's rule.\nZumalac\u00e1rregui had no sympathy with the liberal principles which were spreading in Spain, and became noted as what was called a \"servil\" or strong Royalist. He attracted no attention at headquarters, and was still a captain when the Revolution of 1820 broke out and the \"Trienio Liberal\" was established. His brother officers, whose leanings were liberal, denounced him to the revolutionary government, and asked that he might be removed. The recommendation was not acted on, but Zumalac\u00e1rregui knew of it, and laid up the offence in his mind. Finding that he was suspected (probably with truth) of an intention to bring the soldiers over to the royalist side, he escaped to France.\nIn 1823 he returned as an officer in one of the royalist regiments which had been organized on French soil by the consent of the government. He was now known as a thoroughly trustworthy servant of the royalty, but he was too proud to be a courtier. For some years he was employed in bringing regiments which the government distrusted to order. He became lieutenant-colonel in 1825 and colonel in 1829. In 1832 he was named military governor of Ferrol, Galicia. Before King Ferdinand VII died in 1833, Zumalac\u00e1rregui was marked out as a natural supporter of the traditionalist party, which favoured the king's brother, Infante Carlos, Count of Molina.\nThe Carlist War.\nThe proclamation of the king's daughter Isabel as heiress was almost the occasion of an armed conflict between him and the naval authorities at Ferrol, who were partisans of the liberal and so-called \"constitutional\" cause. He was put on half pay by the new authorities and ordered to live under police observation at Pamplona in Navarre.\nWhen the Carlist uprising began on the death of Ferdinand VII, he is said to have held back because he knew that the first leaders would be politicians and talkers. He did not take the field until the Carlist cause appeared to be at a very low ebb, and until he had received a commission from Don Carlos as Commander-in-Chief in Navarre.\nHe escaped Pamplona on the night of 29 October 1833 and took the command next day in the Araquil Valley. At that time the Carlist forces comprised no more than a few hundred ill-armed and dispirited \"guerrilleros\"; in a few months Zumalac\u00e1rregui had organized them into a regular army. The difficulty he found in obtaining supplies was enormous, for the coast towns and notably Bilbao supported the \"Cristino\" (liberal) cause. It was mainly by seizing equipment from the government troops that he armed his forces. He gradually obtained full possession of the Southern Basque Country, outside of the fortresses, which he had not the means to besiege. He organized the forces known as \"aduaneros\" and the \"Gu\u00edas de Navarra\". His chief bodyguard, and later biographer, was Charles Frederick Henningsen.\nWhether as a guerrilla leader, or as a general conducting regular war in the mountains, he proved unconquerable. He won the battles of Alsasua, Alegr\u00eda de \u00c1lava, and Venta de Echavarri, for example, by employing guerrilla tactics.\nBy July 1834 he had made it safe for Don Carlos to join his headquarters. Zumalac\u00e1rregui was by then strongly envied by the courtiers that surrounded the pretender, as well as by other military officers. Besides, Don Carlos was a somewhat na\u00efve and easily suggestible man, and Zumalac\u00e1rregui had therefore to drag behind him the whole weight of the distrust and intrigues of the court. Yet by the beginning of June 1835 he had made the Carlist cause triumphant to the north of the Ebro, and had formed an army of more than 30,000 men, of much better quality than the constitutional forces. He won the battle of Artaza (20\u201322 April 1835).\nIf Zumalac\u00e1rregui had been allowed to follow his own plans, which were to concentrate his forces and march on Madrid, firstly seizing Logro\u00f1o (La Rioja, Castile), he might well have put Don Carlos in possession of the capital. But the court was eager to obtain command of a seaport, because they thought this would facilitate the official recognition of Don Carlos as the legitimate heir to the Spanish Throne by other European courts. Thus, Zumalac\u00e1rregui was ordered to besiege Bilbao. He obeyed reluctantly, and on 14 June 1835 was wounded in the calf by a musket shot, near the Basilica of Bego\u00f1a. The wound was trifling and would probably have been cured with ease, but Zumalac\u00e1rregui decided to employ a famous Gipuzkoan quack called \"Petriquillo\", whom he trusted. Petriquillo proceeded to remove the bullet from Zumalac\u00e1rregui's leg, provoking a great loss of blood and probably an infection. Don Carlos had insisted on sending his own physicians, but they hesitated about the best prognosis to follow, losing precious time and failing to stop Petriquillo from trying his \"procedure\" (he acted when they were not present) and in their hands the general died on 24 June 1835, not without suspicion of poison and after Petriquillo had hastily left the scene.\nZumalac\u00e1rregui is often popularly credited as the inventor of Spanish omelette (or \"tortilla de patatas\"), which he allegedly elaborated during the Siege of Bilbao, as a simple, fast and nutritious dish with which to satisfy the hardships of the Carlist Army. In search of nourishment, he came across a poor housewife who had nothing other than eggs, onion and potatoes. When he mixed it up, he liked the result and fed it to his starving troops. It is said that after this, the tortilla became incredibly popular throughout the rest of the First Carlist War, and is now one of the most renowned dishes in the world.\nZumalac\u00e1rregui was a fine type of the old royalist and religious principles of his people. The Carlist forces under his command were repeatedly refused quarter by the government's forces (which for years didn't recognize them as legitimate combatants). The increasing ferocity of the war, substantiated in routine executions of Carlist soldiers and officers, convinced him of the necessity of a similar retaliation against the liberal forces. Zumalac\u00e1rregui, however, would later sign the Lord Eliot Convention, shortly before his own death, which aimed to end the indiscriminate executions by firing squad of prisoners on both sides.\nPopularity.\nThe most trustworthy account of Zumalacarregui's Carlist campaign can be found in Juan Antonio de Zaratiegui's \"Vida y hechos de Don Tom\u00e1s de Zumalac\u00e1rregui\". Zaratiegui was his personal assistant, secretary and friend throughout the war, and also himself an important carlist military officer. Accounts of Zumalac\u00e1rregui include \"The Most Striking Events of a Twelvemonth Campaign with Zumalacarregui in Navarre and the Basque Provinces\", by Charles Frederick Henningsen (London, 1836) as well as a chapbook called \"Vida pol\u00edtica y militar de Don Tom\u00e1s Zumalac\u00e1rregui\". Of Zumalac\u00e1rregui, Henningsen writes:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Now that Zumalacarregui's memory must descend, whatever be the issue of the contest, as an heir-loom to all classes of his countrymen, as long as the Spanish language endures, and that his name must be mingled in the songs of the peasantry with that of the Cid, it would be superfluous to say that he was no ordinary man; but, although, on the roll of those who have acquired a title to immortality, by the immense share he had in the early successes of the Royalist army, justice is scarcely done him. It is doubtless that it required the iron frame and indomitable spirit of the mountaineers he commanded, to battle so long against man, want, and the elements.\u2014\u200a\nIn 2017 the People's Party of the Basque Country called for a street named after him to be renamed.\nZumalac\u00e1rregui in the \"Episodios nacionales\".\nZumalac\u00e1rregui is the main character of an eponymous \"Episodio nacional\", by Benito P\u00e9rez Gald\u00f3s. He is portrayed as an intelligent man and an excellent strategist who fights for what he believes in.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58634", "revid": "211905", "url": "https://en.wikipedia.org/wiki?curid=58634", "title": "Ignacio Zuloaga", "text": "Spanish painter (1870\u20131945)\nIgnacio Zuloaga y Zabaleta (July 26, 1870\u00a0\u2013 October 31, 1945) was a Spanish painter, born in Eibar, Guipuzcoa, near the monastery of Loyola.\nFamily.\nHe was the son of metalworker and damascener Pl\u00e1cido Zuloaga and grandson of the organizer and director of the royal armoury (Don Eusebio) in Madrid. His uncle was Daniel Zuloaga. His great-grandfather who was also the royal armourer was a friend and contemporary of Goya.\nBiography.\nIn his youth, he drew and worked in the armourer's workshop of his father, Pl\u00e1cido. His father's craftmanship, a familial trade, was highly respected throughout Europe, but he intended his son for either commerce, engineering, or architecture, but during a short trip to Rome with his father, he decided to become a painter. His first painting was exhibited in Paris in 1890.\nAt the age of 18 he moved to Paris, settling in Montmartre, to find work and training as a painter. He was nearly destitute, and lived off some meager contributions by his mother and the benevolence of fellow Spaniards, including Paco Durrio, Pablo Uranga, and Santiago Rusi\u00f1ol.\nAfter only six months' work he completed his first picture, which was exhibited at the Paris Salon of 1890. Continuing his studies in Paris, where he lived for five years, he was in contact with post-impressionists such as Ramon Casas, Gauguin and Toulouse-Lautrec, yet his tendencies were always to a thematic that was more ethnic in scope.\nHe attempted to gain success during a sojourn in London; but lackluster patronage led him to return to Spain, settling in Seville, then Segovia, and developed a style based on a realist Spanish tradition, recalling Vel\u00e1zquez and Murillo in their earthy colouring and genre themes. He painted portraits of attired bullfighters and flamenco dancers; or portraits of family members and friends in such attire. He also painted village dwarves (\"El enano Gregorio el Botero\"; Hermitage, St Petersburg, Russia) and beggars, often as stark figures in a dreary landscape with a traditional landscape or town in the background. He also painted some village-scape scenes. He favored earth or muted tones, including maroon, black, and grey, with the exception of colorful folk attire or the bright red cassock in some paintings.\nZuloaga married Valentine Dethomas on May 18, 1899. Valentine's brother, Maxime Dethomas, was a fellow student of Zuloaga in Paris.\nZuloaga and his patrons felt slighted in 1900, when his painting \"Before the Bull-fight\" was rejected for inclusion into the Spanish representation at the Universal Exposition in Brussels. In 1899, one of his paintings exhibited in Paris had been purchased for the Luxembourg Palace. However, he did exhibit the painting at the Exposition of the Libre Esthetique in Brussels, and did see it acquired by the Modern Gallery in Brussels. He was accepted into the Venice Biennale in 1901 and 1903, and displayed 34 canvases at the Barcelona International exposition of 1907.\nAmong the more prominently displayed works is his \"Cristo de la Sangre\" (Christ of the Blood) or \"Hermandad del Cristo Crucificado\" (Brotherhood of the Crucified Christ), on display at the Museo Reina Sofia in Madrid. He also painted a similarly painting of individuals undergoing a traditional mortification of the flesh and a bleeding crucified Christ called \"The Flagellants\" (1900). These paintings were praised by Unamuno in his book on \"De Arte Pictorico\" as being honest representation of Spain: a Spain \"religious and tragic, a black Spain\". rooted in the particularly Spanish Catholic fascination with mutilating penance.\nBrinton in his review of an exposition in America in 1909, he states that: It is this racy and picturesque life which Zuloaga seeks above all else to place on record, and it is these popular types unspoiled by ruthless modernism which he pursues into the farthest corners of his native land. In this zealous quest of congenial models he hesitates at nothing. He will haunt for hours a fiesta on the outskirts of some provincial town, or hasten away to the mountains, passing months at a time with smugglers and muleteers, with the superstitious fanatics of Anso in the extreme north of Aragon or with the monkish cutthroats of Las Baluecas, a little village on the southern boundary line of Salamanca.\nGil says that the faces of the old folk he paints are severe, roughly mystical, beset by painful thoughts, shadowed by the remembrance of the glory they once were, they have sad souls, moaning under the weight of an ideal of centuries, they are not individual representations, but the synthesis of the sadness of the Spanish Soul.\nOne of the American collections to feature Zuloaga's work is the Johns Hopkins University's Evergreen Museum &amp; Library, Baltimore, Maryland. Officially owned by the Evergreen House Foundation, an independent entity started by Zuloaga's great friend, philanthropist Alice Warder Garrett (1877\u20131952), Evergreen's works include full-length portraits of Mrs. Garrett (1915; 1928); a seated portrait of Ambassador John Work Garrett (1872\u20131942); a Spanish landscape; a painting based on the opera \"Goyescas\"; and a landscape of Calatayud (Spain).\nAn Iberia airline Airbus A340-642 aircraft, registration EC-IZY, is named after him.\nZuloaga during and after the Spanish Civil War.\nZuloaga was committed to the Nationalist faction during the Spanish Civil War and the Spanish State of the \"caudillo\", Francisco Franco, whose portrait he painted in 1940. During the war, Zuloaga honored the defenders of the \"Siege of the Alc\u00e1zar\" in 1936, when the building's Nationalist defenders refused to surrender despite the building being in flames. This siege, and other events such as the death of General Jos\u00e9 Moscard\u00f3 Ituarte's son, served as a rallying cry for the Nationalist forces. In January 1939, this painting was hung in adjacent room displaying Picasso's modernist painting of Guernica during an exhibition of Spanish art in London. The nationalist content of his depiction of the Alcazar was allied to Zuloaga's celebration of folk traditions. Stylistically, the directness of the \"Siege\" painting also avoids modernity's challenge to realistic depictions: Fascism was not endeared to complex symbolism such as found in works such as \"Guernica\".\nIn an April 1939 letter to his patron, Mrs Garret, Zuloaga stated:Thanks to God, and to Franco, at last the war is won and over! And over, despite the goodwill of those so-called democratic countries \u2013 what a farce, what shame, when those countries learn the truth of this drama! We all will work with all our strength to rebuild a new Spain (free, great and unified) to Spanishize Spain, and get rid of all outside influences, so that we can keep our great nature. That\u2019s my dream in art. I hate fads (which are destructive to racial characteristics) One must (for good or bad) be oneself, and not ape the style of anyone else. I will dedicate the years that are left to me to that end. What shame there will be in the future, for those countries who inflicted crime, savage vandalism, which reigned within the soviet clan in Spain!\nHe was later to claim that he was aghast, as a francophile, when Hitler defeated France in 1940. After his death in 1945, he appeared on Spain's 500 peseta banknote emitted by Francoist Spain in its 1954 series, with a depiction of Toledo on the back.\nBrinton in his 1909 essay was prescient of Zuloaga's future enamourment with Falangism: He personifies in extreme form the spirit of autocracy in art, the principle of absolutism so typical of his race and country. You will meet in these bold, affirmative canvases no hint of cowardice or compromise. The work is defiant, almost despotic. It does not strive to enlist sympathy nor does it fear to be frankly antipathetic...the tones not infrequently acidulous, and the surfaces sometimes hard and metallic. Reactionary if you will...\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58635", "revid": "20612", "url": "https://en.wikipedia.org/wiki?curid=58635", "title": "Hudson Bay", "text": "Large body of saltwater in northeastern Canada\nHudson Bay, sometimes called Hudson's Bay (usually historically), is a large body of saltwater in northeastern Canada with a surface area of . It is located north of Ontario, west of Quebec, northeast of Manitoba, and southeast of Nunavut, but politically entirely part of Nunavut. It is an inland marginal sea of the Arctic Ocean. The Hudson Strait provides a connection to the Labrador Sea and the Atlantic Ocean in the northeast, while the Foxe Channel connects Hudson Bay with the Arctic Ocean in the north. The Hudson Bay drainage basin drains a very large area, about , that includes parts of southeastern Nunavut, Alberta, Saskatchewan, Ontario, Quebec, all of Manitoba, and parts of the U.S. states of North Dakota, South Dakota, Minnesota, and Montana. Hudson Bay's southern arm is called James Bay.\nThe Eastern Cree name for Hudson and James Bay is ' (southern dialect) or ' (northern dialect), meaning muddy or brackish water. Lake Winnipeg is similarly named by the local Cree, as is the location for the city of Winnipeg.\nDescription.\nThe bay is named after Henry Hudson, an Englishman sailing for the Dutch East India Company, and after whom the river that he explored in 1609 is also named. Hudson Bay encompasses , making it the second-largest water body using the term \"bay\" in the world (after the Bay of Bengal). The bay is relatively shallow and is considered an epicontinental sea, with an average depth of about (compared to in the Bay of Bengal). It is about long and wide. On the east it is connected with the Arctic Ocean (Davis Strait) by Hudson Strait; on the north, with the Arctic Ocean by Foxe Basin (which is not considered part of the bay), and Fury and Hecla Strait.\nHudson Bay is often considered part of the Arctic Ocean: the International Hydrographic Organization, in its 2002 working draft of \"Limits of Oceans and Seas\", defined Hudson Bay, with its outlet extending from 62.5 to 66.5 degrees north (just a few miles south of the Arctic Circle) as being part of the Arctic Ocean, specifically \"Arctic Ocean Subdivision 9.11\". Other authorities include it in the Atlantic, in part because of its greater water budget connection with that ocean.\nHistory.\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;\nThe search for a western route to Cathay and the East Indies, which had been actively pursued since the days of Christopher Columbus and John Cabot, in the latter part of the 15th century, directly resulted in the first sighting of Hudson Bay by Europeans. English explorers and colonists named Hudson Bay after Sir Henry Hudson who explored the bay beginning 2 August 1610, on his ship \"Discovery\". On his fourth voyage to North America, Hudson worked his way around Greenland's west coast and into the bay, mapping much of its eastern coast. \"Discovery\" became trapped in the ice over the winter, and the crew survived onshore at the southern tip of James Bay. In the spring, as the ice receded, Henry Hudson expressed a desire to continue exploring the uncharted region. However, on 22 June 1611, the crew mutinied. They left Hudson and others adrift in a small boat. The fate of Hudson and the other men stranded with him remains undetermined. Nevertheless, there is little evidence in historical documents to suggest that they persisted for a long time thereafter. In May 1612, Sir Thomas Button sailed from England with two ships to look for Henry Hudson, and to continue the search for the Northwest Passage to Asia.\nIn 1668, \"Nonsuch\" reached the bay and traded for beaver pelts, leading to the creation of the Hudson's Bay Company (HBC), which still bears the historic name. The HBC negotiated a trading monopoly from the English Crown for the Hudson Bay watershed, called Rupert's Land. In 1670, the English Crown granted a charter to facilitate fur trading within the Hudson Bay drainage basin. France contested this grant by sending several military expeditions to the region, but abandoned its claim in the Treaty of Utrecht (April 1713).\nThe Treaty of Utrecht, signed on 11 April 1713, marked a significant agreement between Britain and France. The treaty was negotiated in Utrecht, Netherlands, and marked a crucial stage in the conclusion of the War of the Spanish Succession. Its provisions had a significant impact in shaping the postwar landscape and establishing a new order in both Europe and North America. French concessions in North America as outlined in the Treaty of Utrecht included: Hudson Bay region, Nova Scotia, and Newfoundland.\nDuring this period, the HBC built several factories (forts and trading posts) along the coast at the mouth of the major rivers (such as Fort Severn; York Factory, Churchill; and the Prince of Wales Fort). The strategic locations were bases for inland exploration. More importantly, they were trading posts with Indigenous peoples who came to them with furs from their trapping season. The HBC shipped the furs to Europe and continued to use some of these posts well into the 20th century.\nThe HBC's trade monopoly was abolished in 1870, by a British Order in Council called the Deed of Surrender, ceded Rupert's Land to Canada, an area of approximately , as part of the Northwest Territories. In 1912, the western shore south of 60\u00b0 and, following the Quebec Boundaries Extension Act, 1912, all the eastern shore were transferred to the adjacent provinces, but the bay and offshore islands remained part of the Northwest Territories. Starting in 1913, the bay was extensively charted by the Canadian government's to develop it for navigation. This mapping progress led to the establishment of Churchill, Manitoba, as a deep-sea port for wheat exports in 1929, after unsuccessful attempts at Port Nelson.\nThe Port of Churchill was an important shipping link for trade with Europe and Russia until its closure in 2016 by owner OmniTRAX. The port and the Hudson Bay Railway were then sold to the Arctic Gateway Group\u2014a consortium of First Nations, local governments, and corporate investors\u2014in 2018.\nOn 9 July 2019, ships resupplying Arctic communities began stopping at the port for additional cargo, and the port began shipping grain again on 7 September 2019.\nGeography and climate.\nExtent.\nThe International Hydrographic Organization defines the northern limit of Hudson Bay as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;A line from Nuvuk Point () to Leyson Point, the Southeastern extreme of Southampton Island, through the Southern and Western shores of Southampton Island to its Northern extremity, thence a line to Beach Point () on the Mainland.\nClimate.\nNorthern Hudson Bay has a polar climate (K\u00f6ppen: \"ET\") being one of the few places in the world where this type of climate is found south of 60 \u00b0N, going farther south towards Quebec, where Inukjuak is still dominated by the tundra. From Arviat, Nunavut, to the west to the south and southeast prevails the subarctic climate (K\u00f6ppen: \"Dfc\"). This is because in the central summer months, heat waves can advance from the hot land and make the weather milder, with the result that the average temperature surpasses . The bay receives water from various surrounding rivers and currents originating from the Foxe Basin in the north, resulting in a counterclockwise overall flow. At the extreme southern tip of the extension known as James Bay arises a humid continental climate with a longer and generally hotter summer. (K\u00f6ppen: \"Dfb\"). The average annual temperature in almost the entire bay is around or below. In the extreme northeast, winter temperatures average as low as .\nThe Hudson Bay region has very low year-round average temperatures. The average annual temperature for Churchill at 59\u00b0N is and Inukjuak, facing cool westerlies in summer at 58\u00b0N, an even colder . By comparison, Magadan, in a comparable position at 59\u00b0N on the Eurasian landmass in the Russian Far East and with a similar subarctic climate, has an annual average of . Vis-\u00e0-vis geographically closer Europe, contrasts stand much more extreme. Arkhangelsk at 64\u00b0N in northwestern Russia has an average of , while the mild continental coastline of Stockholm at 59\u00b0N on the shore of an analogous large hyposaline marine inlet \u2013 the Baltic Sea \u2013 has an annual average of .\nWater temperature peaks at on the western side of the bay in late summer. It is largely frozen over from mid-December to mid-June, when it usually clears from its eastern end westwards and southwards. A steady increase in regional temperatures over the last 100 years has led to decreases in the extent of the sea ice in Hudson Bay by 19.5% per decade. As well as a lengthening of the ice-free period, which was as short as four months in the late 17th century.\nThe polar climate of Hudson Bay means it is home for a variety of polar climate animals, in the Western Hudson Bay (WHB) beluga whale population is the most significant known group in the Canadian Arctic, estimated to consist of approximately 54,473 individuals.\nWaters.\nHudson Bay has a lower average salinity level than that of ocean water. The main causes are the low rate of evaporation (the bay is ice-covered for much of the year), the large volume of terrestrial runoff entering the bay (about annually, the Hudson Bay watershed covering much of Canada, many rivers and streams discharging into the bay), and the limited connection with the Atlantic Ocean and its higher salinity. Sea ice is about three times the annual river flow into the bay, and its annual freezing and thawing significantly alters the salinity of the surface layer. Although its exact effects are not fully understood currently, the cyclonic storms in the bay are responsible for synoptic variability of salinity along the coast.\nOne consequence of the lower salinity of the bay is that the freezing point of the water is higher than in the rest of the world's oceans, thus decreasing the time that the bay remains ice-free. The increase of river inflows during the winter has decreased the season of sea ice by more than one month since the 1960s.\nThe lower salinity of the bay also has effects on the distribution and prevalence of common marine life such as micro algae. Research has shown that the lower salinity of the Hudson Bay limits the growth of micro algae, which causes a notable change in biomass along the bay's salinity gradient.\nShores.\nThe western shores of the bay are a lowland known as the Hudson Bay Lowlands, covering , and are Canada's largest continuous peatland. Much of the landform has been shaped by the actions of glaciers and the shrinkage of the bay over long periods of time. The coastal area, located in a region characterized by permanently frozen layers of soil, known as permafrost, is a low-lying wetland that receives water from lakes and fast-flowing rivers. Signs of numerous former beach fronts can be seen far inland from the current shore. A large portion of the lowlands in the province of Ontario is part of the Polar Bear Provincial Park, and a similar portion of the lowlands in Manitoba is contained in Wapusk National Park, the latter location being a significant maternity denning area for polar bears.\nIn contrast, most of the eastern shores (the Quebec portion) form the western edge of the Canadian Shield in Quebec. The area is rocky and hilly. Its vegetation is typically boreal forest.The northern shores are tundra.\nMeasured by shoreline, Hudson Bay is the largest bay in the world (the largest in area being the Bay of Bengal).\nThe distinctive arcuate segment on the eastern shore of Hudson Bay is referred to as the Nastapoka arc.\nIslands.\nThere are many islands in Hudson Bay, mostly near the eastern coast. All the islands, including those in James Bay, are part of Nunavut and lie in the Arctic Archipelago. Several are disputed by the Cree. One group of islands is the Belcher Islands. The Belcher Islands are located in the centre of the Nastapoka arc. Another group includes the Ottawa Islands which are located near the eastern shore of the Hudson Bay.\nGeology.\nHudson Bay occupies a large structural basin, known as the Hudson Bay basin, that lies within the Canadian Shield. The collection and interpretation of outcrop, seismic and drill hole data for exploration for oil and gas reservoirs within the Hudson Bay basin found that it is filled by, at most, of Ordovician to Devonian limestone, dolomite, evaporites, black shales, and various clastic sedimentary rocks that overlie less than of Cambrian strata that consist of unfossiliferous quartz sandstones and conglomerates, overlain by sandy and stromatolitic dolomites. In addition, a minor amount of terrestrial fluvial sands and gravels of the Cretaceous period are preserved in the fill of a prominent ring-like depression about across created by the dissolution of Silurian evaporites during the Cretaceous period.\nFrom the large quantity of published geologic data that has been collected as the result of hydrocarbon exploration, academic research, and related geological mapping, a detailed history of the Hudson Bay basin has been reconstructed. During the majority of the Cambrian Period, this basin did not exist. Rather, this part of the Canadian Shield area was still topographically high and emergent. It was only during the later part of the Cambrian that the rising sea level of the Sauk marine transgression slowly submerged it. During the Ordovician, this part of the Canadian Shield continued to be submerged by rising sea levels except for a brief middle Ordovician marine regression. Only starting in the Late Ordovician and continuing into the Silurian did the gradual regional subsidence of this part of the Canadian Shield form the Hudson Bay basin. The formation of this basin resulted in the accumulation of black bituminous oil shale and evaporite deposits within its centre, thick basin-margin limestone and dolomite, and the development of extensive reefs that ringed the basin margins that were tectonically uplifted as the basin subsided. During Middle Silurian times, subsidence ceased and this basin was uplifted. It generated an emergent arch, on which reefs grew, that divided the basin into eastern and western sub-basins. During the Devonian Period, this basin filled with terrestrial red beds that interfinger with marine limestone and dolomites. Before deposition was terminated by marine regression, Upper Devonian black bituminous shale accumulated in the south-east of the basin.\nThe remaining history of the Hudson Bay basin is largely unknown as a major unconformity separates Upper Devonian strata from glacial deposits of the Pleistocene. Except for poorly known terrestrial Cretaceous fluvial sands and gravels that are preserved as the fills of a ring of subsided strata around the centre of this basin, strata representing this period of time are absent from the Hudson Bay basin and the surrounding Canadian Shield.\nThe Precambrian Shield underlying Hudson Bay and in which Hudson Bay basin formed is composed of two Archean proto-continents, the Western Churchill and Superior cratons. These cratons are separated by a tectonic collage that forms a suture zone between these cratons and the Trans-Hudson Orogen. The Western Churchill and Superior cratons collided at about 1.9\u20131.8 Ga in the Trans-Hudson orogeny. Because of the irregular shapes of the colliding cratons, this collision trapped between them large fragments of juvenile crust, a sizable microcontinent, and island arc terranes, beneath what is now the centre of modern Hudson Bay as part of the Trans-Hudson Orogen. The Belcher Islands are the eroded surface of the Belcher Fold Belt, which formed as a result of the tectonic compression and folding of sediments that accumulated along the margin of the Superior Craton before its collision with the Western Churchill Craton.\nFree-air gravity anomaly.\nHudson Bay and the associated structural basin lie within the centre of a large free-air gravity anomaly that lies within the Canadian Shield. The similarity in areal extent of the free-air gravity anomaly with the perimeter of the former Laurentide ice sheet that covered this part of Laurentia led to a long-held conclusion that this perturbation in the Earth's gravity reflected still ongoing glacial isostatic adjustment to the melting and disappearance of this ice sheet. Data collected over Canada by the Gravity Recovery and Climate Experiment (GRACE) satellite mission allowed geophysicists to isolate the gravity signal associated with glacial isostatic adjustment from longer\u2013time scale process of mantle convection occurring beneath the Canadian Shield. Based upon this data, geophysicists and other Earth scientists concluded that the Laurentide Ice Sheet was composed of two large domes to the west and east of Hudson Bay. Modelling glacial isostatic adjustment using the GRACE data, they concluded that \u224825 to \u224845% of the observed free-air gravity anomaly was due to ongoing glacial isostatic adjustment, and the remainder likely represents longer time-scale effects of mantle convection.\nSoutheastern semicircle.\nEarth scientists have disagreed about what created the semicircular feature known as the Nastapoka arc that forms a section of the shoreline of southeastern Hudson Bay. The Nastapoka arc forms a 155 degree curve and appears to be very circular. Noting the paucity of impact structures on Earth in relation to the Moon and Mars, Carlyle S. Beals proposed that it is possibly part of a Precambrian extraterrestrial impact structure that is comparable in size to the Mare Crisium on the Moon. In the same volume, John Tuzo Wilson commented on Beals' interpretation and alternately proposed that the Nastapoka arc may have formed as part of an extensive Precambrian continental collisional orogen, linked to the closure of an ancient ocean basin. The current general consensus is that it is an arcuate boundary of tectonic origin between the Belcher Fold Belt and undeformed basement of the Superior Craton created during the Trans-Hudson orogeny. This is because no credible evidence for such an impact structure has been found by regional magnetic, Bouguer gravity, or other geologic studies. However, other Earth scientists have proposed that the evidence of an Archean impact might have been masked by deformation accompanying the later formation of the Trans-Hudson orogen and regard an impact origin as a plausible possibility.\nEconomy.\nArctic Bridge.\nThe longer periods of ice-free navigation and the reduction of Arctic Ocean ice coverage have led to Russian and Canadian interest in the potential for commercial trade routes across the Arctic and into Hudson Bay. The so-called Arctic Bridge would link Churchill, Manitoba, and the Russian port of Murmansk. The increase in ships traversing the proposed Arctic Bridge could result in an increase in accidents. Any pollutants released into the environment would be harder to remove as the cleanup would be complicated by ice sheets.\nPort.\nThe biggest port in the Hudson bay is the city of Churchill, which lies on the river with the same name, Churchill River. The Port of Churchill is a privately owned port on Hudson Bay in Churchill, Manitoba, Canada. Routes from the port connect to the North Atlantic through the Hudson Strait. As of 2008, the port had four deep-sea berths capable of handling Panamax-size vessels for the loading and unloading of grain, bulk commodities, general cargo, and tanker vessels. The port is connected to the Hudson Bay Railway, which shares the same parent company, and cargo connections are made with the Canadian National Railway system at HBR's southern terminus in The Pas. It is the only port of its size and scope in Canada that does not connect directly to the country's road system; all goods shipped overland to and from the port must travel by rail.\nThe port was built and owned by the Government of Canada, but was sold in 1997 to the American company OmniTRAX to run privately. In December 2015, OmniTRAX announced it was negotiating a sale of the port, and the associated Hudson Bay Railway, to a group of First Nations based in northern Manitoba. With no sale finalized by July 2016, OmniTRAX shut down the port and the major railroad freight operations in August 2016. The railway continued to carry cargo to supply the town of Churchill itself until the line was damaged by flooding on 23 May 2017. The Port and the Hudson Bay Railway were sold to Arctic Gateway Group\u2014a consortium of First Nations, local governments, and corporate investors\u2014in 2018. On 9 July 2019, ships resupplying Arctic communities began stopping at the port for additional cargo, and the port began shipping grain again on 7 September 2019.\nCoastal communities.\nThe coast of Hudson Bay is extremely sparsely populated; there are only about a dozen communities. Some of these were founded as trading posts in the 17th and 18th centuries by the Hudson's Bay Company, making them some of the oldest settlements in Western Canada. With the closure of the HBC posts and stores, although many are now run by The North West Company, in the second half of the 20th century, many coastal villages are now almost exclusively populated by Cree and Inuit. Two main historic sites along the coast were York Factory and Prince of Wales Fort.\nCommunities along the Hudson Bay coast or on islands in the bay are (all populations are as of 2016):\nMilitary development.\nThe Hudson's Bay Company built forts as fur trade strongholds against the French or other possible invaders. One example is York Factory with angled walls to help defend the fort. In the 1950s, during the Cold War, a few sites along the coast became part of the Mid-Canada Line, watching for a potential Soviet bomber attack over the North Pole. The only Arctic deep-water port in Canada is the Port of Churchill, located at Churchill, Manitoba.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58637", "revid": "13127810", "url": "https://en.wikipedia.org/wiki?curid=58637", "title": "Erysipelas", "text": "Human disease from a bacterial infection of the skin\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nErysipelas () is a relatively common bacterial infection of the superficial layer of the skin (upper dermis), extending to the superficial lymphatic vessels within the skin, characterized by a raised, well-defined, tender, bright-red rash, typically on the face or legs, but which can occur anywhere on the skin. It is a form of cellulitis and is potentially serious.\nErysipelas is usually caused by the bacterium \"Streptococcus pyogenes\", also known as group A, \u03b2-hemolytic streptococci, which enters the body through a break in the skin, such as a scratch or an insect bite. It is more superficial than cellulitis and is typically more raised and demarcated. The term comes from the Greek \u1f10\u03c1\u03c5\u03c3\u03af\u03c0\u03b5\u03bb\u03b1\u03c2 (\"erys\u00edpelas\"), meaning red skin.\nIn animals, erysipelas is a disease caused by infection with the bacterium \"Erysipelothrix rhusiopathiae\". In animals, it is called diamond skin disease, and occurs especially in pigs. Heart valves and skin are affected. \"E. rhusiopathiae\" can also infect humans, but in that case, the infection is known as erysipeloid and is an occupational skin disease.\nSigns and symptoms.\nSymptoms often occur suddenly. Affected individuals may develop a fever, shivering, chills, fatigue, headaches, and vomiting, and be generally unwell within 48 hours of the initial infection. The red plaque enlarges rapidly and has a sharply demarcated, raised edge. It may appear swollen, feel firm, warm, and tender to touch, and have a consistency similar to orange peel. Pain may be extreme.\nMore severe infections can result in vesicles (pox or insect bite-like marks), blisters, and petechiae (small purple or red spots), with possible skin necrosis (death). Lymph nodes may be swollen and lymphedema may occur. Occasionally, a red streak extending to the lymph node can be seen.\nThe infection may occur on any part of the skin, including the face, arms, fingers, legs, and toes; it tends to favour the extremities. The umbilical stump and sites of lymphedema are also common sites affected. Fat tissue and facial areas, typically around the eyes, ears, and cheeks, are most susceptible to infection. Repeated infection of the extremities can lead to chronic swelling (lymphoedema).\nCause.\nMost cases of erysipelas are due to \"Streptococcus pyogenes\", also known as group A, \u03b2-hemolytic streptococci, less commonly to group C or G streptococci and rarely to \"Staphylococcus aureus\". Newborns may contract erysipelas due to \"Streptococcus agalactiae\", also known as group B streptococcus or GBS.\nThe infecting bacteria can enter the skin through minor trauma, bites (human, insect or animal), surgical incisions, ulcers, burns, or abrasions. Underlying eczema or athlete's foot (tinea pedis) may be present, and it can originate from streptococcal bacteria in the subject's own nasal passages or ear.\nThe rash is due to an exotoxin, not the \"Streptococcus\" bacteria, and is found in areas where no symptoms are present, e.g. the infection may be in the nasopharynx, but the rash is found usually on the epidermis and superficial lymphatics.\nDiagnosis.\nErysipelas is usually diagnosed by the clinician looking at the characteristic well-demarcated rash following a history of injury or recognition of one of the risk factors. Tests, if performed, may show a high white-cell count, raised CRP, or positive blood culture identifying the organism. Skin cultures are often negative.\nErysipelas must be differentiated from herpes zoster, angioedema, contact dermatitis, erythema chronicum migrans of early Lyme disease, gout, septic arthritis, septic bursitis, vasculitis, allergic reaction to an insect bite, acute drug reaction, deep vein thrombosis, and diffuse inflammatory carcinoma of the breast.\nDifferentiating from cellulitis.\nErysipelas can be distinguished from cellulitis by two particular features - its raised advancing edge and its sharp borders. The redness in cellulitis is not raised and its border is relatively indistinct. Bright redness of erysipelas has been described as a third differentiating feature.\nErysipelas does not affect subcutaneous tissue. It does not release pus, only serum or serous fluid. Subcutaneous edema may lead the physician to misdiagnose it as cellulitis.\nTreatment.\nTreatment is with antibiotics; (amoxicillin/clavulanic acid, cefalexin, or cloxacillin) taken by mouth for five days, though sometimes longer. Because of the risk of reinfection, prophylactic antibiotics are sometimes used after resolution of the initial condition.\nPrognosis.\nThe disease prognosis includes:\nEpidemiology.\nCurrently, no validated recent data have been published on the worldwide incidence of erysipelas. From 2004 to 2005, UK hospitals reported 69,576 cases of cellulitis and 516 cases of erysipelas. One book stated that several studies have placed the prevalence rate between one and 250 in every 10,000 people. The development of antibiotics, as well as increased sanitation standards, has contributed to the decreased rate of incidence. Erysipelas caused systemic illness in up to 40% of cases reported by UK hospitals, and 29% of people had recurrent episodes within three years. Anyone can be infected, although incidence rates are higher in infants and elderly. Several studies also reported a higher incidence rate in women. Four out of five cases occur on the legs, although historically, the face was a more frequent site.\nRisk factors for developing the disease include:\nPreventive measures.\nIndividuals can take preventive steps to decrease their risk of catching the disease. Properly cleaning and covering wounds is important for people with an open wound. Effectively treating athlete's foot or eczema if either was the cause of the initial infection decreases the chance of the infection occurring again. People with diabetes should pay attention to maintaining good foot hygiene. Follow up with doctors is important to make sure the disease has not come back or spread. About one-third of people who have had erysipelas will be infected again within three years. Rigorous antibiotics may be needed in the case of recurrent bacterial skin infections.\nHistory.\nIt was historically known as St Anthony's fire, with past treatments including muriated tincture of iron, a solution of Iron(III) chloride in alcohol.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58638", "revid": "13568690", "url": "https://en.wikipedia.org/wiki?curid=58638", "title": "Group A streptococcal infection", "text": "Medical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nGroup A streptococcal infections are a number of infections with \"Streptococcus pyogenes\", a group A streptococcus (GAS). \"S.\u00a0pyogenes\" is a species of beta-hemolytic Gram-positive bacteria that is responsible for a wide range of infections that are mostly common and fairly mild. If the bacteria enters the bloodstream, the infection can become severe and life-threatening, and is called an invasive GAS (iGAS).\nInfection of GAS may spread through direct contact with mucus or sores on the skin. GAS infections can cause over 500,000 deaths per year. Despite the emergence of antibiotics as a treatment for group A streptococcus, cases of iGAS are an increasing problem, particularly on the continent of Africa.\nThere are many other species of \"Streptococcus\", including group B streptococcus \"Streptococcus agalactiae\", and \"Streptococcus pneumoniae\", which cause other types of infections. Several virulence factors contribute to the pathogenesis of GAS, such as M protein, hemolysins, and extracellular enzymes.\nTypes of infection.\nGroup A \u03b2-hemolytic streptococcus can cause infections of the throat and skin. These may vary from very mild conditions to severe, life-threatening diseases. Although it is not completely clear what causes different people to develop different diseases as a result of infection with the same pathogenic bacteria, it is suspected that host phenotypic and epigenetic factors are the source of such variation. Indeed, the many virulence factors of GAS can influence the epigenetics of the host. Furthermore, persons with suppressed or compromised immune systems may be more susceptible to certain diseases caused by GAS than other persons with intact immune systems. A 2019 study shows that GAS's evasion of immune detection is facilitated by protein\"\u00a0\"S, an extracellular and cell wall-associated protein that enables it to camouflage itself by binding fragments of lysed red blood cells.\nHumans may also carry the GAS either on the skin or in the throat and show no symptoms. These carriers are less contagious than symptomatic carriers of the bacteria.\nThe non-invasive infections caused by GAS tend to be less severe and more common. They occur when the bacteria colonizes the throat area, where it recognizes epithelial cells. The two most prominent infections of GAS are both non-invasive: strep throat (pharyngitis) where it causes 15\u201330% of the childhood cases and 10% of adult cases, and impetigo. These may be effectively treated with antibiotics. Scarlet fever is also a non-invasive infection caused by GAS, although much less common.\nThe invasive infections caused by Group A \u03b2-hemolytic streptococcus tend to be more severe and less common. These occurs when the bacterium is able to infect areas where bacteria are not usually found, such as blood and organs. The diseases that may be caused as a result of this include streptococcal toxic shock syndrome (STSS), necrotizing fasciitis (NF), pneumonia, and bacteremia. \nIn addition, infection of GAS may lead to further complications and health conditions, namely acute rheumatic fever and poststreptococcal glomerulonephritis.\nMost common:\nLess common:\nSevere infections.\nSome strains of group A streptococci (GAS) cause severe infection. Severe infections are usually invasive, meaning that the bacteria has entered parts of the body where bacteria are not usually found, such as the blood, lungs, deep muscle or fat tissue. Those at greatest risk include children with chickenpox; persons with suppressed immune systems; burn victims; elderly persons with cellulitis, diabetes, vascular disease, or cancer; and persons taking steroid treatments or chemotherapy. Intravenous drug users and homeless also are at high risk. GAS is an important cause of puerperal fever worldwide, causing serious infection and, if not promptly diagnosed and treated, death in newly delivered mothers. Severe GAS disease may also occur in healthy persons with no known risk factors.\nAll severe GAS infections may lead to shock, multisystem organ failure, and death. Early recognition and treatment are critical. Diagnostic tests include blood counts and urinalysis as well as cultures of blood or fluid from a wound site.\nSevere Group A streptococcal infections often occur sporadically but can be spread by person-to-person contact. Close contacts of people affected by severe Group A streptococcal infections, defined as those having had prolonged household contact in the week before the onset of illness, may be at increased risk of infection. This increased risk may be due to a combination of shared genetic susceptibility within the family, close contact with carriers, and the virulence of the Group A streptococcal strain that is involved.\nPublic health policies internationally reflect differing views of how the close contacts of people affected by severe Group A streptococcal infections should be treated. Health Canada and the US CDC recommend close contacts see their doctor for full evaluation and may require antibiotics; current UK Health Protection Agency guidance is that, for a number of reasons, close contacts should not receive antibiotics unless they are symptomatic but that they should receive information and advice to seek immediate medical attention if they develop symptoms. However, guidance is clearer in the case of mother-baby pairs: both mother and baby should be treated if either develops an invasive GAS infection within the first 28 days following birth (though some evidence suggests that this guidance is not routinely followed in the UK).\nAccording to a 2025 study published in \"JAMA\", cases of invasive group A streptococcal infections more than doubled between 2013 and 2022, following nearly two decades of stable rates. Researchers suggest a combination of factors may be contributing to this surge, including higher rates of diabetes and obesity that weaken immune defenses, increased incidence among individuals who use injectable drugs or face homelessness, and the emergence of new bacterial strains that may be more infectious or resistant to antibiotics. The findings highlight an urgent need for stronger prevention and control strategies.\nDiagnosis.\nDiagnosis is by a swab of the affected area for laboratory testing. A Gram stain is performed to show Gram-positive cocci in chains. Then, the organism is cultured on blood agar. The rapid pyrrolidonyl arylamidase (PYR) test is commonly used, wherein a positive reaction confers a presumptive identification of group A beta-hemolytic streptococci if the appearance and clinical context is consistent. GBS gives a negative finding on the PYR test. There are also latex agglutination kits which can distinguish each of the main groups seen in clinical practice.\nPrevention.\n\"S. pyogenes\" infections are best prevented through effective hand hygiene. No vaccines are currently available to protect against \"S.\u00a0pyogenes\" infection, although research has been conducted into the development of one. Difficulties in developing a vaccine include the wide variety of strains of \"S.\u00a0pyogenes\" present in the environment and the large amount of time and number of people that will be needed for appropriate trials for safety and efficacy of the vaccine.\nTreatment.\nThe treatment of choice is penicillin, and the duration of treatment is around 10 days. Antibiotic therapy (using injected penicillin) has been shown to reduce the risk of acute rheumatic fever. In individuals with a penicillin allergy, erythromycin, other macrolides, and cephalosporins have been shown to be effective treatments.\nTreatment with ampicillin/sulbactam, amoxicillin/clavulanic acid, or clindamycin is appropriate if deep oropharyngeal abscesses are present, in conjunction with aspiration or drainage. In cases of streptococcal toxic shock syndrome, treatment consists of penicillin and clindamycin, given with intravenous immunoglobulin.\nFor toxic shock syndrome and necrotizing fasciitis, high-dose penicillin and clindamycin are used. Additionally, for necrotizing fasciitis, surgery is often needed to remove damaged tissue and stop the spread of the infection.\nNo instance of penicillin resistance has been reported to date, although since 1985, many reports of penicillin tolerance have been made. The reason for the failure of penicillin to treat \"S.\u00a0pyogenes\" is most commonly patient noncompliance, but in cases where patients have been compliant with their antibiotic regimen, and treatment failure still occurs, another course of antibiotic treatment with cephalosporins is common.\nThe 30-valent N-terminal M-protein-based vaccine as well as the M-protein vaccine (minimal epitope J8 vaccine) are two vaccines for GAS that are currently getting close or becoming clinical studies, however, other vaccines using conserved epitopes are progressing.\nEpidemiology.\nCases of GAS are still present today, but were also evident before World War I. This was shown by a training camp located in Texas, where a harmful strain of pneumonia complicating measles was caused by a strain of Streptococcus. Existence of streptococci strains was additionally found in World War II. An epidemic of streptococcal infection in the United States Navy during this war indicated that this type of disease was able to exist and spread in formerly unexposed individuals by environments that serological types of group A streptococci preferred. In later years, a positive test result for the presence of group A streptococci was found in 32.1 percent of individuals after throat cultures were carried out in a 20-year-long (1953/1954\u20131973/1974) study performed in Nashville, Tennessee. Also, from 1972 to 1974, recurring GAS illness was observed with a prevalence of 19 percent in school-aged children as well as a prevalence rate of 25 percent in families. The severity of streptococcal infections has decreased over the years, and so has rheumatic fever (a sequelae of GAS) which is indicated by the change in numerous hospitals from containing wards allocated for the sole purpose of treating rheumatic fever to hardly seeing the disease at all. Environmental factors, such as less crowding and the increase of family living space, can account for the reduction in incidence and severity of group A streptococci. With more space for individuals to reside in, it provides the bacteria with less opportunities to spread from person to person. This is especially important considering an estimated 500,000 deaths worldwide all occurring after acute rheumatic fever, invasive infection, or subsequent heart disease can be accredited to GAS. This number is quite large, often leaving the health care system encumbered, since 91 percent of patients infected with invasive GAS need to be hospitalized with 8950\u201311,500 episodes and 1050\u20131850 deaths taking place each year. A later study that occurred from 2005 to 2012 found that there were 10,649\u201313,434 cases consequently resulting in 1136\u20131607 deaths per year.\nComplications.\nAcute rheumatic fever.\nAcute rheumatic fever (ARF) is a complication of respiratory infections caused by GAS. The M-protein generates antibodies that cross-react with autoantigens on interstitial connective tissue, in particular of the endocardium and synovium, that can lead to significant clinical illness.\nAlthough common in developing countries, ARF is rare in the United States, possibly secondary to improved antibiotic treatment, with small isolated outbreaks reported only occasionally. It is most common among children between 5 and 15 years old and occurs 1\u20133 weeks after an untreated GAS pharyngitis, but caution is advised when interpreting the demographics of the contemporary picture of pediatric cases in the United States.\nARF is often clinically diagnosed based on Jones Criteria, which include: pancarditis, migratory polyarthritis of large joints, subcutaneous nodules, erythema marginatum, and sydenham chorea (involuntary, purposeless movement). The most common clinical finding is a migratory arthritis involving multiple joints.\nOther indicators of GAS infection such as a DNAase or ASO serology test must confirm the GAS infection. Other minor Jones Criteria are fever, elevated ESR and arthralgia. One of the most serious complications is pancarditis, or inflammation of all three heart tissues. A fibrinous pericarditis can develop with a classic friction rub that can be auscultated. This will give increasing pain upon reclining.\nFurther endocarditis can develop with aseptic vegetations along the valve closure lines, in particular the mitral valve. Chronic rheumatic heart disease mostly affects the mitral valve, which can become thickened with calcification of the leaflets, often causing fusion of the commissures and chordae tendineae.\nOther findings of ARF include erythema marginatum (usually over the spine or other bony areas) and a red expanding rash on the trunk and extremities that recurs over weeks to months. Because of the different ways ARF presents itself, the disease may be difficult to diagnose.\nA neurological disorder, Sydenham chorea, can occur months after an initial attack, causing jerky involuntary movements, muscle weakness, slurred speech, and personality changes. Initial episodes of ARF, as well as recurrences, can be prevented by treatment with appropriate antibiotics.\nIt is important to distinguish ARF from rheumatic heart disease. ARF is an acute inflammatory reaction with pathognomonic Aschoff bodies histologically and RHD is a non-inflammatory sequela of ARF.\nPost-streptococcal glomerulonephritis.\nPost-streptococcal glomerulonephritis (PSGN) is an uncommon complication of either a strep throat or a streptococcal skin infection. It is classified as a type III hypersensitivity reaction. Symptoms of PSGN develop within 10 days following a strep throat or 3 weeks following a GAS skin infection. PSGN involves inflammation of the kidney. Symptoms include pale skin, lethargy, loss of appetite, headache, and dull back pain. Clinical findings may include dark-colored urine, swelling of different parts of the body (edema), and high blood pressure. Treatment of PSGN consists of supportive care.\nPANDAS.\nObsessive\u2013compulsive disorder and tic disorders are hypothesized to arise in a subset of children as a result of a post-streptococcal autoimmune process. Its potential effect was described in 1998 by the controversial hypothesis called PANDAS (pediatric autoimmune neuropsychiatric disorders associated with streptococcal infections), a condition thought to be triggered by GABHS infections. The PANDAS hypothesis is unconfirmed and unsupported by data, and two new categories have been proposed: PANS (pediatric acute-onset neuropsychiatric syndrome) and CANS (childhood acute neuropsychiatric syndrome). The CANS/PANS hypotheses include different possible mechanisms underlying acute-onset neuropsychiatric conditions, but do not exclude GABHS infections as a cause in a subset of individuals. PANDAS, PANS and CANS are the focus of clinical and laboratory research but remain unproven.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNote: Elements of the original text of this article are taken from the NIH Fact Sheet \"Group A Streptococcal Infections\", dated March 1999. As a work of the U.S. Federal Government without any other copyright notice, this is assumed to be a public domain resource."}
{"id": "58639", "revid": "57939", "url": "https://en.wikipedia.org/wiki?curid=58639", "title": "Dida language", "text": "Kru dialect cluster of Ivory Coast\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nDida is a dialect cluster of the Kru family spoken in Ivory Coast.\nISO divides Dida into three groups, Yocobou\u00e9 (Yokubwe) Dida (101,600 speakers in 1993), Lakota Dida (93,800 speakers in 1993), and Ga\u0253ogbo (Gu\u00e9bi\u00e9/Gebye) which are only marginally mutually intelligible and best considered separate languages. Yocobou\u00e9 consists of the Lozoua (Lozwa) and Divo dialects (7,100 and 94,500 speakers), and Lakota the Lakota (L\u00e1kota), Abou (Abu), and Vata dialects. The prestige dialect is the Lozoua speech of the town of Guitry.\nPhonology.\nThe Dida lects have consonant and vowel inventories typical of the Eastern Kru languages. However, tone varies significantly between dialects, or at least between their descriptions. The following phonology is that of Abu Dida, from Miller (2005), and of Yocobou\u00e9 Dida, from Masson (1992).\nVowels.\nAbu.\nAbu Dida has a ten-vowel system: nine vowels distinguished by \"tenseness\", likely either pharyngealization or supra-glottal phonation (contraction of the larynx) of the type described as retracted tongue root, plus an uncommon mid-central vowel .\nThe non-contracted vowels are , and the contracted vowels . (These could be analyzed as , but here are transcribed with lower vowels to reflect their phonetic realization. There is no tense contrast with the low vowel.) The formants of the tense vowels show them to be lower than their non-tense counterparts: the formants of the highest tense vowels overlap the formants of the non-tense mid vowels, but there is visible tension in the lips and throat when these are enunciated carefully.\nAbu Dida has a number of diphthongs, which have the same number of tonal distinctions as simple vowels. All start with the higher vowels, , and except for , both elements are either contracted or non-contracted, so the pharyngealization is here transcribed after the second element of the vowel. Examples are \"bottle\" (from English), \"get stuck\", and \"little bone\".\nDida also has nasal vowels, but they are not common and it is not clear how many. Examples are \"nothing\", \"chin\", \"25 cents\" (from English \"pound\"). In diphthongs, nasalization shows up primarily on the second element of the vowel.\nVowel length is not distinctive, apart from phonesthesia (as in \"nothing\"), morphemic contractions, and shortened grammatical words, such as the modal \"will\" (compare its likely lexical source \"get\").\nYocobou\u00e9.\nYocobou\u00e9 Dida has a nine vowel system: four vowels being standard, and five vowels being a retracted series, plus a realization.\nThe four regular vowels are /i e o u/, and the retracted vowels are /\u026a \u025b a \u0254 \u028a/. /a/ may also be realized as [\u028c].\nAll vowels do have nasal realizations, but the nasalization of vowels is not phonemic.\nConsonants.\nThe consonants in Abu Dida are typical for Eastern Kru:\nSyllables may be vowel only, consonant-vowel, or consonant--vowel. is a lateral approximant initially, a lateral flap between vowels and after most consonants ( \"country\"), but a central tap after alveolars ( \"blood\"). After a nasal (), it is itself nasalized, and sounds like a short \"n.\" There is a short epenthetic vowel between the initial consonant and the flap, which takes the quality of the syllabic vowel that follows ( \"country\"). Flap clusters occur with all consonants, even the approximants ( \"top\"), apart from the alveolar sonorants and the marginal consonant , which is only attested in the syllable .\n is implosive in the sense that the airstream is powered by the glottis moving downward, but there is no rush of air into the mouth. occurs in few words, but one of these, \"appear\", occurs in numerous common idioms, so overall it's not an uncommon sound. It is a true fricative and may devoice to word initially. and plus a vowel are distinct from or plus and another vowel. They may also be followed by a flap, as in \"face\".\nWhen emphasized, zero-onset words may take an initial , and initial approximants may become fricated , . becomes palatalized before high front vowels, or when emphasized.\nThe following consonants are for Yocobou\u00e9 Dida:\n/l/ can be realized as when after alveolar stops, and as when after nasals.\nTones.\nDida uses tone as a grammatical device. Morpho-tonology plays a greater role in verb and pronominal paradigms than it does in nouns, and perhaps because of this, Dida verbs utilize a simpler tone system than nouns do: Noun roots have four lexically contrastive tones, subject pronouns have three, and verb roots have just two word tones.\nThere are three level tones in Abou Dida: high , mid , and low , with mid about twice as common as the other two. Speaker intuition hears six contour tones: rising and falling . (The falling tones only reach bottom register at the end of a prosodic unit; otherwise the low falling tone is realized as a simple low tone.) However, some of these only occur in morphologically complex words, such as perfective verbs.\nMonosyllabic nouns contrast four tones: high, mid, low, and mid-falling: \"egg\", \"leopard\", \"buffalo\", \"arrow\", with high and mid being the most frequent.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58640", "revid": "1223485476", "url": "https://en.wikipedia.org/wiki?curid=58640", "title": "B\u00e9t\u00e9 languages", "text": "Language cluster of Kru languages spoken in Ivory Coast\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nThe B\u00e9t\u00e9 languages are a language cluster of Kru languages spoken in central-western Ivory Coast. There are many dialects but they can be grouped as follows:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58641", "revid": "2842084", "url": "https://en.wikipedia.org/wiki?curid=58641", "title": "Jer\u00f3nimo Zurita y Castro", "text": "Spanish historian\nJer\u00f3nimo (or Ger\u00f3nimo) de Zurita y Castro or simply Jer\u00f3nimo (or Ger\u00f3nimo) de Zurita (1512 \u2013 3 November 1580) was a Spanish historian of the sixteenth century who founded the modern tradition of historical scholarship in Spain.\nBorn at Zaragoza, Kingdom of Aragon, he studied at Alcal\u00e1 de Henares under the Hellenist Hern\u00e1n Nu\u00f1ez. Through the influence of his father, Miguel de Zurita, physician to Charles V, Holy Roman Emperor, he entered the public service as magistrate at Barbastro, and in 1537 was appointed assistant-secretary of the Inquisition. In 1548 Zurita was nominated official chronicler of the Kingdom of Aragon, and in 1566 Philip II of Spain attached him as secretary to the council of the Inquisition, delegating to him the conduct of all matters sufficiently important to require the king's signature. Zurita resigned these posts on the January 21, 1571, obtained a sinecure at Zaragoza, and dedicated himself wholly to the composition of his \"Anales de la Corona de Arag\u00f3n\", the first part of which had appeared in 1562; he lived to see the last volume printed at Zaragoza on the April 22, 1580, and died on the November 3 following.\nZurita's style is somewhat crabbed and dry, but his authority is unquestionable; he displayed a new conception of an historian's duties, and, not content with the ample materials stored in the Archives of Aragon, continued his researches in the libraries of Rome, Naples and Sicily.\nQuotes.\n\"Historians use legends as geographers do fabulous animals-to symbolize unknown countries in their maps\" - quoted from \"Spanish Historiography and Iberian Reality\" by J. N. Hillgarth, \"History and Theory\", Vol. 24, No. 1 (Feb., 1985), pp.\u00a023\u201343."}
{"id": "58642", "revid": "4490355", "url": "https://en.wikipedia.org/wiki?curid=58642", "title": "James Bay", "text": "Bay on the southern end of the Hudson Bay, Canada\nJames Bay (, ; ) is a body of water located on the southern end of Hudson Bay in Canada. It borders the provinces of Quebec and Ontario, and is politically part of Nunavut. Its largest island is Akimiski Island.\nNumerous waterways of the James Bay watershed have been modified with dams or diversion for several major hydroelectric projects. These waterways are also destinations for river-based recreation. Several communities are located near or alongside James Bay, including a number of Aboriginal Canadian communities, such as the Kashechewan First Nation and nine communities affiliated with the Cree of northern Quebec.\nAs with the rest of Hudson Bay, the waters of James Bay routinely freeze over in winter. It is the last part of Hudson Bay to freeze over in winter, and the first to thaw in summer.\nHistory.\nHuman presence along the shores of the bay began after the retreat of the glaciers at the end of the last ice age, around 8,150 years ago. A variety of indigenous cultures have lived in this area. At the time of contact with Europeans, the indigenous peoples along both shores of the bay were ethnically Cree peoples.\nHenry Hudson is believed to have been the first European to enter the bay, when he explored it in 1610 as part of his exploration of the larger bay that was named for him. This southerly bay was named in honour of Thomas James, a Welsh captain who explored the area more thoroughly in 1630 and 1631.\nJames Bay is important in the history of Canada as one of the most hospitable parts of the Hudson Bay region, although it has had a low human population. It was an area of importance to the Hudson's Bay Company and British expansion into Canada. The fur-trapping duo of explorers Pierre-Esprit Radisson and M\u00e9dard des Groseilliers convinced the English Crown, primarily Prince Rupert of the Rhine, a favoured nephew of Charles I and cousin to Charles II, that a colonial enterprise in the north would yield wealth in minerals and fur. Des Groseilliers accompanied Captain Zachariah Gillam on the ketch \"Nonsuch\" and they jointly founded Charles Fort, the first European fur-trading post on James Bay.\nTheir success was such that the company was chartered by Charles II on their return, although they did not bring any minerals. This charter granted a complete trading monopoly to the company of the whole Hudson Bay basin (including James Bay). At the same time, the first English colony on what is now mainland Canada, Rupert's Land, was formed, with the first \"capital\" designated at Charles Fort. The first colonial governor, Charles Baley (various spellings exist, including but not limited to \"Bailey\"), was a Quaker, and this is believed to have been a factor in his respectful relations with the company's trading partners, the First Nations.\nSignificant fur trapping has continued in the region. In general, the east coast or East Main of James Bay was too easily accessed by French and independent traders from the south. The Hudson's Bay Company emphasised from an early period trading relations with tribes in interior trapping grounds, reached from the west coasts of James and Hudson bays. East Main was, nevertheless, the gateway to British settlements in what would become Manitoba (Winnipeg, for example) and as far west as the Rocky Mountains.\nGeography.\nJames Bay represents the southern extent of the Arctic Archipelago Marine ecozone. While the coastal areas are primarily in the Hudson Plains, the northeastern coast bordering Quebec is in the Taiga Shield ecozone. This rocky and hilly eastern shore forms the western edge of the Canadian Shield in Quebec and as such, the main habitat is boreal forest of the Eastern Canadian Shield taiga ecoregion. The western shore, however, is characterised by broad tundra lowlands that are an extension of the Hudson Bay Lowlands, and the vegetation is mostly muskeg bog. A large portion of this area is part of the Polar Bear Provincial Park. Ringed seals are common elsewhere along James Bay and polar bears can be seen hunting the seals as prey. Beluga whales within James Bay basin could be distinct from those found in Hudson Bay.\nHundreds of rivers flow into James Bay. The geography of the region gives many of them similar characteristics. They tend to be wide and shallow near the Bay (in the James Bay Lowlands), whereas they are steeper and narrower farther upstream (as they pour off the Canadian Shield). For a larger list of waterways in the region, see list of Hudson Bay rivers.\nHannah Bay.\nHannah Bay is the southernmost bay of James Bay. Here the Kesagami and Harricana Rivers flow into James Bay. About 238\u00a0km2 is protected under the Migratory Birds Convention Act of Canada as the Hannah Bay Bird Sanctuary. This sanctuary has also been designated as a Wetland of International Importance under the Ramsar Convention since May 1987.\nThe shores in this area are a mixture of intertidal mud, sand, and salt flats, estuarine waters, intertidal marshes, freshwater ponds, swamps, and forested peatlands. These elements make an abundance of wildlife.\nIslands.\nJames Bay contains numerous islands. The largest of the islands is Akimiski Island, which covers .\nAll of northern Ontario and northern Quebec were part of the Hudson Bay Company's proprietary colony of Rupert's Land, and after Rupert's Land was purchased by Canada in 1869, the area became part of the North-West Territories (NWT). In the late 19th and early 20th centuries, Canada transferred much of the NWT to Ontario and Quebec, thus forming modern northern Ontario and northern Quebec. However, all of the islands in Hudson Bay and James Bay remained part of the NWT. Following the partition of the NWT in 1999, the islands in Hudson Bay and James Bay were transferred to the new territory of Nunavut.\nHuman development.\nCoastal communities.\nThe shores of James Bay are sparsely populated. On the eastern shore in Quebec there are four coastal communities belonging to the Cree, the indigenous people of the region (from south to north):\nOn the western shore in Ontario there are five coastal communities (from south to north):\nEconomic development.\nSince 1971, the government of Quebec has built hydroelectric dams on rivers in the James Bay watershed, notably La Grande and Eastmain rivers. Built between 1974 and 1996, the James Bay Project now has a combined generating capacity of 16,021 MW and produces about 83 billion kWh of electricity each year, about half of Quebec's consumption. Power is also exported to the United States via a direct transmission high voltage line. The James Bay Project continues to expand, with work that began in 2010 on a new phase that involves the diversion of the Rupert River.\nA proposed development project, the Great Recycling and Northern Development Canal (GRAND Canal), centred on constructing a large dike to separate southern James Bay from Hudson Bay. This would turn the bay into a freshwater lake, due to the numerous rivers that empty into it. The main benefit expected from this would be to redirect this freshwater for human use. Water would be pumped south from the newly formed James Lake into the Harricana River, crossing into the Great Lakes watershed near Amos, into Lake Timiskaming and the Ottawa River, crossing near Mattawa into Lake Nipissing and the French River to Lake Huron (Georgian Bay).\nRecreation.\nCanoeing.\nMany of the rivers flowing into James Bay are popular destinations for wilderness canoe-trippers. Among the more popular rivers are:\nTwo less-travelled rivers are the Groundhog River and the Harricana. The Groundhog is less travelled in modern times due to a series of seven dams that are about a day or two up-river from the Moose. Canoeists can contact the dam company and arrange to be portaged around the dams on company trucks, but they must make arrangements specific to the hour, and they cannot be late. The Groundhog flows into the Mattagami. The Mattagami then flows into the Moose; it is at the meeting of the Missinaibi and Mattagami rivers that the Moose river begins, marked by an island known as Portage Island. This point is about two or three days travel by canoe to Moosonee. Though the Missinaibi and the Groundhog are both fairly high in the summer, the Moose is often quite low. Depending on the tides, groups have had to walk long stretches of the river. Rapids on the Groundhog tend to be bigger and more technical than those on the Missinaibi, but the campsites are few and poor, because the volume of travel is so much less.\nThe Harricana River is wild, powerful, dangerous river that flows into James Bay east of Moosonee after two infamous sections of river known as 1-mile and 7-mile island. Consistent whitewater and waterfalls make these sections of river extremely dangerous. Anyone wishing to take this route must allow about two days to cross the bay, an extremely dangerous proposition if the tides and the weather are unfavourable.\nThe most common access point for paddlers to this area is Moosonee, at the southern end of James Bay. A campsite at Tidewater Provincial Park provides large campgrounds with firepits and outhouses on an island across the river from the town. Water taxis will ferry people back and forth for about C$20 each. Many of these rivers finish near Moosonee, and paddlers can take the Polar Bear Express train south to Cochrane at the end of a trip. This train regularly features a 'canoe car' enabling paddlers to travel with their canoes.\nWaskaganish, Quebec, is a town farther to the north and east on James Bay. It is accessible via the James Bay Road, and is the most common end point for trips on the Broadback, Pontax, and Rupert rivers (the town itself is situated at the mouth of the Rupert).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "58644", "revid": "40338350", "url": "https://en.wikipedia.org/wiki?curid=58644", "title": "Nazg\u00fbl", "text": "Character group from J. R. R. Tolkien's legendarium\nThe Nazg\u00fbl (from Black Speech 'ring', and 'wraith, spirit')\u00a0\u2013 introduced as Black Riders and also called Ringwraiths, Dark Riders, the Nine Riders, or simply the Nine\u00a0\u2013 are fictional characters in J. R. R. Tolkien's Middle-earth. They were nine Men who had succumbed to Sauron's power through wearing Rings of Power, which gave them immortality but reduced them to invisible wraiths, servants bound to the power of the One Ring and completely under Sauron's control.\n\"The Lord of the Rings\" calls them Sauron's \"most terrible servants\". Their leader, known as the Witch-king of Angmar, the Lord of the Nazg\u00fbl, or the Black Captain, was Sauron's chief agent for most of the Third Age. At the end of the Third Age, their main stronghold was the city of Minas Morgul at the entrance to Sauron's realm, Mordor. They dress entirely in black. In their early forays, they ride on black horses; later they ride flying monsters, which Tolkien described as \"pterodactylic\". Their main weapon is terror, though in their pursuit of the Ring-bearer Frodo Baggins, their leader uses a Morgul-knife which would reduce its victim to a wraith, and they carry ordinary swords. In his final battle, the Lord of the Nazg\u00fbl attacks \u00c9owyn with a mace. The hobbit Merry Brandybuck stabs him with an ancient enchanted N\u00famen\u00f3rean blade, allowing \u00c9owyn to kill him with her sword.\nCommentators have written that the Nazg\u00fbl serve on the ordinary level of story as dangerous opponents of the Company of the Ring; at the romantic level as the enemies of the heroic protagonists; and finally at the mythic level. Tolkien knew the \"Lacnunga\", the Old English book of spells; it may have suggested multiple features of the Nazg\u00fbl, the Witch-King, and the Morgul-knife.\nThe Nazg\u00fbl appear in numerous adaptations of Tolkien's writings, including animated and live-action films and computer games.\nFictional history.\nSecond Age.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThose who used the Nine Rings became mighty in their day, kings, sorcerers, and warriors of old. They obtained glory and great wealth, yet it turned to their downfall. They had, as it seemed, unending life, yet life became unendurable to them. They could walk, if they would, unseen by all eyes in this world beneath the sun, and they could see things in worlds invisible to mortal men; but too often they beheld only the phantoms and delusions of Sauron. And one by one, sooner or later, according to their native strength and to the good or evil of their wills in the beginning, they fell under the thraldom of the ring that they bore and of the domination of the One which was Sauron's. And they became forever invisible save to him that wore the Ruling Ring, and they entered into the realm of shadows. The Nazg\u00fbl were they, the Ringwraiths, the \u00dalairi, the Enemy's most terrible servants; darkness went with them, and they cried with the voices of death. \n\"The Silmarillion\", \"Of the Rings of Power and the Third Age\"\nThe Nazg\u00fbl or Ringwraiths (Quenya plural: \"\u00dalairi\") first appeared in the Second Age. The Dark Lord Sauron gave nine Rings of Power to powerful mortal men, including three lords of the once-powerful island realm of N\u00famenor, along with kings of countries in Middle-earth. The rings enslaved their bearers to the power of Sauron's One Ring, into which he had put much of his own power. The corrupting effect of the Rings greatly extended the bearers' lives.\nThe Nazg\u00fbl had a sharp sense of smell. Their sight worked differently, too: \"They themselves do not see the world of light as we do, but our shapes cast shadows in their minds, which only the noon sun destroys; and in the dark they perceive many signs and forms that are hidden from us: then they are most to be feared.\" Their chief weapon was terror; it was so powerful that Sauron faced one disadvantage when using them: they could not easily travel in secret. The terror they spread was greater when they were unclad and invisible; and when they were gathered together.\nOnly two of the Nazg\u00fbl are named or identified individually in Tolkien's works. Their chief, also known as the Lord of the Nazg\u00fbl and the Black Captain, appears as the Witch-king of Angmar during the Third Age, instrumental in the destruction of the North-kingdom of Arnor. In \"Unfinished Tales\", his second-in-command is named as &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Kham\u00fbl, the \"Black Easterling\" or the \"Shadow of the East\". Three of the Nazg\u00fbl were great N\u00famen\u00f3rean lords; in his notes for translators, Tolkien speculated that the Witch-king of Angmar, ruler of a northern kingdom with its capital at Carn D\u00fbm, was of N\u00famen\u00f3rean origin.\nThe Nine soon became Sauron's principal servants. They were dispersed after the first overthrow of Sauron late in the Second Age at the hands of the Last Alliance of Elves and Men, but their survival was assured by the power of the One Ring.\nThird Age.\nThe Nazg\u00fbl re-emerge over a thousand years later in the Third Age, when the Lord of the Nazg\u00fbl leads Sauron's forces against the successor kingdoms of Arnor: Rhudaur, Cardolan, and Arthedain. He destroys all three but is defeated by the armies of Gondor and the Elf-lord Glorfindel, who prophesies that \"not by the hand of man will he fall\". He escapes, and returns to Mordor. There, he gathers the other Nazg\u00fbl to prepare for the return of Sauron.\nThe Nazg\u00fbl besiege Minas Ithil, a Gondorian fortress in the Ephel Duath, capture it, and acquire its \"palant\u00edr\" for Sauron. The city becomes Minas Morgul, the Nazg\u00fbl's stronghold, and the valley is known as Morgul Vale (Imlad Morgul). Sauron returns from Dol Guldur to Mordor and declares himself openly. He sent two or three of the Nazg\u00fbl, led by Khamul, to garrison Dol Guldur.\nSauron learns from Gollum that a hobbit, Bilbo Baggins of the Shire, has acquired the One Ring. Sauron entrusts its recovery to the Nazg\u00fbl. They reappear \"west of the River\", riding black horses that were bred or trained in Mordor to endure their terror. They learn that the Ring has passed to Bilbo's heir, Frodo, and hunt him and his companions across the Shire; the hobbits hear snuffling, and sometimes see them crawling. The hobbits escape, via Tom Bombadil's realm where they are not pursued, to Bree. A Ranger of the North, Aragorn, arrives ahead of them and for some days leads them on paths not closely followed by the Ringwraiths.\nFive of the Nazg\u00fbl corner Frodo and his company at Weathertop, where the Witch-king stabs Frodo in the shoulder with the Morgul-knife, breaking off a piece of it in the Hobbit's flesh. During their assault, they mentally command Frodo to put on the One Ring; while wearing it, he sees them as pale figures robed in white, with \"haggard hands\", helmets and swords. The Witch-king was taller than the others, with \"long and gleaming\" hair and a crown on his helmet.\nWhen all Nine are swept away by the waters of the river Bruinen, their horses are drowned, and the Ringwraiths are forced to return to Mordor to regroup. \nThe nine members of the Company of the Ring, tasked with the destruction of the Ring, leave Rivendell as the \"Nine Walkers\", in opposition to the Nazg\u00fbl, the \"Nine Riders\".\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThe Nazg\u00fbl came again ... like vultures that expect their fill of doomed men's flesh. Out of sight and shot they flew, and yet were ever present, and their deadly voices rent the air. More unbearable they became, not less, at each new cry. At length even the stout-hearted would fling themselves to the ground as the hidden menace passed over them, or they would stand, letting their weapons fall from nerveless hands while into their minds a blackness came, and they thought no more of war, but only of hiding and of crawling, and of death.\n\"The Return of the King\", \"The Siege of Gondor\"\nThe Nazg\u00fbl reappear mounted on hideous flying beasts. During the Battle of the Pelennor Fields, the Lord of the Nazg\u00fbl uses magic, including Grond, a battering-ram engraved with evil spells, to break the gates of Minas Tirith. He is faced by \u00c9owyn, a noblewoman of Rohan; and not far away, Merry, a hobbit of the Company. \u00c9owyn boldly calls the Nazg\u00fbl a \"dwimmerlaik\", telling him to go if he is not deathless. He casts back his hood to reveal a crown, but the head that wears it is invisible. Merry's surreptitious stroke with an enchanted Barrow-blade brings the Nazg\u00fbl to his knees, allowing \u00c9owyn, the niece of Th\u00e9oden, to drive her sword between his crown and mantle. Thus is the Witch-king destroyed by a woman and a Hobbit, fulfilling Glorfindel's prophecy. Both weapons that pierced him disintegrate, and both assailants are stricken with the Black Breath.\nAfter the fall of the Lord of the Nazg\u00fbl, command of Mordor's army in the field falls to Gothmog, the \"lieutenant of Morgul\", of unspecified race.\nThe remaining eight Ringwraiths attack the Army of the West during the Battle of the Morannon. When Frodo claims the Ring for his own in Mount Doom, Sauron, finally realizing his peril, orders the remaining eight Nazg\u00fbl to fly to intercept him. They arrive too late: Gollum seizes the Ring and falls into the Cracks of Doom, destroying the Ring. That ends Sauron's power and everything he had brought into being using it, including the Nazg\u00fbl.\nSteeds.\nThe flying steeds of the Nazg\u00fbl are given various descriptions but no name. The soldier of Gondor Beregond calls them \"Hell Hawks\". Tolkien describes them as \"fell beasts\", though he also applies the adjective \"fell\" (\"fierce, cruel\") to other creatures throughout \"The Lord of the Rings\" \u2013 even at one point to the wizard Gandalf. In a letter, he calls the winged mounts \"Nazg\u00fbl-birds\". In the absence of a proper name, derivative works sometimes press \"fellbeast\" or \"fell-beast\" into service.\nIn the Battle of the Pelennor Fields, where the Lord of the Nazg\u00fbl rode one of the flying beasts against King Th\u00e9oden of Rohan, his mount is described as:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nIt is said to attack with \"beak and claw\". Tolkien wrote that he \"did not intend the steed of the Witch-king to be what is now called a 'pterodactyl'\", while acknowledging \"obviously it is \"pterodactylic\"\" and owed much to the \"new ... mythology\" [of the \"Prehistoric\"], and might even be \"a last survivor of older geological eras.\"\nThe medievalist Marjorie Burns compares the fell beast to the \"Poetic Edda\"'s flying steed Sleipnir, \"Odin's eight-legged otherworldly horse\". She writes that whereas Gandalf's horse Shadowfax resembles Sleipnir in his miraculous speed and in almost seeming to fly, the Nazg\u00fbl's mount actually flies but is a \"negative image\" of Odin's steed; and, she notes, both Odin and the Nazg\u00fbl can cause blindness.\nConcept and creation.\nDevelopment.\nTolkien began writing \"The Lord of the Rings\" with no conception of Black Riders at all. The horseman in dark clothes in the early chapter \"Three is Company\" was originally Gandalf; in 1938, Tolkien called the figure's transformation into a Black Rider \"an unpremeditated turn\". Frodo's ring, too, was simply a magic ring conferring invisibility, both in \"The Hobbit\" and early drafts of \"The Lord of the Rings\", with no link to Sauron. However, Tolkien was at the time starting to consider the true nature of the Ring, and the idea that it had been made by the Necromancer, and drew itself or its bearer back to him. The Black Riders became Ringwraiths when the hobbit, at that time called Bingo rather than Frodo, discussed the Riders with the Elf Gildor, later in the same chapter. Over the next three years, Tolkien gradually developed the connections between the Nazg\u00fbl, the One Ring, Sauron, and all the other Rings of Power. The pieces finally all came together when Tolkien wrote \"The Mirror of Galadriel\", some hundreds of pages later, around the autumn of 1941.\n\"Lacnunga\".\nThe number of the Nazg\u00fbl, nine, may be derived from medieval folklore. Edward Pettit, in \"Mallorn\", states that nine is \"the commonest 'mystic' number in Germanic lore\". He quotes the \"Nine Herbs Charm\" from the \"Lacnunga\", an Old English book of spells:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;&lt;poem&gt;\nagainst venom and vile things\nand all the loathly ones,\nthat through the land rove, \nagainst nine fugitives from glory, \nagainst nine poisons and \nagainst nine flying diseases.&lt;/poem&gt;\nPettit further proposes that Tolkien may have made multiple uses of another \"Lacnunga\" charm, \"Against a sudden stabbing pain\", to derive multiple attributes of the Nazg\u00fbl. He states that Tolkien certainly knew the charm. In Henry Sweet's translation:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;&lt;poem&gt;\nThey were loud, lo, loud, when they rode over the hill,\nThey were resolute when they rode over the land.\nIf a piece of iron is in here.\nThe work of a witch, heat shall melt it!\nIf it were shot of gods, or if it were shot of elves,\nOr if it were shot of witch, now I will help you.\n&lt;/poem&gt;\nPettit writes that Tolkien may have used the \"loud\" riders to come up with the \"thundering hooves\" and \"piercing cry\" of the Nine Riders. The supernatural beings mentioned in the charm \u2013 gods, elves, witches \u2013 may naturally have suggested the Nazg\u00fbl's magical power; in particular, the \"work of a witch\" may have resulted in the Witch-King of Angmar. Finally, the Morgul-knife that breaks off in the victim's body, and which Elrond has to destroy by melting, matches the \"piece of iron ... in here... heat shall melt it!\"\nEtymological connotations.\nTolkien was a philologist. Jason Fisher, writing that \"all stories begin with words\", takes up Edmund Wilson's \"denigrating dismissal\" of \"The Lord of the Rings\" as \"a philological curiosity\", replying that to him this is \"precisely one of its greatest strengths\". Fisher explores in detail the connotations of Tolkien's use of \"Ringwraith\" and its Black Speech translation \"Nazg\u00fbl\", both in languages that Tolkien knew and those that he invented. \"Wraith\" in modern English means 'spectre'. Fisher notes that the word has a history in folktale and fantasy including usage by the Brothers Grimm, William Morris, and George MacDonald. The word \"wraith\" can be connected, Fisher writes, to English \"writhe\", Old English \"wr\u012b\u00fean\", to bend or twist, and in turn to Gothic \"wraiqs\", curved, crooked, or winding, and \"wraks\", a persecutor. There is also English \"wreath\", from Old English \"wrida\", meaning a band, a thing wound around something, and indeed a ring. Another cognate is Old Saxon \"wred\", meaning cruel; Fisher comments that all of these stem from Indo-European \"*wreit\", to turn, bend, or wind.\n\"Nazg\u00fbl\" has the Black Speech roots \"nazg\", ring, and \"g\u00fbl\", wraith. Fisher writes that the former may well be connected, unconsciously on Tolkien's part, to Gaelic \"nasc\", a ring. \"G\u00fbl\" has the meaning \"magic\" in Tolkien's invented language of Sindarin. Fisher comments that this has an English homophone in \"ghoul\", a wraith, which derives from Arabic \u063a\u064f\u0648\u0644\u200e \"\u1e21\u016bl\", a demon that feeds on corpses. The Sindarin word is related to \"\u00f1gol\", wise, wisdom, and to Noldor, F\u00ebanor's elves who became in Fisher's words \"bent and twisted\" by the desire for the Silmarils.\nThe only one of the nine Ringwraiths to be named is Kham\u00fbl. Fisher suggests a link to Welsh \"kam\", crooked, and \"kamy\", to bend. \"Kam\" made its way into English usage, including by Shakespeare, as is recorded in Samuel Johnson's 1755 \"A Dictionary of the English Language\". Fisher writes that this may have come to Tolkien by way of his time with the Lancashire Fusiliers in the First World War, with Lancashire dialect words like \"caimt\", crooked or bad-tempered. In short, Tolkien may have felt many philological associations between his \"Nazg\u00fbl\" and \"Ringwraith\" with the meanings of being bent and twisted as well as ghoulish.\nAnalysis.\nLiterary modes.\nShippey writes that the Nazg\u00fbl function at different stylistic levels or modes (as categorised by Northrop Frye in his \"Anatomy of Criticism\") in the story. At one level, they serve simply as story elements, dangerous opponents. But, Shippey notes, the level rises from the romantic, with heroes taking on the Black Riders, to the mythic, giving as example the assault of Minas Tirith. The leader of the Nazg\u00fbl directs the attack on the Great Gate; he bursts the gate using both the battering-ram Grond, written with \"spells of ruin\", and with \"words of power and terror to rend both heart and stone\".\nInvisible, but corporeal.\nDespite his shadowiness and invisibility, Shippey writes, the Nazg\u00fbl on the Pelennor Fields also comes as close as he ever does to seeming human, having human form inside his black robes, carrying a sword, and laughing to reveal his power when he throws back his hood, revealing a king's crown on his invisible head.\nYvette Kisor, a scholar of literature, writes that while the Ringwraiths and others (like Frodo) who wear Rings of Power become invisible, they do not lose any of their corporeality, being present as physical bodies. They require, she writes, physical steeds to carry them about, and they can wield swords. She notes that only a person in a body can wield the One Ring, so the invisibility is just \"a trick of sight\". When Frodo, wearing the Ring, saw the Nazg\u00fbl in the \"twilight world\", they appeared solid, not shadowy. He also saw Glorfindel in that world, as a figure of white flame; and Gandalf explains later that the Ringwraiths were \"dismayed\" to see \"an Elf-lord revealed in his wrath\". Frodo is in danger of \"fading\" permanently into invisibility and the twilight world, as the Ringwraiths have done, living \"in another mode of reality\". She writes, too, that Merry's sword, with the special power to sever the Witch-king's \"undead flesh\" and in particular to overcome the \"spell that knit his unseen sinews to his will\", has in fact to cut through real, but invisible, sinews and flesh.\nGradual incarnation.\nSteve Walker, a Tolkien scholar, writes that the story gives the Ringwraiths credibility through a \"gradual incarnation of bodiless presence\". Little by little, in his view, Tolkien increases the reader's insight into their nature, starting with Black Riders who are \"spies more human than diabolical\", rather than developing their character. Walker sees this as appropriate: the Nazg\u00fbl's main weapons are psychological, namely fear and despair. He writes that the progressive revelation of their capabilities, and their \"escalation of steeds\" from horses to fell beasts, builds up in the reader's mind an \"increasingly infernal vision\".\nThe Black Breath.\nThe Nazg\u00fbl spread terror and despair among their enemies, and discomfit those on their own side. The Black Breath is stated to have afflicted many during the Battle of the Pelennor Fields. Dr Jennifer Urquart, writing in \"Mallorn\", describes its normal course as \"progressive loss of consciousness and hypothermia, leading to death\". She comments that the Black Breath, contracted by \"excessive proximity\" to a Nazg\u00fbl, seems to be a \"spiritual malady\" combined with \"fear, confusion, reduced levels of consciousness, hypothermia, weakness and death.\" Faramir, on the other hand, who was thought to be suffering from the Black Breath, she diagnoses as most likely exhaustion with heat stroke, combined with \"psychological distress\" and pain, as his symptoms were quite different. Judy Ann Ford and Robin Anne Reid note that Aragorn's use of the herb \"athelas\" to heal Faramir and others of the Black Breath, a condition \"which harms the spirit more than the body\", identifies him to his people as the true King.\nMichael and Victoria Wodzak discuss how the hobbit Merry Brandybuck can be affected by the Black Breath when the Witch-King has not noticed him, pointing out that Tolkien nowhere says that the Nazg\u00fbl breathes on him or on \u00c9owyn. Instead \u00c9owyn \"raised her shield against the horror of her enemy's eye\", and the Wodzaks comment that the Nazg\u00fbl uses his eyes \"to overwhelm\". In their view, the seeming inconsistency is resolved by identifying the Black Breath with his \"pneuma\", his evil spirit, and assuming that it is this which causes the harm all around him.\nTolkien's biographer John Garth finds Christopher Gilson's \"Words, Phrases and Passages in Various Tongues in \"The Lord of the Rings\"\" especially interesting for its rendering of two of the Dark Lord Sauron's epithets, \"Th\u00fb\" meaning \"horrible darkness, black mist\" and \"Gorthu\" meaning \"mist of fear\". Garth comments that these names \"anchor him in the primal night\" of Tolkien's giant spiders, the Black Breath, the fog on the Barrow-downs, and the terror of the Paths of the Dead. He adds that this fog of terror may ultimately derive from Tolkien's First World War experience \"of smoke barrages, gas attacks and 'animal horror' on the Somme.\" Earlier, in his 2003 book \"Tolkien and the Great War\", on the other hand, Garth merely notes the \"Black Breath of despair that brings down even the bravest\" as one of several elements of \"The Lord of the Rings\" which \"suggest[s] the influence of 1914\u201318\".\nIn her Tolkienesque 1961 short story \"The Jewel of Arwen\", the fantasy and science fiction writer Marion Zimmer Bradley provides \"Translator's Notes\" which assert as part of her frame story that the Nazg\u00fbl were contaminated and enslaved by a monstrous form of radioactivity which transformed \"the very cells of their protoplasm\". They thereby became radioactive and \"immune to radiation poisoning, as is shown by their dwelling in the blasted tower of Minas Ithil [which glowed in the dark].\" Further, Bradley writes, the Nazg\u00fbl gave off \"radioactive contamination\", causing the Black Breath.\nOpposed to the Nine Walkers.\nThe Inklings scholar Ariel Little writes that Tolkien explicitly opposes the enslaved Nine Riders with the Nine Walkers, the free Company of the Ring. In \"The Council of Elrond\", Elrond announces that \"The Company of the Ring shall be Nine; and the Nine Walkers shall be set against the Nine Riders that are evil\". Little describes the Nazg\u00fbl as \"homogeneous, discordant, intensely individualistic\", a group bound and trapped by Sauron, noting also Gandalf's description of them in \"The Shadow of the Past\" as \"Mortal Men, proud and great [who] fell under the dominion of the One, and they became Ringwraiths, shadows under his great Shadow, his most terrible servants\". They had thus, Little writes, lost their identities as humans, even losing their substance and becoming what Tolkien calls \"nothingness\" under their black clothing. He adds that the evil characters in \"The Lord of the Rings\" are characterised by infighting, as among the Orcs, lack of harmony, and \"hate-filled discord\", forming an \"anti-community\".\nLittle contrasts this disharmony with the Company of the Ring, which is \"diverse, bound by friendship, relying on each other's strengths\". The Company is joined by its common purpose, and by \"devoted love\". There are strong bonds of friendship, seen initially between all the Hobbits. Further friendships develop throughout the Company as they travel together; Little notes that Frodo says that \"Strider\" (Aragorn), viewed initially with suspicion, is \"dear to me\". He comments that \"the deep affection of the Fellowship breaks down racial and cultural barriers\" as all its members drop their initial reserve and come to an \"appreciation for the cultural distinctiveness\" of their companions. A case in point is the strong friendship between the Dwarf Gimli and the Elf Legolas, members of two races with radically dissimilar cultures, and which had often clashed in the past; Little notes that even the other members of the Company, in Tolkien's words, \"wonder ... at this change\". He writes that even when the Company splits up into smaller groups, it is not destroyed: far from it, Frodo and Sam sustain each other through their arduous journey, their friendship deepening with time; Merry and Pippin supporting each other; Aragorn, Legolas, and Gimli acting as a team, all continuing to function as communities. Little adds that the Company functions as a true team, every member being essential to the success of its mission. The Christian commentator Ralph C. Wood writes that \"the greatness of the Nine Walkers lies in the modesty of both their abilities and accomplishments. Their strength lies in their weakness, in their solidarity as a company unwilling to wield controlling power over others.\" Rebecca Munro notes that in the Company, \"no one acts alone without dependence on the deeds of others\".\nAdaptations.\nFilms.\nThe Nazg\u00fbl are featured in adaptations of \"The Lord of the Rings\" on radio, film, and stage. In Ralph Bakshi's 1978 animated film version of \"The Lord of the Rings\", the Nazg\u00fbl \"shamble and limp like zombies\". They hack and slash the Hobbits' beds at \"The Prancing Pony\" inn, whereas Tolkien does not identify the assailants.\nIn the Rankin-Bass adaptation of \"The Return of the King\", the Nazg\u00fbl are robed skeletons with white hair. They ride winged horses, although the Witch-king rides a creature more in line with the book when he confronts \u00c9owyn. The 1981 BBC Radio serial of \"The Lord of the Rings\" has the Nazg\u00fbl chant the Ring-inscription in the Black Speech of Mordor. The 1991 Russian television play \"Khraniteli\" features a group of Nazg\u00fbl galloping through a snowy pine forest; they wear black cloaks, with glimpses of red equipment.\nIn \"The Lord of the Rings\" film trilogy (2001\u20132003) by Peter Jackson, the Nazg\u00fbl are almost always concealed by cloaks; they attack the inn at Bree themselves. During the siege of Minas Tirith, the Witch-king wears a distinctive helmet over his hood resembling a mask and a crown, rather than the crown worn underneath his hood in the book. Their shrieks are distorted recordings of producer and screenwriter Fran Walsh's scream.\nMinas Morgul is shown first in \"The Fellowship of the Ring\", when the Nazg\u00fbl leave the city and ride towards the Shire to pursue the One Ring. It features again when Frodo and Sam make their way towards Cirith Ungol. These sets were designed by the illustrator John Howe. All nine Nazg\u00fbl are shown riding winged monsters. Jackson's monsters explicitly differ from Tolkien's description in that they have teeth instead of beaks. The Nazg\u00fbl use them in battle more extensively than in the book. In the film the Witch-king's mount is largely responsible for the death of Th\u00e9oden and his horse Snowmane, a departure from the book. As confirmed in the films' audio commentary, the design of the monsters was based largely on illustrations by John Howe.\nThe fan-made 2009 film \"The Hunt for Gollum\" features Aragorn fighting a Ringwraith on the borders of Mirkwood.\nIn Jackson's 2012\u20132014 \"The Hobbit\" film trilogy, the men who became the Nazg\u00fbl are said to have been buried and sealed within the invented High Fells of Rhudaur. In the first film, Radagast briefly encounters the Witch-king while investigating Dol Guldur, and gives the Nazg\u00fbl's Morgul dagger to Gandalf to present at the White Council as proof of their return. In the second film, at Galadriel's behest, Gandalf heads to the High Fells and finds that all the Nazg\u00fbl have left the tomb. This confirms the Necromancer's identity as Sauron, as the Nazg\u00fbl appear alongside their master in the third film in spectral forms wearing Morgul armour and fight Elrond and Saruman before being driven away by Galadriel.\nGames.\nThe Nazg\u00fbl are featured in the video game ' and its sequel '. In the latter, Isildur is revealed to be one of the Nazg\u00fbl before he is killed by the game's protagonist, Talion. Talion takes Isildur's ring to prolong his life and eventually becomes Isildur's replacement until the demise of the Nazg\u00fbl in the \"Return of the King\".\nFor the expansion to its real-time strategy game ', ', Electronic Arts invented the name \"Morgomir\" for one of the Nazg\u00fbl.\nInfluence.\nThe fantasy novelist George R. R. Martin's 1983 \"The Armageddon Rag\" tells the tale of a rock promoter who had managed a band named the Nazg\u00fbl, and was found ritually murdered on the 10th anniversary of the band's breakup.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nPrimary.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSecondary.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58645", "revid": "24902", "url": "https://en.wikipedia.org/wiki?curid=58645", "title": "Hudson Strait", "text": "Strait connecting the Atlantic Ocean to Hudson Bay in Canada\nThe Hudson Strait () in Nunavut links the Atlantic Ocean and the Labrador Sea to Hudson Bay in Canada. This strait lies between Baffin Island and Nunavik, with its eastern entrance marked by Cape Chidley in Newfoundland and Labrador and Nunavut and Resolution Island, off Baffin Island. The strait is about long with an average width of , varying from at the eastern entrance to at Deception Bay.\nEnglish navigator Sir Martin Frobisher was the first European to report entering the strait, in 1578. He named a tidal rip at the entrance the Furious Overfall and called the strait \"Mistaken Strait\", since he felt it held less promise as an entrance to the Northwest Passage than the body of water that was later named Frobisher Bay. Later in his 1587 voyage, explorer John Davis sailed by the entrance to the strait. The first European to explore the strait was George Weymouth who sailed beyond the Furious Overfall in 1602.\nThe strait was named after Henry Hudson who explored it in 1610 in the ship \"Discovery\", the same ship previously used by George Weymouth in 1602. Hudson was followed by Thomas Button in 1612, and a more detailed mapping expedition led by Robert Bylot and William Baffin in 1616.\nThe Hudson Strait links the northern seaports of Manitoba and Ontario with the Atlantic Ocean. The Strait could serve as an eastern entrance to the Northwest Passage if it were not for ice in the Fury and Hecla Strait south of western Baffin Island.\nExtent.\nThe International Hydrographic Organization defines the limits of the Hudson Strait as follows:\n\"On the West.\" A line from Nuvuk Point () to Leyson Point, thence by the Eastern shore of Southampton Island to Seahorse Point, its Eastern extreme, thence a line to Lloyd Point () Baffin Island.\n\"On the North.\" The South coast of Baffin Island between Lloyd Point and East Bluff.\n\"On the East.\" A line from East Bluff, the Southeast extreme of Baffin Island (), to Point Meridian, the Western extreme of Lower Savage Islands, along the coast to its Southwestern extreme and thence a line across to the Western extreme of Resolution Island, through its Southwestern shore to Hatton Headland, its Southern point, thence a line to Cape Chidley, Labrador ().\n\"On the South.\" The mainland between Cape Chidley and Nuvuk Point.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "58646", "revid": "6727347", "url": "https://en.wikipedia.org/wiki?curid=58646", "title": "Strait", "text": "Waterway that connects two larger bodies of water\nA strait is a water body connecting two seas or water basins. The surface water is, for the most part, at the same elevation on both sides and can flow through the strait in either direction, although the topography generally constricts the flow somewhat. In some straits, there is a dominant directional current. Most commonly, the strait is a narrow channel that lies between two land masses. Straits are loci for sediment accumulation, with sand-sized deposits usually occurring on the two strait exits, forming subaqueous fans or deltas. Some straits are not navigable because, for example, they are too narrow or too shallow, or due to the presence of a reef or archipelago.\nTerminology.\nThe terms \"channel\", \"pass\", or \"passage\" can be synonymous and used interchangeably with \"strait\", although each is sometimes differentiated with varying senses. In Scotland, \"firth\" or \"Kyle\" are also sometimes used as synonyms for strait.\nMany straits are economically important. Straits can be important shipping routes and wars have been fought for control of them.\nNumerous artificial channels, called \"canals\", have been constructed to connect two oceans or seas over land, such as the Suez Canal. Although rivers and canals often provide passage between two large lakes, and these seem to suit the formal definition of strait, they are not usually referred to as such. Rivers and often canals, generally have a directional flow tied to changes in elevation, whereas straits often are free flowing in either direction or switch direction, maintaining the same elevation. The term \"strait\" is typically reserved for much larger, wider features of the marine environment. There are exceptions, with straits being called canals; Pearse Canal, for example.\nComparisons.\nStraits are the converse of isthmuses. That is, while a strait lies between two land masses and connects two large areas of ocean, an isthmus lies between two areas of ocean and connects two large land masses.\nSome straits have the potential to generate significant tidal power using tidal stream turbines. Tides are more predictable than wave power or wind power. The Pentland Firth (a strait) may be capable of generating 10\u00a0GW. Cook Strait in New Zealand may be capable of generating 5.6\u00a0GW even though the total energy available in the flow is 15\u00a0GW.\nNavigational (legal) regime.\nStraits used for international navigation through the territorial sea between one part of the high seas or an exclusive economic zone and another part of the high seas or an exclusive economic zone are subject to the legal regime of transit passage (Strait of Gibraltar, Strait of Dover, Strait of Hormuz). The regime of innocent passage applies in straits used for international navigation (1) that connect a part of high seas or an exclusive economic zone with the territorial sea of a coastal nation (Straits of Tiran, Strait of Juan de Fuca, Strait of Baltiysk) and (2) in straits formed by an island of a state bordering the strait and its mainland if there exists seaward of the island a route through the high seas or through an exclusive economic zone of similar convenience with respect to navigational and hydrographical characteristics (Strait of Messina, Pentland Firth). There may be no suspension of innocent passage through such straits.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "58647", "revid": "1311244862", "url": "https://en.wikipedia.org/wiki?curid=58647", "title": "Labrador", "text": "Mainland portion of Newfoundland and Labrador\nLabrador () is a geographic and cultural region within the Canadian province of Newfoundland and Labrador. It is the primarily continental portion of the province and constitutes 71% of the province's area but is home to only 6% of its population. It is separated from the island of Newfoundland by the Strait of Belle Isle. It is the largest and northernmost geographical region in the four Atlantic provinces.\nLabrador occupies most of the eastern part of the Labrador Peninsula. It is bordered to the west and south by the province of Quebec. Labrador also shares a small land border with the territory of Nunavut on Killiniq Island.\nThe indigenous peoples of Labrador include the Northern Inuit of Nunatsiavut, the Southern-Inuit of NunatuKavut, and the Innu of Nitassinan.\nEtymology.\nLabrador is named after Jo\u00e3o Fernandes Lavrador, a Portuguese explorer who sailed along the coasts of the Labrador Peninsula in 1498\u201399.\nLabrador's name in the Inuttitut/Inuktitut language (spoken in Nunatsiavut) is (), meaning \"the big land\" (a common English nickname for Labrador).\nGeography.\nLabrador has a roughly triangular shape that encompasses the easternmost section of the Canadian Shield, a sweeping geographical region of thin soil and abundant mineral resources. Its western border with Quebec is the drainage divide of the Labrador Peninsula. Lands that drain into the Atlantic Ocean are part of Labrador, while lands that drain into Hudson Bay are part of Quebec. Labrador's extreme northern tip, at 60\u00b022\u2032N, shares a short border with Nunavut on Killiniq Island. Labrador also has a maritime border with Greenland. Northern Labrador's climate is classified as polar, while Southern Labrador's climate is classified as subarctic.\nLabrador can be divided into four geographical regions: the North Coast, Central Labrador, Western Labrador, and the South Coast. Each of those regions is described below.\nNorth Coast.\nFrom Cape Chidley to Hamilton Inlet, the long, thin, northern tip of Labrador holds the Torngat Mountains, named after an Inuit spirit believed to inhabit them. The mountains stretch along the coast from Port Manvers to Cape Chidley, the northernmost point of Labrador. The Torngat Mountain range is also home to Mount Caubvick, the highest point in the province. This area is predominantly Inuit, with the exception of a small Innu community, Natuashish. The North Coast is the most isolated region of Labrador, with snowmobiles, boats, and planes being the only modern modes of transportation. The largest community in this region is Nain.\nNunatsiavut.\nNunatsiavut is an Inuit self-government region in Labrador created on June 23, 2005. The settlement area comprises the majority of Labrador's North Coast, while the land-use area also includes land farther to the interior and in Central Labrador. Nain is the administrative centre.\nCentral Labrador.\nCentral Labrador extends from the shores of Lake Melville into the interior. It contains the Churchill River, the largest river in Labrador and one of the largest in Canada. The hydroelectric dam at Churchill Falls is the second-largest underground power station in the world. Most of the supply is bought by Hydro-Qu\u00e9bec under a long-term contract. The Lower Churchill Project will develop the remaining potential of the river and supply it to provincial consumers. Known as \"the heart of the Big Land\", the area's population comprises people from all groups and regions of Labrador.\nCentral Labrador is also home to Happy Valley-Goose Bay. Once a refuelling point for plane convoys to Europe during World War II, CFB Goose Bay is now operated as a NATO tactical flight training site. It was an alternate landing zone for the United States' Space Shuttle. Other major communities in the area are North West River and the large Innu reserve known as Sheshatshiu.\nWestern Labrador.\nThe highlands above the Churchill Falls were once an ancient hunting ground for the Innu First Nations and settled trappers of Labrador. After the construction of the hydroelectric dam at Churchill Falls in 1970, the Smallwood Reservoir has flooded much of the old hunting land\u2014submerging several grave sites and trapping cabins in the process.\nWestern Labrador is also home to the Iron Ore Company of Canada, which operates a large iron ore mine in Labrador City. Together with the small community of Wabush, the two towns are known as \"Labrador West\".\nSouth Coast.\nNunatuKavut.\nFrom Hamilton Inlet to Cape St. Charles/St. Lewis, NunatuKavut is the territory of the NunatuKavummiut or Central-Southern Labrador Inuit (formerly known as the Labrador M\u00e9tis). It includes portions of Central and Western Labrador, but more NunatuKavummiut reside in its South Coast portion: it is peppered with tiny Inuit fishing communities, of which Cartwright is the largest.\nLabrador Straits.\nFrom Cape Charles to the Quebec\u2013Labrador coastal border, the Straits are known for their Labrador seagrass (as is NunatuKavut) and the multitude of icebergs that pass by the coast via the Labrador Current.\nRed Bay is known as one of the best examples of a preserved 16th-century Basque whaling station. It is also the location of four 16th-century Spanish galleons. The lighthouse at Point Amour is the second-largest lighthouse in Canada. , a passenger ferry between the mainland and St. Barbe on the island of Newfoundland, is based in Blanc Sablon, Quebec, near the Labrador border. L'Anse-au-Loup is the largest town on the Labrador Straits. L'Anse-au-Clair is a small town on the Labrador side of the border.\nTime zones of Labrador.\nMost of Labrador (from Cartwright north and west) uses Atlantic Time (UTC\u22124 in winter, UTC\u22123 in summer). The southeastern tip nearest Newfoundland uses Newfoundland Time (UTC\u22123:30 in winter, UTC\u22122:30 in summer) to stay co-ordinated with the more populous part of the province.\nClimate of Labrador.\nMost of Labrador has a subarctic climate (Dfc), but northern Labrador has a tundra climate (ET) and Happy Valley - Goose Bay has a humid continental (Dfb) microclimate. Summers are typically cool to mild across Labrador and very rainy, and usually last from late June to the end of August. Autumn is generally short, lasting only a couple of weeks and is typically cool and cloudy. Winters are long, cold, and extremely snowy, due to the Icelandic Low. Springtime most years does not arrive until late April, with the last snow fall usually falling during early June. Labrador is a very cloudy place, with sunshine levels staying relatively low during spring and summer due to the amount of rain and clouds, before sharply dropping off during September as winter draws nearer.\nNatural features.\nLabrador is home to a number of flora and fauna species. Most of the Upper Canadian and Lower Hudsonian mammalian species are found in Labrador. Notably the polar bear () reaches the southeast of Labrador on its seasonal movements.\nHistory.\nEarly history.\nEarly settlement in Labrador was tied to the sea as demonstrated by the Innu (formerly called Montagnais) and Inuit, although these peoples also made significant forays throughout the interior.\nIt is believed that the Norsemen were the first Europeans to sight Labrador around 1000 AD. The area was known as \"Markland\" in Greenlandic Norse and its inhabitants were known as the \"Skr\u00e6lings\".In 1499 and 1500, the Portuguese explorers Jo\u00e3o Fernandes Lavrador and Pero de Barcelos reached what was probably now Labrador, which is believed to be the origin of its name. Maggiolo's World Map, 1511, shows a solid Eurasian continent running from Scandinavia around the North Pole, including Asia's arctic coast, to Newfoundland-Labrador and Greenland. On the extreme northeast promontory of North America, Maggiolo place names include \"Terra de los Ingres\" (Land of the English), and \"Terra de Lavorador de rey de portugall\" (Land of Lavrador of the King of Portugal). Farther south are the phrases \"Terra de corte real e de rey de portugall\" (Land of the Royal Court and of the King of Portugal) and \"Terra de pescaria\" (Land for Fishing). In the 1532 Wolfenb\u00fcttel map, believed to be the work of Diogo Ribeiro, along the coast of Greenland, the following legend was added: \"As he who first sighted it was a farmer from the Azores Islands, this name remains attached to that country.\" This is believed to be Jo\u00e3o Fernandes. For the first seven decades or so of the sixteenth century, the name Labrador was sometimes also applied to what is now known as Greenland. Labrador (\"lavrador\" in Portuguese) means husbandman or farmer of a tract of land (from \"labor\" in Latin) \u2013 the land of the labourer. European settlement was largely concentrated in coastal communities, particularly those south of St. Lewis and Cape Charles, and are among Canada's oldest European settlements.\nIn 1542, Basque mariners came ashore at a natural harbour on the northeast coast of the Strait of Belle Isle. They gave this \"new land\" its Latin name \"Terranova\". A whaling station was set up around the bay, which they called \"Butus\" and is now named Red Bay after the red terracotta roof tiles they brought with them. A whaling ship, the \"San Juan\", sank there in 1565 and was raised in 1978.\nThe Moravian Brethren of Herrnhut, Saxony, first came to the Labrador Coast in 1760 to minister to the migratory Inuit tribes there. They founded Nain, Okak, Hebron, Hopedale and Makkovik. Quite poor, both European and First Nations settlements along coastal Labrador came to benefit from cargo and relief vessels that were operated as part of the Grenfell Mission (see Wilfred Grenfell). Throughout the 20th century, coastal freighters and ferries operated initially by the Newfoundland Railway and later Canadian National Railway/CN Marine/Marine Atlantic became a critical lifeline for communities on the coast, which for the majority of that century did not have any road connection with the rest of North America.\nLabrador was part of New France until the Seven Years' War. By the Treaty of Paris (1763), which ended the war, New France (including Labrador, though excluding the islands of Saint Pierre and Miquelon southwest of Newfoundland) was transferred to the British, who administered the northern portion of it as the Province of Quebec until splitting it in two in 1791, with Labrador located in Lower Canada. However, in 1809, the British Imperial government detached Labrador from Lower Canada for transfer to the separate, self-governing Newfoundland Colony.\n20th century.\nAs part of Newfoundland since 1809, Labrador was still being disputed by Quebec until the British Privy Council resolved their border in 1927. In 1949, Newfoundland entered into confederation, becoming part of Canada (see above articles for full information).\nLabrador played strategic roles during both World War II and the Cold War. In October 1943, a German U-boat crew installed an automated weather station on the northern tip of Labrador near Cape Chidley, code-named Weather Station Kurt; the installation of the equipment was the only-known armed German military operation on the North American mainland during the war. The station broadcast weather observations to the German navy for only a few days, but was not discovered until 1977 when a historian, working with the Canadian Coast Guard, identified its location and mounted an expedition to recover it. The station is now exhibited in the Canadian War Museum.\nThe Canadian government built a major air force base at Goose Bay, at the head of Lake Melville during the Second World War, a site selected because of its topography, access to the sea, defensible location, and minimal fog. During the Second World War and the Cold War, the base was also home to American, British, and later German, Dutch, and Italian detachments. Today, Serco, the company contracted to operate CFB Goose Bay is one of the largest employers for the community of Happy Valley-Goose Bay.\nAdditionally, both the Royal Canadian Air Force and United States Air Force built and operated a number of radar stations along coastal Labrador as part of the Pinetree Line, Mid-Canada Line and DEW Line systems. Today, the remaining stations are automated as part of the North Warning System; however, the military settlements during the early part of the Cold War surrounding these stations have largely continued as local Innu and Inuit populations have clustered near their port and airfield facilities.\nDuring the first half of the 20th century, some of the largest iron ore deposits in the world were discovered in the western part of Labrador and adjacent areas of Quebec. Deposits at Mont Wright, Schefferville, Labrador City, and Wabush drove industrial development and human settlement in the area during the second half of the 20th century.\nThe present community of Labrador West is entirely a result of the iron ore mining activities in the region. The Iron Ore Company of Canada operates the Quebec North Shore and Labrador Railway to transport ore concentrate south to the port of Sept-\u00celes, Quebec, for shipment to steel mills in North America and elsewhere.\nDuring the 1960s, the Churchill River (Labrador name: Grand River) was diverted at Churchill Falls, resulting in the flooding of an enormous area \u2013 today named the Smallwood Reservoir after Joey Smallwood, the first premier of Newfoundland. The flooding of the reservoir destroyed large areas of habitat for the threatened Woodland Caribou. A hydroelectric generating station was built in Labrador as well as a transmission line to the neighbouring province of Quebec.\nConstruction of a large hydroelectric dam project at Muskrat Falls began in 2012 by Nalcor Energy and the Province of Newfoundland. Muskrat Falls is 45\u00a0km (30 miles) west of Happy Valley-Goose Bay on the Grand River (Newfoundland name: Churchill River). A transmission line began construction in October 2014 and was completed in 2016 that delivers power down to the southern tip of Labrador and underwater across the Strait of Belle Isle to the Province of Newfoundland in 2018.\nFrom the 1970s to early 2000s, the Trans-Labrador Highway was built in stages to connect various inland communities with the North American highway network at Mont Wright, Quebec (which in turn is connected by a highway running north from Baie-Comeau, Quebec). A southern extension of this highway has opened in stages during the early 2000s and is resulting in significant changes to the coastal ferry system in the Strait of Belle Isle and southeastern Labrador. These \"highways\" are so called only because of their importance to the region; they would be better described as roads, and were not completely paved until July 2022.\nA study on a fixed link to Newfoundland, in 2004, recommended that a tunnel under the Strait of Belle Isle, being a single railway that would carry cars, buses and trucks, was technologically the best option for such a link. However, the study also concluded that a fixed link was not economically viable. Conceivably, if built with federal aid, the 1949 terms of union would be amended to remove ferry service from Nova Scotia to Port aux Basques across the Cabot Strait.\nAlthough a highway link has, as of December 2009, been completed across Labrador, this route is somewhat longer than a proposed Quebec North Shore highway that presently does not exist. Part of the \"highway\", Route 389, starting approximately from Baie-Comeau to , is of an inferior alignment, and from there to , the provincial border, is an accident-prone section notorious for its poor surface and sharp curves. Quebec in April 2009 announced major upgrades to Route 389 to be carried out.\nRoute 389 and the Trans-Labrador Highway were added to Canada's National Highway System in September 2005.\nLabrador constitutes a federal electoral district electing one member to the House of Commons of Canada. Due to its size, distinct nature, and large Aboriginal population, Labrador has one seat despite having the smallest population of any electoral district in Canada. Formerly, Labrador was part of a riding that included part of the Island of Newfoundland. Labrador is divided into four provincial electoral districts in the Newfoundland and Labrador House of Assembly.\nBoundary dispute.\nIn 1809, Labrador was transferred from Lower Canada to the Newfoundland Colony, but the inland boundary of Labrador had never been precisely stated. Newfoundland argued it extended to the height of land, while Canada, stressing the historical use of the term \"Coasts of Labrador\", argued the boundary was inland from the high-tide mark. As Canada and Newfoundland were separate Dominions, but both within the British Empire, the matter was referred to the Judicial Committee of the Privy Council (in London). Their decision set the Labrador boundary mostly along the coastal watershed, with part being defined by the 52nd parallel north. One of Newfoundland's conditions for joining Confederation in 1949 was that this boundary be entrenched in the Canadian constitution. While this border has not been formally accepted by the Quebec government, the Henri Dorion Commission () concluded in the early 1970s that Quebec no longer has a legal claim to Labrador.\nIn 2001, Parti Qu\u00e9b\u00e9cois cabinet ministers Jacques Brassard and Joseph Facal erroneously reasserted that Quebec has never recognized the 1927 border:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\n[The ministers reiterate that no Quebec government has ever formally recognised the drawing of the border between Quebec and Newfoundland in the Labrador peninsula according to the opinion rendered by the London Judicial Committee of the Privy Council in 1927. For Quebec, this border has thus never been definitively defined.]\nIn 2023, Jordan Brown, a Newfoundland and Labrador politician, criticized the Bloc Qu\u00e9b\u00e9cois for exhibiting a map of Quebec on which the whole of Labrador was depicted as part of Quebec.\nSelf-government.\nA Royal Commission in 2002 determined that there is some public pressure from Labradorians to break from Newfoundland and become a separate province or territory.\nIndigenous self-government.\nAfter decades of negotiation with the provincial and federal governments, the Nunatsiavut region of northern and northeastern Labrador was created in 2005 as an autonomous region with its own elected Assembly and executive drawn from members of the region's Assembly. Some of the Innu nation would have the entirety of Labrador become a homeland for them, much as Nunavut and Nunatsiavut is for the Inuit, as a good portion of Nitassinan falls within Labrador's borders; a 1999 resolution of the Assembly of First Nations claimed Labrador as a homeland for the Innu and demanded recognition in any further constitutional negotiations regarding the region.\nLabrador's Innu became status Indians under the \"Indian Act\" in 2002. Natuashish became a federal Indian reserve in 2003. Sheshatshiu became a federal reserve in 2006.\nThe Labrador Inuit Association had filed a land claim for portions of Labradorian land in 1977. In 1988, the Labrador Inuit Association, the government of the province of Newfoundland, and the government of Canada began negotiations based on the land claim. An agreement-in-principle was achieved in 2001, and on May 26, 2004, the agreement was ratified by over 75% of eligible voters subject to the land claim. On January 22, 2005, the Inuit of Nunatsiavut signed the Labrador Inuit Lands Claims Agreement with the federal and provincial governments covering of land, including the entire northern salient of Labrador north of Nain as well as a portion of the Atlantic coast south of there. The agreement also includes of sea rights. Although the Inuit will not own the whole area, they were granted special rights related to traditional land use, and they will own designated Labrador Inuit Lands. The agreement also establishes the Torngat Mountains National Park in the northern area of the land claim. The agreement was ratified by the Labrador Inuit, the General Assembly of Newfoundland and Labrador, and the Parliament of Canada, where it received Royal Assent on June 23, 2005, whereafter elections would be held for the Nunatsiavut Assembly and self-government would begin.\nIn the late 1970s, the Labrador Metis Association was created by the inhabitants of Labrador's southern coast to gain recognition as a distinct ethnocultural group, as at the time despite a pre-existing treaty protected under the constitution, the \"Inuit-Metis\" were considered to be merely the descendants of Inuit who had joined Western society. Little was known about the history of the \"Inuit-Metis\" of the time. In 2006, the Labrador Metis Association initiated a project with Memorial University of Newfoundland to better understand their past through the Community-University Research Association (CURA). Following research by CURA, the \"Labrador Metis\" were understood to be a continuation of the Inuit of southern Labrador. In 2010, the Labrador Metis Association changed its name to reflect their newly discovered heritage, and became the NunatuKavut Community Council. The Southern Inuit of NunatuKavut, who are also seeking self-government, have their land claim before the Government of Canada. The Government of Newfoundland and Labrador refuses to recognise or negotiate with the Inuit of NunatuKavut until their claim has been accepted by the Government of Canada.\nDemographics.\nThe Labrador region, with its 26,655 population, is lower than any of the Northern Canada territories, Yukon, Northwest Territories and Nunavut. Newfoundland Island contains the majority of the population of the province of Newfoundland and Labrador.\nCommunities.\nThe municipalities of Labrador are mainly under 1,000 in population.\nComposition.\nAccording to the 2011 Census, Labrador was 55.1% White, 18.5% Inuit and 8.6% First Nations (Innu).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58648", "revid": "5718152", "url": "https://en.wikipedia.org/wiki?curid=58648", "title": "Faraday constant", "text": "Physical constant: Electric charge of one mole of electrons\nIn physical chemistry, the Faraday constant (symbol \"F\", sometimes stylized as \u2131) is a physical constant defined as the quotient of the total electric charge (\"q\") by the amount (\"n\") of elementary charge carriers in any given sample of matter: it is expressed in units of coulombs per mole (C/mol). \nAs such, it represents the \"molar elementary charge\", that is, the electric charge of one mole of elementary carriers (e.g., protons). It is named after the English scientist Michael Faraday. Since the 2019 revision of the SI, the Faraday constant has an exactly defined value, the product of the elementary charge (\"e\", in coulombs) and the Avogadro constant (\"N\"A, in reciprocal moles):\n \"F\" = \"e\" \u00d7 \"N\"A = .\nDerivation.\nThe Faraday constant can be thought of as the proportionality factor between the charge in coulombs (used in physics and in practical electrical measurements) and the amount of substance in moles (used in chemistry), and is therefore of particular use in electrochemistry, particularly in electrolysis calculations. Because the elementary charge is exactly , and there are exactly \"N\"A\u00a0=\u00a0 entities per mole, the Faraday constant is given by the product of these two quantities:\n \"F\" = \"e\" \u00d7 \"N\"A\n \u2002 = .\nThe value of \"F\" was first determined in the 1800s by weighing the amount of silver deposited in an electrochemical reaction, in which a measured current was passed for a measured time, and using Faraday's law of electrolysis. Until about 1970, the most reliable value of the Faraday constant was determined by a related method of electro-dissolving silver metal in perchloric acid.\nFaraday \u2013 a unit of charge.\nRelated to the Faraday constant is the \"faraday\", a unit of electrical charge. Its use is much less common than of the coulomb, but is sometimes used in electrochemistry. One faraday of charge is the charge of one mole of elementary charges (or of negative one mole of electrons), that is,\n 1\u00a0faraday\u00a0=\u00a0\"F\"\u00a0\u00d7\u00a01\u00a0mol\u00a0=\u00a0 =\u00a0\"N\"0\u00a0\u00d7\u00a0\"e\"\u00a0=\u00a0.\nWhere \"N\"0 is Avogadro's number, the unitless counterpart to \"N\"A. Conversely, the Faraday constant \"F\" equals 1 faraday per mole. (The farad is an unrelated unit of capacitance, 1 farad = 1 coulomb / 1 volt).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58649", "revid": "26605309", "url": "https://en.wikipedia.org/wiki?curid=58649", "title": "GE 645", "text": "1960's Mainframe Computer\nThe GE 645 mainframe computer was a development of the GE 635 for use in the Multics project. This was the first computer that implemented a configurable hardware protected memory system. It was designed to satisfy the requirements of Project MAC to develop a platform that would host their proposed next generation time-sharing operating system (Multics) and to meet the requirements of a theorized computer utility. The system was the first truly symmetric multiprocessing machine to use virtual memory, and it was also among the first machines to implement what is now known as a translation lookaside buffer, the foundational patent for which was granted to John Couleur and Edward Glaser. \nGeneral Electric initially publicly announced the GE 645 at the Fall Joint Computer Conference in November 1965. At a subsequent press conference in December of that year it was announced that they would be working towards \"broad commercial availability\" of the system. However they would subsequently withdraw it from active marketing at the end of 1966. In total at least 6 sites ran GE 645 systems in the period from 1967 to 1975.\nSystem configuration.\nThe basic system configuration consisted of a combination of 4 basic modules these were:\nThe System Controller Modules (SCM) effectively acted as the heart of the system. These were passive devices which was connected to each active device (Processor, GIOC, EMU) and provided the following:\nCompared to the rest of the 600 series the 645 did not use the standard IOC's (input/output controllers) for I/O. Nor did it use the DATANET-30 front end processor for communications. Instead both sets of functionality was combined into one unit called a GIOC (Generalized I/O Controller) which provided dedicated channels for both Peripheral (Disc/Tape) and Terminal I/O. The GIOC acted as an Active Device and was directly connected to memory via dedicated links to each System Controller that was present in a specific configuration.\nThe Extended Memory Unit, though termed a drum, was in reality a large fixed-head hard disk with one head per track, this was a OEM product from Librascope. The EMU consisted of 4,096 tracks providing 4MW (megawords) of storage (equivalent to 16MB). Each track had a dedicated read/write head, these were organised into groups of 16 \"track sets\" which are used to read/write a sector. A sector is the default unit of data allocation in the EMU and is made up of 80 words, of which 64 words are data and the remaining 16 were used as a guard band. The average transfer rate between the EMU and memory was 470,000 words per second, all transfers were 72-bits (two words) wide, with it taking 6.7\u03bcs to transfer 4 words. The unit had a rotational speed of 1,725 rpm, which ensured an average latency of 17.4 milliseconds.\nArchitecture.\nProcessor Modes.\nThe GE-645 has two modes of Instruction Execution (Master and Slave) inherited from the GE-635, however it also adds another dimension by having two modes of memory addressing (Absolute and Appending). When the process is executing in Absolute Mode addressing is limited to 218 words of memory and any instructions are executed in Master mode. In comparison Append Mode calculates the address using \"Appending Words\" with an address space of 224 words and with instruction execution occurring in either Master or Slave modes. \nSlave Mode.\nBy default this is normal mode that the processor should be executing in at any point in time. Nearly all instructions will run in this mode aside from a small set of privileged instructions which cannot execute in this mode. Execution of such instructions will trigger an illegal procedure fault, also the ability to inhibit interrupts (bit 28 of instruction word) is forbidden. Format of instruction addresses is via the Appending Process.\nMaster Mode.\nIn this mode the processor can execute all instructions and is able to inhibit interrupts while doing so. Like in Slave mode the default form of address formation is via the Appending Process.\nAbsolute Mode.\nAll instructions can be executed in this mode and full access is given to any privileged features of the hardware. Interrupts can be inhibited and instruction fetching is limited to a 218 (18-bit) absolute address thus restricting the processor to only been able to access the lower 256 KW of physical core memory. The processor will switch to this mode in the event of a fault or interrupt and will remain in it until it executes transfer instruction whose operand address has been obtained via the appending process.\nAppending Mode.\nBy default this is normal mode of Memory addressing, both Master and Slave modes normally operate in this mode. Indirect words and operands are accessed via Appending Mechanism via the process of placing a 1 in bit 29 of the executed instruction. Effective addresses are thus either added to a base address, or the offset is linked to the base address. \nFunctional Units.\nThe 645 processor was divided into four major functional units these were:\nOne of the key differences from the GE 635 was the addition of \"appending unit\" (APU) which was used to implement a hybrid \"Paged Segmentation\" model of virtual memory. The APU was also used to implement a single-level store which is one of the fundamental abstraction that Multics is built around. The instruction format was also extended with the previously unused bit 29 controlling whether the operand address of an instruction used an 18-bit format (bit 29 = 0) or one that was made up of a 3-bit Base Register address with a 15-bit offset (bit 29 = 1).\nThe instruction format with bit 29 set to 1 is:\nAddress base registers.\nThe GE 645 had 8 Address Base Registers (abr's), these could operate in either \"paired\" or \"unpaired\" modes. The later Honeywell 6180 changed these to 8 pointer registers. Each abr was 24-bits wide consisting of 18 bits for an address and 6 bits for control functions.\nOne bit of the control functions field indicates where an abr is \"internal\" or \"external\". If an abr is internal, another 3-bit subfield of the control functions field specifies another abr with which this abr is paired; that other abr is external, with the external abr containing a segment number in the address field and the internal abr containing an offset within the segment specified by the external abr. If an instruction or an indirect word refers to an external abr, the address field in the instruction or indirect word is used as an offset in the segment specified by the external abr. If it refers to an internal abr, the address field in the instruction or indirect word is added to the offset in the abr, and the resulting value is used as an offset in the segment specified by the external abr with which the internal abr is paired.\nThe registers have the following formats depending on how bit 21 is set.\nFormat as an \"external\" base, with bit 21 set:\nFormat as a component to the effective \"internal\" address with a pointer to an \"external\" base, with bit 21 clear:\nIn Multics, an even-numbered abr and the following odd-numbered abr were paired. When writing in Assembly (EPLBSA/ALM) the standard Multics practice was to label these registers as follows:\nThe naming scheme is based around the following:\nThe 8 pointer registers in the Honeywell 6180 and its successors served the same purpose as the 4 paired base registers in the GE-645, referring to an offset within a segment.\nHistory.\nCTSS had originated in the MIT Computation Center using a IBM 709 and was first demonstrated in November 1961, it was subsequently upgraded to a 7090 in 1962, and finally to a 7094 in 1963. This required modification to these standard systems via the addition of a number of RPQ's which among others added two banks of memory and bank-switching between user and supervisor mode, i.e. programs running in the A-core memory bank had access to instructions that programs running in the B-core bank did not.\nProject MAC formally began with signing of contract with ARPA on the 1st of July 1963. By October 1963 they had received a dedicated 7094 to run CTSS under, this was termed the \"Red Machine\" due to it having red side panels. This would provide a time-sharing environment for Project MAC, and would subsequently be heavily used for the development of Multics. During this period exploratory work was carried out into what a replacement for CTSS would look like and what type of hardware it would require to run on. A committee was formed consisting of Fernando J. Corbat\u00f3, Ted Glaser, Jack Dennis and Robert Graham with responsibility to visit computer manufacturers to gauge level of interest in the industry to tender for the hardware platform. It was made clear that Project MAC was looking for a development partner given the considerable hardware modifications that would be required to meet their requirements, which were specified as:\nThey proceeded to visit among others Burroughs, CDC, DEC, General Electric, IBM and Sperry Univac. Of these GE and IBM showed the strongest interest. By the summer of 1964 proposals was received from DEC, IBM and GE, after evaluations by the Technical Committee a unanimous decision was made to accept the GE proposal for the GE 645 which was a design based on the GE 635 but modified to meet the requirements outlined above.\nWhile the GE 645 hardware was being designed and debugged in Phoenix, a system was put in place where a GE 635 could be used to run a simulator known as the 6.36, so that development and checkout of Multics could occur in parallel. This process involved creating a tape on the CTSS system which would be inputted to GECOS on the 635 system in MIT so that it would run under the 6.36 simulator; the resulting output would be carried back via tape to CTSS for debugging/analysis. This simulated environment was replaced by the first 645 hardware in 1967. The GECOS operating system was fully replaced by Multics in 1969 with the Multics supervisor separated by protection rings with \"gates\" allowing access from user mode.\nA later generation in the form of the 645F (F for follow-on) wasn't completed by the time the division was sold to Honeywell, and became known as the Honeywell 6180. The original access control mechanism of the GE/Honeywell 645 were found inadequate for high speed trapping of access instructions and the re-implementation in the 6180 solved those problems. The bulk of these computers running time-sharing on Multics were installed at the NSA and similar governmental sites. Their usage was limited by the extreme security measures and had limited impact on subsequent systems, other than the protection ring.\nThe hardware protection introduced on this computer and modified on the 6180 was later implemented in the Intel 286 computer processor as a four-layer protection ring, but four rings was found to be too cumbersome to program and too slow to operate. Protection ring architecture is now used only to protect kernel mode from user mode code just as it was in the original use of the 645.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58650", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=58650", "title": "Base unit of measurement", "text": "Unit of measurement adopted by convention for a base quantity\nA base unit of measurement (also referred to as a base unit or fundamental unit) is a unit of measurement adopted for a \"base quantity\". A base quantity is one of a conventionally chosen subset of physical quantities, where no quantity in the subset can be expressed in terms of the others. The SI base units, or \"Syst\u00e9me International d'unit\u00e9s\", consists of the metre, kilogram, second, ampere, kelvin, mole and candela.\nA unit multiple (or multiple of a unit) is an integer multiple of a given unit; likewise a unit submultiple (or submultiple of a unit) is a submultiple or a unit fraction of a given unit. \n\"Unit prefixes\" are common base-10 or base-2 powers multiples and submultiples of units.\nWhile a base unit is one that has been explicitly so designated, \na derived unit is unit for a \"derived quantity\", involving the combination of quantities with different units; several \"SI derived units\" are specially named.\nA \"coherent derived unit\" involves no conversion factors.\nBackground.\nIn the language of measurement, \"physical quantities\" are quantifiable aspects of the world, such as time, distance, velocity, mass, temperature, energy, and weight, and \"units\" are used to describe their magnitude or quantity. Many of these quantities are related to each other by various physical laws, and as a result the units of a quantities can be generally be expressed as a product of powers of other units; for example, momentum is mass multiplied by velocity, while velocity is distance divided by time. These relationships are discussed in dimensional analysis. Those that can be expressed in this fashion in terms of the base units are called derived units.\nInternational System of Units.\nIn the International System of Units (SI), there are seven base units: kilogram, metre, candela, second, ampere, kelvin, and mole.\nSeveral derived units have been defined, many with special names and symbols.\nIn 2019 the seven SI base units were redefined in terms of seven defining constants. Therefore the SI base units are no longer necessary but were retained because for historical and practical reasons. See \"2019 revision of the SI\".\nNatural units.\nA set of base dimensions of quantity is a minimal set of units such that every physical quantity can be expressed in terms of this set. The traditional base dimensions are mass, length, time, charge, and temperature, but in principle, other base quantities could be used. Electric current could be used instead of charge or speed could be used instead of length. Some physicists have not recognized temperature as a base dimension since it simply expresses the energy per particle per degree of freedom which can be expressed in terms of energy (or mass, length, and time). Duff argues that only dimensionless values have physical meaning and all dimensional units are human constructs.\nThere are other relationships between physical quantities that can be expressed by means of fundamental constants, and to some extent it is an arbitrary decision whether to retain the fundamental constant as a quantity with dimensions or simply to define it as unity or a fixed dimensionless number, and reduce the number of explicit base quantities by one. The ontological issue is whether these fundamental constants really exist as dimensional or dimensionless quantities. This is equivalent to treating length as the same as time or understanding electric charge as a combination of quantities of mass, length, and time which may seem less natural than thinking of temperature as measuring the same material as energy (which is expressible in terms of mass, length, and time).\nFor instance, time and distance are related to each other by the speed of light, \"c\", which is a fundamental constant. It is possible to use this relationship to eliminate either the base unit of time or that of distance. Similar considerations apply to the Planck constant, \"h\", which relates energy (with dimension expressible in terms of mass, length and time) to frequency (with dimension expressible in terms of time). In theoretical physics it is customary to use such units (natural units) in which \"c\" = 1 and \"\u0127\" = 1. A similar choice can be applied to the vacuum permittivity, \"\u03b5\"0.\nThe preferred choices vary by the field in physics. Using natural units leaves every physical quantity expressed as a dimensionless number, which is noted by physicists disputing the existence of incompatible base quantities.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58651", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=58651", "title": "GE 635", "text": ""}
{"id": "58652", "revid": "16861812", "url": "https://en.wikipedia.org/wiki?curid=58652", "title": "Honeywell 6180", "text": ""}
{"id": "58653", "revid": "4796325", "url": "https://en.wikipedia.org/wiki?curid=58653", "title": "List of kingdoms and royal dynasties", "text": "This is a list of kingdoms and royal dynasties, organized by geographic region.\nNote: many countries have had multiple dynasties over the course of recorded history. This is not a comprehensively exhaustive list and may require further additions or historical verification.\nAsia.\nChina.\nThe following is a list of major dynasties of China:\nAmericas.\nCanada.\n\"See also Monarchism in Canada\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58654", "revid": "38562746", "url": "https://en.wikipedia.org/wiki?curid=58654", "title": "GE-645", "text": ""}
{"id": "58655", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=58655", "title": "Monarchianism", "text": "Christian theological doctrine\nMonarchianism is a doctrine that emphasizes God as one indivisible being, in direct contrast to Trinitarianism, which defines the Godhead as three co-eternal, consubstantial, co-immanent, and equally divine hypostases.\nHistory.\nDuring the patristic period, Christian theologians attempted to clarify the relationship between the Father, Son and Holy Spirit. Monarchianism developed in the 2nd century and persisted further into the 3rd century. \"Monarchianism\" (from the Greek \"monarkhia\", meaning \"ruling of one,\" and \"-ismos\", meaning \"practice or teaching\") stresses the absolute, uncompromising unity of God in contrast to the doctrine of the Trinity, which is often lambasted as veiled tritheism by nontrinitarian Christians and other monotheists. \nMonarchians were opposed by Logos theologians (Tertullian, Hippolytus, Clement of Alexandria, and Origen of Alexandria). The Trinitarian view gained prominence and was adopted at the First Council of Constantinople in 381. Monarchianism was considered a heresy after the 4th century.\nTypes.\nTwo types of monarchianism were propounded. Adoptionism (or \"dynamic monarchianism\" or \"Dynamism\") holds that God is one being, above all else, wholly indivisible, and of one nature. It holds that the Son was not co-eternal with the Father and that Jesus Christ was essentially granted godhood (adopted) for the plans of God and for his own perfect life and works. Different variations of Dynamism hold that Jesus was \"adopted\" either at the time of his baptism or his ascension. Notable adherents included Artemon, Beryllus of Bostra, a third-century bishop who debated with Origen, Paul of Samosata, a bishop of Antioch, and Theodotus of Byzantium.\nModalistic monarchianism (or Modalism) considers God to be one, who appears and works through the different \"modes\" of Father, Son, and Holy Spirit. Following this view, all of the Godhead is understood to dwell in the person of Jesus from the incarnation. The terms \"Father\" and \"Son\" are then used to describe the distinction between the \"transcendence\" of God and the incarnation. Lastly, since God is understood as a Spirit in the context of the Gospel of John, it is held that the Holy Spirit should not be understood as a separate entity but rather as a mere descriptor of God's action. Notable adherents included Noetus, Praxeas, and Sabellius, hence why the view is commonly called Sabellianism. Nevertheless, Sabellius's writings did not survive and so the little that is known about his beliefs is from secondary sources.\nThe name \"Monarchian\" properly does not strictly apply to the Adoptionists, or Dynamists, as they (the latter) \"did not start from the monarchy of God, and their doctrine is strictly Christological\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58658", "revid": "63286", "url": "https://en.wikipedia.org/wiki?curid=58658", "title": "Honeywell 6000 series", "text": "Successors to General Electric's 600-series mainframes\nThe Honeywell 6000 series computers were a further development (using integrated circuits) of General Electric's 600-series mainframes manufactured by Honeywell International, Inc. from 1970 to 1989. Honeywell acquired the line when it purchased GE's computer division in 1970 and continued to develop them under a variety of names for many years. In 1989, Honeywell sold its computer division to the French company Groupe Bull who continued to market compatible machines.\nModels.\nThe high-end model was the 6080, with performance approximately 1\u00a0MIPS. Smaller models were the 6070, 6060, 6050, 6040, and 6030. In 1973, a low-end 6025 was introduced. The models with an even number as the next-to-last digit of the model number included an \"Enhanced Instruction Set\" feature (EIS), which added decimal arithmetic and storage-to-storage operations to the original word-oriented architecture. In 1973, Honeywell introduced the 6180, a 6000-series machine with addressing modifications to support the Multics operating system.\nIn 1974, Honeywell introduced several new computers under the name \"Series 60\"; the \"Level 66\" and \"Level 68\" members of the series were compatible with the 6000 series machines, and were slightly faster (to 1.2\u00a0MIPS) and offered larger MOS memories rather than core memories. The larger machines included a cache memory. The Level 66/20, Level 66/40, Level 66/60, and Level 66/80 were compatible with the 6040, 6060, and 6080; the Level 68/80 was compatible with the 6180, and supported Multics. Lower-end Level 66 and Level 68 processors were introduced in 1975; in the case of the Multics compatible 68/60, the key difference was the removal of the cache memory and limiting the configuration to a maximum of two processors.\nIn 1977, the line was again renamed to the 66/DPS (68/DPS for Multics compatible models). This was part of wide-scale repricing to remain compatible with the prices reductions that IBM had introduced to the market in early 1977. The newly introduced 68/DPS was available in at least five distinct configurations (Level1 through Level5). \nDuring this period the top of the range was only comparable to the IBM System/370 Model 155/158 when it came to performance; this posed an issue for Honeywell when competing against the higher end of the System/370 family. This led to the development and the introduction of the Honeywell Model 66/85 in 1977. This system built with current-mode logic (CML) which promised to offer faster speeds in a more compact format. However Honeywell were unable to produce the CML chips in a cost-effective manner and subsequently withdrew the 66/85 from marketing in 1978. \nIn 1979, the family was renamed to DPS-8, again with a small performance improvement to 1.7\u00a0MIPS. GCOS 8 shipped as the native operating system with support for a new Virtual memory hardware implementation (Virtual Unit - VU) that used a combination of Virtual Spaces, Paging, Segments and Domains. This was known as the \"New System Architecture\" (NSA) and was incompatible with the Multics model of virtual memory. As a result modifications were required to ship the Multics compatible DPS-8/M which omitted the VU and instead implemented Multics Ring based securing model and the hybrid \"Paged Segmentation\" model of Multics virtual memory.\nIn 1982, Honeywell announced the new DPS-88 model which like the previous unsuccessful 66/85 was built using CML instead of the TTL as used in the previous DPS-8 generation. This required a switch from air cooling to using water cooling. The DPS-88 was offered in at two models based on the number of CPU's supported and memory supported: DPS-88/81 (64MB) and DPS-88/82 (128MB). Subsequently Honeywell would sign a pact with NEC to import and sell NEC's S-1000 as the DPS-90.\nHardware.\n6000-series systems were said to be \"memory oriented\" \u2014 a \"system controller\" in each memory module arbitrated requests from other system components (processors, etc.). Memory modules contained 128\u00a0K words of 1.2\u00a0\u03bcs 36-bit words; a system could support one or two memory modules for a maximum of 256\u00a0K words (1\u00a0MB of 9-bit bytes). Each module provided two-way interleaved memory.\nDevices called \"Input/Output Multiplexers (IOMs)\" served as intelligent I/O controllers for communication with most peripherals. The IOM supported two different types of peripheral channels: \"Common Peripheral Channels\" could handle data transfer rates up to 650,000\u00a0cps; \"Peripheral Subsystem Interface Channels\" allowed transfers up to 1.3 million cps.\nThe 6000 supported multiple processors and IOMs. Each processor and IOM had four ports for connection to memory; each memory module had eight ports for communication with other system components, with an interrupt cell for each port.\nMemory protection and relocation was accomplished using a base and bounds register in the processor, the \"Base Address Register (BAR)\". The IOM was passed the contents of the BAR for each I/O request, allowing it to use virtual rather than physical addresses.\nIn the Multics-compatible systems there was an Appending Unit based on the unit of same name in the GE 645. This implemented the Multics model of virtual memory using \"Paged Segments\". These systems also had a hardware implementation of the Multics protection ring architecture, in contrast to the GE 645 which had emulated protection rings in software. This significantly improved the performance of ring passing events in Multics compared to on the GE 645.\nFrom the DPS-8 generation onwards GCOS could use a competing Virtual Memory architecture that was not compatible with what Multics required from the hardware. That model divided the memory space into 512 Working spaces each of which were further divided into 1024 pages (in DPS-8 implementation) of 4096KB size. On top of this GCOS implemented Segments which could be grouped together in Domains (a Domain could have segments from multiple Working Spaces) which a process could access.\nA variety of communications controllers could also be used with the system. The older DATANET-30 and the DATANET 305\u2014 intended for smaller systems with up to twelve terminals attached to an IOM. The DATANET 355 processor attached directly to the system controller in a memory module and was capable of supporting up to 200 terminals.\nCPU.\nThe CPU operates on 36-bit words, and addresses are 18 bits. The \"Accumulator Register\" (AQ) was 72 bits, or could be accessed separately as two 36-bit registers (A and Q) or four 18-bit registers (AU, AL, QU, QL). An eight-bit \"Exponent Register\" contained the exponent for floating point operations (the mantissa was in AQ). There were eight eighteen-bit index registers X0 through X7.\nThe 18-bit \"Base Address Register\" (BAR) contains the base address and number of 1024-word blocks assigned to the program (the 6180 used segmentation rather than the BAR). The system also includes several special-purpose registers: an 18-bit \"Instruction Counter\" (IC) and a 27-bit \"Timer Register\" (TR) with a resolution of 2\u00a0\u03bcs. Sets of special registers are used for fault detection and debugging.\nThe EIS instruction set adds eight additional 24-bit registers AR0 through AR7. These registers contain an 18-bit word address, a 2-bit address of a character within the word, and a 4-bit address of a bit within the character.\nInstruction formats.\nThe 6000-series machine's basic instruction set has more than 185 single-address one-word instructions. The basic instructions are one word; the instruction format is an extension of that of the GE-600 series, with the opcode field extended to 10 bits by adding bit 27 as the low-order bit; that bit is zero in all GE-600 series instructions.\nThe format for basic and one-word EIS instructions is:\nEIS instructions longer than one word are two-word to four-word instructions depending on the specific instruction. The addresses point either to operands or to \"operand descriptors\", which contain the actual operand address and additional information. The format of those instructions is:\nData formats.\nData is stored in big-endian format. Bits are numbered starting from 0 (most-significant) to 35 or 71 (least-significant).\nPeripherals.\nThe following peripherals were available for the 6000-Series machines in 1971.\nSoftware.\nThe primary operating system for the line was the General Comprehensive Operating System (GCOS), which Honeywell originally inherited from General Electric's GECOS. In 1978 Honeywell introduced a rewritten version GCOS 8, which supported virtual memory. The Multics OS also ran on selected CPU models.\nIn 1974, Honeywell purchased Xerox Data Systems (XDS), and developed a work-alike of the Xerox operating system CP-V as CP-6 to run on DPS-8 systems in order to retain Xerox' loyal customer base.\nGEIS also ran their custom Mark III operating system on Level 66 and later DPS/8 hardware. This was based on work that GE had originally done with DTSS but with custom GE modifications particulary in the areas of background batch and in File system clustering. GEIS plans to import the NEC ACOS S1000 series was one of reasons why Honeywell would subsequently OEM this as the DPS-90 series.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58659", "revid": "218586", "url": "https://en.wikipedia.org/wiki?curid=58659", "title": "GE-600 series", "text": "General Electric mainframe computers\nThe GE-600 series is a family of 36-bit mainframe computers originating in the 1960s, built by General Electric (GE). When GE left the mainframe business, the line was sold to Honeywell, which built similar systems into the 1990s as the division moved to Groupe Bull and then NEC.\nThe system is perhaps best known as the hardware used by the Dartmouth Time-Sharing System (DTSS) and the Multics operating system. Multics was supported by virtual memory additions made in the GE 645.\nArchitecture.\nThe 600-series CPU operates on 36-bit words,II-17 and addresses are 18 bits. The \"accumulator Register\" (AQ) is a 72-bit register that can also be accessed separately as two 36-bit registers (A and Q) or four 18-bit registers (AU,AL,QU,QL).II-5 An eight-bit \"Exponent Register\" contain the exponent for floating-point operations (the mantissa is in AQ).II-5 There are eight eighteen-bit index registers X0 through X7.II-5\nThe 18-bit \"Base Address Register\" (BAR) contains the base address and number of 1024-word blocks assigned to the program.II-7 The system also includes several special-purpose registers: an 18-bit \"Instruction Counter\" (IC) and a 24-bit \"Timer Register\" (TR) with a resolution of 15.625\u00a0\u03bcs.II-5-II-7\nInstruction formats.\nThe 600-series machine instructions are one word long. Operand addresses point either to operands or to \"indirect words\", which contain the actual operand address and additional information.\nMost instructions have the following format:II-23\nThe Repeat, Repeat Double, and Repeat Link instructions have a different format.II-23\nAddressing modes.\nThe 600 series has an elaborate set of addressing modes, many of which use indirect words, some of which are auto-incrementing or auto-decrementing. Multiple levels of indirect addressing are supported. Indirect addresses have the same format as instructions, and the address modification indicated by the tag field of the indirect address are performed at each level.II-23\nThe tag field of the instruction consist of a 2-bit \"tag modifier\" (tm) and a 4-bit \"tag designator\" (td).II-24 The tag modifier indicates the type of modification to be performed on the instruction address:II-25\nFor modification types R, RI, and IR the tag designator contains a register to be used for indexing (X0-X7,AU,AL,QU,QL,IC). Other TD values indicate that Y should be used as an immediate operand. Direct addressing is a special case where Y is used as the operand address with no modification.II-26\nFor modification type IT, the indirect word contains an 18-bit address, a 12-bit tally, and a 6-bit tag. The tag designator indicates the operation to be performed, some of which increment the address and decrement the tally of the indirect word or decrement the address and increment the tally of the indirect word. The Character from Indirect and Sequence Character operations can be used to address 6-bit and 9-bit bytes; this supports extracting specific bytes, and incrementing the byte pointer, but not random access to bytes.II-26-II-33a\nData formats.\nData was stored in big-endian format. Bits were numbered starting from 0 (most-significant) to 35 or 71 (least-significant).\nI/O.\nThe 600-series also included a number of channel controllers for handling I/O. The CPU could hand off short programs written in the channel controller's own machine language, which would then process the data, move it to or from the memory, and raise an interrupt when they completed. This allowed the main CPU to move on to other tasks while waiting for the slow I/O to complete, a primary feature of time sharing systems.\nOperating systems.\nOriginally the operating system for the 600-series computers was GECOS, developed by GE beginning in 1962. GECOS was initially a batch processing system, but later added many features seen on more modern systems, including multitasking and multi-user support.\nBetween 1963 and 1964, GE worked with Dartmouth College on their Dartmouth BASIC project, which also led to the development of a new timesharing system to support it on the GE-235. This was a great success and led to a late 1967 proposal for an improved version of the system running on the 635. The first version, known to Dartmouth as \"Phase I\" and GE as \"Mark II\", the original on the GE-235 becoming \"Mark I\", was a similar success. \"Phase II\" at Dartmouth was released as the Dartmouth Time-Sharing System (DTSS), while GE further developed Mark II into the improved Mark III.\nThe Computer History Museum's Corporate Histories Collection describes GE's Mark I history this way:\nThe precursor of General Electric Information Services began as a business unit within General Electric formed to sell excess computer time on the computers used to give customer demos. In 1965, Warner Sinback recommended that they begin to sell time-sharing services using the time-sharing system (Mark 1) developed at Dartmouth on a General Electric 265 computer. The service was an instant success and by 1968, GEIS had 40% of the $ 70 million time-sharing market. The service continued to grow, and over time migrated to the GE developed Mark II and Mark III operating systems running on large mainframe computers.\nThe GE Mark II operating system (later Mark III) was used by GE Information Services as the basis for its timesharing and networked computing business. Although Mark II / Mark III was originally based on the Dartmouth system, the systems quickly diverged. Mark II/III incorporated many features normally associated with on-line transaction-processing systems, such as journalization and granular file locking. In the early-to-mid-1970s, Mark III adopted a high-reliability cluster technology, in which up to eight processing systems (each with its own copy of the operating system) had access to multiple file systems.\nThe Multics operating system was begun in 1964 as an advanced new operating system for the 600 series, though it was not production-ready until 1969. GE supplied the hardware to the project and was one of the development partners (the others were Massachusetts Institute of Technology and Bell Labs). GE saw this project as an opportunity to clearly separate themselves from other vendors by offering this advanced OS which would run best only on their machines. Multics required a number of additional features in the CPU to be truly effective, and John Couleur was joined by Edward Glaser at MIT to make the required modifications. The result was the GE 645, which included support for virtual memory. Addressing was modified to use an 18-bit \"segment\" in addition to the 18-bit address, dramatically increasing the theoretical memory size and making virtual memory much easier to support.\nUnix.\nIn 1969, Ken Thompson had also written a video game, \"Space Travel\", under the GECOS operating system on the smaller GE 635 machine. This had the problem that a typical game cost $75 &amp;lpar;&amp;dollar;\u00a0in &lt;templatestyles src=\"Template:Tooltip/styles.css\" /&gt;) worth of billable CPU runtime. When he learned that Visual and Acoustics Research department had a small PDP-7 that was largely unused, he began to rewrite the game for this machine. This was initially performed by building a binary for the PDP-7 using a cross compiler on the 635, and then moving the resulting code to the PDP-7 using paper tape.\nThis became tedious, and Thompson began considering writing his new operating system on the new machine. This was aided by a timely vacation by his wife, leaving him with a month to work on it full time. Aided by Ritchie and Rudd Canaday, they implemented a version of the hierarchical file system Thompson had studied on the GE 645. The ability to start programs stored in that file system soon followed, and then small programs to copy, delete, print and edit those files, along with a command-line interpreter to allow the user to perform all of these operations interactively. With these in place, a new assembler was written for the machine, and \"Space Travel\" moved entirely to the new platform.\nHistory.\nThe GE-600 line of computers was developed by a team led by John Couleur out of work they had done for the military MISTRAM project in 1959. MISTRAM was a radar tracking system that was used on a number of projects, including Project Apollo. The Air Force required a data-collection computer to be installed in a tracking station downrange from Cape Canaveral. The data would eventually be shared with the 36-bit IBM 7094 machine at the Cape, so the computer would likely have to be 36-bits as well. GE built a machine called the M236 for the task, and as a result of the 36-bit needs, it ended up acting much like the IBM 7094.\nGE originally had not intended to enter the commercial computer market with their own machine. However, by the early 1960s GE was the largest user of IBM mainframes, and producing their own machines seemed like an excellent way to lower the costs of their computing department. In one estimate, the cost of development would be paid for in a single year free of IBM rental fees. Many remained skeptical, but after a year of internal wrangling, the project to commercialize the M236 eventually got the go-ahead in February 1963.\nThe machine was originally offered as the main GE-635, and the slower but compatible GE-625 and GE-615. While most were single-processor systems, the 635 could be configured with four CPUs and up to four input/output controllers (IOC's) each with up to 16 Common Peripheral Interface Channels. The 635 was likely the first example of a general purpose SMP system, though the GECOS/GCOS software treated the processors as a master and up to three slaves.\nIn August 1964, IBM considered the GE 600 series to be \"severe competition in the medium and large-scale scientific areas\". In May 1965 the first GE-625 computer was delivered to the GE Schenectady plant to replace five other computers of various sizes and makes. A number of GE 635's were shipped during 1965 including two to Martin Marietta in November.\nThe 600 line consisted of six models: the 605, 615, 625, 635, 645, and 655. GE offered a box to connect to the 635 called a 9SA that allowed the 635 to run IBM 7094 programs.\nThe 615 was a 635 with Control Unit (CU) and Operations Unit (OU) overlap disabled, and a 36-bit-wide memory path. The 625 was a 635 with Control Unit and Operations Unit overlap disabled and 72-bit-wide memory path. The 635 had a 72-bit-wide memory path and CU/OU overlap enabled. The difference between these models was fewer than 10 wires on the backplane. Field service could convert a 615 to a 635 or 625 or vice versa in a couple of hours if necessary; other than those few wires, the 615, 625 and 635 were identical. The 605 was used in some realtime/military applications and was essentially a 615 without the floating point hardware. Programs coded for a 605 would run without any modification on any other 600 line processor. The 645 was a modified 635 processor that provided hardware support for the Multics operating system developed at MIT. \nThe 605/615/625/635 and 645 were essentially second generation computers with discrete transistor TTL logic and a handful of integrated circuits. Memory consisted of a two-microsecond ferrite core, which could be interleaved. GE bought core memory from Fabri-Tek, Ampex and Lockheed. The Lockheed memory tended to be the most reliable.\nContinuing problems with the reliability of the magnetic tape systems used with the system cast a pall over the entire project. In 1966 GE withdrew the 600 series from active marketing, there was also widespread redundancies in the Phoenix operation, the issues with the 600 series damaged GE's reputation in the computer industry and resulted in the outright cancellations of a number of orders placed for it. By 1967 these problems were cleared up, and the machines were re-launched along with an upgraded version of the GECOS operating system.\nA follow-on project to create a next-generation 635 started in 1967. The new GE-655 replaced the individual transistors from the earlier models with integrated circuits, which doubled the performance of the machine while also greatly reducing assembly costs. However, the machine was still in development in 1969, and was announced but probably never delivered under that name.\nBy that time the Multics project had finally produced an operating system usable by end-users. Besides MIT, Bell Labs, and GE, GE-645 systems running Multics were installed at the US Air Force Rome Development Center, Honeywell Billerica, and Machines Bull in Paris. These last two systems were used as a \"software factory\" by a Honeywell/Bull project to design the Honeywell Level 64 computer.\nDuring this period GE had a relationship with Toshiba of Japan which included licensing of technology, this had originally been formalised in an agreement in 1964 covering the GE-400 series and in 1970 it was extended to include the GE-600 series. As a result of this Toshiba released the TOSBAC 5600 in 1970. This would later be developed in collaboration with NEC into the ACOS-77/ACOS-6 series of mainframes.\nGE sold its computer division to Honeywell in 1970, who renamed the GE-600 series as the Honeywell 6000 series. The 655 was officially released in 1973 as the Honeywell 6070 (with reduced performance versions, the 6030 and 6050). An optional Decimal/Business instruction set was added to improve COBOL performance. This was the Extended Instruction Set, also known as EIS, and the Decimal Unit or DU. The machines with EIS were the 'even' series, the 6040, 6060, 6080 and later the 6025. Several hundred of these processors were sold. Memory was initially 600\u00a0ns ferrite core made by Lockheed. Later versions used 750\u00a0ns MOS memory. The two could co-exist within a system, but not within a memory controller.\nA version of the 6080 with the various Multics-related changes similar to the 645 was released as the 6180. A few dozen 6180-architecture CPUs were shipped. Later members of the 6000 series were released under various names, including Level 66, Level 68, DPS-8, DPS-88, DPS-90, DPS-9000 by Honeywell, Groupe Bull, and NEC."}
{"id": "58660", "revid": "45595768", "url": "https://en.wikipedia.org/wiki?curid=58660", "title": "401 BC", "text": "Calendar year\n \nYear 401 BC was a year of the pre-Julian Roman calendar. At the time, it was known as the Year of the Tribunate of Potitus, Cossus, Camillus, Ambustus, Mamercinus and Iullus (or, less frequently, year 353 \"Ab urbe condita\"). The denomination 401 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy topic.\nLiterature.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58661", "revid": "48822490", "url": "https://en.wikipedia.org/wiki?curid=58661", "title": "CDC 6600", "text": "Mainframe computer by Control Data\nThe CDC 6600 is the flagship of the discontinued 6000 series of mainframe computer systems manufactured by Control Data Corporation. Generally considered to be the first successful supercomputer, it outperformed the industry's prior recordholder, the IBM 7030 Stretch, by a factor of three. With performance of up to three\u00a0megaFLOPS, the CDC 6600 was the world's fastest computer from 1964 to 1969, when it relinquished that status to its successor, the CDC 7600.\nThe first CDC 6600s were delivered in 1965 to Livermore and Los Alamos. They quickly became a must-have system in high-end scientific and mathematical computing, with systems being delivered to Courant Institute of Mathematical Sciences, CERN, the Lawrence Radiation Laboratory, and many others. At least 100 were delivered in total.\nA CDC 6600 is on display at the Computer History Museum in Mountain View, California. The only running CDC 6000 series machine was restored by , however the museum has permanently closed.\nHistory and impact.\nCDC's first products were based on the machines designed at Engineering Research Associates (ERA), which Seymour Cray had been asked to update after moving to CDC. After an experimental machine known as the \"Little Character\", in 1960 they delivered the CDC 1604, one of the first commercial transistor-based computers, and one of the fastest machines on the market. Management was delighted, and made plans for a new series of machines that were more tailored to business use; they would include instructions for character handling and record keeping for instance. Cray was not interested in such a project and set himself the goal of producing a new machine that would be 50 times faster than the 1604. When asked to complete a detailed report on plans at one and five years into the future, he wrote back that his five-year goal was \"to produce the largest computer in the world\", \"largest\" at that time being synonymous with \"fastest\", and that his one-year plan was \"to be one-fifth of the way\".\nTaking his core team to new offices near the original CDC headquarters, they started to experiment with higher quality versions of the \"cheap\" transistors Cray had used in the 1604. After much experimentation, they found that there was simply no way the germanium-based transistors could be run much faster than those used in the 1604. The \"business machine\" that management had originally wanted, now forming as the CDC 3000 series, pushed them about as far as they could go. Cray then decided the solution was to work with the then-new silicon-based transistors from Fairchild Semiconductor, which were just coming onto the market and offered dramatically improved switching performance.\nDuring this period, CDC grew from a startup to a large company and Cray became increasingly frustrated with what he saw as ridiculous management requirements. Things became considerably more tense in 1962 when the new CDC 3600 started to near production quality, and appeared to be exactly what management wanted, when they wanted it. Cray eventually told CDC's CEO, William Norris that something had to change, or he would leave the company. Norris felt he was too important to lose, and gave Cray the green light to set up a new laboratory wherever he wanted.\nAfter a short search, Cray decided to return to his home town of Chippewa Falls, Wisconsin, where he purchased a block of land and started up a new laboratory.\nAlthough this process introduced a fairly lengthy delay in the design of his new machine, once in the new laboratory, without management interference, things started to progress quickly. By this time, the new transistors were becoming quite reliable, and modules built with them tended to work properly on the first try. The 6600 began to take form, with Cray working alongside Jim Thornton, system architect and \"hidden genius\" of the 6600.\nMore than 100 CDC 6600s were sold over the machine's lifetime (1964 to 1969). Many of these went to various nuclear weapon-related laboratories, and quite a few found their way into university computing laboratories. A CDC 6600 was used to disprove Euler's sum of powers conjecture in an early example of direct numerical search.\nCray immediately turned his attention to its replacement, this time setting a goal of ten times the performance of the 6600, delivered as the CDC 7600. The later CDC Cyber 70 and 170 computers were very similar to the CDC 6600 in overall design and were nearly completely backwards compatible.\nThe 6600 was three times faster than the previous record-holder, the IBM 7030 Stretch; this alarmed IBM. Then-CEO Thomas Watson Jr. wrote a memo to his employees on August 28, 1963: \"Last week CDC [...] announced their 6600 system. I understand that in the laboratory developing this system there are only 34 people, \"including the janitor.\" Of these, 14 are engineers and 4 are programmers\u00a0[...] Contrasting this modest effort with our vast development activities, I fail to understand why we have lost our industry leadership position by letting someone else offer the world's most powerful computer.\" Cray's reply was sardonic: \"It seems like Mr. Watson has answered his own question.\"\nDescription.\nTypical machines of the 1950s and 1960s used a single central processing unit (CPU) to drive the entire system. A typical program would first load data into memory (often using pre-rolled library code), process it, and then write it back out. This required the CPUs to be fairly complex in order to handle the complete set of instructions they would be called on to perform, including input/output and processing. A complex CPU implied a large CPU, introducing signalling delays while information flowed between the individual modules making it up. These delays set a maximum upper limit on performance, as the machine could only operate at a cycle speed that allowed the signals time to arrive at the next module. Further, CPUs generally ran slower than the main memory to which they were attached. For instance, a processor might take 15 cycles to multiply two numbers, while each memory access took only one or two cycles. This meant there was a significant time where the main memory was idle. Cray improved performance in several ways, using an opportunity in this idle time.\nInstead of a CPU alone, the CDC 6600 supported the CPU with ten 12-bit 4 KiB peripheral processors (PPs), each with access to a common pool of 12 input/output (I/O) channels that handled input and output, as well as controlling what data were sent into central memory for processing by the CP. The PPs were designed to access memory during the idle times when the CPU was busy performing operations. This allowed them to perform input/output essentially for free in terms of central processing time, keeping the CPU busy as much as possible.\nSince input/output was handled by peripheral processors, the CDC 6600 used a simplified central processor (CP) that was designed to run mathematical and logic operations as rapidly as possible, which demanded it be built as small as possible to reduce the length of wiring and the associated signalling delays. This led to the machine's (typically) cross-shaped main chassis with the circuit boards for the CPU arranged close to the center, and resulted in a much smaller CPU. Combined with the faster switching speeds of the silicon transistors, the new CPU ran at 10\u00a0MHz (100\u00a0ns cycle time), about ten times faster than other machines on the market. In addition to the clock being faster, the simple processor executed instructions in fewer clock cycles; for instance, the CPU could complete a multiplication in ten cycles.\nThe 6600's CP used a 60-bit word and a ones' complement representation of integers, something that later CDC machines would use into the late 1980s, making them the last systems besides some digital signal processors to use this architecture.\nLater, CDC offered options as to the number and type of CPs, PPs and channels, e.g., the CDC 6700 had two central processors, a 6400 CP and a 6600 CP.\nWhile other machines of its day had elaborate front panels to control them, the 6600 has only a \"dead start panel\". There is a dual CRT system console, but it is controlled by the operating system and neither controls nor displays the hardware directly.\nThe entire 6600 machine contained approximately 400,000 transistors.\nPeripheral processors.\nThe CPU could only execute a limited number of simple instructions. A typical CPU of the era had a complex instruction set, which included instructions to handle all the normal \"housekeeping\" tasks, such as memory access and input/output. Cray instead implemented these instructions in separate, simpler processors dedicated solely to these tasks, leaving the CPU with a much smaller instruction set. This was the first of what later came to be called reduced instruction set computer (RISC) design.\nBy allowing the CPU, peripheral processors (PPs) and I/O to operate in parallel, the design considerably improved the performance of the machine. Under normal conditions a machine with several processors would also cost a great deal more. Key to the 6600's design was to make the I/O processors, known as \"peripheral processors\" (PPs), as simple as possible. The PPs were based on the simple 12-bit CDC 160-A, which ran much slower than the CPU, gathering up data and transmitting it as bursts into main memory at high speed via dedicated hardware.\nThe 10 PPs were implemented virtually; there was CPU hardware only for a single PP. This CPU hardware was shared and operated on 10 PP register sets which represented each of the 10 PP \"states\" (similar to modern multithreading processors). The PP \"register barrel\" would \"rotate\", with each PP register set presented to the \"slot\" which the actual PP CPU occupied. The shared CPU would execute all or some portion of a PP's instruction whereupon the barrel would \"rotate\" again, presenting the next PP's register set (state). Multiple \"rotations\" of the barrel were needed to complete an instruction. A complete barrel \"rotation\" occurred in 1000 nanoseconds (100 nanoseconds per PP), and an instruction could take from one to five \"rotations\" of the barrel to be completed, or more if it was a data transfer instruction.\nInstruction-set architecture of CP.\nThe basis for the 6600 CPU is what would later be called a RISC system, one in which the processor is tuned to do instructions that are comparatively simple and have limited and well-defined access to memory. The philosophy of many other machines was toward using instructions which were complicated \u2014 for example, a single instruction which would fetch an operand from memory and add it to a value in a register. \nInstructions for the CP are either 15 bits split into 5 3-bit fields designated as f, m, i, j and k or 30 bits split into 3-bit f, m, i and j and an 18-bit K field. The function (f) and modifier (m) usually specify the opcode, although in some cases, the register number is part of a 9-bit opcode. Most 15-bit instructions perform an operation on two registers and store the result in a third (i) register. Most 30-bit instructions perform an operation on a register and a constant and store the reult in a second (i) register.\nThe CP has no explicit load and store instructions, and only jumps and the SAi instructions reference memory. An SAi instruction reads from central memory into an associated X register when i is 1-5 and writes from it when i is 6 or 7. Thus, in the CP, adding from memory would require two instructions. While slower in theory due to the additional instruction, the fact that in well-scheduled code, multiple instructions could be processing in parallel offloaded this expense. This simplification also forced programmers to be very aware of their memory accesses, and therefore code deliberately to reduce them as much as possible. The CDC 6600 CP, being a three-address machine, allows for the specification of all three operands.\nModels.\nThe CDC 6000 series included four basic models, the CDC 6400, the CDC 6500, the CDC 6600, and the CDC 6700. The models of the 6000 series differed only in their CPUs, which were of two kinds, the 6400 CPU and the 6600 CPU. The 6400 CPU had a unified arithmetic unit, rather than discrete \"functional units\". As such, it could not overlap instructions' execution times. For example, in a 6400 CPU, if an add instruction immediately followed a multiply instruction, the add instruction could not be started until the multiply instruction finished, so the net execution time of the two instructions would be the sum of their individual execution times. The 6600 CPU had multiple functional units which could operate simultaneously, \"i.e.\", \"in parallel\", allowing the CPU to overlap instructions' execution times. For example, a 6600 CPU could begin executing an add instruction in the next CPU cycle following the beginning of a multiply instruction (assuming, of course, that the result of the multiply instruction was not an operand of the add instruction), so the net execution time of the two instructions would simply be the (longer) execution time of the multiply instruction. The 6600 CPU also had an \"instruction stack\", a kind of \"instruction cache\", which helped increase CPU throughput by reducing the amount of CPU idle time caused by waiting for memory to respond to instruction fetch requests. The two kinds of CPUs were instruction compatible, so that a program that ran on either of the kinds of CPUs would run the same way on the other kind but would run faster on the 6600 CPU. Indeed, all models of the 6000 series were fully inter-compatible. The CDC 6400 had one CPU (a 6400 CPU), the CDC 6500 had two CPUs (both 6400 CPUs), the CDC 6600 had one CPU (a 6600 CPU), and the CDC 6700 had two CPUs (one 6600 CPU and one 6400 CPU).\nCentral Processor (CP).\nThe Central Processor (CP) and main memory of the 6400, 6500, and 6600 machines had a 60-bit word length. The Central Processor had eight general purpose 60-bit registers X0 through X7, eight 18-bit address registers A0 through A7, and eight 18-bit \"increment\" registers B0 through B7. B0 was held at zero permanently by the hardware. Many programmers found it useful to set B1 to 1, and similarly treat it as inviolate.\nThe CP had no instructions for input and output, which are accomplished through Peripheral Processors (below). No opcodes were specifically dedicated to loading or storing memory; this occurred as a side effect of assignment to certain A registers. Setting A1 through A5 loaded the word at that address into X1 through X5 respectively; setting A6 or A7 stored a word from X6 or X7. No side effects were associated with A0. A separate hardware load/store unit, called the \"stunt box\", handled the actual data movement independently of the operation of the instruction stream, allowing other operations to complete while memory was being accessed, which required eight cycles, in the best case.\nThe 6600 CP included ten parallel functional units, allowing multiple instructions to be worked on at the same time. Today, this is known as a superscalar processor design, but it was unique for its time. Unlike most modern CPU designs, functional units were not pipelined; the functional unit would become busy when an instruction was \"issued\" to it and would remain busy for the entire time required to execute that instruction. (By contrast, the CDC 7600 introduced pipelining into its functional units.) In the best case, an instruction could be issued to a functional unit every 100\u00a0ns clock cycle. The system read and decoded instructions from memory as fast as possible, generally faster than they could be completed, and fed them off to the units for processing. The units were:\nFloating-point operations were given pride of place in this architecture: the CDC 6600 (and kin) stand virtually alone in being able to execute a 60-bit floating point multiplication in time comparable to that for a program branch.\nA recent analysis by Mitch Alsup of James Thornton's book, \"Design of a Computer\",\nrevealed that the 6600's Floating Point unit is a 2 stage pipelined design.\nFixed point addition and subtraction of 60-bit numbers were handled in the Long Add Unit, using ones' complement for negative numbers. Fixed point multiply was done as a special case in the floating-point multiply unit\u2014if the exponent was zero, the FP unit would do a single-precision 48-bit floating-point multiply and clear the high exponent part, resulting in a 48-bit integer result. Integer divide was performed by a macro, converting to and from floating point.\nPreviously executed instructions were saved in an eight-word cache, called the \"stack\". In-stack jumps were quicker than out-of-stack jumps because no memory fetch was required. The stack was flushed by an unconditional jump instruction, so unconditional jumps at the ends of loops were conventionally written as conditional jumps that would always succeed.\nThe system used a 10\u00a0MHz clock, with a four-phase signal. A floating-point multiplication took ten cycles, a division took 29, and the overall performance, taking into account memory delays and other issues, was about 3\u00a0MFLOPS. Using the best available compilers, late in the machine's history, FORTRAN programs could expect to maintain about 0.5\u00a0MFLOPS.\nMemory organization.\nUser programs are restricted to use only a contiguous area of main memory. The portion of memory to which an executing program has access is controlled by the \"RA\" (Relative Address) and \"FL\" (Field Length) registers which are not accessible to the user program. When a user program tries to read or write a word in central memory at address \"a\", the processor will first verify that a is between 0 and FL-1. If it is, the processor accesses the word in central memory at address RA+a. This process is known as base-bound relocation; each user program sees core memory as a contiguous block words with length FL, starting with address 0; in fact the program may be anywhere in the physical memory. Using this technique, each user program can be moved (\"relocated\") in main memory by the operating system, as long as the RA register reflects its position in memory. A user program which attempts to access memory outside the allowed range (that is, with an address which is not less than FL) will trigger an interrupt, and will be terminated by the operating system. When this happens, the operating system may create a core dump which records the contents of the program's memory and registers in a file, allowing the developer of the program a means to know what happened. Note the distinction with virtual memory systems; in this case, the entirety of a process's addressable space must be in core memory, must be contiguous, and its size cannot be larger than the real memory capacity.\nAll but the first seven CDC 6000 series machines could be configured with an optional Extended Core Storage (ECS) system. ECS was built from a different variety of core memory than was used in the central memory. This memory was slower, but cheap enough that it could be much larger. The primary reason was that ECS memory was wired with only two wires per core (contrast with five for central memory). Because it performed very wide transfers, its sequential transfer rate was the same as that of the small core memory. A 6000 CPU could directly perform block memory transfers between a user's program (or operating system) and the ECS unit. Wide data paths were used, so this was a very fast operation. Memory bounds were maintained in a similar manner as central memory, with an RA/FL mechanism maintained by the operating system. ECS could be used for a variety of purposes, including containing user data arrays that were too large for central memory, holding often-used files, swapping, and even as a communication path in a multi-mainframe complex.\nPeripheral Processors (PPs).\nTo handle the \"housekeeping\" tasks, which in other designs were assigned to the CPU, Cray included ten other processors, based partly on his earlier computer, the CDC 160-A. These machines, called Peripheral Processors, or PPs, were full computers in their own right, but were tuned to performing I/O tasks and running the operating system. (Substantial parts of the operating system ran on the PP's; thus leaving most of the power of the Central Processor available for user programs.) Only the PPs had access to the I/O channels. One of the PPs (PP0) was in overall control of the machine, including control of the program running on the main CPU, while the others would be dedicated to various I/O tasks; PP9 was dedicated to the system console. When the CP program needed to perform an operating system function, it would put a request in a known location (\"Reference Address\" + 1) monitored by PP0. If necessary, PP0 would assign another PP to load any necessary code and to handle the request. The PP would then clear RA+1 to inform the CP program that the task was complete.\nThe unique role of PP0 in controlling the machine was a potential single point of failure, in that a malfunction here could shut down the whole machine, even if the nine other PPs and the CPU were still functioning properly. Cray fixed this in the design of the successor 7600, when any of the PPs could be the controller, and the CPU could reassign any one to this role.\nEach PP included its own memory of 4096 12-bit words. This memory served for both for I/O buffering and program storage, but the execution units were shared by ten PPs, in a configuration called the Barrel and slot. This meant that the execution units (the \"slot\") would execute one instruction cycle from the first PP, then one instruction cycle from the second PP, etc. in a round robin fashion. This was done both to reduce costs, and because access to CP memory required 10 PP clock cycles: when a PP accesses CP memory, the data is available next time the PP receives its slot time.\nCentral Processor access.\nIn addition to a conventional instruction set, the PPs have several instructions specifically intended to communicate with the central processor.\nWordlengths, characters.\nThe central processor has 60-bit words, while the peripheral processors have 12-bit words. CDC used the term \"byte\" to refer to 12-bit entities used by peripheral processors; characters are 6-bit, and central processor instructions are either 15 bits, or 30 bits with a signed 18-bit address field, the latter allowing for a directly addressable memory space of 128K words of central memory (converted to modern terms, with 8-bit bytes, this just under 1\u00a0MB). The signed nature of the address registers limits an individual program to 128K words. (Later CDC 6000-compatible machines could have 256K or more words of central memory, budget permitting, but individual user programs were still limited to 128K words of CM.) Central processor instructions start on a word boundary when they are the target of a jump statement or subroutine return jump instruction, so no-op instructions are sometimes required to fill out the last 15, 30 or 45 bits of a word. Experienced assembler programmers could fine-tune their programs by filling these \"no-op\" spaces with misc instructions that would be needed later in the program.\nThe 6-bit characters, in an encoding called CDC display code, could be used to store up to 10 characters in a word. They permitted a character set of 64 characters, which is enough for all upper case letters, digits, and some punctuation. It was certainly enough to write FORTRAN, or print financial or scientific reports. There were actually two variations of the CDC display code character sets in use\u00a0\u2014 64-character and 63-character. The 64-character set had the disadvantage that the \":\" (colon) character would be ignored (interpreted as zero fill) if it were the last character in a word. A complementary variant, called 6/12 display code, was also used in the Kronos and NOS timesharing systems to allow full use of the ASCII character set in a manner somewhat compatible with older software.\nWith no byte addressing instructions at all, code had to be written to pack and shift characters into words. The very large words, and comparatively small amount of memory, meant that programmers would frequently economize on memory by packing data into words at the bit level.\nDue to the large word size, and with 10 characters per word, it was often faster to process a word's worth of characters at a time, rather than unpacking/processing/repacking them. For example, the CDC COBOL compiler was actually quite good at processing decimal fields using this technique. These sorts of techniques are now commonly used in the vector instructions of current processors, such as AVX.\nPhysical design.\nThe machine was built in a plus-sign-shaped cabinet with a pump and heat exchanger in the outermost of each of the four arms. Cooling was done with Freon circulating within the machine and exchanging heat to an external chilled water supply. Each arm could hold four chassis, each about thick, hinged near the center, and opening a bit like a book. The intersection of the \"plus\" was filled with cables that interconnected the chassis. The chassis were numbered from 1 (containing all 10 PPUs and their memories, as well as the 12 rather minimal I/O channels) to 16. The main memory for the CPU was spread over many of the chassis. In a system with only 64K words of main memory, one of the arms of the \"plus\" was omitted.\nThe logic of the machine was packaged into modules about square and about thick. Each module had a connector (30 pins, two vertical rows of 15) on one edge, and six test points on the opposite edge. The module was placed between two aluminum cold plates to remove heat. The module consisted of two parallel printed circuit boards, with components mounted either on one of the boards or between the two boards. This provided a very dense package; generally impossible to repair, but with good heat transfer characteristics. It was known as cordwood construction.\nOperating system and programming.\nThere was a sore point with the 6600 operating system support\u00a0\u2014 slipping timelines. The machines originally ran a very simple job-control system known as COS (Chippewa Operating System), which was quickly \"thrown together\" based on the earlier CDC 3000 operating system in order to have something running to test the systems for delivery. However the machines were intended to be delivered with a much more powerful system known as SIPROS (for Simultaneous Processing Operating System), which was being developed at the company's System Sciences Division in Los Angeles. Customers were impressed with SIPROS' feature list, and many had SIPROS written into their delivery contracts.\nSIPROS turned out to be a major fiasco. Development timelines continued to slip, costing CDC major amounts of profit in the form of delivery delay penalties. After several months of waiting with the machines ready to be shipped, the project was eventually cancelled. The programmers who had worked on COS had little faith in SIPROS and had continued working on improving COS.\nOperating system development then split into two camps. The CDC-sanctioned evolution of COS was undertaken at the Sunnyvale, California software development laboratory. Many customers eventually took delivery of their systems with this software, then known as SCOPE (Supervisory Control Of Program Execution). SCOPE version 1 was, essentially, dis-assembled COS; SCOPE version 2 included new device and file system support; SCOPE version 3 included permanent file support, EI/200 remote batch support, and INTERCOM time-sharing support. SCOPE always had significant reliability and maintainability issues. \nThe underground evolution of COS took place at the Arden Hills, Minnesota assembly plant. MACE ([Greg] Mansfield And [Dave] Cahlander Executive) was written largely by a single programmer in the off-hours when machines were available. Its feature set was essentially the same as COS and SCOPE 1. It retained the earlier COS file system, but made significant advances in code modularity to improve system reliability and adaptiveness to new storage devices. MACE was never an official product, although many customers were able to wrangle a copy from CDC.\nThe unofficial MACE software was later chosen over the official SCOPE product as the basis of the next CDC operating system, Kronos, named after the Greek god of time. The main marketing reason for its adoption was the development of its TELEX time-sharing feature and its BATCHIO remote batch feature. Kronos continued to use the COS/SCOPE 1 file system with the addition of a permanent file feature.\nAn attempt to unify the SCOPE and Kronos operating system products produced NOS, (Network Operating System). NOS was intended to be the sole operating system for all CDC machines, a fact CDC promoted heavily. Many SCOPE customers remained software-dependent on the SCOPE architecture, so CDC simply renamed it NOS/BE (Batch Environment), and were able to claim that everyone was thus running NOS. In practice, it was far easier to modify the Kronos code base to add SCOPE features than the reverse.\nThe assembly plant environment also produced other operating systems which were never intended for customer use. These included the engineering tools SMM for hardware testing, and KALEIDOSCOPE, for software smoke testing. Another commonly used tool for CDC Field Engineers during testing was MALET (Maintenance Application Language for Equipment Testing), which was used to stress test components and devices after repairs or servicing by engineers. Testing conditions often used hard disk packs and magnetic tapes which were deliberately marked with errors to determine if the errors would be detected by MALET and the engineer.\nThe names SCOPE and COMPASS were used by CDC for both the CDC 6000 series, including the 6600, and the CDC 3000 series:\nCDC 7600.\nThe CDC 7600 was originally intended to be fully compatible with the existing 6000-series machines as well; it started life known as the CDC 6800. But during its design, the designers determined that maintaining complete compatibility with the existing 6000-series machines would limit how much performance improvement they could attain and decided to sacrifice compatibility for performance. While the CDC 7600's CPU was basically instruction compatible with the 6400 and 6600 CPUs, allowing code portability at the high-level language source code level, the CDC 7600's hardware, especially that of its Peripheral Processor Units (PPUs), was quite different, and the CDC 7600 required a different operating system. This turned out to be somewhat serendipitous because it allowed the designers to improve on some of the characteristics of the 6000-series design, such as the latter's complete dependence on Peripheral Processors (PPs), particularly the first (called PP0), to control operation of the entire computer system, including the CPU(s). Unlike the 6600 CPU, the CDC 7600's CPU could control its own operation via a Central Exchange jump (XJ) instruction that swapped all register contents with core memory. In fact, the 6000-series machines were retrofitted with this capability.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58662", "revid": "2175", "url": "https://en.wikipedia.org/wiki?curid=58662", "title": "Vector processing", "text": ""}
{"id": "58663", "revid": "411604", "url": "https://en.wikipedia.org/wiki?curid=58663", "title": "System 370", "text": ""}
{"id": "58664", "revid": "47890572", "url": "https://en.wikipedia.org/wiki?curid=58664", "title": "Gas-turbine engine", "text": "Type of internal and continuous combustion engine\nA gas turbine engine, or, informally, a gas turbine, is a type of continuous flow internal combustion engine. The main parts common to all gas turbine engines form the power-producing part (known as the gas generator or core) and are, in the direction of flow:\nAdditional components have to be added to the gas generator to suit its application. Common to all is an air inlet but with different configurations to suit the requirements of marine use, land use or flight at speeds varying from stationary to supersonic. A propelling nozzle is added to produce thrust for flight. An extra turbine is added to drive a propeller (turboprop) or ducted fan (turbofan) to reduce fuel consumption (by increasing propulsive efficiency) at subsonic flight speeds. An extra turbine is also required to drive a helicopter rotor or land-vehicle transmission (turboshaft), marine propeller or electrical generator (power turbine). Greater thrust-to-weight ratio for flight is achieved with the addition of an afterburner.\nThe basic operation of the gas turbine is a Brayton cycle with air as the working fluid: atmospheric air flows through the compressor that brings it to higher pressure; energy is then added by spraying fuel into the air and igniting it so that the combustion generates a high-temperature flow; this high-temperature pressurized gas enters a turbine, producing a shaft work output in the process, used to drive the compressor; the unused energy comes out in the exhaust gases that can be repurposed for external work, such as directly producing thrust in a turbojet engine, or rotating a second, independent turbine (known as a \"power turbine\") that can be connected to a fan, propeller, or electrical generator. The purpose of the gas turbine determines the design so that the most desirable split of energy between the thrust and the shaft work is achieved. The fourth step of the Brayton cycle (cooling of the working fluid) is omitted, as gas turbines are open systems that do not reuse the same air.\nGas turbines are used to power among others aircraft, trains, ships, electric generators, pumps, gas compressors, and tanks.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nTheory of operation.\nIn an ideal gas turbine, gases undergo four thermodynamic processes: an isentropic compression, an isobaric (constant pressure) combustion, an isentropic expansion and isobaric heat rejection. Together, these make up the Brayton cycle, also known as the \"constant pressure cycle\". It is distinguished from the Otto cycle, in that all the processes (compression, ignition combustion, exhaust), occur at the same time, continuously.\nIn a real gas turbine, mechanical energy is changed irreversibly (due to internal friction and turbulence) into pressure and thermal energy when the gas is compressed (in either a centrifugal or axial compressor). Heat is added in the combustion chamber and the specific volume of the gas increases, accompanied by a slight loss in pressure. During expansion through the stator and rotor passages in the turbine, irreversible energy transformation once again occurs. Fresh air is taken in, in place of the heat rejection.\nAir is taken in by a compressor, called a gas generator, with either an axial or centrifugal design, or a combination of the two. This air is then ducted into the combustor section which can be of a annular, can, or can-annular design. In the combustor section, roughly 70% of the air from the compressor is ducted around the combustor itself for cooling purposes. The remaining roughly 30% the air is mixed with fuel and ignited by the already burning air-fuel mixture, which then expands producing power across the turbine. This expansion of the mixture then leaves the combustor section and has its velocity increased across the turbine section to strike the turbine blades, spinning the disc they are attached to, thus creating useful power. Of the power produced, 60-70% is solely used to power the gas generator. The remaining power is used to power what the engine is being used for, typically an aviation application, being thrust in a turbojet, driving the fan of a turbofan, rotor or accessory of a turboshaft, and gear reduction and propeller of a turboprop.\nIf the engine has a power turbine added to drive an industrial generator or a helicopter rotor, the exit pressure will be as close to the entry pressure as possible with only enough energy left to overcome the pressure losses in the exhaust ducting and expel the exhaust. For a turboprop engine there will be a particular balance between propeller power and jet thrust which gives the most economical operation. In a turbojet engine only enough pressure and energy is extracted from the flow to drive the compressor and other components. The remaining high-pressure gases are accelerated through a nozzle to provide a jet to propel an aircraft.\nThe smaller the engine, the higher the rotation rate of the shaft must be to attain the required blade tip speed. Blade-tip speed determines the maximum pressure ratios that can be obtained by the turbine and the compressor. This, in turn, limits the maximum power and efficiency that can be obtained by the engine. In order for tip speed to remain constant, if the diameter of a rotor is reduced by half, the rotational speed must double. For example, large jet engines operate around 10,000\u201325,000 rpm, while micro turbines spin as fast as 500,000\u00a0rpm.\nMechanically, gas turbines \"can\" be considerably less complex than Reciprocating engines. Simple turbines might have one main moving part, the compressor/shaft/turbine rotor assembly, with other moving parts in the fuel system. This, in turn, can translate into price. For instance, costing for materials, the Jumo 004 proved cheaper than the Junkers 213 piston engine, which was , and needed only 375 hours of lower-skill labor to complete (including manufacture, assembly, and shipping), compared to 1,400 for the BMW 801. This, however, also translated into poor efficiency and reliability. More advanced gas turbines (such as those found in modern jet engines or combined cycle power plants) may have 2 or 3 shafts (spools), hundreds of compressor and turbine blades, movable stator blades, and extensive external tubing for fuel, oil and air systems; they use temperature resistant alloys, and are made with tight specifications requiring precision manufacture. All this often makes the construction of a simple gas turbine more complicated than a piston engine.\nMoreover, to reach optimum performance in modern gas turbine power plants the gas needs to be prepared to exact fuel specifications. Fuel gas conditioning systems treat the natural gas to reach the exact fuel specification prior to entering the turbine in terms of pressure, temperature, gas composition, and the related Wobbe index.\nThe primary advantage of a gas turbine engine is its power to weight ratio. \nSince significant useful work can be generated by a relatively lightweight engine, gas turbines are perfectly suited for aircraft propulsion.\nThrust bearings and journal bearings are a critical part of a design. They are hydrodynamic oil bearings or oil-cooled rolling-element bearings. Foil bearings are used in some small machines such as micro turbines and also have strong potential for use in small gas turbines/auxiliary power units\nCreep.\nA major challenge facing turbine design, especially turbine blades, is reducing the creep that is induced by the high temperatures and stresses that are experienced during operation. Higher operating temperatures are continuously sought in order to increase efficiency, but come at the cost of higher creep rates. Several methods have therefore been employed in an attempt to achieve optimal performance while limiting creep, with the most successful ones being high performance coatings and single crystal superalloys. These technologies work by limiting deformation that occurs by mechanisms that can be broadly classified as dislocation glide, dislocation climb and diffusional flow.\nProtective coatings provide thermal insulation of the blade and offer oxidation and corrosion resistance. Thermal barrier coatings (TBCs) are often stabilized zirconium dioxide-based ceramics and oxidation/corrosion resistant coatings (bond coats) typically consist of aluminides or MCrAlY (where M is typically Fe and/or Cr) alloys. Using TBCs limits the temperature exposure of the superalloy substrate, thereby decreasing the diffusivity of the active species (typically vacancies) within the alloy and reducing dislocation and vacancy creep. It has been found that a coating of 1\u2013200 \u03bcm can decrease blade temperatures by up to . \nBond coats are directly applied onto the surface of the substrate using pack carburization and serve the dual purpose of providing improved adherence for the TBC and oxidation resistance for the substrate. The Al from the bond coats forms Al2O3 on the TBC-bond coat interface which provides the oxidation resistance, but also results in the formation of an undesirable interdiffusion (ID) zone between itself and the substrate. The oxidation resistance outweighs the drawbacks associated with the ID zone as it increases the lifetime of the blade and limits the efficiency losses caused by a buildup on the outside of the blades.\nNickel-based superalloys boast improved strength and creep resistance due to their composition and resultant microstructure. The gamma (\u03b3) FCC nickel is alloyed with aluminum and titanium in order to precipitate a uniform dispersion of the coherent gamma-prime (\u03b3') phases. The finely dispersed \u03b3' precipitates impede dislocation motion and introduce a threshold stress, increasing the stress required for the onset of creep. Furthermore, \u03b3' is an ordered L12 phase that makes it harder for dislocations to shear past it. Further Refractory elements such as rhenium and ruthenium can be added in solid solution to improve creep strength. The addition of these elements reduces the diffusion of the gamma prime phase, thus preserving the fatigue resistance, strength, and creep resistance. The development of single crystal superalloys has led to significant improvements in creep resistance as well. Due to the lack of grain boundaries, single crystals eliminate Coble creep and consequently deform by fewer modes \u2013 decreasing the creep rate. Although single crystals have lower creep at high temperatures, they have significantly lower yield stresses at room temperature where strength is determined by the Hall-Petch relationship. Care needs to be taken in order to optimize the design parameters to limit high temperature creep while not decreasing low temperature yield strength.\nTypes.\nJet engines.\nAirbreathing jet engines are gas turbines optimized to produce thrust from the exhaust gases, or from ducted fans connected to the gas turbines. Jet engines that produce thrust from the direct impulse of exhaust gases are often called turbojets. While still in service with many militaries and civilian operators, turbojets have mostly been phased out in favor of the turbofan engine due to the turbojet's low fuel efficiency, and high noise. Those that generate thrust with the addition of a ducted fan are called turbofans or (rarely) fan-jets. These engines produce nearly 80% of their thrust by the ducted fan, which can be seen from the front of the engine. They come in two types, low-bypass turbofan and high bypass, the difference being the amount of air moved by the fan, called \"bypass air\". These engines offer the benefit of more thrust without extra fuel consumption.\nGas turbines are also used in many liquid-fuel rockets, where gas turbines are used to power a turbopump to permit the use of lightweight, low-pressure tanks, reducing the empty weight of the rocket.\nTurboprop engines.\nA turboprop engine is a turbine engine that drives an aircraft propeller using a reduction gear to translate high turbine section operating speed (often in the 10s of thousands) into low thousands necessary for efficient propeller operation. The benefit of using the turboprop engine is to take advantage of the turbine engines high power-to-weight ratio to drive a propeller, thus allowing a more powerful, but also smaller engine to be used. Turboprop engines are used on a wide range of business aircraft such as the Pilatus PC-12, commuter aircraft such as the Beechcraft 1900, and small cargo aircraft such as the Cessna 208 Caravan or De Havilland Canada Dash 8, and large aircraft (typically military) such as the Airbus A400M transport, Lockheed AC-130 and the 60-year-old Tupolev Tu-95 strategic bomber. While military turboprop engines can vary, in the civilian market there are two primary engines to be found: the Pratt &amp; Whitney Canada PT6, a free-turbine turboshaft engine, and the Honeywell TPE331, a fixed turbine engine (formerly designated as the Garrett AiResearch 331).\nAeroderivative gas turbines.\nAeroderivative gas turbines are generally based on existing aircraft gas turbine engines and are smaller and lighter than industrial gas turbines.\nAeroderivatives are used in electrical power generation due to their ability to be shut down and handle load changes more quickly than industrial machines. They are also used in the marine industry to reduce weight. Common types include the General Electric LM2500, General Electric LM6000, and aeroderivative versions of the Pratt &amp; Whitney PW4000, Pratt &amp; Whitney FT4 and Rolls-Royce RB211.\nAmateur gas turbines.\nIncreasing numbers of gas turbines are being used or even constructed by amateurs.\nIn its most straightforward form, these are commercial turbines acquired through military surplus or scrapyard sales, then operated for display as part of the hobby of engine collecting. In its most extreme form, amateurs have even rebuilt engines beyond professional repair and then used them to compete for the land speed record.\nThe simplest form of self-constructed gas turbine employs an automotive turbocharger as the core component. A combustion chamber is fabricated and plumbed between the compressor and turbine sections.\nMore sophisticated turbojets are also built, where their thrust and light weight are sufficient to power large model aircraft. The Schreckling design constructs the entire engine from raw materials, including the fabrication of a centrifugal compressor wheel from plywood, epoxy and wrapped carbon fibre strands.\nSeveral small companies now manufacture small turbines and parts for the amateur. Most turbojet-powered model aircraft are now using these commercial and semi-commercial microturbines, rather than a Schreckling-like home-build.\nAuxiliary power units.\nSmall gas turbines are used as auxiliary power units (APUs) to supply auxiliary power to larger, mobile, machines such as an aircraft, and are a turboshaft design. They supply:\nIndustrial gas turbines for power generation.\nIndustrial gas turbines differ from aeronautical designs in that the frames, bearings, and blading are of heavier construction. They are also much more closely integrated with the devices they power\u2014often an electric generator\u2014and the secondary-energy equipment that is used to recover residual energy (largely heat).\nThey range in size from portable mobile plants to large, complex systems weighing more than a hundred tonnes housed in purpose-built buildings. When the gas turbine is used solely for shaft power, its thermal efficiency is about 30%. However, it may be cheaper to buy electricity than to generate it. Therefore, many engines are used in CHP (Combined Heat and Power) configurations that can be small enough to be integrated into portable container configurations.\nGas turbines can be particularly efficient when waste heat from the turbine is recovered by a heat recovery steam generator (HRSG) to power a conventional steam turbine in a combined cycle configuration. The 605 MW General Electric 9HA achieved a 62.22% efficiency rate with temperatures as high as .\nFor 2018, GE offers its 826 MW HA at over 64% efficiency in combined cycle due to advances in additive manufacturing and combustion breakthroughs, up from 63.7% in 2017 orders and on track to achieve 65% by the early 2020s.\nIn March 2018, GE Power achieved a 63.08% gross efficiency for its 7HA turbine.\nAeroderivative gas turbines can also be used in combined cycles, leading to a higher efficiency, but it will not be as high as a specifically designed industrial gas turbine. They can also be run in a cogeneration configuration: the exhaust is used for space or water heating, or drives an absorption chiller for cooling the inlet air and increase the power output, technology known as turbine inlet air cooling.\nAnother significant advantage is their ability to be turned on and off within minutes, supplying power during peak, or unscheduled, demand. Since single cycle (gas turbine only) power plants are less efficient than combined cycle plants, they are usually used as peaking power plants, which operate anywhere from several hours per day to a few dozen hours per year\u2014depending on the electricity demand and the generating capacity of the region. In areas with a shortage of base-load and load following power plant capacity or with low fuel costs, a gas turbine powerplant may regularly operate most hours of the day. A large single-cycle gas turbine typically produces 100 to 400\u00a0megawatts of electric power and has 35\u201340% thermodynamic efficiency.\nIndustrial gas turbines for mechanical drive.\nIndustrial gas turbines that are used solely for mechanical drive or used in collaboration with a recovery steam generator differ from power generating sets in that they are often smaller and feature a dual shaft design as opposed to a single shaft. The power range varies from 1 megawatt up to 50 megawatts. These engines are connected directly or via a gearbox to either a pump or compressor assembly. The majority of installations are used within the oil and gas industries. Mechanical drive applications increase efficiency by around 2%.\nOil and gas platforms require these engines to drive compressors to inject gas into the wells to force oil up via another bore, or to compress the gas for transportation. They are also often used to provide power for the platform. These platforms do not need to use the engine in collaboration with a CHP system due to getting the gas at an extremely reduced cost (often free from burn off gas). The same companies use pump sets to drive the fluids to land and across pipelines in various intervals.\nCompressed air energy storage.\nOne modern development seeks to improve efficiency in another way, by separating the compressor and the turbine with a compressed air store. In a conventional turbine, up to half the generated power is used driving the compressor. In a compressed air energy storage configuration, power is used to drive the compressor, and the compressed air is released to operate the turbine when required.\nTurboshaft engines.\nTurboshaft engines are used to drive compressors in gas pumping stations and natural gas liquefaction plants. They are also used in aviation to power all but the smallest modern helicopters, and function as an auxiliary power unit in large commercial aircraft. A primary shaft carries the compressor and its turbine which, together with a combustor, is called a gas generator. A separately spinning power-turbine is usually used to drive the rotor on helicopters. Allowing the gas generator and power turbine/rotor to spin at their own speeds allows more flexibility in their design.\nScale jet engine.\nA typical scale jet engine, or miniature gas turbine or micro-jet, uses a centrifugal compressor.\nThe pioneer of modern micro-jets, Kurt Schreckling, produced one of the world's first micro-turbines, the FD3/67. This engine can produce up to 22 newtons of thrust and can be built by most mechanically minded people with basic engineering tools, such as a metal lathe.\nMicroturbines.\nEvolved from piston engine turbochargers, aircraft APUs or small jet engines, microturbines are 25 to 500 kilowatt turbines the size of a refrigerator.\nMicroturbines have around 15% efficiencies without a recuperator, or 20 to 30% with one, and they can reach 85% combined thermal\u2013electrical efficiency in cogeneration.\nExternal combustion.\nMost gas turbines are internal combustion engines but it is also possible to manufacture an external combustion gas turbine which is, effectively, a turbine version of a hot air engine.\nThose systems are usually indicated as EFGT (externally fired gas turbine) or IFGT (indirectly fired gas turbine).\nExternal combustion has been used for the purpose of using pulverized coal or finely ground biomass (such as sawdust) as a fuel. In the indirect system, a heat exchanger is used and only clean air with no combustion products travels through the power turbine. The thermal efficiency is lower in the indirect type of external combustion; however, the turbine blades are not subjected to combustion products and much lower quality (and therefore cheaper) fuels are able to be used.\nWhen external combustion is used, it is possible to use exhaust air from the turbine as the primary combustion air. This effectively reduces global heat losses, although heat losses associated with the combustion exhaust remain inevitable.\nClosed-cycle gas turbines based on helium or supercritical carbon dioxide also hold promise for use with future high temperature solar and nuclear power generation.\nIn surface vehicles.\nGas turbines are often used on ships, locomotives, helicopters, and tanks and, to a lesser extent, on cars, buses, and motorcycles.\nA key advantage of jets and turboprops for airplane propulsion \u2013 their superior performance at high altitude compared to piston engines, particularly naturally aspirated ones \u2013 is irrelevant in most automobile applications. Their power-to-weight advantage, though less critical than for aircraft, is still important.\nGas turbines offer a high-powered engine in a very small and light package. However, they are not as responsive and efficient as small piston engines over the wide range of engine speed and power needed in vehicle applications. In series hybrid vehicles, as the driving electric motors are mechanically detached from the electricity-generating engine, the problems of responsiveness, poor performance at low speed, and low efficiency at low output are much less important. The turbine can be run at optimum speed for its power output, and batteries and ultracapacitors can supply power as needed, with the engine cycled on and off to run it only at high efficiency. The emergence of the continuously variable transmission may also alleviate the responsiveness problem.\nTurbines have historically been more expensive to produce than piston engines, though this is partly because piston engines have been mass-produced in huge quantities for decades, while small gas turbine engines are rarities; however, turbines are mass-produced in the closely related form of the turbocharger.\nThe turbocharger is basically a compact and simple free shaft radial gas turbine which is driven by the piston engine's exhaust gas. The centripetal turbine wheel drives a centrifugal compressor wheel through a common rotating shaft. This wheel supercharges the engine air intake to a degree that can be controlled by means of a wastegate or by dynamically modifying the turbine housing's geometry (as in a variable geometry turbocharger).\nIt mainly serves as a power recovery device which converts a great deal of otherwise wasted thermal and kinetic energy into engine boost.\nTurbo-compound engines (actually employed on some semi-trailer trucks) are fitted with blow down turbines which are similar in design and appearance to a turbocharger except for the turbine shaft being mechanically or hydraulically connected to the engine's crankshaft instead of to a centrifugal compressor, thus providing additional power instead of boost. While the turbocharger is a pressure turbine, a power recovery turbine is a velocity one.\nPassenger road vehicles (cars, bikes, and buses).\nA number of experiments have been conducted with gas turbine powered automobiles, the largest by Chrysler. More recently, there has been some interest in the use of turbine engines for hybrid electric cars. For instance, a consortium led by micro gas turbine company Bladon Jets has secured investment from the Technology Strategy Board to develop an Ultra Lightweight Range Extender (ULRE) for next-generation electric vehicles. The objective of the consortium, which includes luxury car maker Jaguar Land Rover and leading electrical machine company SR Drives, is to produce the world's first commercially viable \u2013 and environmentally friendly \u2013 gas turbine generator designed specifically for automotive applications.\nThe common turbocharger for gasoline or diesel engines is also a turbine derivative.\nConcept cars.\nThe first serious investigation of using a gas turbine in cars was in 1946 when two engineers, Robert Kafka and Robert Engerstein of Carney Associates, a New York engineering firm, came up with the concept where a unique compact turbine engine design would provide power for a rear wheel drive car. After an article appeared in \"Popular Science\", there was no further work, beyond the paper stage.\nIn 1950, designer F.R. Bell and Chief Engineer Maurice Wilks from British car manufacturers Rover unveiled the first car powered with a gas turbine engine. The two-seater JET1 had the engine positioned behind the seats, air intake grilles on either side of the car, and exhaust outlets on the top of the tail. During tests, the car reached top speeds of , at a turbine speed of 50,000\u00a0rpm. After being shown in the United Kingdom and the United States in 1950, JET1 was further developed, and was subjected to speed trials on the Jabbeke highway in Belgium in June 1952, where it exceeded . The car ran on petrol, paraffin (kerosene) or diesel oil, but fuel consumption problems proved insurmountable for a production car. JET1 is on display at the London Science Museum.\nA French turbine-powered car, the SOCEMA-Gr\u00e9goire, was displayed at the October 1952 Paris Auto Show. It was designed by the French engineer Jean-Albert Gr\u00e9goire.\nThe first turbine-powered car built in the US was the GM Firebird I which began evaluations in 1953. While photos of the Firebird I may suggest that the jet turbine's thrust propelled the car like an aircraft, the turbine actually drove the rear wheels. The Firebird I was never meant as a commercial passenger car and was built solely for testing &amp; evaluation as well as public relation purposes. Additional Firebird concept cars, each powered by gas turbines, were developed for the 1953, 1956 and 1959 Motorama auto shows. The GM Research gas turbine engine also was fitted to a series of transit buses, starting with the Turbo-Cruiser I of 1953.\nStarting in 1954 with a modified Plymouth, the American car manufacturer Chrysler demonstrated several prototype gas turbine-powered cars from the early 1950s through the early 1980s. Chrysler built fifty Chrysler Turbine Cars in 1963 and conducted the only consumer trial of gas turbine-powered cars. Each of their turbines employed a unique rotating recuperator, referred to as a regenerator that increased efficiency.\nIn 1954, Fiat unveiled a concept car with a turbine engine, called Fiat Turbina. This vehicle, looking like an aircraft with wheels, used a unique combination of both jet thrust and the engine driving the wheels. Speeds of were claimed.\nIn the 1960s, Ford and GM also were developing gas turbine semi-trucks. Ford displayed the Big Red at the 1964 World's Fair. With the trailer, it was long, high, and painted crimson red. It contained the Ford-developed gas turbine engine, with output power and torque of and . The cab boasted a highway map of the continental U.S., a mini-kitchen, bathroom, and a TV for the co-driver. The fate of the truck was unknown for several decades, but it was rediscovered in early 2021 in private hands, having been restored to running order. The Chevrolet division of GM built the \"Turbo Titan\" series of concept trucks with turbine motors as analogs of the Firebird concepts, including Turbo Titan I (c.\u20091959, shares GT-304 engine with Firebird II), Turbo Titan II (c.\u20091962, shares GT-305 engine with Firebird III), and Turbo Titan III (1965, GT-309 engine); in addition, the GM Bison gas turbine truck was shown at the 1964 World's Fair.\nAs a result of the U.S. Clean Air Act Amendments of 1970, research was funded into developing automotive gas turbine technology. Design concepts and vehicles were conducted by Chrysler, General Motors, Ford (in collaboration with AiResearch), and American Motors (in conjunction with Williams Research). Long-term tests were conducted to evaluate comparable cost efficiency. Several AMC Hornets were powered by a small Williams regenerative gas turbine weighing and producing at 4450\u00a0rpm.\nIn 1982, General Motors used an Oldsmobile Delta 88 powered by a gas turbine using pulverised coal dust. This was considered for the United States and the western world to reduce dependence on middle east oil at the time\nToyota demonstrated several gas turbine powered concept cars, such as the Century gas turbine hybrid in 1975, the Sports 800 Gas Turbine Hybrid in 1979 and the GTV in 1985. No production vehicles were made. The GT24 engine was exhibited in 1977 without a vehicle.\nIn the early 1990s, Volvo introduced the Volvo ECC which was a gas turbine powered hybrid electric vehicle.\nIn 1993, General Motors developed a gas turbine powered EV1 series hybrid\u2014as a prototype of the General Motors EV1. A Williams International 40\u00a0kW turbine drove an alternator which powered the battery\u2013electric powertrain. The turbine design included a recuperator. In 2006, GM went into the EcoJet concept car project with Jay Leno.\nAt the 2010 Paris Motor Show Jaguar demonstrated its Jaguar C-X75 concept car. This electrically powered supercar has a top speed of and can go from in 3.4 seconds. It uses lithium-ion batteries to power four electric motors which combine to produce 780\u00a0bhp. It will travel on a single charge of the batteries, and uses a pair of Bladon Micro Gas Turbines to re-charge the batteries extending the range to .\nRacing cars.\nThe first race car (in concept only) fitted with a turbine was in 1955 by a US Air Force group as a hobby project with a turbine loaned them by Boeing and a race car owned by Firestone Tire &amp; Rubber company. The first race car fitted with a turbine for the goal of actual racing was by Rover and the BRM Formula One team joined forces to produce the Rover-BRM, a gas turbine powered coupe, which entered the 1963 24 Hours of Le Mans, driven by Graham Hill and Richie Ginther. It averaged and had a top speed of . American Ray Heppenstall joined Howmet Corporation and McKee Engineering together to develop their own gas turbine sports car in 1968, the Howmet TX, which ran several American and European events, including two wins, and also participated in the 1968 24 Hours of Le Mans. The cars used Continental gas turbines, which eventually set six FIA land speed records for turbine-powered cars.\nFor open wheel racing, 1967's revolutionary STP-Paxton Turbocar fielded by racing and entrepreneurial legend Andy Granatelli and driven by Parnelli Jones nearly won the Indianapolis 500; the Pratt &amp; Whitney ST6B-62 powered turbine car was almost a lap ahead of the second place car when a gearbox bearing failed just three laps from the finish line. The next year the STP Lotus 56 turbine car won the Indianapolis 500 pole position even though new rules restricted the air intake dramatically. In 1971 Team Lotus principal Colin Chapman introduced the Lotus 56B F1 car, powered by a Pratt &amp; Whitney STN 6/76 gas turbine. Chapman had a reputation of building radical championship-winning cars, but had to abandon the project because there were too many problems with turbo lag.\nBuses.\nGeneral Motors fitted the GT-30x series of gas turbines (branded \"Whirlfire\") to several prototype buses in the 1950s and 1960s, including Turbo-Cruiser I (1953, GT-300); Turbo-Cruiser II (1964, GT-309); Turbo-Cruiser III (1968, GT-309); RTX (1968, GT-309); and RTS 3T (1972).\nThe arrival of the Capstone Turbine has led to several hybrid bus designs, starting with HEV-1 by AVS of Chattanooga, Tennessee in 1999, and closely followed by Ebus and ISE Research in California, and DesignLine Corporation in New Zealand (and later the United States). AVS turbine hybrids were plagued with reliability and quality control problems, resulting in liquidation of AVS in 2003. The most successful design by Designline is now operated in 5 cities in 6 countries, with over 30 buses in operation worldwide, and order for several hundred being delivered to Baltimore, and New York City.\nBrescia Italy is using serial hybrid buses powered by microturbines on routes through the historical sections of the city.\nMotorcycles.\nThe MTT Turbine Superbike appeared in 2000 (hence the designation of Y2K Superbike by MTT) and is the first production motorcycle powered by a turbine engine \u2013 specifically, a Rolls-Royce Allison model 250 turboshaft engine, producing about 283\u00a0kW (380\u00a0bhp). Speed-tested to 365\u00a0km/h or 227\u00a0mph (according to some stories, the testing team ran out of road during the test), it holds the Guinness World Record for most powerful production motorcycle and most expensive production motorcycle, with a price tag of US$185,000.\nTrains.\nSeveral locomotive classes have been powered by gas turbines, the most recent incarnation being Bombardier's JetTrain.\nTanks.\nThe Third Reich \"Wehrmacht Heer\"'s development division, the Heereswaffenamt (Army Ordnance Board), studied a number of gas turbine engine designs for use in tanks starting in mid-1944. The first gas turbine engine design intended for use in armored fighting vehicle propulsion, the BMW 003-based GT 101, was meant for installation in the Panther tank. Towards the end of the war, a Jagdtiger was fitted with one of the aforementioned gas turbines.\nThe second use of a gas turbine in an armored fighting vehicle was in 1954 when a unit, PU2979, specifically developed for tanks by C. A. Parsons and Company, was installed and trialed in a British Conqueror tank. The Stridsvagn 103 was developed in the 1950s and was the first mass-produced main battle tank to use a turbine engine, the Boeing T50. Since then, gas turbine engines have been used as auxiliary power units in some tanks and as main powerplants in Soviet/Russian T-80s and U.S. M1 Abrams tanks, among others. They are lighter and smaller than diesel engines at the same sustained power output but the models installed to date are less fuel efficient than the equivalent diesel, especially at idle, requiring more fuel to achieve the same combat range. Successive models of M1 have addressed this problem with battery packs or secondary generators to power the tank's systems while stationary, saving fuel by reducing the need to idle the main turbine. T-80s can mount three large external fuel drums to extend their range. Russia has stopped production of the T-80 in favor of the diesel-powered T-90 (based on the T-72), while Ukraine has developed the diesel-powered T-80UD and T-84 with nearly the power of the gas-turbine tank. The French Leclerc tank's diesel powerplant features the \"Hyperbar\" hybrid supercharging system, where the engine's turbocharger is completely replaced with a small gas turbine which also works as an assisted diesel exhaust turbocharger, enabling engine RPM-independent boost level control and a higher peak boost pressure to be reached (than with ordinary turbochargers). This system allows a smaller displacement and lighter engine to be used as the tank's power plant and effectively removes turbo lag. This special gas turbine/turbocharger can also work independently from the main engine as an ordinary APU.\nA turbine is theoretically more reliable and easier to maintain than a piston engine since it has a simpler construction with fewer moving parts, but in practice, turbine parts experience a higher wear rate due to their higher working speeds. The turbine blades are highly sensitive to dust and fine sand so that in desert operations air filters have to be fitted and changed several times daily. An improperly fitted filter, or a bullet or shell fragment that punctures the filter, can damage the engine. Piston engines (especially if turbocharged) also need well-maintained filters, but they are more resilient if the filter does fail.\nLike most modern diesel engines used in tanks, gas turbines are usually multi-fuel engines.\nMarine applications.\nNaval.\nGas turbines are used in many naval vessels, where they are valued for their high power-to-weight ratio and their ships' resulting acceleration and ability to get underway quickly.\nThe first gas-turbine-powered naval vessel was the Royal Navy's motor gunboat \"MGB 2009\" (formerly \"MGB 509\") converted in 1947. Metropolitan-Vickers fitted their F2/3 jet engine with a power turbine. The Steam Gun Boat \"Grey Goose\" was converted to Rolls-Royce gas turbines in 1952 and operated as such from 1953. The Bold class Fast Patrol Boats \"Bold Pioneer\" and \"Bold Pathfinder\" built in 1953 were the first ships created specifically for gas turbine propulsion.\nThe first large-scale, partially gas-turbine powered ships were the Royal Navy's Type 81 (Tribal class) frigates with combined steam and gas powerplants. The first, was commissioned in 1961.\nThe German Navy launched the first in 1961 with 2 Brown, Boveri &amp; Cie gas turbines in the world's first combined diesel and gas propulsion system.\nThe Soviet Navy commissioned in 1962 the first of 25 with 4 gas turbines in combined gas and gas propulsion system. Those vessels used 4 M8E gas turbines, which generated . Those ships were the first large ships in the world to be powered solely by gas turbines.\nThe Danish Navy had 6 \"S\u00f8l\u00f8ven\"-class torpedo boats (the export version of the British Brave class fast patrol boat) in service from 1965 to 1990, which had 3 Bristol Proteus (later RR Proteus) Marine Gas Turbines rated at combined, plus two General Motors Diesel engines, rated at , for better fuel economy at slower speeds. And they also produced 10 Willemoes Class Torpedo / Guided Missile boats (in service from 1974 to 2000) which had 3 Rolls-Royce Marine Proteus Gas Turbines also rated at , same as the S\u00f8l\u00f8ven-class boats, and 2 General Motors Diesel Engines, rated at , also for improved fuel economy at slow speeds.\nThe Swedish Navy produced 6 Spica-class torpedo boats between 1966 and 1967 powered by 3 Bristol Siddeley Proteus 1282 turbines, each delivering . They were later joined by 12 upgraded Norrk\u00f6ping class ships, still with the same engines. With their aft torpedo tubes replaced by antishipping missiles they served as missile boats until the last was retired in 2005.\nThe Finnish Navy commissioned two corvettes, \"Turunmaa\" and \"Karjala\", in 1968. They were equipped with one Rolls-Royce Olympus TM1 gas turbine and three W\u00e4rtsil\u00e4 marine diesels for slower speeds. They were the fastest vessels in the Finnish Navy; they regularly achieved speeds of 35 knots, and 37.3 knots during sea trials. The \"Turunmaa\"s were decommissioned in 2002. \"Karjala\" is today a museum ship in Turku, and \"Turunmaa\" serves as a floating machine shop and training ship for Satakunta Polytechnical College.\nThe next series of major naval vessels were the four Canadian helicopter carrying destroyers first commissioned in 1972. They used 2\u00a0ft-4 main propulsion engines, 2\u00a0ft-12 cruise engines and 3 Solar Saturn 750\u00a0kW generators.\nThe first U.S. gas-turbine powered ship was the U.S. Coast Guard's , a cutter commissioned in 1961 that was powered by two turbines utilizing controllable-pitch propellers. The larger High Endurance Cutters, was the first class of larger cutters to utilize gas turbines, the first of which () was commissioned in 1967. Since then, they have powered the U.S. Navy's s, and s, and guided missile cruisers. , a modified , is to be the Navy's first amphibious assault ship powered by gas turbines.\nThe marine gas turbine operates in a more corrosive atmosphere due to the presence of sea salt in air and fuel and use of cheaper fuels.\nCivilian maritime.\nUp to the late 1940s, much of the progress on marine gas turbines all over the world took place in design offices and engine builder's workshops and development work was led by the British Royal Navy and other Navies. While interest in the gas turbine for marine purposes, both naval and mercantile, continued to increase, the lack of availability of the results of operating experience on early gas turbine projects limited the number of new ventures on seagoing commercial vessels being embarked upon.\nIn 1951, the diesel\u2013electric oil tanker \"Auris\", 12,290 deadweight tonnage (DWT) was used to obtain operating experience with a main propulsion gas turbine under service conditions at sea and so became the first ocean-going merchant ship to be powered by a gas turbine. Built by Hawthorn Leslie at Hebburn-on-Tyne, UK, in accordance with plans and specifications drawn up by the Anglo-Saxon Petroleum Company and launched on the UK's Princess Elizabeth's 21st birthday in 1947, the ship was designed with an engine room layout that would allow for the experimental use of heavy fuel in one of its high-speed engines, as well as the future substitution of one of its diesel engines by a gas turbine. The \"Auris\" operated commercially as a tanker for three-and-a-half years with a diesel\u2013electric propulsion unit as originally commissioned, but in 1951 one of its four diesel engines \u2013 which were known as \"Faith\", \"Hope\", \"Charity\" and \"Prudence\" \u2013 was replaced by the world's first marine gas turbine engine, a open-cycle gas turbo-alternator built by British Thompson-Houston Company in Rugby. Following successful sea trials off the Northumbrian coast, the \"Auris\" set sail from Hebburn-on-Tyne in October 1951 bound for Port Arthur in the US and then Cura\u00e7ao in the southern Caribbean returning to Avonmouth after 44 days at sea, successfully completing her historic trans-Atlantic crossing. During this time at sea the gas turbine burnt diesel fuel and operated without an involuntary stop or mechanical difficulty of any kind. She subsequently visited Swansea, Hull, Rotterdam, Oslo and Southampton covering a total of 13,211 nautical miles. The \"Auris\" then had all of its power plants replaced with a directly coupled gas turbine to become the first civilian ship to operate solely on gas turbine power.\nDespite the success of this early experimental voyage the gas turbine did not replace the diesel engine as the propulsion plant for large merchant ships. At constant cruising speeds the diesel engine simply had no peer in the vital area of fuel economy. The gas turbine did have more success in Royal Navy ships and the other naval fleets of the world where sudden and rapid changes of speed are required by warships in action.\nThe United States Maritime Commission were looking for options to update WWII Liberty ships, and heavy-duty gas turbines were one of those selected. In 1956 the \"John Sergeant\" was lengthened and equipped with a General Electric HD gas turbine with exhaust-gas regeneration, reduction gearing and a variable-pitch propeller. It operated for 9,700 hours using residual fuel (Bunker C) for 7,000 hours. Fuel efficiency was on a par with steam propulsion at per hour, and power output was higher than expected at due to the ambient temperature of the North Sea route being lower than the design temperature of the gas turbine. This gave the ship a speed capability of 18 knots, up from 11 knots with the original power plant, and well in excess of the 15 knot targeted. The ship made its first transatlantic crossing with an average speed of 16.8 knots, in spite of some rough weather along the way. Suitable Bunker C fuel was only available at limited ports because the quality of the fuel was of a critical nature. The fuel oil also had to be treated on board to reduce contaminants and this was a labor-intensive process that was not suitable for automation at the time. Ultimately, the variable-pitch propeller, which was of a new and untested design, ended the trial, as three consecutive annual inspections revealed stress-cracking. This did not reflect poorly on the marine-propulsion gas-turbine concept though, and the trial was a success overall. The success of this trial opened the way for more development by GE on the use of HD gas turbines for marine use with heavy fuels. The \"John Sergeant\" was scrapped in 1972 at Portsmouth PA.\nBoeing launched its first passenger-carrying waterjet-propelled hydrofoil Boeing 929, in April 1974. Those ships were powered by two Allison 501-KF gas turbines.\nBetween 1971 and 1981, Seatrain Lines operated a scheduled container service between ports on the eastern seaboard of the United States and ports in northwest Europe across the North Atlantic with four container ships of 26,000 tonnes DWT. Those ships were powered by twin Pratt &amp; Whitney gas turbines of the FT 4 series. The four ships in the class were named \"Euroliner\", \"Eurofreighter\", \"Asialiner\" and \"Asiafreighter\". Following the dramatic Organization of the Petroleum Exporting Countries (OPEC) price increases of the mid-1970s, operations were constrained by rising fuel costs. Some modification of the engine systems on those ships was undertaken to permit the burning of a lower grade of fuel (i.e., marine diesel). Reduction of fuel costs was successful using a different untested fuel in a marine gas turbine but maintenance costs increased with the fuel change. After 1981 the ships were sold and refitted with, what at the time, was more economical diesel-fueled engines but the increased engine size reduced cargo space.\nThe first passenger ferry to use a gas turbine was the GTS \"Finnjet\", built in 1977 and powered by two Pratt &amp; Whitney FT 4C-1 DLF turbines, generating and propelling the ship to a speed of 31\u00a0knots. However, the Finnjet also illustrated the shortcomings of gas turbine propulsion in commercial craft, as high fuel prices made operating her unprofitable. After four years of service, additional diesel engines were installed on the ship to reduce running costs during the off-season. The Finnjet was also the first ship with a combined diesel\u2013electric and gas propulsion. Another example of commercial use of gas turbines in a passenger ship is Stena Line's HSS class fastcraft ferries. HSS 1500-class \"Stena Explorer\", \"Stena Voyager\" and \"Stena Discovery\" vessels use combined gas and gas setups of twin GE LM2500 plus GE LM1600 power for a total of . The slightly smaller HSS 900-class \"Stena Carisma\", uses twin ABB\u2013STAL GT35 turbines rated at gross. The \"Stena Discovery\" was withdrawn from service in 2007, another victim of too high fuel costs.\nIn July 2000, the \"Millennium\" became the first cruise ship to be powered by both gas and steam turbines. The ship featured two General Electric LM2500 gas turbine generators whose exhaust heat was used to operate a steam turbine generator in a COGES (combined gas electric and steam) configuration. Propulsion was provided by two electrically driven Rolls-Royce Mermaid azimuth pods. The liner uses a combined diesel and gas configuration.\nIn marine racing applications the 2010 C5000 Mystic catamaran Miss GEICO uses two Lycoming T-55 turbines for its power system.\nAdvances in technology.\nGas turbine technology has steadily advanced since its inception and continues to evolve. Development is actively producing both smaller gas turbines and more powerful and efficient engines. Aiding in these advances are computer-based design (specifically computational fluid dynamics and finite element analysis) and the development of advanced materials: Base materials with superior high-temperature strength (e.g., single-crystal superalloys that exhibit yield strength anomaly) or thermal barrier coatings that protect the structural material from ever-higher temperatures. These advances allow higher compression ratios and turbine inlet temperatures, more efficient combustion and better cooling of engine parts.\nComputational fluid dynamics (CFD) has contributed to substantial improvements in the performance and efficiency of gas turbine engine components through enhanced understanding of the complex viscous flow and heat transfer phenomena involved. For this reason, CFD is one of the key computational tools used in design and development of gas turbine engines.\nThe simple-cycle efficiencies of early gas turbines were practically doubled by incorporating inter-cooling, regeneration (or recuperation), and reheating. These improvements, of course, come at the expense of increased initial and operation costs, and they cannot be justified unless the decrease in fuel costs offsets the increase in other costs. The relatively low fuel prices, the general desire in the industry to minimize installation costs, and the tremendous increase in the simple-cycle efficiency to about 40 percent left little desire for opting for these modifications.\nOn the emissions side, the challenge is to increase turbine inlet temperatures while at the same time reducing peak flame temperature in order to achieve lower NOx emissions and meet the latest emission regulations. In May 2011, Mitsubishi Heavy Industries achieved a turbine inlet temperature of on a 320 megawatt gas turbine, and 460 MW in gas turbine combined-cycle power generation applications in which gross thermal efficiency exceeds 60%.\nCompliant foil bearings were commercially introduced to gas turbines in the 1990s. These can withstand over a hundred thousand start/stop cycles and have eliminated the need for an oil system. The application of microelectronics and power switching technology have enabled the development of commercially viable electricity generation by microturbines for distribution and vehicle propulsion.\nIn 2013, General Electric started the development of the GE9X with a compression ratio of 61:1.\nAdvantages and disadvantages.\nThe following are advantages and disadvantages of gas-turbine engines:\nAdvantages include:\nDisadvantages include:\nTesting.\nBritish, German, other national and international test codes are used to standardize the procedures and definitions used to test gas turbines. Selection of the test code to be used is an agreement between the purchaser and the manufacturer, and has some significance to the design of the turbine and associated systems. In the United States, ASME has produced several performance test codes on gas turbines. This includes ASME PTC 22\u20132014. These ASME performance test codes have gained international recognition and acceptance for testing gas turbines. The single most important and differentiating characteristic of ASME performance test codes, including PTC 22, is that the test uncertainty of the measurement indicates the quality of the test and is not to be used as a commercial tolerance.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58665", "revid": "1288213139", "url": "https://en.wikipedia.org/wiki?curid=58665", "title": "Inversions (novel)", "text": "1998 science fiction novel by Iain M. Banks\nInversions is a science fiction novel by Scottish writer Iain M. Banks, first published in 1998. Banks has said \"\"Inversions\" was an attempt to write a Culture novel that wasn't.\"\nPlot.\nThe book takes place on a fictional planet resembling Europe during the Late Middle Ages. A large empire broke up in the decade or so preceding the action, apparently from meteor or asteroid strikes that severely affected farming across much of the globe. The remnants of the empire still war with one another.\nThe narrative alternates chapter-by-chapter between two concurrent story-lines, with alternating chapter headings of The Doctor and The Bodyguard.\n\"The Doctor\".\nThe first storyline is presented as a written account from Oelph, publicly a doctor's assistant, but privately a spy for an individual identified only as \"Master\", to whom much of the account is addressed. Oelph is the assistant to Vosill, the personal doctor to King Quience of Haspidus\u2014and a woman. The latter is unheard of in the patriarchal kingdom, and is tolerated only because Vosill claims citizenship in the far-off country of Drezen. The King himself is appreciative of her and her talents, but nonetheless her elevated position in defiance of the kingdom's social mores inspires hostility among others of the court.\nOelph's account follows Vosill as she attends to the King regularly, as well as more charitable ministrations to the impoverished and those in need. Her methods are unconventional by kingdom standards, for example forgoing the use of leeches and instead using alcohol to \"kill the ill humours which can infect a wound,\" but are more often than not successful. This only serves to inspire more distrust amongst her detractors, notably including a number of Dukes as well as the King's Guard Commander, Adlain. On this topic, Oelph includes a transcript he claims to have found in Vosill's journal, purported to be an exchange between Duke Walen and Adlain in which they make an agreement, \"should it become necessary\", to covertly kidnap the lady doctor and have Nolieti, the King's chief torturer, \"put her to the question.\" Oelph notes that while the transcript appears to have been obtained under impossible circumstances, he somehow does not doubt its veracity.\nWhile Vosill attends to the King, Nolieti is murdered, nearly decapitated, presumably by his assistant Unoure. Vosill examines the body and determines that Unoure could not have killed his master, but her explanation is disregarded. Unoure is captured, but before he can be questioned he is found in his cell dead from a cut throat, apparently self-inflicted. Following this account Oelph includes another found transcript, this time between Walen and Duke Quettil, though Walen is unable to obtain Quettil's agreement for the use of Ralinge, his own chief torturer, in Walen's kidnapping plan. Some days later at a masked ball Walen is found murdered, this time by a stab to the heart. The Duke's murder disquiets much of the royal house, as it occurred in a room no one entered or left.\nResentment towards Vosill continues to build, particularly after King Quience begins implementing somewhat radical reforms, such as permitting commoners to own farmland without the oversight of a noble and the creation of city councils, reforms which Vosill has discussed with the King publicly and at length. Following these reforms Vosill confesses to the King that she loves him, a sentiment he rebuffs, and further informs her that he prefers \"pretty, dainty, delicate women who [have] no brains.\" Oelph finds her after this, drunk, and hints at his own feelings of love towards her; she rebuffs him as well, in what might be considered a more gentle way.\nSome days later Vosill receives a note from Adlain, asking her to meet him and two other Dukes elsewhere in the castle. She leaves alone, but Oelph opts to follow her in secret; after catching a glimpse of someone fleeing, he arrives in time to be arrested by the guard, who proceed to discover Vosill standing over the body of a murdered Duke, stabbed with one of her scalpels. Vosill and Oelph are almost immediately delivered to Ralinge, who binds the two separately and then strips, intending to rape Vosill. The woman issues what sounds to Oelph like commands, albeit in a language he does not recognize even partially. Oelph's eyes are closed at this point, and in his narrative he is unable to adequately describe what he hears next, other than an impression of wind and metal. When he opens his eyes he finds Ralinge and his assistants dead, dispatched bloodily, and Vosill free and in the process of removing her bindings, no indication of how she was freed. Later, she claims that Oelph fell unconscious and the three men fought over who would rape her first, though she indicates to him that this is what he \"should\" remember.\nThe two are taken from the torturer's chamber shortly thereafter, as the King has abruptly taken ill and appears to be dying. Vosill is able to cure King Quience's condition, and is there to witness as the conspiracy against her is revealed to the King, inadvertently, when news of Ralinge's death reaches the conspirators: Commander Adlain and Dukes Quettil and Ulresile. Ultimately the blame is publicly taken by Ulresile, who escapes with being exiled for several months; the King makes it clear that further plots against the doctor will not be tolerated. Because Oelph is not present for these events, his account comes second-hand from servants present; during this scene he reveals his master to be Guard Commander Adlain.\nVosill requests the King release her from her duties, which he does. She leaves just a few days later on a ship for Drezen, and is seen off at the dock by Oelph. Oelph tries to suppress the urge to ask to accompany Vosill, since he knows that her answer will be in the negative, but in the end he does so anyway. The ship leaves sometime later, and Vosill vanishes some days later.\n\"The Bodyguard\".\nThe second, interleaved storyline is told by an initially unnamed narrator, remaining unnamed so as to provide a neutral context for the narrative. The story focuses on DeWar, bodyguard to General UrLeyn, the Prime Protector of the Protectorate of Tassasen. Protector UrLeyn is the leader of Tassasen, having killed the previous monarch in a revolt; subsequently he eliminated official terms such as \"King\" and \"Empire\" within Tassasen. At the beginning of the story the Protectorate is fast approaching a war with the neighbouring land of Ladenscion, led by barons who initially supported UrLeyn's revolution but now intend to establish themselves as independent.\nDeWar is the sometimes-confidant of UrLeyn, but the bodyguard also maintains a friendly, conversational relationship with Perrund, a member of the Tassasen harem. Perrund was once the Protector's prized concubine, which changed following an assassination attempt on UrLeyn; Perrund shielded the Protector with her body, saving his life at the cost of crippling her left arm. Though no longer as prized as a concubine, Perrund is highly regarded by UrLeyn, DeWar, and most of Tassasen society. DeWar in particular finds her easy to confide in, and spends much of his off-time playing board games with her while the two tell each other stories.\nDeWar is on high alert as the conflict with Ladenscion approaches, believing that someone within the court may be a traitor. An attempt is made on UrLeyn's life by an assassin disguised as an ambassador, though DeWar anticipates the threat and kills the man before he can succeed. Nonetheless, this act only reinforces DeWar's fears of a traitor.\nA surprising, unwelcome turn comes when UrLeyn's young son, Lattens, has a seizure and subsequently falls ill. While the boy slowly recovers, DeWar tells him stories of a \"magical land\" called Lavishia, a place where \"every man was a king, every woman a queen\". Eventually the boy recovers, and UrLeyn and his bodyguard depart for the front lines, where the war with Ladenscion is flagging. However, no sooner are they there than word arrives that Lattens has fallen ill again, prompting a distraught UrLeyn to rush back to the castle.\nWhile DeWar is gone, Perrund tells Lattens a story about a girl named Dawn, who spent most of her life locked in a basement by her cruel family and was eventually rescued by a travelling circus. When he returns, Perrund tells DeWar about the story, then tells him it was a shadow of the real story: her story. Rather than her parents locking her in the basement to be cruel, they locked her in to hide her from Imperial soldiers\u2014high-ranking men of the former King's regime. Rather than being rescued, the soldiers found her, raped her, her mother and her sisters, and then forced her to watch as they murdered her father and brothers. The soldiers were eventually killed, but Perrund still feels she is now dead inside. DeWar attempts to in some way comfort her, but she quickly demands he return her to the harem.\nLattens' condition continues to worsen, causing UrLeyn to act more and more erratically, spending less time focusing on the war and more time at his son's bedside. The Protector goes so far as to bar all visitors to his chambers, and even prohibits DeWar from speaking to him unless he is spoken to. His only real contact is with Perrund, who spends most nights holding UrLeyn as he cries himself to sleep. DeWar enlists Perrund's help in focusing UrLeyn on the war, but to no success.\nAn epiphany strikes DeWar when he finds he has drooled on his pillow in his sleep, and he proceeds to Lattens' room. A guard restrains the boy's nurse while DeWar examines his security blanket, finding it has been soaked in an unknown fluid, presumably poison. Under threat of death the nurse reveals who has been orchestrating the poisoning: Perrund. DeWar storms into the harem chambers, intent on revealing the conspiracy to UrLeyn, but arrives too late; Perrund has already killed the Protector, and calmly waits for the bodyguard. Holding her at sword-point, DeWar tearfully demands to know why she conspired against the Protector. Perrund replies that she did it for revenge, for killing her and her family. The soldiers who raped her were not the former King's men at all, not even men allied to UrLeyn, but the man himself, as well as his current, closest advisers. Afterwards she was taken in by men from Haspidus, and recruited as a spy by King Quience directly. Saving UrLeyn from the assassin was simply to prevent him from dying while he was a strong leader; instead, her orders were to ensure he died in \"utter ruin\" to put his citizens off the idea of states without a monarch, as UrLeyn had envisaged Tassasen being.\nAfter her confession, Perrund demands DeWar kill her. He silently refuses, lowering his sword. Perrund grabs his knife and brings it to her own throat, but it is quickly knocked away by DeWar's blade, which he lowers once more.\nEpilogue.\nOelph gives a brief, personal epilogue for both stories. The three conspirators who attempted to kill Vosill died of various diseases, only Adlain lasting longer than a few years. King Quience reigned for forty years before his death, and was succeeded by one of his many daughters, giving the kingdom its first ruling Queen. Vosill disappeared from the ship she departed on; her disappearance was only discovered after a sudden burst of wind and chain-fire struck the ship, then vanished as quickly. Attempts to notify Vosill's family in Drezen were unsuccessful: nobody in the island country could be found who had ever met her. Oelph himself became a doctor, eventually taking Vosill's post as the royal physician. Tassasen endured a civil war after the death of Protector UrLeyn; eventually King Lattens took control of the Empire, ruling it quietly.\nOelph explains that he stopped DeWar's story as he did because that is where versions of the story differ dramatically. The more popular version has DeWar personally execute Perrund, followed by a return to the Half-Hidden Kingdoms where he reclaims his hidden title as Prince, and eventually King. A second version, supposedly written by Perrund herself, instead has DeWar telling the waiting guards and staff that UrLeyn is fine but sleeping, this and other distractions providing enough time for him and the former concubine to flee Tassasen before the Protector's body is discovered. The two elude capture and arrive in the Half-Hidden Kingdoms, eventually marry, have several children, and die many years later in an avalanche in the mountains.\nFinally, Oelph ends his epilogue by revealing that he expects his wife, whom he loves dearly, to return soon, quite possibly with his grandchildren accompanying her.\nReferences to the Culture.\nThe initial hardback printing of the book contained the following \"Note on the Text\", which was omitted from subsequent paperback editions:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;This Text, in two Parts, was discovered amongst the Papers of my late Grandfather. One Part concerns the Story of the Bodyguard to the then Protector of Tassasen, one UrLeyn, and is related, it is alleged, by a Person of his Court at the time, while the other, told by my Grandfather, tells the Story of the Woman Vosill, a Royal Physician during the Reign of King Quience, and who may, or may not, have been from the distant Archipelago of Drezen but who was, without Argument, from a different Culture. Like my much esteemed Grandfather, I have taken on the Task of making the Text I inherited more comprehensible and clear, and hope that I have succeeded in this Aim. Nevertheless, it is in a Spirit of the utmost Humility that I present it to the Society and to whoever might see fit to read it.\u2014\u200a\nSome reviewers noted the joking reference to \"Culture\" in this.\nDeWar's tales of Lavishia clearly parallel The Culture as it is described in Banks' other novels. He also tells of a pair of close friends who disagree about how their advanced society should manage contact with more primitive cultures:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Was it better to leave them alone or was it better to try and make life better for them? Even if you decided it was the right thing to do to make life better for them, which way did you do this? Did you say, Come and join us and be like us? Did you say, Give up all your own ways of doing things, the gods that you worship, the beliefs you hold most dear, the traditions that make you who you are? Or do you say, We have decided you should stay roughly as you are and we will treat you like children and give you toys that might make your life better?\nIt is evident that Vosill and DeWar are these two alien friends, now no longer in contact with each other, who have both come to the medieval planet and are independently attempting to do the \"right thing\" in their own differing ways, with Vosill being active and DeWar reactive.\nDoctor Vosill also habitually carried with her a dagger that came to be peripherally involved in circumstances suggestive of a disguised Culture knife missile, to which dagger she referred as having been useful in \"uncultured places\". This dagger is also described as being encrusted with small gems, the number of which decreases over time\u2014each gem probably one of the many different kinds of ammunition drone missiles are seen to be capable of firing throughout the Culture series.\nThe Epilogue contains this passage:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[...] the Doctor had been invited to dine with the vessel's captain that evening, but had sent a note declining the invitation, citing an indisposition due to special circumstances.\nSpecial Circumstances is the euphemistic name given to the \"black ops\" division of the Culture's Contact unit.\nThe epilogue also relates two different accounts of the fate of DeWar and Perrund. The second of these, where DeWar and Perrund hastily leave after she had killed UrLeyn, tells that the couple became merchants with their company symbol being \"a simple torus, a ring, which might be cut from the end of a hollow pipe.\" Oelph then goes on to speculate that there is some connection between this symbol and facets of his own and the Doctor's story, though is of course unaware of the resemblance between the company's symbol and a Culture orbital.\nReception.\n\"Kirkus Reviews\" described it as \"Atmospheric, ironic, resourceful, and all the parts add up\u2014yet something sets the teeth on edge.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58666", "revid": "42154491", "url": "https://en.wikipedia.org/wiki?curid=58666", "title": "United States Environmental Protection Agency", "text": "U.S. federal government agency\nThe Environmental Protection Agency (EPA) is an independent agency of the United States government tasked with environmental protection matters. President Richard Nixon proposed the establishment of EPA on July 9, 1970; it began operation on December 2, 1970, after Nixon signed an executive order. The order establishing the EPA was ratified by committee hearings in the House and Senate.\nThe agency is led by its administrator, who is appointed by the president and approved by the Senate. Since January 29, 2025, the administrator is Lee Zeldin. The EPA is not a Cabinet department, but the administrator is normally given cabinet rank. The EPA has its headquarters in Washington, D.C. There are regional offices for each of the agency's ten regions, as well as 27 laboratories around the country.\nThe agency conducts environmental assessment, research, and education. It has the responsibility of maintaining and enforcing national standards under a variety of U.S. environmental laws, in consultation with state, tribal, and local governments. EPA enforcement powers include fines, sanctions, and other measures.\nIt delegates some permitting, monitoring, and enforcement responsibility to U.S. states and the federally recognized tribes. The agency also works with industries and all levels of government in a wide variety of voluntary pollution prevention programs and energy conservation efforts.\nThe agency's budgeted employee level in 2023 was 16,204.1 full-time equivalent (FTE). More than half of EPA's employees are engineers, scientists, and environmental protection specialists; other employees include legal, public affairs, financial, and information technologists.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\nBackground.\nBeginning in the late 1950s and through the 1960s, Congress reacted to increasing public concern about the impact that human activity could have on the environment. Senator James E. Murray introduced a bill, the Resources and Conservation Act (RCA) of 1959, in the 86th Congress. The bill would have established a Council on Environmental Quality in the Executive Office of the President, declared a national environmental policy, and required the preparation of an annual environmental report. The conservation movement was weak at the time and the bill did not pass Congress.\nThe 1962 publication of \"Silent Spring\", a best-selling book by Rachel Carson, alerted the public about the detrimental effects on animals and humans of the indiscriminate use of pesticide chemicals.\nIn the years following, Congress discussed possible solutions. In 1968, a joint House\u2013Senate colloquium was convened by the chairmen of the Senate Committee on Interior and Insular Affairs, Senator Henry M. Jackson, and the House Committee on Science and Astronautics, Representative George P. Miller, to discuss the need for and means of implementing a national environmental policy. Congress enacted the National Environmental Policy Act of 1969 (NEPA) and the law was based on ideas that had been discussed in the 1959 and subsequent hearings.\nThe Richard Nixon administration made the environment a policy priority in 1969\u20131971 and created two new agencies, the Council on Environmental Quality (CEQ) and EPA. Nixon signed NEPA into law on January 1, 1970. The law established the CEQ in the Executive Office of the President. NEPA required that a detailed statement of environmental impacts be prepared for all major federal actions significantly affecting the environment. The \"detailed statement\" would ultimately be referred to as an environmental impact statement (EIS).\nEstablishment.\nOn July 9, 1970, Nixon proposed an executive reorganization that consolidated many environmental responsibilities of the federal government under one agency, a new Environmental Protection Agency. This proposal included merging pollution control programs from a number of departments, such as the combination of pesticide programs from the United States Department of Agriculture and the United States Department of the Interior. After conducting hearings during that summer, the House and Senate approved the proposal. The EPA was created 90 days before it had to operate, and officially opened its doors on December 2, 1970. The agency's first administrator, William Ruckelshaus, took the oath of office on December 4, 1970.\nEPA's primary predecessor was the former Environmental Health Divisions of the U.S. Public Health Service (PHS), and its creation caused one of a series of reorganizations of PHS that occurred during 1966\u20131973. From PHS, EPA absorbed the entire National Air Pollution Control Administration, as well as the Environmental Control Administration's Bureau of Solid Waste Management, Bureau of Water Hygiene, and part of its Bureau of Radiological Health. It also absorbed the Federal Water Quality Administration, which had previously been transferred from PHS to the Department of the Interior in 1966. A few functions from other agencies were also incorporated into EPA: the formerly independent Federal Radiation Council was merged into it; pesticides programs were transferred from the Department of the Interior, Food and Drug Administration, and Agricultural Research Service; and some functions were transferred from the Council on Environmental Quality and Atomic Energy Commission.\nUpon its creation, EPA inherited 84 sites spread across 26 states, of which 42 sites were laboratories. The EPA consolidated these laboratories into 22 sites.\n1970s.\nIn its first year, the EPA had a budget of $1.4\u00a0billion and 5,800 employees. At its start, the EPA was primarily a technical assistance agency that set goals and standards. Soon, new acts and amendments passed by Congress gave the agency its regulatory authority. A major expansion of the Clean Air Act was approved in December 1970.\nEPA staff recall that in the early days there was \"an enormous sense of purpose and excitement\" and the expectation that \"there was this agency which was going to do something about a problem that clearly was on the minds of a lot of people in this country,\" leading to tens of thousands of resumes from those eager to participate in the mighty effort to clean up America's environment.\nWhen EPA first began operation, members of the private sector felt strongly that the environmental protection movement was a passing fad. Ruckelshaus stated that he felt pressure to show a public which was deeply skeptical about government's effectiveness, that EPA could respond effectively to widespread concerns about pollution.\nThe burning Cuyahoga River in Cleveland, Ohio, in 1969 led to a national outcry and criminal charges against major steel companies. The US Justice Department in late 1970 began pollution control litigation in cooperation with the new EPA. Congress enacted the Federal Water Pollution Control Act Amendments of 1972, better known as the Clean Water Act (CWA). The CWA established a national framework for addressing water quality, including mandatory pollution control standards, to be implemented by the agency in partnership with the states. Congress amended the Federal Insecticide, Fungicide, and Rodenticide Act (FIFRA) in 1972, requiring EPA to measure every pesticide's risks against its potential benefits.\nIn 1973 President Nixon appointed Russell E. Train to be the next EPA administrator. In 1974 Congress passed the Safe Drinking Water Act, requiring EPA to develop mandatory federal standards for all public water systems, which serve 90% of the US population. The law required EPA to enforce the standards with the cooperation of state agencies.\nIn October 1976, Congress passed the Toxic Substances Control Act (TSCA) which, like FIFRA, related to the manufacture, labeling and usage of commercial products rather than pollution. This act gave the EPA the authority to gather information on chemicals and require producers to test them, gave it the ability to regulate chemical production and use (with specific mention of PCBs), and required the agency to create the National Inventory listing of chemicals.\nCongress also enacted the Resource Conservation and Recovery Act (RCRA) in 1976, significantly amending the Solid Waste Disposal Act of 1965. It tasked the EPA with setting national goals for waste disposal, conserving energy and natural resources, reducing waste, and ensuring environmentally sound management of waste. Accordingly, the agency developed regulations for solid and hazardous waste that were to be implemented in collaboration with states.\nPresident Jimmy Carter appointed Douglas M. Costle as EPA administrator in 1977. To manage the agency's expanding legal mandates and workload, by the end of 1979 the budget grew to $5.4\u00a0billion and the workforce size increased to 13,000.\n1980s.\nIn 1980, following the discovery of many abandoned or mismanaged hazardous waste sites such as Love Canal, Congress passed the Comprehensive Environmental Response, Compensation, and Liability Act, nicknamed \"Superfund.\" The new law authorized EPA to cast a wider net for parties responsible for sites contaminated by previous hazardous waste disposal and established a funding mechanism for assessment and cleanup.\nIn a dramatic move to the right, President Ronald Reagan in 1981 appointed Anne Gorsuch as EPA administrator. Gorsuch based her administration of EPA on the New Federalism approach of downsizing federal agencies by delegating their functions and services to the individual states. She believed that EPA was over-regulating business and that the agency was too large and not cost-effective. During her 22 months as agency head, she cut the budget of the EPA by 22%, reduced the number of cases filed against polluters, relaxed Clean Air Act regulations, and facilitated the spraying of restricted-use pesticides. She cut the total number of agency employees, and hired staff from the industries they were supposed to be regulating. Environmentalists contended that her policies were designed to placate polluters, and accused her of trying to dismantle the agency.\nAssistant Administrator Rita Lavelle was fired by Reagan in February 1983 because of her mismanagement of the Superfund program. Gorsuch had increasing confrontations with Congress over Superfund and other programs, including her refusal to submit subpoenaed documents. Gorsuch was cited for contempt of Congress and the White House directed EPA to submit the documents to Congress. Gorsuch and most of her senior staff resigned in March 1983. Reagan then appointed William Ruckelshaus as EPA administrator for a second term. As a condition for accepting his appointment, Ruckleshaus obtained autonomy from the White House in appointing his senior management team. He then appointed experienced competent professionals to the top management positions, and worked to restore public confidence in the agency.\nLee M. Thomas succeeded Ruckelshaus as administrator in 1985. In 1986 Congress passed the Emergency Planning and Community Right-to-Know Act, which authorized the EPA to gather data on toxic chemicals and share this information with the public. EPA also researched the implications of stratospheric ozone depletion. Under Administrator Thomas, EPA joined with several international organizations to perform a risk assessment of stratospheric ozone, which helped provide motivation for the Montreal Protocol, which was agreed to in August 1987.\nIn 1988, during his first presidential campaign, George H. W. Bush was vocal about environmental issues. Following his election victory, he appointed William K. Reilly, an environmentalist, as EPA administrator in 1989. Under Reilly's leadership, the EPA implemented voluntary programs and initiated the development of a \"cluster rule\" for multimedia regulation of the pulp and paper industry. At the time, there was increasing awareness that some environmental issues were regional or localized in nature, and were more appropriately addressed with sub-national approaches and solutions. This understanding was reflected in the 1990 amendments to the Clean Air Act and in new approaches by the agency, such as a greater emphasis on watershed-based approaches in Clean Water Act programs.\n1990s.\nIn 1992 EPA and the Department of Energy launched the Energy Star program, a voluntary program that fosters energy efficiency.\nCarol Browner was appointed EPA administrator by President Bill Clinton and served from 1993 to 2001. Major projects during Browner's term included:\nSince the passage of the Superfund law in 1980, an excise tax had been levied on the chemical and petroleum industries, to support the cleanup trust fund. Congressional authorization of the tax was due to expire in 1995. Although Browner and the Clinton Administration supported continuation of the tax, Congress declined to reauthorize it. Subsequently, the Superfund program was supported only by annual appropriations, greatly reducing the number of waste sites that are remediated in a given year. (In 2021 Congress reauthorized an excise tax on chemical manufacturers.)\nMajor legislative updates during the Clinton Administration were the Food Quality Protection Act and the 1996 amendments to the Safe Drinking Water Act.\n2000s.\nPresident George W. Bush appointed Christine Todd Whitman as EPA administrator in 2001. Whitman was succeeded by Mike Leavitt in 2003 and Stephen L. Johnson in 2005.\nIn March 2005 nine states (California, New York, New Jersey, New Hampshire, Massachusetts, Maine, Connecticut, New Mexico and Vermont) sued the EPA. The EPA's inspector general had determined that the EPA's regulation of mercury emissions did not follow the Clean Air Act, and that the regulations were influenced by top political appointees. The EPA had suppressed a study it commissioned by Harvard University which contradicted its position on mercury controls. The suit alleged that the EPA's rule exempting coal-fired power plants from \"maximum available control technology\" was illegal, and additionally charged that the EPA's system of cap-and-trade to lower average mercury levels would allow power plants to forego reducing mercury emissions, which they objected would lead to dangerous local hotspots of mercury contamination even if average levels declined. Several states also began to enact their own mercury emission regulations. Illinois's proposed rule would have reduced mercury emissions from power plants by an average of 90% by 2009. In 2008\u2014by which point a total of fourteen states had joined the suit\u2014the U.S. Court of Appeals for the District of Columbia ruled that the EPA regulations violated the Clean Air Act. In response, EPA announced plans to propose such standards to replace the vacated Clean Air Mercury Rule, and did so on March 16, 2011.\nIn July 2005 there was a delay in the issuance of an EPA report showing that auto companies were using loopholes to produce less fuel-efficient cars. The report was supposed to be released the day before a controversial energy bill was passed and would have provided backup for those opposed to it, but the EPA delayed its release at the last minute.\nEPA initiated its voluntary WaterSense program in 2006 to encourage water efficiency through the use of a special label on consumer products.\nIn 2007 the state of California sued the EPA for its refusal to allow California and 16 other states to raise fuel economy standards for new cars. EPA Administrator Stephen Johnson claimed that the EPA was working on its own standards, but the move has been widely considered an attempt to shield the auto industry from environmental regulation by setting lower standards at the federal level, which would then preempt state laws. California governor Arnold Schwarzenegger, along with governors from 13 other states, stated that the EPA's actions ignored federal law, and that existing California standards (adopted by many states in addition to California) were almost twice as effective as the proposed federal standards. It was reported that Johnson ignored his own staff in making this decision.\nIn 2007 it was reported that EPA research was suppressed by career managers. Supervisors at EPA's National Center for Environmental Assessment required several paragraphs to be deleted from a peer-reviewed journal article about EPA's integrated risk information system, which led two co-authors to have their names removed from the publication, and the corresponding author, Ching-Hung Hsu, to leave EPA \"because of the draconian restrictions placed on publishing\". The 2007 report stated that EPA subjected employees who author scientific papers to prior restraint, even if those papers are written on personal time.\nIn December 2007 EPA administrator Johnson approved a draft of a document that declared that climate change imperiled the public welfare\u2014a decision that would trigger the first national mandatory global-warming regulations. Associate Deputy Administrator Jason Burnett e-mailed the draft to the White House. White House aides\u2014who had long resisted mandatory regulations as a way to address climate change\u2014knew the gist of what Johnson's finding would be, Burnett said. They also knew that once they opened the attachment, it would become a public record, making it controversial and difficult to rescind. So they did not open it; rather, they called Johnson and asked him to take back the draft. Johnson rescinded the draft; in July 2008, he issued a new version which did not state that global warming was danger to public welfare. Burnett resigned in protest.\nIn April 2008, the Union of Concerned Scientists said that more than half of the nearly 1,600 EPA staff scientists who responded online to a detailed questionnaire reported they had experienced incidents of political interference in their work. The survey included chemists, toxicologists, engineers, geologists and experts in other fields of science. About 40% of the scientists reported that the interference had been more prevalent in the last five years than in previous years.\nPresident Barack Obama appointed Lisa P. Jackson as EPA administrator in 2009.\n2010s.\nIn 2010 it was reported that a $3\u00a0million mapping study on sea level rise was suppressed by EPA management during both the Bush and Obama administrations, and managers changed a key interagency report to reflect the removal of the maps.\nBetween 2011 and 2012, some EPA employees reported difficulty in conducting and reporting the results of studies on hydraulic fracturing due to industry and governmental pressure, and were concerned about the censorship of environmental reports.\nPresident Obama appointed Gina McCarthy as EPA administrator in 2013.\nIn 2014, the EPA published its \"Tier 3\" standards for cars, trucks and other motor vehicles, which tightened air pollution emission requirements and lowered the sulfur content in gasoline.\nIn 2015, the EPA discovered extensive violations by Volkswagen Group in its manufacture of Volkswagen and Audi diesel engine cars, for the 2009 through 2016 model years. Following notice of violations and potential criminal sanctions, Volkswagen later agreed to a legal settlement and paid billions of US dollars in criminal penalties, and was required to initiate a vehicle buyback program and modify the engines of the vehicles to reduce illegal air emissions.\nIn August 2015, the EPA finalized the Clean Power Plan to regulate emissions from power plants, projecting a 15-year cut of 32%, or 789 million metric tons of carbon dioxide. In 2019 it was voided and replaced by the Affordable Clean Energy rule under the Trump administration, and in 2022 its constitutionality was ruled out by the Supreme Court.\nIn August 2015, the 2015 Gold King Mine waste water spill occurred when EPA contractors examined the level of pollutants such as lead and arsenic in a Colorado mine, and accidentally released over three million gallons of waste water into Cement Creek and the Animas River.\nIn 2015, the International Agency for Research on Cancer (IARC), a branch of the World Health Organization, cited research linking glyphosate, an ingredient of the weed killer Roundup manufactured by the chemical company Monsanto, to non-Hodgkin's lymphoma. In March 2017, the presiding judge in a litigation brought about by people who claim to have developed glyphosate-related non-Hodgkin's lymphoma opened Monsanto emails and other documents related to the case, including email exchanges between the company and federal regulators. According to \"The New York Times\", the \"records suggested that Monsanto had ghostwritten research that was later attributed to academics and indicated that a senior official at the Environmental Protection Agency had worked to quash a review of Roundup's main ingredient, glyphosate, that was to have been conducted by the United States Department of Health and Human Services.\" The records show that Monsanto was able to prepare \"a public relations assault\" on the finding after they were alerted to the determination by Jess Rowland, the head of the EPA's cancer assessment review committee at that time, months in advance. Emails also showed that Rowland \"had promised to beat back an effort by the Department of Health and Human Services to conduct its own review.\"\nOn February 17, 2017, President Donald Trump appointed Scott Pruitt as EPA administrator. The Democratic Party saw the appointment as a controversial move, as Pruitt had spent most of his career challenging environmental regulations and policies. He did not have previous experience in the environmental protection field and had received financial support from the fossil fuel industry. In 2017, the Presidency of Donald Trump proposed a 31% cut to the EPA's budget to $5.7\u00a0billion from $8.1\u00a0billion and to eliminate a quarter of the agency jobs. However, this cut was not approved by Congress. Pruitt resigned from the position on July 5, 2018, citing \"unrelenting attacks\" due to ongoing ethics controversies.\nPresident Trump appointed Andrew R. Wheeler as EPA administrator in 2019. Trump promised to eliminate EPA \"in almost every form\" leaving \"only tidbits\" intact.\nOn July 17, 2019, EPA management prohibited the agency's Scientific Integrity Official, Francesca Grifo, from testifying at a House committee hearing. EPA offered to send a different representative in place of Grifo and accused the committee of \"dictating to the agency who they believe was qualified to speak.\" The hearing was to discuss the importance of allowing federal scientists and other employees to speak freely when and to whom they want to about their research without having to worry about any political consequences.\nIn September 2019 air pollution standards in California were once again under attack, as the Trump administration attempted to revoke a waiver issued to the state which allowed more stringent standards for auto and truck emissions than the federal standards.\n2020\u20132024.\nPresident Joe Biden appointed Michael S. Regan to be administrator in 2021. Regan began serving on March 11, 2021.\nIn October 2021 EPA announced its \"PFAS Strategic Roadmap.\" PFASs are organofluorine chemical compounds referred to as \"forever chemicals\". The roadmap is a \"whole-of-EPA\" strategy and the agency will consider the full life cycle of PFAS, including preventing PFAS from entering the environment, holding polluters accountable, and remediation of contaminated sites. It also will include drinking water monitoring and risk assessment for PFOA and PFOS in biosolids (processed sewage sludge used as fertilizer).\nIn December 2021 EPA issued new greenhouse gas standards for passenger cars and light trucks. The standards, which will reduce climate pollution and improve public health, became effective for the 2023 vehicle model year.\nIn March 2022 the Biden administration allowed California to again set stricter auto emissions standards.\nIn August 2022 the EPA was allotted a listed ~$53.216\u00a0billion in funding pursuant to the Inflation Reduction Act (IRA). The EPA listed 24 total initiatives, the most notable among them being greenhouse gas reduction and monitoring, a superfund petroleum tax, replacing current heavy-duty vehicles with zero-emission vehicles, and a methane incentive program.\nOn February 3, 2023, more than 100 train cars were derailed in East Palestine, and around half of those cars containing chemicals like butyl acrylate, vinyl chloride, and ethylhexyl acrylate. Subsequently, the chemicals combusted into a flame being seen from miles around and the fumes filled the air with residents reporting animals falling ill and a burning sensation in their eyes and nose. The EPA monitered the situation and experts recommended that local residents take part in the EPA's at-home air screening.\nIn March 2024, EPA published regulations for tailpipe emissions standards that accelerate the transition to electric vehicles (EVs). The standards require at least two-thirds of all new cars sold in the United States to be zero-emissions vehicles by 2032, in order to reduce air pollution and climate change. The agency projected that the regulations would cut emissions by 7\u00a0billion metric tons, or 56% of 2026 levels, by 2032.\nIn April 2024, EPA finalized new standards for power plant carbon emissions, projecting cuts of 65,000 tons by 2028 and 1.38\u00a0billion tons by 2047. The agency also issued final drinking water standards for six PFAS compounds.\nIn December, 2024 the EPA announced it approved California's plan to end the sale of gasoline-only vehicles by 2035. EPA Administrator Michael Regan granted a waiver under the Clean Air Act to California to implement the plan which was first announced in 2020. It required that by 2035 at least 80% of new cars sold be electric and up to 20% plug-in hybrid models. California's rules were adopted by 11 other states including New York, Massachusetts and Oregon.\n2025.\nWith the second presidential term of Donald Trump, Lee Zeldin began serving as administrator on January 29, 2025.\nOn February 27, 2025, EPA received a White House memo issued by Russell Vought to prepare for mass layoffs. Hours earlier, Trump had said that there would be a 65 percent reduction in its roughly 17,000 personnel, which was later corrected to 65 percent overall agency budget cuts.\nIn March 2025 the EPA dropped a lawsuit against Denka, a chemical company, which was intended to reduce emissions of chloroprene at its plant in LaPlace, Louisiana.\nAfter the Supreme Court of the United States overturned an injunction against termination of government employees in \"AFGE v. Trump\", the EPA announced in July 2025 that it would be eliminating its Office of Research and Development. The agency had previously denied plans to do so after a leaked memo indicating plans to do so was reported on in March.\nThe EPA released a new proposed rule in July 2025 to repeal the previous endangerment finding that had been established in 2009 that greenhouse gases posed a risk to human health, a basis used in many of the EPA's regulations supporting the Clean Air Act. Zeldin asserted that the impact of these existing regulations was harming American citizens through increased costs, this being his rationale for eliminating the endangerment finding.\nOrganization.\nThe EPA is led by the administrator, appointed following nomination by the president and approval from Congress.\nRegions.\nCreating 10 EPA regions was an initiative that came from President Richard Nixon. \"See\" Standard Federal Regions. Each EPA regional office is responsible within its states for implementing the agency's programs, except those programs that have been specifically delegated to states.\nEach regional office also implements programs on Indian Tribal lands, except those programs delegated to tribal authorities.\nLegal authority.\nThe Environmental Protection Agency can only act pursuant to statutes\u2014the laws passed by Congress. Appropriations statutes authorize how much money the agency can spend each year to carry out the approved statutes. The agency has the power to issue regulations. A regulation interprets a statute, and EPA applies its regulations to various environmental situations and enforces the requirements. The agency must include a rationale of why a regulation is needed. (\"See\" Administrative Procedure Act.) Regulations can be challenged in federal courts, either district court or appellate court, depending on the particular statutory provision.\nRelated legislation.\nEPA has principal implementation authority for the following federal environmental laws:\nThere are additional laws where EPA has a contributing role or provides assistance to other agencies. Among these laws are:\nPrograms.\nEPA established its major programs pursuant to the primary missions originally articulated in the laws passed by Congress. Additional programs have been developed to interpret the primary missions. Some of the newer programs have been specifically authorized by Congress. Former administrator William Ruckelshaus observed in 2016 that a danger for EPA was that air, water, waste and other programs would be unconnected, placed in \"silos\", a problem that persists more than 50 years later, albeit less so than at the start.\nCore programs.\nAir quality and radiation protection.\nThe Office of Air and Radiation (OAR) describes itself as the official authority in charge of \"developing national programs, policies, and regulations for controlling air pollution and radiation exposure.\" The OAR is responsible for enforcing the Clean Air Act, the Atomic Energy Act, the Waste Isolation Pilot Plant Land Withdrawal Act, and other applicable laws. The OAR is in charge of the Offices of Air Quality Planning and Standards, Atmospheric Protection, Transportation and Air Quality, and the Office of Radiation and Indoor Air.\nRadiation protection.\nThe Radiation Protection Program comprises seven project groups.\nEnforcement.\nIn 2019 the Environmental Data &amp; Governance Initiative, \"a network of academics, developers, and non-profit professionals\", published a report which compared EPA enforcement statistics over time. The number of civil cases filed by EPA have gradually decreased, and in 2018 the criminal and civil penalties from EPA claims dropped over four times their amounts in 2013, 2016, and 2017. In 2016 EPA issued $6,307,833,117 in penalties due to violations of agency requirements, and in 2018 the agency issued $184,768,000 in penalties. EPA's inspections and evaluations have steadily decreased from 2015 to 2018. Enforcement activity has decreased partially due to budget cuts within the agency.\nControversies.\nScope and fulfillment of agency's authority.\nCongress enacted laws such as the Clean Air Act, the Resource Conservation and Recovery Act, and CERCLA with the intent of preventing and reconciling environmental damages. Beginning in 2018 under Administrator Andrew Wheeler, EPA revised some pollution standards that resulted in less overall regulation.\nFurthermore, the CAA's discretionary application has caused a varied application of the law among states. In 1970, Louisiana deployed its Comprehensive Toxic Air Pollutant Emission Control Program to comply with federal law. This program does not require pollution monitoring that is equivalent to programs in other states.\nEnvironmental justice.\nThe EPA has been criticized for its lack of progress towards environmental justice. Administrator Christine Todd Whitman was criticized for her changes to President Bill Clinton's Executive Order 12898 during 2001, removing the requirements for government agencies to take the poor and minority populations into special consideration when making changes to environmental legislation, and therefore defeating the spirit of the Executive Order. In a March 2004 report, the inspector general of the agency concluded that the EPA \"has not developed a clear vision or a comprehensive strategic plan, and has not established values, goals, expectations, and performance measurements\" for environmental justice in its daily operations. Another report in September 2006 found the agency still had failed to review the success of its programs, policies, and activities toward environmental justice. Studies have also found that poor and minority populations were underserved by the EPA's Superfund program, and that this situation was worsening.\nIn August 2022 the EPA was allotted a listed ~42.8\u00a0billion in funding from the Inflation Reduction Act (IRA) towards what the EPA classifies as \"Advancing Environmental Justice\", and published the statement \"Through the Inflation Reduction Act, EPA will improve the lives of millions of Americans by reducing pollution in neighborhoods where people live, work, play, and go to school; accelerating environmental justice efforts in communities overburdened by pollution for far too long; and tackling our biggest climate challenges while creating jobs and delivering energy security.\"\nIn September 2022 EPA announced the creation of a new Office of Environmental Justice and External Civil Rights that reports directly to the EPA administrator. The new office has an expanded budget and staff with broader responsibilities than under the previous organizational arrangement.\nFreedom of Information Act processing performance.\nIn the latest Center for Effective Government analysis of 15 federal agencies which receive the most Freedom of Information Act (FOIA) requests, published in 2015 (using 2012 and 2013 data, the most recent years available), the EPA earned a D by scoring 67 out of a possible 100 points, i.e. did not earn a satisfactory overall grade.\nPebble Mine.\nPebble Mine is a copper and gold mining project located in the southwest region of Alaska in the Bristol Bay region organized by Northern Dynasty Minerals. In 2014 the EPA released its statement on the impacts that mining would have on Bristol Bay and its tributaries. Among many things, the statement assesses geological, topographic, ecological, hydrological, and economic data and determined that mining could negatively impact the salmon population. Seeing as Bristol Bay and its watershed provides around 46% of the world's sockeye salmon, the EPA did not want to risk an ecological disaster. In July 2014, before Northern Dynasty Minerals had submitted its EIS, EPA's Region 10 office proposed restrictions pursuant to section 404(c) of the Clean Water Act, restrictions that would effectively prohibit the project. Northern Dynasty Minerals protested this decision and on July 18, 2014, in a published statement, Pebble Partnership CEO Tom Collier said that the project would continue its litigation against EPA; noted that the EPA's action was under investigation by the EPA inspector general and by the House Committee on Oversight and Government Reform; and noted that two bills were pending in Congress seeking to clarify that EPA did not have the authority to preemptively veto or otherwise restrict development projects prior to the onset of federal and state permitting. Collier's statement also said that EPA's proposal was based on outdated mining scenarios that were not part of the project's approach. Multiple journalists and organizations have reported on the controversy including the Natural Resources Defense Council in support of the cancelation of the project and John Stossel in support of the development of the mine. As of 2023[ [update]], the mine remains a controversial topic.\nOn January 30, 2023, the EPA vetoed the mine.\nWater quality in East Palestine, Ohio.\nOhio governor Mike DeWine and administrator of the EPA Michael Regan drank tap water in East Palestine, Ohio, on February 3, 2023, after a train derailment to show that the water was safe. The derailment caused a fire and the release of toxic chemicals into the air and water making locals and environmental groups concerned for the quality of water in the area. Despite the EPA's assurance that the water is safe some residents do not trust the quality of the water and question its long-term effects.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "58667", "revid": "6104108", "url": "https://en.wikipedia.org/wiki?curid=58667", "title": "405 BC", "text": "Calendar year\n \nYear 405 BC was a year of the pre-Julian Roman calendar. At the time, it was known as the Year of the Tribunate of Barbatus, Capitolinus, Cincinnatus, Medullinus, Iullus and Mamercinus (or, less frequently, year 349 \"Ab urbe condita\"). The denomination 405 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy topic.\nArt.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58668", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=58668", "title": "400 BC", "text": "Calendar year\n \nYear 400 BC was a year of the pre-Julian Roman calendar. In the Roman Republic, it was known as the Year of the Tribunate of Esquilinus, Capitolinus, Vulso, Medullinus, Saccus and Vulscus (or, less frequently, year 354 \"Ab urbe condita\"). The denomination 400 BC for this year has been used in Europe since the early medieval period, when the Anno Domini calendar era became prevalent there.\nEvents.\n&lt;onlyinclude&gt;\nBy topic.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58669", "revid": "1318999595", "url": "https://en.wikipedia.org/wiki?curid=58669", "title": "Emperor of China", "text": "Monarchs of imperial China\nThroughout Chinese history, \"Emperor\" () was the superlative title held by the monarchs of imperial China's various dynasties. In traditional Chinese political theory, the emperor was the \"Son of Heaven\", an autocrat with the divine mandate to rule all under Heaven. Emperors were worshiped posthumously under a secular imperial cult. The lineage of emperors descended from a paternal family line constituted a dynasty, and succession in most cases theoretically followed agnatic primogeniture. The emperor of China was an absolute monarch, though in the late Qing reforms plans were made to move the emperor to a constitutional monarch.\nDuring the Han dynasty, Confucianism gained sanction as the official political theory. The absolute authority of the emperor came with a variety of governing duties and moral obligations; failure to uphold these was thought to remove the dynasty's Mandate of Heaven and to justify its overthrow. In practice, emperors sometimes avoided the strict rules of succession and dynasties' purported \"failures\" were detailed in official histories written by their successful replacements or even later dynasties. The power of the emperor was also limited by the imperial bureaucracy, which was staffed by scholar-officials, and eunuchs during some dynasties. An emperor was also constrained by filial obligations to his ancestors' policies and dynastic traditions, such as those first detailed in the Ming-era \"Huang-Ming Zuxun\" (\"Ancestral Instructions\").\nHistory.\nOrigin.\nDuring the Western Zhou dynasty (c.\u20091046 BC\u00a0\u2013 771\u00a0BC), Chinese vassal rulers with power over their particular fiefdoms served a strong central monarch. Following a brutal succession crisis and relocation of the royal capital, the power of the Zhou kings () waned, and during the Eastern Zhou period, the regional lords overshadowed the king and began to usurp that title for themselves. In 221\u00a0BC, after the King of Qin completed the conquest of the various kingdoms of the Warring States period, he adopted a new title to reflect his prestige as a ruler greater than the rulers before him. He called himself \"Shi Huangdi\", or the 'First Emperor'. Before this, \"Huang\" ( 'august', 'sovereign') was most commonly seen as a reverential epithet for a deceased ancestor, and \"Di\" (, *\u200d) was an apical ancestor, originally referring to the deified ancestors of the Shang kings. In the 3rd century\u00a0BC, the two titles had not previously been used together. The emperor of China, like the Zhou kings before him, and the Shang kings before them, was most commonly referred to as \"Tianzi\" ( 'Son of Heaven'), who was divinely appointed to rule. The appellation \"Huangdi\" carried similar shades of meaning. Alternate English translations of the word include \"The August Ancestor\", \"The Holy Ruler\", or \"The Divine Lord\". On that account, some modern scholars translate the title as \"thearch\".\nOn occasion, the father of the ascended emperor was still alive. Such an emperor was titled as the Taishang Huang ('grand imperial sire'). The practice was initiated by Qin Shi Huang, who gave the title as a posthumous name to his own father, as was already common for monarchs of any stratum of power. Liu Bang, who established the Han dynasty, was the first to become emperor while his father yet lived. It was said he granted the title during his father's life because he would not be done obeisance to by his own father, a commoner.\nOwing to political fragmentation, over the centuries, it has not been uncommon to have numerous claimants to the title of \"Son of Heaven\". The Chinese political concept of the Mandate of Heaven essentially legitimized those claimants who emerged victorious. The proper list was considered those made by the official dynastic histories; the compilation of a history of the preceding dynasty was considered one of the hallmarks of legitimacy, along with symbols such as the Nine Ding or the Heirloom Seal of the Realm. As with the First Emperor, it remained very common to grant posthumous titles to the ancestors of the victors.\nThe Yuan and Qing dynasties were founded by successful invaders of different ethnic groups. As part of their rule over China, they also went through the culturally appropriate rituals of formally declaring a new dynasty and taking on the Chinese title of \"Huangdi\", in addition to the titles of their respective people, especially in the case of the Yuan dynasty. Thus, Kublai Khan was simultaneously khagan of the Mongols and emperor of China.\nEnd of the imperial system.\nIn the 1900s, China made a series of reforms to modernise the government and military, adopting Japanese and German governance and laws. In 1911, the title of Prime Minister of the Imperial Cabinet was created to rule alongside the emperor, as part of an attempt to move China from an absolute monarchy to a constitutional monarchy.\nPuyi, who had reigned as the Xuantong Emperor, abdicated on 12 February 1912, ending the Qing dynasty as well as the imperial tradition altogether, after more than 2100 years. Yuan Shikai, former President of the Republic of China, attempted to restore dynastic rule with himself as the Hongxian Emperor, however he abdicated the throne on 22 March 1916 after only 83 days, due to a revolt against his imperial rule. Puyi was briefly restored for 12 days during a coup in 1917 but was overthrown again shortly after. Although permitted to remain in the palace, he absconded to the Japanese concession in Tianjin in 1924. In 1934 he was installed as emperor of Manchukuo, a Japanese puppet state. In 1945, he was captured by the Red Army as a prisoner of war, where he was held in the Siberian city of Chita. In 1950, he was extradited to China and imprisoned in Fushun War Criminals Management Centre. He would be formally pardoned and released in 1959, working in a repair shop and as a researcher of literature and history until his death in 1967. \nThe current head of the House of Aisin-Gioro and hypothetical claimant to the throne is Jin Yuzhang. He has worked for various local councils on China, and has no interest in the restoration of monarchy.\nEnumeration.\nTraditional political theory holds that there can only be one legitimate Son of Heaven at any given time. However, identifying the \"legitimate\" emperor during times of division is not always uncontroversial, and therefore the exact number of legitimate emperors depends on where one stands on a number of succession disputes. The two most notable such controversies are whether Cao Wei or Shu Han had legitimacy during the Three Kingdoms, and at what point the Song dynasty ceased to be the legitimate dynasty in favor of the Yuan dynasty. The Qing view, reported to Europe by the Jesuits, was that there had been 150 emperors from the First Emperor to the Kangxi Emperor. Adding the eight uncontroversial emperors that followed the Kangxi Emperor would give a grand total of 158 emperors from the First Emperor to Puyi.\nBy one count, from the Qin dynasty to the Qing dynasty, there were a total 557 individuals who at one point or another claimed the title of Emperor, including several simultaneous claimants at various times. Some, such as Li Zicheng, Huang Chao, and Yuan Shu, declared themselves the emperors, Son of Heaven and founded their own empires as a rival government to challenge the legitimacy of and overthrow the existing emperor. Among the most famous emperors were Qin Shi Huang of the Qin dynasty, emperors Gaozu, Han Wudi as well as Guangwu of the Han, Emperor Taizong of Tang of the Tang, the Hongwu Emperor and Yongle Emperor of the Ming, and the Kangxi Emperor of the Qing.\nPower.\nThe emperor's words were considered sacred edicts (), and his written proclamations were called 'directives from above' (). In theory, the emperor's orders were to be obeyed immediately. He was elevated above all commoners, nobility and members of the Imperial family. Addresses to the emperor were always to be formal and self-deprecatory, even by the closest of family members.\nIn practice, however, the power of the emperor varied between different emperors and different dynasties. Generally, in the Chinese dynastic cycle, emperors founding a dynasty usually consolidated the empire through comparative autocracy\u2014examples include Qin Shi Huang, emperors Gaozu and Guangwu of Han, Emperor Taizong of Tang, Kublai Khan of the Yuan, and the Kangxi Emperor of the Qing.\nThe usual method for widespread geographic power consolidation was to involve the whole family. From generation to generation, the bonds weakened between the branches of family established as local rulers in different areas. After a sufficient period of time, their loyalty could no longer be assured, and the taxes they collected sapped the imperial coffers. This led to situations like the reign of Emperor Wu of Han, who disenfranchised and annihilated the nobilities of virtually all imperial relatives whose forebears had been enfeoffed by his own ancestor, Gaozu.\nApart from a few very energetic monarchs, the emperor usually delegated the majority of decision making to the civil bureaucracy (chiefly the chancellery and the Central Secretariat), the military, and in some periods the censorate. Paranoid emperors, like Emperor Wu of Han and the Ming's Hongwu Emperor, would cycle through high government officials rapidly, or simply leave top-ranking posts vacant, such that no one could threaten their power. During other reigns, certain officials in the civil bureaucracy wielded more power than the emperor himself.\nUnlike Japanese emperors whom all belonged to a single dynasty, which could not be deposed through a change in the Mandate of Heaven due to being traditionally descended from Shinto goddess Amaterasu, Chinese dynasties could be deposed. Though Chinese emperors often developed imperial cults and personal cults around themselves, they seldom claimed divine descent, for example Hongwu of Ming was born into a peasant family prior to seizing the throne.\nThe emperor's position, unless deposed in a rebellion, was always hereditary, usually by agnatic primogeniture. As a result, many emperors ascended the throne while still children. During minority reigns, the Empress Dowager, the emperor's mother, would usually possess significant political power, along with the male members of her birth family. In fact, the vast majority of female rulers throughout Chinese Imperial history came to power by ruling as regents on behalf of their sons; prominent examples include Empress L\u00fc Zhi of the Han, as well as the empress dowagers Cixi and Ci'an during the Qing, who for a time ruled jointly as co-regents. Where Empresses Dowager were too weak to assume power, or her family too strongly opposed, court officials often seized control. Court eunuchs had a significant role in the power structure, as emperors often relied on a few of them as confidants, which gave them access to many court documents. In a few places, eunuchs wielded vast power; one of the most powerful eunuchs in Chinese history was Wei Zhongxian during the Ming. Occasionally, other nobles seized power as regents.\nThe actual area ruled by the emperor of China varied from dynasty to dynasty. In some cases, such as during the Southern Song dynasty, political power in East Asia was effectively split among several governments; nonetheless, the political fiction that there was but one ruler was maintained.\nHeredity and succession.\nThe title of \"emperor\" was hereditary, traditionally passed on from father to son in each dynasty. There are also instances where the throne is assumed by a younger brother, should the deceased emperor have no male offspring. By convention in most dynasties, the eldest son born to the Empress consort () succeeded to the throne. In some cases when the empress did not bear any children, the emperor would have a child with another of his many wives (all children of the emperor were said also to be the children of the empress, regardless of birth mother). In some dynasties the succession of the empress' eldest son was disputed, and because many emperors had large numbers of progeny, there were wars of succession between rival sons. In an attempt to resolve after-death disputes, the emperor, while still living, often designated a crown prince (). Even such a clear designation, however, was often thwarted by jealousy and distrust, whether it was the crown prince plotting against the emperor, or brothers plotting against each other. Some emperors, like the Yongzheng Emperor, after abolishing the position of Crown Prince, placed the succession papers in a sealed box, only to be opened and announced after his death.\nUnlike, for example, the Japanese monarchy, Chinese political theory allowed for a change in the ruling house. This was based on the concept of the \"Mandate of Heaven\". The theory behind this was that the Chinese emperor acted as the \"Son of Heaven\" and held a mandate to rule over everyone else in the world; but only as long as he served the people well. If the quality of rule became questionable because of repeated natural disasters such as flood or famine, or for other reasons, then rebellion was justified. This important concept legitimized the dynastic cycle or the change of dynasties. This principle made it possible even for peasants to found new dynasties, as happened with the Han and Ming dynasties, and for the establishment of conquest dynasties such as the Mongol-led Yuan dynasty and Manchu-led Qing dynasty. It was moral integrity and benevolent leadership that determined the holder of the \"Mandate of Heaven\".\nThere has been only one lawful female emperor in Chinese history, Wu Zetian, who briefly replaced the Tang dynasty with her own Wu Zhou dynasty. Many women, however, did become de facto leaders, usually as empress dowager. Prominent examples include Empress L\u00fc of the Han, Empress Liu of the Song, and Empress Dowager Cixi of the Qing.\nStyles, names and forms of address.\nAs the emperor had, by law, an absolute position not to be challenged by anyone else, his subjects were to show the utmost respect in his presence, whether in direct conversation or otherwise. When approaching the imperial throne, one was expected to kowtow before the emperor. In a conversation with the emperor, it was considered a crime to compare oneself to the emperor in any way. It was taboo to refer to the emperor by his given name, even for the emperor's own mother, who instead was to use \"Huangdi\" (), or simply \"Er\" ( 'son', for a male emperor). The given names of all the emperor's deceased male ancestors were forbidden from being written, and were avoided () by the use of synonyms, homophones, or leaving out the final stroke of the taboo character. This linguistic feature can sometimes be used to date historical texts, by noting which words in parallel texts are altered.\nThe emperor was never to be addressed as \"you\". Instead, one used \"Bixia\" ( 'bottom of the steps'), corresponding to \"Your Imperial Majesty\" and originally referring to his attendants, \"Huangshang\" ( 'imperial highness', \"Shengshang\" ( 'holy highness') or \"Tianzi\" ( 'Son of Heaven'). The emperor was also alluded to indirectly through reference to the imperial dragon symbology. Servants often addressed the emperor as \"Wansuiye\" ( 'lord of ten thousand years'). The emperor referred to himself as \"zhen\" (), the original Chinese first-person singular pronoun arrogated by Qin Shi Huang, functioning as an equivalent to the royal we. In front of subjects, the emperor may also refer to themselves self-deprecatingly as \"Guaren\" ( 'the morally-deficient one') or \"Gu\" ( 'lonely one').\nIn contrast to the Western convention of using a regnal or personal name (e.g. George V) to refer to a sovereign, the emperor was referred to in the third person simply as \"Huangdi Bixia\" ( 'His Majesty the Emperor') or \"Dangjin Huangshang\" ( 'present emperor above'). Under the Qing, the emperor was usually styled 'His Imperial Majesty the Emperor of the Great Qing Dynasty, Son of Heaven, Lord of Ten Thousand Years', though this varied considerably. In historical texts, the present emperor was almost universally referred to as \"Shang\" ().\nGenerally, emperors also ruled with an era name (). Since the adoption of era names by Emperor Wu of Han and up until the Ming dynasty, the sovereign conventionally changed the era name semi-regularly during his reign. During the Ming and Qing dynasties, emperors simply chose one era name for their entire reign, and people often referred to past emperors with that title. In earlier dynasties, the emperors were known with a temple name given after their death. Most emperors were also given a posthumous name which was sometimes combined with the temple name (e.g. Emperor Shengzu Ren for the Kangxi Emperor). The passing of an emperor was referred to as \"Jiabeng\" ( 'collapse of the imperial chariot') and an emperor that had just died was referred to as \"Daixing Huangdi\" ( 'the emperor of the great journey').\nConsorts and children.\nIn Imperial China, child marriage was the norm. The imperial family was made up of the emperor and the empress () as the primary consort and Mother of the Nation (). In addition, the emperor would typically have several other consorts and concubines (), ranked by importance into a harem, in which the Empress was supreme. However having concubines was not always the case as both Emperor Fei of Western Wei and Hongzhi Emperor were known to be monogamous. Every dynasty had its set of rules regarding the numerical composition of the harem. During the Qing dynasty, for example, imperial convention dictated that at any given time there should be one \"Empress\", one \"Imperial Noble Consort\", two \"Noble Consort\", four \"Consort\" and six \"Concubine\", plus an unlimited number of \"Noble Lady\", \"First Class Attendant\" and \"Second Class Attendant\". Although the emperor had the highest status by law, by tradition and precedent the empress dowager () usually received the greatest respect in the palace and was the decision maker in most family affairs. At times, especially when a young emperor was on the throne, she was the de facto ruler. The emperor's children, the princes () and princesses (), were often referred to by their order of birth\u2014e.g. Eldest Prince or Third Princess. Princes were often given titles of peerage once they reached adulthood. The emperor's brothers and uncles served in court by law, and held equal status with other court officials (). The emperor was always elevated above all others despite any chronological or generational superiority.\nEthnicity.\nRecent scholarship is wary of applying present-day ethnic categories to historical situations. Most Chinese emperors have been considered members of the Han ethnicity, but there were also many Chinese emperors who were of non-Han ethnic origins. The most successful of these were the Khitans of the Liao dynasty, the Jurchens of the Jin dynasty (1115\u20131234), who later ruled the Qing dynasty as the Manchus, and the Mongols of the Yuan dynasty. The orthodox historical view sees these as dynasties as sinicized polities as they adopted Han culture, claimed the Mandate of Heaven, and performed the traditional imperial obligations such as annual sacrifices to Heaven for rain and prosperity. The revisionist New Qing History school, however, argues that the interaction between politics and ethnicity was far more complex and that elements of these dynasties differed from and altered \"native Chinese\" traditions concerning imperial rule.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58670", "revid": "5177550", "url": "https://en.wikipedia.org/wiki?curid=58670", "title": "King (monarch)", "text": ""}
{"id": "58671", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=58671", "title": "Tripropellant rocket", "text": "Rocket that burns 3 propellants at once or 2 fuels with an oxidizer, sequentially\nA tripropellant rocket is a rocket that uses three propellants, as opposed to the more common bipropellant rocket or monopropellant rocket designs, which use two or one propellants, respectively. Tripropellant systems can be designed to have high specific impulse and have been investigated for single-stage-to-orbit designs. While tripropellant engines have been tested by Rocketdyne and NPO Energomash, no tripropellant rocket has been flown.\nThere are two different kinds of tripropellant rockets. One is a rocket engine which mixes three separate streams of propellants, burning all three propellants simultaneously. The other kind of tripropellant rocket is one that uses one oxidizer but two fuels, burning the two fuels in sequence during the flight.\nSimultaneous burn.\nSimultaneous tripropellant systems often involve the use of a high energy density metal additive, like beryllium or lithium, with existing bipropellant systems. In these motors, the burning of the fuel with the oxidizer provides activation energy needed for a more energetic reaction between the oxidizer and the metal. While theoretical modeling of these systems suggests an advantage over bipropellant motors, several factors limit their practical implementation, including the difficulty of injecting solid metal into the thrust chamber; heat, mass, and momentum transport limitations across phases; and the difficulty of achieving and sustaining combustion of the metal.\nIn the 1960s, Rocketdyne test-fired an engine using a mixture of liquid lithium, gaseous hydrogen, and liquid fluorine to produce a specific impulse of 542 seconds, likely the highest measured such value for a chemical rocket motor. Despite the high specific impulse, the technical difficulties of the combination and the hazardous nature of the propellants precluded further development.\nSequential burn.\nIn sequential tripropellant rockets, the fuel is changed during flight, so the motor can combine the high thrust of a dense fuel like kerosene early in flight with the high specific impulse of a lighter fuel like liquid hydrogen (LH2) later in flight. The result is a single engine providing some of the benefits of staging.\nFor example, injecting a small amount of liquid hydrogen into a kerosene-burning engine can yield significant specific impulse improvements without compromising propellant density. This would have been demonstrated by the RD-701, theoretically capable of a specific impulse of 415 seconds in vacuum (higher than the pure LH2/LOX RS-68), where a pure kerosene engine with a similar expansion ratio would achieve 330\u2013340 seconds.\nAlthough liquid hydrogen delivers the largest specific impulse of the plausible rocket fuels, it also requires huge structures to hold it due to its low density. These structures can weigh a lot, offsetting the light weight of the fuel itself to some degree, and also result in higher drag while in the atmosphere. While kerosene has lower specific impulse, its higher density results in smaller structures, which reduces stage mass, and furthermore reduces losses to atmospheric drag. In addition, kerosene-based engines generally provide higher thrust, which is important for takeoff, reducing gravity drag. So in general terms there is a \"sweet spot\" in altitude where one type of fuel becomes more practical than the other.\nTraditional rocket designs use this sweet spot to their advantage via staging. For instance the Saturn Vs used a lower stage powered by RP-1 (kerosene) and upper stages powered by LH2. Some of the early Space Shuttle design efforts used similar designs, with one stage using kerosene into the upper atmosphere, where an LH2 powered upper stage would light and go on from there. The later Shuttle design is somewhat similar, although it used solid rockets for its lower stages.\nSSTO rockets could simply carry two sets of engines, but this would mean the spacecraft would be carrying one or the other set \"turned off\" for most of the flight. With light enough engines this might be reasonable, but an SSTO design requires a very high mass fraction and so has razor-thin margins for extra weight.\nAt liftoff the engine typically burns both fuels, gradually changing the mixture over altitude in order to keep the exhaust plume \"tuned\" (a strategy similar in concept to the plug nozzle but using a normal bell), eventually switching entirely to LH2 once the kerosene is burned off. At that point the engine is largely a straight LH2/LOX engine, with an extra fuel pump hanging onto it.\nThe concept was first explored in the US by Robert Salkeld, who published the first study on the concept in \"Mixed-Mode Propulsion for the Space Shuttle\", \"Astronautics\" \"&amp;\" \"Aeronautics\", which was published in August 1971. He studied a number of designs using such engines, both ground-based and a number that were air-launched from large jet aircraft. He concluded that tripropellant engines would produce gains of over 100% (essentially more than double) in payload fraction, reductions of over 65% in propellant volume and better than 20% in dry weight. A second design series studied the replacement of the Shuttle's SRBs with tripropellant based boosters, in which case the engine almost halved the overall weight of the designs. His last full study was on the \"Orbital Rocket Airplane\" which used both tripropellant and (in some versions) a plug nozzle, resulting in a spaceship only slightly larger than a Lockheed SR-71, able to operate from traditional runways.\nTripropellant engines were built in Russia. Kosberg and Glushko developed a number of experimental engines in 1988 for a SSTO spaceplane called MAKS, but both the engines and MAKS were cancelled in 1991 due to a lack of funding. However, Glushko's RD-701 was never built, and only a smaller-scale test stand version was tested during development. However, Energomash feels that the problems are entirely solvable and that the design does represent one way to reduce launch costs by about 10 times.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58672", "revid": "12975570", "url": "https://en.wikipedia.org/wiki?curid=58672", "title": "Sola scriptura", "text": "Protestant Christian theological doctrine\n (Latin for 'by scripture alone') is a Christian theological doctrine held by most Protestant Christian denominations, in particular the Lutheran and Reformed traditions, that posits the Bible as the sole infallible source of authority for Christian faith and practice. is a formal principle of many Protestant Christian denominations, and one of the five \"solae\" theorized in the early 20th Century in attempts to characterize common ground in disparate Protestant theologies.\nThe Catholic Church considers it heresy and generally the Orthodox churches consider it to be contrary to the phronema of the Church. While the scriptures' meaning is mediated through many kinds of subordinate authority\u2014such as the ordinary teaching offices of a church, the ecumenical creeds, councils of the Catholic Church, or even personal special revelation\u2014 in contrast rejects any infallible authority other than the Bible.\nIt was a foundational doctrinal principle of the Protestant Reformation held by many of the Reformers, who taught that authentication of Scripture is governed by the discernible excellence of the text, as well as the personal witness of the Holy Spirit to the heart of each man. \nBy contrast, the Protestant traditions of Anglicanism, Methodism and Pentecostalism uphold the doctrine of , with scripture being illumined by tradition and reason. The Methodists thought reason should be delineated from experience, though the latter was classically filed under the former and guided by reason, nonetheless this was added, thus changing the \"Anglican Stool\" to the four sides of the Wesleyan Quadrilateral. The Eastern Orthodox Church holds that to \"accept the books of the canon is also to accept the ongoing Spirit-led authority of the church's tradition, which recognizes, interprets, worships, and corrects itself by the witness of Holy Scripture\". The Catholic Church officially regards tradition and scripture as equal, forming a single deposit, and considers the magisterium as the living organ which interprets said deposit. The Roman magisterium thus serves Tradition and Scripture as \"one common source [...] with two distinct modes of transmission\", while some Protestant authors call it \"a dual source of revelation\".\nMany Protestants want to distinguish the view that scripture is the only rule of faith with the exclusion of other sources (nuda scriptura), from the view taught by Luther and Calvin that the scripture alone is infallible, without excluding church tradition in its entirety, viewing them as subordinate and ministerial.\nHistory.\nAugustine of Hippo is frequently cited by Protestants as a Church Father who espoused the doctrine of \"sola scriptura\". The following is a passage in Augustine's letter (82) to Jerome, which is given as evidence for Augustine's adherence to the notion that Scripture is of a uniquely infallible authority in contrast to the writings of all other men. It is also noteworthy that Augustine attributes his view to Jerome.I admit to your Charity that it is from those books alone of the Scriptures, which are now called canonical, that I have learned to pay them such honor and respect as to believe most firmly that not one of their authors has erred in writing anything at all. If I do find anything in those books which seems contrary to truth, I decide that either the text is corrupt, or the translator did not follow what was really said, or that I failed to understand it. But, when I read other authors, however eminent they may be in sanctity and learning, I do not necessarily believe a thing is true because they think so, but because they have been able to convince me, either on the authority of the canonical writers or by a probable reason which is not inconsistent with truth. And I think that you, my brother, feel the same way; moreover, I say, I do not believe that you want your books to be read as if they were those of Prophets or Apostles, about whose writings, free of all error, it is unlawful to doubt.Protestants also argue that Augustine professes the sufficiency of Scripture in this sentence from \"On Christian Doctrine\", \"among the things that are plainly laid down in Scripture are to be found all matters that concern faith and the manner of life\".\nIn the 14th century, Marsilius of Padua believed that the only authority for a Christian is the scriptures, instead of the pope. The same point was made by John Wycliffe who foreshadowed the doctrine in the 14th century.\nJohann Ruchrat von Wesel, Wessel Gansfort and Johannes von Goch also foreshadowed the Protestant view of : they viewed the scripture as being the only infallible authority and denied the authority of the pope or the church as infallible. Peter Abelard believed that human reason was a means of understanding the scriptures, instead of submitting to everything the Catholic Church defines.\nSome elements of sola-scriptura are also foreshadowed by William of Ockham and Girolamo Savonarola.\nOverview.\n is one of the five , considered by some Protestant groups to be the theological pillars of the Reformation. The key implication of the principle is that interpretations and applications of the scriptures don't have the same authority as the scriptures themselves; hence, the authority of the church is viewed as subject to correction by the scriptures, even by an individual member of the church.\nMartin Luther, 16th-century friar and figurehead of the Protestant Reformation, stated that \"a simple layman armed with Scripture is greater than the mightiest pope without it\". The intention of the Reformation was thus to correct what he asserted to be the errors of the Catholic Church, by appealing to the uniqueness of the Bible's textual authority. Catholic doctrine is based on sacred tradition, as well as scripture. rejected the assertion that infallible authority was given to the magisterium to interpret both Scripture and tradition.\n, however, does not ignore Christian history, tradition, or the church when seeking to understand the Bible. Rather, it sees the church as the Bible's interpreter, the \"rule of faith\" () embodied in the ecumenical creeds as the interpretive context, and scripture as the only final authority in matters of faith and practice. As Luther said, \"The true rule is this: God's Word shall establish articles of faith, and no one else, not even an angel can do so.\"\nProtestantism.\nLutheranism.\nLutheranism teaches that the books of the Old and New Testaments are the only divinely inspired books and the only source of divinely revealed knowledge. Scripture alone is the formal principle of the faith in Lutheranism, the final authority for all matters of faith and morals because of its inspiration, authority, clarity, efficacy, and sufficiency.\nInspiration.\nLutheranism teaches that the Bible does not merely contain the Word of God, but every word of it is, because of verbal inspiration, the word of God. Most Lutheran traditions acknowledge that understanding scriptures is complex given that the Bible contains a collection of manuscripts and manuscript fragments that were written and collected over thousands of years. For example, the Evangelical Lutheran Church in America teaches that \"Lutheran Christians believe that the story of God's steadfast love and mercy in Jesus is the heart and center of what the Scriptures have to say.\"\nAs Lutherans confess in the Nicene Creed, the Holy Spirit \"spoke through the prophets\". The Apology of the Augsburg Confession identifies \"Holy Scripture\" with the Word of God and calls the Holy Spirit the author of the Bible. Because of this, Lutherans confess in the Formula of Concord, \"we receive and embrace with our whole heart the prophetic and apostolic Scriptures of the Old and New Testaments as the pure, clear fountain of Israel\".\nThe prophetic and apostolic Scriptures are said by the Lutheran church to be authentic as written by the prophets and apostles, and that a correct translation of their writings is God's Word because it has the same meaning as the original Biblical Hebrew and Koine Greek. A mistranslation is not God's word, and no human authority can invest it with divine authority.\nComposition and authority.\nFor early Lutherans, \"sola scriptura\" did not mean that all books of the Bible are equal: there is an authoritative first-class subset for dogma: this has been called \"the canon within the canon.\"\nThe phrase \"prophetic and apostolic\" serves to exclude as sources of dogma those (canonical) biblical books which do not directly deal with Christ or the Gospel: this may not only exclude the Old Testament Deuterocanonicals but the New Testament \"antilegomena\" such as Hebrews, James, 2 Peter, 2 &amp; 3 John, Jude and Revelation. \nEarly Lutherans used \"apostolic\" in what has been called a theological rather than historical sense: Luther wrote \"what preaches Christ would be apostolic\". At one stage of Luther's developing opinion, he rejected the Epistle of James as a foundation of the faith and held that the Book of Revelation was neither prophetic nor apostolic in his terms. \nLuther's followers to an extent restored the historical link between authority and canonicity by appealing to ideas of New Testament \"antilegomena\" to favour those books deemed to have initially been accepted by all the early churches. Martin Chemnitz listed the first-class books of the Old and New Testament: for Chemnitz \"no dogma ought therefore to be drawn out of these books\" (the antilegomena) \"which does not have reliable and clear foundations and testimonies in other canonical books. Nothing controversial can be proved out of these books, unless there are other proofs and confirmations in the canonical books,\" which moderates or contradicts Luther's general hermeneutic principle \"scripture interprets scripture.\" However, Chemnitz himself had to use \"antilegomena\" to justify some anti-Roman positions. \nBy the early 20th century, Lutheran theologian J.P. Koehler taught that a statement of the \"homologoumena\" must not be restricted by a statement taken from the \"antilegomena\". However, conventionally many Lutheran theologians hold that there is no statement in the former that actually contradicts the latter, as a matter of logical necessity or actual examination, making the idea of a canon-within-the-canon moot: Catholic theologians have disputed this. Another contemporary theologian August Pieper wrote that the Lutheran church \"wisely failed to determine formally the extent of the New Testament canon\" in the sense of not explicitly formalizing the canon-within-the-canon.\nAccording to Lutheran scholars, the so-called apocryphal books of the Old Testament were not written by the prophets, nor by inspiration; they contain errors, were never included in the Palestinian Canon that Jesus was theorized (before the discovery of the Dead Sea Scrolls) to use, and therefore are not a part of scripture.\nDivine authority.\nScripture, regarded as the word of God, carries the full authority of God in Lutheranism: every single statement of the Bible calls for instant, unqualified and unrestricted acceptance. Every doctrine of the Bible is the teaching of God and therefore requires full agreement. Every promise of the Bible calls for unshakable trust in its fulfillment; every command of the Bible is the directive of God himself and therefore demands willing observance.\nWhat is said here of \"every statement of the Bible\" does not represent the faith of all Lutherans: a 2001 survey showed that 72 percent of members of the Evangelical Lutheran Church in America do not accept that everything in the Bible is literal, but that it may contain scientific or historical errors or describe events symbolically.\nClarity.\nLutheranism teaches that the Bible presents all doctrines and commands of the Christian faith clearly; that God's word is freely accessible to every reader or hearer of ordinary intelligence, without requiring any special education. It also teaches that readers must understand the language God's word is presented in, and not be so preoccupied by contrary thoughts so as to prevent understanding. It teaches that, consequently, no one needs to wait for any clergy, and pope, scholar, or ecumenical council to explain the real meaning of any part of the Bible.\nEfficacy.\nLutheranism teaches that scripture is united with the power of the Holy Spirit and with it, not only demands but also creates the acceptance of its teaching. This teaching produces faith and obedience. Scripture is not a dead letter, but rather, the power of the Holy Spirit is inherent in it. Scripture does not compel a mere intellectual assent to its doctrine, resting on logical argumentation, but rather it creates the living agreement of faith. The Smalcald Articles affirm, \"in those things which concern the spoken, outward Word, we must firmly hold that God grants His Spirit or grace to no one, except through or with the preceding outward Word\".\nSufficiency.\nLutheranism teaches that the Bible contains everything that one needs to know in order to obtain salvation and to live a Christian life. There are no deficiencies in scripture that need to be filled with by tradition, pronouncements of the Pope, new revelations, or present-day development of doctrine.\nReformed faith (Calvinism).\n\"Sola scriptura\" in the Reformed faith possesses the same characteristics to those of Lutheranism: inspiration, authority, clarity, efficacy, and sufficiency.\nArticle 3 of the Belgic Confession, a Reformed confessional of faith, teaches the divine inspiration of Scripture, \"We confess that this Word of God was not sent nor delivered by the will of man, but \"that holy men of God spake as they were moved by the Holy Ghost\", as the apostle Peter saith ().\"2\nArticle 7 teaches the sole infallibility or unique authority of Scripture, \"Neither do we consider of equal value any writing of men, however holy these men may have been, with those divine Scriptures; nor ought we to consider custom, or the great multitude, or antiquity, or succession of times and persons, or councils, decrees or statutes, as of equal value with the truth of God\".4\nChapter 1.7 of Westminster Confession of Faith, another authoritative Reformed confession, speaks of the use of \"ordinary means\" (such as turning to pastors and teachers) for reaching an understanding of what is contained in scripture and what is necessary to know, while still espousing the doctrine of the clarity or perspicuity of Scripture; \"All things in Scripture are not alike plain in themselves, nor alike clear unto all, yet those things which are necessary to be known, believed, and observed for salvation, are so clearly propounded, and opened in some place of Scripture or other, that not only the learned, but the unlearned, in a due use of the ordinary means, may attain unto a sufficient understanding of them\".\nIn the same chapter, \"efficacy\" is ascribed to the doctrine of Scripture.\nThe sufficiency of Scripture is also taught in Article 7 of the Belgic Confession, \"We believe that those Holy Scriptures fully contain the will of God, and that whatsoever man ought to believe unto salvation is sufficiently taught therein.\"4\n\"Nuda scriptura\" (Fundamentalist Evangelicals, etc.).\nThe view that scripture is the only rule of faith to the total exclusion of all other sources, even non-infallible or less authoritative ones such as historical or patristic evidence. (Sometimes called \"solo scriptura\".)\nAlternatives.\n\"Prima scriptura\" (Anglicanism, Methodism).\n may be contrasted with , which holds that, besides canonical scripture, there are other guides for what a believer should believe, and how he or she should live. Examples of this include the general revelation in creation, traditions, charismatic gifts, mystical insight, angelic visitations, conscience, common sense, the views of experts, the spirit of the times or something else. suggests that ways of knowing or understanding God and his will, that do not originate from canonized scripture, are in a second place, perhaps helpful in interpreting that scripture, but testable by the canon and correctable by it, if they seem to contradict the scriptures.\nTwo Christian denominations that uphold the position of are Anglicanism and Methodism. In the Anglican tradition, scripture, tradition, and reason form the \"Anglican triad\" or \"three-legged stool\", formulated by the Anglican theologian Richard Hooker. With respect to the Methodist tradition, \"A Dictionary for United Methodists\" states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Building on the Anglican theological tradition, Wesley added a fourth emphasis, experience. The resulting four components or \"sides\" of the [Wesleyan] quadrilateral are (1) Scripture, (2) tradition, (3) reason, and (4) experience. For United Methodists, Scripture is considered the primary source and standard for Christian doctrine. Tradition is experience and the witness of development and growth of the faith through the past centuries and in many nations and cultures. Experience is the individual's understanding and appropriating of the faith in the light of his or her own life. Through reason the individual Christian brings to bear on the Christian faith discerning and cogent thought. These four elements taken together bring the individual Christian to a mature and fulfilling understanding of the Christian faith and the required response of worship and service.\n\"Sola scriptura\" rejects any original infallible authority, other than the Bible. In this view, all secondary authority is derived from the authority of the scriptures and is therefore subject to reform when compared to the teaching of the Bible. Church councils, preachers, biblical commentators, private revelation, or even a message allegedly from an angel or an apostle are not an original authority alongside the Bible in the \"sola scriptura\" approach.\nScripture in sacred tradition (Catholicism, Eastern Orthodoxy).\nFor the Eastern Orthodox, \"the Holy Bible forms a part of Holy Tradition, but does not lie outside of it. One would be in error to suppose that Scripture and Tradition are two separate and distinct sources of Christian Faith, as some do, since there is, in reality, only one source; and the Holy Bible exists and found its formulation within Tradition\".\nThe Tradition here in question comes from the apostles and hands on what they received from Jesus' teaching and example and what they learned from the Holy Spirit. As explained by Athanasius of Alexandria, \"Let us look at the very tradition, teaching, and faith of the Catholic Church from the very beginning, which the Logos gave (edoken), the Apostles preached (ekeryxan), and the Fathers preserved (ephylaxan). Upon this the Church is founded (tethemeliotai)\" (St. Athanasius, \"First Letter to Serapion\", 28).\nThe Catholic Church has not seen Scripture and the Sacred Tradition of the faith as different sources of authority, but that Scripture was handed down as part of Sacred Tradition (see 2 Thessalonians 2:15, 2 Timothy 2:2). (The Catholic Church distinguishes Sacred Tradition from lesser ecclesiastical traditions\u2014local customs that may be retained, modified or even abandoned.) \nThe Catholic Church holds that the Gospel was transmitted by the apostles by their oral preaching, by example, and by observances handed on what they had received from the lips of Christ, from living with Him, and from what He did, or what they had learned through the prompting of the Holy Spirit; as well as by those apostles and apostolic men who under the inspiration of the Holy Spirit committed the message of salvation to writing. \"This living transmission, accomplished in the Holy Spirit, is called Tradition, since it is distinct from Sacred Scripture, though closely connected to it.\" \"Sacred Tradition and Sacred Scripture make up a single sacred deposit of the Word of God.\"\nThe doctrines which constitute Sacred Tradition are also perceived by the Church as cohesive in nature. The proper interpretation of the Scriptures was seen as part of the faith of the Church and seen indeed as the manner in which biblical authority was upheld (see Book of Acts 15:28\u201329). The meaning of Scripture was seen as proven from the faith universally held in the churches (see Phil. 2:1, Acts 4:32), and the correctness of that universal faith was seen as proven from the Scriptures and apostolic Sacred Tradition (see 2 Thes. 2:15, 2 Thes. 3:6, 1 Corinthians 11:2). The Biblical canon itself was thus viewed by the Church as part of the Church's tradition, as defined by its leadership and acknowledged by its laity. The first generation of Christians did not yet have a written New Testament, and the New Testament itself demonstrates the process of living Tradition.\nThe Catholic \"Dei verbum\" and the papal encyclicals \"Providentissimus Deus\" by Pope Leo XIII and \"Divino afflante Spiritu\" by Pope Pius XII set out Catholic teaching on tradition versus individual interpretation.\nApostolic tradition.\nCatholics apply to apostolic tradition many of the qualities that many Protestants apply to scripture alone. For example, the 1978 Evangelical declaration \"Chicago Statement on Biblical Inerrancy\", states: \"We affirm that inspiration was the work in which God by His Spirit, through human writers, gave us His Word. The origin of Scripture is divine. The mode of divine inspiration remains largely a mystery to us. We deny that inspiration can be reduced to human insight, or to heightened states of consciousness of any kind.\"\nSince the Catholic Church professes that apostolic tradition and scripture are both the word of God, Catholics can affirm that many of these propositions apply equally well to tradition: It is the work of the Holy Spirit, which cannot be reduced to human insight or heightened consciousness.\nThis ties in with the question of what constitutes apostolic tradition. The Catechism of the Catholic Church states that this tradition is given \"by the apostles who handed on, by the spoken word of their preaching, by the example they gave, by the institutions they established, what they themselves had received \u2013 whether from the lips of Christ, from his way of life and his works, or whether they had learned it at the prompting of the Holy Spirit\".\nThere is a distinction between apostolic tradition, which in the Catholic view does not change (but needs elucidation), and theology, such as moral theology and doctrine, which develops. According to Catholic academic and judge John T. Noonan Jr. \"history cannot leave a principle or a teaching untouched; every application to a situation affects our understanding of the principle itself.\"\nAdditional Scriptures (Church of Jesus Christ of Latter-day Saints).\nThe Church of Jesus Christ of Latter-day Saints (LDS Church) states: \"The official, canonized scriptures of the Church, often called the standard works, are the Bible, the Book of Mormon, the Doctrine and Covenants, and the Pearl of Great Price.\" The Church accepts the Bible as the word of God \"as far as it is translated correctly,\" and it regards parts of the Apocrypha, some writings of the Protestant Reformers and non-Christian religious leaders, and the non-religious writings of some philosophers \u2013 and, notably, the Constitution of the United States of America \u2013 to be \"inspired\", though \"not canonical\".\nRegarding the Church's view on the belief held by many that the Holy Bible, as presently constituted (in any translation, or even from the extant Hebrew and Greek manuscripts), is inerrant or infallible, etc, or the doctrine of \"sola scriptura\", the Church has said the following: \"The Latter-day Saints have a great reverence and love for the Bible. They study it and try to live its teachings. They treasure its witness of the life and mission of the Lord Jesus Christ. The Prophet Joseph Smith studied the Bible all his life, and he taught its precepts. He testified that a person who can 'mark the power of Omnipotence, inscribed upon the heavens, can also see God\u2019s own handwriting in the sacred volume: and he who reads it oftenest will like it best, and he who is acquainted with it, will know the hand [of the Lord] wherever he can see it'.\"\nThe Church further said on the subject of \"sola scriptura\": \"Latter-day Saints believe in an open scriptural canon, which means that there are other books of scripture besides the Bible (such as the Book of Mormon) and that God continues to reveal His word through living prophets. The argument is often made that to be a Christian means to assent to the principle of \"sola scriptura,\" or the self-sufficiency of the Bible. But to claim that the Bible is the final word of God\u2014more specifically, the final written word of God\u2014is to claim more for the Bible than it claims for itself. Nowhere does the Bible proclaim that all revelations from God would be gathered into a single volume to be forever closed and that no further scriptural revelation could be received.\"\nCritiques.\nCatholic.\nFollowing the Protestant churches' separation from the Catholic Church, the relatively new idea of came under serious critique by the Catholic theologians. \nSelf-contradictory.\nThe American Roman Catholic author and television presenter Patrick Madrid wrote that is self-referentially incoherent, as the Bible itself does not teach , and therefore the belief that the scriptures are the only source of Christian belief is self-contradicting given that it cannot be supported without extra-scriptural doctrine.\nUncertain.\nIn the 2008 book \"Catholicism and Science\", the authors Peter M.\u00a0J. Hess and Paul Allen wrote that is \"inherently divisive\", citing the Marburg Colloquy where Martin Luther and Huldrych Zwingli debated the real presence of Christ in the Eucharist on scriptural grounds but were unable to reach agreement on sacramental union. Hess and Allen argue that, when scripture is seen as the only source of infallible teaching, its interpretation is subject to fallible interpretation, and without an infallible interpreter, a certainty of Christian belief is not possible.\nRequires external authority.\nThe Roman Catholic \"Encyclopedia of Theology\" notes that, since the 27 books that make up the New Testament canon of scripture are not based on a scriptural list that authenticates them to be inspired, their legitimacy would be impossible to distinguish with certainty without appealing to another infallible source, such as the magisterium of the Catholic Church, which assembled and authenticated this list at Synod of Rome and the Synod of Carthage, both of which took place in the fourth century. Before this, a compiled and authenticated Bible as it is now known did not yet exist.\nUnscriptural.\nThe American Roman Catholic writer Dave Armstrong wrote that there are several examples of Jesus and his Apostles accepting oral and extrabiblical tradition in the New Testament:\nArmstrong argues that since Jesus and the Apostles acknowledge authoritative Jewish oral tradition, Christians can therefore not dispute oral tradition's legitimacy and authority. However, according to scripture, Jesus also challenges some man-made Jewish traditions. But Catholics also make a similar distinction today between Sacred Tradition, which is considered inerrant, and lesser ecclesiastical traditions or disciplines, which can be subject to change. In the Catholic view, one can know what belongs to Sacred Tradition and what is an ecclesiastical tradition or discipline by consulting the Magisterium of the Church. The difference between the two, in the Catholic view, is that Sacred Tradition is apostolic and part of the deposit of faith, while ecclesiastical traditions and disciplines are not.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "58673", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=58673", "title": "Liquid hydrogen", "text": "Liquid state of the element hydrogen\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nLiquid hydrogen () is the liquid state of the element hydrogen. Hydrogen is found naturally in the molecular H2 form.\nTo exist as a liquid, H2 must be cooled below its critical point of 33\u00a0K. However, for it to be in a fully liquid state at atmospheric pressure, H2 needs to be cooled to . A common method of obtaining liquid hydrogen involves a compressor resembling a jet engine in both appearance and principle. Liquid hydrogen is typically used as a concentrated form of hydrogen storage. Storing it as liquid takes less space than storing it as a gas at normal temperature and pressure. However, the liquid density is very low compared to other common fuels. Once liquefied, it can be maintained as a liquid for some time in thermally insulated containers.\nThere are two spin isomers of hydrogen: Room temperature hydrogen is 75% orthohydrogen. At cryogenic temperature it converts exothermically to parahydrogen. The thermodynamic lowest energy state for liquid hydrogen consists of 99.79% parahydrogen and 0.21% orthohydrogen. To avoid that the exothermic heat release occurs in storage, and thereby causes excessive boil-off, catalytic conversion to parahydrogen during liquification is employed.\nHydrogen requires a theoretical minimum of to liquefy, and including converting the hydrogen to the para isomer. Existing liquification facilities use compared to a heating value of hydrogen. More recent work shows future facilities are expected to cut the specific energy demand by half to \nHistory.\nIn 1885, Zygmunt Florenty Wr\u00f3blewski published hydrogen's critical temperature as ; critical pressure, ; and boiling point, .\nHydrogen was liquefied by James Dewar in 1898 by using regenerative cooling and his invention, the vacuum flask. The first synthesis of the stable isomer form of liquid hydrogen, parahydrogen, was achieved by Paul Harteck and Karl Friedrich Bonhoeffer in 1929.\nSpin isomers of hydrogen.\nThe two nuclei in a dihydrogen molecule can have two different spin states.\nParahydrogen, in which the two nuclear spins are antiparallel, is more stable than orthohydrogen, in which the two are parallel. At room temperature, gaseous hydrogen is mostly in the ortho isomeric form due to thermal energy, but an ortho-enriched mixture is only metastable when liquified at low temperature. It slowly undergoes an exothermic reaction to become the para isomer, with enough energy released as heat to cause some of the liquid to boil. To prevent loss of the liquid during long-term storage, it is therefore intentionally converted to the para isomer as part of the production process, typically using a catalyst such as iron(III) oxide, activated carbon, platinized asbestos, rare earth metals, uranium compounds, chromium(III) oxide, or some nickel compounds.\nUses.\nLiquid hydrogen is a common liquid rocket fuel for rocketry application and is used by NASA and the U.S. Air Force, which operate a large number of liquid hydrogen tanks with an individual capacity up to 3.8 million liters (1 million U.S. gallons).\nIn most rocket engines fueled by liquid hydrogen, it first cools the nozzle and other parts before being mixed with the oxidizer, usually liquid oxygen, and burned to produce water with traces of ozone and hydrogen peroxide. Practical H2\u2013O2 rocket engines run fuel-rich so that the exhaust contains some unburned hydrogen. This reduces combustion chamber and nozzle erosion. It also reduces the molecular weight of the exhaust, which can increase specific impulse, despite the incomplete combustion.\nLiquid hydrogen can be used as the fuel for an internal combustion engine or fuel cell. Various submarines, including the Type 212 submarine, Type 214 submarine, and others, and concept hydrogen vehicles have been built using this form of hydrogen, such as the DeepC, BMW H2R, and others. Due to its similarity, builders can sometimes modify and share equipment with systems designed for liquefied natural gas (LNG). Liquid hydrogen is being investigated as a zero carbon fuel for aircraft. Because of the lower volumetric energy, the hydrogen volumes needed for combustion are large. Unless direct injection is used, a severe gas-displacement effect also hampers maximum breathing and increases pumping losses.\nLiquid hydrogen is also used to cool neutrons to be used in neutron scattering. Since neutrons and hydrogen nuclei have similar masses, kinetic energy exchange per interaction is maximum (elastic collision). Finally, superheated liquid hydrogen was used in many bubble chamber experiments.\nThe first thermonuclear bomb, Ivy Mike, used liquid deuterium, also known as hydrogen-2, for nuclear fusion.\nProperties.\nThe product of hydrogen combustion in a pure oxygen environment is solely water vapor. However, the high combustion temperatures and present atmospheric nitrogen can result in the breaking of N\u2261N bonds, forming toxic NOx if no exhaust scrubbing is done. Since water is often considered harmless to the environment, an engine burning it can be considered \"zero emissions\". In aviation, however, water vapor emitted in the atmosphere contributes to global warming (to a lesser extent than CO2). Liquid hydrogen also has a much higher specific energy than gasoline, natural gas, or diesel.\nThe density of liquid hydrogen is only 70.85\u00a0kg/m3 (at 20\u00a0K), a relative density of just 0.07. Although the specific energy is more than twice that of other fuels, this gives it a remarkably low volumetric energy density, many fold lower.\nLiquid hydrogen requires cryogenic storage technology such as special thermally insulated containers and requires special handling common to all cryogenic fuels. This is similar to, but more severe than liquid oxygen. Even with thermally insulated containers it is difficult to keep such a low temperature, and the hydrogen will gradually leak away (typically at a rate of 1% per day). It also shares many of the same safety issues as other forms of hydrogen, as well as being cold enough to liquefy, or even solidify atmospheric oxygen, which can be an explosion hazard.\nThe triple point of hydrogen is at 13.81\u00a0K and 7.042\u00a0kPa.\nSafety.\nDue to its cold temperatures, liquid hydrogen is a hazard for cold burns. Hydrogen itself is biologically inert and its only human health hazard as a vapor is displacement of oxygen, resulting in asphyxiation, and its very high flammability and ability to detonate when mixed with air. Because of its flammability, liquid hydrogen should be kept away from heat or flame unless ignition is intended. Unlike ambient-temperature gaseous hydrogen, which is lighter than air, hydrogen recently vaporized from liquid is so cold that it is heavier than air and can form flammable heavier-than-air air\u2013hydrogen mixtures.\nAn indirect safety risk exists due to the cryogenic temperature being lower than the boiling point of oxygen. Exposure of insuffiently thermally insulated liquid hydrogen containments can result in air condensing on the outside of the containment, leading to oxygen enrichment that can spontaneously ignite flammable materials.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58674", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=58674", "title": "Sola fide", "text": "Christian theological doctrine\n, meaning \"faith alone,\" is a Christian doctrine that teaches sinners are forgiven and declared \u201cnot guilty\u201d through faith\u2014apart from good works or religious deeds. Protestants traditionally believe that this doctrine of salvation is the cornerstone of Christianity, the very teaching \"upon which the church stands or falls\".\nIn classical Protestant theologies, works are the natural \"evidence\" of faith, but they do not determine salvation. Confessional Lutheranism sees justification as \"free forgiveness\", received only through faith. Without faith, God's forgiveness is rejected and its benefits are forfeited. Methodism affirms the doctrine of justification by faith alone, but holds that holy living with the goal of Christian perfection (entire sanctification) is essential for salvation; maintenance of sanctification is contingent on continual faith in and obedience to God. \nAnabaptist theology categorically rejects the Lutheran and Reformed doctrine of \"sola fide\", and instead emphasizes a \"faith that works\"; Anabaptists teach that \"justification [began] a dynamic process by which the believer partook of the nature of Christ and was so enabled to live increasingly like Jesus.\"\nUnlike the Protestant teaching of \"faith apart from works\", Catholicism teaches that salvation is by \"faith and works\", holding to the concept of \"fides formata\" \u2014 faith formed by charity. Catholic theology emphasizes that faith must be accompanied by personal \"merit\" and the \"observance of the commandments.\" Eastern Orthodoxy shares a similar view, teaching that salvation requires both faith and the sinner\u2019s active cooperation.\nOrigin of the term.\nAlthough modern Catholic scholars are against Luther's use of the word \"only\", Catholic sources before the Reformation had done the same. In 1916, Lutheran scholar Theodore Engelder published an article titled \"The Three Principles of the Reformation: \"Sola Scriptura, Sola Gratia, Sola Fides\"\" (\"only scripture, only grace, only faith\").\nMartin Luther.\nMartin Luther elevated \"sola fide\" to the principal cause of the Protestant Reformation, the rallying cry of the Lutheran cause, and the chief distinction of the Lutheran and Reformed branches of Christianity from Roman Catholicism.\nLuther added the word \"allein\" (\"alone\" in German) to Romans controversially so that it read: \"So now we hold, that man is justified without the help of the works of the law, \"alone\" through faith\". The word \"alone\" does not appear in the Greek manuscripts and Luther acknowledged this fact, but he defended his translation by maintaining that the adverb \"alone\" was required by idiomatic German:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I knew very well that the word \"solum\" [\"alone\" in Latin] is not in the Greek or Latin text (\u2026) It is a fact that these four letters S O L A are not there (\u2026) At the same time (\u2026) it belongs there if the translation is to be clear and vigorous. I wanted to speak German, not Latin or Greek, since it was German I had undertaken to speak in the translation. But it is the nature of our German language that in speaking of two things, one of which is affirmed and the other denied, we use the word \"solum\" (\"allein\") along with the word \"nicht\" [not] or \"kein\" [no]. For example, we say, 'The farmer brings \"allein\" [only] grain and \"kein\" [no] money.\nLuther further claimed that \"sola\" was used in theological traditions before him and this adverb makes Paul's intended meaning clearer:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I am not the only one, nor the first, to say that \"faith alone\" makes one righteous. There was Ambrose, Augustine and many others who said it before me. And if a man is going to read and understand St. Paul, he will have to say the same thing, and he can say nothing else. Paul's words are too strong \u2013 they allow no works, none at all! Now if it is not works, it must be faith alone.\nTranslations.\nHistorically, expressions similar to \"sola fide\" had appeared in a number of Catholic bible translations:\nThe \"faith alone\" expression also appears in at least nine modern English Bible translations:\nHistory.\nEarly Church.\nClement of Rome.\nAccording to Protestant historian Philip Schaff faith alone was not clearly taught by most church fathers, except for Clement of Rome. In contrast, the Catholic Encyclopedia indicates that Clement of Rome held works to be meritorious and holding works to be a part of justification.\nAccording to Baptist theologian Thomas Schreiner \"sola fide\" can be found in some apostolic fathers. He contends that Clement of Rome, Ignatius of Antioch and the Epistle to Diognetus viewed salvation as being God's work granted to those who exercise faith, which then causes works. Clement's view on justification has caused much scholarly discussion, because Clement asserted: \"we are not justified through ourselves, but through faith\", but still emphasizing God's judgement upon wickedness. Some see Clement as believing in faith alone but that faith will lead into doing good works, while some others have argued that Clement held synergist views.\nEarly literature.\nThe Epistle to Diognetus talks much about the human inability to merit justification themselves by their own good works.\nThe Shepherd of Hermas has a clear rejection of the faith alone doctrine, instead holding works to have merit. The Didache also appears to see works as meritorious, though not unambiguously.\nThomas R. Schreiner argued that the Odes of Solomon taught that works do not justify a person, but instead faith, he also argued that the book supports imputed righteousness.\nPatristic statements.\nThomas Schreiner asserted that because justification wasn't a big issue in the patristic period, \"thus the theology isn\u2019t always integrated or consistent\", however Schreiner argued that people such as John Chrysostom, and Ambrosiaster had similarities to the views of justification as the reformers did:\"By faith alone one is freely forgiven of all sins and the believer is no longer burdened by the Law for meriting good works. Our works, however, are demonstrative of our faith and will determine whether we are ultimately justified\" &lt;br&gt; \u2014Ambrosiaster \nSchreiner observes that Augustine of Hippo differs from the reformers as he understood the word \"justify\" to mean make righteous and not declare righteous, and thus he denied imputed righteousness. He also saw salvation as a process, despite that he still held very grace-oriented views of salvation, having similarities to the views reformers later would believe. Jovinian, who is often seen as a heretic by Catholics and as a forerunner by Protestants, has been argued to have been a very early witness to a Protestant view of justification. It has been argued that Marius Victorinus and Hilary of Poitiers taught faith alone. Marius Victorinus wrote that our own merits do not justify us and that we are justified by faith alone, however works should follow from that faith. Hilary of Poitiers seemed to have believed grace oriented views of salvation, which is by faith: as he declared \"salvation is entirely by faith\", Hilary often contrasts salvific faith and salvation by works, which leads to unbelief. He also believed salvation to be by grace in the Old Testament and he saw Abraham as a model for the Jews, who was justified by faith.\nSchreiner wrote that some statements made by Origen are consistent with the doctrine of faith alone, claiming that faith is the foundation of justification, but that he is not very clear on his view of justification.\nClement of Alexandria taught that faith was the basis of salvation, however he also believed that faith was also the basis of \"gnosis\" which for him mean spiritual and mystical knowledge.\nBecause Polycarp does not make enough statements on salvation, he could have been either believed \"sola fide\" or that both works and faith are needed, but it is unclear which one he believed from his few statements.\nCatholic Answers wrote that Origen, Cyprian, Aphraates, Gregory of Nyssa, Clement of Alexandria, Gregory the Great and Jerome held that both faith and works are part of the process of salvation.Whoever dies in his sins, even if he profess to believe in Christ, does not truly believe in him; and even if that which exists without works be called faith, such faith is dead in itself, as we read in the epistle bearing the name of James\u201d \u2013 Origen\nPaul, joining righteousness to faith and weaving them together, constructs of them the breastplates for the infantryman, armoring the soldier properly and safely on both sides. A soldier cannot be considered safely armored when either shield is disjoined from the other. Faith without works of justice is not sufficient for salvation; neither is righteous living secure in itself of salvation, if it is disjoined from faith \u2013 Gregory of Nyssa\nNeither faith without works nor works without faith is of any avail, except, perhaps, that works may go towards the reception of faith, just as Cornelius, before he had become one of the faithful, merited to be heard on account of his good works. From this it can be gathered that his performance of good works furthered his reception of faith\u201d \u2013 Gregory the Great\nWhen we hear, \u2018Your faith has saved you,\u2019 we do not understand the Lord to say simply that they will be saved who have believed in whatever manner, even if works have not followed. To begin with, it was to the Jews alone that he spoke this phrase, who had lived in accord with the law and blamelessly and who had lacked only faith in the Lord \u2013 Clement of AlexandriaAccording to Ken Wilson, Augustine criticized unnamed individuals who held to a stronger view of faith alone as espoused by Free Grace theologians. The individuals Augustine criticized held that one is saved by faith alone and that God's future judgement for Christians only consisted of temporal punishment and reward; hell was out of question. Thus, they held that deeds such as repentance and good works were not necessary to enter heaven.\nMedieval.\nEarly medieval thinkers whose statements on faith that have been interpreted as preceding Luther's include Gottschalk (c. 808 \u2013 868 AD), Claudius of Turin (8.\u20139. century AD)\nSome have argued that Ildefonsus and Julian of Toledo believed that faith alone was sufficient for salvation, Julian of Toledo made statements such as \"all effort of human argument must be suspended where faith alone is sufficient\".\nProtestants also have claimed that the writings of Bernard of Clairvaux include the doctrine of justification by faith alone.\nPre-Reformation.\nThe doctrine of faith alone precedes Martin Luther in the theologies of many so-called proto-Protestant reformers: Wessel Gansfort (1419 \u2013 1489), Jacques Lef\u00e8vre d'\u00c9taples (c. 1455 \u2013 1536), and possibly also in Johann Pupper (c.\u20091400 \u2013 1475). The doctrine of \"sola fide\" also seems to appear in the doctrine of John Wycliffe (c. 1328 \u2013 1384), as he stated: \"Trust wholly in Christ; rely altogether on his sufferings; beware of seeking to be justified in any other way than by his righteousness. Faith in our Lord Jesus Christ is sufficient for salvation.\". According to some historians Luther's view on the doctrine of \"sola fide\" was influenced by the Italian reformer Girolamo Savonarola.\nCentrality in the doctrine of the Protestant Reformation.\nThe doctrine of \"sola fide\" asserts that God's pardon for guilty sinners is granted to and received through faith alone, excluding all \"works\" (good deeds). Without God's input, mankind, Christianity asserts, is fallen and sinful, meaning its actions and omissions are afflicted by the curse and most if not all would face God's wrath due to the fall of man (which spelt the end of Eden). God, the faith holds, sent his only Son in human form, to be reborn in all mankind so through Jesus Christ alone (\"solus Christus\") sinners may receive pardon (justification), which is granted solely through faith.\nChrist's righteousness, according to the followers of \"sola fide\", is imputed (or attributed) by God to sinners coming to a state of true, loving belief (as opposed to infused or imparted). If so God's verdict and potential pardon is from genuinely held Christian faith (or in a few more liberal sects, all of Christ's principles) rather than anything in the sinner. This contrasts with other supposed means of grace, such as priestly confession and rituals such as weekly taking of the sacrament. See the \"ordo salutis\" for more detail on the doctrine of salvation considered more broadly than justification by faith alone.\nThe standalone \"sola fide\" justification of souls is a tenet of the Lutheran and Reformed churches but neither the Roman Catholic nor the Eastern Orthodox churches affirm it. These Protestant traditions exclude all human works (except the works of Jesus Christ, which form the basis of justification) from the legal verdict (or pardon) of justification. According to Martin Luther, justification by faith alone is the article on which the Church stands or falls. Thus, \"faith alone\" is foundational to Lutheranism and Reformed Christianity, and as a formula distinguishes it from other Christian denominations.\nLutheran theology.\nFrom 1510 to 1520, Martin Luther lectured on the Book of Psalms and the Pauline epistles to the Galatians, Hebrews, and Romans. As he studied these portions of the Bible, he came to view the use of terms such as penance and righteousness by the Roman Catholic Church in new ways (see Genesis , Galatians , Romans ). He became convinced that the Roman Catholic Church was corrupt in its ways and had lost sight of what he saw as several of the central truths of Christianity, the most important of which, for Luther, was the doctrine of justification\u2014God's act of declaring a sinner righteous\u2014by faith alone through God's grace. Therefore, he began to teach that salvation or redemption is a gift of God's grace, attainable exclusively through faith in Jesus Christ.\n\"This one and firm rock, which we call the doctrine of justification,\" insisted Luther, \"is the chief article of the whole Christian doctrine, which comprehends the understanding of all godliness.\" He also called this doctrine the \"articulus stantis et cadentis ecclesiae\" (\"article of the standing and falling church\"): \"if this article stands, the Church stands; if it falls, the Church falls.\" For Lutherans this doctrine is the material principle of theology in relation to the Bible, which is the formal principle. They believe justification by grace alone through faith alone in Christ's righteousness alone is the gospel, the core of the Christian faith around which all other Christian doctrines are centered and based.\nLuther came to understand justification as entirely the work of God. When God's righteousness is mentioned in the gospel, it is God's action of declaring righteous the unrighteous sinner who has faith in Jesus Christ. The righteousness by which the person is justified (declared righteous) is not his own (theologically, \"proper\" righteousness) but that of another, Christ (\"alien\" righteousness). \"That is why faith alone makes someone just and fulfills the law,\" said Luther. \"Faith is that which brings the Holy Spirit through the merits of Christ.\" Thus faith, for Luther, is a gift from God, and \"a living, bold trust in God's grace, so certain of God's favor that it would risk death a thousand times trusting in it.\" This faith grasps Christ's righteousness and appropriates it for the believer. He explained his concept of \"justification\" in the Smalcald Articles:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200a\nTraditionally, Lutherans have taught \"forensic\" (or legal) justification, a divine verdict of acquittal pronounced on the believing sinner. God declares the sinner to be \"not guilty\" because Christ has taken his place, living a perfect life according to God's law and suffering for his sins. For Lutherans, justification is in no way dependent upon the thoughts, words, and deeds of those justified through faith alone in Christ. The new obedience that the justified sinner renders to God through sanctification follows justification as a consequence, but is not part of justification.\nLutherans believe that individuals receive this gift of salvation through faith alone. Saving faith is the knowledge of, acceptance of, and trust in the promise of the Gospel. Even faith itself is seen as a gift of God, created in the hearts of Christians by the work of the Holy Spirit through the Word and Baptism. Faith is seen as an instrument that receives the gift of salvation, not something that causes salvation. Thus, Lutherans reject the \"decision theology\" which is common among modern evangelicals, such as Baptists and Methodists.\nFor Lutherans, justification provides the power by which Christians can grow in holiness and do good works (cf. \"Sanctification in Christianity#Lutheranism\"). Such improvement comes about in the believer only after he has become a new creation in Christ through Holy Baptism. This improvement is not completed in this life: Christians are always \"saint and sinner at the same time\" (\"simul iustus et peccator\")\u2014saints because they are holy in God's eyes, for Christ's sake, and do works that please him; sinners because they continue to sin until death.\nReformed theology.\nThe Reformed tradition, which includes the Continental Reformed, Presbyterian, Reformed Anglican and Congregationalist denominations, upholds the doctrine of \"sola fide\".\nAt present, the Reformed tradition includes different theological views, including Auburn Avenue Theology (Federal Vision Theology), which distinguishes between initial justification by faith alone and final justification \"through faith and works or faith and faithfulness.\" Likewise, in the sacrament of baptism, Auburn Avenue Theology holds that \"all the benefits of Christ (i.e., election, effectual calling, regeneration, faith, union with Christ, and adoption) are given but must be retained by grace and cooperation with grace.\"\nAnglican theology.\nAt the time of the Protestant Reformation in England, Thomas Cranmer, the architect who shaped the foundational Anglican formularies\u2014The Thirty-nine Articles of Religion, Books of Homilies and Book of Common Prayer\u2014\"fully integrated justification \"sola fide et sola gratia\" into the doctrine and worship of the Church of England.\"\nEcclesiastical historian and theologian Gerald Bray states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nCranmer's \"Homily on Salvation\", which was regularly read in every parish of the Church of England, \"make the Protestant understanding of justification normative for Anglican doctrine (Articles 9-14, 17, 22).\"\nFaith and works.\nWhile salvation cannot be achieved through works (Titus ), faith being a unity with Christ in the Spirit naturally issues in love (Galatians ). This was Martin Luther's emphasis likewise.\nIn relation to \"sola fide\", the place of works is found in the second chapter of the Epistle to the Ephesians: Justification is by grace through faith, \"\"not from yourselves\" and \"not by works\"\". In other words, it is by faith alone since all human efforts are excluded here (Ephesians ). Ephesians goes on to say that every person who has faith is to produce good works, according to God's plan (Ephesians ). These works, however, are not a cause of forgiveness but a result of forgiveness. Faith alone justifies but faith is never alone. It is followed by works. In short, works of love are the goal of the saving faith (1 Timothy ).\nAccording to the Defense of the Augsburg Confession of Philipp Melanchthon, the Epistle of James clearly teaches that the recipients of the letter have been justified by God through the saving Gospel (James ):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nIn answer to a question on James (\"you see that a person is justified by what he does and not by faith alone\"), the Wisconsin Evangelical Lutheran Synod has written: \"In James 2, the author was dealing with errorists who said that if they had faith they didn't need to show their love by a life of faith (2:14\u201317). James countered this error by teaching that true, saving faith is alive, showing itself to be so by deeds of love (James 2:18, 26). The author of James taught that justification is by faith alone and also that faith is never alone but shows itself to be alive by good deeds that express a believer's thanks to God for the free gift of salvation by faith in Jesus Christ.\"\nAccording to the Defense of the Augsburg Confession again,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;James, therefore, did not believe that by good works we merit the remission of sins and grace. For he speaks of the works of those who have been justified, who have already been reconciled and accepted, and have obtained remission of sins.\nIn \"Article XX of Good Works\", the Augsburg Confession states that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[I]t is taught on our part that it is necessary to do good works, not that we should trust to merit grace by them, but because it is the will of God. It is only by faith that forgiveness of sins is apprehended\nThe Lutheran Churches teach that God does reward good works done by Christians; the Apology of the Augsburg Confession teaches: \"We also affirm what we have often said, that although justification and eternal life go along with faith, nevertheless, good works merit other bodily and spiritual rewards and degrees of reward. According to 1 Corinthians 3:8, \u2018Each will receive his wages according to his labor.\u2019\"\nMartin Luther, who opposed antinomianism, is recorded as stating, \"Works are necessary for salvation but they do not cause salvation; for faith alone gives life.\"\nIn his Introduction to Romans, Luther stated that saving faith is,\na living, creative, active and powerful thing, this faith. Faith cannot help doing good works constantly. It doesn\u2019t stop to ask if good works ought to be done, but before anyone asks, it already has done them and continues to do them without ceasing. Anyone who does not do good works in this manner is an unbeliever...Thus, it is just as impossible to separate faith and works as it is to separate heat and light from fire!\nScottish theologian John Murray of Westminster Theological Seminary in Philadelphia, asserted:\n\"Faith alone justifies but a justified person with faith alone would be a monstrosity which never exists in the kingdom of grace. Faith works itself out through love (Gal. 5:6). And Faith without works is dead (James 2:17\u201320).\"\n\"It is living faith that justifies and living faith unites to Christ both in the virtue of his death and in the power of his resurrection. No one has entrusted himself to Christ for deliverance from the guilt of sin who has not also entrusted himself to him for deliverance from the power of sin.\"\nContemporary evangelical theologian R. C. Sproul writes:\nThe relationship of faith and good works is one that may be distinguished but never separated ... if good works do not follow from our profession of faith, it is a clear indication that we do not possess justifying faith. The Reformed formula is, \"We are justified by faith alone but not by a faith that is alone.\"\nMichael Horton concurs by saying:\nThis debate, therefore, is not over the question of whether God renews us and initiates a process of gradual growth in holiness throughout the course of our lives. 'We are justified by faith alone, but not by a faith that is alone,' Luther stated, and this recurring affirmation of the new birth and sanctification as necessarily linked to justification leads one to wonder how the caricatures continue to be perpetuated without foundation.\nReconciliation of differing emphases.\nChristian theologies answer questions about the nature, function, and meaning of justification quite differently. These issues include: Is justification an event occurring instantaneously or is it an ongoing process? Is justification effected by divine action alone (\"monergism\"), by divine and human action together (\"synergism\"), or by human action (erroneously called \"Pelagianism\")? Is justification permanent or can it be lost? What is the relationship of justification to sanctification, the process whereby sinners become righteous and are enabled by the Holy Spirit to live lives pleasing to God?\nDiscussion in the centuries since the Reformation and in some ways liberalising Counter-Reformation has suggested that the differences are in emphasis and concepts rather than doctrine, since Catholic and Orthodox Christians concede works are not the basis of \"justification\" nor relatedly \"salvation\", and most Protestants accept the need for repentance and the primacy of grace (see and below). Further, many Protestant churches actually hold more nuanced positions such as \"sola gratia, sola fide\" or \"justification by faith\" (i.e. without the \"alone\"). According to a 2017 survey conducted in Western Europe by the Pew Research Center, \"fewer people say that faith alone (in Latin, \"sola fide\") leads to salvation, the position that Martin Luther made a central rallying cry of 16th-century Protestant reformers.\" Protestants in every country surveyed except Norway are more likely to say that both good deeds and faith in God are necessary for salvation.\nThe Joint Declaration on the Doctrine of Justification (JDDJ), signed by both the Lutheran World Federation and the Roman Catholic Church on 31 October 1999 declares:\nWe confess together that good works \u2013 a Christian life lived in faith, hope and love \u2013 follow justification and are its fruits. When the justified live in Christ and act in the grace they receive, they bring forth, in biblical terms, good fruit. Since Christians struggle against sin their entire lives, this consequence of justification is also for them an obligation they must fulfill. Thus both Jesus and the apostolic Scriptures admonish Christians to bring forth the works of love.\nThe Joint Declaration on the Doctrine of Justification (JDDJ), signed by the Lutheran World Federation and the Catholic Church, says that \"sinners are justified by faith in the saving action of God in Christ. ... Such a faith is active in love and thus the Christian cannot and should not remain without works.\" And later, \"Good works \u2013 a Christian life lived in faith, hope and love \u2013 follow justification and are its fruits. When the justified live in Christ and act in the grace they receive, they bring forth, in biblical terms, good fruit. Since Christians struggle against sin their entire lives, this consequence of justification is also for them an obligation they must fulfill. Thus both Jesus and the apostolic Scriptures admonish Christians to bring forth the works of love.\"\nThe Joint Declaration never mentions the expression \"Sola Fide\" and the Catechism of the Catholic Church clearly teaches that salvation is obtained by a combination of both faith and good works, which are considered to be a human response to God's prior and continuing grace.\nEpistle of James and Pauline Epistles.\nChapter 2 of the Epistle of James, verses 14\u201326, discusses faith and works, starting with verse 14, \"What use is it, my brothers, if someone says he has faith but he has no works? Can that faith save him?\" In verse 17 it says, \"Even so faith, if it has no works, is dead by itself\". It concludes in verse 26 by saying \"For just as the body without the spirit is dead, so also faith without works is dead.\"\nThe Defense of the Augsburg Confession rejects the idea that the Epistle of James contradicts the Lutheran teaching on Justification.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;He who has faith and good works is righteous, not indeed, on account of the works, but for Christ's sake, through faith. And as a good tree should bring forth good fruit, and yet the fruit does not make the tree good, so good works must follow the new birth, although they do not make man accepted before God; but as the tree must first be good, so also must man be first accepted before God by faith for Christ's sake. The works are too insignificant to render God gracious to us for their sake, if He were not gracious to us for Christ's sake. Therefore James does not contradict St. Paul, and does not say that by our works we merit, etc.\nConfessional Lutheran theologians summarize James 2: \"we are justified/declared righteous by people when they see the good works we do as a result of our faith and they conclude that our faith is sincere.\"\nIn answer to another question on James 2:24 as well as Romans 3:23\u201324, the Wisconsin Evangelical Lutheran Synod replied:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Paul is writing to people who said that faith in Jesus alone does not save a person, but one has to also obey God's law in order to be justified (Gal 3:3, 5:4). To counter the false idea that what we do in keeping the law must be added to faith in what Christ did for us. Paul often emphasizes in his letters (esp. Galatians, Romans, Colossians) that we are saved by grace through faith alone. James is writing to people who felt that believing in Jesus saved a person, but that having faith did not mean that a person necessarily would keep God's commandments out of love for God (James 2:14, 17). To show that faith is not really faith unless it leads a person to thank God for salvation in a life of glad and willing obedience to God's holy will. James emphasized that a faith which did not show that it was living faith was really not faith at all.\nA Lutheran exegesis further points out that James is simply reaffirming Jesus' teaching in https://, and that in https:// of the same chapter (\"For whoever keeps the whole law and yet stumbles at just one point is guilty of breaking all of it\"), James too denies works as a means to obtain forgiveness:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;James here (verse 10) also shoots down the false doctrine of work-righteousness. The only way to be free of sin is to keep the law perfectly and in its entirety. If we offend it in the slightest, tiniest little way, we are guilty of all. Thank God that He sent Jesus to fulfill the Law in its entirety for us\nLutheran and Reformed Protestants, as well as others, base the sola fide on the fact that the New Testament contains almost two hundred statements that appear to imply that faith or belief is sufficient for salvation, for example: \"Jesus said unto her, I am the resurrection, and the life: he that believeth in me, though he were dead, yet shall he live.\" () and especially Paul's words in Romans, \"Therefore we conclude that a man is justified by faith without the deeds of the law.\" ()\n\"Now to him that worketh is the reward not reckoned of grace, but of debt. But to him that worketh not, but believeth on him that justifieth the ungodly, his faith is counted for righteousness.\" ()\nThe precise relationship between faith and good works remains an area of controversy in some Protestant traditions (see also Law and Gospel). Even at the outset of the Reformation, subtle differences of emphasis appeared. For example, because the Epistle of James emphasizes the importance of good works, Martin Luther sometimes referred to it as the \"epistle of straw\". Calvin on the other hand, while not intending to differ with Luther, wrote of the necessity of good works as a consequence or 'fruit' of faith. The Anabaptists tended to emphasize a \"faith that works\".\nA recent article suggests that the current confusion regarding the Epistle of James about faith and works resulted from Augustine of Hippo's anti-Donatist polemic in the early fifth century. This approach reconciles the views of Paul and James on faith and works. Recent meetings of scholars and clergy have attempted to soften the antithesis between Protestant and Catholic conceptions of the role of faith in salvation, which, if they were successful, would have far reaching implications for the relationship between most Protestant churches and the Catholic Church. These attempts to form a consensus are accepted among many Protestants and Catholics, but among others, \"sola fide\" continues to divide the Reformation churches, including many Lutherans, Reformed, and others, from other denominations. Some statements of the doctrine are interpreted as a denial of the doctrine as understood by other groups.\nCatholic view.\nThe alternate Catholic formulation to \"sola fide\" is \"fides formata\", a faith formed by love. An apologist has noted that Catholic theology typically does not treat justification independently from sanctification as Protestant theology does, however on questions of certainty it does treat faith and hope as distinct, unlike Protestant theology which traditionally combines them.\nIn the Council of Trent (1545\u20131563), the Catholic Church cautioned against an extreme version of \"sola fide\" in canon XIV on self-righteousness and justification without repentance, declaring: \"If any one says, that man is truly absolved from his sins and justified, because that he assuredly believed himself absolved and justified; or, that no one is truly justified but he who believes himself justified; and that, by this faith alone, absolution and justification are effected; let him be anathema.\"\nPope Benedict XVI summarized the Catholic position as \"\"...Luther's phrase: \"faith alone\" is true, if it is not opposed to faith in charity, in love. Faith is looking at Christ, entrusting oneself to Christ, being united to Christ, conformed to Christ, to his life. ... St Paul speaks of faith that works through love (cf. Gal 5: 14).\"\"https://\nThe following principles from the Catechism of the Catholic Church (labeled by paragraph number) are useful for understanding the Catholic view of justification.\nThus the Catholic view could perhaps be interpreted as a progression or flow: first grace, then initial trust/repentance/conversion, then faith/hope/charity, combined with an emphasis that none of these elements should be isolated thus missing the package.\nFurther, the sacraments of baptism, Eucharist, and reconciliation relate to each: baptism for the removal of sin (in the case of an infant, original sin), Eucharist for the participation in Jesus' sacrifice, and penance for the confession of lapses of faith and charity and the assignment of prayers/actions to rejoin faith and charity. \"Sola fide\" is rejected only as far is it would ignore or reject grace or the New Commandment.\nGrace.\nThe Catholic view holds instead that grace, specifically, the form of grace known as \"sanctifying grace\", and which first floods the soul at baptism, which empowers one's ability both to believe and to perform good works, is essential as the gateway to salvation, but not the only element needed for salvation (Eph 2:8\u201310). God's freely given grace is offered and empowers one's ability to believe and to perform good works, both then becoming meritorious because they are joined to Christ's saving power of the Cross. (Phil 2:12\u201313) (Catechism of the Catholic Church, 1987\u20132029) A Christian must respond to this free gift of Grace from God given first, ordinarily, in Baptism (1 Pet 3:21) both by having faith and by living in the light of Christ through love (Jn 3:16; 1 Jn 1:7) (https://) which perfects the Christian throughout his or her life (https://). The Catholic position is best summed up in John 3:16, if one has the proper, contextual understanding of the word \"believe\". \"Believe\", in context and in ancient Judaism, meant more than an intellectual assent. \"To believe\" also meant to obey, which is seen, in context, in Jn 3:36, 1 Jn 2:3ff, and 1 Jn 5:1ff. Without our positive response to grace offered, salvation is not possible.\nAs expounded in the Catechism of the Catholic Church, the Catholic Church's teaching is that it is the grace of God, \"the free and undeserved help that God gives us to respond to his call\", that justifies us, a grace that is a prerequisite for our free response of \"collaboration in justification through faith, and in sanctification through charity\".\nJustification.\nAccording to the Catechism of the Catholic Church justification is conferred in baptism, the sacrament of faith. The sacrament of reconciliation enables recovery of justification, if lost through committing a mortal sin. A mortal sin makes justification lost, even if faith is still present.\nThe Council of Trent sought to clarify the Catholic Church's teaching on justification and the manner in which it differed from that proposed by Lutheran and Reformed Christians. It stated: \"Faith is the beginning of human salvation, the foundation and root of all justification, without which it is impossible to please God () and to come to the fellowship of His sons; and we are therefore said to be justified gratuitously, because none of those things that precede justification, whether faith or works, merit the grace of justification.\" \"Faith, unless hope and charity be added to it, neither unites man perfectly with Christ nor makes him a living member of His body. For which reason it is most truly said that faith without works is dead () and of no profit, and in Christ Jesus neither circumcision availeth anything nor uncircumcision, but faith that worketh by charity ().\" After being justified, \"to those who work well unto the end and trust in God, eternal life is to be offered, both as a grace mercifully promised to the sons of God through Christ Jesus, and as a reward promised by God himself, to be faithfully given to their good works and merits. ... Since Christ Jesus Himself, as the head into the members and the vine into the branches (), continually infuses strength into those justified, which strength always precedes, accompanies and follows their good works, and without which they could not in any manner be pleasing and meritorious before God, we must believe that nothing further is wanting to those justified to prevent them from being considered to have, by those very works which have been done in God, fully satisfied the divine law according to the state of this life and to have truly merited eternal life, to be obtained in its [due] time, provided they depart [this life] in grace\".\nIn its canons, the Council condemned the following propositions:\nErasmus.\nIn Catholic biblical scholar Erasmus's final fifth edition of his New Testament (1535), he made a lengthy word study of \"sola fide\" in relation to 1 Corinthians 3:2 and denied Luther's construal and insertion of \"alone\": when \"sola is used in an expression such as sola fides, it means not \u2018apart from everything else\u2019 but \u2018pre-eminently.\u2019\"\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Accordingly, whoever says we are justified by faith alone does not forthwith exclude charity or charitable works, but human philosophy, or the ceremonies and works of the Law, or the life lived before baptism, or something similar gathered from the context \u2026 In all his Epistles Paul nowhere separates charity from purifying faith.\u2014\u200a\nCatholic exegesis of Letter of James.\nCatholic exegetes believe that St. James, to continue the thread above, had no other object than to emphasize the fact\u2014already emphasized by St. Paul\u2014that only such faith as is active in charity and good works (\"fides caritate formata\") possesses any power to justify man (cf. Galatians 5:6; 1 Corinthians 13:2), whilst faith devoid of charity and good works (\"fides informis\") is a dead faith and in the eyes of God insufficient for justification (cf. James 2:17 sqq.)\nIn response to sola fide, Robert Sungenis argues in his 1997 book \"Not by Faith Alone\" that:\nAnabaptist view.\nAnabaptist cleric David Griffin writes:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For early Anabaptists, \"sola fide\" muted the call to imitate Christ by excusing anti-Christian behavior generally, and justifying violence towards fellow Christians in particular. True \"fide\", it was argued, takes Christ both as savior and example. That is, faith is directed not just to the soteriological work of Christ's death, but also towards his exemplary human life. Faith accepts that because Christ's earthly life pleased God, it is normative for proper human experience. Consequently, early Anabaptism expected an affirmative answer to two basic questions: 1) \"Do you believe that Christ bore your sins?\" and 2) \"Do you believe that Jesus' human life, which pleased God, should be copied?\"\n\"The beginning of the Anabaptist path to salvation was thus marked not by a forensic understanding of salvation by 'faith alone', but by the entire process of repentance, self-denial, faith, rebirth and obedience. It was this process that was marked by the biblical sign of baptism.\" After becoming a believer, Anabaptist theology emphasizes \"a faith that works.\"\nAnabaptist denominations teach:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nHans Denck wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;To believe is to obey God's Word\u2014be it unto death or life\u2014in the sure confidence that it leads to the best. \nObedience to Jesus and other New Testament teachings, loving one another and being at peace with others, and walking in holiness are seen as \"earmarks of the saved.\" Good works thus have an important role in the life of an Anabaptist believer, with the teaching \"that faith without works is a dead faith\" (cf. ) occupying a cornerstone in Anabaptist Christianity. \nAnabaptists do not teach faith \"and\" works\u2014in the sense of two separate entities\u2014are necessary for salvation, but rather that true faith will \"always\" produce good works. Balthasar Hubmaier wrote that \"faith by itself alone is not worthy to be called faith, for there can be no true faith without the works of love.\"\nAnabaptists \"dismissed the Lutheran doctrine of justification, a dead faith as they called it, which was unable to produce Christian love and good works.\" Peter Riedemann wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;These so-called Christians can be compared with the heathen who were led into the land of Israel by the Assyrian king and were settled in cities. The Lord sent lions among them to kill them, until a priest from Israel came and taught them the manner and practice of the law. Those heathen learned to serve the God of heaven. But they continued in their abominable practices. God was not pleased with their service, and their children followed in their footsteps. ()\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;That is just what can be seen in the so-called Christians of today, especially the Lutherans. They continually profess to love and serve God and will not give up evil, sinful practices and the whole service of the devil. They continue to walk from generation to generation; as their fathers did, so do they, and even worse. John clearly states in what way they walk in truth! \nRather than a forensic justification that only gave a legal change of one's status before God, early Anabaptists taught that \"justification begun a dynamic process by which the believer partook of the nature of Christ and was so enabled to live increasingly like Jesus.\" Christians of the Anabaptist tradition (who teach salvation by \"faith that works\") have argued that being a disciple of Jesus by careful obedience to New Testament commands (such as the holy kiss, baptism, communion, headcovering, and feet washing), is \"crucial evidence that an individual has repented, believed, and yielded to Christ.\" The Anabaptist theologian Menno Simons rebuffed the Lutheran charge of legalism by referencing :\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nFree Grace view.\nThe modern Free Grace movement originated primarily from the perspective of some faculty members at Dallas Theological Seminary, notably through the writings of Lewis Sperry Chafer (1871\u20131952) and the influential advocacy of Zane C. Hodges (1932\u20132008). It is commonly associated with the Lordship salvation controversy which began in the late 1970\u2019s to early 1980\u2019s. However, earlier individuals such as Robert Sandeman (1718\u20131771) and Robert Govett (1813\u20131901) are often seen as having had similar views prior to the modern form of Free Grace theology. Free Grace theology is distinguished from other traditions by holding an especially strong version of the doctrine of faith alone. It holds that things such as turning from sin, baptism or perseverance in the faith are not necessary for salvation, but instead hold that these things are necessary for eternal rewards. It holds eternal security, and denies that every believer will necessarily persevere. Thus, they hold that anyone who believes in Jesus Christ will go to heaven regardless of any future actions\u2014including future sin, unbelief, or apostasy\u2014though Christians who sin or abandon the faith will face God's discipline.\nFor example, Charles Stanley stated:Look at that verse [John 3:18] and answer this question: According to Jesus, what must a person do to keep from being judged for sin? Must he stop doing something? Must he promise to stop doing something? Must he have never done something? The answer is so simple that many stumble all over it without ever seeing it. All Jesus requires is that the individual \"believe in\" Him. Similarly Robert Thieme, a Free Grace theologian wrote:Although the believer can never lose his eternal life, he can be in danger of destroying his spiritual life and losing all the blessings that \u201cGod has prepared for those who love himFree grace views of salvation have been mainly taught among Southern Baptists, Independent Baptists, Plymouth Brethren, Calvary Chapel churches, non-denominational churches, Churches affiliated with Florida Bible College, Bible churches, Local churches influenced by Watchman Nee, Doctrinal Churches influenced by R. B. Thieme, Greater Grace churches, the IFCA and other Independent churches. Similar views were in the past were also held in some form by the exinct Sandemanian churches alongside some old Scotch Baptists.\nFree grace theology is distinguished by its treatment of the words \"salvation\" and \"save\" in the Bible. These theologians argue that there are many ways believers can experience \"salvation\", not necessarily referring to salvation from hell. This view cites verses such as Acts 27:34, where the Greek word \"s\u014dt\u0113r\u00ed\u0101\" \u2013 typically translated as 'salvation' \u2013 is translated \"health\" or \"strength\" because food will assist their deliverance from physical death. Spiritually, salvation is seen as referring to deliverance from the eternal penalty of sin (justification), the current power of sin over the Christian (sanctification), the removal of any possibility to sin (glorification), and being restored to stewardship over the world as God intended for humankind at creation (restoration to rule). Most Free Grace theologians such as Bob Wilkin, Zane Hodges, and Joseph Dillow, among others hold that the one who possesses \"dead faith\" \u2013 as mentioned James 2:17 \u2013 is not a false convert, in this view the word \"dead\" refers to a faith that is not profitable in this life nor in the judgement seat of Christ, but does not imply false conversion. Thus, when the epistle of James says \"can that faith save him\", it is either understood as salvation from temporal consequences of sin (as with Hodges), salvation from a loss of reward (as with Bing), both (as with Dillow), or as the physical salvation of the poor person described in the chapter (as with R. T. Kendall).\nThere are some differences among free grace theologians on the issue of fruit in a Christian life. More moderate free grace theologians still affirm that faith will necessarily lead into good works, although it may not be outwardly evident or last to the end of one's life. However, those who hold to a more strong form of free grace theology deny that every Christian will bear fruit in their life.\nMethodist view.\nMethodism affirms the doctrine of justification by faith, but in Wesleyan\u2013Arminian theology, justification refers to \"pardon, the forgiveness of sins\", rather than \"being made actually just and righteous\", which Methodists believe is accomplished through sanctification. John Wesley, the founder of the Methodist Churches, taught that the keeping of the moral law contained in the Ten Commandments, as well as engaging in the works of piety and the works of mercy, were \"indispensable for our sanctification\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"It is incumbent on all that are justified to be zealous of good works,\" says Wesley, \"And these are so necessary that if a man willingly neglects them, he cannot reasonably expect that he shall ever be sanctified.\"\u2014\u200a\nMethodist pastor Amy Wagner has written:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Wesley understood faith as a necessity for salvation, even calling it \"the sole condition\" of salvation, in the sense that it led to justification, the beginning point of salvation. At the same time, \"as glorious and honorable as [faith] is, it is not the end of the commandment. God hath given this honor to love alone.\"\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Faith is \"an unspeakable blessing\" because \"it leads to that end, the establishing anew the law of love in our hearts\".\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;This end, the law of love ruling in our hearts, is the fullest expression of salvation; it is Christian perfection.\u2014\u200a\nMethodist soteriology emphasizes the importance of the pursuit of holiness in salvation. Thus, for Wesley, \"true faith\u00a0... \"cannot\" subsist without works\". Bishop Scott J. Jones in \"United Methodist Doctrine\" (2002) writes that in Wesleyan theology:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Faith is necessary to salvation unconditionally. Good works are necessary only conditionally, that is if there is time and opportunity. The thief on the cross in Luke 23:39\u201343 is Wesley's example of this. He believed in Christ and was told, \"Truly I tell you, today you will be with me in Paradise.\" This would be impossible if the good works that are the fruit of genuine repentance and faith were unconditionally necessary for salvation. The man was dying and lacked time; his movements were confined and he lacked opportunity. In his case, faith alone was necessary. However, for the vast majority of human beings good works are necessary for continuance in faith because those persons have both the time and opportunity for them.\nBishop Jones concludes that \"Methodist doctrine thus understands true, saving faith to be the kind that, given time and opportunity, will result in good works. Any supposed faith that does not in fact lead to such behaviors is not genuine, saving faith.\" Methodist evangelist Phoebe Palmer stated that \"justification would have ended with me had I refused to be holy\". While \"faith is essential for a meaningful relationship with God, our relationship with God also takes shape through our care for people, the community, and creation itself.\" Methodism, inclusive of the Holiness movement, thus teaches that \"justification [is made] conditional on obedience and progress in sanctification\", emphasizing \"a deep reliance upon Christ not only in coming to faith, but in remaining in the faith\". The believer who is entirely sanctified (cleansed \"from all inward sin and empowered for service\") maintains his/her salvation by \"faith and obedience\" to God.\nRichard P. Bucher contrasts this position with the Lutheran one, discussing an analogy put forth by John Wesley:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Whereas in Lutheran theology the central doctrine and focus of all our worship and life is justification by grace through faith, for Methodists the central focus has always been holy living and the striving for perfection. Wesley gave the analogy of a house. He said repentance is the porch. Faith is the door. But holy living is the house itself. Holy living is true religion. \"Salvation is like a house. To get into the house you first have to get on the porch (repentance) and then you have to go through the door (faith). But the house itself\u2014one's relationship with God\u2014is holiness, holy living.\nSupporting confessional excerpts.\nAnabaptism.\nThe position of the Mennonite Church USA is set out in the pamphlet \"Confession of Faith in a Mennonite Perspective\" (1995). The commentary to Article 8 of the \"Confession\" emphasizes both faith and obedience as normative for salvation:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;This confession uses a variety of expressions for salvation. For example, salvation is often expressed as \"justification by faith\". The justification that is \"reckoned\" to us as salvation (Rom. 4:1\u201312) is experienced as a covenant relationship with God. A covenant is a binding agreement between two parties. God offers the relationship. The just, or righteous, person has received the offer, lives according to the covenant, and trusts in God's faithfulness. Justification by faith and faithful obedience to the covenant relationship are inseparable (Heb. 11).\nAnglicanism.\nThe Anglican position is set out in the Thirty-nine Articles, specifically Article XI \"Of the Justification of Man\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We are accounted righteous before God, only for the merit of our Lord and Saviour Jesus Christ by faith, and not for our own works or deservings. Wherefore that we are justified by faith only is a most wholesome doctrine, and very full of comfort; as more largely is expressed in the Homily of Justification.\u2014\u200a\nLutheranism.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Our churches by common consent\u00a0... teach that men cannot be justified before God by their own strength, merits, or works, but are freely justified for Christ's sake, through faith, when they believe that they are received into favor, and that their sins are forgiven for Christ's sake, who, by His death, has made satisfaction for our sins. This faith God imputes for righteousness in His sight. Rom. 3 and 4.\u2014\u200a\nBaptist.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Justification is God's gracious and full acquittal upon principles of His righteousness of all sinners who repent and believe in Christ. Justification brings the believer unto a relationship of peace and favor with God.\u2014\u200a\nReformed.\nContinental Reformed.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We believe that our blessedness lies in the forgiveness of our sins because of Jesus Christ, and that in it our righteousness before God is contained, as David and Paul teach us when they declare that man blessed to whom God grants righteousness apart from works.\nAnd the same apostle says that we are justified \"freely\" or \"by grace\" through redemption in Jesus Christ. And therefore we cling to this foundation, which is firm forever, giving all glory to God, humbling ourselves, and recognizing ourselves as we are; not claiming a thing for ourselves or our merits and leaning and resting on the sole obedience of Christ crucified, which is ours when we believe in him.\nThat is enough to cover all our sins and to make us confident, freeing the conscience from the fear, dread, and terror of God's approach, without doing what our first father, Adam, did, who trembled as he tried to cover himself with fig leaves.\nIn fact, if we had to appear before God relying\u2014no matter how little\u2014on ourselves or some other creature, then, alas, we would be swallowed up.\nTherefore everyone must say with David: \"Lord, do not enter into judgment with your servants, for before you no living person shall be justified.\"\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Question 86\": Since then we are delivered from our misery, merely of grace, through Christ, without any merit of ours, why must we still do good works?\nAnswer: Because Christ, having redeemed and delivered us by his blood, also renews us by his Holy Spirit, after his own image; that so we may testify, by the whole of our conduct, our gratitude to God for his blessings, and that he may be praised by us; also, that every one may be assured in himself of his faith, by the fruits thereof; and that, by our godly conversation others may be gained to Christ.\n\"Question 87\": Cannot they then be saved, who, continuing in their wicked and ungrateful lives, are not converted to God?\nAnswer: By no means; for the holy scripture declares that no unchaste person, idolater, adulterer, thief, covetous man, drunkard, slanderer, robber, or any such like, shall inherit the kingdom of God.\u2014\u200a\nPresbyterian.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I. Those whom God effectually calls, He also freely justifies; not by infusing righteousness into them, but by pardoning their sins, and by accounting and accepting their persons as righteous; not for any thing wrought in them, or done by them, but for Christ's sake alone; nor by imputing faith itself, the act of believing, or any other evangelical obedience to them, as their righteousness; but by imputing the obedience and satisfaction of Christ unto them, they receiving and resting on Him and His righteousness by faith; which faith they have not of themselves, it is the gift of God.\u2014\u200a\nReformed Baptist.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"XXVIII.\" That those which have union with Christ, are justified from all their sins, past, present, and to come, by the blood of Christ; which justification we conceive to be a gracious and free acquittance of a guilty, sinful creature, from all sin by God, through the satisfaction that Christ hath made by his death; and this applied in the manifestation of it through faith.\u2014\u200a\nChapter XI of the London Baptist Confession of Faith 1689 is the same as the Westminster Confession of Faith.\nMethodism.\nThe following statements from confessions of faiths of the Wesleyan\u2013Arminian tradition reflect Methodist theology on salvation:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We are accounted righteous before God only for the merit of our Lord and Saviour Jesus Christ, by faith, and not for our own works or deservings. Wherefore, that we are justified by faith, only, is a most wholesome doctrine, and very full of comfort.\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We believe good works are the necessary fruits of faith and follow regeneration but they do not have the virtue to remove our sins or to avert divine judgment. We believe good works, pleasing and acceptable to God in Christ, spring from a true and living faith, for through and by them faith is made evident.\u2014\u200a\nNon-denominational Evangelicals.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The justification of the sinner solely by the grace of God through faith in Christ crucified and risen from the dead.\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We believe in\u00a0... the Salvation of lost and sinful man through the shed blood of the Lord Jesus Christ by faith apart from works, and regeneration by the Holy Spirit\u00a0...\u2014\u200a\nAdditional ecumenical statements.\nEvangelical Protestants and Roman Catholics.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The New Testament makes it clear that the gift of salvation is received through faith. \"By grace you have been saved through faith; and this is not your own doing, it is the gift of God\" (Ephesians 2:8). By faith, which is also the gift of God, we repent of our sins and freely adhere to the gospel, the good news of God's saving work for us in Christ. By our response of faith to Christ, we enter into the blessings promised by the gospel. Faith is not merely intellectual assent but an act of the whole persons involving the mind, the will, and the affections, issuing in a changed life. We understand that what we here affirm is in agreement with what the Reformation traditions have meant by justification by faith alone (\"sola fide\").\u2014\u200a\nLutheran World Federation and the Roman Catholic Church.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"4.3 Justification by Faith and through Grace \"\n25. We confess together that sinners are justified by faith in the saving action of God in Christ. By the action of the Holy Spirit in Baptism, they are granted the gift of salvation, which lays the basis for the whole Christian life. They place their trust in God's gracious promise by justifying faith, which includes hope in God and love for him. Such a faith is active in love and thus the Christian cannot and should not remain without works. But whatever in the justified precedes or follows the free gift of faith is neither the basis of justification nor merits it.\u2014\u200a\nIn the preamble https://, it is suggested that much of the debate on \"sola fide\" has been based on condemnations of caricatured positions not actually held: \"The teaching of the Lutheran Churches presented in the Declaration does not fall under the condemnations from the Council of Trent. The condemnations in the Lutheran Confessions do not apply to the teaching of the Roman Catholic Church presented in this Declaration.\"\nLutheran-Orthodox Joint Commission.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;5. Regarding the way in which salvation is appropriated by the believers, Lutherans, by teaching that justification and salvation are by grace alone through faith (\"sola gratia, sola fide\"), stress the absolute priority of divine grace in salvation. When they speak about saving faith they do not think of the dead faith which even the demons have (cf. James 2:19), but the faith which Abraham showed and which was reckoned to him as righteousness (cf. Gen. 15:6, Rom. 4:3,9). The Orthodox also affirm the absolute priority of divine grace. They underline that it is God's grace which enables our human will to conform to the divine will (cf. Phil 2:13) in the steps of Jesus praying, \"not as I will but as You will\" (), so that we may work out our salvation in fear and trembling (cf. Phil. 2:12). This is what the Orthodox mean by \"synergy\" (working together) of divine grace and the human will of the believer in the appropriation of the divine life in Christ. The understanding of synergy in salvation is helped by the fact that the human will in the one person of Christ was not abolished when the human nature was united in Him with the divine nature, according to the Christological decisions of the Ecumenical Councils. While Lutherans do not use the concept of synergy, they recognize the personal responsibility of the human being in the acceptance or refusal of divine grace through faith, and in the growth of faith and obedience to God. Lutherans and Orthodox both understand good works as the fruits and manifestations of the believer's faith and not as a means of salvation.\nProtestant Controversies.\nSome scholars of Early Christianity are adherents of the New Perspective on Paul and so believe sola fide is a misinterpretation on the part of Lutherans and that Paul was actually speaking about laws (such as Circumcision, Dietary laws, Sabbath, Temple rituals, etc.) that were considered essential for the Jews of the time.\nThe doctrine of justification by faith alone and the role of repentance in salvation has been interpreted differently by different Protestants, causing multiple controversies such as the Majoristic controversy (16th century), Antinomian Controversy (17th century), the Marrow Controversy (18th century), the Lordship salvation controversy (1980s), and the Hyper-Grace controversy (21st century).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58675", "revid": "50521651", "url": "https://en.wikipedia.org/wiki?curid=58675", "title": "IEA", "text": "IEA may refer to:\nOthers.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "58677", "revid": "525927", "url": "https://en.wikipedia.org/wiki?curid=58677", "title": "IADB", "text": "IADB may refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "58678", "revid": "125972", "url": "https://en.wikipedia.org/wiki?curid=58678", "title": "IDB", "text": "IDB can mean:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "58679", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=58679", "title": "Chicago Boys", "text": "Chilean economists and political advisors\nThe Chicago Boys were a group of Chilean economists who rose to prominence in the 1970s and 1980s. Most were educated at the University of Chicago Department of Economics under influential figures like Milton Friedman, Arnold Harberger, and Larry Sjaastad, or at its academic partner, the Pontificia Universidad Cat\u00f3lica de Chile. After returning to Latin America, they assumed key roles as economic advisors in several South American governments, most notably the military dictatorship of Chile (1973\u20131990), where many attained the highest economic offices. Their free-market policies later influenced conservative governments abroad, including those of Ronald Reagan in the United States and Margaret Thatcher in the United Kingdom.\nOrigins and the Chile Project.\nThe term \"Chicago Boys\" emerged in the 1980s to describe Latin American economists who espoused the liberal economic theories taught at the University of Chicago. Their training stemmed from the \"Chile Project,\" an initiative organized in the 1950s by the U.S. State Department under the Point Four Program, the first U.S. global economic development scheme. Funded by the Ford Foundation and the Rockefeller Foundation, the project aimed to reshape Chilean economic thought.\nThe University of Chicago's Economics Department established scholarship programs with Chile's Catholic University. Between 1957 and 1970, approximately one hundred selected Chilean students underwent training, first in Chile and then in postgraduate studies at Chicago. Professor Larry Sjaastad was a central figure, supervising 139 doctoral dissertations, many for Latin American students, during his 42-year tenure.\nRise to power.\nThe Chicago Boys' ideas remained marginal in Chilean politics until the early 1970s. A group of them prepared a comprehensive 189-page economic blueprint titled \"El ladrillo\" (\"the brick\"), which was presented during Jorge Alessandri's unsuccessful 1969 presidential campaign. Alessandri rejected the plan, but it was revived following the 1973 Chilean coup d'\u00e9tat that brought General Augusto Pinochet to power, ultimately forming the basis of the new regime's economic policy. As Milton and Rose Friedman noted in their memoir: \"In 1975, when inflation still raged and a world recession triggered a depression in Chile, General Pinochet turned to the 'Chicago Boys'; he appointed several of them to powerful positions in the government.\"\nEconomic policies and impact.\nAs the principal economic architects of the Pinochet regime, the Chicago Boys implemented a radical program of neoliberal reforms. Their policies, often described as \"shock therapy,\" aimed to curb hyperinflation and stimulate growth through severe austerity, deep cuts in government spending, widespread deregulation, and the privatization of state-owned enterprises. They also liberalized trade, dismantling protectionist barriers to integrate Chile into the global market.\nThe immediate results were severe. By 1982, Chile's GDP had contracted by approximately 15%, and the reforms exacerbated income inequality, a legacy that continues to affect the country. However, these market-oriented policies, underpinned by the anti-Marxist ideology of the junta, were framed as a necessary corrective to the preceding socialist policies and a bulwark against communism during the Cold War.\nThe relationship between the Chicago Boys and international financial institutions like the International Monetary Fund (IMF) was complex, marked by both alignment and rivalry. The combination of free-market capitalism with authoritarian political control became a hallmark of Pinochetism, and the Chicago Boys' policies remain deeply controversial in Chile and internationally.\nInternational influence.\nThe perceived economic success of the Chicago Boys, often termed the \"Chilean Miracle,\" provided the Pinochet regime with a degree of international legitimacy, helping to offset criticism of its human rights record. Their pioneering use of structural adjustment, tax cuts, and free-trade policies attracted the attention of conservative leaders worldwide. The Chilean experiment served as a key case study for the application of Chicago School principles and influenced the neoliberal turn in the United States and United Kingdom during the 1980s.\nScholars have extensively analyzed the long-term significance of this influence. The Chicago Boys' restructuring of Chile's economy is a pivotal chapter in the history of neoliberal policy. While credited by supporters with creating a stable and growing economy, critics highlight the social costs, including increased inequality and the implementation of these policies under a repressive dictatorship.\nLater history and legacy.\nFollowing the end of military rule and the return to democracy in 1990, the Chicago Boys as a cohesive group lost direct political power, with many moving into the private sector. However, the core tenets of their economic model remained largely in place.\nThe academic connection between Chile and the University of Chicago endured beyond the original Chile Project. Alumni networks, including the Chicago Boys, are maintained through organizations like the \"Latin American Business Group at Chicago Booth School of Business.\" The term \"Chicago Boys\" persists in popular culture, media, and academic discourse, and was the title of a 2015 Chilean documentary film.\nNotable members.\nIn Chile.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nElsewhere in Latin America.\nGraduates from the University of Chicago influenced economic policies across the region, including:\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58680", "revid": "27991771", "url": "https://en.wikipedia.org/wiki?curid=58680", "title": "Chicago school", "text": "Chicago school may refer to:\nOther.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "58681", "revid": "47380524", "url": "https://en.wikipedia.org/wiki?curid=58681", "title": "Worcester, England", "text": "Cathedral city in Worcestershire, England\nWorcester ( ) is a cathedral city in Worcestershire, England, of which it is the county town. It is south-west of Birmingham, north of Gloucester and north-east of Hereford. The population was 103,872 in the 2021 census.\nThe River Severn flanks the western side of the city centre, overlooked by Worcester Cathedral. Worcester is the home of Royal Worcester Porcelain, Lea &amp; Perrins (makers of traditional Worcestershire sauce), the University of Worcester, and \"Berrow's Worcester Journal\", claimed as the world's oldest newspaper. By the early 19th century glove making in Worcester had become a significant industry with a large export trade employing up to 30,000 people in the area. The composer Edward Elgar (1857\u20131934) grew up in the city and spent much of his life in nearby Malvern. Worcester was selected as the location for the evacuation of the entire British government if required during the Second World War, with a large stately home in nearby Madresfield reserved for the British royal family. \nThe Battle of Worcester in 1651 was the final battle of the English Civil War, during which Oliver Cromwell's New Model Army defeated King Charles II's Royalists.\nToponymy.\nDuring the 7th-century period under the Angles of Mercia, the town was known as Weogorna which evolved from the Old English \"Weogorna ceaster,\" meaning \"the Roman town of the Weogoran people\". The \"cester\" part of the name, derived from 'ceaster', indicates that the place was built on the site of a Roman military settlement or town; the word \u2018castle\u2019 is derived from the same source.\nHistory.\nEarly history.\nA trade route past Worcester dating from Neolithic times became the Roman Icknield Street included a ford crossing the River Severn, which was tidal below Worcester, and around 400 BC linked Celtic built British hillforts. Evidence exists that Iron Age defensive ditches may have been constructed in the first century AD, while there are no signs of Roman military use or of municipal buildings to indicate an administrative role. By the 3rd century AD, Roman Worcester was larger than the later medieval city but shrank to a defended position on the river's southern end.\nBy the 7th century, following centuries of warfare with the Vikings, Worcester had become a centre for the Anglo-Saxon army. In 680, Worcester was chosen by the Hwicce as their fort over the larger Gloucester fort.\nFollowing their conquest of England, in 1069 the Normans completed a Motte and Bailey castle just south of the cathedral on what had been a cemetery for the cathedral monks. Nothing now remains of the former Worcester Castle.\nDuring the early medieval period, Worcester's position as the only river crossing between the bridges at Gloucester and Bridgnorth led to its growth as a market town on the main road from London to mid-Wales running through to Kidderminster, Bridgnorth, and Shrewsbury. Worcester continued to be a centre of religious life. Several monasteries were established which provided a hospital and education, including Worcester School. Parts of the city were destroyed by fire during a civil war between King Stephen and Empress Matilda, daughter of Henry I in 1139, 1150 and 1151. A later fire in 1189 destroyed much of the city for the fourth time that century. In 1189 the city received a royal charter and in 1227 a further charter allowed the creation of guild of merchants.\nThe late 12th century saw persecution and expulsion of the small Jewish community of Worcester. The bishop of Worcester wrote an anti-Judaic treatise around 1190, and in 1219 strict rules were imposed on Jews within the diocese. In 1263 the Jews were attacked by baronial forces and most were killed. In 1275 the remaining Jews were expelled to Hereford.\nBy late medieval times the population had reached 1,025 families, excluding the cathedral quarter, so that it probably stood under 10,000, and the suburbs extended beyond the city walls. Manufacture of cloth and allied trades developed into an important local industry. Worcester elected its Member of Parliament and the city council was organised into two chambers whose committees agreed the city's finances, rules and ordinances.\n The Dissolution of the monasteries by Henry VIII between 1536 and 1541, forced the city to found schools to replace monastic education. The city was designated a county corporate in 1621, giving it autonomy from local government and permitting governance by a mayor and co-opted councillors.\nModern era.\nThe English Civil Wars broke out in 1642, lasting until 1651 and were marked with several major events in and around Worcester including the Battle of Powick Bridge of September 1642. The Battle of Worcester, the final conflict of the wars, was fought from the Royalist Headquarters at the Commandery but ended with a victory for the Oliver Cromwell forces of 30,000 men. \nAfter the restoration of the monarchy in 1660, and during the 18th century Worcester experienced significant economic growth, and in 1748 Daniel Defoe could note that 'the inhabitants are generally esteemed rich, being full of business, occasioned chiefly by the clothing-trade'. The Royal Worcester Porcelain Company was established in 1751. However, significant poverty existed, and in 1794 a large workhouse was built at Tallow Hill.\nWorcester's Georgian architecture, has been described as 'one of the most impressive Georgian streetscapes in the Midlands'. Many public buildings were built or rebuilt in this period, including the Grade I listed Worcester Guildhall, the city bridge, and the Royal Infirmary (since 2010 the city campus of the University of Worcester).\nThe annual Three Choirs Festival and horse races on Pitchcroft attracts many visitors.\nBy the late 18th century Worcester's cloth industry had developed into a major centre for glove-making industry, employing around 30,000 people in the area at its peak employed by over 150 firms making half the gloves in Britain and with large worldwide exports. The industry had declined by the mid 20th century due to low import duty on foreign competitors and cheaper products. Surviving manufacturers concentrated on high-end fashionable goods with one company still making gloves for the Royal Family as of 2011.\nRiots took place in 1831 reflecting discontent with the city administration and the lack of democratic representation. Citizens petitioned the House of Lords for permission to build a County Hall. Local government reform took place in 1835 creating elections for councillors. The Shire Hall, which was designed by Charles Day and Henry Rowe in the Greek Revival style, was completed in 1835.\nIn 1815 the Worcester and Birmingham Canal opened. Railways reached Worcester in 1850 with Shrub Hill station and Foregate Street stationin the middle of the city was opened in 1860. The railways created many jobs building passenger coaches and signalling in the Worcester Engine Works alongside Shrub Hill Station. Their 1864 polychrome brick building was probably designed by Thomas Dickson.\nThe British Medical Association (BMA) was founded in 1832 in the board room of the old Worcester Royal Infirmary building in Castle Street.\nThe Kays was one of the most successful mail-order business in the UK and was founded in Worcester in 1889. It and operated from a large warehouse and many premises in the city where it remained as a major employer until 2007. The warehouse was demolished in 2008 and replaced by housing. In 1882 in the huge former railway factory alongside Shrub Hill station, the city hosted the Worcestershire Exhibition with sections for fine arts, historical manuscripts and industrial items, receiving over 222,000 visitors.\n20th century to present.\nThe Foregate Street cast-iron railway bridge was remodelled by the Great Western Railway in 1908 with a decorative cast-iron exterior serving no structural purpose. \nBy the mid-20th century, only a few Worcester glove firms survived, as gloves became less fashionable and free trade enabled cheaper imports from the Far East. Nevertheless, at least three glove manufacturers survived into the late 20th century: Dent Allcroft, Fownes and Milore. In the 1940s, some Jewish refugees from Europe settled in Worcester. Emil Rich, a refugee from Germany, founded one of Worcester's last remaining glovemakers, Milore Glove Factory. Queen Elizabeth II's coronation gloves were designed by Emil Rich and manufactured in the Worcester factory.\nWorcester was a centre for recruitment of soldiers to fight in World War I , into the Worcestershire Regiment, based at Norton Barracks. The regiment took part in early battles in the war, most notably at the Battle of Gheluvelt in 1914, which is commemorated by a park near the city centre. \nRapid growth in leading engineering and machine-tool manufacturing firms took place in the inter-war years and all became major employers in the city. \nDuring World War II, the city was chosen to be the seat of an evacuated government in case of mass German invasion. The War Cabinet, along with Winston Churchill and some 16,000 state workers, would have moved to Hindlip Hall (now part of the complex forming the Headquarters of West Mercia Police), north of Worcester. The Perdiswell Aerodrome on the north-east edge of the city was the first municipal aerodrome in the world. It was the base for the former RAF station RAF Worcester and was an important pilot training and aircraft testing site during World War II .\nIn the 1950s and 1960s large areas of the medieval centre of Worcester were demolished and rebuilt. This was condemned by many such as Nikolaus Pevsner who described it as a \"totally incomprehensible... act of self-mutilation\". A significant area of medieval Worcester remains, with well-preserved examples examples of half-timbered Tudor houses in the shopping streets of City Walls Road, Friar Street and New Street.\nGovernance.\nWorcester is administered by two tiers of local government: the non-metropolitan city district by Worcester City Council, and the non-metropolitan county level by Worcestershire County Council. The two civil parishes within the city of Warndon and St Peter the Great County, form a third tier of local government in those areas; the rest of the city is an unparished area. Worcester forms one of the six local government districts within the county. \nWorcester City Council is based at Worcester Guildhall on the High Street in the city centre. Worcestershire County Council also has its headquarters in Worcester, being based at County Hall in Spetchley Road, on the eastern outskirts of the city. Worcester was an ancient borough which had held city status from time immemorial. When elected county councils were established in 1889, the city was considered large enough to run its own county-level services and so it became a county borough, independent from the surrounding Worcestershire County Council.\nThe city was reformed to become a non-metropolitan district in 1974 under the Local Government Act 1972. The city's territory was enlarged to gaining the parishes of Warndon and St Peter the Great County, and it was transferred to the short-lived combined county of Hereford and Worcester, which was re-established as separate counties again in 1998, since which time the Worcestershire County Council has been the upper-tier authority for Worcester. The seat of Worcester's one constituency has been held by Tom Collins of the Labour Party since the July 2024 general election.\nCoat of arms.\nThe city of Worcester is unusual among English cities in having an arms of alliance as the main part of its coat of arms. The shield on the dexter side is the \"ancient\" arms: \"Quarterly sable and gules, a castle triple-towered argent\". First recorded in 1569 but probably older, there is little doubt that it refers to the Worcester Castle, now vanished. The shield on the sinister side is the \"modern\" arms: \"Argent, a fess between three pears sable\". Despite its name, the modern arms goes back to 1634. It is said to represent a visit of Queen Elizabeth I to the city in 1575, when according to folklore, she saw a tree with black pears on Foregate and was so impressed with it that she allowed Worcester to have pears on its coat of arms. The city has used several mottos: one is \"Floreat semper fidelis civitas\", Latin for \"Let the faithful city ever flourish\", while the one currently used is \"Civitas in bello et pace fidelis\" (A city faithful in peace and war). Both refer to Worcester's support for Royalists in the English Civil War.\nGeography.\nThe district is bounded by the districts of Malvern Hills to the west, and Wychavon to the east. The population of the local government district in 2021 was 103,837. The built up area extends slightly beyond the city boundaries in places and had a population in 2021 of 105,465.\nNotable suburbs include Barbourne, Blackpole, Cherry Orchard, Claines, Diglis, Dines Green, Henwick, Northwick, Red Hill, Ronkswood, St Peter the Great (also known as St Peter's), Tolladine, Warndon and Warndon Villages. Most of Worcester is on the eastern side of the River Severn. However, Henwick, Lower Wick, St John's and Dines Green are on the western side.\nClimate.\nWorcester enjoys a temperate climate with generally warm summers and mild winters. However, it can experience more extreme weather and flooding is often a problem. In 1670, the River Severn burst its banks in the worst flood ever seen by the city. The closest flood height to the Flood of 1670 was when torrential rains caused the Severn to flood in July 2007, which is recorded in the Diglis Basin. This recurred in 2014.\nDuring the winters of 2009\u20132010 and 2010\u20132011, the city underwent long periods of sub-freezing temperatures and heavy snowfalls. In December 2010 the temperature dropped to in nearby Pershore. The Severn and the River Teme partly froze over in Worcester during this cold period. By contrast, Worcester recorded a temperature on 2 August 1990. Between 1990 and 2003, weather data for the area was collected at Barbourne, Worcester. Since the closure of this weather station, the nearest is located at Pershore.\nGreen belt.\nWorcester is in a regional green belt that extends into the surrounding counties. It is set to reduce urban sprawl between the cities and towns in the nearby West Midlands conurbations centred round Birmingham and Coventry, to discourage further convergence, protect the identity of outlying communities, encourage brownfield reuse, and preserve nearby countryside. This is done by restricting inappropriate development within the designated areas and imposing strict conditions on permitted building.\nWithin the city boundary, there is a small area of green belt north of the Worcester and Birmingham canal and of the Perdiswell and Northwick suburbs. This is part of a larger isolated tract south of the main green belt that extends into the adjacent Wychavon district, minimising urban sprawl between Fernhill Heath and Droitwich Spa, and keeping them separate. The green belt was first drawn up under Worcestershire County Council in 1975; the size within the borough in 2017 amounted to some .\nDemography and religion.\nThe 2011 census put Worcester's population at 98,768. About 93.4 per cent were classed as white, of whom 89.1 percentage points were White British \u2013 higher than the national average. The largest religious group consists of Christians, with 63.7 per cent of the city's population. Those reporting no religion or declining to state an allegiance make up 32.3 per cent. The next largest religious group, Muslims, makes up 2.9 per cent. The ethnic minorities include people of Pakistani, Bangladeshi, Chinese, Indian, Italian and Polish origin, the largest single group being British Pakistanis, numbering around 1,900: 1.95 per cent of the population. This has led to Worcester containing a small but diverse range of religious groups; as well as the prominent Anglican Worcester Cathedral, there are also Catholic, United Reformed and Baptist churches, a large centre for the Church of Jesus Christ of Latter-day Saints, a small number of Islamic mosques and a number of smaller groups for oriental religions such as Buddhism and the International Society for Krishna Consciousness.\nWorcester is the seat of a Church of England bishop, whose official signature is the personal Christian name followed by \"Wigorn\". (abbreviating the Latin \"Wigorniensis\", meaning \"of Worcester\"). This is also used occasionally to abbreviate the name of the county. The previous Archdeacon of Worcester, Robert Jones, inducted in November 2014, had been Rector of St Barnabas with Christ Church in Worcester for eight years. He retired on 30 November 2023\nEconomy.\nManufacturing.\n One of Worcester's famous products, Lea &amp; Perrins Worcestershire sauce, is made and bottled at a Midland Road factory, its home since 16 October 1897. Lea and Perrins originally partnered a chemist's shop on the site of the Debenhams's store in Crowngate Shopping Centre. Worcester has what is claimed to be the oldest newspaper in the world still in publication: \"Berrow's Worcester Journal\". It traces its descent from a news-sheet started in 1690.\nThe foundry heritage of the city is represented by Morganite Crucible at Norton which produces graphitic shaped products and cements for use in the modern industry. The city is home to the European manufacturing plant of Yamazaki Mazak Corporation, a global Japanese machine tool builder established here in 1980. Worcester Heating Systems was started in the city in 1962 by Cecil Duckworth. The company was bought by Bosch and renamed Worcester Bosch in 1996.\nRetail trade.\nThe city is a major retail centre, with several covered shopping centres to accommodate the major chains and many independent shops and restaurants, particularly in Friar Street and New Street. Worcester's main shopping centre is the High Street, with several major retail chains. The High Street was controversially part-modernised in 2005, and further modernised in 2015; with current redevelopment of Cathedral Plaza and Lychgate Shopping Centre. Much of the protest came at the felling of old trees, the duration of the work (caused by weather and an archaeological find) and removal of flagstones outside the city's 18th-century Guildhall. The other main thoroughfares are the Shambles and Broad Street. The Cross and its immediate surrounding area are the city's financial centre for most of Worcester's main bank branches.\nCrownGate Shopping Centre, Cathedral Plaza and Reindeer Court are the three main covered shopping centres in the city centre and immediately east of the city centre is the unenclosed shopping area of Shrub Hill Retail Park in the St Martin's Quarter. The inner suburb shopping centres, the Elgar and Blackpole retail parks are located in the Blackpole district and include many nation-wide retail chains.\nAmenities and landmarks.\nThe most famous landmark in Worcester is the Anglican Worcester Cathedral. Officially the Cathedral Church of Christ and the Blessed Virgin Mary, it was known as Worcester Priory before the English Reformation. Construction began in 1084. Its crypt dates from the 11th century. It includes the only circular chapter house in the country. It houses the tombs of King John and Prince Arthur. Near the cathedral is the spire of St Andrew's Church, which is all that remains after church was demolished in 1949 due to being unsafe. Known as Glover's Needle from the city's association with the glove-making industry, it has the steepest church spire in the UK.\nThe Parish Church of St Helen, on the north side of the High Street, is mainly medieval, with a west tower rebuilt in 1813. The east end, re-fenestration and porch were completed by Frederick Preedy in 1857\u20131863. There was further restoration, by Aston Webb in 1879\u20131880. It is a Grade II*listed building.\nThe high-water marks from the flood of 1670 and more recent flood levels are shown on a brass plate on a wall adjacent to the path along the river that leads to the cathedral.\nMuseums include Worcester City Art Gallery and Museum, Greyfriars' House, the Infirmary Museum, Tudor House Museum, George Marshall Medical Museum, RAF Defford Museum, Museum of Royal Worcester, Mercian Regiment Museum, the Commandery, and Worcestershire Yeomanry Museum. The Battle of Worcester site is just south of the city. Limited parts of Worcester's city wall remain.\nThe Hive, on the north side of the River Severn at the former cattle market site, is Worcester's joint public and university library and archive centre, heralded as \"the first of its kind in Europe\", and a prominent feature on the skyline. With seven towers and a golden rooftop, it has gained recognition, winning two international awards for building design and sustainability.\nThe city's three main open spaces: Gheluvelt Park in the in the Barbourne inner-city suburb of the city, and Fort Royal Park in the south-east of the city a short walk from the Commandery on the site of the last battle of the English Civil War in 1651. The large Gheluvelt Park commemorates the part played by Worcestershire Regiment's 2nd Battalion in the Battle of Gheluvelt in the First World War; and Cripplegate Park, located on the right bank after the bridge, adjacent to the Worcester County Cricket ground, which has a wide variety of leisure facilities serving the western suburbs. \nAn additional large area known as Pitchcroft close to the city centre on the east bank of the River Severn next to the railway viaduct, is an open public space except on days when it is used for horse racing. \nA statue of the composer Edward Elgar, commissioned from Kenneth Potts and unveiled in 1981, stands at the end of Worcester High Street facing the cathedral, a few metres from the original location of his father's music shop which was demolished in the 1960s. Elgar's birthplace was the nearby village of Broadheath. Plaques installed in the city include a dedication to the medieval Jewish community at Copenhagen Street.\nThe city has two large wooded areas: Perry Wood and Nunnery Wood . Perry Wood is often said to be where Oliver Cromwell met and made a pact with the Devil. Nunnery Wood is integral to the adjacent Worcester Woods Country Park, which is adjacent to the County Hall on the east side of the city.\nTransport.\nRoad.\nThe M5 Motorway runs north\u2013south immediately to the east of the city. It is accessed by junction 6 (Worcester North) and junction 7 (Worcester South). It connects Worcester to most parts of the country, including London, which is only using the A44 scenic route via the Cotswolds and M40. A faster journey to London but with an increased distance of goes via the M5, M42 and M40 motorways. \nThe main roads through the city include the A449 road south-west to Malvern and north to Kidderminster. The A44 runs south-east to Evesham and west to Leominster and Aberystwyth and crosses Worcester Bridge. The A38 trunk road runs south to Tewkesbury and Gloucester and north-north-east to Droitwich and Bromsgrove and Birmingham. The A4103 goes west-south-west to Hereford. The A422 heads east to Alcester, branching from the A44 a mile east of the M5. The city is partly ringed by A4440.\nCarrington Bridge on the A4440 is the second road bridge across the Severn. Opened on 20 April 1985 after decades of pressure for a second bridge to relieve traffic over the narrow city centre bridge, it links the A38 from Worcester towards Gloucester with the A449 to Malvern. It is one of Worcestershire's busiest roads. The single-carriageway bridge was doubled with work being completed on 5 August 2022, making the Southern Link Road dual between junction 7 of the M5 and Powick Roundabout. As of 2025 it remains the only river crossing in the between Worcester and Upton-upon-Severn.\nRail.\nWorcester is served by three stations. Worcester Foregate Street is in the middle of the city centre, Worcester Shrub Hill is located just over to the east, and Worcestershire Parkway which opened in 2020 is located the south-east of the city centre. Together, they serve all stations in the county and have frequent trains to Birmingham and the North, Oxford and London (Paddington), Malvern and Hereford, and Cardiff, Bristol, and the West Country.\nBuses.\nThe main operator in and around the city is First Midland Red. A few smaller operators provide services in Worcester, including Astons, DRM and LMS Travel. Diamond Bus operates a service from Kidderminster to communities along the A449. The terminus and interchange for many bus services is Crowngate bus station in the city centre.\nThe city had two park and ride sites: off the A38 in Perdiswell and at Sixways Stadium next to the M5. Worcestershire County Council voted to close both in 2014 as part of a package of cutbacks. The service at Sixways Stadium has since been reinstated, with LMS Travel operating the W3 route to Worcestershire Royal Hospital, but avoiding the city centre bus station.\nAir.\nWorcester's nearest airport is Birmingham International away, which is accessible by motorway (40 minutes) and rail from via Birmingham New Street station where trains leave every few minutes (202 trains per day) taking 10 - 12 minutes direct to the airport on the Birmingham - London line. Gloucestershire Airport in Staverton at about away at 29 minutes by motorway is the busiest general aviation airport in the UK for business and private charter, flying clubs, and private and commercial pilot training.\nCycling.\n Worcester is on routes 45 and 46 of the National Cycle Network. There are various routes around the city. Diglis Bridge, a pedestrian and Cycle bridge across the Severn, opened in 2010 to St Peter's with Lower Wick. Beryl bikes were introduced in 2024 to hire across Worcester, providing 175 e-bikes and 50 pedal bikes, from a network of 53 bays.\nWaterways.\nThe River Severn is navigable through Worcester, and here it links to the Worcester and Birmingham Canal, which connects Worcester with Birmingham and the rest of the national canal network. Historically used for the transport of goods, the canal network is now mostly used for leisure boating.\nEducation.\nThe high schools located in the city are Bishop Perowne CofE College, Blessed Edward Oldcorne Catholic College, Christopher Whitehead Language College, Tudor Grange Academy, Nunnery Wood High School, and the New College Worcester which caters for blind and partially sighted pupils aged 11\u201318. Independent schools in the city include some of the oldest schools in the country The Royal Grammar School (founded in 1291) and Alice Ottley School merged in 2007. The King's School located in the grounds of Worcester Cathedral was re-founded in 1541 under King Henry VIII. Other independent schools include the Independent Christian School, the River School in Fernhill Heath, and New College Worcester.\nThe University of Worcester was awarded university status in 2005 by the Privy Council, previously known since 1997 as University College Worcester (UCW) and before that as Worcester College of Higher Education. The city is also home to two colleges, Worcester Sixth Form College and Heart of Worcestershire College.\nHospitals.\nThe Worcestershire Royal Hospital is the principal NHS hospital serving the city and county of Worcester. It opened in 2002, replacing the Worcester Royal Infirmary. The former Worcester Eye Hospital was based in the Grade II listed Thornloe House, Barbourne Road, from 1940 to 1995. St Oswald's Hospital on the Tything was founded as alsmhouses and is now a care home.\nCulture.\nFestivals and shows.\nEvery three years Worcester becomes home to the Three Choirs Festival, which dates from the 18th century and is credited with being the oldest music festival in the British Isles. The location rotates between the cathedral cities of Gloucester, Hereford and Worcester. Famous for championing English music, especially that of Elgar, Vaughan Williams and Gustav Holst, Worcester hosted the festival in July 2017, but had to postpone its 2020 festival until 2021. The Worcester Festival (established in 2003 by Chris Jaeger MBE) occurs in August and consists of music, theatre, cinema and workshop events, along with a beer festival. For one weekend a year the city plays host to the Worcester Music Festival \u2013 a weekend of original music performed predominantly by local bands and musicians. All performances are free and take place around the city centre in bars, clubs, community buildings, churches and the central library.\nFounded in 2012, the Worcester Film Festival, places Worcestershire on the film-making map and encourages local people to get involved in making film. The first festival took place at and included screenings, workshops and talks.\nThe Victorian-themed Christmas Fayre is a busy event in late November/early December, with over 200 stalls lining the streets, and over 100,000 visitors. The CAMRA Worcester Beer, Cider and Perry Festival takes place for three days each August on Pitchcroft Race Course. It is the largest beer festival in the West Midlands and in the UK top ten with attendances of around 14,000. The Worcester Vegan Market began in 2021 and takes place in late spring and autumn. The Vegan Market fills High Street and Cathedral Square with vegan vendors, vegan food sellers, and vegan food trucks.\nArts and cinema.\nThe 18th-century actress Sarah Siddons made her acting d\u00e9but at the Theatre Royal in Angel Street. Her sister, the novelist Ann Julia Kemble Hatton, otherwise Ann of Swansea, was born in the city. Also born in Worcester was Matilda Alice Powles, better known as Vesta Tilley, a leading male impersonator and music hall artiste.\nThe Swan Theatre stages professional touring and local amateur productions and is the base for the Worcester Repertory Company. Past heads have included John Doyle and David Wood OBE. The director of the company and the theatre as of 2019 is Sarah-Jane Morgan. Stars who started their careers in the Worcester Repertory Company and the Swan Theatre include Imelda Staunton, Sean Pertwee, Celia Imrie, Rufus Norris, Kevin Whately and Bonnie Langford.\nHuntingdon Hall is a historic church now used as venue for an eclectic range of musical and comedy performances. Recent acts have included Van Morrison, Eddie Izzard, Jack Dee, Omid Djalili and Jason Manford. The Marrs Bar (in Pierpoint Street) is a venue for gigs and stand-up comedy. \nWorcester has two multi-screen cinemas; the Vue Cinema complex is located in Friar Street and the Odeon in Foregate Street \u2013 both were 3D-equipped by March 2010. \nAfter being closed for decades, the Scala building on Angle Place that opened as a cinema in 1922 is due to become a new cultural venue that will create spaces for \"live performance, film, workshops, courses and classes\" and festivals. The council has signed a contract with a Malvern-based contractor who has announced that work on the Angel Place site will begin in early 2025. Work began in 2025 and the venue is expected to open in late 2026.\nThe northern suburb of Northwick has the Art Deco Northwick Cinema. Built in 1938, it contains one of only two remaining interiors in Britain designed by John Alexander. The original perspective drawings are held by RIBA. It was a bingo hall from 1966 to 1982, then empty until 1991, a music venue until 1996, and empty again until autumn 2006, when it became an antiques and lifestyle centre, owned by Grey's Interiors, which was previously located in the Tything.\nMedia.\nNewspapers.\n&lt;templatestyles src=\"Plainlist/styles.css\"/&gt;\nRadio stations.\n&lt;templatestyles src=\"Plainlist/styles.css\"/&gt;\nTelevision.\nLocal news and television programmes are provided by BBC West Midlands and ITV Central from the Ridge Hill TV transmitter.\nIn popular culture.\n\"Mildred Arkell\".\nThe depression that hit the Worcester glove industry in the 1820s and 1830s is the background to a three-volume novel, \"Mildred Arkell\", by the Victorian novelist Ellen Wood (then Mrs Henry Wood).\n\"Cadfael Chronicles\".\nThe well-researched historical novel \"The Virgin in the Ice\", part of Ellis Peters' \"The Cadfael Chronicles\" series, depicts Worcester at the time of the Anarchy. It begins with the words:\n\"It was early in November of 1139 that the tide of civil war, lately so sluggish and inactive, rose suddenly to wash over the city of Worcester, wash away half of its livestock, property and women and send all those of its inhabitants who could get away in time scurrying for their lives northwards away from the marauders.\" (These are mentioned as arriving from Gloucester, leaving a long-lasting legacy of bitterness between the two cities.)\nTwinning.\nWorcester is twinned with:\nNotable people.\nIn birth order:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "58682", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=58682", "title": "Alan Shearer", "text": "English former footballer and pundit (born 1970)\nAlan Shearer (born 13 August 1970) is an English football pundit and former professional player who played as a striker. Widely regarded as one of the best strikers of all time and one of the greatest players in Premier League history, he is the league's record goalscorer with 260 goals. He was named Football Writers' Association Player of the Year in 1994 and won the PFA Player of the Year award in 1995. In 1996, he came third in both Ballon d'Or and FIFA World Player of the Year awards. In 2004, he was named by Pel\u00e9 in the FIFA 100 list of the world's greatest living players. Shearer was one of the first two players inducted into the Premier League Hall of Fame in 2021.\nShearer played his entire career in the top level of English football. He started his career at Southampton in 1988 before moving to Blackburn Rovers in 1992, where he established himself as among the most prolific goalscorers in Europe and won the 1994\u201395 Premier League. In the summer of 1996, he joined his hometown club Newcastle United for a then world record \u00a315 million, and in his first season won his third consecutive Premier League Golden Boot. He played in the 1998 FA Cup and 1999 FA Cup finals, captaining the team in the latter, and eventually became the club's all-time top scorer. He retired at the end of the 2005\u201306 season.\nFor the England national team, Shearer appeared 63 times and scored 30 goals. UEFA Euro 1996 was his biggest success at international football; England reached the semi-finals and Shearer was awarded the UEFA Euro Golden Boot and was named in the UEFA Euro Team of the Tournament. He went on to captain England at 1998 FIFA World Cup and UEFA Euro 2000, then retired from international football.\nSince retiring as a player in 2006, Shearer has worked as a television pundit for the BBC. In 2009, he briefly left his BBC role to become Newcastle United's manager in the last eight games of their 2008\u201309 season, in an unsuccessful attempt to save them from relegation. Shearer is a Commander of the Order of the British Empire (CBE), a Deputy Lieutenant of Northumberland, a Freeman of Newcastle upon Tyne and an honorary Doctor of Civil Law of Northumbria and Newcastle Universities.\nEarly life.\nAlan Shearer was born on 13 August 1970 in the Gosforth area of Newcastle upon Tyne, the son of Anne and sheet-metal worker Alan Shearer. His parents were working class. His father encouraged him to play football in his youth, and Shearer continued with the sport as he progressed through school. He was educated at Gosforth Central Middle School and Gosforth High School. Growing up, he played on the streets of his hometown and was originally a midfielder because \"it meant [he] could get more involved in the games\". Shearer captained his school team and helped a Newcastle City Schools team win a seven-a-side tournament at St James' Park, before joining the amateur Wallsend Boys Club as a teenager. It was while playing for the Wallsend club that he was spotted by Southampton's scout Jack Hixon, which resulted in him spending his summers training with the club's youth team, a time he would later refer to as \"the making of me\". Shearer had successful trials for First Division clubs West Bromwich Albion, Manchester City and Newcastle United, before being offered a youth contract with Southampton in April 1986.\nClub career.\n1986\u20131992: Southampton.\nShearer was promoted to the first team after spending two years with the youth squad. He made his professional debut for Southampton on 26 March 1988, coming on as a substitute in a First Division fixture at Chelsea, before prompting national headlines in his full debut at The Dell two weeks later. He scored a hat-trick, helping the team to a 4\u20132 victory against Arsenal, thus becoming the youngest player \u2013 at 17 years, 240 days \u2013 to score a hat-trick in the top division, breaking Jimmy Greaves' 30-year\u2013old record. Shearer ended the 1987\u201388 season with three goals in five games, and was rewarded with his first professional contract.\nDespite this auspicious start to his career, Shearer was only eased into the first team gradually and made just ten goalless appearances for the club the following season. Throughout his career Shearer was recognised for his strength, which, during his time at Southampton, enabled him to retain the ball and provide opportunities for teammates. Playing as a lone striker between wide men, Rod Wallace and Matt Le Tissier, Shearer scored three goals in 26 appearances in the 1989\u201390 season, and in the next, four goals in 36 games. His performances in the centre of the \"Saints\" attack were soon recognised by the fans, who voted him their Player of the Year for 1991.\nIn the middle of 1991, Shearer was a member of the England national under-21 football squad in the Toulon Tournament in Toulon, France. Shearer was the star of the tournament where he scored seven goals in four games. It was during the 1991\u201392 season that Shearer rose to national prominence. 13 goals in 41 appearances for the \"Saints\" led to an England call-up; he scored on his debut, and was strongly linked in the press with a summer move to Manchester United. A possible move for Shearer was being mentioned in the media during late autumn of 1991, but he rejected talk of a transfer and vowed to see out the season with Southampton, resisting the temptation of a possible transfer to the two clubs who headed the title race for most of the season. Speculation of a transfer to Liverpool, who finished the season as FA Cup winners, also came to nothing.\nDuring the middle of 1992, Southampton's manager, Ian Branfoot, became \"the most popular manager in English football\", as he took telephone calls from clubs \"trying to bargain with players they don't want plus cash\". Although Branfoot accepted that a sale was inevitable, he claimed that \"whatever happens, we are in the driving seat\". In July 1992, Shearer was sold to Blackburn Rovers for a fee of \u00a33.6 million, with David Speedie reluctantly moving to The Dell as part of the deal. Despite Branfoot's claim to be \"in the driving seat\", \"Saints\" failed to include a \"sell-on clause\" in the contract. Shearer, less than a month off his 22nd birthday, was the most expensive player in British football. In his four years in the Southampton first team, Shearer made a total of 158 appearances in all competitions, scoring 43 goals.\n1992\u20131996: Blackburn Rovers.\nDespite making just one goalless appearance as England failed to progress past the Euro 1992 group stages, Shearer was soon subject to an English transfer record-breaking \u00a33.6\u00a0million bid from Blackburn Rovers. Although there was also interest from Manchester United manager Alex Ferguson, Blackburn benefactor Jack Walker's millions were enough to prise the striker from Southampton, and Shearer moved north to Ewood Park in the middle of 1992.\nOn 15 August 1992, the opening weekend of the first Premier League season, Shearer scored twice against Crystal Palace with two strikes from the edge of the 18-yard box. He missed half of his first season with Blackburn through injury after snapping his right anterior cruciate ligament in a match against Leeds United in December 1992, but scored 16 goals in the 21 games in which he did feature. Shearer also became a regular in the England team this season and scored his second international goal; it came in a 4\u20130 1994 FIFA World Cup qualifier win over Turkey in November. Shearer was forced to miss January through to May due to injury and England's World Cup qualification chances were hit by a run of poor form.\nReturning to fitness for the 1993\u201394 season, he scored 31 goals from 40 games as Blackburn finished runners-up in the Premier League. His performances for the club led to him being named the Football Writers' Association Footballer of the Year for that season. On the international scene, England had failed to qualify for the 1994 World Cup finals, but Shearer added three more goals to his international tally before embarking on his most successful domestic season as a player to date.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n \"Shearer is the classic working class sporting hero\u00a0... everything legend demands an English centre-forward should be\u00a0... As a striker he comes closer to fitting the \"Roy of the Rovers\" fantasy than anyone else lately admired by English crowds\".\n Shearer as described in \"The Guardian\" on 10 April 1995.\nThe arrival of Chris Sutton for the 1994\u201395 season established a strong attacking partnership at Blackburn. Shearer's 34\u00a0goals, coupled with Sutton's 15, helped the Lancashire club take the Premier League title from archrivals Manchester United on the final day of the season, and the duo gained the nickname \"the SAS\" (Shearer And Sutton). Shearer finished the Premier League season with 47 goal-involvements (34 goals, 13 assists); a joint record Shearer shared with Andy Cole of Newcastle United. After being asked by the press how he planned to celebrate winning the title, Shearer replied with \"creosoting the fence\". Shearer also had his first taste of European football in the UEFA Cup that season, and scored in the second leg as Blackburn went out in the first round, losing to Trelleborgs FF of Sweden. His efforts for the club led to Shearer being awarded the PFA Players' Player of the Year for 1995.\nAlthough the club could not retain the title the following year, Shearer again ended the (now 38-game) season as Premier League top scorer, with 31\u00a0goals in 35\u00a0games, as Blackburn finished seventh in the league. The previous season's first-place finish also saw the club enter the Champions League. Shearer's only goal in six full Champions League games was a penalty in a 4\u20131 victory against Rosenborg BK in the final fixture and Blackburn finished fourth in their group, failing to progress to the next stage.\nHe passed the 100-goal milestone for Blackburn in all competitions on 23 September 1995, scoring a hat-trick in their 5\u20131 home win over Coventry City in the Premier League. On 30 December, he scored his 100th Premier League goal, making him the first player to hit the landmark, in a 2\u20131 home win over Tottenham Hotspur. His final tally for the club was 112 goals in the Premier League and 130 in all competitions. His final goals for the club came on 17 April 1996, when he scored twice in a 3\u20132 home league win over Wimbledon.\nShearer's international strike rate had also dried up, with no goals in the twelve matches leading up to Euro 96. He missed the final three games of the season for his club due to injury, but recovered in time to play in England's UEFA European Championship campaign.\n1996\u20132006: Newcastle United.\nAfter Euro 96, Manchester United and Real Madrid again sought to sign Shearer, and attempted to enter the battle for his signature. Manchester United chairman Martin Edwards and Real Madrid president Lorenzo Sanz stated that Blackburn Rovers refused to let Shearer go to Old Trafford or Estadio Santiago Bernab\u00e9u. Ultimately Shearer joined his boyhood club: Newcastle United, Manchester United's title rivals.\nOn 30 July 1996, for a world transfer record-breaking \u00a315 million (equivalent to \u00a3 million today), Shearer joined his hometown club and league runners-up Newcastle United, managed by his hero Keegan.\nShearer made his league debut away at Everton, on 17 August 1996, and maintained his form during the rest of the season, finishing as Premier League top-scorer for the third consecutive season with 25\u00a0goals in 31 Premier League games, as well as winning another PFA Player of the Year accolade, despite a groin injury forcing him to miss seven matches. Among his best performances of the season came on 2 February 1997, when Newcastle went into the final 15 minutes of the game 3\u20131 down at home to Leicester City in the league, only for Shearer to win them the game 4\u20133 by scoring a late hat-trick. The league title still eluded the club, who finished second in the league for a second consecutive year, with Keegan resigning midway through the season.\nAnother injury problem, this time an ankle ligament injury sustained in a pre-season match at Goodison Park, restricted Shearer to just two\u00a0goals in 17\u00a0games in the 1997\u201398 season. His injury was reflected in the club's form, and Newcastle finished just 13th in the Premier League. To help Shearer get over the injury, club physiotherapist Paul Ferris devised unorthodox methods. At the club's training ground at Durham University, Ferris stacked six school benches and placed Shearer on top with high-jump mats either side \u2013 the striker trying to improve his balance by standing on one leg and bending over to pick up coins while having objects thrown at him, while a crowd of student onlookers watched on. United (now managed by Shearer's former Blackburn manager, Kenny Dalglish) had a good run in the FA Cup; Shearer scored the winning goal in a semi-final victory over Sheffield United as the team reached the final. The team were unable to get on the scoresheet at Wembley, and lost the game 2\u20130 to Arsenal.\nAn incident during a game against Leicester City in the league saw Shearer charged with misconduct by the FA, with media sources claiming that video footage showed him intentionally kicking Neil Lennon in the head following a challenge. The referee of the game took no action against Shearer, and he was then cleared of all charges by the FA, with Lennon giving evidence in the player's defence. Former Football Association chief Graham Kelly, who brought the charges against the player, later wrote in his autobiography that Shearer had threatened to withdraw himself from the 1998 World Cup squad if the charges were upheld, which was strenuously denied by Shearer.\nAn almost injury-free season helped Shearer improve on his previous year's tally in the 1998\u201399 season, the striker converting 14\u00a0goals in 30 league games and replacing Rob Lee as Newcastle captain, but Newcastle finished 13th again, with Ruud Gullit having replaced Kenny Dalglish just after the season got underway. He also helped Newcastle to a second consecutive FA Cup final and qualification for the following season's UEFA Cup, scoring twice in the semi-final against Tottenham Hotspur, but they once again lost 2\u20130, this time to treble-chasing Manchester United.\nOn the opening day of the 1999\u20132000 season, Shearer received the first red card of his career in his 100th appearance for Newcastle. After dropping Shearer to the bench in a Tyne-Wear derby loss against Sunderland, the unpopular Gullit resigned to be replaced by the 66-year-old Bobby Robson. Despite Gullit giving Shearer the captain's armband, reports of a rift between club captain and manager were rife, Gullit's decision to drop Shearer proved deeply unpopular with fans and his departure capped a dismal start to the season. The animosity between Shearer and Gullit was later confirmed by the latter, who reportedly told the striker that he was \"...the most overrated player I have ever seen.\" Robson had tried to sign Shearer for Barcelona in 1997, making a bid of \u00a320 million which would have seen Shearer break the world's transfer fee record for the second time in 12 months. Newcastle's manager at the time, Kenny Dalglish, rejected the offer.\nIn Robson's first match in charge, Shearer scored five goals in an 8\u20130 defeat of Sheffield Wednesday. With Robson in charge, the team moved away from the relegation zone, finishing in mid-table and reached the FA Cup semi-finals, but a third consecutive final was beyond them as they were beaten by Chelsea. Shearer missed only one league game and notched up 23\u00a0goals.\nShearer suffered an injury-hit and frustrating season in the 2000\u201301 season, having retired from international football after the UEFA Euro 2000 tournament to focus on club football. He managed only five\u00a0goals in 19\u00a0games in the league. The 2001\u201302 season was much better though: Shearer bagged 23\u00a0goals in 37 league games as Newcastle finished fourth \u2013 their highest standing since 1997 \u2013 meaning they would qualify for the following season's Champions League competition. One of the most memorable incidents of the season saw Roy Keane sent off after a confrontation with Shearer during Newcastle's 4\u20133 win over the \"Red Devils\" in September 2001. Shearer also saw red for the second time in his career this season, after allegedly elbowing an opposition player in a match against Charlton Athletic, but this decision was later rescinded.\nThe 2002\u201303 season saw Shearer and Newcastle make their return to the UEFA Champions League. Newcastle lost their first three matches in the opening group stage, but Shearer's goal against Dynamo Kyiv, coupled with further wins against Juventus and Feyenoord saw the club progress to the second group stage.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"I know at first hand how fierce the gladiatorial battles are between a striker and defenders. So, to maintain your performance as a top class goalscorer over a long period of time takes phenomenal dedication, self belief and enormous willpower. If you then throw in a number of serious injuries...how many? Three? And for the man to still be producing at the highest level is really an amazing feat. After a match against Juventus I met Alex Del Piero who like myself could only speak in the most glowing of terms about Shearer. He'd terrorised the Juve defenders when the clubs met in Newcastle. They found him one of the most difficult opponents they had ever faced. The coach Marcello Lippi had been purring about Shearer's performance. So much so that his strikers Alex, David (Trezeguet) and Marcelo (Salas) were ordered to take home videos and study Shearer's display.\"\u2014\u200a\nShearer's Champions League hat-trick against Bayer Leverkusen and a brace against Inter Milan in the second group stage helped him reach a total of seven Champions League goals, along with his 17 in 35 games in the league, and a total of 25 for the season as the team again improved to finish in third place in the Premier League.\nAfter this, Newcastle would have one more chance to progress in the Champions League in early 2003, but Shearer was one of those who failed to score as the team were eliminated in a penalty shootout by Partizan Belgrade in the third qualifying round. United progressed well in that season's UEFA Cup and Shearer's six goals helped the club reach the semi-finals, where they were beaten by eventual runners up Olympique de Marseille. Domestically he also had a good season, with 22\u00a0goals in 37\u00a0appearances, but this did not prevent the club dropping out of the Champions League places to finish in fifth, qualifying once again for the UEFA Cup.\nAnnouncing that this would be his final season before retirement, Shearer's form in the 2004\u201305 season was patchy; alongside new signing Patrick Kluivert, he scored only seven\u00a0goals in his 28\u00a0games as the club finished the season in 14th place. The club fared better in the cup competitions, eventually losing out to Sporting CP in the UEFA Cup quarter-finals and Manchester United in the FA Cup semi-finals. Shearer scored a hat-trick in the first round win against Hapoel Bnei Sakhnin, and ended the season with a haul of 11 European goals, in addition to his one goal in domestic cups.\nThe middle of 2005 saw Shearer reverse his decision to retire, after persuasion from manager Graeme Souness. He decided to continue playing in a player-coach capacity until the end of the following season. and he returned for one more season in the 2005\u201306 season. This last season saw him break Jackie Milburn's 49-year-old record of 200\u00a0goals for Newcastle United (not including his 38 World War II Wartime League goals) when he netted his 201st strike in a home Premier League fixture against Portsmouth on 4 February 2006, becoming the club's highest-ever league and cup competition goalscorer with 201 goals altogether. On 17 April 2006, with three games remaining in his final season as a player, Shearer suffered a tear to the medial collateral ligament in his left knee after a collision during a 4\u20131 win at Sunderland in which he scored his 206th and final goal in what was his 395th appearance for the club. The injury caused him to miss those final three games, effectively bringing forward his retirement. Shearer finished his final season with 10\u00a0goals in 32 league games.\nTribute and testimonial.\nIn tribute to Shearer's contribution to Newcastle United over more than ten years, the club erected a large banner of Shearer on the outside of the cantilever superstructure of the Gallowgate End of St James' Park. The banner measured high by wide, covering almost half of the Gallowgate End, aptly placed above the club bar, Shearer's Bar, opened in his honour in 2005. The banner depicted Shearer as the \"Gallowgate Giant\", with one arm aloft in his signature goal celebration, with the message \"Thanks for 10 great years\", and was featured in the media coverage reflecting on his career at the club, with the banner being displayed from 19 April 2006 until 11 May 2006, the day of his testimonial match.\nShearer was awarded a testimonial match by the club, against Scottish side Celtic. All proceeds of the match went to charitable causes. Because of the injury he sustained three games earlier at Sunderland, Shearer was unable to play in the whole match, but he kicked off the game and came off the bench to score a penalty, helping Newcastle win the game 3\u20132. The match was a sell-out, and saw Shearer perform a lap of honour at the end with his family, with his young son covering his ears due to the volume of noise produced by the crowd in tribute.\nInternational career.\nShearer's international career began in 1990 when he was handed a callup to the England under-21 squad under Dave Sexton. During his time with the squad, he scored 13 times in 11 games, a record return which is still unbeaten. The striker's goals at this level, coupled with his club form, meant he was soon promoted to the senior squad by coach Graham Taylor. Marking his debut in the 2\u20130 win against France in February 1992 with a goal, he made his only appearance for the England B team a month later. Due to replace Gary Lineker, who retired from international action after UEFA Euro 1992, in the England attack, Shearer played only intermittently in the qualifying campaign for the 1994 FIFA World Cup due to injury and the team failed to reach the competition finals.\nUEFA Euro 1996 was a more positive experience for both Shearer and England. With England not required to qualify as hosts, Shearer had not scored in 12 games in the 21 months prior, and even his overall goalscoring record for England did not look too impressive so far, with five goals in 23 games. Shearer scored in the 22nd minute of the first game, against Switzerland. Scoring once in the following game against Scotland and twice in a 4\u20131 win over the Netherlands, Shearer helped England to progress to the next stage in front of their own fans in Wembley. In the quarter-finals, England were outplayed by Spain but got through to a penalty shootout after a goalless draw. Shearer scored the first England penalty, while the Spaniards failed to score from two of theirs, sending England into the semi-final against Germany. Shearer headed England into the lead after three minutes, but the Germans quickly equalised and the match went to penalties again. This time, Germany won from the spot; although Shearer scored, his teammate Gareth Southgate missed his kick and England were eliminated. Shearer's five\u00a0goals made him the competition's top scorer, and he was included with teammate Paul Gascoigne in the official UEFA team of the tournament. \nThe new England manager Glenn Hoddle appointed Shearer captain for the 1998 FIFA World Cup qualifier against Moldova on 1 September 1996, and the player held onto the captaincy after scoring once in that match and twice in the following game against Poland. He scored a total of five\u00a0goals in England's successful qualification campaign for the World Cup, adding strikes against Georgia and away to Poland to his tally. Shearer was sidelined for much of the 1997\u201398 season, but recovered to play in the World Cup finals. He scored England's first goal of the tournament, in a 2\u20130 win over Tunisia, his only goal in the three group matches. England faced long-time rivals Argentina in the second round. Shearer scored a first-half equaliser from the penalty-spot before David Beckham was sent off early in the second half. In the final minutes of the game Sol Campbell headed in what could have been the winning goal only for the referee to disallow it due to Shearer having elbowed goalkeeper Carlos Roa. The scores tied 2\u20132, the game went to penalties. Shearer scored again, but England were eliminated after David Batty's shot was saved by the Argentina goalkeeper. This defeat ended England's participation in what was to be Shearer's only World Cup tournament.\nIn September 1999, Shearer scored his only England hat-trick in a UEFA Euro 2000 qualifier against Luxembourg. This helped England reach a play-off against Scotland; England won the game over two legs and in doing so qualified for the European Championship. By now, Shearer was approaching his 30th birthday, and he announced that he intended to retire from international football after the Euro 2000 tournament.\nShearer did not score in England's opening 3\u20132 defeat against Portugal, but did so as England defeated Germany 1\u20130 in Charleroi, ensuring that England beat Germany for the first time in a competitive match since the 1966 World Cup final. To remain in the tournament, England only required a draw against Romania in the final group match, and Shearer scored a penalty as England went in at half-time 2\u20131 up, but Romania ultimately won 3\u20132. England's tournament was over, and so was Shearer's international career. From his 63 caps, he captained the team 34 times and scored 30 goals; he is ranked 7th in the England all-time goalscorers list, level with Nat Lofthouse and Tom Finney. Shearer remained in international retirement despite speculation of a return during the 2002 World Cup and 2004 European Championship campaigns, and further declined an offer to be assistant manager to Steve McClaren after the 2006 World Cup \u2013 a position ultimately filled by Terry Venables.\nStyle of play.\nWidely regarded as one of the best strikers of all time and one of the greatest players in the history of the Premier League, Shearer was often styled as a classic English centre-forward, owing to his strength, physical stature, heading ability and strong shot, which enabled him to be a highly prolific goalscorer. Of his 206 Newcastle goals, 49 were scored with his head. Earlier in his career, especially at Southampton, Shearer played a more creative role: providing chances for fellow strikers, and making runs into space, owing to his link-up play, work-rate, and early development as a midfielder. Later on in his career, Shearer played a more forward role, after his age robbed him of some of his pace. Able to hold the ball up well, he often functioned as a target man, providing balls for other players. Although his strength allowed him to hold on to the ball, his playing style sometimes brought him criticism \u2013 most commonly that his play was too physical, and that he used his elbows too aggressively. It was this that contributed to both of his dismissals, although one was later rescinded on appeal. In addition to his playing ability, he also stood out for his leadership qualities throughout his career.\nShearer was noted as a proficient penalty taker for both club and country, and he scored 45 times from the spot for Newcastle, where he was the first-choice taker; with 56 goals from 67 attempts, he is also the most prolific penalty-taker in Premier League history. He also scored five goals from free-kicks for the north-east club. He was known for his accuracy and shooting power from outside the penalty area either when taking set-pieces or from open play.\nManagerial career.\nEarly career.\nOn his retirement as a player, Shearer responded to speculation of an immediate move into coaching, saying that he would take some personal time off to \"enjoy life\" for the next couple of years. He was also quoted as saying that he would eventually like to move into management \"when the time was right\". As of March 2009 he was yet to start the UEFA Pro Licence course, which is required to be permitted to manage a team in the Premier League and European competition.\nReflecting his desire for personal time off to \"enjoy life\", in July 2006 he turned down a coaching role with England, citing his BBC commitments and desire to be away from the pressure of a job within football. Despite this, Shearer was often linked in the media with managerial or coaching positions at his three former clubs.\nShearer took a brief role in the dugout for his final three games under Glenn Roeder. Shearer had rejected offers of coaching or assistant roles at Newcastle under both the returning Kevin Keegan in February 2008 and Joe Kinnear in November 2008. Shearer had previously had talks about, but never been offered, a full-time manager's role at Newcastle until his appointment on 1 April 2009.\nNewcastle United.\nIn a surprise move, late on 1 April 2009, it was announced that Shearer would become the manager of his former club Newcastle United for the remaining eight games of the season, taking over from head coach Chris Hughton who was in temporary charge while the permanent manager Joe Kinnear recovered from heart surgery, having taken ill on 7 February. Shearer stated \"It's a club I love and I don't want them to go down. I'll do everything I can to stop that.\"\nShearer was unveiled at a press conference the following day by club managing director Derek Llambias. In explaining his acceptance of a managerial role at Newcastle at this time, Shearer stated that he would not have done this for any other club in this position, including his two other previous Premier League clubs. Amid persistent questioning regarding the permanency of the appointment, Llambias announced that Shearer was to be manager for the remaining eight games, and after his recovery, Joe Kinnear would return as manager after the end of the season. Shearer confirmed that the BBC had agreed to giving him an 8-week sabbatical from his \"Match of the Day\" role. Llambias also confirmed Dennis Wise had left his executive role at the club and the club had no plans to appoint a replacement, with Shearer stating that \"the people that have moved, were moving on anyways, that had nothing to do with me\". Wise's presence had previously been speculated as being a blockage to any possible appointment of a manager. Shearer accepted the surprise offer on the Monday on the condition that he could bring in Iain Dowie as his assistant. Shearer also brought in Paul Ferris to oversee club medical, physio and dietary matters. Ferris had previously worked with Shearer in his playing days, and had been at the club for 13 years prior to an earlier departure under then manager Glenn Roeder.\nShearer's first match in charge ended in a 2\u20130 defeat against Chelsea at St James' Park. On 11 April, Newcastle earned their first point under Shearer with a 1\u20131 draw with Stoke City at the Britannia Stadium with Andy Carroll scoring a late equalising goal. After a defeat to Tottenham Hotspur and a draw against Portsmouth, his first win for Newcastle came in a 3\u20131 victory over Middlesbrough that lifted Newcastle from the relegation zone.\nOn the eve of the final day of the season on 24 May, where all fixtures are played simultaneously, Newcastle faced the prospect of being relegated to the Championship, along with Hull City, Middlesbrough and Sunderland, which would end their 16-year unbroken spell in the Premier League. After losing 1\u20130 at Aston Villa with Damien Duff scoring an own goal, Newcastle were relegated with local rivals Middlesbrough, joining West Bromwich Albion whose relegation had been confirmed in previous weeks, while Sunderland and Hull City survived. Shearer's eight games yielded only five points out of a possible twenty-four.\nShearer did not get the manager's job on a permanent basis. Chris Hughton stepped up from the coaching staff to take charge of the quest to get Newcastle back into the Premier League, which was achieved at the first attempt as Newcastle finished top of the Championship in the 2009\u201310 season.\nOutside football.\nPersonal life.\nShearer met his future wife, Lainya, whilst playing for Southampton. They lived locally with her parents in the city during his second year at the club, and were married on 8 June 1991 at St James' Church, West End, near Southampton. They have three children together. Shearer has described his wife as a quiet and reserved person who is uncomfortable with the public attention his fame sometimes brings. He cited not wanting to uproot his family as a key reason for remaining in England during his career, having had the chance to move to Juventus or Barcelona when leaving Blackburn. In May 2006, his family accompanied him onto the pitch at St James' Park as he performed a lap of honour following his testimonial match.\nPersonal honours.\nOn 6 December 2000, Shearer was given Honorary Freedom of the City of Newcastle upon Tyne, with the citation \"in recognition of his role as captain of Newcastle United Football Club and as former captain of England which have enhanced the reputation of the City\". Shearer was appointed Officer of the Order of the British Empire (OBE) in the 2001 Queen's Birthday Honours and Commander of the Order of the British Empire (CBE) in the 2016 Birthday Honours for charitable services to the community in North East England.\nOn 4 December 2006, Shearer was created a Doctor of Civil Law by Northumbria University, at a ceremony at Newcastle City Hall, where the university vice-chancellor declared that \"Throughout his career Alan Shearer has been hard-working, committed, disciplined and focused in his endeavours, fighting back from career-threatening injuries with great determination and courage\".\nOn 1 October 2009, Shearer was commissioned as Deputy Lieutenant of Northumberland, having been nominated by the Duchess of Northumberland in her capacity as Lord Lieutenant of Northumberland, and approved for the position by the Queen. In this role, Shearer, along with 21 other deputies, is the stand-in for the Duchess when she cannot fulfill her role as the Queen's official representative in the region at official engagements. Deputies must live within seven miles of the county boundaries, and retain their appointment until age 75. The Duchess said of the appointment that \"You could not find a more iconic person than Alan, not just for what he has done in football but for all the extra work he tirelessly does for charity and communities. I am delighted he has accepted the role of Deputy Lieutenant because he is a real role model. I have promised him he is not going to have to do too much, but even if it is just one occasion a year he is the perfect choice\"\nOn 7 December 2009, Shearer was made a Doctor of Civil Law by Newcastle University. Chancellor Liam Donaldson stated \"Newcastle United are my team. Alan Shearer is more than just a local legend, he's probably one of the greatest footballers of all time\". On 12 September 2016, a statue of Shearer's likeness was unveiled outside St James' Park. It was sculpted by Tom Maley, and paid for by the Shepherd family.\nOn 26 April 2021, Shearer was announced as the first inductee in the Premier League Hall of Fame.\nMedia.\nAfter his retirement and following guest appearances, Shearer became a regular pundit for the BBC's \"Match of the Day\". He also formed part of the team which covered the World Cups and European Championships from 2006 onwards for the BBC.\nFormer Newcastle chairman Freddy Shepherd announced that, after Shearer finished the 2005\u201306 season as Newcastle's caretaker assistant manager, he would become the club's \"Sporting Ambassador\" for the 2006\u201307 season. However, in September 2008, tabloids reported that Shearer was removed from this largely honorary position by the club's owner Mike Ashley \u2013 though these reports were denied by the club.\nDuring his playing career Shearer appeared in commercials for the sports drink Lucozade. He is among a group of high-profile athletic figures in British pop culture to promote the brand, which includes Olympic champions Daley Thompson and Linford Christie, footballer John Barnes, rugby player Jonny Wilkinson, and \"Tomb Raider\" heroine Lara Croft.\nShearer features in EA Sports' \"FIFA\" video game series; he was included in the \"FIFA 15\" Ultimate Team Legends.\nOn 10 March 2023, following the suspension of Gary Lineker as the host of Match of the Day for allegedly breaching BBC impartiality rules by criticising the government's asylum policy on Twitter, Shearer alongside other pundits announced that they would not present the following episode of the show in solidarity with Lineker.\nIn October 2024, Shearer's famous quote from UEFA Euro 2024, \"pressure is for tyres\" was used by the HarrisWalz campaign.\nIn November 2024, it was announced that Shearer is set to manage one of the 12 teams in the upcoming Baller League, a six-a-side football league.\nPhilanthropy.\nDuring his playing days, Shearer had been involved with the National Society for the Prevention of Cruelty to Children (NSPCC), taking part in the organisation's Full Stop campaign in 1999. Since retiring from football Shearer has also done work for several charities both nationally and in the Newcastle area.\nIn his testimonial match, he raised \u00a31.64m benefiting fourteen good causes including \u00a3400,000 for the NSPCC and \u00a3320,000 for completion of the \"Alan Shearer Centre\", a respite care facility based in West Denton, Newcastle. In October 2006, he became an ambassador for the NSPCC, describing it as \"the kick-off to my most important role yet\". He has also worked with The Dream Foundation. In 2006, Shearer founded the Alan Shearer Academy Scholarship to aid the development of promising young players in the region.\nIn 2008, he raised over \u00a3300,000 for Sport Relief in a bike ride with fellow \"Match of the Day\" presenter Adrian Chiles, the idea for which emerged in an off the cuff question from cycling fan Chiles to Shearer as to how he kept fit since retirement. Shearer also played and scored twice in Soccer Aid, a game involving celebrities and former players at Wembley Stadium in September 2008, to raise money for UNICEF.\nOn 26 July 2009, Shearer played and scored in the Sir Bobby Robson Trophy match, a charity match held at St James' Park in tribute of Bobby Robson and in aid of his cancer charity the Sir Bobby Robson Foundation. It proved to be Robson's last public appearance, as he died five days later. On 15 October 2009, Shearer became the new patron of the Sir Bobby Robson Foundation.\nCareer statistics.\nClub.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n\"Scores and results list England's goal tally first, score column indicates score after each Shearer goal\".\n \"As of 24 May 2009\"\nHonours and achievements.\nSouthampton\nBlackburn Rovers\nNewcastle United\nEngland U21\nEngland\nIndividual\nRecords\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58683", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=58683", "title": "Bookmaker", "text": "Organization or person that takes bets on sporting events\nA bookmaker, bookie, or turf accountant is an organization or a person that accepts and pays out bets on sporting and other events at agreed-upon odds.\nHistory.\nThe first bookmaker, Harry Ogden, stood at Newmarket in 1795, although similar activities had existed in other forms earlier in the eighteenth century.\nFollowing the Gaming Act 1845, the only gambling allowed in the United Kingdom was at race tracks. The introduction of special excursion trains meant that all classes of society could attend the new racecourses opening across the country. Runners working for bookmakers would collect bets in clock bags. Cash flowed to the bookmakers who employed bodyguards against protection gangs operating within the vast crowds. Illegal betting shops were fined, but some, like Bella Thomasson, ran betting businesses that the police appeared to turn a blind eye to.\nRange of events.\nBookmakers in many countries focus on accepting bets on professional sports, especially horse racing and association football or Indian Premier League cricket. However, a wider range of bets, including on political elections, awards ceremonies such as the Oscars, and novelty bets are accepted by bookmakers in some countries.\nOperational procedures.\nBy \"adjusting the odds\" in their favour (paying out amounts using odds that are less than what they determined to be the true odds) or by having a point spread, bookmakers aim to guarantee a profit by achieving a 'balanced book', either by getting an equal number of bets for each possible outcome or (when they are offering odds) by getting the amounts wagered on each outcome to reflect the odds. When a large bet comes in, a bookmaker may also try to \"lay off\" the risk by buying bets from other bookmakers. Bookmakers do not generally attempt to make money from the bets themselves but rather by acting as market makers and profiting from the event regardless of the outcome. Their working methods are similar to those of an actuary, who does a similar balancing of financial outcomes of events for the assurance and insurance industries.\nGambling industry by country.\nUnited Kingdom.\nIn 1961, Harold Macmillan's Conservative government legalised betting shops, with tough measures enacted to ensure that bookmakers remained honest. A large industry has grown since. At one time, there were over 15,000 betting shops. Now, through consolidation, they have been reduced to between 9,100 and 9,200 in 2013. This number has reduced further to 6,219 as of March 2022, largely as a result of Covid-19 and the forced closure of shops on the UK high street. The group of the largest bookmakers in the country, known as the \"Big Three\", comprises William Hill, Ladbrokes, and Coral.\nThe United Kingdom's Gambling Act 2005 introduced a new regulatory system for governing gambling in Great Britain. This system includes new provisions for regulating the advertising of gambling products. These provisions of the Act came into effect in September 2007. It is an offence to advertise in the UK, gambling that physically takes place in a non-European Economic Area (EEA) or, in the case of gambling by remote means, gambling that is not regulated by the gambling laws of an EEA state. The Gambling Commission is the body that makes sure all sites and operators follow the new restrictions. In addition to the Gambling Act of 2005, according to the new gambling bill, online gambling sites are only allowed to offer services within the United Kingdom, if they are registered at the UK Gambling Commission.\nImproved TV coverage and the modernisation of the law have allowed betting in shops and casinos in most countries. In the UK, on-track bookies still mark up the odds on boards beside the racecourse and use tic-tac or mobile telephones to communicate the odds between their staff and to other bookies, but, with the modernisation of United Kingdom bookmaking laws, online and high street gambling are at an all-time high. A so-called super-casino had been planned for construction in Manchester, but the government announced that this plan had been scrapped on 26 February 2008.\nGermany.\nThe law on betting on horse racing and lotteries was passed by the German legislature and came into force on 1 July 2012. Since then, a tax of 5% of the bet must be paid to the tax authorities for all sports betting (offline and online). This affects the entire sports betting market in Germany.\nMany of the bookmakers are sponsoring some of the major football teams in the major European football leagues, although Werder Bremen are currently fighting the German courts for the freedom to continue featuring bookmaker Bwin on their shirts, as Germany and France take action against online gamers. For example, as of 1 January 2020, Germany bettors will not be able to bet more than \u20ac1,000 a month. The latest amendment of the ITG states that. New online sportsbook laws are expected shortly in Germany, as this law is only temporary: the expiration date is set to be on 20 June 2020.\nCanada.\nThe fundamental law governing gambling activities in Canada is the federal Criminal Code (the \"Code\"). Sections 201 to 206, including section 206, make all types of gambling, betting and lotteries illegal throughout Canada with very limited exceptions, such as betting-mutuel on horse racing (provided for in section 204). While the federal Code is the applicable prohibitionist law, all regulations (and regulatory bodies) are provincial, with one exception - pari-mutuel betting on horse racing, which is regulated by the federal Canadian agency Pari-Mutuel. However, this law has many critics, as it is believed that the Canadian sports betting market can generate $25 billion a year.\nUnited States.\nAttempts to restrict operators of foreign gambling websites from accessing their domestic market resulted in a 2007 ruling against the US government by the World Trade Organization. However, common online gambling laws in the United States still don't exist \u2013 it differs from state to state. All forms of online gambling are illegal within the states of Utah and Hawaii, while the states of Delaware, Pennsylvania and New Jersey took a different approach: almost all forms of online gambling are legal in these states. These are the only US states where online casino sites can be legally registered. It is important to mention that Native Americans have their own gambling legislation - the Indian Gaming Regulatory Act of 1988. However, they need their state's approval to be able to offer their services online.\nThe Supreme Court overturned the federal ban on online gambling in 2018. However, while online gambling and casinos are legal, each state has its own rules. In Pennsylvania and New Jersey, the legal bookmakers are DraftKings, FanDuel and Pointsbet. Mississippi, New Jersey, Delaware, Nevada and West Virginia are on the road to legalisation, but Nevada and New Jersey have already passed laws. Most analysts predict the trend towards legalization of online gambling will continue in more and more US states.\nAustralia.\nSome bookmakers have taken to using betting exchanges as a way of laying off unfavourable bets and thus reducing their overall exposure. This has led to insecurity from some TABs in Australia, state-run betting agencies that attempted to deny Betfair an Australian licence by running unfavourable ads in the media regarding the company. When Tasmania granted Betfair a licence despite these efforts, the Western Australian state legislature passed a law that specifically criminalised using betting exchanges from within the state; however, the law was later ruled to be unconstitutional. As a result, internet gambling in Australia required a new legal framework. The Interactive Gambling Act 2001 regulates the online gambling market in Australia, together with all its amendments. The last amendment was introduced on 13 September 2017. This bill states that online casinos, online poker and live betting are illegal in Australia. The Australian Communication and Media Authority (ACMA) is the regulatory body responsible for all supervising online gambling activities. Online sports betting is legal, however.\nFrance.\nOnline sports betting in France is divided into two sections: Autorit\u00e9 de R\u00e9gulation des Jeux en Ligne (ARJEL) regulates online sports betting, while online horse betting is regulated by the law \"Decree 2010-498 from 17 May 2010. International bookmakers are allowed to enter the French market, thanks to the Law No. 2010-476 from 12 May 2010.\nInternet gambling.\nWith the increasing number of online betting exchanges, betting exchanges are now providing free bet offers in an attempt to lure customers away from the competition. These free bets are generally based on the size of the deposit made into the gambling account. For example, if a customer deposited \u00a320, the betting exchange would deposit an additional \u00a320 for the customer to use. Free bet rules vary depending on the betting exchange.\nSponsorships.\nMost televised sports in the United Kingdom and the rest of Europe are now sponsored wholly or partly by Internet and high street bookmakers, with sometimes several bookmakers and online casinos being displayed on players' shirts, advertising hoardings, stadium signs and competition event titles. Sponsors are especially highlighted in the football category since football fans present a significant percentage of the bookmakers' target group.\nWith the recent banning of tobacco sponsorship and the significant commercial budgets available to the gaming industry, sponsorship by car manufacturers, alcoholic drinks, soft drinks and fast-food marketers is being rapidly replaced by sponsorship from gaming companies in the Far East and Europe.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58684", "revid": "473593", "url": "https://en.wikipedia.org/wiki?curid=58684", "title": "Ruud Gullit", "text": "Dutch association football player and manager\nRuud Gullit (; born Rudi Dil; 1 September 1962) is a Dutch former footballer and subsequent manager. He was noted for his ability to play in multiple positions.\nAt club level, Gullit moved from PSV to AC Milan in 1987 for a world record transfer fee. Nicknamed \"The Black Tulip\", he was part of a notable Dutch trio at AC Milan which included Marco van Basten and Frank Rijkaard. Gullit won three Serie A titles and two European Cups with Milan. In 1995, he signed for Chelsea and was appointed the club's player-manager a year later. In his debut season, he led Chelsea to FA Cup success, the club's first major title for 26 years, and in doing so, became the first overseas manager to win the FA Cup.\nGullit captained the Netherlands national team that was victorious at the UEFA Euro 1988 and was also a member of the squad for the 1990 FIFA World Cup and Euro 1992. He won the Ballon d'Or in 1987 and was named the World Soccer Player of the Year in 1987 and 1989. In 2004, he was named one of the Top 125 greatest living footballers as part of FIFA's 100th anniversary celebration.\nEarly life.\nGullit was born as Rudi Dil in Amsterdam to George Gullit, a Surinamese who arrived in the Netherlands with Herman Rijkaard (father of Frank Rijkaard), and Dutch mistress Ria Dil from the Jordaan district of Amsterdam. The Gullit family lived in one split level room on the top floor of a small apartment building. Gullit's father worked as an economics teacher at a local school, his mother as a custodian at the Rijksmuseum.\nGullit developed his football skills in the confines of the Rozendwarsstraat, and street football was instrumental in his formative years. Gullit's first team were the Meerboys, where he joined as a junior in 1970. At the age of ten, however, Gullit moved from the Jordaan to Amsterdam Old West where he played street football alongside Rijkaard. Gullit joined the DWS club after his move, and came to the attention of the Dutch youth team, where he played alongside future full international teammates, Erwin Koeman, Ronald Koeman and Wim Kieft.\nIt was during his time at DWS that Gullit first took to using his father's surname, rather than his registered surname (from his mother), as he thought Gullit sounded more like a football player.\nClub career.\nHFC Haarlem.\nOn 22 September 1978, Gullit signed professionally for HFC Haarlem under coach and former West Bromwich Albion player Barry Hughes. Gullit made 91 league appearances for Haarlem, scoring 32 goals. He made his debut for the club at just 16 years and 11 months old, on 19 August 1979 (Haarlem-MVV Maastricht 2-2), becoming at the time the youngest player in the history of the Eredivisie. In his first year at Haarlem, the club finished bottom of the Eredivisie, but bounced back the following season winning the Eerste Divisie. Gullit was named as the best player in the Eerste Divisie that season.\nIn the 1981\u201382 season, Gullit was in fine form as Haarlem finished fourth and qualified for Europe for the only time in their history. In that same season, Gullit scored the goal he would later consider his finest: \"Playing against Utrecht I went past four defenders and then the goalkeeper, and scored. It was an unforgettable goal for me.\" Hughes was so impressed with the young Gullit that he described him as the \"Dutch Duncan Edwards\".\nFeyenoord.\nThe young Gullit was considered as a signing by English sides Arsenal and Ipswich Town, but managers Terry Neill and Bobby Robson turned him down. Neill later said that he considered \u00a330,000 too much for \"this wild kid\". Gullit therefore moved to Feyenoord in 1982, where he made 85 league appearances, scoring 31 goals. At Feyenoord, Gullit found himself playing in his second season, 1983\u201384, alongside Johan Cruyff, while the assistant manager was Wim van Hanegem, and they were to leave a lasting impression.\nGullit's first season saw Feyenoord miss out on major honours, but the following year they completed the league and cup double. Gullit was named Dutch Footballer of the Year in recognition of his contribution to Feyenoord's success. At Feyenoord, Gullit occupied an increasingly advanced role in midfield, having played predominantly as a sweeper at Haarlem. While at Feyenoord, Gullit became the focus of a race row as manager Thijs Libregts was alleged to have referred to Gullit as \"blackie\" and criticised him for being lazy, though Libregts defended himself by stating that it was merely a nickname. While playing for Feyenoord at St Mirren in September 1983, he was racially abused and spat on by supporters of the Scottish club. Gullit called it \"the saddest night of my life\".\nPSV.\nIn 1985, Gullit moved to PSV for 1.2\u00a0million Dutch guilders and wound up scoring 46 goals in 68 league appearances for the team. Gullit was again named Footballer of the Year in 1986 as he helped PSV capture the Eredivisie crown, a feat they repeated the following year.\nAC Milan.\nGullit signed for AC Milan in 1987, paying the then world record transfer fee of 18\u00a0million guilders as a replacement for Ray Wilkins. Milan's club president Silvio Berlusconi had an ambition to revive the fortunes of the Italian club which had stagnated after its glory days in the 1960s. Among Gullit's teammates at the club were compatriot van Basten, who came at the same time. Later, they were joined by fellow compatriot, close friend as well as Ajax teammate of van Basten, Rijkaard. The club also had a young Paolo Maldini, along with a more experienced Franco Baresi. Gullit's exploits with first PSV and then Milan helped him win the Ballon d'Or award in 1987 which he dedicated to Nelson Mandela.\nWhen he first arrived at Milan, Gullit initially struggled to fit in as he spoke no Italian and was new to living in a foreign country. Gullit's first season at Milan, however, saw the club win the \"Scudetto\" for the first time in nine years, under coach Arrigo Sacchi. Initially used on the right of an attacking trio alongside van Basten and Pietro Virdis, after van Basten received an injury it was changed to a front two. The following season Milan built on their domestic success by adding the European Cup to their list of honours. That performance was followed by a 4\u20130 victory over Steaua Bucure\u0219ti in the 1989 final, with Gullit scoring two crucial goals. According to Gullit: \u201cThe year that we won the Champions League, in the semi-final against Real Madrid I got injured. My meniscus was broken. I got a very quick operation so that I could play the final. The next season when I started to train again, not only my meniscus was damaged but also the cartilage, so for that reason, I couldn't play almost the whole season. It was hard because I was on the edge of maybe not playing football anymore.\".\nThe following year, Milan retained the trophy as they defeated Benfica in the 1990 final. However, serious injuries sustained to the ligaments of his right knee limited Gullit's playing time, only managed just two domestic games in the 1989\u201390 season before appearing in the cup final.\nIn 1990\u201391, Milan's pursuit of a third consecutive European Cup was cut short by Marseille at the quarter-final stage. Having drawn the first leg at the San Siro, Milan trailed to a Chris Waddle goal with little time remaining when the floodlights went out. After a short delay the lighting was restored, but Milan had returned to their dressing room and refused to return to complete the game. UEFA awarded Marseille a 3\u20130 victory and expelled Milan from all European competitions for the following season.\nWhile Milan continued their domestic dominance by winning the scudetto in both 1991\u201392 (a season in which they went undefeated) and 1992\u201393, Gullit's position became an increasingly peripheral one under new coach Fabio Capello. This was demonstrated by his omission from the 1993 Champions League final in which Milan lost to Marseille, as under the UEFA rules clubs were only allowed to field three foreigners, which was later abolished after the decision of the Bosman ruling. Gullit: \"After my injury, I was not the Ruud Gullit anymore what I was before. I had to adjust myself to a different way of playing football, because of the injury and because I was that much out of the game. I had to adapt my game, but I could deal with it. But of course, the role at Milan was less important than before, because at that moment the rotation system was introduced. So we were only allowed to have three foreigners. So sometimes you couldn't play. So that was also hard. When you are used to playing most of the games and all of a sudden you have to rest, so that was hard.\u201d.\nTorino was interested in signing him, with the chairman claiming that an agreement with Milan was likely. Bayern Munich was also in talks with Gullit, but fell through. Instead, Gullit was loaned to Sampdoria.\nSampdoria.\nIn 1993, Gullit moved to Sampdoria and led them to victory in the Coppa Italia in the 1993\u201394 season. He also scored the winner in a 3\u20132 victory over Milan, one of 15 goals he scored during the league campaign. He returned to Milan and scored in the season-opening 1994 Supercoppa Italiana against Sampdoria, but soon returned to the Genoese club before the midway point of the 1994\u201395 season, with Alessandro Melli being loaned in the opposite direction as part of the deal. During his time with Sampdoria, Gullit served under future England national team manager Sven-G\u00f6ran Eriksson and the two had a strong understanding and mutual respect.\nChelsea.\nIn July 1995, Gullit signed for Chelsea on a free transfer. Initially played as sweeper by manager Glenn Hoddle with limited success, Gullit was moved to his more familiar role in midfield, where he scored six goals. The signing of Gullit, alongside the likes of Mark Hughes and Dan Petrescu, propelled Chelsea to the semi-final of the FA Cup, although they only finished 11th in the FA Premier League.\nGullit had some difficulties adapting to the style of play at Chelsea: \"I would take a difficult ball, control it, make space and play a good ball in front of the right back, except that he didn't want that pass. Eventually Glenn said to me, 'Ruud, it would be better if you do these things in midfield.'\" His adjustment, however, was rapid and he ended the season by being named runner-up to Eric Cantona as Footballer of the Year.\nGullit has since often stated in interviews that it was in London he enjoyed his career the most and felt happiest: \"Every time I played for Chelsea, I thought, 'Nice game, beautiful stadium, great crowd, I'm playing well.' It was the only time I really had fun.\" In moving to Chelsea, Gullit played an important part in the \"foreign revolution\" as numerous high-profile international stars, such as Italian Gianfranco Zola and Dutchman Dennis Bergkamp, joined Chelsea and Arsenal respectively, which helped to increase the Premier League's worldwide profile.\nInternational career.\n1980s.\nIn 1981, on his 19th birthday, Gullit debuted for the Netherlands national team against Switzerland as a substitute, a game the Dutch lost 2\u20131.\nGullit was one of the key players for the Netherlands as he helped his country win UEFA Euro 1988 under coach Rinus Michels. Having lost their opening game of the tournament to the Soviet Union, the Netherlands beat England and the Republic of Ireland to reach the semi-finals, with Gullit setting up two of van Basten's three goals in the 3\u20131 win in the second group match against England. After defeating West Germany 2\u20131 in Hamburg, the Netherlands faced the Soviet Union again in the final. Gullit opened the scoring with a header and van Basten scored a volley from a narrow angle to cap a 2\u20130 victory. Gullit was thus the first Dutch captain to hold aloft international silverware.\n1990s.\nGullit's knee injuries also hampered his playing time at the 1990 FIFA World Cup, but his dribble and shot against the Republic of Ireland helped the Netherlands qualify for the second round. The Netherlands faced West Germany in a match marred by an altercation between Rijkaard and Rudi V\u00f6ller. The Germans gained revenge for their defeat at Euro 1988 by beating the Netherlands 2\u20131 and going on to win the tournament.\nAt UEFA Euro 1992, Gullit appeared in strong form against Scotland in their opening game of the tournament as he supplied Bergkamp with the only goal of the match. However, after a goalless draw with CIS and beating Germany 3\u20131, the Netherlands suffered a shock exit on penalties to Denmark in the semi-finals, after a 2\u20132 draw; during regulation time, Gullit assisted Rijkaard for a late equaliser. The Danish side ended up winning the championship's Henri Delaunay Trophy.\nIn 1993, Gullit and Netherlands manager Dick Advocaat began what was to be a long-running dispute which ultimately ended Gullit's international career. Advocaat's decision to play Gullit on the right side of midfield in a game against England at Wembley, rather than his usual central position, upset him and this was exacerbated by his substitution for Peter van Vossen. Gullit refused to play for the Netherlands following this but later changed his mind and agreed to return, facing Scotland in May 1994. Shortly before the 1994 World Cup, Gullit walked out of the pre-tournament training camp and would never play international football again.\nStyle of play.\nA complete and versatile player capable of aiding his team both defensively and offensively, Gullit epitomised the ethos of Total Football, possessing work rate, adeptness in ball-winning, tactical intelligence, skills and physical qualities. Normally utilised as an attacking midfielder or second striker, he was capable of playing anywhere in midfield or along the front line, on either wing or even in the centre, and could also play as a sweeper.\nGullit's foremost attribute was athleticism, being tall, powerful and an excellent jumper. Yet, unusually for a man of his stature, Gullit had outstanding natural balance, poise, technique, dribbling and free kick ability. He was also noted for his mental acuity, creativity, vision and spatial abilities, which helped him score many goals early on and enabled him to play in a deep-lying playmaker role late in his days, where he was known for creating chances for teammates. Beyond his footballing qualities, Gullit also stood out with his leadership and tenacity. Despite his talent, however, he struggled with injuries throughout his career, which later affected his fitness.\nGullit's brilliance prompted Garth Crooks to comment in his 1990 Team of the Week column, \"Ruud Gullit is a great player by any standards. He has all the skills. He's not afraid to do things with the ball. And he looks as if he's enjoying every second of it. By my reckoning that's what makes him an even better player than Maradona. Both have the key quality you will find in all the best players: balance. You just can't knock them off the ball. It was the same with Pel\u00e9, Beckenbauer and Cruyff.\"\nManagerial career.\nChelsea.\nIn the summer of 1996, when Hoddle left Chelsea to become manager of the England national team, Gullit was appointed as a player-manager becoming the first Dutch manager in the Premier League. Gullit made a promising start to his managerial career when in the first season as a player-manager he guided Chelsea to an FA Cup triumph in 1997, the club's first major trophy in 26 years. In doing so he became the first manager from outside the British Isles and the first black manager to win a major British football trophy. The club also finished at a creditable sixth place in the Premiership.\nThe following season, with Chelsea in second place in the Premiership and proceeding to the quarter-finals in two cup competitions, he was sacked, allegedly for a disagreement with the club's board over compensation, though Gullit himself disputed this. He was replaced by Gianluca Vialli, a man he had helped to bring to the club, and who went on to guide them to UEFA Cup Winners' Cup and Football League Cup glory over the remainder of the season. Gullit's last appearance as a player came in the first leg of that season's League Cup semi-final against Arsenal, but Gullit was sacked before the second leg. After Gullit's controversial sacking by Chelsea, chairman Ken Bates said of Gullit, \"I didn't like his arrogance \u2013 in fact I never liked him.\"\nNewcastle United.\nIn August 1998, Gullit was named manager of Newcastle United two games into the new league season and reached the 1999 FA Cup Final in his first year. Fans remained supportive despite a poor run of results, although well-publicised disagreements with the team's top scorer Alan Shearer and captain Rob Lee did not put him in a favourable light. Gullit refused to assign Lee a squad number, giving Lee's number 7 to new signing Kieron Dyer. In a match between Newcastle and local rivals Sunderland following the latter's return to the Premiership, Gullit left the usual starting strikers Shearer and Duncan Ferguson on the bench. Newcastle lost 2\u20131, and Gullit resigned three days later, five games into the 1999\u20132000 season.\nFeyenoord.\nBefore the start of the 2004\u201305 season, Gullit took charge of Feyenoord, quitting at the end of that season without winning any trophies, being replaced by Erwin Koeman. Feyenoord had finished a disappointing fourth in the Eredivisie, behind Ajax, PSV and AZ.\nLos Angeles Galaxy.\nOn 8 November 2007, Gullit became head coach for the LA Galaxy, signing a three-year contract. His US$2 million per year salary was the highest ever given to a Major League Soccer (MLS) head coach. Gullit arrived as replacement for Frank Yallop who was let go after Galaxy failed to make the 2007 MLS playoffs despite having record signing David Beckham on the roster.\nGullit's time with Galaxy was troublesome. Not well-versed in the intricacies and specifics of the MLS such as salary cap and draft rules, the Dutchman did not adapt well to the North American league. After losing 0\u20134 in the season opener, Gullit clashed with midfielder Peter Vagenas, who criticized him for neglecting set-play practice during training.\nAs the season progressed, Gullit clashed with several players, including Landon Donovan and Abel Xavier; the latter criticized Gullit's managerial style and said he did not have respect for most of the players. It was later reported that Gullit's appointment had been made in controversial fashion as Galaxy general manager, Alexi Lalas, had been bypassed in the process, with the decision being led by David Beckham's advisers: his management company 19 Entertainment and his personal manager Terry Byrne.\nOn 11 August 2008, Gullit resigned as coach of the Galaxy, citing personal reasons. This came following a seven-game winless streak. General manager Lalas was fired at the same time.\nTerek Grozny.\nOn 18 January 2011, Russian Premier League side Terek Grozny announced that Gullit has agreed to sign a year-and-a-half contract and become the head coach for the Chechen side. Upon signing, Gullit told \"Sovetsky Sport\", \"I'd like to believe that I can bring joy into the lives of the Chechen people through football... Of course, I won't deny that I'm getting lots of money from Terek.\" Gullit left the club on 14 June 2011.\nMedia career.\nIn 1988, together with the reggae band Revelation Time, Gullit gained a No. 3 chart hit with the anti-apartheid song \"South Africa\" in the Dutch Top 40. Previously, he had a modest hit in 1984 with the song \"Not the Dancing Kind\". Gullit also joined his band in front of 3,000 people at concerts in Italy, in the year he made a move to AC Milan.\nAfter his spell at Newcastle, Gullit spent several years working as a football commentator, having previously coined the term \"sexy football\" during his spell as a BBC pundit for Euro 1996 while still playing professionally for Chelsea. Gullit used the term to describe teams, such as Portugal at that tournament, who played attractive football with an emphasis on the defense-penetrating pass-and-move game.\nBy 2006, Gullit had a talk show on Dutch TV, where he has interviewed, amongst others, Nelson Mandela. When Gullit was named winner of the Ballon d'Or in 1987, he dedicated the award to the then imprisoned Nelson Mandela. Gullit has since said in interviews that he met Mandela after he was released, and that Mandela had said to him, \"Ruud, I have lots of friends now. When I was on the inside, you were one of the few.\"\nIn 2007, Gullit recalled, \"Four months ago I visited Robben Island and met three guys who were cell-mates of Nelson Mandela. They remembered me dedicating my award in 1987 to Mandela and they said they couldn't believe what I had done, and were sure the football authorities would withdraw the award. That's what apartheid did to them, it made them believe injustice was a normal part of life.\"\nGullit also appeared as a pundit for ITV during the 2006 World Cup and works as an analyst for Champions League games on Sky Sports and Al Jazeera Sports. During the 2010 FIFA World Cup, Gullit worked as a studio analyst alongside former players J\u00fcrgen Klinsmann and Steve McManaman for ESPN. He subsequently worked as an analyst for Al Jazeera Sports during Euro 2012 alongside Glenn Hoddle and Terry Venables, among others.\nIn 2013, Gullit and many other former footballers were brought into EA Sports's \"FIFA 14\" as \"Legends\" cards in FIFA Ultimate Team; his card is one of the highest rated in the game.\nIn 2014, Gullit joined BBC's \"Match of the Day\" as a studio pundit and first appeared during the 2014\u201315 season.\nGullit embarked on the Heineken Champions League Trophy Tour in 2016 where he visited Vietnam with Carles Puyol. For the 2022 World Cup, Gullit worked for BeIN Sports and has continued to do so for the UEFA Champions League coverage for the 2022\u201323 season.\nPersonal life.\nGullit is a Feyenoord supporter. Gullit was married to Yvonne de Vries from 1984 to 1991, with whom he had two daughters. From 1994 to 2000 he was married to Italian Christina Pensa, with whom he also had two children. From 2000 to 2012 he was married to Estelle Cruyff, a niece of Johan Cruyff. He also had two children with her. Their son Maxim Gullit played professional football and had a contract with SC Cambuur.\nCareer statistics.\nClub.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n\"Scores and results list the Netherlands' goal tally first, score column indicates score after each Gullit goal.\"\nManagerial statistics.\nAll competitive league games (league and domestic cup) and international matches (including friendlies) are included.\n \"As of 2 May 2015\"\nHonours.\nPlayer.\nHFC Haarlem\nFeyenoord\nPSV\nAC Milan\nSampdoria\nChelsea\nNetherlands\nManager.\nChelsea\nIndividual\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58685", "revid": "50886740", "url": "https://en.wikipedia.org/wiki?curid=58685", "title": "Hypothalamus", "text": "Area of the brain below the thalamus\nThe hypothalamus (pl.: hypothalami; from grc \" ' ()\"\u00a0'under' and \" ' ()\"\u00a0'chamber') is a small part of the vertebrate brain that contains a number of nuclei with a variety of functions. One of the most important functions is to link the nervous system to the endocrine system via the pituitary gland. The hypothalamus is located below the thalamus and is part of the limbic system. It forms the basal part of the diencephalon. All vertebrate brains contain a hypothalamus. In humans, it is about the size of an almond.\nThe hypothalamus has the function of regulating certain metabolic processes and other activities of the autonomic nervous system. It synthesizes and secretes certain neurohormones, called releasing hormones or hypothalamic hormones, and these in turn stimulate or inhibit the secretion of hormones from the pituitary gland. The hypothalamus controls body temperature, hunger, important aspects of parenting and maternal attachment behaviours, thirst, fatigue, sleep, circadian rhythms, and is important in certain social behaviors, such as sexual and aggressive behaviors.\nStructure.\nThe hypothalamus is divided into four regions (preoptic, supraoptic, tuberal, mammillary) in a parasagittal plane, indicating location anterior-posterior; and three zones (periventricular, intermediate, lateral) in the coronal plane, indicating location medial-lateral. Hypothalamic nuclei are located within these specific regions and zones. It is found in all vertebrate nervous systems. In mammals, magnocellular neurosecretory cells in the paraventricular nucleus and the supraoptic nucleus of the hypothalamus produce neurohypophysial hormones, oxytocin and vasopressin. These hormones are released into the blood in the posterior pituitary. Much smaller parvocellular neurosecretory cells, neurons of the paraventricular nucleus, release corticotropin-releasing hormone and other hormones into the hypophyseal portal system, where these hormones diffuse to the anterior pituitary.\nNuclei.\nThe hypothalamic nuclei include the following:\nConnections.\nThe hypothalamus is highly interconnected with other parts of the central nervous system, in particular the brainstem and its reticular formation. As part of the limbic system, it has connections to other limbic structures including the amygdala and septum, and is also connected with areas of the autonomous nervous system. \nThe hypothalamus receives many inputs from the brainstem, the most notable from the nucleus of the solitary tract, the locus coeruleus, and the ventrolateral medulla. \nMost nerve fibres within the hypothalamus run in two ways (bidirectional).\nSexual dimorphism.\nSeveral hypothalamic nuclei are sexually dimorphic; i.e., there are clear differences in both structure and function between males and females. Some differences are apparent even in gross neuroanatomy: most notable is the sexually dimorphic nucleus within the preoptic area, in which the differences are subtle changes in the connectivity and chemical sensitivity of particular sets of neurons. The importance of these changes can be recognized by functional differences between males and females. For instance, males of most species prefer the odor and appearance of females over males, which is instrumental in stimulating male sexual behavior. If the sexually dimorphic nucleus is lesioned, this preference for females by males diminishes. Also, the pattern of secretion of growth hormone is sexually dimorphic(for mice); this is why in many species, adult males are visibly distinct sizes from females.\nResponsiveness to ovarian steroids.\nDimorphism is also found in physiological and behavioral responses to ovarian steroids in adults, where males and females respond to these hormones differently. For example, estrogen receptor sensitivity for different sets of neurons is dimorphic already early on in development. Hypothalamic dimorphism underlies some known behavioral differences in mice, and has known physiological effects in humans, e.g. affecting thermoregulation and metabolism. Although human hypothalami exhibit various sex differences, it is not certain which behaviors are caused, predisposed, and not caused by these. In addition to confounding environmental factors, the hypothalamus also contributes to dimorphic human behaviors where the hypothalamus does not itself cause dimorphism, but rather exhibits conditional, dimorphic responses as part of greater pathways, such as the HPG-axis or the HPA-axis.\nEstrogen and progesterone can influence gene expression in particular neurons or induce changes in cell membrane potential and kinase activation, leading to diverse non-genomic cellular functions. Estrogen and progesterone bind to their cognate nuclear hormone receptors, which translocate to the cell nucleus and interact with regions of DNA known as hormone response elements (HREs) or get tethered to another transcription factor's binding site. Estrogen receptor (ER) has been shown to transactivate other transcription factors in this manner, despite the absence of an estrogen response element (ERE) in the proximal promoter region of the gene. In general, ERs and progesterone receptors (PRs) are gene activators, with increased mRNA and subsequent protein synthesis following hormone exposure.\nMale and female brains differ in the distribution of estrogen receptors; this is widely assumed to be caused by neonatal estradiol exposure, with some mechanisms being proven, however the complete underlying mechanism remains uncertain. Estrogen and progesterone receptors show differential expression where they are found in neurons of the anterior and mediobasal hypothalamus, notably:\nDevelopment.\nIn neonatal life, gonadal steroids are thought to influence the development of the hypothalamus. For instance, they correlate with the ability of females to exhibit a normal reproductive cycle, and of males and females to display appropriate reproductive behaviors in adult life:\nIn primates, the developmental influence of androgens is less clear, and the consequences are less understood. Within the brain, testosterone is aromatized (to estradiol), which is the principal active hormone for developmental influences. The human testis secretes high levels of testosterone from about week eight of fetal life until five to six months after birth (a similar perinatal surge in testosterone is observed in many species), a process that appears to underlie the male phenotype. Estrogen from the maternal circulation is relatively ineffective, partly because of the high circulating levels of steroid-binding proteins in pregnancy.\nSex steroids are not the only important influences upon hypothalamic development; in particular, pre-pubertal stress in early life (of rats) determines the capacity of the adult hypothalamus to respond to an acute stressor. Unlike gonadal steroid receptors, glucocorticoid receptors are very widespread throughout the brain; in the paraventricular nucleus, they mediate negative feedback control of CRF synthesis and secretion, but elsewhere their role is not well understood.\nFunction.\nHormone release.\nThe hypothalamus has a central neuroendocrine function, most notably by its control of the anterior pituitary, which in turn regulates various endocrine glands and organs. Releasing hormones (also called releasing factors) are produced in hypothalamic nuclei then transported along axons to either the median eminence or the posterior pituitary, where they are stored and released as needed.\nIn the hypothalamic\u2013adenohypophyseal axis, releasing hormones, also known as hypophysiotropic or hypothalamic hormones, are released from the median eminence, a prolongation of the hypothalamus, into the hypophyseal portal system, which carries them to the anterior pituitary where they exert their regulatory functions on the secretion of adenohypophyseal hormones. These hypophysiotropic hormones are stimulated by parvocellular neurosecretory cells located in the periventricular area of the hypothalamus. After their release into the capillaries of the third ventricle, the hypophysiotropic hormones travel through what is known as the hypothalamo-pituitary portal circulation. Once they reach their destination in the anterior pituitary, these hormones bind to specific receptors located on the surface of pituitary cells. Depending on which cells are activated through this binding, the pituitary will either begin secreting or stop secreting hormones into the rest of the bloodstream.\nOther hormones secreted from the median eminence include vasopressin, oxytocin, and neurotensin.\nIn the hypothalamic\u2013pituitary\u2013adrenal axis, neurohypophysial hormones are released from the posterior pituitary, which is actually a prolongation of the hypothalamus, into the circulation.\nIt is also known that hypothalamic\u2013pituitary\u2013adrenal axis (HPA) hormones are related to certain skin diseases and skin homeostasis. There is evidence linking hyperactivity of HPA hormones to stress-related skin diseases and skin tumors.\nStimulation.\nThe hypothalamus coordinates many hormonal and behavioural circadian rhythms, complex patterns of neuroendocrine outputs, complex homeostatic mechanisms, and important behaviours. The hypothalamus must, therefore, respond to many different signals, some of which are generated externally and some internally. Delta wave signalling arising either in the thalamus or in the cortex influences the secretion of releasing hormones; GHRH and prolactin are stimulated whilst TRH is inhibited. \nThe hypothalamus is responsive to:\nOlfactory stimuli.\nOlfactory stimuli are important for sexual reproduction and neuroendocrine function in many species. For instance, if a pregnant mouse is exposed to the urine of a 'strange' male during a critical period after coitus then the pregnancy fails (the Bruce effect). Thus, during coitus, a female mouse forms a precise 'olfactory memory' of her partner that persists for several days. Pheromonal cues aid synchronization of oestrus in many species; in women, synchronized menstruation may also arise from pheromonal cues, although the role of pheromones in humans is disputed. \nBlood-borne stimuli.\nPeptide hormones have important influences upon the hypothalamus, and to do so they must pass through the blood\u2013brain barrier. The hypothalamus is bounded in part by specialized brain regions that lack an effective blood\u2013brain barrier; the capillary endothelium at these sites is fenestrated to allow free passage of even large proteins and other molecules. Some of these sites are the sites of neurosecretion - the neurohypophysis and the median eminence. However, others are sites at which the brain samples the composition of the blood. Two of these sites, the SFO (subfornical organ) and the OVLT (organum vasculosum of the lamina terminalis) are so-called circumventricular organs, where neurons are in intimate contact with both blood and CSF. These structures are densely vascularized, and contain osmoreceptive and sodium-receptive neurons that control drinking, vasopressin release, sodium excretion, and sodium appetite. They also contain neurons with receptors for angiotensin, atrial natriuretic factor, endothelin and relaxin, each of which important in the regulation of fluid and electrolyte balance. Neurons in the OVLT and SFO project to the supraoptic nucleus and paraventricular nucleus, and also to preoptic hypothalamic areas. The circumventricular organs may also be the site of action of interleukins to elicit both fever and ACTH secretion, via effects on paraventricular neurons.\nIt is not clear how all peptides that influence hypothalamic activity gain the necessary access. In the case of prolactin and leptin, there is evidence of active uptake at the choroid plexus from the blood into the cerebrospinal fluid (CSF). Some pituitary hormones have a negative feedback influence upon hypothalamic secretion; for example, growth hormone feeds back on the hypothalamus, but how it enters the brain is not clear. There is also evidence for central actions of prolactin.\nFindings have suggested that thyroid hormone (T4) is taken up by the hypothalamic glial cells in the infundibular nucleus/ median eminence, and that it is here converted into T3 by the type 2 deiodinase (D2). Subsequent to this, T3 is transported into the thyrotropin-releasing hormone (TRH)-producing neurons in the paraventricular nucleus. Thyroid hormone receptors have been found in these neurons, indicating that they are indeed sensitive to T3 stimuli. In addition, these neurons expressed MCT8, a thyroid hormone transporter, supporting the theory that T3 is transported into them. T3 could then bind to the thyroid hormone receptor in these neurons and affect the production of thyrotropin-releasing hormone, thereby regulating thyroid hormone production.\nThe hypothalamus functions as a type of thermostat for the body. It sets a desired body temperature, and stimulates either heat production and retention to raise the blood temperature to a higher setting or sweating and vasodilation to cool the blood to a lower temperature. All fevers result from a raised setting in the hypothalamus; elevated body temperatures due to any other cause are classified as hyperthermia. Rarely, direct damage to the hypothalamus, such as from a stroke, will cause a fever; this is sometimes called a \"hypothalamic fever\". However, it is more common for such damage to cause abnormally low body temperatures.\nSteroids.\nThe hypothalamus contains neurons that react strongly to steroids and glucocorticoids (the steroid hormones of the adrenal gland, released in response to ACTH). It also contains specialized glucose-sensitive neurons (in the arcuate nucleus and ventromedial hypothalamus), which are important for appetite. The preoptic area contains thermosensitive neurons; these are important for TRH secretion. \nNeural.\nOxytocin secretion in response to suckling or vagino-cervical stimulation is mediated by some of these pathways; vasopressin secretion in response to cardiovascular stimuli arising from chemoreceptors in the carotid body and aortic arch, and from low-pressure atrial volume receptors, is mediated by others. In the rat, stimulation of the vagina also causes prolactin secretion, and this results in pseudo-pregnancy following an infertile mating. In the rabbit, coitus elicits reflex ovulation. In the sheep, cervical stimulation in the presence of high levels of estrogen can induce maternal behavior in a virgin ewe. These effects are all mediated by the hypothalamus, and the information is carried mainly by spinal pathways that relay in the brainstem. Stimulation of the nipples stimulates release of oxytocin and prolactin and suppresses the release of LH and FSH. \nCardiovascular stimuli are carried by the vagus nerve. The vagus also conveys a variety of visceral information, including for instance signals arising from gastric distension or emptying, to suppress or promote feeding, by signalling the release of leptin or gastrin, respectively. Again, this information reaches the hypothalamus via relays in the brainstem. \nIn addition, hypothalamic function is responsive to\u2014and regulated by\u2014levels of all three classical monoamine neurotransmitters, noradrenaline, dopamine, and serotonin (5-hydroxytryptamine), in those tracts from which it receives innervation. For example, noradrenergic inputs arising from the locus coeruleus have important regulatory effects upon corticotropin-releasing hormone (CRH) levels. \nControl of food intake.\nThe extreme lateral part of the ventromedial nucleus of the hypothalamus is responsible for the control of food intake. Stimulation of this area causes increased food intake. Bilateral lesion of this area causes complete cessation of food intake. Medial parts of the nucleus have a controlling effect on the lateral part. Bilateral lesion of the medial part of the ventromedial nucleus causes hyperphagia and obesity of the animal. Further lesion of the lateral part of the ventromedial nucleus in the same animal produces complete cessation of food intake.\nThere are different hypotheses related to this regulation:\nFear processing.\nThe medial zone of hypothalamus is part of a circuitry that controls motivated behaviors, like defensive behaviors. Analyses of Fos-labeling showed that a series of nuclei in the \"behavioral control column\" is important in regulating the expression of innate and conditioned defensive behaviors.\nExposure to a predator (such as a cat) elicits defensive behaviors in laboratory rodents, even when the animal has never been exposed to a cat. In the hypothalamus, this exposure causes an increase in Fos-labeled cells in the anterior hypothalamic nucleus, the dorsomedial part of the ventromedial nucleus, and in the ventrolateral part of the premammillary nucleus (PMDvl). The premammillary nucleus has an important role in expression of defensive behaviors towards a predator, since lesions in this nucleus abolish defensive behaviors, like freezing and flight. The PMD does not modulate defensive behavior in other situations, as lesions of this nucleus had minimal effects on post-shock freezing scores. The PMD has important connections to the dorsal periaqueductal gray, an important structure in fear expression. In addition, animals display risk assessment behaviors to the environment previously associated with the cat. Fos-labeled cell analysis showed that the PMDvl is the most activated structure in the hypothalamus, and inactivation with muscimol prior to exposure to the context abolishes the defensive behavior. Therefore, the hypothalamus, mainly the PMDvl, has an important role in expression of innate and conditioned defensive behaviors to a predator.\nLikewise, the hypothalamus has a role in social defeat: nuclei in medial zone are also mobilized during an encounter with an aggressive conspecific. The defeated animal has an increase in Fos levels in sexually dimorphic structures, such as the medial pre-optic nucleus, the ventrolateral part of ventromedial nucleus, and the ventral premammilary nucleus. Such structures are important in other social behaviors, such as sexual and aggressive behaviors. Moreover, the premammillary nucleus also is mobilized, the dorsomedial part but not the ventrolateral part. Lesions in this nucleus abolish passive defensive behavior, like freezing and the \"on-the-back\" posture.\nLearning arbitrator.\nRecent research has questioned whether the lateral hypothalamus's role is only restricted to initiating and stopping innate behaviors and argued it learns about food-related cues. Specifically, that it opposes learning about information what is neutral or distant to food. According this view, the lateral hypothalamus is \"a unique arbitrator of learning capable of shifting behavior toward or away from important events\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58686", "revid": "42964511", "url": "https://en.wikipedia.org/wiki?curid=58686", "title": "Cerebral cortex", "text": "Outer layer of the cerebrum of the mammalian brain\nThe cerebral cortex, also known as the cerebral mantle, is the outer layer of neural tissue of the cerebrum of the brain in humans and other mammals. It is the largest site of neural integration in the central nervous system, and plays a key role in attention, perception, awareness, thought, memory, language, and consciousness.\nThe six-layered neocortex makes up approximately 90% of the cortex, with the allocortex making up the remainder. The cortex is divided into left and right parts by the longitudinal fissure, which separates the two cerebral hemispheres that are joined beneath the cortex by the corpus callosum and other commissural fibers. In most mammals, apart from small mammals that have small brains, the cerebral cortex is folded, providing a greater surface area in the confined volume of the cranium. Apart from minimising brain and cranial volume, cortical folding is crucial for the brain circuitry and its functional organisation. In mammals with small brains, there is no folding and the cortex is smooth.\nA fold or ridge in the cortex is termed a gyrus (plural gyri) and a groove is termed a sulcus (plural sulci). These surface convolutions appear during fetal development and continue to mature after birth through the process of gyrification. In the human brain, the majority of the cerebral cortex is not visible from the outside, but buried in the sulci. The major sulci and gyri mark the divisions of the cerebrum into the lobes of the brain. The four major lobes are the frontal, parietal, occipital and temporal lobes. Other lobes are the limbic lobe, and the insular cortex often referred to as the \"insular lobe\".\nThere are between 14 and 16 billion neurons in the human cerebral cortex. These are organised into horizontal cortical layers, and radially into cortical columns and minicolumns. Cortical areas have specific functions such as movement in the motor cortex, and sight in the visual cortex. The motor cortex is primarily located in the precentral gyrus, and the visual cortex is located in the occipital lobe.\nStructure.\nThe cerebral cortex is the outer covering of the surfaces of the cerebral hemispheres and is folded into peaks called gyri, and grooves called sulci. In the human brain, it is between 2 and 3-4 mm. thick, and makes up 40% of the brain's mass. 90% of the cerebral cortex is the six-layered neocortex whilst the other 10% is made up of the three/four-layered allocortex. There are between 14 and 16 billion neurons in the cortex. These cortical neurons are organized radially in cortical columns, and minicolumns, in the horizontally organized layers of the cortex.\nThe neocortex is separable into different regions of cortex known in the plural as cortices, and include the motor cortex and visual cortex. About two thirds of the cortical surface is buried in the sulci and the insular cortex is completely hidden. The cortex is thickest over the top of a gyrus and thinnest at the bottom of a sulcus.\nFolds.\nThe cerebral cortex is folded in a way that allows a large surface area of neural tissue to fit within the confines of the neurocranium. When unfolded in the human, each hemispheric cortex has a total surface area of about . The folding is inward away from the surface of the brain, and is also present on the medial surface of each hemisphere within the longitudinal fissure. Most mammals have a cerebral cortex that is convoluted with the peaks known as gyri and the troughs or grooves known as sulci. Some small mammals including some small rodents have smooth cerebral surfaces without gyrification.\nLobes.\nThe larger sulci and gyri mark the divisions of the cortex of the cerebrum into the lobes of the brain. There are four main lobes: the frontal lobe, parietal lobe, temporal lobe, and occipital lobe. The insular cortex is often included as the insular lobe. The limbic lobe is a rim of cortex on the medial side of each hemisphere and is also often included. There are also three lobules of the brain described: the paracentral lobule, the superior parietal lobule, and the inferior parietal lobule.\nThickness.\nFor species of mammals, larger brains (in absolute terms, not just in relation to body size) tend to have thicker cortices. The smallest mammals, such as shrews, have a neocortical thickness of about 0.5\u00a0mm; the ones with the largest brains, such as humans and fin whales, have thicknesses of 2\u20134\u00a0mm. There is an approximately logarithmic relationship between brain weight and cortical thickness.\nMagnetic resonance imaging of the brain (MRI) makes it possible to get a measure for the thickness of the human cerebral cortex and relate it to other measures. The thickness of different cortical areas varies but in general, sensory cortex is thinner than motor cortex. One study has found some positive association between the cortical thickness and intelligence.\nAnother study has found that the somatosensory cortex is thicker in migraine patients, though it is not known if this is the result of migraine attacks, the cause of them or if both are the result of a shared cause.\nA later study using a larger patient population reports no change in the cortical thickness in patients with migraine.\nA genetic disorder of the cerebral cortex, whereby decreased folding in certain areas results in a microgyrus, where there are four layers instead of six, is in some instances seen to be related to dyslexia.\nLayers of neocortex.\nThe neocortex is formed of six layers, numbered I to VI, from the outermost layer I \u2013 near to the pia mater, to the innermost layer VI \u2013 near to the underlying white matter. Each cortical layer has a characteristic distribution of different neurons and their connections with other cortical and subcortical regions. There are direct connections between different cortical areas and indirect connections via the thalamus.\nOne of the clearest examples of cortical layering is the line of Gennari in the primary visual cortex. This is a band of whiter tissue that can be observed with the naked eye in the calcarine sulcus of the occipital lobe. The line of Gennari is composed of axons bringing visual information from the thalamus into layer IV of the visual cortex.\nStaining cross-sections of the cortex to reveal the position of neuronal cell bodies and the intracortical axon tracts allowed neuroanatomists in the early 20th century to produce a detailed description of the \"laminar structure of the cortex\" in different species. The work of Korbinian Brodmann (1909) established that the mammalian neocortex is consistently divided into six layers.\nLayer I.\nLayer I is the molecular layer, and contains few scattered neurons, including GABAergic rosehip neurons. Layer I consists largely of extensions of apical dendritic tufts of pyramidal neurons and horizontally oriented axons, as well as glial cells. During development, Cajal\u2013Retzius cells and subpial granular layer cells are present in this layer. Also, some spiny stellate cells can be found here. Inputs to the apical tufts are thought to be crucial for the \"feedback\" interactions in the cerebral cortex involved in associative learning and attention.\nWhile it was once thought that the input to layer I came from the cortex itself, it is now known that layer I across the cerebral cortex receives substantial input from \"matrix\" or M-type thalamus cells, as opposed to \"core\" or C-type that go to layer IV.\nIt is thought that layer I serves as a central hub for collecting and processing widespread information. It integrates ascending sensory inputs with top-down expectations, regulating how sensory perceptions align with anticipated outcomes. Further, layer I sorts, directs, and combines excitatory inputs, integrating them with neuromodulatory signals. Inhibitory interneurons, both within layer I and from other cortical layers, gate these signals. Together, these interactions dynamically calibrate information flow throughout the neocortex, shaping perceptions and experiences.\nLayer II.\nLayer II, the external granular layer, contains small pyramidal neurons and numerous stellate neurons.\nLayer III.\nLayer III, the external pyramidal layer, contains predominantly small and medium-size pyramidal neurons, as well as non-pyramidal neurons with vertically oriented intracortical axons; layers I through III are the main target of commissural corticocortical afferents, and layer III is the principal source of corticocortical efferents.\nLayer IV.\nLayer IV, the internal granular layer, contains different types of stellate and pyramidal cells, and is the main target of thalamocortical afferents from thalamus type C neurons (core-type) as well as intra-hemispheric corticocortical afferents. The layers above layer IV are also referred to as supragranular layers (layers I-III), whereas the layers below are referred to as infragranular layers (layers V and VI). African elephants, cetaceans, and hippopotamus do not have a layer IV with axons which would terminate there going instead to the inner part of layer III. \nLayer V.\nLayer V, the internal pyramidal layer, contains large pyramidal neurons. Axons from these leave the cortex and connect with subcortical structures including the basal ganglia. In the primary motor cortex of the frontal lobe, layer V contains giant pyramidal cells called Betz cells, whose axons travel through the internal capsule, the brain stem, and the spinal cord forming the corticospinal tract, which is the main pathway for voluntary motor control.\nLayer VI.\nLayer VI, the polymorphic layer or multiform layer, contains few large pyramidal neurons and many small spindle-like pyramidal and multiform neurons; layer VI sends efferent fibers to the thalamus, establishing a very precise reciprocal interconnection between the cortex and the thalamus. That is, layer VI neurons from one cortical column connect with thalamus neurons that provide input to the same cortical column. These connections are both excitatory and inhibitory. Neurons send excitatory fibers to neurons in the thalamus and also send collaterals to the thalamic reticular nucleus that inhibit these same thalamus neurons or ones adjacent to them. One theory is that because the inhibitory output is reduced by cholinergic input to the cerebral cortex, this provides the brainstem with adjustable \"gain control for the relay of lemniscal inputs\".\nColumns.\nThe cortical layers are not simply stacked one over the other; there exist characteristic connections between different layers and neuronal types, which span all the thickness of the cortex. These cortical microcircuits are grouped into cortical columns and minicolumns. It has been proposed that the minicolumns are the basic functional units of the cortex. In 1957, Vernon Mountcastle showed that the functional properties of the cortex change abruptly between laterally adjacent points; however, they are continuous in the direction perpendicular to the surface. Later works have provided evidence of the presence of functionally distinct cortical columns in the visual cortex (Hubel and Wiesel, 1959), auditory cortex,\nand associative cortex.\nCortical areas that lack a layer IV are called agranular. Cortical areas that have only a rudimentary layer IV are called dysgranular. Information processing within each layer is determined by different temporal dynamics with that in layers II/III having a slow 2\u00a0Hz oscillation while that in layer V has a fast 10\u201315\u00a0Hz oscillation.\nTypes of cortex.\nBased on the differences in laminar organization the cerebral cortex can be classified into two types, the large area of neocortex which has six cell layers, and the much smaller area of allocortex that has three or four layers:\nThere is a transitional area between the neocortex and the allocortex called the paralimbic cortex, where layers 2, 3 and 4 are merged. This area incorporates the proisocortex of the neocortex and the periallocortex of the allocortex. In addition, the cerebral cortex may be classified into four lobes: the frontal lobe, temporal lobe, the parietal lobe, and the occipital lobe, named from their overlying bones of the skull.\nBlood supply and drainage.\nBlood supply to the cerebral cortex is part of the cerebral circulation. Cerebral arteries supply the blood that perfuses the cerebrum. This arterial blood carries oxygen, glucose, and other nutrients to the cortex. Cerebral veins drain the deoxygenated blood, and metabolic wastes including carbon dioxide, back to the heart.\nThe main arteries supplying the cortex are the anterior cerebral artery, the middle cerebral artery, and the posterior cerebral artery. The anterior cerebral artery supplies the anterior portions of the brain, including most of the frontal lobe. The middle cerebral artery supplies the parietal lobes, temporal lobes, and parts of the occipital lobes. The middle cerebral artery splits into two branches to supply the left and right hemisphere, where they branch further. The posterior cerebral artery supplies the occipital lobes.\nThe circle of Willis is the main blood system that deals with blood supply in the cerebrum and cerebral cortex.\nDevelopment.\nThe prenatal development of the cerebral cortex is a complex and finely tuned process called corticogenesis, influenced by the interplay between genes and the environment.\nNeural tube.\nThe cerebral cortex develops from the most anterior part, the forebrain region, of the neural tube. The neural plate folds and closes to form the neural tube. From the cavity inside the neural tube develops the ventricular system, and, from the neuroepithelial cells of its walls, the neurons and glia of the nervous system. The most anterior (front, or cranial) part of the neural plate, the prosencephalon, which is evident before neurulation begins, gives rise to the cerebral hemispheres and later cortex.\nCortical neuron development.\nCortical neurons are generated within the ventricular zone, next to the ventricles. At first, this zone contains neural stem cells, that transition to radial glial cells\u2013progenitor cells, which divide to produce glial cells and neurons.\nRadial glia.\nThe cerebral cortex is composed of a heterogenous population of cells that give rise to different cell types. The majority of these cells are derived from radial glia migration that form the different cell types of the neocortex and it is a period associated with an increase in neurogenesis. Similarly, the process of neurogenesis regulates lamination to form the different layers of the cortex. During this process there is an increase in the restriction of cell fate that begins with earlier progenitors giving rise to any cell type in the cortex and later progenitors giving rise only to neurons of superficial layers. This differential cell fate creates an inside-out topography in the cortex with younger neurons in superficial layers and older neurons in deeper layers. In addition, laminar neurons are stopped in S or G2 phase in order to give a fine distinction between the different cortical layers. Laminar differentiation is not fully complete until after birth since during development laminar neurons are still sensitive to extrinsic signals and environmental cues.\nAlthough the majority of the cells that compose the cortex are derived locally from radial glia there is a subset population of neurons that migrate from other regions. Radial glia give rise to neurons that are pyramidal in shape and use glutamate as a neurotransmitter, however these migrating cells contribute neurons that are stellate-shaped and use GABA as their main neurotransmitter. These GABAergic neurons are generated by progenitor cells in the medial ganglionic eminence (MGE) that migrate tangentially to the cortex via the subventricular zone. This migration of GABAergic neurons is particularly important since GABA receptors are excitatory during development. This excitation is primarily driven by the flux of chloride ions through the GABA receptor, however in adults chloride concentrations shift causing an inward flux of chloride that hyperpolarizes postsynaptic neurons.\nThe glial fibers produced in the first divisions of the progenitor cells are radially oriented, spanning the thickness of the cortex from the ventricular zone to the outer, pial surface, and provide scaffolding for the migration of neurons outwards from the ventricular zone.\nAt birth there are very few dendrites present on the cortical neuron's cell body, and the axon is undeveloped. During the first year of life the dendrites become dramatically increased in number, such that they can accommodate up to a hundred thousand synaptic connections with other neurons. The axon can develop to extend a long way from the cell body.\nAsymmetric division.\nThe first divisions of the progenitor cells are symmetric, which duplicates the total number of progenitor cells at each mitotic cycle. Then, some progenitor cells begin to divide asymmetrically, producing one postmitotic cell that migrates along the radial glial fibers, leaving the ventricular zone, and one progenitor cell, which continues to divide until the end of development, when it differentiates into a glial cell or an ependymal cell. As the G1 phase of mitosis is elongated, in what is seen as selective cell-cycle lengthening, the newly born neurons migrate to more superficial layers of the cortex. The migrating daughter cells become the pyramidal cells of the cerebral cortex. The development process is time ordered and regulated by hundreds of genes and epigenetic regulatory mechanisms.\nLayer organization.\nThe layered structure of the mature cerebral cortex is formed during development. The first pyramidal neurons generated migrate out of the ventricular zone and subventricular zone, together with reelin-producing Cajal\u2013Retzius neurons, from the preplate. Next, a cohort of neurons migrating into the middle of the preplate divides this transient layer into the superficial marginal zone, which will become layer I of the mature neocortex, and the subplate, forming a middle layer called the cortical plate. These cells will form the deep layers of the mature cortex, layers five and six. Later born neurons migrate radially into the cortical plate past the deep layer neurons, and become the upper layers (two to four). Thus, the layers of the cortex are created in an inside-out order. The only exception to this inside-out sequence of neurogenesis occurs in the layer I of primates, in which, in contrast to rodents, neurogenesis continues throughout the entire period of corticogenesis.\nCortical patterning.\nThe map of functional cortical areas, which include primary motor and visual cortex, originates from a 'protomap', which is regulated by molecular signals such as fibroblast growth factor FGF8 early in embryonic development. These signals regulate the size, shape, and position of cortical areas on the surface of the cortical primordium, in part by regulating gradients of transcription factor expression, through a process called cortical patterning. Examples of such transcription factors include the genes EMX2 and PAX6. Together, both transcription factors form an opposing gradient of expression. Pax6 is highly expressed at the rostral lateral pole, while Emx2 is highly expressed in the caudomedial pole. The establishment of this gradient is important for proper development. For example, mutations in Pax6 can cause expression levels of Emx2 to expand out of its normal expression domain, which would ultimately lead to an expansion of the areas normally derived from the caudal medial cortex, such as the visual cortex. On the contrary, if mutations in Emx2 occur, it can cause the Pax6-expressing domain to expand and result in the frontal and motor cortical regions enlarging. Therefore, researchers believe that similar gradients and signaling centers next to the cortex could contribute to the regional expression of these transcription factors.\nTwo very well studied patterning signals for the cortex include FGF and retinoic acid. If FGFs are misexpressed in different areas of the developing cortex, cortical patterning is disrupted. Specifically, when Fgf8 is increased in the anterior pole, Emx2 is downregulated and a caudal shift in the cortical region occurs. This ultimately causes an expansion of the rostral regions. Therefore, Fgf8 and other FGFs play a role in the regulation of expression of Emx2 and Pax6 and represent how the cerebral cortex can become specialized for different functions.\nRapid expansion of the cortical surface area is regulated by the amount of self-renewal of radial glial cells and is partly regulated by FGF and Notch genes. During the period of cortical neurogenesis and layer formation, many higher mammals begin the process of gyrification, which generates the characteristic folds of the cerebral cortex. Gyrification is regulated by a DNA-associated protein Trnp1 and by FGF and SHH signaling.\nEvolution.\nOf all the different brain regions, the cerebral cortex shows the largest evolutionary variation and has evolved most recently. In contrast to the highly conserved circuitry of the medulla oblongata, for example, which serves critical functions such as regulation of heart and respiration rates, many areas of the cerebral cortex are not strictly necessary for survival. Thus, the evolution of the cerebral cortex has seen the advent and modification of new functional areas\u2014particularly association areas that do not directly receive input from outside the cortex.\nA key theory of cortical evolution is embodied in the radial unit hypothesis and related protomap hypothesis, first proposed by Rakic. This theory states that new cortical areas are formed by the addition of new radial units, which is accomplished at the stem cell level. The protomap hypothesis states that the cellular and molecular identity and characteristics of neurons in each cortical area are specified by cortical stem cells, known as radial glial cells, in a primordial map. This map is controlled by secreted signaling proteins and downstream transcription factors.\nFunction.\nConnections.\nThe cerebral cortex is connected to various subcortical structures such as the thalamus and the basal ganglia, sending information to them along efferent connections and receiving information from them via afferent connections. Most sensory information is routed to the cerebral cortex via the thalamus. Olfactory information, however, passes through the olfactory bulb to the olfactory cortex (piriform cortex). The majority of connections are from one area of the cortex to another, rather than from subcortical areas; Braitenberg and Sch\u00fcz (1998) claim that in primary sensory areas, at the cortical level where the input fibers terminate, up to 20% of the synapses are supplied by extracortical afferents but that in other areas and other layers the percentage is likely to be much lower.\nCortical areas.\nThe whole of the cerebral cortex was divided into 52 different areas in an early presentation by Korbinian Brodmann. These areas, known as Brodmann areas, are based on their cytoarchitecture but also relate to various functions. An example is Brodmann area 17, which is the primary visual cortex.\nIn more general terms the cortex is typically described as comprising three parts: sensory, motor, and association areas. Sensory and motor areas are defined as primary regions, while association areas work with primary regions but go beyond them.\nSensory areas.\nThe sensory areas are the cortical areas that receive and process information from the senses. Parts of the cortex that receive sensory inputs from the thalamus are called primary sensory areas. The senses of vision, hearing, and touch are served by the primary visual cortex, primary auditory cortex and primary somatosensory cortex respectively. In general, the two hemispheres receive information from the opposite (contralateral) side of the body. For example, the right primary somatosensory cortex receives information from the left limbs, and the right visual cortex receives information from the left visual field.\nThe organization of sensory maps in the cortex reflects that of the corresponding sensing organ, in what is known as a topographic map. Neighboring points in the primary visual cortex, for example, correspond to neighboring points in the retina. This topographic map is called a retinotopic map. In the same way, there exists a tonotopic map in the primary auditory cortex and a somatotopic map in the primary sensory cortex. This last topographic map of the body onto the posterior central gyrus has been illustrated as a deformed human representation, the somatosensory homunculus, where the size of different body parts reflects the relative density of their innervation. Areas with much sensory innervation, such as the fingertips and the lips, require more cortical area to process finer sensation.\nMotor areas.\nThe motor areas are located in both hemispheres of the cortex. The motor areas are very closely related to the control of voluntary movements, especially fine fragmented movements performed by the hand. The right half of the motor area controls the left side of the body, and vice versa.\nTwo areas of the cortex are commonly referred to as motor:\nIn addition, motor functions have been described for:\nJust underneath the cerebral cortex are interconnected subcortical masses of grey matter called basal ganglia (or nuclei). The basal ganglia receive input from the substantia nigra of the midbrain and motor areas of the cerebral cortex, and send signals back to both of these locations. They are involved in motor control. They are found lateral to the thalamus. The main components of the basal ganglia are the caudate nucleus, the putamen, the globus pallidus, the substantia nigra, the nucleus accumbens, and the subthalamic nucleus. The putamen and globus pallidus are also collectively known as the lentiform nucleus, because together they form a lens-shaped body. The putamen and caudate nucleus are also collectively called the corpus striatum after their striped appearance.\nAssociation areas.\nThe association areas are the parts of the cerebral cortex that do not belong to the primary regions. They function to produce a meaningful perceptual experience of the world, enable us to interact effectively, and support abstract thinking and language. The parietal, temporal, and occipital lobes \u2013 all located in the posterior part of the cortex \u2013 integrate sensory information and information stored in memory. The frontal lobe or prefrontal association complex is involved in planning actions and movement, as well as abstract thought. Globally, the association areas are organized as distributed networks. Each network connects areas distributed across widely spaced regions of the cortex. Distinct networks are positioned adjacent to one another yielding a complex series of interwoven networks. The specific organization of the association networks is debated with evidence for interactions, hierarchical relationships, and competition between networks.\nIn humans, association networks are particularly important to language function. In the past it was theorized that language abilities are localized in Broca's area in areas of the left inferior frontal gyrus, BA44 and BA45, for language expression and in Wernicke's area BA22, for language reception. However, the processes of language expression and reception have been shown to occur in areas other than just those structures around the lateral sulcus, including the frontal lobe, basal ganglia, cerebellum, and pons.\nClinical significance.\nNeurodegenerative diseases such as Alzheimer's disease, show as a marker, an atrophy of the grey matter of the cerebral cortex.Fractal dimension of the cerebral cortex of patients with Alzheimer's disease differs from the fractal dimension of the cerebral cortex of healthy individuals.\nOther diseases of the central nervous system include neurological disorders such as epilepsy, movement disorders, and different types of aphasia (difficulties in speech expression or comprehension).\nBrain damage from disease or trauma, can involve damage to a specific lobe such as in frontal lobe disorder, and associated functions will be affected. The blood\u2013brain barrier that serves to protect the brain from infection can become compromised allowing entry to pathogens.\nThe developing fetus is susceptible to a range of environmental factors that can cause birth defects and problems in later development. Maternal alcohol consumption for example can cause fetal alcohol spectrum disorder. Other factors that can cause neurodevelopment disorders are toxicants such as drugs, and exposure to radiation as from X-rays. Infections can also affect the development of the cortex. A viral infection is one of the causes of lissencephaly, which results in a smooth cortex without gyrification.\nA type of electrocorticography called cortical stimulation mapping is an invasive procedure that involves placing electrodes directly onto the exposed brain in order to localise the functions of specific areas of the cortex. It is used in clinical and therapeutic applications including pre-surgical mapping.\nGenes associated with cortical disorders.\nThere are a number of genetic mutations that can cause a wide range of genetic disorders of the cerebral cortex, including microcephaly, schizencephaly and types of lissencephaly. Chromosome abnormalities can also result causing a number of neurodevelopmental disorders such as fragile X syndrome and Rett syndrome.\nMCPH1 codes for microcephalin, and disorders in this and in ASPM are associated with microcephaly. Mutations in the gene NBS1 that codes for nibrin can cause Nijmegen breakage syndrome, characterised by microcephaly.\nMutations in EMX2, and COL4A1 are associated with schizencephaly, a condition marked by the absence of large parts of the cerebral hemispheres.\nHistory.\nIn 1909, Korbinian Brodmann distinguished 52 different regions of the cerebral cortex based on their cytoarchitecture. These are known as Brodmann areas.\nRafael Lorente de N\u00f3, a student of Santiago Ramon y Cajal, identified more than 40 different types of cortical neurons based on the distribution of their dendrites and axons.\nOther animals.\nThe cerebral cortex is derived from the pallium, a layered structure found in the forebrain of all vertebrates. The basic form of the pallium is a cylindrical layer enclosing fluid-filled ventricles. Around the circumference of the cylinder are four zones, the dorsal pallium, medial pallium, ventral pallium, and lateral pallium, which are thought to be homologous to the neocortex, hippocampus, amygdala, and olfactory cortex, respectively.\nIn avian brains, evidence suggests the avian pallium's neuroarchitecture to be reminiscent of the mammalian cerebral cortex. The avian pallium has also been suggested to be an equivalent neural basis for consciousness.\nUntil recently no counterpart to the cerebral cortex had been recognized in invertebrates. However, a study published in the journal \"Cell\" in 2010, based on gene expression profiles, reported strong affinities between the cerebral cortex and the mushroom bodies of the ragworm \"Platynereis dumerilii\". Mushroom bodies are structures in the brains of many types of worms and arthropods that are known to play important roles in learning and memory; the genetic evidence indicates a common evolutionary origin, and therefore indicates that the origins of the earliest precursors of the cerebral cortex date back to the Precambrian era.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58687", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=58687", "title": "Aggression", "text": "Social interaction aiming at inflicting harm or unpleasantness\nAggression is behavior aimed at opposing or attacking something or someone. Though often done with the intent to cause harm, some might channel it into creative and practical outlets. It may occur either reactively or without provocation. In humans, aggression can be caused by various triggers. For example, built-up frustration due to blocked goals or perceived disrespect. Human aggression can be classified into direct and indirect aggression; while the former is characterized by physical or verbal behavior intended to cause harm to someone, the latter is characterized by behavior intended to harm the social relations of an individual or group.\nIn definitions commonly used in the social sciences and behavioral sciences, aggression is an action or response by an individual that delivers something unpleasant to another person. Some definitions include that the individual must intend to harm another person.\nIn an interdisciplinary perspective, aggression is regarded as \"an ensemble of mechanism formed during the course of evolution in order to assert oneself, relatives, or friends against others, to gain or to defend resources (ultimate causes) by harmful damaging means. These mechanisms are often motivated by emotions like fear, frustration, anger, feelings of stress, dominance or pleasure (proximate causes). Sometimes aggressive behavior serves as a stress relief or a subjective feeling of power.\" Predatory or defensive behavior between members of different species may not be considered aggression in the same sense.\nAggression can take a variety of forms, which may be expressed physically, or communicated verbally or non-verbally, including: anti-predator aggression, defensive aggression (fear-induced), predatory aggression, dominance aggression, inter-male aggression, resident-intruder aggression, maternal aggression, species-specific aggression, sex-related aggression, territorial aggression, isolation-induced aggression, irritable aggression, and brain-stimulation-induced aggression (hypothalamus). There are two subtypes of human aggression: (1) controlled-instrumental subtype (purposeful or goal-oriented); and (2) reactive-impulsive subtype (often elicits uncontrollable actions that are inappropriate or undesirable). Aggression differs from what is commonly called assertiveness, although the terms are often used interchangeably among laypeople (as in phrases such as \"an aggressive salesperson\").\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nOverview.\nDollard et al. (1939) proposed that aggression was due to frustration, which was described as an unpleasant emotion resulting from any interference with achieving a rewarding goal. Berkowitz extended this frustration\u2013aggression hypothesis and proposed that it is not so much the frustration as the unpleasant emotion that evokes aggressive tendencies, and that all aversive events produce negative affect and thereby aggressive tendencies, as well as fear tendencies. Besides conditioned stimuli, Archer categorized aggression-evoking (as well as fear-evoking) stimuli into three groups; pain, novelty, and frustration, although he also described looming, which refers to an object rapidly moving towards the visual sensors of a subject, and can be categorized as \"intensity.\"\nAggression can have adaptive benefits or negative effects. Aggressive behavior is an individual or collective social interaction that is a hostile behavior with the intention of inflicting damage or harm. Two broad categories of aggression are commonly distinguished. One includes affective (emotional) and hostile, reactive, or retaliatory aggression that is a response to provocation, and the other includes instrumental, goal-oriented or predatory, in which aggression is used as a means to achieve a goal. An example of hostile aggression would be a person who punches someone that insulted him or her. An instrumental form of aggression would be armed robbery. Research on violence from a range of disciplines lend some support to a distinction between affective and predatory aggression. However, some researchers question the usefulness of a hostile versus instrumental distinction in humans, despite its ubiquity in research, because most real-life cases involve mixed motives and interacting causes.\nA number of classifications and dimensions of aggression have been suggested. These depend on such things as whether the aggression is verbal or physical; whether or not it involves relational aggression such as covert bullying and social manipulation; whether harm to others is intended or not; whether it is carried out actively or expressed passively; and whether the aggression is aimed directly or indirectly. Classification may also encompass aggression-related emotions (e.g., anger) and mental states (e.g., impulsivity, hostility). Aggression may occur in response to non-social as well as social factors, and can have a close relationship with stress coping style. Aggression may be displayed in order to intimidate.\nThe operative definition of aggression may be affected by moral or political views. Examples are the axiomatic moral view called the non-aggression principle and the political rules governing the behavior of one country toward another. Likewise in competitive sports, or in the workplace, some forms of aggression may be sanctioned and others not (see Workplace aggression). Aggressive behaviors are associated with adjustment problems and several psychopathological symptoms such as antisocial personality disorder, borderline personality disorder, and intermittent explosive disorder.\nBiological approaches conceptualize aggression as an internal energy released by external stimuli, a product of evolution through natural selection, part of genetics, and a product of hormonal fluctuations. Psychological approaches conceptualize aggression as a destructive instinct, a response to frustration, an affect excited by a negative stimulus, a result of observed learning of society and diversified reinforcement, and a result of variables that affect personal and situational environments.\nEtymology.\nThe term aggression comes from the Latin word \"aggressio\", meaning attack. The Latin was itself a joining of \"ad\"- and \"gradi\"-, which meant \"step at\". The first known use dates back to 1611, in the sense of an unprovoked attack.\nA psychological sense of \"hostile or destructive behavior\" dates back to a 1912 English translation of Sigmund Freud's writing. Alfred Adler theorized about an \"aggressive drive\" in 1908. Child raising experts began to refer to aggression, rather than anger, from the 1930s.\nEthology.\nEthologists study aggression as it relates to the interaction and evolution of animals in natural settings. In such settings aggression can involve bodily contact such as biting, hitting or pushing, but most conflicts are settled by threat displays and intimidating thrusts that cause no physical harm. This form of aggression may include the display of body size, antlers, claws or teeth; stereotyped signals including facial expressions; vocalizations such as bird song; the release of chemicals; and changes in coloration. The term agonistic behavior is sometimes used to refer to these forms of behavior.\nMost ethologists believe that aggression confers biological advantages. Aggression may help an animal secure territory, including resources such as food and water. Aggression between males often occurs to secure mating opportunities, and results in selection of the healthier/more vigorous animal. Aggression may also occur for self-protection or to protect offspring. Aggression between groups of animals may also confer advantage; for example, hostile behavior may force a population of animals into a new territory, where the need to adapt to a new environment may lead to an increase in genetic flexibility.\nBetween species and groups.\nThe most apparent type of interspecific aggression is that observed in the interaction between a predator and its prey. However, according to many researchers, predation is not aggression. A cat does not hiss or arch its back when pursuing a rat, and the active areas in its hypothalamus resemble those that reflect hunger rather than those that reflect aggression. However, others refer to this behavior as predatory aggression, and point out cases that resemble hostile behavior, such as mouse-killing by rats. In aggressive mimicry a predator has the appearance of a harmless organism or object attractive to the prey; when the prey approaches, the predator attacks.\nAn animal defending against a predator may engage in either \"fight or flight\" or \"tend and befriend\" in response to predator attack or threat of attack, depending on its estimate of the predator's strength relative to its own. Alternative defenses include a range of antipredator adaptations, including alarm signals. An example of an alarm signal is Nerol, a chemical which is found in the mandibular glands of \"Trigona fulviventris\" individuals. Release of Nerol by T. fulviventris individuals in the nest has been shown to decrease the number of individuals leaving the nest by fifty percent, as well as increasing aggressive behaviors like biting. Alarm signals like nerol can also act as attraction signals; in T. fulviventris, individuals that have been captured by a predator may release nerol to attract nest mates, who will proceed to attack or bite the predator.\nAggression between groups is determined partly by willingness to fight, which depends on a number of factors including numerical advantage, distance from home territories, how often the groups encounter each other, competitive abilities, differences in body size, and whose territory is being invaded. Also, an individual is more likely to become aggressive if other aggressive group members are nearby. One particular phenomenon \u2013 the formation of coordinated coalitions that raid neighboring territories to kill conspecifics \u2013 has only been documented in two species in the animal kingdom: 'common' chimpanzees and humans.\nWithin a group.\nAggression between conspecifics in a group typically involves access to resources and breeding opportunities. One of its most common functions is to establish a dominance hierarchy. This occurs in many species by aggressive encounters between contending males when they are first together in a common environment. Usually the more aggressive animals become the more dominant. In test situations, most of the conspecific aggression ceases about 24 hours after the group of animals is brought together. Aggression has been defined from this viewpoint as \"behavior which is intended to increase the social dominance of the organism relative to the dominance position of other organisms\". Losing confrontations may be called social defeat, and winning or losing is associated with a range of practical and psychological consequences.\nConflicts between animals occur in many contexts, such as between potential mating partners, between parents and offspring, between siblings and between competitors for resources. Group-living animals may dispute over the direction of travel or the allocation of time to joint activities. Various factors limit the escalation of aggression, including communicative displays, conventions, and routines. In addition, following aggressive incidents, various forms of conflict resolution have been observed in mammalian species, particularly in gregarious primates. These can mitigate or repair possible adverse consequences, especially for the recipient of aggression who may become vulnerable to attacks by other members of a group. Conciliatory acts vary by species and may involve specific gestures or simply more proximity and interaction between the individuals involved. However, conflicts over food are rarely followed by post conflict reunions, even though they are the most frequent type in foraging primates.\nOther questions that have been considered in the study of primate aggression, including in humans, is how aggression affects the organization of a group, what costs are incurred by aggression, and why some primates avoid aggressive behavior. For example, bonobo chimpanzee groups are known for low levels of aggression within a partially matriarchal society. Captive animals including primates may show abnormal levels of social aggression and self-harm that are related to aspects of the physical or social environment; this depends on the species and individual factors such as gender, age and background (e.g., raised wild or captive).\nAggression, fear and curiosity.\nWithin ethology, it has long been recognized that there is a relation between aggression, fear, and curiosity. A cognitive approach to this relationship puts aggression in the broader context of inconsistency reduction, and proposes that aggressive behavior is caused by an inconsistency between a desired, or expected, situation and the actually perceived situation (e.g., \"frustration\"), and functions to forcefully manipulate the perception into matching the expected situation. In this approach, when the inconsistency between perception and expectancy is small, learning as a result of curiosity reduces inconsistency by updating expectancy to match perception. If the inconsistency is larger, fear or aggressive behavior may be employed to alter the perception in order to make it match expectancy, depending on the size of the inconsistency as well as the specific context. Uninhibited fear results in fleeing, thereby removing the inconsistent stimulus from the perceptual field and resolving the inconsistency. In some cases, thwarted escape may trigger aggressive behavior in an attempt to remove the thwarting stimulus.\nEvolutionary explanations.\nLike many behaviors, aggression can be examined in terms of its ability to help an animal itself survive and reproduce, or alternatively to risk survival and reproduction. This cost\u2013benefit analysis can be looked at in terms of evolution. However, there are profound differences in the extent of acceptance of a biological or evolutionary basis for human aggression.\nViolence and conflict.\nAggression can involve violence that may be adaptive under certain circumstances in terms of natural selection. This is most obviously the case in terms of attacking prey to obtain food, or in anti-predatory defense. It may also be the case in competition between members of the same species or subgroup, if the average reward (e.g., status, access to resources, protection of self or kin) outweighs average costs (e.g., injury, exclusion from the group, death). There are some hypotheses of specific adaptions for violence in humans under certain circumstances, including for homicide, but it is often unclear what behaviors may have been selected for and what may have been a byproduct, as in the case of collective violence.\nAlthough aggressive encounters are ubiquitous in the animal kingdom, with often high stakes, most encounters that involve aggression may be resolved through posturing, or displaying and trial of strength. Game theory is used to understand how such behaviors might spread by natural selection within a population, and potentially become 'Evolutionary Stable Strategies'. An initial model of resolution of conflicts is the hawk-dove game. Others include the Sequential assessment model and the Energetic war of attrition. These try to understand not just one-off encounters but protracted stand-offs, and mainly differ in the criteria by which an individual decides to give up rather than risk loss and harm in physical conflict (such as through estimates of resource holding potential).\nGender.\nGeneral.\nGender plays an important role in human aggression. There are multiple theories that seek to explain findings that males and females of the same species can have differing aggressive behaviors. One review concluded that male aggression tended to produce pain or physical injury, whereas female aggression tended towards psychological or social harm.\nIn general, sexual dimorphism can be attributed to greater intraspecific competition in one sex, either between rivals for access to mates and/or to be chosen by mates. This may stem from the other gender being constrained by providing greater parental investment, in terms of factors such as gamete production, gestation, lactation, or upbringing of young. Although there is much variation in species, generally the more physically aggressive sex is the male, particularly in mammals. In species where parental care by both sexes is required, there tends to be less of a difference. When the female can leave the male to care for the offspring, then females may be the larger and more physically aggressive. Competitiveness despite parental investment has also been observed in some species. A related factor is the rate at which males and females are able to mate again after producing offspring, and the basic principles of sexual selection are also influenced by ecological factors affecting the ways or extent to which one sex can compete for the other. The role of such factors in human evolution is controversial.\nThe pattern of male and female aggression is argued to be consistent with evolved sexually selected behavioral differences, while alternative or complementary views emphasize conventional social roles stemming from physical evolved differences. Aggression in women may have evolved to be, on average, less physically dangerous and more covert or indirect. However, there are critiques of using animal behavior to explain human behavior, especially in the application of evolutionary explanations to contemporary human behavior, including differences between genders.\nAccording to the 2015 \"International Encyclopedia of the Social &amp; Behavioral Sciences\", sex differences in aggression is one of the most robust and oldest findings in psychology. Past meta-analyses in the encyclopedia found males regardless of age engaged in more physical and verbal aggression while small effect for females engaging in more indirect aggression such as rumor spreading or gossiping. It also found males tend to engage in more unprovoked aggression at higher frequency than females. This analysis also conforms with the \"Oxford Handbook of Evolutionary Psychology\" which reviewed past analysis which found men to use more verbal and physical aggression with the difference being greater in the physical type.\nThere are more recent findings that show that differences in male and female aggression appear at about two years of age, though the differences in aggression are more consistent in middle-aged children and adolescence. Tremblay, Japel and P\u00e9russe (1999) asserted that physically aggressive behaviors such as kicking, biting and hitting are age-typical expressions of innate and spontaneous reactions to biological drives such as anger, hunger, and affiliation. Girls' relational aggression, meaning non-physical or indirect, tends to increase after age two while physical aggression decreases. There was no significant difference in aggression between males and females before two years of age. A possible explanation for this could be that girls develop language skills more quickly than boys, and therefore have better ways of verbalizing their wants and needs. They are more likely to use communication when trying to retrieve a toy with the words \"Ask nicely\" or \"Say please.\"\nAccording to the journal of \"Aggressive Behaviour\", an analysis across 9 countries found boys reported more in the use of physical aggression. At the same time no consistent sex differences emerged within relational aggression. It has been found that girls are more likely than boys to use reactive aggression and then retract, but boys are more likely to increase rather than to retract their aggression after their first reaction. Studies show girls' aggressive tactics included gossip, ostracism, breaking confidences, and criticism of a victim's clothing, appearance, or personality, whereas boys engage in aggression that involves a direct physical and/or verbal assault. This could be due to the fact that girls' frontal lobes develop earlier than boys, allowing them to self-restrain.\nOne factor that shows insignificant differences between male and female aggression is in sports. In sports, the rate of aggression in both contact and non-contact sports is relatively equal. Since the establishment of Title IX, female sports have increased in competitiveness and importance, which could contribute to the evening of aggression and the \"need to win\" attitude between both genders. Among sex differences found in adult sports were that females have a higher scale of indirect hostility while men have a higher scale of assault. Another difference found is that men have up to 20 times higher levels of testosterone than women.\nIn intimate relationships.\nSome studies suggest that romantic involvement in adolescence decreases aggression in males and females, but decreases at a higher rate in females. Females will seem more desirable to their mate if they fit in with society and females that are aggressive do not usually fit well in society. They can often be viewed as antisocial. Female aggression is not considered the norm in society and going against the norm can sometimes prevent one from getting a mate. However, studies have shown that an increasing number of women are getting arrested on domestic violence charges. In many states, women now account for a quarter to a third of all domestic violence arrests, up from less than 10 percent a decade ago.\nThe new statistics reflect a reality documented in research: women are perpetrators as well as victims of family violence. However, another equally possible explanation is a case of improved diagnostics: it has become more acceptable for men to report female domestic violence to the authorities while at the same time actual female domestic violence has not increased at all. This could be the case in a situation where men had become less ashamed of reporting female violence against them\u2060such a situation could conceivably lead to an increasing number of women being arrested despite the actual number of violent women remaining the same.\nIn addition, males in competitive sports are often advised by their coaches not to be in intimate relationships based on the premise that they become more docile and less aggressive during an athletic event. The circumstances in which males and females experience aggression are also different. A study showed that social anxiety and stress were positively correlated with aggression in males, meaning that as stress and social anxiety increase, so does aggression. Furthermore, a male with higher social skills has a lower rate of aggressive behavior than a male with lower social skills. In females, higher rates of aggression were only correlated with higher rates of stress. Other than biological factors that contribute to aggression, there are physical factors as well.\nPhysiological factors.\nRegarding sexual dimorphism, humans fall into an intermediate group with moderate sex differences in body size but relatively large testes. This is a typical pattern of primates where several males and females live together in a group and the male faces an intermediate number of challenges from other males compared to exclusive polygyny and monogamy but frequent sperm competition.\nEvolutionary psychology and sociobiology have also discussed and produced theories for some specific forms of male aggression such as sociobiological theories of rape and theories regarding the Cinderella effect.\nPhysiology.\nBrain pathways.\nMany researchers focus on the brain to explain aggression. Numerous circuits within both neocortical and subcortical structures play a central role in controlling aggressive behavior, depending on the species, and the exact role of pathways may vary depending on the type of trigger or intention.\nIn mammals, the hypothalamus and periaqueductal gray of the midbrain are critical areas, as shown in studies on cats, rats, and monkeys. These brain areas control the expression of both behavioral and autonomic components of aggression in these species, including vocalization. Electrical stimulation of the hypothalamus causes aggressive behavior and the hypothalamus has receptors that help determine aggression levels based on their interactions with serotonin and vasopressin. In rodents, activation of estrogen receptor-expressing neurons in the ventrolateral portion of the ventromedial hypothalamus (VMHvl) was found to be sufficient to initiate aggression in both males and females. Midbrain areas involved in aggression have direct connections with both the brainstem nuclei controlling these functions, and with structures such as the amygdala and prefrontal cortex.\nStimulation of the amygdala results in augmented aggressive behavior in hamsters, while lesions of an evolutionarily homologous area in the lizard greatly reduce competitive drive and aggression (Bauman et al. 2006). In rhesus monkeys, neonatal lesions in the amygdala or hippocampus results in reduced expression of social dominance, related to the regulation of aggression and fear. Several experiments in attack-primed Syrian golden hamsters, for example, support the claim of circuitry within the amygdala being involved in control of aggression. The role of the amygdala is less clear in primates and appears to depend more on situational context, with lesions leading to increases in either social affiliatory or aggressive responses. Amygdalotomy, which involves removing or destroying parts of the amygdala, has been performed on people to reduce their violent behaviour.\nThe broad area of the cortex known as the prefrontal cortex (PFC) is crucial for self-control and inhibition of impulses, including inhibition of aggression and emotions. Reduced activity of the prefrontal cortex, in particular its medial and orbitofrontal portions, has been associated with violent/antisocial aggression. In addition, reduced response inhibition has been found in violent offenders, compared to non-violent offenders.\nThe role of the chemicals in the brain, particularly neurotransmitters, in aggression has also been examined. This varies depending on the pathway, the context and other factors such as gender. A deficit in serotonin has been theorized to have a primary role in causing impulsivity and aggression. At least one epigenetic study supports this supposition. Nevertheless, low levels of serotonin transmission may explain a vulnerability to impulsiveness, potential aggression, and may have an effect through interactions with other neurochemical systems. These include dopamine systems which are generally associated with attention and motivation toward rewards, and operate at various levels. Norepinephrine, also known as noradrenaline, may influence aggression responses both directly and indirectly through the hormonal system, the sympathetic nervous system or the central nervous system (including the brain). It appears to have different effects depending on the type of triggering stimulus, for example social isolation/rank versus shock/chemical agitation which appears not to have a linear relationship with aggression. Similarly, GABA, although associated with inhibitory functions at many CNS synapses, sometimes shows a positive correlation with aggression, including when potentiated by alcohol.\nThe hormonal neuropeptides vasopressin and oxytocin play a key role in complex social behaviours in many mammals such as regulating attachment, social recognition, and aggression. Vasopressin has been implicated in male-typical social behaviors which includes aggression. Oxytocin may have a particular role in regulating female bonds with offspring and mates, including the use of protective aggression. Initial studies in humans suggest some similar effects.\nIn human, aggressive behavior has been associated with abnormalities in three principal regulatory systems in the body serotonin systems, catecholamine systems, and the hypothalamic\u2013pituitary\u2013adrenal axis. Abnormalities in these systems also are known to be induced by stress, either severe, acute stress or chronic low-grade stress\nTestosterone.\nEarly androgenization has an organizational effect on the developing brains of both males and females, making more neural circuits that control sexual behavior as well as intermale and interfemale aggression become more sensitive to testosterone. There are noticeable sex differences in aggression. Testosterone is present to a lesser extent in females, who may be more sensitive to its effects. Animal studies have also indicated a link between incidents of aggression and the individual level of circulating testosterone. However, results in relation to primates, particularly humans, are less clear cut and are at best only suggestive of a positive association in some contexts.\nIn humans, there is a seasonal variation in aggression associated with changes in testosterone. For example, in some primate species, such as rhesus monkeys and baboons, females are more likely to engage in fights around the time of ovulation as well as right before menstruation. If the results were the same in humans as they are in rhesus monkeys and baboons, then the increase in aggressive behaviors during ovulation is explained by the decline in estrogen levels. This makes normal testosterone levels more effective. Castrated mice and rats exhibit lower levels of aggression. Males castrated as neonates exhibit low levels of aggression even when given testosterone throughout their development.\nChallenge hypothesis.\nThe challenge hypothesis outlines the dynamic relationship between plasma testosterone levels and aggression in mating contexts in many species. It proposes that testosterone is linked to aggression when it is beneficial for reproduction, such as in mate guarding and preventing the encroachment of intrasexual rivals. The challenge hypothesis predicts that seasonal patterns in testosterone levels in a species are a function of mating system (monogamy versus polygyny), paternal care, and male-male aggression in seasonal breeders.\nThis pattern between testosterone and aggression was first observed in seasonally breeding birds, such as the song sparrow, where testosterone levels rise modestly with the onset of the breeding season to support basic reproductive functions. The hypothesis has been subsequently expanded and modified to predict relationships between testosterone and aggression in other species. For example, chimpanzees, which are continuous breeders, show significantly raised testosterone levels and aggressive male-male interactions when receptive and fertile females are present. Currently, no research has specified a relationship between the modified challenge hypothesis and human behavior, or the human nature of concealed ovulation, although some suggest it may apply.\nEffects on the nervous system.\nAnother line of research has focused on the proximate effects of circulating testosterone on the nervous system, as mediated by local metabolism within the brain. Testosterone can be metabolized to estradiol by the enzyme aromatase, or to dihydrotestosterone (DHT) by 5\u03b1-reductase.\nAromatase is highly expressed in regions involved in the regulation of aggressive behavior, such as the amygdala and hypothalamus. In studies using genetic knockout techniques in inbred mice, male mice that lacked a functional aromatase enzyme displayed a marked reduction in aggression. Long-term treatment with estradiol partially restored aggressive behavior, suggesting that the neural conversion of circulating testosterone to estradiol and its effect on estrogen receptors influences inter-male aggression. In addition, two different estrogen receptors, ER\u03b1 and ER\u03b2, have been identified as having the ability to exert different effects on aggression in mice. However, the effect of estradiol appears to vary depending on the strain of mouse, and in some strains it reduces aggression during long days (16 h of light), while during short days (8 h of light) estradiol rapidly increases aggression.\nAnother hypothesis is that testosterone influences brain areas that control behavioral reactions. Studies in animal models indicate that aggression is affected by several interconnected cortical and subcortical structures within the so-called social behavior network. A study involving lesions and electrical-chemical stimulation in rodents and cats revealed that such a neural network consists of the medial amygdala, medial hypothalamus and periaqueductal grey (PAG), and it positively modulates reactive aggression. Moreover, a study done in human subjects showed that prefrontal-amygdala connectivity is modulated by endogenous testosterone during social emotional behavior.\nIn human studies, testosterone-aggression research has also focused on the role of the orbitofrontal cortex (OFC). This brain area is strongly associated with impulse control and self-regulation systems that integrate emotion, motivation, and cognition to guide context-appropriate behavior. Patients with localized lesions to the OFC engage in heightened reactive aggression. Aggressive behavior may be regulated by testosterone via reduced medial OFC engagement following social provocation. When measuring participants' salivary testosterone, higher levels can predict subsequent aggressive behavioral reactions to unfairness faced during a task. Moreover, brain scanning with fMRI shows reduced activity in the medial OFC during such reactions. Such findings may suggest that a specific brain region, the OFC, is a key factor in understanding reactive aggression.\nGeneral associations with behavior.\nScientists have for a long time been interested in the relationship between testosterone and aggressive behavior. In most species, males are more aggressive than females. Castration of males usually has a pacifying effect on aggressive behavior in males. In humans, males engage in crime and especially violent crime more than females. The involvement in crime usually rises in the early teens to mid teens which happen at the same time as testosterone levels rise. Research on the relationship between testosterone and aggression is difficult since the only reliable measurement of brain testosterone is by a lumbar puncture which is not done for research purposes. Studies therefore have often instead used more unreliable measurements from blood or saliva.\n\"The Handbook of Crime Correlates\", a review of crime studies, states most studies support a link between adult criminality and testosterone although the relationship is modest if examined separately for each sex. However, nearly all studies of juvenile delinquency and testosterone are not significant. Most studies have also found testosterone to be associated with behaviors or personality traits linked with criminality such as antisocial behavior and alcoholism. Many studies have also been done on the relationship between more general aggressive behavior/feelings and testosterone. About half the studies have found a relationship and about half no relationship.\nStudies of testosterone levels in male athletes before and after a competition revealed that testosterone levels rise shortly before their matches, as if in anticipation of the competition, and are dependent on the outcome of the event: testosterone levels of winners are high relative to those of losers. No specific response of testosterone levels to competition was observed in female athletes, although a mood difference was noted. In addition, some experiments have failed to find a relationship between testosterone levels and aggression in humans.\nThe possible correlation between testosterone and aggression could explain the \"roid rage\" that can result from anabolic steroid use, although an effect of abnormally high levels of steroids does not prove an effect at physiological levels.\nDehydroepiandrosterone.\nDehydroepiandrosterone (DHEA) is the most abundant circulating androgen hormone and can be rapidly metabolized within target tissues into potent androgens and estrogens. Gonadal steroids generally regulate aggression during the breeding season, but non-gonadal steroids may regulate aggression during the non-breeding season. Castration of various species in the non-breeding season has no effect on territorial aggression. In several avian studies, circulating DHEA has been found to be elevated in birds during the non-breeding season. These data support the idea that non-breeding birds combine adrenal and/or gonadal DHEA synthesis with neural DHEA metabolism to maintain territorial behavior when gonadal testosterone secretion is low. Similar results have been found in studies involving different strains of rats, mice, and hamsters. DHEA levels also have been studied in humans and may play a role in human aggression. Circulating DHEAS (its sulfated ester) levels rise during adrenarche (\u22487 years of age) while plasma testosterone levels are relatively low. This implies that aggression in pre-pubertal children with aggressive conduct disorder might be correlated with plasma DHEAS rather than plasma testosterone, suggesting an important link between DHEAS and human aggressive behavior.\nGlucocorticoids.\nGlucocorticoid hormones have an important role in regulating aggressive behavior. In adult rats, acute injections of corticosterone promote aggressive behavior, and acute reduction of corticosterone decreases aggression; however, chronic reduction of corticosterone levels can produce abnormally aggressive behavior. In addition, glucocorticoids affect the development of aggression and the establishment of social hierarchies. Adult mice with low baseline levels of corticosterone are more likely to become dominant than mice with high baseline corticosterone levels.\nGlucocorticoids are released by the hypothalamic pituitary adrenal (HPA) axis in response to stress, of which cortisol is the most prominent in humans. Results in adults suggest that reduced levels of cortisol, linked to lower fear or a reduced stress response, can be associated with more aggression. However, it may be that proactive aggression is associated with low cortisol levels while reactive aggression may be accompanied by elevated levels. Differences in assessments of cortisol may also explain a diversity of results, particularly in children.\nThe HPA axis is related to the general fight-or-flight response or acute stress reaction, and the role of catecholamines such as epinephrine, popularly known as adrenaline.\nPheromones.\nIn many animals, aggression can be linked to pheromones released between conspecifics. In mice, major urinary proteins (Mups) have been demonstrated to promote innate aggressive behavior in males, and can be mediated by neuromodulatory systems. Mups activate olfactory sensory neurons in the vomeronasal organ (VNO), a subsystem of the nose known to detect pheromones via specific sensory receptors, of mice and rats. Pheremones have also been identified in fruit flies, detected by neurons in the antenna, that send a message to the brain eliciting aggression; it has been noted that aggression pheremones have not been identified in humans.\nGenetics.\nIn general, differences in a continuous phenotype such as aggression are likely to result from the action of a large number of genes, each of small effect, which interact with each other and the environment through development and life.\nIn a non-mammalian example of genes related to aggression, the fruitless gene in fruit flies is a critical determinant of certain sexually dimorphic behaviors, and its artificial alteration can result in a reversal of stereotypically male and female patterns of aggression in fighting. However, in what was thought to be a relatively clear case, inherent complexities have been reported in deciphering the connections between interacting genes in an environmental context and a social phenotype involving multiple behavioral and sensory interactions with another organism.\nIn mice, candidate genes for differentiating aggression between the sexes are the Sry (sex determining region Y) gene, located on the Y chromosome and the Sts (steroid sulfatase) gene. The Sts gene encodes the steroid sulfatase enzyme, which is pivotal in the regulation of neurosteroid biosynthesis. It is expressed in both sexes, is correlated with levels of aggression among male mice, and increases dramatically in females after parturition and during lactation, corresponding to the onset of maternal aggression. At least one study has found a possible epigenetic signature (i.e., decreased methylation at a specific CpG site on the promoter region) of the serotonin receptor 5-HT3a that is associated with maternal aggression among human subjects.\nMice with experimentally elevated sensitivity to oxidative stress (through inhibition of copper-zinc superoxide dismutase, SOD1 activity) were tested for aggressive behavior. Males completely deficient in SOD1 were found to be more aggressive than both wild-type males and males that express 50% of this antioxidant enzyme. They were also faster to attack another male. The causal connection between SOD1 deficiency and increased aggression is not yet understood.\nIn humans, there is good evidence that the basic human neural architecture underpinning the potential for flexible aggressive responses is influenced by genes as well as environment. In terms of variation between individual people, more than 100 twin and adoption studies have been conducted in recent decades examining the genetic basis of aggressive behavior and related constructs such as conduct disorders. According to a meta-analysis published in 2002, approximately 40% of variation between individuals is explained by differences in genes, and 60% by differences in environment (mainly non-shared environmental influences rather than those that would be shared by being raised together). However, such studies have depended on self-report or observation by others including parents, which complicates interpretation of the results.\nThe few laboratory-based analyses have not found significant amounts of individual variation in aggression explicable by genetic variation in the human population. Furthermore, linkage and association studies that seek to identify specific genes, for example that influence neurotransmitter or hormone levels, have generally resulted in contradictory findings characterized by failed attempts at replication. One possible factor is an allele (variant) of the MAO-A gene which, in interaction with certain life events such as childhood maltreatment (which may show a main effect on its own), can influence development of brain regions such as the amygdala and as a result some types of behavioral response may be more likely. The generally unclear picture has been compared to equally difficult findings obtained in regard to other complex behavioral phenotypes. For example, both 7R and 5R, ADHD-linked VNTR alleles of dopamine receptor D4 gene are directly associated with the incidence of proactive aggression in the men with no history of ADHD.\nSociety and culture.\nHumans share aspects of aggression with non-human animals, and have specific aspects and complexity related to factors such as genetics, early development, social learning and flexibility, culture and morals.\nKonrad Lorenz stated in his 1963 classic, \"On Aggression,\" that human behavior is shaped by four main, survival-seeking animal drives. Taken together, these drives\u2014hunger, fear, reproduction, and aggression\u2014achieve natural selection. E. O. Wilson elaborated in \"On Human Nature\" that aggression is, typically, a means of gaining control over resources. Aggression is, thus, aggravated during times when high population densities generate resource shortages. According to Richard Leakey and his colleagues, aggression in humans has also increased by becoming more interested in ownership and by defending his or her property. However, UNESCO adopted the Seville Statement of Violence in 1989 that refuted claims, by evolutionary scientists, that genetics by itself was the sole cause of aggression.\nSocial and cultural aspects may significantly interfere with the distinct expression of aggressiveness. For example, a high population density, when associated with a decrease of available resources, might be a significant intervening variable for the occurrence of violent acts.\nCulture.\nCulture is one of the factors that influence aggression. Tribal or band societies existing before or outside of modern states have sometimes been depicted as peaceful \"noble savages\". The \u01c3Kung people, for instance, were described as \"The Harmless People\" in a popular work by Elizabeth Marshall Thomas in 1958. However, Lawrence Keeley's 1996 War Before Civilization suggested that regular warfare without modern technology was conducted by most groups throughout human history, including most Native American tribes. \nResearch on hunter-gatherers has revealed a range of behavioral patterns. While aggression, conflict and violence can occur, direct confrontation is generally avoided, and disputes are often managed through various verbal and non-verbal social mechanisms. Different rates of aggression or violence\u2014whether contemporary or historical\u2014have been associated with social structures and environmental factors such as resource distribution or property acquisition, land use, subsistence strategies, and population dynamics.\nAmerican psychologist Peter Gray hypothesizes that band hunter-gatherer societies are able maintain relatively egalitarian and peaceful relationships through mechanisms such as fostering a pervasive playful spirit, the use of humor to deter dominance, and non-coercive, indulgent child-rearing practices. Gray likens hunter-gatherer bands to social play groups, while stressing that such play is not frivolous or even easy at all times. According to Gray, \"Social play\u2014that is, play involving more than one player\u2014is necessarily egalitarian. It always requires a suspension of aggression and dominance along with a heightened sensitivity to the needs and desires of the other players\".\nJoan Durrant of the University of Manitoba reports that multiple studies have found an association between physical punishment and higher levels of aggression directed toward parents, siblings, peers, and spouses, even when controlling for other influencing factors.\nSimilarly, Elizabeth Gershoff of the University of Texas at Austin has found that the more frequently children experience physical punishment, the more likely they are, as adults, to engage in violent behavior toward family members, including intimate partners.\nIn countries where the physical punishment of children is more culturally accepted, its association with increased aggression tends to be weaker. However, research indicates that physical punishment predicts some increase in child aggression regardless of cultural context.\nAlthough these associations do not establish causality, a number of longitudinal studies suggest that experiencing physical punishment can have a direct causal impact on later aggressive behavior. In a review of several such studies examining the relationship between disciplinary spanking and aggression in children from preschool through adolescence, Elizabeth Gershoff concluded: \"Spanking consistently predicted increases in children's aggression over time, regardless of how aggressive children were when the spanking occurred\".\nSimilar findings were reported in a 2010 study led by Catherine Taylor at Tulane University, which identified a link between maternal spanking of three-year-old children and an increased risk of later aggressive behavior.\nFamily violence researcher Murray A. Straus contends that such evidence has often been overlooked, largely due to a prevailing belief that spanking is more effective than nonviolent forms of discipline. He warns, however, that this belief persists despite evidence of harmful side effects.\nCultural and political interpretations of aggression are further complicated by the subjective use of the term \"aggressive\", which may reflect value judgments depending on the observer's cultural or ideological standpoint. Whether a coercive or violent act is viewed as aggression\u2014or as legitimate or illegitimate aggression\u2014often depends on the social positions of those involved relative to their culture's structure. Relevant factors may include: norms governing coordination and resource distribution; definitions of self-defense and provocation; attitudes toward outsiders and marginalized groups such as women, disabled individuals, or people of lower status; the presence of alternative conflict resolution mechanisms; levels of trade interdependence and participation in collective security pacts; and broader material or social objectives.\nCross-cultural research has found differences in attitudes towards aggression in different cultures. In one questionnaire study of university students, in addition to men overall justifying some types of aggression more than women, United States respondents justified defensive physical aggression more readily than Japanese or Spanish respondents, whereas Japanese students preferred direct verbal aggression (but not indirect) more than their American and Spanish counterparts.\nWithin American culture, men from the southern United States were found in a study of university students to react more strongly and respond more aggressively than their northern counterparts when randomly insulted after being bumped into. This behavior was theorized to reflect a traditional culture of honor prevalent in the Southern United States, associated with concepts such as \"saving face.\"\nOther cultural frameworks frequently considered in aggression research include contrasts between individualistic and collectivist orientations. These may influence how individuals respond to disputes\u2014for example, through open competition or by accommodating others and avoiding conflict. \nIn a study including 62 countries, school principals reported higher levels of aggressive student behavior in cultures characterized as more individualistic and, correspondingly, less collectivist.\nOther cross-cultural comparisons related to aggression and conflict have examined differences between democratic and authoritarian political systems, as well as between egalitarian and stratified societies.\nThe economic system known as capitalism has been interpreted by some scholars as relying on human competitiveness and aggression to drive the pursuit of resources and trade. This perspective has been viewed both positively, as a motivator for innovation and efficiency, and negatively, as a source of inequality and conflict.\nFinally, the perceived legitimacy of aggressive acts are influenced by cultural and political attitudes regarding the social acceptability of certain actions or targets. These perceptions are often contested, particularly in cases involving religion or international disputes. One prominent example is the Arab\u2013Israeli conflict, where acts labeled as aggression by one group may be framed as defense or resistance by another.\nMedia.\nSome researchers argue that behaviors such as aggression may be partially learned through observation and imitation of others, a concept rooted in social learning theory. This perspective includes the view that exposure to media violence may exert small effects on aggressive behavior. However, this remains a subject of ongoing debate, and other scholars have challenged the strength or consistency of such effects.\nFor example, a prospective study of adolescents found no long-term relationship between violent video game use and subsequent youth violence or bullying. A meta-analysis concluded that the effect of violent video games on aggression is generally smaller than that found in studies on television violence. The magnitude of this effect was positively associated with the intensity of violent content and negatively associated with the amount of time spent playing. The study concluded that the available evidence was insufficient to establish a causal relationship between violent video games and increased aggression.\nConversely, other research has reported associations between violent video game exposure and heightened aggressive thoughts, feelings, and behaviors both in laboratory settings and real-life contexts.\nChildren.\nThe frequency of physical aggression in humans peaks at around 2\u20133 years of age. It then declines gradually on average. These observations suggest that physical aggression is not only a learned behavior but that development provides opportunities for the learning and biological development of self-regulation. However, a small subset of children fail to acquire all the necessary self-regulatory abilities and tend to show atypical levels of physical aggression across development. They may be at risk for later violent behavior or, conversely, a lack of aggression that may be considered necessary within society.\nHowever, some findings suggest that early aggression does not necessarily lead to aggression later on, although the course through early childhood is an important predictor of outcomes in middle childhood. In addition, physical aggression that continues is likely occurring in the context of family adversity, including socioeconomic factors. Moreover, 'opposition' and 'status violations' in childhood appear to be more strongly linked to social problems in adulthood than simply aggressive antisocial behavior. Social learning through interactions in early childhood has been seen as a building block for levels of aggression which play a crucial role in the development of peer relationships in middle childhood. Overall, an interplay of biological, social and environmental factors can be considered. Some research indicates that changes in the weather can increase the likelihood of children exhibiting deviant behavior.\nAggression triggers.\nThe Bobo doll experiment was conducted by Albert Bandura in 1961. In this work, Bandura found that children exposed to an aggressive adult model acted more aggressively than those who were exposed to a nonaggressive adult model. This experiment suggests that anyone who comes in contact with and interacts with children can affect the way they react and handle situations.\nGender.\nGender is a factor that plays a role in both human and animal aggression. Males are historically believed to be generally more physically aggressive than females from an early age, and men commit the vast majority of murders (Buss 2005). This is one of the most robust and reliable behavioral sex differences, and it has been found across many different age groups and cultures. However, some empirical studies have found the discrepancy in male and female aggression to be more pronounced in childhood and the gender difference in adults to be modest when studied in an experimental context. Still, there is evidence that males are quicker to aggression (Frey et al. 2003) and more likely than females to express their aggression physically. When considering indirect forms of non-violent aggression, such as relational aggression and social rejection, some scientists argue that females can be quite aggressive, although female aggression is rarely expressed physically. An exception is intimate partner violence that occurs among couples who are engaged, married, or in some other form of intimate relationship.\nAlthough females are less likely than males to initiate physical violence, they can express aggression by using a variety of non-physical means. Exactly which method women use to express aggression is something that varies from culture to culture. On Bellona Island, a culture based on male dominance and physical violence, women tend to get into conflicts with other women more frequently than with men. When in conflict with males, instead of using physical means, they make up songs mocking the man, which spread across the island and humiliate him. If a woman wanted to kill a man, she would either convince her male relatives to kill him or hire an assassin. Although these two methods involve physical violence, both are forms of indirect aggression, since the aggressor herself avoids getting directly involved or putting herself in immediate physical danger.\nSee also the sections on testosterone and evolutionary explanations for gender differences above.\nSituational factors.\nThere has been some links between those prone to violence and their alcohol use. Those who are prone to violence and use alcohol are more likely to carry out violent acts. Alcohol impairs judgment, making people much less cautious than they usually are (MacDonald et al. 1996). It also disrupts the way information is processed (Bushman 1993, 1997; Bushman &amp; Cooper 1990).\nRecent research further demonstrates that in everyday situations, violations of social norms can be perceived as provocations that trigger aggression, which can have negative consequences for individuals and social coexistence. Based on the General Aggression Model (GAM), experimental evidence shows that physical provocation affects the internal state (cognition, arousal, and affect) of the provoked person and shapes their responses. The social status of the provocateur can play a moderating role in this process: a higher-status provocateur induces a more aggression-prone internal state, but the likelihood of verbal retaliation is less affected by internal state when provocation comes from high status. These dynamics, illustrate how intentional provocation reduces the probability of ignoring the incident and increases the likelihood of verbal or physical aggression, mediated by changes in the internal state. Overall, this mechanism highlights the importance of situational and social factors\u2014such as status\u2014in everyday aggression and its regulation. This also adds to the currently inconclusive evidence about the role of the social status on aggression and highlights to importance of further inquiry.\nPain and discomfort also increase aggression. Even the simple act of placing one's hands in hot water can cause an aggressive response. Hot temperatures have been implicated as a factor in a number of studies. One study completed in the midst of the civil rights movement found that riots were more likely on hotter days than cooler ones (Carlsmith &amp; Anderson 1979). Students were found to be more aggressive and irritable after taking a test in a hot classroom (Anderson et al. 1996, Rule, et al. 1987). Drivers in cars without air conditioning were also found to be more likely to honk their horns (Kenrick &amp; MacFarlane 1986), which is used as a measure of aggression and has shown links to other factors such as generic symbols of aggression or the visibility of other drivers.\nFrustration is another major cause of aggression. The Frustration aggression theory states that aggression increases if a person feels that he or she is being blocked from achieving a goal (Aronson et al. 2005). One study found that the closeness to the goal makes a difference. The study examined people waiting in line and concluded that the 2nd person was more aggressive than the 12th one when someone cut in line (Harris 1974). Unexpected frustration may be another factor. In a separate study to demonstrate how unexpected frustration leads to increased aggression, Kulik &amp; Brown (1979) selected a group of students as volunteers to make calls for charity donations. One group was told that the people they would call would be generous and the collection would be very successful. The other group was given no expectations. The group that expected success was more upset when no one was pledging than the group who did not expect success (everyone actually had horrible success). This research suggests that when an expectation does not materialize (successful collections), unexpected frustration arises which increases aggression.\nThere is some evidence to suggest that the presence of violent objects such as a gun can trigger aggression. In a study done by Leonard Berkowitz and Anthony Le Page (1967), college students were made angry and then left in the presence of a gun or badminton racket. They were then led to believe they were delivering electric shocks to another student, as in the Milgram experiment. Those who had been in the presence of the gun administered more shocks. It is possible that a violence-related stimulus increases the likelihood of aggressive cognitions by activating the semantic network.\nA new proposal links military experience to anger and aggression, developing aggressive reactions and investigating these effects on those possessing the traits of a serial killer. Castle and Hensley state, \"The military provides the social context where servicemen learn aggression, violence, and murder.\" Post-traumatic stress disorder (PTSD) is also a serious issue in the military, also believed to sometimes lead to aggression in soldiers who are suffering from what they witnessed in battle. They come back to the civilian world and may still be haunted by flashbacks and nightmares, causing severe stress. In addition, it has been claimed that in the rare minority who are claimed to be inclined toward serial killing, violent impulses may be reinforced and refined in war, possibly creating more effective murderers.\nAs a positive adaptation theory.\nSome recent scholarship has questioned traditional psychological conceptualizations of aggression as universally negative. Most traditional psychological definitions of aggression focus on the harm to the recipient of the aggression, implying this is the intent of the aggressor; however this may not always be the case. From this alternate view, although the recipient may or may not be harmed, the perceived intent is to increase the status of the aggressor, not necessarily to harm the recipient. Such scholars contend that traditional definitions of aggression have no validity because of how challenging it is to study directly.\nFrom this view, rather than concepts such as assertiveness, aggression, violence and criminal violence existing as distinct constructs, they exist instead along a continuum with moderate levels of aggression being most adaptive. Such scholars do not consider this a trivial difference, noting that many traditional researchers' aggression measurements may measure outcomes lower down in the continuum, at levels which are adaptive, yet they generalize their findings to non-adaptive levels of aggression, thus losing precision.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58688", "revid": "1994682", "url": "https://en.wikipedia.org/wiki?curid=58688", "title": "Farmer", "text": "Person engaged in agriculture, raising living organisms for food or raw materials\nA farmer is a person engaged in agriculture, raising living organisms for food or raw materials. The term usually applies to people who do some combination of raising field crops, orchards, vineyards, poultry, or other livestock. A farmer might own the farmland or might work as a laborer on land owned by others. In most developed economies, a \"farmer\" is usually a farm owner (landowner), while employees of the farm are known as \"farm workers\" (or farmhands). However, in other older definitions a farmer was a person who promotes or improves the growth of plants, land, or crops or raises animals (as livestock or fish) by labor and attention.\nOver half a billion farmers are smallholders, most of whom are in developing countries and who economically support almost two billion people. Globally, women constitute more than 40% of agricultural employees.\nHistory.\nFarming dates back as far as the Neolithic, being one of the defining characteristics of that era. By the Bronze Age, the Sumerians had an agriculture specialized labor force by 5000\u20134000 BCE, and heavily depended on irrigation to grow crops. They relied on three-person teams when harvesting in the spring. The Ancient Egypt farmers farmed and relied and irrigated their water from the Nile.\nAnimal husbandry, the practice of rearing animals specifically for farming purposes, has existed for thousands of years. Dogs were domesticated in East Asia about 15,000 years ago. Goats and sheep were domesticated around 8000 BCE in Asia. Swine or pigs were domesticated by 7000 BCE in the Middle East and China. The earliest evidence of horse domestication dates to around 4000 BCE.\nAdvancements in technology.\nIn the US of the 1930s, one farmer could produce only enough food to feed three other consumers. A modern farmer produces enough food to feed well over a hundred people. However, some authors consider this estimate to be flawed, as it does not take into account that farming requires energy and many other resources which have to be provided by additional workers, so that the ratio of people fed to farmers is actually smaller than 100 to 1.\nTypes.\nMore distinct terms are commonly used to denote farmers who raise specific domesticated animals. For example, those who raise grazing livestock, such as cattle, sheep, goats and horses, are known as \"ranchers\" (U.S.), \"graziers\" (Australia &amp; UK) or simply \"stockmen\". Sheep, goat and cattle farmers might also be referred to, respectively, as \"shepherds\", \"goatherds\" and \"cowherds\". The term \"dairy farmer\" is applied to those engaged primarily in milk production, whether from cattle, goats, sheep, or other milk producing animals. A \"poultry farmer\" is one who concentrates on raising chickens, turkeys, ducks or geese, for either meat, egg or feather production, or commonly, all three. A person who raises a variety of vegetables for market may be called a \"truck farmer\" or \"market gardener\". \"Dirt farmer\" is an American colloquial term for a practical farmer, or one who farms his own land.\nIn developed nations, a farmer (as a profession) is usually defined as someone with an ownership interest in crops or livestock, and who provides land or management in their production. Those who provide only labor are most often called \"farmhands\". Alternatively, growers who manage farmland for an absentee landowner, sharing the harvest (or its profits) are known as \"sharecroppers\" or \"sharefarmers\". In the context of agribusiness, a farmer is defined broadly, and thus many individuals not necessarily engaged in full-time farming can nonetheless legally qualify under agricultural policy for various subsidies, incentives, and tax deductions.\nTechniques.\nIn the context of developing nations or other pre-industrial cultures, most farmers practice a meager subsistence agriculture\u2014a simple organic-farming system employing crop rotation, seed saving, slash and burn, or other techniques to maximize efficiency while meeting the needs of the household or community. One subsisting in this way may become labelled as a \"peasant\", often associated disparagingly with a \"peasant mentality\".\nIn developed nations, however, a person using such techniques on small patches of land might be called a gardener and be considered a hobbyist. Alternatively, one might be driven into such practices by poverty or, ironically\u2014against the background of large-scale agribusiness\u2014might become an organic farmer growing for discerning/faddish consumers in the local food market.\nFarming organizations.\nFarmers are often members of local, regional, or national farmers' unions or agricultural producers' organizations and can exert significant political influence. The Grange movement in the United States was effective in advancing farmers' agendas, especially against railroad and agribusiness interests early in the 20th century. The FNSEA is very politically active in France, especially pertaining to genetically modified food. Agricultural producers, both small and large, are represented globally by the International Federation of Agricultural Producers (IFAP), representing over 600 million farmers through 120 national farmers' unions in 79 countries.\nYouth farming organizations.\nThere are many organizations that are targeted at teaching young people how to farm and advancing the knowledge and benefits of sustainable agriculture. \nIncome.\nFarmed products might be sold either to a market, in a farmers' market, or directly from a farm. In a subsistence economy, farm products might to some extent be either consumed by the farmer's family or pooled by the community.\nOccupational hazards.\nThere are several occupational hazards for those in agriculture; farming is a particularly dangerous industry. Farmers can encounter and be stung or bitten by dangerous insects and other arthropods, including scorpions, fire ants, bees, wasps and hornets. Farmers also work around heavy machinery which can kill or injure them. Farmers can also establish muscle and joints pains from repeated work. Farmers also faces unique mental stressors, like the stress of uncertain crop yield based on weather events and uncertain economic stability due to market fluctuations. In the US, farmers are 3.5 times more likely to die by suicide than the general US population.\nEtymology.\nThe word 'farmer' originally meant a person collecting taxes from tenants working a field owned by a landlord. The word changed to refer to the person farming the field.\nPrevious names for a farmer were churl and husbandman.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "58689", "revid": "6941696", "url": "https://en.wikipedia.org/wiki?curid=58689", "title": "Guoyu", "text": "Guoyu or Guo Yu may refer to:\nPeople.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "58690", "revid": "4078968", "url": "https://en.wikipedia.org/wiki?curid=58690", "title": "Crystal structure", "text": "Ordered arrangement of atoms, ions, or molecules in a crystalline material\nIn crystallography, crystal structure is a description of the ordered arrangement of atoms, ions, or molecules in a crystalline material. Ordered structures occur from the intrinsic nature of constituent particles to form symmetric patterns that repeat along the principal directions of three-dimensional space in matter.\nThe smallest group of particles in a material that constitutes this repeating pattern is the unit cell of the structure. The unit cell completely reflects the symmetry and structure of the entire crystal, which is built up by repetitive translation of the unit cell along its principal axes. The translation vectors define the nodes of the Bravais lattice.\nThe lengths of principal axes/edges, of the unit cell and angles between them are lattice constants, also called \"lattice parameters\" or \"cell parameters\". The symmetry properties of a crystal are described by the concept of space groups. All possible symmetric arrangements of particles in three-dimensional space may be described by 230 space groups.\nThe crystal structure and symmetry play a critical role in determining many physical properties, such as cleavage, electronic band structure, and optical transparency.\nUnit cell.\nCrystal structure is described in terms of the geometry of the arrangement of particles in the unit cells. The unit cell is defined as the smallest repeating unit having the full symmetry of the crystal structure. The geometry of the unit cell is defined as a parallelepiped, providing six lattice parameters taken as the lengths of the cell edges (\"a\", \"b\", \"c\") and the angles between them (\u03b1, \u03b2, \u03b3). The positions of particles inside the unit cell are described by the fractional coordinates (\"xi\", \"yi\", \"zi\") along the cell edges, measured from a reference point. It is thus only necessary to report the coordinates of a smallest asymmetric subset of particles, called the crystallographic asymmetric unit. The asymmetric unit may be chosen so that it occupies the smallest physical space, which means that not all particles need to be physically located inside the boundaries given by the lattice parameters. All other particles of the unit cell are generated by the symmetry operations that characterize the symmetry of the unit cell. The collection of symmetry operations of the unit cell is expressed formally as the space group of the crystal structure.\nMiller indices.\nVectors and planes in a crystal lattice are described by the three-value Miller index notation. This syntax uses the indices \"h\", \"k\", and \"\u2113\" as directional parameters.\nBy definition, the syntax (\"hk\u2113\") denotes a plane that intercepts the three points \"a\"1/\"h\", \"a\"2/\"k\", and \"a\"3/\"\u2113\", or some multiple thereof. That is, the Miller indices are proportional to the inverses of the intercepts of the plane with the unit cell (in the basis of the lattice vectors). If one or more of the indices is zero, the planes do not intersect that axis (i.e., the intercept is \"at infinity\"). A plane containing a coordinate axis is translated to no longer contain that axis before its Miller indices are determined. The Miller indices for a plane are integers with no common factors. Negative indices are indicated with horizontal bars, as in (123). In an orthogonal coordinate system for a cubic cell, the Miller indices of a plane are the Cartesian components of a vector normal to the plane.\nConsidering only (\"hk\u2113\") planes intersecting one or more lattice points (the \"lattice planes\"), the distance \"d\" between adjacent lattice planes is related to the (shortest) reciprocal lattice vector orthogonal to the planes by the formula\nformula_1\nPlanes and directions.\nThe crystallographic directions are geometric lines linking nodes (atoms, ions or molecules) of a crystal. Likewise, the crystallographic planes are geometric \"planes\" linking nodes. Some directions and planes have a higher density of nodes. These high-density planes influence the behaviour of the crystal as follows:\nSome directions and planes are defined by symmetry of the crystal system. In monoclinic, trigonal, tetragonal, and hexagonal systems there is one unique axis (sometimes called the principal axis) which has higher rotational symmetry than the other two axes. The basal plane is the plane perpendicular to the principal axis in these crystal systems. For triclinic, orthorhombic, and cubic crystal systems the axis designation is arbitrary and there is no principal axis.\nCubic structures.\nFor the special case of simple cubic crystals, the lattice vectors are orthogonal and of equal length (usually denoted \"a\"); similarly for the reciprocal lattice. So, in this common case, the Miller indices (\"\u2113mn\") and [\"\u2113mn\"] both simply denote normals/directions in Cartesian coordinates. For cubic crystals with lattice constant \"a\", the spacing \"d\" between adjacent (\u2113mn) lattice planes is (from above):\nformula_2\nBecause of the symmetry of cubic crystals, it is possible to change the place and sign of the integers and have equivalent directions and planes:\nFor face-centered cubic (fcc) and body-centered cubic (bcc) lattices, the primitive lattice vectors are not orthogonal. However, in these cases the Miller indices are conventionally defined relative to the lattice vectors of the cubic supercell and hence are again simply the Cartesian directions.\nInterplanar spacing.\nThe perpendicular spacing d between adjacent (\"hk\u2113\") lattice planes is given by:\nClassification by symmetry.\nThe defining property of a crystal is its inherent symmetry. Performing certain symmetry operations on the crystal lattice leaves it unchanged. All crystals have translational symmetry in three directions, but some have other symmetry elements as well. For example, rotating the crystal 180\u00b0 about a certain axis may result in an atomic configuration that is identical to the original configuration; the crystal has twofold rotational symmetry about this axis. In addition to rotational symmetry, a crystal may have symmetry in the form of mirror planes, and also the so-called compound symmetries, which are a combination of translation and rotation or mirror symmetries. A full classification of a crystal is achieved when all inherent symmetries of the crystal are identified.\nLattice systems.\nLattice systems are a grouping of crystal structures according to the point groups of their lattice. All crystals fall into one of seven lattice systems. They are related to, but not the same as the seven crystal systems. \nThe most symmetric, the cubic or isometric system, has the symmetry of a cube, that is, it exhibits four threefold rotational axes oriented at 109.5\u00b0 (the tetrahedral angle) with respect to each other. These threefold axes lie along the body diagonals of the cube. The other six lattice systems, are hexagonal, tetragonal, rhombohedral (often confused with the trigonal crystal system), orthorhombic, monoclinic and triclinic which is the least symmetrical as it possess only identity (E).\nBravais lattices.\nBravais lattices, also referred to as \"space lattices\", describe the geometric arrangement of the lattice points, and therefore the translational symmetry of the crystal. The three dimensions of space afford 14 distinct Bravais lattices describing the translational symmetry. All crystalline materials recognized today, not including quasicrystals, fit in one of these arrangements. The fourteen three-dimensional lattices, classified by lattice system, are shown above.\nThe crystal structure consists of the same group of atoms, the \"basis\", positioned around each and every lattice point. This group of atoms therefore repeats indefinitely in three dimensions according to the arrangement of one of the Bravais lattices. The characteristic rotation and mirror symmetries of the unit cell is described by its crystallographic point group.\nCrystal systems.\nA crystal system is a set of point groups in which the point groups themselves and their corresponding space groups are assigned to a lattice system. Of the 32 point groups that exist in three dimensions, most are assigned to only one lattice system, in which case the crystal system and lattice system both have the same name. However, five point groups are assigned to two lattice systems, rhombohedral and hexagonal, because both lattice systems exhibit threefold rotational symmetry. These point groups are assigned to the trigonal crystal system.\nIn total there are seven crystal systems: triclinic, monoclinic, orthorhombic, tetragonal, trigonal, hexagonal, and cubic.\nPoint groups.\nThe crystallographic point group or \"crystal class\" is the mathematical group comprising the symmetry operations that leave at least one point unmoved and that leave the appearance of the crystal structure unchanged. These symmetry operations include\nRotation axes (proper and improper), reflection planes, and centers of symmetry are collectively called \"symmetry elements\". There are 32 possible crystal classes. Each one can be classified into one of the seven crystal systems.\nSpace groups.\nIn addition to the operations of the point group, the space group of the crystal structure contains translational symmetry operations. These include:\nThere are 230 distinct space groups.\nAtomic coordination.\nBy considering the arrangement of atoms relative to each other, their coordination numbers, interatomic distances, types of bonding, etc., it is possible to form a general view of the structures and alternative ways of visualizing them.\nClose packing.\nThe principles involved can be understood by considering the most efficient way of packing together equal-sized spheres and stacking close-packed atomic planes in three dimensions. For example, if plane A lies beneath plane B, there are two possible ways of placing an additional atom on top of layer B. If an additional layer were placed directly over plane A, this would give rise to the following series:\n...ABABABAB...\nThis arrangement of atoms in a crystal structure is known as hexagonal close packing (hcp).\nIf, however, all three planes are staggered relative to each other and it is not until the fourth layer is positioned directly over plane A that the sequence is repeated, then the following sequence arises:\n...ABCABCABC...\nThis type of structural arrangement is known as cubic close packing (ccp).\nThe unit cell of a ccp arrangement of atoms is the face-centered cubic (fcc) unit cell. This is not immediately obvious as the closely packed layers are parallel to the {111} planes of the fcc unit cell. There are four different orientations of the close-packed layers.\nAPF and CN.\nOne important characteristic of a crystalline structure is its atomic packing factor (APF). This is calculated by assuming that all the atoms are identical spheres, with a radius large enough that each sphere abuts on the next. The atomic packing factor is the proportion of space filled by these spheres which can be worked out by calculating the total volume of the spheres and dividing by the volume of the cell as follows:\nformula_10\nAnother important characteristic of a crystalline structure is its coordination number (CN). This is the number of nearest neighbours of a central atom in the structure.\nThe APFs and CNs of the most common crystal structures are shown below:\nThe 74% packing efficiency of the FCC and HCP is the maximum density possible in unit cells constructed of spheres of only one size.\nInterstitial sites.\nInterstitial sites refer to the empty spaces in between the atoms in the crystal lattice. These spaces can be filled by oppositely charged ions to form multi-element structures. They can also be filled by impurity atoms or self-interstitials to form interstitial defects.\nDefects and impurities.\nReal crystals feature defects or irregularities in the ideal arrangements described above and it is these defects that critically determine many of the electrical and mechanical properties of real materials.\nImpurities.\nWhen one atom substitutes for one of the principal atomic components within the crystal structure, alteration in the electrical and thermal properties of the material may ensue. Impurities may also manifest as electron spin impurities in certain materials. Research on magnetic impurities demonstrates that substantial alteration of certain properties such as specific heat may be affected by small concentrations of an impurity, as for example impurities in semiconducting ferromagnetic alloys may lead to different properties as first predicted in the late 1960s.\nDislocations.\nDislocations in a crystal lattice are line defects that are associated with local stress fields. Dislocations allow shear at lower stress than that needed for a perfect crystal structure. The local stress fields result in interactions between the dislocations which then result in strain hardening or cold working.\nGrain boundaries.\nGrain boundaries are interfaces where crystals of different orientations meet. A grain boundary is a single-phase interface, with crystals on each side of the boundary being identical except in orientation. The term \"crystallite boundary\" is sometimes, though rarely, used. Grain boundary areas contain those atoms that have been perturbed from their original lattice sites, dislocations, and impurities that have migrated to the lower energy grain boundary.\nTreating a grain boundary geometrically as an interface of a single crystal cut into two parts, one of which is rotated, we see that there are five variables required to define a grain boundary. The first two numbers come from the unit vector that specifies a rotation axis. The third number designates the angle of rotation of the grain. The final two numbers specify the plane of the grain boundary (or a unit vector that is normal to this plane).\nGrain boundaries disrupt the motion of dislocations through a material, so reducing crystallite size is a common way to improve strength, as described by the Hall\u2013Petch relationship. Since grain boundaries are defects in the crystal structure they tend to decrease the electrical and thermal conductivity of the material. The high interfacial energy and relatively weak bonding in most grain boundaries often makes them preferred sites for the onset of corrosion and for the precipitation of new phases from the solid. They are also important to many of the mechanisms of creep.\nGrain boundaries are in general only a few nanometers wide. In common materials, crystallites are large enough that grain boundaries account for a small fraction of the material. However, very small grain sizes are achievable. In nanocrystalline solids, grain boundaries become a significant volume fraction of the material, with profound effects on such properties as diffusion and plasticity. In the limit of small crystallites, as the volume fraction of grain boundaries approaches 100%, the material ceases to have any crystalline character, and thus becomes an amorphous solid.\nPrediction of structure.\nThe difficulty of predicting stable crystal structures based on the knowledge of only the chemical composition has long been a stumbling block on the way to fully computational materials design. Now, with more powerful algorithms and high-performance computing, structures of medium complexity can be predicted using such approaches as evolutionary algorithms, random sampling, or metadynamics.\nThe crystal structures of simple ionic solids (e.g., NaCl or table salt) have long been rationalized in terms of Pauling's rules, first set out in 1929 by Linus Pauling, referred to by many since as the \"father of the chemical bond\". Pauling also considered the nature of the interatomic forces in metals, and concluded that about half of the five d-orbitals in the transition metals are involved in bonding, with the remaining nonbonding d-orbitals being responsible for the magnetic properties. Pauling was therefore able to correlate the number of d-orbitals in bond formation with the bond length, as well as with many of the physical properties of the substance. He subsequently introduced the metallic orbital, an extra orbital necessary to permit uninhibited resonance of valence bonds among various electronic structures.\nIn the resonating valence bond theory, the factors that determine the choice of one from among alternative crystal structures of a metal or intermetallic compound revolve around the energy of resonance of bonds among interatomic positions. It is clear that some modes of resonance would make larger contributions (be more mechanically stable than others), and that in particular a simple ratio of number of bonds to number of positions would be exceptional. The resulting principle is that a special stability is associated with the simplest ratios or \"bond numbers\": &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20443, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;2\u20443, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3\u20444, etc. The choice of structure and the value of the axial ratio (which determines the relative bond lengths) are thus a result of the effort of an atom to use its valency in the formation of stable bonds with simple fractional bond numbers.\nAfter postulating a direct correlation between electron concentration and crystal structure in beta-phase alloys, Hume-Rothery analyzed the trends in melting points, compressibilities and bond lengths as a function of group number in the periodic table in order to establish a system of valencies of the transition elements in the metallic state. This treatment thus emphasized the increasing bond strength as a function of group number. The operation of directional forces were emphasized in one article on the relation between bond hybrids and the metallic structures. The resulting correlation between electronic and crystalline structures is summarized by a single parameter, the weight of the d-electrons per hybridized metallic orbital. The \"d-weight\" calculates out to 0.5, 0.7 and 0.9 for the fcc, hcp and bcc structures respectively. The relationship between d-electrons and crystal structure thus becomes apparent.\nIn crystal structure predictions/simulations, the periodicity is usually applied, since the system is imagined as being unlimited in all directions. Starting from a triclinic structure with no further symmetry property assumed, the system may be driven to show some additional symmetry properties by applying Newton's second law on particles in the unit cell and a recently developed dynamical equation for the system period vectors\n (lattice parameters including angles), even if the system is subject to external stress.\nPolymorphism.\nPolymorphism is the occurrence of multiple crystalline forms of a material. It is found in many crystalline materials including polymers, minerals, and metals. According to Gibbs' rules of phase equilibria, these unique crystalline phases are dependent on intensive variables such as pressure and temperature. Polymorphism is related to allotropy, which refers to elemental solids. The complete morphology of a material is described by polymorphism and other variables such as crystal habit, amorphous fraction or crystallographic defects. Polymorphs have different stabilities and may spontaneously and irreversibly transform from a metastable form (or thermodynamically unstable form) to the stable form at a particular temperature. They also exhibit different melting points, solubilities, and X-ray diffraction patterns.\nOne good example of this is the quartz form of silicon dioxide, or SiO2. In the vast majority of silicates, the Si atom shows tetrahedral coordination by 4 oxygens. All but one of the crystalline forms involve tetrahedral {SiO4} units linked together by shared vertices in different arrangements. In different minerals the tetrahedra show different degrees of networking and polymerization. For example, they occur singly, joined in pairs, in larger finite clusters including rings, in chains, double chains, sheets, and three-dimensional frameworks. The minerals are classified into groups based on these structures. In each of the 7 thermodynamically stable crystalline forms or polymorphs of crystalline quartz, only 2 out of 4 of each the edges of the {SiO4} tetrahedra are shared with others, yielding the net chemical formula for silica: SiO2.\nAnother example is elemental tin (Sn), which is malleable near ambient temperatures but is brittle when cooled. This change in mechanical properties due to existence of its two major allotropes, \u03b1- and \u03b2-tin. The two allotropes that are encountered at normal pressure and temperature, \u03b1-tin and \u03b2-tin, are more commonly known as \"gray tin\" and \"white tin\" respectively. Two more allotropes, \u03b3 and \u03c3, exist at temperatures above 161\u00a0\u00b0C and pressures above several GPa. White tin is metallic, and is the stable crystalline form at or above room temperature. Below 13.2\u00a0\u00b0C, tin exists in the gray form, which has a diamond cubic crystal structure, similar to diamond, silicon or germanium. Gray tin has no metallic properties at all, is a dull gray powdery material, and has few uses, other than a few specialized semiconductor applications. Although the \u03b1\u2013\u03b2 transformation temperature of tin is nominally 13.2\u00a0\u00b0C, impurities (e.g. Al, Zn, etc.) lower the transition temperature well below 0\u00a0\u00b0C, and upon addition of Sb or Bi the transformation may not occur at all.\nPhysical properties.\nTwenty of the 32 crystal classes are piezoelectric, and crystals belonging to one of these classes (point groups) display piezoelectricity. All piezoelectric classes lack inversion symmetry. Any material develops a dielectric polarization when an electric field is applied, but a substance that has such a natural charge separation even in the absence of a field is called a polar material. Whether or not a material is polar is determined solely by its crystal structure. Only ten of the 32 point groups are polar. All polar crystals are pyroelectric, so the ten polar crystal classes are sometimes referred to as the pyroelectric classes.\nThere are a few crystal structures, notably the perovskite structure, which exhibit ferroelectric behavior. This is analogous to ferromagnetism, in that, in the absence of an electric field during production, the ferroelectric crystal does not exhibit a polarization. Upon the application of an electric field of sufficient magnitude, the crystal becomes permanently polarized. This polarization can be reversed by a sufficiently large counter-charge, in the same way that a ferromagnet can be reversed. However, although they are called ferroelectrics, the effect is due to the crystal structure (not the presence of a ferrous metal).\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "58692", "revid": "15952795", "url": "https://en.wikipedia.org/wiki?curid=58692", "title": "Expendable rocket", "text": ""}
{"id": "58693", "revid": "1302184", "url": "https://en.wikipedia.org/wiki?curid=58693", "title": "Abyss", "text": "Abyss may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "58695", "revid": "48998989", "url": "https://en.wikipedia.org/wiki?curid=58695", "title": "Semitic people", "text": "Racial group that includes Jews and Arabs\nSemitic people or Semites is a term for an ethnic, cultural or racial group associated with people of the Middle East and the Horn of Africa, including Akkadians (Assyrians and Babylonians), Arabs, Arameans, Canaanites (Ammonites, Edomites, Israelites, Moabites, Phoenicians, and Philistines) and Habesha peoples. The terminology is now largely unused outside the grouping \"Semitic languages\" in linguistics. First used in the 1770s by members of the G\u00f6ttingen school of history, this biblical terminology for race was derived from Shem (), one of the three sons of Noah in the Book of Genesis, together with the parallel terms Hamites and Japhetites.\nIn archaeology, the term is sometimes used informally as \"a kind of shorthand\" for ancient Semitic-speaking peoples. Identification of pro-Caucasian racism has either partially or completely devalued the use of the term as a racial category, with the caveat that an inverse assessment would still be considered scientifically obsolete.\nEthnicity and race.\nCategorization of racial groups by reference to skin color was common in classical antiquity. For example, it is found in e.g. \"Physiognomica\", a Greek treatise dated to c. 300 BC.\nThe transmission of the \"color terminology\" for race from antiquity to early anthropology in 17th century Europe took place via rabbinical literature, where the term \"Semite\" in a racial sense was coined. Specifically, Pirke De-Rabbi Eliezer (a medieval rabbinical text dated roughly to between the 7th to 12th centuries) contains the division of mankind into three groups based on the three sons of Noah, viz. Shem, Ham and Japheth: \n\"He [Noah] especially blessed \"Shem\" (emphasis added) and his sons, (making them) black but comely [\u05e9\u05d7\u05d5\u05e8\u05d9\u05dd \u05d5\u05e0\u05d0\u05d9\u05dd], and he gave them the habitable earth. He blessed Ham and his sons, (making them) black like the raven [\u05e9\u05d7\u05d5\u05e8\u05d9\u05dd \u05db\u05e2\u05d5\u05e8\u05d1], and he gave them as an inheritance the coast of the sea. He blessed Japheth and his sons, (making) them entirely white [\u05db\u05dc\u05dd \u05dc\u05d1\u05e0\u05d9], and he gave them for an inheritance the desert and its fields\" (trans. Gerald Friedlander 1916, https://)\nJews were identified as a belonging to a subrace of the Semite greater race in this division of mankind. In Rabbi Eliezer and other rabbinical texts was it then received by Georgius Hornius (1666). In Hornius' scheme, Semites are \"brownish-yellow\" (), and almost all Jews being neither black nor white but \"light brown\" (, the color of boxwood), following \"Mishnah Sanhedrin\", they accordingly are classified as Semites.\nThe term \"Semitic\" in a racial sense was coined by members of the G\u00f6ttingen school of history in the early 1770s. Other members of the G\u00f6ttingen school of history coined the separate term Caucasian in the 1780s. These terms were used and developed by numerous other scholars over the next century. In the early 20th century, the pseudo-scientific classifications of Carleton S. Coon included the Semitic peoples in the Caucasian race, as similar in appearance to the Indo-European, Northwest Caucasian, and Kartvelian-speaking peoples. Due to the interweaving of language studies and cultural studies, the term also came to be applied to the religions (ancient Semitic and Abrahamic) and ethnicities of various cultures associated by geographic and linguistic distribution.\nAntisemitism.\nGerman historian Christoph Meiners, supporter of the polygenist theory of human origins, became favorite intellectual ancestor of the Nazis. In his \"\"binary [greater] racial scheme\" of superior Caucasians and inferior Mongoloids, Meiners did not include Jews as Caucasians and ascribed them a \"permanently degenerate nature\"\". Other members of the G\u00f6ttingen school of history would make the addition of Negroids.\nIn part he resented the French Revolution for leading to French Jewish emancipation and threatening the Germans' supposed rightful place in a racial hierarchy in which they were assessed as superior in all domains due to inheriting naturally occurring higher purity of blood from their ancestors, yet already degenerating through indulgence in civilization's luxuries. Using a \"bundle of notions\" led to creations of purported subraces on a continental and state basis with implied decreased respective scientific weight. In 1772 he became extraordinary professor, and in 1775 full professor, of \"Weltweisheit\", also at the University of G\u00f6ttingen, when over the course of tenures he had the opportunity to join the G\u00f6ttingen school of history of which he was a member.\nThe terms \"anti-Semite\" or \"antisemitism\" came by a circuitous route to refer more narrowly to anyone who was hostile or discriminatory towards Jews in particular.\nAnthropologists of the 19th century such as Ernest Renan readily aligned linguistic groupings with ethnicity and culture, appealing to anecdote, science and folklore in their efforts to define racial character. Moritz Steinschneider, in his periodical of Jewish letters \"Hamaskir\" (3 (Berlin 1860), 16), discusses an article by Heymann Steinthal criticising Renan's article \"New Considerations on the General Character of the Semitic Peoples, In Particular Their Tendency to Monotheism\". Renan had acknowledged the importance of the ancient civilisations of Mesopotamia, Israel etc. but called the Semitic races inferior to the Aryan for their monotheism, which he held to arise from their supposed lustful, violent, unscrupulous and selfish racial instincts. Steinthal summed up these predispositions as \"Semitism\", and so Steinschneider characterised Renan's ideas as \"anti-Semitic prejudice\".\nIn 1879, the German journalist Wilhelm Marr began the politicisation of the term by speaking of a struggle between Jews and Germans in a pamphlet called \"Der Weg zum Siege des Germanenthums \u00fcber das Judenthum\" (\"The Way to Victory of Germanism over Judaism\"). He accused the Jews of being liberals, a people without roots who had Judaized Germans beyond salvation. In 1879, Marr's adherents founded the \"League for Anti-Semitism\", which concerned itself entirely with anti-Jewish political action.\nCharacterizations of \"Semite\" as having little to no value on the socially constructed racial spectrum combined with its overuse due to popularization stemming from pro-Caucasian racism, as identification with antisemitism and as an antisemite was politically advantageous in Europe at least during the late 19th century\u2014for example, Karl Lueger, the popular mayor of fin de si\u00e8cle Vienna, skillfully exploited antisemitism as a way of channeling public discontent to his political advantage\u2014thereby diluting anti-Judaism, have been made since at least the 1930s.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "58697", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=58697", "title": "Music in Puerto Rico", "text": ""}
{"id": "58698", "revid": "76340842", "url": "https://en.wikipedia.org/wiki?curid=58698", "title": "Punitive damage", "text": ""}
{"id": "58699", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=58699", "title": "Coast douglas-fir", "text": ""}
{"id": "58701", "revid": "48984234", "url": "https://en.wikipedia.org/wiki?curid=58701", "title": "Eiffel tower", "text": ""}
