{"id": "21485", "revid": "50666884", "url": "https://en.wikipedia.org/wiki?curid=21485", "title": "Neutrino", "text": "Elementary particle with extremely low mass\nA neutrino ( ; denoted by the Greek letter \u03bd) is an elementary particle that interacts via the weak interaction and gravity. The neutrino is so named because it is electrically neutral and because its rest mass is so small (\"-ino\") that it was long thought to be zero. The rest mass of the neutrino is much smaller than that of the other known elementary particles (excluding massless particles).\nThe weak force has a very short range, the gravitational interaction is extremely weak due to the very small mass of the neutrino, and neutrinos do not participate in the electromagnetic interaction or the strong interaction.\nConsequently, neutrinos typically pass through normal matter unimpeded and with no detectable effect.\nWeak interactions create neutrinos in one of three leptonic flavors:\nEach flavor is associated with the correspondingly named charged lepton. Although neutrinos were long believed to be massless, it is now known that there are three discrete neutrino masses with different values (all tiny, the smallest of which could be zero), but the three masses do not uniquely correspond to the three flavors: A neutrino created with a specific flavor is a specific mixture of all three mass states (a \"quantum superposition\"). Similar to some other neutral particles, neutrinos oscillate between different flavors in flight as a consequence. For example, an electron neutrino produced in a beta decay reaction may interact in a distant detector as a muon or tau neutrino. The three mass values are not yet known as of 2024, but laboratory experiments and cosmological observations have determined the differences of their squares, an upper limit on their sum (&lt;\u00a0), and an upper limit on the mass of the electron neutrino. Neutrinos are fermions, which have spin of \"\u0127\".\nFor each neutrino, there also exists a corresponding antiparticle, called an \"antineutrino\", which also has spin of \"\u0127\" and no electric charge. Antineutrinos are distinguished from neutrinos by having opposite-signed lepton number and weak isospin, and right-handed instead of left-handed chirality. To conserve total lepton number (in nuclear beta decay), electron neutrinos only appear together with positrons (anti-electrons) or electron-antineutrinos, whereas electron antineutrinos only appear with electrons or electron neutrinos.\nNeutrinos are created by various radioactive decays; the following list is not exhaustive, but includes some of those processes:\nThe majority of neutrinos which are detected about the Earth are from nuclear reactions inside the Sun. At the surface of the Earth, the flux is about 65\u00a0billion () solar neutrinos, per second per square centimeter. Neutrinos can be used for tomography of the interior of the Earth.\nHistory.\nPauli's proposal.\nThe neutrino was postulated first by Wolfgang Pauli in 1930 to explain how beta decay could conserve energy, momentum, and angular momentum (spin). In contrast to Niels Bohr, who proposed a statistical version of the conservation laws to explain the observed continuous energy spectra in beta decay, Pauli hypothesized an undetected particle that he called a \"neutron\", using the same \"-on\" ending employed for naming both the proton and the electron. He considered that the new particle was emitted from the nucleus together with the electron or beta particle in the process of beta decay and had a mass similar to the electron.\nJames Chadwick discovered a much more massive neutral nuclear particle in 1932 and named it a neutron also, leaving two kinds of particles with the same name. The word \"neutrino\" entered the scientific vocabulary through Enrico Fermi, who used it during a conference in Paris in July\u00a01932 and at the Solvay Conference in October\u00a01933, where Pauli also employed it. The name (the Italian equivalent of \"little neutral one\") was jokingly coined by Edoardo Amaldi during a conversation with Fermi at the Institute of Physics of via Panisperna in Rome, in order to distinguish this light neutral particle from Chadwick's heavy neutron.\nIn Fermi's theory of beta decay, Chadwick's large neutral particle could decay to a proton, electron, and the smaller neutral particle (now called an \"electron antineutrino\"):\nFermi's paper, written in 1934, unified Pauli's neutrino with Paul Dirac's positron and Werner Heisenberg's neutron\u2013proton model and gave a solid theoretical basis for future experimental work.\nBy 1934, there was experimental evidence against Bohr's idea that energy conservation is invalid for beta decay: At the Solvay conference of that year, measurements of the energy spectra of beta particles (electrons) were reported, showing that there is a strict limit on the energy of electrons from each type of beta decay. Such a limit is not expected if the conservation of energy is invalid, in which case any amount of energy would be statistically available in at least a few decays. The natural explanation of the beta decay spectrum as first measured in 1934 was that only a limited (and conserved) amount of energy was available, and a new particle was sometimes taking a varying fraction of this limited energy, leaving the rest for the beta particle. Pauli made use of the occasion to publicly emphasize that the still-undetected \"neutrino\" must be an actual particle.25 The first evidence of the reality of neutrinos came in 1938 via simultaneous cloud-chamber measurements of the electron and the recoil of the nucleus.\nDirect detection.\nIn 1942, Wang Ganchang first proposed the use of beta capture to experimentally detect neutrinos. In the 20\u00a0July 1956 issue of \"Science\", Clyde Cowan, Frederick Reines, Francis B. \"Kiko\" Harrison, Herald W. Kruse, and Austin D. McGuire published confirmation that they had detected the neutrino, a result that was rewarded almost forty years later with the 1995 Nobel Prize.\nIn this experiment, now known as the Cowan\u2013Reines neutrino experiment, antineutrinos created in a nuclear reactor by beta decay reacted with protons to produce neutrons and positrons:\nThe positron quickly finds an electron, and they annihilate each other. The two resulting gamma rays (\u03b3) are detectable. The neutron can be detected by its capture on an appropriate nucleus, releasing a gamma ray. The coincidence of both events\u2014positron annihilation and neutron capture\u2014gives a unique signature of an antineutrino interaction.\nIn February\u00a01965, the first neutrino found in nature was identified by a group including Frederick Reines and Friedel Sellschop. The experiment was performed in a specially prepared chamber at a depth of 3\u00a0km in the East Rand (\"ERPM\") gold mine near Boksburg, South Africa. A plaque in the main building commemorates the discovery. The experiments also implemented a primitive neutrino astronomy and looked at issues of neutrino physics and weak interactions.\nNeutrino flavor.\nThe antineutrino discovered by Clyde Cowan and Frederick Reines was the antiparticle of the electron neutrino.\nIn 1962, Leon M. Lederman, Melvin Schwartz, and Jack Steinberger showed that more than one type of neutrino exists by first detecting interactions of the muon neutrino (already hypothesised with the name \"neutretto\"), which earned them the 1988 Nobel Prize in Physics.\nWhen the third type of lepton, the tau, was discovered in 1975 at the Stanford Linear Accelerator Center, it was also expected to have an associated neutrino (the tau neutrino). The first evidence for this third neutrino type came from the observation of missing energy and momentum in tau decays analogous to the beta decay leading to the discovery of the electron neutrino. The first detection of tau neutrino interactions was announced in 2000 by the DONUT collaboration at Fermilab; its existence had already been inferred by both theoretical consistency and experimental data from the Large Electron\u2013Positron Collider.\nSolar neutrino problem.\nIn the 1960s, the now-famous Homestake experiment made the first measurement of the flux of electron neutrinos arriving from the core of the Sun and found a value that was between one third and one half the number predicted by the Standard Solar Model. This discrepancy, which became known as the solar neutrino problem, remained unresolved for some thirty years, while possible problems with both the experiment and the solar model were investigated, but none could be found. Eventually, it was realized that both were actually correct and that the discrepancy between them was due to neutrinos being more complex than was previously assumed. It was postulated that the three neutrinos had nonzero and slightly different masses, and could therefore oscillate into undetectable flavors on their flight to the Earth. This hypothesis was investigated by a new series of experiments, thereby opening a new major field of research that still continues. Eventual confirmation of the phenomenon of neutrino oscillation led to two Nobel prizes, one to R. Davis, who conceived and led the Homestake experiment and Masatoshi Koshiba of Kamiokande, whose work confirmed it, and one to Takaaki Kajita of Super-Kamiokande and A.B. McDonald of Sudbury Neutrino Observatory for their joint experiment, which confirmed the existence of all three neutrino flavors and found no deficit.\nOscillation.\nA practical method for investigating neutrino oscillations was first suggested by Bruno Pontecorvo in 1957 using an analogy with kaon oscillations; over the subsequent 10\u00a0years, he developed the mathematical formalism and the modern formulation of vacuum oscillations. In 1985 Stanislav Mikheyev and Alexei Smirnov (expanding on 1978 work by Lincoln Wolfenstein) noted that flavor oscillations can be modified when neutrinos propagate through matter. This so-called Mikheyev\u2013Smirnov\u2013Wolfenstein effect (MSW effect) is important to understand because many neutrinos emitted by fusion in the Sun pass through the dense matter in the solar core (where essentially all solar fusion takes place) on their way to detectors on Earth.\nStarting in 1998, experiments began to show that solar and atmospheric neutrinos change flavors (see \"Super-Kamiokande\" and \"Sudbury Neutrino Observatory\"). This resolved the solar neutrino problem: the electron neutrinos produced in the Sun had partly changed into other flavors which the experiments could not detect.\nAlthough individual experiments, such as the set of solar neutrino experiments, are consistent with non-oscillatory mechanisms of neutrino flavor conversion, taken altogether, neutrino experiments imply the existence of neutrino oscillations. Especially relevant in this context are the reactor experiment KamLAND and the accelerator experiments such as MINOS. The KamLAND experiment has indeed identified oscillations as the neutrino flavor conversion mechanism involved in the solar electron neutrinos. Similarly MINOS confirms the oscillation of atmospheric neutrinos and gives a better determination of the mass squared splitting. Takaaki Kajita of Japan, and Arthur B. McDonald of Canada, received the 2015 Nobel Prize for Physics for their landmark finding, theoretical and experimental, that neutrinos can change flavors.\nCosmic neutrinos.\nAs well as specific sources, a general background level of neutrinos is expected to pervade the universe, theorized to occur due to two main sources.\nAround 1\u00a0second after the Big Bang, neutrinos decoupled, giving rise to a background level of neutrinos known as the cosmic neutrino background (CNB).\nRaymond Davis, Jr. and Masatoshi Koshiba were jointly awarded the 2002 Nobel Prize in Physics. Both conducted pioneering work on solar neutrino detection, and Koshiba's work also resulted in the first real-time observation of neutrinos from the SN 1987A supernova in the nearby Large Magellanic Cloud. These efforts marked the beginning of neutrino astronomy.\nSN 1987A represents the only verified detection of neutrinos from a supernova. However, many stars have exploded as supernovae in the universe, leaving a theorized diffuse supernova neutrino background.\nProperties and reactions.\nNeutrinos have half-integer spin (\"\u0127\"); therefore they are fermions. Neutrinos are leptons; therefore they are colorless fermions that cannot interact with the gluons of the strong force. They have only been observed to interact through the weak force, although it is assumed that they also interact gravitationally. Since they have non-zero mass, some theories permit, but do not require, neutrinos to interact magnetically; as yet there is no experimental evidence for a non-zero magnetic moment in neutrinos.\nFlavor, mass, and their mixing.\nWeak interactions create neutrinos in one of three leptonic flavors: electron neutrinos (), muon neutrinos (), or tau neutrinos (), associated with the corresponding charged leptons, the electron (), muon (), and tau (), respectively.\nAlthough neutrinos were long believed to be massless, it is now known that there are three discrete neutrino masses; each neutrino flavor state is a linear combination of the three distinct mass eigenstates. From calculations based on cosmological models, the sum of the three neutrino masses must be below . Direct and independent measurements by the Karlsruhe Tritium Neutrino (KATRIN) experiment found the upper limit of the mass of the electron antineutrino as , that is at least 5\u00a0orders of magnitude below the next lightest fermion. This large ratio suggests the possibility that the mass-creation mechanism for neutrinos differs from that of other fermions. \nMore formally, neutrino flavor eigenstates (creation and annihilation combinations) are not the same as the neutrino mass eigenstates (simply labeled \"1\", \"2\", and \"3\"). As of 2024, it is not known which of these three is the heaviest. The neutrino mass hierarchy consists of two possible configurations. In analogy with the mass hierarchy of the charged leptons, the configuration with mass\u00a02 being lighter than mass\u00a03 is conventionally called the \"normal hierarchy\", while in the \"inverted hierarchy\", the opposite would hold. Several major experimental efforts are underway to help establish which is correct.\nA neutrino created in a specific flavor eigenstate is in an associated specific quantum superposition of all three mass eigenstates. The three masses differ so little that they cannot possibly be distinguished experimentally within any practical flight path. The proportion of each mass state in the pure flavor states produced has been found to depend profoundly on the flavor. The relationship between flavor and mass eigenstates is encoded in the PMNS matrix. Experiments have established moderate- to low-precision values for the elements of this matrix, with the single complex phase in the matrix being only poorly known, as of 2016.\nA non-zero mass means neutrinos could have a tiny magnetic moment. If so, neutrinos would interact electromagnetically, albeit probably undetectably considering their enormous velocities. No such interaction has ever been observed.\nFlavor oscillations.\nNeutrinos oscillate between different flavors in flight. For example, an electron neutrino produced in a beta decay reaction may interact in a distant detector as a muon or tau neutrino, as defined by the flavor of the charged lepton produced in the detector. This oscillation occurs because the three mass state components of the produced flavor travel at slightly different speeds, so that their quantum mechanical wave packets develop relative phase shifts that change how they combine to produce a varying superposition of three flavors. Each flavor component thereby oscillates as the neutrino travels, with the flavors varying in relative strengths. The relative flavor proportions when the neutrino interacts represent the relative probabilities for that flavor of interaction to produce the corresponding flavor of charged lepton.\nThere are other possibilities in which neutrinos could oscillate even if they were massless: If Lorentz symmetry were not an exact symmetry, neutrinos could experience Lorentz-violating oscillations.\nMikheyev\u2013Smirnov\u2013Wolfenstein effect.\nNeutrinos traveling through matter, in general, undergo a process analogous to light traveling through a transparent material. This process is not directly observable because it does not produce ionizing radiation, but gives rise to the Mikheyev\u2013Smirnov\u2013Wolfenstein effect. Only a small fraction of the neutrino's energy is transferred to the material.\nAntineutrinos.\nFor each neutrino, there also exists a corresponding antiparticle, called an \"antineutrino\", which also has no electric charge and half-integer spin. They are distinguished from the neutrinos by having opposite signs of lepton number and opposite chirality (and consequently opposite-sign weak isospin). As of 2016, no evidence has been found for any other difference.\nSo far, despite extensive and continuing searches for exceptions, in all observed leptonic processes there has never been any change in total lepton number; for example, if the total lepton number is zero in the initial state, then the final state has only matched lepton and anti-lepton pairs: electron neutrinos appear in the final state together with only positrons (anti-electrons) or electron antineutrinos, and electron antineutrinos with electrons or electron neutrinos.\nAntineutrinos are produced in nuclear beta decay together with a beta particle (in beta decay a neutron decays into a proton, electron, and antineutrino). All antineutrinos observed thus far had right-handed helicity (i.e., only one of the two possible spin states has ever been seen), while neutrinos were all left-handed. Nevertheless, because neutrinos have mass, their helicity is frame-dependent, so particle physicists have fallen back on the frame-independent property of chirality that is closely related to helicity, and for practical purposes the same as the helicity of the ultra-relativistic neutrinos that can be observed in detectors.\nAntineutrinos were first detected as a result of their interaction with protons in a large tank of water. This was installed next to a nuclear reactor as a controllable source of the antineutrinos (see \"Cowan\u2013Reines neutrino experiment\"). Researchers around the world have begun to investigate the possibility of using antineutrinos for reactor monitoring in the context of preventing the proliferation of nuclear weapons.\nMajorana mass.\nBecause antineutrinos and neutrinos are neutral particles, it is possible that they are the same particle. Rather than conventional Dirac fermions, neutral particles can be another type of spin\u00a0 particle called \"Majorana particles\", named after the Italian physicist Ettore Majorana who first proposed the concept. For the case of neutrinos this theory has gained popularity as it can be used, in combination with the seesaw mechanism, to explain why neutrino masses are so small compared to those of the other elementary particles, such as electrons or quarks. Majorana neutrinos would have the property that the neutrino and antineutrino could be distinguished only by chirality; what experiments observe as a difference between the neutrino and antineutrino could simply be due to one particle with two possible chiralities.\nAs of 2019[ [update]], it is not known whether neutrinos are Majorana or Dirac particles. It is possible to test this property experimentally. For example, if neutrinos are indeed Majorana particles, then lepton-number violating processes such as neutrinoless double-beta decay would be allowed, while they would not if neutrinos are Dirac particles. Several experiments have been and are being conducted to search for this process, e.g. GERDA, EXO, SNO+, and CUORE. The cosmic neutrino background is also a probe of whether neutrinos are Majorana particles, since there should be a different number of cosmic neutrinos detected in either the Dirac or Majorana case.\nNuclear reactions.\nNeutrinos can interact with a nucleus, changing it to different nucleus. This process is used in radiochemical neutrino detectors. In this case, the energy levels and spin states within the target nucleus have to be taken into account to estimate the probability for an interaction. In general the interaction probability increases with the number of neutrons and protons within a nucleus.\nIt is very hard to uniquely identify neutrino interactions among the natural background of radioactivity. For this reason, in early experiments a special reaction channel was chosen to facilitate the identification: the interaction of an antineutrino with one of the hydrogen nuclei in the water molecules. A hydrogen nucleus is a single proton, so simultaneous nuclear interactions, which would occur within a heavier nucleus, do not need to be considered for the detection experiment. Within a cubic meter of water placed right outside a nuclear reactor, only relatively few such interactions can be recorded, but the setup is now used for measuring the reactor's plutonium production rate.\nInduced fission and other disintegration events.\nVery much like neutrons do in nuclear reactors, neutrinos can induce fission reactions within heavy nuclei. So far, this reaction has not been measured in a laboratory, but is predicted to happen within stars and supernovae. The process affects the abundance of isotopes seen in the universe. Neutrino-induced disintegration of deuterium nuclei has been observed in the Sudbury Neutrino Observatory, which uses a heavy water detector.\nTypes.\nThere are three known types (\"flavors\") of neutrinos: electron neutrino , muon neutrino , and tau neutrino , named after their partner leptons in the Standard Model (see table at right). The current best measurement of the number of neutrino types comes from observing the decay of the Z boson. This particle can decay into any light neutrino and its antineutrino, and the more available types of light neutrinos, the shorter the lifetime of the Z\u00a0boson. Measurements of the Z lifetime have shown that three light neutrino flavors couple to the Z. The correspondence between the six quarks in the Standard Model and the six leptons, among them the three neutrinos, suggests to physicists' intuition that there should be exactly three types of neutrino.\nResearch.\nThere are several active research areas involving the neutrino with aspirations of finding:\nDetectors near artificial neutrino sources.\nInternational scientific collaborations install large neutrino detectors near nuclear reactors or in neutrino beams from particle accelerators to better constrain the neutrino masses and the values for the magnitude and rates of oscillations between neutrino flavors. These experiments are thereby searching for the existence of CP violation in the neutrino sector; that is, whether or not the laws of physics treat neutrinos and antineutrinos differently.\nThe KATRIN experiment in Germany began to acquire data in June 2018 to determine the value of the mass of the electron neutrino, with other approaches to this problem in the planning stages.\nGravitational effects.\nDespite their tiny masses, neutrinos are so numerous that their gravitational force can influence other matter in the universe.\nThe three known neutrino flavors are the only candidates for dark matter that are experimentally established elementary particles \u2013 specifically, they would be hot dark matter. However, the currently known neutrino types seem to be essentially ruled out as a substantial proportion of dark matter, based on observations of the cosmic microwave background. It still seems plausible that heavier, sterile neutrinos might compose warm dark matter, if they exist.\nSterile neutrino searches.\nOther efforts search for evidence of a sterile neutrino \u2013 a fourth neutrino flavor that would not interact with matter like the three known neutrino flavors. The possibility of sterile neutrinos is unaffected by the Z\u00a0boson decay measurements described above: If their mass is greater than half the Z\u00a0boson's mass, they could not be a decay product. Therefore, to be consistent with not having been detected in Z\u00a0boson decays, heavy sterile neutrinos would need to have a mass of at least 45.6\u00a0GeV.\nThe existence of such particles is in fact hinted by experimental data from the LSND experiment. On the other hand, the currently running MiniBooNE experiment suggested that sterile neutrinos are not required to explain the experimental data, although the latest research into this area is on-going and anomalies in the MiniBooNE data may allow for exotic neutrino types, including sterile neutrinos. A re-analysis of reference electron spectra data from the Institut Laue-Langevin in 2011 has also hinted at a fourth, light sterile neutrino. Triggered by the 2011 findings, several experiments at very short distances from nuclear reactors have searched for sterile neutrinos since then. While most of them were able to rule out the existence of a light sterile neutrino, the combined results are ambiguous.\nAccording to an analysis published in 2010, data from the Wilkinson Microwave Anisotropy Probe of the cosmic background radiation is compatible with either three or four types of neutrinos.\nNeutrinoless double-beta decay searches.\nAnother hypothesis concerns \"neutrinoless double-beta decay\", which, if it exists, would violate lepton number conservation. Searches for this mechanism are underway but have not yet found evidence for it. If they were to, then what are now called antineutrinos could not be true antiparticles.\nCosmic ray neutrinos.\nCosmic ray neutrino experiments detect neutrinos from space to study both the nature of neutrinos and the cosmic sources producing them.\nSpeed.\nBefore neutrinos were found to oscillate, they were generally assumed to be massless, propagating at the speed of light (c). According to the theory of special relativity, the question of neutrino velocity is closely related to their mass: If neutrinos are massless, they must travel at the speed of light, and if they have mass they cannot reach the speed of light. Due to their tiny mass, the predicted speed is extremely close to the speed of light in all experiments, and current detectors are not sensitive to the expected difference.\nAlso, there are some Lorentz-violating variants of quantum gravity which might allow faster-than-light neutrinos. A comprehensive framework for Lorentz violations is the Standard-Model Extension (SME).\nThe first measurements of neutrino speed were made in the early 1980s using pulsed pion beams (produced by pulsed proton beams hitting a target). The pions decayed producing neutrinos, and the neutrino interactions observed within a time window in a detector at a distance were consistent with the speed of light. This measurement was repeated in 2007 using the MINOS detectors, which found the speed of neutrinos to be, at the 99% confidence level, in the range between and . The central value of is higher than the speed of light but, with uncertainty taken into account, is also consistent with a velocity of exactly c or slightly less. This measurement set an upper bound on the mass of the muon neutrino at with 99% confidence. After the detectors for the project were upgraded in 2012, MINOS refined their initial result and found agreement with the speed of light, with the difference in the arrival time of neutrinos and light of .\nA similar observation was made, on a much larger scale, with supernova 1987A (SN 1987A). Antineutrinos with an energy of 10\u00a0MeV from the supernova were detected within a time window that was consistent with the speed of light for the neutrinos. So far, all measurements of neutrino speed have been consistent with the speed of light.\nSuperluminal neutrino glitch.\nIn September\u00a02011, the OPERA collaboration released calculations showing velocities of 17\u00a0GeV and 28\u00a0GeV neutrinos exceeding the speed of light in their experiments. In November\u00a02011, OPERA repeated its experiment with changes so that the speed could be determined individually for each detected neutrino. The results showed the same faster-than-light speed. In February\u00a02012, reports came out that the results may have been caused by a loose fiber optic cable attached to one of the atomic clocks which measured the departure and arrival times of the neutrinos. An independent recreation of the experiment in the same laboratory by ICARUS found no discernible difference between the speed of a neutrino and the speed of light.\nMass.\n&lt;templatestyles src=\"Unsolved/styles.css\" /&gt;\nUnsolved problem in physics\nCan we measure the neutrino masses? Do neutrinos follow Dirac or Majorana statistics?\nMore unsolved problems in physics\nThe Standard Model of particle physics assumed that neutrinos are massless. The experimentally established phenomenon of neutrino oscillation, which mixes neutrino flavor states with neutrino mass states (analogously to CKM mixing), requires neutrinos to have nonzero masses. Massive neutrinos were originally conceived by Bruno Pontecorvo in the 1950s. Enhancing the basic framework to accommodate their mass is straightforward by adding a right-handed Lagrangian.\nProviding for neutrino mass can be done in two ways, and some proposals use both:\nA hard upper limit on the masses of neutrinos comes from cosmology: the Big Bang model predicts that there is a fixed ratio between the number of neutrinos and the number of photons in the cosmic microwave background. If the total mass of all three types of neutrinos exceeded an average of per neutrino, there would be so much mass in the universe that it would collapse. This limit can be circumvented by assuming that the neutrino is unstable, but there are limits within the Standard Model that make this difficult. A much more stringent constraint comes from a careful analysis of cosmological data, such as the cosmic microwave background radiation, galaxy surveys, and the Lyman-alpha forest. Analysis of data from the WMAP microwave space telescope found that the sum of the masses of the three neutrino species must be less than . In 2018, the Planck collaboration published a stronger bound of , which was derived by combining their CMB total intensity, polarization and gravitational lensing observations with baryon-acoustic oscillation measurements from galaxy surveys and supernova measurements from Pantheon. A 2021 reanalysis that adds redshift space distortion measurements from the SDSS-IV eBOSS survey gets an even tighter upper limit of . However, several ground-based telescopes with similarly sized error bars as Planck prefer higher values for the neutrino mass sum, indicating some tension in the data sets.\nThe Nobel prize in Physics 2015 was awarded to Takaaki Kajita and Arthur B. McDonald for their experimental discovery of neutrino oscillations, which demonstrates that neutrinos have mass.\nIn 1998, research results at the Super-Kamiokande neutrino detector determined that neutrinos can oscillate from one flavor to another, which requires that they must have a nonzero mass. While this shows that neutrinos have mass, the absolute neutrino mass scale is still not known. This is because neutrino oscillations are sensitive only to the difference in the squares of the masses. As of 2020, the best-fit value of the difference of the squares of the masses of mass eigenstates 1 and 2 is , while for eigenstates 2 and 3 it is . Since |\u0394\"m\"322| is the difference of two squared masses, at least one of them must have a value that is at least the square root of this value. Thus, there exists at least one neutrino mass eigenstate with a mass of at least .\nA number of efforts are under way to directly determine the absolute neutrino mass scale in laboratory experiments, especially using nuclear beta decay. Upper limits on the effective electron neutrino masses come from beta decays of tritium. The Mainz Neutrino Mass Experiment set an upper limit of \"m\" &lt; at 95% confidence level. Since June\u00a02018 the KATRIN experiment searches for a mass between and in tritium decays. An upper limit of \"m\"\u03bd &lt; at 90% CL was set by KATRIN from 259 days of measurement.\nOn 31 May 2010, OPERA researchers observed the first tau neutrino candidate event in a muon neutrino beam, the first time this transformation in neutrinos had been observed, providing further evidence that they have mass.\nIf the neutrino is a Majorana particle, the mass may be calculated by finding the half-life of neutrinoless double-beta decay of certain nuclei. The current lowest upper limit on the Majorana mass of the neutrino has been set by KamLAND-Zen: .\nChirality.\nExperimental results show that within the margin of error, all produced and observed neutrinos have left-handed helicities (spins antiparallel to momenta), and all antineutrinos have right-handed helicities. In the massless limit, that means that only one of two possible chiralities is observed for either particle. These are the only chiralities included in the Standard Model of particle interactions.\nIt is possible that their counterparts (right-handed neutrinos and left-handed antineutrinos) simply do not exist. If they \"do\" exist, their properties are substantially different from observable neutrinos and antineutrinos. It is theorized that they are either very heavy (on the order of GUT scale\u2014see \"Seesaw mechanism\"), do not participate in weak interaction (so-called \"sterile neutrinos\"), or both.\nThe existence of nonzero neutrino masses somewhat complicates the situation. Neutrinos are produced in weak interactions as chirality eigenstates. Chirality of a massive particle is not a constant of motion; helicity is, but the chirality operator does not share eigenstates with the helicity operator. Free neutrinos propagate as mixtures of left- and right-handed helicity states, with mixing amplitudes on the order of \u00a0. This does not significantly affect the experiments, because neutrinos involved are nearly always ultrarelativistic, and thus mixing amplitudes are vanishingly small. Effectively, they travel so quickly and time passes so slowly in their rest-frames that they do not have enough time to change over any observable path. For example, most solar neutrinos have energies on the order of to ; consequently, the fraction of neutrinos with \"wrong\" helicity among them cannot exceed .\nGSI anomaly.\nAn unexpected series of experimental results for the rate of decay of heavy highly charged radioactive ions circulating in a storage ring has provoked theoretical activity in an effort to find a convincing explanation. The observed phenomenon is known as the GSI anomaly, as the storage ring is a facility at the GSI Helmholtz Centre for Heavy Ion Research in Darmstadt, Germany.\nThe rates of weak decay of two radioactive species with half-lives of about 40\u00a0seconds and 200\u00a0seconds were found to have a significant oscillatory modulation, with a period of about 7\u00a0seconds. As the decay process produces an electron neutrino, some of the suggested explanations for the observed oscillation rate propose new or altered neutrino properties. Ideas related to flavor oscillation met with skepticism. A later proposal is based on differences between neutrino mass eigenstates.\nSources.\nArtificial.\nReactor neutrinos.\nNuclear reactors are the major source of human-generated neutrinos. The majority of energy in a nuclear reactor is generated by fission (the four main fissile isotopes in nuclear reactors are [&lt;noinclude /&gt;[uranium-235|U]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[uranium-238|U]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[plutonium-239|Pu]&lt;noinclude /&gt;] and [&lt;noinclude /&gt;[plutonium-241|Pu]&lt;noinclude /&gt;]), the resultant neutron-rich daughter nuclides rapidly undergo additional beta decays, each converting one neutron to a proton and an electron and releasing an electron antineutrino. Including these subsequent decays, the average nuclear fission releases about of energy, of which roughly 95.5% remains in the core as heat, and roughly 4.5% (or about ) is radiated away as antineutrinos. For a typical nuclear reactor with a thermal power of , the total power production from fissioning atoms is actually , of which is radiated away as antineutrino radiation and never appears in the engineering. This is to say, of fission energy is \"lost\" from this reactor and does not appear as heat available to run turbines, since antineutrinos penetrate all building materials practically without interaction.\nThe antineutrino energy spectrum depends on the degree to which the fuel is burned (plutonium-239 fission antineutrinos on average have slightly more energy than those from uranium-235 fission), but in general, the \"detectable\" antineutrinos from fission have a peak energy between about 3.5 and , with a maximum energy of about . There is no established experimental method to measure the flux of low-energy antineutrinos, though experiments to demonstrate the capacity of low-energy neutrino detection via the threshold-less CE\u03bdNS interaction are ongoing. Only antineutrinos with an energy above threshold of can trigger inverse beta decay and thus be unambiguously identified (see \"\" below).\nAn estimated 3% of all antineutrinos from a nuclear reactor carry an energy above that threshold. Thus, an average nuclear power plant may generate over antineutrinos per second above the threshold, but also a much larger number (97% / 3% \u2248 30 times this number) below the energy threshold; these lower-energy antineutrinos are invisible to present detector technology.\nAccelerator neutrinos.\nSome particle accelerators have been used to make neutrino beams. The technique is to collide protons with a fixed target, producing charged pions or kaons. These unstable particles are then magnetically focused into a long tunnel where they decay while in flight. Because of the relativistic boost of the decaying particle, the neutrinos are produced as a beam rather than isotropically. Efforts to design an accelerator facility where neutrinos are produced through muon decays are ongoing. Such a setup is generally known as a \"neutrino factory\".\nCollider neutrinos.\nUnlike other artificial sources, colliders produce both neutrinos and anti-neutrinos of all flavors at very high energies. The first direct observation of collider neutrinos was reported in 2023 by the FASER experiment at the Large Hadron Collider.\nNuclear weapons.\nFred Reines and Clyde Cowan suspected that nuclear weapons produce very large quantities of neutrinos but concluded that short timescale of the blast would make detection impossible. They instead turned to nuclear reactors as a possible source; a fission reactor was recommended as a better alternative by Los Alamos physics division leader J.M.B. Kellogg. Fission weapons produce antineutrinos (from the fission process), and fusion weapons produce both neutrinos (from the fusion process) and antineutrinos (from the initiating fission explosion).\nGeologic.\nNeutrinos are produced together with the natural background radiation. In particular, the decay chains of [&lt;noinclude /&gt;[uranium-238|U]&lt;noinclude /&gt;] and [&lt;noinclude /&gt;[thorium-232|Th]&lt;noinclude /&gt;] isotopes, as well as [&lt;noinclude /&gt;[potassium-40|K]&lt;noinclude /&gt;], include beta decays which emit antineutrinos. These so-called geoneutrinos can provide valuable information on the Earth's interior. A first indication for geoneutrinos was found by the KamLAND experiment in 2005, updated results have been presented by KamLAND, and Borexino. The main background in the geoneutrino measurements are the antineutrinos coming from reactors.\nAtmospheric.\nAtmospheric neutrinos result from the interaction of cosmic rays with atomic nuclei in the Earth's atmosphere, creating showers of particles, many of which are unstable and produce neutrinos when they decay. A collaboration of particle physicists from Tata Institute of Fundamental Research (India), Osaka City University (Japan) and Durham University (UK) recorded the first cosmic ray neutrino interaction in an underground laboratory in Kolar Gold Fields in India in 1965.\nSolar.\nSolar neutrinos originate from the nuclear fusion powering the Sun and other stars.\nThe details of the operation of the Sun are explained by the Standard Solar Model. In short: when four protons fuse to become one helium nucleus, two of them have to convert into neutrons, and each such conversion releases one electron neutrino.\nThe Sun sends enormous numbers of neutrinos in all directions. Each second, about 65 billion () solar neutrinos pass through every square centimeter on the part of the Earth orthogonal to the direction of the Sun. Since neutrinos are insignificantly absorbed by the mass of the Earth, the surface area on the side of the Earth opposite the Sun receives about the same number of neutrinos as the side facing the Sun.\nSupernovae.\nColgate &amp; White (1966) calculated that neutrinos carry away most of the gravitational energy released during the collapse of massive stars, events now categorized as Type\u00a0Ib and Ic and Type\u00a0II supernovae. When such stars collapse, matter densities at the core become so high () that the degeneracy of electrons is not enough to prevent protons and electrons from combining to form a neutron and an electron neutrino. Mann (1997) found a second and more profuse neutrino source is the thermal energy (100\u00a0billion\u00a0kelvins) of the newly formed neutron core, which is dissipated via the formation of neutrino\u2013antineutrino pairs of all flavors.\nColgate and White's theory of supernova neutrino production was confirmed in 1987, when neutrinos from Supernova\u00a01987A were detected. The water-based detectors Kamiokande II and IMB detected 11 and 8\u00a0antineutrinos (lepton number\u00a0=\u00a0\u22121) of thermal origin, respectively, while the scintillator-based Baksan detector found 5\u00a0neutrinos (lepton number\u00a0=\u00a0+1) of either thermal or electron-capture origin, in a burst less than 13\u00a0seconds long. The neutrino signal from the supernova arrived at Earth several hours before the arrival of the first electromagnetic radiation, as expected from the evident fact that the latter emerges along with the shock wave. The exceptionally feeble interaction with normal matter allowed the neutrinos to pass through the churning mass of the exploding star, while the electromagnetic photons were slowed.\nBecause neutrinos interact so little with matter, it is thought that a supernova's neutrino emissions carry information about the innermost regions of the explosion. Much of the \"visible\" light comes from the decay of radioactive elements produced by the supernova shock wave, and even light from the explosion itself is scattered by dense and turbulent gases, and thus delayed. The neutrino burst is expected to reach Earth before any electromagnetic waves, including visible light, gamma rays, or radio waves. The exact time delay of the electromagnetic waves' arrivals depends on the velocity of the shock wave and on the thickness of the outer layer of the star. For a Type\u00a0II supernova, astronomers expect the neutrino flood to be released seconds after the stellar core collapse, while the first electromagnetic signal may emerge hours later, after the explosion shock wave has had time to reach the surface of the star. The SuperNova Early Warning System project uses a network of neutrino detectors to monitor the sky for candidate supernova events; the neutrino signal will provide a useful advance warning of a star exploding in the Milky Way.\nAlthough neutrinos pass through the outer gases of a supernova without scattering, they provide information about the deeper supernova core with evidence that here, even neutrinos scatter to a significant extent. In a supernova core the densities are those of a neutron star (which is expected to be formed in this type of supernova), becoming large enough to influence the duration of the neutrino signal by delaying some neutrinos. The 13-second-long neutrino signal from SN\u00a01987A lasted far longer than it would take for unimpeded neutrinos to cross through the neutrino-generating core of a supernova, expected to be only 3,200\u00a0kilometers in diameter for SN\u00a01987A.\nThe number of neutrinos counted was also consistent with a total neutrino energy of , which was estimated to be nearly all of the total energy of the supernova.\nFor an average supernova, approximately (an octodecillion) neutrinos are released, but the actual number detected at a terrestrial detector formula_1 will be far smaller, at the level of\nformula_2\nwhere formula_3 is the mass of the detector (with e.g. Super Kamiokande having a mass of 50\u00a0kton) and formula_4 is the distance to the supernova.\nHence in practice it will only be possible to detect neutrino bursts from supernovae within or nearby the Milky Way (our own galaxy). In addition to the detection of neutrinos from individual supernovae, it should also be possible to detect the diffuse supernova neutrino background, which originates from all supernovae in the Universe.\nSupernova remnants.\nThe energy of supernova neutrinos ranges from a few to several tens of MeV. The sites where cosmic rays are accelerated are expected to produce neutrinos that are at least one million times more energetic, produced from turbulent gaseous environments left over by supernova explosions: Supernova remnants. The origin of the cosmic rays was attributed to supernovas by Baade and Zwicky; this hypothesis was refined by Ginzburg and Syrovatsky who attributed the origin to supernova remnants, and supported their claim by the crucial remark, that the cosmic ray losses of the Milky Way is compensated, if the efficiency of acceleration in supernova remnants is about 10\u00a0percent. Ginzburg and Syrovatskii's hypothesis is supported by the specific mechanism of \"shock wave acceleration\" happening in supernova remnants, which is consistent with the original theoretical picture drawn by Enrico Fermi, and is receiving support from observational data. The very high-energy neutrinos are still to be seen, but this branch of neutrino astronomy is just in its infancy. The main existing or forthcoming experiments that aim at observing very-high-energy neutrinos from our galaxy are Baikal, AMANDA, IceCube, ANTARES, NEMO and Nestor. Related information is provided by very-high-energy gamma ray observatories, such as VERITAS, HESS and MAGIC. Indeed, the collisions of cosmic rays are supposed to produce charged pions, whose decay give the neutrinos, neutral pions, and gamma rays the environment of a supernova remnant, which is transparent to both types of radiation.\nStill-higher-energy neutrinos, resulting from the interactions of extragalactic cosmic rays, could be observed with the Pierre Auger Observatory or with the dedicated experiment named ANITA.\nBig Bang.\nIt is thought that, just like the cosmic microwave background radiation leftover from the Big Bang, there is a background of low-energy neutrinos in our Universe. In the 1980s it was proposed that these may be the explanation for the dark matter thought to exist in the universe. Neutrinos have one important advantage over most other dark matter candidates: They are known to exist. This idea also has serious problems.\nFrom particle experiments, it is known that neutrinos are very light. This means that they easily move at speeds close to the speed of light. For this reason, dark matter made from neutrinos is termed \"hot dark matter\". The problem is that being fast moving, the neutrinos would tend to have spread out evenly in the universe before cosmological expansion made them cold enough to congregate in clumps. This would cause the part of dark matter made of neutrinos to be smeared out and unable to cause the large galactic structures that we see.\nThese same galaxies and groups of galaxies appear to be surrounded by dark matter that is not fast enough to escape from those galaxies. Presumably this matter provided the gravitational nucleus for formation. This implies that neutrinos cannot make up a significant part of the total amount of dark matter.\nFrom cosmological arguments, relic background neutrinos are estimated to have density of 56\u00a0of\u00a0each type per cubic centimeter and temperature () if they are massless, much colder if their mass exceeds . Although their density is quite high, they have not yet been observed in the laboratory, as their energy is below thresholds of most detection methods, and due to extremely low neutrino interaction cross-sections at sub-eV energies. In contrast, boron-8 solar neutrinos\u2014which are emitted with a higher energy\u2014have been detected definitively despite having a space density that is lower than that of relic neutrinos by some six orders of magnitude.\nDetection.\nNeutrinos are extremely difficult to detect directly, as they do not carry electric charge, which means they do not ionize the materials they pass through. They however carry a Weak charge, and can therefore interact with matter through the Weak interaction, in both charged and neutral current forms. However, given its short range and weak coupling, such interactions are exceedingly rare.\nAntineutrinos were first detected in the 1950s near a nuclear reactor. Reines and Cowan used two targets containing a solution of cadmium chloride in water. Two scintillation detectors were placed next to the cadmium targets. Antineutrinos with an energy above the threshold of caused charged current interactions with the protons in the water, an interaction usually known as inverse beta decay, producing positrons and neutrons. This is very much like decay, where energy is used to convert a proton into a neutron, a positron () and an electron neutrino () is emitted:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nIn the Cowan and Reines experiment, instead of an outgoing neutrino, an incoming antineutrino () from a nuclear reactor interacts with a proton:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nThe resulting positron annihilation with electrons in the detector material created photons with an energy of about . Pairs of photons in coincidence could be detected by the two scintillation detectors above and below the target. The neutrons were captured by cadmium nuclei resulting in gamma rays of about that were detected a few microseconds after the photons from a positron annihilation event.\nSince then, various detection methods have been used. Super Kamiokande is a large volume of water surrounded by photomultiplier tubes that watch for the Cherenkov radiation emitted when an incoming neutrino creates an electron or muon in the water. The Sudbury Neutrino Observatory is similar, but used heavy water as the detecting medium, which uses the same effects, but also allows the additional reaction any-flavor neutrino photo-dissociation of deuterium, resulting in a free neutron which is then detected from gamma radiation after chlorine-capture. Other detectors such as the one used in the Homestake Experiment, have consisted of large volumes of chlorine or gallium which are periodically checked for excesses of argon or germanium, respectively, which are created by electron-neutrinos interacting with the original substance. MINOS used a solid plastic scintillator coupled to photomultiplier tubes, while Borexino uses a liquid pseudocumene scintillator also watched by photomultiplier tubes and the NO\u03bdA detector uses liquid scintillator watched by avalanche photodiodes. The IceCube Neutrino Observatory uses of the Antarctic ice sheet near the South Pole with photomultiplier tubes distributed throughout the volume. Another modern detection method is the The Liquid Argon Time Projection Chamber (LArTPC), which conists of a large volume of liquid argon with a high voltage drift field applied to drift the ionization electrons to a series of charge collection planes, allowing for 3D reconstruction of particle tracks. Several experiments have used this technology, including MicroBooNE, the Short-Baseline Neutrino Detector (SBND), and the upcoming Deep Underground Neutrino Experiment (DUNE).\nMore exotically, some experiments (such as COHERENT and CONUS) leverage the neutral current interaction of neutrinos with a whole nucleus, the Coherent elastic neutrino-nucleus scattering (CE\u03bdNS) interaction, to detect neutrinos below the threshold of inverse beta decay. These experiments, which overwhelmingly use crystal-based detectors very similar to the solid-state detectors in use for direct detection of dark matter experiments, are some of the most sensitive particle detectors in modern physics, boasting thresholds as low as 20\u00a0eV deposited in the detector. This is necessary as the heavier nuclei, selected for the high probability of interaction, will retain very little of the energy in an elastic scattering, being much more massive than the neutrino.\nOther ways neutrinos might affect their environment, such as the MSW effect, do not produce traceable radiation, and are not predicted to be detectable.\nScientific interest.\nNeutrinos' low mass and neutral charge mean they interact exceedingly weakly with other particles and fields. This feature of weak interaction interests scientists because it means neutrinos can be used to probe environments that other radiation (such as light or radio waves) cannot penetrate.\nUsing neutrinos as a probe was first proposed in the mid-20th\u00a0century as a way to detect conditions at the core of the Sun. The solar core cannot be imaged directly because electromagnetic radiation (such as light) is diffused by the great amount and density of matter surrounding the core. On the other hand, neutrinos pass through the Sun with few interactions. Whereas photons emitted from the solar core may require to diffuse to the outer layers of the Sun, neutrinos generated in stellar fusion reactions at the core cross this distance practically unimpeded at nearly the speed of light.\nNeutrinos are also useful for probing astrophysical sources beyond the Solar System because they are the only known particles that are not significantly attenuated by their travel through the interstellar medium. Optical photons can be obscured or diffused by dust, gas, and background radiation. High-energy cosmic rays, in the form of swift protons and atomic nuclei, are unable to travel more than about 100\u00a0megaparsecs due to the Greisen\u2013Zatsepin\u2013Kuzmin limit (GZK cutoff). Neutrinos, in contrast, can travel even greater distances barely attenuated.\nThe galactic core of the Milky Way is fully obscured by dense gas and numerous bright objects. Neutrinos produced in the galactic core might be measurable by Earth-based neutrino telescopes.\nAnother important use of the neutrino is in the observation of supernovae, the explosions that end the lives of highly massive stars. The core collapse phase of a supernova is an extremely dense and energetic event. It is so dense that no known particles are able to escape the advancing core front except for neutrinos. Consequently, supernovae are known to release approximately 99% of their radiant energy in a short (10-second) burst of neutrinos. These neutrinos are a very useful probe for core collapse studies.\nThe rest mass of the neutrino is an important test of cosmological and astrophysical theories. The neutrino's significance in probing cosmological phenomena is as great as any other method, and is thus a major focus of study in astrophysical communities.\nThe study of neutrinos is important in particle physics because neutrinos typically have the lowest rest mass among massive particles (i.e. the lowest non-zero rest mass, i.e. excluding the zero rest mass of photons and gluons), and hence are examples of the lowest-energy massive particles theorized in extensions of the Standard Model of particle physics.\nIn November\u00a02012, American scientists used a particle accelerator to send a coherent neutrino message through 780\u00a0feet of rock. This marks the first use of neutrinos for communication, and future research may permit binary neutrino messages to be sent immense distances through even the densest materials, such as the Earth's core.\nIn July\u00a02018, the IceCube Neutrino Observatory announced that they have traced an extremely-high-energy neutrino that hit their Antarctica-based research station in September\u00a02017 back to its point of origin in the blazar TXS 0506+056 located 3.7\u00a0billion light-years away in the direction of the constellation Orion. This is the first time that a neutrino detector has been used to locate an object in space and that a source of cosmic rays has been identified.\nIn November\u00a02022, the IceCube Neutrino Observatory found evidence of high-energy neutrino emission from NGC 1068, also known as Messier 77, an active galaxy in the constellation Cetus and one of the most familiar and well-studied galaxies to date.\nIn June 2023, astronomers reported using a new technique to detect, for the first time, the release of neutrinos from the galactic plane of the Milky Way galaxy.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21486", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=21486", "title": "Numerical Analysis", "text": ""}
{"id": "21487", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=21487", "title": "Nonplayer characters", "text": ""}
{"id": "21488", "revid": "5846", "url": "https://en.wikipedia.org/wiki?curid=21488", "title": "Nanotechnology", "text": "Technology with features near one nanometer\nNanotechnology is the manipulation of matter with at least one dimension sized from 1 to 100 nanometers (nm). At this scale, commonly known as the nanoscale, surface area and quantum mechanical effects become important in describing properties of matter. This definition of nanotechnology includes all types of research and technologies that deal with these special properties. It is common to see the plural form \"nanotechnologies\" as well as \"nanoscale technologies\" to refer to research and applications whose common trait is scale. An earlier understanding of nanotechnology referred to the particular technological goal of precisely manipulating atoms and molecules for fabricating macroscale products, now referred to as molecular nanotechnology.\nNanotechnology defined by scale includes fields of science such as surface science, organic chemistry, molecular biology, semiconductor physics, energy storage, engineering, microfabrication, and molecular engineering. The associated research and applications range from extensions of conventional device physics to molecular self-assembly, from developing new materials with dimensions on the nanoscale to direct control of matter on the atomic scale.\nNanotechnology may be able to create new materials and devices with diverse applications, such as in nanomedicine, nanoelectronics, agricultural sectors, biomaterials energy production, and consumer products. However, nanotechnology raises issues, including concerns about the toxicity and environmental impact of nanomaterials, and their potential effects on global economics, as well as various doomsday scenarios. These concerns have led to a debate among advocacy groups and governments on whether special regulation of nanotechnology is warranted.\nOrigins.\nThe concepts that seeded nanotechnology were first discussed in 1959 by physicist Richard Feynman in his talk \"There's Plenty of Room at the Bottom\", in which he described the possibility of synthesis via direct manipulation of atoms.\nThe term \"nano-technology\" was first used by Norio Taniguchi in 1974, though it was not widely known. Inspired by Feynman's concepts, K. Eric Drexler used the term \"nanotechnology\" in his 1986 book \"Engines of Creation: The Coming Era of Nanotechnology\", which achieved popular success and helped thrust nanotechnology into the public sphere. In it he proposed the idea of a nanoscale \"assembler\" that would be able to build a copy of itself and of other items of arbitrary complexity with atom-level control. Also in 1986, Drexler co-founded The Foresight Institute to increase public awareness and understanding of nanotechnology concepts and implications.\nThe emergence of nanotechnology as a field in the 1980s occurred through the convergence of Drexler's theoretical and public work, which developed and popularized a conceptual framework, and experimental advances that drew additional attention to the prospects. In the 1980s, two breakthroughs helped to spark the growth of nanotechnology. First, the invention of the scanning tunneling microscope in 1981 enabled visualization of individual atoms and bonds, and was successfully used to manipulate individual atoms in 1989. The microscope's developers Gerd Binnig and Heinrich Rohrer at IBM Zurich Research Laboratory received a Nobel Prize in Physics in 1986. Binnig, Quate and Gerber also invented the analogous atomic force microscope that year.\nSecond, fullerenes (buckyballs) were discovered in 1985 by Harry Kroto, Richard Smalley, and Robert Curl, who together won the 1996 Nobel Prize in Chemistry. C60 was not initially described as nanotechnology; the term was used regarding subsequent work with related carbon nanotubes (sometimes called graphene tubes or Bucky tubes) which suggested potential applications for nanoscale electronics and devices. The discovery of carbon nanotubes is attributed to Sumio Iijima of NEC in 1991, for which Iijima won the inaugural 2008 Kavli Prize in Nanoscience.\nIn the early 2000s, the field garnered increased scientific, political, and commercial attention that led to both controversy and progress. Controversies emerged regarding the definitions and potential implications of nanotechnologies, exemplified by the Royal Society's report on nanotechnology. Challenges were raised regarding the feasibility of applications envisioned by advocates of molecular nanotechnology, which culminated in a public debate between Drexler and Smalley in 2001 and 2003.\nMeanwhile, commercial products based on advancements in nanoscale technologies began emerging. These products were limited to bulk applications of nanomaterials and did not involve atomic control of matter. Some examples include the Silver Nano platform for using silver nanoparticles as an antibacterial agent, nanoparticle-based sunscreens, carbon fiber strengthening using silica nanoparticles, and carbon nanotubes for stain-resistant textiles.\nGovernments moved to promote and fund research into nanotechnology, such as American the National Nanotechnology Initiative, which formalized a size-based definition of nanotechnology and established research funding, and in Europe via the European Framework Programmes for Research and Technological Development.\nBy the mid-2000s scientific attention began to flourish. Nanotechnology roadmaps centered on atomically precise manipulation of matter and discussed existing and projected capabilities, goals, and applications.\nFundamental concepts.\nNanotechnology is the science and engineering of functional systems at the molecular scale. In its original sense, nanotechnology refers to the projected ability to construct items from the bottom up making complete, high-performance products.\nOne nanometer (nm) is one billionth, or 10\u22129, of a meter. By comparison, typical carbon\u2013carbon bond lengths, or the spacing between these atoms in a molecule, are in the range 0.12\u20130.15 nm, and DNA's diameter is around 2\u00a0nm. On the other hand, the smallest cellular life forms, the bacteria of the genus \"Mycoplasma\", are around 200\u00a0nm in length. By convention, nanotechnology is taken as the scale range 1 to 100 nm, following the definition used by the American National Nanotechnology Initiative. The lower limit is set by the size of atoms (hydrogen has the smallest atoms, which have an approximately ,25\u00a0nm kinetic diameter). The upper limit is more or less arbitrary, but is around the size below which phenomena not observed in larger structures start to become apparent and can be made use of. These phenomena make nanotechnology distinct from devices that are merely miniaturized versions of an equivalent macroscopic device; such devices are on a larger scale and come under the description of microtechnology.\nTo put that scale in another context, the comparative size of a nanometer to a meter is the same as that of a marble to the size of the earth.\nTwo main approaches are used in nanotechnology. In the \"bottom-up\" approach, materials and devices are built from molecular components which assemble themselves chemically by principles of molecular recognition. In the \"top-down\" approach, nano-objects are constructed from larger entities without atomic-level control.\nAreas of physics such as nanoelectronics, nanomechanics, nanophotonics and nanoionics have evolved to provide nanotechnology's scientific foundation.\nLarger to smaller: a materials perspective.\nSeveral phenomena become pronounced as system size. These include statistical mechanical effects, as well as quantum mechanical effects, for example, the \"quantum size effect\" in which the electronic properties of solids alter along with reductions in particle size. Such effects do not apply at macro or micro dimensions. However, quantum effects can become significant when nanometer scales. Additionally, physical (mechanical, electrical, optical, etc.) properties change versus macroscopic systems. One example is the increase in surface area to volume ratio altering mechanical, thermal, and catalytic properties of materials. Diffusion and reactions can be different as well. Systems with fast ion transport are referred to as nanoionics. The mechanical properties of nanosystems are of interest in research.\nSimple to complex: a molecular perspective.\nModern synthetic chemistry can prepare small molecules of almost any structure. These methods are used to manufacture a wide variety of useful chemicals such as pharmaceuticals or commercial polymers. This ability raises the question of extending this kind of control to the next-larger level, seeking methods to assemble single molecules into supramolecular assemblies consisting of many molecules arranged in a well-defined manner.\nThese approaches utilize the concepts of molecular self-assembly and/or supramolecular chemistry to automatically arrange themselves into a useful conformation through a bottom-up approach. The concept of molecular recognition is important: molecules can be designed so that a specific configuration or arrangement is favored due to non-covalent intermolecular forces. The Watson\u2013Crick basepairing rules are a direct result of this, as is the specificity of an enzyme targeting a single substrate, or the specific folding of a protein. Thus, components can be designed to be complementary and mutually attractive so that they make a more complex and useful whole.\nSuch bottom-up approaches should be capable of producing devices in parallel and be much cheaper than top-down methods, but could potentially be overwhelmed as the size and complexity of the desired assembly increases. Most useful structures require complex and thermodynamically unlikely arrangements of atoms. Nevertheless, many examples of self-assembly based on molecular recognition in exist in biology, most notably Watson\u2013Crick basepairing and enzyme-substrate interactions.\nMolecular nanotechnology: a long-term view.\n \nMolecular nanotechnology, sometimes called molecular manufacturing, concerns engineered nanosystems (nanoscale machines) operating on the molecular scale. Molecular nanotechnology is especially associated with molecular assemblers, machines that can produce a desired structure or device atom-by-atom using the principles of mechanosynthesis. Manufacturing in the context of productive nanosystems is not related to conventional technologies used to manufacture nanomaterials such as carbon nanotubes and nanoparticles.\nWhen Drexler independently coined and popularized the term \"nanotechnology\", he envisioned manufacturing technology based on molecular machine systems. The premise was that molecular-scale biological analogies of traditional machine components demonstrated molecular machines were possible: biology was full of examples of sophisticated, stochastically optimized biological machines.\nDrexler and other researchers have proposed that advanced nanotechnology ultimately could be based on mechanical engineering principles, namely, a manufacturing technology based on the mechanical functionality of these components (such as gears, bearings, motors, and structural members) that would enable programmable, positional assembly to atomic specification. The physics and engineering performance of exemplar designs were analyzed in Drexler's book \"Nanosystems: Molecular Machinery, Manufacturing, and Computation\".\nIn general, assembling devices on the atomic scale requires positioning atoms on other atoms of comparable size and stickiness. Carlo Montemagno's view is that future nanosystems will be hybrids of silicon technology and biological molecular machines. Richard Smalley argued that mechanosynthesis was impossible due to difficulties in mechanically manipulating individual molecules.\nThis led to an exchange of letters in the American Chemical Society publication \"Chemical &amp; Engineering News\" in 2003. Though biology clearly demonstrates that molecular machines are possible, non-biological molecular machines remained in their infancy. Alex Zettl and colleagues at Lawrence Berkeley Laboratories and UC Berkeley constructed at least three molecular devices whose motion is controlled via changing voltage: a nanotube nanomotor, a molecular actuator, and a nanoelectromechanical relaxation oscillator.\nHo and Lee at Cornell University in 1999 used a scanning tunneling microscope to move an individual carbon monoxide molecule (CO) to an individual iron atom (Fe) sitting on a flat silver crystal and chemically bound the CO to the Fe by applying a voltage.\nResearch.\nNanomaterials.\nMany areas of science develop or study materials having unique properties arising from their nanoscale dimensions.\nBottom-up approaches.\nThe bottom-up approach seeks to arrange smaller components into more complex assemblies.\nTop-down approaches.\nThese seek to create smaller devices by using larger ones to direct their assembly.\nFunctional approaches.\nFunctional approaches seek to develop useful components without regard to how they might be assembled.\nSpeculative.\nThese subfields seek to anticipate what inventions nanotechnology might yield, or attempt to propose an agenda along which inquiry could progress. These often take a big-picture view, with more emphasis on societal implications than engineering details.\nDimensionality in nanomaterials.\nNanomaterials can be classified in 0D, 1D, 2D and 3D nanomaterials. Dimensionality plays a major role in determining the characteristic of nanomaterials including physical, chemical, and biological characteristics. With the decrease in dimensionality, an increase in surface-to-volume ratio is observed. This indicates that smaller dimensional nanomaterials have higher surface area compared to 3D nanomaterials. Two dimensional (2D) nanomaterials have been extensively investigated for electronic, biomedical, drug delivery and biosensor applications.\nTools and techniques.\nScanning microscopes.\nThe atomic force microscope (AFM) and the scanning tunneling microscope (STM) are two versions of scanning probes that are used for nano-scale observation. Other types of scanning probe microscopy have much higher resolution, since they are not limited by the wavelengths of sound or light.\nThe tip of a scanning probe can also be used to manipulate nanostructures (positional assembly). Feature-oriented scanning may be a promising way to implement these nano-scale manipulations via an automatic algorithm. However, this is still a slow process because of low velocity of the microscope.\nThe top-down approach anticipates nanodevices that must be built piece by piece in stages, much as manufactured items are made. Scanning probe microscopy is an important technique both for characterization and synthesis. Atomic force microscopes and scanning tunneling microscopes can be used to look at surfaces and to move atoms around. By designing different tips for these microscopes, they can be used for carving out structures on surfaces and to help guide self-assembling structures. By using, for example, feature-oriented scanning approach, atoms or molecules can be moved around on a surface with scanning probe microscopy techniques.\nLithography.\nVarious techniques of lithography, such as optical lithography, X-ray lithography, dip pen lithography, electron beam lithography or nanoimprint lithography offer top-down fabrication techniques where a bulk material is reduced to a nano-scale pattern.\nAnother group of nano-technological techniques include those used for fabrication of nanotubes and nanowires, those used in semiconductor fabrication such as deep ultraviolet lithography, electron beam lithography, focused ion beam machining, nanoimprint lithography, atomic layer deposition, and molecular vapor deposition, and further including molecular self-assembly techniques such as those employing di-block copolymers.\nBottom-up.\nIn contrast, bottom-up techniques build or grow larger structures atom by atom or molecule by molecule. These techniques include chemical synthesis, self-assembly and positional assembly. Dual-polarization interferometry is one tool suitable for characterization of self-assembled thin films. Another variation of the bottom-up approach is molecular-beam epitaxy or MBE. Researchers at Bell Telephone Laboratories including John R. Arthur. Alfred Y. Cho, and Art C. Gossard developed and implemented MBE as a research tool in the late 1960s and 1970s. Samples made by MBE were key to the discovery of the fractional quantum Hall effect for which the 1998 Nobel Prize in Physics was awarded. MBE lays down atomically precise layers of atoms and, in the process, build up complex structures. Important for research on semiconductors, MBE is also widely used to make samples and devices for the newly emerging field of spintronics.\nTherapeutic products based on responsive nanomaterials, such as the highly deformable, stress-sensitive transfersome vesicles, are approved for human use in some countries.\nApplications.\nAs of August 21, 2008, the Project on Emerging Nanotechnologies estimated that over 800 manufacturer-identified nanotech products were publicly available, with new ones hitting the market at a pace of 3\u20134 per week. Most applications are \"first generation\" passive nanomaterials that includes titanium dioxide in sunscreen, cosmetics, surface coatings, and some food products; Carbon allotropes used to produce gecko tape; silver in food packaging, clothing, disinfectants, and household appliances; zinc oxide in sunscreens and cosmetics, surface coatings, paints and outdoor furniture varnishes; and cerium oxide as a fuel catalyst.\nIn the electric car industry, single wall carbon nanotubes (SWCNTs) address key lithium-ion battery challenges, including energy density, charge rate, service life, and cost. SWCNTs connect electrode particles during charge/discharge process, preventing battery premature degradation. Their exceptional ability to wrap active material particles enhanced electrical conductivity and physical properties, setting them apart multi-walled carbon nanotubes and carbon black.\nFurther applications allow tennis balls to last longer, golf balls to fly straighter, and bowling balls to become more durable. Trousers and socks have been infused with nanotechnology to last longer and lower temperature in the summer. Bandages are infused with silver nanoparticles to heal cuts faster. Video game consoles and personal computers may become cheaper, faster, and contain more memory thanks to nanotechnology. Also, to build structures for on chip computing with light, for example on chip optical quantum information processing, and picosecond transmission of information.\nNanotechnology may have the ability to make existing medical applications cheaper and easier to use in places like the doctors' offices and at homes. Cars use nanomaterials in such ways that car parts require fewer metals during manufacturing and less fuel to operate in the future.\nNanoencapsulation involves the enclosure of active substances within carriers. Typically, these carriers offer advantages, such as enhanced bioavailability, controlled release, targeted delivery, and protection of the encapsulated substances. In the medical field, nanoencapsulation plays a significant role in drug delivery. It facilitates more efficient drug administration, reduces side effects, and increases treatment effectiveness. Nanoencapsulation is particularly useful for improving the bioavailability of poorly water-soluble drugs, enabling controlled and sustained drug release, and supporting the development of targeted therapies. These features collectively contribute to advancements in medical treatments and patient care.\nNanotechnology may play role in tissue engineering. When designing scaffolds, researchers attempt to mimic the nanoscale features of a cell's microenvironment to direct its differentiation down a suitable lineage. For example, when creating scaffolds to support bone growth, researchers may mimic osteoclast resorption pits.\nResearchers used DNA origami-based nanobots capable of carrying out logic functions to target drug delivery in cockroaches.\nA nano bible (a .5mm2 silicon chip) was created by the Technion in order to increase youth interest in nanotechnology.\nImplications.\nOne concern is the effect that industrial-scale manufacturing and use of nanomaterials will have on human health and the environment, as suggested by nanotoxicology research. For these reasons, some groups advocate that nanotechnology be regulated. However, regulation might stifle scientific research and the development of beneficial innovations. Public health research agencies, such as the National Institute for Occupational Safety and Health research potential health effects stemming from exposures to nanoparticles.\nNanoparticle products may have unintended consequences. Researchers have discovered that bacteriostatic silver nanoparticles used in socks to reduce foot odor are released in the wash. These particles are then flushed into the wastewater stream and may destroy bacteria that are critical components of natural ecosystems, farms, and waste treatment processes.\nPublic deliberations on risk perception in the US and UK carried out by the Center for Nanotechnology in Society found that participants were more positive about nanotechnologies for energy applications than for health applications, with health applications raising moral and ethical dilemmas such as cost and availability.\nExperts, including director of the Woodrow Wilson Center's Project on Emerging Nanotechnologies David Rejeski, testified that commercialization depends on adequate oversight, risk research strategy, and public engagement. As of 206 Berkeley, California was the only US city to regulate nanotechnology.\nHealth and environmental concerns.\nInhaling airborne nanoparticles and nanofibers may contribute to pulmonary diseases, e.g. fibrosis. Researchers found that when rats breathed in nanoparticles, the particles settled in the brain and lungs, which led to significant increases in biomarkers for inflammation and stress response and that nanoparticles induce skin aging through oxidative stress in hairless mice.\nA two-year study at UCLA's School of Public Health found lab mice consuming nano-titanium dioxide showed DNA and chromosome damage to a degree \"linked to all the big killers of man, namely cancer, heart disease, neurological disease and aging\".\nA \"Nature Nanotechnology\" study suggested that some forms of carbon nanotubes could be as harmful as asbestos if inhaled in sufficient quantities. Anthony Seaton of the Institute of Occupational Medicine in Edinburgh, Scotland, who contributed to the article on carbon nanotubes said \"We know that some of them probably have the potential to cause mesothelioma. So those sorts of materials need to be handled very carefully.\" In the absence of specific regulation forthcoming from governments, Paull and Lyons (2008) have called for an exclusion of engineered nanoparticles in food. A newspaper article reports that workers in a paint factory developed serious lung disease and nanoparticles were found in their lungs.\nRegulation.\nCalls for tighter regulation of nanotechnology have accompanied a debate related to human health and safety risks. Some regulatory agencies cover some nanotechnology products and processes \u2013 by \"bolting on\" nanotechnology to existing regulations \u2013 leaving clear gaps. Davies proposed a road map describing steps to deal with these shortcomings.\nAndrew Maynard, chief science advisor to the Woodrow Wilson Center's Project on Emerging Nanotechnologies, reported insufficient funding for human health and safety research, and as a result inadequate understanding of human health and safety risks. Some academics called for stricter application of the precautionary principle, slowing marketing approval, enhanced labelling and additional safety data.\nA Royal Society report identified a risk of nanoparticles or nanotubes being released during disposal, destruction and recycling, and recommended that \"manufacturers of products that fall under extended producer responsibility regimes such as end-of-life regulations publish procedures outlining how these materials will be managed to minimize possible human and environmental exposure\".\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21489", "revid": "51010305", "url": "https://en.wikipedia.org/wiki?curid=21489", "title": "NetHack", "text": "1987 text-based roguelike video game\nNetHack is an open source single-player roguelike video game, first released in 1987 and maintained by the NetHack DevTeam. The game is a fork of the 1984 game \"Hack\", itself inspired by the 1980 game \"Rogue\". The player takes the role of one of several pre-defined character classes to descend through multiple dungeon floors, fighting monsters and collecting treasure, to recover the \"Amulet of Yendor\" at the lowest floor and then escape.\nAs an exemplar of the traditional \"roguelike\" game, \"NetHack\" features turn-based, grid-based hack and slash and dungeon crawling gameplay, procedurally generated dungeons and treasure, and permadeath, requiring the player to restart the game anew should the player character die. The game uses simple ASCII graphics by default so as to display readily on a wide variety of computer displays, but can use curses with box-drawing characters, as well as substitute graphical tilesets on machines with graphics. While \"Rogue\", \"Hack\" and other earlier roguelikes stayed true to a high fantasy setting, \"NetHack\" introduced humorous and anachronistic elements over time, including popular cultural reference to works such as \"Discworld\" and \"Raiders of the Lost Ark\".\nIt is identified as one of the \"major roguelikes\" by John Harris. Comparing it with \"Rogue\", \"Engadget\"'s Justin Olivetti wrote that it took its exploration aspect and \"made it far richer with an encyclopedia of objects, a larger vocabulary, a wealth of pop culture mentions, and a puzzler's attitude.\" In 2000, \"Salon\" described it as \"one of the finest gaming experiences the computing world has to offer\".\nGameplay.\nBefore starting a game, players choose their character's race, role, sex, and alignment, or allow the game to assign the attributes randomly. There are traditional fantasy roles such as knight, wizard, rogue, and priest; but there are also unusual roles, including archaeologist, tourist, and caveman. The player character's role and alignment dictate which deity the character serves and is supported by in the game, \"how other monsters react toward you\", as well as character skills and attributes.\nAfter the player character is created, the main objective is introduced. To win the game, the player must retrieve the Amulet of Yendor, found at the lowest level of the dungeon, and offer it to their deity. Successful completion of this task rewards the player with the gift of immortality, and the player is said to \"ascend\", attaining the status of demigod. Along the path to the amulet, a number of sub-quests must be completed, including one class-specific quest.\nThere are three major antagonists in NetHack: the Luciferesque god Moloch, who stole the Amulet of Yendor from the creator god Marduk; the high priest (or priestess) of Moloch, who holds the Amulet of Yendor; and the most prominent antagonist, the Wizard of Yendor, who will stalk the player throughout the rest of the game after the first encounter by resurrecting and attacking them periodically. The game's final bosses in the Astral Plane are the Riders: three of the Four Horsemen of the Apocalypse, Death, Famine and Pestilence. It is often proposed that the player character represents the fourth horseman, War.\nThe player's character is, unless they opt not to be, accompanied by a pet animal, typically a kitten or little dog, although knights begin with a saddled pony. Pets grow from fighting, and they can be changed by various means. Most of the other monsters may also be tamed using magic or food.\nDungeon levels.\n\"NetHack\"'s dungeon spans about fifty primary levels, most of which are procedurally generated when the player character enters them for the first time. A typical level contains a way \"up\" and \"down\" to other levels. These may be stairways, ladders, trapdoors, etc. Levels also contain several \"rooms\" joined by corridors. These rooms are randomly generated rectangles (as opposed to the linear corridors) and may contain features such as altars, shops, fountains, traps, thrones, pools of water, and sinks based on the randomly generated features of the room. Some specific levels follow one of many fixed designs or contain fixed elements. Later versions of the game added special branches of dungeon levels. These are optional routes that may feature more challenging monsters but can reward more desirable treasure to complete the main dungeon. Levels, once generated, persist throughout a single game, in contrast to the non-persistent levels in \"Moria\"-style games.\nItems and tools.\n\"NetHack\" features a variety of items: weapons (melee or ranged), armor to protect the player, scrolls and spellbooks to read, potions to quaff, wands, rings, amulets, and an assortment of tools, such as keys and lamps.\n\"NetHack\"'s identification of items is almost identical to \"Rogue\"'s. For example, a newly discovered potion may be referred to as a \"pink potion\" with no other clues as to its identity. Players can perform a variety of actions and tricks to deduce, or at least narrow down, the identity of the potion. The most obvious is the somewhat risky tactic of simply drinking it. All items of a certain type will have the same description. For instance, all \"scrolls of enchant weapon\" may be labeled \"TEMOV\", and once one has been identified, all \"scrolls of enchant weapon\" found later will be labeled unambiguously as such. Starting a new game will scramble the items' descriptions again, so the \"silver ring\" that is a \"ring of levitation\" in one game might be a \"ring of hunger\" in another.\nBlessings and curses.\nAs in many other roguelike games, all items in \"NetHack\" are either \"blessed\", \"uncursed\", or \"cursed\". The majority of items are found uncursed, but the blessed or cursed status of an item is unknown until it is identified or detected through other means. Such statuses can be changed (blessed to uncursed, uncursed to cursed, and vice versa) depending on player interaction.\nGenerally, a blessed item will be more powerful than an uncursed item, and a cursed item will be less powerful, with the added disadvantage that once it has been equipped by the player, it cannot be easily unequipped. Where an object would bestow an effect upon the character, a curse will generally make the effect harmful, or increase the amount of harm done. However, there are very specific exceptions. For example, drinking a cursed \"potion of gain level\" will make the character literally rise through the ceiling to the level above, instead of gaining an experience level.\nCharacter death.\nAs in other roguelike games, \"NetHack\" features permadeath: expired characters cannot be revived.\nAlthough \"NetHack\" can be completed without any artificial limitations, experienced players can attempt \"conducts\" for an additional challenge. These are voluntary restrictions on actions taken, such as using no wishes, following a vegetarian or vegan diet, or even killing no monsters. While conducts are generally tracked by the game and are displayed at death or ascension, unofficial conducts are practiced within the community.\nWhen a player dies, the cause of death and score is created and added to the list where the player's character is ranked against other previous characters. The prompt \"Do you want your possessions identified?\" is given by default at the end of any game, allowing the player to learn any unknown properties of the items in their inventory at death. The player's attributes (such as resistances, luck, and others), conduct (usually self-imposed challenges, such as playing as an atheist or a vegetarian), and a tally of creatures killed, may also be displayed.\nThe game sporadically saves a level on which a character has died and then integrates that level into a later game. This is done via \"bones files\", which are saved on the computer hosting the game. A player using a publicly hosted copy of the game can thus encounter the remains and possessions of many other players, although many of these possessions may have become cursed.\nBecause of the numerous ways that a player-character could die between a combination of their own actions as well as from reactions from the game's interacting systems, players frequently refer to untimely deaths as \"Yet Another Stupid Death\" (YASD). Such deaths are considered part of learning to play \"NetHack\" as to avoid conditions where the same death may happen again.\n\"NetHack\" does allow players to save the game so that one does not have to complete the game in one session, but on opening a new game, the previous save file is subsequently wiped as to enforce the permadeath option. One option some players use is to make a backup copy of the save game file before playing a game, and, should their character die, restoring from the copied version, a practice known as \"save scumming\". Additionally, players can also manipulate the \"bones files\" in a manner not intended by the developers. While these help the player to learn the game and get around limits of permadeath, both are considered forms of cheating the game.\nCulture around spoilers.\n\"NetHack\" is largely based on discovering secrets and tricks during gameplay. It can take years for one to become well-versed in them, and even experienced players routinely discover new ones. A number of \"NetHack\" fan sites and discussion forums offer lists of game secrets known as \"spoilers\".\nInterface.\n\"NetHack\" was originally created with only a simple ASCII text-based user interface, although the option to use something more elaborate was added later in its development. Interface elements such as the environment, entities, and objects are represented by arrangements of ASCII or Extended ASCII glyphs, \"DECgraphics\", or \"IBMgraphics\" mode. In addition to the environment, the interface also displays character and situational information.\nA detailed example:\nThe player (the '@' sign, a wizard in this case) has entered the level via the stairs (the '&lt;' sign) and killed a few monsters, leaving their corpses (the '%' signs) behind. Exploring, the player has uncovered three rooms joined by corridors (the '#' signs): one with an altar (the '_' sign), another empty, and the final one (that the player is currently in) containing a potion (the '!' sign) and chest (the '(' sign). The player has just moved onto a square containing a silver ring. Parts of the level are still unexplored (probably accessible through the door to the west (the '+' sign)) and the player has yet to find the downstairs (a '&gt;' sign) to the next level.\nApart from the original termcap interface shown above, there are other interfaces that replace standard screen representations with two-dimensional images, or tiles, collectively known as \"tiles mode\". Graphic interfaces of this kind have been successfully implemented on the Amiga, the X Window System, the Microsoft Windows GUI, the Qt toolkit, and the GNOME libraries.\nEnhanced graphical options also exist, such as the isometric perspective of \"Falcon's Eye\" and \"Vulture's Eye\", or the three-dimensional rendering that noegnud offers. \"Vulture's Eye\" is a fork of the now defunct Falcon's Eye project. \"Vulture's Eye\" adds additional graphics, sounds, bug fixes and performance enhancements and is under active development in an open collaborative environment.\nHistory and development.\n\"NetHack\" is a software derivative of \"Hack\", which itself was inspired by \"Rogue\". \"Hack\" was created by students Jay Fenlason, Kenny Woodland, Mike Thome, and Jonathan Payne at Lincoln-Sudbury Regional High School as part of a computer class, after seeing and playing \"Rogue\" at the University of California, Berkeley computer labs. The group had tried to get the source code of \"Rogue\" from Glenn Wichman and Michael Toy to build upon, but Wichman and Toy had refused, forcing the students to build the dungeon-creation routines on their own. As such, the game was named \"Hack\" in part for the hack-and-slash gameplay and that the code to generate the dungeons was considered a programming hack. After their classes ended, the students' work on the program also ended, though they had a working game. Fenlason provided the source code to a local USENIX conference, and eventually it was uploaded to USENET newsgroups. The code drew the attention of many players who started working to modify and improve the game as well as port it to other computer systems. \"Hack\" did not have any formal maintainer and while one person was generally recognized to hold the main code to the current version of \"Hack\", many software forks emerged from the unorganized development of the game.\nEventually, Mike Stephenson took on the role as maintainer of the \"Hack\" source code. At this point, he decided to create a new fork of the game, bringing in novel ideas from Izchak Miller, a philosophy professor at University of Pennsylvania, and Janet Walz, another computer hacker. They called themselves the DevTeam and renamed their branch \"NetHack\" since their collaboration work was done over the Internet. They expanded the bestiary and other objects in the game, and drew from other sources outside of the high fantasy setting, such as from \"Discworld\" with the introduction of the tourist character class. Knowing of the multiple forks of \"Hack\" that existed, the DevTeam established a principle that while the game was open source and anyone could create a fork as a new project, only a few select members in the DevTeam could make modifications to the main source repository of the game, so that players could be assured that the DevTeam's release was the legitimate version of \"NetHack\".\nRelease history.\nThe DevTeam's first release of \"NetHack\" was on 28 July 1987.\nThe core DevTeam had expanded with the release of \"NetHack\" 3.0 in July 1989. By that point, they had established a tight-lipped culture, revealing little, if anything, between releases. Owing to the ever-increasing depth and complexity found in each release, the development team enjoys a near-mythical status among fans. This perceived omniscience is captured in the initialism TDTTOE, \"The DevTeam Thinks of Everything\", in that many of the possible emergent gameplay elements that could occur due to the behavior of the complex game systems had already been programmed in by the DevTeam. Since version 3.0, the DevTeam has typically kept to minor bug fix updates, represented by a change in the third version number (e.g. v3.0.1 over v3.0.0), and only releases major updates (v3.1.0 over v3.0.0) when significant new features are added to the game, including support for new platforms. Many of those from the community that helped with the ports to other systems were subsequently invited to be part of the DevTeam as the team's needs grew, with Stephenson remaining the key member currently.\nUpdates to the game were generally regular from around 1987 through 2003, with the DevTeam releasing v3.4.3 in December 2003. Subsequent updates from the DevTeam included new tilesets and compatibility with variants of Mac OS, but no major updates to the game had been made. In the absence of new releases from the developers, several community-made updates to the code and variants developed by fans emerged.\nOn 7 December 2015, version 3.6.0 was released, the first major release in over a decade. While the patch did not add major new gameplay features, the update was designed to prepare the game for expansion in the future, with the DevTeam's patch notes stating: \"This release consists of a series of foundational changes in the team, underlying infrastructure and changes to the approach to game development\". Stephenson said that despite the number of roguelike titles that had emerged since the v3.4.3 release, they saw that \"NetHack\" was still being talked about online in part due to its high degree of portability, and decided to continue its development. According to DevTeam member Paul Winner, they looked to evaluate what community features had been introduced in the prior decade to improve the game while maintaining the necessary balance. The update came shortly after the death of Terry Pratchett, whose \"Discworld\" had been influential on the game, and the new update included a tribute to him. With the v3.6.0 release, \"NetHack\" remains \"one of the oldest games still being developed\".\nA public read-only mirror of \"NetHack\"'s git repository was made available on 10 February 2016. Since v3.6.0, the DevTeam has continued to push updates to the title, with the latest being v3.6.7 on 16 February 2023. Version 3.7.0 is currently in development.\nAs of 2020[ [update]], the official source release supports the following systems: Windows, Linux, macOS, Windows CE, OS/2, Unix (BSD, System V, Solaris, HP-UX), BeOS, and VMS.\nLicensing, ports, and derivative ports.\n\"NetHack\" is released under the NetHack General Public License, which was written in 1989 by Mike Stephenson, patterned after the GNU bison license (which was written by Richard Stallman in 1988). Like the Bison license, and Stallman's later GNU General Public License, the \"NetHack\" license was written to allow the free sharing and modification of the source code under its protection. At the same time, the license explicitly states that the source code is not covered by any warranty, thus protecting the original authors from litigation. The NetHack General Public License is a copyleft software license certified as an open source license by the Open Source Initiative.\nThe NetHack General Public License allows anyone to port the game to a platform not supported by the official DevTeam, provided that they use the same license. Over the years this licensing has led to a large number of ports and internationalized versions in German, Japanese, and Spanish. The license also allows for software forks as long as they are distributed under the same license, except that the creator of a derivative work is allowed to offer warranty protection on the new work. The derivative work is required to indicate the modifications made and the dates of changes. In addition, the source code of the derivative work must be made available, free of charge except for nominal distribution fees. This has also allowed source code forks of \"NetHack\" including \"Slash'EM\", \"UnNetHack\", and \"dNethack\".\nOnline support.\nBugs, humorous messages, stories, experiences, and ideas for the next version are discussed on the Usenet newsgroup rec.games.roguelike.nethack.\nA public server at nethack.alt.org, commonly known as \"NAO\", gives players access to NetHack through a Telnet or SSH interface. A browser-based client is also available on the same site. Ebonhack connects to NAO with a graphical tiles-based interface.\nDuring the whole month of November, the annual /dev/null NetHack Tournament took place every year from 1999 to 2016. The November NetHack Tournament, initially conceived as a one-time tribute to devnull, has taken place each year since 2018. The Junethack Cross-Variant Summer Tournament has taken place annually since 2011.\nNetHack Learning Environment.\nThe Facebook artificial intelligence (AI) research team, along with researchers at the University of Oxford, New York University, the Imperial College London, and University College London, developed an open-source platform called the NetHack Learning Environment, designed to teach AI agents to play \"NetHack\". The base environment is able to maneuver the agent and fight its way through dungeons, but the team seeks community help to build an AI on the complexities of \"NetHack\"'s interconnected systems, using implicit knowledge that comes from player-made resources, thus giving a means for programmers to hook into the environment with additional resources. Facebook's research led the company to pose \"NetHack\" as a grand challenge in AI in June 2021, in part due to the game's permadeath and inability to experiment with the environment without creating a reaction. The competition at the 2021 Conference on Neural Information Processing Systems involved agents of various designs attempting to ascend. None of the agents managed this; the results were ranked by median in-game score, with the highest-ranked agent (Team AutoAscend) using a symbolic (non-machine-learning) design.\nLegacy.\n\"NetHack\" has influenced \"ADOM\", \"Minecraft\", \"Spelunky\", \"Diablo\" and \"Mystery Dungeon\". \"Time\" included \"NetHack\" in its top 100 video games list in 2012. The game was part of the video game exhibit \"Never Alone\", in the Museum of Modern Art's collection, which ran from September 2022 to July 2023.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21490", "revid": "10379", "url": "https://en.wikipedia.org/wiki?curid=21490", "title": "Nylon", "text": "Early synthetic polymer developed as a textile fiber\nNylon is a family of synthetic polymers characterized by amide linkages, typically connecting aliphatic or semi-aromatic groups.\nNylons are generally brownish in color and can possess a soft texture, with some varieties exhibiting a silk-like appearance. As thermoplastics, nylons can be melt-processed into fibers, films, and diverse shapes. The properties of nylons are often modified by blending with a variety of additives.\nNumerous types of nylon are available. One family, designated nylon-XY, is derived from diamines and dicarboxylic acids of carbon chain lengths X and Y, respectively. An important example is nylon-6,6 (). Another family, designated nylon-Z, is derived from aminocarboxylic acids with carbon chain length Z. An example is nylon-[6].\nNylon polymers have extensive commercial applications, including uses in textiles and fibers (such as apparel, flooring and rubber reinforcement), molded components for automotive and electrical equipment, and films (mostly for food packaging).\nHistory.\nDuPont and the invention of nylon.\nResearchers at DuPont began developing cellulose-based fibers, culminating in the synthetic fiber rayon. DuPont's experience with rayon was an important precursor to its development and marketing of nylon.\nDuPont's invention of nylon spanned an eleven-year period, ranging from the initial research program in polymers in 1927 to its announcement in 1938, shortly before the opening of the 1939 New York World's Fair. The project grew from a new organizational structure at DuPont, suggested by Charles Stine in 1927, in which the chemical department would be composed of several small research teams that would focus on \"pioneering research\" in chemistry and would \"lead to practical applications\". Harvard instructor Wallace Hume Carothers was hired to direct the polymer research group. Initially he was allowed to focus on pure research, building on and testing the theories of German chemist Hermann Staudinger. He was very successful, as research he undertook greatly improved the knowledge of polymers and contributed to the science.\nNylon was the first commercially successful synthetic thermoplastic polymer. DuPont began its research project in 1927.\nThe first nylon, nylon 66, was synthesized on February 28, 1935, by Wallace Hume Carothers at DuPont's research facility at the DuPont Experimental Station. In response to Carothers' work, Paul Schlack at IG Farben developed nylon\u00a06, a different molecule based on caprolactam, on January 29, 1938.\nIn the spring of 1930, Carothers and his team had already synthesized two new polymers. The first was neoprene, a synthetic rubber widely used during World War II. The second was an elastic paste that became very strong upon cooling; this would later become nylon. After these discoveries, Carothers' team was made to shift its research from a more pure research approach investigating general polymerization to a more practically focused goal of finding \"one chemical combination that would lend itself to industrial applications\".\nIt was not until the beginning of 1935 that a polymer called \"polymer 6-6\" was finally produced. Carothers' coworker, Washington University alumnus Julian W. Hill had used a cold drawing method to produce a polyester in 1930. This cold drawing method was later used by Carothers in 1935 to fully develop nylon. The first example of nylon (nylon 6.6) was produced on February 28, 1935, at DuPont's research facility at the DuPont Experimental Station. It had all the desired properties of elasticity and strength. However, it also required a complex manufacturing process that would become the basis of industrial production in the future. DuPont obtained a patent for the polymer in September 1938, and quickly achieved a monopoly of the fiber. Carothers died 16 months before the announcement of nylon, therefore he was never able to see his success. The name \"Nylon\" came from the modification of \"norun\" (no run) into a unique name that could be used to market the product but was not trademarked.\nNylon was first used commercially in a nylon-bristled toothbrush in 1938, followed more famously in women's stockings or \"nylons\" which were shown at the 1939 New York World's Fair and first sold commercially in 1940, whereupon they became an instant commercial success with 64 million pairs sold during their first year on the market. During World War II, almost all nylon production was diverted to the military for use in parachutes and parachute cord. Wartime uses of nylon and other plastics greatly increased the market for the new materials.\nThe production of nylon required interdepartmental collaboration between three departments at DuPont: the Department of Chemical Research, the Ammonia Department, and the Department of Rayon. Some of the key ingredients of nylon had to be produced using high pressure chemistry, the main area of expertise of the Ammonia Department. Nylon was considered a \"godsend to the Ammonia Department\", which had been in financial difficulties. The reactants of nylon soon constituted half of the Ammonia Department's sales and helped them come out of the period of the Great Depression by creating jobs and revenue at DuPont.\nDuPont's nylon project demonstrated the importance of chemical engineering in industry, helped create jobs, and furthered the advancement of chemical engineering techniques. In fact, it developed a chemical plant that provided 1800 jobs and used the latest technologies of the time, which are still used as a model for chemical plants today. The ability to acquire a large number of chemists and engineers quickly was a huge contribution to the success of DuPont's nylon project. The first nylon plant was located at Seaford, Delaware, beginning commercial production on December 15, 1939. On October 26, 1995, the Seaford plant was designated a National Historic Chemical Landmark by the American Chemical Society.\nEarly marketing strategies.\nAn important part of nylon's popularity stems from DuPont's marketing strategy. DuPont promoted the fiber to increase demand before the product was available to the general market. Nylon's commercial announcement occurred on October 27, 1938, at the final session of the \"Herald Tribune\"'s yearly \"Forum on Current Problems\", on the site of the approaching New York City world's fair. The \"first man-made organic textile fibre\" which was derived from \"coal, water and air\" and promised to be \"as strong as steel, as fine as the spider's web\" was received enthusiastically by the audience, many of them middle-class women, and made the headlines of most newspapers. Nylon was introduced as part of \"The world of tomorrow\" at the 1939 New York World's Fair and was featured at DuPont's \"Wonder World of Chemistry\" at the Golden Gate International Exposition in San Francisco in 1939. Actual nylon stockings were not shipped to selected stores in the national market until May 15, 1940. However, a limited number were released for sale in Delaware before that. The first public sale of nylon stockings occurred on October 24, 1939, in Wilmington, Delaware. 4,000 pairs of stockings were available, all of which were sold within three hours.\nAnother added bonus to the campaign was that it meant reducing silk imports from Japan, an argument that won over many wary customers. Nylon was even mentioned by President Roosevelt's cabinet, which addressed its \"vast and interesting economic possibilities\" five days after the material was formally announced.\nHowever, the early excitement over nylon also caused problems. It fueled unreasonable expectations that nylon would be better than silk, a miracle fabric as strong as steel that would last forever and never run. Realizing the danger of claims such as \"New Hosiery Held Strong as Steel\" and \"No More Runs\", DuPont scaled back the terms of the original announcement, especially those stating that nylon would possess the strength of steel.\nAlso, DuPont executives marketing nylon as a revolutionary man-made material did not at first realize that some consumers experienced a sense of unease and distrust, even fear, towards synthetic fabrics. A particularly damaging news story, drawing on DuPont's 1938 patent for the new polymer, suggested that one method of producing nylon might be to use cadaverine (pentamethylenediamine), a chemical extracted from corpses. Although scientists asserted that cadaverine was also extracted by heating coal, the public often refused to listen. A woman confronted one of the lead scientists at DuPont and refused to accept that the rumour was not true.\nDuPont changed its campaign strategy, emphasizing that nylon was made from \"coal, air and water\", and started focusing on the personal and aesthetic aspects of nylon, rather than its intrinsic qualities. Nylon was thus domesticated, and attention shifted to the material and consumer aspect of the fiber with slogans like \"If it's nylon, it's prettier, and oh! How fast it dries!\".\nProduction of nylon fabric.\nAfter nylon's nationwide release in 1940, its production ramped up significantly. In that year alone, 1300 tons of the fabric were produced, marking a remarkable start for this innovative material.[8]:\u200a100\u200a The demand for nylon surged, particularly for nylon stockings, which became an instant sensation. During their first year on the market, an astounding 64 million pairs of nylon stockings were sold, reflecting the fabric's rapid integration into daily life and fashion.[8]:\u200a101\u200a Such was the success of nylon that in 1941, just a year after its launch, a second plant was opened in Martinsville, Virginia, to meet the growing demand and ensure a steady supply of this popular fabric. This expansion underscored the profound impact nylon had on the textile industry and its rapid rise to prominence as a versatile and sought-after material.\nWhile nylon was marketed as the durable and indestructible material of the people, it was sold at about one-and-a-half times the price of silk stockings ($4.27 per pound of nylon versus $2.79 per pound of silk). Sales of nylon stockings were strong in part due to changes in women's fashion. As Lauren Olds explains: \"by 1939 [hemlines] had inched back up to the knee, closing the decade just as it started off\". The shorter skirts were accompanied by a demand for stockings that offered fuller coverage without the use of garters to hold them up.\nHowever, as of February 11, 1942, nylon production was redirected from being a consumer material to one used by the military. DuPont's production of nylon stockings and other lingerie stopped, and most manufactured nylon was used to make parachutes and tents for World War II. Although nylon stockings already made before the war could be purchased, they were generally sold on the black market for as high as $20.\nOnce the war ended, the return of nylon was awaited with great anticipation. Although DuPont projected yearly production of 360 million pairs of stockings, there were delays in converting back to consumer rather than wartime production. In 1946, the demand for nylon stockings could not be satisfied, which led to the nylon riots. In one instance, an estimated 40,000 people lined up in Pittsburgh to buy 13,000 pairs of nylons. In the meantime, women cut up nylon tents and parachutes left from the war in order to make blouses and wedding dresses. Between the end of the war and 1952, production of stockings and lingerie used 80% of the world's nylon. DuPont put focus on catering to the civilian demand, and continually expanded its production.\nIntroduction of nylon blends.\nAs pure nylon hosiery was sold in a wider market, problems became apparent. Nylon stockings were found to be fragile, in the sense that the thread often tended to unravel lengthwise, creating 'runs'. People also reported that pure nylon textiles could be uncomfortable due to nylon's lack of absorbency. Moisture stayed inside the fabric near the skin under hot or moist conditions instead of being \"wicked\" away. Nylon fabric could also be itchy and tended to cling and sometimes spark as a result of static electrical charge built up by friction. Also, under some conditions, nylon could degrade, perforating or shredding stockings.147 Scientists explained this as acid hydrolysis resulting from air pollution, attributing it to London smog in 1952, as well as poor air quality in New York and Los Angeles.\nThe solution found to problems with pure nylon fabric was to blend nylon with other existing fibers or polymers such as cotton, polyester, and spandex. This led to the development of a wide array of blended fabrics. The new nylon blends retained the desirable properties of nylon (elasticity, durability, ability to be dyed) and kept clothes prices low and affordable. As of 1950, the New York Quartermaster Procurement Agency (NYQMPA), which developed and tested textiles for the Army and Navy, had committed to developing a wool-nylon blend. They were not the only ones to introduce blends of both natural and synthetic fibers. \"America's Textile Reporter\" referred to 1951 as the \"Year of the blending of the fibres\". Fabric blends included mixes like \"Bunara\" (wool-rabbit-nylon) and \"Casmet\" (wool-nylon-fur). In Britain, in November 1951, the inaugural address of the 198th session of the Royal Society for the Encouragement of Arts, Manufactures and Commerce focused on the blending of textiles.\nDuPont's Fabric Development Department cleverly targeted French fashion designers, supplying them with fabric samples. In 1955, designers such as Coco Chanel, Jean Patou, and Christian Dior showed gowns created with DuPont fibers, and fashion photographer Horst P. Horst was hired to document their use of DuPont fabrics. \"American Fabrics\" credited blends with providing \"creative possibilities and new ideas for fashions which had been hitherto undreamed of.\"\nEtymology.\nDuPont went through an extensive process to generate names for its new product. In 1940, John W. Eckelberry of DuPont stated that the letters \"nyl\" were arbitrary, and the \"on\" was copied from the suffixes of other fibers such as cotton and rayon. A later publication by DuPont (\"Context\", vol.\u00a07, no.\u00a02, 1978) explained that the name was originally intended to be \"No-Run\" (\"run\" meaning \"unravel\") but was modified to avoid making such an unjustified claim. Since the products were not really run-proof, the vowels were swapped to produce \"nuron\", which was changed to \"nilon\" \"to make it sound less like a nerve tonic\". For clarity in pronunciation, the \"i\" was changed to \"y\".\nA persistent urban legend exists that the name is derived from \"New York\" and \"London\"; however, no organization in London was ever involved in the research and production of nylon.\nLonger-term popularity.\nNylon\u2019s popularity soared in the 1940s and 1950s due to its durability and sheerness. In the 1970s, it became more popular due to its flexibility and price.\nIn spite of oil shortages in the 1970s, consumption of nylon textiles continued to grow by 7.5% per year between the 1960s and 1980s. Overall production of synthetic fibers, however, dropped from 63% of the worlds textile production in 1965, to 45% of the world's textile production in early 1970s. The appeal of \"new\" technologies wore off, and nylon fabric \"was going out of style in the 1970s\". Also, consumers became concerned about environmental costs throughout the production cycle: obtaining the raw materials (oil), energy use during production, waste produced during creation of the fiber, and eventual waste disposal of materials that were not biodegradable. \nSynthetic fibers have not dominated the market since the 1950s and 1960s. As of 2020[ [update]], the worldwide production of nylon is estimated at 8.9 million tons.\nAlthough pure nylon has many flaws and is now rarely used, its derivatives have greatly influenced and contributed to society. From scientific discoveries relating to the production of plastics and polymerization, to economic impact during the depression and the changing of women's fashion, nylon was a revolutionary product. The Lunar Flag Assembly, the first flag planted on the moon in a symbolic gesture of celebration, was made of nylon. The flag itself cost $5.50 but had to have a specially designed flagpole with a horizontal bar so that it would appear to \"fly\". One historian describes nylon as \"an object of desire\", comparing the invention to Coca-Cola in the eyes of 20th century consumers.\nChemistry.\nIn common usage, the prefix \"PA\" (polyamide) or the name \"Nylon\" are used interchangeably and are equivalent in meaning.\nThe nomenclature used for nylon polymers was devised during the synthesis of the first simple aliphatic nylons and uses numbers to describe the number of carbons in each monomer unit, including the carbon(s) of the carboxylic acid(s). Subsequent use of cyclic and aromatic monomers required the use of letters or sets of letters. One number after \"PA\" or \"Nylon\" indicates a homopolymer which is \"monadic\" or based on one amino acid (minus H2O) as monomer:\n PA 6 or Nylon 6: [NH\u2212(CH2)5\u2212CO]\"n\" made from \u03b5-caprolactam.\nTwo numbers or sets of letters indicate a \"dyadic\" homopolymer formed from two monomers: one diamine and one dicarboxylic acid. The first number indicates the number of carbons in the diamine. The two numbers should be separated by a comma for clarity, but the comma is often omitted.\n PA or Nylon 6,10 (or 610): [NH\u2212(CH2)6\u2212NH\u2212CO\u2212(CH2)8\u2212CO]\"n\" made from hexamethylenediamine and sebacic acid;\nFor copolymers the comonomers or pairs of comonomers are separated by slashes:\n PA 6/66: [NH\u2212(CH2)6\u2212NH\u2212CO\u2212(CH2)4\u2212CO]\"n\"\u2212[NH\u2212(CH2)5\u2212CO]\"m\" made from caprolactam, hexamethylenediamine and adipic acid;\n PA 66/610: [NH\u2212(CH2)6\u2212NH\u2212CO\u2212(CH2)4\u2212CO]\"n\"\u2212[NH\u2212(CH2)6\u2212NH\u2212CO\u2212(CH2)8\u2212CO]\"m\" made from hexamethylenediamine, adipic acid and sebacic acid.\nThe term polyphthalamide (abbreviated to PPA) is used when 60% or more moles of the carboxylic acid portion of the repeating unit in the polymer chain is composed of a combination of terephthalic acid (TPA) and isophthalic acid (IPA).\nTypes.\nNylon 66 and related heteropolymers.\nNylon 66 and related polyamides are condensation polymers forms from equal parts of diamine and dicarboxylic acids. In the first case, the \"repeating unit\" has the ABAB structure, as also seen in many polyesters and polyurethanes. Since each monomer in this copolymer has the same reactive group on both ends, the direction of the amide bond reverses between each monomer, unlike natural polyamide proteins, which have overall directionality: C\u00a0terminal\u00a0\u2192 N\u00a0terminal. In the second case (so called AA), the repeating unit corresponds to the single monomer.\nWallace Carothers at DuPont patented nylon\u00a066. \nIn the case of nylons that involve reaction of a diamine and a dicarboxylic acid, it is difficult to get the proportions exactly correct, and deviations can lead to chain termination at molecular weights less than a desirable 10,000 daltons. To overcome this problem, a crystalline, solid \"nylon salt\" can be formed at room temperature, using an exact 1:1 ratio of the acid and the base to neutralize each other. The salt is crystallized to purify it and obtain the desired precise stoichiometry. Heated to , the salt reacts to form nylon polymer with the production of water.\nNylon\u00a0510, made from pentamethylene diamine and sebacic acid, was included in the Carothers patent to nylon\u00a066 Nylon 610 is produced similarly using hexamethylene diamine. These materials are more expensive because of the relatively high cost of sebacic acid. Owing to the high hydrocarbon content, nylon 610 is more hydrophobic and finds applications suited for this property, such as bristles.\nExamples of these polymers that are or were commercially available:\nNylon 6 and related homopolymers.\nThese polymers are made from a lactam or amino acid. The synthetic route using lactams (cyclic amides) was developed by Paul Schlack at IG Farben, leading to nylon\u00a06, or polycaprolactam\u2014formed by a ring-opening polymerization. The peptide bond within the caprolactam is broken with the exposed active groups on each side being incorporated into two new bonds as the monomer becomes part of the polymer backbone.\nThe melting point of nylon 6 is lower than the melting point of nylon 66. Homopolymer nylons are derived from one monomer.\nExamples of these polymers that are or were commercially available:\nNylon 1,6.\nNylons can also be synthesized from dinitriles using acid catalysis. For example, this method is applicable for preparation of nylon 1,6 from adiponitrile, formaldehyde and water. Additionally, nylons can be synthesized from diols and dinitriles using this method as well.\nCopolymers.\nIt is easy to make mixtures of the monomers or sets of monomers used to make nylons to obtain copolymers. This lowers crystallinity and can therefore lower the melting point.\nSome copolymers that have been or are commercially available are listed below: \nBlends.\nMost nylon polymers are miscible with each other allowing a range of blends to be made. The two polymers can react with one another by transamidation to form random copolymers.\nCrystallinity.\nAccording to their crystallinity, polyamides can be:\nAccording to this classification, PA66, for example, is an aliphatic semi-crystalline homopolyamide.\nEnvironmental impact.\nAll nylons are susceptible to hydrolysis, especially by strong acids, a reaction essentially the reverse of their synthesis. The molecular weight of nylon products so attacked drops, and cracks form quickly at the affected zones. Lower members of the nylons (such as nylon 6) are affected more than higher members such as nylon 12. This means that nylon parts cannot be used in contact with sulfuric acid for example, such as the electrolyte used in lead\u2013acid batteries.\nWhen being molded, nylon must be dried to prevent hydrolysis in the molding machine barrel since water at high temperatures can also degrade the polymer. The reaction is shown above.\nThe average greenhouse gas footprint of nylon in manufacturing carpets is estimated at 5.43\u00a0kg CO2 equivalent per kg, when produced in Europe. This gives it almost the same carbon footprint as wool, but with greater durability and therefore a lower overall carbon footprint.\nData published by PlasticsEurope indicates for nylon 66 a greenhouse gas footprint of 6.4\u00a0kg CO2 equivalent per kg, and an energy consumption of 138 kJ/kg. When considering the environmental impact of nylon, it is important to consider the use phase.\nVarious nylons break down in fire and form hazardous smoke, and toxic fumes or ash, typically containing hydrogen cyanide. Incinerating nylons to recover the high energy used to create them is usually expensive, so most nylons reach the garbage dumps, decaying slowly. Discarded nylon fabric takes 30\u201340 years to decompose. Nylon used in discarded fishing gear such as fishing nets is a contributor to debris in the ocean. Nylon is a robust polymer and lends itself well to recycling. Much nylon resin is recycled directly in a closed loop at the injection molding machine, by grinding sprues and runners and mixing them with the virgin granules being consumed by the molding machine.\nThe process of recycling nylon is very expensive and difficult, so few companies utilize it while most favor using cheaper, newly made plastics for their products instead. US clothing company Patagonia has products containing recycled nylon and in the mid-2010s invested in Bureo, a company that recycles nylon from used fishing nets to use in sunglasses and skateboards. The Italian company Aquafil also has demonstrated recycling fishing nets lost in the ocean into apparel. Vanden Recycling recycles nylon and other polyamides (PA) and has operations in the UK, Australia, Hong Kong, the UAE, Turkey and Finland.\nNylon is the most popular fiber type in the residential carpet industry today. The US EPA estimates that 9.2% of carpet fiber, backing and padding was recycled in 2018, 17.8% was incinerated in waste-to-energy facilities, and 73% was discarded in landfills. Some of the world's largest carpet and rug companies are promoting \"cradle to cradle\"\u2014the reuse of non-virgin materials including ones not historically recycled\u2014as the industry's pathway forward.\nProperties.\nAbove their melting temperatures, \"T\"m, thermoplastics like nylon are amorphous solids or viscous fluids in which the chains approximate random coils. Below \"T\"m, amorphous regions alternate with regions which are lamellar crystals. The amorphous regions contribute elasticity, and the crystalline regions contribute strength and rigidity. The planar amide (-CO-NH-) groups are very polar, so nylon forms multiple hydrogen bonds among adjacent strands. Because the nylon backbone is so regular and symmetrical, especially if all the amide bonds are in the \"trans\" configuration, nylons often have high crystallinity and make excellent fibers. The amount of crystallinity depends on the details of formation, as well as on the kind of nylon.\nNylon\u00a066 can have multiple parallel strands aligned with their neighboring peptide bonds at coordinated separations of exactly six and four carbons for considerable lengths, so the carbonyl oxygens and amide hydrogens can line up to form interchain hydrogen bonds repeatedly, without interruption (see the figure opposite). Nylon\u00a0510 can have coordinated runs of five and eight carbons. Thus parallel (but not antiparallel) strands can participate in extended, unbroken, multi-chain \u03b2-pleated sheets, a strong and tough supermolecular structure similar to that found in natural silk fibroin and the \u03b2-keratins in feathers. (Proteins have only an amino acid \u03b1-carbon separating sequential -CO-NH- groups.) Nylon\u00a06 will form uninterrupted H-bonded sheets with mixed directionalities, but the \u03b2-sheet wrinkling is somewhat different. The three-dimensional disposition of each alkane hydrocarbon chain depends on rotations about the 109.47\u00b0 tetrahedral bonds of singly bonded carbon atoms.\nWhen extruded into fibers through pores in an industry spinneret, the individual polymer chains tend to align because of viscous flow. If subjected to cold drawing afterwards, the fibers align further, increasing their crystallinity, and the material acquires additional tensile strength. In practice, nylon fibers are most often drawn using heated rolls at high speeds.\nBlock nylon tends to be less crystalline, except near the surfaces due to shearing stresses during formation. Nylon is clear and colorless, or milky, but is easily dyed. Multistranded nylon cord and rope is slippery and tends to unravel. The ends can be melted and fused with a heat source such as a flame or electrode to prevent this.\nNylons are hygroscopic and will absorb or desorb moisture as a function of the ambient humidity. Variations in moisture content have several effects on the polymer. Firstly, the dimensions will change, but more importantly moisture acts as a plasticizer, lowering the glass transition temperature (\"T\"g), and consequently the elastic modulus at temperatures below the \"T\"g\nWhen dry, polyamide is a good electrical insulator. However, polyamide is hygroscopic. The absorption of water will change some of the material's properties such as its electrical resistance. Nylon is less absorbent than wool or cotton.\nThe characteristic features of nylon 66 include:\nOn the other hand, nylon 6 is easy to dye, more readily fades; it has a higher impact resistance, a more rapid moisture absorption, greater elasticity, and elastic recovery.\nNylon clothing tends to be less flammable than cotton and rayon, but nylon fibers may melt and stick to skin.\nUses.\nNylon was first used commercially in a nylon-bristled toothbrush in 1938, followed more famously in women's stockings or \"nylons\" which were shown at the 1939 New York World's Fair and first sold commercially in 1940. Its use increased dramatically during World War II, when the need for fabrics increased dramatically.\nFibers.\nBill Pittendreigh, DuPont, and other individuals and corporations worked diligently during the first few months of World War II to find a way to replace Asian silk and hemp with nylon in parachutes. It was also used to make tires, tents, ropes, ponchos, and other military supplies. It was even used in the production of a high-grade paper for U.S. currency. At the outset of the war, cotton accounted for more than 80% of all fibers used and manufactured, and wool fibers accounted for nearly all of the rest. By August 1945, manufactured fibers had taken a market share of 25%, at the expense of cotton. After the war, because of shortages of both silk and nylon, nylon parachute material was sometimes repurposed to make dresses.\nNylon 6 and 66 fibers are used in carpet manufacture.\nNylon is one kind of fiber used in tire cord. Herman E. Schroeder pioneered application of nylon in tires.\nMolds and resins.\nNylon resins are widely used in the automobile industry especially in the engine compartment.\nMolded nylon is used in hair combs and mechanical parts such as machine screws, gears, gaskets, and other low- to medium-stress components previously cast in metal. Engineering-grade nylon is processed by extrusion, casting, and injection molding. Type 6,6 Nylon 101 is the most common commercial grade of nylon, and Nylon 6 is the most common commercial grade of molded nylon. For use in tools such as spudgers, nylon is available in glass-filled variants which increase structural and impact strength and rigidity, and molybdenum disulfide-filled variants which increase lubricity. Nylon can be used as the matrix material in composite materials, with reinforcing fibers like glass or carbon fiber; such a composite has a higher density than pure nylon. Such thermoplastic composites (25% to 30% glass fiber) are frequently used in car components next to the engine, such as intake manifolds, where the good heat resistance of such materials makes them feasible competitors to metals.\nNylon was used to make the stock of the Remington Nylon 66 rifle. The frame of the modern Glock pistol is made of a nylon composite.\nFood packaging.\nNylon resins are used as a component of food packaging films where an oxygen barrier is needed. Some of the terpolymers based upon nylon are used every day in packaging. Nylon has been used for meat wrappings and sausage sheaths. The high temperature resistance of nylon makes it useful for oven bags.\nFilaments.\nNylon filaments are primarily used in brushes especially toothbrushes and string trimmers. They are also used as monofilaments in fishing line. Nylon 610 and 612 are the most used polymers for filaments.\nIts various properties also make it very useful as a material in additive manufacturing; specifically, as a filament in consumer and professional grade fused deposition modeling 3D printers.\nOther forms.\nNylon resins can be extruded into rods, tubes, and sheets.\nNylon powders are used to powder coat metals. Nylon 11 and nylon 12 are the most widely used.\nIn the mid-1940s, classical guitarist Andr\u00e9s Segovia mentioned the shortage of good guitar strings in the United States, particularly his favorite Pirastro catgut strings, to a number of foreign diplomats at a party, including General Lindeman of the British Embassy. A month later, the General presented Segovia with some nylon strings which he had obtained via some members of the DuPont family. Segovia found that although the strings produced a clear sound, they had a faint metallic timbre which he hoped could be eliminated. Nylon strings were first tried on stage by Olga Coelho in New York in January 1944. In 1946, Segovia and string maker Albert Augustine were introduced by their mutual friend Vladimir Bobri, editor of Guitar Review. On the basis of Segovia's interest and Augustine's past experiments, they decided to pursue the development of nylon strings. DuPont, skeptical of the idea, agreed to supply the nylon if Augustine would endeavor to develop and produce the actual strings. After three years of development, Augustine demonstrated a nylon first string whose quality impressed guitarists, including Segovia, in addition to DuPont. Wound strings, however, were more problematic. Eventually, however, after experimenting with various types of metal and smoothing and polishing techniques, Augustine was also able to produce high quality nylon wound strings.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21491", "revid": "42867806", "url": "https://en.wikipedia.org/wiki?curid=21491", "title": "Nucleus", "text": "Nucleus (pl.: nuclei) is a Latin word for the seed inside a fruit. It most often refers to:\nNucleus may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "21492", "revid": "47125377", "url": "https://en.wikipedia.org/wiki?curid=21492", "title": "Nuclei", "text": ""}
{"id": "21494", "revid": "48646116", "url": "https://en.wikipedia.org/wiki?curid=21494", "title": "Nerd", "text": "Type of person\nA nerd is a person seen as over-intellectual, obsessive, introverted, or lacking social skills. Such a person may spend inordinate amounts of time on unpopular, little-known, or non-mainstream activities, which are generally either highly technical, abstract, or relating to niche topics such as science fiction or fantasy, to the exclusion of more mainstream activities. Additionally, many so-called nerds are described as being shy, quirky, pedantic, and unattractive.\nOriginally derogatory, the term \"nerd\" was a stereotype, but as with other pejoratives, it has been reclaimed and redefined by some as a term of pride and group identity. The term may be considered a synonym for geek.\nEtymology.\nThe first documented appearance of the word \"nerd\" is as the name of a creature in Dr. Seuss's book \"If I Ran the Zoo\" (1950), in which the narrator Gerald McGrew claims that he would collect \"a Nerkle, a Nerd, and a Seersucker too\" for his imaginary zoo. The slang meaning of the term dates to 1951. That year, \"Newsweek\" magazine reported on its popular use as a synonym for \"drip\" or \"square\" in Detroit, Michigan. By the early 1960s, usage of the term had spread throughout the United States, and even as far as Scotland. At some point, the word took on connotations of bookishness and social ineptitude.\nAn alternate spelling, as \"nurd\" or \"gnurd\", also began to appear in the mid-1960s, or early 1970s. Author Philip K. Dick claimed to have coined the \"nurd\" spelling in 1973, but its first recorded use appeared in a 1965 student publication at Rensselaer Polytechnic Institute (RPI). Oral tradition there holds that the word is derived from \"knurd\" (\"drunk\" spelled backward), which was used to describe people who studied rather than partied. The term \"gnurd\" (spelled with the \"g\") was in use at the Massachusetts Institute of Technology (MIT) by the year 1965. The term \"nurd\" was also in use at the Massachusetts Institute of Technology as early as 1971.\nAccording to \"Online Etymology Dictionary\", the word is an alteration of the 1940s term \"nert\" (meaning \"stupid or crazy person\"), which is in itself an alteration of \"nut\" (nutcase).\nThe term was popularized in the 1970s by its heavy use in the sitcom \"Happy Days\". On 28 January 1978, recurring characters The Nerds premiered on Saturday Night Live. The term was further popularized in the 1984 film \"Revenge of the Nerds\".\nCulture and perception.\nStereotype.\nIntellect and alleged nerdiness.\nBecause of the nerd stereotype, many intelligent people are often thought of as nerdy. This belief can be harmful, as it can cause high school students to \"switch off their lights\" out of fear of being branded as a nerd, and cause otherwise appealing people to be considered nerdy simply for their intellect.\nIt has been argued that intellectuals are automatically nerdy because they were secretly envied, arrogant, or out of touch. However, Paul Graham stated in his essay, \"Why Nerds are Unpopular\", that intellect is neutral, meaning that many high school students neither admire nor deride classmates for intelligence itself. He also states that it is only the correlation that makes smart teens automatically seem nerdy, and personally defines a nerd as someone deemed not socially adept enough. Additionally, he says that the reason why many smart kids are unpopular is that they \"don't have time for the activities required for popularity,\" since they instead prioritize intellectual, solitary pursuits, at the cost of being branded as \"nerds.\" He also goes on to criticize suburbia and the public education system for enabling a popularity contest.\nStereotypical \"nerd\" appearance and fashion.\nStereotypical nerd appearance, often lampooned in caricatures, can include very large glasses, dental braces, buck teeth, severe acne and pants worn high at the waist. Following suit of popular use in emoticons, Unicode released in 2015 its \"Nerd Face\" character, featuring some of those stereotypes: \ud83e\udd13 (code point U+1F913). In the media, many nerds are males, portrayed as being physically unfit, either overweight or skinny due to lack of physical exercise.\nThe stereotype across race and gender.\nIt has been suggested by some, such as linguist Mary Bucholtz, that being a nerd may be a state of being \"hyperwhite\" and rejecting African-American culture and slang that \"cool\" white children use. However, after the \"Revenge of the Nerds\" movie franchise (with multicultural nerds), and the introduction of the Steve Urkel character on the television series \"Family Matters\", nerds have been seen in all races and colors as well as more recently being a frequent young East Asian or Indian male stereotype in North America. Portrayal of \"nerd girls\", in films such as \"She's Out of Control\", \"Welcome to the Dollhouse\" and \"She's All That\" depicts that smart but nerdy women might suffer later in life if they do not focus on improving their physical attractiveness.\nIn the United States, a 2010 study published in the \"Journal of International and Intercultural Communication\" indicated that Asian Americans are perceived as most likely to be nerds, followed by White Americans, while non-White Hispanics and African Americans were perceived as least likely to be nerds. These stereotypes stem from concepts of Orientalism and Primitivism, as discussed in Ron Eglash's essay \"Race, Sex, and Nerds: From Black Geeks to Asian American Hipsters\".\nPsychosocial conditions.\nSome of the stereotypical behaviors associated with the \"nerd\" stereotype have correlations with the traits of Asperger syndrome or other autism spectrum conditions.\nPride.\nSome measures of \"nerdiness\" are now considered desirable by many commentators. To some, \"nerd\" suggests a person who is intelligent, respectful, interesting, dedicated, individualistic, and able to earn a large salary doing what they love. Stereotypical nerd qualities are evolving, going from awkwardness and social ostracism to an allegedly more widespread acceptance and sometimes even celebration of their differences. Many so-called \"nerdy people\" have accumulated large fortunes, and many are able to find their niche in the American computer industry, concentrated in California's Silicon Valley, the Greater Seattle area (working for companies like Amazon or Microsoft), and the Silicon Slopes. These engineers and programmers have influenced popular culture in many ways, caught the attention of the media, and effectively designed a new category of everyday objects.\nBeing adept with computers, often considered a \"nerdy\" interest, is now widespread and even an expectation in professional and academic spaces. Many celebrities in the first decade of the 2000s publicly expressed interest in smartphones and other handheld devices. Similarly, many stereotypical \"nerdy\" interests, such as video games, tabletop RPGs, comic book franchises, and fantasy and science fiction works, are now international popular culture hits.\nJohannes Grenzfurthner, researcher, self-proclaimed nerd and director of nerd documentary \"Traceroute\", reflects on the emergence of nerds and nerd culture:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I think that the figure of the nerd provides a beautiful template for analyzing the transformation of the disciplinary society into the control society. The nerd, in his clich\u00e9 form, first stepped out upon the world stage in the mid-1970s, when we were beginning to hear the first rumblings of what would become the Cambrian explosion of the information society. The nerd must serve as comic relief for the future-anxieties of Western society. ...The germ cell of burgeoning nerdism is difference. The yearning to be understood, to find opportunities to share experiences, to not be left alone with one's bizarre interest. At the same time one derives an almost perverse pleasure from wallowing in this deficit. Nerds love deficiency: that of the other, but also their own. Nerds are eager explorers, who enjoy measuring themselves against one another and also compete aggressively. And yet the nerd's existence also comprises an element of the occult, of mystery. The way in which this power is expressed or focused is very important.\u2014\u200a\nIn the 1984 film \"Revenge of the Nerds\", Robert Carradine worked to embody the nerd stereotype; in doing so, he helped create a definitive image of nerds. Additionally, the storyline presaged, and may have helped inspire, the \"nerd pride\" that emerged in the late 1990s. \"American Splendor\" regular Toby Radloff claims this was the movie that inspired him to become \"The Genuine Nerd from Cleveland, Ohio\". In the \"American Splendor\" film, Toby's friend, \"American Splendor\" author Harvey Pekar, was less receptive to the movie, believing it to be hopelessly idealistic, explaining that Toby, an adult low income file clerk, had nothing in common with the middle class kids in the film who would eventually attain college degrees, success, and cease being perceived as nerds. Many, however, seem to share Radloff's view, as \"nerd pride\" has become more widespread in the years since. MIT professor Gerald Sussman, for example, seeks to instill pride in nerds:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;My idea is to present an image to children that it is good to be intellectual, and not to care about the peer pressures to be anti-intellectual. I want every child to turn into a nerd \u2013 where that means someone who prefers studying and learning to competing for social dominance, which can unfortunately cause the downward spiral into social rejection.\u2014\u200a\nBullying.\nIndividuals who are labeled as \"nerds\" are often the target of bullying due to a range of reasons that may include physical appearance or social background. Paul Graham has suggested that the reason nerds are frequently singled out for bullying is their indifference to popularity or social context, in the face of a youth culture that views popularity as paramount. However, research findings suggest that bullies are often as socially inept as their academically better-performing victims, and that popularity fails to confer protection from bullying. Other commentators have pointed out that pervasive harassment of intellectually-oriented youth began only in the mid-twentieth century.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21496", "revid": "11689218", "url": "https://en.wikipedia.org/wiki?curid=21496", "title": "Nucleic acid", "text": "Class of large biomolecules essential to all known life\nNucleic acids are large biomolecules that are crucial in all cells and viruses. They are composed of nucleotides, which are the monomer components: a 5-carbon sugar, a phosphate group and a nitrogenous base. The two main classes of nucleic acids are deoxyribonucleic acid (DNA) and ribonucleic acid (RNA). If the sugar is ribose, the polymer is RNA; if the sugar is deoxyribose, a variant of ribose, the polymer is DNA.\nNucleic acids are chemical compounds that are found in nature. They carry information in cells and make up genetic material. These acids are very common in all living things, where they create, encode, and store information in every living cell of every life-form on Earth. In turn, they send and express that information inside and outside the cell nucleus. From the inner workings of the cell to the young of a living thing, they contain and provide information via the nucleic acid sequence. This gives the RNA and DNA their unmistakable 'ladder-step' order of nucleotides within their molecules. Both play a crucial role in directing protein synthesis.\nStrings of nucleotides are bonded to form spiraling backbones and assembled into chains of bases or base-pairs selected from the five primary, or canonical, nucleobases. RNA usually forms a chain of single bases, whereas DNA forms a chain of base pairs. The bases found in RNA and DNA are: adenine, cytosine, guanine, thymine, and uracil. Thymine occurs only in DNA and uracil only in RNA. Using amino acids and protein synthesis, the specific sequence in DNA of these nucleobase-pairs helps to keep and send coded instructions as genes. In RNA, base-pair sequencing helps to make new proteins that determine most chemical processes of all life forms.\nHistory.\nNucleic acid was, partially, first discovered by Friedrich Miescher in 1869 at the University of T\u00fcbingen, Germany. He discovered a new substance, which he called nuclein and which - depending on how his results are interpreted in detail - can be seen in modern terms either as a nucleic acid-histone complex or as the actual nucleic acid. Phoebus Levene determined the basic structure of nucleic acids. In the early 1880s, Albrecht Kossel further purified the nucleid acid substance and discovered its highly acidic properties. He later also identified the nucleobases.\nIn 1889 Richard Altmann created the term nucleic acid \u2013 at that time DNA and RNA were not differentiated.\nIn 1938 Astbury and Bell published the first X-ray diffraction pattern of DNA.\nIn 1944 the Avery\u2013MacLeod\u2013McCarty experiment showed that DNA is the carrier of genetic information and in 1953 Watson and Crick .\nExperimental studies of nucleic acids constitute a major part of modern biological and medical research, and form a foundation for genome and forensic science, and the biotechnology and pharmaceutical industries.\nOccurrence and nomenclature.\nThe term \"nucleic acid\" is the overall name for DNA and RNA, members of a family of biopolymers, and is a type of \"polynucleotide\". Nucleic acids were named for their initial discovery within the nucleus, and for the presence of phosphate groups (related to phosphoric acid). Although first discovered within the nucleus of eukaryotic cells, nucleic acids are now known to be found in all life forms including within bacteria, archaea, mitochondria, chloroplasts, and viruses (There is debate as to whether viruses are living or non-living). All living cells contain both DNA and RNA (except some cells such as mature red blood cells), while viruses contain either DNA or RNA, but usually not both.\nThe basic component of biological nucleic acids is the nucleotide, each of which contains a pentose sugar (ribose or deoxyribose), a phosphate group, and a nucleobase.\nNucleic acids are also generated within the laboratory, through the use of enzymes (DNA and RNA polymerases) and by solid-phase chemical synthesis.\nMolecular composition and size.\nNucleic acids are generally very large molecules. Indeed, DNA molecules are probably the largest individual molecules known. Well-studied biological nucleic acid molecules range in size from 21 nucleotides (small interfering RNA) to large chromosomes (human chromosome 1 is a single molecule that contains 247 million base pairs).\nIn most cases, naturally occurring DNA molecules are double-stranded and RNA molecules are single-stranded. There are numerous exceptions, however\u2014some viruses have genomes made of double-stranded RNA and other viruses have single-stranded DNA genomes, and, in some circumstances, nucleic acid structures with three or four strands can form.\nNucleic acids are linear polymers (chains) of nucleotides. Each nucleotide consists of three components: a purine or pyrimidine nucleobase (sometimes termed \"nitrogenous base\" or simply \"base\"), a pentose sugar, and a phosphate group which makes the molecule acidic. The substructure consisting of a nucleobase plus sugar is termed a nucleoside. Nucleic acid types differ in the structure of the sugar in their nucleotides\u2013DNA contains 2'-deoxyribose while RNA contains ribose (where the only difference is the presence of a hydroxyl group). Also, the nucleobases found in the two nucleic acid types are different: adenine, cytosine, and guanine are found in both RNA and DNA, while thymine occurs in DNA and uracil occurs in RNA.\nThe sugars and phosphates in nucleic acids are connected to each other in an alternating chain (sugar-phosphate backbone) through phosphodiester linkages. In conventional nomenclature, the carbons to which the phosphate groups attach are the 3'-end and the 5'-end carbons of the sugar. This gives nucleic acids directionality, and the ends of nucleic acid molecules are referred to as 5'-end and 3'-end. The nucleobases are joined to the sugars via an \"N\"-glycosidic linkage involving a nucleobase ring nitrogen (\"N\"-1 for pyrimidines and \"N\"-9 for purines) and the 1' carbon of the pentose sugar ring.\nNon-standard nucleosides are also found in both RNA and DNA and usually arise from modification of the standard nucleosides within the DNA molecule or the primary (initial) RNA transcript. Transfer RNA (tRNA) molecules contain a particularly large number of modified nucleosides.\nTopology.\nDouble-stranded nucleic acids are made up of complementary sequences, in which extensive Watson-Crick base pairing results in a highly repeated and quite uniform nucleic acid double-helical three-dimensional structure. In contrast, single-stranded RNA and DNA molecules are not constrained to a regular double helix, and can adopt highly complex three-dimensional structures that are based on short stretches of intramolecular base-paired sequences including both Watson-Crick and noncanonical base pairs, and a wide range of complex tertiary interactions.\nNucleic acid molecules are usually unbranched and may occur as linear and circular molecules. For example, bacterial chromosomes, plasmids, mitochondrial DNA, and chloroplast DNA are usually circular double-stranded DNA molecules, while chromosomes of the eukaryotic nucleus are usually linear double-stranded DNA molecules. Most RNA molecules are linear, single-stranded molecules, but both circular and branched molecules can result from RNA splicing reactions. The total amount of pyrimidines in a double-stranded DNA molecule is equal to the total amount of purines. The diameter of the helix is about 20 \u00c5.\nSequences.\nOne DNA or RNA molecule differs from another primarily in the sequence of nucleotides. Nucleotide sequences are of great importance in biology since they carry the ultimate instructions that encode all biological molecules, molecular assemblies, subcellular and cellular structures, organs, and organisms, and directly enable cognition, memory, and behavior. Enormous efforts have gone into the development of experimental methods to determine the nucleotide sequence of biological DNA and RNA molecules, and today hundreds of millions of nucleotides are sequenced daily at genome centers and smaller laboratories worldwide. In addition to maintaining the GenBank nucleic acid sequence database, the National Center for Biotechnology Information (NCBI) provides analysis and retrieval resources for the data in GenBank and other biological data made available through the NCBI web site.\nTypes.\nDeoxyribonucleic acid.\nDeoxyribonucleic acid (DNA) is a nucleic acid containing the genetic instructions used in the development and functioning of all known living organisms. The chemical DNA was discovered in 1869, but its role in genetic inheritance was not demonstrated until 1943. The DNA segments that carry this genetic information are called genes. Other DNA sequences have structural purposes, or are involved in regulating the use of this genetic information. Along with RNA and proteins, DNA is one of the three major macromolecules that are essential for all known forms of life.\nDNA consists of two long polymers of monomer units called nucleotides, with backbones made of sugars and phosphate groups joined by ester bonds. These two strands are oriented in opposite directions to each other and are, therefore, antiparallel. Attached to each sugar is one of four types of molecules called nucleobases (informally, bases). It is the sequence of these four nucleobases along the backbone that encodes genetic information. This information specifies the sequence of the amino acids within proteins according to the genetic code. The code is read by copying stretches of DNA into the related nucleic acid RNA in a process called transcription.\nWithin cells, DNA is organized into long sequences called chromosomes. During cell division these chromosomes are duplicated in the process of DNA replication, providing each cell its own complete set of chromosomes. Eukaryotic organisms (animals, plants, fungi, and protists) store most of their DNA inside the cell nucleus and some of their DNA in organelles, such as mitochondria or chloroplasts. In contrast, prokaryotes (bacteria and archaea) store their DNA only in the cytoplasm. Within the chromosomes, chromatin proteins such as histones compact and organize DNA. These compact structures guide the interactions between DNA and other proteins, helping control which parts of the DNA are transcribed.\nRibonucleic acid.\nRibonucleic acid (RNA) functions in converting genetic information from genes into the amino acid sequences of proteins. The three universal types of RNA include transfer RNA (tRNA), messenger RNA (mRNA), and ribosomal RNA (rRNA). Messenger RNA acts to carry genetic sequence information between DNA and ribosomes, directing protein synthesis and carries instructions from DNA in the nucleus to ribosome . Ribosomal RNA reads the DNA sequence, and catalyzes peptide bond formation. Transfer RNA serves as the carrier molecule for amino acids to be used in protein synthesis, and is responsible for decoding the mRNA. In addition, many other classes of RNA are now known.\nArtificial nucleic acid.\nArtificial nucleic acid analogues have been designed and synthesized. They include peptide nucleic acid, morpholino- and locked nucleic acid, glycol nucleic acid, and threose nucleic acid. Each of these is distinguished from naturally occurring DNA or RNA by changes to the backbone of the molecules.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21497", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=21497", "title": "Nitrate", "text": "Polyatomic ion (NO3, charge \u20131) found in explosives and fertilisers\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nNitrate is a polyatomic ion with the chemical formula NO3\u2212. Salts containing this ion are called nitrates. Nitrates are common components of fertilizers and explosives. Almost all inorganic nitrates are soluble in water. An example of an insoluble nitrate is bismuth oxynitrate.\nChemical structure.\nThe nitrate anion is the conjugate base of nitric acid, consisting of one central nitrogen atom surrounded by three identically bonded oxygen atoms in a trigonal planar arrangement. The nitrate ion carries a formal charge of \u22121. This charge results from a combination formal charge in which each of the three oxygens carries a \u2212&lt;templatestyles src=\"Fraction/styles.css\" /&gt;2\u20443 charge, whereas the nitrogen carries a +1 charge, all these adding up to formal charge of the polyatomic nitrate ion. This arrangement is commonly used as an example of resonance. Like the isoelectronic carbonate ion, the nitrate ion can be represented by three resonance structures:\nChemical and biochemical properties.\nIn the NO3- anion, the oxidation state of the central nitrogen atom is V (+5). This corresponds to the highest possible oxidation number of nitrogen. Nitrate is a potentially powerful oxidizer as evidenced by its explosive behaviour at high temperature when it is detonated in ammonium nitrate (), or black powder, ignited by the shock wave of a primary explosive. In contrast to red fuming nitric acid (), or concentrated nitric acid (), nitrate in aqueous solution at neutral or high pH is only a weak oxidizing agent in redox reactions in which the reductant does not produce hydrogen ions (such as mercury going to calomel). However, it is still a strong oxidizer when the reductant does produce hydrogen ions, such as in the oxidation of hydrogen itself. Nitrate is stable in the absence of microorganisms, or reductants such as organic matter. In fact, nitrogen gas is thermodynamically stable in the presence of of oxygen only in very acidic conditions, and otherwise would combine with it to form nitrate. This is shown by subtracting the two oxidation reactions:\n formula_1\n formula_2\ngiving:\n formula_3\nDividing by 0.0118 and rearranging gives the equilibrium relation:\n formula_4\nHowever, in reality, nitrogen, oxygen, and water do not combine directly to form nitrate. Rather, a reductant such as hydrogen reacts with nitrogen to produce \"fixed nitrogen\" such as ammonia, which is then oxidized, eventually becoming nitrate. Nitrate does not accumulate to high levels in nature because it reacts with reductants in the process called denitrification (see Nitrogen cycle).\nNitrate is used as a powerful terminal electron acceptor by denitrifying bacteria to deliver the energy they need to thrive. Under anaerobic conditions, nitrate is the strongest electron acceptor used by prokaryote microorganisms (bacteria and archaea) to respirate. The redox couple is at the top of the redox scale for the anaerobic respiration, just below the couple oxygen (/), but above the couples Mn(IV)/Mn(II), Fe(III)/Fe(II), /, CO2/. In natural waters inevitably contaminated by microorganisms, nitrate is a quite unstable and labile dissolved chemical species because it is metabolised by denitrifying bacteria. Water samples for nitrate/nitrite analyses need to be kept at 4 \u00b0C in a refrigerated room and analysed as quick as possible to limit the loss of nitrate.\nIn the first step of the denitrification process, dissolved nitrate () is catalytically reduced into nitrite () by the enzymatic activity of bacteria. In aqueous solution, dissolved nitrite, N(III), is a more powerful oxidizer that nitrate, N(V), because it has to accept less electrons and its reduction is less kinetically hindered than that of nitrate.\nElectrochemical reduction of nitrate is also well-known, although its use for energy storage and denitrification remains underdeveloped.\nDuring the biological denitrification process, further nitrite reduction also gives rise to another powerful oxidizing agent: nitric oxide (NO). NO can fix on myoglobin, accentuating its red coloration. NO is an important biological signaling molecule and intervenes in the vasodilation process. Still, it can also produce free radicals in biological tissues, accelerating their degradation and aging process. The reactive oxygen species (ROS) generated by NO contribute to the oxidative stress, a condition involved in vascular dysfunction and atherogenesis.\nDetection in chemical analysis.\nThe nitrate anion is commonly analysed in water by ion chromatography (IC) along with other anions also present in the solution. The main advantage of IC is its ease and the simultaneous analysis of all the anions present in the aqueous sample. Since the emergence of IC instruments in the 1980s, this separation technique, coupled with many detectors, has become commonplace in the chemical analysis laboratory and is the preferred and most widely used method for nitrate and nitrite analyses. \nPreviously, nitrate determination relied on spectrophotometric and colorimetric measurements after a specific reagent is added to the solution to reveal a characteristic color (often red because it absorbs visible light in the blue). Because of interferences with the brown color of dissolved organic matter (DOM: humic and fulvic acids) often present in soil pore water, artefacts can easily affect the absorbance values. In case of weak interference, a blank measurement with only a naturally brown-colored water sample can be sufficient to subtract the undesired background from the measured sample absorbance. If the DOM brown color is too intense, the water samples must be pretreated, and inorganic nitrogen species must be separated before measurement. Meanwhile, for clear water samples, colorimetric instruments retain the advantage of being less expensive and sometimes portable, making them an affordable option for fast routine controls or field measurements. \nColorimetric methods for the specific detection of nitrate () often rely on its conversion to nitrite () followed by nitrite-specific tests. The reduction of nitrate to nitrite can be effected by a copper-cadmium alloy, metallic zinc, or hydrazine. The most popular of these assays is the Griess test, whereby nitrite is converted to a deeply red colored azo dye suited for UV\u2013vis spectrophotometry analysis. The method exploits the reactivity of nitrous acid () derived from the acidification of nitrite. Nitrous acid selectively reacts with aromatic amines to give diazonium salts, which in turn couple with a second reagent to give the azo dye. The detection limit is 0.02 to 2 \u03bcM. Such methods have been highly adapted to biological samples and soil samples.\nIn the dimethylphenol method, 1 mL of concentrated sulfuric acid () is added to 200 \u03bcL of the solution being tested for nitrate. Under strongly acidic conditions, nitrate ions react with 2,6-dimethylphenol, forming a yellow compound, 4-nitro-2,6-dimethylphenol. This occurs through electrophilic aromatic substitution where the intermediate nitronium () ions attack the aromatic ring of dimethylphenol. The resulting product (ortho- or para-nitro-dimethylphenol) is analyzed using UV-vis spectrophotometry at 345 nm according to the Lambert-Beer law.\nAnother colorimetric method based on the chromotropic acid (dihydroxynaphthalene-disulfonic acid) was also developed by West and Lyles in 1960 for the direct spectrophotometric determination of nitrate anions.\nIf formic acid is added to a mixture of brucine (an alkaloid related to strychnine) and potassium nitrate (), its color instantly turns red. This reaction has been used for the direct colorimetric detection of nitrates.\nFor direct online chemical analysis using a flow-through system, the water sample is introduced by a peristaltic pump in a flow injection analyzer, and the nitrate or resulting nitrite-containing effluent is then combined with a reagent for its colorimetric detection.\nOccurrence and production.\nNitrate salts are found naturally on earth in arid environments as large deposits, particularly of nitratine, a major source of sodium nitrate.\nNitrates are produced by a number of species of nitrifying bacteria in the natural environment using ammonia or urea as a source of nitrogen and source of free energy. Nitrate compounds for gunpowder were historically produced, in the absence of mineral nitrate sources, by means of various fermentation processes using urine and dung.\nLightning strikes in earth's nitrogen- and oxygen-rich atmosphere produce a mixture of oxides of nitrogen, which form nitrous ions and nitrate ions, which are washed from the atmosphere by rain or in occult deposition.\nNitrates are produced industrially from nitric acid.\nUses.\nAgriculture.\nNitrate is a chemical compound that serves as a primary form of nitrogen for many plants. This essential nutrient is used by plants to synthesize proteins, nucleic acids, and other vital organic molecules. The transformation of atmospheric nitrogen into nitrate is facilitated by certain bacteria and lightning in the nitrogen cycle, which exemplifies nature's ability to convert a relatively inert molecule into a form that is crucial for biological productivity.\nNitrates are used as fertilizers in agriculture because of their high solubility and biodegradability. The main nitrate fertilizers are ammonium, sodium, potassium, calcium, and magnesium salts. Several billion kilograms are produced annually for this purpose. The significance of nitrate extends beyond its role as a nutrient since it acts as a signaling molecule in plants, regulating processes such as root growth, flowering, and leaf development.\nWhile nitrate is beneficial for agriculture since it enhances soil fertility and crop yields, its excessive use can lead to nutrient runoff, water pollution, and the proliferation of aquatic dead zones. Therefore, sustainable agricultural practices that balance productivity with environmental stewardship are necessary. Nitrate's importance in ecosystems is evident since it supports the growth and development of plants, contributing to biodiversity and ecological balance.\nFirearms.\nNitrates are used as oxidizing agents, most notably in explosives, where the rapid oxidation of carbon compounds liberates large volumes of gases (see gunpowder as an example).\nIndustrial.\nSodium nitrate is used to remove air bubbles from molten glass and some ceramics. Mixtures of molten salts are used to harden the surface of some metals.\nPhotographic film.\nNitrate was also used as a film stock through nitrocellulose. Due to its high combustibility, the film making studios swapped to cellulose acetate safety film in 1950.\nMedicinal and pharmaceutical use.\nIn the medical field, nitrate-derived organic esters, such as glyceryl trinitrate, isosorbide dinitrate, and isosorbide mononitrate, are used in the prophylaxis and management of acute coronary syndrome, myocardial infarction, acute pulmonary oedema. This class of drug, to which amyl nitrite also belongs, is known as nitrovasodilators.\nToxicity and safety.\nThe two areas of concerns about the toxicity of nitrate are the following: \nMethemoglobinemia.\nOne of the most common cause of methemoglobinemia in infants is due to the ingestion of nitrates and nitrites through well water or foods. \nIn fact, nitrates (), often present at too high concentration in drinkwater, are only the precursor chemical species of nitrites (), the real culprits of methemoglobinemia. Nitrites produced by the microbial reduction of nitrate (directly in the drinkwater, or after ingestion by the infant's digestive system) are more powerful oxidizers than nitrates and are the chemical agent really responsible for the oxidation of Fe2+ into Fe3+ in the tetrapyrrole heme of hemoglobin. Indeed, nitrate anions are too weak oxidizers in aqueous solution to be able to directly, or at least sufficiently rapidly, oxidize Fe2+ into Fe3+, because of kinetics limitations.\nInfants younger than four months are at greater risk given that they drink more water per body weight, they have a lower NADH-cytochrome b5 reductase activity, and they have a higher level of fetal hemoglobin which converts more easily to methemoglobin. Additionally, infants are at an increased risk after an episode of gastroenteritis due to the production of nitrites by bacteria. \nHowever, other causes than nitrates can also affect infants and pregnant women. Indeed, the blue baby syndrome can also be caused by a number of other factors such as the cyanotic heart disease, a congenital heart defect resulting in low levels of oxygen in the blood, or by gastric upset, such as diarrheal infection, protein intolerance, heavy metal toxicity, etc.\nDrinking water standards.\nThrough the Safe Drinking Water Act, the United States Environmental Protection Agency has set a maximum contaminant level of 10\u00a0mg/L or 10 ppm of nitrate in drinking water.\nAn acceptable daily intake (ADI) for nitrate ions was established in the range of 0\u20133.7\u00a0mg (kg body weight)\u22121 day\u22121 by the Joint FAO/WHO Expert Committee on Food Additives (JEFCA).\nAquatic toxicity.\nIn freshwater or estuarine systems close to land, nitrate can reach concentrations that are lethal to fish. While nitrate is much less toxic than ammonia, levels over 30 ppm of nitrate can inhibit growth, impair the immune system and cause stress in some aquatic species. Nitrate toxicity remains a subject of debate.\nIn most cases of excess nitrate concentrations in aquatic systems, the primary sources are wastewater discharges, as well as surface runoff from agricultural or landscaped areas that have received excess nitrate fertilizer. The resulting eutrophication and algae blooms result in anoxia and dead zones. As a consequence, as nitrate forms a component of total dissolved solids, they are widely used as an indicator of water quality.\nHuman impacts on ecosystems through nitrate deposition.\nNitrate deposition into ecosystems has markedly increased due to anthropogenic activities, notably from the widespread application of nitrogen-rich fertilizers in agriculture and the emissions from fossil fuel combustion. Annually, about 195 million metric tons of synthetic nitrogen fertilizers are used worldwide, with nitrates constituting a significant portion of this amount. In regions with intensive agriculture, such as parts of the U.S., China, and India, the use of nitrogen fertilizers can exceed 200 kilograms per hectare.\nThe impact of increased nitrate deposition extends beyond plant communities to affect soil microbial populations. The change in soil chemistry and nutrient dynamics can disrupt the natural processes of nitrogen fixation, nitrification, and denitrification, leading to altered microbial community structures and functions. This disruption can further impact the nutrient cycling and overall ecosystem health.\nDietary nitrate.\nA source of nitrate in the human diets arises from the consumption of leafy green foods, such as spinach and arugula. NO3\u2212 can be present in beetroot juice. Drinking water represents also a primary nitrate intake source.\nNitrate ingestion rapidly increases the plasma nitrate concentration by a factor of 2 to 3, and this elevated nitrate concentration can be maintained for more than 2 weeks. Increased plasma nitrate enhances the production of nitric oxide, NO. Nitric oxide is a physiological signaling molecule which intervenes in, among other things, regulation of muscle blood flow and mitochondrial respiration.\nCured meats.\n\"Nitrite\" () consumption is primarily determined by the amount of processed meats eaten, and the concentration of nitrates () added to these meats (bacon, sausages\u2026) for their curing. Although nitrites are the nitrogen species chiefly used in meat curing, nitrates are used as well and can be transformed into nitrite by microorganisms, or in the digestion process, starting by their dissolution in saliva and their contact with the microbiota of the mouth. Nitrites lead to the formation of carcinogenic nitrosamines. The production of nitrosamines may be inhibited by the use of the antioxidants vitamin C and the alpha-tocopherol form of vitamin E during curing.\nMany meat processors claim their meats (e.g. bacon) is \"uncured\" \u2013 which is a marketing claim with no factual basis: there is no such thing as \"uncured\" bacon (as that would be, essentially, raw sliced pork belly). \"Uncured\" meat is in fact actually cured with nitrites with virtually \"no\" distinction in process \u2013 the only difference being the USDA labeling requirement between nitrite of vegetable origin (such as from celery) vs. \"synthetic\" sodium nitrite. An analogy would be purified \"sea salt\" vs. sodium chloride \u2013 both being exactly the same chemical with the only essential difference being the origin.\nAnti-hypertensive diets, such as the DASH diet, typically contain high levels of nitrates, which are first reduced to nitrite in the saliva, as detected in saliva testing, prior to forming nitric oxide (NO).\nDomestic animal feed.\nSymptoms of nitrate poisoning in domestic animals include increased heart rate and respiration; in advanced cases blood and tissue may turn a blue or brown color. Feed can be tested for nitrate; treatment consists of supplementing or substituting existing supplies with lower nitrate material. Safe levels of nitrate for various types of livestock are as follows:\nThe values above are on a dry (moisture-free) basis.\nSalts and covalent derivatives.\nNitrate formation with elements of the periodic table:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21499", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=21499", "title": "Nucleic Acid", "text": ""}
{"id": "21502", "revid": "15213913", "url": "https://en.wikipedia.org/wiki?curid=21502", "title": "Nike", "text": "Nike often refers to:\nNike may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "21503", "revid": "14965160", "url": "https://en.wikipedia.org/wiki?curid=21503", "title": "Nevis", "text": "Island in the Caribbean Sea\nNevis ( ) is an island in the Caribbean Sea that forms part of the inner arc of the Leeward Islands chain of the West Indies. Nevis and the neighbouring island of Saint Kitts constitute the Federation of Saint Kitts and Nevis, a sovereign state. Nevis is located near the northern end of the Lesser Antilles archipelago about east-southeast of Puerto Rico and west of Antigua. Its area is and the capital is Charlestown.\nSaint Kitts and Nevis are separated by The Narrows, a shallow channel. Nevis is roughly conical in shape with a volcano, Nevis Peak, at its centre. The island is fringed on its western and northern coastlines by sandy beaches composed of a mixture of white coral sand with brown and black sand eroded and washed down from the volcanic rocks that make up the island. The gently-sloping coastal plain ( wide) has natural freshwater springs as well as non-potable volcanic hot springs, especially along the western coast.\nThe island was named \"Oualie\", translated as \"land of beautiful waters\", by the Kalinago and \"Dulcina\" (\"Sweet Island\") by the early British settlers. The name \"Nevis\" is derived from the Spanish phrase , which translates as Our Lady of the Snows; the name was given by the island's Spanish discoverers and first appeared on maps in the 16th century. Nevis is also known by the sobriquet \"Queen of the Caribees\", which it earned in the 18th century because of its many sugar plantations.\nNevis is both geographically smaller and less populous than Saint Kitts. It maintains significant autonomy within the federation, including a separate government headed by the premier of Nevis and a separate legislature. Nevis has twice voted \u2013 in 1977, in an unofficial referendum, and in 1998, in an official one \u2013 to secede from the federation, but neither attempt succeeded.\nThe majority of the approximately 12,000 Nevisians are of primarily African descent, with notable British, Portuguese, and Lebanese minority communities. English is the official language, and its literacy rate of 98 per cent is one of the highest in the Western Hemisphere.\nEtymology.\nIn 1493, Christopher Columbus gave the island the name \"San Mart\u00edn\" (Saint Martin). However, the confusion of numerous poorly charted small islands in the Leeward Island chain meant that this name ended up being accidentally transferred to another island, which is still known as Saint-Martin.\nThe current name \"Nevis\" might be derived from the Spanish name via process of abbreviation and anglicisation or named after the highest mountain in Scotland, namely Ben Nevis. The Spanish name means Our Lady of the Snows. It is not known who chose this name for the island, but it is a reference to the story of a 4th-century Catholic miracle related to a snowfall on the Esquiline Hill in Rome. Presumably the white clouds that usually cover the top of Nevis Peak reminded someone of this story of a miraculous snowfall in a hot climate.\nNevis was part of the Spanish claim to the Caribbean islands, a claim pursued until the 1670 Treaty of Madrid, even though there were no Spanish settlements on the island. According to Vincent Hubbard, author of \"Swords, Ships &amp; Sugar: History of Nevis\", the Spanish ruling caused many of the Arawak groups who were not ethnically Caribs to \"be redefined as Kalinago overnight\". Records indicate that the Spanish enslaved large numbers of the native inhabitants on the more accessible of the Leeward Islands and sent them to Cubagua, Venezuela, to dive for pearls. Hubbard suggests that the reason the first European settlers found so few Kalinago on Nevis is that they had already been rounded up by the Spanish and shipped off to be used as slaves.\nHistory.\nAmerindians.\nNevis had been settled for more than 2,000 years by Amerindian peoples prior to having been sighted by Columbus in 1493. The indigenous people of Nevis during these periods belonged to the Leeward Island Amerindian groups popularly referred to as Arawaks and Kalinago, a complex mosaic of ethnic groups with similar culture and language. Dominican anthropologist Lennox Honychurch traces the European use of the term \"Carib\" to refer to the Leeward Island aborigines to Columbus, who picked it up from the Ta\u00ednos on Hispaniola. It was not a name the Kalinago called themselves. \"Carib Indians\" was the generic name used for all groups believed involved in cannibalistic war rituals, more particularly, the consumption of parts of a killed enemy's body.\nThe Amerindian name for Nevis was \"Oualie\", land of beautiful waters. The structure of the Kalinago language has been linguistically identified as Arawakan.\nColonial era.\nDespite the Spanish claim, Nevis continued to be a popular stop over point for English and Dutch ships on their way to North America. Captain Bartholomew Gilbert of Plymouth visited the island in 1603, spending two weeks to cut 20 tons of lignum vitae wood. Gilbert sailed on to Virginia to seek out survivors of the Roanoke settlement in what is now North Carolina. Captain John Smith visited Nevis on his way to Virginia in 1607 on the voyage that founded Jamestown, the first permanent English settlement in the New World.\nOn 30 August 1620, James I of England asserted sovereignty over Nevis by giving a Royal Patent for colonisation to the Earl of Carlisle. However, actual English settlement did not happen until 1628, when Anthony Hilton moved from nearby Saint Kitts following a murder plot against him. 80 English settlers accompanied him, soon boosted by a further 100 settlers from London who had initially hoped to settle Barbuda. Hilton became the first Governor of Nevis.\nAfter the Treaty of Madrid between Spain and England, Nevis became a major part of the English West Indies and an admiralty court also sat in Nevis. Between 1675 and 1730, the island was the headquarters for the slave trade to the Leeward Islands, with approximately 6,000\u20137,000 enslaved West Africans passing through en route to other islands each year. The Royal African Company brought all its ships through Nevis. A 1678 census shows a community of Irish people \u2013 22% of the population \u2013 existing as either indentured servants or freemen.\nDue to the profitable slave trade and the high quality of Nevisian sugar cane, Nevis soon became a dominant source of wealth for the colonial slavocracy. When the Leeward Islands were separated from Barbados in 1671, Nevis became the seat of the Leeward Islands colony and was given the nickname \"Queen of the Caribees\". It remained the colonial capital for the Leeward Islands until the seat was transferred to Antigua for military reasons in 1698. During this period, Nevis was the richest of the English Leeward Islands.\nNevis outranked larger islands like Jamaica in sugar production in the late 17th century. The planters' wealth on the island is evident in the tax records preserved at the Calendar State Papers in the Colonial Office's Public Records, where the amount of tax collected on the Leeward Islands was recorded. The sums recorded for 1676 as \"head tax on slaves\", a tax payable in sugar, amounted to 384,600 pounds in Nevis, as opposed to 67,000 each in Antigua and Saint Kitts, 62,500 in Montserrat, and 5,500 total in the other five islands.\nThe profits on sugar cultivation in Nevis was enhanced by the fact that the cane juice from Nevis yielded an unusually high amount of sugar. A gallon (3.79 litres) of cane juice from Nevis yielded 24 ounces (0.71 litres) of sugar, whereas a gallon from Saint Kitts yielded 16 ounces (0.47 litres). Twenty per cent of the English colonial empire's total sugar production in 1700 was derived from Nevisian plantations. Exports from West Indian colonies like Nevis were worth more than all the exports from all the mainland Thirteen Colonies of North America combined at the time of the American Revolutionary War.\nThe enslaved families formed the large labour force required to work the sugar plantations. After the 1650s, the supply of white indentured servants began to dry up due to increased wages in England and less incentive to migrate to the colonies. By the end of the 17th century, the population of Nevis consisted of a small, wealthy planter elite in control, a marginal population of poor Whites, a great majority of African-descended slaves, and an unknown number of maroons, escaped slaves living in the mountains. In 1780, 90 per cent of the 10,000 people living on Nevis were Black. Some of the maroons joined with the few remaining Kalinago in Nevis. Memories of the Nevisian maroons' struggle under the plantation system are preserved in place names such as Maroon Hill, an early centre of resistance.\nThe great wealth generated by the colonies of the West Indies led to wars among the great powers of Europe. The formation of the United States can be said to be a partial by-product of these wars, and the strategic trade aims that often ignored North America. Three privateers (William Kidd being one of them) were employed by the Crown to help protect ships in Nevis' waters.\nDuring the 17th century, the French, based on Saint Kitts, launched many attacks on Nevis, sometimes assisted by the Kalinago, who in 1667 sent a large fleet of canoes along in support. In the same year, a Franco-Dutch invasion fleet was repelled off Nevis by an English fleet. Letters and other records from the era indicate that colonists on Nevis hated and feared the Kalinago. In 1674 and 1683, they participated in attacks on Kalinago villages in Dominica and St. Vincent, despite a lack of official approval from the Crown for the attack. On Nevis, the English built Fort Charles and a series of smaller fortifications to aid in defending the island. This included Saddle Hill Battery, built in 1740 to replace a deodand on Mount Nevis.\nEmancipation.\nIn 1706, Pierre Le Moyne d'Iberville, the French-Canadian founder of Louisiana in North America, decided to drive the English out of Nevis and thus also stop pirate attacks on French ships; he considered Nevis the region's headquarters for piracy against French trade. During d'Iberville's invasion of Nevis, French buccaneers were used in the front line, infamous for being ruthless killers after the pillaging during the wars with Spain where they gained a reputation for torturing and murdering non-combatants. In the face of the invading force, the English militiamen of Nevis fled.\nSome planters burned the plantations, rather than letting the French have them, and hid in the mountains. It was the enslaved Africans who held the French at bay by taking up arms to defend their families and the island. The slave quarters had been looted and burned as well, as the main reward promised the men fighting on the French side in the attack was the right to capture as many slaves as possible and resell them in Martinique.\nDuring the fighting, 3,400 enslaved Nevisians were captured and sent off to Martinique, but about 1,000 more, poorly armed and militarily untrained, held the French troops at bay, by \"murderous fire\" according to an eyewitness account by an English militiaman. He wrote that \"the slaves' brave behaviour and defence there shamed what some of their masters did, and they do not shrink to tell us so.\" After 18 days of fighting, the French were driven off the island. Among the Nevisian men, women and children carried away on d'Iberville's ships, six ended up in Louisiana, the first persons of African descent to arrive there.\nOne consequence of the French attack was a collapsed sugar industry and during the ensuing hardship on Nevis, small plots of land on the plantations were made available to the enslaved families in order to control the loss of life due to starvation. With less profitability for the absentee plantation owners, the import of food supplies for the plantation workers dwindled. Between 1776 and 1783, when the food supplies failed to arrive altogether due to the rebellion in North America, 300\u2013400 enslaved Nevisians starved to death. On 1 August 1834, slavery was abolished in the British Empire. In Nevis, 8,815 slaves were freed. The first Monday in August is celebrated as Emancipation Day and is part of the annual Nevis Culturama festival.\nA four-year apprenticeship programme followed the abolishment of slavery on the plantations. In spite of the continued use of the labour force, the Nevisian slave owners were paid over \u00a3150,000 in compensation from the British Government for the loss of property, whereas the enslaved families received nothing for 200 years of labour. One of the wealthiest planter families in Nevis, the Pinneys of Mountravers Plantation, claimed \u00a336,396 () in compensation for the slaves on the family-owned plantations around the Caribbean.\nBecause of the early distribution of plots and because many of the planters departed from the island when sugar cultivation became unprofitable, a relatively large percentage of Nevisians already owned or controlled land at emancipation. Others settled on crown land. This early development of a society with a majority of small, landowning farmers and entrepreneurs created a stronger middle class in Nevis than in Saint Kitts, where the sugar industry continued until 2006. Even though the 15 families in the wealthy planter elite no longer control the arable land, Saint Kitts still has a large, landless working class population.\n1800 to the present day.\nThe population had reached 7,470 by 1842. Nevis was united with Saint Kitts and Anguilla in 1882, and they became an associated state with full internal autonomy in 1967, though Anguilla seceded in 1971. Together, Saint Kitts and Nevis became independent on 19 September 1983. On 10 August 1998, a referendum on Nevis to separate from Saint Kitts had 2,427 votes in favour and 1,498 against, falling short of the two-thirds majority needed.\nBefore 1967, the local government of Saint Kitts was also the government of Nevis and Anguilla. Nevis had two seats and Anguilla one seat in the government. The economic and infrastructural development of the two smaller islands was not a priority to the colonial federal government.\nWhen the hospital in Charlestown was destroyed in a hurricane in 1899, planting of trees in the squares of Saint Kitts and refurbishing of government buildings, also in Saint Kitts, took precedence over the rebuilding of the only hospital in Nevis. After five years without any proper medical facilities, the leaders in Nevis initiated a campaign, threatening to seek independence from Saint Kitts. The British Administrator in Saint Kitts, Charles Cox, was unmoved. He stated that Nevis did not need a hospital since there had been no significant rise in the number of deaths during the time Nevisians had been without a hospital. Therefore, no action was needed on behalf of the government, and besides, Cox continued, the Legislative Council regarded \"Nevis and Anguilla as a drag on St. Kitts and would willingly see a separation\".\nA letter of complaint to the metropolitan British Foreign Office gave result and the federal government in Saint Kitts was ordered by their superiors in London to take speedy action. The Legislative Council took another five years to consider their options. The final decision by the federal government was to not rebuild the old hospital after all but to instead convert the old Government House in Nevis into a hospital, named Alexandra Hospital after Queen Alexandra, wife of King Edward VII. A majority of the funds assigned for the hospital could thus be spent on the construction of a new official residence in Nevis.\nAfter d'Iberville's invasion in 1704, records show Nevis' sugar industry in ruins and a decimated population begging the English Parliament and relatives for loans and monetary assistance to stave off island-wide starvation. The sugar industry on the island never fully recovered and during the general depression that followed the loss of the West Indian sugar monopoly, Nevis fell on hard times and the island became one of the poorest in the region. The island remained poorer than Saint Kitts until 1991, when the fiscal performance of Nevis edged ahead of the fiscal performance of Saint Kitts for the first time since the French invasion.\nElectricity was introduced in Nevis in 1954 when two generators were shipped in to provide electricity to the area around Charlestown. In this regard, Nevis fared better than Anguilla, where there were no paved roads, no electricity and no telephones until 1967. However, electricity did not become available island-wide on Nevis until 1971.\nAn ambitious infrastructure development programme was introduced in the early 2000s which included a transformation of the Charlestown port, construction of a new deep-water harbour, resurfacing and widening the Island Main Road, a new airport terminal and control tower, and a major airport expansion, which required the relocation of an entire village in order to make room for the runway extension.\nModernised classrooms and better-equipped schools, as well as improvements in the educational system, have contributed to a leap in academic performance on the island. The pass rate among the Nevisian students sitting for the Caribbean Examination Council (CXC) exams, the Cambridge General Certificate of Education Examination (GCE) and the Caribbean Advance Proficiency Examinations is now consistently among the highest in the English-speaking Caribbean.\nGeography.\nThe formation of the island began in mid-Pliocene times, approximately 3.45 million years ago. Nine distinct eruptive centres from different geological ages, ranging from mid-Pliocene to Pleistocene, contributed to the formation. No single model of the island's geological evolution can therefore be ascertained.\nNevis Peak ( high) is the dormant remnant of one of these ancient stratovolcanoes. The last activity took place about 100,000 years ago, but active fumaroles and hot springs are still found on the island, the most recent formed in 1953. The composite cone of Nevis volcano has two overlapping summit craters that are partially filled by a lava dome, created in recent, pre-Columbian time. Pyroclastic flows and mudflows were deposited on the lower slopes of the cone simultaneously.\nNevis Peak is located on the outer crater rim. Four other lava domes were constructed on the flanks of the volcano, one on the northeast flank (Madden's Mount), one on the eastern flank (Butlers Mountain), one on the northwest coast (Mount Lily) and one on the south coast (Saddle Hill, with a height of ). The southernmost point on the island is Dogwood Point which is also the southernmost point of the Federation of Saint Kitts and Nevis.\nDuring the last ice age, when the sea level was lower, the three islands of Saint Kitts, Nevis and Sint Eustatius (also known as Statia) were connected as one island. Saba, however, is separated from these three by a deeper channel.\nThere are visible wave-breaking reefs along the northern and eastern shorelines. To the south and west, the reefs are located in deeper water. The most developed beach on Nevis is the or Pinney's Beach, on the western or Caribbean coast. There is sheltered swimming at Pinney, Nisbet, Lovers, and Oualie beaches. The eastern coast of the island faces into the Atlantic Ocean.\nThe colour of the sand on the beaches of Nevis is variable: on a lot of the bigger beaches the sand is a yellow-grey in colour, but some beaches on the southern coast have darker, reddish, or even black sand. Under a microscope it becomes clear that Nevis sand is a mixture of tiny fragments of coral, many foraminifera, and small crystals of the various mineral constituents of the volcanic rock of which the island is made.\nGeology.\nSeven volcanic centers make up Nevis. These include Round Hill (3.43 Ma), Cades Bay (3.22 Ma), Hurricane Hill (2.7 Ma), Saddle Hill (1.8 Ma), Butlers Mountain (1.1 Ma), Red Cliff and Nevis Peak (0.98 Ma). These are mainly andesite and dacite lava domes, with associated block and ash flows, plus lahars. Nevis Peak has the highest elevation, at 984 m. Cades Bay and Farm Estate Soufriere are noted areas of hydrothermal activity.\nWater has been piped since 1911 from a spring called the Source, up the mountain, to storage tanks at Rawlins Village, and since 1912 to Butler's Village. Additional drinking water comes from Nelson's Spring near Cotton Ground and Bath Spring. Groundwater has been extracted since the 1990s, and mixed with the Source water.\nColonial deforestation.\nDuring the 17th and 18th centuries, massive deforestation was undertaken by the planters as the land was initially cleared for sugar cultivation. This intense land exploitation by the sugar and cotton industry lasted almost 300 years, and greatly changed the island's ecosystem.\nIn some places along the windswept southeast or \"Windward\" coast of the island, the landscape is radically altered compared with how it used to be in pre-colonial times. Due to extreme land erosion, the topsoil was swept away, and in some places at the coast, sheer cliffs as high as have developed.\nThick forest once covered the eastern coastal plain, where the Amerindians built their first settlements during the Aceramic period, complementing the ecosystem surrounding the coral reef just offshore. It was the easy access to fresh water on the island and the rich food source represented by the ocean life sheltered by the reef that made it feasible for the Amerindians to settle this area around 600 BC. With the loss of the natural vegetation, the balance in runoff nutrients to the reef was disturbed, eventually causing as much as 80 per cent of the large eastern fringing reef to become inactive. As the reef broke apart, it, in turn, provided less protection for the coastline.\nDuring times of maximum cultivation, sugar cane fields stretched from the coastline of Nevis up to an altitude at which the mountain slopes were too steep and rocky to farm. Nonetheless, once the sugar industry was finally abandoned, vegetation on the leeward side of the island regrew reasonably well, as scrub and secondary forest.\nWater resources.\nNevis has several natural freshwater springs, including Nelson's Spring. The island also has numerous non-potable volcanic hot springs, including most notably the Bath Spring near Bath village, just south of the capital Charlestown.\nAfter heavy rains, powerful rivers of rainwater pour down the numerous ravines, known as ghauts. When the water reaches the coastline, the corresponding coastal ponds, both freshwater and brackish, fill to capacity and beyond, spilling over into the sea.\nWith modern development, the existing freshwater springs are no longer enough to supply water to the whole island. The water supply now comes mostly from Government wells. The major source of potable water for the island is groundwater, obtained from 14 active wells. Water is pumped from the wells, stored and allowed to flow by gravity to the various locations.\nClimate.\nThe climate is tropical with little variation, tempered all year round (but particularly from December through February) by the steady north-easterly winds, called the trade winds. There is a slightly hotter and somewhat rainier season from May to November.\nNevis lies within the track area of tropical storms and occasional hurricanes. These storms can develop between June 1 and November 30. This time of year has the heaviest rainfalls.\nNevis also experiences many fires, including the devastating Nevisian Fire of 1876.\nEconomy.\nThe official currency is the Eastern Caribbean dollar (EC$), which is used by the eight member countries of the Eastern Caribbean Central Bank.\nThe European Commission's Delegation in Barbados and the Eastern Caribbean estimates the annual per capita Gross Domestic Product (GDP) on Nevis to be about 10 per cent higher than on St Kitts.\nTourism.\nThe major source of revenue for Nevis as of 2023 according to the IMF is tourism. During the 2003\u20132004 season, approximately 40,000 tourists visited the island. A five-star hotel \"(The Four Seasons Resort Nevis, West Indies)\", four exclusive restored plantation inns, and several smaller hotels including Oualie Beach Resort are currently in operation. Larger developments along the west coast have been approved and are being developed (c.2006).\nOffshore banking.\nThe introduction of secrecy legislation has made offshore financial services a rapidly growing economic sector in Nevis. Incorporation of companies, international insurance and reinsurance, as well as several international banks, trust companies, asset management firms, have created a boost in the economy. During 2005, the Nevis Island Treasury collected $94.6 million in annual revenue, compared to $59.8 million during 2001.\nIn 1998, 17,500 international banking companies were registered in Nevis. Registration and annual filing fees paid in 1999 by these entities amounted to over 10 per cent of Nevis' revenues. The offshore financial industry gained importance during the financial disaster of 1999 when Hurricane Lenny damaged the major resort on the island, causing the hotel to be closed down for a year and 400 of the 700 employees to be laid off.\nIn 2000, the Financial Action Task Force, part of the Organisation for Economic Co-operation and Development (OECD), issued a blacklist of 35 countries which were said to be non-cooperative in the campaign against tax evasion and money laundering. At the time, the list included the Federation of Saint Kitts and Nevis, although the country was subsequently removed following various reforms.\nPolitics.\nThe political structure for the Federation of Saint Kitts and Nevis is based on the Westminster Parliamentary system, but it is a unique structure in that Nevis has its own unicameral legislature, consisting of the monarch's representative, the Deputy Governor General, and members of the Nevis Island Assembly. Nevis has considerable autonomy in its legislative branch. The constitution actually empowers the Nevis Island Legislature to make laws that cannot be abrogated by the National Assembly.\nNevis has a constitutionally protected right to secede from the federation should a two-thirds majority of the island's population vote for independence in a local referendum. Section 113.(1) of the constitution states: \"The Nevis Island Legislature may provide that the island of Nevis shall cease to be federated with the island of Saint Christopher and accordingly that this Constitution shall no longer have effect in the island of Nevis.\"\nNevis has its own premier and its own government, the Nevis Island Administration. It collects its own taxes and has a separate budget, with a current account surplus. According to a statement released by the Nevis Ministry of Finance in 2005, Nevis had one of the highest growth rates in gross national product and per capita income in the Caribbean at that point.\nElections.\nNevis elections are scheduled every five years. The Nevis elections of 2013, called on 23 January 2013, were won by the party in opposition, the Concerned Citizens Movement (CCM), led by Vance Amory. The CCM won three of the five seats in the Nevis Island Assembly, while the incumbent party, the Nevis Reformation Party (NRP), won two.\nIn the federal elections of 2010, the CCM won two of the three Nevis assigned Federal seats, while the NRP won one. Of the eight Saint Kitts assigned federal seats, the St Kitts-Nevis Labour Party won six and the People's Action Movement (PAM) two.\nMovement for constitutional reform.\nJoseph Parry, leader of the opposition, has indicated that he favours constitutional reform over secession for Nevis. His party, the NRP, has historically been the strongest and most ardent proponent for Nevis independence; the party came to power with secession as the main campaign issue. In 1975, the NRP manifesto declared that: \"The Nevis Reformation Party will strive at all costs to gain secession for Nevis from St. Kitts \u2013 a privilege enjoyed by the island of Nevis prior to 1882.\"\nA cursory proposal for constitutional reform was presented by the NRP in 1999, but the issue was not prominent in the 2006 election campaign and it appears a detailed proposal has yet to be worked out and agreed upon within the party.\nIn \"Handbook of Federal Countries\" published by Forum of Federations, the authors consider the constitution problematic because it does not \"specifically outline\" the federal financial arrangements or the means by which the central government and Nevis Island Administration can raise revenue: \"In terms of the NIA, the constitution only states (in s. 108(1)) that 'all revenues...raised or received by the Administration...shall be paid into and form a fund styled the Nevis Island Consolidated Fund.' [...] Section 110(1) states that the proceeds of all 'takes' collected in St. Kitts and Nevis under any law are to be shared between the federal government and the Nevis Island Administration based on population. The share going to the NIA, however, is subject to deductions (s. 110(2)), such as the cost of common services and debt charges, as determined by the Governor-General (s.110(3)) on the advice of the Prime Minister who can also take advice from the Premier of Nevis (s.110(4)).\"\nAccording to a 1995 report by the Commonwealth Observer Group of the Commonwealth Secretariat, \"the federal government is also the local government of St Kitts and this has resulted in a perception among the political parties in Nevis that the interests of the people of Nevis are being neglected by the federal government which is more concerned with the administration of St Kitts than with the federal administration.\"\nSecession movement.\nSimeon Daniel, Nevis' first Premier and former leader of the Nevis Reformation Party (NRP) and Vance Amory, Premier and leader of the Concerned Citizens' Movement (CCM), made sovereign independence for Nevis from the Federation of Saint Kitts and Nevis part of the agenda of their parties. Since the island group gained independence from the United Kingdom in 1983, the Nevis Island Administration and the Federal Government have been involved in several conflicts over the interpretation of the new constitution which came into effect when the federation was formed. During an interview on Voice of America in March 1998, repeated in a government-issued press release headlined \"PM Douglas Maintains 1983 Constitution is Flawed\", Prime Minister Denzil Douglas called the constitution a \"recipe for disaster and disharmony among the people of both islands\".\nA crisis developed in 1984 when the People's Action Movement (PAM) won a majority in the Federal elections and temporarily ceased honouring the Federal Government's financial obligations to Nevis. Consequently, cheques issued by the Nevis Administration were not honoured by the Bank, public servants in Nevis were not paid on time and the Nevis Island Administration experienced difficulties in meeting its financial obligations.\nThere is also substantial support in Nevis for British Overseas Territory status similar to Anguilla's, which was formerly the third of the tri-state Saint Christopher-Nevis-Anguilla colony.\nLegislative motivation for secession.\nIn 1996, four new bills were introduced in the National Assembly in Saint Kitts, one of which made provisions to have revenue derived from activities in Nevis paid directly to the treasury in Saint Kitts instead of to the treasury in Nevis. Another bill, The Financial Services Committee Act, contained provisions that all investments in Saint Kitts and Nevis would require approval by an investment committee in Saint Kitts. This was controversial, because ever since 1983 the Nevis Island Administration had approved all investments for Nevis, on the basis that the constitution vests legislative authority for industries, trades and businesses and economic development in Nevis to the Nevis Island Administration.\nAll three representatives from Nevis, including the leader of the opposition in the Nevis Island Assembly, objected to the introduction of these bills into the National Assembly in Saint Kitts, arguing that the bills would affect the ability of Nevis to develop its offshore financial services sector and that the bills would be detrimental to the Nevis economy. All the representatives in opposition in the National Assembly shared the conviction that the bills if passed into law, would be unconstitutional and undermine the constitutional and legislative authority of the Nevis Island Administration, as well as result in the destruction of the economy of Nevis.\nThe constitutional crisis initially developed when the newly appointed Attorney General refused to grant permission for the Nevis Island Administration to assert its legal right in the Courts. After a decision of the High Court in favour of the Nevis Island Administration, the Prime Minister gave newspaper interviews stating that he \"refused to accept the decision of the High Court\". Due to the deteriorating relationship between the Nevis Island Administration and the Federal Government, a Constitutional Committee was appointed in April 1996 to advise on whether or not the present constitutional arrangement between the islands should continue. The committee recommended constitutional reform and the establishment of an island administration for Saint Kitts, separate from the Federal Government.\nThe Federal Government in Saint Kitts fills both functions today and Saint Kitts does not have an equivalent to the Nevis Island Administration. Disagreements between the political parties in Nevis and between the Nevis Island Administration and the Federal Government have prevented the recommendations by the electoral committee from being implemented. The problematic political arrangement between the two islands, therefore, continues to date.\nNevis has continued developing its own legislation, such as The Nevis International Insurance Ordinance and the Nevis International Mutual Funds Ordinance of 2004, but calls for secession are often based on concerns that the legislative authority of the Nevis Island Administration might be challenged again in the future.\nFiscal motivation for secession.\nThe issues of political dissension between Saint Kitts and Nevis are often centred around perceptions of imbalance in the economic structure. As noted by many scholars, Nevisians have often referred to a structural imbalance in Saint Kitts' favour in how funds are distributed between the two islands and this issue has made the movement for Nevis secession a constant presence in the island's political arena, with many articles appearing in the local press expressing concerns such as those compiled by Everton Powell in \"What Motivates Our Call for Independence\": \n1998 referendum.\nA referendum on secession from the Federation of St. Kitts and Nevis was held in 1998. Although 62% voted in favor of a secession, a two-thirds majority would have been necessary for the referendum to succeed.\nAdministrative divisions.\nThe island of Nevis is divided into five administrative subdivisions called parishes, each of which has an elected representative in the Nevis Island Assembly. The division of this almost round island into parishes was done in a circular sector pattern, so each parish is shaped like a pie slice, reaching from the highest point of Nevis Peak down to the coastline.\nSome of the parishes have double names. For example the first part of the name of Saint George Gingerland is the name of the patron saint of the parish church, and the second part of the name is the traditional common name of the parish. Often the parishes are referred to simply by their common names. The religious part of a parish name is sometimes written or pronounced in the possessive, as follows: Saint George's Gingerland.\nThe five parishes of Nevis are:\nCulture.\n\"Culturama\", the annual cultural festival of Nevis, is celebrated during the Emancipation Day weekend, the first week of August. The festivities include many traditional folk dances, such as the masquerade, the Moko jumbies on stilts, Cowboys and Indians, and Plait the Ribbon, a May pole dance. The celebration was given a more organised form in 1974, including a Miss Culture Show and a Calypso Competition, as well as drama performances, old fashion Troupes (including Johnny Walkers, Giant and Spear, Bulls, Red Cross and Blue Ribbon), arts and crafts exhibitions and recipe competitions. According to the Nevis Department of Culture, the aim is to protect and encourage indigenous folklore, in order to make sure that the uniquely Caribbean culture can \"reassert itself and flourish\".\nLanguage.\nThe official language is English. Saint Kitts Creole is also spoken on Nevis and less so on the neighbouring island.\nMusic, theatre and dance.\nNevisian culture has since the 17th century incorporated African, European, and East Indian cultural elements, creating a distinct Afro-Caribbean culture. Several historical anthropologists have done field research Nevis and in Nevisian migrant communities in order to trace the creation and constitution of a Nevisian cultural community. Karen Fog Olwig published her research about Nevis in 1993, writing that the areas where the Afro-Caribbean traditions were especially strong and flourishing relate to kinship and subsistence farming. However, she adds, Afro-Caribbean cultural impulses were not recognised or valued in the colonial society and were therefore often expressed through Euro-Caribbean cultural forms.\nExamples of European forms appropriated to express Afro-Caribbean culture are the Nevisian and Kittitian \"Tea Meetings\" and \"Christmas Sports\". According to anthropologist Roger D. Abrahams, these traditional performance art forms are \"Nevisian approximation of British performance codes, techniques, and patterns\". He writes that the Tea Meetings were staged as theatrical \"battles between decorum and chaos\", decorum represented by the ceremony chairmen and chaos the hecklers in the audience, with a diplomatic King or a Queen presiding over the battle to ensure fairness.\nThe Christmas Sports included a form of comedy and satire based on local events and gossip. They were historically an important part of the Christmas celebrations in Nevis, performed on Christmas Eve by small troupes consisting of five or six men accompanied by string bands from different parts of the island. One of the men in the troupe was dressed as a woman, playing all the female parts in the dramatisations. The troupes moved from yard to yard to perform their skits, using props, face paint and costumes to play the roles of well-known personalities in the community.\nExamples of gossip about undesired behaviour that could surface in the skits for comic effect were querulous neighbours, adulterous affairs, planters mistreating workers, domestic disputes or abuse, crooked politicians and any form of stealing or cheating experienced in the society. Even though no names were mentioned in these skits, the audience would usually be able to guess who the heckling message in the troupe's dramatised portrayals was aimed at, as it was played out right on the person's own front yard. The acts thus functioned as social and moral commentaries on current events and behaviours in Nevisian society. This particular form is called \"Bazzarding\" by many locals. Abrahams theorises that Christmas Sports are rooted in the pre-emancipation Christmas and New Year holiday celebrations, when the enslaved population had several days off.\nAmerican folklorist and musicologist Alan Lomax visited Nevis in 1962 in order to conduct long-term research into the black folk culture of the island. His field trip to Nevis and surrounding islands resulted in the anthology \"Lomax Caribbean Voyage\" series. \nAmong the Nevisians recorded were chantey-singing fishermen in a session organised in a rum shop in Newcastle; Santoy, the Calypsonian, performing calypsos by Nevisian ballader and local legend Charles Walters to guitar and cuatro; and string bands, fife players and drummers from Gingerland, performing quadrilles.\nThe island is also known for \"Jamband music\", which is the kind of music performed by local bands during the \"Culturama Festival\" and is key to \"Jouvert\" dancing. The sounds of the so-called \"Iron Band\" are also popular within the culture; many locals come together using any old pans, sinks, or other kits of any sort; which they use to create sounds and music. This form of music is played throughout the villages during the Christmas and carnival seasons.\nArchitecture.\nA series of earthquakes during the 18th century severely damaged most of the colonial-era stone buildings of Charlestown. The Georgian stone buildings in Charlestown that are visible today had to be partially rebuilt after the earthquakes, and this led to the development of a new architectural style, consisting of a wooden upper floor over a stone ground floor; the new style resisted earthquake damage much more effectively.\nTwo important Nevisian buildings from the 18th century are Hermitage Plantation, built of lignum vitae wood in 1740, the oldest surviving wooden house still in use in the Caribbean today, and the Bath Hotel, the first hotel in the Caribbean, a luxury hotel and spa built by John Huggins in 1778. The soothing waters of the hotel's hot spring and the lively social life on Nevis attracted Europeans including Antigua-based Admiral Nelson, and Prince William Henry, Duke of Clarence, (future William IV of the United Kingdom), who attended balls and private parties at the Bath Hotel. Today, the building serves as government offices, and there are two outdoor hot-spring bathing spots which were specially constructed in recent years for public use.\nAccording to local folklore, a destructive 1680 or 1690 earthquake and tsunami destroyed the buildings of the original capital Jamestown on the west coast. Folk tales say that the town sank beneath the ocean, and the tsunami is blamed for the escape of (possibly fictional) pirate Red Legs Greaves. However, archaeologists from the University of Southampton who have done excavations in the area have found no evidence for such a tsunami. They state that this story may originate with an over-excited Victorian letter writer sharing somewhat exaggerated accounts of his exotic life in the tropical colony with a British audience back home.\nOne such letter recounts that so much damage was done to the town that it was completely evacuated, and was engulfed by the sea. Early maps do not, however, actually show a settlement called \"Jamestown\", only \"Morton's Bay\", and later maps show that all that was left of Jamestown/Morton's Bay in 1818 was a building labelled \"Pleasure House\". Very old bricks that wash up on Pinney's Beach after storms may have contributed to this legend of a sunken town; however, these bricks are thought to be dumped ballast from 17th and 18th century sailing ships.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21504", "revid": "51013655", "url": "https://en.wikipedia.org/wiki?curid=21504", "title": "Nicole Kidman", "text": "Australian and American actress (born 1967)\nNicole Mary Kidman (born 20 June 1967) is an Australian and American actress and producer. Known for her work in film and television productions across many genres, she has consistently ranked among the world's highest-paid actresses since the late 1990s. Her accolades include an Academy Award, a British Academy Film Award, six Golden Globe Awards and a Volpi Cup. Nicole Kidman played Marisa Coulter in The Golden Compass.\nKidman began her career in Australia with the 1983 films \"Bush Christmas\" and \"BMX Bandits\". Her breakthrough came with lead roles in \"Dead Calm\" and the miniseries \"Bangkok Hilton\" (both 1989). She came to international prominence with a supporting role in \"Days of Thunder\" (1990) followed by leading roles in \"Far and Away\" (1992), \"To Die For\" (1995), \"Batman Forever\" (1995), \"Practical Magic\" (1998), and \"Eyes Wide Shut\" (1999). She received consecutive nominations for the Academy Award for Best Actress for \"Moulin Rouge!\" (2001) and \"The Hours\" (2002), winning for her portrayal of Virginia Woolf in the latter. Her career continued with the box office successes \"The Others\" (2001), \"Cold Mountain\" (2003), \"Australia\" (2008), \"Paddington\" (2014), and \"Aquaman\" (2018), and acclaimed independent films \"Rabbit Hole\" (2010) and \"Lion\" (2016).\nFor producing and starring in the HBO series \"Big Little Lies\" (2017\u20132019), Kidman won a Primetime Emmy Awards for Outstanding Limited Series and Outstanding Lead Actress in a Limited Series or Movie. She went on to star in further mainstream films such as the biographical dramas \"Bombshell\" (2019) and \"Being the Ricardos\" (2021), and independent films \"The Killing of a Sacred Deer\" (2017), \"The Beguiled\" (2017), \"The Northman\" (2022), and \"Babygirl\" (2024), winning the Volpi Cup for Best Actress for her performance in the latter. Her other notable roles include the television series \"Hemingway &amp; Gellhorn\" (2012), \"Top of the Lake: China Girl\" (2017), \"The Undoing\" (2020), \"Nine Perfect Strangers\" (2021\u2013present), \"\" (2023-present), \"Expats\" (2024), and \"The Perfect Couple\" (2024).\nKidman has served as a goodwill ambassador for UNICEF since 1994 and UNWomen since 2006. She was appointed Companion of the Order of Australia in 2006. Divorced from actor Tom Cruise and separated from country musician Keith Urban, she has two children from each relationship. In 2010, she founded the production company Blossom Films. In 2004 and 2018, \"Time\" included her on its list of the 100 most influential people in the world, and in 2020, \"The New York Times\" named her one of the greatest actors of the 21st century. She was also honored with a star on the Hollywood Walk of Fame in 2003, and in 2024, became the first Australian actor to receive the AFI Life Achievement Award.\nEarly life.\nNicole Mary Kidman was born on 20 June 1967 in Honolulu, Hawaii, while her Australian parents were temporarily in the United States on student visas. Her mother, Janelle Ann (n\u00e9e Glenny), a nursing instructor and member of the Women's Electoral Lobby, edited her husband's books; her father, Antony Kidman, was a biochemist, clinical psychologist, and author. She has a younger sister, Antonia, who is a journalist and television presenter. Having been born in the US to Australian parents, Kidman holds dual Australian and US citizenship. She has English, Irish, and Scottish ancestry. Being born in Hawaii, she was given the Hawaiian name \"H\u014dk\u016blani\" (), meaning \"heavenly star\". The inspiration came from a baby elephant born around the same time at the Honolulu Zoo.\nWhen Kidman was born, her father was a graduate student at the University of Hawai\u02bbi at M\u0101noa. He became a visiting fellow at the National Institute of Mental Health. While living in Washington, D.C., following Kidman's birth during the Vietnam War, her parents participated in anti-Vietnam War protests. Her family eventually returned to Australia three years later. She grew up in the Longueville suburb of Sydney, where she attended Lane Cove Public School and North Sydney Girls High School. She was enrolled in ballet at the age of three and showed her natural talent for acting during her primary and high school years.\nKidman has said she first aspired to become an actress upon watching Margaret Hamilton's performance as the Wicked Witch of the West in \"The Wizard of Oz\". She revealed that she was timid as a child, saying, \"I am very shy\u00a0\u2013 really shy\u00a0\u2013 I even had a stutter as a kid, which I slowly got over, but I still regress into that shyness. So I don't like walking into a crowded restaurant by myself; I don't like going to a party by myself.\" During her teenage years, she attended the Phillip Street Theatre, alongside fellow actress Naomi Watts, and the Australian Theatre for Young People, where she took up drama and mime as she found acting to be a refuge. Owing to her fair skin and naturally red hair, the sun drove her to rehearse in the halls of the theatre. A regular at the Phillip Street Theatre, she was encouraged to pursue acting full-time, which she did by dropping out of high school.\nCareer.\nEarly work and breakthrough (1983\u20131994).\nIn 1983, 16-year-old Kidman made her film debut in a remake of the Australian holiday classic \"Bush Christmas\". By the end of that year, she had a supporting role in the television series \"Five Mile Creek\". In 1984, her mother was diagnosed with breast cancer, which caused Kidman to halt her acting work temporarily while she studied massage therapy to help her mother with physical therapy. She began gaining recognition during this decade after appearing in several Australian films, such as the action comedy \"BMX Bandits\" (1983) and the romantic comedy \"Windrider\" (1986). Throughout the rest of the 1980s, she appeared in various Australian television programs, including the 1987 miniseries \"Vietnam\", for which she won her first Australian Film Institute Award.\nKidman next appeared in the Australian film \"Emerald City\" (1988), based on the play of the same name, which earned her a second Australian Film Institute Award. She then starred alongside Sam Neill in the 1989 thriller \"Dead Calm\" as Rae Ingram, the wife of a naval officer who is menaced by a castaway at sea, played by Billy Zane. The film proved to be her breakthrough role, one of the first films for which she gained international recognition. Regarding her performance, \"Variety\" commented how \"throughout the film, Kidman is excellent. She gives the character of Rae real tenacity and energy.\" Meanwhile, critic Roger Ebert noted the excellent chemistry between the leads, stating, \"Kidman and Zane do generate real, palpable hatred in their scenes together.\" She followed that up with the Australian miniseries \"Bangkok Hilton\" before moving on to star alongside her then-boyfriend and future husband, Tom Cruise, in the 1990 sports action film \"Days of Thunder\", as a young doctor who falls in love with a NASCAR driver. It was considered her international breakout film and was among the year's highest-grossing films.\nIn 1991, Kidman co-starred alongside Thandiwe Newton and former classmate Naomi Watts in the Australian independent film \"Flirting\". They portrayed high school girls in this coming of age story, which won the Australian Film Institute Award for Best Film. That same year, her work in the film \"Billy Bathgate\" earned Kidman her first Golden Globe Award nomination, for Best Supporting Actress. \"The New York Times\", in its film review, called her \"a beauty with, it seems, a sense of humor\". The following year, she and Cruise re-teamed for Ron Howard's Irish epic \"Far and Away\" (1992), which was a modest critical and commercial success. In 1993, she starred in the thriller \"Malice\", opposite Alec Baldwin, and the drama \"My Life\", opposite Michael Keaton.\nCritical acclaim and worldwide recognition (1995\u20132003).\nIn 1995, Kidman played Dr. Chase Meridian, the damsel in distress, in the superhero film \"Batman Forever\", opposite Val Kilmer as the film's title character. That same year, she starred in Gus Van Sant's critically acclaimed dark comedy \"To Die For\", in which she played the murderous newscaster Suzanne Stone. Regarding her performance, Mick LaSalle of the \"San Francisco Chronicle\" said \"[she] brings to the role layers of meaning, intention and impulse. Telling her story in close-up \u2013 as she does throughout the film \u2013 Kidman lets you see the calculation, the wheels turning, the transparent efforts to charm that succeed in charming all the same.\" For her performance in the film, she received the Golden Globe Award for Best Actress in a Motion Picture - Musical or Comedy. In the following years, she appeared alongside Barbara Hershey and John Malkovich in \"The Portrait of a Lady\" (1996), based on the novel of the same name, and starred in \"The Peacemaker\" (1997) as nuclear expert Dr. Julia Kelly, opposite George Clooney. The latter film grossed US$110\u00a0million worldwide. In 1998, she starred alongside Sandra Bullock in the romantic comedy \"Practical Magic\" as two witch sisters who face a threatening curse that prevents them from finding lasting love. While the film opened at the top of the charts during its North American opening weekend, it was a commercial failure at the box office. She returned to the stage that same year for the David Hare play \"The Blue Room\", which opened in London. For her performance, she received a Laurence Olivier Award nomination for Best Actress.\nIn 1999, Kidman reunited with then-husband Tom Cruise to portray a couple on a sexual odyssey in \"Eyes Wide Shut\", their third film together and the final film of director Stanley Kubrick. It was subject to censorship controversies due to the explicit nature of its sex scenes. After a brief hiatus and a highly publicised divorce from Cruise, Kidman returned to the screen to play a mail-order bride in the British-American drama \"Birthday Girl\". In 2001, she took on the role of cabaret actress and courtesan Satine in Baz Luhrmann's musical \"Moulin Rouge!\", opposite Ewan McGregor. Her performance and her singing received positive reviews; Paul Clinton of CNN called it her best work since \"To Die For\", and wrote \"[she] is smoldering and stunning as Satine. She moves with total confidence throughout the film ... Kidman seems to specialize in 'ice queen' characters, but with Satine, she allows herself to thaw, just a bit.\" She subsequently received her second Golden Globe Award for Best Actress \u2013 Motion Picture Comedy or Musical, among several other awards and nominations, including her first nomination for the Academy Award for Best Actress.\nAlso in 2001, Kidman starred in Alejandro Amen\u00e1bar's psychological horror film \"The Others\" (2001) as Grace Stewart, a mother living in the Channel Islands during World War II who suspects her house is haunted. Grossing over US$210\u00a0million worldwide, her performance earned her several award nominations, including a Goya Award nomination for Best Actress, in addition to receiving her second BAFTA Award and fifth Golden Globe Award nominations. Roger Ebert commented that \"Alejandro Amen\u00e1bar has the patience to create a languorous, dreamy atmosphere, and Nicole Kidman succeeds in convincing us that she is a normal person in a disturbing situation, and not just a standard-issue horror movie hysteric.\" A. O. Scott of \"The New York Times\" highlighted Kidman's performance, writing that she \"embodies this unstable amalgam with a conviction that is in itself terrifying. The icy reserve that sometimes stands in the way of her expressive gifts here becomes the foundation of her most emotionally layered performance to date.\"\nThe following year, Kidman garnered critical acclaim for her portrayal of Virginia Woolf in Stephen Daldry's \"The Hours\", co-starring alongside Meryl Streep and Julianne Moore. Kidman wore prosthetics, which were applied to her nose, to portray the author during the 1920s in England, making her look almost unrecognisable. The film was a critical success, earning several awards and nominations, including a nomination for the Academy Award for Best Picture. \"The New York Times\" wrote that \"Ms. Kidman, in a performance of astounding bravery, evokes the savage inner war waged by a brilliant mind against a system of faulty wiring that transmits a searing, crazy static into her brain.\" She won numerous critic and industry awards for her performance, including her first BAFTA Award, third Golden Globe Award, and the Academy Award for Best Actress, becoming the first Australian to win the award. During her Oscar's acceptance speech, she referenced the Iraq War which was occurring at the time when speaking about the importance of art saying, \"Why do you come to the Academy Awards when the world is in such turmoil? Because art is important. And because you believe in what you do and you want to honour that, and it is a tradition that needs to be upheld.\" That same year, she was named the World's Most Beautiful Person by \"People\" magazine.\nFollowing her Oscar win, Kidman appeared in three distinctly different films in 2003. The first of those, a leading role in director Lars von Trier's \"Dogville\", was an experimental film set on a bare soundstage. Though the film divided critics in the United States, Kidman earned praise for her performance. Peter Travers of \"Rolling Stone\" stated, \"Kidman gives the most emotionally bruising performance of her career in \"Dogville\", a movie that never met a cliche it didn't stomp on.\" The second film was an adaptation of Philip Roth's novel \"The Human Stain\", opposite Anthony Hopkins. Her third film that year was Anthony Minghella's war drama \"Cold Mountain\", where she starred opposite Jude Law and Ren\u00e9e Zellweger, playing southerner Ada Monroe, a woman who falls in love with Law's character. They became separated by the American Civil War. Regarding her performance, \"Time\" magazine wrote, \"Kidman takes strength from Ada's plight and grows steadily, literally luminous. Her sculptural pallor gives way to warm radiance in the firelight.\" The film garnered several awards and nominations, most notably for the performances of the cast, with Kidman receiving her sixth Golden Globe Award nomination for Best Actress.\nEstablished actress (2004\u20132009).\nIn 2004, Kidman starred in the drama film \"Birth\", which sparked controversy over a scene in which she shares a bath with her co-star Cameron Bright, then aged ten. During a press conference at the 61st Venice International Film Festival, she addressed the controversy, saying, \"It wasn't that I wanted to make a film where I kiss a 10-year-old boy. I wanted to make a film where you understand love.\" For her performance, she received her seventh Golden Globe nomination. That same year, she starred alongside Matthew Broderick, Bette Midler, Christopher Walken and Glenn Close in the black comedy science-fiction film \"The Stepford Wives\", a remake of the 1975 film of the same name, directed by Frank Oz. The following year, she starred opposite Sean Penn in the Sydney Pollack thriller \"The Interpreter\", playing UN translator Silvia Broome, and starred alongside Will Ferrell in the romantic comedy \"Bewitched\", based on the 1960s TV sitcom of the same name. While neither film performed well in the United States, both were international successes. For the latter film, she and Ferrell earned the Razzie Award for Worst Screen Couple.\nIn conjunction with her success within the film industry, Kidman became the face of the Chanel No. 5 perfume brand. She starred in a television and print ads campaign with Rodrigo Santoro, directed by \"Moulin Rouge!\" director Baz Luhrmann, to promote the fragrance during the holiday seasons of 2004, 2005, 2006, and 2008. \"No. 5 the Film\", a three-minute commercial produced for Chanel No. 5, made Kidman the record holder for the most money paid per minute to an actor after she reportedly earned US$12\u00a0million for the three-minute advert. During this time, she was also featured as the 45th Most Powerful Celebrity on \"Forbes\"' 2005 Celebrity 100 List. She reportedly earned US$14.5\u00a0million between 2004 and 2005. On \"People\" magazine's list of 2005's highest-paid actresses, Kidman came in second behind Julia Roberts, with a US$16\u201317\u00a0million per-film price tag.\nIn 2006, Kidman portrayed photographer Diane Arbus in the biographical film \"Fur\", opposite Robert Downey Jr., and lent her voice to the animated film \"Happy Feet\", which grossed over US$384\u00a0million worldwide, becoming her highest-grossing film at the time. The following year, she starred in the science-fiction film \"The Invasion\", a remake of the 1956 \"Invasion of the Body Snatchers\", directed by Oliver Hirschbiegel, and starred opposite Jennifer Jason Leigh and Jack Black in Noah Baumbach's comedy-drama \"Margot at the Wedding\", which earned her a Satellite Award nomination for Best Actress \u2013 Musical or Comedy. Also in 2007, she starred as the main antagonist Marisa Coulter in the fantasy-adventure film \"The Golden Compass\", which grossed over US$370\u00a0million worldwide, also becoming one of her highest-grossing films to date.\nThe following year, Kidman reunited with \"Moulin Rouge!\" director Baz Luhrmann for the Australian period film \"Australia\" (2008), set in the remote Northern Territory during the Japanese attack on Darwin during World War II. Starring opposite Hugh Jackman, she played an Englishwoman feeling overwhelmed by the continent. Though the film received mixed reviews from critics, it turned out to be a box office success, grossing over $211\u00a0million worldwide against a budget of $130\u00a0million. In 2009, she appeared in the Rob Marshall musical \"Nine\", portraying the muse Claudia Jenssen, alongside an ensemble cast consisting of Daniel Day-Lewis, Marion Cotillard, Pen\u00e9lope Cruz, Judi Dench, Fergie, Kate Hudson and Sophia Loren. Kidman, whose screen time was brief in comparison to the other actresses, performed the musical number \"Unusual Way\" alongside Day-Lewis. The film received several Golden Globe Award and Academy Award nominations, with Kidman earning her fourth Screen Actors Guild Award nomination, as part of the Outstanding Performance by a Cast in a Motion Picture award.\nBiographical and independent films (2010\u20132016).\nKidman began the 2010s by producing and starring in the film adaptation of the Pulitzer Prize-winning play \"Rabbit Hole\", alongside Aaron Eckhart. Her performance as a grieving mother coping with the death of her son earned her critical acclaim, and she received nominations for the Academy Award, Golden Globe Award and Screen Actors Guild Award for Best Actress. The following year, she appeared with Adam Sandler and Jennifer Aniston in Dennis Dugan's romantic comedy \"Just Go with It\", as a trophy wife, and subsequently starred alongside Nicolas Cage in director Joel Schumacher's action-thriller \"Trespass\", with the stars playing a married couple taken hostage.\nIn 2012, Kidman starred alongside Clive Owen in the HBO film \"Hemingway &amp; Gellhorn\", which depicted the relationship between journalist couple Ernest Hemingway and Martha Gellhorn. For her performance as Gellhorn, she received her first Primetime Emmy Award nomination for Outstanding Lead Actress in a Miniseries or Movie. That same year, she portrayed death row groupie Charlotte Bless in Lee Daniels' adaptation of the Pete Dexter novel, \"The Paperboy\" (2012). The film competed at the 2012 Cannes Film Festival and Kidman's performance garnered her nominations for the Screen Actors Guild Award and the Saturn Award for Best Supporting Actress, in addition to her second Golden Globe Award nomination for Best Supporting Actress, her tenth nomination overall. Also in 2012, her audiobook recording of Virginia Woolf's \"To the Lighthouse\" was released through Audible. The following year she starred as an unstable mother in Park Chan-wook's \"Stoker\", which was released to positive reception and a Saturn Award nomination for Best Supporting Actress. In April 2013, she was selected as a member of the main competition jury at the 2013 Cannes Film Festival.\nIn 2014, Kidman starred as the titular character in the biographical film \"Grace of Monaco\", which chronicles the 1962 crisis in which Charles de Gaulle blockaded the tiny principality, angered by Monaco's status as a tax haven for wealthy French subjects and Kelly's contemplative Hollywood return to star in Alfred Hitchcock's \"Marnie\". Opening out of competition at the 2014 Cannes Film Festival, the film received largely negative reviews. She also starred in two films with Colin Firth that year, the first being the British-Australian historical drama \"The Railway Man\", in which she played an officer's wife. Katherine Monk of the Montreal Gazette said of Kidman's performance, \"It's a truly masterful piece of acting that transcends Teplitzky's store-bought framing, but it's Kidman who delivers the biggest surprise: For the first time since her eyebrows turned into solid marble arches, the Australian Oscar winner is truly terrific\". Her second film with Firth was the British thriller film \"Before I Go to Sleep\", portraying a car crash survivor with brain damage. Also in 2014, she appeared in the live-action animated comedy film \"Paddington\" as the film's main antagonist.\nIn 2015, Kidman starred in the drama \"Strangerland\", which opened at the 2015 Sundance Film Festival, and the Jason Bateman-directed \"The Family Fang\", produced by Kidman's production company, Blossom Films, which premiered at the 2015 Toronto International Film Festival. In her other 2015 film release, the biographical drama \"Queen of the Desert\", she portrayed writer, traveller, political officer, administrator and archaeologist Gertrude Bell. That same year, she played a district attorney, opposite Julia Roberts and Chiwetel Ejiofor, in the film \"Secret in Their Eyes\", a remake of the 2009 Argentine film of the same name, both based on the novel \"La pregunta de sus ojos\" by author Eduardo Sacheri. After more than 15 years, she returned to the West End in the UK premiere of \"Photograph 51\" at the No\u00ebl Coward Theatre. She starred as British scientist Rosalind Franklin, working for the discovery of the structure of DNA, in the production from 5 September to 21 November 2015, directed by Michael Grandage. The production was met with considerable praise from critics, particularly for Kidman, and her return to the West End was hailed a success. For her performance, she won an Evening Standard Theatre Award and received a second Laurence Olivier Award nomination for Best Actress.\nIn 2016's \"Lion\", Kidman portrayed Sue, the adoptive mother of Saroo Brierley, an Indian boy who was separated from his birth family, a role she felt connected to as she is the mother of adopted children. She received positive reviews for her performance, in addition to her first nomination for the Academy Award for Best Supporting Actress, her fourth nomination overall, and her eleventh Golden Globe Award nomination, among several others. Richard Roeper of the \"Chicago Sun-Times\" thought that \"Kidman gives a powerful and moving performance as Saroo's adoptive mother, who loves her son with every molecule of her being, but comes to understand his quest. It's as good as anything she's done in the last decade.\" Budgeted at US$12\u00a0million, \"Lion\" earned over US$140\u00a0million globally. She also gave a voice-over performance for the English version of the animated film \"The Guardian Brothers\".\nTelevision expansion and continued acclaim (2017\u20132020).\nIn 2017, Kidman returned to television for \"Big Little Lies\", a drama series based on Liane Moriarty's novel of the same name, which premiered on HBO. She also served as executive producer alongside her co-star, Reese Witherspoon, and the show's director, Jean-Marc Vall\u00e9e. She played Celeste Wright, a former lawyer and housewife, who conceals an abusive relationship with her husband, played by Alexander Skarsg\u00e5rd. Matthew Jacobs of \"The Huffington Post\" considered that she \"delivered a career-defining performance\", while Ann Hornaday of \"The Washington Post\" wrote that \"Kidman belongs in the pantheon of great actresses\". She won the Primetime Emmy Award for Outstanding Lead Actress in a Limited Series or Movie for her performance, as well as the Primetime Emmy Award for Outstanding Limited Series as a producer. She also received a Screen Actors Guild Award, two Critics' Choice Television Awards and two Golden Globe Awards for her work in the show.\nKidman next played Martha Farnsworth, the headmistress of an all-girls school during the American Civil War, in Sofia Coppola's drama \"The Beguiled\", a remake of the 1971 film of the same name, which premiered at the 2017 Cannes Film Festival, competing for the Palme d'Or. Both films were adaptations of a novel by Thomas P. Cullinan. The film was an arthouse success, and Katie Walsh of the \"Tribune News Service\" found Kidman \"particularly, unsurprisingly excellent in her performance as the steely Miss Martha. She is controlled and in control, unflappable. Her genteel manners and femininity co-exist easily with her toughness.\" Kidman had two other films premiere at the festival: the science-fiction romantic comedy \"How to Talk to Girls at Parties\", reuniting her with director John Cameron Mitchell, and the psychological thriller \"The Killing of a Sacred Deer\", directed by Yorgos Lanthimos, which also competed for the Palme d'Or. Also in 2017, she played supporting roles in the BBC Two television series \"\" and in the comedy-drama \"The Upside\", a remake of the 2011 French comedy \"The Intouchables\", starring Bryan Cranston and Kevin Hart.\nIn 2018, Kidman starred in two dramas, \"Destroyer\" and \"Boy Erased\". In the former, she played a detective troubled by a case for two decades. Peter Debruge of \"Variety\" and Brooke Marine of \"W\" both found her \"unrecognizable\" in the role and Debruge added that \"she disappears into an entirely new skin, rearranging her insides to fit the character's tough hide\", whereas Marine highlighted Kidman's method acting. The latter film is based on Garrard Conley's \"\", and features Russell Crowe and Kidman as socially conservative parents who send their son (played by Lucas Hedges) to a gay conversion program. Richard Lawson of \"Vanity Fair\" credited all three performers for \"elevating the fairly standard-issue material to poignant highs\". That same year, Kidman took on the role of Queen Atlanna, the mother of the title character, in the DC Extended Universe superhero film \"Aquaman\", which grossed over US$1.1\u00a0billion worldwide, becoming her highest-grossing film to date. Also in 2018, she was interviewed for a BAFTA event \"A Life in Pictures\", where she reflected on her extensive film career.\n\"Forbes\" ranked her as the fourth highest-paid actress in the world in 2019, with an annual income of $34\u00a0million. Kidman kicked off 2019 by reprising her role in the second season of the hit series \"Big Little Lies\", which premiered in June. The second season not only drew a larger audience than the first but also became the most-watched night of viewing for an HBO original series that year. In September 2019, she took on the supporting part of a rich socialite in John Crowley's drama \"The Goldfinch\", an adaptation of the novel of the same name by Donna Tartt, starring Ansel Elgort. Although it was poorly received, Owen Gleiberman commended Kidman for playing her part with \"elegant affection\". She next co-starred alongside Charlize Theron and Margot Robbie in the drama \"Bombshell\", a film depicting the scandal concerning the sexual harassment accusations against former Fox News CEO Roger Ailes, in which she portrayed journalist Gretchen Carlson. Manohla Dargis of \"The New York Times\" opined that despite lesser screen time than her two co-protagonists, Kidman successfully made Carlson \"ever-so-slightly ridiculous, adding a sharp sliver of comedy that underscores how self-serving and futile her rebellious gestures at the network are\". For her performance, she received an additional Screen Actors Guild Award nomination for Outstanding Performance by a Female Actor in a Supporting Role.\nKidman started off the 2020s with her role of Grace Fraser, a successful New York therapist, in the HBO psychological thriller miniseries \"The Undoing\", based on the novel \"You Should Have Known\" by Jean Hanff Korelitz. She served as executive producer alongside the show's director, Susanne Bier, and David E. Kelley, who previously adapted and produced \"Big Little Lies\". Throughout its season, the series gained increasing momentum and broke records. HBO celebrated a historic achievement as the show became the network's first original series to increase its viewership consistently week by week. The finale marked the most-watched night on HBO since the season 2 finale of \"Big Little Lies\". Furthermore, the series surpassed \"Big Little Lies\" to become HBO's most-watched show of 2020 based on audience numbers. For her performance, she received additional Golden Globe Award and Screen Actors Guild Award nominations. Her only film release of 2020 was the musical comedy \"The Prom\", based on the Broadway musical of the same name, starring alongside Meryl Streep, James Corden and Keegan-Michael Key.\nTelevision and independent films (2021\u2013present).\nIn August 2021, she starred and served as executive producer on the Hulu drama series \"Nine Perfect Strangers\", based on the novel of the same name by Liane Moriarty. Despite receiving mixed reviews, it was reported that the premiere of the show became the most-watched Hulu original on its premiere day and continued to hold that title after five days on the service. That same year, she portrayed actress-comedian Lucille Ball alongside Javier Bardem as Ball's husband, Desi Arnaz, in the biographical drama \"Being the Ricardos\", directed by Aaron Sorkin. Despite unfavourable reactions in response to her casting as Ball, her portrayal was met with critical acclaim. She subsequently won the Golden Globe Award for Best Actress in a Motion Picture \u2013 Drama for her performance, in addition to receiving nominations for the Critics' Choice Movie Award for Best Actress and the Screen Actors Guild Award for Outstanding Performance by a Female Actor in a Leading Role, as well as her fourth Academy Award nomination for Best Actress, her fifth nomination overall.\nIn September 2021, Kidman starred in a commercial for AMC Theatres entitled \"We Make Movies Better\", which would play before every film in the theatres owned by the chain beginning that month and Kidman's sponsorship was later extended for another year in August 2022. The commercial and Kidman's delivery of her speech proved popular with audiences who viewed it as a way to drive moviegoers back to seeing films theatrically in the midst of the COVID-19 pandemic. AMC's CEO Adam Aron described Kidman's viral ad as \"iconic and revered\" during a 2022 earnings call and CNN reported that the ad \"has inspired memes, homages and debate\" and became a \"cultural thing\".\nIn April 2022, Kidman appeared in an episode of the anthology series \"Roar\", based on Cecelia Ahern's 2018 short story collection, in addition to serving as executive producer. The miniseries attracted mixed attention due to its unconventional and controversial feminist themes. That same month, she starred alongside her \"Big Little Lies\" co-star Alexander Skarsg\u00e5rd, Anya Taylor-Joy, Ethan Hawke and Willem Dafoe in the historical drama \"The Northman\", directed by Robert Eggers. The film was received with widespread acclaim upon its release.\nIn 2023, Kidman began starring in the Paramount+ television series \"\", on which she also serves as an executive producer. The miniseries received mixed attention upon release and reviewer Anita Singh of \"The Telegraph\" criticised \"the one thing that lets the show down is Nicole Kidman as a CIA boss, whose frozen face these days is a total distraction\". Initially, reviewer Mike Hale, writing for \"The New York Times\", remarked that the show resembled many other counterterrorism thrillers, noting its visceral action and somewhat artificial setting in the first episode. However, upon further reflection, he found that the show evolved into a moody, suspenseful, and intricately crafted genre piece with compelling characters. In December 2023, Kidman reprised the role of Queen Atlanna in the sequel to the 2018 superhero film \"Aquaman\", titled \"Aquaman and the Lost Kingdom\".\n\"Forbes\" ranked her as the highest-paid actress in the world in 2024, with an annual income of $31 million. In January 2024, Kidman starred in and served as executive producer of the drama television series \"Expats.\" Her performance garnered mixed reviews from critics. In June 2024, she reunited with her \"The Paperboy\" co-star Zac Efron in Netflix's \"A Family Affair\". Although it received mixed reviews from critics, the film was well received by audiences. It achieved the #1 spot among Netflix originals during its first weekend and maintained a strong position at #2 on the second weekend of its release. Kidman portrayed a high-ranking CEO in the A24 erotic thriller \"Babygirl\" written and directed by Halina Reijn. Robbie Collin of \"The Telegraph\" highlighted Kidman's work as \"ferociously good, convincing utterly as this formerly level-headed careerist whose deeply buried, long-denied appetites are simultaneously proving her making and downfall.\" For her performance, she received the Volpi Cup for Best Actress at the 81st Venice International Film Festival. Kidman was absent from the ceremony due to the death of her mother. She was also nominated for the Golden Globe Award for Best Actress in a Motion Picture \u2013 Drama and subsequently earned her first Best Actress win at National Board of Review Awards for her performance.\nIn September 2024, Kidman starred in, and served as executive producer on the Netflix series \"The Perfect Couple\", based on Elin Hilderbrand's novel. The series received mixed reviews from critics with many reviews criticizing Kidman for her constantly repeating herself. However, it became Netflix's global hit leading the charts for two consecutive weeks before dropping but still maintaining strong positions for the following weeks. In October 2024, Kidman starred in the second season of the television series \"Lioness\", on which she earned a nomination for Critics' Choice Television Award for Best Supporting Actress in a Drama Series and was executive producer. In November 2024, Kidman was voiced Queen Ellsmere in the animated fantasy film \"Spellbound\". The film received mixed reviews mainly for its subject matter; however, it managed to place #3 and #2 position in Netflix's top series for the first and second week since its release.\nIn March 2025, Kidman portrayed Nancy, a teacher in Amazon's \"Holland\" directed by Mimi Cave and executive produced \"The Last Anniversary\", adapted from Liane Moriarty's novel.\nKidman is also set to star in, and serve as executive producer on, numerous projects, including an Amazon Prime Video \"Scarpetta\" series based on Patricia Cornwell's Kay Scarpetta novels and the Apple TV+ series \"Margo's Got Money Troubles\".\nReception and legacy.\nKidman is often regarded to be among the finest actresses of her generation. She is also considered one of Hollywood\u2019s bravest performers. She has been noted for seeking eccentric roles in risky projects helmed by auteurs, as well as for her volatile performances and versatile work, having appeared in a variety of eclectic films from several genres throughout her extensive career spanning nearly four decades. \"Vanity Fair\" stated that, despite struggling with her personal life being publicly scrutinised by the media during the early years of her career, \"[Kidman] has shown herself to be a major talent, a remarkable actress who can get in there with the best of them, go toe-to-toe, and come out with her credibility intact. What's more, she's proved herself to be a star with a capital S, the one-in-a-generation kind who, like Elizabeth Taylor, is bigger than the Hollywood system, and is also unafraid to be human and real, which only makes her more popular.\" According to \"The New York Times\", \"the plucky, disciplined indomitability she brings to her performances, even more than the artistry she displays within them, may be the secret of her appeal, the source of her bond with the audience.\" Emily Nussbaum of \"The New Yorker\" commented how \"in each role, there is something waxen and watchful and self-possessed about Kidman, so that, even when she's smiling, she never seems liberated. While other actors specialize in transparency, Kidman has a different gift: she can wear a mask and simultaneously let you feel what it's like to hide behind it.\" Kidman\u2019s most remarkable accomplishment lies in her ability to consistently deliver surprising performances, often standing out as the highlight even in otherwise lackluster projects. She remains a captivating figure, sparking more conversation and strong opinions than nearly anyone else in the industry. Leila Latif of \"The Guardian\" commented that Kidman continuously proved again and again \"why she is one of Hollywood\u2019s best and subtly most transgressive stars.\" In 2004 and 2018, \"Time\" magazine named Kidman one of the 100 most influential people in the world on their annual \"Time\" 100 list. In 2020, \"The New York Times\" ranked her fifth on its list of the greatest actors of the 21st century, and in a 2022 readers' poll by \"Empire\" magazine, she was voted one of the 50 greatest actors of all time. In 2025, Kidman was named one of the Women of the Year of \"Time\" magazine.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"I'm a character [actor]. I was trained as a character actor. That's what I want to do. I believe in changing the way you look, the way you move, the way you speak. I'm not great at playing myself, so what really gives me the greatest satisfaction is changing into something else.\"\n\u2014 Kidman on her approach to acting\nKidman continues to defy age-related stereotypes in Hollywood, thriving in an industry often criticized for its challenges for women over 50. Her ability to secure leading roles and produce compelling work highlights her resilience and determination, proving that age is no barrier to success in her career. Kidman\u2019s journey inspires, challenging the industry\u2019s norms and paving the way for other women in Hollywood.\nKidman is known to practice method acting for many of her roles. It has been noted that she oftentimes transforms herself physically, mentally and emotionally to resemble her characters, to the point where it has adversely affected her health. Mark Caro from the \"Los Angeles Times\" stated that \"to Nicole Kidman, acting isn't a mere technical feat; it's the art of transformation. To hear her tell it, the change can be as dramatic as a caterpillar-into-butterfly metamorphosis. She'll be working and working to get under the skin of a character.\" \"W\" described her as a \"cipher\", and pointed out how \"she gets under her character's skin so thoroughly, it's nearly impossible to distinguish the actress from the role. It's why she has become so synonymous with a few key roles ... and why those films are so defined by Kidman's presence in them.\"\nScholars have also commented on her acting style and approach to roles. Sharon Marie Carnicke, a professor of critical studies and acting at the USC School of Dramatic Arts, mentioned that \"Kidman's [acting] choices are believable and natural as reactions to the specific circumstances in her world\" and described her work as \"kinetic\". Dennis Bingham, a professor of English and director of film studies at Indiana University\u2013Purdue University Indianapolis, stated that \"Kidman acts always a step or two outside the character, telegraphing her reactions, elongating the time she takes to articulate her decisions and conclusions. Even her emotional responses are presented as signs.\" Pam Cook, a professor of film at the University of Southampton, suggests in her biography of Kidman that \"her emphasis on artifice and technique points to a conception of screen acting that looks to cinematic expression rather than to the actor's body and intentions for the realisation of character.\" Mary Luckhurst, a professor and head of the University of Bristol School of Arts with credentials in theatre and performance, stated how \"she has strategically pursued a high-risk mutability and versatility, and regularly traverses between naturalist and non-naturalist roles and artforms.\" She continues saying that \"she can continually test her own emotional limits, physical skills, politics, values and frames of reference\" and mentions how \"her conception of character acting involves metamorphosing gradually into something that she feels is so 'other' that she frequently speaks of losing herself or getting lost in the role, and her preparedness to challenge herself in this respect has continually surprised other actors, directors and producers.\"\nAfter nearly four decades in the industry and over 80 film and TV projects, Kidman emphasizes her acting approach, saying, \"I still approach acting like I\u2019ve just come out of drama school.\"\nArte France released a 53-minute documentary in 2023, \"Nicole Kidman \u2013 Eyes Wide Open\".\nKidman has also been described as a fashion icon. The chartreuse Dior gown she wore to the 1997 Academy Awards is regarded as one of the greatest dresses in Oscar history and has been credited with changing red carpet fashion forever. \"Vogue\" described how \"from her embroidered chartreuse John Galliano for Christian Dior gown in 1997, at the side of then-husband Tom Cruise, to that impeccable red Balenciaga moment at the 2007 Oscars, to the unforgettable Calvin Klein ballerina dress she wore to the 2017 Cannes Film Festival, the Australian native has mastered the art of red carpet dressing, always piquing our [interest] and taking risks while never overdoing it.\" \"Insider\" stated that \"over the years, Kidman has experimented with all sorts of trends, including bold colors, statement jewelry, and everything in between, making herself one of the most iconic celebrities when it comes to her fashion choices.\" In 2003, she received the Fashion Icon Award, which was awarded to her by the Council of Fashion Designers of America. Regarding her bestowal, Peter Arnold, executive director of the CFDA, said, \"Nicole Kidman's style, both on and off the screen, has had an undeniable impact on fashion. As an actress, she has developed her many memorable characters with an innate understanding of the artistry of clothes. At the same time, she has elegantly established her personal style and own iconic presence worldwide.\"\nWorking with female filmmakers.\nIn 2017, Kidman has pledged to collaborate with a female director every 18 months to address gender disparities in the film industry. This commitment has led to her involvement in numerous projects, including \"The Perfect Couple\" where she portrays Greer Garrison Winbury, a role reminiscent of her previous characters in \"Big Little Lies\" and \"The Undoing\". Some critics argued that such choices resulted in repetitive portrayals, potentially diminishing the impact of her performances. \nDespite criticisms, Kidman continues to support female filmmakers, contributing to increased representation in the industry and creating more jobs.\nIn a February 2025 interview with \"Time\", she reflected on her career, emphasizing the importance of humility, continuous learning, and taking risks in her craft. Kidman also highlighted her commitment to telling diverse stories and supporting female filmmakers, aiming to create more opportunities for women in the industry. Her efforts have elevated her career and inspired a new generation of talent, solidifying her legacy as both an artist and a trailblazer.\nHalina Reijn, director of \"Babygirl\", highlighted her experience with Kidman, stating, \"She is one of the few people who practices what she preaches when it comes to feminism and empowering women.\" Mimi Cave, director of \"Holland\", reflected on working with Kidman, saying that she \"makes herself completely available to you as a director\" and praising her collaborative spirit. She added, \"She's really incredible to watch and she's someone I've learned a great deal from. It was a pretty magnificent experience for me,\" underscoring Kidman's professionalism and the lasting impression she leaves on collaborators. Lulu Wang, director of \"Expats\", praised Kidman, stating, \"Nicole, being able to support me, created this entire network and world of filmmakers, women, people of color who\u2019ve never had the opportunity to be in this space.\" Jamie Lee Curtis, Kidman's co-star in \"Scarpetta\", shared that \"People work when Nicole works. I\u2019m working because Nicole is working.\"\nAs of February 2025, Kidman has worked with 19 female directors, either in an acting or producing capacity, over the past eight years to champion gender equality in Hollywood.\nPersonal life.\nRelationships and family.\nKidman met US actor Tom Cruise in 1989 while working on the set of \"Days of Thunder\", a film in which both starred, and they married on Christmas Eve of 1990 in Colorado. While married, the couple adopted a daughter and a son. On 5 February 2001, the couple's spokesperson announced their separation. Cruise filed for divorce two days later, and their marriage was dissolved later that year, with Cruise citing irreconcilable differences. In 2013, Kidman said their marriage failed because of her young age when they married. \"I was a child, really, when I got married,\" she said. \"And I needed to grow up.\" In a 2007 interview with \"Marie Claire\", Kidman noted the incorrect reporting of a miscarriage early in her marriage: \"It was wrongly reported as miscarriage by everyone who picked up the story. So it's huge news, and it didn't happen. I had a miscarriage at the end of my marriage, but I had an ectopic pregnancy at the beginning of my marriage.\"\nKidman described the divorce as a \"major shock\" and said of Cruise: \"He was huge; still is. To me, he was just Tom, but to everybody else, he is huge. But he was lovely to me and I loved him. I still love him.\" In 2015, former Church of Scientology executive Mark Rathbun said in a documentary film that he was instructed to \"facilitate [Cruise's] break-up with Nicole Kidman\". Cruise's Scientology auditor said Kidman had been wiretapped on Cruise's suggestion. In 2015, Kidman said her divorce from Cruise led her to focus her attention on her career. She stated, \"Out of my divorce came work that was applauded, so that was an interesting thing for me.\"\nBefore marrying Cruise, Kidman had been in relationships with Australian actor Marcus Graham and \"Windrider\" co-star Tom Burlinson. The film \"Cold Mountain\" brought rumours that an affair between Kidman and co-star Jude Law was responsible for the break-up of his marriage. Both denied the allegations, and Kidman won an undisclosed sum from the British tabloids that published the story. She began dating musician Lenny Kravitz in 2003. According to Kidman, they were engaged before deciding to end their relationship. However, they remain on good terms. Kravitz's daughter, Zo\u00eb Kravitz, later said that Kidman was a loving potential stepmother to her. In 2003, she briefly dated A Tribe Called Quest rapper Q-Tip.\nIn January 2005, Kidman met Australian-American country singer Keith Urban at G'Day LA, an event honouring Australians. In May 2006, she revealed they were engaged. Kidman married Urban on 25 June 2006 at Cardinal Cerretti Memorial Chapel on the grounds of St Patrick's Estate, Manly, in Sydney. For their honeymoon, they went to French Polynesia. In a 2015 interview, regarding her relationship with Urban, Kidman said, \"We didn't really know each other \u2013 we got to know each other during our marriage.\" Urban has credited Kidman for helping him overcome his struggles with alcohol addiction. They maintain homes in Nashville (Tennessee, US), Beverly Hills (California, US), two apartments in Sydney (New South Wales, Australia), a farmhouse in Sutton Forest (New South Wales, Australia), and an apartment in Manhattan (New York, US). The couple's first daughter was born in 2008, in Nashville. In 2010, their second daughter was born via gestational surrogacy at Nashville's Centennial Women's Hospital. In September 2025, it was revealed that they had separated and that Kidman had filed for divorce citing irreconcilable differences.\nReligious beliefs and political views.\nKidman was brought up in a Catholic family. She attended Mary Mackillop Memorial Chapel and Museum in North Sydney. Following criticism by Catholic leaders regarding her role in \"The Golden Compass\" as anti-Catholic, Kidman told \"Entertainment Weekly\" that the source material had been \"watered down a little\" and that her religious beliefs would prevent her from taking a role in a film she perceived as anti-Catholic. Since her divorce from Tom Cruise, she has been reluctant to discuss Scientology.\nA supporter of women's rights, Kidman testified before the United States House of Representatives Committee on Foreign Affairs to support the International Violence Against Women Act in 2009. In January 2017, she stated her support for the legalisation of same-sex marriage in Australia. Kidman has also donated to US Democratic party candidates.\nNet worth.\nKidman has featured in annual rankings of the world's highest-paid actors multiple times, including the leading place for a female actor in 2006. In 2002, she first appeared on the \"Australian Financial Review\" Rich List, following her divorce from Tom Cruise, with an estimated net worth of A$122\u00a0million. As of \u00a02023[ [update]], Kidman's net worth, listed jointly with Urban's, was assessed at A$596\u00a0million by the \"Financial Review\", after several years of not meeting the threshold for inclusion on the Rich List. In 2021 it was reported that \"Celebrity Net Worth\" had assessed Kidman's net worth, not including that of Urban's, at US$250\u00a0million.\nNicole Kidman applied for Portuguese residency in July 2025 in order to buy a house in the luxury resort Costa Terra Golf &amp; Ocean Club in Melides. She had previously already purchased an apartment in Lisbon.\nPhilanthropy.\nKidman has raised money for, and drawn attention to, disadvantaged children around the world. In 1994, she was appointed a Goodwill ambassador for UNICEF. She also joined the Little Tee Campaign for breast cancer care to design T-shirts or vests to raise money to fight the disease; motivated by her mother's battle with breast cancer in 1984. Kidman was also appointed Goodwill ambassador of the United Nations Development Fund for Women (UNIFEM) in 2006.\nShe visited Kosovo in 2006 to learn about women's experiences of conflict and UNIFEM's support efforts. She is also the international spokesperson for UNIFEM's Say NO\u00a0\u2013 UNiTE to End Violence against Women initiative. Kidman and the UNIFEM executive director presented over five million signatures collected during the first phase of this to the UN Secretary-General on 25 November 2008. On 8 January 2010, alongside Nancy Pelosi, Joan Chen and Joe Torre, Kidman attended the ceremony to help the Family Violence Prevention Fund break ground on a new international centre located in the Presidio of San Francisco.\nIn 2014, Kidman designed a gold coloured Paddington Bear statue, one of fifty located around London prior to the release of the film \"Paddington\", which was auctioned to raise funds for the National Society for the Prevention of Cruelty to Children (NSPCC). In 2016, she donated $50,000 to UN Women.\nEndorsement deals and ventures.\nKidman has taken part in several endorsement deals representing various companies. In 2003, she served as the face of the Chanel No. 5 perfume. She has also served as an ambassador for Omega watches since 2005. In 2007, Nintendo announced that she would be the new face of Nintendo's advertising campaign for the Nintendo DS game \"More Brain Training\" in its European market. In 2010, Kidman starred in the inauguration campaign of the Brazilian mall VillageMall, owned by the company Multiplan, located in Barra da Tijuca, in Rio de Janeiro. In 2013, she served as the face of Jimmy Choo shoes. In 2015, she became the brand ambassador for Etihad Airways. In 2017, she was announced as the new face of Neutrogena. In 2020, she joined SeraLabs as their global brand ambassador. In December 2023, she joined Balenciaga as their brand ambassador.\nKidman supports the Nashville Predators, being seen and photographed almost nightly throughout the season. Additionally, she supports the Sydney Swans in the Australian Football League and once served as a club ambassador.\nActing credits and accolades.\nAccording to the review aggregation website Rotten Tomatoes, which assigns film scores based on critic reviews and audience reception, some of Kidman's highest-scoring films include \"Paddington\" (2014), \"Flirting\" (1990), \"To Die For\" (1995), \"Rabbit Hole\" (2010), \"Lion\" (2016), \"The Others\" (2001), \"The Family Fang\" (2015), \"Dead Calm\" (1989), \"Boy Erased\" (2018), \"The Killing of a Sacred Deer\" (2017) and \"The Northman\" (2022). Her most financially successful films include \"Aquaman\" (2018) and its sequel \"Aquaman and the Lost Kingdom\" (2023), \"Happy Feet\" (2006), \"The Golden Compass\" (2008), \"Batman Forever\" (1995) and \"Paddington\" (2014), as listed by the box office tracking website \"The Numbers\" as her highest-grossing films. Her other screen credits include:\nKidman has been recognized by the Academy of Motion Picture Arts and Sciences for the following:\nIn 2003, Kidman received a star on the Hollywood Walk of Fame for her achievements in the motion picture industry. In addition to her Academy Award for Best Actress win, she has received many other awards and nominations for her performances on the screen and stage, including four additional Academy Award nominations, one BAFTA Award from five nominations, two Laurence Olivier Award nominations, two Primetime Emmy Awards from three nominations, a Screen Actors Guild Award from fifteen nominations, three Critics' Choice Awards from fifteen nominations and six Golden Globe Awards from seventeen nominations, among various others. Nicole Kidman was selected for the 49th AFI Life Achievement Award, originally scheduled to be received at Hollywood's Dolby Theatre on 10 June 2023, but was postponed to 27 April 2024 due to the WGA strike.\nIn 2004, Kidman was honoured as a \"Citizen of the World\" by the United Nations. During the 2006 Australia Day Honours, she was appointed Companion of the Order of Australia (AC) for \"service to the performing arts as an acclaimed motion picture performer, to health care through contributions to improve medical treatment for women and children and advocacy for cancer research, to youth as a principal supporter of young performing artists, and to humanitarian causes in Australia and internationally\". However, due to film commitments and her wedding to Urban, it was not until 13 April 2007 that she was presented with the honour. It was presented by the Governor-General of Australia, Major General Michael Jeffery, in a ceremony at Government House, Canberra. At the beginning of 2009, Kidman appeared in a series of postage stamps featuring Australian actors. She, Geoffrey Rush, Russell Crowe, and Cate Blanchett each appear twice in the series: once as themselves and once as their Academy Award-nominated characters, with Kidman appearing as Satine from \"Moulin Rouge!\".\nDiscography.\nKidman's discography consists of several audio recordings, including one spoken word album, one extended play and three singles. Kidman, primarily known for her acting career, entered the music industry during the early 2000s after recording a number of tracks for the original motion picture soundtrack to Baz Luhrmann's 2001 musical film \"Moulin Rouge!\", which she starred in. Her duet with Ewan McGregor entitled \"Come What May\" was released as her debut single and the second single from the film's original soundtrack album through Interscope Records on 24 September 2001. The composition became the eighth-highest selling single by an Australian artist that year, being certified Gold by the Australian Recording Industry Association, while peaking at number twenty-seven on the UK singles chart. In addition, the song received a Best Original Song nomination at the 59th Golden Globe Awards and was listed at eighty-fifth within AFI's 100 Years...100 Songs by the American Film Institute.\n\"Somethin' Stupid\", a cover version of Frank and Nancy Sinatra's version, followed soon after. The track, recorded as a duet with English singer-songwriter Robbie Williams, was issued on 14 December 2001 by Chrysalis Records as the lead single off his fourth studio album, \"Swing When You're Winning\". Kidman's second single topped the official music charts in New Zealand, Portugal, and the UK, in addition to reaching top ten placings all over Europe, including Austria, Belgium, Denmark, Germany, the Netherlands, Norway and Switzerland, as well as Australia. Apart from being certified either Gold in a number of countries, it was ranked as the thirteenth best-selling single of 2002 in the UK, the fifty-ninth in Australia and the ninety-third in France, respectively. The song peaked at No. 8 on the Australian ARIAnet Singles Chart and at No. 1, for three weeks, in the UK.\nOn 5 April 2002, Kidman released through Interscope Records her third single, a cover of Randy Crawford's \"One Day I'll Fly Away\". The song, a Tony Philips remix, was promoted as the pilot single for the follow-up to the \"Moulin Rouge!\" original soundtrack, titled \"Moulin Rouge! Vol. 2\". In 2006, she contributed to the original motion picture soundtrack of \"Happy Feet\", recording a rendition of the Prince song \"Kiss\" for the film. In 2009, she was featured on the original soundtrack of Rob Marshall's 2009 musical film \"Nine\", recording the song \"Unusual Way\". In 2012, she narrated an audiobook and in 2017, she contributed with background vocals to her husband's, country music singer Keith Urban, song titled \"Female\". In 2022, Kidman joined Luke Evans to release a cover of \"Say Something\", originally performed by A Great Big World and Christina Aguilera.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21505", "revid": "42219488", "url": "https://en.wikipedia.org/wiki?curid=21505", "title": "Nucleotide", "text": "Biological molecules constituting nucleic acids\nNucleotides are organic molecules composed of a nitrogenous base, a pentose sugar and a phosphate. They serve as monomeric units of the nucleic acid polymers \u2013 deoxyribonucleic acid (DNA) and ribonucleic acid (RNA), both of which are essential biomolecules within all life-forms on Earth. Nucleotides are obtained in the diet and are also synthesized from common nutrients by the liver.\nNucleotides are composed of three subunit molecules: a nucleobase, a five-carbon sugar (ribose or deoxyribose), and a phosphate group consisting of one to three phosphates. The four nucleobases in DNA are guanine, adenine, cytosine, and thymine; in RNA, uracil is used in place of thymine.\nNucleotides also play a central role in metabolism at a fundamental, cellular level. They provide chemical energy\u2014in the form of the nucleoside triphosphates, adenosine triphosphate (ATP), guanosine triphosphate (GTP), cytidine triphosphate (CTP), and uridine triphosphate (UTP)\u2014throughout the cell for the many cellular functions that demand energy, including: amino acid, protein and cell membrane synthesis, moving the cell and cell parts (both internally and intercellularly), cell division, etc.. In addition, nucleotides participate in cell signaling (cyclic guanosine monophosphate or cGMP and cyclic adenosine monophosphate or cAMP) and are incorporated into important cofactors of enzymatic reactions (e.g., coenzyme A, FAD, FMN, NAD, and NADP+).\nIn experimental biochemistry, nucleotides can be radiolabeled using radionuclides to yield radionucleotides.\n5-nucleotides are also used in flavour enhancers as food additive to enhance the umami taste, often in the form of a yeast extract.\nStructure.\nA nucleotide is composed of three distinctive chemical sub-units: a five-carbon sugar molecule, a nucleobase (the two of which together are called a nucleoside), and one phosphate group. With all three joined, a nucleotide is also termed a \"nucleoside \"mono\"phosphate\", \"nucleoside \"di\"phosphate\" or \"nucleoside \"tri\"phosphate\", depending on how many phosphates make up the phosphate group.\nIn nucleic acids, nucleotides contain either a purine or a pyrimidine base\u2014i.e., the nucleobase molecule, also known as a nitrogenous base\u2014and are termed \"ribo\"nucleotides if the sugar is ribose, or \"deoxyribo\"nucleotides if the sugar is deoxyribose. Individual phosphate molecules repetitively connect the sugar-ring molecules in two adjacent nucleotide monomers, thereby connecting the nucleotide monomers of a nucleic acid end-to-end into a long chain. These chain-joins of sugar and phosphate molecules create a 'backbone' strand for a single- or double helix. In any one strand, the chemical orientation (directionality) of the chain-joins runs from the 5'-end to the 3'-end (\"read\": 5 prime-end to 3 prime-end)\u2014referring to the five carbon sites on sugar molecules in adjacent nucleotides. In a double helix, the two strands are oriented in opposite directions, which permits base pairing and complementarity between the base-pairs, all which is essential for replicating or transcribing the encoded information found in DNA.\nNucleic acids, then, are polymeric macromolecules assembled from nucleotides, the monomer-units of nucleic acids. The purine bases adenine and guanine and pyrimidine base cytosine occur in both DNA and RNA, while the pyrimidine bases thymine (in DNA) and uracil (in RNA) occur in just one. Adenine forms a base pair with thymine with two hydrogen bonds, while guanine pairs with cytosine with three hydrogen bonds.\nIn addition to being building blocks for the construction of nucleic acid polymers, singular nucleotides play roles in cellular energy storage and provision, cellular signaling, as a source of phosphate groups used to modulate the activity of proteins and other signaling molecules, and as enzymatic cofactors, often carrying out redox reactions. Signaling cyclic nucleotides are formed by binding the phosphate group twice to the same sugar molecule, bridging the 5'- and 3'- hydroxyl groups of the sugar. Some signaling nucleotides differ from the standard single-phosphate group configuration, in having multiple phosphate groups attached to different positions on the sugar. Nucleotide cofactors include a wider range of chemical groups attached to the sugar via the glycosidic bond, including nicotinamide and flavin, and in the latter case, the ribose sugar is linear rather than forming the ring seen in other nucleotides.\nSynthesis.\nNucleotides can be synthesized by a variety of means, both in vitro and in vivo.\nIn vitro, protecting groups may be used during laboratory production of nucleotides. A purified nucleoside is protected to create a phosphoramidite, which can then be used to obtain analogues not found in nature and/or to synthesize an oligonucleotide.\nIn vivo, nucleotides can be synthesized de novo or recycled through salvage pathways. The components used in de novo nucleotide synthesis are derived from biosynthetic precursors of carbohydrate and amino acid metabolism, and from ammonia and carbon dioxide. Recently it has been also demonstrated that cellular bicarbonate metabolism can be regulated by mTORC1 signaling. The liver is the major organ of de novo synthesis of all four nucleotides. De novo synthesis of pyrimidines and purines follows two different pathways. Pyrimidines are synthesized first from aspartate and carbamoyl-phosphate in the cytoplasm to the common precursor ring structure orotic acid, onto which a phosphorylated ribosyl unit is covalently linked. Purines, however, are first synthesized from the sugar template onto which the ring synthesis occurs. For reference, the syntheses of the purine and pyrimidine nucleotides are carried out by several enzymes in the cytoplasm of the cell, not within a specific organelle. Nucleotides undergo breakdown such that useful parts can be reused in synthesis reactions to create new nucleotides.\nPyrimidine ribonucleotide synthesis.\nThe synthesis of the pyrimidines cytidine triphosphate (CTP) and uridine triphosphate (UTP) occurs in the cytoplasm and starts with the formation of carbamoyl phosphate from glutamine and CO2. Next, aspartate carbamoyltransferase catalyzes a condensation reaction between aspartate and carbamoyl phosphate to form carbamoyl aspartic acid, which is cyclized into 4,5-dihydroorotic acid by dihydroorotase. The latter is converted to orotate by dihydroorotate oxidase. The net reaction is:\n(\"S\")-Dihydroorotate + O2 \u2192 Orotate + H2O2\nOrotate is covalently linked with a phosphorylated ribosyl unit. The covalent linkage between the ribose and pyrimidine occurs at position C1 of the ribose unit, which contains a pyrophosphate, and N1 of the pyrimidine ring. Orotate phosphoribosyltransferase (PRPP transferase) catalyzes the net reaction yielding Orotidine 5'-monophosphate (OMP):\nOrotate + 5-Phospho-\u03b1-D-ribose 1-diphosphate (PRPP) \u2192 Orotidine 5'-phosphate + Pyrophosphate\nOrotidine 5'-monophosphate is decarboxylated by orotidine-5'-phosphate decarboxylase to form uridine monophosphate (UMP). PRPP transferase catalyzes both the ribosylation and decarboxylation reactions, forming UMP from orotic acid in the presence of PRPP. It is from UMP that other pyrimidine nucleotides are derived. UMP is phosphorylated by two kinases to uridine triphosphate (UTP) via two sequential reactions with ATP. First, the diphosphate from UDP is produced, which in turn is phosphorylated to UTP. Both steps are fueled by ATP hydrolysis:\nATP + UMP \u2192 ADP + UDP\nUDP + ATP \u2192 UTP + ADP\nCTP is subsequently formed by the amination of UTP by the catalytic activity of CTP synthetase. Glutamine is the NH3 donor and the reaction is fueled by ATP hydrolysis, too:\nUTP + Glutamine + ATP + H2O \u2192 CTP + ADP + Pi\nCytidine monophosphate (CMP) is derived from cytidine triphosphate (CTP) with subsequent loss of two phosphates.\nPurine ribonucleotide synthesis.\nThe atoms that are used to build the purine nucleotides come from a variety of sources:\nThe de novo synthesis of purine nucleotides by which these precursors are incorporated into the purine ring proceeds by a 10-step pathway to the branch-point intermediate IMP, the nucleotide of the base hypoxanthine. AMP and GMP are subsequently synthesized from this intermediate via separate, two-step pathways. Thus, purine moieties are initially formed as part of the ribonucleotides rather than as free bases.\nSix enzymes take part in IMP synthesis. Three of them are multifunctional:\nThe pathway starts with the formation of PRPP. PRPS1 is the enzyme that activates R5P, which is formed primarily by the pentose phosphate pathway, to PRPP by reacting it with ATP. The reaction is unusual in that a pyrophosphoryl group is directly transferred from ATP to C1 of R5P and that the product has the \u03b1 configuration about C1. This reaction is also shared with the pathways for the synthesis of Trp, His, and the pyrimidine nucleotides. Being on a major metabolic crossroad and requiring much energy, this reaction is highly regulated.\nIn the first reaction unique to purine nucleotide biosynthesis, PPAT catalyzes the displacement of PRPP's pyrophosphate group (PPi) by an amide nitrogen donated from either glutamine (N), glycine (N&amp;C), aspartate (N), folic acid (C1), or CO2. This is the committed step in purine synthesis. The reaction occurs with the inversion of configuration about ribose C1, thereby forming \u03b2-5-phosphorybosylamine (5-PRA) and establishing the anomeric form of the future nucleotide.\nNext, a glycine is incorporated fueled by ATP hydrolysis, and the carboxyl group forms an amine bond to the NH2 previously introduced. A one-carbon unit from folic acid coenzyme N10-formyl-THF is then added to the amino group of the substituted glycine followed by the closure of the imidazole ring. Next, a second NH2 group is transferred from glutamine to the first carbon of the glycine unit. A carboxylation of the second carbon of the glycin unit is concomitantly added. This new carbon is modified by the addition of a third NH2 unit, this time transferred from an aspartate residue. Finally, a second one-carbon unit from formyl-THF is added to the nitrogen group and the ring is covalently closed to form the common purine precursor inosine monophosphate (IMP).\nInosine monophosphate is converted to adenosine monophosphate in two steps. First, GTP hydrolysis fuels the addition of aspartate to IMP by adenylosuccinate synthase, substituting the carbonyl oxygen for a nitrogen and forming the intermediate adenylosuccinate. Fumarate is then cleaved off forming adenosine monophosphate. This step is catalyzed by adenylosuccinate lyase.\nInosine monophosphate is converted to guanosine monophosphate by the oxidation of IMP forming xanthylate, followed by the insertion of an amino group at C2. NAD+ is the electron acceptor in the oxidation reaction. The amide group transfer from glutamine is fueled by ATP hydrolysis.\nPyrimidine and purine degradation.\nIn humans, pyrimidine rings (C, T, U) can be degraded completely to CO2 and NH3 (urea excretion). That having been said, purine rings (G, A) cannot. Instead, they are degraded to the metabolically inert uric acid which is then excreted from the body. Uric acid is formed when GMP is split into the base guanine and ribose. Guanine is deaminated to xanthine which in turn is oxidized to uric acid. This last reaction is irreversible. Similarly, uric acid can be formed when AMP is deaminated to IMP from which the ribose unit is removed to form hypoxanthine. Hypoxanthine is oxidized to xanthine and finally to uric acid. Instead of uric acid secretion, guanine and IMP can be used for recycling purposes and nucleic acid synthesis in the presence of PRPP and aspartate (NH3 donor).\nPrebiotic synthesis of nucleotides.\nTheories about the origin of life require knowledge of chemical pathways that permit formation of life's key building blocks under plausible prebiotic conditions. The RNA world hypothesis holds that in the primordial soup there existed free-floating ribonucleotides, the fundamental molecules that combine in series to form RNA. Complex molecules like RNA must have arisen from small molecules whose reactivity was governed by physico-chemical processes. RNA is composed of purine and pyrimidine nucleotides, both of which are necessary for reliable information transfer, and thus Darwinian evolution. Becker et al. showed how pyrimidine nucleosides can be synthesized from small molecules and ribose, driven solely by wet-dry cycles. Purine nucleosides can be synthesized by a similar pathway. 5'-mono- and di-phosphates also form selectively from phosphate-containing minerals, allowing concurrent formation of polyribonucleotides with both the purine and pyrimidine bases. Thus a reaction network towards the purine and pyrimidine RNA building blocks can be established starting from simple atmospheric or volcanic molecules.\nUnnatural base pair (UBP).\nAn unnatural base pair (UBP) is a designed subunit (or nucleobase) of DNA which is created in a laboratory and does not occur in nature. Examples include d5SICS and dNaM. These artificial nucleotides bearing hydrophobic nucleobases, feature two fused aromatic rings that form a (d5SICS\u2013dNaM) complex or base pair in DNA. \"E. coli\" have been induced to replicate a plasmid containing UBPs through multiple generations. This is the first known example of a living organism passing along an expanded genetic code to subsequent generations.\nMedical applications of synthetic nucleotides.\nThe applications of synthetic nucleotides vary widely and include disease diagnosis, treatment, or precision medicine. \nLength unit.\nNucleotide (abbreviated \"nt\") is a common unit of length for single-stranded nucleic acids, similar to how base pair is a unit of length for double-stranded nucleic acids.\nAbbreviation codes for degenerate bases.\nThe IUPAC has designated the symbols for nucleotides. Apart from the five (A, G, C, T/U) bases, often degenerate bases are used especially for designing PCR primers. These nucleotide codes are listed here. Some primer sequences may also include the character \"I\", which codes for the non-standard nucleotide inosine. Inosine occurs in tRNAs and will pair with adenine, cytosine, or thymine. This character does not appear in the following table, however, because it does not represent a degeneracy. While inosine can serve a similar function as the degeneracy \"H\", it is an actual nucleotide, rather than a representation of a mix of nucleotides that covers each possible pairing needed.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21506", "revid": "48456760", "url": "https://en.wikipedia.org/wiki?curid=21506", "title": "Numerical analysis", "text": "Methods for numerical approximations\nNumerical analysis is the study of algorithms that use numerical approximation (as opposed to symbolic manipulations) for the problems of mathematical analysis (as distinguished from discrete mathematics). It is the study of numerical methods that attempt to find approximate solutions of problems rather than the exact ones. Numerical analysis finds application in all fields of engineering and the physical sciences, and in the 21st century also the life and social sciences like economics, medicine, business and even the arts. Current growth in computing power has enabled the use of more complex numerical analysis, providing detailed and realistic mathematical models in science and engineering. Examples of numerical analysis include: ordinary differential equations as found in celestial mechanics (predicting the motions of planets, stars and galaxies), numerical linear algebra in data analysis, and stochastic differential equations and Markov chains for simulating living cells in medicine and biology.\nBefore modern computers, numerical methods often relied on hand interpolation formulas, using data from large printed tables. Since the mid-20th century, computers calculate the required functions instead, but many of the same formulas continue to be used in software algorithms.\nThe numerical point of view goes back to the earliest mathematical writings. A tablet from the Yale Babylonian Collection (YBC 7289), gives a sexagesimal numerical approximation of the square root of 2, the length of the diagonal in a unit square.\nNumerical analysis continues this long tradition: rather than giving exact symbolic answers translated into digits and applicable only to real-world measurements, approximate solutions within specified error bounds are used.\nApplications.\nThe overall goal of the field of numerical analysis is the design and analysis of techniques to give approximate but accurate solutions to a wide variety of hard problems, many of which are infeasible to solve symbolically:\nHistory.\nThe field of numerical analysis predates the invention of modern computers by many centuries. Linear interpolation was already in use more than 2000 years ago. Many great mathematicians of the past were preoccupied by numerical analysis, as is obvious from the names of important algorithms like Newton's method, Lagrange interpolation polynomial, Gaussian elimination, or Euler's method. The origins of modern numerical analysis are often linked to a 1947 paper by John von Neumann and Herman Goldstine,\nbut others consider modern numerical analysis to go back to work by E. T. Whittaker in 1912.\nTo facilitate computations by hand, large books were produced with formulas and tables of data such as interpolation points and function coefficients. Using these tables, often calculated out to 16 decimal places or more for some functions, one could look up values to plug into the formulas given and achieve very good numerical estimates of some functions. The canonical work in the field is the NIST publication edited by Abramowitz and Stegun, a 1000-plus page book of a very large number of commonly used formulas and functions and their values at many points. The function values are no longer very useful when a computer is available, but the large listing of formulas can still be very handy.\nThe mechanical calculator was also developed as a tool for hand computation. These calculators evolved into electronic computers in the 1940s, and it was then found that these computers were also useful for administrative purposes. But the invention of the computer also influenced the field of numerical analysis, since now longer and more complicated calculations could be done.\nThe Leslie Fox Prize for Numerical Analysis was initiated in 1985 by the Institute of Mathematics and its Applications.\nKey concepts.\nDirect and iterative methods.\nDirect methods compute the solution to a problem in a finite number of steps. These methods would give the precise answer if they were performed in infinite precision arithmetic. Examples include Gaussian elimination, the QR factorization method for solving systems of linear equations, and the simplex method of linear programming. In practice, finite precision is used and the result is an approximation of the true solution (assuming stability).\nIn contrast to direct methods, iterative methods are not expected to terminate in a finite number of steps, even if infinite precision were possible. Starting from an initial guess, iterative methods form successive approximations that converge to the exact solution only in the limit. A convergence test, often involving the residual, is specified in order to decide when a sufficiently accurate solution has (hopefully) been found. Even using infinite precision arithmetic these methods would not reach the solution within a finite number of steps (in general). Examples include Newton's method, the bisection method, and Jacobi iteration. In computational matrix algebra, iterative methods are generally needed for large problems.\nIterative methods are more common than direct methods in numerical analysis. Some methods are direct in principle but are usually used as though they were not, e.g. GMRES and the conjugate gradient method. For these methods the number of steps needed to obtain the exact solution is so large that an approximation is accepted in the same manner as for an iterative method.\nAs an example, consider the problem of solving\n3\"x\"3 + 4 = 28\nfor the unknown quantity \"x\".\nFor the iterative method, apply the bisection method to \"f\"(\"x\") = 3\"x\"3 \u2212 24. The initial values are \"a\" = 0, \"b\" = 3, \"f\"(\"a\") = \u221224, \"f\"(\"b\") = 57.\nFrom this table it can be concluded that the solution is between 1.875 and 2.0625. The algorithm might return any number in that range with an error less than 0.2.\nConditioning.\nIll-conditioned problem: Take the function \"f\"(\"x\") = 1/(\"x\"\u00a0\u2212\u00a01). Note that \"f\"(1.1) = 10 and \"f\"(1.001) = 1000: a change in \"x\" of less than 0.1 turns into a change in \"f\"(\"x\") of nearly 1000. Evaluating \"f\"(\"x\") near \"x\" = 1 is an ill-conditioned problem.\nWell-conditioned problem: By contrast, evaluating the same function \"f\"(\"x\") = 1/(\"x\"\u00a0\u2212\u00a01) near \"x\" = 10 is a well-conditioned problem. For instance, \"f\"(10) = 1/9 \u2248 0.111 and \"f\"(11) = 0.1: a modest change in \"x\" leads to a modest change in \"f\"(\"x\").\nDiscretization.\nFurthermore, continuous problems must sometimes be replaced by a discrete problem whose solution is known to approximate that of the continuous problem; this process is called 'discretization'. For example, the solution of a differential equation is a function. This function must be represented by a finite amount of data, for instance by its value at a finite number of points at its domain, even though this domain is a continuum.\nGeneration and propagation of errors.\nThe study of errors forms an important part of numerical analysis. There are several ways in which error can be introduced in the solution of the problem.\nRound-off.\nRound-off errors arise because it is impossible to represent all real numbers exactly on a machine with finite memory (which is what all practical digital computers are).\nTruncation and discretization error.\nTruncation errors are committed when an iterative method is terminated or a mathematical procedure is approximated and the approximate solution differs from the exact solution. Similarly, discretization induces a discretization error because the solution of the discrete problem does not coincide with the solution of the continuous problem. In the example above to compute the solution of formula_1, after ten iterations, the calculated root is roughly 1.99. Therefore, the truncation error is roughly 0.01.\nOnce an error is generated, it propagates through the calculation. For example, the operation + on a computer is inexact. A calculation of the type &amp;NoBreak;&amp;NoBreak; is even more inexact.\nA truncation error is created when a mathematical procedure is approximated. To integrate a function exactly, an infinite sum of regions must be found, but numerically only a finite sum of regions can be found, and hence the approximation of the exact solution. Similarly, to differentiate a function, the differential element approaches zero, but numerically only a nonzero value of the differential element can be chosen.\nNumerical stability and well-posed problems.\nAn algorithm is called \"numerically stable\" if an error, whatever its cause, does not grow to be much larger during the calculation. This happens if the problem is \"well-conditioned\", meaning that the solution changes by only a small amount if the problem data are changed by a small amount. To the contrary, if a problem is 'ill-conditioned', then any small error in the data will grow to be a large error.\nBoth the original problem and the algorithm used to solve that problem can be well-conditioned or ill-conditioned, and any combination is possible.\nSo an algorithm that solves a well-conditioned problem may be either numerically stable or numerically unstable. An art of numerical analysis is to find a stable algorithm for solving a well-posed mathematical problem.\nAreas of study.\nThe field of numerical analysis includes many sub-disciplines. Some of the major ones are:\nComputing values of functions.\nOne of the simplest problems is the evaluation of a function at a given point. The most straightforward approach, of just plugging in the number in the formula is sometimes not very efficient. For polynomials, a better approach is using the Horner scheme, since it reduces the necessary number of multiplications and additions. Generally, it is important to estimate and control round-off errors arising from the use of floating-point arithmetic.\nInterpolation, extrapolation, and regression.\nInterpolation solves the following problem: given the value of some unknown function at a number of points, what value does that function have at some other point between the given points?\nExtrapolation is very similar to interpolation, except that now the value of the unknown function at a point which is outside the given points must be found.\nRegression is also similar, but it takes into account that the data are imprecise. Given some points, and a measurement of the value of some function at these points (with an error), the unknown function can be found. The least squares-method is one way to achieve this.\nSolving equations and systems of equations.\nAnother fundamental problem is computing the solution of some given equation. Two cases are commonly distinguished, depending on whether the equation is linear or not. For instance, the equation formula_2 is linear while formula_3 is not.\nMuch effort has been put in the development of methods for solving systems of linear equations. Standard direct methods, i.e., methods that use some matrix decomposition are Gaussian elimination, LU decomposition, Cholesky decomposition for symmetric (or hermitian) and positive-definite matrix, and QR decomposition for non-square matrices. Iterative methods such as the Jacobi method, Gauss\u2013Seidel method, successive over-relaxation and conjugate gradient method are usually preferred for large systems. General iterative methods can be developed using a matrix splitting.\nRoot-finding algorithms are used to solve nonlinear equations (they are so named since a root of a function is an argument for which the function yields zero). If the function is differentiable and the derivative is known, then Newton's method is a popular choice. Linearization is another technique for solving nonlinear equations.\nSolving eigenvalue or singular value problems.\nSeveral important problems can be phrased in terms of eigenvalue decompositions or singular value decompositions. For instance, the spectral image compression algorithm is based on the singular value decomposition. The corresponding tool in statistics is called principal component analysis.\nOptimization.\nOptimization problems ask for the point at which a given function is maximized (or minimized). Often, the point also has to satisfy some constraints.\nThe field of optimization is further split in several subfields, depending on the form of the objective function and the constraint. For instance, linear programming deals with the case that both the objective function and the constraints are linear. A famous method in linear programming is the simplex method.\nThe method of Lagrange multipliers can be used to reduce optimization problems with constraints to unconstrained optimization problems.\nEvaluating integrals.\nNumerical integration, in some instances also known as numerical quadrature, asks for the value of a definite integral. Popular methods use one of the Newton\u2013Cotes formulas (like the midpoint rule or Simpson's rule) or Gaussian quadrature. These methods rely on a \"divide and conquer\" strategy, whereby an integral on a relatively large set is broken down into integrals on smaller sets. In higher dimensions, where these methods become prohibitively expensive in terms of computational effort, one may use Monte Carlo or quasi-Monte Carlo methods (see Monte Carlo integration), or, in modestly large dimensions, the method of sparse grids.\nDifferential equations.\nNumerical analysis is also concerned with computing (in an approximate way) the solution of differential equations, both ordinary differential equations and partial differential equations.\nPartial differential equations are solved by first discretizing the equation, bringing it into a finite-dimensional subspace. This can be done by a finite element method, a finite difference method, or (particularly in engineering) a finite volume method. The theoretical justification of these methods often involves theorems from functional analysis. This reduces the problem to the solution of an algebraic equation.\nSoftware.\nSince the late twentieth century, most algorithms are implemented in a variety of programming languages. The Netlib repository contains various collections of software routines for numerical problems, mostly in Fortran and C. Commercial products implementing many different numerical algorithms include the IMSL and NAG libraries; a free-software alternative is the GNU Scientific Library.\nOver the years the Royal Statistical Society published numerous algorithms in its \"Applied Statistics\" (code for these \"AS\" functions is https://); \nACM similarly, in its \"Transactions on Mathematical Software\" (\"TOMS\" code is https://).\nThe Naval Surface Warfare Center several times published its https:// (code https://).\nThere are several popular numerical computing applications such as MATLAB, TK Solver, S-PLUS, and IDL as well as free and open-source alternatives such as FreeMat, Scilab, GNU Octave (similar to Matlab), and IT++ (a C++ library). There are also programming languages such as R (similar to S-PLUS), Julia, and Python with libraries such as NumPy, SciPy and SymPy. Performance varies widely: while vector and matrix operations are usually fast, scalar loops may vary in speed by more than an order of magnitude.\nMany computer algebra systems such as Mathematica also benefit from the availability of arbitrary-precision arithmetic which can provide more accurate results.\nAlso, any spreadsheet software can be used to solve simple problems relating to numerical analysis. \nExcel, for example, has hundreds of available functions, including for matrices, which may be used in conjunction with its built in \"solver\".\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21508", "revid": "1891007", "url": "https://en.wikipedia.org/wiki?curid=21508", "title": "Noosphere", "text": "Philosophical concept of biosphere successor via humankind's rational activities\nThe noosphere (alternate spelling no\u00f6sphere) is a philosophical concept developed and popularized by the biogeochemist Vladimir Vernadsky and philosopher and Jesuit priest Pierre Teilhard de Chardin. Vernadsky defined the noosphere as the new state of the biosphere, and described it as the planetary \"sphere of reason\". The noosphere represents the highest stage of biospheric development, that of humankind's rational activities.\nThe word is derived from the Greek \u03bd\u03cc\u03bf\u03c2 (\"nous, mind, reason\") and (\"sphere\"), in lexical analogy to \"atmosphere\" and \"biosphere\". The concept cannot be accredited to a single author. The founding authors Vernadsky and de Chardin developed two related but starkly different concepts, the former grounded in the geological sciences, and the latter in theology. Both conceptions of the noosphere share the common thesis that together human reason and scientific thought have created, and will continue to create, the next evolutionary geological layer. This geological layer is part of the evolutionary chain. Second-generation authors, predominantly of Russian origin, have further developed the Vernadskian concept, creating the related concepts: noocenosis and noocenology.\nConcept.\nIn the theory of Vernadsky, the noosphere is the third in a succession of phases of development of the Earth, after the geosphere (inanimate matter) and the biosphere (biological life). Just as the emergence of life fundamentally transformed the geosphere, the emergence of human cognition fundamentally transforms the biosphere. In contrast to the conceptions of the Gaia theorists, or the promoters of cyberspace, Vernadsky's noosphere emerges at the point where humankind, through the mastery of nuclear processes, begins to create resources through the transmutation of elements. It is a study area of the Global Consciousness Project.\nFor de Chardin, the noosphere emerges through and is constituted by the interaction of human minds. The noosphere has grown in step with the organization of the human mass in relation to itself as it populates the Earth. As mankind organizes itself in more complex social networks, the higher the noosphere will grow in awareness. This concept extends Teilhard's Law of Complexity/Consciousness, the law describing the nature of evolution in the universe. Teilhard argued the noosphere is growing towards an even greater integration and unification, culminating in the Omega Point - an apex of thought/consciousness - which he saw as the goal of history.\nFounding authors.\nThe term noosphere was first used in the publications of Pierre Teilhard de Chardin in 1922 in his \"Cosmogenesis\". Vernadsky was most likely introduced to the term by a common acquaintance, \u00c9douard Le Roy, during a stay in Paris. Some sources claim \u00c9douard Le Roy actually first proposed the term. Vernadsky himself wrote that he was first introduced to the concept by Le Roy in his 1927 lectures at the College of France, and that Le Roy had emphasized a mutual exploration of the concept with Teilhard de Chardin. According to Vernadsky's own letters, he took Le Roy's ideas on the noosphere from Le Roy's article \"Les origines humaines et l\u2019evolution de l\u2019intelligence\", part III: \"La noosphere et l\u2019hominisation\", before reworking the concept within his own field, biogeochemistry. The historian Bailes concludes that Vernadsky and Teilhard de Chardin were mutual influences on each other, as Teilhard de Chardin also attended Vernadsky's lectures on biogeochemistry, before creating the concept of the noosphere.\nAn account stated that Le Roy and Teilhard were not aware of the concept of biosphere in their noosphere concept and that it was Vernadsky who introduced them to this notion, which gave their conceptualization a grounding on natural sciences. Both Teilhard de Chardin and Vernadsky base their conceptions of the noosphere on the term 'biosphere', developed by Eduard Suess in 1875. Despite the differing backgrounds, approaches and focuses of Teilhard and Vernadsky, they have a few fundamental themes in common. Both scientists overstepped the boundaries of the natural sciences and attempted to create all-embracing theoretical constructions founded in philosophy, the social sciences and authorized interpretations of the evolutionary theory. Moreover, both thinkers were convinced of the teleological character of evolution. They also argued that human activity becomes a geological power and that the manner by which it is directed can influence the environment. There are fundamental differences in the two conceptions.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21509", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=21509", "title": "Norwegian Blue parrot", "text": ""}
{"id": "21511", "revid": "2842084", "url": "https://en.wikipedia.org/wiki?curid=21511", "title": "Niccol\u00f2 Paganini", "text": "Italian violinist and composer (1782\u20131840)\nNiccol\u00f2 (or Nicol\u00f2) Paganini (; ; 27 October 1782\u00a0\u2013 27 May 1840) was an Italian violinist and composer. He was the most celebrated violin virtuoso of his time, and left his mark as one of the pillars of modern violin technique. His 24 Caprices for Solo Violin Op. 1 are among the best known of his compositions and have served as an inspiration for many prominent composers.\nSon of a ship chandler from Genoa, Paganini showed great gifts for music from an early age and studied under Alessandro Rolla, Ferdinando Paer and Gasparo Ghiretti. Accompanied by his father, he toured northern Italy extensively as a teenager. By 1805 he had come into the service of Napoleon's sister, Elisa Bonaparte, who then ruled Lucca where Paganini was first violin. From 1809 on he returned to touring and achieved continental fame in the subsequent two and a half decades, developing a reputation for his technical brilliance and showmanship, as well as his extravagant, philandering lifestyle. Paganini ended his concert career in 1834 amid declining health, and the failure of his Paris casino left him in financial ruin. He retired to southern France and died in Nice in 1840 at the age of 57.\nBiography.\nChildhood.\nNiccol\u00f2 Paganini was born in Genoa (then capital of the Republic of Genoa) on 27 October 1782, the third of the six children of Antonio and Teresa (n\u00e9e Bocciardo) Paganini. Antonio Paganini was an unsuccessful ship chandler, but he managed to supplement his income by working as a musician and by selling mandolins.11 At the age of five, Paganini started learning the mandolin from his father and moved to the violin by the age of seven. His musical talents were quickly recognized, earning him numerous scholarships for violin lessons. The young Paganini studied under various local violinists, including Giovanni Servetto and Giacomo Costa, but his progress quickly outpaced their abilities. Paganini and his father then traveled to Parma to seek further guidance from Alessandro Rolla. But upon listening to Paganini's playing, Rolla immediately referred him to his own teacher, Ferdinando Paer and, later, Paer's own teacher, Gasparo Ghiretti.\nEarly career.\nThe French invaded northern Italy in March 1796, and the political situation in Genoa became unstable. The Paganinis sought refuge in their country property in Romairone, near Bolzaneto. It was in this period that Paganini is thought to have developed his relationship with the guitar.18 He mastered the guitar, but preferred to play it in exclusively intimate, rather than public concerts. He later described the guitar as his \"constant companion\" on his concert tours. By 1800, Paganini and his father traveled to Livorno, where Paganini played in concerts and his father resumed his maritime work. In 1801, the 18-year-old Paganini was appointed first violin of the Republic of Lucca, but a substantial portion of his income came from freelancing. His fame as a violinist was matched only by his reputation as a gambler and philanderer.\nIn 1805, Lucca was annexed by Napoleonic France, and the region was ceded to Napoleon's sister, Elisa Bonaparte. Paganini became a violinist for the Baciocchi court, while giving private lessons to Elisa's husband, Felice for ten years. During this time, his wife and Paganini were also carrying on a romantic affair. In 1807, Baciocchi became the Grand Duchess of Tuscany and her court was transferred to Florence. Paganini was part of the entourage but, towards the end of 1809, he left Baciocchi to resume his freelance career.\nTravelling virtuoso.\nFor the next few years, Paganini returned to touring in the areas surrounding Parma and Genoa. Though he was very popular with the local audience, he was still not very well known in the rest of Europe. His first break came from an 1813 concert at La Scala in Milan. The concert was a great success. As a result, Paganini began to attract the attention of other prominent, though more conservative, musicians across Europe. His early encounters with Charles Philippe Lafont and Louis Spohr created intense rivalry.\nIn 1827, Pope Leo XII honoured Paganini with the Order of the Golden Spur. His fame spread across Europe with a concert tour that started in Vienna in August 1828, stopping in every major European city in Germany, Poland, and Bohemia until February 1831 in Strasbourg. This was followed by tours in Paris and Britain. His technical ability and his willingness to display it received much critical acclaim. In addition to his own compositions, theme and variations being the most popular, Paganini also performed modified versions of works (primarily concertos) written by his early contemporaries, such as Rodolphe Kreutzer and Giovanni Battista Viotti.\nPaganini's travels also brought him into contact with eminent guitar virtuosi of the day, including Ferdinando Carulli in Paris and Mauro Giuliani in Vienna.\nLate career and health decline.\nThroughout his life, Paganini was no stranger to chronic illnesses. Although no definite medical proof exists, it has been later theorized that he might have been affected by Marfan syndrome or Ehlers\u2013Danlos syndrome. His frequent concert schedule, as well as his extravagant lifestyle, may have affected his health. Paganini was diagnosed with syphilis as early as 1822, and his remedy, which included mercury and opium, came with serious physical and psychological side effects. In 1834, while still in Paris, he was treated for tuberculosis.\nIn September 1834, Paganini put an end to his concert career and returned to Genoa. Contrary to popular beliefs involving his wishing to keep his music and techniques secret, Paganini devoted his time to the publication of his compositions and violin methods. He accepted students, of whom two enjoyed moderate success: violinist Camillo Sivori and cellist Gaetano Ciandelli. Neither, however, considered Paganini helpful or inspirational. In 1835, Paganini returned to Parma, this time under the employ of Archduchess Marie Louise of Austria, Napoleon's second wife. He was in charge of reorganizing her court orchestra, but he eventually conflicted with the players and court, so his visions never saw completion. In Paris, he befriended the 11-year-old Polish virtuoso Apollinaire de Kontski, giving him some lessons and a signed testimonial. It was widely put about, falsely, that Paganini was so impressed with de Kontski's skills that he bequeathed him his violins and manuscripts.\nFinal years, death, and burial.\nIn 1836, Paganini returned to Paris to set up a casino. Its immediate failure left him in financial ruin, and he auctioned off his personal effects, including his musical instruments, to recoup his losses. At Christmas of 1838, he left Paris for Marseille and, after a brief stay, traveled to Nice where his condition worsened. In May 1840, the Bishop of Nice sent Paganini a local parish priest to perform the last rites. Paganini assumed the sacrament was premature, and refused.\nA week later, on 27 May 1840, the 57-year-old Paganini died from internal hemorrhaging before a priest could be summoned. Because of this, and his widely rumored association with the devil, the Church denied his body a Catholic burial in Genoa. It took four years and an appeal to the Pope before the Church let his body be transported to Genoa, but it was still not buried. His body was finally buried in 1876, in a cemetery in Parma. In 1893, the Czech violinist Franti\u0161ek Ond\u0159\u00ed\u010dek persuaded Paganini's grandson, Attila, to allow a viewing of the violinist's body. After this episode, Paganini's body was finally reinterred in a new cemetery in Parma in 1896.\nPersonal life.\nThough having no shortage of romantic conquests, Paganini was seriously involved with a singer named Antonia Bianchi from Como, whom he met in Milan in 1813. The two gave concerts together throughout Italy. They had a son, Achille Ciro Alessandro, born on 23 July 1825 in Palermo and baptized at San Bartolomeo's. They never legalized their union and it ended around April 1828 in Vienna. Paganini brought Achille on his European tours, and Achille later accompanied his father until the latter's death.\nThroughout his career, Paganini also became close friends with composers Gioachino Rossini and Hector Berlioz. Rossini and Paganini met in Bologna in the summer of 1818. In January 1821, on his return from Naples, Paganini met Rossini again in Rome, just in time to become the substitute conductor for Rossini's opera \"Matilde di Shabran\", upon the sudden death of the original conductor. Paganini's efforts earned great gratitude from Rossini.\nPaganini met Berlioz in Paris in 1833 and they continued to correspond. He commissioned a piece from the composer, but was not satisfied with the resultant four-movement piece for orchestra and viola obbligato, \"Harold en Italie\". He never performed it; instead, it was premiered a year later by violist Christian Urhan. He did, however, write his own \"Sonata per Gran Viola\" Op. 35 (with orchestra or guitar accompaniment). Despite his alleged lack of interest in \"Harold\", Paganini often referred to Berlioz as the resurrection of Beethoven and, towards the end of his life, he gave large sums to the composer. They shared an active interest in the guitar, which they both played and used in compositions. Paganini gave Berlioz a guitar, which they both signed on its sound box.\nPlaying style.\nInstruments.\nPaganini was in possession of a number of fine stringed instruments, including 11 Stradivari at the time of his death. More legendary than these were the circumstances under which he obtained (and lost) some of them. While Paganini was still a teenager in Livorno, a wealthy businessman named Livron lent him a violin, made by the master luthier Giuseppe Guarneri, for a concert. Livron was so impressed with Paganini's playing that he refused to take it back. This particular violin came to be known as \"Il Cannone Guarnerius\" (\"The Cannon of Guarnieri\") because of its powerful voice and resonance.\nOther instruments associated with Paganini include the \"Antonio Amati\" 1600, the \"Nicol\u00f2 Amati\" 1657, the \"Paganini-Desaint\" 1680 Stradivari, the Guarneri-filius \"Andrea\" 1706, the \"Le Brun\" 1712 Stradivari, the \"Vuillaume\" c.\u00a01720 Bergonzi, the \"Hubay\" 1726 Stradivari, and the \"Comte\u00a0Cozio di Salabue\" 1727 violins; the \"Countess of Flanders\" 1582 da\u00a0Sal\u00f2-di\u00a0Bertolotti, and the \"Mendelssohn\" 1731 Stradivari violas; the \"Piatti\" 1700 Goffriller, the \"Stanlein\" 1707 Stradivari, and the \"Ladenburg\" 1736 Stradivari cellos; and the \"Grobert of Mirecourt\" 1820 (guitar).\nOf his guitars, there is little evidence remaining of his various choices of instrument. The aforementioned guitar that he gave to Berlioz is a French instrument made by one Grobert of Mirecourt. The luthier made his instrument in the style of Ren\u00e9 Lac\u00f4te, a more well-known Paris-based guitar-maker. It is preserved and on display in the Mus\u00e9e de la Musique in Paris.\nOf the guitars he owned through his life, there was an instrument by Gennaro Fabricatore that he had refused to sell even in his periods of financial stress, and was among the instruments in his possession at the time of his death.\nViolin technique.\nThe Israeli violinist Ivry Gitlis once referred to Paganini as a phenomenon rather than a development. Though some of the techniques frequently employed by Paganini were already present, most accomplished violinists of the time focused on intonation and bowing techniques. Arcangelo Corelli (1653\u20131713) was considered a pioneer in transforming the violin from an ensemble instrument to a solo instrument. Other notable violinists included Antonio Vivaldi (1678\u20131741) and Giuseppe Tartini (1692\u20131770), who, in their compositions, reflected the increasing technical and musical demands on the violinist. Although the role of the violin in music drastically changed through this period, progress in violin technique was steady but slow.\nMuch of Paganini's playing (and his violin composition) was influenced by two violinists, Pietro Locatelli (1693\u20131746) and August Duranowski (Auguste Fr\u00e9d\u00e9ric Durand) (1770\u20131834). During Paganini's study in Parma, he came across the 24 Caprices of Locatelli (entitled \"L'arte di nuova modulazione \u2013 Capricci enigmatici\" or \"The art of the new style \u2013 the enigmatic caprices\"). Published in the 1730s, they were shunned by the musical authorities for their technical innovations, and were forgotten by the musical community at large. Around the same time, Durand, a former student of Giovanni Battista Viotti (1755\u20131824), became a celebrated violinist. He was renowned for his use of harmonics, both natural and artificial (which had previously not been attempted in performance), and the left hand pizzicato in his performance. Paganini was impressed by Durand's innovations and showmanship, which later also became the hallmarks of the young violin virtuoso. Paganini was instrumental in the revival and popularization of these violinistic techniques.\nAnother aspect of Paganini's violin techniques concerned his flexibility. He had exceptionally long fingers and was capable of playing three octaves across four strings in a hand span, an extraordinary feat even by today's standards.\nCompositions.\nPaganini composed his own works to play exclusively in his concerts, all of which profoundly influenced the evolution of violin technique. His 24 Caprices were likely composed between 1805 and 1809, while he was in the service of the Baciocchi court. Also during this period, he composed the majority of the solo pieces, duo-sonatas, trios, and quartets for the guitar, either as a solo instrument or with strings. These chamber works may have been inspired by the publication, in Lucca, of the guitar quintets of Boccherini. Many of his variations, including \"Le Streghe\", \"The Carnival of Venice\", and \"Nel cor pi\u00f9 non mi sento\", were composed, or at least first performed, before his European concert tour. His were written between 1817 and 1830.\nGenerally speaking, Paganini's compositions were technically imaginative, and the timbre of the instrument was greatly expanded as a result of these works. Sounds of different musical instruments and animals were often imitated. One such composition was titled \"Il Fandango Spanolo\" (The Spanish Dance), which featured a series of humorous imitations of farm animals. Even more outrageous was a solo piece \"Duetto Amoroso\", in which the sighs and groans of lovers were intimately depicted on the violin. There survives a manuscript of the \"Duetto\", which has been recorded. The existence of the \"Fandango\" is known only through concert posters.Eug\u00e8ne Ysa\u00ffe criticized Paganini's works for lacking characteristics of true polyphonism. Yehudi Menuhin, on the other hand, suggested that this might have been the result of Paganini's reliance on the guitar (in lieu of the piano) as an aid in composition. The orchestral parts for his concertos were often polite, unadventurous, and clearly supportive of the soloist. In this, his style is consistent with that of other Italian composers such as Giovanni Paisiello, Gioachino Rossini, and Gaetano Donizetti, who were influenced by the guitar-song milieu of Naples during this period.\nPaganini's \"La Campanella\" and the A\u00a0minor Caprice (No.\u00a024) have inspired many composers, including Franz Liszt, Robert Schumann, Johannes Brahms, Sergei Rachmaninoff, Boris Blacher, Andrew Lloyd Webber, George Rochberg, and Witold Lutos\u0142awski, all of whom wrote variations on these works.\nLegacy and influence.\nInspired works.\nNotable works inspired by compositions of Paganini include:\nThe \"Caprice No. 24 in A minor\", Op. 1, (\"Tema con variazioni\") has been the basis of works by many other composers. Notable examples include Brahms's \"Variations on a Theme of Paganini\" and Rachmaninoff's \"Rhapsody on a Theme of Paganini\".\nMemorials and other tributes.\nIn 1904 the Genoa Conservatory was renamed the \"Conservatorio Niccol\u00f2 Paganini\" in honor of the composer. The conservatory is also host to the Paganini Competition (\"Premio Paganini\"); an international violin competition created in 1954.\nIn 1972 the State of Italy purchased a large collection of Niccol\u00f2 Paganini manuscripts from the W. Heyer Library of Cologne. They are housed at the Biblioteca Casanatense in Rome.\nIn 1982 the city of Genoa commissioned a thematic catalogue of music by Paganini, edited by Maria Rosa Moretti and Anna Sorrento, hence the abbreviation \"MS\" assigned to his catalogued works.\nA minor planet 2859 Paganini discovered in 1978 by Soviet astronomer Nikolai Chernykh is named after him.\nFiorini daguerreotype.\nAlthough no photographs of Paganini are known to exist, in 1900 Italian violin maker Giuseppe Fiorini forged the now famous fake daguerreotype of the celebrated violinist. So well in fact, that even the great classical author and conversationalist Arthur M. Abell was led to believe it to be true, reprinting the image in the 22 January 1901 issue of the \"Musical Courier\".\nDramatic portrayals.\nPaganini has been portrayed by a number of actors in film and television productions, including Stewart Granger in the 1946 biographical portrait \"The Magic Bow\", Roxy Roth in \"A Song to Remember\" (1945), Klaus Kinski in \"Kinski Paganini\" (1989), and David Garrett in \"The Devil's Violinist\" (2013).\nIn the Soviet 1982 miniseries \"Niccolo Paganini\", the musician was portrayed by the Armenian actor Vladimir Msryan. The series focuses on Paganini's relationship with the Roman Catholic Church. Another Soviet actor, Armen Dzhigarkhanyan, played Paganini's fictionalized arch-rival, an insidious Jesuit official. The information in the series is generally spurious, and it also plays to some of the myths and legends rampant during the musician's lifetime. One memorable scene shows Paganini's adversaries sabotaging his violin before a high-profile performance, causing all strings but one to break during the concert. An undeterred Paganini continues to perform on three, two, and finally on a single string. In actuality, Paganini himself occasionally broke strings during his performances on purpose so he could further display his virtuosity. He did this by carefully filing notches into them to weaken them, so that they would break when in use.\nIn Don Nigro's satirical comedy play \"Paganini\" (1995), the great violinist seeks vainly for his salvation, claiming that he unknowingly sold his soul to the Devil. \"Variation upon variation,\" he cries at one point, \"but which variation leads to salvation and which to damnation? Music is a question for which there is no answer.\" Paganini is portrayed as having killed three of his lovers and sinking repeatedly into poverty, prison, and drink. Each time he is \"rescued\" by the Devil, who appears in different guises, returning Paganini's violin so he can continue playing. In the end, Paganini's salvation\u2014administered by a god-like Clockmaker\u2014turns out to be imprisonment in a large bottle where he plays his music for the amusement of the public through all eternity. \"Do not pity him, my dear,\" the Clockmaker tells Antonia, one of Paganini's murdered wives. \"He is alone with the answer for which there is no question. The saved and the damned are the same.\"\nThe musical \"CROSS ROAD ~The Devil's Violinist Paganini~\", premiered 2022 and revived 2024, features Niccolo Paganini as a main character, played by Hiroki Aiba (2022 and 2024), Kenta Mizue (2022), and Kento Kinouchi (2024). The story is about his making a contract with the Devil of Music, Amduscias, played by Akinori Nakagawa in both productions. The musical is by Bun-O Fujisawa, composed by Toshiyuki Muranaka. It was performed at Theater Creation in Tokyo, Japan, with a national tour in 2024.\nAnother musical about Paganini has been produced in South Korea, called \"Paganini\". It focuses on his son, Achille.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nImages"}
{"id": "21512", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=21512", "title": "North Atlantic Current", "text": "Current of the Atlantic Ocean\nThe North Atlantic Current (NAC), also known as North Atlantic Drift and North Atlantic Sea Movement, is a powerful warm western boundary current within the Atlantic Ocean that extends the Gulf Stream northeastward.\nCharacteristics.\nThe NAC originates from where the Gulf Stream turns north at the Southeast Newfoundland Rise, a submarine ridge that stretches southeast from the Grand Banks of Newfoundland. The NAC flows northward east of the Grand Banks, from 40\u00b0N to 51\u00b0N, before turning sharply east to cross the Atlantic. It transports more warm tropical water to northern latitudes than any other boundary current; more than 40\u00a0Sv () in the south and 20\u00a0Sv () as it crosses the Mid-Atlantic Ridge. It reaches speeds of near the North American coast. Directed by topography, the NAC meanders heavily, but in contrast to the meanders of the Gulf Stream, the NAC meanders remain stable without breaking off into eddies.\nThe colder parts of the Gulf Stream turn northward near the \"tail\" of the Grand Banks at 50\u00b0W where the Azores Current branches off to flow south of the Azores. From there the NAC flows northeastward, east of the Flemish Cap (47\u00b0N, 45\u00b0W). Approaching the Mid-Atlantic Ridge, it then turns eastward and becomes much broader and more diffuse. It then splits into a colder northeastern branch and a warmer eastern branch. As the warmer branch turns southward, most of the subtropical component of the Gulf Stream is diverted southward, and as a consequence, the North Atlantic is mostly supplied by subpolar waters, including a contribution from the Labrador Current recirculated into the NAC at 45\u00b0N.\nWest of Continental Europe, it splits into two major branches. One branch goes southeast, becoming the Canary Current as it passes northwest Africa and turns southwest. The other major branch continues north along the coast of Northwestern Europe.\nOther branches include the Irminger Current and the Norwegian Current. Driven by the global thermohaline circulation, the North Atlantic Current is part of the wind-driven Gulf Stream, which goes further east and north from the North American coast across the Atlantic and into the Arctic Ocean.\nThe North Atlantic Current, together with the Gulf Stream, have a long-lived reputation for having a considerable warming influence on European climate. However, the principal cause for differences in winter climate between North America and Europe seems to be winds rather than ocean currents (although the currents do exert influence at very high latitudes by preventing the formation of sea ice).\nClimate change.\nUnlike the AMOC, the observations of Labrador Sea outflow showed no negative trend from 1997 to 2009, and the Labrador Sea convection began to intensify in 2012, reaching a new high in 2016. As of 2022, the trend of strengthened Labrador Sea convection appears to hold, and is associated with observed increases in marine primary production. Yet, a 150-year dataset suggests that even this recently strengthened convection is anomalously weak compared to its baseline state.\nSome climate models indicate that the deep convection in Labrador-Irminger Seas could collapse under certain global warming scenarios, which would then collapse the entire circulation in the North subpolar gyre. It is considered unlikely to recover even if the temperature is returned to a lower level, making it an example of a climate tipping point. This would result in rapid cooling, with implications for economic sectors, agriculture industry, water resources and energy management in Western Europe and the East Coast of the United States. Frajka-Williams et al. 2017 pointed out that recent changes in cooling of the subpolar gyre, warm temperatures in the subtropics and cool anomalies over the tropics, increased the spatial distribution of meridional gradient in sea surface temperatures, which is not captured by the AMO Index.\nA 2021 study found that this collapse occurs in only four CMIP6 models out of 35 analyzed. However, only 11 models out of 35 can simulate North Atlantic Current with a high degree of accuracy, and this includes all four models which simulate collapse of the subpolar gyre. As the result, the study estimated the risk of an abrupt cooling event over Europe caused by the collapse of the current at 36.4%, which is lower than the 45.5% chance estimated by the previous generation of models. In 2022, a paper suggested that previous disruption of subpolar gyre was connected to the Little Ice Age.\nA 2022 Science Magazine review study on climate tipping points noted that in the scenarios where this convection collapses, it is most likely to be triggered by 1.8 degrees of global warming. However, model differences mean that the required warming may be as low as 1.1 degrees or as high as 3.8 degrees. Once triggered, the collapse of the current would most likely take 10 years from start to end, with a range between 5 and 50 years. The loss of this convection is estimated to lower the global temperature by up to 0.5 degrees, while the https://. There are also substantial impacts on regional precipitation.\nA 2023 study warns that the collapse could already happen by mid century.\nA 2023 study published in Nature Communications projected that the Atlantic Meridional Overturning Circulation (AMOC), of which the North Atlantic Current is a part, could collapse by mid-century under continued high emissions, posing major risks of abrupt climate changes in Europe and beyond.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21513", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=21513", "title": "North Atlantic Deep Water", "text": "Deep water mass formed in the North Atlantic Ocean\nNorth Atlantic Deep Water (NADW) is a deep water mass formed in the North Atlantic Ocean. Thermohaline circulation (properly described as meridional overturning circulation) of the world's oceans involves the flow of warm surface waters from the southern hemisphere into the North Atlantic. Water flowing northward becomes modified through evaporation and mixing with other water masses, leading to increased salinity. When this water reaches the North Atlantic, it cools and sinks through convection, due to its decreased temperature and increased salinity resulting in increased density. NADW is the outflow of this thick deep layer, which can be detected by its high salinity, high oxygen content, nutrient minima, high 14C/12C, and chlorofluorocarbons (CFCs).\nCFCs are anthropogenic substances that enter the surface of the ocean from gas exchange with the atmosphere. This distinct composition allows its path to be traced as it mixes with Circumpolar Deep Water (CDW), which in turn fills the deep Indian Ocean and part of the South Pacific. NADW and its formation is essential to the Atlantic meridional overturning circulation (AMOC), which is responsible for transporting large amounts of water, heat, salt, carbon, nutrients and other substances from the Tropical Atlantic to the Mid and High Latitude Atlantic. \nIn the conveyor belt model of thermohaline circulation of the world's oceans, the sinking of NADW pulls the waters of the North Atlantic drift northward. However, this is almost certainly an oversimplification of the actual relationship between NADW formation and the strength of the Gulf Stream/North Atlantic drift.\nNADW has a temperature of 2.0-3.5\u00a0\u00b0C with a practical salinity of \"S\"P\u00a0=\u00a034.9-35.0, found at a depth between 1500 and 4000m.\nFormation and sources.\nThe NADW is a complex of several water masses formed by deep convection and overflow of dense water across the Greenland-Iceland-Scotland Ridge.\nThe upper layers are formed by deep open ocean convection during winter. Labrador Sea Water (LSW), formed in the Labrador Sea, can reach depths of 2000 m as dense water sinks downward. Classical Labrador Sea Water (CLSW) production is dependent on preconditioning of water in the Labrador Sea from the previous year and the strength of the North Atlantic oscillation (NAO).\nDuring a positive NAO phase, conditions exist for strong winter storms to develop. These storms freshen the surface water, and their winds increase cyclonic flow, which allows denser waters to sink. As a result, the temperature, salinity, and density vary yearly. In some years these conditions do not exist and CLSW is not formed. CLSW has characteristic potential temperature of 3\u00a0\u00b0C, salinity of 34.88 psu, and density of 34.66.\nAnother component of LSW is the Upper Labrador Sea Water (ULSW). ULSW forms at a density lower than CLSW and has a CFC maximum between 1200 and 1500 m in the subtropical North Atlantic. Eddies of cold less saline ULSW have similar densities of warmer saltier water and flow along the DWBC, but maintain their high CFCs. The ULSW eddies erode rapidly as they mix laterally with this warmer saltier water.\nThe lower waters mass of NADW form from overflow of the Greenland-Iceland-Scotland Ridge. They are Iceland-Scotland Overflow Water (ISOW) and Denmark Strait Overflow Water (DSOW). The overflows are a combination of dense Arctic Ocean water (18%), modified Atlantic water (32%), and intermediate water from the Nordic seas (20%), that entrain and mix with other water masses (contributing 30%) as they flow over the Greenland-Iceland-Scotland Ridge.\nThe formation of both of these waters involves the conversion of warm, salty, northward-flowing surface waters to cold, dense, deep waters behind the Greenland-Iceland-Scotland Ridge. Water flow from the North Atlantic current enters the Arctic Ocean through the Norwegian Current, which splits into the Fram Strait and Barents Sea Branch. Water from the Fram Strait recirculates, reaching a density of DSOW, sinks, and flows towards the Denmark Strait. Water flowing into the Barents Sea feeds ISOW.\nISOW enters the eastern North Atlantic over the Iceland-Scotland Ridge through the Faeroe Bank Channel at a depth of 850 m, with some water flowing over the shallower Iceland-Faeroe Rise. ISOW has a low CFC concentrations and it has been estimated from these concentrations that ISOW resides behind the ridge for 45 years. As the water flows southward at the bottom of the channel, it entrains surrounding water of the eastern North Atlantic, and flows to the western North Atlantic through the Charlie\u2013Gibbs fracture zone, entraining with LSW. This water is less dense than DSOW and lays above it as it flows cyclonically in the Irminger Basin.\nDSOW is the coldest, densest, and freshest water mass of NADW. DSOW formed behind the ridge flows over the Denmark Strait at a depth of 600m. The most significant water mass contributing to DSOW is Arctic Intermediate Water (AIW). Winter cooling and convection allow AIW to sink and pool behind the Denmark Strait. Upper AIW has a high amount of anthropogenic tracers due its exposure to the atmosphere. AIW's tritium and CFC signature is observed in DSOW at the base of the Greenland continental slope. This also showed that the DSOW flowing 450\u00a0km to the south was no older than 2 years. Both the DSOW and ISOW flow around the Irminger Basin and Labrador Sea in a deep boundary current. Leaving the Greenland Sea with 2.5 Sv, its flow increases to 10 Sv south of Greenland. It is cold and relatively fresh, flowing below 3500 m in the DWBC and spreading inward the deep Atlantic basins.\nSpreading pathways.\nThe southward spread of NADW along the Deep Western Boundary current (DWBC) can be traced by its high oxygen content, high CFCs, and density.\nULSW is the major source of upper NADW. ULSW advects southward from the Labrador Sea in small eddies that mix into the DWBC. A CFC maximum associated with ULSW has been observed along 24\u00b0N in the DWBC at 1500 m. Some of the upper ULSW recirculates into the Gulf Stream, while some remains in the DWBC. High CFCs in the subtropics indicate recirculation in the subtropics.\nULSW that remains in the DWBC dilutes as it moves equatorward. Deep convection in the Labrador Sea during the late 1980s and early 1990s resulted in CLSW with a lower CFC concentration due to downward mixing. Convection allowed the CFCs to penetrate further downward to 2000m. These minima could be tracked, and were first observed in the subtropics in the early 1990s.\nISOW and DSOW flow around the Irminger Basin and DSOW entering the DWBC. These are the two lower portions of the NADW. Another CFC maximum is seen at 3500 m in the subtropics from the DSOW contribution to NADW. Some of the NADW recirculates with the northern gyre. To the south of the gyre, NADW flows under the Gulf Stream, where it continues along the DWBC until it reaches another gyre in the subtropics.\nLower North Atlantic Deep Water (LNADW), originating in the Greenland and Norwegian seas, brings high salinity, oxygen, and freon concentrations towards to the Romanche Trench, an equatorial fracture zone in the Mid-Atlantic Ridge (MAR). Found at depths around , LNADW flow east through the trench over Antarctic Bottom Water\u2014the trench is the only opening in the MAR where inter-basin exchange is possible for these two water masses.\nVariability.\nIt is believed that North Atlantic Deep Water formation has been dramatically reduced at times during the past (such as during the Younger Dryas or during Heinrich events), and that this might correlate with a decrease in the strength of the Gulf Stream and the North Atlantic drift, in turn cooling the climate of northwestern Europe.\nThere is concern that global warming might cause this to happen again. It is also hypothesized that during the Last Glacial Maximum, NADW was replaced with an analogous watermass that occupied a shallower depth known as Glacial North Atlantic Intermediate Water.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21514", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=21514", "title": "Nanomedicine", "text": "Medical application of nanotechnology\nNanomedicine is the medical application of nanotechnology, translating historic nanoscience insights and inventions into practical application. Nanomedicine ranges from the medical applications of nanomaterials and biological devices, to nanoelectronic biosensors, and even possible future applications of molecular nanotechnology such as biological machines. Current problems for nanomedicine involve understanding the issues related to toxicity and environmental impact of nanoscale materials (materials whose structure is on the scale of nanometers, i.e. billionths of a meter).\nFunctionalities can be added to nanomaterials by interfacing them with biological molecules or structures. The size of nanomaterials is similar to that of most biological molecules and structures; therefore, nanomaterials can be useful for both in vivo and in vitro biomedical research and applications. Thus far, the integration of nanomaterials with biology has led to the development of diagnostic devices, contrast agents, analytical tools, physical therapy applications, and drug delivery vehicles.\nNanomedicine seeks to deliver a valuable set of research tools and clinically useful devices in the near future. The National Nanotechnology Initiative expects new commercial applications in the pharmaceutical industry that may include advanced drug delivery systems, new therapies, and in vivo imaging. Nanomedicine research is receiving funding from the US National Institutes of Health Common Fund program, supporting four nanomedicine development centers. The goal of funding this newer form of science is to further develop the biological, biochemical, and biophysical mechanisms of living tissues. More medical and drug companies today are becoming involved in nanomedical research and medications. These include Bristol-Myers Squibb, which focuses on drug delivery systems for immunology and fibrotic diseases; Moderna known for their COVID-19 vaccine and their work on mRNA therapeutics; and Nanobiotix, a company that focuses on cancer and currently has a drug in testing that increases the effect of radiation on targeted cells. More companies include Generation Bio, which specializes in genetic medicines and has developed the cell-targeted lipid nanoparticle, and Jazz Pharmaceuticals, which developed Vyxeos , a drug that treats acute myeloid leukemia, and concentrates on cancer and neuroscience. Cytiva is a company that specializes in producing delivery systems for genomic medicines that are non-viral, including mRNA vaccines and other therapies utilizing nucleic acid and Ratiopharm is known for manufacturing Pazenir, a drug for various cancers. Finally, Pacira specializes in pain management and is known for producing ZILRETTA for osteoarthritis knee pain, the first treatment without opioids.\nNanomedicine sales reached $16 billion in 2015, with a minimum of $3.8 billion in nanotechnology R&amp;D being invested every year. Global funding for emerging nanotechnology increased by 45% per year in recent years, with product sales exceeding $1 trillion in 2013. In 2023, the global market was valued at $189.55 billion and is predicted to exceed $500 billion in the next ten years. As the nanomedicine industry continues to grow, it is expected to have a significant impact on the economy.\nDrug delivery.\n Nanotechnology has provided the possibility of delivering drugs to specific cells using nanoparticles. This use of drug delivery systems was first proposed by Gregory Gregoriadis in 1974, who outlined liposomes as a drug delivery system for chemotherapy. The overall drug consumption and side-effects may be lowered significantly by depositing the active pharmaceutical agent in the diseased region only and in no higher dose than needed. Targeted drug delivery is intended to reduce the side effects of drugs in tandem decreases in consumption and treatment expenses. Additionally, targeted drug delivery reduces the side effects of crude or naturally occurring drugs by minimizing undesired exposure to healthy cells. Drug delivery focuses on maximizing bioavailability both at specific places in the body and over a period of time. This can potentially be achieved by molecular targeting by nanoengineered devices. A benefit of using nanoscale for medical technologies is that smaller devices are less invasive and can possibly be implanted inside the body, plus biochemical reaction times are much shorter. These devices are faster and more sensitive than typical drug delivery. The efficacy of drug delivery through nanomedicine is largely based upon: a) efficient encapsulation of the drugs, b) successful delivery of drug to the targeted region of the body, and c) successful release of the drug. Several nano-delivery drugs were on the market by 2019.\nDrug delivery systems, lipid- or polymer-based nanoparticles, can be designed to improve the pharmacokinetics and biodistribution of the drug. However, the pharmacokinetics and pharmacodynamics of nanomedicine is highly variable among different patients. When designed to avoid the body's defense mechanisms, nanoparticles have beneficial properties that can be used to improve drug delivery. Complex drug delivery mechanisms are being developed, including the ability to get drugs through cell membranes and into cell cytoplasm. Triggered response is one way for drug molecules to be used more efficiently. Drugs are placed in the body and only activate on encountering a particular signal. For example, a drug with poor solubility will be replaced by a drug delivery system where both hydrophilic and hydrophobic environments exist, improving the solubility. Drug delivery systems may also be able to prevent tissue damage through regulated drug release; reduce drug clearance rates; or lower the volume of distribution and reduce the effect on non-target tissue. However, the biodistribution of these nanoparticles is still imperfect due to the complex host's reactions to nano- and microsized materials and the difficulty in targeting specific organs in the body. Nevertheless, a lot of work is still ongoing to optimize and better understand the potential and limitations of nanoparticulate systems. While advancement of research proves that targeting and distribution can be augmented by nanoparticles, the dangers of nanotoxicity become an important next step in further understanding of their medical uses. The toxicity of nanoparticles varies, depending on size, shape, and material. These factors also affect the build-up and organ damage that may occur. Nanoparticles are made to be long-lasting, but this causes them to be trapped within organs, specifically the liver and spleen, as they cannot be broken down or excreted. This build-up of non-biodegradable material has been observed to cause organ damage and inflammation in mice. Delivering magnetic nanoparticles to a tumor using uneven stationary magnetic fields may lead to enhanced tumor growth. In order to avoid this, alternating electromagnetic fields should be used.\nNanoparticles are under research for their potential to decrease antibiotic resistance or for various antimicrobial uses. Nanoparticles might also be used to circumvent multidrug resistance (MDR) mechanisms.\nSystems under research.\nAdvances in lipid nanotechnology were instrumental in engineering medical nanodevices and novel drug delivery systems, as well as in developing sensing applications. Another system for microRNA delivery under preliminary research is nanoparticles formed by the self-assembly of two different microRNAs to possibly shrink tumors. One potential application is based on small electromechanical systems, such as nanoelectromechanical systems being investigated for the active release of drugs and sensors for possible cancer treatment with iron nanoparticles or gold shells. Another system of drug delivery involving nanoparticles is the use of aquasomes, self-assembled nanoparticles with a nanocrystalline center, a coating made of a polyhydroxyl oligomer, covered in the desired drug, which protects it from dehydration and conformational change.\nManufacturing of Nanomedicines.\nThe manufacturing of nanomedicines like lipid nanoparticles (LNPs), mRNA-loaded LNPs, liposomes and magnetic nanocarriers requires precise control of particle size, surface properties and encapsulation efficiency for a safe in vivo use and reproducable efficacy of the therapeutic. Traditionally, these nanoformulations have been manufactured using batch processes, which can have limitations such as variability in product quality and limited scalability due to the limited mixing efficiency in batch processes. In contrast, more modern approaches rely on continuous manufacturing techniques to enhance scalability and reproducability. Microfluidic methods and other rapid mixing methods enable improved control over key process parameters during the nanoparticle formation. These techniques allow the continuous production of reproducable nanoparticles with narrow size distributions and highly scalable throughput.\nThe large-scale production of mRNA-LNP Covid-19 vaccines (Comirnaty\u00ae and Spikevax\u00ae) relies on continuous processes like T-mixing (turbulent mixing). This method enables a efficient encapsulation of mRNA and a high throughput which was critical for mass vaccine production during Covid-19. However, scalability rely on parallelization of T-Mixers with multiple parallel operating pumps as the T-mixing is not scalable by increasing the inner dimensions of the T-Mixer. Characterization of Comirnaty\u00ae shows a broad particle size distribution (PDI \u2265 0,2), which is acceptable for vaccines but is suboptimal for small-molecule drugs due to higher regulatory requirements. To produce more refined LNPs with narrower size distributions, microfluidic mixers are increasingly employed which can enable more uniform LNPs and a higher scalability due to there inner microfluidic structure as demonstrated in multiple recent studies.\nApplications.\nSome nanotechnology-based drugs that are commercially available or in human clinical trials include:\nImaging.\n\"In vivo\" imaging is another area where tools and devices are being developed. Using nanoparticle contrast agents, images such as ultrasound and MRI have a better distribution and improved contrast. In cardiovascular imaging, nanoparticles have potential to aid visualization of blood pooling, ischemia, angiogenesis, atherosclerosis, and focal areas where inflammation is present.\nThe small size of nanoparticles gives them with properties that can be very useful in oncology, particularly in imaging. Quantum dots (nanoparticles with quantum confinement properties, such as size-tunable light emission), when used in conjunction with MRI (magnetic resonance imaging), can produce exceptional images of tumor sites. Nanoparticles of cadmium selenide (quantum dots) glow when exposed to ultraviolet light. When injected, they seep into cancer tumors. The surgeon can see the glowing tumor, and use it as a guide for more accurate tumor removal. These nanoparticles are much brighter than organic dyes and only need one light source for activation. This means that the use of fluorescent quantum dots could produce a higher contrast image and at a lower cost than today's organic dyes used as contrast media. The downside, however, is that quantum dots are usually made of quite toxic elements, but this concern may be addressed by use of fluorescent dopants, substances added to create fluorescence.\nTracking movement can help determine how well drugs are being distributed or how substances are metabolized. It is difficult to track a small group of cells throughout the body, so scientists used to dye the cells. These dyes needed to be excited by light of a certain wavelength in order for them to light up. While different color dyes absorb different frequencies of light, there was a need for as many light sources as cells. A way around this problem is with luminescent tags. These tags are quantum dots attached to proteins that penetrate cell membranes. The dots can be random in size, can be made of bio-inert material, and they demonstrate the nanoscale property that color is size-dependent. As a result, sizes are selected so that the frequency of light used to make a group of quantum dots fluoresce is an even multiple of the frequency required to make another group incandesce. Then both groups can be lit with a single light source. They have also found a way to insert nanoparticles into the affected parts of the body so that those parts of the body will glow showing the tumor growth or shrinkage or also organ trouble.\nSensing.\nNanotechnology-on-a-chip is one more dimension of lab-on-a-chip technology. Magnetic nanoparticles, bound to a suitable antibody, are used to label specific molecules, structures or microorganisms. Silica nanoparticles, in particular, are inert from a photophysical perspective and can accumulate a large number of dye(s) within their shells. Gold nanoparticles tagged with short DNA segments can be used to detect genetic sequences in a sample. Multicolor optical coding for biological assays has been achieved by embedding different-sized quantum dots into polymeric microbeads. Nanopore technology for analysis of nucleic acids converts strings of nucleotides directly into electronic signatures.\nSensor test chips containing thousands of nanowires, able to detect proteins and other biomarkers left behind by cancer cells, could enable the detection and diagnosis of cancer in the early stages from a few drops of a patient's blood. Nanotechnology is helping to advance the use of arthroscopes, which are pencil-sized devices that are used in surgeries with lights and cameras so surgeons can do the surgeries with smaller incisions. The smaller the incisions the faster the healing time which is better for the patients. It is also helping to find a way to make an arthroscope smaller than a strand of hair.\nResearch on nanoelectronics-based cancer diagnostics could lead to tests that can be done in pharmacies. The results promise to be highly accurate and the product promises to be inexpensive. They could take a very small amount of blood and detect cancer anywhere in the body in about five minutes, with a sensitivity that is a thousand times better a conventional laboratory test. These devices are built with nanowires to detect cancer proteins; each nanowire detector is primed to be sensitive to a different cancer marker. The biggest advantage of the nanowire detectors is that they could test for anywhere from ten to one hundred similar medical conditions without adding cost to the testing device. Nanotechnology has also helped to personalize oncology for the detection, diagnosis, and treatment of cancer. It is now able to be tailored to each individual's tumor for better performance. They have found ways that they will be able to target a specific part of the body that is being affected by cancer.\nSepsis treatment.\nIn contrast to dialysis, which works on the principle of the size-related diffusion of solutes and ultrafiltration of fluid across a semi-permeable membrane, the purification using nanoparticles allows specific targeting of substances. Additionally, larger compounds which are commonly not dialyzable can be removed.\nThe purification process is based on functionalized iron oxide or carbon coated metal nanoparticles with ferromagnetic or superparamagnetic properties. Binding agents such as proteins, antibiotics, or synthetic ligands are covalently linked to the particle surface. These binding agents are able to interact with target species forming an agglomerate. Applying an external magnetic field gradient exerts a force on the nanoparticles, allowing them to be separated from the bulk fluid, thus removing contaminants. This can neutralize the toxicity of sepsis, but runs the risk of nephrotoxicity and neurotoxicity.\nThe small size (&lt; 100\u00a0nm) and large surface area of functionalized nanomagnets offer advantages properties compared to hemoperfusion, which is a clinically used technique for the purification of blood and is based on surface adsorption. These advantages include high loading capacity, high selectivity towards the target compound, fast diffusion, low hydrodynamic resistance, and low dosage requirements.\nTissue engineering.\nNanotechnology may be used as part of tissue engineering to help reproduce, repair, or reshape damaged tissue using suitable nanomaterial-based scaffolds and growth factors. If successful, tissue engineering may replace conventional treatments like organ transplants or artificial implants. Nanoparticles such as graphene, carbon nanotubes, molybdenum disulfide and tungsten disulfide are being used as reinforcing agents to fabricate mechanically strong biodegradable polymeric nanocomposites for bone tissue engineering applications. The addition of these nanoparticles to the polymer matrix at low concentrations (~0.2 weight %) significantly improves in the compressive and flexural mechanical properties of polymeric nanocomposites. These nanocomposites may potentially serve as novel, mechanically strong, lightweight bone implants.\nFor example, a flesh welder was demonstrated to fuse two pieces of chicken meat into a single piece using a suspension of gold-coated nanoshells activated by an infrared laser. This could be used to weld arteries during surgery.\nAnother example is nanonephrology, the use of nanomedicine on the kidney.\nThe full potential and implications of nanotechnology uses within the tissue engineering are not yet fully understood, despite research spanning the past two decades.\nVaccine development.\nToday, a significant proportion of vaccines against viral diseases are created using nanotechnology. Solid lipid nanoparticles represent a novel delivery system for some vaccines against SARS-CoV-2 (the virus that causes COVID-19). In recent decades, nanosized adjuvants have been widely used to enhance immune responses to targeted vaccine antigens. Inorganic nanoparticles of aluminum, silica and clay, as well as\u00a0organic nanoparticles based on polymers and lipids, are commonly used adjuvants within modern vaccine formulations. Nanoparticles of natural polymers such as chitosan are commonly used adjuvants in modern vaccine formulations. Ceria nanoparticles appear very promising for both enhancing vaccine responses and mitigating inflammation, as their adjuvanticity can be adjusted by modifying parameters such as size, crystallinity, surface state, and stoichiometry.\nIn addition, virus-like nanoparticles are also being researched. These structures allow vaccines to self-assemble without encapsulating viral RNA, making them non-infectious and incapable of replication. These virus-like nanoparticles are designed to elicit a strong immune response by using a self-assembled layer of virus capsid proteins.\nRegulation.\nAs the development of nanomedicine continues to develop as a potential treatment for diseases, regulatory challenges have assessed reproducible manufacturing processes, scalability, availability of appropriate characterization methods, safety issues, and poor understanding of disease heterogeneity and patient preselection strategies. Global interaction of the various stakeholders is leading to harmonized regulation.\nSeveral therapeutic nanomedicine products have been approved by the FDA and European Medicines Agency. For market approval, these therapies are evaluated for biocompatibility, immunotoxicity, and a preclinical assessment.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21518", "revid": "10289486", "url": "https://en.wikipedia.org/wiki?curid=21518", "title": "NMR (disambiguation)", "text": "NMR, or nuclear magnetic resonance, is a phenomenon in which nuclei in a magnetic field absorb and re-emit electromagnetic radiation.\nNMR may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nEntertainment media.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "21519", "revid": "44106950", "url": "https://en.wikipedia.org/wiki?curid=21519", "title": "News agencies", "text": ""}
{"id": "21520", "revid": "274535", "url": "https://en.wikipedia.org/wiki?curid=21520", "title": "Null set", "text": "Measurable set whose measure is zero\nIn mathematical analysis, a null set is a Lebesgue measurable set of real numbers that has measure zero. This can be characterized as a set that can be covered by a countable union of intervals of arbitrarily small total length. \nThe notion of null set should not be confused with the empty set as defined in set theory. Although the empty set has Lebesgue measure zero, there are also non-empty sets which are null. For example, any non-empty countable set of real numbers has Lebesgue measure zero and therefore is null.\nMore generally, on a given measure space formula_1 a null set is a set formula_2 such that formula_3\nExamples.\nEvery finite or countably infinite subset of the real numbers &amp;NoBreak;&amp;NoBreak; is a null set. For example, the set of natural numbers &amp;NoBreak;&amp;NoBreak;, the set of rational numbers &amp;NoBreak;&amp;NoBreak; and the set of algebraic numbers &amp;NoBreak;&amp;NoBreak; are all countably infinite and therefore are null sets when considered as subsets of the real numbers.\nThe Cantor set is an example of an uncountable null set. It is uncountable because it contains all real numbers between 0 and 1 whose ternary expansion can be written using only 0s and 2s (see Cantor's diagonal argument), and it is null because it is constructed by beginning with the closed interval of real numbers from 0 to 1 and iteratively removing a third of the previous set, thereby multiplying the length by 2/3 with every step.\nDefinition for Lebesgue measure.\nThe Lebesgue measure is the standard way of assigning a length, area or volume to subsets of Euclidean space.\nA subset formula_4 of the real line formula_5 has null Lebesgue measure and is considered to be a null set (also known as a set of zero-content) in formula_5 if and only if:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nThis condition can be generalised to formula_8 using formula_9-cubes instead of intervals. In fact, the idea can be made to make sense on any manifold, even if there is no Lebesgue measure there.\nFor instance:\nIf formula_18 is Lebesgue measure for formula_5 and \u03c0 is Lebesgue measure for formula_20, then the product measure formula_21 In terms of null sets, the following equivalence has been styled a Fubini's theorem: \nMeasure-theoretic properties.\nLet formula_25 be a measure space. We have:\nTogether, these facts show that the null sets of formula_25 form a \ud835\udf0e-ideal of the \ud835\udf0e-algebra formula_31. Accordingly, null sets may be interpreted as negligible sets, yielding a measure-theoretic notion of \"almost everywhere\".\nUses.\nNull sets play a key role in the definition of the Lebesgue integral: if functions formula_32 and formula_33 are equal except on a null set, then formula_32 is integrable if and only if formula_33 is, and their integrals are equal. This motivates the formal definition of formula_36 spaces as sets of equivalence classes of functions which differ only on null sets.\nA measure in which all subsets of null sets are measurable is \"complete\". Any non-complete measure can be completed to form a complete measure by asserting that subsets of null sets have measure zero. Lebesgue measure is an example of a complete measure; in some constructions, it is defined as the completion of a non-complete Borel measure.\nA subset of the Cantor set which is not Borel measurable.\nThe Borel measure is not complete. One simple construction is to start with the standard Cantor set formula_37 which is closed hence Borel measurable, and which has measure zero, and to find a subset formula_38 of formula_39 which is not Borel measurable. (Since the Lebesgue measure is complete, this formula_38 is of course Lebesgue measurable.)\nFirst, we have to know that every set of positive measure contains a nonmeasurable subset. Let formula_32 be the Cantor function, a continuous function which is locally constant on formula_42 and monotonically increasing on formula_43 with formula_44 and formula_45 Obviously, formula_46 is countable, since it contains one point per component of formula_47 Hence formula_46 has measure zero, so formula_49 has measure one. We need a strictly monotonic function, so consider formula_50 Since formula_33 is strictly monotonic and continuous, it is a homeomorphism. Furthermore, formula_52 has measure one. Let formula_53 be non-measurable, and let formula_54 Because formula_33 is injective, we have that formula_56 and so formula_38 is a null set. However, if it were Borel measurable, then formula_58 would also be Borel measurable (here we use the fact that the preimage of a Borel set by a continuous function is measurable; formula_59 is the preimage of formula_38 through the continuous function formula_61). Therefore formula_38 is a null, but non-Borel measurable set.\nHaar null.\nIn a separable Banach space formula_63 addition moves any subset formula_64 to the translates formula_65 for any formula_66 When there is a probability measure \"\u03bc\" on the \u03c3-algebra of Borel subsets of formula_67 such that for all formula_68 formula_69 then formula_7 is a Haar null set.\nThe term refers to the null invariance of the measures of translates, associating it with the complete invariance found with Haar measure.\nSome algebraic properties of topological groups have been related to the size of subsets and Haar null sets.\nHaar null sets have been used in Polish groups to show that when A is not a meagre set then formula_71 contains an open neighborhood of the identity element. This property is named for Hugo Steinhaus since it is the conclusion of the Steinhaus theorem.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21521", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=21521", "title": "Nabakov", "text": ""}
{"id": "21522", "revid": "28089545", "url": "https://en.wikipedia.org/wiki?curid=21522", "title": "November 24", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearNovember 24 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21523", "revid": "4626", "url": "https://en.wikipedia.org/wiki?curid=21523", "title": "Neural network (machine learning)", "text": "Computational model used in machine learning, based on connected, hierarchical functions\nIn machine learning, a neural network or neural net (NN), also called artificial neural network (ANN), is a computational model inspired by the structure and functions of biological neural networks.\nA neural network consists of connected units or nodes called \"artificial neurons\", which loosely model the neurons in the brain. Artificial neuron models that mimic biological neurons more closely have also been recently investigated and shown to significantly improve performance. These are connected by \"edges\", which model the synapses in the brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the totality of its inputs, called the \"activation function\". The strength of the signal at each connection is determined by a \"weight\", which adjusts during the learning process.\nTypically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the \"input layer\") to the last layer (the \"output layer\"), possibly passing through multiple intermediate layers (\"hidden layers\"). A network is typically called a deep neural network if it has at least two hidden layers.\nArtificial neural networks are used for various tasks, including predictive modeling, adaptive control, and solving problems in artificial intelligence. They can learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nTraining.\nNeural networks are typically trained through empirical risk minimization, which is based on the idea of optimizing, the network's parameters to minimize the difference, or empirical risk, between the predicted output and the actual target values in a given dataset. Gradient-based methods such as backpropagation are usually used to estimate the parameters of the network. During the training phase, ANNs learn from labeled training data by iteratively updating their parameters to minimize a defined loss function. This method allows the network to generalize to unseen data.\nHistory.\nEarly work.\nToday's deep neural networks are based on early work in statistics over 200 years ago. The simplest kind of feedforward neural network (FNN) is a linear network, which consists of a single layer of output nodes with linear activation functions; the inputs are fed directly to the outputs via a series of weights. The sum of the products of the weights and the inputs is calculated at each node. The mean squared errors between these calculated outputs and the given target values are minimized by creating an adjustment to the weights. This technique has been known for over two centuries as the method of least squares or linear regression. It was used as a means of finding a good rough linear fit to a set of points by Legendre (1805) and Gauss (1795) for the prediction of planetary movement.\nHistorically, digital computers such as the von Neumann model operate via the execution of explicit instructions with access to memory by a number of processors. Some neural networks, on the other hand, originated from efforts to model information processing in biological systems through the framework of connectionism. Unlike the von Neumann model, connectionist computing does not separate memory and processing.\nWarren McCulloch and Walter Pitts (1943) considered a non-learning computational model for neural networks. This model paved the way for research to split into two approaches. One approach focused on biological processes while the other focused on the application of neural networks to artificial intelligence.\nIn the late 1940s, D. O. Hebb proposed a learning hypothesis based on the mechanism of neural plasticity that became known as Hebbian learning. It was used in many early neural networks, such as Rosenblatt's perceptron and the Hopfield network. Farley and Clark (1954) used computational machines to simulate a Hebbian network. Other neural network computational machines were created by Rochester, Holland, Habit and Duda (1956). \nIn 1958, psychologist Frank Rosenblatt described the perceptron, one of the first implemented artificial neural networks, funded by the United States Office of Naval Research.\nR. D. Joseph (1960) mentions an even earlier perceptron-like device by Farley and Clark: \"Farley and Clark of MIT Lincoln Laboratory actually preceded Rosenblatt in the development of a perceptron-like device.\" However, \"they dropped the subject.\"\nThe perceptron raised public excitement for research in Artificial Neural Networks, causing the US government to drastically increase funding. This contributed to \"the Golden Age of AI\" fueled by the optimistic claims made by computer scientists regarding the ability of perceptrons to emulate human intelligence.\nThe first perceptrons did not have adaptive hidden units. However, Joseph (1960) also discussed multilayer perceptrons with an adaptive hidden layer. Rosenblatt (1962) cited and adopted these ideas, also crediting work by H. D. Block and B. W. Knight. Unfortunately, these early efforts did not lead to a working learning algorithm for hidden units, i.e., deep learning.\nDeep learning breakthroughs in the 1960s and 1970s.\nFundamental research was conducted on ANNs in the 1960s and 1970s. The first working deep learning algorithm was the Group method of data handling, a method to train arbitrarily deep neural networks, published by Alexey Ivakhnenko and Lapa in the Soviet Union (1965). They regarded it as a form of polynomial regression, or a generalization of Rosenblatt's perceptron. A 1971 paper described a deep network with eight layers trained by this method, which is based on layer by layer training through regression analysis. Superfluous hidden units are pruned using a separate validation set. Since the activation functions of the nodes are Kolmogorov-Gabor polynomials, these were also the first deep networks with multiplicative units or \"gates.\"\nThe first deep learning multilayer perceptron trained by stochastic gradient descent was published in 1967 by Shun'ichi Amari. In computer experiments conducted by Amari's student Saito, a five layer MLP with two modifiable layers learned internal representations to classify non-linearily separable pattern classes. Subsequent developments in hardware and hyperparameter tunings have made end-to-end stochastic gradient descent the currently dominant training technique.\nIn 1969, Kunihiko Fukushima introduced the ReLU (rectified linear unit) activation function. The rectifier has become the most popular activation function for deep learning.\nNevertheless, research stagnated in the United States following the work of Minsky and Papert (1969), who emphasized that basic perceptrons were incapable of processing the exclusive-or circuit. This insight was irrelevant for the deep networks of Ivakhnenko (1965) and Amari (1967).\nIn 1976 transfer learning was introduced in neural networks learning.\nDeep learning architectures for convolutional neural networks (CNNs) with convolutional layers and downsampling layers and weight replication began with the neocognitron introduced by Kunihiko Fukushima in 1979, though not trained by backpropagation.\nBackpropagation.\nBackpropagation is an efficient application of the chain rule derived by Gottfried Wilhelm Leibniz in 1673 to networks of differentiable nodes. The terminology \"back-propagating errors\" was actually introduced in 1962 by Rosenblatt, but he did not know how to implement this, although Henry J. Kelley had a continuous precursor of backpropagation in 1960 in the context of control theory. In 1970, Seppo Linnainmaa published the modern form of backpropagation in his Master's thesis (1970). G.M. Ostrovski et al. republished it in 1971. Paul Werbos applied backpropagation to neural networks in 1982 (his 1974 PhD thesis, reprinted in a 1994 book, did not yet describe the algorithm). In 1986, David E. Rumelhart et al. popularised backpropagation but did not cite the original work.\nConvolutional neural networks.\nKunihiko Fukushima's convolutional neural network (CNN) architecture of 1979 also introduced max pooling, a popular downsampling procedure for CNNs. CNNs have become an essential tool for computer vision.\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel to apply CNN to phoneme recognition. It used convolutions, weight sharing, and backpropagation. In 1988, Wei Zhang applied a backpropagation-trained CNN to alphabet recognition.\nIn 1989, Yann LeCun et al. created a CNN called LeNet for recognizing handwritten ZIP codes on mail. Training required 3 days. In 1990, Wei Zhang implemented a CNN on optical computing hardware. In 1991, a CNN was applied to medical image object segmentation and breast cancer detection in mammograms. LeNet-5 (1998), a 7-level CNN by Yann LeCun et al., that classifies digits, was applied by several banks to recognize hand-written numbers on checks digitized in 32\u00d732 pixel images.\nFrom 1988 onward, the use of neural networks transformed the field of protein structure prediction, in particular when the first cascading networks were trained on \"profiles\" (matrices) produced by multiple sequence alignments.\nRecurrent neural networks.\nOne origin of RNN was statistical mechanics. In 1972, Shun'ichi Amari proposed to modify the weights of an Ising model by Hebbian learning rule as a model of associative memory, adding in the component of learning. This was popularized as the Hopfield network by John Hopfield (1982). Another origin of RNN was neuroscience. The word \"recurrent\" is used to describe loop-like structures in anatomy. In 1901, Cajal observed \"recurrent semicircles\" in the cerebellar cortex. Hebb considered \"reverberating circuit\" as an explanation for short-term memory. The McCulloch and Pitts paper (1943) considered neural networks that contain cycles, and noted that the current activity of such networks can be affected by activity indefinitely far in the past.\nIn 1982 a recurrent neural network with an array architecture (rather than a multilayer perceptron architecture), namely a Crossbar Adaptive Array, used direct recurrent connections from the output to the supervisor (teaching) inputs. In addition of computing actions (decisions), it computed internal state evaluations (emotions) of the consequence situations. Eliminating the external supervisor, it introduced the self-learning method in neural networks. \nIn cognitive psychology, the journal American Psychologist in early 1980's carried out a debate on the relation between cognition and emotion. Zajonc in 1980 stated that emotion is computed first and is independent from cognition, while Lazarus in 1982 stated that cognition is computed first and is inseparable from emotion. In 1982 the Crossbar Adaptive Array gave a neural network model of cognition-emotion relation. It was an example of a debate where an AI system, a recurrent neural network, contributed to an issue in the same time addressed by cognitive psychology.\nTwo early influential works were the Jordan network (1986) and the Elman network (1990), which applied RNN to study cognitive psychology. \nIn the 1980s, backpropagation did not work well for deep RNNs. To overcome this problem, in 1991, J\u00fcrgen Schmidhuber proposed the \"neural sequence chunker\" or \"neural history compressor\" which introduced the important concepts of self-supervised pre-training (the \"P\" in ChatGPT) and neural knowledge distillation. In 1993, a neural history compressor system solved a \"Very Deep Learning\" task that required more than 1000 subsequent layers in an RNN unfolded in time.\nIn 1991, Sepp Hochreiter's diploma thesis identified and analyzed the vanishing gradient problem and proposed recurrent residual connections to solve it. He and Schmidhuber introduced long short-term memory (LSTM), which set accuracy records in multiple applications domains. This was not yet the modern version of LSTM, which required the forget gate, which was introduced in 1999. It became the default choice for RNN architecture.\nDuring 1985\u20131995, inspired by statistical mechanics, several architectures and methods were developed by Terry Sejnowski, Peter Dayan, Geoffrey Hinton, etc., including the Boltzmann machine, restricted Boltzmann machine, Helmholtz machine, and the wake-sleep algorithm. These were designed for unsupervised learning of deep generative models.\nDeep learning.\nBetween 2009 and 2012, ANNs began winning prizes in image recognition contests, approaching human level performance on various tasks, initially in pattern recognition and handwriting recognition. In 2011, a CNN named \"DanNet\" by Dan Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella, and J\u00fcrgen Schmidhuber achieved for the first time superhuman performance in a visual pattern recognition contest, outperforming traditional methods by a factor of 3. It then won more contests. They also showed how max-pooling CNNs on GPU improved performance significantly.\nIn October 2012, AlexNet by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton won the large-scale ImageNet competition by a significant margin over shallow machine learning methods. Further incremental improvements included the VGG-16 network by Karen Simonyan and Andrew Zisserman and Google's Inceptionv3.\nIn 2012, Ng and Dean created a network that learned to recognize higher-level concepts, such as cats, only from watching unlabeled images. Unsupervised pre-training and increased computing power from GPUs and distributed computing allowed the use of larger networks, particularly in image and visual recognition problems, which became known as \"deep learning\".\nRadial basis function and wavelet networks were introduced in 2013. These can be shown to offer best approximation properties and have been applied in nonlinear system identification and classification applications.\nGenerative adversarial network (GAN) (Ian Goodfellow et al., 2014) became state of the art in generative modeling during 2014\u20132018 period. The GAN principle was originally published in 1991 by J\u00fcrgen Schmidhuber who called it \"artificial curiosity\": two neural networks contest with each other in the form of a zero-sum game, where one network's gain is the other network's loss. The first network is a generative model that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. Excellent image quality is achieved by Nvidia's StyleGAN (2018) based on the Progressive GAN by Tero Karras et al. Here, the GAN generator is grown from small to large scale in a pyramidal fashion. Image generation by GAN reached popular success, and provoked discussions concerning deepfakes. Diffusion models (2015) eclipsed GANs in generative modeling since then, with systems such as DALL\u00b7E 2 (2022) and Stable Diffusion (2022).\nIn 2014, the state of the art was training \"very deep neural network\" with 20 to 30 layers. Stacking too many layers led to a steep reduction in training accuracy, known as the \"degradation\" problem. In 2015, two techniques were developed to train very deep networks: the highway network was published in May 2015, and the residual neural network (ResNet) in December 2015. ResNet behaves like an open-gated Highway Net. \nDuring the 2010s, the seq2seq model was developed, and attention mechanisms were added. It led to the modern Transformer architecture in 2017 in \"Attention Is All You Need\".\nIt requires computation time that is quadratic in the size of the context window. J\u00fcrgen Schmidhuber's fast weight controller (1992) scales linearly and was later shown to be equivalent to the unnormalized linear Transformer.\nTransformers have increasingly become the model of choice for natural language processing. Many modern large language models such as ChatGPT, GPT-4, and BERT use this architecture.\nModels.\nANNs began as an attempt to exploit the architecture of the human brain to perform tasks that conventional algorithms had little success with. They soon reoriented towards improving empirical results, abandoning attempts to remain true to their biological precursors. ANNs have the ability to learn and model non-linearities and complex relationships. This is achieved by neurons being connected in various patterns, allowing the output of some neurons to become the input of others. The network forms a directed, weighted graph.\nAn artificial neural network consists of simulated neurons. Each neuron is connected to other nodes via links like a biological axon-synapse-dendrite connection. All the nodes connected by links take in some data and use it to perform specific operations and tasks on the data. Each link has a weight, determining the strength of one node's influence on another, allowing weights to choose the signal between neurons.\nArtificial neurons.\nANNs are composed of artificial neurons which are conceptually derived from biological neurons. Each artificial neuron has inputs and produces a single output which can be sent to multiple other neurons. The inputs can be the feature values of a sample of external data, such as images or documents, or they can be the outputs of other neurons. The outputs of the final \"output neurons\" of the neural net accomplish the task, such as recognizing an object in an image.\nTo find the output of the neuron we take the weighted sum of all the inputs, weighted by the \"weights\" of the \"connections\" from the inputs to the neuron. We add a \"bias\" term to this sum. This weighted sum is sometimes called the \"activation\". This weighted sum is then passed through a (usually nonlinear) activation function to produce the output. The initial inputs are external data, such as images and documents. The ultimate outputs accomplish the task, such as recognizing an object in an image.\nOrganization.\nThe neurons are typically organized into multiple layers, especially in deep learning. Neurons of one layer connect only to neurons of the immediately preceding and immediately following layers. The layer that receives external data is the \"input layer\". The layer that produces the ultimate result is the \"output layer\". In between them are zero or more \"hidden layers\". Single layer and unlayered networks are also used. Between two layers, multiple connection patterns are possible. They can be 'fully connected', with every neuron in one layer connecting to every neuron in the next layer. They can be \"pooling\", where a group of neurons in one layer connects to a single neuron in the next layer, thereby reducing the number of neurons in that layer. Neurons with only such connections form a directed acyclic graph and are known as \"feedforward networks\". Alternatively, networks that allow connections between neurons in the same or previous layers are known as \"recurrent networks\".\nHyperparameter.\nA hyperparameter is a constant parameter defining any configurable part of the learning process, whose value is set prior to training. Examples of hyperparameters include learning rate, batch size and regularization parameters.. The performance of a neural network is strongly influenced by the choice of hyperparameter values, and thus the hyperparameters are often optimized as part of the training process, a process called hyperparameter tuning or hyperparameter optimization.\nLearning.\nLearning is the adaptation of the network to better handle a task by considering sample observations. Learning involves adjusting the weights (and optional thresholds) of the network to improve the accuracy of the result. This is done by minimizing the observed errors. Learning is complete when examining additional observations does not usefully reduce the error rate. Even after learning, the error rate typically does not reach 0. If after learning, the error rate is too high, the network typically must be redesigned. Practically this is done by defining a cost function that is evaluated periodically during learning. As long as its output continues to decline, learning continues. The cost is frequently defined as a statistic whose value can only be approximated. The outputs are actually numbers, so when the error is low, the difference between the output (almost certainly a cat) and the correct answer (cat) is small. Learning attempts to reduce the total of the differences across the observations. Most learning models can be viewed as a straightforward application of optimization theory and statistical estimation.\nLearning rate.\nThe learning rate defines the size of the corrective steps that the model takes to adjust for errors in each observation. A high learning rate shortens the training time, but with lower ultimate accuracy, while a lower learning rate takes longer, but with the potential for greater accuracy. Optimizations such as Quickprop are primarily aimed at speeding up error minimization, while other improvements mainly try to increase reliability. In order to avoid oscillation inside the network such as alternating connection weights, and to improve the rate of convergence, refinements use an adaptive learning rate that increases or decreases as appropriate. The concept of momentum allows the balance between the gradient and the previous change to be weighted such that the weight adjustment depends to some degree on the previous change. A momentum close to 0 emphasizes the gradient, while a value close to 1 emphasizes the last change.\nCost function.\nWhile it is possible to define a cost function ad hoc, frequently the choice is determined by the function's desirable properties (such as convexity) because it arises from the model (e.g. in a probabilistic model, the model's posterior probability can be used as an inverse cost).\nBackpropagation.\nBackpropagation is a method used to adjust the connection weights to compensate for each error found during learning. The error amount is effectively divided among the connections. Technically, backpropagation calculates the gradient (the derivative) of the cost function associated with a given state with respect to the weights. The weight updates can be done via stochastic gradient descent or other methods, such as \"extreme learning machines\", \"no-prop\" networks, training without backtracking, \"weightless\" networks, and non-connectionist neural networks.\nLearning paradigms.\nMachine learning is commonly separated into three main learning paradigms, supervised learning, unsupervised learning and reinforcement learning. Each corresponds to a particular learning task.\nSupervised learning.\nSupervised learning uses a set of paired inputs and desired outputs. The learning task is to produce the desired output for each input. In this case, the cost function is related to eliminating incorrect deductions. A commonly used cost is the mean-squared error, which tries to minimize the average squared error between the network's output and the desired output. Tasks suited for supervised learning are pattern recognition (also known as classification) and regression (also known as function approximation). Supervised learning is also applicable to sequential data (e.g., for handwriting, speech and gesture recognition). This can be thought of as learning with a \"teacher\", in the form of a function that provides continuous feedback on the quality of solutions obtained thus far.\nUnsupervised learning.\nIn unsupervised learning, input data is given along with the cost function, some function of the data formula_1 and the network's output. The cost function is dependent on the task (the model domain) and any \"a priori\" assumptions (the implicit properties of the model, its parameters and the observed variables). As a trivial example, consider the model formula_2 where formula_3 is a constant and the cost formula_4. Minimizing this cost produces a value of formula_3 that is equal to the mean of the data. The cost function can be much more complicated. Its form depends on the application: for example, in compression it could be related to the mutual information between formula_1 and formula_7, whereas in statistical modeling, it could be related to the posterior probability of the model given the data (note that in both of those examples, those quantities would be maximized rather than minimized). Tasks that fall within the paradigm of unsupervised learning are in general estimation problems; the applications include clustering, the estimation of statistical distributions, compression and filtering.\nReinforcement learning.\nIn applications such as playing video games, an actor takes a string of actions, receiving a generally unpredictable response from the environment after each one. The goal is to win the game, i.e., generate the most positive (lowest cost) responses. In reinforcement learning, the aim is to weight the network (devise a policy) to perform actions that minimize long-term (expected cumulative) cost. At each point in time the agent performs an action and the environment generates an observation and an instantaneous cost, according to some (usually unknown) rules. The rules and the long-term cost usually only can be estimated. At any juncture, the agent decides whether to explore new actions to uncover their costs or to exploit prior learning to proceed more quickly.\nFormally, the environment is modeled as a Markov decision process (MDP) with states formula_8 and actions formula_9. Because the state transitions are not known, probability distributions are used instead: the instantaneous cost distribution formula_10, the observation distribution formula_11 and the transition distribution formula_12, while a policy is defined as the conditional distribution over actions given the observations. Taken together, the two define a Markov chain (MC). The aim is to discover the lowest-cost MC.\nANNs serve as the learning component in such applications. Dynamic programming coupled with ANNs (giving neurodynamic programming) has been applied to problems such as those involved in vehicle routing, video games, natural resource management and medicine because of ANNs ability to mitigate losses of accuracy even when reducing the discretization grid density for numerically approximating the solution of control problems. Tasks that fall within the paradigm of reinforcement learning are control problems, games and other sequential decision making tasks.\nSelf-learning.\nSelf-learning in neural networks was introduced in 1982 along with a neural network capable of self-learning named \"crossbar adaptive array\" (CAA). It is a system with only one input, situation s, and only one output, action (or behavior) a. It has neither external advice input nor external reinforcement input from the environment. The CAA computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about encountered situations. The system is driven by the interaction between cognition and emotion. Given the memory matrix, W =||w(a,s)||, the crossbar self-learning algorithm in each iteration performs the following computation:\n In situation s perform action a;\n Receive consequence situation s';\n Compute emotion of being in consequence situation v(s');\n Update crossbar memory w'(a,s) = w(a,s) + v(s').\nThe backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is behavioral environment where it behaves, and the other is genetic environment, where from it receives initial emotions (only once) about to be encountered situations in the behavioral environment. Having received the genome vector (species vector) from the genetic environment, the CAA will learn a goal-seeking behavior, in the behavioral environment that contains both desirable and undesirable situations.\nNeuroevolution.\nNeuroevolution can create neural network topologies and weights using evolutionary computation. It is competitive with sophisticated gradient descent approaches. One advantage of neuroevolution is that it may be less prone to get caught in \"dead ends\".\nStochastic neural network.\nStochastic neural networks originating from Sherrington\u2013Kirkpatrick models are a type of artificial neural network built by introducing random variations into the network, either by giving the network's artificial neurons stochastic transfer functions , or by giving them stochastic weights. This makes them useful tools for optimization problems, since the random fluctuations help the network escape from local minima. Stochastic neural networks trained using a Bayesian approach are known as Bayesian neural networks.\nTopological deep learning.\nTopological deep learning, first introduced in 2017, is an emerging approach in machine learning that integrates topology with deep neural networks to address highly intricate and high-order data. Initially rooted in algebraic topology, TDL has since evolved into a versatile framework incorporating tools from other mathematical disciplines, such as differential topology and geometric topology. As a successful example of mathematical deep learning, TDL continues to inspire advancements in mathematical artificial intelligence, fostering a mutually beneficial relationship between AI and mathematics. \nOther.\nIn a Bayesian framework, a distribution over the set of allowed models is chosen to minimize the cost. Evolutionary methods, gene expression programming, simulated annealing, expectation\u2013maximization, non-parametric methods and particle swarm optimization are other learning algorithms. Convergent recursion is a learning algorithm for cerebellar model articulation controller (CMAC) neural networks.\nModes.\nTwo modes of learning are available: stochastic and batch. In stochastic learning, each input creates a weight adjustment. In batch learning, weights are adjusted based on a batch of inputs, accumulating errors over the batch. Stochastic learning introduces \"noise\" into the process, using the local gradient calculated from one data point; this reduces the chance of the network getting stuck in local minima. However, batch learning typically yields a faster, more stable descent to a local minimum, since each update is performed in the direction of the batch's average error. A common compromise is to use \"mini-batches\", small batches with samples in each batch selected stochastically from the entire data set.\nTypes.\nANNs have evolved into a broad family of techniques that have advanced the state of the art across multiple domains. The simplest types have one or more static components, including number of units, number of layers, unit weights and topology. Dynamic types allow one or more of these to evolve via learning. The latter is much more complicated but can shorten learning periods and produce better results. Some types allow/require learning to be \"supervised\" by the operator, while others operate independently. Some types operate purely in hardware, while others are purely software and run on general purpose computers.\nSome of the main breakthroughs include: \nNetwork design.\nUsing artificial neural networks requires an understanding of their characteristics.\nNeural architecture search (NAS) uses machine learning to automate ANN design. Various approaches to NAS have designed networks that compare well with hand-designed systems. The basic search algorithm is to propose a candidate model, evaluate it against a dataset, and use the results as feedback to teach the NAS network. Available systems include AutoML and AutoKeras. scikit-learn library provides functions to help with building a deep network from scratch. We can then implement a deep network with TensorFlow or Keras.\nHyperparameters must also be defined as part of the design (they are not learned), governing matters such as how many neurons are in each layer, learning rate, step, stride, depth, receptive field and padding (for CNNs), etc. \ndef train(X, y, n_hidden, learning_rate, n_iter):\n \"\"\"Training function.\n Args:\n X: Argument X.\n y: Argument y.\n n_hidden: The number of hidden layer units.\n learning_rate: The learning rate.\n n_iter: The number of iterations.\n Returns:\n dict: A dictionary.\n m, n_input = X.shape\n # 1. random initialize weights and biases\n w1 = np.random.randn(n_input, n_hidden)\n b1 = np.zeros((1, n_hidden))\n w2 = np.random.randn(n_hidden, 1)\n b2 = np.zeros((1, 1))\n # 2. in each iteration, feed all layers with the latest weights and biases\n for i in range(n_iter + 1):\n z2 = np.dot(X, w1) + b1\n a2 = sigmoid(z2)\n z3 = np.dot(a2, w2) + b2\n a3 = z3\n dz3 = a3 - y\n dw2 = np.dot(a2.T, dz3)\n db2 = np.sum(dz3, axis=0, keepdims=True)\n dz2 = np.dot(dz3, w2.T) * sigmoid_derivative(z2)\n dw1 = np.dot(X.Y, dz2)\n db1 = np.sum(dz2, axis=0)\n # 3. update weights and biases with gradients\n w1 -= learning_rate * dw1 / m\n w2 -= learning_rate * dw2 / m\n b1 -= learning_rate * db1 / m\n b2 -= learning_rate * db2 / m\n if i % 1000 == 0:\n print(\"Epoch\", i, \"loss: \", np.mean(np.square(dz3)))\n return model\nMonitoring and concept drift detection of ANNs.\nWhen neural networks are deployed in real-world applications, the statistical properties of the input data may change over time, a phenomenon known as concept drift or non-stationarity. Drift can reduce predictive accuracy and lead to unreliable or biased decisions if it is not detected and corrected. In practice, this means that the model's accuracy in deployment may differ substantially from the levels observed during training or cross-validation. \nSeveral strategies have been developed to monitor neural networks for drift and degradation: \nApplications.\nBecause of their ability to model and reproduce nonlinear processes, artificial neural networks have found applications in many disciplines. These include:\nANNs have been used to diagnose several types of cancers and to distinguish highly invasive cancer cell lines from less invasive lines using only cell shape information.\nANNs have been used to accelerate reliability analysis of infrastructures subject to natural disasters and to predict foundation settlements. It can also be useful to mitigate flood by the use of ANNs for modelling rainfall-runoff. ANNs have also been used for building black-box models in geoscience: hydrology, ocean modelling and coastal engineering, and geomorphology. ANNs have been employed in cybersecurity, with the objective to discriminate between legitimate activities and malicious ones. For example, machine learning has been used for classifying Android malware, for identifying domains belonging to threat actors and for detecting URLs posing a security risk. Research is underway on ANN systems designed for penetration testing, for detecting botnets, credit cards frauds and network intrusions.\nANNs have been proposed as a tool to solve partial differential equations in physics and simulate the properties of many-body open quantum systems. In brain research ANNs have studied short-term behavior of individual neurons, the dynamics of neural circuitry arise from interactions between individual neurons and how behavior can arise from abstract neural modules that represent complete subsystems. Studies considered long-and short-term plasticity of neural systems and their relation to learning and memory from the individual neuron to the system level.\nIt is possible to create a profile of a user's interests from pictures, using artificial neural networks trained for object recognition.\nBeyond their traditional applications, artificial neural networks are increasingly being utilized in interdisciplinary research, such as materials science. For instance, graph neural networks (GNNs) have demonstrated their capability in scaling deep learning for the discovery of new stable materials by efficiently predicting the total energy of crystals. This application underscores the adaptability and potential of ANNs in tackling complex problems beyond the realms of predictive modeling and artificial intelligence, opening new pathways for scientific discovery and innovation.\nTheoretical properties.\nComputational power.\nThe multilayer perceptron is a universal function approximator, as proven by the universal approximation theorem. However, the proof is not constructive regarding the number of neurons required, the network topology, the weights and the learning parameters.\nA specific recurrent architecture with rational-valued weights (as opposed to full precision real number-valued weights) has the power of a universal Turing machine, using a finite number of neurons and standard linear connections. Further, the use of irrational values for weights results in a machine with super-Turing power.\nCapacity.\nA model's \"capacity\" property corresponds to its ability to model any given function. It is related to the amount of information that can be stored in the network and to the notion of complexity.\nTwo notions of capacity are known by the community. The information capacity and the VC Dimension. The information capacity of a perceptron is intensively discussed in Sir David MacKay's book which summarizes work by Thomas Cover. The capacity of a network of standard neurons (not convolutional) can be derived by four rules that derive from understanding a neuron as an electrical element. The information capacity captures the functions modelable by the network given any data as input. The second notion, is the VC dimension. VC Dimension uses the principles of measure theory and finds the maximum capacity under the best possible circumstances. This is, given input data in a specific form. As noted in, the VC Dimension for arbitrary inputs is half the information capacity of a perceptron. The VC Dimension for arbitrary points is sometimes referred to as Memory Capacity.\nConvergence.\nModels may not consistently converge on a single solution, firstly because local minima may exist, depending on the cost function and the model. Secondly, the optimization method used might not guarantee to converge when it begins far from any local minimum. Thirdly, for sufficiently large data or parameters, some methods become impractical.\nAnother issue worthy to mention is that training may cross some saddle point which may lead the convergence to the wrong direction.\nThe convergence behavior of certain types of ANN architectures are more understood than others. When the width of network approaches to infinity, the ANN is well described by its first order Taylor expansion throughout training, and so inherits the convergence behavior of affine models. Another example is when parameters are small, it is observed that ANNs often fit target functions from low to high frequencies. This behavior is referred to as the spectral bias, or frequency principle, of neural networks. This phenomenon is the opposite to the behavior of some well studied iterative numerical schemes such as Jacobi method. Deeper neural networks have been observed to be more biased towards low frequency functions.\nGeneralization and statistics.\nApplications whose goal is to create a system that generalizes well to unseen examples, face the possibility of over-training. This arises in convoluted or over-specified systems when the network capacity significantly exceeds the needed free parameters. \nTwo approaches address over-training. The first is to use cross-validation and similar techniques to check for the presence of over-training and to select hyperparameters to minimize the generalization error. The second is to use some form of \"regularization\". This concept emerges in a probabilistic (Bayesian) framework, where regularization can be performed by selecting a larger prior probability over simpler models; but also in statistical learning theory, where the goal is to minimize over two quantities: the 'empirical risk' and the 'structural risk', which roughly corresponds to the error over the training set and the predicted error in unseen data due to overfitting.\nSupervised neural networks that use a mean squared error (MSE) cost function can use formal statistical methods to determine the confidence of the trained model. The MSE on a validation set can be used as an estimate for variance. This value can then be used to calculate the confidence interval of network output, assuming a normal distribution. A confidence analysis made this way is statistically valid as long as the output probability distribution stays the same and the network is not modified.\nBy assigning a softmax activation function, a generalization of the logistic function, on the output layer of the neural network (or a softmax component in a component-based network) for categorical target variables, the outputs can be interpreted as posterior probabilities. This is useful in classification as it gives a certainty measure on classifications.\nThe softmax activation function is:\nformula_13\n&lt;section end=\"theory\" /&gt;\nCriticism.\nTraining.\nA common criticism of neural networks, particularly in robotics, is that they require too many training samples for real-world operation.\nAny learning machine needs sufficient representative examples in order to capture the underlying structure that allows it to generalize to new cases. Potential solutions include randomly shuffling training examples, by using a numerical optimization algorithm that does not take too large steps when changing the network connections following an example, grouping examples in so-called mini-batches and/or introducing a recursive least squares algorithm for CMAC.\nDean Pomerleau uses a neural network to train a robotic vehicle to drive on multiple types of roads (single lane, multi-lane, dirt, etc.), and a large amount of his research is devoted to extrapolating multiple training scenarios from a single training experience, and preserving past training diversity so that the system does not become overtrained (if, for example, it is presented with a series of right turns\u2014it should not learn to always turn right).\nTheory.\nA central claim of ANNs is that they embody new and powerful general principles for processing information. These principles are ill-defined. This allows simple statistical association (the basic function of artificial neural networks) to be described as learning or recognition. In 1997, Alexander Dewdney, a former \"Scientific American\" columnist, commented that as a result, artificial neural networks have a \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;something-for-nothing quality, one that imparts a peculiar aura of laziness and a distinct lack of curiosity about just how good these computing systems are. No human hand (or mind) intervenes; solutions are found as if by magic; and no one, it seems, has learned anything. One response to Dewdney is that neural networks have been successfully used to handle many complex and diverse tasks, ranging from autonomously flying aircraft to detecting credit card fraud to mastering the game of Go.\nTechnology writer Roger Bridgman commented:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Neural networks, for instance, are in the dock not only because they have been hyped to high heaven, (what hasn't?) but also because you could create a successful net without understanding how it worked: the bunch of numbers that captures its behaviour would in all probability be \"an opaque, unreadable table...valueless as a scientific resource\".\nIn spite of his emphatic declaration that science is not technology, Dewdney seems here to pillory neural nets as bad science when most of those devising them are just trying to be good engineers. An unreadable table that a useful machine could read would still be well worth having.\nAlthough it is true that analyzing what has been learned by an artificial neural network is difficult, it is much easier to do so than to analyze what has been learned by a biological neural network. Moreover, recent emphasis on the explainability of AI has contributed towards the development of methods, notably those based on attention mechanisms, for visualizing and explaining learned neural networks. Furthermore, researchers involved in exploring learning algorithms for neural networks are gradually uncovering generic principles that allow a learning machine to be successful. For example, Bengio and LeCun (2007) wrote an article regarding local vs non-local learning, as well as shallow vs deep architecture.\nBiological brains use both shallow and deep circuits as reported by brain anatomy, displaying a wide variety of invariance. Weng argued that the brain self-wires largely according to signal statistics and therefore, a serial cascade cannot catch all major statistical dependencies.\nHardware.\nLarge and effective neural networks require considerable computing resources. While the brain has hardware tailored to the task of processing signals through a graph of neurons, simulating even a simplified neuron on von Neumann architecture may consume vast amounts of memory and storage. Furthermore, the designer often needs to transmit signals through many of these connections and their associated neurons\u00a0\u2013 which require enormous CPU power and time.\nSome argue that the resurgence of neural networks in the twenty-first century is largely attributable to advances in hardware: from 1991 to 2015, computing power, especially as delivered by GPGPUs (on GPUs), has increased around a million-fold, making the standard backpropagation algorithm feasible for training networks that are several layers deeper than before. The use of accelerators such as FPGAs and GPUs can reduce training times from months to days.\nNeuromorphic engineering or a physical neural network addresses the hardware difficulty directly, by constructing non-von-Neumann chips to directly implement neural networks in circuitry. Another type of chip optimized for neural network processing is called a Tensor Processing Unit, or TPU.\nPractical counterexamples.\nAnalyzing what has been learned by an ANN is much easier than analyzing what has been learned by a biological neural network. Furthermore, researchers involved in exploring learning algorithms for neural networks are gradually uncovering general principles that allow a learning machine to be successful. For example, local vs. non-local learning and shallow vs. deep architecture.\nHybrid approaches.\nAdvocates of hybrid models (combining neural networks and symbolic approaches) say that such a mixture can better capture the mechanisms of the human mind.\nDataset bias.\nNeural networks are dependent on the quality of the data they are trained on, thus low quality data with imbalanced representativeness can lead to the model learning and perpetuating societal biases. These inherited biases become especially critical when the ANNs are integrated into real-world scenarios where the training data may be imbalanced due to the scarcity of data for a specific race, gender or other attribute. This imbalance can result in the model having inadequate representation and understanding of underrepresented groups, leading to discriminatory outcomes that exacerbate societal inequalities, especially in applications like facial recognition, hiring processes, and law enforcement. For example, in 2018, Amazon had to scrap a recruiting tool because the model favored men over women for jobs in software engineering due to the higher number of male workers in the field. The program would penalize any resume with the word \"woman\" or the name of any women's college. However, the use of synthetic data can help reduce dataset bias and increase representation in datasets.\nRecent advancements and future directions.\nArtificial neural networks (ANNs) have undergone significant advancements, particularly in their ability to model complex systems, handle large data sets, and adapt to various types of applications. Their evolution over the past few decades has been marked by a broad range of applications in fields such as image processing, speech recognition, natural language processing, finance, and medicine.\nImage processing.\nIn the realm of image processing, ANNs are employed in tasks such as image classification, object recognition, and image segmentation. For instance, deep convolutional neural networks (CNNs) have been important in handwritten digit recognition, achieving state-of-the-art performance. This demonstrates the ability of ANNs to effectively process and interpret complex visual information, leading to advancements in fields ranging from automated surveillance to medical imaging.\nSpeech recognition.\nBy modeling speech signals, ANNs are used for tasks like speaker identification and speech-to-text conversion. Deep neural network architectures have introduced significant improvements in large vocabulary continuous speech recognition, outperforming traditional techniques. These advancements have enabled the development of more accurate and efficient voice-activated systems, enhancing user interfaces in technology products.\nNatural language processing.\nIn natural language processing, ANNs are used for tasks such as text classification, sentiment analysis, and machine translation. They have enabled the development of models that can accurately translate between languages, understand the context and sentiment in textual data, and categorize text based on content. This has implications for automated customer service, content moderation, and language understanding technologies.\nControl systems.\nIn the domain of control systems, ANNs are used to model dynamic systems for tasks such as system identification, control design, and optimization. For instance, deep feedforward neural networks are important in system identification and control applications.\nFinance.\nANNs are used for stock market prediction and credit scoring: \nANNs require high-quality data and careful tuning, and their \"black-box\" nature can pose challenges in interpretation. Nevertheless, ongoing advancements suggest that ANNs continue to play a role in finance, offering valuable insights and enhancing risk management strategies.\nMedicine.\nANNs are able to process and analyze vast medical datasets. They enhance diagnostic accuracy, especially by interpreting complex medical imaging for early disease detection, and by predicting patient outcomes for personalized treatment planning. In drug discovery, ANNs speed up the identification of potential drug candidates and predict their efficacy and safety, significantly reducing development time and costs. Additionally, their application in personalized medicine and healthcare data analysis allows tailored therapies and efficient patient care management. Ongoing research is aimed at addressing remaining challenges such as data privacy and model interpretability, as well as expanding the scope of ANN applications in medicine.\nContent creation.\nANNs such as generative adversarial networks (GAN) and transformers are used for content creation across numerous industries. This is because deep learning models are able to learn the style of an artist or musician from huge datasets and generate completely new artworks and music compositions. For instance, DALL-E is a deep neural network trained on 650 million pairs of images and texts across the internet that can create artworks based on text entered by the user. In the field of music, transformers are used to create original music for commercials and documentaries through companies such as AIVA and Jukedeck. In the marketing industry, generative models are used to create personalized advertisements for consumers. Additionally, major film companies are partnering with technology companies to analyze the financial success of a film, such as the partnership between Warner Bros and technology company Cinelytic established in 2020. Furthermore, neural networks have found uses in video game creation, where non-player characters (NPCs) can make decisions based on all the characters currently in the game.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21524", "revid": "14383484", "url": "https://en.wikipedia.org/wiki?curid=21524", "title": "Neural networks", "text": ""}
{"id": "21525", "revid": "50865928", "url": "https://en.wikipedia.org/wiki?curid=21525", "title": "Nutrition", "text": "Provision to cells and organisms to support life\nNutrition is the biochemical and physiological process by which an organism uses food and water to support its life. The intake of these substances provides organisms with nutrients (divided into macro- and micro-) which can be metabolized to create energy and chemical structures; too much or too little of an essential nutrient can cause malnutrition. Nutritional science, the study of nutrition as a hard science, typically emphasizes human nutrition.\nThe type of organism determines what nutrients it needs and how it obtains them. Organisms obtain nutrients by consuming organic matter, consuming inorganic matter, absorbing light, or some combination of these. Some can produce nutrients internally by consuming basic elements, while others must consume other organisms to obtain pre-existing nutrients. All forms of life require carbon, energy, and water as well as various other molecules. Animals require complex nutrients such as carbohydrates, lipids, and proteins, obtaining them by consuming other organisms. Humans have developed agriculture and cooking to replace foraging and advance human nutrition. Plants acquire nutrients through the soil and the atmosphere. Fungi absorb nutrients around them by breaking them down and absorbing them through the mycelium.\nHistory.\nScientific analysis of food and nutrients began during the chemical revolution in the late 18th century. Chemists in the 18th and 19th centuries experimented with different elements and food sources to develop theories of nutrition. Modern nutrition science began in the 1910s as individual micronutrients began to be identified. The first vitamin to be chemically identified was thiamine in 1926, and vitamin C was identified as a protection against scurvy in 1932. The role of vitamins in nutrition was studied in the following decades. The first recommended dietary allowances for humans were developed to address fears of disease caused by food deficiencies during the Great Depression and the Second World War. Due to its importance in human health, the study of nutrition has heavily emphasized human nutrition and agriculture, while ecology is a secondary concern.\nNutrients.\nNutrients are substances that provide energy and physical components to the organism, allowing it to survive, grow, and reproduce. Nutrients can be basic elements or complex macromolecules. Approximately 30 elements are found in organic matter, with nitrogen, carbon, and phosphorus being the most important. Macronutrients are the primary substances required by an organism, and micronutrients are substances required by an organism in trace amounts. Organic micronutrients are classified as vitamins, and inorganic micronutrients are classified as minerals. Over-nutrition of macronutrients is a major cause of obesity and increases the risk of developing various non-communicable diseases (NCDs), including type 2 diabetes, stroke, hypertension, coronary heart disease, osteoporosis, and some forms of cancer. Nutrients can also be classified as essential or nonessential, with essential meaning the body cannot synthesize the nutrient on its own.\nNutrients are absorbed by the cells and used in metabolic biochemical reactions. These include fueling reactions that create precursor metabolites and energy, biosynthetic reactions that convert precursor metabolites into building block molecules, polymerizations that combine these molecules into macromolecule polymers, and assembly reactions that use these polymers to construct cellular structures.\nNutritional groups.\nOrganisms can be classified by how they obtain carbon and energy. Heterotrophs are organisms that obtain nutrients by consuming the carbon of other organisms, while autotrophs are organisms that produce their own nutrients from the carbon of inorganic substances like carbon dioxide. Mixotrophs are organisms that can be heterotrophs and autotrophs, including some plankton and carnivorous plants. Phototrophs obtain energy from light, while chemotrophs obtain energy by consuming chemical energy from matter. Organotrophs consume other organisms to obtain electrons, while lithotrophs obtain electrons from inorganic substances, such as water, hydrogen sulfide, dihydrogen, iron(II), sulfur, or ammonium. Prototrophs can create essential nutrients from other compounds, while auxotrophs must consume preexisting nutrients.\nDiet.\nIn nutrition, the diet of an organism is the sum of the foods it eats. A healthy diet improves the physical and mental health of an organism. This requires ingestion and absorption of vitamins, minerals, essential amino acids from protein and essential fatty acids from fat-containing food. Carbohydrates, protein and fat play major roles in ensuring the quality of life, health and longevity of the organism. Some cultures and religions have restrictions on what is acceptable for their diet.\nNutrient cycle.\nA nutrient cycle is a biogeochemical cycle involving the movement of inorganic matter through a combination of soil, organisms, air or water, where they are exchanged in organic matter. Energy flow is a unidirectional and noncyclic pathway, whereas the movement of mineral nutrients is cyclic. Mineral cycles include the carbon cycle, sulfur cycle, nitrogen cycle, water cycle, phosphorus cycle, and oxygen cycle, among others that continually recycle along with other mineral nutrients into productive ecological nutrition.\nBiogeochemical cycles that are performed by living organisms and natural processes are water, carbon, nitrogen, phosphorus, and sulfur cycles. Nutrient cycles allow these essential elements to return to the environment after being absorbed or consumed. Without proper nutrient cycling, there would be a risk of change in oxygen levels, climate, and ecosystem function.\nForaging.\nForaging is the process of seeking out nutrients in the environment. It may also be defined to include the subsequent use of the resources. Some organisms, such as animals and bacteria, can navigate to find nutrients, while others, such as plants and fungi, extend outward to find nutrients. Foraging may be random, in which the organism seeks nutrients without method, or it may be systematic, in which the organism can go directly to a food source. Organisms are able to detect nutrients through taste or other forms of nutrient sensing, allowing them to regulate nutrient intake. Optimal foraging theory is a model that explains foraging behavior as a cost\u2013benefit analysis in which an animal must maximize the gain of nutrients while minimizing the amount of time and energy spent foraging. It was created to analyze the foraging habits of animals, but it can also be extended to other organisms. Some organisms are specialists that are adapted to forage for a single food source, while others are generalists that can consume a variety of food sources.\nNutrient deficiency.\nNutrient deficiencies, known as malnutrition, occur when an organism does not have the nutrients that it needs. A deficiency is not the same as a nutrient inadequacy which occurs when the intake of nutrients is above the level of deficiency, but below the recommended dietary level. This may lead to hidden symptoms of nutrient deficiency that are difficult to identify. Nutrient deficiency may be caused by a sudden decrease in nutrient intake or by an inability to absorb essential nutrients. Not only is malnutrition the result of a lack of necessary nutrients, but it can also be a result of other illnesses and health conditions. When this occurs, an organism will adapt by reducing energy consumption and expenditure to prolong the use of stored nutrients. It will use stored energy reserves until they are depleted.\nA balanced diet includes appropriate amounts of all essential and non-essential nutrients. These can vary by age, weight, sex, physical activity levels, and more. A lack of just one essential nutrient can cause bodily harm, just as an overabundance can cause toxicity. The Daily Reference Values keep the majority of people from nutrient deficiencies. DRVs are not recommendations but a combination of nutrient references to educate professionals and policymakers on what the maximum and minimum nutrient intakes are for the average person. Food labels also use DRVs as a reference to create safe nutritional guidelines for the average healthy person.\nIn organisms.\nAnimal.\nAnimals are heterotrophs that consume other organisms to obtain nutrients. Herbivores are animals that eat plants, carnivores are animals that eat other animals, and omnivores are animals that eat both plants and other animals. Many herbivores rely on bacterial fermentation to create digestible nutrients from indigestible plant cellulose, while obligate carnivores must eat animal meats to obtain certain vitamins or nutrients their bodies cannot otherwise synthesize. Animals generally have a higher requirement of energy in comparison to plants. The macronutrients essential to animal life are carbohydrates, amino acids, and fatty acids.\nAll macronutrients except water are required by the body for energy, however, this is not their sole physiological function. The energy provided by macronutrients in food is measured in kilocalories, usually called Calories, where 1 Calorie is the amount of energy required to raise 1 kilogram of water by 1 degree Celsius.\nCarbohydrates are molecules that store significant amounts of energy. Animals digest and metabolize carbohydrates to obtain this energy. Carbohydrates are typically synthesized by plants during metabolism, and animals have to obtain most carbohydrates from nature, as they have only a limited ability to generate them. They include sugars, oligosaccharides, and polysaccharides. Glucose is the simplest form of carbohydrate. Carbohydrates are broken down to produce glucose and short-chain fatty acids, and they are the most abundant nutrients for herbivorous land animals. Carbohydrates contain 4 calories per gram.\nLipids provide animals with fats and oils. They are not soluble in water, and they can store energy for an extended period of time. They can be obtained from many different plant and animal sources. Most dietary lipids are triglycerides, composed of glycerol and fatty acids. Phospholipids and sterols are found in smaller amounts. An animal's body will reduce the amount of fatty acids it produces as dietary fat intake increases, while it increases the amount of fatty acids it produces as carbohydrate intake increases. Fats contain 9 calories per gram.\nProtein consumed by animals is broken down to amino acids, which would be later used to synthesize new proteins. Protein is used to form cellular structures, fluids, and enzymes (biological catalysts). Enzymes are essential to most metabolic processes, as well as DNA replication, repair, and transcription. Protein contains 4 calories per gram.\nMuch of animal behavior is governed by nutrition. Migration patterns and seasonal breeding take place in conjunction with food availability, and courtship displays are used to display an animal's health. Animals develop positive and negative associations with foods that affect their health, and they can instinctively avoid foods that have caused toxic injury or nutritional imbalances through a conditioned food aversion. Some animals, such as rats, do not seek out new types of foods unless they have a nutrient deficiency.\nHuman.\nEarly human nutrition consisted of foraging for nutrients, like other animals, but it diverged at the beginning of the Holocene with the Neolithic Revolution, in which humans developed agriculture to produce food. The Chemical Revolution in the 18th century allowed humans to study the nutrients in foods and develop more advanced methods of food preparation. Major advances in economics and technology during the 20th century allowed mass production and food fortification to better meet the nutritional needs of humans. Human behavior is closely related to human nutrition, making it a subject of social science in addition to biology. Nutrition in humans is balanced with eating for pleasure, and optimal diet may vary depending on the demographics and health concerns of each person. Social determinants of health (SDOH) and structural factors drive nutrition and diet-related health disparities. \nHumans are omnivores that eat a variety of foods. Cultivation of cereals and production of bread has made up a key component of human nutrition since the beginning of agriculture. Early humans hunted animals for meat, and modern humans domesticate animals to consume their meat and eggs. The development of animal husbandry has also allowed humans in some cultures to consume the milk of other animals and process it into foods such as cheese. Other foods eaten by humans include nuts, seeds, fruits, and vegetables. Access to domesticated animals as well as vegetable oils has caused a significant increase in human intake of fats and oils. Humans have developed advanced methods of food processing that prevent contamination of pathogenic microorganisms and simplify the production of food. These include drying, freezing, heating, milling, pressing, packaging, refrigeration, and irradiation. Most cultures add herbs and spices to foods before eating to add flavor, though most do not significantly affect nutrition. Other additives are also used to improve the safety, quality, flavor, and nutritional content of food.\nHumans obtain most carbohydrates as starch from cereals, though sugar has grown in importance. Lipids can be found in animal fat, butterfat, vegetable oil, and leaf vegetables, and they are also used to increase flavor in foods. Protein can be found in virtually all foods, as it makes up cellular material, though certain methods of food processing may reduce the amount of protein in a food. Humans can also obtain energy from ethanol, which is both a food and a drug, but it provides relatively few essential nutrients and is associated with nutritional deficiencies and other health risks.\nIn humans, poor nutrition can cause deficiency-related diseases, such as blindness, anemia, scurvy, preterm birth, stillbirth and cretinism, or nutrient-excess conditions, such as obesity and metabolic syndrome. Other conditions possibly affected by nutrition disorders include cardiovascular diseases, diabetes, and osteoporosis. Undernutrition can lead to wasting in acute cases, and stunting of marasmus in chronic cases of malnutrition.\nDomesticated animal.\nIn domesticated animals, such as pets, livestock, and working animals, as well as other animals in captivity, nutrition is managed by humans through animal feed. Fodder and forage are provided to livestock. Specialized pet food has been manufactured since 1860, and subsequent research and development have addressed the nutritional needs of pets. Dog food and cat food in particular are heavily studied and typically include all essential nutrients for these animals. Cats are sensitive to some common nutrients, such as taurine, and require additional nutrients derived from meat. Large-breed puppies are susceptible to overnutrition, as small-breed dog food is more energy dense than they can absorb.\nPlant.\nMost plants obtain nutrients through inorganic substances absorbed from the soil or the atmosphere. Carbon, hydrogen, oxygen, nitrogen, and sulfur are essential nutrients that make up organic material in a plant and allow enzymic processes. These are absorbed ions in the soil, such as bicarbonate, nitrate, ammonium, and sulfate, or they are absorbed as gases, such as carbon dioxide, water, oxygen gas, and sulfur dioxide. Phosphorus, boron, and silicon are used for esterification. They are obtained through the soil as phosphates, boric acid, and silicic acid, respectively. Other nutrients used by plants are potassium, sodium, calcium, magnesium, manganese, chlorine, iron, copper, zinc, and molybdenum.\nPlants uptake essential elements from the soil through their roots and from the air (consisting of mainly nitrogen and oxygen) through their leaves. Nutrient uptake in the soil is achieved by cation exchange, wherein root hairs pump hydrogen ions (H+) into the soil through proton pumps. These hydrogen ions displace cations attached to negatively charged soil particles so that the cations are available for uptake by the root. In the leaves, stomata open to take in carbon dioxide and expel oxygen. Although nitrogen is plentiful in the Earth's atmosphere, very few plants can use this directly. Most plants, therefore, require nitrogen compounds to be present in the soil in which they grow. This is made possible by the fact that largely inert atmospheric nitrogen is changed in a nitrogen fixation process to biologically usable forms in the soil by bacteria.\nAs these nutrients do not provide the plant with energy, they must obtain energy by other means. Green plants absorb energy from sunlight with chloroplasts and convert it to usable energy through photosynthesis.\nFungus.\nFungi are chemoheterotrophs that consume external matter for energy. Most fungi absorb matter through the root-like mycelium, which grows through the organism's source of nutrients and can extend indefinitely. The fungus excretes extracellular enzymes to break down surrounding matter and then absorbs the nutrients through the cell wall. Fungi can be parasitic, saprophytic, or symbiotic. Parasitic fungi attach and feed on living hosts, such as animals, plants, or other fungi. Saprophytic fungi feed on dead and decomposing organisms. Symbiotic fungi grow around other organisms and exchange nutrients with them.\nProtist.\nProtists include all eukaryotes that are not animals, plants, or fungi, resulting in great diversity between them. Algae are photosynthetic protists that can produce energy from light. Several types of protists use mycelium similar to those of fungi. Protozoa are heterotrophic protists, and different protozoa seek nutrients in different ways. Flagellate protozoa use a flagellum to assist in hunting for food, and some protozoa travel via infectious spores to act as parasites. Many protists are mixotrophic, having both phototrophic and heterotrophic characteristics. Mixotrophic protists will typically depend on one source of nutrients while using the other as a supplemental source or a temporary alternative when its primary source is unavailable.\nProkaryote.\nProkaryotes, including bacteria and archaea, vary greatly in how they obtain nutrients across nutritional groups. Prokaryotes can only transport soluble compounds across their cell envelopes, but they can break down chemical components around them. Some lithotrophic prokaryotes are extremophiles that can survive in nutrient-deprived environments by breaking down inorganic matter. Phototrophic prokaryotes, such as cyanobacteria and Chloroflexia, can engage in photosynthesis to obtain energy from sunlight. This is common among bacteria that form in mats atop geothermal springs. Phototrophic prokaryotes typically obtain carbon from assimilating carbon dioxide through the Calvin cycle.\nSome prokaryotes, such as \"Bdellovibrio\" and \"Ensifer\", are predatory and feed on other single-celled organisms. Predatory prokaryotes seek out other organisms through chemotaxis or random collision, merge with the organism, degrade it, and absorb the released nutrients. Predatory strategies of prokaryotes include attaching to the outer surface of the organism and degrading it externally, entering the cytoplasm of the organism, or by entering the periplasmic space of the organism. Groups of predatory prokaryotes may forgo attachment by collectively producing hydrolytic enzymes.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21526", "revid": "17517001", "url": "https://en.wikipedia.org/wiki?curid=21526", "title": "November 22", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearNovember 22 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21527", "revid": "6727347", "url": "https://en.wikipedia.org/wiki?curid=21527", "title": "Number theory", "text": "Branch of mathematics\nNumber theory is a branch of pure mathematics devoted primarily to the study of the integers and arithmetic functions. Number theorists study prime numbers as well as the properties of mathematical objects constructed from integers (for example, rational numbers), or defined as generalizations of the integers (for example, algebraic integers). \nIntegers can be considered either in themselves or as solutions to equations (Diophantine geometry). Questions in number theory can often be understood through the study of analytical objects, such as the Riemann zeta function, that encode properties of the integers, primes or other number-theoretic objects in some fashion (analytic number theory). One may also study real numbers in relation to rational numbers, as for instance how irrational numbers can be approximated by fractions (Diophantine approximation).\nNumber theory is one of the oldest branches of mathematics alongside geometry. One quirk of number theory is that it deals with statements that are simple to understand but are very difficult to solve. Examples of this are Fermat's Last Theorem, which was proved 358 years after the original formulation, and Goldbach's conjecture, which remains unsolved since the 18th century. German mathematician Carl Friedrich Gauss (1777\u20131855) once remarked, \"Mathematics is the queen of the sciences\u2014and number theory is the queen of mathematics.\" It was regarded as the epitome of pure mathematics, with no applications outside mathematics, until the 1970s, when prime numbers became the basis for the creation of public-key cryptography algorithms, such as the RSA cryptosystem.\nDefinition.\nNumber theory is the branch of mathematics that studies integers and their properties and relations. The integers comprise a set that extends the set of natural numbers formula_1 to include number formula_2 and the negation of natural numbers formula_3. Number theorists study prime numbers as well as the properties of mathematical objects constructed from integers (for example, rational numbers), or defined as generalizations of the integers (for example, algebraic integers).\nNumber theory is closely related to arithmetic and some authors use the terms as synonyms. However, the word \"arithmetic\" is used today to mean the study of numerical operations and extends to the real numbers. In a more specific sense, number theory is restricted to the study of integers and focuses on their properties and relationships. Traditionally, it is known as higher arithmetic. By the early twentieth century, the term \"number theory\" had been widely adopted. The term number means whole numbers, which refers to either the natural numbers or the integers.\nElementary number theory studies aspects of integers that can be investigated using elementary methods such as elementary proofs. Analytic number theory, by contrast, relies on complex numbers and techniques from analysis and calculus. Algebraic number theory employs algebraic structures such as fields and rings to analyze the properties of and relations between numbers. Geometric number theory uses concepts from geometry to study numbers. Further branches of number theory are probabilistic number theory, combinatorial number theory, computational number theory, and applied number theory, which examines the application of number theory to science and technology.\nHistory.\nIn recorded history, knowledge of numbers existed in the ancient civilisations of Mesopotamia, Egypt, China, and India. The earliest historical find of an arithmetical nature is the Plimpton 322, dated c.\u00a01800\u00a0BC. It is a broken clay tablet that contains a list of Pythagorean triples, that is, integers formula_4 such that formula_5. The triples are too numerous and too large to have been obtained by brute force. The table's layout suggests that it was constructed by means of what amounts, in modern language, to the identityformula_6which is implicit in routine Old Babylonian exercises. It has been suggested instead that the table was a source of numerical examples for school problems. Plimpton 322 tablet is the only surviving evidence of what today would be called number theory within Babylonian mathematics, though a kind of Babylonian algebra was much more developed.\nAlthough other civilizations probably influenced Greek mathematics at the beginning, all evidence of such borrowings appear relatively late, and it is likely that Greek (the theoretical or philosophical study of numbers) is an indigenous tradition. The ancient Greeks developed a keen interest in divisibility. The Pythagoreans attributed mystical quality to perfect and amicable numbers. The Pythagorean tradition also spoke of so-called polygonal or figurate numbers. Euclid devoted part of his \"Elements\" to topics that belong to elementary number theory, including prime numbers and divisibility. He gave the Euclidean algorithm for computing the greatest common divisor of two numbers and a proof implying the infinitude of primes. The foremost authority in in Late Antiquity was Diophantus of Alexandria, who probably lived in the 3rd century\u00a0AD. He wrote \"Arithmetica\", a collection of worked-out problems where the task is invariably to find rational solutions to a system of polynomial equations, usually of the form formula_7 or formula_8. In modern parlance, Diophantine equations are polynomial equations to which rational or integer solutions are sought.\nAfter the fall of Rome, development shifted to Asia, albeit intermittently. The Chinese remainder theorem appears as an exercise in \"Sunzi Suanjing\" (between the third and fifth centuries). The result was later generalized with a complete solution called \"Da-yan-shu\" () in Qin Jiushao's 1247 \"Mathematical Treatise in Nine Sections.\" There is also some numerical mysticism in Chinese mathematics, but, unlike that of the Pythagoreans, it seems to have led nowhere. While Greek astronomy probably influenced Indian learning it seems to be the case that Indian mathematics is otherwise an autochthonous tradition. \u0100ryabha\u1e6da (476\u2013550\u00a0AD) showed that pairs of simultaneous congruences formula_9, formula_10 could be solved by a method he called \"ku\u1e6d\u1e6daka\", or \"pulveriser\"; this is a procedure close to the Euclidean algorithm. \u0100ryabha\u1e6da seems to have had in mind applications to astronomical calculations. Brahmagupta (628\u00a0AD) started the systematic study of indefinite quadratic equations\u2014in particular, the Pell equation. A general procedure for solving Pell's equation was probably found by Jayadeva; the earliest surviving exposition appears in Bh\u0101skara II's B\u012bja-ga\u1e47ita (twelfth century).\nIn the early ninth century, the caliph al-Ma'mun ordered translations of many Greek mathematical works and at least one Sanskrit work.\nDiophantus's main work, the \"Arithmetica\", was translated into Arabic by Qusta ibn Luqa (820\u2013912).\nPart of the treatise \"al-Fakhri\" (by al-Karaj\u012b, 953\u00a0\u2013 c.\u00a01029) builds on it to some extent. According to Rashed Roshdi, Al-Karaj\u012b's contemporary Ibn al-Haytham knew what would later be called Wilson's theorem. Other than a treatise on squares in arithmetic progression by Fibonacci no number theory to speak of was done in western Europe during the Middle Ages. Matters started to change in Europe in the late Renaissance, thanks to a renewed study of the works of Greek antiquity. A catalyst was the textual emendation and translation into Latin of Diophantus' \"Arithmetica\".\nFrench mathematician Pierre de Fermat (1607\u20131665) never published his writings but communicated through correspondence and wrote in marginal notes instead. His contributions to number theory brought renewed interest in the field in Europe. He conjectured Fermat's little theorem, a basic result in modular arithmetic, and Fermat's Last Theorem, as well as proved Fermat's right triangle theorem. He also studied prime numbers, the four-square theorem, and Pell's equations.\nThe interest of Leonhard Euler (1707\u20131783) in number theory was first spurred in 1729, when a friend of his, the amateur Christian Goldbach, pointed him towards some of Fermat's work on the subject. This has been called the \"rebirth\" of modern number theory, after Fermat's relative lack of success in getting his contemporaries' attention for the subject. He proved Fermat's assertions, including Fermat's little theorem; made initial work towards a proof that every integer is the sum of four squares; and specific cases of Fermat's Last Theorem. He wrote on the link between continued fractions and Pell's equation. He made the first steps towards analytic number theory.\nThree European contemporaries continued the work in elementary number theory. Joseph-Louis Lagrange (1736\u20131813) gave full proofs of the four-square theorem, Wilson's theorem, and developed the basic theory of Pell's equations. Adrien-Marie Legendre (1752\u20131833) stated the law of quadratic reciprocity. He also conjectured what amounts to the prime number theorem and Dirichlet's theorem on arithmetic progressions. He gave a full treatment of the equation formula_11. In his old age, he was the first to prove Fermat's Last Theorem for formula_12. Carl Friedrich Gauss (1777\u20131855) wrote \"Disquisitiones Arithmeticae\" (1801), which had an immense influence in the area of number theory and set its agenda for much of the 19th century. Gauss proved in this work the law of quadratic reciprocity and developed the theory of quadratic forms. He also introduced some basic notation to congruences and devoted a section to computational matters, including primality tests. He established a link between roots of unity and number theory. In this way, Gauss arguably made forays towards \u00c9variste Galois's work and the area algebraic number theory.\nStarting early in the nineteenth century, the following developments gradually took place:\nAlgebraic number theory may be said to start with the study of reciprocity and cyclotomy, but truly came into its own with the development of abstract algebra and early ideal theory and valuation theory; see below. A conventional starting point for analytic number theory is Dirichlet's theorem on arithmetic progressions (1837), whose proof introduced L-functions and involved some asymptotic analysis and a limiting process on a real variable. The first use of analytic ideas in number theory actually goes back to Euler (1730s), who used formal power series and non-rigorous (or implicit) limiting arguments. The use of \"complex\" analysis in number theory comes later: the work of Bernhard Riemann (1859) on the zeta function is the canonical starting point; Jacobi's four-square theorem (1839), which predates it, belongs to an initially different strand that has by now taken a leading role in analytic number theory (modular forms).\nThe American Mathematical Society awards the \"Cole Prize in Number Theory\". Moreover, number theory is one of the three mathematical subdisciplines rewarded by the \"Fermat Prize\".\nMain subdivisions.\nElementary number theory.\nElementary number theory deals with the topics in number theory by means of basic methods in arithmetic. Its primary subjects of study are divisibility, factorization, and primality, as well as congruences in modular arithmetic. Other topics in elementary number theory include Diophantine equations, continued fractions, integer partitions, and Diophantine approximations.\nArithmetic is the study of numerical operations and investigates how numbers are combined and transformed using the arithmetic operations of addition, subtraction, multiplication, division, exponentiation, extraction of roots, and logarithms. Multiplication, for instance, is an operation that combines two numbers, referred to as factors, to form a single number, termed the product, such as formula_13.\nDivisibility is a property between two nonzero integers related to division. An integer formula_14 is said to be divisible by a nonzero integer formula_15 if formula_14 is a multiple of formula_15; that is, if there exists an integer formula_18 such that formula_19. An equivalent formulation is that formula_15 divides formula_14 and is denoted by a vertical bar, which in this case is formula_22. Conversely, if this were not the case, then formula_14 would not be divided evenly by formula_15, resulting in a remainder. Euclid's division lemma asserts that formula_14 and formula_15 can generally be written as formula_27, where the remainder formula_28 accounts for the smallest positive leftover quantity. Elementary number theory studies divisibility rules in order to quickly identify if a given integer is divisible by a fixed divisor. For instance, it is known that any integer is divisible by 3 if its decimal digit sum is divisible by 3.\nA common divisor of several nonzero integers is an integer that divides all of them. The greatest common divisor (gcd) is the largest of such divisors. Two integers are said to be coprime or relatively prime to one another if their greatest common divisor, and simultaneously their only divisor, is 1. The Euclidean algorithm computes the greatest common divisor of two integers formula_29 by means of repeatedly applying the division lemma and shifting the divisor and remainder after every step. The algorithm can be extended to solve a special case of linear Diophantine equations formula_30. A Diophantine equation has several unknowns and integer coefficients. Another kind of Diophantine equation is described in the Pythagorean theorem, formula_31, whose solutions are called Pythagorean triples if they are all integers. Another kind of expression is the continued fraction, which writes a sum of an integer and a fraction whose denominator is another such sum.\nElementary number theory studies the divisibility properties of integers such as parity (even and odd numbers), prime numbers, and perfect numbers. Important number-theoric functions include the divisor-counting function, the divisor summatory function and its modifications, and Euler's totient function. A prime number is an integer greater than 1 whose only positive divisors are 1 and the prime itself. A positive integer greater than 1 that is not prime is called a composite number. Euclid's theorem demonstrates that there are infinitely many prime numbers that comprise the set {2, 3, 5, 7, 11, ...}. The sieve of Eratosthenes was devised as an efficient algorithm for identifying all primes up to a given natural number by eliminating all composite numbers.\nFactorization is a method of expressing a number as a product. Specifically in number theory, integer factorization is the decomposition of an integer into a product of integers. The process of repeatedly applying this procedure until all factors are prime is known as prime factorization. A fundamental property of primes is shown in Euclid's lemma. It is a consequence of the lemma that if a prime divides a product of integers, then that prime divides at least one of the factors in the product. The unique factorization theorem is the fundamental theorem of arithmetic that relates to prime factorization. The theorem states that every integer greater than 1 can be factorised into a product of prime numbers and that this factorisation is unique up to the order of the factors. For example, formula_32 is expressed uniquely as formula_33 or simply formula_34.\nModular arithmetic works with finite sets of integers and introduces the concepts of congruence and residue classes. A congruence of two integers formula_35 modulo formula_36 (a positive integer called the modulus) is an equivalence relation whereby formula_37 is true. Performing Euclidean division on both formula_14 and formula_36, and on formula_15 and formula_36, yields the same remainder. This written as formula_42. In a manner analogous to the 12-hour clock, the sum of 4 and 9 is equal to 13, yet congruent to 1. A residue class modulo formula_36 is a set that contains all integers congruent to a specified formula_28 modulo formula_36. For example, formula_46 contains all multiples of 6 incremented by 1. Modular arithmetic provides a range of formulas for rapidly solving congruences of very large powers. An influential theorem is Fermat's little theorem, which states that if a prime formula_47 is coprime to some integer formula_14, then formula_49 is true. Euler's theorem extends this to assert that every integer formula_36 satisfies the congruenceformula_51where Euler's totient function formula_52 counts all positive integers up to formula_36 that are coprime to formula_36. Modular arithmetic also provides formulas that are used to solve congruences with unknowns in a similar vein to equation solving in algebra, such as the Chinese remainder theorem.\nAnalytic number theory.\nAnalytic number theory, in contrast to elementary number theory, relies on complex numbers and techniques from analysis and calculus. Analytic number theory may be defined\nIt studies the distribution of primes, behavior of number-theoric functions, and irrational numbers.\nNumber theory has the reputation of being a field many of whose results can be stated to the layperson. At the same time, many of the proofs of these results are not particularly accessible, in part because the range of tools they use is, if anything, unusually broad within mathematics. The following are examples of problems in analytic number theory: the prime number theorem, the Goldbach conjecture, the twin prime conjecture, the Hardy\u2013Littlewood conjectures, the Waring problem and the Riemann hypothesis. Some of the most important tools of analytic number theory are the circle method, sieve methods and L-functions (or, rather, the study of their properties). The theory of modular forms (and, more generally, automorphic forms) also occupies an increasingly central place in the toolbox of analytic number theory.\nAnalysis is the branch of mathematics that studies the limit, defined as the value to which a sequence or function tends as the argument (or index) approaches a specific value. For example, the limit of the sequence 0.9, 0.99, 0.999, ... is 1. In the context of functions, the limit of formula_55 as formula_56 approaches infinity is 0. The complex numbers extend the real numbers with the imaginary unit formula_57 defined as the solution to formula_58. Every complex number can be expressed as formula_59, where formula_56 is called the real part and formula_61 is called the imaginary part.\nThe distribution of primes, described by the function formula_62 that counts all primes up to a given real number, is unpredictable and is a major subject of study in number theory. Elementary formulas for a partial sequence of primes, including Euler's prime-generating polynomials have been developed. However, these cease to function as the primes become too large. The prime number theorem in analytic number theory provides a formalisation of the notion that prime numbers appear less commonly as their numerical value increases. One distribution states, informally, that the function formula_63 approximates formula_64. Another distribution involves an offset logarithmic integral which converges to formula_64 more quickly.\nThe zeta function has been demonstrated to be connected to the distribution of primes. It is defined as the seriesformula_66that converges if formula_67 is greater than 1. Euler demonstrated a link involving the infinite product over all prime numbers, expressed as the identity formula_68Riemann extended the definition to a complex variable and conjectured that all nontrivial cases (formula_69) where the function returns a zero are those in which the real part of formula_70 is equal to formula_71. He established a connection between the nontrivial zeroes and the prime-counting function. In what is now recognised as the unsolved Riemann hypothesis, a solution to it would imply direct consequences for understanding the distribution of primes.\nOne may ask analytic questions about algebraic numbers, and use analytic means to answer such questions; it is thus that algebraic and analytic number theory intersect. For example, one may define prime ideals (generalizations of prime numbers in the field of algebraic numbers) and ask how many prime ideals there are up to a certain size. This question can be answered by means of an examination of Dedekind zeta functions, which are generalizations of the Riemann zeta function, a key analytic object at the roots of the subject. This is an example of a general procedure in analytic number theory: deriving information about the distribution of a sequence (here, prime ideals or prime numbers) from the analytic behavior of an appropriately constructed complex-valued function.\nElementary number theory works with \"elementary proofs\", a term that excludes the use of complex numbers but may include basic analysis. For example, the prime number theorem was first proven using complex analysis in 1896, but an elementary proof was found only in 1949 by Erd\u0151s and Selberg. The term is somewhat ambiguous. For example, proofs based on complex Tauberian theorems, such as Wiener\u2013Ikehara, are often seen as quite enlightening but not elementary despite using Fourier analysis, not complex analysis. Here as elsewhere, an \"elementary\" proof may be longer and more difficult for most readers than a more advanced proof.\nSome subjects generally considered to be part of analytic number theory (e.g., sieve theory) are better covered by the second rather than the first definition. Small sieves, for instance, use little analysis and yet still belong to analytic number theory.\nAlgebraic number theory.\nAn \"algebraic number\" is any complex number that is a solution to some polynomial equation formula_72 with rational coefficients; for example, every solution formula_56 of formula_74 is an algebraic number. Fields of algebraic numbers are also called \"algebraic number fields\", or shortly \"number fields\". Algebraic number theory studies algebraic number fields.\nIt could be argued that the simplest kind of number fields, namely quadratic fields, were already studied by Gauss, as the discussion of quadratic forms in \"Disquisitiones Arithmeticae\" can be restated in terms of ideals and\nnorms in quadratic fields. (A \"quadratic field\" consists of all\nnumbers of the form formula_75, where\nformula_14 and formula_15 are rational numbers and formula_78\nis a fixed rational number whose square root is not rational.)\nFor that matter, the eleventh-century chakravala method amounts\u2014in modern terms\u2014to an algorithm for finding the units of a real quadratic number field. However, neither Bh\u0101skara nor Gauss knew of number fields as such.\nThe grounds of the subject were set in the late nineteenth century, when \"ideal numbers\", the \"theory of ideals\" and \"valuation theory\" were introduced; these are three complementary ways of dealing with the lack of unique factorization in algebraic number fields. (For example, in the field generated by the rationals\nand formula_79, the number formula_80 can be factorised both as formula_81 and\nformula_82; all of formula_83, formula_84, formula_85 and\nformula_86\nare irreducible, and thus, in a na\u00efve sense, analogous to primes among the integers.) The initial impetus for the development of ideal numbers (by Kummer) seems to have come from the study of higher reciprocity laws, that is, generalizations of quadratic reciprocity.\nNumber fields are often studied as extensions of smaller number fields: a field \"L\" is said to be an \"extension\" of a field \"K\" if \"L\" contains \"K\".\nClassifying the possible extensions of a given number field is a difficult and partially open problem. Abelian extensions\u2014that is, extensions \"L\" of \"K\" such that the Galois group Gal(\"L\"/\"K\") of \"L\" over \"K\" is an abelian group\u2014are relatively well understood.\nTheir classification was the object of the programme of class field theory, which was initiated in the late nineteenth century (partly by Kronecker and Eisenstein) and carried out largely in 1900\u20131950.\nAn example of an active area of research in algebraic number theory is Iwasawa theory. The Langlands program, one of the main current large-scale research plans in mathematics, is sometimes described as an attempt to generalise class field theory to non-abelian extensions of number fields.\nDiophantine geometry.\nThe central problem of Diophantine geometry is to determine when a Diophantine equation has integer or rational solutions, and if it does, how many. The approach taken is to think of the solutions of an equation as a geometric object.\nFor example, an equation in two variables defines a curve in the plane. More generally, an equation or system of equations in two or more variables defines a curve, a surface, or some other such object in \"n\"-dimensional space. In Diophantine geometry, one asks whether there are any \"rational points\" (points all of whose coordinates are rationals) or\n\"integral points\" (points all of whose coordinates are integers) on the curve or surface. If there are any such points, the next step is to ask how many there are and how they are distributed. A basic question in this direction is whether there are finitely\nor infinitely many rational points on a given curve or surface.\nConsider, for instance, the Pythagorean equation formula_87. One would like to know its rational solutions, namely formula_88 such that \"x\" and \"y\" are both rational. This is the same as asking for all integer solutions\nto formula_89; any solution to the latter equation gives us a solution formula_90, formula_91 to the former. It is also the\nsame as asking for all points with rational coordinates on the curve described by formula_92 (a circle of radius 1 centered on the origin).\nThe rephrasing of questions on equations in terms of points on curves is felicitous. The finiteness or not of the number of rational or integer points on an algebraic curve (that is, rational or integer solutions to an equation formula_93, where formula_94 is a polynomial in two variables) depends crucially on the genus of the curve. A major achievement of this approach is Wiles's proof of Fermat's Last Theorem, for which other geometrical notions are just as crucial.\nThere is also the closely linked area of Diophantine approximations: given a number formula_56, determine how well it can be approximated by rational numbers. One seeks approximations that are good relative to the amount of space required to write the rational number: call formula_96 (with formula_97) a good approximation to formula_56 if formula_99, where formula_100 is large. This question is of special interest if formula_56 is an algebraic number. If formula_56 cannot be approximated well, then some equations do not have integer or rational solutions. Moreover, several concepts (especially that of height) are critical both in Diophantine geometry and in the study of Diophantine approximations. This question is also of special interest in transcendental number theory: if a number can be approximated better than any algebraic number, then it is a transcendental number. It is by this argument that \u03c0 and e have been shown to be transcendental.\nDiophantine geometry should not be confused with the geometry of numbers, which is a collection of graphical methods for answering certain questions in algebraic number theory. Arithmetic geometry is a contemporary term for the same domain covered by Diophantine geometry, particularly when one wishes to emphasize the connections to modern algebraic geometry (for example, in Faltings's theorem) rather than to techniques in Diophantine approximations.\nOther subfields.\nProbabilistic number theory starts with questions such as the following: Take an integer n at random between one and a million. How likely is it to be prime? (this is just another way of asking how many primes there are between one and a million). How many prime divisors will n have on average? What is the probability that it will have many more or many fewer divisors or prime divisors than the average?\nCombinatorics in number theory starts with questions like the following: Does a fairly \"thick\" infinite set formula_103 contain many elements in arithmetic progression: formula_14,\nformula_105? Should it be possible to write large integers as sums of elements of formula_103?There are two main questions: \"Can this be computed?\" and \"Can it be computed rapidly?\" Anyone can test whether a number is prime or, if it is not, split it into prime factors; doing so rapidly is another matter. Fast algorithms for testing primality are now known, but, in spite of much work (both theoretical and practical), no truly fast algorithm for factoring.\nApplications.\nFor a long time, number theory in general, and the study of prime numbers in particular, was seen as the canonical example of pure mathematics, with no applications outside of mathematics other than the use of prime numbered gear teeth to distribute wear evenly. In particular, number theorists such as British mathematician G. H. Hardy prided themselves on doing work that had absolutely no military significance. The number-theorist Leonard Dickson (1874\u20131954) said \"Thank God that number theory is unsullied by any application\". Such a view is no longer applicable to number theory. \nThis vision of the purity of number theory was shattered in the 1970s, when it was publicly announced that prime numbers could be used as the basis for the creation of public-key cryptography algorithms. Schemes such as RSA are based on the difficulty of factoring large composite numbers into their prime factors. These applications have led to significant study of algorithms for computing with prime numbers, and in particular of primality testing, methods for determining whether a given number is prime. Prime numbers are also used in computing for checksums, hash tables, and pseudorandom number generators.\nIn 1974, Donald Knuth said \"virtually every theorem in elementary number theory arises in a natural, motivated way in connection with the problem of making computers do high-speed numerical calculations\".\nElementary number theory is taught in discrete mathematics courses for computer scientists. It also has applications to the continuous in numerical analysis.\nNumber theory has now several modern applications spanning diverse areas such as:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\nTwo of the most popular introductions to the subject are:\nHardy and Wright's book is a comprehensive classic, though its clarity sometimes suffers due to the authors' insistence on elementary methods (Apostol 1981).\nVinogradov's main attraction consists in its set of problems, which quickly lead to Vinogradov's own research interests; the text itself is very basic and close to minimal. Other popular first introductions are:\nPopular choices for a second textbook include:"}
{"id": "21528", "revid": "256455", "url": "https://en.wikipedia.org/wiki?curid=21528", "title": "Nintendo Gameboy", "text": ""}
{"id": "21530", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=21530", "title": "Nitroglycerin", "text": "Chemical compound\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nNitroglycerin (NG) (alternative spelling nitroglycerine), also known as trinitroglycerol (TNG), nitro, glyceryl trinitrate (GTN), or 1,2,3-trinitroxypropane, is a dense, colorless or pale yellow, oily, explosive liquid most commonly produced by nitrating glycerol with white fuming nitric acid under conditions appropriate to the formation of the nitric acid ester. Chemically, the substance is a nitrate ester rather than a nitro compound, but the traditional name is retained. Discovered in 1846 by Ascanio Sobrero, nitroglycerin has been used as an active ingredient in the manufacture of explosives, namely dynamite, and as such it is employed in the construction, demolition, and mining industries. It is combined with nitrocellulose to form double-based smokeless powder, used as a propellant in artillery and firearms since the 1880s. \nAs is the case for many other explosives, nitroglycerin becomes more and more prone to exploding (i.e., spontaneous decomposition) as the temperature is increased. Upon exposure to heat above 218 \u00b0C at sea-level atmospheric pressure, nitroglycerin becomes extremely unstable and tends to explode. When placed in vacuum, it has an autoignition temperature of 270 \u00b0C instead. With a melting point of 12.8 \u00b0C, the chemical is almost always encountered as a thick and viscous fluid, changing to a crystalline solid when frozen. Although the pure compound itself is colorless, in practice the presence of nitric oxide impurities left over during production tends to give it a slight yellowish tint. \nDue to its high boiling point and consequently low vapor pressure (0.00026 mmHg at 20 \u00b0C), pure nitroglycerin has practically no odor at room temperature, with a sweet and burning taste when ingested. Unintentional detonation may ensue when dropped, shaken, lit on fire, rapidly heated, exposed to sunlight and ozone, subjected to sparks and electrical discharges, or roughly handled. Its sensitivity to exploding is responsible for numerous devastating industrial accidents throughout its history. The chemical's characteristic reactivity may be reduced through the addition of desensitizing agents, which makes it less likely to explode. Clay (diatomaceous earth) is an example of such an agent, forming dynamite, a much more easily handled composition. The addition of other desensitizing agents gives birth to the various formulations of dynamite. \nNitroglycerin has been used for over 130 years as a medication as a potent vasodilator (causing dilation of the vascular system) to treat heart conditions, such as angina pectoris and chronic heart failure. Though it was previously known that these beneficial effects are due to nitroglycerin being converted to nitric oxide, a potent vasodilator, the enzyme for this conversion was only discovered to be mitochondrial aldehyde dehydrogenase (ALDH2) in 2002. Nitroglycerin is available in sublingual tablets, sprays, ointments, and patches.\nHistory.\nNitroglycerin was the first practical explosive produced that was stronger than black powder. It was synthesized by the Italian chemist Ascanio Sobrero in 1846, working under Th\u00e9ophile-Jules Pelouze at the University of Turin. Sobrero initially called his discovery \"pyroglycerin\" and warned vigorously against its use as an explosive.\nNitroglycerin was adopted as a commercially useful explosive by Alfred Nobel, who experimented with safer ways to handle the dangerous compound after his younger brother, Emil Oskar Nobel, and several factory workers were killed in an explosion at the Nobels' armaments factory in 1864 in Heleneborg, Sweden.\nOne year later, Nobel founded Alfred Nobel and Company in Germany and built an isolated factory in the Kr\u00fcmmel hills of Geesthacht near Hamburg. This business exported a liquid combination of nitroglycerin and gunpowder called \"Blasting Oil\", but this was extremely unstable and difficult to handle, as evidenced in numerous catastrophes. The buildings of the Kr\u00fcmmel factory were destroyed twice.\nIn April 1866, several crates of nitroglycerin were shipped to California, three of which were destined for the Central Pacific Railroad, which planned to experiment with it as a blasting explosive to expedite the construction of the Summit Tunnel through the Sierra Nevada Mountains. One of the remaining crates exploded, destroying a Wells Fargo company office in San Francisco and killing 15 people. This led to a complete ban on the transportation of liquid nitroglycerin in California. The on-site manufacture of nitroglycerin was thus required for the remaining hard-rock drilling and blasting required for the completion of the First transcontinental railroad in North America.\nOn Christmas Day 1867, an attempt to dispose of nine canisters of Blasting Oil that had been illegally stored at the White Swan Inn in the centre of Newcastle upon Tyne resulted in an explosion on the Town Moor that killed eight people. \nIn June 1869, two one-ton wagons loaded with nitroglycerin, then known locally as Powder-Oil, exploded during transport while passing through the village of Cwm-y-glo in North Wales. The explosion led to the loss of six lives, many injuries, and much damage to the village. Little trace was found of the two horses. The UK Government was so alarmed at the damage caused and what could have happened in a city location (these two tons were part of a larger load coming from Germany via Liverpool) that they soon passed the Nitro-Glycerine Act of 1869. Liquid nitroglycerin was widely banned elsewhere, as well, and these legal restrictions led to Alfred Nobel and his company developing dynamite in 1867. This was made by mixing nitroglycerin with diatomaceous earth ( in German) found in the Kr\u00fcmmel hills. Similar mixtures, such as \"dualine\" (1867), \"lithofracteur\" (1869), and \"gelignite\" (1875), were formed by mixing nitroglycerin with other inert absorbents, and many combinations were tried by other companies in attempts to get around Nobel's tightly held patents for dynamite.\nDynamite mixtures containing nitrocellulose, which increases the viscosity of the mix, are commonly known as \"gelatins\".\nFollowing the discovery that amyl nitrite helped alleviate chest pain, the physician William Murrell experimented with the use of nitroglycerin to alleviate angina pectoris and to reduce the blood pressure. He began treating his patients with small diluted doses of nitroglycerin in 1878, and this treatment was soon adopted into widespread use after Murrell published his results in \"The Lancet\" in 1879. A few months before he died in 1896, Alfred Nobel was prescribed nitroglycerin for this heart condition, writing to a friend: \"Isn't it the irony of fate that I have been prescribed nitro-glycerin, to be taken internally! They call it Trinitrin, so as not to scare the chemist and the public.\" The medical establishment also used the name \"glyceryl trinitrate\" for the same reason.\nWartime production rates.\nLarge quantities of nitroglycerin were manufactured during World War I and World War II for use as military propellants and in military engineering work. During World War I, HM Factory, Gretna, the largest propellant factory in the United Kingdom, produced about 800 tonnes of cordite RDB per week. This amount required at least 336 tonnes of nitroglycerin per week (assuming no losses in production). The Royal Navy had its own factory at the Royal Navy Cordite Factory, Holton Heath, in Dorset, England. A large cordite factory was also built in Canada during World War I. The Canadian Explosives Limited cordite factory at Nobel, Ontario was designed to produce of cordite per month, requiring about 286 tonnes of nitroglycerin per month.\nInstability and desensitization.\nIn its undiluted form, nitroglycerin is a contact explosive, meaning physical shock causes it to explode. If it has not been adequately purified during manufacture, it can degrade over time to even more unstable forms. This makes nitroglycerin highly dangerous to transport or use. In its undiluted form, it is one of the world's most powerful explosives, comparable to the more recently developed RDX and PETN.\nEarly in its history, liquid nitroglycerin was found to be \"desensitized\" by freezing it at a temperature below depending on its purity. Its sensitivity to shock while frozen is somewhat unpredictable: \"It is more insensitive to the shock from a fulminate cap or a rifle ball when in that condition but on the other hand it appears to be more liable to explode on breaking, crushing, tamping, etc.\" Frozen nitroglycerin is much less energetic than liquid, and so must be thawed before use. Thawing it out can be extremely sensitizing, especially if impurities are present or the warming is too rapid. Ethylene glycol dinitrate or another polynitrate may be added to lower the melting point and thereby avoid the necessity of thawing frozen explosive.\nChemically \"desensitizing\" nitroglycerin is possible to a point where it can be considered about as \"safe\" as modern high explosives, such as by the addition of ethanol, acetone, or dinitrotoluene. The nitroglycerin may have to be extracted from the desensitizer chemical to restore its effectiveness before use, for example, by adding water to draw off ethanol used as a desensitizer.\nDetonation.\nWhen nitroglycerin explodes, the products after cooling are given by:\n4 \u2192 12 + 10 + 6 + \nThe heat released can be calculated from the heats of formation. Using \u2212371\u00a0kJ/mol for the heat of formation of condensed phase nitroglycerin gives 1414\u00a0kJ/mol released if forming water vapor, and 1524 if forming liquid water.\nThe detonation velocity of nitroglycerin is 7820 meters per second, which is about 113% the speed of TNT. Accordingly, nitroglycerin is considered to be a high-brisance explosive, which is to say, it has excellent shattering ability. The heat liberated during detonation raises the temperature of the gaseous byproducts to about . With a standard enthalpy of explosive decomposition of \u22121414\u00a0kJ/mol and a molecular weight of 227.0865\u00a0g/mol, nitroglycerin has a specific explosive energy density of 1.488\u00a0kilocalories per gram, or 6.23\u00a0kJ/g, making nitroglycerin 49% more energetic on a mass basis than the standard definitional value assigned to TNT (precisely 1\u00a0kcal/g).\nManufacturing.\nNitroglycerin can be produced by acid-catalyzed nitration of glycerol (glycerin).\nThe industrial manufacturing process often reacts glycerol with a nearly 1:1 mixture of concentrated sulfuric acid and concentrated nitric acid. This can be produced by mixing white fuming nitric acid\u2014a quite expensive pure nitric acid in which the oxides of nitrogen have been removed, as opposed to red fuming nitric acid, which contains nitrogen oxides\u2014and concentrated sulfuric acid. More often, this mixture is attained by the cheaper method of mixing fuming sulfuric acid, also known as oleum\u2014sulfuric acid containing excess sulfur trioxide\u2014and azeotropic nitric acid (consisting of about 70% nitric acid, with the rest being water).\nThe sulfuric acid produces protonated nitric acid species, which are attacked by glycerol's nucleophilic oxygen atoms. The nitro group is thus added as an ester C\u2212O\u2212NO2, and water is produced. This is different from an electrophilic aromatic substitution reaction in which nitronium ions are the electrophile.\nThe addition of glycerol results in an exothermic reaction (i.e., heat is produced), as usual for mixed-acid nitrations. If the mixture becomes too hot, it results in a runaway reaction, a state of accelerated nitration accompanied by the destructive oxidation of organic materials by the hot nitric acid and the release of poisonous nitrogen dioxide gas at high risk of an explosion. Thus, the glycerin mixture is added slowly to the reaction vessel containing the mixed acid (not acid to glycerin). The nitrator is cooled with cold water or some other coolant mixture and maintained throughout the glycerin addition at about , hot enough for esterification to occur at a fast rate but cold enough to avoid runaway reaction. The nitrator vessel, often constructed of iron or lead and generally stirred with compressed air, has an emergency trap door at its base, which hangs over a large pool of very cold water and into which the whole reaction mixture (called the charge) can be dumped to prevent an explosion, a process referred to as drowning. If the temperature of the charge exceeds about (actual value varying by country) or brown fumes are seen in the nitrator's vent, then it is immediately drowned.\nUse as an explosive and a propellant.\nNitroglycerin is an oily liquid that explodes when subjected to heat, shock, or flame. The main use of nitroglycerin, by tonnage, is in explosives such as dynamite and in propellants as an ingredient. However, its sensitivity has limited the usefulness of nitroglycerin as a military explosive; less sensitive explosives such as TNT, RDX, and HMX have largely replaced it in munitions.\nAlfred Nobel developed the use of nitroglycerin as a blasting explosive by mixing nitroglycerin with inert absorbents, particularly \"\", or diatomaceous earth. He named this explosive dynamite and patented it in 1867. It was supplied ready for use in the form of sticks, individually wrapped in greased waterproof paper. Dynamite and similar explosives were widely adopted for civil engineering tasks, such as in drilling highway and railroad tunnels, for mining, for clearing farmland of stumps, in quarrying, and in demolition work. Likewise, military engineers have used dynamite for construction and demolition work.\nNitroglycerin has been used in conjunction with hydraulic fracturing, a process used to recover oil and gas from shale formations. The technique involves displacing and detonating nitroglycerin in natural or hydraulically induced fracture systems, or displacing and detonating nitroglycerin in hydraulically induced fractures followed by wellbore shots using pelletized TNT.\nNitroglycerin has an advantage over some other high explosives in that, on detonation, it produces practically no visible smoke. Therefore, it is useful as an ingredient in the formulation of various kinds of smokeless powder.\nAlfred Nobel then developed ballistite by combining nitroglycerin and guncotton. He patented it in 1887. Ballistite was adopted by several European governments as a military propellant. Italy was the first to adopt it. The British government and the Commonwealth governments adopted cordite instead, which had been developed by Sir Frederick Abel and Sir James Dewar of the United Kingdom in 1889. The original Cordite Mk\u00a0I consisted of 58% nitroglycerin, 37% guncotton, and 5.0% petroleum jelly. Ballistite and cordite were both manufactured in the form of \"cords\".\nSmokeless powders were originally developed using nitrocellulose as the sole explosive ingredient. Therefore, they were known as single-base propellants. A range of smokeless powders that contain both nitrocellulose and nitroglycerin, known as double-base propellants, was also developed. Smokeless powders were originally supplied only for military use, but they were also soon developed for civilian use and were quickly adopted for sports. Some are known as sporting powders. Triple-base propellants contain nitrocellulose, nitroglycerin, and nitroguanidine, but are reserved mainly for extremely high-caliber ammunition rounds such as those used in tank cannons and naval artillery. Blasting gelatin, also known as gelignite, was invented by Nobel in 1875, using nitroglycerin, wood pulp, and sodium or potassium nitrate. This was an early, low-cost, flexible explosive.\nMedical use.\nNitroglycerin belongs to a group of drugs called nitrates, which includes many other nitrates like isosorbide dinitrate (Isordil) and isosorbide mononitrate (Imdur, Ismo, Monoket). These agents all exert their effect by being converted to nitric oxide in the body by mitochondrial aldehyde dehydrogenase (ALDH2), and nitric oxide is a potent natural vasodilator.\nIn medicine, nitroglycerin is probably most commonly prescribed for angina pectoris, a painful symptom of ischemic heart disease caused by inadequate flow of blood and oxygen to the heart, and as a potent antihypertensive agent. Nitroglycerin corrects the imbalance between the flow of oxygen and blood to the heart and the heart's energy demand. There are many formulations on the market at different doses. At low doses, nitroglycerin dilates veins more than arteries, thereby reducing preload (volume of blood in the heart after filling); this is thought to be its primary mechanism of action. By decreasing preload, the heart has less blood to pump, which decreases oxygen requirement since the heart does not have to work as hard. Additionally, having a smaller preload reduces the ventricular transmural pressure (pressure exerted on the walls of the heart), which decreases the compression of heart arteries to allow more blood to flow through the heart. At higher doses, it also dilates arteries, thereby reducing afterload (decreasing the pressure against which the heart must pump). An improved ratio of myocardial oxygen demand to supply leads to the following therapeutic effects during episodes of angina pectoris: subsiding of chest pain, decrease of blood pressure, increase of heart rate, and orthostatic hypotension. Patients experiencing angina when doing certain physical activities can often prevent symptoms by taking nitroglycerin 5 to 10 minutes before the activity. Overdoses may generate methemoglobinemia.\nNitroglycerin is available in tablets, ointment, solution for intravenous use, transdermal patches, or sprays administered sublingually. Some forms of nitroglycerin last much longer in the body than others. Nitroglycerin, as well as the onset and duration of action of each form, is different. The sublingual or tablet spray of nitroglycerin has a two-minute onset and a twenty-five-minute duration of action. The oral formulation of nitroglycerin has a thirty-five-minute onset and a duration of action of 4\u20138 hours. The transdermal patch has an onset of thirty minutes and a duration of action of ten to twelve hours. Continuous exposure to nitrates has been shown to cause the body to stop responding normally to this medicine. Experts recommend that the patches be removed at night, allowing the body a few hours to restore its responsiveness to nitrates. Shorter-acting preparations of nitroglycerin can be used several times a day with less risk of developing tolerance. Nitroglycerin was first used by William Murrell to treat angina attacks in 1878, with the discovery published that same year.\nIndustrial exposure.\nInfrequent exposure to high doses of nitroglycerin can cause severe headaches known as \"NG head\" or \"bang head\". These headaches can be severe enough to incapacitate some people; however, humans develop a tolerance to and dependence on nitroglycerin after long-term exposure. Although rare, withdrawal can be fatal; symptoms include chest pain and other heart problems. These symptoms may be relieved with re-exposure to nitroglycerin or other suitable organic nitrates.\nFor workers in nitroglycerin (NTG) manufacturing facilities, the effects of withdrawal sometimes include \"Sunday heart attacks\" in those experiencing regular nitroglycerin exposure in the workplace, leading to the development of tolerance for the venodilating effects. Over the weekend, the workers lost their tolerance, and when they were re-exposed on Monday, the drastic vasodilation produced a fast heart rate, dizziness, and a headache. This is referred to as \"Monday disease\".\nPeople can be exposed to nitroglycerin in the workplace by breathing it in, skin absorption, swallowing it, or eye contact. The Occupational Safety and Health Administration has set the legal limit (permissible exposure limit) for nitroglycerin exposure in the workplace as 0.2\u00a0ppm (2\u00a0mg/m3) skin exposure over an 8-hour workday. The National Institute for Occupational Safety and Health has set a recommended exposure limit of 0.1\u00a0mg/m3 skin exposure over an 8-hour workday. At levels of 75\u00a0mg/m3, nitroglycerin is immediately dangerous to life and health.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21533", "revid": "9977423", "url": "https://en.wikipedia.org/wiki?curid=21533", "title": "Navy", "text": "Military branch involved in naval warfare\nA navy, naval force, military maritime fleet, war navy, or maritime force is the branch of a state's armed forces principally designated for naval and amphibious warfare; namely, lake-borne, riverine, littoral, or ocean-borne combat operations and related functions. It includes anything conducted by surface ships, amphibious ships, submarines, and seaborne aviation, as well as ancillary support, communications, training, and other fields.\nThe strategic offensive role of a navy is projection of force into areas beyond a country's shores (for example, to protect sea-lanes, deter or confront piracy, ferry troops, or attack other navies, ports, or shore installations). The strategic defensive purpose of a navy is to frustrate seaborne projection-of-force by enemies. The strategic task of a navy also may incorporate nuclear deterrence by use of submarine-launched ballistic missiles. Naval operations can be broadly divided between riverine and littoral applications (brown-water navy), open-ocean applications (blue-water navy), and something in between (green-water navy), although these distinctions are more about strategic scope than tactical or operational division.\nEtymology and meanings.\nFirst attested in English in the early 14th century, the word \"navy\" came via Old French , \"fleet of ships\", from the Latin , \"a vessel, a ship, bark, boat\", from , \"ship\". The word \"naval\" came from Latin , \"pertaining to ship\"; cf. Greek (), \"ship\", (), \"seaman, sailor\". The earliest attested form of the word is in the Mycenaean Greek compound word , \"na-u-do-mo\" (*), \"shipbuilders\", written in Linear B syllabic script.\nThe word formerly denoted fleets of both commercial and military nature. In modern usage \"navy\" used alone always denotes a military fleet, although the term \"merchant navy\" for a commercial fleet still incorporates the non-military word sense. This overlap in word senses between commercial and military fleets grew out of the inherently dual-use nature of fleets; centuries ago, nationality was a trait that unified a fleet across both civilian and military uses. Although nationality of commercial vessels has little importance in peacetime trade other than for tax avoidance, it can have greater meaning during wartime, when supply chains become matters of patriotic attack and defense, and when in some cases private vessels are even temporarily converted to military vessels. The latter was especially important, and common, before 20th-century military technology existed, when merely adding artillery and naval infantry to any sailing vessel could render it fully as martial as any military-owned vessel. Such privateering has been rendered obsolete in blue-water strategy since modern missile and aircraft systems grew to leapfrog over artillery and infantry in many respects; but privateering nevertheless remains potentially relevant in littoral warfare of a limited and asymmetric nature.\nHistory.\nNaval warfare developed when humans first fought from water-borne vessels. Before the introduction of the cannon and ships with enough capacity to carry them, navy warfare primarily involved ramming and boarding actions. In the time of ancient Greece and the Roman Empire, naval warfare centered on long, narrow vessels powered by banks of oarsmen (such as triremes and quinqueremes) designed to ram and sink enemy vessels or come alongside the enemy vessel so its occupants could be attacked hand-to-hand. Naval warfare continued in this vein through the Middle Ages until the cannon became commonplace and capable of being reloaded quickly enough to be reused in the same battle. \nIn ancient China, large naval battles were known since the Qin dynasty (\"also see\" Battle of Red Cliffs, 208), employing the war junk during the Han dynasty. However, China's first official standing navy was not established until the Southern Song dynasty in the 12th century, a time when gunpowder was a revolutionary new application to warfare. The Chola Dynasty in Southern India had a navy composed of trade ships transporting armies overseas. The Chola Navy reached its peak under Rajendra I, and was most notably used in invasions of Sri Lanka and Southeast Asia.\nNusantaran thalassocracies made extensive use of naval power and technologies. This enabled the seafaring local people (either Malays of Srivijaya or Javanese of Mataram) to attack as far as the coast of Tanzania and Mozambique with 1000 boats and attempted to take the citadel of Qanbaloh, about 7,000\u00a0km to their West, in 945\u2013946 AD. In 1350 AD Majapahit launched its largest military expedition, the invasion of Pasai, with 400 large jong and innumerable smaller vessels. The second largest military expedition, invasion of Singapura in 1398, Majapahit deployed 300 jong with no less than 200,000 men. The average jong used by Majapahit would be about 76.18\u201379.81 m LOA, carrying 600\u2013700 men, with 1200\u20131400 tons deadweight.\nThe mass and deck space required to carry a large number of cannon made oar-based propulsion impossible, and ships came to rely primarily on sails. Warships were designed to carry increasing numbers of cannon and naval tactics evolved to bring a ship's firepower to bear in a broadside, with ships-of-the-line arranged in a line of battle.\nThe development of large capacity, sail-powered ships carrying cannon led to a rapid expansion of European navies, especially the Spanish and Portuguese navies that dominated in the 16th and early 17th centuries, and helped propel the Age of Discovery and colonialism. The repulsion of the Spanish Armada (1588) by the English fleet revolutionized naval warfare by the success of a guns-only strategy and caused a major overhaul of the Spanish Navy, partly along English lines, which resulted in even greater dominance by the Spanish. From the beginning of the 17th century the Dutch cannibalized the Portuguese Empire in the East and, with the immense wealth gained, challenged Spanish hegemony at sea. From the 1620s, Dutch raiders seriously troubled Spanish shipping and, after a number of battles that went both ways, the Dutch Navy finally broke the long dominance of the Spanish Navy in the Battle of the Downs (1639).\nEngland emerged as a major naval power in the mid-17th century during the First Anglo-Dutch War. The Second and Third Anglo-Dutch Wars confirmed the Dutch Republic's mastery of the seas during the Dutch Golden Age, financed by the expansion of the Dutch colonial empire. The French Navy won some important victories near the end of the 17th century but a focus upon land forces led to the French Navy's relative neglect, which allowed the Royal Navy to emerge with an ever-growing advantage in size and quality, especially in tactics and experience, from 1695. As a response to growing naval influence of the navies of Portuguese, the warrior king of the Marathas, Shivaji laid the foundation of the Maratha navy in 1654.\nThroughout the 18th century the Royal Navy gradually gained ascendancy over the French Navy, with victories in the War of the Spanish Succession (1701\u20131714), inconclusive battles in the War of the Austrian Succession (1740\u20131748), victories in the Seven Years' War (1754\u20131763), a partial reversal during the American War of Independence (1775\u20131783), and consolidation into uncontested supremacy during the 19th century from the Battle of Trafalgar in 1805. These conflicts saw the development and refinement of tactics that came to be called the line of battle.\nThe next stage in the evolution of naval warfare was the introduction of metal plating along the hull sides. The increased mass required steam-powered engines, resulting in an arms race between armor and weapon thickness and firepower. The first armored vessels, the French and British , made wooden vessels obsolete. Another significant improvement came with the invention of the rotating turrets, which allowed the guns to be aimed independently of ship movement. The battle between and during the American Civil War (1861\u20131865) is often cited as the beginning of this age of maritime conflict. The Russian Navy was considered the third strongest in the world on the eve of the Russo-Japanese War, which turned to be a catastrophe for the Russian military in general and the Russian Navy in particular. Although neither party lacked courage, the Russians were defeated by the Japanese in the Battle of Port Arthur, which was the first time in warfare that mines were used for offensive purposes. The warships of the Baltic Fleet sent to the Far East were lost in the Battle of Tsushima. A further step change in naval firepower occurred when the United Kingdom launched in 1906, but naval tactics still emphasized the line of battle.\nThe first practical military submarines were developed in the late 19th century and by the end of World War I had proven to be a powerful arm of naval warfare. During World War II, Nazi Germany's submarine fleet of U-boats attempted to starve the United Kingdom into submission and inflicted tremendous losses on U.S. coastal shipping. The , a sister ship of , was almost put out of action by miniature submarines known as X-Craft. The X-Craft severely damaged her and kept her in port for some months.\nA major paradigm shift in naval warfare occurred with the introduction of the aircraft carrier. First at Taranto in 1940 and then at Pearl Harbor in 1941, the carrier demonstrated its ability to strike decisively at enemy ships out of sight and range of surface vessels. The Battle of Leyte Gulf (1944) was arguably the largest naval battle in history; it was also the last battle in which battleships played a significant role. By the end of World War II, the carrier had become the dominant force of naval warfare.\nWorld War II also saw the United States become by far the largest naval power in the world. In the late 20th and early 21st centuries, the United States Navy possessed over 70% of the world's total numbers and total tonnage of naval vessels of 1,000\u00a0tons or greater. Throughout the rest of the 20th century, the United States Navy would maintain a tonnage greater than that of the next 17 largest navies combined. During the Cold War, the Soviet Navy became a significant armed force, with large numbers of large, heavily armed ballistic missile submarines and extensive use of heavy, long-ranged antisurface missiles to counter the numerous United States carrier battle groups. Only two countries, the United States and France, presently operate CATOBAR carriers of any size, while Russia, China and India operate sizeable STOBAR carriers (although all three are originally of Soviet design). The United Kingdom is also operating two carriers, which are the largest STOVL vessels in service, and India is currently building one aircraft carrier, , and considering another. France is also looking at a new carrier, probably using a CATOBAR system and possibly based on the British \"Queen Elizabeth\" design.\nOperations.\nA navy typically operates from one or more naval bases. The base is a port that is specialized in naval operations, and often includes housing, a munitions depot, docks for the vessels, and various repair facilities. During times of war temporary bases may be constructed in closer proximity to strategic locations, as it is advantageous in terms of patrols and station-keeping. States with historically strong naval forces have found it advantageous to obtain basing rights in other countries in areas of strategic interest.\nNavy ships can operate independently or with a group, which may be a small squadron of comparable ships, or a larger naval fleet of various specialized ships. The commander of a fleet travels in the flagship, which is usually the most powerful vessel in the group. Before radio was invented, commands from the flagship were communicated by means of flags. At night signal lamps could be used for a similar purpose. Later these were replaced by the radio transmitter, or the flashing light when radio silence was needed.\nA \"blue water navy\" is designed to operate far from the coastal waters of its home nation. These are ships capable of maintaining station for long periods of time in deep ocean, and will have a long logistical tail for their support. Many are also nuclear powered to save having to refuel. By contrast a \"brown water navy\" operates in the coastal periphery and along inland waterways, where larger ocean-going naval vessels can not readily enter. Regional powers may maintain a \"green water navy\" as a means of localized force projection. Blue water fleets may require specialized vessels, such as minesweepers, when operating in the littoral regions along the coast.\nTraditions.\nA basic tradition is that all ships commissioned in a navy are referred to as ships rather than vessels, with the exception of destroyers and submarines, which are known as boats. The prefix on a ship's name indicates that it is a commissioned ship.\nAn important tradition on board naval vessels of some nations has been the ship's bell. This was historically used to mark the passage of time, as warning devices in heavy fog, and for alarms and ceremonies.\nThe ship's captain, and more senior officers are \"piped\" aboard the ship using a Boatswain's call.\nIn the United States, the First Navy Jack is a flag that has the words, \"Don't Tread on Me\" on the flag.\nBy English tradition, ships have been referred to as a \"she\". However, it was long considered bad luck to permit women to sail on board naval vessels. To do so would invite a terrible storm that would wreck the ship. The only women that were welcomed on board were figureheads mounted on the prow of the ship.\nFiring a cannon salute partially disarms the ship, so firing a cannon for no combat reason showed respect and trust. As the tradition evolved, the number of cannons fired became an indication of the rank of the official being saluted.\nNaval organization.\nShips.\nHistorically, navy ships were primarily intended for warfare. They were designed to withstand damage and to inflict the same, but only carried munitions and supplies for the voyage (rather than merchant cargo). Often, other ships that were not built specifically for warfare, such as the galleon or the armed merchant ships in World War II, did carry armaments. In more recent times, navy ships have become more specialized and have included supply ships, troop transports, repair ships, oil tankers and other logistics support ships as well as combat ships.\nModern navy combat ships are generally divided into seven main categories: aircraft carriers, cruisers, destroyers, frigates, corvettes, submarines, and amphibious assault ships. There are also support and auxiliary ships, including the oiler, minesweeper, patrol boat, hydrographic and oceanographic survey ship and tender. During the age of sail, the ship categories were divided into the ship of the line, frigate, and sloop-of-war.\nNaval ship names are typically prefixed by an abbreviation indicating the national navy in which they serve. For a list of the prefixes used with ship names (HMS, USS, L\u00c9, etc.) see ship prefix.\nToday's warships are significantly faster than in years past, thanks to much improved propulsion systems. Also, the efficiency of the engines has improved, in terms of fuel, and of how many sailors it takes to operate them. In World War II, ships needed to refuel very often. However, today ships can go on very long journeys without refueling. Also, in World War II, the engine room needed about a dozen sailors to work the many engines, however, today, only about four or five are needed (depending on the class of the ship). Today, naval strike groups on longer missions are always followed by a range of support and replenishment ships supplying them with anything from fuel and munitions, to medical treatment and postal services. This allows strike groups and combat ships to remain at sea for several months at a time.\nBoats.\nThe term \"boat\" refers to small craft limited in their use by size and usually not capable of making lengthy independent voyages at sea. The old navy adage to differentiate between ships and boats is that boats are capable of being carried by ships. (Submarines by this rule are ships rather than boats, but are customarily referred to as boats reflecting their previous smaller size.)\nNavies use many types of boat, ranging from dinghies to landing craft. They are powered by either diesel engines, out-board gasoline engines, or waterjets. Most boats are built of aluminum, fiberglass, or steel. Rigid-hulled inflatable boats are also used.\nPatrol boats are used for patrols of coastal areas, lakes and large rivers.\nLanding craft are designed to carry troops, vehicles, or cargo from ship to shore under combat conditions, to unload, to withdraw from the beach, and to return to the ship. They are rugged, with powerful engines, and usually armed. There are many types in today's navies including hovercraft. They will typically have a power-operated bow ramp, a cargo well and after structures that house engine rooms, pilot houses, and stowage compartments. These boats are sometimes carried by larger ships.\nSpecial operations craft are high-speed craft used for insertion and extraction of special forces personnel and some may be transportable (and deployed) by air.\nBoats used in non-combat roles include lifeboats, mail boats, line handling boats, buoy boats, aircraft rescue boats, torpedo retrievers, explosive ordnance disposal craft, utility boats, dive boats, targets, and work boats. Boats are also used for survey work, tending divers, and minesweeping operations. Boats for carrying cargo and personnel are sometimes known as launches, gigs, barges or shore party boats.\nUnits.\nNaval forces are typically arranged into units based on the number of ships included, a single ship being the smallest operational unit. Ships may be combined into squadrons or flotillas, which may be formed into fleets. The largest unit size may be the whole Navy or Admiralty.\nA task force can be assembled using ships from different fleets for an operational task.\nPersonnel.\nDespite their acceptance in many areas of naval service, female sailors were not permitted to serve on board U.S. submarines until the U.S. Navy lifted the ban in April 2010. The major reasons historically cited by the U.S. Navy were the extended duty tours and close conditions which afford almost no privacy. The United Kingdom's Royal Navy has had similar restrictions. Australia, Canada, Norway, and Spain previously opened submarine service to women sailors.\nRanks.\nA navy will typically have two sets of ranks, one for enlisted personnel and one for officers.\nTypical ranks for commissioned officers include the following, in ascending order (Commonwealth ranks are listed first on each line; USA ranks are listed second in those instances where they differ from Commonwealth ranks):\n\"Flag officers\" include any rank that includes the word \"admiral\" (or commodore in services other than the US Navy), and are generally in command of a battle group, strike group or similar flotilla of ships, rather than a single ship or aspect of a ship. However, commodores can also be temporary or honorary positions. For example, during World War II, a Navy captain was assigned duty as a convoy commodore, which meant that he was still a captain, but in charge of all the merchant vessels in the convoy.\nThe most senior rank employed by a navy will tend to vary depending on the size of a navy and whether it is wartime or peacetime, for example, few people have ever held the rank of Fleet Admiral in the U.S. Navy, the chief of the Royal Australian Navy holds the rank of Vice Admiral, and the chief of the Irish Naval Service holds the rank of Commodore.\nNaval infantry.\nNaval infantry, commonly known as marines, are a category of infantry that form part of a state's naval forces and perform roles on land and at sea, including amphibious operations, as well as other, naval roles. They also perform other tasks, including land warfare, separate from naval operations.\nDuring the era of the Roman Empire, naval forces included marine legionaries for maritime boarding actions. These were troops primarily trained in land warfare, and did not need to be skilled at handling a ship. Much later during the age of sail, a component of marines served a similar role, being ship-borne soldiers who were used either during boarding actions, as sharp-shooters, or in raids along shorelines.\nThe Spanish \"Infanter\u00eda de Marina\" was formed in 1537, making it the oldest, current marine force in the world. The British Royal Marines combine being both a ship-based force and also being specially trained in commando frogman-style operations and tactics, operating in some cases separately from the rest of the Royal Navy. The Royal Marines also have their own special forces unit.\nIn the majority of countries, the marine force is an integral part of the navy but there are variations such as the French Troupes de marine, which is actually part of the French Army. The United States Marine Corps is a separate armed service within the United States Department of the Navy, with its own leadership structure.\nNaval aviation.\nNaval aviation is the application of military air power by navies, whether from warships that embark aircraft, or land bases.\nIn World War I, several navies used floatplanes and flying boats \u2013 mainly for scouting. By World War II, aircraft carriers could carry bomber aircraft capable of attacking naval and land targets, as well as fighter aircraft for defence. Since World War II helicopters have been embarked on smaller ships in roles such as anti-submarine warfare and transport. Some navies have also operated land-based aircraft in roles such as maritime patrol and training.\nNaval aviation forces primarily perform naval roles at sea. However, they are also used in a variety of other roles.\nNotes and references.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21535", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=21535", "title": "Nature journal", "text": ""}
{"id": "21538", "revid": "1311860404", "url": "https://en.wikipedia.org/wiki?curid=21538", "title": "Normed vector space", "text": "Vector space on which a distance is defined\nIn mathematics, a normed vector space or normed space is a vector space, typically over the real or complex numbers, on which a norm is defined. A norm is a generalization of the intuitive notion of \"length\" in the physical world. If formula_1 is a vector space over formula_2, where formula_2 is a field equal to formula_4 or to formula_5, then a norm on formula_1 is a map formula_7, typically denoted by formula_8, satisfying the following four axioms:\nIf formula_1 is a real or complex vector space as above, and formula_21 is a norm on formula_1, then the ordered pair formula_23 is called a normed vector space. If it is clear from context which norm is intended, then it is common to denote the normed vector space simply by formula_1.\nA norm induces a distance, called its (norm) induced metric, by the formula\nformula_25\nwhich makes any normed vector space into a metric space and a topological vector space. If this metric space is complete then the normed space is a Banach space. Every normed vector space can be \"uniquely extended\" to a Banach space, which makes normed spaces intimately related to Banach spaces. Every Banach space is a normed space but converse is not true. For example, the set of the finite sequences of real numbers can be normed with the Euclidean norm, but it is not complete for this norm. \nAn inner product space is a normed vector space whose norm is the square root of the inner product of a vector and itself. The Euclidean norm of a Euclidean vector space is a special case that allows defining Euclidean distance by the formula\nformula_26\nThe study of normed spaces and Banach spaces is a fundamental part of functional analysis, a major subfield of mathematics.\nDefinition.\nA normed vector space is a vector space equipped with a norm. A &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;seminormed vector space is a vector space equipped with a seminorm.\nA useful variation of the triangle inequality is\nformula_27 \nfor any vectors formula_13 and formula_29\nThis also shows that a vector norm is a (uniformly) continuous function.\nProperty 3 depends on a choice of norm formula_30 on the field of scalars. When the scalar field is formula_31 (or more generally a subset of formula_32), this is usually taken to be the ordinary absolute value, but other choices are possible. For example, for a vector space over formula_33 one could take formula_30 to be the formula_35-adic absolute value.\nTopological structure.\nIf formula_36 is a normed vector space, the norm formula_37 induces a metric (a notion of \"distance\") and therefore a topology on formula_38 This metric is defined in the natural way: the distance between two vectors formula_39 and formula_40 is given by formula_41 This topology is precisely the weakest topology which makes formula_37 continuous and which is compatible with the linear structure of formula_1 in the following sense:\nSimilarly, for any seminormed vector space we can define the distance between two vectors formula_39 and formula_40 as formula_41 This turns the seminormed space into a pseudometric space (notice this is weaker than a metric) and allows the definition of notions such as continuity and convergence.\nTo put it more abstractly every seminormed vector space is a topological vector space and thus carries a topological structure which is induced by the semi-norm.\nOf special interest are complete normed spaces, which are known as Banach spaces. \nEvery normed vector space formula_1 sits as a dense subspace inside some Banach space; this Banach space is essentially uniquely defined by formula_1 and is called the completion of formula_38\nTwo norms on the same vector space are called equivalent if they define the same topology. On a finite-dimensional vector space (but not infinite-dimensional vector spaces), all norms are equivalent (although the resulting metric spaces need not be the same) And since any Euclidean space is complete, we can thus conclude that all finite-dimensional normed vector spaces are Banach spaces.\nA normed vector space formula_1 is locally compact if and only if the unit ball formula_55 is compact, which is the case if and only if formula_1 is finite-dimensional; this is a consequence of Riesz's lemma. (In fact, a more general result is true: a topological vector space is locally compact if and only if it is finite-dimensional. The point here is that we don't assume the topology comes from a norm.)\nThe topology of a seminormed vector space has many nice properties. Given a neighbourhood system formula_57 around 0 we can construct all other neighbourhood systems as\nformula_58\nwith\nformula_59\nMoreover, there exists a neighbourhood basis for the origin consisting of absorbing and convex sets. As this property is very useful in functional analysis, generalizations of normed vector spaces with this property are studied under the name locally convex spaces. \nA norm (or seminorm) formula_60 on a topological vector space formula_61 is continuous if and only if the topology formula_62 that formula_60 induces on formula_64 is coarser than formula_65 (meaning, formula_66), which happens if and only if there exists some open ball formula_67 in formula_68 (such as maybe formula_69 for example) that is open in formula_61 (said different, such that formula_71).\nNormable spaces.\nA topological vector space formula_61 is called normable if there exists a norm formula_73 on formula_64 such that the canonical metric formula_75 induces the topology formula_65 on formula_77\nThe following theorem is due to Kolmogorov:\nKolmogorov's normability criterion: A Hausdorff topological vector space is normable if and only if there exists a convex, von Neumann bounded neighborhood of formula_78\nA product of a family of normable spaces is normable if and only if only finitely many of the spaces are non-trivial (that is, formula_79). Furthermore, the quotient of a normable space formula_64 by a closed vector subspace formula_81 is normable, and if in addition formula_64's topology is given by a norm formula_83 then the map formula_84 given by formula_85 is a well defined norm on formula_86 that induces the quotient topology on formula_87\nIf formula_64 is a Hausdorff locally convex topological vector space then the following are equivalent:\nFurthermore, formula_64 is finite-dimensional if and only if formula_96 is normable (here formula_96 denotes formula_98 endowed with the weak-* topology).\nThe topology formula_65 of the Fr\u00e9chet space formula_100 as defined in the article on spaces of test functions and distributions, is defined by a countable family of norms but it is not a normable space because there does not exist any norm formula_60 on formula_102 such that the topology that this norm induces is equal to formula_103 \nEven if a metrizable topological vector space has a topology that is defined by a family of norms, then it may nevertheless still fail to be normable space (meaning that its topology can not be defined by any single norm). \nAn example of such a space is the Fr\u00e9chet space formula_100 whose definition can be found in the article on spaces of test functions and distributions, because its topology formula_65 is defined by a countable family of norms but it is not a normable space because there does not exist any norm formula_60 on formula_102 such that the topology this norm induces is equal to formula_103 \nIn fact, the topology of a locally convex space formula_64 can be a defined by a family of norms on formula_64 if and only if there exists at least one continuous norm on formula_77\nLinear maps and dual spaces.\nThe most important maps between two normed vector spaces are the continuous linear maps. Together with these maps, normed vector spaces form a category.\nThe norm is a continuous function on its vector space. All linear maps between finite-dimensional vector spaces are also continuous.\nAn \"isometry\" between two normed vector spaces is a linear map formula_112 which preserves the norm (meaning formula_113 for all vectors formula_40). Isometries are always continuous and injective. A surjective isometry between the normed vector spaces formula_1 and formula_116 is called an \"isometric isomorphism\", and formula_1 and formula_116 are called \"isometrically isomorphic\". Isometrically isomorphic normed vector spaces are identical for all practical purposes.\nWhen speaking of normed vector spaces, we augment the notion of dual space to take the norm into account. The dual formula_119 of a normed vector space formula_1 is the space of all \"continuous\" linear maps from formula_1 to the base field (the complexes or the reals) \u2014 such linear maps are called \"functionals\". The norm of a functional formula_122 is defined as the supremum of formula_123 where formula_40 ranges over all unit vectors (that is, vectors of norm formula_125) in formula_38 This turns formula_119 into a normed vector space. An important theorem about continuous linear functionals on normed vector spaces is the Hahn\u2013Banach theorem.\nNormed spaces as quotient spaces of seminormed spaces.\nThe definition of many normed spaces (in particular, Banach spaces) involves a seminorm defined on a vector space and then the normed space is defined as the quotient space by the subspace of elements of seminorm zero. For instance, with the formula_128 spaces, the function defined by\nformula_129\nis a seminorm on the vector space of all functions on which the Lebesgue integral on the right hand side is defined and finite. However, the seminorm is equal to zero for any function supported on a set of Lebesgue measure zero. These functions form a subspace which we \"quotient out\", making them equivalent to the zero function.\nFinite product spaces.\nGiven formula_130 seminormed spaces formula_131 with seminorms formula_132 denote the product space by\nformula_133\nwhere vector addition defined as\nformula_134\nand scalar multiplication defined as\nformula_135\nDefine a new function formula_136 by\nformula_137\nwhich is a seminorm on formula_77 The function formula_139 is a norm if and only if all formula_140 are norms.\nMore generally, for each real formula_141 the map formula_136 defined by \nformula_143\nis a semi norm. \nFor each formula_35 this defines the same topological space.\nA straightforward argument involving elementary linear algebra shows that the only finite-dimensional seminormed spaces are those arising as the product space of a normed space and a space with trivial seminorm. Consequently, many of the more interesting examples and applications of seminormed spaces occur for infinite-dimensional vector spaces.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21541", "revid": "48985617", "url": "https://en.wikipedia.org/wiki?curid=21541", "title": "Nicene Creed", "text": "Statement of belief adopted at the First Ecumenical Council in 325\nThe Nicene Creed, also called the Creed of Constantinople, is the defining statement of belief of Nicene Christianity and in those Christian denominations that adhere to it.\nThe original Nicene Creed was first adopted at the First Council of Nicaea in 325. According to the traditional view, forwarded by the Council of Chalcedon of 451, the Creed was amended in 381 by the First Council of Constantinople as \"consonant to the holy and great Synod of Nice.\" However, many scholars comment on these ancient Councils, saying \"there is a failure of evidence\" for this position since no one between the years of 381\u2013451 thought of it in this light. Further, a creed \"almost identical in form\" was used as early as 374 by St. Epiphanius of Salamis. Nonetheless, the amended form is presently referred to as the Nicene Creed or the Niceno-Constantinopolitan Creed. \nJ.N.D. Kelly, who stands among historians as an authority on creedal statements, disagrees with the assessment above. He argues that since the First Council of Constantinople was not considered ecumenical until the Council of Chalcedon in 451, the absence of documentation during this period does not logically necessitate rejecting the amended creed as an expansion of the original Nicene Creed of 325.\nThe Nicene Creed is part of the profession of faith required of those undertaking important functions within the Eastern Orthodox, Roman Catholic, Evangelical Lutheran, Anglican, Methodist, and other Protestant traditions including the Waldensian and Reformed (Continental Reformed, Presbyterian, Congregationalist and Reformed Baptist). Nicene Christianity regards Jesus as divine and \"begotten of the Father\". Various conflicting theological views existed before the fourth century, and these disagreements would eventually spur the ecumenical councils to develop the Nicene Creed. Various non-Nicene beliefs have emerged and re-emerged since the fourth century, all of which are considered heresies by adherents of Nicene Christianity.\nIn the liturgical churches of Western Christianity, the Nicene Creed is in use alongside the less widespread Apostles' Creed and Athanasian Creed. An affirmation of faith, by default the Nicene Creed, is usually said immediately after the sermon or homily following the Gospel reading at the Eucharist, at least on Sundays and major festivals. \nIn musical settings, particularly when sung in Latin, this creed is usually referred to by its first word, . On Sundays and solemnities, one of these two creeds is recited in the Roman Rite Mass after the homily. In the Byzantine Rite, the Nicene Creed is sung or recited at the Divine Liturgy, immediately preceding the Anaphora (eucharistic prayer) is also recited daily at compline.\nThe current authoritative English translation in use in the Catholic Church since 2011 was done by the International Commission on English in the Liturgy.\nHistory.\nThe purpose of a creed is to provide a doctrinal statement of correct belief among Christians amid controversy. The creeds of Christianity have been drawn up at times of conflict about doctrine: acceptance or rejection of a creed served to distinguish believers and heretics, particularly the adherents of Arianism. For that reason, a creed was called in Greek a , which originally meant half of a broken object which, when fitted to the other half, verified the bearer's identity. The Greek word passed through Latin into English \"symbol\", which only later took on the meaning of an outward sign of something.\nThe Nicene Creed was adopted to resolve the Arian controversy, whose leader, Arius, a clergyman of Alexandria, \"objected to Alexander's (the bishop of the time) apparent carelessness in blurring the distinction of nature between the Father and the Son by his emphasis on eternal generation\". Emperor Constantine called the Council at Nicaea to resolve the dispute in the church, which resulted from the widespread adoption of Arius' teachings, which threatened to destabilize the entire Roman Empire. Following the formulation of the Nicene Creed, Arius' teachings were henceforth marked as heresy.\nThe Nicene Creed of 325 explicitly affirms the Father as the \"one God\" and as the \"Almighty,\" and Jesus Christ as \"the Son of God\", as \"begotten of[...] the essence of the Father,\" and therefore as \"consubstantial with the Father,\" meaning, \"of the same substance\" as the Father; \"very God of very God.\" The Creed of 325 does mention the Holy Spirit but not as \"God\" or as \"consubstantial with the Father.\" The 381 revision of the creed at Constantinople (i.e., the Niceno-Constantinopolitan Creed), which is often simply referred to as the \"Nicene Creed,\" speaks of the Holy Spirit as worshipped and glorified with the Father and the Son.\nThe Athanasian Creed, formulated approximately a century later, is not the product of any known church council and is not used in Eastern Christianity. It describes in much greater detail the relationship between the Father, the Son, and the Holy Spirit. The earlier Apostles' Creed, apparently formulated before the Arian controversy arose in the fourth century, does not describe the Son or the Holy Spirit as \"God\" or as \"consubstantial with the Father.\"\nThomas Aquinas stated that the phrase \"for us men, and for our salvation\" was to refute the error of Origen, \"who alleged that by the power of Christ's Passion even the devils were to be set free.\" He also stated that the phrases stating Jesus was made \"incarnate by the Holy Spirit\" was to refute the Manicheans \"so that we may believe that He assumed true flesh and not a phantastic body,\" and \"He came down from Heaven\" was to refute the error of Photinus, \"who asserted that Christ was no more than a man.\" Furthermore, the phrase \"and He was made man\" was to \"exclude the error of Nestorius, according to whose contention the Son of God ... would be said to dwell in man [rather] than to be man.\"\nOriginal Nicene Creed of 325.\nThe original Nicene Creed was first adopted at the First Council of Nicaea, which opened on 19 June 325. The text ends with anathemas against Arian propositions, preceded by the words: \"We believe in the Holy Spirit\" which terminates the statements of belief.\nF. J. A. Hort and Adolf von Harnack argued that the Nicene Creed was the local creed of Caesarea (an important center of Early Christianity) recited in the council by Eusebius of Caesarea. Their case relied largely on a particular interpretation of Eusebius' account of the council's proceedings. More recent scholarship has not been convinced by their arguments. The large number of secondary divergences from the text of the creed quoted by Eusebius make it unlikely that it was used as a starting point by those who drafted the conciliar creed. Their initial text was probably a local creed from a Syro-Palestinian source into which they inserted phrases to define the Nicene theology. The Eusebian Creed may thus have been either a second or one of many nominations for the Nicene Creed.\nThe 1911 \"Catholic Encyclopedia\" says that soon after the Council of Nicaea the church composed new formulae of faith, most of them variations of the Nicene Symbol, to meet new phases of Arianism, of which there were at least four before the Council of Sardica (341), at which a new form was presented and inserted in its acts. However, the council did not accept it.\nNiceno-Constantinopolitan Creed.\nWhat is known as the \"Niceno-Constantinopolitan Creed\" or the \"Nicene-Constantinopolitan Creed\", received this name because it was adopted at the Second Ecumenical Council held in Constantinople in 381 as a modification of the original Nicene Creed of 325. In that light, it also became very commonly known simply as the \"Nicene Creed.\" It is the only authoritative \"ecumenical\" statement of the Christian faith accepted by the Catholic Church (with the addition of the Filioque), the Eastern Orthodox Church, Oriental Orthodoxy, the Church of the East, and much of Protestantism including the Anglican communion. (The Apostles' and Athanasian creeds are not as widely accepted.)\nIt differs in several respects, both by addition and omission, from the creed adopted at the First Council of Nicaea. The most notable difference is the additional section:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;And [we believe] in the Holy Ghost, the Lord and Giver-of-Life, who proceedeth from the Father, who with the Father and the Son together is worshipped and glorified, who spake by the prophets.\nAnd [we believe] in one, holy, catholic and Apostolic Church. We acknowledge one Baptism for the remission of sins, [and] we look for the resurrection of the dead and the life of the world to come. Amen.\nSince the end of the 19th century, scholars have questioned the traditional explanation of the origin of this creed, which has been passed down in the name of the council, whose official acts have been lost over time. A local council of Constantinople in 382 and the Third Ecumenical Council (Council of Ephesus of 431) made no mention of it, with the latter affirming the 325 creed of Nicaea as a valid statement of the faith and using it to denounce Nestorianism. Though some scholarship claims that hints of the later creed's existence are discernible in some writings, no extant document gives its text or makes explicit mention of it earlier than the Fourth Ecumenical Council at Chalcedon in 451. Many of the bishops of the 451 council themselves had never heard of it and initially greeted it skeptically, but it was then produced from the episcopal archives of Constantinople, and the council accepted it \"not as supplying any omission but as an authentic interpretation of the faith of Nicaea\". Despite the questions raised, it is considered most likely that this creed was introduced at the 381 Second Ecumenical Council.\nBased on evidence both internal and external to the text, it has been argued that this creed originated not as an editing of the original Creed proposed at Nicaea in 325, but as an independent creed (probably an older baptismal creed) modified to make it more like the Nicene Creed. Some scholars have argued that the creed may have been presented at Chalcedon as \"a precedent for drawing up new creeds and definitions to supplement the Creed of Nicaea, as a way of getting round the ban on new creeds in Canon 7 of Ephesus\". It is generally agreed that the Niceno-Constantinopolitan Creed is not simply an expansion of the Creed of Nicaea, and was probably based on another traditional creed independent of the one from Nicaea.\nThe Third Ecumenical Council (Ephesus) reaffirmed the original version of 325. of the Nicene Creed and declared that \"it is unlawful for any man to bring forward, or to write, or to compose a different () faith as a rival to that established by the holy Fathers assembled with the Holy Ghost in Nicaea\" (i.e., the 325 creed). The word is more accurately translated as used by the council to mean \"different\", \"contradictory\", rather than \"another\". This statement has been interpreted as a prohibition against changing this creed or composing others, but not all accept this interpretation. This question is connected with the controversy whether a creed proclaimed by an ecumenical council is definitive in excluding not only excisions from its text but also additions to it.\nIn one respect, the Eastern Orthodox Church's received text of the Niceno-Constantinopolitan Creed differs from the earliest text, which is included in the acts of the Council of Chalcedon of 451: The Eastern Orthodox Church uses the singular forms of verbs such as \"I believe\", in place of the plural form (\"we believe\") used by the council. Byzantine Rite Eastern Catholic Churches use the same form of the creed, since the Catholic Church teaches that it is wrong to add \"and the Son\" to the Greek verb \"\", though correct to add it to the Latin , which does not have precisely the same meaning. The form generally used in Western churches does add \"and the Son\" and also the phrase \"God from God\", which is found in the original 325 Creed.\nComparison between the creed of 325 and the creed of 381.\nThe following table, which indicates by square brackets the portions of the 325 text that were omitted or moved in 381, and uses italics to indicate what phrases, absent in the 325 text, were added in 381, juxtaposes the earlier (AD 325) and later (AD 381) forms of this creed in the English translation given in Philip Schaff's compilation \"The Creeds of Christendom\" (1877).\nFilioque controversy.\nIn the late 6th century, some Latin-speaking churches added the word (\"and the Son\") to the description of the procession of the Holy Spirit, in what many Eastern Orthodox Christians have at a later stage argued is a violation of Canon VII of the Third Ecumenical Council, since the words were not included in the text by either the Council of Nicaea or that of Constantinople. This was incorporated into the liturgical practice of Rome in 1014. eventually became one of the leading causes for the East-West Schism in 1054, and the failures of the repeated union attempts.\nViews on the importance of this creed.\nNearly all Christian denominations, including Catholic, Orthodox, and most Protestant churches (e.g., Lutherans, Anglicans, Methodists, Continental Reformed, Presbyterians, Congregationalists and Baptists), regard the Nicene Creed as a foundational and authoritative statement of faith. Thus approximately 98.5% of the world's Christians are Nicene Christians, adhering to the Nicene Creed's Trinitarian and Christological doctrines. The remaining 1.5% include non-Trinitarian groups such as the LDS Church, Jehovah's Witnesses, Swedenborgians, etc. (see below).\nAs mentioned above, there are a minority of Evangelical and non-denominational groups, such as some independent Churches of Christ, certain neo-charismatic congregations, or some fundamentalist churches, who view the Nicene Creed as a helpful summary of biblical truth but not authoritative, emphasizing that only the Bible is authoritative and rule of faith and practice. Furthermore, certain non-Trinitarian groups explicitly reject the Nicene Creed's Trinitarian doctrines: examples include the Church of the New Jerusalem, The Church of Jesus Christ of Latter-day Saints, and Jehovah's Witnesses, whose theologies are incompatible with the Creed's teachings on the Trinity and Christ's divinity.\nThe view that the Nicene Creed can serve as a touchstone of genuine Christian faith is reflected in the name \"symbol of faith\", which was given to it in Greek and Latin, when in those languages the word \"symbol\" meant a \"token for identification (by comparison with a counterpart)\". In the Roman Rite Mass, the Latin text of the Niceno-Constantinopolitan Creed, with (God from God) and (and from the Son), phrases absent in the original text, was previously the only form used for the \"profession of faith\". The Roman Missal now refers to it jointly with the Apostles' Creed as \"the Symbol or Profession of Faith or Creed\", describing the second as \"the baptismal Symbol of the Roman Church, known as the Apostles' Creed\".\nAncient liturgical versions.\nThere are several designations for the two forms of the Nicene Creed, some with overlapping meanings:\nThis section is not intended to collect the texts of all liturgical versions of the Nicene Creed, but rather provides only three of special interest: the Greek, the Latin, and the Armenian. Others are mentioned separately, but without the texts. All ancient liturgical versions, even the Greek, differ to some extent, however small, from the text adopted by the First Councils of Nicaea and Constantinople. The Creed was originally written in Greek, owing to the location of the two councils.\nAlthough the councils' texts have (\"we believe[...] confess[...] await\"), the creed that the Churches of Byzantine tradition use in their liturgy has (\"I believe[...] confess[...] await\"), accentuating the personal nature of recitation of the creed. The Latin text, as well as using the singular, has two additions: (God from God) and (and from the Son). The Armenian text has many more additions, and is included as showing how that ancient church has chosen to recite the creed with these numerous elaborations of its contents.\nAn English translation of the Armenian text is provided; English translations of the Greek and Latin liturgical texts are included in English versions of the Nicene Creed in current use.\nGreek liturgical text.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nLatin liturgical version.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe Latin text adds and to the Greek. For further information, see The Filioque Controversy above. Inevitably also, the overtones of the terms used, such as a and , differ ( meaning ruler of all; meaning omnipotent, almighty). The implications of the difference in overtones of and was the object of the study \"The Greek and the Latin Traditions regarding the Procession of the Holy Spirit\" published by the Pontifical Council for Promoting Christian Unity in 1996.\nAgain, the terms and , translated as \"of one being\" or \"consubstantial\", have different overtones, being based respectively on Greek (stable being, immutable reality, substance, essence, true nature), and Latin (that of which a thing consists, the being, essence, contents, material, substance).\n, which in classical Latin is used with the accusative case of the thing held to be true (and with the dative of the person to whom credence is given), is here used three times with the preposition \"in\", a literal translation of the Greek (), and once in the classical preposition-less construction ().\nArmenian liturgical text.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nEnglish translation of the Armenian version.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nOther ancient liturgical versions.\nThe version in the Church Slavonic language, used by several Eastern Orthodox churches is practically identical with the Greek liturgical version.\nThis version is also used by some Byzantine Rite Eastern Catholic Churches. Although the Union of Brest excluded addition of the Filioque, this was sometimes added by Ruthenian Catholics, whose older liturgical books also show the phrase in brackets, and by Ukrainian Catholics. Writing in 1971, the Ruthenian scholar Casimir Kucharek noted, \"In Eastern Catholic Churches, the may be omitted except when scandal would ensue. Most of the Eastern Catholic Rites use it.\" However, in the decades that followed 1971, it has come to be used more rarely.\nThe versions used by Oriental Orthodoxy and the Church of the East may differ from the Greek liturgical version in having \"We believe\", as in the original text, instead of \"I believe\".\nIndulgence.\nIn the Roman Catholic Church, to obtain the plenary indulgence once a day, it is necessary to visit a church or oratory to which the indulgence is attached and the recitation of the Sunday prayers, \"Creed\" and \"Hail Mary\".\nRecitation of the \"Apostles' Creed\" or the \"Nicene-Constantinopolitan Creed\" is required to obtain a partial \"indulgence\".\nEnglish translations.\nThe version found in the 1662 \"Book of Common Prayer\" is still commonly used by some English speakers, but more modern translations are now more common. The International Consultation on English Texts (later known as English Language Liturgical Consultation (ELLC)) published an English translation of the Nicene Creed, first in 1970 and then in successive revisions in 1971 and 1975. Several churches adopted these texts.\nThe Roman Catholic Church in the United States adopted the 1971 version in 1973. The Catholic Church in other English-speaking countries adopted the 1975 version in 1975. They continued to use them until 2011, when they were replaced with the version in the \"Roman Missal\" third edition. The 1975 version was included in the 1979 Episcopal Church (United States) \"Book of Common Prayer\", but with one variation: in the line \"For us men and for our salvation\", it omitted the word \"men\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21544", "revid": "1934512", "url": "https://en.wikipedia.org/wiki?curid=21544", "title": "Nuclear fusion", "text": "Process of combining atomic nuclei\nNuclear fusion is a reaction in which two or more atomic nuclei combine to form a larger nucleus. The difference in mass between the reactants and products is manifested as either the release or the absorption of energy. This difference in mass arises as a result of the difference in nuclear binding energy between the atomic nuclei before and after the fusion reaction. Nuclear fusion is the process that powers all active stars, via many reaction pathways.\nFusion processes require an extremely large triple product of temperature, density, and confinement time. These conditions occur only in stellar cores, advanced nuclear weapons, and are approached in fusion power experiments.\nA nuclear fusion process that produces atomic nuclei lighter than nickel-62 is generally exothermic, due to the positive gradient of the nuclear binding energy curve. The most fusible nuclei are among the lightest, especially deuterium, tritium, and helium-3. The opposite process, nuclear fission, is most energetic for very heavy nuclei, especially the actinides.\nApplications of fusion include fusion power, thermonuclear weapons, boosted fission weapons, neutron sources, and superheavy element production.\nHistory.\nTheory.\nAmerican chemist William Draper Harkins was the first to propose the concept of nuclear fusion in 1915. Francis William Aston's 1919 invention of the mass spectrometer allowed the discovery that four hydrogen atoms are heavier than one helium atom. Thus in 1920, Arthur Eddington correctly predicted fusion of hydrogen into helium could be the primary source of stellar energy. \nQuantum tunneling was discovered by Friedrich Hund in 1927, with relation to electron levels. In 1928, George Gamow was the first to apply tunneling to the nucleus, first to alpha decay, then to fusion as an inverse process. From this, in 1929, Robert Atkinson and Fritz Houtermans made the first estimates for stellar fusion rates. \nIn 1938, Hans Bethe worked with Charles Critchfield to enumerate the proton\u2013proton chain that dominates Sun-type stars. In 1939, Bethe published the discovery of the CNO cycle common to higher-mass stars.\nEarly experiments.\nDuring the 1920s, Patrick Blackett made the first conclusive experiments in artificial nuclear transmutation at the Cavendish Laboratory. There, John Cockcroft and Ernest Walton built their generator on the inspiration of Gamow's paper. In April 1932, they published experiments on the reaction: \n[&lt;noinclude /&gt;[lithium-7|Li]&lt;noinclude /&gt;] + p \u2192 X \u2192 2 [&lt;noinclude /&gt;[helium-4|He]&lt;noinclude /&gt;]\nwhere the intermediary nuclide was later confirmed to be the extremely short-lived beryllium-8. This has a claim to the first artificial fusion reaction. \nIn papers from July and November 1933, Ernest Lawrence et. al. at the University of California Radiation Laboratory, in some of the earliest cyclotron experiments, accidentally produced the first deuterium\u2013deuterium fusion reactions: \n D + D \u2192 T + p\n D + D \u2192 He + \nThe Radiation Lab, only detecting the resulting energized protons and neutrons, misinterpreted the source as an exothermic disintegration of the deuterons, now known to be impossible. In May 1934, Mark Oliphant, Paul Harteck, and Ernest Rutherford at the Cavendish Laboratory, published an intentional deuterium fusion experiment, and made the discovery of both tritium and helium-3. This is widely considered the first experimental demonstration of fusion.\nIn 1938, Arthur Ruhlig at the University of Michigan made the first observation of deuterium\u2013tritium (DT) fusion and its characteristic 14\u00a0MeV neutrons, now known as the most favourable reaction: \n D + T \u2192 He + \nWeaponization.\nResearch into fusion for military purposes began in the early 1940s as part of the Manhattan Project. In 1941, Enrico Fermi and Edward Teller had a conversation about the possibility of a fission bomb creating conditions for thermonuclear fusion. In 1942, Emil Konopinski brought Ruhlig's work on the deuterium\u2013tritium reaction to the project's attention. J. Robert Oppenheimer initially commissioned physicists at Chicago and Cornell to use the Harvard University cyclotron to secretly investigate its cross-section, and that of the lithium reaction (see below). Measurements were obtained at Purdue, Chicago, and Los Alamos from 1942 to 1946. Theoretical assumptions about DT fusion gave it a similar cross-section to DD. However, in 1946 Egon Bretscher discovered a resonance enhancement giving the DT reaction a cross-section ~100 times larger.\nFrom 1945, John von Neumann, Teller, and other Los Alamos scientists used ENIAC, one of the first electronic computers, to simulate thermonuclear weapon detonations.\nThe first artificial thermonuclear fusion reaction occurred during the 1951 US Greenhouse George nuclear test, using a small amount of deuterium\u2013tritium gas. This produced the largest yield to date, at 225 kt, 15 times that of Little Boy. The first \"true\" thermonuclear weapon detonation i.e. a two-stage device, was the 1952 Ivy Mike test of a liquid deuterium-fusing device, yielding over 10 Mt. The key to this jump was the full utilization of the fission blast by the Teller\u2013Ulam design.\nThe Soviet Union had begun their focus on a hydrogen bomb program earlier, and in 1953 carried out the RDS-6s test. This had international impacts as the first air-deliverable bomb using fusion, but yielded 400 kt and was limited by its single-stage design. The first Soviet two-stage test was RDS-37 in 1955 yielding 1.5\u00a0Mt, using an independently reached version of the Teller\u2013Ulam design.\nModern devices benefit from the usage of solid lithium deuteride with an enrichment of lithium-6. This is due to the Jetter cycle involving the exothermic reaction:\n [&lt;noinclude /&gt;[lithium-6|Li]&lt;noinclude /&gt;] + \u2192 He + T\nDuring thermonuclear detonations, this provides tritium for the highly energetic DT reaction, and benefits from its neutron production, creating a closed neutron cycle.\nFusion energy.\nWhile fusion bomb detonations were loosely considered for energy production, the possibility of controlled and sustained reactions remained the scientific focus for peaceful fusion power. Research into developing controlled fusion inside fusion reactors has been ongoing since the 1930s, with Los Alamos National Laboratory's Scylla I device producing the first laboratory thermonuclear fusion in 1958, but the technology is still in its developmental phase.\nThe first experiments producing large amounts of controlled fusion power were the experiments with mixes of deuterium and tritium in Tokamaks. Experiments in the TFTR at thePPPL in Princeton University Princeton NJ, USA during 1993\u20131996 produced 1.6\u00a0GJ of fusion energy. The peak fusion power was 10.3\u00a0MW from reactions per second, and peak fusion energy created in one discharge was 7.6\u00a0MJ. Subsequent experiments in the JET in 1997 achieved a peak fusion power of 16\u00a0MW (). The central \"Q\", defined as the local fusion power produced to the local applied heating power, is computed to be 1.3. A JET experiment in 2024 produced 69\u00a0MJ of fusion power, consuming 0.2\u00a0mgm of D and T.\nThe US National Ignition Facility, which uses laser-driven inertial confinement fusion, was designed with a goal of achieving a fusion energy gain factor (Q) of larger than one; the first large-scale laser target experiments were performed in June 2009 and ignition experiments began in early 2011. On 13 December 2022, the United States Department of Energy announced that on 5 December 2022, they had successfully accomplished break-even fusion, \"delivering 2.05\u00a0megajoules (MJ) of energy to the target, resulting in 3.15\u00a0MJ of fusion energy output\". The rate of supplying power to the experimental test cell is hundreds of times larger than the power delivered to the target.\nPrior to this breakthrough, controlled fusion reactions had been unable to produce break-even (self-sustaining) controlled fusion. The two most advanced approaches for it are magnetic confinement (toroid designs) and inertial confinement (laser designs). Workable designs for a toroidal reactor that theoretically will deliver ten times more fusion energy than the amount needed to heat plasma to the required temperatures are in development (see ITER). The ITER facility is currently expected to initiate plasma experiments in 2034, but is not expected to begin full deuterium\u2013tritium fusion until 2039.\nPrivate companies pursuing the commercialization of nuclear fusion received $2.6 billion in private funding in 2021 alone, going to many notable startups including but not limited to Commonwealth Fusion Systems, Helion Energy Inc., General Fusion, TAE Technologies Inc. and Zap Energy Inc.\nOne of the most recent breakthroughs to date in maintaining a sustained fusion reaction occurred in France's WEST fusion reactor. It maintained a 90 million degree plasma for a record time of six minutes. This is a tokamak-style reactor which is the same style as the upcoming ITER reactor.\nProcess.\nThe release of energy with the fusion of light elements is due to the interplay of two opposing forces: the nuclear force, a manifestation of the strong interaction, which holds protons and neutrons tightly together in the atomic nucleus; and the Coulomb force, which causes positively charged protons in the nucleus to repel each other. Lighter nuclei (nuclei smaller than iron and nickel) are sufficiently small and proton-poor to allow the nuclear force to overcome the Coulomb force. This is because the nucleus is sufficiently small that all nucleons feel the short-range attractive force at least as strongly as they feel the infinite-range Coulomb repulsion. Building up nuclei from lighter nuclei by fusion releases the extra energy from the net attraction of particles. For larger nuclei, however, no energy is released, because the nuclear force is short-range and cannot act across larger nuclei.\nFusion powers stars and produces most elements lighter than cobalt in a process called nucleosynthesis. The Sun is a main-sequence star, and, as such, generates its energy by nuclear fusion of hydrogen nuclei into helium. In its core, the Sun fuses 620\u00a0million metric tons of hydrogen and makes 616\u00a0million metric tons of helium each second. The fusion of lighter elements in stars releases energy and the mass that always accompanies it. For example, in the fusion of two hydrogen nuclei to form helium, 0.645% of the mass is carried away in the form of kinetic energy of an alpha particle or other forms of energy, such as electromagnetic radiation.\nIt takes considerable energy to force nuclei to fuse, even those of the lightest element, hydrogen. When accelerated to high enough speeds, nuclei can overcome this electrostatic repulsion and be brought close enough such that the attractive nuclear force is greater than the repulsive Coulomb force. The strong force grows rapidly once the nuclei are close enough, and the fusing nucleons can essentially \"fall\" into each other and the result is fusion; this is an exothermic process.\nEnergy released in most nuclear reactions is much larger than in chemical reactions, because the binding energy that holds a nucleus together is greater than the energy that holds electrons to a nucleus. For example, the ionization energy gained by adding an electron to a hydrogen nucleus is \u2014less than one-millionth of the released in the deuterium\u2013tritium (D\u2013T) reaction shown in the adjacent diagram. Fusion reactions have an energy density many times greater than nuclear fission; the reactions produce far greater energy per unit of mass even though \"individual\" fission reactions are generally much more energetic than \"individual\" fusion ones, which are themselves millions of times more energetic than chemical reactions. Via the mass\u2013energy equivalence, fusion yields a 0.7% efficiency of reactant mass into energy. This can only be exceeded by the extreme cases of the accretion process involving neutron stars or black holes, approaching 40% efficiency, and antimatter annihilation at 100% efficiency. (The complete conversion of one gram of matter would expel of energy.)\nIn astrophysics.\nFusion is responsible for the astrophysical production of the majority of elements lighter than iron. This includes most types of Big Bang nucleosynthesis and stellar nucleosynthesis. Non-fusion processes that contribute include the s-process and r-process in neutron merger and supernova nucleosynthesis, responsible for elements heavier than iron.\nStars.\nAn important fusion process is the stellar nucleosynthesis that powers stars, including the Sun. In the 20th century, it was recognized that the energy released from nuclear fusion reactions accounts for the longevity of stellar heat and light. The fusion of nuclei in a star, starting from its initial hydrogen and helium abundance, provides that energy and synthesizes new nuclei. Different reaction chains are involved, depending on the mass of the star (and therefore the pressure and temperature in its core).\nAround 1920, Arthur Eddington anticipated the discovery and mechanism of nuclear fusion processes in stars, in his paper \"The Internal Constitution of the Stars\". At that time, the source of stellar energy was unknown; Eddington correctly speculated that the source was fusion of hydrogen into helium, liberating enormous energy according to Einstein's equation \"E\" \n \"mc\"2. This was a particularly remarkable development since at that time fusion and thermonuclear energy had not yet been discovered, nor even that stars are largely composed of hydrogen &lt;templatestyles src=\"Crossreference/styles.css\" /&gt;. Eddington's paper reasoned that:\nAll of these speculations were proven correct in the following decades.\nThe primary source of solar energy, and that of similar size stars, is the fusion of hydrogen to form helium (the proton\u2013proton chain reaction), which occurs at a solar-core temperature of 14\u00a0million kelvin. The net result is the fusion of four protons into one alpha particle, with the release of two positrons and two neutrinos (which changes two of the protons into neutrons), and energy. In heavier stars, the CNO cycle and other processes are more important. As a star uses up a substantial fraction of its hydrogen, it begins to fuse heavier elements. In massive cores, silicon-burning is the final fusion cycle, leading to a build-up of iron and nickel nuclei.\nNuclear binding energy makes the production of elements heavier than nickel via fusion energetically unfavorable. These elements are produced in non-fusion processes: the s-process, r-process, and the variety of processes that can produce p-nuclei. Such processes occur in giant star shells, or supernovae, or neutron star mergers.\nBrown dwarfs.\nBrown dwarfs fuse deuterium and in very high mass cases also fuse lithium.\nWhite dwarfs.\nCarbon\u2013oxygen white dwarfs, which accrete matter either from an active stellar companion or white dwarf merger, approach the Chandrasekhar limit of 1.44 solar masses. Immediately prior, carbon burning fusion begins, destroying the Earth-sized dwarf within one second, in a Type Ia supernova.\nMuch more rarely, helium white dwarfs may merge, which does not cause an explosion but begins helium burning in an extreme type of helium star.\nNeutron stars.\nSome neutron stars accrete hydrogen and helium from an active stellar companion. Periodically, the helium accretion reaches a critical level, and a thermonuclear burn wave propagates across the surface, on the timescale of one second. \nBlack hole accretion disks.\nSimilar to stellar fusion, extreme conditions within black hole accretion disks can allow fusion reactions. Calculations show the most energetic reactions occur around lower stellar mass black holes, below 10 solar masses, compared to those above 100. Beyond five Schwarzschild radii, carbon-burning and fusion of helium-3 dominates the reactions. Within this distance, around lower mass black holes, fusion of nitrogen, oxygen, neon, and magnesium can occur. In the extreme limit, the silicon-burning process can begin with the fusion of silicon and selenium nuclei.\nBig Bang.\nFrom the period approximately 10 seconds to 20 minutes after the Big Bang, the universe cooled from over 100 keV to 1 keV. This allowed the combination of protons and neutrons in deuterium nuclei, and beginning a rapid fusion chain into tritium and helium-3 and ending in predominantly helium-4, with a minimal fraction of lithium, beryllium, and boron nuclei.\nObservational evidence shows that pockets of gas in the early universe became thick to collapse under their own gravity. This activated nuclear fusion with the formation of the first stars around 13.6 billion years ago.\nRequirements.\nA substantial energy barrier of electrostatic forces must be overcome before fusion can occur. At large distances, two naked nuclei repel one another because of the repulsive electrostatic force between their positively charged protons. If two nuclei can be brought close enough together, however, the electrostatic repulsion can be overcome by the quantum effect in which nuclei can tunnel through coulomb forces.\nWhen a nucleon such as a proton or neutron is added to a nucleus, the nuclear force attracts it to all the other nucleons of the nucleus (if the atom is small enough), but primarily to its immediate neighbors due to the short range of the force. The nucleons in the interior of a nucleus have more neighboring nucleons than those on the surface. Since smaller nuclei have a larger surface-area-to-volume ratio, the binding energy per nucleon due to the nuclear force generally increases with the size of the nucleus but approaches a limiting value corresponding to that of a nucleus with a diameter of about four nucleons. It is important to keep in mind that nucleons are quantum objects. So, for example, since two neutrons in a nucleus are identical to each other, the goal of distinguishing one from the other, such as which one is in the interior and which is on the surface, is in fact meaningless, and the inclusion of quantum mechanics is therefore necessary for proper calculations.\nThe electrostatic force, on the other hand, is an inverse-square force, so a proton added to a nucleus will feel an electrostatic repulsion from \"all\" the other protons in the nucleus. The electrostatic energy per nucleon due to the electrostatic force thus increases without limit as nuclei atomic number grows.\nThe net result of the opposing electrostatic and strong nuclear forces is that the binding energy per nucleon generally increases with increasing size, up to the elements iron and nickel, and then decreases for heavier nuclei. Eventually, the binding energy becomes negative and very heavy nuclei (all with more than 208 nucleons, corresponding to a diameter of about 6 nucleons) are not stable. The four most tightly bound nuclei, in decreasing order of binding energy per nucleon, are [&lt;noinclude /&gt;[nickel-62|Ni]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[iron-58|Fe]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[iron-56|Fe]&lt;noinclude /&gt;], and [&lt;noinclude /&gt;[nickel-60|Ni]&lt;noinclude /&gt;]. Even though the nickel isotope, [&lt;noinclude /&gt;[nickel-62|Ni]&lt;noinclude /&gt;], is more stable, the iron isotope [&lt;noinclude /&gt;[iron-56|Fe]&lt;noinclude /&gt;] is an order of magnitude more common. This is due to the fact that there is no easy way for stars to create [&lt;noinclude /&gt;[nickel-62|Ni]&lt;noinclude /&gt;] through the alpha process.\nAn exception to this general trend is the helium-4 nucleus, whose binding energy is higher than that of lithium, the next heavier element. This is because protons and neutrons are fermions, which according to the Pauli exclusion principle cannot exist in the same nucleus in exactly the same state. Each proton or neutron's energy state in a nucleus can accommodate both a spin up particle and a spin down particle. Helium-4 has an anomalously large binding energy because its nucleus consists of two protons and two neutrons (it is a doubly magic nucleus), so all four of its nucleons can be in the ground state. Any additional nucleons would have to go into higher energy states. Indeed, the helium-4 nucleus is so tightly bound that it is commonly treated as a single quantum mechanical particle in nuclear physics, namely, the alpha particle.\nThe situation is similar if two nuclei are brought together. As they approach each other, all the protons in one nucleus repel all the protons in the other. Not until the two nuclei actually come close enough for long enough so the strong attractive nuclear force can take over and overcome the repulsive electrostatic force. This can also be described as the nuclei overcoming the so-called Coulomb barrier. The kinetic energy to achieve this can be lower than the barrier itself because of quantum tunneling.\nThe Coulomb barrier is smallest for isotopes of hydrogen, as their nuclei contain only a single positive charge. A diproton is not stable, so neutrons must also be involved, ideally in such a way that a helium nucleus, with its extremely tight binding, is one of the products.\nUsing deuterium\u2013tritium fuel, the resulting energy barrier is about 0.1\u00a0MeV. In comparison, the energy needed to remove an electron from hydrogen is 13.6\u00a0eV. The (intermediate) result of the fusion is an unstable 5He nucleus, which immediately ejects a neutron with 14.1\u00a0MeV. The recoil energy of the remaining 4He nucleus is 3.5\u00a0MeV, so the total energy liberated is 17.6\u00a0MeV. This is many times more than what was needed to overcome the energy barrier.\nThe reaction cross section (\u03c3) is a measure of the probability of a fusion reaction as a function of the relative velocity of the two reactant nuclei. If the reactants have a distribution of velocities, e.g. a thermal distribution, then it is useful to perform an average over the distributions of the product of cross-section and velocity. This average is called the 'reactivity', denoted . The reaction rate (fusions per volume per time) is times the product of the reactant number densities:\n formula_1\nIf a species of nuclei is reacting with a nucleus like itself, such as the DD reaction, then the product formula_2 must be replaced by formula_3.\nformula_4 increases from virtually zero at room temperatures up to meaningful magnitudes at temperatures of . At these temperatures, well above typical ionization energies (13.6\u00a0eV in the hydrogen case), the fusion reactants exist in a plasma state.\nThe significance of formula_4 as a function of temperature in a device with a particular energy confinement time is found by considering the Lawson criterion. This is an extremely challenging barrier to overcome on Earth, which explains why fusion research has taken many years to reach the current advanced technical state.\nArtificial fusion.\nThermonuclear fusion.\nThermonuclear fusion is the process of atomic nuclei combining or \"fusing\" using high temperatures to drive them close enough together for this to become possible. Such temperatures cause the matter to become a plasma and, if confined, fusion reactions may occur due to collisions with extreme thermal kinetic energies of the particles. There are two forms of thermonuclear fusion: \"uncontrolled\", in which the resulting energy is released in an uncontrolled manner, as it is in thermonuclear weapons (\"hydrogen bombs\") and in most stars; and \"controlled\", where the fusion reactions take place in an environment allowing some or all of the energy released to be harnessed.\nTemperature is a measure of the average kinetic energy of particles, so by heating the material it will gain energy. After reaching sufficient temperature, given by the Lawson criterion, the energy of accidental collisions within the plasma is high enough to overcome the Coulomb barrier and the particles may fuse together.\nIn a deuterium\u2013tritium fusion reaction, for example, the energy necessary to overcome the Coulomb barrier is 0.1\u00a0MeV. Converting between energy and temperature shows that the 0.1 MeV barrier would be overcome at a temperature in excess of 1.2 billion kelvin.\nThere are two effects that are needed to lower the actual temperature. One is the fact that temperature is the \"average\" kinetic energy, implying that some nuclei at this temperature would actually have much higher energy than 0.1\u00a0MeV, while others would be much lower. It is the nuclei in the high-energy tail of the velocity distribution that account for most of the fusion reactions. The other effect is quantum tunnelling. The nuclei do not actually have to have enough energy to overcome the Coulomb barrier completely. If they have nearly enough energy, they can tunnel through the remaining barrier. For these reasons fuel at lower temperatures will still undergo fusion events, at a lower rate.\n\"Thermonuclear\" fusion is one of the methods being researched in the attempts to produce fusion power. If thermonuclear fusion becomes favorable to use, it would significantly reduce the world's carbon footprint.\nBeam\u2013beam or beam\u2013target fusion.\nAccelerator-based light-ion fusion is a technique using particle accelerators to achieve particle kinetic energies sufficient to induce light-ion fusion reactions.\nAccelerating light ions is relatively easy, and can be done in an efficient manner\u2014requiring only a vacuum tube, a pair of electrodes, and a high-voltage transformer; fusion can be observed with as little as 10 kV between the electrodes. The system can be arranged to accelerate ions into a static fuel-infused target, known as \"beam\u2013target\" fusion, or by accelerating two streams of ions towards each other, \"beam\u2013beam\" fusion. The key problem with accelerator-based fusion (and with cold targets in general) is that fusion cross sections are many orders of magnitude lower than Coulomb interaction cross-sections. Therefore, the vast majority of ions expend their energy emitting bremsstrahlung radiation and the ionization of atoms of the target. Devices referred to as sealed-tube neutron generators are particularly relevant to this discussion. These small devices are miniature particle accelerators filled with deuterium and tritium gas in an arrangement that allows ions of those nuclei to be accelerated against hydride targets, also containing deuterium and tritium, where fusion takes place, releasing a flux of neutrons. Hundreds of neutron generators are produced annually for use in the petroleum industry where they are used in measurement equipment for locating and mapping oil reserves.\nA number of attempts to recirculate the ions that \"miss\" collisions have been made over the years. One of the better-known attempts in the 1970s was Migma, which used a unique particle storage ring to capture ions into circular orbits and return them to the reaction area. Theoretical calculations made during funding reviews pointed out that the system would have significant difficulty scaling up to contain enough fusion fuel to be relevant as a power source. In the 1990s, a new arrangement using a field-reversed configuration (FRC) as the storage system was proposed by Norman Rostoker and continues to be studied by TAE Technologies as of 2021[ [update]]. A closely related approach is to merge two FRC's rotating in opposite directions, which is being actively studied by Helion Energy. Because these approaches all have ion energies well beyond the Coulomb barrier, they often suggest the use of alternative fuel cycles like p-11B that are too difficult to attempt using conventional approaches.\nElement synthesis.\nFusion of very heavy target nuclei with accelerated ion beams is the primary method of element synthesis. In early 1930s nuclear experiments, deuteron beams were used, to discover the first synthetic elements, such as technetium, neptunium, and plutonium:\nformula_6\nFusion of very heavy target nuclei with heavy ion beams has been used to discover superheavy elements:\nformula_7\nformula_8\nMuon-catalyzed fusion.\nMuon-catalyzed fusion is a fusion process that occurs at ordinary temperatures. It was studied in detail by Steven Jones in the early 1980s. Net energy production from this reaction has been unsuccessful because of the high energy required to create muons, their short 2.2\u00a0\u03bcs half-life, and the high chance that a muon will bind to the new alpha particle and thus stop catalyzing fusion.\nOther principles.\nSome other confinement principles have been investigated.\nConfinement in thermonuclear fusion.\nThe key problem in achieving thermonuclear fusion is how to confine the hot plasma. Due to the high temperature, the plasma cannot be in direct contact with any solid material, so it has to be located in a vacuum. Also, high temperatures imply high pressures. The plasma tends to expand immediately and some force is necessary to act against it. This force can take one of three forms: gravitation in stars, magnetic forces in magnetic confinement fusion reactors, or inertial as the fusion reaction may occur before the plasma starts to expand, so the plasma's inertia is keeping the material together.\nGravitational confinement.\nOne force capable of confining the fuel well enough to satisfy the Lawson criterion is gravity. The mass needed, however, is so great that gravitational confinement is only found in stars\u2014the least massive stars capable of sustained fusion are red dwarfs, while brown dwarfs are able to fuse deuterium and lithium if they are of sufficient mass. In stars heavy enough, after the supply of hydrogen is exhausted in their cores, their cores (or a shell around the core) start fusing helium to carbon. In the most massive stars (at least 8\u201311 solar masses), the process is continued until some of their energy is produced by fusing lighter elements to iron. As iron has one of the highest binding energies, reactions producing heavier elements are generally endothermic. Therefore, significant amounts of heavier elements are not formed during stable periods of massive star evolution, but are formed in supernova explosions. Some lighter stars also form these elements in the outer parts of the stars over long periods of time, by absorbing energy from fusion in the inside of the star, by absorbing neutrons that are emitted from the fusion process.\nAll of the elements heavier than iron have some potential energy to release, in theory. At the extremely heavy end of element production, these heavier elements can produce energy in the process of being split again back toward the size of iron, in the process of nuclear fission. Nuclear fission thus releases energy that has been stored, sometimes billions of years before, during stellar nucleosynthesis.\nMagnetic confinement.\nElectrically charged particles (such as fuel ions) will follow magnetic field lines (see Guiding centre). The fusion fuel can therefore be trapped using a strong magnetic field. A variety of magnetic configurations exist, including the toroidal geometries of tokamaks and stellarators and open-ended mirror confinement systems.\nInertial confinement.\nA third confinement principle is to apply a rapid pulse of energy to a large part of the surface of a pellet of fusion fuel, causing it to simultaneously \"implode\" and heat to very high pressure and temperature. If the fuel is dense enough and hot enough, the fusion reaction rate will be high enough to burn a significant fraction of the fuel before it has dissipated. To achieve these extreme conditions, the initially cold fuel must be explosively compressed. Inertial confinement is used in the hydrogen bomb, where the driver is x-rays created by a fission bomb. Inertial confinement is also attempted in \"controlled\" nuclear fusion, where the driver is a laser, ion, or electron beam, or a Z-pinch. Another method is to use conventional high explosive material to compress a fuel to fusion conditions. The UTIAS explosive-driven-implosion facility was used to produce stable, centred and focused hemispherical implosions to generate neutrons from D\u2013D reactions. The simplest and most direct method proved to be in a predetonated stoichiometric mixture of deuterium\u2013oxygen. The other successful method was using a miniature Voitenko compressor, where a plane diaphragm was driven by the implosion wave into a secondary small spherical cavity that contained pure deuterium gas at one atmosphere.\nElectrostatic confinement.\nThere are also electrostatic confinement fusion devices. These devices confine ions using electrostatic fields. The best known is the fusor. This device has a cathode inside an anode wire cage. Positive ions fly towards the negative inner cage, and are heated by the electric field in the process. If they miss the inner cage they can collide and fuse. Ions typically hit the cathode, however, creating prohibitory high conduction losses. Also, fusion rates in fusors are very low due to competing physical effects, such as energy loss in the form of light radiation. Designs have been proposed to avoid the problems associated with the cage, by generating the field using a non-neutral cloud. These include a plasma oscillating device, a Penning trap and the polywell. The technology is relatively immature, however, and many scientific and engineering questions remain.\nThe most well known Inertial electrostatic confinement approach is the fusor. Starting in 1999, a number of amateurs have been able to do amateur fusion using these homemade devices. Other IEC devices include: the Polywell, MIX POPS and Marble concepts.\nImportant reactions.\nStellar reaction chains.\nAt the temperatures and densities in stellar cores, the rates of fusion reactions are notoriously slow. For example, at solar core temperature (\"T\" \u2248 15\u00a0MK) and density (160\u00a0g/cm3), the energy release rate is only 276\u00a0\u03bcW/cm3\u2014about a quarter of the volumetric rate at which a resting human body generates heat. Thus, reproduction of stellar core conditions in a lab for nuclear fusion power production is completely impractical. Because nuclear reaction rates depend on density as well as temperature, and most fusion schemes operate at relatively low densities, those methods are strongly dependent on higher temperatures. The fusion rate as a function of temperature (exp(\u2212\"E\"/\"kT\")), leads to the need to achieve temperatures in terrestrial reactors 10\u2013100 times higher than in stellar interiors: \"T\" \u2248 .\nCriteria and candidates for terrestrial reactions.\nIn artificial fusion, the primary fuel is not constrained to be protons and higher temperatures can be used, so reactions with larger cross-sections are chosen. Another concern is the production of neutrons, which activate the reactor structure radiologically, but also have the advantages of allowing volumetric extraction of the fusion energy and tritium breeding. Reactions that release no neutrons are referred to as \"aneutronic\".\nTo be a useful energy source, a fusion reaction must satisfy several criteria. It must:\nFew reactions meet these criteria. The following are those with the largest cross sections:\nFor reactions with two products, the energy is divided between them in inverse proportion to their masses, as shown. In most reactions with three products, the distribution of energy varies. For reactions that can result in more than one set of products, the branching ratios are given.\nSome reaction candidates can be eliminated at once. The D\u20136Li reaction has no advantage compared to p+\u2013[&lt;noinclude /&gt;[boron-11|B]&lt;noinclude /&gt;] because it is roughly as difficult to burn but produces substantially more neutrons through [&lt;noinclude /&gt;[deuterium|D]&lt;noinclude /&gt;]\u2013[&lt;noinclude /&gt;[deuterium|D]&lt;noinclude /&gt;] side reactions. There is also a p+\u2013[&lt;noinclude /&gt;[lithium-7|Li]&lt;noinclude /&gt;] reaction, but the cross section is far too low, except possibly when \"T\"\"i\" &gt; 1 MeV, but at such high temperatures an endothermic, direct neutron-producing reaction also becomes very significant. Finally there is also a p+\u2013[&lt;noinclude /&gt;[beryllium-9|Be]&lt;noinclude /&gt;] reaction, which is not only difficult to burn, but [&lt;noinclude /&gt;[beryllium-9|Be]&lt;noinclude /&gt;] can be easily induced to split into two alpha particles and a neutron.\nIn addition to the fusion reactions, the following reactions with neutrons are important in order to \"breed\" tritium in \"dry\" fusion bombs and some proposed fusion reactors:\nThe latter of the two equations was unknown when the U.S. conducted the Castle Bravo fusion bomb test in 1954. Being just the second fusion bomb ever tested (and the first to use lithium), the designers of the Castle Bravo \"Shrimp\" had understood the usefulness of 6Li in tritium production, but had failed to recognize that 7Li fission would greatly increase the yield of the bomb. While 7Li has a small neutron cross-section for low neutron energies, it has a higher cross section above 5 MeV. The 15 Mt yield was 150% greater than the predicted 6 Mt and caused unexpected exposure to fallout.\nTo evaluate the usefulness of these reactions, in addition to the reactants, the products, and the energy released, one needs to know something about the nuclear cross section. Any given fusion device has a maximum plasma pressure it can sustain, and an economical device would always operate near this maximum. Given this pressure, the largest fusion output is obtained when the temperature is chosen so that is a maximum. This is also the temperature at which the value of the triple product nT\u03c4 required for ignition is a minimum, since that required value is inversely proportional to (see Lawson criterion). (A plasma is \"ignited\" if the fusion reactions produce enough power to maintain the temperature without external heating.) This optimum temperature and the value of at that temperature is given for a few of these reactions in the following table.\nNote that many of the reactions form chains. For instance, a reactor fueled with T and He creates some D, which is then possible to use in the D\u2013He reaction if the energies are \"right\". An elegant idea is to combine the reactions (8) and (9). The He from reaction (8) can react with Li in reaction (9) before completely thermalizing. This produces an energetic proton, which in turn undergoes reaction (8) before thermalizing. Detailed analysis shows that this idea would not work well, but it is a good example of a case where the usual assumption of a Maxwellian plasma is not appropriate.\nNeutronicity, confinement requirement, and power density.\nAny of the reactions above can in principle be the basis of fusion power production. In addition to the temperature and cross section discussed above, we must consider the total energy of the fusion products \"E\"fus, the energy of the charged fusion products \"E\"ch, and the atomic number \"Z\" of the non-hydrogenic reactant.\nSpecification of the D\u2013D reaction entails some difficulties, though. To begin with, one must average over the two branches (2i) and (2ii). More difficult is to decide how to treat the T and He products. T burns so well in a deuterium plasma that it is almost impossible to extract from the plasma. The D\u2013He reaction is optimized at a much higher temperature, so the burnup at the optimum D\u2013D temperature may be low. Therefore, it seems reasonable to assume the T but not the He gets burned up and adds its energy to the net reaction, which means the total reaction would be the sum of (2i), (2ii), and (1):\n5 [&lt;noinclude /&gt;[deuterium|D]&lt;noinclude /&gt;] \u2192 [&lt;noinclude /&gt;[helium-4|He]&lt;noinclude /&gt;] + 2 n0 + [&lt;noinclude /&gt;[helium-3|He]&lt;noinclude /&gt;] + p+, \"E\"fus = 4.03 + 17.6 + 3.27 = 24.9\u00a0MeV, \"E\"ch = 4.03 + 3.5 + 0.82 = 8.35\u00a0MeV.\nFor calculating the power of a reactor (in which the reaction rate is determined by the D\u2013D step), we count the D\u2013D fusion energy \"per D\u2013D reaction\" as \"E\"fus = (4.03\u00a0MeV + 17.6\u00a0MeV) \u00d7 50% + (3.27\u00a0MeV) \u00d7 50% = 12.5\u00a0MeV and the energy in charged particles as \"E\"ch = (4.03\u00a0MeV + 3.5\u00a0MeV) \u00d7 50% + (0.82\u00a0MeV) \u00d7 50% = 4.2\u00a0MeV. (Note: if the tritium ion reacts with a deuteron while it still has a large kinetic energy, then the kinetic energy of the helium-4 produced may be quite different from 3.5 MeV, so this calculation of energy in charged particles is only an approximation of the average.) The amount of energy per deuteron consumed is 2/5 of this, or 5.0\u00a0MeV (a specific energy of about 225\u00a0million MJ per kilogram of deuterium).\nAnother unique aspect of the D\u2013D reaction is that there is only one reactant, which must be taken into account when calculating the reaction rate.\nWith this choice, we tabulate parameters for four of the most important reactions\nThe last column is the neutronicity of the reaction, the fraction of the fusion energy released as neutrons. This is an important indicator of the magnitude of the problems associated with neutrons like radiation damage, biological shielding, remote handling, and safety. For the first two reactions it is calculated as (\"E\"fus \u2212 \"E\"ch)/\"E\"fus. For the last two reactions, where this calculation would give zero, the values quoted are rough estimates based on side reactions that produce neutrons in a plasma in thermal equilibrium.\nOf course, the reactants should also be mixed in the optimal proportions. This is the case when each reactant ion plus its associated electrons accounts for half the pressure. Assuming that the total pressure is fixed, this means that particle density of the non-hydrogenic ion is smaller than that of the hydrogenic ion by a factor 2/(\"Z\" + 1). Therefore, the rate for these reactions is reduced by the same factor, on top of any differences in the values of . On the other hand, because the D\u2013D reaction has only one reactant, its rate is twice as high as when the fuel is divided between two different hydrogenic species, thus creating a more efficient reaction.\nThus there is a \"penalty\" of 2/(\"Z\" + 1) for non-hydrogenic fuels arising from the fact that they require more electrons, which take up pressure without participating in the fusion reaction. (It is usually a good assumption that the electron temperature will be nearly equal to the ion temperature. Some authors, however, discuss the possibility that the electrons could be maintained substantially colder than the ions. In such a case, known as a \"hot ion mode\", the \"penalty\" would not apply.) There is at the same time a \"bonus\" of a factor 2 for D\u2013D because each ion can react with any of the other ions, not just a fraction of them.\nWe can now compare these reactions in the following table.\nThe maximum value of is taken from a previous table. The \"penalty/bonus\" factor is that related to a non-hydrogenic reactant or a single-species reaction. The values in the column \"inverse reactivity\" are found by dividing by the product of the second and third columns. It indicates the factor by which the other reactions occur more slowly than the [&lt;noinclude /&gt;[deuterium|D]&lt;noinclude /&gt;]\u2013[&lt;noinclude /&gt;[tritium|T]&lt;noinclude /&gt;] reaction under comparable conditions. The column \"Lawson criterion\" weights these results with \"E\"ch and gives an indication of how much more difficult it is to achieve ignition with these reactions, relative to the difficulty for the [&lt;noinclude /&gt;[deuterium|D]&lt;noinclude /&gt;]\u2013[&lt;noinclude /&gt;[tritium|T]&lt;noinclude /&gt;] reaction. The next-to-last column is labeled \"power density\" and weights the practical reactivity by \"E\"fus. The final column indicates how much lower the fusion power density of the other reactions is compared to the [&lt;noinclude /&gt;[deuterium|D]&lt;noinclude /&gt;]\u2013[&lt;noinclude /&gt;[tritium|T]&lt;noinclude /&gt;] reaction and can be considered a measure of the economic potential.\nBremsstrahlung losses in quasineutral, isotropic plasmas.\nThe ions undergoing fusion in many systems will essentially never occur alone but will be mixed with electrons that in aggregate neutralize the ions' bulk electrical charge and form a plasma. The electrons will generally have a temperature comparable to or greater than that of the ions, so they will collide with the ions and emit x-ray radiation of 10\u201330 keV energy, a process known as Bremsstrahlung.\nThe huge size of the Sun and stars means that the x-rays produced in this process will not escape and will deposit their energy back into the plasma. They are said to be opaque to x-rays. But any terrestrial fusion reactor will be optically thin for x-rays of this energy range. X-rays are difficult to reflect but they are effectively absorbed (and converted into heat) in less than mm thickness of stainless steel (which is part of a reactor's shield). This means the bremsstrahlung process is carrying energy out of the plasma, cooling it.\nThe ratio of fusion power produced to x-ray radiation lost to walls is an important figure of merit. This ratio is generally maximized at a much higher temperature than that which maximizes the power density (see the previous subsection). The following table shows estimates of the optimum temperature and the power ratio at that temperature for several reactions:\nThe actual ratios of fusion to Bremsstrahlung power will likely be significantly lower for several reasons. For one, the calculation assumes that the energy of the fusion products is transmitted completely to the fuel ions, which then lose energy to the electrons by collisions, which in turn lose energy by Bremsstrahlung. However, because the fusion products move much faster than the fuel ions, they will give up a significant fraction of their energy directly to the electrons. Secondly, the ions in the plasma are assumed to be purely fuel ions. In practice, there will be a significant proportion of impurity ions, which will then lower the ratio. In particular, the fusion products themselves \"must\" remain in the plasma until they have given up their energy, and \"will\" remain for some time after that in any proposed confinement scheme. Finally, all channels of energy loss other than Bremsstrahlung have been neglected. The last two factors are related. On theoretical and experimental grounds, particle and energy confinement seem to be closely related. In a confinement scheme that does a good job of retaining energy, fusion products will build up. If the fusion products are efficiently ejected, then energy confinement will be poor, too.\nThe temperatures maximizing the fusion power compared to the Bremsstrahlung are in every case higher than the temperature that maximizes the power density and minimizes the required value of the fusion triple product. This will not change the optimum operating point for [&lt;noinclude /&gt;[deuterium|D]&lt;noinclude /&gt;]\u2013[&lt;noinclude /&gt;[tritium|T]&lt;noinclude /&gt;] very much because the Bremsstrahlung fraction is low, but it will push the other fuels into regimes where the power density relative to [&lt;noinclude /&gt;[deuterium|D]&lt;noinclude /&gt;]\u2013[&lt;noinclude /&gt;[tritium|T]&lt;noinclude /&gt;] is even lower and the required confinement even more difficult to achieve. For [&lt;noinclude /&gt;[deuterium|D]&lt;noinclude /&gt;]\u2013[&lt;noinclude /&gt;[deuterium|D]&lt;noinclude /&gt;] and [&lt;noinclude /&gt;[deuterium|D]&lt;noinclude /&gt;]\u2013[&lt;noinclude /&gt;[helium-3|He]&lt;noinclude /&gt;], Bremsstrahlung losses will be a serious, possibly prohibitive problem. For [&lt;noinclude /&gt;[helium-3|He]&lt;noinclude /&gt;]\u2013[&lt;noinclude /&gt;[helium-3|He]&lt;noinclude /&gt;], p+\u2013[&lt;noinclude /&gt;[lithium-6|Li]&lt;noinclude /&gt;] and p+\u2013[&lt;noinclude /&gt;[boron-11|B]&lt;noinclude /&gt;] the Bremsstrahlung losses appear to make a fusion reactor using these fuels with a quasineutral, isotropic plasma impossible. Some ways out of this dilemma have been considered but rejected. This limitation does not apply to non-neutral and anisotropic plasmas; however, these have their own challenges to contend with.\nMathematical description of cross section.\nFusion under classical physics.\nIn a classical picture, nuclei can be understood as hard spheres that repel each other through the Coulomb force but fuse once the two spheres come close enough for contact. Estimating the radius of an atomic nuclei as about one femtometer, the energy needed for fusion of two hydrogen is:\n formula_9\nThis would imply that for the core of the sun, which has a Boltzmann distribution with a temperature of around 1.4\u00a0keV, the probability hydrogen would reach the threshold is , that is, fusion would never occur. However, fusion in the sun does occur due to quantum mechanics.\nParameterization of cross section.\nThe probability that fusion occurs is greatly increased compared to the classical picture, thanks to the smearing of the effective radius as the de Broglie wavelength as well as quantum tunneling through the potential barrier. To determine the rate of fusion reactions, the value of most interest is the cross section, which describes the probability that particles will fuse by giving a characteristic area of interaction. An estimation of the fusion cross-sectional area is often broken into three pieces:\n formula_10\nwhere formula_11 is the geometric cross section, T is the barrier transparency and R is the reaction characteristics of the reaction.\nformula_11 is of the order of the square of the de Broglie wavelength formula_13 where formula_14 is the reduced mass of the system and formula_15 is the center of mass energy of the system.\nT can be approximated by the Gamow transparency, which has the form: formula_16 where formula_17 is the Gamow factor and comes from estimating the quantum tunneling probability through the potential barrier.\nR contains all the nuclear physics of the specific reaction and takes very different values depending on the nature of the interaction. However, for most reactions, the variation of formula_18 is small compared to the variation from the Gamow factor and so is approximated by a function called the astrophysical S-factor, formula_19, which is weakly varying in energy. Putting these dependencies together, one approximation for the fusion cross section as a function of energy takes the form:\n formula_20\nMore detailed forms of the cross-section can be derived through nuclear physics-based models and R-matrix theory.\nFormulas of fusion cross sections.\nThe Naval Research Lab's plasma physics formulary gives the total cross section in barns as a function of the energy (in keV) of the incident particle towards a target ion at rest fit by the formula:\n formula_21 with the following coefficient values:\nBosch-Hale also reports a R-matrix calculated cross sections fitting observation data with Pad\u00e9 rational approximating coefficients. With energy in units of keV and cross sections in units of millibarn, the factor has the form:\n formula_22, with the coefficient values: \nwhere formula_23\nMaxwell-averaged nuclear cross sections.\nIn fusion systems that are in thermal equilibrium, the particles are in a Maxwell\u2013Boltzmann distribution, meaning the particles have a range of energies centered around the plasma temperature. The sun, magnetically confined plasmas and inertial confinement fusion systems are well modeled to be in thermal equilibrium. In these cases, the value of interest is the fusion cross-section averaged across the Maxwell\u2013Boltzmann distribution. The Naval Research Lab's plasma physics formulary tabulates Maxwell averaged fusion cross sections reactivities in formula_24.\nFor energies formula_25 the data can be represented by:\n formula_26\n formula_27\nwith T in units of keV.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21550", "revid": "48523215", "url": "https://en.wikipedia.org/wiki?curid=21550", "title": "National Geographic Society", "text": "American scientific organization\nThe National Geographic Society, headquartered in Washington, D.C., United States, is one of the largest nonprofit scientific and educational organizations in the world.\nFounded in 1888, its interests include geography, archaeology, natural science, the promotion of environmental and historical conservation, and the study of world culture and history. The National Geographic Society's logo is a yellow portrait frame\u2014rectangular in shape\u2014which appears on the margins surrounding the front covers of its magazines and as its television channel logo. Through National Geographic Partners (a joint venture with The Walt Disney Company), the Society operates the magazine, TV channels, a website, worldwide events, and other media operations.\nOverview.\nThe National Geographic Society was founded on January 13, 1888 \"to increase and diffuse geographic knowledge\". It is governed by a board of trustees whose 33 members include distinguished educators, business executives, former government officials and conservationists. The organization sponsors and funds scientific research and exploration. National Geographic maintains a museum for the public in its Washington, D.C., headquarters.\nIt has helped to sponsor popular traveling exhibits, such as the early 2010s \"King Tut\" exhibit featuring artifacts from the tomb of the young Egyptian Pharaoh. The Education Foundation gives grants to education organizations and individuals to improve geography education. The Committee for Research and Exploration has awarded more than 11,000 grants for scientific research and exploration.\nNational Geographic has retail stores in Washington, D.C., London, Sydney, and Panama. The locations outside of the United States are operated by Worldwide Retail Store S.L., a Spanish holding company.\nThe Society's media arm is National Geographic Partners, a joint venture between The Walt Disney Company and the Society, which publishes a journal, \"National Geographic\" in English and nearly 40 local-language editions. It also publishes other magazines, books, school products, maps, and Web and film products in numerous languages and countries. National Geographic's various media properties reach more than 280 million people monthly. Its efforts are supported by a wide range of individual, charitable, governmental and corporate donors, including the Leonardo DiCaprio Foundation, Gates Foundation, Lockheed Martin, Pfizer, National Endowment for the Humanities and many others.\nHistory.\nThe National Geographic Society began as a club for an elite group of academics and wealthy patrons interested in travel and exploration. On January 13, 1888, 33 explorers and scientists gathered at the Cosmos Club, a private club then located on Lafayette Square in Washington, D.C., to organize \"a society for the increase and diffusion of geographical knowledge.\" After preparing a constitution and a plan of organization, the National Geographic Society was incorporated two weeks later on January 27. Gardiner Greene Hubbard (co-founder of AT&amp;T) became its first president and his son-in-law, Alexander Graham Bell (also co-founder of AT&amp;T), succeeded him in 1897.\nIn 1899, Bell's son-in-law Gilbert Hovey Grosvenor was named the first full-time editor of National Geographic magazine and eventually elected as the President of the society in 1920. Grosvenor resigned as editor and president in 1954 and served as chairman of the organization's board until his death in 1966. Members of the Grosvenor family have played important roles in the organization since. Bell and Gilbert Hovey Grosvenor devised the successful marketing notion of Society membership and the first major use of photographs to tell stories in magazines.\nThe chairman of the National Geographic Society currently is Jean Case. Michael Ulica is president. Jill Tiefenthaler is the chief executive officer. The editor-in-chief of National Geographic magazine is Susan Goldberg. Gilbert Melville Grosvenor, a former chairman, received the Presidential Medal of Freedom in 2005 for his leadership in geography education.\nIn 2004, the National Geographic Society Headquarters in Washington, D.C., was one of the first buildings to receive a \"Green\" certification from Global Green USA. The National Geographic received the prestigious Prince of Asturias Award for Communication and Humanities in October 2006 in Oviedo, Spain.\nNational Geographic Expeditions was launched in 1999 to fulfill one of its missions and for the proceeds to go towards its mission.\nIn 2006, the society purchased \"Hampton-Brown\", an English-as-a-second-language educational material publisher, using a good part of its endowments. However, the publisher did not generate much profit. By 2009, the society's endowments were about $200 million.\nNational Geographic Ventures, its commercial arm, launched a music division, National Geographic Music and Radio, in 2007. The society formed in October 2007 National Geographic Entertainment division to include its entertainment units.\nIn 2013, the society was investigated for possible violation of the Foreign Corrupt Practices Act relating to their close association with an Egyptian government official responsible for antiquities.\nOn September 9, 2015, the Society announced that it would re-organize its media properties and publications into a new company known as National Geographic Partners, which would be majority-owned by 21st Century Fox (21CF) with a 73% stake. This new, for-profit corporation, would own \"National Geographic\" and other magazines, as well as its affiliated television networks\u2014most of which were already owned in joint ventures with 21CF. As a consequence, the Society and 21st Century Fox announced on November 2, 2015, that 9 percent of National Geographic's 2,000 employees, approximately 180 people, would be laid off, constituting the biggest staff reduction in the Society's history. Later, The Walt Disney Company assumed 21CF's share in National Geographic Partners, following the completion of Disney's acquisition of most of 21CF assets on March 20, 2019. On June 29, 2023, National Geographic laid off the remaining staff writers for their magazine and announced their publications would no longer be sold at physical newsstands in the United States in 2024. In a statement to the press, a spokesperson for the society said that the company will continue to publish a monthly magazine \"dedicated to exceptional multi-platform storytelling with cultural impact\" through the work of freelance writers and the few remaining editors on staff.\nList of original founders.\nThe 33 original founders of the National Geographic Society in 1888:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nAlthough Alexander Graham Bell is sometimes discussed as a founder, he was actually the second president, elected on January 7, 1898, and serving until 1903.\nActivities.\nSupport for research and projects.\nThe Society has helped sponsor many expeditions and research projects over the years.\nAwards.\nHubbard Medal.\nThe Hubbard Medal is awarded by the National Geographic Society for distinction in exploration, discovery, and research. The medal is named for Gardiner Greene Hubbard, the first National Geographic Society president. The Hubbard Medal has been presented 44 times as of 2018[ [update]], the most recent award going to Peter H. Raven.\nAlexander Graham Bell Medal.\nThe National Geographic Society also awards, rarely, the Alexander Graham Bell Medal, for exceptional contributions to geographic research. The award is named after Alexander Graham Bell, scientist, inventor of the telephone and the second president of the NGS. Up to mid-2011, the medal has been twice presented:\nNational Geographic Museum.\nThe Society operates the National Geographic Museum, located at 1145 17th Street, NW (17th and M), in Washington, D.C. The museum features changing exhibitions featuring the work of National Geographic explorers, photographers, and scientists. There are also changing exhibits related to natural history, culture, history or society. Permanent exhibits include artifacts like the camera Robert Peary used at the North Pole and pottery that Jacques Cousteau recovered from a shipwreck.\nNational Geographic Explorers program.\nThe NGS names individuals as \"Explorers\" for \"exceptional individuals in their fields who receive funding and support from the Society to illuminate and protect our world through their work in science, exploration, education, and storytelling.\" They consist of scientists or content producers, such as photographers and filmmakers.\nCommercial ventures.\nNational Geographic Partners, a for-profit joint venture between The Walt Disney Company (which owns a 73% stake) and the Society (which owns 27%), was established in 2015 to handle commercial activities of the Society, including television channels worldwide (which were already co-owned by the Society and Fox) and magazine publications. The Walt Disney Company assumed 21CF's share of National Geographic Partners in March 2019.\nMost of National Geographic Partners' businesses predate the establishment in 2015, and even the launch of National Geographic Channel in Asia and Europe by the original News Corporation (of which 21st Century Fox is one of the successors) in the late 1990s.\nThe society formed in October 2007 National Geographic Entertainment division to include Cinema Ventures, Feature Films, Kids Entertainment, Home Entertainment and Music &amp; Radio divisions. Music and Radio division president David Beal was appointed head of Nat Geo Entertainment.\nPublications.\n\"National Geographic\".\n\"The National Geographic Magazine\", later shortened to \"National Geographic\", published its first issue in October 1888, nine months after the Society was founded, as the Society's official journal, a benefit for joining the tax-exempt National Geographic Society. Starting with the February 1910 (Vol XXI, No. 2) issue, the magazine began using its now famous trademarked yellow border around the edge of its covers.\nThere are 12 monthly issues of \"National Geographic\" per year. The magazine contains articles about geography, popular science, world history, culture, current events and photography of places and things all over the world and universe. \"National Geographic\" magazine is currently published in 40 local-language editions in many countries around the world. Combined English and other language circulation is around 6.8 million monthly, with some 60 million readers. The Society has held a minority interest in the magazine since 2015.\nOther publications.\nIn addition to its flagship magazine, the Society publishes several other periodicals:\nThe Society also ran an online daily news outlet called \"National Geographic News\".\nAdditionally, the Society publishes atlases, books, and maps through National Geographic Books and National Geographic Maps, commercial publishing divisions of National Geographic Partners. It previously published and co-published other magazines, including \"National Geographic Adventure\", \"National Geographic Research\" (a scientific journal), and others, and continues to publish special issues of various magazines.\nThe Society published a series of books about natural remedies and medicinal herbs. Titles include \"Guide to Medicinal Herbs,\" \"Complete Guide to Natural Home Remedies,\" \"Nature's Best Remedies,\" \"Healing Remedies,\" and \"Natural Home Remedies.\" The books make claims to describe, among other things, plants, herbs, and essential oils purported to help treat diseases and ailments. While giving some appropriate warnings about such concerns as anecdotal evidence and side effects are given, the books have been criticized from a medical perspective for a number of reasons. These include making recommendations that lack scientific evidence, inconsistent claims from one book to the next as well as internal contradictions, and failure to mention effective and safe alternatives. The journal \"Skeptical Inquirer\" devoted thirty-four pages in 2019 discussing these books. Experts such as Harriet Hall, Joe Nickell, Cees Renckens and Barry Kosmin addressed each subject in the series of books. Summing up the series, Hall wrote in a review of the series that, \"The author Nancy J. Hajeski is a fiction and nonfiction writer with no medical or scientific credentials. The forward is by Tieraona Low Dog, MD, an integrative medicine specialist. ... which is a marketing term designed to infiltrate quackery into science-based medicine.\"\nFilms and television.\nNational Geographic Films.\nNational Geographic Films was a wholly owned taxable subsidiary of the National Geographic Society.\nNational Geographic Films appointed Adam Leipzig as president in 2004. The society formed in October 2007 National Geographic Entertainment division to include Cinema Ventures and Feature Films. In 2008, the film division and Image Nation formed a $100 million fund to develop, produce, finance and acquire over five years 10\u201315 films. The first film the fund invested in was \"The Way Back\".\nLeipzig left the company in January 2010. On March 15, 2010, former Miramax president Daniel Battsek started as National Geographic Films president. Basttsek ended up also over seeing Nat Geo Cinema Ventures distribution and big screen production before he left in 2012 becoming president of Cohen Media Group.\nFilms it has produced include:\nIn 2005, the National Geographic Society acquired the film distribution arm of Destination Cinema and entered the film distribution business.\nDuring the COVID-19 pandemic, National Geographic partnered with pharmaceutical company Pfizer to produce a sponsored documentary chronicling the development of Pfizer and BioNTech's COVID-19 vaccine.\nCinema Ventures.\nNational Geographic Cinema Ventures (NGCV) was a giant-screen, 3D and specialty films production and distribution company operated under National Geographic Entertainment.\nAt the late 2011 American Alliance of Museums conference, National Geographic Cinema Ventures launched the Museum Partnership Program as museums want a brand for their giant screen theaters. Starting on February 1, 2018, Cosmic Pictures gained distribution rights to a number of the NGCV library.\nMuseum Partnership Program.\nThe Museum Partnership Program is the branding and content program of National Geographic Cinema Ventures. Partner museums would receive immediate market exclusivity on their 2 new digital 3D films per year and gain access to the National Geographic organization from members to exhibition to television.\nThere were nine partner museums as of 2012:\nTelevision programs.\nTelevision programs produced by the National Geographic Society are also broadcast on television. National Geographic television specials and series have been aired on PBS and other networks in the United States and globally for many years. The \"Geographic\" series in the U.S. started on CBS in 1964, moved to ABC in 1973, shifted to PBS (produced by WQED, Pittsburgh) in 1975, shifted to NBC in 1995, and returned to PBS in 2000. It moved to National Geographic Channel in 2005.\nIt has featured stories on numerous scientific figures such as Jacques Cousteau, Jane Goodall, and Louis Leakey that not only featured their work but as well helped make them world-famous and accessible to millions. Most of the specials were narrated by various actors, including Glenn Close, Linda Hunt, Stacy Keach, Richard Kiley, Burgess Meredith, Susan Sarandon, Alexander Scourby, Martin Sheen, and Peter Strauss. The specials' theme music, by Elmer Bernstein, was also adopted by the National Geographic Channel.\nAnother long-running show is \"National Geographic Explorer\".\nTelevision channels.\nThe original News Corporation launched National Geographic Channel in Asia and Europe in the late 1990s, in partnership with the Society. The Society provides programming to the National Geographic-branded channels worldwide, while, as of March 2019, The Walt Disney Company's subsidiaries (Walt Disney Television in the United States and Fox Networks Group outside the United States) handle distribution of the channels and advertisement sales. The National Geographic Channel has begun to launch a number of sub-branded channels in international markets, such as Nat Geo Wild, Nat Geo People and Nat Geo Kids.\nThe U.S. domestic version of National Geographic Channel was launched in January 2001 as a joint venture of National Geographic and Fox Cable Networks.\nMusic and radio.\nNational Geographic Music and Radio (NGMR) is the music and radio division of National Geographic Ventures. The scope of the division includes National Geographic Live! events, digital music distribution, music publishing, radio content, Nat Geo Music TV channel (closed; formerly available in parts of Asia and Europe) and film and TV music. Clear Channel, Salem Communications and NPR were distribution partners.\nIn early August 2007, National Geographic Ventures announced the existence of the then-recently formed division. The division was already creating music for its feature film and kids units. Initially hired to run the division were Mark Bauman, executive vice president of radio and video production, and David Beal, head of music labels, publishing and radio operations. With National Geographic Channels, Music and Radio on October 15, 2007, launched the Nat Geo Music channel in Italy.\nThe society formed in October 2007 National Geographic Entertainment division to include the Music &amp; Radio division and promoted the division president David Beal was appointed head of Nat Geo Entertainment. In 2009, the division became a full-service record label as Nat Geo Music with Mat Whittington appointed as president.\nMore recently, NGMR has leaned into the digital landscape with the rise of streaming services, maintaining an active presence on platforms such as Spotify, Apple Music and YouTube, showcasing soundtracks, artist collaborations, and music related to National Geographic\u2019s programming.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21551", "revid": "196471", "url": "https://en.wikipedia.org/wiki?curid=21551", "title": "NP-complete problem", "text": ""}
{"id": "21555", "revid": "3113", "url": "https://en.wikipedia.org/wiki?curid=21555", "title": "Nonstandard real numbers", "text": ""}
{"id": "21556", "revid": "1319281647", "url": "https://en.wikipedia.org/wiki?curid=21556", "title": "Norns", "text": "Group of deities in Norse mythology\nThe Norns ( , plural: ) are a group of deities in Norse mythology responsible for shaping the course of human destinies.\nThe Norns are often represented as three goddesses known as Ur\u00f0r, Ver\u00f0andi, and Skuld, who weave the threads of fate and tend to the world tree, Yggdrasil, ensuring it stays alive at the center of the cosmos.\nEtymology.\nThe origin of the name is uncertain; it may derive from a word meaning 'to twine', which would refer to their twining the thread of fate. Bek-Pedersen suggests that the word has relation to the Swedish dialect word (), a verb that means 'communicate secretly'. This interpretation relates to the perception of norns as shadowy, background figures who only really ever reveal their fateful secrets to people as their fates come to pass.\nThe name (Old English: , 'weird') means 'fate'. and are etymological cognates, a situation that does not mean necessarily that and share the same semantic quality of \"fate\" over time. Both and are derived from the Old Norse verb , 'to become', which itself derives from Proto-Germanic \"*wurdiz\", from Proto-Indo-European \"*wrti-\", which is a verbal abstract from the root \"*wert-\" (\"to turn\") Often, it is asserted that while derives from the past tense ('that which became or happened'), derives from the present tense of ('that which is happening'). is derived from the Old Norse verb , \"need/ought to be/shall be\"; its meaning is \"that which should become, or that needs to occur\". Due to this, it has often been inferred that the three norns are in some way connected with the past, present and future respectively, but it has been disputed that their names really imply a temporal distinction. It has been emphasised that the words do not in their own right denote chronological periods in Old Norse but rather the idea of past, present, and future in terms of fate itself.\nRelation to other Germanic female deities.\nThere is no clear distinction between norns, fylgjas, hamingjas, and valkyries, nor with the generic term d\u00edsir. Moreover, artistic license permitted such terms to be used for mortal women in Old Norse poetry. To quote Snorri Sturluson's \"Sk\u00e1ldskaparm\u00e1l\" on the various names used for women:\nWoman is also metaphorically called by the names of the Asynjur or the Valkyrs or Norns or women of supernatural kind.\nAttestations.\nThere are a number of surviving Old Norse sources that relate to the norns. The most important sources are the Prose Edda and the Poetic Edda. The latter contains pagan poetry where the Norns are frequently referred to, while the former contains pagan poetry as well as retellings, descriptions and commentaries by the 12th and 13th century Icelandic chieftain and scholar Snorri Sturluson.\nSkaldic poetry.\nA skaldic reference to the norns appears in Hvini's poem in \"Ynglingatal\" 24 found in \"Ynglingasaga\" 47, where King Halfdan is put to rest by his men at Borr\u00f3. This reference brings in the phrase \"norna d\u00f3mr\" which means \"judgment of the nornir\". In most cases, when the norns pass judgment, it means death to those who have been judged - in this case, Halfdan. Along with being associated with being bringers of death, Bek-Pedersen suggests that this phrase brings in a quasi-legal aspect to the nature of the norns. This legal association is employed quite frequently within skaldic and eddic sources. This phrase can also be seen as a threat, as death is the final and inevitable decision that the norns can make with regard to human life.\nPoetic Edda.\nThe Poetic Edda is valuable in representing older material in poetry from which Snorri Sturluson tapped information in the \"Prose Edda\". Like \"Gylfaginning\", the \"Poetic Edda\" mentions the existence of many lesser norns beside the three main norns. Moreover, it also agrees with \"Gylfaginning\" by telling that they were of several races and that the dwarven norns were the daughters of Dvalin. It also suggests that the three main norns were giantesses (female Jotuns).\n\"F\u00e1fnism\u00e1l\" contains a discussion between the hero Sigurd and the dragon Fafnir who is dying from a mortal wound from Sigurd. The hero asks Fafnir of many things, among them the nature of the norns. Fafnir explains that they are many and from several races:\nIt appears from \"V\u00f6lusp\u00e1\" and \"Vaf\u00fer\u00fa\u00f0nism\u00e1l\" that the three main norns were not originally goddesses but giants (Jotuns), and that their arrival ended the early days of bliss for the gods, but that they come for the good of humankind.\n\"V\u00f6lusp\u00e1\" relates that three giants of huge might are reported to have arrived to the gods from Jotunheim:\n\"Vaf\u00fer\u00fa\u00f0nism\u00e1l\" probably refers to the norns when it talks of maiden giants who arrive to protect the people of Earth as protective spirits (hamingjas):\nThe \"V\u00f6lusp\u00e1\" contains the names of the three main Norns referring to them as maidens like \"Vaf\u00fer\u00fa\u00f0nism\u00e1l\" probably does:\n\"Helgakvi\u00f0a Hundingsbana I\".\nThe norns visited each newly born child to allot his or her future, and in \"Helgakvi\u00f0a Hundingsbana I\", the hero Helgi Hundingsbane has just been born and norns arrive at the homestead:\n\"Helgakvi\u00f0a Hundingsbana II\".\nIn \"Helgakvi\u00f0a Hundingsbana II\", Helgi Hundingsbane blames the norns for the fact that he had to kill Sigr\u00fan's father H\u00f6gni and brother Bragi in order to wed her:\n\"Reginsm\u00e1l\".\nAs Snorri Sturluson stated in \"Gylfaginning\", one's fate depended on the Norn's good or bad will. In \"Reginsm\u00e1l\", the water dwelling dwarf Andvari blames his plight on an evil norn, presumably one of the daughters of Dvalin:\n\"Sigur\u00f0arkvi\u00f0a hin skamma\".\nAnother account blaming the Norns for misfortune occurs in \"Sigur\u00f0arkvi\u00f0a hin skamma\", where the valkyrie Brynhild blames malevolent Norns for her yearning for the embrace of Sigurd:\n\"Gu\u00f0r\u00fanarkvi\u00f0a II\".\nIn \"Gu\u00f0r\u00fanarkvi\u00f0a II\", the Norns actively enter the series of events by informing Atli in a dream that his wife would kill him. Brynhild's solution was to have Gunnarr and his brothers, the lords of the Burgundians, kill Sigurd and afterwards to commit suicide in order to join Sigurd in the afterlife. Her brother Atli (Attila the Hun) avenged her death by killing the lords of the Burgundians, but since he was married to their sister Gu\u00f0r\u00fan, Atli would soon be killed by her. The description of the dream begins with this stanza:\n\"Gu\u00f0r\u00fanarhv\u00f6t\".\nIn Gu\u00f0r\u00fanarhv\u00f6t, after having killed both her husband and son, Gu\u00f0r\u00fan blames the Norns themselves for her misfortune. In this excerpt Gu\u00f0r\u00fan talks of trying to escaping the wrath of the Norns by making an attempt on her own life, attempting to escape the fate they had woven for her:\n\"Ham\u00f0ism\u00e1l\".\n\"Gu\u00f0r\u00fanarhv\u00f6t\" deals with how Gu\u00f0r\u00fan incited her sons to avenge the cruel death of their sister Svanhild. In \"Ham\u00f0ism\u00e1l\", her sons' expedition to the Gothic King Ermanaric to exact vengeance. Knowing that he is about to die at the hands of the Goths, her son S\u00f6rli talks of the cruelty of the norns:\n\"Sigrdr\u00edfum\u00e1l\".\nThe Norns were known as beings of ultimate power who worked in the dark and were often referred to in charms, as they are by Sigrdr\u00edfa in \"Sigrdr\u00edfum\u00e1l\":\n\"Prose Edda\".\nIn the part of Snorri Sturluson's \"Prose Edda\" which is called \"Gylfaginning\", Gylfi, the king of Sweden, has arrived at Valhalla calling himself Gangleri. There, he receives an education in Norse mythology from what is Odin in the shape of three men. They explain to Gylfi that there are three primary Norns, but also many others of various races, \u00e6sir, elves and dwarves:\nA hall stands there, fair, under the ash by the well, and out of that hall come three maids, who are called thus: Urdr, Verdandi, Skuld; these maids determine the period of men's lives: we call them Norns; but there are many norns: those who come to each child that is born, to appoint his life; these are of the race of the gods, but the second are of the Elf-people, and the third are of the kindred of the dwarves, as it is said here:\nMost sundered in birth\nI say the Norns are;\nThey claim no common kin:\nSome are of \u00c6sir-kin,\nsome are of Elf-kind,\nSome are Dvalinn's daughters.\nThen said Gangleri: \"If the Norns determine the weirds of men, then they apportion exceeding unevenly, seeing that some have a pleasant and luxurious life, but others have little worldly goods or fame; some have long life, others short.\" H\u00e1rr said: \"Good norns and of honorable race appoint good life; but those men that suffer evil fortunes are governed by evil norns.\"\nThe three main norns take water out of the well of Urd and water Yggdrasil:\nIt is further said that these Norns who dwell by the Well of Urdr take water of the well every day, and with it that clay which lies about the well, and sprinkle it over the Ash, to the end that its limbs shall not wither nor rot; for that water is so holy that all things which come there into the well become as white as the film which lies within the egg-shell,--as is here said:\nI know an Ash standing\ncalled Yggdrasill,\nA high tree sprinkled\nwith snow-white clay;\nThence come the dews\nin the dale that fall--\nIt stands ever green\nabove Urdr's Well.\nThat dew which falls from it onto the earth is called by men honey-dew, and thereon are bees nourished. Two fowls are fed in Urdr's Well: they are called Swans, and from those fowls has come the race of birds which is so called.\"\nSnorri Sturluson furthermore informs the reader that the Norn of present, Skuld, is also a valkyrie, taking part in the selection of warriors from the slain:\nThese are called Valkyrs: them Odin sends to every battle; they determine men's feyness and award victory. Gudr and R\u00f3ta and the youngest Norn, she who is called Skuld, ride ever to take the slain and decide fights.\nLegendary sagas.\nSome of the legendary sagas also contain references to the Norns. The \"Hervarar saga\" contains a poem named \"Hl\u00f6\u00f0skvi\u00f0a\", where the Gothic king Angant\u00fdr defeats a Hunnish invasion led by his Hunnish half-brother Hl\u00f6\u00f0r. Knowing that his sister, the shieldmaiden Herv\u00f6r, is one of the casualties, Angant\u00fdr looks at his dead brother and laments the cruelty of the Norns:\nIn younger legendary sagas, such as \"Norna-Gests \u00fe\u00e1ttr\" and \"Hr\u00f3lfs saga kraka\", the Norns appear to have been synonymous with v\u00f6lvas (witches, female shamans). In \"Norna-Gests \u00fe\u00e1ttr\", where they arrive at the birth of the hero to shape his destiny, the Norns are not described as weaving the web of fate, instead \"Norna\" appears to be interchangeable and possibly a synonym of \"vala\" (v\u00f6lva).\nOne of the last legendary sagas to be written down, the \"Hr\u00f3lfs saga kraka\" references the Norns as evil witches. When the malevolent half-elven princess Skuld assembles her army to attack Hr\u00f3lfr Kraki, it contains in addition to undead warriors, elves and Norns.\nRunic inscription N 351 M.\nRunic inscription N 351 M from the Borgund stave church attests to the belief in the Norns as bringers of both gain and loss after the Christianisation of Scandinavia, reading:\n\u00de\u00f3rir carved these runes on the eve of Olaus-mass, when he travelled past here. The norns did both good and evil, great toil ... they created for me.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral and cited references.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21557", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=21557", "title": "Niflheim", "text": "Realm of primordial ice and cold in Norse mythology\nIn Norse cosmology, Niflheim or Niflheimr (Old Norse: ; \"World of Mist\", literally \"Home of Mist\") is a location which sometimes overlaps with the notions of Niflhel and Hel. The name \"Niflheimr\" appears only in two extant sources: \"Gylfaginning\" and the much-debated \"Hrafnagaldr \u00d3\u00f0ins\".\nNiflheim was primarily a realm of primordial ice and cold, with the frozen rivers of \u00c9liv\u00e1gar and the well of Hvergelmir, from which come all the rivers.\nAccording to \"Gylfaginning\", Niflheim was the first of the two primordial realms to emanate out of Ginnungagap, the other one being Muspelheim, the realm of fire. Between these two realms of cold and heat, creation began when its waters mixed with the heat of Muspelheim to form a \"creating steam\". Later, it became the abode of Hel, a goddess daughter of Loki, and the afterlife for her subjects, those who did not die a heroic or notable death.\nEtymology.\n\"Nifl\" (\"mist\"; whence the Icelandic \"nifl\") is a cognate to the Old English \"nifol\" (\"dark, gloomy\"), (Middle) Dutch \"nevel\", Old High German \"nebul\" (\"fog\") and Ancient Greek \"\u03bd\u03b5\u03c6\u03ad\u03bb\u03b7\", , (\"cloud\").\n\"Gylfaginning\".\nIn \"Gylfaginning\" by Snorri Sturluson, Gylfi, the king of ancient Scandinavia, receives an education in Norse mythology from Odin in the guise of three men. Gylfi learns from Odin (as \"Jafnh\u00e1rr\") that Niflheimr was the first world to be created after Muspelheim:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It was many ages before the earth was shaped that the Mist-World [Niflheimr] was made; and midmost within it lies the well that is called Hvergelmir, from which spring the rivers called Sv\u00f6l, Gunnthr\u00e1, Fj\u00f6rm, Fimbulthul, Sl\u00eddr and Hr\u00edd, Sylgr and Ylgr, V\u00edd, Leiptr; Gj\u00f6ll is hard by Hel-gates.\nOdin (as \"\u00deri\u00f0i\") further tells Gylfi that it was when the ice from Niflheimr met the flames from Muspelheimr that creation began and Ymir was formed:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Just as cold arose out of Niflheim, and all terrible things, so also all that looked toward M\u00faspellheim became hot and glowing; but Ginnungagap was as mild as windless air, and when the breath of heat met the rime, so that it melted and dripped, life was quickened from the yeast-drops, by the power of that which sent the heat, and became a man's form. And that man is named Ymir, but the Rime-Giants call him Aurgelmir; ...\nIn relation to the world tree Yggdrasill, \"Jafnh\u00e1rr\" (Odin) tells Gylfi that frost j\u00f6tnar is located under the second root, where Ginnungagap (\"Yawning Void\") once was:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Ash is greatest of all trees and best: its limbs spread out over all the world and stand above heaven. Three roots of the tree uphold it and stand exceeding broad: one is among the \u00c6sir; another among the Rime-Giants, in that place where aforetime was the Yawning Void; the third stands over Niflheim, and under that root is Hvergelmir, and N\u00eddh\u00f6ggr gnaws the root from below.\nGylfi is furthermore informed that when Loki had engendered Hel, she was cast into Niflheimr by Odin:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Hel he cast into Niflheim, and gave to her power over nine worlds, to apportion all abodes among those that were sent to her: that is, men dead of sickness or of old age. She has great possessions there; her walls are exceeding high and her gates great.\nHel thus became the mistress of the world of those dead in disease and old age. This is the only instance in which Niflheim and Hel are equated (the Poetic Edda mentions Hel but doesn't say anything about Niflheim).\nHowever, there is some confusion in the different versions of the manuscript, with some of them saying Niflheim where others say Niflhel (the lowest level of Hel). Thus in the passage about the last destination of the \"j\u00f6tunn\" who was killed by Thor after he had built Asgard:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Now that the \u00c6sir saw surely that the hill-giant was come thither, they did not regard their oaths reverently, but called on Thor, who came as quickly. And straightway the hammer Mj\u00f6llnir was raised aloft; he paid the wright's wage, and not with the sun and the moon. Nay, he even denied him dwelling in J\u00f6tunheim, and struck but the one first blow, so that his skull was burst into small crumbs, and sent him down below under Niflhel [Niflheim].\n\"Hrafnagaldr \u00d3\u00f0ins\".\nIn \"Hrafnagaldr \u00d3\u00f0ins\", there is a brief mention of Niflheimr as a location in the North, towards which the sun (Alfr's illuminator) chased the night as it rose:\nNotes and references.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21558", "revid": "47179870", "url": "https://en.wikipedia.org/wiki?curid=21558", "title": "Nanna", "text": "Nanna may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "21559", "revid": "50079837", "url": "https://en.wikipedia.org/wiki?curid=21559", "title": "Nasdaq", "text": "American stock exchange\nNasdaq Stock Market (National Association of Securities Dealers Automated Quotations) is an American stock exchange, the second-largest by market cap on the list of stock exchanges, and the first fully electronic stock market. The exchange is based in Manhattan, New York City and is the most active stock trading venue in the U.S. by volume.\nThe exchange platform is owned by Nasdaq, Inc., which also owns the Nasdaq Nordic stock market network and several U.S.-based stock and options exchanges. The exchange is the primary listing for many technology companies and also trades stock in many foreign firms, with China and Israel being the largest foreign sources.\nAs of December 31, 2024, 4,075 companies listed securities on Nasdaq, including 1,383 listings on The Nasdaq Global Select Market, 1,366 on The Nasdaq Global Market, and 1,326 on The Nasdaq Capital Market.\nThe Nasdaq Composite, Nasdaq-100, Nasdaq Financial-100 stock market indices are made up only of stocks listed on the Nasdaq.\nHistory.\n1972\u20132000.\nFounding and Origins.\nNasdaq, Inc. was founded in 1971 by the National Association of Securities Dealers (NASD), now known as the Financial Industry Regulatory Authority (FINRA). \"Nasdaq\" (originally and still commonly spelled with all-capital letters as \"NASDAQ\") is an acronym for \"National Association of Securities Dealers Automated Quotations\". On February 8, 1971, the Nasdaq Stock Market commenced operations as the world's first fully electronic stock market. Initially, Nasdaq served as a \"quotation system\" rather than a platform for electronic trading. Intel Corporation was one of the first major corporations to list its shares on Nasdaq; other major companies that have been listed on Nasdaq since its early years include Comcast and Applied Materials.\nMarket Growth.\nSince the launch of Nasdaq, many major companies trading on the over-the-counter (OTC) market began switching to Nasdaq. As late as 1987, the Nasdaq exchange was still commonly referred to as \"OTC\" in media reports and also in the monthly Stock Guides issued by Standard &amp; Poor's Corporation. Over the years, it became more of a stock market with the addition of trade and volume reporting and automated trading systems. In 1981, Nasdaq traded 37% of the U.S. securities markets' total of 21\u00a0billion shares. By 1991, Nasdaq's share had grown to 46%. In 1992, the Nasdaq Stock Market joined with the London Stock Exchange to form the first intercontinental linkage of capital markets.\nIn 1996, the SEC issued a report alleging that Nasdaq market makers fixed prices by avoiding \"odd-eighths\" quotes (at the time, stock prices were quoted in increments of an eighth of a dollar) to artificially widen spreads. The report was followed by a new set of rules for how Nasdaq handled orders.\nOnline Trading.\nIn 1998, it became the first stock market in the United States to trade online, using the slogan \"the stock market for the next hundred years\". The Nasdaq Stock Market attracted many companies during the dot-com bubble.\n2000\u20132020.\nPublic listing and market change.\nIn a series of sales in 2000 and 2001, FINRA sold its stake in the Nasdaq. On July 2, 2002, Nasdaq, Inc. became a public company via an initial public offering, listing its own shares on the exchange (traded under the ticker symbol NDAQ). In 2006, the status of the NASDAQ Stock Market was changed from a stock market to a licensed national securities exchange. In 2007, it merged with OMX, a leading exchange operator in the Nordic countries, expanded its global footprint, and changed its name to the Nasdaq OMX Group.\nTo qualify for listing on the exchange, a company must be registered with the United States Securities and Exchange Commission (SEC), must have at least three market makers (financial firms that act as brokers or dealers for specific securities) and must meet minimum requirements for assets, capital, public shares, and shareholders.\nIn 2011, after an announced merger of NYSE Euronext with , Nasdaq partnered with Intercontinental Exchange to launch a rival bid, but the bid was withdrawn on regulatory concerns.\nAcquisitions.\nIn December 2005, Nasdaq acquired Instinet for $1.9\u00a0billion, retaining the Inet ECN and subsequently selling the agency brokerage business to Silver Lake Partners and Instinet management.\nThe European Association of Securities Dealers Automatic Quotation System (EASDAQ) was founded as a European equivalent to the Nasdaq Stock Market. It was purchased by NASDAQ in 2001 and became NASDAQ Europe. In 2003, operations were shut down as a result of the burst of the dot-com bubble. In 2007, Nasdaq Europe was revived first as Equiduct and was acquired by B\u00f6rse Berlin later that year.\nOn November 7, 2007, Nasdaq acquired the Philadelphia Stock Exchange, the oldest stock exchange in the U.S.\nSustainability and leadership milestones.\nOn June 18, 2012, Nasdaq OMX became a founding member of the United Nations Sustainable Stock Exchanges Initiative on the eve of the United Nations Conference on Sustainable Development (Rio+20).\nIn November 2016, chief operating officer Adena Friedman was promoted to chief executive officer, becoming the first woman to run a major exchange in the U.S.\nIn 2016, Nasdaq earned $272\u00a0million in listings-related revenues.\nIn October 2018, the SEC blocked the New York Stock Exchange (NYSE) and Nasdaq from raising certain market-data prices. This was the first time the commission rejected increases for the exchanges' stock market data feeds.\nIn December 2020, Nasdaq announced that it would remove shares of four Chinese companies from indexes it maintains in accordance with Executive Order 13959.\n2021\u2013present.\nIn September 2024, the European Commission said it had carried out an unannounced inspection at the offices of Nasdaq over potential anti-competitive practices.\nIn October 2024, Nasdaq added artificial intelligence capabilities to its Calypso platform with the launch of XVA Accelerator, a tool for portfolio risk calculations. Calypso is used by banks and insurers for capital markets access and regulatory reporting.\nIn March 2025, pending approval by the U.S. Securities and Exchange Commission, Nasdaq announced plans to introduce 24-hour 5-day a week trading on its United States exchange during the second half of 2026 in response to increased global demand for U.S. equities.\nIn May 2025, Nasdaq and Amazon Web Services (AWS) expanded their partnership with the launch of Nasdaq Eqlipse Trading, a cloud-based platform emphasizing data sovereignty and flexible deployment. Early adopters include Johannesburg Stock Exchange, Mexico's Grupo BMV, and the Philippine Stock Exchange.\nQuote availability.\nA quote is the price of a stock as listed on an exchange. Quotes consist of bids, the price buyers are willing to pay, and offers, the price sellers will accept. Nasdaq quotes are available at three levels:\nTrading schedule.\nNasdaq sessions in Eastern Time Zone are:\n4:00\u00a0a.m. to 9:30\u00a0a.m.: extended-hours trading session (premarket)\n9:30\u00a0a.m. to 4:00\u00a0p.m.: normal trading session\n4:00\u00a0p.m. to 8:00\u00a0p.m.: extended-hours trading session (postmarket)\nThe Nasdaq Stock Market averages about 253 trading days per year.\nMarket tiers.\nWithin the NASDAQ Composite Index, the NASDAQ exchange has three different market tiers for listed companies:\nDifference between NYSE and Nasdaq.\nNasdaq is the second largest stock exchange in the United States. In addition to age and market capitalization, there are other key differences between the two exchanges: \nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21560", "revid": "47513291", "url": "https://en.wikipedia.org/wiki?curid=21560", "title": "New York Stock Exchange", "text": "American stock exchange \nThe New York Stock Exchange (NYSE, nicknamed \"the Big Board\") is an American stock exchange headquartered at the New York Stock Exchange Building in the Financial District of Lower Manhattan in New York City. It is the largest stock exchange in the world by market capitalization, exceeding $25 trillion in July 2024. The NYSE is owned by Intercontinental Exchange, an American holding company that it also lists (ticker symbol ICE). Previously, it was part of NYSE Euronext (NYX), which was formed by the NYSE's 2007 merger with Euronext. According to a Gallup poll conducted in 2022, approximately 58% of American adults reported having money invested in the stock market, either through individual stocks, mutual funds, or retirement accounts.\nHistory.\nThe earliest recorded organization of securities trading in New York among brokers directly dealing with each other can be traced to the Buttonwood Agreement. Previously, securities exchange had been intermediated by auctioneers, who also conducted more mundane auctions of commodities such as wheat and tobacco. On May 17, 1792, twenty-four brokers signed the Buttonwood Agreement, which set a floor commission rate charged to clients and bound the signers to give preference to the other signers in securities sales. The earliest securities traded were mostly governmental securities such as War Bonds from the Revolutionary War and First Bank of the United States stock, although Bank of New York stock was a non-governmental security traded in the early days. The Bank of North America, along with the First Bank of the United States and the Bank of New York, were the first shares traded on the New York Stock Exchange.\nIn 1817, the stockbrokers of New York, operating under the Buttonwood Agreement, instituted new reforms and reorganized. After sending a delegation to Philadelphia to observe the organization of their board of brokers, restrictions on manipulative trading were adopted, as well as formal organs of governance. After re-forming as the New York Stock and Exchange Board, the broker organization began renting out space exclusively for securities trading, which previously had been taking place at the Tontine Coffee House. Several locations were used between 1817 and 1865, when the present location was adopted.\nThe invention of the electrical telegraph consolidated markets and New York's market rose to dominance over Philadelphia after weathering some market panics better than other alternatives. The Open Board of Stock Brokers was established in 1864 as a competitor to the NYSE. With 354 members, the Open Board of Stock Brokers rivaled the NYSE in membership (which had 533) \"because it used a more modern, continuous trading system superior to the NYSE's twice-daily call sessions\". The Open Board of Stock Brokers merged with the NYSE in 1869. Robert Wright of \"Bloomberg\" writes that the merger increased the NYSE's members as well as trading volume, as \"several dozen regional exchanges were also competing with the NYSE for customers. Buyers, sellers and dealers all wanted to complete transactions as quickly and cheaply as technologically possible and that meant finding the markets with the most trading, or the greatest liquidity in today's parlance. Minimizing competition was essential to keep a large number of orders flowing, and the merger helped the NYSE maintain its reputation for providing superior liquidity.\" The Civil War greatly stimulated speculative securities trading in New York. By 1869, membership had to be capped, and has been sporadically increased since. The latter half of the nineteenth century saw rapid growth in securities trading.\nSecurities trade in the latter nineteenth and early twentieth centuries was prone to panics and crashes. Government regulation of securities trading was eventually seen as necessary, with arguably the most dramatic changes occurring in the 1930s after a major stock market crash occurred near the beginning of the Great Depression. The NYSE has also imposed additional rules in response to shareholder protection controls, e.g. in 2012, the NYSE imposed rules restricting brokers from voting uninstructed shares.\nThe Stock Exchange Luncheon Club was situated on the seventh floor from 1898 until its closure in 2006.\nOn April 21, 2005, the NYSE announced its plans to merge with Archipelago in a deal intended to reorganize the NYSE as a publicly traded company. NYSE's governing board voted to merge with rival Archipelago on December 6, 2005, and became a for-profit, public company. It began trading under the name NYSE Group on March 8, 2006. On April 4, 2007, the NYSE Group completed its merger with Euronext, the European combined stock market, thus forming NYSE Euronext, the first transatlantic stock exchange.\nWall Street is the leading U.S. money center for international financial activities and the foremost U.S. location for the conduct of wholesale financial services. \"It comprises a matrix of wholesale financial sectors, financial markets, financial institutions, and financial industry firms\" (Robert, 2002). The principal sectors are securities industry, commercial banking, asset management, and insurance.\nPrior to the acquisition of NYSE Euronext by the ICE in 2013, Marsh Carter was the Chairman of the NYSE and the CEO was Duncan Niederauer. Currently, the chairman is Jeffrey Sprecher. In 2016, NYSE owner Intercontinental Exchange Inc. earned $419 million in listings-related revenues.\nFrom its opening until August 2000, all stock prices on the New York Stock Exchange were quoted in fractional increments of eighths, based on the 17th century Spanish trading system's practice of using pieces of eight. On August 28, 2000, some stocks were quoted in decimals, and all NYSE stocks were decimalized by the end of 2001.\nNotable events.\n20th century.\nThe exchange was closed shortly after the beginning of World War I (July 31, 1914), but it partially re-opened on November 28 of that year in order to help the war effort by trading bonds, and completely reopened for stock trading on December 12, 1914.\nOn September 16, 1920, the Wall Street bombing occurred outside the building, killing forty people and injuring hundreds more.\nThe Black Thursday crash of the Exchange on October 24, 1929, and the sell-off panic which started on Black Tuesday, October 29, are often blamed for precipitating the Great Depression. In an effort to restore investor confidence, the Exchange unveiled a fifteen-point program aimed to upgrade protection for the investing public on October 31, 1938.\nOn October 1, 1934, the exchange was registered as a national securities exchange with the U.S. Securities and Exchange Commission, with a president and a thirty-three-member board. On February 18, 1971, the non-profit corporation was formed, and the number of board members was reduced to twenty-five.\nOne of Abbie Hoffman's well-known publicity stunts took place in 1967, when he led members of the Yippie movement to the Exchange's gallery. The provocateurs hurled fistfuls of dollars toward the trading floor below. Some traders booed, and some laughed and waved. Three months later the stock exchange enclosed the gallery with bulletproof glass. Hoffman wrote a decade later, \"We didn't call the press; at that time we really had no notion of anything called a media event.\"\nOn October 19, 1987, the Dow Jones Industrial Average (DJIA) dropped 508 points, a 22.6% loss in a single day, the second-biggest one-day drop the exchange had experienced. Black Monday was followed by Terrible Tuesday, a day in which the Exchange's systems did not perform well and some people had difficulty completing their trades.\nSubsequently, there was another major drop for the Dow on October 13, 1989\u2014the Mini-Crash of 1989. The crash was apparently caused by a reaction to a news story of a $6.75\u00a0billion leveraged buyout deal for UAL Corporation, the parent company of United Airlines, which broke down. When the UAL deal fell through, it helped trigger the collapse of the junk bond market causing the Dow to fall 190.58 points, or 6.91 percent.\nSimilarly, there was a panic in the financial world during the year of 1997; the Asian Financial Crisis. Like the fall of many foreign markets, the Dow suffered a 7.18% drop in value (554.26 points) on October 27, 1997, in what later became known as the 1997 Mini-Crash but from which the DJIA recovered quickly. This was the first time that the \"circuit breaker\" rule had operated.\n21st century.\nOn January 26, 2000, an altercation during filming of the music video for Rage Against the Machine's \"Sleep Now in the Fire\", directed by Michael Moore, caused the doors of the exchange to be closed and the band to be escorted from the site by security after the members attempted to gain entry into the exchange.\nIn the aftermath of the September 11 attacks, the NYSE was closed for four trading sessions, resuming on Monday, September 17, one of the rare times the NYSE was closed for more than one session and only the third time since March 1933. On the first day, the NYSE suffered a 7.1% drop in value (684 points); after a week, it dropped by 14% (1,370 points). An estimated $1.4 trillion was lost within five days of trading. The NYSE was only 5 blocks from Ground Zero. The same day it was announced that the exchange and the New York Stock Exchange building would be closed to the general public, a practice that continues to the present day. \nOn May 6, 2010, the Dow Jones Industrial Average posted its largest intraday percentage drop since the crash on October 19, 1987, with a 998-point loss later being called the 2010 Flash Crash (as the drop occurred for only 36 minutes before rebounding). The SEC and CFTC published a report on the event, although it did not come to a conclusion as to the cause. The regulators found no evidence that the fall was caused by erroneous (\"fat finger\") orders.\nOn October 29, 2012, the stock exchange was shut down for two days due to Hurricane Sandy. The last time the stock exchange was closed due to weather for a full two days was on March 12 and 13, 1888.\nOn May 1, 2014, the stock exchange was fined $4.5\u00a0million by the Securities and Exchange Commission to settle charges that it had violated market rules.\nOn August 14, 2014, Berkshire Hathaway's A Class shares, the highest priced shares on the NYSE, hit $200,000 a share for the first time.\nOn July 8, 2015, technical issues affected the stock exchange, halting trading at 11:32\u00a0am ET. The NYSE reassured stock traders that the outage was \"not a result of a cyber breach\", and the Department of Homeland Security confirmed that there was \"no sign of malicious activity\". Trading eventually resumed at 3:10\u00a0pm ET the same day.\nOn May 25, 2018, Stacey Cunningham, the NYSE's chief operating officer, became the Big Board's 67th president, succeeding Thomas Farley. She is the first female leader in the exchange's 226-year history.\nIn March 2020, the NYSE announced plans to temporarily move to all-electronic trading on March 23, 2020, due to the COVID-19 pandemic. Along with the PHLX and the BSE, the NYSE reopened on May 26, 2020.\nBuilding.\nThe main New York Stock Exchange Building, built in 1903, is at 18 Broad Street, between the corners of Wall Street and Exchange Place, and was designed in the Beaux Arts style by George B. Post. The adjacent structure at 11 Wall Street, completed in 1922, was designed in a similar style by Trowbridge &amp; Livingston. The buildings were both designated a National Historic Landmark in 1978. 18 Broad Street is also a New York City designated landmark.\nOfficial holidays.\nThe New York Stock Exchange is closed on New Year's Day, Martin Luther King Jr. Day, Washington's Birthday, Good Friday, Memorial Day, Juneteenth National Independence Day, Independence Day, Labor Day, Thanksgiving, and Christmas. When those holidays occur on a weekend, the holiday is observed on the closest weekday. In addition, the Stock Exchange closes early on the day before Independence Day, the day after Thanksgiving, and Christmas Eve. The NYSE averages about 253 trading days per year.\nTrading.\nThe New York Stock Exchange (sometimes referred to as \"The Big Board\") provides a means for buyers and sellers to trade shares of stock in companies registered for public trading. The NYSE is open for trading Monday through Friday from 9:30\u00a0am \u2013 4:00\u00a0pm ET, with the exception of holidays declared by the Exchange in advance. Proposals for round-the-clock trading have been considered by NYSE.\nThe NYSE trades in a continuous auction format, where traders can execute stock transactions on behalf of investors. They will gather around the appropriate post where a specialist broker, who is employed by a NYSE member firm (that is, they are not an employee of the New York Stock Exchange), acts as an auctioneer in an open outcry auction market environment to bring buyers and sellers together and to manage the actual auction. They do on occasion (approximately 10% of the time) facilitate the trades by committing their own capital and as a matter of course disseminate information to the crowd that helps to bring buyers and sellers together. The auction process moved toward automation in 1995 through the use of wireless handheld computers (HHC). The system enabled traders to receive and execute orders electronically via wireless transmission. On September 25, 1995, NYSE member Michael Einersen, who designed and developed this system, executed 1000 shares of IBM through this HHC, ending a 203-year process of paper transactions and ushering in an era of automated trading.\nAs of January 24, 2007, all NYSE stocks can be traded via its electronic hybrid market (except for a small group of very high-priced stocks). Customers can now send orders for immediate electronic execution, or route orders to the floor for trade in the auction market. In the first three months of 2007, in excess of 82% of all order volume was delivered to the floor electronically. NYSE works with US regulators such as the SEC and CFTC to coordinate risk management measures in the electronic trading environment through the implementation of mechanisms like circuit breakers and liquidity replenishment points.\nFollowing the Black Monday market crash in 1987, NYSE imposed trading curbs to reduce market volatility and massive panic sell-offs. Following the 2011 rule change, at the start of each trading day, the NYSE sets three circuit breaker levels at levels of 7% (Level 1), 13% (Level 2), and 20% (Level 3) of the average closing price of the S&amp;P 500 for the preceding trading day. Level 1 and Level 2 declines result in a 15-minute trading halt unless they occur after 3:25\u00a0pm, when no trading halts apply. A Level 3 decline results in trading being suspended for the remainder of the day. (The biggest one-day decline in the S&amp;P 500 since 1987 was the 11.98% drop on March 16, 2020.)\nFloor seats.\nUntil 2005, the right to directly trade shares on the exchange was conferred upon owners of a limited number of \"seats\". The term comes from the fact that up until the 1870s NYSE members sat in chairs to trade. In 1868, the number of seats was fixed at 533, and this number was increased several times over the years. In 1953, the number of seats was set permanently at 1,366.\nThese seats were a sought-after commodity as they conferred the ability to directly trade stock on the NYSE, and seat holders were commonly referred to as members of the NYSE. Seat prices varied widely over the years, generally falling during recessions and rising during economic expansions. In January 1927 the cost of a seat reached a then-record $185,000. The most expensive inflation-adjusted seat was sold in 1929 for $625,000, which, today, would be over six million dollars. In recent times, seats have sold for as high as $4\u00a0million in the late 1990s and as low as $1\u00a0million in 2001. In 2005, seat prices shot up to $3.25\u00a0million as the exchange entered into an agreement to merge with Archipelago and became a for-profit, publicly traded company. Seat owners received $500,000 in cash per seat and 77,000 shares of the newly formed corporation. The NYSE now sells one-year licenses to trade directly on the exchange. Licenses for floor trading are available for $40,000 and a license for bond trading is available for as little as $1,000 as of 2010. Neither are resellable, but may be transferable during a change of ownership of a corporation holding a trading license.\nThe Barnes family is the only known lineage to have five generations of NYSE members: Winthrop H. Barnes (admitted 1894), Richard W.P. Barnes (admitted 1926), Richard S. Barnes (admitted 1951), Robert H. Barnes (admitted 1972), and Derek J. Barnes (admitted 2003).\nNYSE Composite Index.\nIn the mid-1960s, the NYSE Composite Index (NYSE: NYA) was created, with a base value of 50 points equal to the 1965 yearly close. This was done to reflect the value of all stocks trading at the exchange, in contrast with the then predominant Dow Jones Industrial Average which tracks just 30 stocks. To raise the profile of the composite index, in 2003, the NYSE set its new base value of 5,000 points equal to the 2002 yearly close. Its close at the end of 2013 was 10,400.32.\nMerger, acquisition, and control.\nIn October 2008, NYSE Euronext completed acquisition of the American Stock Exchange (AMEX) for $260 million in stock.\nOn February 15, 2011, NYSE and announced their merger to form a new company, as yet unnamed, wherein shareholders would have 60% ownership of the new entity, and NYSE Euronext shareholders would have 40%.\nOn February 1, 2012, the European Commission blocked the merger of NYSE with , after commissioner Joaqu\u00edn Almunia stated that the merger \"would have led to a near-monopoly in European financial derivatives worldwide\". Instead, and NYSE would have to sell either their Eurex derivatives or LIFFE shares in order to not create a monopoly. On February 2, 2012, NYSE Euronext and agreed to scrap the merger.\nIn April 2011, Intercontinental Exchange (ICE), an American futures exchange, and NASDAQ OMX Group had together made an unsolicited proposal to buy NYSE Euronext for approximately $11 billion, a deal in which NASDAQ would have taken control of the stock exchanges. NYSE Euronext rejected this offer twice, and it was finally terminated after the United States Department of Justice indicated their intention to block the deal due to antitrust concerns.\nIn December 2012, ICE proposed to buy NYSE Euronext in a stock swap with a valuation of $8\u00a0billion. NYSE Euronext shareholders would receive either $33.12 in cash, or $11.27 in cash and approximately a sixth of a share of ICE. Jeffrey Sprecher, the chairman and CEO of ICE, would retain those positions, but four members of the NYSE board of directors would be added to the ICE board.\nOn January 24, 2023, a glitch in NYSE caused panic due to unintentional trade orders opened and closed in more than 250 securities.\nOpening and closing bells.\nThe NYSE's opening and closing bells mark the beginning and the end of each trading day. The opening bell is rung at 9:30\u00a0am ET to mark the start of the day's trading session. At 4\u00a0pm ET the closing bell is rung and trading for the day stops. There are bells located in each of the four main sections of the NYSE that all ring at the same time once a button is pressed. There are three buttons that control the bells, located on the control panel behind the podium which overlooks the trading floor. The main bell, which is rung at the beginning and end of the trading day, is controlled by a green button. The second button, colored orange, activates a single-stroke bell that is used to signal a moment of silence. A third, red button controls a backup bell which is used in case the main bell fails to ring.\nThe ringing of the bells is usually accompanied with applause and is often done by VIPs and celebrities (see pictures and the section \"Notable bell-ringers\").\nHistory.\nThe signal to start and stop trading was not always a bell; a gavel was the original signal, which is still utilized alongside the bell. However, the gavel is frequently damaged. During the late 1800s, the NYSE decided to switch the gavel for a gong to signal the day's beginning and end. After the NYSE changed to its present location at 18 Broad Street in 1903, the gong was switched to the bell format that is currently being used. The bell itself was produced by Bevin Brothers in East Hampton, Connecticut, which is known colloquially as \"Bell Town\" for its history of bell foundries and metal toy manufacturing.\nA common sight today is the highly publicized events in which a celebrity or executive from a corporation stands behind the NYSE podium and pushes the button that signals the bells to ring. Due to the amount of coverage that the opening/closing bells receive, many companies coordinate new product launches and other marketing-related events to start on the same day as when the company's representatives ring the bell. It was only in 1995 that the NYSE began having special guests ring the bells on a regular basis; prior to that, ringing the bells was usually the responsibility of the exchange's floor managers.\nNotable bell-ringers.\nMany of the people who ring the bell are business executives whose companies trade on the exchange, usually to announce new products, acquisitions, mergers or public offerings. However, there have also been many famous people from outside the world of business that have rung the bell, such as the Mayor of New York City Rudy Giuliani and the President of South Africa Nelson Mandela. Two United Nations Secretaries General have also rung the bell. On April 27, 2006, Secretary-General Kofi Annan rang the opening bell to launch the United Nations Principles for Responsible Investment. On July 24, 2013, Secretary-General Ban Ki-moon rang the closing bell to celebrate the NYSE joining the United Nations Sustainable Stock Exchanges Initiative. President-Elect Donald Trump rang the bell on December 12, 2024 after being named the \"Time\" Person of the Year.\nCelebrities that have rung the bell include athletes such as Joe DiMaggio of the New York Yankees and Olympic swimming champion Michael Phelps, entertainers such as rapper Snoop Dogg, members of ESPN's College GameDay crew, singer and actress Liza Minnelli, members of the rock band Kiss, and the members of .\nIn addition there have been many bell-ringers selected for their public contributions, such as members of the New York City Police Department and New York City Fire Department following the September 11 attacks, members of the United States Armed Forces serving overseas, and participants in various charitable organizations.\nSeveral fictional characters, like mascots of companies and characters from movies and television or toys made by companies listed on the exchange, have rung the bell as well, including Mickey Mouse, the Pink Panther, Mr. Potato Head, the Aflac Duck, Gene and Jailbreak of \"The Emoji Movie\", and Darth Vader.\nSee also.\n&lt;templatestyles src=\"A-Z multipage list/styles.css\"/&gt;&lt;templatestyles src=\"TOC top/styles.css\"/&gt;\nCompanies listed on the New York Stock Exchange\n&lt;templatestyles src=\"Hlist/styles.css\"/&gt;\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21561", "revid": "575347", "url": "https://en.wikipedia.org/wiki?curid=21561", "title": "Nanoengineering", "text": "Engineering on the nanoscale\nNanoengineering is the practice of engineering on the nanoscale. It derives its name from the nanometre, a unit of measurement equalling one billionth of a meter.\nNanoengineering is largely a synonym for nanotechnology, but emphasizes the engineering rather than the pure science aspects of the field.\nDegree programs.\nThe first nanoengineering program was started at the University of Toronto within the Engineering Science program as one of the options of study in the final years. In 2003, the Lund Institute of Technology started a program in Nanoengineering. In 2004, the College of Nanoscale Science and Engineering at the University at Albany, SUNY was founded as the first of its kind in the United States. The college later merged with SUNY Poly, but will rejoin the University at Albany in 2023. In 2005, the University of Waterloo established a unique program which offers a full degree in Nanotechnology Engineering. Louisiana Tech University started the first program in the U.S. in 2005. In 2006 the University of Duisburg-Essen started a Bachelor and a Master program NanoEngineering. Unlike early NanoEngineering programs, the first NanoEngineering Department in the world, offering both undergraduate and graduate degrees, was established by the University of California, San Diego in 2007.\nIn 2009, the University of Toronto began offering all Options of study in Engineering Science as degrees, bringing the second nanoengineering degree to Canada. Rice University established in 2016 a Department of Materials Science and NanoEngineering (MSNE).\nDTU Nanotech - the Department of Micro- and Nanotechnology - is a department at the Technical University of Denmark established in 1990.\nIn 2013, Wayne State University began offering a Nanoengineering Undergraduate Certificate Program, which is funded by a Nanoengineering Undergraduate Education (NUE) grant from the National Science Foundation. The primary goal is to offer specialized undergraduate training in nanotechnology. Other goals are: 1) to teach emerging technologies at the undergraduate level, 2) to train a new adaptive workforce, and 3) to retrain working engineers and professionals.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21562", "revid": "25859633", "url": "https://en.wikipedia.org/wiki?curid=21562", "title": "NP (complexity)", "text": "Complexity class used to classify decision problems\n&lt;templatestyles src=\"Unsolved/styles.css\" /&gt;\nUnsolved problem in computer science\nMore unsolved problems in computer science\nIn computational complexity theory, NP (nondeterministic polynomial time) is a complexity class used to classify decision problems. NP is the set of decision problems for which the problem instances, where the answer is \"yes\", have proofs verifiable in polynomial time by a deterministic Turing machine, or alternatively the set of problems that can be solved in polynomial time by a nondeterministic Turing machine.\nThe first definition is the basis for the abbreviation NP; \"nondeterministic, polynomial time\". These two definitions are equivalent because the algorithm based on the Turing machine consists of two phases, the first of which consists of a guess about the solution, which is generated in a nondeterministic way, while the second phase consists of a deterministic algorithm that verifies whether the guess is a solution to the problem.\nThe complexity class P (all problems solvable, deterministically, in polynomial time) is contained in NP (problems where solutions can be verified in polynomial time), because if a problem is solvable in polynomial time, then a solution is also verifiable in polynomial time by simply solving the problem. It is widely believed, but not proven, that P is smaller than NP, in other words, that decision problems exist that cannot be solved in polynomial time even though their solutions can be checked in polynomial time. The hardest problems in NP are called NP-complete problems. An algorithm solving such a problem in polynomial time is also able to solve any other NP problem in polynomial time. If P were in fact equal to NP, then a polynomial-time algorithm would exist for solving NP-complete, and by corollary, all NP problems.\nThe complexity class NP is related to the complexity class co-NP, for which the answer \"no\" can be verified in polynomial time. Whether or not NP \n co-NP is another outstanding question in complexity theory.\nFormal definition.\nThe complexity class NP can be defined in terms of NTIME as follows:\n formula_1\nwhere formula_2 is the set of decision problems that can be solved by a nondeterministic Turing machine in formula_3 time.\nEquivalently, NP can be defined using deterministic Turing machines as verifiers. A language \"L\" is in NP if and only if there exist polynomials \"p\" and \"q\", and a deterministic Turing machine \"M\", such that\nBackground.\nMany computer science problems are contained in NP, like decision versions of many search and optimization problems.\nVerifier-based definition.\nIn order to explain the verifier-based definition of NP, consider the subset sum problem:\nAssume that we are given some integers, {\u22127, \u22123, \u22122, 5, 8}, and we wish to know whether some of these integers sum up to zero. Here the answer is \"yes\", since the integers {\u22123, \u22122, 5} corresponds to the sum (\u22123) + (\u22122) + 5 \n 0.\nTo answer whether some of the integers add to zero we can create an algorithm that obtains all the possible subsets. As the number of integers that we feed into the algorithm becomes larger, both the number of subsets and the computation time grows exponentially.\nBut notice that if we are given a particular subset, we can \"efficiently verify\" whether the subset sum is zero, by summing the integers of the subset. If the sum is zero, that subset is a \"proof\" or witness for the answer is \"yes\". An algorithm that verifies whether a given subset has sum zero is a \"verifier\". Clearly, summing the integers of a subset can be done in polynomial time, and the subset sum problem is therefore in NP.\nThe above example can be generalized for any decision problem. Given any instance I of problem formula_4 and witness W, if there exists a \"verifier\" V so that given the ordered pair (I,\u00a0W) as input, V returns \"yes\" in polynomial time if the witness proves that the answer is \"yes\" or \"no\" in polynomial time otherwise, then formula_4 is in NP.\nThe \"no\"-answer version of this problem is stated as: \"given a finite set of integers, does every non-empty subset have a nonzero sum?\". The verifier-based definition of NP does \"not\" require an efficient verifier for the \"no\"-answers. The class of problems with such verifiers for the \"no\"-answers is called co-NP. In fact, it is an open question whether all problems in NP also have verifiers for the \"no\"-answers and thus are in co-NP.\nIn some literature the verifier is called the \"certifier\", and the witness the \"certificate\".\nMachine-definition.\nEquivalent to the verifier-based definition is the following characterization: NP is the class of decision problems solvable by a nondeterministic Turing machine that runs in polynomial time. That is to say, a decision problem formula_4 is in NP whenever formula_4 is recognized by some polynomial-time nondeterministic Turing machine formula_8 with an existential acceptance condition, meaning that formula_9 if and only if some computation path of formula_10 leads to an accepting state. This definition is equivalent to the verifier-based definition because a nondeterministic Turing machine could solve an NP problem in polynomial time by nondeterministically selecting a certificate and running the verifier on the certificate. Similarly, if such a machine exists, then a polynomial time verifier can naturally be constructed from it.\nIn this light, we can define co-NP dually as the class of decision problems recognizable by polynomial-time nondeterministic Turing machines with an existential rejection condition. Since an existential rejection condition is exactly the same thing as a universal acceptance condition, we can understand the \"NP vs. co-NP\" question as asking whether the existential and universal acceptance conditions have the same expressive power for the class of polynomial-time nondeterministic Turing machines.\nProperties.\nNP is closed under union, intersection, concatenation, Kleene star and reversal. It is not known whether NP is closed under complement (this question is the so-called \"NP versus co-NP\" question).\nWhy some NP problems are hard to solve.\nBecause of the many important problems in this class, there have been extensive efforts to find polynomial-time algorithms for problems in NP. However, there remain a large number of problems in NP that defy such attempts, seeming to require super-polynomial time. Whether these problems are not decidable in polynomial time is one of the greatest open questions in computer science (see P versus NP (\"P\u00a0=\u00a0NP\") problem for an in-depth discussion).\nAn important notion in this context is the set of NP-complete decision problems, which is a subset of NP and might be informally described as the \"hardest\" problems in NP. If there is a polynomial-time algorithm for even \"one\" of them, then there is a polynomial-time algorithm for \"all\" the problems in NP. Because of this, and because dedicated research has failed to find a polynomial algorithm for any NP-complete problem, once a problem has been proven to be NP-complete, this is widely regarded as a sign that a polynomial algorithm for this problem is unlikely to exist.\nHowever, in practical uses, instead of spending computational resources looking for an optimal solution, a good enough (but potentially suboptimal) solution may often be found in polynomial time. Also, the real-life applications of some problems are easier than their theoretical equivalents.\nEquivalence of definitions.\nThe two definitions of NP as the class of problems solvable by a nondeterministic Turing machine (TM) in polynomial time and the class of problems verifiable by a deterministic Turing machine in polynomial time are equivalent. The proof is described by many textbooks, for example, Sipser's \"Introduction to the Theory of Computation\", section 7.3.\nTo show this, first, suppose we have a deterministic verifier. A non-deterministic machine can simply nondeterministically run the verifier on all possible proof strings (this requires only polynomially many steps because it can nondeterministically choose the next character in the proof string in each step, and the length of the proof string must be polynomially bounded). If any proof is valid, some path will accept; if no proof is valid, the string is not in the language and it will reject.\nConversely, suppose we have a non-deterministic TM called A accepting a given language L. At each of its polynomially many steps, the machine's computation tree branches in at most a finite number of directions. There must be at least one accepting path, and the string describing this path is the proof supplied to the verifier. The verifier can then deterministically simulate A, following only the accepting path, and verifying that it accepts at the end. If A rejects the input, there is no accepting path, and the verifier will always reject.\nRelationship to other classes.\nNP contains all problems in P, since one can verify any instance of the problem by simply ignoring the proof and solving it. NP is contained in PSPACE\u2014to show this, it suffices to construct a PSPACE machine that loops over all proof strings and feeds each one to a polynomial-time verifier. Since a polynomial-time machine can only read polynomially many bits, it cannot use more than polynomial space, nor can it read a proof string occupying more than polynomial space (so we do not have to consider proofs longer than this). NP is also contained in EXPTIME, since the same algorithm operates in exponential time.\nco-NP contains those problems that have a simple proof for \"no\" instances, sometimes called counterexamples. For example, primality testing trivially lies in co-NP, since one can refute the primality of an integer by merely supplying a nontrivial factor. NP and co-NP together form the first level in the polynomial hierarchy, higher only than P.\nNP is defined using only deterministic machines. If we permit the verifier to be probabilistic (this, however, is not necessarily a BPP machine), we get the class MA solvable using an Arthur\u2013Merlin protocol with no communication from Arthur to Merlin.\nThe relationship between BPP and NP is unknown: it is not known whether BPP is a subset of NP, NP is a subset of BPP or neither. If NP is contained in BPP, which is considered unlikely since it would imply practical solutions for NP-complete problems, then NP = RP and PH \u2286 BPP.\nNP is a class of decision problems; the analogous class of function problems is FNP.\nThe only known strict inclusions come from the time hierarchy theorem and the space hierarchy theorem, and respectively they are formula_11 and formula_12.\nOther characterizations.\nIn terms of descriptive complexity theory, NP corresponds precisely to the set of languages definable by existential second-order logic (Fagin's theorem).\nNP can be seen as a very simple type of interactive proof system, where the prover comes up with the proof certificate and the verifier is a deterministic polynomial-time machine that checks it. It is complete because the right proof string will make it accept if there is one, and it is sound because the verifier cannot accept if there is no acceptable proof string.\nA major result of complexity theory is that NP can be characterized as the problems solvable by probabilistically checkable proofs where the verifier uses O(log \"n\") random bits and examines only a constant number of bits of the proof string (the class PCP(log \"n\", 1)). More informally, this means that the NP verifier described above can be replaced with one that just \"spot-checks\" a few places in the proof string, and using a limited number of coin flips can determine the correct answer with high probability. This allows several results about the hardness of approximation algorithms to be proven.\nExamples.\nP.\nAll problems in P, denoted formula_13. Given a certificate for a problem in P, we can ignore the certificate and just solve the problem in polynomial time.\nInteger factorization.\nThe decision problem version of the integer factorization problem: given integers \"n\" and \"k\", is there a factor \"f\" with 1 &lt; \"f\" &lt; \"k\" and \"f\" dividing \"n\"?\nNP-complete problems.\nEvery NP-complete problem is in NP.\nBoolean satisfiability.\nThe Boolean satisfiability problem (SAT), where we want to know whether or not a certain formula in propositional logic with Boolean variables is true for some value of the variables.\nTravelling salesman.\nThe decision version of the travelling salesman problem is in NP. Given an input matrix of distances between \"n\" cities, the problem is to determine if there is a route visiting all cities with total distance less than \"k\".\nA proof can simply be a list of the cities. Then verification can clearly be done in polynomial time. It simply adds the matrix entries corresponding to the paths between the cities.\nA nondeterministic Turing machine can find such a route as follows:\nOne can think of each guess as \"forking\" a new copy of the Turing machine to follow each of the possible paths forward, and if at least one machine finds a route of distance less than \"k\", that machine accepts the input. (Equivalently, this can be thought of as a single Turing machine that always guesses correctly)\nA binary search on the range of possible distances can convert the decision version of Traveling Salesman to the optimization version, by calling the decision version repeatedly (a polynomial number of times).\nSubgraph isomorphism.\nThe subgraph isomorphism problem of determining whether graph G contains a subgraph that is isomorphic to graph H.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21565", "revid": "37005538", "url": "https://en.wikipedia.org/wiki?curid=21565", "title": "November 5", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearNovember 5 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21566", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=21566", "title": "Noam Chomsky", "text": "American linguist and activist (born 1928)\nAvram Noam Chomsky (born December 7, 1928) is an American professor and public intellectual known for his work in linguistics, political activism, and social criticism. Sometimes called \"the father of modern linguistics\", Chomsky is also a major figure in analytic philosophy and one of the founders of the field of cognitive science. He is a laureate professor of linguistics at the University of Arizona and an institute professor emeritus at the Massachusetts Institute of Technology (MIT). Among the most cited living authors, Chomsky has written more than 150 books on topics such as linguistics, war, and politics. In addition to his work in linguistics, since the 1960s Chomsky has been an influential voice on the American left as a consistent critic of U.S. foreign policy, contemporary capitalism, and corporate influence on political institutions and the media.\nBorn to Ashkenazi Jewish immigrants in Philadelphia, Chomsky developed an early interest in anarchism from alternative bookstores in New York City. He studied at the University of Pennsylvania. During his postgraduate work in the Harvard Society of Fellows, Chomsky developed the theory of transformational grammar for which he earned his doctorate in 1955. That year he began teaching at MIT, and in 1957 emerged as a significant figure in linguistics with his landmark work \"Syntactic Structures\", which played a major role in remodeling the study of language. From 1958 to 1959 Chomsky was a National Science Foundation fellow at the Institute for Advanced Study. He created or co-created the universal grammar theory, the generative grammar theory, the Chomsky hierarchy, and the minimalist program. Chomsky also played a pivotal role in the decline of linguistic behaviorism, and was particularly critical of the work of B. F. Skinner.\nAn outspoken opponent of U.S. involvement in the Vietnam War, which he saw as an act of American imperialism, in 1967 Chomsky rose to national attention for his anti-war essay \"The Responsibility of Intellectuals\". Becoming associated with the New Left, he was arrested multiple times for his activism and placed on President Richard Nixon's list of political opponents. While expanding his work in linguistics over subsequent decades, he also became involved in the linguistics wars. In collaboration with Edward S. Herman, Chomsky later articulated the propaganda model of media criticism in \"Manufacturing Consent\", and worked to expose the Indonesian occupation of East Timor. His defense of unconditional freedom of speech, including that of Holocaust denial, generated significant controversy in the Faurisson affair of the 1980s. Chomsky's commentary on the Cambodian genocide and the Bosnian genocide also generated controversy. Since retiring from active teaching at MIT, he has continued his vocal political activism, including opposing the 2003 invasion of Iraq and supporting the Occupy movement. An anti-Zionist, Chomsky considers Israel's treatment of Palestinians to be worse than South African\u2013style apartheid, and criticizes U.S. support for Israel.\nChomsky is widely recognized as having helped to spark the cognitive revolution in the human sciences, contributing to the development of a new cognitivistic framework for the study of language and the mind. Chomsky remains a leading critic of U.S. foreign policy, contemporary capitalism, U.S. involvement and Israel's role in the Israeli\u2013Palestinian conflict, and mass media. Chomsky and his ideas remain highly influential in the anti-capitalist and anti-imperialist movements.\nLife.\nChildhood: 1928\u20131945.\nChomsky was born on December 7, 1928, in the East Oak Lane neighborhood of Philadelphia, Pennsylvania. His parents, William Chomsky and Elsie Simonofsky, were Ashkenazi Jewish immigrants. William had fled the Russian Empire from what is present-day Ukraine in 1913 to escape conscription and worked in Baltimore sweatshops and Hebrew elementary schools before attending university. Elsie immigrated from the region of what is present-day Belarus. Both parents' first language was Yiddish although it was taboo to speak it at home; his father spoke English with a foreign accent while his mother spoke a native New York City English dialect. After moving to Philadelphia, William became principal of the Congregation Mikveh Israel religious school and joined the Gratz College faculty. He placed great emphasis on educating people so that they would be \"well integrated, free and independent in their thinking, concerned about improving and enhancing the world, and eager to participate in making life more meaningful and worthwhile for all\", a mission that shaped and was subsequently adopted by his son. Elsie, who also taught at Mikveh Israel, shared her leftist politics and care for social issues with her sons.\nNoam's only sibling, David Eli Chomsky (1934\u20132021), was born five years later, and worked as a cardiologist in Philadelphia. The brothers were close, although David was more easygoing, while Noam could be very competitive. They were raised Jewish, being taught Hebrew and regularly involved with discussing the political theories of Zionism; the family was particularly influenced by the Left Zionist writings of Ahad Ha'am. He faced antisemitism as a child, particularly from Philadelphia's Irish and German communities.\nChomsky attended the independent, Deweyite Oak Lane Country Day School and Philadelphia's Central High School, where he excelled academically and joined various clubs and societies, but was troubled by the school's hierarchical and domineering teaching methods. He also attended Hebrew High School at Gratz College, where his father taught.\nChomsky has described his parents as \"normal Roosevelt Democrats\" with center-left politics, but relatives involved in the International Ladies' Garment Workers' Union exposed him to socialism and far-left politics. He was substantially influenced by his uncle and the Jewish leftists who frequented his New York City newspaper stand to debate current affairs. Chomsky himself often visited left-wing and anarchist bookstores when visiting his uncle in the city, voraciously reading political literature. He became absorbed in the story of the 1939 fall of Barcelona and suppression of the Spanish anarchosyndicalist movement, writing his first article on the topic at the age of 10. That he came to identify with anarchism first rather than another leftist movement, he described as a \"lucky accident\". Chomsky was firmly anti-Bolshevik by his early teens.\nUniversity: 1945\u20131955.\nIn 1945, at the age of 16, Chomsky began a general program of study at the University of Pennsylvania, where he explored philosophy, logic, and languages and developed a primary interest in learning Arabic. Living at home, he funded his undergraduate degree by teaching Hebrew. Frustrated with his experiences at the university, he considered dropping out and moving to a kibbutz in Mandatory Palestine, but his intellectual curiosity was reawakened through conversations with the linguist Zellig Harris, whom he first met in a political circle in 1947. Harris introduced Chomsky to the field of theoretical linguistics and convinced him to major in the subject. Chomsky's BA honors thesis, \"Morphophonemics of Modern Hebrew\", applied Harris's methods to the language. Chomsky revised this thesis for his MA, which he received from the University of Pennsylvania in 1951; it was subsequently published as a book. He also developed his interest in philosophy while at university, in particular under the tutelage of Nelson Goodman.\nFrom 1951 to 1955, Chomsky was a member of the Society of Fellows at Harvard University, where he undertook research on what became his doctoral dissertation. Having been encouraged by Goodman to apply, Chomsky was attracted to Harvard in part because the philosopher Willard Van Orman Quine was based there. Both Quine and a visiting philosopher, J. L. Austin of the University of Oxford, strongly influenced Chomsky. In 1952, Chomsky published his first academic article in \"The Journal of Symbolic Logic\". Highly critical of the established behaviorist currents in linguistics, in 1954, he presented his ideas at lectures at the University of Chicago and Yale University. He had not been registered as a student at Pennsylvania for four years, but in 1955 he submitted a thesis setting out his ideas on transformational grammar; he was awarded a Doctor of Philosophy degree for it, and it was privately distributed among specialists on microfilm before being published in 1975 as part of \"The Logical Structure of Linguistic Theory\". Harvard professor George Armitage Miller was impressed by Chomsky's thesis and collaborated with him on several technical papers in mathematical linguistics. Chomsky's doctorate exempted him from compulsory military service, which was otherwise due to begin in 1955.\nIn 1947, Chomsky began a romantic relationship with Carol Doris Schatz, whom he had known since early childhood. They married in 1949. After Chomsky was made a Fellow at Harvard, the couple moved to the Allston area of Boston and remained there until 1965, when they relocated to the suburb of Lexington. The couple took a Harvard travel grant to Europe in 1953. He enjoyed living in Hashomer Hatzair's HaZore'a kibbutz while in Israel, but was appalled by his interactions with Jewish nationalism, anti-Arab racism and, within the kibbutz's leftist community, Stalinism. On visits to New York City, Chomsky continued to frequent the office of the Yiddish anarchist journal \"Fraye Arbeter Shtime\" and became enamored with the ideas of Rudolf Rocker, a contributor whose work introduced Chomsky to the link between anarchism and classical liberalism. Chomsky also read other political thinkers: the anarchists Mikhail Bakunin and Diego Abad de Santill\u00e1n, democratic socialists George Orwell, Bertrand Russell, and Dwight Macdonald, and works by Marxists Karl Liebknecht, Karl Korsch, and Rosa Luxemburg. His politics were reaffirmed by Orwell's depiction of Barcelona's functioning anarchist society in \"Homage to Catalonia\" (1938). Chomsky read the leftist journal \"Politics\", which furthered his interest in anarchism, and the council communist periodical \"Living Marxism\", though he rejected the Marxist orthodoxy of its editor, Paul Mattick.\nEarly career: 1955\u20131966.\nChomsky befriended two linguists at the Massachusetts Institute of Technology (MIT)\u2014Morris Halle and Roman Jakobson\u2014the latter of whom secured him an assistant professor position there in 1955. At MIT, Chomsky spent half his time on a mechanical translation project and half teaching a course on linguistics and philosophy. He described MIT as open to experimentation where he was free to pursue his idiosyncratic interests. MIT promoted him to the position of associate professor in 1957, and over the next year he was also a visiting professor at Columbia University. The Chomskys had their first child, Aviva, that same year. He also published his first book on linguistics, \"Syntactic Structures\", a work that radically opposed the dominant Harris\u2013Bloomfield trend in the field. Responses to Chomsky's ideas ranged from indifference to hostility, and his work proved divisive and caused \"significant upheaval\" in the discipline. The linguist John Lyons later asserted that \"Syntactic Structures\" \"revolutionized the scientific study of language\". From 1958 to 1959 Chomsky was a National Science Foundation fellow at the Institute for Advanced Study in Princeton, New Jersey.\nChomsky's provocative critique of B. F. Skinner, who viewed language as entirely learned behavior, and that critique's challenge to the dominant behaviorist paradigm thrust Chomsky into the limelight. Chomsky argued that behaviorism underplayed the role of human creativity in learning language and overplayed the role of external conditions in influencing verbal behavior. He proceeded to found MIT's graduate program in linguistics with Halle. In 1961, Chomsky received tenure and became a full professor in the Department of Modern Languages and Linguistics. He was appointed plenary speaker at the Ninth International Congress of Linguists, held in 1962 in Cambridge, Massachusetts, which established him as the \"de facto\" spokesperson of American linguistics. Between 1963 and 1965 he consulted on a military-sponsored project to teach computers to understand natural English commands from military generals.\nChomsky continued to publish his linguistic ideas throughout the decade, including in \"Aspects of the Theory of Syntax\" (1965), \"Topics in the Theory of Generative Grammar\" (1966), and \"\" (1966). Along with Halle, he also edited the \"Studies in Language\" series of books for Harper and Row. As he began to accrue significant academic recognition and honors for his work, Chomsky lectured at the University of California, Berkeley, in 1966. These lectures were published as \"Language and Mind\" in 1968. In the late 1960s, a high-profile intellectual rift later known as the linguistic wars developed between Chomsky and some of his colleagues and doctoral students\u2014including Paul Postal, John Ross, George Lakoff, and James D. McCawley\u2014who contended that Chomsky's syntax-based, interpretivist linguistics did not properly account for semantic context (general semantics). A post hoc assessment of this period concluded that the opposing programs ultimately were complementary, each informing the other.\nAnti-war activism and dissent: 1967\u20131975.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n[I]t does not require very far-reaching, specialized knowledge to perceive that the United States was invading South Vietnam. And, in fact, to take apart the system of illusions and deception which functions to prevent understanding of contemporary reality [is] not a task that requires extraordinary skill or understanding. It requires the kind of normal skepticism and willingness to apply one's analytical skills that almost all people have and that they can exercise.\n\u2014Chomsky on the Vietnam War\nChomsky joined protests against U.S. involvement in the Vietnam War in 1962, speaking on the subject at small gatherings in churches and homes. His 1967 critique of U.S. involvement, \"The Responsibility of Intellectuals\", among other contributions to \"The New York Review of Books\", debuted Chomsky as a public dissident. This essay and other political articles were collected and published in 1969 as part of Chomsky's first political book, \"American Power and the New Mandarins\". He followed this with further political books, including \"At War with Asia\" (1970), \"The Backroom Boys\" (1973), \"For Reasons of State\" (1973), and \"Peace in the Middle East?\" (1974), published by Pantheon Books. These publications led to Chomsky's association with the American New Left movement, though he thought little of prominent New Left intellectuals Herbert Marcuse and Erich Fromm and preferred the company of activists to that of intellectuals. Chomsky remained largely ignored by the mainstream press throughout this period.\nChomsky also became involved in left-wing activism. Chomsky refused to pay half his taxes, publicly supported students who refused the draft, and was arrested while participating in an anti-war teach-in outside the Pentagon. During this time, Chomsky co-founded the anti-war collective RESIST with Hans Koning, Mitchell Goodman, Denise Levertov, William Sloane Coffin, and Dwight Macdonald. Although he questioned the objectives of the 1968 student protests, Chomsky regularly gave lectures to student activist groups and, with his colleague Louis Kampf, ran undergraduate courses on politics at MIT independently of the conservative-dominated political science department. When student activists campaigned to stop weapons and counterinsurgency research at MIT, Chomsky was sympathetic but felt that the research should remain under MIT's oversight and limited to systems of deterrence and defense. Chomsky has acknowledged that his MIT lab's funding at this time came from the military. He later said he considered resigning from MIT during the Vietnam War. There has since been a wide-ranging debate about what effects Chomsky's employment at MIT had on his political and linguistic ideas.\nChomsky's anti-war activism led to his arrest on multiple occasions and he was on President Richard Nixon's master list of political opponents. Chomsky was aware of the potential repercussions of his civil disobedience, and his wife began studying for her own doctorate in linguistics to support the family in the event of Chomsky's imprisonment or joblessness. Chomsky's scientific reputation insulated him from administrative action based on his beliefs. In 1970 he visited southeast Asia to lecture at Vietnam's Hanoi University of Science and Technology and toured war refugee camps in Laos. In 1973 he helped lead a committee commemorating the 50th anniversary of the War Resisters League.\nChomsky's work in linguistics continued to gain international recognition as he received multiple honorary doctorates. He delivered public lectures at the University of Cambridge, Columbia University (Woodbridge Lectures), and Stanford University. His appearance in a 1971 debate with French continental philosopher Michel Foucault positioned Chomsky as a symbolic figurehead of analytic philosophy. He continued to publish extensively on linguistics, producing \"Studies on Semantics in Generative Grammar\" (1972), an enlarged edition of \"Language and Mind\" (1972), and \"Reflections on Language\" (1975). In 1974 Chomsky became a corresponding fellow of the British Academy.\nEdward S. Herman and the Faurisson affair: 1976\u20131980.\nIn the late 1970s and 1980s, Chomsky's linguistic publications expanded and clarified his earlier work, addressing his critics and updating his grammatical theory. His political talks often generated considerable controversy, particularly when he criticized the Israeli government and military. In the early 1970s Chomsky began collaborating with Edward S. Herman, who had also published critiques of the U.S. war in Vietnam. Together they wrote \"\", a book that criticized U.S. military involvement in Southeast Asia and the mainstream media's failure to cover it. Warner Modular published it in 1973, but its parent company disapproved of the book's contents and ordered all copies destroyed.\nWhile mainstream publishing options proved elusive, Chomsky found support from Michael Albert's South End Press, an activist-oriented publishing company. In 1979, South End published Chomsky and Herman's revised \"Counter-Revolutionary Violence\" as the two-volume \"The Political Economy of Human Rights\", which compares U.S. media reactions to the Cambodian genocide and the Indonesian occupation of East Timor. It argues that because Indonesia was a U.S. ally, U.S. media ignored the East Timorese situation while focusing on events in Cambodia, a U.S. enemy. Chomsky's response included two testimonials before the United Nations' Special Committee on Decolonization, successful encouragement for American media to cover the occupation, and meetings with refugees in Lisbon. Marxist academic Steven Lukes most prominently publicly accused Chomsky of betraying his anarchist ideals and acting as an apologist for Cambodian leader Pol Pot. Herman said that the controversy \"imposed a serious personal cost\" on Chomsky, who considered the personal criticism less important than the evidence that \"mainstream intelligentsia suppressed or justified the crimes of their own states\".\nChomsky had long publicly criticized Nazism, and totalitarianism more generally, but his commitment to freedom of speech led him to defend the right of French historian Robert Faurisson to advocate a position widely characterized as Holocaust denial. Without Chomsky's knowledge, his plea for Faurisson's freedom of speech was published as the preface to the latter's 1980 book . Chomsky was widely condemned for defending Faurisson, and France's mainstream press accused Chomsky of being a Holocaust denier himself, refusing to publish his rebuttals to their accusations. Critiquing Chomsky's position, sociologist Werner Cohn later published an analysis of the affair titled \"Partners in Hate: Noam Chomsky and the Holocaust Deniers\". The Faurisson affair had a lasting, damaging effect on Chomsky's career, especially in France.\nCritique of propaganda and international affairs.\nIn 1985, during the Nicaraguan Contra War\u2014in which the U.S. supported the contra militia against the Sandinista government\u2014Chomsky traveled to Managua to meet with workers' organizations and refugees of the conflict, giving public lectures on politics and linguistics. Many of these lectures were published in 1987 as \"On Power and Ideology: The Managua Lectures\". In 1983 he published \"The Fateful Triangle\", which argued that the U.S. had continually used the Israeli\u2013Palestinian conflict for its own ends. In 1988, Chomsky visited the Palestinian territories to witness the impact of Israeli occupation.\nChomsky and Herman's \"\" (1988) outlines their propaganda model for understanding mainstream media. Even in countries without official censorship, they argued, the news is censored through five filters that greatly influence both what and how news is presented. The book received . In 1989, Chomsky published \"Necessary Illusions: Thought Control in Democratic Societies,\" in which he suggests that a worthwhile democracy requires that its citizens undertake intellectual self-defense against the media and elite intellectual culture that seeks to control them. By the 1980s, Chomsky's students had become prominent linguists who, in turn, expanded and revised his linguistic theories.\nIn the 1990s, Chomsky embraced political activism to a greater degree than before. Retaining his commitment to the cause of East Timorese independence, in 1995 he visited Australia to talk on the issue at the behest of the East Timorese Relief Association and the National Council for East Timorese Resistance. The lectures he gave on the subject were published as \"Powers and Prospects\" in 1996. As a result of the international publicity Chomsky generated, his biographer Wolfgang Sperlich opined that he did more to aid the cause of East Timorese independence than anyone but the investigative journalist John Pilger. After East Timor attained independence from Indonesia in 1999, the Australian-led International Force for East Timor arrived as a peacekeeping force; Chomsky was critical of this, believing it was designed to secure Australian access to East Timor's oil and gas reserves under the Timor Gap Treaty.\nChomsky was widely interviewed after the September 11 attacks in 2001 as the American public attempted to make sense of the attacks. He argued that the ensuing War on Terror was not a new development but a continuation of U.S. foreign policy and concomitant rhetoric since at least the Reagan era. He gave the D.T. Lakdawala Memorial Lecture in New Delhi in 2001, and in 2003 visited Cuba at the invitation of the Latin American Association of Social Scientists. Chomsky's 2003 \"Hegemony or Survival\" articulated what he called the United States' \"imperial grand strategy\" and critiqued the Iraq War and other aspects of the war on terror. Chomsky toured internationally with greater regularity during this period.\nRetirement.\nChomsky retired from MIT in 2002, but continued to conduct research and seminars on campus as an emeritus. That same year he visited Turkey to attend the trial of a publisher who had been accused of treason for printing one of Chomsky's books; Chomsky insisted on being a co-defendant and amid international media attention, the Security Courts dropped the charge on the first day. During that trip Chomsky visited Kurdish areas of Turkey and spoke out in favor of the Kurds' human rights. A supporter of the World Social Forum, he attended its conferences in Brazil in both 2002 and 2003, also attending the Forum event in India.\nChomsky supported the 2011 Occupy movement, speaking at encampments and publishing on the movement, which he called a reaction to a 30-year class war. The 2015 documentary \"Requiem for the American Dream\" summarizes his views on capitalism and economic inequality through a \"75-minute teach-in\".\nIn 2015, Chomsky and his wife purchased a residence in S\u00e3o Paulo, Brazil, and began splitting their time between Brazil and the U.S. Chomsky taught a short-term politics course at the University of Arizona in 2017. He was later hired as the Agnese Nelms Haury Chair in the Agnese Nelms Haury Program in Environment and Social Justice, a part-time professorship in the linguistics department with duties including teaching and public seminars. His salary was covered by philanthropic donations. After a stroke in June 2023, Chomsky moved to Brazil full-time.\nLinguistic theory.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nWhat started as purely linguistic research\u00a0... has led, through involvement in political causes and an identification with an older philosophic tradition, to no less than an attempt to formulate an overall theory of man. The roots of this are manifest in the linguistic theory\u00a0... The discovery of cognitive structures common to the human race but only to humans (species specific), leads quite easily to thinking of unalienable human attributes.\n \u2014Edward Marcotte on the significance of Chomsky's linguistic theory\nThe basis of Chomsky's linguistic theory lies in biolinguistics, the linguistic school that holds that the principles underpinning the structure of language are biologically preset in the human mind and hence genetically inherited. He argues that all humans share the same underlying linguistic structure, irrespective of sociocultural differences. In adopting this position Chomsky rejects the radical behaviorist psychology of B.\u00a0F. Skinner, who viewed speech, thought, and all behavior as a completely learned product of the interactions between organisms and their environments. Accordingly, Chomsky argues that language is a unique evolutionary development of the human species and distinguished from modes of communication used by any other animal species. Chomsky argues that his nativist, internalist view of language is consistent with the philosophical school of \"rationalism\" and contrasts with the anti-nativist, externalist view of language consistent with the philosophical school of \"empiricism\", which contends that all knowledge, including language, comes from external stimuli. Historians have disputed Chomsky's claim about rationalism on the basis that his theory of innate grammar excludes propositional knowledge and instead focuses on innate learning capacities or structures.\nUniversal grammar.\nSince the 1960s, Chomsky has maintained that syntactic knowledge is partially inborn, implying that children need only learn certain language-specific features of their native languages. He bases his argument on observations about human language acquisition and describes a \"poverty of the stimulus\": an enormous gap between the linguistic stimuli to which children are exposed and the rich linguistic competence they attain. For example, although children are exposed to only a very small and finite subset of the allowable syntactic variants within their first language, they somehow acquire the highly organized and systematic ability to understand and produce an infinite number of sentences, including ones that have never before been uttered, in that language. To explain this, Chomsky proposed that the primary linguistic data must be supplemented by an innate linguistic capacity. Furthermore, while a human baby and a kitten are both capable of inductive reasoning, if they are exposed to exactly the same linguistic data, the human will always acquire the ability to understand and produce language, while the kitten will never acquire either ability. Chomsky referred to this difference in capacity as the language acquisition device, and suggested that linguists needed to determine both what that device is and what constraints it imposes on the range of possible human languages. The universal features that result from these constraints would constitute \"universal grammar\". Multiple researchers have challenged universal grammar on the grounds of the evolutionary infeasibility of its genetic basis for language, the lack of crosslinguistic surface universals, and the unproven link between innate/universal structures and the structures of specific languages. Michael Tomasello has challenged Chomsky's theory of innate syntactic knowledge as based on theory and not behavioral observation. The empirical basis of poverty of the stimulus arguments has been challenged by Geoffrey Pullum and others, leading to back-and-forth debate in the language acquisition literature. Recent work has also suggested that some recurrent neural network architectures can learn hierarchical structure without an explicit constraint.\nGenerative grammar.\nChomsky is generally credited with launching the research tradition of generative grammar, which aims to explain the cognitive basis of language by formulating and testing explicit models of humans' subconscious grammatical knowledge. Generative grammar proposes models of language consisting of explicit rule systems, which make testable falsifiable predictions. The goal of generative grammar is sometimes described as answering the question \"What is that that you know when you know a language?\"\nWithin generative grammar, Chomsky's initial model was called transformational grammar. Chomsky developed transformational grammar in the mid-1950s, whereupon it became the dominant syntactic theory in linguistics for two decades. \"Transformations\" are syntactic rules that derive \"surface structure\" from \"deep structure\", which was often considered to reflect the structure of meaning. Transformational grammar later developed into the 1980s government and binding theory and thence into the minimalist program. This research focused on the principles and parameters framework, which explained children's ability to learn any language by filling open parameters (a set of universal grammar principles) that adapt as the child encounters linguistic data. The minimalist program, initiated by Chomsky, asks which minimal principles and parameters theory fits most elegantly, naturally, and simply.\nChomsky is commonly credited with inventing transformational-generative grammar, but his original contribution was considered modest when he first published his theory. In his 1955 dissertation and his 1957 textbook \"Syntactic Structures\", he presented recent developments in the analysis formulated by Zellig Harris, who was Chomsky's PhD supervisor, and by Charles F. Hockett. Their method derives from the work of the structural linguist Louis Hjelmslev, who introduced algorithmic grammar to general linguistics. Based on this rule-based notation of grammars, Chomsky grouped logically possible phrase-structure grammar types into a series of four nested subsets and increasingly complex types, together known as the Chomsky hierarchy. This classification remains relevant to formal language theory and theoretical computer science, especially programming language theory, compiler construction, and automata theory. Chomsky's \"Syntactic Structures\" became, beyond generative linguistics as such, a catalyst for connecting what in Hjelmslev's and Jespersen's time was the beginnings of structural linguistics, which has become cognitive linguistics.\nPolitical views.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThe second major area to which Chomsky has contributed\u2014and surely the best known in terms of the number of people in his audience and the ease of understanding what he writes and says\u2014is his work on sociopolitical analysis; political, social, and economic history; and critical assessment of current political circumstance. In Chomsky's view, although those in power might\u2014and do\u2014try to obscure their intentions and to defend their actions in ways that make them acceptable to citizens, it is easy for anyone who is willing to be critical and consider the facts to discern what they are up to.\n\u2014James McGilvray, 2014\nChomsky is a prominent political dissident. His political views have changed little since his childhood, when he was influenced by the emphasis on political activism that was ingrained in Jewish working-class tradition. He usually identifies as an anarcho-syndicalist or a libertarian socialist. He views these positions not as precise political theories but as ideals that he thinks best meet human needs: liberty, community, and freedom of association. Unlike some other socialists, such as Marxists, Chomsky believes that politics lies outside the remit of science, but he still roots his ideas about an ideal society in empirical data and empirically justified theories.\nIn Chomsky's view, the truth about political realities is systematically distorted or suppressed by an elite corporatocracy, which uses corporate media, advertising, and think tanks to promote its own propaganda. His work seeks to reveal such manipulations and the truth they obscure. Chomsky believes this web of falsehood can be broken by \"common sense\", critical thinking, and understanding the roles of self-interest and self-deception, and that intellectuals abdicate their moral responsibility to tell the truth about the world in fear of losing prestige and funding. He argues that, as such an intellectual, it is his duty to use his social privilege, resources, and training to aid popular democracy movements in their struggles.\nAlthough he has participated in direct action demonstrations\u2014joining protests, being arrested, organizing groups\u2014Chomsky's primary political outlet is education, i.e., free public lessons. Chomsky is a longtime member of the Democratic Socialists of America (DSA) and a longtime member of the Industrial Workers of the World (IWW) international union, as was his father.\nUnited States foreign policy.\nChomsky has been a prominent critic of American imperialism, but is not a pacifist, believing World War II was justified as America's last defensive war. He believes that U.S. foreign policy's basic principle is the establishment of \"open societies\" that are economically and politically controlled by the U.S. and where U.S.-based businesses can prosper. He argues that the U.S. seeks to suppress any movements within these countries that are not compliant with U.S. interests and to ensure that U.S.-friendly governments are placed in power. When discussing current events, he emphasizes their place within a wider historical perspective. He believes that official, sanctioned historical accounts of U.S. and British extraterritorial operations have consistently whitewashed these nations' actions in order to present them as having benevolent motives in either spreading democracy or, in older instances, spreading Christianity; by criticizing these accounts, he seeks to correct them. Prominent examples he regularly cites are the actions of the British Empire in India and Africa and U.S. actions in Vietnam, the Philippines, Latin America, and the Middle East.\nChomsky's political work has centered heavily on criticizing the actions of the United States. He has said he focuses on the U.S. because the country has militarily and economically dominated the world during his lifetime and because its liberal democratic electoral system allows the citizenry to influence government policy. His hope is that, by spreading awareness of the impact U.S. foreign policies have on the populations affected by them, he can sway the populations of the U.S. and other countries into opposing the policies. He urges people to criticize their governments' motivations, decisions, and actions, to accept responsibility for their own thoughts and actions, and to apply the same standards to others as to themselves.\nChomsky has been critical of U.S. involvement in the Israeli\u2013Palestinian conflict, arguing that it has consistently blocked a peaceful settlement. He also criticizes the U.S.'s close ties with Saudi Arabia and involvement in Saudi Arabian-led intervention in Yemen, highlighting that Saudi Arabia has \"one of the most grotesque human rights records in the world\".\nChomsky called the Russian invasion of Ukraine a criminal act of aggression and noted that Russia was committing major war crimes in the country. He considered support for Ukraine's self-defense legitimate and said Ukraine should be given enough military aid to defend itself, but not enough to cause \"an escalation\". His criticism of the war focused on the United States. He alleged that the U.S. rejected any compromise with Russia and that this might have provoked the invasion. According to Chomsky, the U.S. was arming Ukraine only to weaken Russia, and Ukrainian requests for heavy weaponry were untrue \"Western propaganda\", despite Ukraine's President Volodymyr Zelenskyy repeatedly asking for them. More than a year into the invasion, Chomsky argued that Russia was waging the war \"more humanely\" than the U.S. did the invasion of Iraq.\nCapitalism and socialism.\nIn his youth, Chomsky developed a dislike of capitalism and the pursuit of material wealth. At the same time, he developed a disdain for authoritarian socialism, as represented by the Marxist\u2013Leninist policies of the Soviet Union. Rather than accepting the common view among U.S. economists that a spectrum exists between total state ownership of the economy and total private ownership, he instead suggests that a spectrum should be understood between total democratic control of the economy and total autocratic control (whether state or private). He argues that Western capitalist countries are not really democratic, because, in his view, a truly democratic society is one in which all persons have a say in public economic policy. He has stated his opposition to ruling elites, among them institutions like the IMF, World Bank, and GATT (precursor to the WTO).\nChomsky highlights that, since the 1970s, the U.S. has become increasingly economically unequal as a result of the repeal of various financial regulations and the unilateral rescinding of the Bretton Woods financial control agreement by the U.S. He characterizes the U.S. as a \"de facto\" one-party state, viewing both the Republican Party and Democratic Party as manifestations of a single \"Business Party\" controlled by corporate and financial interests. Chomsky highlights that, within Western capitalist liberal democracies, at least 80% of the population has no control over economic decisions, which are instead in the hands of a management class and ultimately controlled by a small, wealthy elite.\nNoting the entrenchment of such an economic system, Chomsky believes that change is possible through the organized cooperation of large numbers of people who understand the problem and know how they want to reorganize the economy more equitably. Acknowledging that corporate domination of media and government stifles any significant change to this system, he sees reason for optimism in historical examples such as the social rejection of slavery as immoral, the advances in women's rights, and the forcing of government to justify invasions. He views violent revolution to overthrow a government as a last resort to be avoided if possible, citing the example of historical revolutions where the population's welfare has worsened as a result of upheaval.\nChomsky sees libertarian socialist and anarcho-syndicalist ideas as the descendants of the classical liberal ideas of the Age of Enlightenment, arguing that his ideological position revolves around \"nourishing the libertarian and creative character of the human being\". He envisions an anarcho-syndicalist future with direct worker control of the means of production and government by workers' councils, who would select temporary and revocable representatives to meet together at general assemblies. The point of this self-governance is to make each citizen, in Thomas Jefferson's words, \"a direct participator in the government of affairs\". He believes that there will be no need for political parties. By controlling their productive life, he believes that individuals can gain job satisfaction and a sense of fulfillment and purpose. He argues that unpleasant and unpopular jobs could be fully automated, specially remunerated, or communally shared.\nIsraeli\u2013Palestinian conflict.\nChomsky has written prolifically about the Israeli\u2013Palestinian conflict, aiming to raise public awareness of it. A labor Zionist who later became what is today considered an anti-Zionist, Chomsky has criticized the Israeli settlements in the Israeli-occupied West Bank, which he likens to a settler colony. He has said that the 1947 United Nations Partition Plan for Palestine was a bad decision, but given the realpolitik of the situation, he has also considered a two-state solution on the condition that the nation-states exist on equal terms.\nChomsky has said that characterizing Israel's treatment of the Palestinians as apartheid, similar to the system that existed in South Africa, would be a \"gift to Israel\", as he has long held that \"the Occupied Territories are much worse than South Africa\". South Africa depended on its black population for labor, but Chomsky argues the same is not true of Israel, which in his view seeks to make the situation for Palestinians under its occupation unlivable, especially in the West Bank and the Gaza Strip, where \"atrocities\" take place every day. He also argues that, unlike South Africa, Israel has not sought the international community's approval, but rather relies solely on U.S. support. Chomsky has said that the Israeli-led blockade of the Gaza Strip has turned it into a \"concentration camp\" and expressed fears similar to Israeli intellectual Yeshayahu Leibowitz's 1990s warning that the continued occupation of the Palestinian territories could turn Israeli Jews into \"Judeo-Nazis\". Chomsky has said that Leibowitz's warning \"was a direct reflection of the continued occupation, the humiliation of people, the degradation, and the terrorist attacks by the Israeli government\". He has also called the U.S. a violent state that exports violence by supporting Israeli \"atrocities\" against the Palestinians and said that listening to American mainstream media, including CBS, is like listening to \"Israeli propaganda agencies\".\nChomsky was denied entry to the West Bank in 2010 because of his criticisms of Israel. He had been invited to deliver a lecture at Bir Zeit University and was to meet with Palestinian Prime Minister Salam Fayyad. An Israeli Foreign Ministry spokesman later said that Chomsky was denied entry by mistake.\nIn his 1983 book \"The Fateful Triangle\", Chomsky criticized the Palestine Liberation Organization for its \"self-destructiveness\" and \"suicidal character\" and disapproved of its programs of \"armed struggle\" and \"erratic violence\". He also criticized the Arab governments as not \"decent\". Given what he has described as his very Jewish upbringing with deeply Zionist activist parents, Chomsky's views have drawn controversy and criticism. They are rooted in the kibbutzim and socialist binational cooperation. In a 2014 interview on \"Democracy Now!\", Chomsky said that the charter of Hamas, which calls for Israel's destruction, \"means practically nothing\", having been created \"by a small group of people under siege, under attack in 1988\". He compared it to the electoral program of the Likud party, which, he said, \"states explicitly that there can never be a Palestinian state west of the Jordan River. And they not only state it in their charter, that's a call for the destruction of Palestine, explicit call for it\".\nMass media and propaganda.\nChomsky's political writings have largely focused on ideology, social and political power, mass media, and state policy. One of his best-known works, \"Manufacturing Consent\", dissects the media's role in reinforcing and acquiescing to state policies across the political spectrum while marginalizing contrary perspectives. Chomsky asserts that this version of censorship, by government-guided \"free market\" forces, is subtler and harder to undermine than was the equivalent propaganda system in the Soviet Union. As he argues, the mainstream press is corporate-owned and thus reflects corporate priorities and interests. Acknowledging that many American journalists are dedicated and well-meaning, he argues that the mass media's choices of topics and issues, the unquestioned premises on which that coverage rests, and the range of opinions expressed are all constrained to reinforce the state's ideology: although mass media will criticize individual politicians and political parties, it will not undermine the wider state-corporate nexus of which it is a part. As evidence, he highlights that the U.S. mass media does not employ any socialist journalists or political commentators. He also points to examples of important news stories that the U.S. mainstream media has ignored because reporting on them would reflect badly upon the country, including the murder of Black Panther Fred Hampton with possible FBI involvement, the massacres in Nicaragua perpetrated by U.S.-funded Contras, and the constant reporting on Israeli deaths without equivalent coverage of the far larger number of Palestinian deaths in that conflict. To remedy this situation, Chomsky calls for grassroots democratic control and involvement of the media.\nChomsky considers most conspiracy theories fruitless, distracting substitutes for thinking about policy formation in an institutional framework, where individual manipulation is secondary to broader social imperatives. He separates his Propaganda Model from conspiracy in that he is describing institutions following their natural imperatives rather than collusive forces with secret controls. Instead of supporting the educational system as an antidote, he believes that most education is counterproductive. Chomsky describes mass education as a system solely intended to turn farmers from independent producers into unthinking industrial employees.\nReactions of critics and counter-criticism: 1980s\u2013present.\nIn the 2004 book \"The Anti-Chomsky Reader\", Peter Collier and David Horowitz accuse Chomsky of cherry-picking facts to suit his theories. Horowitz has also criticized Chomsky's anti-Americanism:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For 40 years Noam Chomsky has turned out book after book, pamphlet after pamphlet and speech after speech with one message, and one message alone: America is the Great Satan; it is the fount of evil in the world. In Chomsky's demented universe, America is responsible not only for its own bad deeds, but for the bad deeds of others, including those of the terrorists who struck the World Trade Center and the Pentagon. In this attitude he is the medium for all those who now search the ruins of Manhattan not for the victims and the American dead, but for the \"root causes\" of the catastrophe that befell them.\nFor the conservative public policy think tank the Hoover Institution, Peter Schweizer wrote in January 2006, \"Chomsky favors the estate tax and massive income redistribution\u2014just not the redistribution of his income.\" Schweizer criticized Chomsky for setting up an estate plan and protecting his own intellectual property as it relates to his published works, as well as the high speaking fees that Chomsky received on a regular basis, around $9,000\u2013$12,000 per talk at that time.\nChomsky has been accused of treating socialist or communist regimes with credulity and examining capitalist regimes with greater scrutiny or criticism:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Chomsky's analysis of U.S. actions plunged deep into dark U.S. machinations, but when traveling among the Communists he rested content with appearances. The countryside outside Hanoi, he reported in \"The New York Review of Books\", displayed \"a high degree of democratic participation at the village and regional levels.\" But how could he tell? Chomsky did not speak Vietnamese, and so he depended on government translators, tour guides, and handlers for information. In [Communist] Vietnamese hands, the clear-eyed skepticism turned into willing credulousness.According to Nikolas Kozloff, writing for \"Al Jazeera\" in September 2012, Chomsky \"has drawn the world's attention to the various misdeeds of the US and its proxies around the world, and for that he deserves credit. Yet, in seeking to avoid controversy at all costs Chomsky has turned into something of an ideologue. Scour the Chomsky web site and you won't find significant discussion of Belarus or Latin America's flirtation with outside authoritarian leaders, for that matter.\"\nPolitical activist George Monbiot has argued that \"Part of the problem is that a kind of cult has developed around Noam Chomsky and John Pilger, which cannot believe they could ever be wrong, and produces ever more elaborate conspiracy theories to justify their mistakes.\"\nDefenders of Chomsky have countered that he has been censored or left out of public debate. Claims of this nature date to the Reagan era. Writing for \"The Washington Post\" in February 1988, Saul Landau wrote, \"It is unhealthy that Chomsky's insights are excluded from the policy debate. His relentless prosecutorial prose, with a hint of Talmudic whine and the rationalist anarchism of Tom Paine, may reflect a justified frustration.\"\nPhilosophy.\nChomsky has also been active in a number of philosophical fields, including philosophy of mind, philosophy of language, and philosophy of science. In these fields he is credited with ushering in the \"cognitive revolution\", a significant paradigm shift that rejected logical positivism, the prevailing philosophical methodology of the time, and reframed how philosophers think about language and the mind. Chomsky views the cognitive revolution as rooted in 17th-century rationalist ideals. His position\u2014the idea that the mind contains inherent structures to understand language, perception, and thought\u2014has more in common with rationalism than behaviorism. He named one of his key works \"Cartesian Linguistics: A Chapter in the History of Rationalist Thought\" (1966). This sparked criticism from historians and philosophers who disagreed with Chomsky's interpretations of classical sources and use of philosophical terminology. In the philosophy of language, Chomsky is particularly known for his criticisms of the notion of reference and meaning in human language and his perspective on the nature and function of mental representations.\nChomsky's famous 1971 debate on human nature with the French philosopher Michel Foucault was a symbolic clash of the analytic and continental philosophy traditions, represented by Chomsky and Foucault, respectively. It showed what appeared to be irreconcilable differences between two moral and intellectual luminaries of the 20th century. Foucault held that any definition of human nature is connected to our present-day conceptions of ourselves; Chomsky held that human nature contained universals such as a common standard of moral justice as deduced through reason. Chomsky criticized postmodernism and French philosophy generally, arguing that the obscure language of postmodern, leftist philosophers gives little aid to the working classes. He has also debated analytic philosophers, including Tyler Burge, Donald Davidson, Michael Dummett, Saul Kripke, Thomas Nagel, Hilary Putnam, Willard Van Orman Quine, and John Searle.\nChomsky's contributions span intellectual and world history, including the history of philosophy. Irony is a recurring characteristic of his writing, such as rhetorically implying that his readers already know something to be true, which engages the reader more actively in assessing the veracity of his claims.\nPersonal life.\nChomsky endeavors to separate his family life, linguistic scholarship, and political activism from each other. An intensely private person, he is uninterested in appearances and the fame his work has brought him. McGilvray suggests that Chomsky is not motivated by a desire for fame, but impelled to tell what he perceives as the truth and a desire to aid others in doing so. Chomsky acknowledges that his income affords him a privileged life compared to the majority of the world's population; nevertheless, he characterizes himself as a \"worker\", albeit one who uses his intellect as his employable skill. He reads four or five newspapers daily; in the U.S., he subscribes to \"The Boston Globe\", \"The New York Times\", \"The Wall Street Journal\", \"Financial Times\", and \"The Christian Science Monitor\". Chomsky is not religious but has expressed approval of forms of religion such as liberation theology.\nChomsky is known to use charged language (\"corrupt\", \"fascist\", \"fraudulent\") when describing established political and academic figures, which can polarize his audience but is in keeping with his belief that much scholarship is self-serving. His colleague Steven Pinker has said that Chomsky \"portrays people who disagree with him as stupid or evil, using withering scorn in his rhetoric\", and that this contributes to the extreme reactions he receives. Chomsky avoids academic conferences, including left-oriented ones such as the Socialist Scholars Conference, preferring to speak to activist groups or hold university seminars for mass audiences. His approach to academic freedom has led him to support MIT academics whose actions he deplores; in 1969, when Chomsky heard that Walt Rostow, a major architect of the Vietnam war, wanted to return to work at MIT, Chomsky threatened \"to protest publicly\" if Rostow were denied a position at MIT. In 1989, when Pentagon adviser John Deutch applied to be president of MIT, Chomsky supported his candidacy. Later, when Deutch became head of the CIA, \"The New York Times\" quoted Chomsky as saying, \"He has more honesty and integrity than anyone I've ever met... If somebody's got to be running the CIA, I'm glad it's him.\"\nChomsky was married to Carol Doris (n\u00e9e\u00a0Schatz) from 1949 until her death in 2008. They had three children together: Aviva (b. 1957), Diane (b. 1960), and Harry (b. 1967). In 2014, Chomsky married Valeria Wasserman, a translator for the Institute for Advanced Studies at the University of S\u00e3o Paulo. They have owned a home in Wasserman's native country, Brazil, since 2015. Judith Chomsky and Marvin J. Chomsky are cousins of Noam Chomsky.\nIn 2023, Chomsky suffered a massive stroke and was flown to a hospital in S\u00e3o Paulo, Brazil, to recuperate. He can no longer walk or communicate, making his return to public life improbable, but he continues to follow current events such as the Gaza war. He was discharged in June 2024 to continue his recovery at home. The same month, Chomsky trended on social media amid false reports of his death. Periodicals retracted premature obituaries.\nEmails related to the activities of convicted child sex offender Jeffrey Epstein released by the House Oversight Committee in November 2025 revealed that Chomsky befriended him after his 2008 conviction; remained in contact with him at least through 2017; and called him a \u201chighly valued friend.\u201d The discussions went beyond what Chomsky had previously said were the boundaries of his interactions with Epstein and included a formal letter of endorsement from 2017 or later. Valeria, acting as Chomsky's assistant, sent Epstein belated birthday wishes in 2017.\nReception and influence.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n[Chomsky's] voice is heard in academia beyond linguistics and philosophy: from computer science to neuroscience, from anthropology to education, mathematics and literary criticism. If we include Chomsky's political activism then the boundaries become quite blurred, and it comes as no surprise that Chomsky is increasingly seen as enemy number one by those who inhabit that wide sphere of reactionary discourse and action.\n\u2014Sperlich, 2006\nChomsky has been a defining Western intellectual figure, central to the field of linguistics and definitive in cognitive science, computer science, philosophy, and psychology. In addition to being known as one of the most important intellectuals of his time, Chomsky has a dual legacy as a leader and luminary in both linguistics and the realm of political dissent. Despite his academic success, his political viewpoints and activism have resulted in his being distrusted by mainstream media, and he is regarded as being \"on the outer margin of acceptability\". Chomsky's public image and social reputation often color his work's public reception.\nIn academia.\nMcGilvray observes that Chomsky inaugurated the \"cognitive revolution\" in linguistics, and that he is largely responsible for establishing the field as a formal, natural science, moving it away from the procedural form of structural linguistics dominant during the mid-20th century. As such, some have called Chomsky \"the father of modern linguistics\". Linguist John Lyons further remarked that within a few decades of publication, Chomskyan linguistics had become \"the most dynamic and influential\" school of thought in the field. By the 1970s his work had also come to exert a considerable influence on philosophy, and a Minnesota State University Moorhead poll ranked \"Syntactic Structures\" as the single most important work in cognitive science. In addition, his work in automata theory and the Chomsky hierarchy have become well known in computer science, and he is much cited in computational linguistics.\nChomsky's criticisms of behaviorism contributed substantially to the decline of behaviorist psychology; in addition, he is generally regarded as one of the primary founders of the field of cognitive science. Some arguments in evolutionary psychology are derived from his research results; Nim Chimpsky, a chimpanzee who was the subject of a study in animal language acquisition at Columbia University, was named after Chomsky in reference to his view of language acquisition as a uniquely human ability.\nACM Turing Award winner Donald Knuth credited Chomsky's work with helping him combine his interests in mathematics, linguistics, and computer science. IBM computer scientist John Backus, another Turing Award winner, used some of Chomsky's concepts to help him develop FORTRAN, the first widely used high-level computer programming language. Chomsky's theory of generative grammar has also influenced work in music theory and analysis, such as Fred Lerdahl's and Ray Jackendoff's generative theory of tonal music.\nChomsky is among the most cited authors living or dead. He was cited within the Arts and Humanities Citation Index more often than any other living scholar from 1980 to 1992. Chomsky was also extensively cited in the Social Sciences Citation Index and Science Citation Index during the same period. The librarian who conducted the research said that the statistics show that \"he is very widely read across disciplines and that his work is used by researchers across disciplines... it seems that you can't write a paper without citing Noam Chomsky.\" As a result of his influence, there are dueling camps of Chomskyan and non-Chomskyan linguistics. Their disputes are often acrimonious. Additionally, according to journalist Maya Jaggi, Chomsky is among the most quoted sources in the humanities, ranking alongside Marx, Shakespeare and the Bible.\nIn politics.\nChomsky's status as the \"most-quoted living author\" is credited to his political writings, which vastly outnumber his writings on linguistics. Chomsky biographer Wolfgang B. Sperlich characterizes him as \"one of the most notable contemporary champions of the people\"; journalist John Pilger has described him as a \"genuine people's hero; an inspiration for struggles all over the world for that basic decency known as freedom. To a lot of people in the margins\u2014activists and movements\u2014he's unfailingly supportive.\" Arundhati Roy has called him \"one of the greatest, most radical public thinkers of our time\", and Edward Said thought him \"one of the most significant challengers of unjust power and delusions\". Fred Halliday has said that by the start of the 21st century Chomsky had become a \"guru\" for the world's anti-capitalist and anti-imperialist movements. The propaganda model of media criticism that he and Herman developed has been widely accepted in radical media critiques and adopted to some level in mainstream criticism of the media, also exerting a significant influence on the growth of alternative media, including radio, publishers, and the Internet, which in turn have helped to disseminate his work.\nDespite this broad influence, university departments devoted to history and political science rarely include Chomsky's work on their undergraduate syllabi. Critics have argued that despite publishing widely on social and political issues, Chomsky has no formal expertise in these areas; he has responded that such issues are not as complex as many social scientists claim and that almost everyone is able to comprehend them regardless of whether they have been academically trained to do so. Some have responded to these criticisms by questioning the critics' motives and their understanding of Chomsky's ideas. Sperlich, for instance, says that Chomsky has been vilified by corporate interests, particularly in the mainstream press. Likewise, according to McGilvray, many of Chomsky's critics \"do not bother quoting his work or quote out of context, distort, and create straw men that cannot be supported by Chomsky's text\".\nChomsky drew criticism for not calling the Bosnian War's Srebrenica massacre a \"genocide\". While he did not deny the fact of the massacre, which he called \"a horror story and major crime\", he felt the massacre did not meet the definition of genocide. Critics have accused Chomsky of denying the Bosnian genocide.\nChomsky's far-reaching criticisms of U.S. foreign policy and the legitimacy of U.S. power have raised controversy. A document obtained pursuant to a Freedom of Information Act (FOIA) request from the U.S. government revealed that the Central Intelligence Agency (CIA) monitored his activities and for years denied doing so. The CIA also destroyed its files on Chomsky at some point, possibly in violation of federal law. He has often received undercover police protection at MIT and when speaking on the Middle East but has refused uniformed police protection. German news magazine \"Der Spiegel\" described Chomsky as \"the Ayatollah of anti-American hatred\", while American conservative commentator David Horowitz called him \"the most devious, the most dishonest and\u00a0... the most treacherous intellect in America\", whose work is infused with \"anti-American dementia\" and evidences his \"pathological hatred of his own country\".\nChomsky's criticism of Israel has led to his being called a traitor to the Jewish people and an antisemite. Criticizing Chomsky's defense of the right of individuals to engage in Holocaust denial on the grounds that freedom of speech must be extended to all viewpoints, Werner Cohn called Chomsky \"the most important patron\" of the neo-Nazi movement. The Anti-Defamation League (ADL) called him a Holocaust denier, describing him as a \"dupe of intellectual pride so overweening that he is incapable of making distinctions between totalitarian and democratic societies, between oppressors and victims\". In turn, Chomsky has claimed that the ADL is dominated by \"Stalinist types\" who oppose democracy in Israel. The lawyer Alan Dershowitz has called Chomsky a \"false prophet of the left\"; Chomsky called Dershowitz \"a complete liar\" who is on \"a crazed jihad, dedicating much of his life to trying to destroy my reputation\". In early 2016, President Recep Tayyip Erdo\u011fan of Turkey publicly rebuked Chomsky after he signed an open letter condemning Erdo\u011fan for his anti-Kurdish repression and double standards on terrorism. Chomsky accused Erdo\u011fan of hypocrisy, noting that Erdo\u011fan supports al-Qaeda's Syrian affiliate, the al-Nusra Front.\nAcademic achievements, awards, and honors.\nIn 1970, the London \"Times\" named Chomsky one of the \"makers of the twentieth century\". He was voted the world's leading public intellectual in The 2005 Global Intellectuals Poll jointly conducted by American magazine \"Foreign Policy\" and British magazine \"Prospect\". \"New Statesman\" readers listed Chomsky among the world's foremost heroes in 2006. In 2011, the US Peace Memorial Foundation awarded The US Peace Prize to Chomsky, \"whose antiwar activities for five decades both educate and inspire.\"\nIn the United States he is a Member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Association for the Advancement of Science, the American Philosophical Association, and the American Philosophical Society. Abroad he is a corresponding fellow of the British Academy, an honorary member of the British Psychological Society, a member of the Deutsche Akademie der Naturforscher Leopoldina, and a foreign member of the Department of Social Sciences of the Serbian Academy of Sciences and Arts. He received a 1971 Guggenheim Fellowship, the 1984 American Psychological Association Award for Distinguished Contributions to Psychology, the 1988 Kyoto Prize in Basic Sciences, the 1996 Helmholtz Medal, the 1999 Benjamin Franklin Medal in Computer and Cognitive Science, the 2010 Erich Fromm Prize, and the British Academy's 2014 Neil and Saras Smith Medal for Linguistics. He is also a two-time winner of the NCTE George Orwell Award for Distinguished Contribution to Honesty and Clarity in Public Language (1987 and 1989). He has also received the Rabindranath Tagore Centenary Award from The Asiatic Society.\nChomsky received the 2004 Carl-von-Ossietzky Prize from the city of Oldenburg, Germany, to acknowledge his body of work as a political analyst and media critic. He received an honorary fellowship in 2005 from the Literary and Historical Society of University College Dublin. He received the 2008 President's Medal from the Literary and Debating Society of the National University of Ireland, Galway. Since 2009, he has been an honorary member of International Association of Professional Translators and Interpreters (IAPTI). He received the University of Wisconsin's A.E. Havens Center's Award for Lifetime Contribution to Critical Scholarship and was inducted into IEEE Intelligent Systems' AI's Hall of Fame for \"significant contributions to the field of AI and intelligent systems.\" Chomsky has an Erd\u0151s number of four.\nIn 2011, the US Peace Memorial Foundation awarded Chomsky the US Peace Prize for anti-war activities over five decades. For his work in human rights, peace, and social criticism, he received the 2011 Sydney Peace Prize, the Sretenje Order in 2015, the 2017 Se\u00e1n MacBride Peace Prize and the Dorothy Eldridge Peacemaker Award.\nChomsky has received honorary doctorates from institutions including the University of London and the University of Chicago (1967), Loyola University Chicago and Swarthmore College (1970), Bard College (1971), Delhi University (1972), the University of Massachusetts (1973), and the International School for Advanced Studies (2012). Public lectures given by Chomsky include the 1969 John Locke Lectures, 1975 Whidden Lectures, 1977 Huizinga Lecture, and 1988 Massey Lectures.\nVarious tributes to Chomsky have been dedicated over the years. He is the eponym for a bee species, a frog species, an , and a building complex at the Indian university Jamia Millia Islamia. Actor Viggo Mortensen and avant-garde guitarist Buckethead dedicated their 2003 album \"Pandemoniumfromamerica\" to Chomsky.\nSelected bibliography.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21571", "revid": "8005368", "url": "https://en.wikipedia.org/wiki?curid=21571", "title": "Nial", "text": "Programming language\nNial (from \"Nested Interactive Array Language\") is a high-level array programming language developed from about 1981 by Mike Jenkins of Queen's University, Kingston, Ontario, Canada. Jenkins co-created the Jenkins\u2013Traub algorithm.\nNial combines a functional programming notation for arrays based on an array theory developed by Trenchard More with structured programming concepts for numeric, character, and symbolic data.\nIt is most often used for prototyping and artificial intelligence.\nQ'Nial.\n In 1982, Jenkins formed a company (Nial Systems Ltd) to market the language and the Q'Nial implementation of Nial. As of 2014, the company website supports an Open Source project for the Q'Nial software with the binary and source available for download. Its license is derived from Artistic License 1.0, the only differences being the preamble, the definition of \"Copyright Holder\" (which is changed from \"whoever is named in the copyright or copyrights for the package\" to \"NIAL Systems Limited\"), and an instance of \"whoever\" (which is changed to \"whomever\").\nNial concepts.\nNial uses a generalized and expressive Array Theory in its Version 4, but sacrificed some of the generality of functional model, and modified the Array Theory in the Version 6. Only Version 6 is available now.\nNial defines all its data types as nested rectangular arrays. ints, booleans, chars etc. are considered as a solitary array or an array containing a single member. Arrays themselves can contain other arrays to form arbitrarily deep structures. Nial also provides Records. They are defined as non-homogenous array structure.\nFunctions in Nial are called Operations. From Nial manual: \"An operation is a functional object that is given an argument array and returns a result array. The process of executing an operation by giving it an argument value is called an operation call or an operation application.\"\nApplication of operations.\nNial like other APL-derived languages allows the unification of binary operators and operations. Thus the below notations have the same meaning.\nNote: codice_1 is same as codice_2\nBinary operation:\n 2 + 3 \n 2 sum 3\nArray notation:\n + [2,3]\n sum [2,3]\nStrand notation:\n + 2 3\n sum 2 3\nGrouped notation:\n + (2 3)\n sum (2 3)\nNial also uses transformers which are higher order functions. They use the argument operation to construct a new modified operation.\n twice is transformer f (f f) \n twice rest [4, 5, 6, 7, 8] \n |6 7 8\nAtlas.\n An atlas in Nial is an operation made up of an array of component operations. When an atlas is applied to a value, each element of the atlas is applied in turn to the value to provide an result. This is used to provide point free (without-variables) style of definitions. It is also used by the transformers. In the below examples 'inner [+,*]' the list '[+,*]' is an atlas.\nExamples.\nCreating arrays.\n count 6\n |1 2 3 4 5 6\nArrays can also be literal\n Arr := [5, 6, 7, 8, 9]\n |5 6 7 8 9\nShape gives the array dimensions and reshape can be used to reshape the dimensions.\n shape Arr\n |5\n a := 2 3 reshape Arr\n # reshape is a binary operation with two arguments. It can also be written in prefix as\n # a := reshape [[2,3], Arr]\n |5 6 7\n |8 9 5\n b := 3 2 reshape Arr\n |5 6\n |7 8\n |9 5\n a inner[+,*] b\n |130 113\n |148 145\nComputing an average.\nDefinitions are of the form '&lt;name&gt; is &lt;expression&gt;'\n average is / [sum, tally] \n average Arr\n |7.\nComputing a factorial.\n fact is recur [ 0 =, 1 first, pass, product, -1 +]\n fact 4\n |24\nReversing an array.\n rev is reshape [ shape, across [pass, pass, converse append ] ]\n rev [1, 2, 3, 4]\n |4 3 2 1\nGenerating primes.\nContrast with [[APL programming language|APL]]\n primes is sublist [ each (2 = sum eachright (0 = mod) [pass,count]), pass ] rest count\n primes 10\n |2 3 5 7\nExplanation.\n Checking the divisibility of A by B\n is_divisible is 0 = mod [A,B]\nDefining is_prime filter\n is_prime is 2 = sum eachright is_divisible [pass,count]\nCount generates an array [1..N] and pass is N (identity operation).\neachright applies is_divisible (pass, element) in each element of count-generated array. \nThus this transforms the count-generated array into an array where numbers that can divide N are replaced by '1' and others by '0'. Hence if the number N is prime, sum [transformed array] must be 2 (itself and 1).\nNow all that remains is to generate another array using count N, and filter all that are not prime.\n primes is sublist [each is_prime, pass] rest count\nQuickSort.\n quicksort is fork [ &gt;= [1 first,tally],\n pass,\n link [\n quicksort sublist [ &lt; [pass, first], pass ],\n sublist [ match [pass,first],pass ],\n quicksort sublist [ &gt; [pass,first], pass ]\n ]\nUsing it:\n quicksort [5, 8, 7, 4, 3]\n |3 4 5 7 8\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n[[Category:Array programming languages]]"}
{"id": "21572", "revid": "8713122", "url": "https://en.wikipedia.org/wiki?curid=21572", "title": "Nag Hammadi", "text": "City in Qena, Egypt\n \nNag Hammadi ( ; ) is a city and markaz in Upper Egypt.\nIt is located on the west bank of the Nile in the Qena Governorate, about north-west of Luxor. The city had a population of close to 61,737 as of 2023[ [update]].\nHistory.\nThe town of Nag Hammadi was found on the site of older villages Ansan () and al-Luaqi () in the 19th century and was named after its founder, Mahmoud Pasha Hammadi, a member of the Hammadi family in Sohag, Egypt. Mahmoud Pasha Hammadi was a major landholder in Sohag, and known for his strong opposition to the British rule in Egypt beginning in 1882.\nIn the city of Nag Hammadi, there is the palace of Prince Youssef Kamal, a member of the royal family (the family of Muhammad Ali Pasha), which overlooks the Nile River and is now an archaeological site.\nNag Hammadi is about west of ancient Chenoboskion ()\nThe \"Nag Hammadi library\", an important collection of 2nd-century Gnostic texts, was found at \nJabal al-\u1e6c\u0101rif near Nag Hammadi in 1945.\nThe city was the site of the Nag Hammadi Massacre in January 2010, in which eight Coptic Christians were shot dead by three men. In total, nineteen Coptic Christians were attacked.\nEconomy.\nSugar and aluminium are produced in Nag Hammadi. The Nag Hammadi Sugar factory was built in 1895\u20131897 by French contractors Cail and Fives. It is still in operation in 2018. Egyptalum is one of the largest aluminium producer in the Middle East. Wood particleboard is manufactured from sugar cane bagasse.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21573", "revid": "36378140", "url": "https://en.wikipedia.org/wiki?curid=21573", "title": "Niels Henrik Abel", "text": "Norwegian mathematician (1802\u20131829)\nNiels Henrik Abel ( , ; 5 August 1802 \u2013 6 April 1829) was a Norwegian mathematician who made pioneering contributions in a variety of fields. His most famous single result is the first complete proof demonstrating the impossibility of solving the general quintic equation in radicals. This question was one of the outstanding open problems of his day, and had been unresolved for over 250 years. He was also an innovator in the field of elliptic functions and the discoverer of Abelian functions. He made his discoveries while living in poverty and died at the age of 26 from tuberculosis.\nMost of his work was done in six or seven years of his working life. Regarding Abel, the French mathematician Charles Hermite said: \"Abel has left mathematicians enough to keep them busy for five hundred years.\" Another French mathematician, Adrien-Marie Legendre, said: \"What a head the young Norwegian has!\"\nLife.\nEarly life.\nNiels Henrik Abel was born prematurely in \nNedstrand, Norway, as the second child of the pastor S\u00f8ren Georg Abel and Anne Marie Simonsen. When Niels Henrik Abel was born, the family was living at a rectory on Finn\u00f8y. Much suggests that Niels Henrik was born in the neighboring parish, as his parents were guests of the bailiff in Nedstrand in July / August of his year of birth.\nNiels Henrik Abel's father, S\u00f8ren Georg Abel, had a degree in theology and philosophy and served as pastor at Finn\u00f8y. S\u00f8ren's father, Niels's grandfather, Hans Mathias Abel, was also a pastor, at Gjerstad Church near the town of Ris\u00f8r. S\u00f8ren had spent his childhood at Gjerstad, and had also served as chaplain there; and after his father's death in 1804, S\u00f8ren was appointed pastor at Gjerstad and the family moved there. The Abel family originated in Schleswig and came to Norway in the 17th century.\nAnne Marie Simonsen was from Ris\u00f8r; her father, Niels Henrik Saxild Simonsen, was a tradesman and merchant ship-owner, and said to be the richest person in Ris\u00f8r. Anne Marie had grown up with two stepmothers, in relatively luxurious surroundings. At Gjerstad rectory, she enjoyed arranging balls and social gatherings. Much suggests she was early on an alcoholic and took little interest in the upbringing of the children. Niels Henrik and his brothers were given their schooling by their father, with handwritten books to read. An addition table in a book of mathematics reads: 1+0=0.\nCathedral School and Royal Frederick University.\nWith Norwegian independence and the first election held in Norway, in 1814, S\u00f8ren Abel was elected as a representative to the Storting. Meetings of the Storting were held until 1866 in the main hall of the Cathedral School in Christiania (now known as Oslo). Almost certainly, this is how he came into contact with the school, and he decided that his eldest son, Hans Mathias, should start there the following year. However, when the time for his departure approached, Hans was so saddened and depressed over having to leave home that his father did not dare send him away. He decided to send Niels instead.\nIn 1815, Niels Abel entered the Cathedral School at the age of 13. His elder brother Hans joined him there a year later. They shared rooms and had classes together. Hans got better grades than Niels; however, a new mathematics teacher, Bernt Michael Holmboe, was appointed in 1818. He gave the students mathematical tasks to do at home. He saw Niels Henrik's talent in mathematics, and encouraged him to study the subject to an advanced level. He even gave Niels private lessons after school.\nIn 1818, S\u00f8ren Abel had a public theological argument with the theologian Stener Johannes Stenersen regarding his catechism from 1806. The argument was well covered in the press. S\u00f8ren was given the nickname \"Abel Treating\" \"(Norwegian: \"Abel Spandabel\")\". Niels' reaction to the quarrel was said to have been \"excessive gaiety\". At the same time, S\u00f8ren also almost faced impeachment after insulting Carsten Anker, the host of the Norwegian Constituent Assembly; and in September 1818 he returned to Gjerstad with his political career in ruins. He began drinking heavily and died only two years later, in 1820, aged 48.\nBernt Michael Holmboe supported Niels Henrik Abel with a scholarship to remain at the school and raised money from his friends to enable him to study at the Royal Frederick University.\nWhen Abel entered the university in 1821, he was already the most knowledgeable mathematician in Norway. Holmboe had nothing more he could teach him and Abel had studied all the latest mathematical literature in the university library. During that time, Abel started working on the quintic equation in radicals. Mathematicians had been looking for a solution to this problem for over 250 years. In 1821, Abel thought he had found the solution. The two professors of mathematics in Christiania, S\u00f8ren Rasmussen and Christopher Hansteen, found no errors in Abel's formulas, and sent the work on to the leading mathematician in the Nordic countries, Carl Ferdinand Degen in Copenhagen. He too found no faults but still doubted that the solution, which so many outstanding mathematicians had sought for so long, could really have been found by an unknown student in far-off Christiania. Degen noted, however, Abel's unusually sharp mind, and believed that such a talented young man should not waste his abilities on such a \"sterile object\" as the fifth degree equation, but rather on elliptic functions and transcendence; for then, wrote Degen, he would \"discover Magellanian thoroughfares to large portions of a vast analytical ocean\". Degen asked Abel to give a numerical example of his method. While trying to provide an example, Abel found a mistake in his paper. This led to a discovery in 1823 that a solution by formula to a fifth- or higher-degree equation was not necessarily possible.\nAbel graduated in 1822. His performance was exceptionally high in mathematics and average in other matters.\nCareer.\nAfter he graduated, professors from university supported Abel financially, and Professor Christopher Hansteen let him live in a room in the attic of his home. Abel would later view Ms. Hansteen as his second mother. While living here, Abel helped his younger brother, Peder Abel, through examen artium. He also helped his sister Elisabeth to find work in the town.\nIn early 1823, Niels Abel published his first article in \"Magazin for Naturvidenskaberne\", Norway's first scientific journal, which had been co-founded by Professor Hansteen. Abel published several articles, but the journal soon realized that this was not material for the common reader. In 1823, Abel also wrote a paper in French. It was \"a general representation of the possibility to integrate all differential formulas\" (\"Norwegian: en alminnelig Fremstilling af Muligheten at integrere alle mulige Differential-Formler)\". He applied for funds at the university to publish it. However, the work was lost while being reviewed, never to be found thereafter.\nIn mid-1823, Professor Rasmussen gave Abel a gift of 100 speciedaler so he could travel to Copenhagen and visit Ferdinand Degen and other mathematicians there. While in Copenhagen, Abel did some work on Fermat's Last Theorem. Abel's uncle, Peder Mandrup Tuxen, lived at the naval base in Christianshavn, Copenhagen, and at a ball there Niels Abel met Christine Kemp, his future fianc\u00e9e. In 1824, Christine moved to Son, Norway, to work as a governess and the couple got engaged over Christmas.\nAfter returning from Copenhagen, Abel applied for a government scholarship in order to visit top mathematicians in Germany and France, but he was instead granted 200 speciedaler yearly for two years, to stay in Christiania and study German and French. In the next two years, he was promised a scholarship of 600 speciedaler yearly and he would then be permitted to travel abroad. While studying these languages, Abel published his first notable work in 1824, \"M\u00e9moire sur les \u00e9quations alg\u00e9briques o\u00f9 on d\u00e9montre l'impossibilit\u00e9 de la r\u00e9solution de l'\u00e9quation g\u00e9n\u00e9rale du cinqui\u00e8me degr\u00e9\" (Memoir on algebraic equations, in which the impossibility of solving the general equation of the fifth degree is proven). By 1823, Abel had at last proved the impossibility of solving the quintic equation in radicals (now referred to as the Abel\u2013Ruffini theorem). However, this paper was in an abstruse and difficult form, in part because he had restricted himself to only six pages in order to save money on printing. A more detailed proof was published in 1826 in the first volume of \"Crelle's Journal\".\nIn 1825, Abel wrote a personal letter to King Carl Johan of Norway/Sweden requesting permission to travel abroad. He was granted this permission, and in September 1825 he left Christiania together with four friends from university (Christian P.B Boeck, Balthazar M. Keilhau, Nicolay B. M\u00f8ller and Otto Tank). These four friends of Abel were traveling to Berlin and to the Alps to study geology. Abel wanted to follow them to Copenhagen and from there make his way to G\u00f6ttingen. The terms for his scholarship stipulated that he was to visit Gauss in G\u00f6ttingen and then continue to Paris. However, when he got as far as Copenhagen, he changed his plans. He wanted to follow his friends to Berlin instead, intending to visit G\u00f6ttingen and Paris afterwards.\nOn the way, he visited the astronomer Heinrich Christian Schumacher in Altona, now a district of Hamburg. He then spent four months in Berlin, where he became well acquainted with August Leopold Crelle, who was then about to publish his mathematical journal, \"Journal f\u00fcr die reine und angewandte Mathematik\". This project was warmly encouraged by Abel, who contributed much to the success of the venture. Abel contributed seven articles to it in its first year.\nFrom Berlin Abel also followed his friends to the Alps. He went to Leipzig and Freiberg to visit Georg Amadeus Carl Friedrich Naumann and his brother the mathematician August Naumann. In Freiberg Abel did research in the theory of functions, particularly, elliptic, hyperelliptic, and a new class now known as abelian functions.\nFrom Freiberg they went on to Dresden, Prague, Vienna, Trieste, Venice, Verona, Bolzano, Innsbruck, Luzern and Basel. From July 1826 Abel traveled on his own from Basel to Paris. Abel had sent most of his work to Berlin to be published in Crelle's Journal, but he had saved what he regarded as his most important work for the French Academy of Sciences, a theorem on addition of algebraic differentials. With the help of a painter, Johan G\u00f8rbitz, he found an apartment in Paris and continued his work on the theorem. He finished in October 1826 and submitted it to the academy. It was to be reviewed by Augustin-Louis Cauchy. Abel's work was scarcely known in Paris, and his modesty restrained him from proclaiming his research. The theorem was put aside and forgotten until his death.\nAbel's limited finances finally compelled him to abandon his tour in January 1827. He returned to Berlin, and was offered a position as editor of Crelle's Journal, but opted out. By May 1827 he was back in Norway. His tour abroad was viewed as a failure. He had not visited Gauss in G\u00f6ttingen and he had not published anything in Paris. His scholarship was therefore not renewed and he had to take up a private loan in Norges Bank of 200 spesidaler. He never repaid this loan. He also started tutoring. He continued to send most of his work to Crelle's Journal. But in mid-1828 he published, in rivalry with Carl Jacobi, an important work on elliptic functions in \"Astronomische Nachrichten\" in Altona.\nDeath.\nWhile in Paris, Abel had contracted tuberculosis. At Christmas 1828, he traveled by sled to Froland, Norway, to visit his fianc\u00e9e. He became seriously ill on the journey. Although a temporary improvement allowed the couple to enjoy the holiday together, he died relatively soon after on 6 April 1829, just two days before a letter arrived from August Crelle telling Abel that Crelle had secured him an appointment as a professor at the University of Berlin.\nContributions to mathematics.\nAbel showed that there is no general algebraic solution for the roots of a quintic equation, or any general polynomial equation of degree greater than four, in terms of explicit algebraic operations with the Abel-Ruffini theorem. To do this, he invented (independently of Galois) a branch of mathematics known as group theory, which is invaluable not only in many areas of mathematics, but for much of physics as well. Abel sent a paper on the unsolvability of the quintic equation to Carl Friedrich Gauss, who proceeded to discard without a glance what he believed to be the worthless work of a crank.\nAs a 16-year-old, Abel gave a rigorous proof of the binomial theorem valid for all numbers, extending Euler's result which had held only for rationals. Abel wrote a fundamental work on the theory of elliptic integrals, containing the foundations of the theory of elliptic functions.\nWhile travelling to Paris he published a paper revealing the double periodicity of elliptic functions, which Adrien-Marie Legendre later described to Augustin-Louis Cauchy as \"a monument more lasting than bronze\" (borrowing a famous sentence by the Roman poet Horatius). The paper was, however, misplaced by Cauchy.\nWhile abroad Abel had sent most of his work to Berlin to be published in the \"Crelle's Journal\", but he had saved what he regarded as his most important work for the French Academy of Sciences, a theorem on addition of algebraic differentials. The theorem was put aside and forgotten until his death. While in Freiberg, Abel did research in the theory of functions, particularly, elliptic, hyperelliptic, and a new class now known as abelian functions.\nIn 1823 Abel wrote a paper titled \"a general representation of the possibility to integrate all differential formulas\" (Norwegian: \"en alminnelig Fremstilling af Muligheten at integrere alle mulige Differential-Formler\"). He applied for funds at the university to publish it. However the work was lost, while being reviewed, never to be found thereafter.\nAbel said famously of Carl Friedrich Gauss's writing style, \"He is like the fox, who effaces his tracks in the sand with his tail.\" Gauss replied to him by saying, \"No self-respecting architect leaves the scaffolding in place after completing his building.\"\nLegacy.\nUnder Abel's guidance, the prevailing obscurities of analysis began to be cleared, new fields were entered upon and the study of functions so advanced as to provide mathematicians with numerous ramifications along which progress could be made. His works, the greater part of which originally appeared in \"Crelle's Journal\", were edited by Bernt Michael Holmboe and published in 1839 by the Norwegian government, and a more complete edition by Ludwig Sylow and Sophus Lie was published in 1881. The adjective \"abelian\", derived from his name, has become so commonplace in mathematical writing that it is conventionally spelled with a lower-case initial \"a\" (e.g., abelian group, abelian category, and abelian variety).\nOn 6 April 1929, four Norwegian stamps were issued for the centenary of Abel's death. His portrait appears on the 500-kroner banknote (version V) issued during 1978\u20131985. On 5 June 2002, four Norwegian stamps were issued in honour of Abel two months before the bicentenary of his birth. There is also a 20-kroner coin issued by Norway in his honour. A statue of Abel stands in Oslo, and crater Abel on the Moon was named after him.\nThe Abel Prize in mathematics was established in Abel's memory and named in his honour. Although it was originally proposed in 1899 to complement the Nobel Prizes, it was first awarded in 2003, while Selberg received an honorary Abel Prize the previous year.\nMathematician Felix Klein wrote about Abel:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;But I would not like to part from this ideal type of researcher, such as has seldom appeared in the history of mathematics, without evoking a figure from another sphere who, in spite of his totally different field, still seems related. Thus, although Abel shared with many mathematicians a complete lack of musical talent, I will not sound absurd if I compare his kind of productivity and his personality with Mozart's. Thus one might erect a monument to this divinely inspired mathematician like the one to Mozart in Vienna: simple and unassuming he stands there listening, while graceful angels float about, playfully bringing him inspiration from another world.\nInstead, I must mention the very different type of memorial that was in fact erected to Abel in Christiania and which must greatly disappoint anyone familiar with his nature. On a towering, steep block of granite a youthful athlete of the Byronic type steps over two greyish sacrificial victims, his direction toward the heavens. If needed be, one might take the hero to be a symbol of the human spirit, but one ponders the deeper significance of the two monsters in vain. Are they the conquered quintic equations or elliptic functions? Or the sorrows and cares of his everyday life? The pedestal of the monument bears, in immense letters, the inscription ABEL.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21574", "revid": "473593", "url": "https://en.wikipedia.org/wiki?curid=21574", "title": "November 19", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearNovember 19 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21575", "revid": "473593", "url": "https://en.wikipedia.org/wiki?curid=21575", "title": "November 20", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearNovember 20 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21576", "revid": "754658", "url": "https://en.wikipedia.org/wiki?curid=21576", "title": "November 21", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearNovember 21 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21577", "revid": "14157892", "url": "https://en.wikipedia.org/wiki?curid=21577", "title": "November 30", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearNovember 30 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21578", "revid": "51035641", "url": "https://en.wikipedia.org/wiki?curid=21578", "title": "November 29", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearNovember 29 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21579", "revid": "14650386", "url": "https://en.wikipedia.org/wiki?curid=21579", "title": "November 28", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearNovember 28 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21580", "revid": "28089545", "url": "https://en.wikipedia.org/wiki?curid=21580", "title": "November 25", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearNovember 25 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21581", "revid": "9795500", "url": "https://en.wikipedia.org/wiki?curid=21581", "title": "November 26", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearNovember 26 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21582", "revid": "41088876", "url": "https://en.wikipedia.org/wiki?curid=21582", "title": "Nicolaus von Amsdorf", "text": "German Protestant reformer (1483\u20131565)\nNicolaus von Amsdorf (Latin: Nicolaus Amsdorfius, 3 December 1483 \u2013 14 May 1565) was a German Lutheran theologian and an early Protestant reformer. As bishop of Naumburg (1542\u20131546), he became the first Lutheran bishop in the Holy Roman Empire.\nBiography.\nHe was born in Torgau, on the Elbe.\nHe was educated at Leipzig, and then at Wittenberg, where he was one of the first who matriculated (1502) in the recently founded university. He soon obtained various academic honours, and became professor of theology in 1511.\nLike Andreas Karlstadt, he was at first a leading exponent of the older type of scholastic theology, but under the influence of Luther abandoned his Aristotelian positions for a theology based on the Augustinian doctrine of grace. Throughout his life he remained one of Luther's most determined supporters; he was with him at the Leipzig conference (1519), and the Diet of Worms (1521); and was privy to the secret of his Wartburg seclusion. He assisted the first efforts of the Reformation at Magdeburg (1524), at Goslar (1531) and at Einbeck (1534); took an active part in the debates at Schmalkalden (1537), where he defended the use of the sacrament by the unbelieving; and (1539) spoke out strongly against the bigamy of the Landgrave of Hesse.\nAfter the death of Philip of the Palatinate, bishop of Naumburg-Zeitz, he was installed there on 20 January 1542, though in opposition to the chapter, by the Prince-elector of Saxony and Luther. His position was a painful one, and he longed to get back to Magdeburg, but was persuaded by Luther to stay. After Luther's death (1546) and the Battle of M\u00fchlberg (1547) he had to yield to his rival, Julius von Pflug, and retire to the protection of the young duke of Weimar. Here he took part in founding Jena University (1558); opposed the \"Augsburg Interim\" (1548); superintended the publication of the Jena edition of Luther's works; and debated on the freedom of the will, original sin, and, more noticeably, on the Christian value of good works, in regard to which he held that they were not only useless, but prejudicial in the matter of man's salvation. He urged the separation of the High Lutheran party from Melanchthon (1557), got the Saxon dukes to oppose the Frankfurt Recess (1558) and continued to fight for the purity of Lutheran doctrine.\nHe died at Eisenach in 1565, and was buried in the church of St. Georg there, where his effigy shows a well-knit frame and sharp-cut features.\nAssessment.\nHe was a man of strong will, of great aptitude for controversy, and considerable learning, and thus exercised a decided influence on the Reformation. Many letters and other short productions of his pen are extant in manuscript, especially five thick volumes of Amsdorfiana, in the Weimar library. They are a valuable source for our knowledge of Luther. A small sect, which adopted his opinion on good works, was called after him; but it is now of mere historical interest.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n "}
{"id": "21583", "revid": "1314600365", "url": "https://en.wikipedia.org/wiki?curid=21583", "title": "Nationality", "text": "Legal status establishing the person as a subject of a sovereign state\nNationality is the legal status of belonging to a particular nation, defined as a group of people organized in one country, under one legal jurisdiction, or as a group of people who are united on the basis of citizenship.\nIn international law, nationality is a legal identification establishing the person as a subject, a \"national\", of a sovereign state. It affords the state jurisdiction over the person and affords the person the protection of the state against other states. The rights and duties of nationals vary from state to state, and are often complemented by citizenship law, in some contexts to the point where citizenship is synonymous with nationality. However, nationality differs technically and legally from citizenship, which is a different legal relationship between a person and a country. The noun \"national\" can include both citizens and non-citizens. The most common distinguishing feature of citizenship is that citizens have the right to participate in the political life of the state, such as by voting or standing for election. However, in most modern countries all nationals are citizens of the state, and full citizens are always nationals of the state.\nIn international law, a \"stateless person\" is someone who is \"not considered as a national by any state under the operation of its law\". To address this, Article 15 of the Universal Declaration of Human Rights states that \"Everyone has the right to a nationality\", and \"No one shall be arbitrarily deprived of his nationality nor denied the right to change his nationality\", even though, by international custom and conventions, it is the right of each state to determine who its nationals are. Such determinations are part of nationality law. In some cases, determinations of nationality are also governed by public international law\u2014for example, by treaties on statelessness or the European Convention on Nationality. For when a person lacks nationality, globally only 23 countries have established dedicated statelessness determination procedures. Even where such procedures exist, they still have shortcomings in accessibility and functionality, preventing stateless people from accessing rights connected to being determined stateless.\nThe general process of acquiring nationality is called naturalization. Each state determines in its nationality law the conditions (statute) under which it will recognize persons as its nationals, and the conditions under which that status will be withdrawn. Some countries permit their nationals to have multiple nationalities, while others insist on exclusive allegiance.\nDue to the etymology of nationality, in older texts or other languages the word \"nationality\", rather than \"ethnicity\", is often used to refer to an ethnic group (a group of people who share a common ethnic identity, language, culture, lineage, history, and so forth). Individuals may also be considered nationals of groups with autonomous status that have ceded some power to a larger sovereign state.\nNationality is also employed as a term for national identity, with some cases of identity politics and nationalism conflating the legal nationality as well as ethnicity with a national identity.\nInternational law.\nNationality is the status that allows a nation to grant rights to the subject and to impose obligations upon the subject. In most cases, no rights or obligations are automatically attached to this status, although the status is a necessary precondition for any rights and obligations created by the state.\nIn European law, nationality is the status or relationship that gives the nation the right to protect a person from other nations. Diplomatic and consular protection are dependent upon this relationship between the person and the state. A person's status as being the national of a country is used to resolve the conflict of laws.\nWithin the broad limits imposed by a few treaties and international law, states may freely define who are and are not their nationals. However, since the \"Nottebohm\" case, other states are only required to respect the claim(s) by a state to protect an alleged national if the nationality is based on a true social bond. In the case of dual nationality, the states may determine the most effective nationality for the person, to determine which state's laws are the most relevant. There are also limits on removing a person's status as a national. Article 15 of the Universal Declaration of Human Rights states that \"Everyone has the right to a nationality,\" and \"No one shall be arbitrarily deprived of his nationality nor denied the right to change his nationality.\"\nDetermining factors.\nA person can be recognized or granted nationality on a number of bases. Usually, nationality based on circumstances of birth is automatic, but an application may be required.\nLegal protections.\nThe following instruments address the right to a nationality:\nNational law.\nNationals normally have the right to enter or return to the country they belong to. Passports are issued to nationals of a state, rather than only to citizens, because a passport is a travel document used to enter the country. However, nationals may not have the right of abode (the right to live permanently) in the countries that granted them passports.\nNationality versus citizenship.\nConceptually citizenship and nationality are different dimensions of state membership. Citizenship is focused on the internal political life of the state and nationality is the dimension of state membership in international law. Article 15 of the Universal Declaration of Human Rights states that everyone has the right to nationality. As such nationality in international law can be called and understood as citizenship, or more generally as subject or belonging to a sovereign state, and not as ethnicity. This notwithstanding, around 10 million people are stateless.\nToday, the concept of full citizenship encompasses not only active political rights, but full civil rights and social rights.\nHistorically, the most significant difference between a national and a citizen is that the citizen has the right to vote for elected officials, and the right to be elected. This distinction between full citizenship and other, lesser relationships goes back to antiquity. Until the 19th and 20th centuries, it was typical for only a certain percentage of people who belonged to the state to be considered as full citizens. In the past, a number of people were excluded from citizenship on the basis of sex, socioeconomic class, ethnicity, religion, and other factors. However, they held a legal relationship with their government akin to the modern concept of nationality.\nNationality in context.\nUnited States nationality law defines some persons born in some of the US outlying possessions as US nationals but not citizens. British nationality law defines six classes of British national, among which \"British citizen\" is one class (having the right of abode in the United Kingdom, along with some \"British subjects\"). Similarly, in the Republic of China, commonly known as Taiwan, the status of national without household registration applies to people who have the Republic of China nationality, but do not have an automatic entitlement to enter or reside in the Taiwan Area, and do not qualify for civic rights and duties there. Under the nationality laws of Mexico, Colombia, and some other Latin American countries, nationals do not become citizens until they turn the age of majority.\nList of nationalities which do not have full citizenship rights:\nEven if the nationality law classifies people with the same nationality on paper (\"de jure\"), the right conferred can be different according to the place of birth or residence, creating different \"de facto\" classes of nationality, sometimes with different passports as well. For example, although Chinese nationality law operates uniformly in China, including Hong Kong and Macau SARs, with all Chinese nationals classified the same under the nationality law, in reality local laws, in mainland and also in the SARs, govern the right of Chinese nationals in their respective territories which give vastly different rights, including different passports, to Chinese nationals according to their birthplace or residence place, effectively making a distinction between Chinese national of mainland China, Hong Kong or Macau, both domestically and internationally. The United Kingdom had a similar distinction as well before 1983, where all nationals with a connection to the UK or one of the colonies were classified as \"Citizens of the United Kingdom and Colonies\", but their rights were different depending on the connection under different laws, which was formalised into different classes of nationalities under the British Nationality Act 1981.\nNationality versus ethnicity.\nNationality is sometimes used simply as an alternative word for ethnicity or national origin, just as some people assume that citizenship and nationality are identical. In some countries, the cognate word for \"nationality\" in local language may be understood as a synonym of ethnicity or as an identifier of cultural and family-based self-determination, rather than on relations with a state or current government. For example, some Kurds say that they have Kurdish nationality, even though there is no Kurdish sovereign state at this time in history.\nIn the context of former Soviet Union and former Socialist Federal Republic of Yugoslavia, \"nationality\" is often used as translation of the Russian \"nacional'nost' \" and Serbo-Croatian \"narodnost\", which were the terms used in those countries for ethnic groups and local affiliations within the member states of the federation. In the Soviet Union, more than 100 such groups were formally recognized. Membership in these groups was identified on Soviet internal passports, and recorded in censuses in both the USSR and Yugoslavia. In the early years of the Soviet Union's existence, ethnicity was usually determined by the person's native language, and sometimes through religion or cultural factors, such as clothing. Children born after the revolution were categorized according to their parents' recorded ethnicities. Many of these ethnic groups are still recognized by modern Russia and other countries.\nSimilarly, the term \"nationalities of China\" refers to ethnic and cultural groups in China. Spain is one nation, made up of nationalities, which are not politically recognized as nations (state), but can be considered smaller nations within the Spanish nation. Spanish law recognizes the autonomous communities of Andalusia, Aragon, Balearic Islands, Canary Islands, Catalonia, Valencia, Galicia and the Basque Country as \"nationalities\" (\"nacionalidades\").\nIn 2013, the Supreme Court of Israel unanimously affirmed the position that \"citizenship\" (e.g. Israeli) is separate from \"le'om\" (; \"nationality\" or \"ethnic affiliation\"; e.g. Jewish, Arab, Druze, Circassian), and that the existence of a unique \"Israeli\" \"le'om\" has not been proven. Israel recognizes more than 130 \"le'umim\" in total.\nThe older ethnicity meaning of \"nationality\" is not defined by political borders or passport ownership and includes nations that lack an independent state (such as the Assyrians, Scots, Welsh, English, Andalusians, Basques, Catalans, Kurds, Punjabis, Kabyles, Baluchs, Pashtuns, Berbers, Bosniaks, Palestinians, Hmong, Inuit, Copts, M\u0101ori, Wakhis, Xhosas and Zulus, among others).\nNationality versus national identity.\nNational identity is person's subjective sense of belonging to one state or to one nation. A person may be a national of a state, in the sense of being its citizen, without subjectively or emotionally feeling a part of that state, for example a migrant may identify with their ancestral and/or religious background rather than with the state of which they are citizens. Conversely, a person may feel that he belongs to one state without having any legal relationship to it. For example, children who were brought to the US illegally when quite young and grew up there while having little contact with their native country and their culture often have a national identity of feeling American, despite legally being nationals of a different country.\nDual nationality.\nDual nationality is when a single person has a formal relationship with two separate, sovereign states. This might occur, for example, if a person's parents are nationals of separate countries, and the mother's country claims all offspring of the mother's as their own nationals, but the father's country claims all offspring of the father's.\nNationality, with its historical origins in allegiance to a sovereign monarch, was seen originally as a permanent, inherent, unchangeable condition, and later, when a change of allegiance was permitted, as a strictly exclusive relationship, so that becoming a national of one state required rejecting the previous state.\nDual nationality was considered a problem that caused a conflict between states and sometimes imposed mutually exclusive requirements on affected people, such as simultaneously serving in two countries' military forces. Through the middle of the 20th century, many international agreements were focused on reducing the possibility of dual nationality. Since then, many accords recognizing and regulating dual nationality have been formed.\nStatelessness.\nStatelessness is the condition in which an individual has no formal or protective relationship with any state. There are various reasons why a person can become stateless. This might occur, for example, if a person's parents are nationals of separate countries, and the mother's country rejects all offspring of mothers married to foreign fathers, but the father's country rejects all offspring born to foreign mothers. People in this situation may not legally be the national of any state despite possession of an emotional national identity.\nAnother stateless situation arises when a person holds a travel document (passport) which recognizes the bearer as having the nationality of a \"state\" which is not internationally recognized, has no entry into the International Organization for Standardization's country list, is not a member of the United Nations, etc. In the current era, persons native to Taiwan who hold passports of Republic of China are one example.\nSome countries (like Kuwait, the UAE, and Saudi Arabia) can also remove one's citizenship; the reasons for removal can be fraud and/or security issues. There are also people who are abandoned at birth and the parents' whereabouts are not known.\n\"De jure\" vs \"de facto\" statelessness.\nNationality law defines nationality and statelessness. Nationality is awarded based on two well-known principles: \"jus sanguinis\" and \"jus soli\". \"Jus sanguinis\" translated from Latin means \"right of blood\". According to this principle, nationality is awarded if the parent(s) of the person are nationals of that country. \"Jus soli\" is referred to as \"birthright citizenship\". It means, anyone born in the territory of the country is awarded nationality of that country.\nStatelessness is defined thus in the 1954 Statelessness Convention: \"For the purpose of this Convention, the term 'stateless person' means a person who is not considered as a national by any State under the operation of\nits law.\" A person can become stateless because of administrative reasons. For example, \"A person may be at risk of statelessness if she is born in a State that applies \"jus sanguinis\" while her parents were born in a State that applies \"jus soli\", leaving the person ineligible for citizenship in both States due to conflicting laws.\" Moreover, there are countries in which if a person does not reside for a specified period of time, they can automatically lose their nationality. To protect those individuals from being deemed \"stateless\", the 1961 Statelessness Convention places limitations on nationality laws.\nConferment of nationality.\nThe following list includes states in which parents are able to confer nationality on their children or spouses.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21584", "revid": "41195652", "url": "https://en.wikipedia.org/wiki?curid=21584", "title": "Near-Earth asteroid", "text": ""}
{"id": "21585", "revid": "8975592", "url": "https://en.wikipedia.org/wiki?curid=21585", "title": "Nereus", "text": "Ancient Greek sea god and father of the Nereids\nIn Greek mythology, Nereus ( ; ) was the eldest son of Pontus (the Sea) and Gaia (the Earth), with Pontus himself being a son of Gaia. Nereus and Doris became the parents of 50 daughters (the Nereids) and a son (Nerites), with whom Nereus lived in the Aegean Sea.\nName.\nThe name Nereus is absent from Homer's epics; the god's name in the Iliad is the descriptive 'Old Man of the Sea', and in the Odyssey the combination of and 'Proteus'. Besides Nereus and Proteus, the descriptive \"Old Man of the Sea\" was used for other water deities in Greek mythology who share several traits, among them Phorcys, Glaucus, and perhaps Triton. It is suggested that the \"Old Man of the Sea\" had at one time played a cosmogonic role comparable to that of Oceanus and could have received different names in different places. It is not known whether the name Nereus was known to Homer or not, but the name of the Nereids is attested before it and can be found in the Iliad. Since Nereus only has relevance as the father of the Nereids, it has been suggested that his name could actually be derived from that of his daughters; while the derivation of the Nereids from Nereus, as a patronymic, has also been suggested. According to Martin Litchfield West (1966), Nereus is much less important than his daughters, mentioning that Herodotus offered \"the Nereids, not Nereus, as an example of a divine name not derived from Egypt\".\nIn Hesiod's \"Theogony\", where the name was first attested, Nereus is presented in immediate juxtaposition to Eris, and this extends to their children. First of all, there exists a feminine-masculine opposition. Eris is the youngest child of Nyx and the only one for whom children are mentioned, while Nereus is Pontus' oldest son and, again, is granted the most attention. Hesiod chooses verbs and adjectives to describe Nereus in juxtaposition to Eris' children, such as 'does-not-lie' and 'does-not-forget', as opposed to 'Lies' and 'Forgetfulness'. This has prompted scholars to propose a derivation from 'Discord' with the negative prefix added to it; namely, \"Ne-Eris\" 'Not-Discord', which evolved to (&lt; ). Furthermore, Hesiod plays with the verbal likeness between \"Nereus\" and his last daughter 'Unerring', whose name also bears the negative prefix .\nAnother possible etymology could be from , '(fresh) water or fish', which is a contraction of the Greek adjective , 'new, fresh, young'. It is commonly believed that the contraction of \u03bd\u03b5\u03b1\u03c1\u03cc\u03c2 to \u03bd\u03b7\u03c1\u03cc\u03c2 happened later than Hesiod; however, the contraction of \u03b5 and \u03b1 to \u03b7 is quite old and widespread over many Greek dialects.\nThe name could be related to the Hesychian glosses 'hollow rocks' or 'low-lying'. Robert S. P. Beekes (2010) favors a Pre-Greek (pre-Indo-European) origin, as is suggested by the suffix . Another view is that of Apostolos Athanassakis (1983), who suggested an Illyrian origin for the name and compared it to the Albanian word 'man'.\nAccording to August Fick (1890), the closest Indo-European relative of \"Nereus\" and \"Nereids\" is the Lithuanian verb 'to dive'; moreover, the Lithuanian noun 'mermaid' has been associated with the Nereids. Papachristophorou (1998) supported a derivation from the aforementioned Lithuanian verb, citing Pierre Chantraine (1968), while Tsantsanoglou (2015) considered the relation plausible.\nThe name of the Nereids has survived in modern Greek folklore as \u03bd\u03b5\u03c1\u03ac\u03b9\u03b4\u03b5\u03c2, 'fairies'.\nMythology.\nIn the \"Iliad\", the Old Man of the Sea is the father of Nereids, though Nereus is not directly named. He was never more manifestly the Old Man of the Sea than when he was described, like Proteus, as a shapeshifter with the power of prophecy, who would aid heroes such as Heracles who managed to catch him even as he changed shapes. Nereus and Proteus (the \"first\") seem to be two manifestations of the god of the sea who was supplanted by Poseidon when Zeus overthrew Cronus.\nThe earliest poet to link Nereus with the labours of Heracles was Pherekydes, according to a \"scholion\" on Apollonius of Rhodes.\nDuring the course of the 5th century BC, Nereus was gradually replaced by Triton, who does not appear in Homer, in the imagery of the struggle between Heracles and the sea-god who had to be restrained in order to deliver his information that was employed by the vase-painters, independent of any literary testimony.\nIn a late appearance, according to a fragmentary papyrus, Alexander the Great paused at the Syrian seashore before the climacteric battle of Issus (333 BC), and resorted to prayers, \"calling on Thetis, Nereus and the Nereids, nymphs of the sea, and invoking Poseidon the sea-god, for whom he ordered a four-horse chariot to be cast into the waves.\"\nNereus was known for his truthfulness and virtue:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;But Pontos, the great sea, was father of truthful Nereus who tells no lies, eldest of his sons. They call him the Old Gentleman because he is trustworthy, and gentle, and never forgetful of what is right, but the thoughts of his mind are mild and righteous.\nThe Attic vase-painters showed the draped torso of Nereus issuing from a long coiling scaly fishlike tail. Bearded Nereus generally wields a staff of authority. He was also shown in scenes depicting the flight of the Nereides as Peleus wrestled their sister Thetis.\nIn Aelian's natural history, written in the early third century, Nereus was also the father of a watery consort of Aphrodite and lover of Poseidon named Nerites who was transformed into \"a shellfish with a spiral shell, small in size but of surpassing beauty.\"\nNereus was father to Thetis, one of the Nereids, who in turn was mother to the great Greek hero Achilles, and Amphitrite, who married Poseidon.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21586", "revid": "196446", "url": "https://en.wikipedia.org/wiki?curid=21586", "title": "Nereids", "text": "Greek Sea nymphs, daughters of Nereus\nIn Greek mythology, the Nereids or Nereides ( ; ; sg. , also \u039d\u03b7\u03bc\u03b5\u03c1\u03c4\u03ad\u03c2) are sea nymphs (female spirits of sea waters), the 50 daughters of the 'Old Man of the Sea' Nereus and the Oceanid Doris, sisters to their brother Nerites. They often accompany Poseidon, the god of the sea, and can be friendly and helpful to sailors (such as the Argonauts in their search for the Golden Fleece).\nName.\nIt is not known whether the name Nereus was known to Homer or not, but the name of the Nereids is attested before it, and can be found in the \"Iliad\". Since Nereus only has relevance as the father of the Nereids, it has been suggested that his name could actually be derived from that of his daughters; while the derivation of the Nereids from Nereus, as a patronymic, has also been suggested. According to Martin Litchfield West (1966), Nereus is much less important than his daughters, mentioning that Herodotus offered \"the Nereids, not Nereus, as an example of a divine name not derived from Egypt\".\nThe name of the Nereids has survived in modern Greek folklore as \u03bd\u03b5\u03c1\u03ac\u03b9\u03b4\u03b5\u03c2, 'fairies'.\nMythology.\nThe Nereids symbolized everything that is beautiful and kind about the sea. Their melodious voices sang as they danced around their father. They are represented as beautiful women, crowned with branches of red coral and dressed in white silk robes trimmed with gold.\nThese nymphs are particularly associated with the Aegean Sea, where they dwelt with their father Nereus in the depths within a golden palace. The most notable of them are Thetis, wife of Peleus and mother of Achilles; Amphitrite, wife of Poseidon and mother of Triton; Galatea, the vain love interest of the Cyclops Polyphemus, and lastly, Psamathe who became the mother of Phocus by King Aeacus of Aegina, and Theoclymenus and Theonoe by Proteus, a sea-god or king of Egypt.\nIn Homer's \"Iliad\" XVIII, when Thetis cries out in sympathy for the grief of Achilles for the slain Patroclus, her sisters appear. Four of her siblings, Cymodoce, Thalia, Nesaea and Spio were also among the nymphs in the train of Cyrene. Later on, these four together with their other sisters Thetis, Melite and Panopea, were able to help the hero Aeneas and his crew during a storm.\nIn one account, Cassiopeia boasted that her daughter Andromeda was more beautiful than the Nereides, who were enraged by the claim. Poseidon, in sympathy for them, sent a flood and a sea monster to the land of the Aethiopians, demanding as well the sacrifice of the princess. These sea goddesses also were said to reveal to men the mysteries of Dionysus and Persephone.\nList of Nereids.\nThis list is correlated from four sources: Homer's \"Iliad\", Hesiod's \"Theogony\", the \"Bibliotheca\" of Pseudo-Apollodorus and the \"Fabulae\" of Hyginus. Because of this, the total number of names goes beyond fifty.\nIconography.\nIn ancient art the Nereides appear in the retinue of Poseidon, Amphitrite, Thetis and other sea-divinities. On black-figure Greek vases they appear fully clothed, such as on a Corinthian hydra (sixth century BCE; Paris) where they stand near the bier of Achilles. Later vase-paintings depict them nude or partially nude, mounted on dolphins, sea-horses or other marine creatures, and often grouped together with Tritons. They appear as such on Roman frescoes and sarcophagi. An Etruscan bronze cista from Palestrina depicts winged Nereides.\nFamous is the Nereid Monument, a marble tomb from Xanthos (Lycia, Asia Minor), partially in the collection of the British Museum. At the top is a small temple surrounded by pillars between which Nereides stood. They were depicted in motion and with billowing, transparent clothes. The style is Attic-Ionian and dates to c.\u2009400 BCE.\nIn the Renaissance and baroque periods the Nereid was frequently used to decorate fountains and garden monuments.\nWorship.\nNereides were worshiped in several parts of Greece, but more especially in seaport towns, such as Cardamyle, and on the Isthmus of Corinth. The epithets given them by the poets refer partly to their beauty and partly to their place of abode.\nModern use.\nIn modern Greek folklore, the term \"nereid\" () has come to be used for all nymphs, fairies, or mermaids, not merely nymphs of the sea.\nIn modern folklore.\nThe appears in modern Greek folktales as a kind of supernatural wife, akin to the swan maiden, and gives its name to the homonymous type in the Catalogue of Greek Folktales: tale type ATU 400, \"The Nera\u00efda\". She has been compared to the nymph, the female character of ancient Greek mythology. She is said to inhabit water sources (rivers and wells), similar to their ancient mythical counterpart, the \"Nereids\" (water nymphs). However, in modern speech, the term also encompasses fairy maidens from mountains and woodlands.\nGreek folklorist Nicolaos Politis amassed a great amount of modern folkloric material regarding the . In modern tales from Greek tellers, the are said to dance at noon or at midnight; to have beautiful golden hair; to dress in white or rose garments and to appear wearing a veil on the head, or holding a handkerchief. Due to their beauty, young men are drawn to the and steal their veils or kerchiefs to force their stay in the mortal realm. The women marry these men, but later regain their piece of clothing back and disappear forever. Greek scholar Anna Angeloupoulos terms this storyline \"The Stolen Scarf\", one of four narratives involving the . Also, this sequence is \"the most frequent and stable introductory episode\" in Greek variants of tale type 400.\nIn a tale from Greece, a human goatherd named Demetros, dances with ten fairies three nights, and in the third night, on a full moon, he dances with them and accidentally touches the handkerchief of Katena. Her companions abandon her to the mortal world and she becomes Demetros's wife, bearing him a daughter. For seven years, Demetros has hidden the handkerchief, until his wife Katena asks him for it. She takes the handkerchief and dances with it in a festival, taking the opportunity to return home and leave her mortal husband. Years later, their daughter follows her mother when she turns fifteen years old.\nAnother introductory episode of the Greek variants is one Angelopoulos dubbed \"The Sisters of Alexander the Great\". This refers to a pseudo-historical or mythological account about Alexander the Great and a quest for a water of life that grants immortality. His sister (or sisters) drinks it instead of him, is thrown in the sea and becomes a , a half-human, half-fish creature with power over the storm who can sink boats and become birds. They approach ships to ask if Alexander still lives, and can only be appeased if answered positively. In one tale, a youth on a ship captures a three times (or three ) and beats her until she promises not to threaten any more ships. The youth then arrives on a deserted island and sees three birds that become human (or flying maidens), and steals their garments. Richard MacGillivray Dawkins suggested that the modern was a merging of three mythological characters (the Sirens, the Gorgons, and the Scylla), and reported alternate tales where Alexander's sisters are replaced for his mother or a female lover.\nOther uses.\nNereid, a moon of the planet Neptune, is named after the Nereids, as is Nereid Lake in Antarctica.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21587", "revid": "50460291", "url": "https://en.wikipedia.org/wiki?curid=21587", "title": "Nemesis (disambiguation)", "text": "Nemesis is a Greek mythological spirit of divine retribution against those who succumb to hubris.\nNemesis may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "21588", "revid": "237572", "url": "https://en.wikipedia.org/wiki?curid=21588", "title": "Nereid (moon)", "text": "Moon of Neptune\nNereid, or Neptune II, is the third-largest moon of Neptune. It has the second-most eccentric orbit of all known moons in the Solar System, after S/2023 S 38. It was the second moon of Neptune to be discovered, by Gerard Kuiper in 1949.\nDiscovery and naming.\nNereid was discovered on 1 May 1949 by Gerard P. Kuiper using photographic plates taken with the 82-inch telescope at the McDonald Observatory. He proposed the name in the report of his discovery. It is named after the Nereids, sea-nymphs of Greek mythology and attendants of the god Neptune. It was the second moon of Neptune to be discovered, and the last before the arrival of \"Voyager 2\" (not counting a single observation of an occultation by Larissa in 1981).\nPhysical characteristics.\nNereid is third-largest of Neptune's satellites, and has a mean radius of about , similar to Saturn's moon Mimas. It is by far the largest normal irregular satellite known, having about two-thirds the mass of all irregular moons combined. (Triton is much larger, but is very unusual for an irregular satellite.) Nereid also accounts for about 98% of the mass of Neptune's entire irregular satellite system altogether (excluding Triton), which is similar to the situation of Phoebe at Saturn (the second-largest normal irregular moon in the Solar System).\nThe shape of Nereid is unknown. Since 1987 some photometric observations of Nereid have detected large (by ~1 magnitude) variations of its brightness, which can happen over years and months, but sometimes even over a few days. They persist even after a correction for distance and phase effects. On the other hand, not all astronomers who have observed Nereid have noticed such variations. This means that they may be quite chaotic. To date, there is no credible explanation of the variations, but if they exist, they are likely related to the rotation of Nereid. Nereid's rotation could be either in the state of forced precession or even chaotic rotation (like Hyperion) due to its highly elliptical orbit.\nIn 2016, extended observations with the Kepler space telescope showed only low-amplitude variations (0.033 magnitudes). Thermal modeling based on infrared observations from the Spitzer and Herschel space telescopes suggests that Nereid is only moderately elongated with a maximum aspect ratio of 1.3:1, which disfavors forced precession of the rotation. The thermal model also indicates that the surface roughness of Nereid is very high, likely similar to the Saturnian moon Hyperion.\nSpectrally, Nereid appears neutral in colour and water ice has been detected on its surface. Its spectrum appears to be intermediate between Uranus's moons Titania and Umbriel, which suggests that Nereid's surface is composed of a mixture of water ice and some spectrally neutral material. The spectrum is markedly different from minor planets of the outer solar system, centaurs Pholus, Chiron and Chariklo, suggesting that Nereid formed around Neptune rather than being a captured body.\nHalimede, which displays a similar gray neutral colour, may be a fragment of Nereid that was broken off during a collision.\nOrbit and rotation.\nNereid orbits Neptune in the prograde direction at an average distance of , but its high eccentricity of 0.749 takes it as close as and as far as .\nThe unusual orbit suggests that it may be either a captured asteroid or Kuiper belt object, or that it was an inner moon in the past and was perturbed during the capture of Neptune's largest moon Triton. If the latter is true, it may be the only survivor of Neptune's original (pre-Triton capture) set of regular satellites.\nIn 1991, a rotation period of Nereid of about 13.6\u00a0hours was determined by an analysis of its light curve. In 2003, another rotation period of about 11.52 \u00b1 0.14 hours was measured. However, this determination was later disputed, and other researchers for a time failed to detect any periodic modulation in Nereid's light curve from ground-based observations. In 2016, a clear rotation period of 11.594 \u00b1 0.017\u00a0hours was determined based on observations with the Kepler space telescope.\nExploration.\nThe only spacecraft to visit Nereid was \"Voyager 2\", which passed it at a distance of between 20 April and 19 August 1989. \"Voyager 2\" obtained 83 images with observation accuracies of to . Prior to \"Voyager 2\"'s arrival, observations of Nereid had been limited to ground-based observations that could only establish its intrinsic brightness and orbital elements. Although the images obtained by \"Voyager 2\" do not have a high enough resolution to allow surface features to be distinguished, \"Voyager 2\" was able to measure the size of Nereid and found that it was grey in colour and had a higher albedo than Neptune's other small satellites.\nIf selected, the Arcanum mission would do a flyby of Nereid before its primary purposes of orbiting Neptune and observing Triton.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21592", "revid": "50724356", "url": "https://en.wikipedia.org/wiki?curid=21592", "title": "Netball", "text": "Seven-a-side ball sport\nNetball is a ball sport played on a rectangular court by two teams of seven players. The primary objective is to shoot a ball through the defender's goal ring while preventing the opposing team from shooting through their own. It is one of a few sports created exclusively for women and girls, and it remains primarily played by them, on indoor and outdoor courts, especially in schools, and most popularly in the Commonwealth of Nations.\nAccording to World Netball, the sport is played by more than 20 million people in more than 80 countries. World Netball comprises more than 70 national teams organized into five global regions. Major domestic leagues in the sport include the Netball Superleague in Great Britain, Super Netball in Australia, and the ANZ Premiership in New Zealand.\nFour major competitions take place internationally: the World Netball Championships and Commonwealth Games, both quadrennial, and the Quad Series and Fast5 Series, both annual. In 1995, the International Netball Federation (now known as World Netball) became an International Olympic Committee recognised sport federation, but netball has not been played at the Olympics.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nDescription and rules.\nThe objective of a game is to score more goals than the opposition. Goals are scored when a team member positioned in the attacking \"shooting circle\" shoots the ball through the goal ring. The goal rings are in diameter and sit atop -high goal posts that have no backboards. The -radius semi-circular shooting circles are located at each end of the court, and contain the goal posts. Each team defends one shooting circle and attacks the other. The netball court is long, wide, and divided lengthwise into thirds. The ball is usually made of leather or rubber, measures in circumference (\u2248 in diameter), and weighs . A normal game consists of four 15-minute quarters and can be played outdoors or in a covered stadium.\nEach team is allowed seven players on the court. Each player is assigned a specific position, which limits their movement to a certain area of the court. A \"bib\" worn by each player contains a one- or two-letter abbreviation indicating this position. Only two positions are permitted in the attacking shooting circle, and can therefore shoot for a goal. Similarly, only two positions are permitted in the defensive shooting circle to prevent the opposition from shooting goals. Other players are restricted to two-thirds of the court, with the exception of the centre, who may move anywhere on the court except for a shooting circle.\nAt the beginning of every quarter and after a goal has been scored, play starts with a player in the centre position passing the ball from the centre of the court. These \"centre passes\" alternate between the teams, regardless of which team scored the last goal. When the umpire blows the whistle to restart play, four players from each team can move into the centre third to receive the pass. The centre pass must be caught or touched in the centre third.\nThe ball is then moved up and down the court through passing and must be touched by a player in each adjacent third of the court. Players can hold the ball for only three seconds at any time. It must be released before the foot they were standing on when they caught it touches the ground again.\nContact between players is only permitted if it does not impede an opponent or the general play. When defending a pass or shot players must be at least away from the player with the ball. If illegal contact is made, the player who contacted cannot participate in play until the player taking the penalty has passed or shot the ball. If the ball is held in two hands and either dropped or a shot at goal is missed, the same player cannot be the first to touch it unless it first rebounds off the goal.\nA player is offside if they enter an area of the court in which their position is not permitted. Each position has specific court areas where they may move, and stepping into a restricted zone is considered an offside infringement. Being offside can occur with or without the ball. If two opposing players enter an offside area simultaneously neither gains an advantage, play continues under the advantage rule. When an offside infringement is penalised, a free pass is awarded to the opposing team in the area where the violation occurred, and the infringing player must remain out of play until the pass is taken.https://\nEquipment.\nAside from the court and nets, netball uses a ball that is around 70\u00a0cm in circumference and weighs 400 to 450 grams. Balls are made from leather, rubber, or similar material.\nA player typically wears a jersey or tank top with a skort or shorts. Players may alternatively wear specialist one-piece netball dresses, particularly at higher levels. These are accompanied by socks and trainers. Specialist netball dresses and jerseys usually have Velcro to attach a fabric patch bearing their position letter(s), which can instead be worn on bibs when wearing clothes without Velcro.\nHistory.\nNetball's early development emerged from Clara Baer's misinterpretation of the early rules of James Naismith's new sport of basketball, and eventually evolved into its own sport. Basketball, invented in 1891, was initially played indoors between two teams of nine players, using an association football that was thrown into closed-end peach baskets. Naismith's game spread quickly across the United States and variations of the rules soon emerged.\nAt the same time, physical education instructor Senda Berenson developed modified rules for women in 1892. Berenson's rules eventually gave rise to women's basketball, and separate intercollegiate rules for basketball for men and women developed around the same time.\nClara Baer was a sports teacher living in New Orleans when she wrote to Naismith asking for a copy of the rules for his game of basketball. Once she received them, they included a diagram of the court with lines across it which were meant to show the areas various players could best patrol. She misinterpreted the lines and believed they marked out restricted areas of play which players could not leave. Her mistake marks the beginning of netball. Baer's version for the rules of women's basketball defined these areas as restricted zones, an error which then became ratified into the rules for women's basketball in 1899 and proliferated.\nMartina Bergman-\u00d6sterberg introduced a version of basketball in 1893 to her female students at the Physical Training College in Hampstead, London. The rules of the game were modified at the college over several years: the game moved outdoors and was played on grass; the baskets were replaced by rings that had nets; and in 1897 and 1899, rules from women's basketball in the United States were incorporated. \u00d6sterberg's new sport acquired the name \"net ball\". The first codified rules of netball were published in 1901 by the Ling Association, later the Physical Education Association of the United Kingdom. From England, netball spread to other countries in the British Empire. Variations of the rules and even names for the sport arose in different areas: \"women's (outdoor) basketball\" arrived in Australia around 1900 and in New Zealand from 1906, while \"netball\" was being played in Jamaican schools by 1909.\nFrom the start, it was considered socially appropriate for women to play netball; netball's restricted movement appealed to contemporary notions of women's participation in sports, and the sport was distinct from potential rival male sports. Netball became a popular women's sport in countries where it was introduced and spread rapidly through school systems. School leagues and domestic competitions emerged during the first half of the 20th century, and in 1924 the first national governing body was established in New Zealand. International competition was initially hampered by a lack of funds and varying rules in different countries. Australia hosted New Zealand in the first international game of netball in Melbourne on 20 August 1938; Australia won 40\u201311. Efforts began in 1957 to standardise netball rules globally: by 1960 international playing rules had been standardised, and the International Federation of Netball and Women's Basketball, later the International Netball Federation (INF), was formed to administer the sport worldwide.\nRepresentatives from England, Australia, New Zealand, South Africa, and the West Indies were part of a 1960 meeting in Sri Lanka that standardised the rules for the game. The game spread to other African countries in the 1970s. South Africa was prohibited from competing internationally from 1969 to 1994 due to apartheid. In the United States, Netball's popularity also increased during the 1970s, particularly in the New York area, and the United States of America Netball Association was created in 1992. The game also became popular in the Pacific Island nations of the Cook Islands, Fiji and Samoa during the 1970s. Netball Singapore was created in 1962, and the Malaysian Netball Association was created in 1978.\nIn Australia, the term \"women's basketball\" was used to refer to both netball and basketball. During the 1950s and 1960s, a movement arose to change the Australian name of the game from \"women's basketball\" to \"netball\" in order to avoid confusion between the two sports. The Australian Basketball Union offered to pay the costs involved to alter the name, but the netball organisation rejected the change. In 1970, the Council of the All Australia Netball Association officially changed the name to \"netball\" in Australia.\nIn 1963, the first international tournament was held in Eastbourne, England. Originally called the World Tournament, it later became known as the World Netball Championships. Following the first tournament, one of the organisers, Miss R. Harris, declared,&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe World Netball Championships have been held every four years since then. The World Youth Netball Championships started in Canberra in 1988, and have been held roughly every four years since. In 1995, the International Olympic Committee recognized the International Federation of Netball Associations. Three years later netball debuted at the 1998 Commonwealth Games in Kuala Lumpur. Other international competitions also emerged in the late 20th century, including the Nations Cup and the Asian Netball Championship.\nComparison with basketball.\nNetball's development traces back to American sports teacher Clara Gregory Baer's misinterpretation of the basketball rule book in 1895. The book had lines of patrol drawn on it and she interpreted this to mean that players had to stay in those zones. Baer's modifications proliferated and were later officially ratified into the rules for women's basketball by 1899. Martina Bergman-\u00d6sterberg had also introduced basketball to her female students at her Physical Training College in England in 1893. In the beginning it was also described as \"women's basketball\", but by 1897 it started to evolve into a distinctly separate sport based on modifications developed at Bergman-\u00d6sterberg's college combined with Baer's rules.\nThe first codified rules of Bergman-\u00d6sterberg's new sport, \"netball\", were then published in 1901. By 1960, international playing rules had been standardised for the game, and the International Federation of Netball and Women's Basketball, later renamed World Netball, was formed to be the sport's international governing body.\nNetball differs in many ways from basketball, principally in the absence of the backboards from the hoop or goal ring and the prohibition of dribbling, bouncing, and running while in possession of the ball. Physical player contact is more controlled than in basketball. In addition, netball not only identifies the different positions of its players, but also defines where and in which areas of the court specific players are allowed to be when they compete.\nSex category.\nThe sport was created for girls and women and remains most popular among this demographic, with women's netball at elite and national levels receiving outside funding. Though male netball teams exist in some areas, men's and mixed-sex teams are largely self-funded. Men's netball started to grow in Australia during the 1980s, with the first men's championship being held in 1985. Other countries with men's national teams include Canada, Fiji, Jamaica, Kenya, Pakistan and the United Arab Emirates. In England, the England men's and mixed netball association (EMMNA) was founded in 2019 to develop, promote and govern men's and mixed netball teams in partnership with the national governing body. In June 2025, World Netball announced a major update to its global events strategy, including the introduction of the first Men's Netball World Cup, marking a step towards establishing a global competitive pathway for male athletes.\nOther.\nIn 2004, New Zealand and Fiji sent teams to compete in the Australian Mixed and Men's National Championships. By 2006, mixed netball teams in Australia had as many male participants as rugby union.\nAn all-transgender netball team from Indonesia competed at the 1994 Gay Games. The team had been the Indonesian national champions.\nAt the Gay Games VI in Sydney in 2000, netball and volleyball were the two sports with the highest rates of transgender athletes participating. There were eight teams of indigenous players, with seven identifying as transgender. They came from places like Palm Island in northern Queensland, Samoa, Tonga and Papua New Guinea. Teams with transgender players were allowed to participate in several divisions including men's, mixed and transgender; they were not allowed to compete against women's teams.\nVariants.\nIndoor netball.\nIndoor netball is a variation of netball, played exclusively indoors, in which the playing court is often surrounded on each side and overhead by a net. The net prevents the ball from leaving the court, permitting faster play by reducing playing stoppages.\nDifferent forms of indoor netball exist. In a seven-per-side version called \"action netball\", seven players per team play most standard rules, except a game is split into fifteen-minute halves around a three-minute break. This version is played in Australia, New Zealand, South Africa and England.\nA six-per-side version of the sport is also played in New Zealand. Two Centres per team can play in the whole court except the shooting circles; the remaining attacking and defending players are each restricted to one half of the court, including the shooting circles. The attacking and Centre players may shoot from outside the shooting circle for a two-point goal.\nA five-per-side game is also common in indoor netball. Players can move throughout the court, with the exception of the shooting circles, which are restricted to certain attacking or defending players.\nFast5.\nFast5 (originally called Fastnet) is a variation on the rules of netball designed to make games faster and more television-friendly. The World Netball Series promotes it to raise the sport's profile and attract more spectators and greater sponsorship. The game is much shorter, with each quarter lasting only six minutes and only a two-minute break between quarters. The coaches can give instructions from the sideline during play, and unlimited substitutions are allowed. Like six-per-side indoor netball, attacking players may shoot two-point goals from outside the shooting circle. Each team can separately nominate one \"power play\" quarter, in which each goal scored by that team is worth double points and the centre pass is taken by the team that conceded the goal.\nFor children.\nNetball has been adapted in several ways to meet children's needs. The rules for children are similar to those for adults, but various aspects of the game (such as the length of each quarter, goal height, and ball size) are modified.\nFun Net is a version of netball developed by Netball Australia for five- to seven-year-olds. It aims to improve basic netball skills using games and activities. The Fun Net program runs for 8\u201316 weeks. There are no winners or losers. The goal posts are high, and a smaller ball is used.\nNetball Australia also runs a modified game called Netta aimed at 8- to 11-year-olds. The goal height and ball size are the same as for adults, but players rotate positions during the game, permitting each player to play each position. Netta was created to develop passing and catching skills. Its rules permit six seconds between catching and passing the ball, instead of the three seconds permitted in the adult game. Most players under 11 play this version at netball clubs.\nA version called High Five Netball is promoted by the All England Netball Association. It is aimed at 9- to 11-year-old girls and includes only five positions. The players swap positions during the game. When a player is not on the court, she is expected to help the game in some other way, such as being the timekeeper or scorekeeper. High Five Netball has four six-minute quarters.\nWalking netball.\nWalking netball is a slower-paced version of netball designed to encourage participation by older or less fit players. The rules forbid running or jumping, and allow an extra step with the ball and 4 seconds, rather than 3, to hold the ball.\nGovernance.\nThe recognised international governing body of netball is World Netball, based in Manchester, England. Founded in 1960, the organisation was initially called the International Federation of Netball and Women's Basketball. World Netball is responsible for compiling world rankings for national teams, maintaining the rules for netball and organising several major international competitions.\nAs of April 2025, World Netball has 63 full and 12 associate national members in five regions. Each region has a World Netball regional federation.\nWorld Netball is affiliated with the General Association of International Sports Federations, the International World Games Association and the Association of IOC Recognised International Sports Federations. It is also a signatory to the World Anti-Doping Code.\nInternational competition.\nNetball is a popular participant sport in countries of the Commonwealth of Nations. Non-Commonwealth entities with full IFNA membership include Switzerland, Taiwan, Thailand, Argentina, Bermuda, the Cayman Islands and the United States, along with former Commonwealth members Zimbabwe, Ireland and Hong Kong. According to the IFNA, over 20\u00a0million people play netball in more than 80 countries. International tournaments are held among countries in each of the five IFNA regions, either annually or every four years. School leagues and national club competitions have been organised in England, Australia, New Zealand and Jamaica since the early twentieth century. Franchise-based netball leagues did not emerge until the late 1990s. These competitions sought to increase the profile of the sport in their respective countries. Despite widespread local interest, participation was largely amateur.\nNetball was first included in the 1998 Commonwealth Games and has been included ever since; it is currently one of the \"core\" sports that must be contested at each edition of the Games.\nThe Confederation of African Netball Associations organises a major African tournament, which invites teams from Botswana, Namibia, Zambia, Malawi, South Africa, Kenya, Lesotho, Eswatini, Zimbabwe and the Seychelles to take part. The tournament is hosted by a country within the region; senior and under 21 teams compete. The tournament has served as a qualifier for the World Championships. South Africa launched a new domestic competition in 2011 called Netball Grand Series. It features eight regional teams from South Africa and is aimed at increasing the amount of playing time for players. It runs for 17 weeks and replaces the National Netball League, which was played over only two weeks. According to Proteas captain Elsje Jordaan, it was hoped that the competition would create an opportunity for players to become professional.\nThe Americas Federation of Netball Associations (AFNA) hosts two tournaments each year: the Caribbean Netball Association (CNA) Under 16 Championship and the AFNA Senior Championship. The CNA championship involves two divisions of teams from the Caribbean islands. In 2010 five teams competed in two rounds of round robin matches in the Championship Division, while four teams competed in the Developmental Division. Jamaica, which has lost only once in the tournament, decided not to play the 2011 tournament. The AFNA Senior Championship includes Canada and the US along with the Caribbean nations. The tournament serves as a qualifier for the World Championship. Jamaica, with its high ranking, does not have to qualify; this leaves two spots to the other teams in the tournament.\nThe Asian Netball Championship is held every four years. The seventh Asian games were held in 2009 and featured Singapore, Thailand, Maldives, Taiwan, Malaysia, Sri Lanka, Hong Kong, India and Pakistan. There is also an Asian Youth Netball Championship for girls under 21 years of age, the seventh of which was held in 2010.\nThe major netball competition in Europe is the Netball Superleague, which features teams from England, Wales and Scotland. The league was created in 2005. Matches are broadcast on Sky Sports.\nNetball has been featured at the Pacific Games, a multi-sport event with participation from 22 countries from around the South Pacific. The event is held every four years and has 12 required sports; the host country chooses the other four. Netball is not a required sport and has missed selection, particularly when former French or American territories host the games.\nThe ANZ Championship was a Trans-Tasman competition held between 2008 and 2016 that was broadcast on television in both New Zealand and Australia. It was contested among ten teams from Australia and New Zealand. It began in April 2008, succeeding Australia's Commonwealth Bank Trophy and New Zealand's National Bank Cup as the pre-eminent netball league in those countries. The competition was held annually between April and July, consisting of 69 matches played over 17 weeks. The ANZ Championship saw netball become a semi-professional sport in both countries, with increased media coverage and player salaries. The competition was replaced by new leagues in 2017, the Super Netball (Australia) and ANZ Premiership (New Zealand).\nMajor championships.\nThere are four major international netball competitions; the Netball World Cup, Netball at the Commonwealth Games, Netball Quad Series and Fast5 Netball World Series. Netball is also played at large regional multi-sport events such as the Southeast Asian Games.\nNetball's important competition is the Netball World Cup (previously known as the World Netball Championships), held every four years. It was first held in 1963 at the Chelsea College of Physical Education at Eastbourne, England, with eleven nations competing. Since its inception the competition has been dominated primarily by the Australian and New Zealand teams, which hold ten and four titles, respectively. Trinidad and Tobago is the only other team to win a championship title. That title, won in 1979, was shared with New Zealand and Australia; all three teams finished with equal points at the end of the round robin, and there were no finals.\nThe Fast5 Series is a competition among the top six national netball teams, as ranked by the INF World Rankings. It is organised by the INF in conjunction with the national governing bodies of the six competing nations, UK Sport, and the host city's local council. The All England Netball Association covers air travel, accommodation, food and local travel expenses for all teams, while the respective netball governing bodies cover player allowances. It is held over three days, with each team playing each other once during the first two days in a round-robin format. The four highest-scoring teams advance to the semi-finals; the winners face each other in the Grand Final. The competition features modified fastnet rules and has been likened to Twenty20 cricket and rugby sevens. A new format featuring shorter matches with modified rules was designed to make the game more appealing to spectators and television audiences. The World Netball Series was held annually in England from 2009 to 2011.\nNetball's governing federation gained Olympic recognition in 1995 after 20 years of lobbying. Although it has never been played at the Summer Olympics, politicians and administrators have been campaigning unsuccessfully to have it included. Its absence from the Olympics has been seen by the netball community as a hindrance in the global growth of the game by limiting access to media attention and funding sources. Some funding sources became available with recognition in 1995, including the International Olympic Committee, national Olympic committees, national sport organisations, and state and federal governments.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral bibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21593", "revid": "25859633", "url": "https://en.wikipedia.org/wiki?curid=21593", "title": "New York Times", "text": ""}
{"id": "21594", "revid": "41906662", "url": "https://en.wikipedia.org/wiki?curid=21594", "title": "Nj\u00f6r\u00f0r", "text": "God among the Vanir in Norse mythology\nIn Norse mythology, Nj\u00f6r\u00f0r (Old Norse: ) is a god among the Vanir. Nj\u00f6r\u00f0r, father of the deities Freyr and Freyja by his unnamed sister, was in an ill-fated marriage with the goddess Ska\u00f0i, lives in N\u00f3at\u00fan and is associated with the sea, seafaring, wind, fishing, wealth, and crop fertility.\nNj\u00f6r\u00f0r is attested in the \"Poetic Edda\", compiled in the 13th century from earlier traditional sources, the \"Prose Edda\", written in the 13th century by Snorri Sturluson, in euhemerized form as a beloved mythological early king of Sweden in \"Heimskringla\", also written by Snorri Sturluson in the 13th century, as one of three gods invoked in the 14th century \"Hauksb\u00f3k\" ring oath, and in numerous Scandinavian place names. Veneration of Nj\u00f6r\u00f0r survived into the 18th or 19th century Norwegian folk practice, where the god is recorded as Njor and thanked for a bountiful catch of fish.\nNj\u00f6r\u00f0r has been the subject of an amount of scholarly discourse and theory, often connecting him with the figure of the much earlier attested Germanic goddess Nerthus, the hero Hadingus, and theorizing on his formerly more prominent place in Norse paganism due to the appearance of his name in numerous place names. \"Nj\u00f6r\u00f0r\" is sometimes modernly anglicized as Njord, Njoerd, or Njorth.\nName and eponyms.\nThe name \"Nj\u00f6r\u00f0r\" corresponds to that of the older Germanic fertility goddess \"Nerthus\" (early 1st c. CE). Both derive from the Proto-Germanic theonym \"*Ner\u00feuz\".\nThe original meaning of the name is contested, but it may be related to the Irish word \"nert\" which means \"force\" and \"power\". It has been suggested that the change of sex from the female \"Nerthus\" to the male \"Nj\u00f6r\u00f0r\" is due to the fact that feminine nouns with u-stems disappeared early in Germanic language while the masculine nouns with u-stems prevailed. However, other scholars hold the change to be based not on grammatical gender but on the evolution of religious beliefs; that *Ner\u00feuz and Nj\u00f6r\u00f0r appear as different genders because they are to be considered separate beings. The name \"Nj\u00f6r\u00f0r\" may be related to the name of the Norse goddess Nj\u00f6run.\nNj\u00f6r\u00f0r's name appears in various place names in Scandinavia, such as \"N\u00e6rdh\u00e6wi\" (now Nalavi, N\u00e4rke), \"Nj\u00e6rdhavi\" (now Mj\u00e4rdevi, Link\u00f6ping; both using the religious term v\u00e9), \"N\u00e6rdh\u00e6lunda\" (now N\u00e4rlunda, Helsingborg), \"Nierdhatunum\" (now N\u00e4rtuna, Uppland) in Sweden, Njar\u00f0v\u00edk in southwest Iceland, Njar\u00f0arl\u00f6g and Njar\u00f0ey (now N\u00e6r\u00f8ya) in Norway. Nj\u00f6r\u00f0r's name appears in a word for sponge; \"Njar\u00f0arv\u00f6ttr\" (Old Norse: , \"Nj\u00f6r\u00f0r's glove\"). Additionally, in Old Icelandic translations of Classical mythology the Roman god Saturn's name is glossed as \"Nj\u00f6r\u00f0r\".\nAttestations.\n\"Poetic Edda\".\nNj\u00f6r\u00f0r is described as a future survivor of Ragnar\u00f6k in stanza 39 of the poem \"Vaf\u00fer\u00fa\u00f0nism\u00e1l\". In the poem, the god Odin, disguised as \"Gagnr\u00e1\u00f0r\" faces off with the wise j\u00f6tunn Vaf\u00fer\u00fa\u00f0nir in a battle of wits. While Odin states that Vaf\u00fer\u00fa\u00f0nir knows all the fates of the gods, Odin asks Vaf\u00fer\u00fa\u00f0nir \"from where Nj\u00f6r\u00f0r came to the sons of the \u00c6sir\", that Nj\u00f6r\u00f0r rules over quite a lot of temples and h\u00f6rgrs (a type of Germanic altar), and further adds that Nj\u00f6r\u00f0r was not raised among the \u00c6sir. In response, Vaf\u00fer\u00fa\u00f0nir says:\n&lt;poem&gt;In Vanaheim the wise Powers made him\nand gave him as hostage to the gods;\nat the doom of men he will come back\nhome among the wise Vanir.&lt;/poem&gt;\nIn stanza 16 of the poem \"Gr\u00edmnism\u00e1l\", Nj\u00f6r\u00f0r is described as having a hall in N\u00f3at\u00fan made for himself. The stanza describes Nj\u00f6r\u00f0r as a \"prince of men\", that he is \"lacking in malice\", and that he \"rules over the \"high-timbered temple.\" In stanza 43, the creation of the god Freyr's ship Sk\u00ed\u00f0bla\u00f0nir is recounted, and Freyr is cited as the son of Nj\u00f6r\u00f0r. In the prose introduction to the poem \"Sk\u00edrnism\u00e1l\", Freyr is mentioned as the son of Nj\u00f6r\u00f0r, and stanza 2 cites the goddess Ska\u00f0i as the mother of Freyr. Further in the poem, Nj\u00f6r\u00f0r is again mentioned as the father of Freyr in stanzas 38, 39, and 41.\nIn the late flyting poem \"Lokasenna\", an exchange between Nj\u00f6r\u00f0r and Loki occurs in stanzas 33, 34, 35, and 36. After Loki has an exchange with the goddess Freyja, in stanza 33 Nj\u00f6r\u00f0r states:\n&lt;poem&gt;That's harmless, if, besides a husband, a woman has\na lover or someone else;\nwhat is surprising is a pervert god coming in here,\nwho has borne children.&lt;/poem&gt;\nLoki responds in the stanza 34, stating that \"from here you were sent east as hostage to the gods\" (a reference to the \u00c6sir-Vanir War) and that \"the daughters of Hymir used you as a pisspot, and pissed in your mouth.\" In stanza 35, Nj\u00f6r\u00f0r responds that:\n&lt;poem&gt;\nThat was my reward, when I, from far away,\nwas sent as a hostage to the gods,\nthat I fathered that son, whom no one hates\nand is thought the prince of the \u00c6sir.&lt;/poem&gt;\nLoki tells Nj\u00f6r\u00f0r to \"stop\" and \"keep some moderation\", and that he \"won't keep it a secret any longer\" that Nj\u00f6r\u00f0r's son Freyr was produced with his unnamed sister, \"though you'd expect him to be worse than he is.\" The god Tyr then interjects and the flyting continues in turn.\nNj\u00f6r\u00f0r is referenced in stanza 22 of the poem \"\u00derymskvi\u00f0a\", where he is referred to as the father of the goddess Freyja. In the poem, the j\u00f6tunn \u00derymr mistakenly thinks that he will be receiving the goddess Freyja as his bride, and while telling his fellow j\u00f6tunn to spread straw on the benches in preparation for the arrival of Freyja, he refers to her as the daughter of Nj\u00f6r\u00f0r of N\u00f3at\u00fan. Towards the end of the poem \"S\u00f3larlj\u00f3\u00f0\", Nj\u00f6r\u00f0r is cited as having nine daughters. Two of the names of these daughters are given; the eldest R\u00e1\u00f0veig and the youngest Kreppv\u00f6r.\n\"Prose Edda\".\nNj\u00f6r\u00f0r is also mentioned in the \"Prose Edda\" books \"Gylfaginning\" and \"Sk\u00e1ldskaparm\u00e1l\".\n\"Gylfaginning\".\nIn the \"Prose Edda\", Nj\u00f6r\u00f0r is introduced in chapter 23 of the book \"Gylfaginning\". In this chapter, Nj\u00f6r\u00f0r is described by the enthroned figure of High as living in the heavens at N\u00f3at\u00fan, but also as ruling over the movement of the winds, having the ability to calm both sea and fire, and that he is to be invoked in seafaring and fishing. High continues that Nj\u00f6r\u00f0r is very wealthy and prosperous, and that he can also grant wealth in land and valuables to those who request his aid. Nj\u00f6r\u00f0r originates from Vanaheimr and is devoid of \u00c6sir stock, and he is described as having been traded with H\u0153nir in hostage exchange with between the \u00c6sir and Vanir.\nHigh further states that Nj\u00f6r\u00f0r's wife is Ska\u00f0i, that she is the daughter of the j\u00f6tunn \u00dejazi, and recounts a tale involving the two. High recalls that Ska\u00f0i wanted to live in the home once owned by her father called \u00derymheimr (\"Thunder Home\"). However, Nj\u00f6r\u00f0r wanted to live nearer to the sea. Subsequently, the two made an agreement that they would spend nine nights in \u00derymheimr and then next three nights in N\u00f3at\u00fan (or nine winters in \u00derymheimr and another nine in N\u00f3at\u00fan according to the \"Codex Regius\" manuscript). However, when Nj\u00f6r\u00f0r returned from the mountains to N\u00f3at\u00fan, he says:\n&lt;poem&gt;\nHateful for me are the mountains,\nI was not long there,\nonly nine nights.\nThe howling of the wolves\nsounded ugly to me\nafter the song of the swans.&lt;/poem&gt;\nSka\u00f0i then responds:\n&lt;poem&gt;\nSleep I could not\non the sea beds\nfor the screeching of the bird.\nThat gull wakes me\nwhen from the wide sea\nhe comes each morning.&lt;/poem&gt;\nHigh states that afterward Ska\u00f0i went back up to the mountains to \u00derymheimr and recites a stanza where Ska\u00f0i skis around, hunts animals with a bow, and lives in her fathers old house. Chapter 24 begins, which describes Nj\u00f6r\u00f0r as the father of two beautiful and powerful children: Freyr and Freyja. In chapter 37, after Freyr has spotted the beautiful j\u00f6tunn Ger\u00f0r, he becomes overcome with sorrow, and refuses to sleep, drink, or talk. Nj\u00f6r\u00f0r then sends for Sk\u00edrnir to find out who he seems to be so angry at, and, not looking forward to being treated roughly, Sk\u00edrnir reluctantly goes to Freyr.\n\"Sk\u00e1ldskaparm\u00e1l\".\nNj\u00f6r\u00f0r is introduced in \"Sk\u00e1ldskaparm\u00e1l\" within a list of 12 \u00c6sir attending a banquet held for \u00c6gir. Further in \"Sk\u00e1ldskaparm\u00e1l\", the skaldic god Bragi recounts the death of Ska\u00f0i's father \u00dejazi by the \u00c6sir. As one of the three acts of reparation performed by the \u00c6sir for \u00dejazi's death, Ska\u00f0i was allowed by the \u00c6sir to choose a husband from amongst them, but given the stipulation that she may not see any part of them but their feet when making the selection. Expecting to choose the god Baldr by the beauty of the feet she selects, Ska\u00f0i instead finds that she has picked Nj\u00f6r\u00f0r.\nIn chapter 6, a list of kennings is provided for Nj\u00f6r\u00f0r: \"God of chariots\", \"Descendant of Vanir\", \"a Van\", father of Freyr and Freyja, and \"the giving God\". This is followed by an excerpt from a composition by the 11th century skald \u00de\u00f3r\u00f0r Sj\u00e1reksson, explained as containing a reference to Ska\u00f0i leaving Nj\u00f6r\u00f0r:\nGundrun became her son's slayer; the wise god-bride [Skadi] could not love the Van; Kialar [Odin] trained horses pretty well; Hamdir is said not to have held back sword-play.\nChapter 7 follows and provides various kennings for Freyr, including referring to him as the son of Nj\u00f6r\u00f0r. This is followed by an excerpt from a work by the 10th-century skald Egill Skallagr\u00edmsson that references Nj\u00f6r\u00f0r (here anglicized as \"Niord\"):\nFor Freyr and Niord have endowed Griotbiorn with a power of wealth.\nIn chapter 20, \"daughter of Nj\u00f6r\u00f0r\" is given as a kenning for Freyja. In chapter 33, Nj\u00f6r\u00f0r is cited among the gods attending a banquet held by \u00c6gir. In chapter 37, Freyja is again referred to as Nj\u00f6r\u00f0r's daughter in a verse by the 12th century skald Einarr Sk\u00falason. In chapter 75, Nj\u00f6r\u00f0r is included in a list of the \u00c6sir. Additionally, \"Nj\u00f6r\u00f0r\" is used in kennings for \"warrior\" or \"warriors\" various times in \"Sk\u00e1ldskaparm\u00e1l\".\n\"Heimskringla\".\nNj\u00f6r\u00f0r appears in or is mentioned in three Kings' sagas collected in \"Heimskringla\"; \"Ynglinga saga\", the \"Saga of H\u00e1kon the Good\" and the \"Saga of Harald Graycloak\". In chapter 4 of \"Ynglinga saga\", Nj\u00f6r\u00f0r is introduced in connection with the \u00c6sir-Vanir War. When the two sides became tired of war, they came to a peace agreement and exchanged hostages. For their part, the Vanir send to the \u00c6sir their most \"outstanding men\"; Nj\u00f6r\u00f0r, described as wealthy, and Freyr, described as his son, in exchange for the \u00c6sir's H\u0153nir. Additionally, the \u00c6sir send M\u00edmir in exchange for the wise Kvasir.\nFurther into chapter 4, Odin appoints Nj\u00f6r\u00f0r and Freyr as priests of sacrificial offerings, and they became gods among the \u00c6sir. Freyja is introduced as a daughter of Nj\u00f6r\u00f0r, and as the priestess at the sacrifices. In the saga, Nj\u00f6r\u00f0r is described as having once wed his unnamed sister while he was still among the Vanir, and the couple produced their children Freyr and Freyja from this union, though this custom was forbidden among the \u00c6sir.\nChapter 5 relates that Odin gave all of his temple priests dwelling places and good estates, in Nj\u00f6r\u00f0r's case being N\u00f3at\u00fan. Chapter 8 states that Nj\u00f6r\u00f0r married a woman named Ska\u00f0i, though she would not have intercourse with him. Ska\u00f0i then marries Odin, and the two had numerous sons.\nIn chapter 9, Odin dies and Nj\u00f6r\u00f0r takes over as ruler of the Swedes, and he continues the sacrifices. The Swedes recognize him as their king, and pay him tribute. Nj\u00f6r\u00f0r's rule is marked with peace and many great crops, so much so that the Swedes believed that Nj\u00f6r\u00f0r held power over the crops and over the prosperity of mankind. During his rule, most of the \u00c6sir die, their bodies are burned, and sacrifices are made by men to them. Nj\u00f6r\u00f0r has himself \"marked for\" Odin and he dies in his bed. Nj\u00f6r\u00f0r's body is burnt by the Swedes, and they weep heavily at his tomb. After Nj\u00f6r\u00f0r's reign, his son Freyr replaces him, and he is greatly loved and \"blessed by good seasons like his father.\"\nIn chapter 14 of \"Saga of H\u00e1kon the Good\" a description of the pagan Germanic custom of Yule is given. Part of the description includes a series of toasts. The toasts begin with Odin's toasts, described as for victory and power for the king, followed by Nj\u00f6r\u00f0r and Freyr's toast, intended for good harvests and peace (). Following this, a beaker is drunk for the king, and then a toast is given for departed kin. Chapter 28 quotes verse where the kenning \"Nj\u00f6r\u00f0r-of-roller-horses\" is used for \"sailor\". In the \"Saga of Harald Graycloak\", a stanza is given of a poem entitled \"Vellekla\" (\"Lack of Gold\") by the 10th century Icelandic skald Einarr sk\u00e1laglamm that mentions Nj\u00f6r\u00f0r in a kenning for \"warrior\".\n\"Egils saga\".\nIn chapter 80 of the 13th century Icelandic saga \"Egils saga\", Egill Skallagr\u00edmsson composes a poem in praise of Arinbj\u00f6rn (\"Arinbjarnarkvi\u00f0a\"). In stanza 17, Egill writes that all others watch in marvel how Arinbj\u00f6rn gives out wealth, as he has been so endowed by the gods Freyr and Nj\u00f6r\u00f0r.\nModern era folk practice.\nVeneration of Nj\u00f6r\u00f0r survived into 18th or 19th century Norwegian folk practice, as recorded in a tale collected by Halldar O. Opedal from an informant in Odda, Hordaland, Norway. The informant comments on a family tradition in which the god is thanked for a bountiful catch of fish:\nThe old folk [folk in the olden days?] were always rather lucky when they went fishing. One night old Gunnhild Reinsnos (born in 1746) and Johannes Reinsnos were fishing in the Sjosavatn. They had taken a torch and were fishing with live bait. The fish bit well, and it wasn't long before Gunnhild had a week's supply of fish for her pot. So she wound her line around her rod with the words: \"Thanks be to him, to Njor, for this time.\"\nScholar Georges Dum\u00e9zil further cites various tales of \"sea people\" () who govern over sea weather, wealth, or, in some incidents, give magic boats, and proposes that they are historically connected to Nj\u00f6r\u00f0r.\nScholastic reception.\nNerthus.\nNj\u00f6r\u00f0r is often identified with the goddess Nerthus, whose reverence by various Germanic tribes is described by Roman historian Tacitus in his 1st CE century work \"Germania\". The connection between the two is due to the linguistic relationship between \"Nj\u00f6r\u00f0r\" and the reconstructed \"*Ner\u00feuz\", \"Nerthus\" being the feminine, Latinized form of what \"Nj\u00f6r\u00f0r\" would have looked like around 1\u00a0CE. This has led to theories about the relation of the two, including that Nj\u00f6r\u00f0r may have once been a hermaphroditic god or, generally considered more likely, that the name may indicate an otherwise unattested divine brother and sister pair such as Freyr and Freyja. Consequently, Nerthus has been identified with Nj\u00f6r\u00f0r's unnamed sister with whom he had Freyja and Freyr, which is mentioned in \"Lokasenna\".\nBieka-Galles.\nIn Saami mythology, Bieka-Galles (or Biega-, Biegga-Galles, depending on dialect; \"The Old Man of the Winds\") is a deity who rules over rain and wind, and is the subject of boat and wooden shovel (or, rather, oar) offerings. Due to similarities in between descriptions of Nj\u00f6r\u00f0r in \"Gylfaginning\" and descriptions of Bieka-Galles in 18th century missionary reports, Axel Olrik identified this deity as the result of influence from the seafaring North Germanic peoples on the landbound Saami.\nHadingus.\nParallels have been pointed out between Nj\u00f6r\u00f0r and the figure of Hadingus, attested in book I of Saxo Grammaticus' 13th century work \"Gesta Danorum\". Some of these similarities include that, in parallel to Ska\u00f0i and Nj\u00f6r\u00f0r in \"Sk\u00e1ldskaparm\u00e1l\", Hadingus is chosen by his wife Ragnhild after selecting him from other men at a banquet by his lower legs, and, in parallel to Ska\u00f0i and Nj\u00f6r\u00f0r in \"Gylfaginning\", Hadingus complains in verse of his displeasure at his life away from the sea and how he is disturbed by the howls of wolves, while his wife Regnhild complains of life at the shore and states her annoyance at the screeching sea birds. Georges Dum\u00e9zil theorized that in the tale Hadingus passes through all three functions of his trifunctional hypothesis, before ending as an Odinic hero, paralleling Nj\u00f6r\u00f0r's passing from the Vanir to the \u00c6sir in the \u00c6sir-Vanir War.\nSvafr\u00feorinn.\nIn stanza 8 of the poem \"Fj\u00f6lsvinnsm\u00e1l\", Svafr\u00feorinn is stated as the father of Mengl\u00f6\u00f0 by an unnamed mother, who the hero Svipdagr seeks. Mengl\u00f6\u00f0 has often been theorized as the goddess Freyja, and according to this theory, Svafr\u00feorinn would therefore be Nj\u00f6r\u00f0r. The theory is complicated by the etymology of the name \"Svafr\u00feorinn\" (\"\u00feorinn\" meaning \"brave\" and \"svafr\" means \"gossip\") (or possibly connects to \"sofa\" \"sleep\"), which Rudolf Simek says makes little sense when attempting to connect it to Nj\u00f6r\u00f0r.\nModern influence.\nNj\u00f6r\u00f0r has been the subject of an amount of artistic depictions. Depictions include \"Freyr und Gerda; Skade und Niurd\" (drawing, 1883) by K. Ehrenberg, \"Nj\u00f6r\u00f0r\" (1893) by Carl Frederick von Saltza, \"Skadi\" (1901) by E. Doepler d. J., and \"Nj\u00f6rd's Desire of the Sea\" (1908) by W. G. Collingwood.\nNj\u00f6r\u00f0r is one of the incarnated gods in the New Zealand comedy/drama \"The Almighty Johnsons\". The part of \"Johan Johnson/Nj\u00f6r\u00f0r\" is played by Stuart Devenie.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral and cited references.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21597", "revid": "47773670", "url": "https://en.wikipedia.org/wiki?curid=21597", "title": "Neutral", "text": "Neutral or neutrality may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "21601", "revid": "49473253", "url": "https://en.wikipedia.org/wiki?curid=21601", "title": "Niger\u2013Congo languages", "text": "Large language family of Sub-Saharan Africa\nNiger\u2013Congo is a proposed family of languages spoken over the majority of sub-Saharan Africa. It unites the Mande languages, the Atlantic\u2013Congo languages (which share a characteristic noun class system), and possibly several smaller groups of languages that are difficult to classify. If valid, Niger\u2013Congo would be the world's largest language family in terms of member languages, the third-largest in terms of speakers, and Africa's largest in terms of geographical area. The number of named Niger\u2013Congo languages listed by \"Ethnologue\" is 1,540.\nThe proposed family would be the third-largest in the world by number of native speakers, with around 600 million people as of 2025. Within Niger\u2013Congo, the Bantu languages alone account for 350 million people (2015), or half the total Niger\u2013Congo speaking population. The most widely spoken Niger\u2013Congo languages by number of native speakers are Yoruba, Igbo, Fula, Lingala, Ewe, Fon, Ga-Dangme, Shona, Sesotho, Xhosa, Zulu, Akan, and Moor\u00e9. The most widely spoken by the total number of speakers is Swahili, which is used as a lingua franca in parts of eastern and southeastern Africa.\nWhile the ultimate genetic unity of the core of Niger\u2013Congo (called Atlantic\u2013Congo) is widely accepted, the internal cladistic structure is not well established. Other primary branches may include Mande, Dogon, Ijaw, Katla and Rashad. The connection of the Mande languages especially has never been demonstrated, and without them, the validity of Niger\u2013Congo family as a whole (as opposed to Atlantic\u2013Congo or a similar subfamily) has not been established.\nOne of the most distinctive characteristics common to Atlantic\u2013Congo languages is the use of a noun-class system, which is essentially a gender system with multiple genders.\nOrigin.\nThe language family most likely originated in or near the area where these languages were spoken prior to Bantu expansion (i.e. West Africa or Central Africa). Its expansion may have been associated with the expansion of Sahel agriculture in the African Neolithic period, following the desiccation of the Sahara in c. 3500 BCE.\nSimilar classifications to Niger\u2013Congo have been made ever since Diedrich Westermann in 1922. Joseph Greenberg continued that tradition, making it the starting point for modern linguistic classification in Africa, with some of his publications going to press starting in the 1960s. However, there has been active debate for many decades over the appropriate subclassifications of the languages in this language family, which is a key tool used in localising a language's place of origin. No definitive \"Proto-Niger\u2013Congo\" lexicon or grammar has been developed for the language family as a whole.\nAn important unresolved issue in determining the time and place where the Niger\u2013Congo languages originated and their range prior to recorded history is this language family's relationship to the Kordofanian languages, now spoken in the Nuba Mountains of Sudan, which is not contiguous with the remainder of the Niger\u2013Congo-language-speaking region and is at the northeasternmost extent of the current Niger\u2013Congo linguistic region. The current prevailing linguistic view is that the Kordofanian languages are part of the Niger\u2013Congo language family and may be the oldest languages in the region. The evidence is insufficient to determine if this outlier group of Niger\u2013Congo language speakers represents a prehistoric range of a Niger\u2013Congo linguistic region that has since contracted as other languages have intruded, or if instead, this represents a group of Niger\u2013Congo language speakers who migrated to the area at some point in prehistory where they were an isolated linguistic community from the beginning.\nThere is more agreement regarding the place of origin of Benue\u2013Congo, the largest subfamily of the group. Within Benue\u2013Congo, the place of origin of the Bantu languages as well as time at which it started to expand is known with great specificity. Blench (2004), relying particularly on prior work by Kay Williamson and P. De Wolf, argued that Benue\u2013Congo probably originated at the confluence of the Benue and Niger Rivers in central Nigeria. These estimates of the place of origin of the Benue\u2013Congo language family do not fix a date for the start of that expansion, other than that it must have been sufficiently prior to the Bantu expansion to allow for the diversification of the languages within this language family that includes Bantu.\nThe classification of the relatively divergent family of the Ubangian languages, centred in the Central African Republic, as part of the Niger\u2013Congo language family is disputed. Ubangian was grouped with Niger\u2013Congo by Greenberg (1963), and later authorities concurred, but it was questioned by Dimmendaal (2008).\nThe Bantu expansion, beginning around 1000 BC, swept across much of Central and Southern Africa, leading to the assimilation and extinction of many of the indigenous Pygmy and Bushmen (Khoisan) populations there.\nMajor branches.\nThe following is an overview of the language groups usually included in Niger\u2013Congo. The genetic relationship of some branches is not universally accepted, and the cladistic connection between those who are accepted as related may also be unclear.\nThe core phylum of the Niger\u2013Congo group are the Atlantic\u2013Congo languages. The non-Atlantic\u2013Congo languages within Niger\u2013Congo are grouped as Dogon, Mande, Ijo (sometimes with Defaka as Ijoid), Katla, and Rashad.\nAtlantic\u2013Congo.\nAtlantic\u2013Congo combines the Atlantic languages, which do not form one branch, and Volta\u2013Congo. It comprises more than 80% of the Niger\u2013Congo speaking population, or close to 600 million people (2015).\nThe proposed Savannas group combines Adamawa, Ubangian and Gur. Outside of the Savannas group, Volta\u2013Congo comprises Kru, Kwa (or \"West Kwa\"), Volta\u2013Niger (also \"East Kwa\" or \"West Benue\u2013Congo\"), and Benue\u2013Congo (or \"East Benue\u2013Congo\"). Volta\u2013Niger includes the two largest languages of Nigeria, Yoruba, and Igbo. Benue\u2013Congo includes the Southern Bantoid group, which is dominated by the Bantu languages, which account for 350 million people (2015), or half the total Niger\u2013Congo speaking population.\nThe strict genetic unity of any of these subgroups may themselves be under dispute. For example, Roger Blench (2012) argued that Adamawa, Ubangian, Kwa, Bantoid, and Bantu are not coherent groups.\nAlthough the Kordofanian branch is generally included in the Niger\u2013Congo languages, some researchers do not agree with its inclusion. \"Glottolog\" 3.4 (2019) does not accept that the Kordofanian branches (Lafofa, Talodi and Heiban) or the difficult-to-classify Laal language have been demonstrated to be Atlantic\u2013Congo languages. It otherwise accepts the family but not its inclusion within a broader Niger\u2013Congo. Glottolog also considers Ijoid, Mande, and Dogon to be independent language phyla that have not been demonstrated to be related to each other.\nThe Atlantic\u2013Congo group is characterised by the noun class systems of its languages. Atlantic\u2013Congo largely corresponds to Mukarovsky's \"Western Nigritic\" phylum.\nThe polyphyletic Atlantic group accounts for about 35 million speakers as of 2016, mostly accounted for by Fula and Wolof speakers. Atlantic is not considered to constitute a valid group.\nOther.\nThe putative Niger\u2013Congo languages outside of the Atlantic\u2013Congo family are centred in the upper Senegal and Niger river basins, south and west of Timbuktu (Mande, Dogon), the Niger Delta (Ijoid), and far to the east in south-central Sudan, around the Nuba Mountains (the Kordofanian families). They account for a total population of about 100 million (2015), mostly Mand\u00e9 and Ijaw.\n\"Kordofanian\".\nThe various Kordofanian languages are spoken in south-central Sudan, around the Nuba Mountains, an area of linguistic diversity. \"Kordofanian\" is a geographic grouping, not a genetic one, named for the Kordofan region. These are minor languages, spoken by a total of about 100,000 people according to 1980s estimates. Katla and Rashad languages show isoglosses with Benue\u2013Congo that the other families lack.\nThe endangered or extinct Laal, Mpre and Jalaa languages are often assigned to Niger\u2013Congo.\nClassification history.\nEarly classifications.\nNiger\u2013Congo as it is known today was only gradually recognized as a linguistic unit. In early classifications of the languages of Africa, one of the principal criteria used to distinguish different groupings was the languages' use of prefixes to classify nouns, or the lack thereof. A major advance came with the work of Sigismund Wilhelm Koelle, who in his 1854 \"Polyglotta Africana\" attempted a careful classification, the groupings of which in quite a number of cases correspond to modern groupings. An early sketch of the extent of Niger\u2013Congo as one language family can be found in Koelle's observation, echoed in Bleek (1856), that the Atlantic languages used prefixes just like many Southern African languages. Subsequent work of Bleek, and some decades later the comparative work of Meinhof, solidly established Bantu as a linguistic unit.\nIn many cases, wider classifications employed a blend of typological and racial criteria. Thus, Friedrich M\u00fcller, in his ambitious classification (1876\u201388), separated the 'Negro' and Bantu languages. Likewise, the Africanist Karl Richard Lepsius considered Bantu to be of African origin, and many 'Mixed Negro languages' as products of an encounter between Bantu and intruding Asiatic languages.\nIn this period a relation between Bantu and languages with Bantu-like (but less complete) noun class systems began to emerge. Some authors saw the latter as languages which had not yet completely evolved to full Bantu status, whereas others regarded them as languages which had partly lost original features still found in Bantu. The Bantuist Meinhof made a major distinction between Bantu and a 'Semi-Bantu' group which according to him was originally of the unrelated Sudanic stock.\nWestermann, Greenberg, and others.\nWestermann, a pupil of Meinhof, set out to establish the internal classification of the then Sudanic languages. In a 1911 work he established a basic division between 'East' and 'West'. A historical reconstruction of West Sudanic was published in 1927, and in his 1935 'Charakter und Einteilung der Sudansprachen' he conclusively established the relationship between Bantu and West Sudanic.\nJoseph Greenberg took Westermann's work as a starting-point for his own classification. In a series of articles published between 1949 and 1954, he argued that Westermann's 'West Sudanic' and Bantu formed a single genetic family, which he named Niger\u2013Congo; that Bantu constituted a subgroup of the Benue\u2013Congo branch; that Adamawa-Eastern, previously not considered to be related, was another member of this family; and that Fula belonged to the West Atlantic languages. Just before these articles were collected in final book form (\"The Languages of Africa\") in 1963, he amended his classification by adding Kordofanian as a branch co-ordinate with Niger\u2013Congo as a whole; consequently, he renamed the family \"Congo-Kordofanian\", later \"Niger\u2013Kordofanian\". Greenberg's work on African languages, though initially greeted with scepticism, became the prevailing view among scholars.\nBennet and Sterk (1977) presented an internal reclassification based on lexicostatistics that laid the foundation for the regrouping in Bendor-Samuel (1989). Kordofanian was presented as one of several primary branches rather than being coordinate to the family as a whole, prompting re-introduction of the term \"Niger\u2013Congo\", which is in current use among linguists. Many classifications continue to place Kordofanian as the most distant branch, but mainly due to negative evidence (fewer lexical correspondences), rather than positive evidence that the other languages form a valid genealogical group. Likewise, Mande is often assumed to be the second-most distant branch based on its lack of the noun-class system prototypical of the Niger\u2013Congo family. Other branches lacking any trace of the noun-class system are Dogon and Ijaw, whereas the Talodi branch of Kordofanian does have cognate noun classes, suggesting that Kordofanian is also not a unitary group.\nPozdniakov (2012) stated: \"The hypothesis of kinship between Niger\u2013Congo languages didn't appear as a result of discovery of numerous related forms, for example, in Mande and Adamawa. It appeared as a result of comparison between the Bantu languages, for which the classical comparative method was possible to be applied and which were reliably reconstructed, with other African languages. Niger\u2013Congo does not exist without Bantu. We need to say clearly that if we establish a genetic relationship between a form in Bantu and in Atlantic languages, or between Bantu and Mande, we have all grounds to trace this form back to Niger\u2013Congo. If we establish such a relationship between Mel and Kru or between Mande and Dogon, we don't have enough reason to claim it Niger\u2013Congo. In other words, all Niger\u2013Congo languages are equal, but Bantu languages are \"more equal\" than the others.\"\n\"Glottolog\" (2013) accepts the core with noun-class systems, the Atlantic\u2013Congo languages, apart from the recent inclusion of some of the Kordofanian groups, but not Niger\u2013Congo as a whole. They list the following as separate families: Atlantic\u2013Congo, Mande, Dogon, Ijoid, Lafofa, Katla-Tima, Heiban, Talodi, and Rashad.\nBabaev (2013) stated: \"The truth here is that almost no attempts in fact have been made to verify Greenberg's Niger\u2013Congo hypothesis. This might seem strange but the path laid by Joseph Greenberg to Proto\u2013Niger\u2013Congo was not followed by much research. Most scholars have focused on individual families or groups, and classifications as well as reconstructions were made on lower levels. Compared with the volume of literature on Atlantic or Mande languages, the list of papers considering the aspects of Niger\u2013Congo reconstruction per se is quite scarce.\"\n\"Oxford Handbooks Online\" (2016) has indicated that the continuing reassessment of Niger\u2013Congo's \"internal structure is due largely to the preliminary nature of Greenberg's classification, explicitly based as it was on a methodology that doesn't produce proofs for genetic affiliations between languages but rather aims at identifying \"likely candidates.\"...The ongoing descriptive and documentary work on individual languages and their varieties, greatly expanding our knowledge on formerly little-known linguistic regions, is helping to identify clusters and units that allow for the application of the historical-comparative method. Only the reconstruction of lower-level units, instead of \"big picture\" contributions based on mass comparison, can help to verify (or disprove) our present concept of Niger\u2013Congo as a genetic grouping consisting of Benue\u2013Congo plus Volta\u2013Niger, Kwa, Adamawa plus Gur, Kru, the so-called Kordofanian languages, and probably the language groups traditionally classified as Atlantic.\"\nThe coherence of Niger\u2013Congo as a language phylum is supported by Grollemund, et al. (2016), using computational phylogenetic methods. The East/West Volta\u2013Congo division, West/East Benue\u2013Congo division, and North/South Bantoid division are not supported, whereas a Bantoid group consisting of Ekoid, Bendi, Dakoid, Jukunoid, Tivoid, Mambiloid, Beboid, Mamfe, Tikar, Grassfields, and Bantu is supported.\nThe Automated Similarity Judgment Program (ASJP) also groups many Niger\u2013Congo branches together.\nDimmendaal, Crevels, and Muysken (2020) stated: \"Greenberg's hypothesis of Niger\u2013Congo phylum has sometimes been taken as an established fact rather than a hypothesis awaiting further proof, but there have also been attempts to look at his argumentation in more detail. Much of the discussion concerning Niger\u2013Congo after Greenberg's seminal contribution in fact centered around the inclusion or exclusion of specific languages or language groups.\"\nGood (2020) stated: \"First proposed by Greenberg (1949), Niger\u2013Congo (NC) has for decades been treated as one of the four major phyla of African languages. The term, as presently used, however, is not without its difficulties. On the one hand, it is employed as a referential label for a group of over 1,500 languages, putting it among the largest commonly cited language groups in the world. On the other hand, the term is also intended to embody a hypothesis of genealogical relationship between the referential NC languages that has not been proven.\"\nReconstruction.\nThe lexicon of Proto\u2013Niger\u2013Congo (or Proto-Atlantic\u2013Congo) has not been comprehensively reconstructed, although Konstantin Pozdniakov reconstructed the numeral system of Proto\u2013Niger\u2013Congo in 2018. The most extensive reconstructions of lower-order Niger\u2013Congo branches include several reconstructions of Proto-Bantu, which has consequently had a disproportionate influence on conceptions of what Proto\u2013Niger\u2013Congo may have been like. The only stage higher than Proto-Bantu that has been reconstructed is a pilot project by Stewart, who since the 1970s has reconstructed the common ancestor of the Potou-Tano and Bantu languages, without so far considering the hundreds of other languages which presumably descend from that same ancestor.\nNiger\u2013Congo and Nilo-Saharan.\nOver the years, several linguists have suggested a link between Niger\u2013Congo and the proposed Nilo-Saharan language family, probably starting with Westermann's comparative work on the \"Sudanic\" family in which 'Eastern Sudanic' (proposed to be classified as Nilo-Saharan) and 'Western Sudanic' (now classified as Niger\u2013Congo) were united. Gregersen (1972) proposed that Niger\u2013Congo and Nilo-Saharan be united into a larger phylum, which he termed \"Kongo-Saharan\". His evidence was mainly based on the uncertainty in the classification of Songhay, morphological resemblances, and lexical similarities. A more recent proponent was Roger Blench (1995), who puts forward phonological, morphological and lexical evidence for uniting Niger\u2013Congo and Nilo-Saharan in a \"Niger\u2013Saharan\" phylum, with special affinity between Niger\u2013Congo and Central Sudanic. However, fifteen years later his views had changed, with Blench (2011) proposing instead that the noun-classifier system of Central Sudanic, commonly reflected in a tripartite general-singulative-plurative number system, triggered the development or elaboration of the noun-class system of the Atlantic\u2013Congo languages, with tripartite number marking surviving in the Plateau and Gur languages of Niger\u2013Congo, and the lexical similarities being due to loans.\nCommon features.\nPhonology.\nNiger\u2013Congo languages have a clear preference for open syllables of the type CV (Consonant Vowel). The typical word structure of Proto\u2013Niger\u2013Congo (though it has not been reconstructed) is thought to have been CVCV, a structure still attested in, for example, Bantu, Mande and Ijoid \u2013 in many other branches this structure has been reduced through phonological change. Verbs are composed of a root followed by one or more extensional suffixes. Nouns consist of a root originally preceded by a noun class prefix of (C)V- shape which is often eroded by phonological change.\nConsonants.\nSeveral branches of Niger\u2013Congo have a regular phonological contrast between two classes of consonants. Pending more clarity as to the precise nature of this contrast, it is commonly characterized as a contrast between fortis and lenis consonants.\nVowels.\nMany Niger\u2013Congo languages' vowel harmony is based on the [ATR] (advanced tongue root) feature. In this type of vowel harmony, the position of the root of the tongue in regards to backness is the phonetic basis for the distinction between two harmonizing sets of vowels. In its fullest form, this type involves two classes, each of five vowels.\nThe roots are then divided into [+ATR] and [\u2212ATR] categories. This feature is lexically assigned to the roots because there is no determiner within a normal root that causes the [ATR] value.\nThere are two types of [ATR] vowel harmony controllers in Niger\u2013Congo. The first controller is the root. When a root contains a [+ATR] or [\u2212ATR] vowel, then that value is applied to the rest of the word, which involves crossing morpheme boundaries. For example, suffixes in Wolof assimilate to the [ATR] value of the root to which they attach. The following examples of these suffixes alternate depending on the root.\nFurthermore, the directionality of assimilation in [ATR] root-controlled vowel harmony need not be specified. The root features [+ATR] and [\u2212ATR] spread left and/or right as needed, so that no vowel would lack a specification and be ill-formed.\nUnlike in the root-controlled harmony system, where the two [ATR] values behave symmetrically, a large number of Niger\u2013Congo languages exhibit a pattern where the [+ATR] value is more active or dominant than the [\u2212ATR] value. This results in the second vowel harmony controller being the [+ATR] value. If there is even one vowel that is [+ATR] in the whole word, then the rest of the vowels harmonize with that feature. However, if there is no vowel that is [+ATR], the vowels appear in their underlying form. This form of vowel harmony control is best exhibited in West African languages. For example, in Nawuri, the diminutive suffix /-bi/ will cause the underlying [\u2212ATR] vowels in a word to become phonetically [+ATR].\nThere are two types of vowels which affect the harmony process. These are known as neutral or opaque vowels. Neutral vowels do not harmonize to the [ATR] value of the word, and instead maintain their own [ATR] value. The vowels that follow them, however, will receive the [ATR] value of the root. Opaque vowels maintain their own [ATR] value as well, but they affect the harmony process behind them. All of the vowels following an opaque vowel will harmonize with the [ATR] value of the opaque vowel instead of the [ATR] vowel of the root.\nThe vowel inventory listed above is a ten-vowel language. This is a language in which all of the vowels of the language participate in the harmony system, producing five harmonic pairs. Vowel inventories of this type are still found in some branches of Niger\u2013Congo, for example in the Ghana-Togo Mountain languages. However, this is the rarer inventory as oftentimes there are one or more vowels that are not part of a harmonic pair. This has resulted in seven- and nine-vowel systems being the more popular systems. The majority of languages with [ATR] controlled vowel harmony have either seven or nine vowel phonemes, with the most common non-participatory vowel being /a/. It has been asserted that this is because vowel quality differences in the mid-central region where /\u0259/, the counterpart of /a/, is found, are difficult to perceive. Another possible reason for the non-participatory status of /a/ is that there is articulatory difficulty in advancing the tongue root when the tongue body is low in order to produce a low [+ATR] vowel. Therefore, the vowel inventory for nine-vowel languages is generally:\nAnd seven-vowel languages have one of two inventories:\nNote that in the nine-vowel language, the missing vowel is, in fact, [\u0259], [a]'s counterpart, as would be expected.\nThe fact that ten vowels have been reconstructed for proto-Ijoid has led to the hypothesis that the original vowel inventory of Niger\u2013Congo was a full ten-vowel system. On the other hand, Stewart, in recent comparative work, reconstructs a seven-vowel system for his proto-Potou-Akanic-Bantu.\nNasality.\nSeveral scholars have documented a contrast between oral and nasal vowels in Niger\u2013Congo. In his reconstruction of proto-Volta\u2013Congo, Steward (1976) postulates that nasal consonants have originated under the influence of nasal vowels; this hypothesis is supported by the fact that there are several Niger\u2013Congo languages that have been analysed as lacking nasal consonants altogether. Languages like this have nasal vowels accompanied with complementary distribution between oral and nasal consonants before oral and nasal vowels. Subsequent loss of the nasal/oral contrast in vowels may result in nasal consonants becoming part of the phoneme inventory. In all cases reported to date, the bilabial /m/ is the first nasal consonant to be phonologized. Niger\u2013Congo thus invalidates two common assumptions about nasals: that all languages have at least one primary nasal consonant, and that if a language has only one primary nasal consonant it is /n/.\nNiger\u2013Congo languages commonly show fewer nasalized than oral vowels. Kasem, a language with a ten-vowel system employing ATR vowel harmony, has seven nasalized vowels. Similarly, Yoruba has seven oral vowels and only five nasal ones. However, the language of Zialo has a nasal equivalent for each of its seven oral vowels.\nTone.\nThe large majority of present-day Niger\u2013Congo languages are tonal. A typical Niger\u2013Congo tone system involves two or three contrastive level tones. Four-level systems are less widespread, and five-level systems are rare. Only a few Niger\u2013Congo languages are non-tonal; Swahili is perhaps the best known, but within the Atlantic branch some others are found. Proto\u2013Niger\u2013Congo is thought to have been a tone language with two contrastive levels. Synchronic and comparative-historical studies of tone systems show that such a basic system can easily develop more tonal contrasts under the influence of depressor consonants or through the introduction of a downstep. Languages which have more tonal levels tend to use tone more for lexical and less for grammatical contrasts.\nMorphosyntax.\nNoun classification.\nNiger\u2013Congo languages are known for their system of noun classification, traces of which can be found in every branch of the family but Mande, Ijoid, Dogon, and the Katla and Rashad branches of Kordofanian. These noun-classification systems are somewhat analogous to grammatical gender in other languages, but there are often a fairly large number of classes (often 10 or more), and the classes may be male human/female human/animate/inanimate, or even completely gender-unrelated categories such as places, plants, abstracts, and groups of objects. For example, in Bantu, the Swahili language is called \"Kiswahili,\" while the Swahili people are \"Waswahili.\" Likewise, in Ubangian, the Zande language is called \"Pazande,\" while the Zande people are called \"Azande.\"\nIn the Bantu languages, where noun classification is particularly elaborate, it typically appears as prefixes, with verbs and adjectives marked according to the class of the noun they refer to. For example, in Swahili, \"watu wazuri wataenda\" is 'good \"(zuri)\" people \"(tu)\" will go \"(ta-enda)\"'.\nVerbal extensions.\nThe same Atlantic\u2013Congo languages which have noun classes also have a set of verb applicatives and other verbal extensions, such as the reciprocal suffix \"-na\" (Swahili \"penda\" 'to love', \"pendana\" 'to love each other'; also applicative \"pendea\" 'to love for' and causative \"pendeza\" 'to please').\nWord order.\nA subject-verb-object word order is quite widespread among today's Niger\u2013Congo languages, but SOV is found in branches as divergent as Mande, Ijoid and Dogon. As a result, there has been quite some debate as to the basic word order of Niger\u2013Congo.\nWhereas Claudi (1993) argues for SVO on the basis of existing SVO &gt; SOV grammaticalization paths, Gensler (1997) points out that the notion of 'basic word order' is problematic as it excludes structures with, for example, auxiliaries. However, the structure SC-OC-VbStem (Subject concord, Object concord, Verb stem) found in the \"verbal complex\" of the SVO Bantu languages suggests an earlier SOV pattern (where the subject and object were at least represented by pronouns).\nNoun phrases in most Niger\u2013Congo languages are characteristically \"noun-initial\", with adjectives, numerals, demonstratives and genitives all coming after the noun. The major exceptions are found in the western areas where verb-final word order predominates and genitives precede nouns, though other modifiers still come afterwards. Degree words almost always follow adjectives, and except in verb-final languages adpositions are prepositional.\nThe verb-final languages of the Mende region have two quite unusual word order characteristics. Although verbs follow their direct objects, oblique adpositional phrases (like \"in the house\", \"with timber\") typically come after the verb, creating a SOVX word order. Also noteworthy in these languages is the prevalence of internally headed and correlative relative clauses, in both of which the head occurs \"inside\" the relative clause rather than the main clause.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "21603", "revid": "1043125", "url": "https://en.wikipedia.org/wiki?curid=21603", "title": "Nuclear Test Ban", "text": ""}
{"id": "21606", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=21606", "title": "Napo River", "text": "River of Ecuador\nThe Napo River () is a tributary to the Amazon River that rises in Ecuador on the flanks of the east Andean volcanoes of Antisana, Sincholagua and Cotopaxi.\nThe total length is . The river drains an area of ca 103,000 km2. The mean annual discharge at Maz\u00e1n .\nGeography.\nBefore it reaches the plains it receives a great number of small streams from impenetrable, saturated and much broken mountainous districts, where the dense and varied vegetation seems to fight for every piece of ground. From the north it is joined by the Coca River, having its sources in the gorges of Cayambe volcano on the equator, and also a powerful river, the Aguarico having its headwaters between Cayambe and the Colombia frontier.\nFrom the west, it receives a secondary tributary, the Curaray, from the Andean slopes, between Cotopaxi and the Tungurahua volcano. From its Coca branch to the mouth of the Curaray the Napo is full of snags and shelving sandbanks and throws out numerous canoes among jungle-tangled islands, which in the wet season are flooded, giving the river an immense width. From the Coca to the Amazon it runs through a forested plain where not a hill is visible from the river - its uniformly level banks being only interrupted by swamps and lagoons. From the Amazon the Napo is navigable for river craft up to its Curaray branch, a distance of about , and perhaps a bit further; thence, by painful canoe navigation, its upper waters may be ascended as far as \"Santa Rosa\", the usual point of embarkation for any venturesome traveller who descends from the Quito tableland. The Coca river may be penetrated as far up as its middle course, where it is jammed between two mountain walls, in a deep canyon, along which it dashes over high falls and numerous reefs. This is the stream made famous by the expedition of the Spanish conquistador Gonzalo Pizarro.\nHydrometric stations on the Napo River:\nDischarge.\nNapo River at Bellavista average (Q), dominante (Qd) discharge (m3/s) and sediment load (S \u2013 million ton/year). Period from 1991/09\u20132009/08:\nNapo River at Bellavista average, minimum and maximum discharge (m3/s). Period from 2009/09 to 2023/08:\nMinimum 498.6 m3/s (2016/02); Maximum: 15,820 m3/s (2015/07);\nNapo River at Bellavista average, maximum, minimum and multiannual average (normal) discharge (m3/s) and anomaly (%):\nTributaries.\nList of the major tributaries of the Napo River (from the mouth upwards):\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21607", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=21607", "title": "Nanay River", "text": "The Nanay River is a river in northern Peru. It is a tributary of the Amazon River, merging into this river at the city of Iquitos. The lower part of the Nanay flows to the north and west of the city, while the Itaya River flows to the south and east. Other nearby settlements on the Nanay River include the villages of Santo Tom\u00e1s, Padre Cocha, and Santa Clara. During periods when the river is low, the many beaches along the Nanay are popular destinations. The Nanay belongs entirely to the lowlands, and is very crooked, has a slow current and divides into many \"canos\" and strings of lagoons which flood the flat, low areas of country on either side. It is simply the drainage ditch of districts which are extensively overflowed in the rainy season. Captain Archibald Butt USN, ascended it , to near its source. A part of the Nanay River flows through the Allpahuayo-Mishana National Reserve.\nThe Nanay is a blackwater river and it has a high fish species richness, including several that are well known from the aquarium industry. Some of these, notably green discus, are the result of accidental introductions that happened in the 1970s.\nThe river is the location of hundreds of illegal artisanal mines digging for gold.\nThe 2012 floods of the Amazon, Itaya, and Nanay rivers, amid the heaviest rains the region had faced in 40 years, left approximately 80,000 people homeless.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21609", "revid": "50885127", "url": "https://en.wikipedia.org/wiki?curid=21609", "title": "Nine-ball", "text": "Type of cue sport\nNine-ball (sometimes written 9-ball) is a discipline of the cue sport pool. The game's origins are traceable to the 1920s in the United States. It is played on a rectangular billiard table with &lt;dfn id=\"\"&gt;pockets&lt;/dfn&gt; at each of the four corners and in the middle of each long side. Using a cue stick, players must strike the white cue ball to &lt;dfn id=\"\"&gt;pocket&lt;/dfn&gt; nine colored billiard balls, hitting them in ascending numerical order. An individual game (or &lt;dfn id=\"\"&gt;rack&lt;/dfn&gt;) is won by the player pocketing the &lt;dfn id=\"\"&gt;9 ball&lt;/dfn&gt;. Matches are usually played as a &lt;dfn id=\"\"&gt;race&lt;/dfn&gt; to a set number of racks, with the player who reaches the set number winning the match.\nThe game is currently governed by the World Pool-Billiard Association (WPA), with multiple regional tours. The most prestigious nine-ball tournaments are the WPA World Nine-ball Championship and the U.S. Open Nine-ball Championships. Notable 9-Ball players in the game include Luther Lassiter, Buddy Hall, Efren Reyes, Fedor Gorst, Earl Strickland and Shane Van Boening. The game is often associated with hustling and gambling, with tournaments often having a \"buy-in\" amount to become a participant. The sport has featured in popular culture, notably in the 1961 film \"The Hustler\" and its 1986 sequel \"The Color of Money\".\nNine-ball has been played with varied rules, with games such as ten-ball, seven-ball and three-ball being derived from the game. While usually a singles sport, the game can be played in doubles, with players completing alternate shots. Examples of tournaments featuring doubles include the World Cup of Pool, World Team Championship and the Mosconi Cup.\nHistory.\nThe game was established in America by 1920, although its exact origins are unknown. Nine-ball is played with the same equipment as eight-ball and other pool games.\nRules.\nThe game of nine-ball is played on a billiard table with six pockets. The &lt;dfn id=\"\"&gt;cue ball&lt;/dfn&gt;, which is usually a solid shade of white (but may be spotted in some tournaments), is struck to hit the nine &lt;dfn id=\"\"&gt;object balls&lt;/dfn&gt;, which are numbered 1 through 9, each a distinct color, with the 9 ball typically having a yellow stripe on a white base. The aim of the game is to hit the lowest numbered ball on the table (often referred to as the &lt;dfn id=\"\"&gt;ball on&lt;/dfn&gt;) and &lt;dfn id=\"\"&gt;pocket&lt;/dfn&gt; balls in succession to eventually pocket the nine-ball. As long as the lowest numbered ball on the table is contacted first by the cueball, and any one or more of the object balls are pocketed in any of the pockets with no &lt;dfn id=\"\"&gt;foul&lt;/dfn&gt; being committed, a player's &lt;dfn id=\"\"&gt;inning&lt;/dfn&gt; continues. When the table passes to another player, they must play from where the balls were last positioned, except if the prior inning ended in a foul. In that case, the incoming player takes &lt;dfn id=\"\"&gt;ball in hand&lt;/dfn&gt;, anywhere on the table. The winner is the player who legally pockets the nine-ball, the game's &lt;dfn id=\"\"&gt;money ball&lt;/dfn&gt;, regardless of how many balls have been pocketed beforehand. This can happen earlier than the nine-ball being the sole remaining object ball on the table if it is pocketed via a &lt;dfn id=\"\"&gt;combination&lt;/dfn&gt; or other indirect method.\nBreaking.\nEach rack begins with the object balls placed in a rack and one player playing a &lt;dfn id=\"\"&gt;break&lt;/dfn&gt;. The object balls are placed in a diamond-shaped configuration, with the 1 ball positioned at the front, and the 9 ball placed in the center on the &lt;dfn id=\"\"&gt;foot spot&lt;/dfn&gt;, although some tournaments may rack with the 1 ball on the foot spot. The rack used to position the balls, typically wooden or plastic, may be either triangle-shaped, as is used for eight-ball and other pool games, or a specific diamond-shaped rack that holds only nine balls may be used. A template that lies on the table during the break has also come into use.\nThe break consists of hitting the 1 ball, with the attempt to pocket any ball. If the 9 ball is successfully potted, the player automatically wins the rack. This is sometimes known as a &lt;dfn id=\"\"&gt;golden break&lt;/dfn&gt;. Additional rules in some tournaments exist, such as a number of balls having to reach the &lt;dfn id=\"\"&gt;head string&lt;/dfn&gt;, and players can be chosen to break alternately or whoever won the preceding rack. The break is often the most crucial shot in nine-ball, as it is possible to win a rack without the opponent having taken a single shot. This is often called a &lt;dfn id=\"\"&gt;break and run&lt;/dfn&gt;, or running the rack. Earl Strickland holds the record for break and runs, after he successfully ran 11 consecutive racks in a tournament in 1996. The first break of a match is sometimes decided by a flip of a coin, but often by playing a &lt;dfn id=\"\"&gt;lag&lt;/dfn&gt;, with both players playing a cue ball down the table, the closest to the top rail winning the initial break.\nPush out and fouls.\nAfter the break, if no fouls were committed, the shooter has the option to continue the rack as usual, or to play a &lt;dfn id=\"\"&gt;push out&lt;/dfn&gt;. The rules on a push out are different to those of a regular shot, as the shot does not need to hit a rail or ball. After the push out, the opposing player has the option to play the shot that has been left, or to force their opponent to play on from that location. In early versions of nine-ball the push out could be called at any time during the game, but is now only for the shot after the break.\nIf a player misses potting a ball on a shot, or commits a foul shot, then their opponent plays the next shot. A foul shot can involve not making first contact with the lowest numbered ball, pocketing the cue ball, or, after hitting the lowest numbered ball, not pocketing an object ball and not making contact with a &lt;dfn id=\"\"&gt;rail&lt;/dfn&gt; by an object ball or the cue ball. A foul shot for any reason offers the opponent &lt;dfn id=\"\"&gt;ball in hand&lt;/dfn&gt;, which means they can place the cue ball at any location on the table. A player making three successive fouls (for any reason) awards that rack to the opponent. Unlike some other cue sports, such as snooker, players are allowed to jump the cue ball over other balls. However, if any ball leaves the cloth at the end of a shot, it is counted as a foul. Jumping is common in nine-ball, and players often have a dedicated jump cue.\nEuropean alterations.\nAs of the 2000s, the rules have been somewhat in flux in certain contexts, especially in Europe. The European Pocket Billiard Federation (EPBF), the WPA-affiliate in Europe, has instituted a requirement on the Euro Tour is that the break shot be taken from a \"&lt;dfn id=\"\"&gt;break box&lt;/dfn&gt;\" a rectangular box smaller than the regular nine-ball breaking area. While making the money ball on breaks are still possible, they are much more difficult with the break box. This was later used on the annual international Mosconi Cup tournaments. Another Mosconi Cup rule change in 2007 called for racking such that the 9 ball rather than the 1 ball is on the &lt;dfn id=\"\"&gt;foot spot&lt;/dfn&gt;, which further stops overpowered break-off shots. This rule change was later adopted by the WPA in their 2025 rule changes.\nGovernance.\nThe general rules of the game are fairly consistent and usually do not stray too far from the earliest format set by the Billiard Congress of America (BCA). These later formed the basis of the standardized WPA rules, which the BCA follows as a member, although amateur league play may be governed by similar but slightly different rules promulgated by the American Poolplayers Association (APA) and other organizations.\nTournaments.\nNine-ball events worldwide are run at the highest level by the WPA. The WPA World Nine-ball Championship has events for men, women and junior players. Events are generally open to any player who can pay the entry fee, however, some events are based on qualification. The WPA hosts a world ranking schedule based on WPA events, with other ranking systems also operated by the APA and the EPBF. Other major events held by the WPA include the U.S. Open 9-Ball Championship, China Open 9-Ball Championship and the International 9-Ball Open.\nIn addition, Matchroom Sport runs major international competitions including the Mosconi Cup, World Cup of Pool and World Pool Masters.\nOutside those events held on an worldwide basis, nine-ball is played in continental tour series. Events are held on series such as the Diamond Pool Tour, Asian Tour and Euro Tour.\nDerived games.\nSeveral games have been derived from nine-ball. Six-ball is essentially identical to nine-ball but with three fewer balls, which are racked in a three-row triangle, with the money ball placed in the center of the back row. According to Rudolf Wanderone, the game arose in early 20th century billiard halls; halls charged for matches by the 15 ball rack rather than by table, so players of nine-ball had six balls left over. For this reason, the game is often played with the balls numbered between 10 and 15, with the 15 ball as the money ball.\nSeven-ball is also similar to nine-ball, though it differs in two key ways: the game uses only seven object balls, which are racked in a hexagon, and players are restricted to pocketing the money ball on their designated side of the table. William D. Clayton is credited with the game's invention in the early 1980s. While not a common game, it was featured on television broadcaster ESPN's \"Sudden Death Seven-ball\" which aired in the early 2000s.\nThe most common derivative game is the game of ten-ball. The game is a more stringent variant, using ten balls in which all pocketed balls must be &lt;dfn id=\"\"&gt;called&lt;/dfn&gt;. Unlike in nine-ball, the money ball cannot be pocketed on the break for an instant win. Due to its more challenging nature, and the fact that there is no publicly known technique for reliably pocketing specific object balls on the break shot, there have been suggestions among the professional circuit that ten-ball should replace nine-ball as the pro game of choice, especially since the rise of the nine-ball soft break, which is still legal in most international and non-European competition. Ten-ball has its own world championship known as the WPA World Ten-ball Championship.\nPopular culture.\nThe sport has featured in popular culture, most notably in the 1959 novel \"The Hustler\" and its 1961 film adaptation, and the 1984 sequel novel \"The Color of Money\" and subsequent film. In \"\", Nineball Island, which serves as the player's home base, is won through a game of nine-ball.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21610", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=21610", "title": "Network Marketing", "text": ""}
{"id": "21611", "revid": "47179870", "url": "https://en.wikipedia.org/wiki?curid=21611", "title": "New World Order", "text": "New World Order may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "21614", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=21614", "title": "New testament", "text": ""}
{"id": "21615", "revid": "1934512", "url": "https://en.wikipedia.org/wiki?curid=21615", "title": "Nostradamus", "text": "French seer and astrologer (1503\u20131566)\nMichel de Nostredame (December 1503 \u2013 July 1566), usually Latinised as Nostradamus, was a French astrologer, apothecary, physician, and reputed seer, who is best known for his book \"Les Proph\u00e9ties\" (published in 1555), a collection of 942 poetic quatrains allegedly predicting future events.\nNostradamus's father's family had originally been Jewish, but had converted to Catholic Christianity a generation before Nostradamus was born. He studied at the University of Avignon, but was forced to leave after just over a year when the university closed due to an outbreak of the plague. He worked as an apothecary for several years before entering the University of Montpellier, hoping to earn a doctorate, but was almost immediately expelled after his work as an apothecary (a manual trade forbidden by university statutes) was discovered. He first married in 1531, but his wife and two children died in 1534 during another plague outbreak. He worked against the plague alongside other doctors before remarrying to Anne Ponsarde, with whom he had six children. He wrote an almanac for 1550 and, as a result of its success, continued writing them for future years as he began working as an astrologer for various wealthy patrons. Catherine de' Medici became one of his foremost supporters. His \"Les Proph\u00e9ties\", published in 1555, relied heavily on historical and literary precedent, and initially received mixed reception. He suffered from severe gout toward the end of his life, which eventually developed into edema. He died on 1 or 2 July 1566. Many popular authors have retold apocryphal legends about his life.\nIn the years since the publication of his \"Les Proph\u00e9ties\", Nostradamus has attracted many supporters, who, along with some of the popular press, credit him with having accurately predicted many major world events. Academic sources reject the notion that Nostradamus had any genuine supernatural prophetic abilities and maintain that the associations made between world events and Nostradamus's quatrains are the result of (sometimes deliberate) misinterpretations or mistranslations. These academics also argue that Nostradamus's predictions are characteristically vague, meaning they could be applied to virtually anything, and are useless for determining whether their author had any real prophetic powers.\nLife.\nChildhood.\nNostradamus was born on either 14 or 21 December 1503 in Saint-R\u00e9my-de-Provence, Provence, France, where his claimed birthplace still exists, and baptized Michel. He was one of at least nine children of notary Jaume (or Jacques) de Nostredame and Reyni\u00e8re, granddaughter of Pierre de Saint-R\u00e9my who worked as a physician in Saint-R\u00e9my. Jaume's family had originally been Jewish, but his father, Cresquas, a grain and money dealer based in Avignon, had converted to Catholicism around 1459\u201360, taking the Christian name \"Pierre\" and the surname \"Nostredame\" (Our Lady), the saint on whose day his conversion was solemnised. The earliest ancestor who can be identified on the paternal side is Astruge of Carcassonne, who died about 1420. Michel's known siblings included Delphine, Jean (c. 1507\u20131577), Pierre, Hector, Louis, Bertrand, Jean II (born 1522) and Antoine (born 1523).\nLittle else is known about his childhood, although there is a persistent tradition that he was educated by his maternal great-grandfather Jean de St. R\u00e9my\u2014a tradition which is somewhat undermined by the fact that the latter disappears from the historical record after 1504 when the child was only one year old.\nStudent years.\nAt the age of 14, Nostradamus entered the University of Avignon to study for his baccalaureate. After little more than a year (when he would have studied the regular \"trivium\" of grammar, rhetoric and logic rather than the more advanced \"quadrivium\" of geometry, arithmetic, music, and astronomy/astrology), he was forced to leave Avignon when the university closed its doors during an outbreak of the plague. After leaving Avignon, Nostradamus, by his own account, traveled the countryside for eight years from 1521 researching herbal remedies. In 1529, after some years as an apothecary, he entered the University of Montpellier to study for a doctorate in medicine. He was expelled shortly afterwards by the student \"procurator\", Guillaume Rondelet, when it was discovered that he had been an apothecary, a \"manual trade\" expressly banned by the university statutes, and had been slandering doctors. The expulsion document, \"BIU Montpellier, Register S 2 folio 87\", still exists in the faculty library. Some of his publishers and correspondents would later call him \"Doctor\". After his expulsion, Nostradamus continued working, presumably still as an apothecary, and became famous for creating a \"rose pill\" that purportedly protected against the plague.\nMarriage and healing work.\nIn 1531 Nostradamus was invited by Jules-C\u00e9sar Scaliger, a leading Renaissance scholar, to come to Agen. There he married a woman of uncertain name (possibly Henriette d'Encausse), with whom he had two children. In 1534 his wife and children died, presumably from the plague. After their deaths, he continued to travel, passing through France and possibly Italy.\nOn his return in 1545, he assisted the prominent physician Louis Serre in his fight against a major plague outbreak in Marseille, and then tackled further outbreaks of disease on his own in Salon-de-Provence and in the regional capital, Aix-en-Provence. Finally, in 1547, he settled in Salon-de-Provence in the house which exists today, where he married a rich widow named Anne Ponsarde, with whom he had six children\u2014three daughters and three sons. Between 1556 and 1567 he and his wife acquired a one-thirteenth share in a huge canal project, organised by Adam de Craponne, to create the Canal de Craponne to irrigate the largely waterless Salon-de-Provence and the nearby D\u00e9sert de la Crau from the river Durance.\nOccultism.\nAfter another visit to Italy, Nostradamus began to move away from medicine and toward the \"occult\". Following popular trends, he wrote an almanac for 1550, for the first time in print Latinising his name to Nostradamus. He was so encouraged by the almanac's success that he decided to write one or more annually. Taken together, they are known to have contained at least 6,338 prophecies, as well as at least eleven annual calendars, all of them starting on 1 January and not, as is sometimes supposed, in March. It was mainly in response to the almanacs that the nobility and other prominent people from far away soon started asking for horoscopes and \"psychic\" advice from him, though he generally expected his clients to supply the birth charts on which these would be based, rather than calculating them himself as a professional astrologer would have done. When obliged to attempt this himself on the basis of the published tables of the day, he frequently made errors and failed to adjust the figures for his clients' place or time of birth.\nHe then began his project of writing a book of one thousand mainly French quatrains, which constitute the largely undated prophecies for which he is most famous today. Feeling vulnerable to opposition on religious grounds, he devised a method of obscuring his meaning by using \"Virgilianised\" syntax, word games and a mixture of other languages such as Greek, Italian, Latin, and Proven\u00e7al. For technical reasons connected with their publication in three instalments (the publisher of the third and last instalment seems to have been unwilling to start it in the middle of a \"Century,\" or book of 100 verses), the last fifty-eight quatrains of the seventh \"Century\" have not survived in any extant edition.\nThe quatrains, published in a book titled \"Les Proph\u00e9ties\" (The Prophecies), received a mixed reaction when they were published. Some people thought Nostradamus was a servant of evil, a fake, or insane, while many of the elite evidently thought otherwise. Catherine de' Medici, wife of King Henry II of France, was one of Nostradamus's greatest admirers. After reading his almanacs for 1555, which hinted at unnamed threats to the royal family, she summoned him to Paris to explain them and to draw up horoscopes for her children. At the time, he feared that he would be beheaded, but by the time of his death in 1566, Queen Catherine had made him Counselor and Physician-in-Ordinary to her son, the young King Charles IX of France.\nSome accounts of Nostradamus's life state that he was afraid of being persecuted for heresy by the Inquisition, but neither prophecy nor astrology fell in this bracket, and he would have been in danger only if he had practised magic to support them. In 1538 he came into conflict with the Church in Agen after an Inquisitor visited the area looking for anti-Catholic views. His brief imprisonment at Marignane in late 1561 was because he had violated a recent royal decree by publishing his 1562 almanac without the prior permission of a bishop.\nFinal years and death.\nBy 1566, Nostradamus' gout, which had plagued him painfully for many years and made movement very difficult, turned into edema. In late June he summoned his lawyer to draw up an extensive will bequeathing his property plus 3,444 crowns (around US$300,000 today), minus a few debts, to his wife pending her remarriage, in trust for her sons pending their twenty-fifth birthdays and her daughters pending their marriages. This was followed by a much shorter codicil. On the evening of 1 July, he is alleged to have told his secretary Jean de Chavigny, \"You will not find me alive at sunrise.\" As he predicted, the next morning he was reportedly found dead, lying on the floor next to his bed and a bench (Presage 141 [originally 152] \"for November 1567\", as posthumously edited by Chavigny to fit what happened). He was buried in the local Franciscan chapel in Salon (part of it now incorporated into the restaurant \"La Brocherie\") but re-interred during the French Revolution in the Coll\u00e9giale Saint-Laurent, where his tomb remains to this day.\nWorks.\nIn \"The Prophecies\" Nostradamus compiled his collection of major, long-term predictions. The first installment was published in 1555 and contained 353 quatrains. The third edition, with three hundred new quatrains, was reportedly printed in 1558, but now survives as only part of the omnibus edition that was published after his death in 1568. This version contains one unrhymed and 941 rhymed quatrains, grouped into nine sets of 100 and one of 42, called \"Centuries\".\nGiven printing practices at the time (which included type-setting from dictation), no two editions turned out to be identical, and it is relatively rare to find even two copies that are exactly the same. Certainly there is no warrant for assuming\u2014as would-be \"code-breakers\" are prone to do\u2014that either the spellings or the punctuation of any edition are Nostradamus's originals.\nThe \"Almanacs\", by far the most popular of his works, were published annually from 1550 until his death. He often published two or three in a year, entitled either \"Almanachs\" (detailed predictions), \"Prognostications\" or \"Presages\" (more generalised predictions).\nNostradamus was not only a diviner, but a professional healer. It is known that he wrote at least two books on medical science. One was an extremely free translation (or rather a paraphrase) of \"The Protreptic\" of Galen (\"Paraphrase de C. GALIEN, sus l'Exhortation de Menodote aux estudes des bonnes Artz, mesmement Medicine\"), and in his so-called \"Trait\u00e9 des fardemens\" (basically a medical cookbook containing, once again, materials borrowed mainly from others), he included a description of the methods he used to treat the plague, including bloodletting, none of which apparently worked. The same book also describes the preparation of cosmetics.\nA manuscript normally known as the \"Orus Apollo\" also exists in the Lyon municipal library, where upwards of 2,000 original documents relating to Nostradamus are stored under the aegis of Michel Chomarat. It is a purported translation of an ancient Greek work on Egyptian hieroglyphs based on later Latin versions, all of them unfortunately ignorant of the true meanings of the ancient Egyptian script, which was not correctly deciphered until Champollion in the 19th century.\nSince his death, only the \"Prophecies\" have continued to be popular, but in this case they have been quite extraordinarily so. Over two hundred editions of them have appeared in that time, together with over 2,000 commentaries. Their persistence in popular culture seems to be partly because their vagueness and lack of dating make it easy to quote them selectively after every major dramatic event and retrospectively claim them as \"hits\".\nOrigins of \"The Prophecies\".\nNostradamus claimed to base his published predictions on judicial astrology\u2014the astrological 'judgment', or assessment, of the 'quality' (and thus potential) of events such as births, weddings, coronations etc.\u2014but was heavily criticised by professional astrologers of the day such as Laurens Videl for incompetence and for assuming that \"comparative horoscopy\" (the comparison of future planetary configurations with those accompanying known past events) could actually predict what would happen in the future.\nResearch suggests that much of his prophetic work paraphrases collections of ancient end-of-the-world prophecies (mainly Bible-based), supplemented with references to historical events and anthologies of omen reports, and then projects those into the future in part with the aid of comparative horoscopy. Hence the many predictions involving ancient figures such as Sulla, Gaius Marius, Nero, and others, as well as his descriptions of \"battles in the clouds\" and \"frogs falling from the sky\". Astrology itself is mentioned only twice in Nostradamus's \"Preface\" and 41 times in the \"Centuries\" themselves, but more frequently in his dedicatory \"Letter to King Henry II\". In the last quatrain of his sixth \"century\" he specifically attacks astrologers.\nHis historical sources include easily identifiable passages from Livy, Suetonius' \"The Twelve Caesars\", Plutarch and other classical historians, as well as from medieval chroniclers such as Geoffrey of Villehardouin and Jean Froissart. Many of his astrological references are taken almost word for word from Richard Roussat's \"\" of 1549\u201350.\nOne of his major prophetic sources was evidently the \"Mirabilis Liber\" of 1522, which contained a range of prophecies by Pseudo-Methodius, the Tiburtine Sibyl, Joachim of Fiore, Savonarola and others (his \"Preface\" contains 24 biblical quotations, all but two in the order used by Savonarola). This book had enjoyed considerable success in the 1520s, when it went through half a dozen editions, but did not sustain its influence, perhaps owing to its mostly Latin text (mixed with ancient Greek and modern French and Proven\u00e7al), Gothic script and many difficult abbreviations. Nostradamus was one of the first to re-paraphrase these prophecies in French, which may explain why they are credited to him. Modern views of plagiarism did not apply in the 16th century; authors frequently copied and paraphrased passages without acknowledgement, especially from the classics. The latest research suggests that he may in fact have used bibliomancy for this\u2014randomly selecting a book of history or prophecy and taking his cue from whatever page it happened to fall open at.\nFurther material was gleaned from the \"De honesta disciplina\" of 1504 by Petrus Crinitus, which included extracts from Michael Psellos's \"De daemonibus\", and the \"De Mysteriis Aegyptiorum\" (\"Concerning the mysteries of Egypt\"), a book on Chaldean and Assyrian magic by Iamblichus, a 4th-century Neo-Platonist. Latin versions of both had recently been published in Lyon, and extracts from both are paraphrased (in the second case almost literally) in his first two verses, the first of which is appended to this article. While it is true that Nostradamus claimed in 1555 to have burned all of the occult works in his library, no one can say exactly what books were destroyed in this fire.\nOnly in the 17th century did people start to notice his reliance on earlier, mainly classical sources.\nNostradamus's reliance on historical precedent is reflected in the fact that he explicitly rejected the label \"prophet\" (i.e. a person having prophetic powers of his own) on several occasions:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Although, my son, I have used the word \"prophet\", I would not attribute to myself a title of such lofty sublimity.\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Not that I would attribute to myself either the name or the role of a prophet.\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[S]ome of [the prophets] predicted great and marvelous things to come: [though] for me, I in no way attribute to myself such a title here.\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Not that I am foolish enough to claim to be a prophet.\u2014\u200a\nGiven this reliance on literary sources, it is unlikely that Nostradamus used any particular methods for entering a trance state, other than contemplation, meditation and incubation. His sole description of this process is contained in 'letter 41' of his collected Latin correspondence. The popular legend that he attempted the ancient methods of flame gazing, water gazing or both simultaneously is based on a naive reading of his first two verses, which merely liken his efforts to those of the Delphic and Branchidic oracles. The first of these is reproduced at the bottom of this article and the second can be seen by visiting the relevant facsimile site (see External Links). In his dedication to King Henry II, Nostradamus describes \"emptying my soul, mind and heart of all care, worry and unease through mental calm and tranquility\", but his frequent references to the \"bronze tripod\" of the Delphic rite are usually preceded by the words \"as though\" (compare, once again, External References to the original texts).\nInterpretations.\nContent of the quatrains.\nMost of the quatrains deal with disasters, such as plagues, earthquakes, wars, floods, invasions, murders, droughts, and battles\u2014all undated and based on foreshadowings by the \"Mirabilis Liber\". Some quatrains cover these disasters in overall terms; others concern a single person or small group of people. Some cover a single town, others several towns in several countries. A major, underlying theme is an impending invasion of Europe by Muslim forces from farther east and south headed by the expected Antichrist, directly reflecting the then-current Ottoman invasions and the earlier Saracen equivalents, as well as the prior expectations of the \"Mirabilis Liber\". All of this is presented in the context of the supposedly imminent end of the world\u2014even though this is not in fact mentioned\u2014a conviction that sparked numerous collections of end-time prophecies at the time, including an unpublished collection by Christopher Columbus. Views on Nostradamus have varied widely throughout history. Academic views, such as those of Jacques Halbronn, regard Nostradamus's \"Prophecies\" as antedated forgeries written by later authors for political reasons.\nPopular claims.\nMany of Nostradamus's supporters believe his prophecies are genuine. Owing to the subjective nature of these interpretations, no two of them completely agree on what Nostradamus predicted, whether for the past or for the future. Many supporters do agree, for example, that he predicted the Great Fire of London, the French Revolution, the rise of Napoleon and of Adolf Hitler, both world wars, and the nuclear destruction of Hiroshima and Nagasaki. Popular authors frequently claim that he predicted whatever major event had just happened at the time of each of their books' publication, such as the Apollo Moon landing in 1969, the Space Shuttle \"Challenger\" disaster in 1986, the death of Diana, Princess of Wales in 1997, and the September 11 attacks on the World Trade Center in 2001. This 'movable feast' aspect appears to be characteristic of the genre.\nPossibly the first of these books to become popular in English was Henry C. Roberts' \"The Complete Prophecies of Nostradamus\" of 1947, reprinted at least seven times during the next forty years, which contained both transcriptions and translations, with brief commentaries. This was followed in 1961 (reprinted in 1982) by Edgar Leoni's \"Nostradamus and His Prophecies\". After that came Erika Cheetham's \"The Prophecies of Nostradamus\", incorporating a reprint of the posthumous 1568 edition, which was reprinted, revised and republished several times from 1973 onwards, latterly as \"The Final Prophecies of Nostradamus\". This served as the basis for the documentary \"The Man Who Saw Tomorrow\" and both did indeed mention possible generalised future attacks on New York (via nuclear weapons), though not specifically on the World Trade Center or on any particular date.\nA two-part translation of Jean-Charles de Fontbrune's \"Nostradamus: historien et proph\u00e8te\" was published in 1980, and John Hogue has published a number of books on Nostradamus from about 1987, including \"Nostradamus and the Millennium: Predictions of the Future\", \"Nostradamus: The Complete Prophecies\" (1999) and \"Nostradamus: A Life and Myth\" (2003). In 1992 one commentator who claimed to be able to contact Nostradamus under hypnosis even had him \"interpreting\" his own verse X.6 (a prediction specifically about floods in southern France around the city of N\u00eemes and people taking refuge in its \"collosse\", or Colosseum, a Roman amphitheatre now known as the \"Ar\u00e8nes\") as a prediction of an undated \"attack on the Pentagon\", despite the historical seer's clear statement in his dedicatory letter to King Henri II that his prophecies were about Europe, North Africa and part of Asia Minor.\nWith the exception of Roberts, these books and their many popular imitators were almost unanimous not merely about Nostradamus's powers of prophecy but also in inventing intriguing aspects of his purported biography: that he had been a descendant of the Israelite tribe of Issachar; he had been educated by his grandfathers, who had both been physicians to the court of Good King Ren\u00e9 of Provence; he had attended Montpellier University in 1525 to gain his first degree; after returning there in 1529, he had successfully taken his medical doctorate; he had gone on to lecture in the Medical Faculty there, until his views became too unpopular; he had supported the heliocentric view of the universe; he had travelled to the Habsburg Netherlands, where he had composed prophecies at the abbey of Orval; in the course of his travels, he had performed a variety of prodigies, including identifying future Pope, Sixtus V, who was then only a seminary monk. He is credited with having successfully cured the Plague at Aix-en-Provence and elsewhere; he had engaged in scrying, using either a magic mirror or a bowl of water; he had been joined by his secretary Chavigny at Easter 1554; having published the first installment of his \"Proph\u00e9ties\", he had been summoned by Queen Catherine de' Medici to Paris in 1556 specifically in order to discuss with her his prophecy at quatrain I.35 that her husband King Henri II would be killed in a duel; he had examined the royal children at Blois; he had bequeathed to his son a \"lost book\" of his own prophetic paintings; he had been buried standing up; and he had been found, when dug up at the French Revolution, to be wearing a medallion bearing the exact date of his disinterment. This was first recorded by Samuel Pepys as early as 1667, long before the French Revolution. Pepys records in his celebrated diary a legend that, before his death, Nostradamus made the townsfolk swear that his grave would never be disturbed; but that 60 years later his body was exhumed, whereupon a brass plaque was found on his chest correctly stating the date and time when his grave would be opened and cursing the exhumers.\nIn 2000, Li Hongzhi claimed that the 1999 prophecy at X.72 was a prediction of the Chinese Falun Gong persecution which began in July 1999, leading to an increased interest in Nostradamus among Falun Gong members.\nUsage during World War II.\nNostradamus's work was used in propaganda during World War II by both Nazi Germany and the Allies. The Reichsminister of Public Enlightenment and Propaganda, Josef Goebbels, was introduced to Nostradamus's work by his wife Magda, \"who brought to her husband's attention a claim made in a 1921 book by a German postal worker named C. L. Loog\" which allegedly predicted \"that there would be a crisis in Poland\" and that England would be defeated in 1939. \nGoebbels found \"the predictions not only intriguing but potentially useful\", and \"tried to find someone to write propaganda based on Nostradamus.\" However, \"Loog declined, so Goebbels eventually settled on a Swiss astrologer named Karl Ernst Krafft\", who had allegedly used Nostradamus to \"correctly predict an assassination attempt on Adolf Hitler in November 1939.\" Goebbels wrote in his diary on 9 January 1940 that he had \"set up an expert committee to deal with Nostradamus and Astrology\" in order to \"supply the necessary material for propaganda\", and on 16 January 1940 he wrote: \"Trash out the Nostradamus verses in cooperation with the Intelligence Service for use in France and neutral countries. Every little helps.\" Krafft \"produced propaganda booklets using spurious verses of Nostradamus which German planes airdropped over Belgium and France during the Nazi invasion of May 1940.\" The Allies responded by dropping \"Nostradamus pamphlets of their own over occupied Europe, and MGM made four short Nostradamus films to boost American morale.\"\nHowever, Goebbels seems to have seen Nostradamus simply as a black propaganda tool. He wrote that his friend, the Nazi journalist Alfred-Ingemar Berndt, had \"drawn up a plan demonstrating how we could enlist the aid of the occult in our propaganda. ... The Americans and English fall easily for that type of thing. ... Nostradamus must once again submit to being quoted.\" One passage that Goebbels made use of \"was found to read as follows: And war will break out in Europe on so vast and fearful a scale as never before. Death and destruction, conflict and bloodshed, will descend on princes and people alike, and press hard on the people of the middle kingdom until in the end the cities of Paris and London and those that be far to the East will be engulfed in a sea of flame. But that people which stands under the sign of the crooked cross, that people will triumph, to live in peace, prosperity and happiness, a proud dominion for a thousand years.\"\nHowever, \"Nostradamus did not write a word of all this. Goebbels himself was the author.\" According to Nazi diplomat and author Hans Otto Meissner, Goebbels also allegedly had \"a few folios from the mid-sixteenth century carefully copied and the operative sentences, in Latin text and Gothic script, laboriously inscribed on genuine parchment\" and falsified \"futher passages ... such as 'giant fish which swim around in the sea with sailors in their bellies' or 'birds of iron'. When the forgeries had accomplished their objective, the volumes in question disappeared from the libraries, so that a more thorough examination was no longer possible.\"\nScholarly rebuttal.\nFrom the 1980s onward, an academic reaction set in, especially in France. The publication in 1983 of Nostradamus' private correspondence and, during succeeding years, of the original editions of 1555 and 1557 discovered by Chomarat and Benazra, together with the unearthing of much original archival material, revealed that much that was claimed about Nostradamus did not fit the documented facts. The academics revealed that not one of the claims just listed was backed up by any known contemporary documentary evidence. Most of them had evidently been based on unsourced rumours relayed as fact by much later commentators, such as Jaubert (1656), Guynaud (1693) and Bareste (1840); on modern misunderstandings of the 16th-century French texts; or on pure invention. Even the often-advanced suggestion that quatrain I.35 had successfully prophesied King Henry II's death did not actually appear in print for the first time until 1614, 55 years after the event.\nSkeptics such as James Randi suggest that his reputation as a prophet is largely manufactured by modern-day supporters who fit his words to events that have either already occurred or are so imminent as to be inevitable, a process sometimes known as \"retroactive clairvoyance\" (postdiction). No Nostradamus quatrain is known to have been interpreted as predicting a specific event before it occurred, other than in vague, general terms that could equally apply to any number of other events. This even applies to quatrains that contain specific dates, such as III.77, which predicts \"in 1727, in October, the king of Persia [shall be] captured by those of Egypt\"\u2014a prophecy that has, as ever, been interpreted retrospectively in the light of later events, in this case as though it presaged the known peace treaty between the Ottoman Empire and Persia of that year; Egypt was also an important Ottoman territory at this time. Similarly, Nostradamus's notorious \"1999\" prophecy at X.72 (see Nostradamus in popular culture) describes no event that commentators have succeeded in identifying either before or since, other than by twisting the words to fit whichever of the many contradictory happenings they claim as \"hits\". Moreover, no quatrain suggests, as is often claimed by books and films on the alleged Mayan Prophecy, that the world would end in December 2012. In his preface to the \"Prophecies\", Nostradamus himself stated that his prophecies extend \"from now to the year 3797\"\u2014an extraordinary date which, given that the preface was written in 1555, may have more than a little to do with the fact that 2242 (3797\u20131555) had recently been proposed by his major astrological source Richard Roussat as a possible date for the end of the world.\nAdditionally, scholars have pointed out that almost all English translations of Nostradamus's quatrains are of extremely poor quality: they seem to display little or no knowledge of 16th-century French, are tendentious, and are sometimes intentionally altered in order to make them fit whatever events to which the translator believed they were supposed to refer (or vice versa). None of them were based on the original editions of \"Les Proph\u00e9ties\": Roberts based his writings on that of Garenci\u00e8res's 1672 translation, while Cheetham and Hogue used the posthumous edition published in 1568. Even Leoni accepted that he had never seen the earliest editions of Nostradamus's work, which he claimed were \"neither complete nor available\", and indicated elsewhere in his book that much of the biographical material he had included about Nostradamus was unsourced.\nNone of this research and criticism was originally known to most of the English-language commentators, by dint of the dates when they were writing and, to some extent, the language in which it was written. Hogue was in a position to take advantage of it, but it was only in 2003 that he accepted that some of his earlier biographical material had in fact been apocryphal. Meanwhile, some of the more recent sources listed (Lemesurier, Gruber, Wilson) have been particularly scathing about later attempts by some lesser-known authors and Internet enthusiasts to extract alleged hidden meanings from the texts, whether with the aid of anagrams, numerical codes, graphs or otherwise.\nIn popular culture.\nThe prophecies retold and expanded by Nostradamus figured largely in popular culture in the 20th and 21st centuries. As well as being the subject of hundreds of books (both fiction and nonfiction), Nostradamus' life has been depicted in several films and videos, and his life and writings continue to be a subject of media interest.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21619", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=21619", "title": "List of multi-level marketing companies", "text": "List of companies which use multi-level marketing\nThis is a list of companies which use multi-level marketing (also known as network marketing, direct selling, referral marketing, and pyramid selling) for most of their sales.\nActive.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDefunct.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21620", "revid": "40905105", "url": "https://en.wikipedia.org/wiki?curid=21620", "title": "Noah Webster", "text": "American lexicographer and author (1758\u20131843)\nNoah Webster (October 16, 1758 \u2013 May 28, 1843) was an American lexicographer, textbook pioneer, English-language spelling reformer, political writer, editor, and author. He has been called the \"Father of American Scholarship and Education\". He authored a large number of \"Blue-Backed Speller\" books which were used to teach American children how to spell and read. He is also the author for the modern Merriam-Webster dictionary that was first published in 1828 as \"An American Dictionary of the English Language\".\nBorn in West Hartford, Connecticut, Webster graduated from Yale College in 1778. He passed the bar examination after studying law under Oliver Ellsworth and others but was unable to find work as a lawyer. He found some financial success by opening a private school and writing a series of educational books, including the \"Blue-Backed Speller\". A strong supporter of the American Revolution and the ratification of the United States Constitution, Webster later criticized American society as being in need of an intellectual foundation. He believed American nationalism had distinctive qualities that differed from European values.\nIn 1793, Alexander Hamilton recruited Webster to move to New York City and become an editor for a Federalist Party newspaper. He became a prolific author, publishing newspaper articles, political essays, and textbooks. He returned to Connecticut in 1798 and served in the Connecticut House of Representatives. Webster founded the Connecticut Society for the Abolition of Slavery in 1791 but later became somewhat disillusioned with the abolitionist movement.\nIn 1806, Webster published his first dictionary, \"\". The following year, he started working on an expanded and comprehensive dictionary, finally publishing it in 1828. He was influential in popularizing certain American spellings. He played a role in advocating for copyright reform, contributing to the Copyright Act of 1831, the first major statutory revision of U.S. copyright law. While working on a second volume of his dictionary, Webster died in 1843, and the rights to the dictionary were acquired by George and Charles Merriam.\nEarly life and education.\nWebster was born on October 16, 1758, in the Noah Webster House in western Hartford, Connecticut Colony, during the Colonial Era. The area of his birth later became West Hartford, Connecticut. He was born into an established family, and the Noah Webster House continues to highlight his life and serves as the headquarters of the West Hartford Historical Society. His father, Noah Webster Sr. (1722\u20131813), was a descendant of Connecticut Governor John Webster; his mother Mercy (Steele) Webster (1727\u20131794) was a descendant of Governor William Bradford of Plymouth Colony. His father was primarily a farmer, though he was also a deacon of the local Congregational church, captain of the town's militia, and a founder of a local book society, a precursor to the public library. After American independence, he was appointed a justice of the peace.\nWebster's father never attended college, but placed a strong emphasis on education. Webster's mother spent long hours teaching her children spelling, mathematics, and music. At age six, Webster began attending a dilapidated one-room primary school built by West Hartford's Ecclesiastical Society. Years later, he described the teachers as the \"dregs of humanity\" and complained that the instruction was mainly in religion. Webster's experiences there motivated him to improve the educational experience of future generations.\nAt age fourteen, he received tutoring from his church pastor in Latin and Greek to prepare him for entering Yale College. Webster enrolled at Yale just before his 16th birthday, and during his senior year studied with Ezra Stiles, Yale's president. He was also a member of Brothers in Unity, a secret society at Yale. His four years at Yale overlapped the American Revolutionary War and, because of food shortages and the possibility of a British invasion, many classes were held in other towns. Webster served in the Connecticut Militia. His father mortgaged the farm to send Webster to Yale, but after graduating, Webster had little contact with his family.\nCareer.\nWebster lacked clear career plans after graduating from Yale in 1779, later writing that a liberal arts education \"disqualifies a man for business\". He taught school briefly in Glastonbury, but due to harsh working conditions and low pay, he resigned to study law. While studying law under future U.S. Supreme Court Chief Justice Oliver Ellsworth, Webster also taught full-time in Hartford\u2014a grueling experience that ultimately proved unsustainable. He quit his legal studies for a year and lapsed into a depression; he then found another practicing attorney to tutor him, and completed his studies, and passed the bar examination in 1781.\nWith the American Revolutionary War still ongoing, Webster was unable to find work as a lawyer. He received a master's degree from Yale by delivering an oral dissertation to the graduating class. Later that year, he opened a small private school in western Connecticut, which initially succeeded but was eventually closed, possibly due to a failed romance. Turning to literary work as a way to overcome his losses and channel his ambitions, he began writing a series of well-received articles for a prominent New England newspaper justifying and praising the American Revolution and arguing that the separation from Britain would be a permanent state of affairs. He then founded a private school catering to wealthy parents in Goshen, New York and, by 1785, he had written his speller, a grammar book and a reader for elementary schools. Proceeds from continuing sales of the popular blue-backed speller enabled Webster to spend many years working on his famous dictionary.\nWebster was by nature a revolutionary, seeking American independence from the cultural thralldom to Europe. He aimed to create a utopian America, free from luxury and ostentation, and a champion of freedom. By 1781, Webster had an expansive view of the new nation. American nationalism was superior to European nationalism due to the perceived superiority of American values.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;America sees the absurdities\u2014she observes the kingdoms of Europe, disturbed by wrangling sectaries, or their commerce, population, and improvements of every kind cramped and retarded, because the human mind like the body is fettered 'and bound fast by the chords of policy and superstition': She laughs at their folly and shuns their errors: She founds her empire upon the idea of universal toleration: She admits all religions into her bosom; She secures the sacred rights of every individual; and (astonishing absurdity to Europeans!) she sees a thousand discordant opinions live in the strictest harmony ... it will finally raise her to a pitch of greatness and lustre, before which the glory of ancient Greece and Rome shall dwindle to a point, and the splendor of modern Empires fade into obscurity.\nWebster dedicated his \"Speller\" and \"Dictionary\" to providing an intellectual foundation for American nationalism. From 1787 to 1789, Webster was an outspoken supporter of the new Constitution. In October 1787, he wrote a pamphlet entitled \"An Examination into the Leading Principles of the Federal Constitution Proposed by the Late Convention Held at Philadelphia\", published under the pen name \"A Citizen of America\". The pamphlet was influential, particularly outside New York State.\nIn political theory, Webster emphasized widespread property ownership, a key element of Federalism. He was also one of the few early American thinkers who applied the theories of the French theorist Jean-Jacques Rousseau in America. He relied heavily on Rousseau's \"Social Contract\" while writing \"Sketches of American Policy\", one of the earliest, widely-published arguments for a strong central government in America. He also wrote two \"fan fiction\" sequels to Rousseau's \"Emile, or On Education\" (1762) and included them in his Reader for schoolchildren. Webster's Reader also contains an idealized word portrait of Sophie, the girl in Rousseau's \"Emile,\" and Webster used Rousseau's theories in \"Emile\" to argue for the civic necessity of broad-based female education.\nFederalist editor.\nNoah Webster married Rebecca Greenleaf (1766\u20131847) on October 26, 1789, in New Haven, Connecticut. They had eight children:\nWebster joined the elite in Hartford, Connecticut, but did not have substantial financial resources. In 1793, Alexander Hamilton lent him $1,500 (~$ in 2024) to move to New York City to edit the leading Federalist Party newspaper. In December, he founded New York's first daily newspaper \"American Minerva\", later renamed the \"Commercial Advertiser\", which he edited for four years, writing the equivalent of 20 volumes of articles and editorials. He also published the semi-weekly publication \"The Herald, A Gazette for the country\", later known as the \"New-York Spectator\".\nAs a Federalist spokesman, Webster defended the administrations of George Washington and John Adams, especially their policy of neutrality between Britain and France, and he especially criticized the excesses of the French Revolution and its Reign of Terror. When French ambassador Citizen Gen\u00eat set up a network of pro-Jacobin \"Democratic-Republican Societies\" that entered American politics and attacked President Washington, he condemned them. He later defended Jay's Treaty between the United States and Britain. As a result, he was repeatedly denounced by the Jeffersonian Republicans as \"a pusillanimous, half-begotten, self-dubbed patriot\", \"an incurable lunatic\", and \"a deceitful newsmonger ... Pedagogue and Quack.\"\nFor decades, he was one of the most prolific authors in the new nation, publishing textbooks, political essays, a report on infectious diseases, and newspaper articles for his Federalist party. \nIn 1799 Webster wrote two massive volumes on the causes of \"epidemics and pestilential diseases\". Medical historians have considered him as \"America's first epidemiologist\". He was so prolific that a modern bibliography of his works spans 655 pages. He moved back to New Haven in 1798 and was elected as a Federalist to the Connecticut House of Representatives in 1800 and 1802\u20131807.\nWebster was elected a fellow of the American Academy of Arts and Sciences in 1799. He moved to Amherst, Massachusetts in 1812, where he helped to found Amherst College. In 1822, his family moved back to New Haven, where Webster was awarded an honorary degree from Yale the following year. In 1827, Webster was elected to the American Philosophical Society.\nSchool Books.\nAs a teacher, Webster grew dissatisfied with American elementary schools. They could be overcrowded, with up to seventy children of all ages crammed into one-room schoolhouses. They suffered from poorly paid staff, lacked desks, and used unsatisfactory textbooks imported from England. Webster thought that Americans should learn from American books, so he began writing the three-volume compendium \"A Grammatical Institute of the English Language\". The work consisted of a speller (published in 1783), a grammar (published in 1784), and a reader (published in 1785). His aim was to provide a uniquely American approach to education. His most important improvement, he claimed, was to rescue \"our native tongue\" from \"the clamour of pedantry\" that surrounded English grammar and pronunciation. He complained that the English language had been corrupted by the British aristocracy, which set its own standard for proper spelling and pronunciation. Webster rejected the notion that the study of Greek and Latin must precede the study of English grammar. The appropriate standard for the American language, argued Webster, was \"the same republican principles as American civil and ecclesiastical constitutions.\" This meant that the people at large must control the language; popular sovereignty in government must be accompanied by popular usage of language.\nThe \"Speller\" was designed to be easily taught to students, progressing according to age. From his own experiences as a teacher, Webster thought that the \"Speller\" should be simple and give an orderly presentation of words and the rules of spelling and pronunciation. He believed that students learned most readily when he broke a complex problem into its component parts and had each pupil master one part before moving to the next.\nEllis argues that Webster anticipated some of the insights currently associated with Jean Piaget's theory of cognitive development. Webster said that children pass through distinctive learning phases in which they master increasingly complex or abstract tasks. Therefore, teachers must not try to teach a three-year-old how to read; they could not do it until age five. He organized his speller accordingly, beginning with the alphabet and moving systematically through the different sounds of vowels and consonants, then syllables, then simple words, then more complex words, then sentences.\nThe speller was originally titled \"The First Part of the Grammatical Institute of the English Language\". Over the course of 385 editions in his lifetime, the title was changed in 1786 to \"The American Spelling Book\", and again in 1829 to \"The Elementary Spelling Book\". Most people called it the \"Blue-Backed Speller\" because of its blue cover and, for the next one hundred years, Webster's book taught children how to read, spell, and pronounce words. It was the most popular American book of its time; by 1837, it had sold 15 million copies, and some 60 million by 1890\u2014reaching the majority of young students in the nation's first century. Its royalty of a half-cent per copy was enough to sustain Webster in his other endeavors. It also helped create the popular contests known as spelling bees.\nAs time went on, Webster changed the spellings in the book to more phonetic ones. Most of them already existed as alternative spellings. He chose spellings such as \"defense\", \"color\", and \"traveler\", and changed the \"re\" to \"er\" in words such as \"center\". He also changed \"tongue\" to the older spelling \"tung\", but this did not catch on.\nPart three of his \"Grammatical Institute\" (1785) was a reader designed to uplift the mind and \"diffuse the principles of virtue and patriotism.\"\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"In the choice of pieces\", he explained, \"I have not been inattentive to the political interests of America. Several of those masterly addresses of Congress, written at the commencement of the late Revolution, contain such noble, just, and independent sentiments of liberty and patriotism, that I cannot help wishing to transfuse them into the breasts of the rising generation.\"\nStudents received the usual quota of Plutarch, Shakespeare, Swift, and Joseph Addison, as well as such Americans as Joel Barlow's \"Vision of Columbus\", Timothy Dwight's \"Conquest of Canaan\", and John Trumbull's poem \"M'Fingal.\" The Reader included two, original, fan-fiction sequels to \"Emile or On Education\" by \"Jean-Jacques Rousseau\", a portrait of Rousseau's character, Sophie, and a tribute to Juliana Smith who had recently rejected Webster's romantic advances. Webster also included excerpts from Tom Paine's \"The Crisis\" and an essay by Thomas Day calling for the abolition of slavery in accord with the Declaration of Independence.\nWebster's Speller was relatively secular. It ended with two pages of important dates in American history, beginning with Columbus's discovery of America in 1492 and ending with the battle of Yorktown in 1781. \"Let sacred things be appropriated for sacred purposes,\" Webster wrote. As Ellis explains, \"Webster began to construct a secular catechism to the nation-state. Here was the first appearance of 'civics' in American schoolbooks. In this sense, Webster's speller became what was to be the secular successor to \"The New England Primer\" with its explicitly biblical injunctions.\"\nLater in life, Webster became more religious and incorporated religious themes into his work. However, after 1840, Webster's books lost market share to the \"McGuffey Eclectic Readers\" of William Holmes McGuffey, which sold over 120 million copies.\nVincent P. Bynack (1984) examines Webster in relation to his commitment to the idea of a unified American national culture that would stave off the decline of republican virtues and solidarity. Webster acquired his perspective on language from such theorists as Maupertuis, Michaelis, and Herder. There he found the belief that a nation's linguistic forms and the thoughts correlated with them shaped individuals' behavior. Thus, the etymological clarification and reform of American English promised to improve citizens' manners and thereby preserve republican purity and social stability. This presupposition animated Webster's \"Speller\" and \"Grammar\".\nDictionary.\nPublication.\nIn 1806, Webster published his first dictionary, . By 1807, he began work on a more extensive dictionary, \"An American Dictionary of the English Language\", which took twenty-six years to complete. To evaluate the etymology of words, Webster learned twenty-eight languages, including Old English, Gothic, German, Greek, Latin, Italian, Spanish, French, Dutch, Welsh, Russian, Hebrew, Aramaic, Persian, Arabic, and Sanskrit. His goal was to standardize American English, which varied widely across the country. They also spelled, pronounced, and used English words differently. However, his level of understanding for these languages was challenged with Charlton Laird claiming that Webster struggled with \"elements of Anglo-Saxon grammar\" and that he did \"not recognize common words\". Thomas Pyles also went on to write that Webster showed \"an ignorance of German which would disgrace a freshman\".\nWebster completed his dictionary during his year abroad in January 1825 in a boarding house in Cambridge, England. His book contained seventy thousand words, of which twelve thousand had never appeared in a published dictionary before. As a spelling reformer, Webster preferred spellings that matched pronunciation better. In \"A Companion to the American Revolution\" (2008), John Algeo notes: \"It is often assumed that characteristically American spellings were invented by Noah Webster. He was very influential in popularizing certain spellings in America, but he did not originate them. Rather ... he chose already existing options such as \"center, color\" and \"check\" on such grounds as simplicity, analogy or etymology.\" He also added American words, like \"skunk\", that did not appear in British dictionaries. At the age of seventy, Webster published his dictionary in 1828, registering the copyright on April 14.\nDespite its significant place in the history of American English, Webster's first dictionary sold only 2,500 copies. He was forced to mortgage his home to develop a second edition, and for the rest of his life, he had debt problems.\nIn 1840, the second edition was published in two volumes. On May 28, 1843, a few days after he had completed making more specific definitions to the second edition, and with much of his efforts with the dictionary still unrecognized, Noah Webster died. The rights to his dictionary were acquired by Charles and George Merriam in 1843 from Webster's estate and all contemporary Merriam-Webster dictionaries trace their lineage to that of Webster, although many others have adopted his name, attempting to share in the popularity. He is buried in New Haven's Grove Street Cemetery.\nInfluence.\nLepore (2008) illustrates Webster's paradoxical views on language and politics and explains why his work was initially poorly received. Culturally conservative Federalists denounced the work as radical\u2014too inclusive in its lexicon and even bordering on vulgar. Meanwhile, Webster's old foes the Republicans attacked the man, labeling him mad for such an undertaking.\nScholars have long seen Webster's 1844 dictionary to be an important resource for reading poet Emily Dickinson's life and work; she once commented that the \"Lexicon\" was her \"only companion\" for years. One biographer said, \"The dictionary was no mere reference book to her; she read it as a priest his breviary\u2014over and over, page by page, with utter absorption.\"\nNathan Austin has explored the intersection of lexicographical and poetic practices in American literature, and attempts to map out a \"lexical poetics\" using Webster's definitions as his base. Poets mined his dictionaries, often drawing upon the lexicography in order to express word play. Austin explicates key definitions from both the \"Compendious\" (1806) and \"American\" (1828) dictionaries, and finds a range of themes such as the politics of \"American\" versus \"British\" English and issues of national identity and independent culture. Austin argues that Webster's dictionaries helped redefine Americanism in an era of highly flexible cultural identity. Webster himself saw the dictionaries as a nationalizing device to separate America from Britain, calling his project a \"federal language\", with competing forces towards regularity on the one hand and innovation on the other. Austin suggests that the contradictions of Webster's lexicography were part of a larger play between liberty and order within American intellectual discourse, with some pulled toward Europe and the past, and others pulled toward America and the new future.\nIn 1850 Blackie and Son in Glasgow published the first general dictionary of English that relied heavily upon pictorial illustrations integrated with the text. Its \"The Imperial Dictionary, English, Technological, and Scientific, Adapted to the Present State of Literature, Science, and Art; On the Basis of Webster's English Dictionary\" used Webster's for most of their text, adding some additional technical words that went with illustrations of machinery.\nOn a 2024 article on Webster's legacy and role in the American Revolution, journalist Kelly J. Byrne from Fox News stated that he was \"a patriot armed with the pen\", who \"fought for American independence with words, not swords\" by \"defining the language of the new nation\". Quoting Merriam-Webster's editor-in chief Peter Sokolowski and biographies by Harlow Giles Unger and Joshua Kendall, Byrne highlighted Webster's belief that \"the new political America also needed a new cultural America\", which led to his role in establishing the distinct identity of American English, which resonates with Webster's idea of \"America as a concept and as a country distinct from everywhere else\". As a testament to his cultural and linguistic role in the American Revolution, Byrne mentioned that Joshua Kendall named his biography of Noah Webster \"The Forgotten Founding Father\".\nViews.\nReligion.\nIn his early years, Webster was a freethinker, but in 1808 he became a convert to Calvinistic orthodoxy, and thereafter became a devout Congregationalist who preached the need to Christianize the nation. Webster viewed language as a means to control disruptive thoughts. His \"American Dictionary\" emphasized the virtues of social control over human passions and individualism, submission to authority, and fear of God; they were necessary for the maintenance of the American social order. As he grew older, Webster's attitudes changed from those of an optimistic revolutionary in the 1780s to those of a pessimistic critic of man and society by the 1820s.\nHis 1828 \"American Dictionary\" contained the greatest number of Biblical definitions given in any reference volume. Webster said of education,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Education is useless without the Bible. The Bible was America's basic text book in all fields. God's Word, contained in the Bible, has furnished all necessary rules to direct our conduct.\nWebster released his own edition of the Bible in 1833, called the Common Version. He used the King James Version (KJV) as a base and consulted the Hebrew and Greek along with various other versions and commentaries. Webster molded the KJV to correct grammar, replaced words that were no longer used, and removed words and phrases that could be seen as offensive.\nIn 1834, he published \"Value of the Bible and Excellence of the Christian Religion\", an apologetic book in defense of the Bible and Christianity itself.\nSlavery.\nInitially supportive of the abolitionist movement, Webster helped found the Connecticut Society for the Abolition of Slavery in 1791. However, by the 1830s he began to disagree with the movement's arguments that Americans who did not actively oppose the institution of slavery were complicit in the system. In 1832, Webster wrote and published a history textbook titled \"History of the United States\", which omitted any reference to the role of slavery in American history and included racist characterizations of African Americans. The textbook also \"spoke of whiteness as the supreme race and declared Anglo Saxons as the only true Americans.\" In 1837, Webster criticized his daughter Eliza for her support for the abolitionist movement, writing that \"slavery is a great sin and a general calamity\u2014but it is not \"our\" sin, though it may prove to be a terrible calamity to us in the North. But we cannot legally interfere with the South on this subject. To come north to preach and thus disturb \"our\" peace, when we can legally do nothing to effect this object, is, in my view, highly criminal and the preachers of abolitionism deserve the penitentiary.\"\nCopyright.\nWebster advocated for the expansion of copyright protections. The Copyright Act of 1831 was the first major statutory revision of U.S. copyright law, a result of intensive lobbying by Noah Webster and his agents in Congress. Webster played a critical role lobbying individual states throughout the country during the 1780s to pass the first American copyright laws, which were expected to have distinct nationalistic implications for the young nation.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21623", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=21623", "title": "Nobel Prize in physiology or medicine", "text": ""}
{"id": "21625", "revid": "279219", "url": "https://en.wikipedia.org/wiki?curid=21625", "title": "Neil D. Levin", "text": ""}
{"id": "21626", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=21626", "title": "Near-Earth object", "text": "Small Solar System body with an orbit that can bring it close to Earth\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nA near-Earth object (NEO) is any small Solar System body orbiting the Sun whose closest approach to the Sun (perihelion) is less than 1.3 times the Earth\u2013Sun distance (astronomical unit, AU). This definition applies to the object's orbit around the Sun, rather than its current position, thus an object with such an orbit is considered an NEO even at times when it is far from making a close approach of Earth. If an NEO's orbit crosses the Earth's orbit, and the object is larger than across, it is considered a potentially hazardous object (PHO). Most known PHOs and NEOs are asteroids, but about a third of a percent are comets.\nThere are over 37,000 known near-Earth asteroids (NEAs) and over 120 known short-period near-Earth comets (NECs). A number of solar-orbiting meteoroids were large enough to be tracked in space before striking Earth. It is now widely accepted that collisions in the past have had a significant role in shaping the geological and biological history of Earth. Asteroids as small as in diameter can cause significant damage to the local environment and human populations. Larger asteroids penetrate the atmosphere to the surface of the Earth, producing craters if they impact a continent or tsunamis if they impact the sea. Interest in NEOs has increased since the 1980s because of greater awareness of this risk. Asteroid impact avoidance by deflection is possible in principle, and methods of mitigation are being researched.\nTwo scales, the simple Torino scale and the more complex Palermo scale, rate the risk presented by an identified NEO based on the probability of it impacting the Earth and on how severe the consequences of such an impact would be. Some NEOs have had temporarily positive Torino or Palermo scale ratings after their discovery. Since 1998, the United States, the European Union, and other nations have been scanning the sky for NEOs in an effort called Spaceguard. The initial US Congress mandate to NASA to catalog at least 90% of NEOs that are at least in diameter, sufficient to cause a global catastrophe, was met by 2011. In later years, the survey effort was expanded to include smaller objects which have the potential for large-scale, though not global, damage.\nNEOs have low surface gravity, and many have Earth-like orbits that make them easy targets for spacecraft. As of \u00a02024[ [update]], five near-Earth comets and six near-Earth asteroids, one of them with a moon, have been visited by spacecraft. Samples of three have been returned to Earth, and one successful deflection test was conducted. Similar missions are in progress. Preliminary plans for commercial asteroid mining have been drafted by private startup companies, but few of these plans were pursued.\nDefinitions.\nNear-Earth objects (NEOs) are formally defined by the International Astronomical Union (IAU) as all small Solar System bodies with orbits around the Sun that are at least partially closer than 1.3 astronomical units (AU; Sun\u2013Earth distance) from the Sun. This definition excludes larger bodies such as planets, like Venus; natural satellites which orbit bodies other than the Sun, like Earth's Moon; and artificial bodies orbiting the Sun. A small Solar System body can be an asteroid or a comet, thus an NEO is either a near-Earth asteroid (NEA) or a near-Earth comet (NEC). The organisations cataloging NEOs further limit their definition of NEO to objects with an orbital period under 200 years, a restriction that applies to comets in particular, but this approach is not universal. Some authors further restrict the definition to orbits that are at least partly further than 0.983 AU away from the Sun. NEOs are thus not necessarily currently near the Earth, but they can potentially approach the Earth relatively closely. Many NEOs have complex orbits due to constant perturbation by the Earth's gravity, and some of them can temporarily change from an orbit around the Sun to one around the Earth, but the term is applied flexibly for these objects, too.\nThe orbits of some NEOs intersect that of the Earth, so they pose a collision danger. These are considered potentially hazardous objects (PHOs) if their estimated diameter is above 140 meters. PHOs include potentially hazardous asteroids (PHAs). PHAs are defined based on two parameters relating to respectively their potential to approach the Earth dangerously closely and the estimated consequences that an impact would have if it occurs. Objects with both an Earth minimum orbit intersection distance (MOID) of 0.05\u00a0AU or less and an absolute magnitude of 22.0 or brighter (a rough indicator of large size) are considered PHAs. Objects that either cannot approach closer to the Earth than , or which are fainter than H = 22.0 (about in diameter with assumed albedo of 14%), are not considered PHAs.\nHistory of human awareness of NEOs.\nThe first near-Earth objects to be observed by humans were comets. Their extraterrestrial nature was recognised and confirmed only after Tycho Brahe tried to measure the distance of a comet through its parallax in 1577 and the lower limit he obtained was well above the Earth diameter; the periodicity of some comets was first recognised in 1705, when Edmond Halley published his orbit calculations for the returning object now known as Halley's Comet. The 1758\u20131759 return of Halley's Comet was the first comet appearance predicted.\nThe extraterrestrial origin of meteors (shooting stars) was only recognised on the basis of the analysis of the 1833 Leonid meteor shower by astronomer Denison Olmsted. The 33-year period of the Leonids led astronomers to suspect that they originate from a comet that would today be classified as an NEO, which was confirmed in 1867, when astronomers found that the newly discovered comet 55P/Tempel\u2013Tuttle has the same orbit as the Leonids.\nThe first near-Earth asteroid to be discovered was 433 Eros in 1898. The asteroid was subject to several extensive observation campaigns, primarily because measurements of its orbit enabled a precise determination of the then imperfectly known distance of the Earth from the Sun.\nEncounters with Earth.\nIf a near-Earth object is near the part of its orbit closest to Earth's at the same time Earth is at the part of its orbit closest to the near-Earth object's orbit, the object has a close approach, or, if the orbits intersect, could even impact the Earth or its atmosphere.\nClose approaches.\nAs of \u00a02019[ [update]], only 23 comets have been observed to pass within of Earth, including 10 which are or have been short-period comets. Two of these near-Earth comets, Halley's Comet and 73P/Schwassmann\u2013Wachmann, have been observed during multiple close approaches. The closest observed approach was 0.0151\u00a0AU (5.88\u00a0LD) for Lexell's Comet on July 1, 1770. After an orbit change due to a close approach of Jupiter in 1779, this object is no longer an NEC. The closest approach ever observed for a current short-period NEC is 0.0229\u00a0AU (8.92\u00a0LD) for Comet Tempel\u2013Tuttle in 1366. Orbital calculations show that P/1999 J6 (SOHO), a faint sungrazing comet and confirmed short-period NEC observed only during its close approaches to the Sun, passed Earth undetected at a distance of 0.0120\u00a0AU (4.65\u00a0LD) on June 12, 1999.\nIn 1937, asteroid 69230 Hermes was discovered when it passed the Earth at twice the distance of the Moon. On June 14, 1968, the diameter asteroid 1566 Icarus passed Earth at a distance of , or 16.5 times the distance of the Moon. During this approach, Icarus became the first minor planet to be observed using radar. This was the first close approach predicted years in advance, since Icarus had been discovered in 1949. The first near-Earth asteroid known to have passed Earth closer than the distance of the Moon was 1991 BA, a body which passed at a distance of . As NEA surveys were enhanced, at least one such object was observed each year from 2001, at least a dozen from 2005, and over a hundred from 2020.\nAs astronomers became able to discover ever smaller and fainter and ever more numerous near-Earth objects, they began to routinely observe and catalogue close approaches. As of \u00a02024[ [update]], the closest approach without atmospheric or ground impact ever detected was an encounter with asteroid on November 14, 2020, with a minimum distance of about from the Earth's centre, or about above its surface. On November 8, 2011, asteroid , relatively large at about in diameter, passed within (0.845 lunar distances) of Earth. On February 15, 2013, the asteroid 367943 Duende (2012 DA14) passed approximately above the surface of Earth, closer than satellites in geosynchronous orbit. The asteroid was not visible to the unaided eye. This was the first sub-lunar close passage of an object discovered during a previous passage, and was thus the first to be predicted well in advance. On October 8, 2025, asteroid 2025 TN2, approximately 87 feet (\u224827 m) in diameter, passed safely by Earth at a distance of 1.34 million km (\u22480.00895 AU). On the same day, three additional small asteroids \u2014 2025 SJ29, 2025 TF1, and 2020 QU5, measuring about 55 ft, 65 ft, and 81 ft respectively \u2014 also made close approaches, all without any risk of impact.\nEarth-grazers.\nSome small asteroids that enter the upper atmosphere of Earth at a shallow angle remain intact and leave the atmosphere again, continuing on a solar orbit. During the passage through the atmosphere, due to the burning of its surface, such an object can be observed as an Earth-grazing fireball.\nOn August 10, 1972, a meteor that became known as the 1972 Great Daylight Fireball was witnessed by many people and even filmed as it moved north over the Rocky Mountains from the U.S. Southwest to Canada. It passed within of the Earth's surface.\nOn October 13, 1990, Earth-grazing meteoroid EN131090 was observed above Czechoslovakia and Poland, moving at along a trajectory from south to north. The closest approach to the Earth was above the surface. It was captured by two all-sky cameras of the European Fireball Network, which for the first time enabled geometric calculations of the orbit of such a body.\nImpacts.\nWhen a near-Earth object impacts Earth, objects up to a few tens of metres across ordinarily explode in the upper atmosphere (most of them harmlessly), with most or all of the solids vaporized and only small amounts of meteorites arriving to the Earth surface. Larger objects, by contrast, hit the water surface, forming tsunami waves, or the solid surface, forming impact craters.\nThe frequency of impacts of objects of various sizes is estimated on the basis of orbit simulations of NEO populations, the frequency of impact craters on the Earth and the Moon, and the frequency of close encounters. The study of impact craters indicates that impact frequency has been more or less steady for the past 3.5\u00a0billion years, which requires a steady replenishment of the NEO population from the asteroid main belt. One impact model based on widely accepted NEO population models estimates the average time between the impact of two stony asteroids with a diameter of at least at about one year; for asteroids across (which impacts with as much energy as the atomic bomb dropped on Hiroshima, approximately 15 kilotonnes of TNT) at five years, for asteroids across (an impact energy of 10 megatons, comparable to the Tunguska event in 1908) at 1,300 years, for asteroids across at 440 thousand years, and for asteroids across at 18 million years. Some other models estimate similar impact frequencies, while others calculate higher frequencies. For Tunguska-sized (10 megaton) impacts, the estimates range from one event every 2,000\u20133,000 years to one event every 300 years.\nThe second-largest observed event after the Tunguska meteor was a 1.1 megaton air blast in 1963 near the Prince Edward Islands between South Africa and Antarctica. However, this event was detected only by infrasound sensors, which led to speculation that this may have been a nuclear test. The third-largest, but by far best-observed impact, was the Chelyabinsk meteor of 15 February 2013. A previously unknown asteroid exploded above this Russian city with an equivalent blast yield of 400\u2013500 kilotons. The calculated orbit of the pre-impact asteroid is similar to that of Apollo asteroid , making the latter the meteor's possible parent body.\nOn October 7, 2008, 20 hours after it was first observed and 11 hours after its trajectory has been calculated and announced, asteroid blew up above the Nubian Desert in Sudan. It was the first time that an asteroid was observed and its impact was predicted prior to its entry into the atmosphere as a meteor. of meteorites were recovered after the impact. As of \u00a02024[ [update]], eleven impacts have been predicted, all of them small bodies that produced meteor explosions, with some impacts in remote areas only detected by the Comprehensive Nuclear-Test-Ban Treaty Organization's International Monitoring System (IMS), a network of infrasound sensors designed to detect the detonation of nuclear devices. Asteroid impact prediction remains in its infancy and successfully predicted asteroid impacts are rare. The vast majority of impacts recorded by IMS are not predicted.\nObserved impacts aren't restricted to the surface and atmosphere of Earth. Dust-sized NEOs have impacted man-made spacecraft, including the space probe Long Duration Exposure Facility, which collected interplanetary dust in low Earth orbit for six years from 1984. Impacts on the Moon can be observed as flashes of light with a typical duration of a fraction of a second. The first lunar impacts were recorded during the 1999 Leonid storm. Subsequently, several continuous monitoring programs were launched. A lunar impact that was observed on September 11, 2013, lasted 8 seconds, was likely caused by an object in diameter, and created a new crater across, was the largest ever observed as of \u00a02019[ [update]].\nRisk.\nThrough human history, the risk that any near-Earth object poses has been viewed having regard to both the culture and the technology of human society. Through history, humans have associated NEOs with changing risks, based on religious, philosophical or scientific views, as well as humanity's technological or economical capability to deal with such risks. Thus, NEOs have been seen as omens of natural disasters or wars; harmless spectacles in an unchanging universe; the source of era-changing cataclysms or potentially poisonous fumes (during Earth's passage through the tail of Halley's Comet in 1910); and finally as a possible cause of a crater-forming impact that could even cause extinction of humans and other life on Earth.\nThe potential of catastrophic impacts by near-Earth comets was recognised as soon as the first orbit calculations provided an understanding of their orbits: in 1694, Edmond Halley presented a theory that Noah's flood in the Bible was caused by a comet impact.\nHuman perception of near-Earth asteroids as benign objects of fascination or killer objects with high risk to human society has ebbed and flowed during the short time that NEAs have been scientifically observed. The 1937 close approach of Hermes and the 1968 close approach of Icarus first raised impact concerns among scientists. Icarus earned significant public attention due to alarmist news reports, while Hermes was considered a threat because it was lost after its discovery; thus its orbit and potential for collision with Earth were not known precisely. Hermes was only re-discovered in 2003, and it is now known to be no threat for at least the next century.\nScientists have recognised the threat of impacts that create craters much bigger than the impacting bodies and have indirect effects on an even wider area since the 1980s, with mounting evidence for the theory that the Cretaceous\u2013Paleogene extinction event (in which the non-avian dinosaurs died out) 65 million years ago was caused by a large asteroid impact. On March 23, 1989, the diameter Apollo asteroid 4581 Asclepius (1989 FC) missed the Earth by . If the asteroid had impacted it would have created the largest explosion in recorded history, equivalent to 20,000 megatons of TNT. It attracted widespread attention because it was discovered only after the closest approach.\nFrom the 1990s, a typical frame of reference in searches for NEOs has been the scientific concept of risk. The awareness of the wider public of the impact risk rose after the observation of the impact of the fragments of Comet Shoemaker\u2013Levy 9 into Jupiter in July 1994. In March 1998, early orbit calculations for recently discovered asteroid showed a potential 2028 close approach from the Earth, well within the orbit of the Moon, but with a large error margin allowing for a direct hit. Further data allowed a revision of the 2028 approach distance to , with no chance of collision. By that time, inaccurate reports of a potential impact had caused a media storm.\nIn 1998, the movies \"Deep Impact\" and \"Armageddon\" popularised the notion that near-Earth objects could cause catastrophic impacts. Also at that time, a conspiracy theory arose about a supposed 2003 impact of a planet called Nibiru with Earth, which persisted on the internet as the predicted impact date was moved to 2012 and then 2017.\nRisk scales.\nThere are two schemes for the scientific classification of impact hazards from NEOs, as a way to communicate the risk of impacts to the general public.\nThe simple Torino scale was established at an IAU workshop in Turin () in June 1999, in the wake of the public confusion about the impact risk of . It rates the risks of impacts in the next 100 years according to impact energy and impact probability, using integer numbers between 0 and 10:\nThe more complex Palermo scale, established in 2002, compares the likelihood of an impact at a certain date to the probable number of impacts of a similar energy or greater until the possible impact, and takes the logarithm of this ratio. Thus, a Palermo scale rating can be any positive or negative real number, and risks of any concern are indicated by values above zero. Unlike the Torino scale, the Palermo scale is not sensitive to newly discovered small objects with an orbit known with low confidence.\nHighly rated risks.\nThe National Aeronautics and Space Administration NASA maintains an automated system to evaluate the threat from known NEOs over the next 100 years, which generates the continuously updated Sentry Risk Table. All or nearly all of the objects are highly likely to drop off the list eventually as more observations come in, reducing the uncertainties and enabling more accurate orbital predictions. When the close approach of a newly discovered asteroid is first put on a risk list with a significant risk, it is normal for the risk to first increase, regardless of whether the potential impact will eventually be ruled out or confirmed with the help of additional observations. Similar tables are maintained by the Near-Earth Object Coordination Centre (NEOCC) of the European Space Agency (ESA) and on the NEODyS (Near Earth Objects Dynamic Site) by the University of Pisa spin-off company SpaceDyS.\nIn March 2002, became the first asteroid with a temporarily positive rating on the Torino Scale, with about a 1 in 9,300 chance of an impact in 2049. Additional observations reduced the estimated risk to zero, and the asteroid was removed from the Sentry Risk Table in April 2002. It is now known that within the next two centuries, 2002 CU11 will pass the Earth at a safe closest distance (perigee) of on August 31, 2080.\nAsteroid has a diameter of about a kilometer (0.6 miles), and an impact would therefore be globally catastrophic. Although this asteroid will not strike for at least 800 years and thus has no Torino scale rating, it was added to the Sentry list in April 2002 as the first object with a Palermo scale value greater than zero. The then-calculated 1 in 300 maximum chance of impact and +0.17 Palermo scale value was roughly 50% greater than the background risk of impact by all similarly large objects until 2880. After additional radar and optical observations, as of \u00a02025[ [update]], the probability of this impact is assessed at 1 in 2,600. The corresponding Palermo scale value of \u22120.92 is the second-highest for all objects on the Sentry List Table.\nOn December 24, 2004, five days after discovery, asteroid 99942 Apophis was assigned a 4 on the Torino scale, the highest rating given to date, as the information available at the time translated to a 1.6% chance of Earth impact in April 2029. As observations were collected over the next three days, the calculated chance of impact first increased to as high as 2.7%, then fell back to zero, as the shrinking uncertainty zone for this close approach no longer included the Earth. There was at that time still some uncertainty about potential impacts during later close approaches. However, as the precision of orbital calculations improved due to additional observations, the risk of impact at any date was eliminated and Apophis was removed from the Sentry Risk Table in February 2021.\nAs of \u00a02025[ [update]], was listed on the Sentry List Table with the highest chance of impacting Earth, at 1 in 10 on September 5, 2095. At only across, the asteroid however is much too small to be considered a potentially hazardous asteroid and it poses no serious threat: the possible 2095 impact therefore rates only \u22122.97 on the Palermo Scale.\nIn January 2025, asteroid reached a 3 rating on the Torino scale for a possible impact on December 22, 2032, triggering an action plan to schedule observations with more powerful telescopes as the object recedes and gets dimmer, to determine its orbit with more precision and thus refine the impact risk prediction. In February 2025, the impact risk peaked at 1 in 32, then dropped below 1 in 1000 and the Torino scale rating was reduced to 0. As of 2025[ [update]], the impact risk for the 2032 encounter was down to 1 in 120,000. By April, 2024 YR4 was on the other hand estimated to have a 4% chance of impacting a 70% waning gibbous moon on 22 December 2032 around 15:17 to 15:21\u00a0UTC.\nProjects to minimize the threat.\nA year before the 1968 close approach of asteroid Icarus, Massachusetts Institute of Technology students launched Project Icarus, devising a plan to deflect the asteroid with rockets in case it was found to be on a collision course with Earth. Project Icarus received wide media coverage, and inspired the 1979 disaster movie \"Meteor\", in which the US and the USSR join forces to blow up an Earth-bound fragment of an asteroid hit by a comet.\nThe first astronomical program dedicated to the discovery of near-Earth asteroids was the Palomar Planet-Crossing Asteroid Survey. The link to impact hazard, the need for dedicated survey telescopes and options to head off an eventual impact were first discussed at a 1981 interdisciplinary conference in Snowmass, Colorado. Plans for a more comprehensive survey, named the Spaceguard Survey, were developed by NASA from 1992, under a mandate from the United States Congress. To promote the survey on an international level, the International Astronomical Union (IAU) organised a workshop at Vulcano, Italy in 1995, and set up The Spaceguard Foundation also in Italy a year later. In 1998, the United States Congress gave NASA a mandate to detect 90% of near-Earth asteroids over diameter (that threaten global devastation) by 2008.\nSeveral surveys have undertaken \"Spaceguard\" activities (an umbrella term), including Lincoln Near-Earth Asteroid Research (LINEAR), Spacewatch, Near-Earth Asteroid Tracking (NEAT), Lowell Observatory Near-Earth-Object Search (LONEOS), Catalina Sky Survey (CSS), Campo Imperatore Near-Earth Object Survey (CINEOS), Japanese Spaceguard Association, Asiago-DLR Asteroid Survey (ADAS) and Near-Earth Object WISE (NEOWISE). As a result, the ratio of the known and the estimated total number of near-Earth asteroids larger than 1\u00a0km in diameter rose from about 20% in 1998 to 65% in 2004, 80% in 2006, and 93% in 2011. The original Spaceguard goal has thus been met, only three years late. As of \u00a02024[ [update]], 867 NEAs larger than 1\u00a0km have been discovered, of which one was discovered in 2024 and two in 2023.\nIn 2005, the original USA Spaceguard mandate was extended by the George E. Brown, Jr. Near-Earth Object Survey Act, which calls for NASA to detect 90% of NEOs with diameters of or greater, by 2020. In January 2016, NASA announced the creation of the Planetary Defense Coordination Office (PDCO) to coordinate an effective threat assessment, response and mitigation effort, which reinforced the goal to detect 90% of NEOs or greater, but without a deadline. In September 2020, it was estimated that about half of these have been found, but objects of this size hit the Earth only about once in 30,000 years. In December 2023, using a lower absolute brightness estimate for smaller asteroids, the ratio of discovered NEOs with diameters of or greater was estimated at 38%. The Chile-based Vera C. Rubin Observatory, which will survey the southern sky for transient events from 2025, is expected to increase the number of known asteroids by a factor of 10 to 100 and increase the ratio of known NEOs with diameters of or greater to at least 60%, while the NEO Surveyor satellite, to be launched in 2027, is expected to push the ratio to 76% during its 5-year mission.\nSurvey programs aim to identify threats years in advance, giving humanity time to prepare a space mission to avert the threat.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;REP. STEWART: ... are we technologically capable of launching something that could intercept [an asteroid]? ... DR. A'HEARN: No. If we had spacecraft plans on the books already, that would take a year ... I mean a typical small mission ... takes four years from approval to start to launch ...\u2014\u200a\nThe ATLAS project, by contrast, aims to find impacting asteroids shortly before impact, much too late for deflection maneuvers but still in time to evacuate and otherwise prepare the affected Earth region. Another project, the Zwicky Transient Facility (ZTF), which surveys for objects that change their brightness rapidly, also detects asteroids passing close to Earth.\nScientists involved in NEO research have also considered options for actively averting the threat if an object is found to be on a collision course with Earth. All viable methods aim to deflect rather than destroy the threatening NEO, because the fragments would still cause widespread destruction. Deflection, which means a change in the object's orbit months to years prior to the predicted impact, also requires orders of magnitude less energy.\nNumber and classification.\nWhen an NEO is detected, like all other small Solar System bodies, its positions and brightness are submitted to the (IAU's) Minor Planet Center (MPC) for cataloging. The MPC maintains separate lists of confirmed NEOs and potential NEOs. The MPC maintains a separate list for the potentially hazardous asteroids (PHAs). NEOs are also catalogued by two separate units of the Jet Propulsion Laboratory (JPL) of NASA: the Center for Near-Earth Object Studies (CNEOS) and the Solar System Dynamics Group. CNEOS's catalog of near-Earth objects includes the approach distances of asteroids and comets. NEOs are also catalogued by a unit of ESA, the Near-Earth Object Coordination Centre (NEOCC).\nNear-Earth objects are classified as meteoroids, asteroids, or comets depending on size, composition, and orbit. Those which are asteroids can additionally be members of an asteroid family, and comets create meteoroid streams that can generate meteor showers.\nAs of \u00a030, 2024[ [update]] and according to statistics maintained by CNEOS, 37,378 NEOs have been discovered. Only 123 (0.33%) of them are comets, whilst 37,255 (99.67%) are asteroids. 2,465 of those NEOs are classified as potentially hazardous asteroids (PHAs).\nAs of \u00a02, 2025[ [update]], 1,886 NEAs appear on the Sentry impact risk page at the NASA website. All but 106 of these NEAs are less than 50 meters in diameter, only one recently discovered object has an impact risk meriting a Torino Scale rating higher than zero, while none have a Palermo scale rating higher than zero.\nObservational biases.\nThe main problem with estimating the number of NEOs is that the probability of detecting one is influenced by a number of aspects of the NEO, starting naturally with its size but also including the characteristics of its orbit and the reflectivity of its surface. What is easily detected will be more counted, and these observational biases need to be compensated when trying to calculate the number of bodies in a population from the list of its detected members.\nBigger asteroids reflect more light, and the two biggest near-Earth objects, 433 Eros and 1036 Ganymed, were naturally also among the first to be detected. 1036 Ganymed is about in diameter and 433 Eros is about in diameter. Meanwhile, the apparent brightness of objects that are closer is higher, introducing a bias that favours the discovery of NEOs of a given size that get closer to Earth.\nEarth-based astronomy requires dark skies and hence nighttime observations, and even space-based telescopes avoid looking into directions close to the Sun, thus most NEO surveys are blind towards objects passing Earth on the side of the Sun. This bias is further enhanced by the effect of phase: the narrower the angle of the asteroid and the Sun from the observer, the lesser part of the observed side of the asteroid will be illuminated. Another bias results from the different surface brightness or albedo of the objects, which can make a large but low-albedo object as bright as a small but high-albedo object. In addition, the reflexivity of asteroid surfaces is not uniform but increases towards the direction opposite of illumination, resulting in the phenomenon of phase darkening, which makes asteroids even brighter when the Earth is close to the axis of sunlight. An asteroid's observed albedo usually has a strong peak or opposition surge very close to the direction opposite of the Sun. Different surfaces display different levels of phase darkening, and research showed that, on top of albedo bias, this favours the discovery of silicon-rich S-type asteroids over carbon-rich C types, for example. As a result of these observational biases, in Earth-based surveys, NEOs tended to be discovered when they were in opposition, that is, opposite from the Sun when viewed from the Earth.\nThe most practical way around many of these biases is to use thermal infrared telescopes in space that observe their thermal emissions instead of the visible light they reflect, with a sensitivity that is almost independent of the illumination. In addition, space-based telescopes in an orbit around the Sun in the shadow of the Earth can make observations as close as 45 degrees to the direction of the Sun.\nFurther observational biases favour objects that have more frequent encounters with the Earth, which makes the detection of Atens more likely than that of Apollos; and objects that move slower when encountering the Earth, which makes the detection of NEAs with low eccentricities more likely.\nSuch observational biases must be identified and quantified to determine NEO populations, as studies of asteroid populations then take those known observational selection biases into account to make a more accurate assessment. In the year 2000 and taking into account all known observational biases, it was estimated that there are approximately 900 near-Earth asteroids of at least kilometer size, or technically and more accurately, with an absolute magnitude brighter than 17.75.\nNear-Earth asteroids.\nThese are asteroids in a near-Earth orbit without the tail or coma of a comet. As of \u00a02024[ [update]], 37,255 near-Earth asteroids (NEAs) are known, 2,465 of which are both sufficiently large and may come sufficiently close to Earth to be classified as potentially hazardous.\nNEAs survive in their orbits for just a few million years. They are eventually eliminated by planetary perturbations, causing ejection from the Solar System or a collision with the Sun, a planet, or other celestial body. With orbital lifetimes short compared to the age of the Solar System, new asteroids must be constantly moved into near-Earth orbits to explain the observed asteroids. The accepted origin of these asteroids is that main-belt asteroids are moved into the inner Solar System through orbital resonances with Jupiter. The interaction with Jupiter through the resonance perturbs the asteroid's orbit and it comes into the inner Solar System. The asteroid belt has gaps, known as Kirkwood gaps, where these resonances occur as the asteroids in these resonances have been moved onto other orbits. New asteroids migrate into these resonances, due to the Yarkovsky effect that provides a continuing supply of near-Earth asteroids. Compared to the entire mass of the asteroid belt, the mass loss necessary to sustain the NEA population is relatively small; totalling less than 6% over the past 3.5 billion years. The composition of near-Earth asteroids is comparable to that of asteroids from the asteroid belt, reflecting a variety of asteroid spectral types.\nA small number of NEAs are extinct comets that have lost their volatile surface materials, although having a faint or intermittent comet-like tail does not necessarily result in a classification as a near-Earth comet, making the boundaries somewhat fuzzy. The rest of the near-Earth asteroids are driven out of the asteroid belt by gravitational interactions with Jupiter.\nMany asteroids have natural satellites (minor-planet moons). As of \u00a02024[ [update]], 104 NEAs were known to have at least one moon, including five known to have two moons. The asteroid 3122 Florence, one of the largest PHAs with a diameter of , has two moons measuring across, which were discovered by radar imaging during the asteroid's 2017 approach to Earth.\nIn May 2022, an algorithm known as Tracklet-less Heliocentric Orbit Recovery or THOR and developed by University of Washington researchers to discover asteroids in the solar system was announced as a success. The International Astronomical Union's Minor Planet Center confirmed a series of first candidate asteroids identified by the algorithm.\nSize distribution.\nWhile the size of a very small fraction of these asteroids is known to better than 1%, from radar observations, from images of the asteroid surface, or from stellar occultations, the diameter of the vast majority of near-Earth asteroids has only been estimated on the basis of their brightness and a representative asteroid surface reflectivity or albedo, which is commonly assumed to be 14%. Such indirect size estimates are uncertain by over a factor of 2 for individual asteroids, since asteroid albedos can range at least as low as 5% and as high as 30%. This makes the volume of those asteroids uncertain by a factor of 8, and their mass by at least as much, since their assumed density also has its own uncertainty. Using this crude method, an absolute magnitude of 17.75 roughly corresponds to a diameter of and an absolute magnitude of 22.0 to a diameter of . Diameters of intermediate precision, better than from an assumed albedo but not nearly as precise as good direct measurements, can be obtained from the combination of reflected light and thermal infrared emission, using a thermal model of the asteroid to estimate both its diameter and its albedo. The reliability of this method, as applied by the Wide-field Infrared Survey Explorer and NEOWISE missions, has been the subject of a dispute between experts, with the 2018 publication of two independent analyses, one criticising and another giving results consistent with the WISE method. A 2023 study re-evaluated the relationship of brightness, albedo and diameter. For many objects with a diameter larger than 1\u00a0km, brightness estimates were reduced slightly. Meanwhile, based on new albedo estimates of smaller objects, the study found that H \n 23 best corresponds to a diameter of 140\u00a0m.\nIn 2000, NASA reduced from 1,000\u20132,000 to 500\u20131,000 its estimate of the number of existing near-Earth asteroids over one kilometer in diameter, or more exactly brighter than an absolute magnitude of 17.75. Shortly thereafter, the LINEAR survey provided an alternative estimate of . In 2011, on the basis of NEOWISE observations, the estimated number of one-kilometer NEAs was narrowed to (of which 93% had been discovered at the time), while the number of NEAs larger than 140 meters across was estimated at . The NEOWISE estimate differed from other estimates primarily in assuming a slightly lower average asteroid albedo, which produces larger estimated diameters for the same asteroid brightness. This resulted in 911 then known asteroids at least 1\u00a0km across, as opposed to the 830 then listed by CNEOS from the same inputs but assuming a slightly higher albedo. In 2017, two studies using an improved statistical method reduced the estimated number of NEAs brighter than absolute magnitude 17.75 (approximately over one kilometer in diameter) slightly to . The estimated number of near-Earth asteroids brighter than absolute magnitude of 22.0 (approximately over 140\u00a0m across) rose to , double the WISE estimate, of which about a fourth were known at the time. The number of asteroids brighter than H \n 25, which corresponds to about in diameter, is estimated at \u2014of which about 1.3 percent had been discovered by February 2016; the number of asteroids brighter than H \n 30 (larger than ) is estimated at million\u2014of which about 0.003 percent had been discovered by February 2016.\nA September 2021 study revised the estimated number of NEAs with a diameter larger than 1\u00a0km (using both WISE data and the absolute brightness lower than 17.75 as proxy) slightly upwards to , of which 911 were discovered at the time, but reduced the estimated number of asteroids brighter than absolute magnitude of 22.0 (as proxy for a diameter of 140\u00a0m) to under 20,000, of which about half were discovered at the time. The 2023 study that re-evaluated the relationship of average absolute brightness, albedo and diameter confirmed the ratios of the number of discovered and estimated total asteroids of different sizes in the 2021 study, but by changing the proxy for a diameter of 140\u00a0m to H \n 23, it estimated that only about 44% of the estimated 35,000 total larger than that have been discovered by the end of 2022. As of \u00a02024[ [update]], NEO catalogues still use H \n 22 as proxy for a diameter of 140\u00a0m.\nAs of \u00a030, 2024[ [update]], and using diameters mostly estimated crudely from a measured absolute magnitude and an assumed albedo, 867 NEAs listed by CNEOS, including 152 PHAs, measure at least 1\u00a0km in diameter, and 11,167 known NEAs, including 2,465 PHAs, are larger than 140\u00a0m in diameter.\nThe smallest known near-Earth asteroid is 2015 FF415 with an absolute magnitude of 34.34, corresponding to an estimated diameter of about . The largest such object is 1036 Ganymed, with an absolute magnitude of 9.18 and directly measured irregular dimensions which are equivalent to a diameter of about .\nOrbital classification.\nNear-Earth asteroids are divided into groups based on their semi-major axis (a), perihelion distance (q), and aphelion distance (Q):\nSome authors define Atens differently: they define it as being all the asteroids with a semi-major axis of less than 1\u00a0AU. That is, they consider the Atiras to be part of the Atens. Historically, until 1998, there were no known or suspected Atiras, so the distinction wasn't necessary.\nAtiras and Amors do not cross the Earth's orbit and are not immediate impact threats, but their orbits may change to become Earth-crossing orbits in the future.\nAs of \u00a030, 2024[ [update]], 34 Atiras, 2,952 Atens, 21,132 Apollos and 13,137 Amors have been discovered and cataloged.\nCo-orbital asteroids.\nMost NEAs have orbits that are significantly more eccentric than that of the Earth and the other major planets and their orbital planes can tilt several degrees relative to that of the Earth. NEAs which have orbits that do resemble the Earth's in eccentricity, inclination and semi-major axis are grouped as Arjuna asteroids. Within this group are NEAs that have the same orbital period as the Earth, or a co-orbital configuration, which corresponds to an orbital resonance at a ratio of 1:1. All co-orbital asteroids have special orbits that are relatively stable and, paradoxically, can prevent them from getting close to Earth:\nNear-Earth asteroids also include the co-orbitals of Venus. As of \u00a02023[ [update]], all known co-orbitals of Venus have orbits with high eccentricity, also crossing Earth's orbit.\nMeteoroids.\nIn 1961, the IAU defined meteoroids as a class of solid interplanetary objects distinct from asteroids by their considerably smaller size. This definition was useful at the time because, with the exception of the Tunguska event, all historically observed meteors were produced by objects significantly smaller than the smallest asteroids then observable by telescopes. As the distinction began to blur with the discovery of ever smaller asteroids and a greater variety of observed NEO impacts, revised definitions with size limits have been proposed from the 1990s. In April 2017, the IAU adopted a revised definition that generally limits meteoroids to a size between 30\u00a0\u03bcm and 1\u00a0m in diameter, but permits the use of the term for any object of any size that caused a meteor, thus leaving the distinction between asteroid and meteoroid blurred.\nNear-Earth comets.\nNear-Earth comets (NECs) are objects in a near-Earth orbit with a tail or coma made up of dust, gas or ionized particles emitted by a solid nucleus. Comet nuclei are typically less dense than asteroids but they pass Earth at higher relative speeds, thus the impact energy of a comet nucleus is slightly larger than that of a similar-sized asteroid. NECs may pose an additional hazard due to fragmentation: the meteoroid streams which produce meteor showers may include large inactive fragments, effectively NEAs. Although no impact of a comet in Earth's history has been conclusively confirmed, the Tunguska event may have been caused by a fragment of Comet Encke.\nComets are commonly divided between short-period and long-period comets. Short-period comets, with an orbital period of less than 200 years, originate in the Kuiper belt, beyond the orbit of Neptune; while long-period comets originate in the Oort Cloud, in the outer reaches of the Solar System. The orbital period distinction is of importance in the evaluation of the risk from near-Earth comets because short-period NECs are likely to have been observed during multiple apparitions and thus their orbits can be determined with some precision, while long-period NECs can be assumed to have been seen for the first and last time when they appeared since the start of precise observations, thus their approaches cannot be predicted well in advance. Since the threat from long-period NECs is estimated to be at most 1% of the threat from NEAs, and long-period comets are very faint and thus difficult to detect at large distances from the Sun, Spaceguard efforts have consistently focused on asteroids and short-period comets. Both NASA's CNEOS and ESA's NEOCC restrict their definition of NECs to short-period comets. As of \u00a030, 2024[ [update]], 123 such objects have been discovered.\nComet 109P/Swift\u2013Tuttle, which is also the source of the Perseid meteor shower every year in August, has a roughly 130-year orbit that passes close to the Earth. During the comet's September 1992 recovery, when only the two previous returns in 1862 and 1737 had been identified, calculations showed that the comet would pass close to Earth during its next return in 2126, with an impact within the range of uncertainty. By 1993, even earlier returns (back to at least 188 AD) had been identified, and the longer observation arc eliminated the impact risk. The comet will pass Earth in 2126 at a distance of 23 million kilometers. In 3044, the comet is expected to pass Earth at less than 1.6 million kilometers.\nArtificial near-Earth objects.\nDefunct space probes and final stages of rockets can end up in near-Earth orbits around the Sun. Examples of such artificial near-Earth objects include a Tesla Roadster used as dummy payload in a 2018 rocket test and the Kepler space telescope. Some of these objects have been re-discovered by NEO surveys when they returned to Earth's vicinity and classified as asteroids before their artificial origin was recognised.\nAn object classified as asteroid 1991 VG was discovered during its transition from a temporary satellite orbit around Earth to a solar orbit in November 1991, and could only be observed until April 1992. Some scientists suspected it to be a returning piece of man-made space debris. After new observations in 2017 provided better data on its orbit and surface characteristics, a new study found the artificial origin unlikely.\nIn September 2002, astronomers found an object designated J002E3. The object was on a temporary satellite orbit around Earth, leaving for a solar orbit in June 2003. Calculations showed that it was also on a solar orbit before 2002, but was close to Earth in 1971. J002E3 was identified as the third stage of the Saturn V rocket that carried Apollo 12 to the Moon. In 2006, two more apparent temporary satellites were discovered which were suspected of being artificial. One of them was eventually confirmed as an asteroid and classified as the temporary satellite 2006 RH120. The other, 6Q0B44E, was confirmed as an artificial object, but its identity is unknown. Another temporary satellite was discovered in 2013, and was designated 2013 QW1 as a suspected asteroid. It was later found to be an artificial object of unknown origin. 2013 QW1 is no longer listed as an asteroid by the Minor Planet Center. In September 2020, an object detected on an orbit very similar to that of the Earth was temporarily designated 2020 SO. However, orbital calculations and spectral observations confirmed that the object was the Centaur rocket booster of the 1966 Surveyor 2 uncrewed lunar lander.\nIn some cases, active space probes on solar orbits have been observed by NEO surveys and erroneously catalogued as asteroids before identification. During its 2007 flyby of Earth on its route to a comet, ESA's space probe \"Rosetta\" was detected unidentified and classified as asteroid 2007 VN84, with an alert issued due to its close approach. The designation 2015 HP116 was similarly removed from asteroid catalogues when the observed object was identified with \"Gaia\", ESA's space observatory for astrometry.\nExploratory missions.\nSome NEOs are of special interest because the sum total of changes in orbital speed required to send a spacecraft on a mission to physically explore an NEO \u2013 and thus the amount of rocket fuel required for the mission \u2013 is lower than what is necessary for even lunar missions, due to their combination of low velocity with respect to Earth and weak gravity. They may present interesting scientific opportunities both for direct geochemical and astronomical investigation, and as potentially economical sources of extraterrestrial materials for human exploitation. This makes them an attractive target for exploration.\nMissions to NEAs.\nThe IAU held a minor planets workshop in Tucson, Arizona, in March 1971. At that point, launching a spacecraft to asteroids was considered premature; the workshop only inspired the first astronomical survey specifically aiming for NEAs. Missions to asteroids were considered again during a workshop at the University of Chicago held by NASA's Office of Space Science in January 1978. Of all of the near-Earth asteroids (NEA) that had been discovered by mid-1977, it was estimated that spacecraft could rendezvous with and return from only about 1 in 10 using less propulsive energy than is necessary to reach Mars. It was recognised that due to the low surface gravity of all NEAs, moving around on the surface of an NEA would cost very little energy, and thus space probes could gather multiple samples. Overall, it was estimated that about one percent of all NEAs might provide opportunities for human-crewed missions, or no more than about ten NEAs known at the time. A five-fold increase in the NEA discovery rate was deemed necessary to make a crewed mission within ten years worthwhile.\nThe first near-Earth asteroid to be visited by a spacecraft was 433 Eros when NASA's \"NEAR Shoemaker\" probe orbited it from February 2000, landing on the surface of the asteroid in February 2001. A second NEA, the long peanut-shaped 25143 Itokawa, was explored from September 2005 to April 2007 by JAXA's \"Hayabusa\" mission, which succeeded in taking material samples back to Earth. A third NEA, the long elongated 4179 Toutatis, was explored by CNSA's \"Chang'e 2\" spacecraft during a flyby in December 2012.\nThe Apollo asteroid 162173 Ryugu was explored from June 2018 until November 2019 by JAXA's \"Hayabusa2\" space probe, which returned a sample to Earth. A second sample-return mission, NASA's \"OSIRIS-REx\" probe, targeted the Apollo asteroid 101955 Bennu, which, as of \u00a02025[ [update]], has the third-highest cumulative Palermo scale rating (\u22121.40 for several close encounters between 2178 and 2290). On its journey to Bennu, the probe had searched unsuccessfully for Earth's Trojan asteroids, entered into orbit around Bennu in December 2018, touched down on its surface in October 2020, and was successful in returning samples to Earth three years later. China launched its own sample-return mission, \"Tianwen-2\", in May 2025, targeting Earth quasi-satellite 469219 Kamo\u02bboalewa and returning samples to Earth in late 2027.\nAfter completing its mission to Bennu, the probe \"OSIRIS-REx\" was redirected towards 99942 Apophis, which it is planned to orbit from April 2029. After completing its exploration of 162173 Ryugu, the mission of the \"Hayabusa2\" space probe was extended, to include flybys of S-type Apollo asteroid 98943 Torifune in July 2026 and fast-rotating Apollo asteroid in July 2031. In 2025, JAXA plans to launch another probe, \"DESTINY+\", to explore Apollo asteroid 3200 Phaethon, the parent body of the Geminid meteor shower, during a flyby.\nAsteroid deflection tests.\nOn September 26, 2022, NASA's \"DART\" spacecraft reached the system of 65803 Didymos and impacted the Apollo asteroid's moon Dimorphos, in a test of a method of planetary defense against near-Earth objects. In addition to telescopes on or in orbit around the Earth, the impact was observed by the Italian mini-spacecraft or CubeSat \"LICIACube\", which separated from \"DART\" 15 days before impact. The impact shortened the orbital period of Dimorphos around Didymos by 33 minutes, indicating that the moon's momentum change was 3.6 times the momentum of the impacting spacecraft, thus most of the change was due to the ejected material of the moon itself.\nIn October 2024, ESA launched the spacecraft \"Hera\", which is to enter orbit around Didymos in December 2026, to study the consequences of the DART impact. China plans to launch its own pair of asteroid deflection and observation probes in 2027, which are to target Aten asteroid .\nSpace mining.\nFrom the 2000s, there were plans for the commercial exploitation of near-Earth asteroids, either through the use of robots or even by sending private commercial astronauts to act as space miners, but few of these plans were pursued.\nIn April 2012, the company Planetary Resources announced its plans to mine asteroids commercially. In a first phase, the company reviewed data and selected potential targets among NEAs. In a second phase, space probes would be sent to the selected NEAs; mining spacecraft would be sent in a third phase. Planetary Resources launched two testbed satellites in April 2015 and January 2018, and the first prospecting satellite for the second phase was planned for a 2020 launch prior to the company closing and its assets purchased by ConsenSys Space in 2018.\nAnother American company established with the goal of space mining, AstroForge, launched the probe \"Odin\" (formerly \"Brokkr-2\") on February 26, 2025, to perform a flyby of asteroid , but the probe showed technical problems. The goal of the mission was to confirm if 2022 OB5 is a metal-rich M-type asteroid. Regardless of the success of \"Odin\", AstroForge plans to follow it up a year later with the probe \"Vestri\", which is to land on the same asteroid.\nMissions to NECs.\nThe first near-Earth comet visited by a space probe was 21P/Giacobini\u2013Zinner in 1985, when the NASA/ESA probe \"International Cometary Explorer\" (\"ICE\") passed through its coma. In March 1986, ICE, along with Soviet probes \"Vega 1\" and \"Vega 2\", ISAS probes \"Sakigake\" and \"Suisei\" and ESA probe \"Giotto\" flew by the nucleus of Halley's Comet. In 1992, \"Giotto\" also visited another NEC, 26P/Grigg\u2013Skjellerup.\nIn November 2010, after completing its primary mission to non-near-Earth comet Tempel 1, the NASA probe \"Deep Impact\" flew by the near-Earth comet 103P/Hartley.\nIn August 2014, ESA probe \"Rosetta\" began orbiting near-Earth comet 67P/Churyumov\u2013Gerasimenko, while its lander \"Philae\" landed on its surface in November 2014. After the end of its mission, Rosetta was crashed into the comet's surface in 2016.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
