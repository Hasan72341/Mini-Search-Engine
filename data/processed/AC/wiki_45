{"id": "24653", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=24653", "title": "Princess Mononoke", "text": "1997 Japanese animated film by Hayao Miyazaki\n is a 1997 Japanese animated historical fantasy film written and directed by Hayao Miyazaki. Set in the Muromachi period of Japanese history, the film follows Ashitaka, a young Emishi prince who journeys west to cure his cursed arm and becomes embroiled in the conflict between Irontown and the forest of the gods, as well as the feud between Lady Eboshi and a human girl raised by wolves named San. Produced by Toshio Suzuki, animated by Studio Ghibli, and distributed by Toho, it stars the voices of Y\u014dji Matsuda, Yuriko Ishida, Y\u016bko Tanaka, Kaoru Kobayashi, Masahiko Nishimura, Tsunehiko Kamij\u014d, Akihiro Miwa, Mitsuko Mori, and Hisaya Morishige.\nMiyazaki began developing early concepts in 1980 and later considered basing a film on the Japanese literary classic the (1212); elements of both evolved substantially into the eventual film. After taking a break to direct \"On Your Mark\"(1995), he led the production with a budget of \u00a5, making it the most expensive animated film at the time. Some computer-generated imagery and other digital techniques were used in conjunction with hand-drawn animation, a first for Miyazaki. The film explores themes of environmentalism and societal diversity, partly inspired by Miyazaki's readings into novel historical and cultural studies, and presents a feminist portrayal of its characters. It also blends fantastical elements with its depiction of medieval Japanese history, influenced by the style. The score was composed by Joe Hisaishi, a longtime collaborator of Miyazaki's.\n\"Princess Mononoke\" was theatrically released in Japan on July 12, 1997, and broke several box office records. Suzuki led the film's marketing, then the largest advertisement campaign in Japan. It eventually became the highest-grossing film in the country. Following a distribution deal struck between Tokuma Shoten and Walt Disney Studios, it was the first of Studio Ghibli's films to be released internationally and was given to Miramax Films to be dubbed into English and distributed in North America. Neil Gaiman wrote the translation, making significant alterations for its American audience; the dub underperformed at the box office. As of 2025[ [update]], the film has grossed US$ through various theatrical and home media releases. It received a broadly positive critical response in both Japan and the United States and earned a number of major Japanese accolades, including top awards at the Mainichi Film Awards and the Japan Academy Film Prize. Its sustained popularity and cultural impact have since made it a cult film.\nPlot summary.\nIn Muromachi-era Japan, the last Emishi prince, Ashitaka, kills a gigantic demon to protect his village, but his arm is afflicted by its curse. The demon, once the boar god Nago, was corrupted by an iron ball embedded in its body. Learning that the curse will eventually kill him, Ashitaka is exiled to the west, seeking a cure by uncovering the source of Nago's hatred.\nOn his journey, Ashitaka discovers that the curse grants him supernatural strength. He encounters a monk named Jigo, who advises him to seek answers in the nearby mountains from the Forest Spirit\u2013 a deer-like god of life and death that transforms into the giant Nightwalker at sunset. Guided by tiny , Ashitaka passes through the forest of the gods, where he catches a glimpse of the Forest Spirit. Meanwhile, a group of men led by Lady Eboshi repel an attack by a pack of wolves led by the goddess Moro and her adopted human daughter, San.\nAshitaka arrives at Irontown, a settlement that has deforested the surrounding area to mine iron, leading to conflicts with the animal gods of the forest. However, the town shelters former prostitutes and people with leprosy, who work to manufacture firearms. Eboshi, the town's leader, admits to shooting Nago, instilling the hatred that corrupted him. She also reveals her plan to kill the Forest Spirit, hoping to eradicate the gods and enable Irontown to prosper. Though Ashitaka's cursed arm tries attacking Eboshi, he resists its influence. Eboshi is collaborating with Jigo, who stands to be richly rewarded for delivering the Forest Spirit's head\u2013 believed to grant immortality\u2013 to the Emperor.\nThe wolves attack; San infiltrates Irontown and duels Eboshi. Ashitaka subdues them both, but a townsperson shoots him. Strengthened by the curse, he takes San out of the town before collapsing. San threatens to kill him for sparing Eboshi, but is taken aback when he compliments her beauty. She brings Ashitaka to the Forest Spirit, who heals his wound but leaves the curse. The next day, a boar clan, led by the blind god Okkoto, declares their intention to attack Irontown, preferring to die in battle rather than allow their kind to diminish. Ashitaka recovers and implores Moro to let San escape with him, but is banished from the forest instead.\nThe boars assault Irontown's forces but are annihilated by their weaponry. San and the mortally wounded Okkoto retreat to the forest, unknowingly followed by Eboshi and Jigo, who use the blood of the fallen boars to deceive Okkoto into leading them to the Forest Spirit. San tries stopping him, but his pain transforms him into a demon, engulfing her. With Moro's remaining strength, she and Ashitaka free San. The Forest Spirit grants peaceful deaths to Okkoto and Moro. As it transforms into the Nightwalker, Eboshi beheads it. Its body explodes into a dark, chaotic fluid that expands in search of its head, killing everything it touches\u2013 including the forest\u2013 and briefly reanimates Moro's head, which bites off Eboshi's arm.\nThough reluctant to help the humans, San joins Ashitaka in pursuing Jigo to recover the Forest Spirit's head. Ashitaka evacuates Irontown as the Nightwalker's body floods it, and together, he and San retrieve the head from Jigo, returning it to the Nightwalker. As the sun rises, the Nightwalker dies and dissolves into the wind. In its place, the devastated land is renewed with abundant flora, and Ashitaka's curse is lifted. A repentant Eboshi resolves to build a better town. While Ashitaka chooses to help with Irontown's reconstruction, San, unable to forgive humanity, stays in the forest. They promise to meet as often as they can.\nVoice cast.\n&lt;templatestyles src=\"Plain row headers/styles.css\"/&gt;\nDevelopment.\nEarly concepts and pre-production.\nHayao Miyazaki composed the preliminary ideas for what would become \"Princess Mononoke\" in 1980 after releasing his first film, \"The Castle of Cagliostro\"(1979), drawing sketches of a princess living in the woods with a beast. The story was roughly based on the \"Beauty and the Beast\"(1740) fairy tale, set in historical Japan. The Beast was realized as an animalistic spirit () whom the protagonist, the daughter of a nobleman, is forced to marry. After unsuccessfully proposing the film project to several production companies, Miyazaki published his concepts in a book in 1983, republished in 2014 as \"\". He reused various ideas from this project in works such as \"My Neighbor Totoro\"(1988) and \"Porco Rosso\"(1992). \"Shuna's Journey\"(1983) in particular bears the closest resemblance to the eventual film, featuring a protagonist who rides an elk to the land of gods. A few fundamental ideas from the 1980 concept appear in the final film, but the character designs and plot are entirely different. The film scholar Raz Greenberg wrote that the original concept also \"[portrayed] the end of tyranny vividly\", in contrast with the film, showing the antagonist's fortress destroyed and its slaves emancipated. According to the film scholar Rayna Denison, the stark difference between the original idea and the final film demonstrates the radical change of Miyazaki's filmmaking philosophies during that time. He took cues from Japanese folklore, especially the tale of a princess with a birthmark, which evolved over time into Ashitaka's curse.\nInspired by the writings of Yoshie Hotta, Miyazaki also considered creating a film adaptation of the (1212), a Japanese literary classic on the ephemerality of life. It was written by the poet Kamo no Ch\u014dmei during a period of political turmoil and natural disasters, which the animation scholar Susan J. Napier felt resonated with the \"increasing sense of vulnerability\" in Japanese culture during the time of the film's production. However, Miyazaki felt the concept was \"far removed from common sense\" and had no possibility of commercial success; he never moved forward with this concept but continued to consider creating a historical piece. Upon the completion of his manga series \"Nausica\u00e4 of the Valley of the Wind\"(1982\u20131994), Miyazaki began work on the project proposal for the film in August 1994. However, encountering writer's block in December, he took a break from the production to direct the short film \"On Your Mark\"(1995) as a side project. Miyazaki returned to the film in April 1995 and began working on the storyboards in May. The film's broad scope and high level of detail extended the pre-production process. That month, Miyazaki took four of the art directors to visit the island of Yakushima, which had already inspired some environments in \"Nausica\u00e4 of the Valley of the Wind\", to achieve the environmental depiction that he was seeking to portray. The island's relative lack of development informed their sketches of the film's forest of the gods. The fifth art director, Kazuo Oga, went to the Shirakami-Sanchi mountains to draw inspiration for the Emishi village.\nProduction and animation.\n\"Princess Mononoke\" was the most expensive animated film ever produced in Japan at the time. It was originally allocated a budget of \u00a5, which was expanded to \u00a5 later in the production, more than double that of any previous Studio Ghibli film. Miyazaki stated, \"I don't care if the studio goes bankrupt.\" The animation production commenced in July 1995. Miyazaki created the storyboards using the approach he took toward serialized manga, writing the film's plot as he drew the scenes. His declining sight initially caused him to use oversized paper, but he switched back to the normal size to increase the pace of the storyboarding. This process was done in parallel with the animation, and the final boards outlining the end of the film were not finished until January 1997.\nAn unusually high level of detail was afforded illustrating backgrounds and animating background characters due to the large budget available. The decision to assign five art directors to the film was also unprecedented. Each tackled a different aspect; for example, one handled daylight shots while another covered the nighttime. The film used approximately 144,000 cels, 80,000 of them being key animation frames, more than any other Studio Ghibli film. Miyazaki is estimated to have drawn or retouched nearly 80,000 cels himself. The final shots were completed in June 1997, less than a month from the release date.\nComputer graphics.\nThe film was created using a combination of hand-drawn animation and computer-generated imagery; approximately five minutes were animated entirely using digital processes. A further ten minutes use digital ink and paint, a technique used in all subsequent Studio Ghibli films. The company's hand-drawn methods were becoming outdated by the late 1990s, and by 1997, members of Studio Ghibli's computer graphics team felt that the adoption was made largely out of necessity. According to Mamoru Oshii\u2013 a contemporary of Miyazaki's\u2013 digital painting was adopted at the insistence of Michiyo Yasuda, a senior colorist at Studio Ghibli. While Studio Ghibli had already begun experimenting with digital techniques a few years prior on \"Pom Poko\"(1994), its computer graphics department was opened during the production of \"Princess Mononoke\".\nMiyazaki's distaste for digital animation techniques was well known in Japan before the film's release, so his use of computer graphics came as a surprise, according to Denison. He made the decision to use the new techniques early in the production, starting with the demon god in the opening sequence. Certain sequences were created using 3D tools and then processed to resemble a traditionally animated sequence using a program called Toon Shader, developed by Microsoft at the studio's request. Some of this work was outsourced to the animation studio Toyo Links. Three broad categories of digital techniques were applied to the animation: the use of digital ink and paint to finish coloring hand-drawn frames; 3D rendering and digital compositing, which put the hand-drawn images in a three-dimensional environment to create more visual depth; and morphing and particle effects, which create additional detail and smoother transitions. Yoshinori Sugano, the head of the computer graphics department, recalled that the most involved uses of digital techniques were to mask the transitions between the digital and hand-drawn elements on screen. Some characters, particularly the gods, alternate between rendering approaches in different shots.\nThemes.\nConflicts of nature, technology, and humanity.\nEnvironmentalism is a central theme of \"Princess Mononoke\". In the war between the forest gods and the people of Irontown, Ashitaka serves as the mediator. Unlike many Western works with similar themes, the film does not present these positions as complete opposites, nor does it outright reject modernity and technology. The scholars Tracey Daniels-Lerberg and Matthew Lerberg wrote that it instead \"[embraces] the unpredictable outcomes that emerge in the uncertainty that remains.\" Both humanity and nature are given equal standing in the film's world, and Napier wrote that the film \"offers a vision of life as a densely interwoven design, rather than a simple allegory of dichotomized opposites.\" Additionally, the film portrays internal strife within parties on both sides of the conflict: the different clans of spirits disagree on how to handle the conflict, and the humans war amongst themselves for various reasons. Ashitaka's relationships with both parties are volatile and \"even dissatisfying at moments\", according to Daniels-Lerberg and Lerberg. They attribute this sense of unease to the focus on emotion, rather than strict logic, that the film puts on the conflict. According to the film critic Roger Ebert, \"Princess Mononoke\" is not a \"simplistic tale of good and evil, but the story of how humans, forest animals, and nature gods all fight for their share of the new emerging order.\"\nThe film scholars Colin Odell and Michelle Le Blanc wrote that the film simultaneously mounts a criticism of humanity's mistreatment of the natural world and \"grudgingly admits\" that some disputes are inevitable to facilitate technological progress. While Irontown is shown to be a haven for downtrodden members of society, who have the opportunity to live honest lives and enjoy fair treatment from Eboshi, the conflict arises from the harm that the settlement causes to the surrounding environment. Greenberg identified this dynamic as a marked increase in complexity from Miyazaki's earlier works, which typically presented a utopian model as an answer to social issues. Miyazaki expressed that he \"meant to state [his] objection to the way environmental issues are treated\", referring to the general exclusion of humanity's role in environmental discourse in Japan. The ecological writings of the historian Sasuke Nakao, especially his \"evergreen forest culture theory\", were greatly influential on Miyazaki when creating the film's forest of the gods. Miyazaki stated that \"[Nakao's book] taught me what I was the descendent of\", and provided him an alternative to many traditional depictions of Japanese history that he disliked.\nNapier saw the film as an \"elegy for a lost Japan\", a version of the country that predates the modern patriarchal society and was controlled by nature. Setting the film in the Muromachi period allowed Miyazaki to depict the country before it had been deforested and altered by rice agriculture and positions the film within the moment of history when \"humankind pushed nature into submission\", according to the animation writers Jonathan Clements and Helen McCarthy. Miyazaki intended to portray the gods as \"living animals, tortured by humans\", feeling it to be an important aspect to depict in the relationship between nature and humanity. He was inspired for the film's concept by the Epic of Gilgamesh(c.2100\u20131200 BCE), an ancient epic poem that depicts the death of the forest god and the ruin of humanity. The philosopher Takeshi Umehara, who wrote a stage play titled \"Gilgamesh\"(1988), had previously suggested that Miyazaki adapt his work into a film; Miyazaki had declined the offer at the time but later stated that he had unconsciously included elements similar to the play in \"Princess Mononoke\". The film shares several themes with the \"Nausica\u00e4 of the Valley of the Wind\" manga, which Miyazaki had completed in 1994, namely the \"environmental catastrophe, the role of technology and warfare, and human interactions with nonhuman species\", according to Napier. Clements and McCarthy wrote that the film was conceived partly due to Miyazaki's discontent with the narrative of the manga's film adaptation(1984), in which the environmental theme was suddenly resolved via a \"deus ex machina\".\nMiyazaki's filmmaking style changed considerably in the 1990s in response to various geopolitical conflicts, including the Gulf War and the Yugoslav Wars following the dissolution of the Soviet Union. He was especially critical of Japan's decision to provide military aid in the Gulf War, which he considered a violation of Article 9 of the Japanese Constitution. These events disheartened Miyazaki, who compared them to the preamble to World War I and felt he was watching history repeat itself. In 1995, two disasters occurred in Japan that had a marked negative impact on its culture: the Great Hanshin earthquake, which killed thousands and became the worst on record since 1923, and the Tokyo subway sarin attack perpetrated by the Aum Shinrikyo cult. Napier wrote that these had an effect \"on both a psychological and an environmental level\" and heightened the country's cultural \"emptiness\" following the Japanese asset price bubble bursting in 1992. After finishing \"Porco Rosso\", Miyazaki resolved to create a \"substantial film\" that acknowledged academic discourse, eschewing the escapist philosophy of his earlier works. He instead set out to depict the philosophy that, \"no matter how messy things get, we have no choice but to go on living.\"\nHeterogeneity of society.\nNapier wrote that \"the sense of a broken heterogeneous world is stridently manifest\" within \"Princess Mononoke\". The film challenges popular cultural beliefs, such as the existence of a homogenous Japanese ethnicity (), by depicting social outcasts and peoples not of Yamato origin. The Emishi people are related to the modern Ainu people, and Miyazaki highlights this difference in the film: Ashitaka is immediately treated as a stranger at many of the villages he visits. The film scholar Eija Niskanen wrote that the film also critiques the , a group of ethnonationalist theories about Japan that claim its culture is unique from others and depict the nation's people as uniform. The film scholar Shiro Yoshioka felt that the writing of Yoshihiko Amino, another historical scholar, influenced Miyazaki's writing in this regard. According to Denison, his explorations result in highly polarized characters and participants on both sides of the conflict becoming \"monstrous\". Miyazaki said that more recent historical studies had increasingly focused on the lifestyles of common people outside the nobility, many of which do not align with the theories of a . He was also inspired to portray people with leprosy after visiting the Tama Zenshoen Sanatorium near his home in Tokyo. He commented afterwards, \"In the middle of no matter what kind of misery there is joy and laughter. In human life which tends toward ambiguity, I have never seen a place which shows this with such clarity.\"\nNapier felt that the film proposes a possible future Japanese identity that highlights non-uniformity and the role of women. Toshio Suzuki\u2013 the film's producer and a longtime friend of Miyazaki's\u2013 stated that Miyazaki was a feminist and brought ideals of gender equality to his professional life as well as his fictional works. However, McCarthy felt that his prior portrayals of women were predicated in a fundamentally patriarchal worldview; Miyazaki's female characters succeed only when given the opportunity to in a society ultimately governed by men. She argued that the protagonists Ashitaka and San were constructed incrementally through various predecessors in Miyazaki's works. His earlier films also portrayed young characters as able and driven to change the world, which is not continued here. San, according to Napier, is an \"embodiment of Miyazaki's anger with what he increasingly perceived as a stupid and chaotic world.\" She also found San's early appearance in the film with a bloodstained face to create a vivid image of violence, wildness, and \"aggressive sexuality that is confrontational rather than alluring.\" McCarthy wrote that San is Miyazaki's only female protagonist to be entirely unbound from patriarchy, refusing to accept a domestic life even despite her love for Ashitaka. In a divergence from Miyazaki's previous works that close with clearly optimistic outlooks, the film ends in an ambiguous manner; the Forest Spirit's death revives nature, but the wild forests remain felled, and Ashitaka and San do not stay together but agree to occasionally meet.\nNapier felt that the film's conflicting philosophies do not facilitate the inclusion of an antagonist of a similar kind to the Count from \"The Castle of Cagliostro\" or Muska from \"Castle in the Sky\"(1986). Eboshi's initial characterization sets her in the role of a villain: the belligerent of the environmental conflict and the cause of Nago's demonic corruption. However, this impression is repeatedly challenged by depictions of her leadership and caregiving qualities; the community of Irontown holds sincere respect for her, and her sheltering of former prostitutes and people affected by leprosy contravenes many traditional roles of femininity. Miyazaki's depictions of female characters working on iron and people with leprosy manufacturing weapons are considerable departures from historical views. Napier emphasized that the decision to place a female character in this leadership position prevents her stance from being viewed as a clich\u00e9 of oppressive militarism or the interpretation of technology as inherently detrimental. She wrote that Eboshi can be viewed as a tragic character because she is not evil but is forced to become an aggressor to safeguard her progressive community. Although Eboshi and San represent diametrically opposed views, they share many leadership and nurturing characteristics, and the scholar Alice Vernon examined the relationship between the two as a symbiotic one, where Eboshi represents a possible future image of San.\nStyle.\n\"Princess Mononoke\" marked the first time Miyazaki explored a style\u2013 a period drama focusing on the lives of historic Japanese people. He particularly appreciated the works of Akira Kurosawa, who had directed several key films in the genre. The film subverts many traditional elements of the , such as the portrayals of the Emperor and the samurai as sacred and noble. Miyazaki chose not to align with typical depictions of the Muromachi period, such as the development of high culture or Zen aesthetics in the capital city of Kyoto. Napier wrote that the forest of the gods also subverts typical depictions of nature in the Muromachi period; as opposed to carefully tended Zen gardens, it is untamed, violent, and largely avoided by humans. The film exaggerates its historical perspective to facilitate the narrative; Irontown, for example, was inspired primarily by metalworking settlements in China as well as a furnace in the Shimane Prefecture. Miyazaki lacked a historical reference for the Emishi people's garments, so the clothing worn by the girls in Ashitaka's village is influenced by styles from Bhutan and Thailand, and other characters' embroidered fabrics resemble traditional Ainu clothing. Instead of traditional arms, guns are the primary weapons in the film's conflict. Isao Takahata\u2013 a fellow director and longtime friend of Miyazaki's\u2013 said that the film was \"dangerously liable to give the audiences misconceived impressions of history.\" Napier wrote that the film goes \"beyond realism\" to support its themes, and the critic Kazuhiko Komatsu felt that its world, while sometimes consistent with historical fact, is essentially Miyazaki's fantasy.\nAccording to Napier, the film presents a much \"grimmer\" tone than Miyazaki's previous works, inspired by the themes of the . She contrasted Miyazaki's previous depictions of historical settings to the film's rendering of the Muromachi period, which she wrote \"refuses to sentimentalize the medieval history it highlights\". The film is unusual in Miyazaki's filmography for its lack of flying sequences. Napier suggested that its focus on lateral motion over vertical can be tied to the \"sense of entrapment and desperation\" it presents. Studio Ghibli had begun hiring full-time animators by the early 1990s, in contrast to the industry standard of staff being employed on short-term contracts. Denison wrote that this helped the studio develop an animated \"house style\" over time. Miyazaki felt that an important aspect of this style was the studio's aptitude for illustrating the natural world; Denison observed from an interview with the art directors that their approach was to \"simplify and caricature nature's essential meanings\", prioritizing moments of contemplation and mindfulness of the surrounding landscape. The film uses a palette for the forest that contrasts with the pastel colors typically used in Miyazaki films, employing darker shades of green and brown. Napier emphasized that the medium of animation, compared to live action, is well suited for exploring the film's themes. The film depicts a number of animals and gods, but she noted that they are entirely distinct from the humans; most notably, the Forest Spirit presents a serene yet entirely foreign visage.\nRelease.\nMarketing and Japanese release.\nThe promotional strategy was spearheaded by Suzuki, who by 1997 had already developed relationships within the media industry while promoting previous Studio Ghibli releases. Napier noted that the marketing put the film under the Studio Ghibli brand for the first time\u2013 as opposed to previous works that were labeled primarily as Miyazaki films\u2013 which she felt reflected Suzuki's rising position as the studio's main producer. According to Suzuki, three important elements of the campaign were the repeated use of a recognizable title logo, key imagery from the film, and a tagline. The tagline underwent several iterations before, with Suzuki's input, the final phrase was chosen: \"Live.\" Suzuki also changed the title from the original intention of \"The Legend of Ashitaka\"\u200a without Miyazaki's initial approval, as he found it less interesting. The budget allotted for the film's promotion was at least \u00a5, even higher than the production budget, making it the largest film advertisement campaign in Japan at the time. Yoshioka argued that it was essential for \"Princess Mononoke\" to be a commercial success to make up for the large production budget, and the scale of its campaign was significantly expanded from previous films' as a result. Several types of merchandise, such as stuffed and copies of San's mask, were sold. A number of preview screenings were organized before the release to advertise the film by word of mouth; 130 of them were originally scheduled, and 70 were ultimately held, a number that the film scholar Seiji Kan\u014d still found \"astonishing\". Miyazaki's previous film, \"Porco Rosso\", had had only 23 screenings by comparison.\nAfter Walt Disney Studios and Studio Ghibli's then\u2013parent company, Tokuma Shoten, secured their distribution deal in 1997, the film would be the first among Miyazaki's works to receive a worldwide release. While the arrangement did extend the studio's reach to new regions, the announcement was made primarily to attract local audiences. Miyazaki also hinted at his retirement following the film's release, further piquing audience interest. The film was marketed as a split between an anime and an art house film, avoiding advertising in the mainstream ahead of its release. Denison felt that this choice was indicative of the studio's initial lack of confidence in the film's commercial viability and their perception of its financial riskiness. Yasuyoshi Tokuma, the president of Tokuma Shoten who frequently worked with Miyazaki, said in an interview before the release that it would be a \"huge success\" just to make back the investments that had been put into the film. Denison argued, however, that the marketing campaign's scale revealed the studio's ultimate aim to achieve a commercial success; she interpreted this approach as a \"local equivalent of the 'calculated' blockbuster film.\"\n\"Princess Mononoke\" was presented by Tokuma Shoten, Nippon Television, and Dentsu, and released by Toho in Japan on July 12, 1997. It was the subject of immense public anticipation, and it was screened at 260 of the country's 1800 cinemas, many of which reported audiences queueing to purchase tickets in previously unseen numbers. Tokuma Shoten's specialist magazine \"Animage\", which had been closely associated with Studio Ghibli since the 1980s, released special issues on the film, as did several other publications. Newspapers began to refer to the film's release as the \"\"Mononoke\" phenomenon\", as by the end of its first week, the film had brought in over a million viewers and earned \u00a5 at the box office. Advertising for the film labeled it a blockbuster (), and it increasingly competed with many high-profile films in the Japanese market, including Hollywood imports such as \"\"(1997). By November, it had surpassed \u00a5 in distribution rental sales, breaking the national record previously held by \"E.T. the Extra-Terrestrial\"(1982). During that period, 12million people, a tenth of Japan's population at the time, saw the film in theaters. A year after the film's release, it had attracted over 14.2million viewers and earned \u00a5 in gross revenue, making it the all-time highest-grossing film in the country.\nEnglish dub and American release.\nAs part of the Disney\u2013Tokuma deal, the film was handed over to Miramax Films, a Disney subsidiary at the time, to dub and distribute in the United States and other regions. The dub was directed by Jack Fletcher, who had previously worked on the dubs of other Studio Ghibli films such as \"Kiki's Delivery Service\", and its script was written by the fantasy author Neil Gaiman, who was an unusual choice for anime localizations at the time, according to Denison. Gaiman claimed that Harvey Weinstein, who was the head of Miramax at the time, initially offered the role to the film director Quentin Tarantino, who had then recommended Gaiman instead. Gaiman had intended to decline the offer before being impressed by a scene in which a stone wets in the falling rain, saying, \"I have never seen anything like this. This is real filmmaking.\" Steve Alpert, an executive at Studio Ghibli, assisted with the translation.\nDenison wrote that Miramax's approach to the dub \"might be termed a project of indigenization\" with an intent to form a new identity for the film outside of Japan. The language scholar JenniferE. Nicholson wrote that the English dub's changes more closely approach an adaptation than a translation. Cultural differences between the United States and Japan, amplified by the film's discussion of specifically Japanese elements, resulted in a script that co-mingled the two languages and cultures. Gaiman inserted dialog for off-screen characters elucidating cultural concepts considered obscure for American audiences. Humor in particular demanded significant alterations; Gaiman approached the issue by searching for an \"emotional equivalent\" for the lines instead of considering the reason the originals were humorous. Gaiman later recalled that although he oversaw the writing process, some script alterations were made without his knowledge. Several of the changes removed terms that identified the setting, such as substituting with \"wine\" and removing mentions of Japan and China. Nicholson found these decisions indicative of Miramax's intent to strip the film of its cultural context and divorce it from history entirely. Gaiman also recalled his drafts receiving contradictory corrections from both Miramax and Studio Ghibli, to which he responded by writing two sets of revisions and asking them to \"go fight it out amongst [themselves].\"\nThe film featured a variety of celebrity voice actors who had developed followings in both traditional acting and voice acting roles. Denison wrote that various American and British accents were chosen to further remove elements of Japanese culture and color the film with \"the 'American' voice that narrates it.\" The English-language release was marketed primarily as an art house film, and the media scholar Emma Pett felt that choosing the Miramax label rather than the family film\u2013oriented Buena Vista label helped target the film towards a \"middlebrow, culturally sophisticated audience\" outside the mainstream. By this time, Weinstein had developed a reputation for importing and cutting international films to appeal to domestic audiences. However, among the terms of the distribution deal were that Studio Ghibli would approve and have ultimate control of the translation and that the film would not have any time cut. Weinstein attempted to convince Miyazaki and Suzuki otherwise but was unsuccessful. Gaiman said that Miramax rolled back the planned marketing campaign and opened the film in a very limited number of screens. The English dub was first screened at the 48th Berlin International Film Festival on February 11, 1998, and premiered at the Avery Fisher Hall in New York City on September 26, 1999. It underperformed at the American box office, earning only US$.\nHome media and other releases.\nThe film was released on VHS in Japan by Buena Vista Home Entertainment in 1997 and on LaserDisc by Tokuma Shoten in 1998. Several related books have been published, including a manga series derived from the film's cels, art books with early sketches and storyboards, and reference works written by various academics. The English dub was released theatrically in Japan on April 29, 2000, with Japanese-language subtitles. A documentary titled \"Mononoke-hime in U.S.A.\" was released concurrently. These and other screenings internationally brought the English dub's total earnings to US$ at the time. The film has also been released on home media in various European and Asian regions.\nThe DVD release in North America was not initially set to include the Japanese audio track. Online petitions were opened to retain it, and the planned August 2000 release was consequently delayed. Miramax released the DVD on December 19, 2000, featuring the original Japanese audio, the English dub audio, and extras including a trailer and a documentary. \"Nikkei Business\" reported that 4.4million DVD units were sold in Japan as of 2007[ [update]].\nWalt Disney Studios Home Entertainment released the film on Blu-ray in 2014, and it was included in a collection of Miyazaki's films in 2015. GKIDS re-issued it on DVD and Blu-ray in 2017. As of \u00a02020[ [update]], the film has grossed US$ from Blu-ray sales in the United States. It has since received multiple worldwide theatrical re-releases, including at the annual Studio Ghibli Fest organized by GKIDS.\nGKIDS released the film in IMAX theaters in March 2025, featuring a remastered version in 4K resolution. Atsushi Okui, the vice president of Studio Ghibli, said that the original negatives had been preserved and rescanned in 4K over 10 years prior. The remaster has grossed US$ in the North American box office as of \u00a0, 2025[ [update]], bringing the film's cumulative worldwide total to US$.\nMusic.\nAs with most of Miyazaki's previous films, \"Princess Mononoke\"'s score was composed by Joe Hisaishi. According to McCarthy, the score's development involved a much closer collaboration between the two than on previous works. Hisaishi first composed an image album\u2013 a collection of demos and musical sketches that serve as a precursor to the finished score\u2013 which he shared with Miyazaki and Suzuki. The unused title \"The Legend of Ashitaka\" appears here as the title of the opening theme. With their input, the demos were then worked into the final score, performed by the Tokyo City Philharmonic Orchestra. Tokuma Shoten released the image album in July 1996 and the soundtrack album in July 1997. The vocal theme song performed by the countertenor singer Yoshikazu Mera was released as a single before the film's release and became popular with Japanese audiences. A third version of the soundtrack, arranged for symphony orchestra and performed by the Czech Philharmonic, was released in 1998. All three albums were issued on vinyl records in 2020.\nThe vocal theme was re-recorded for the English dub by the American vocalist Sasha Lazard. Denison argued that this was a part of Miramax's efforts to remove the film's Japanese elements, but she also acknowledged that the score deviates substantially from a typical Hollywood-style compositional approach. For example, leitmotifs, which are commonly used to represent characters or settings, are instead used in transitional moments between more significant narrative events. McCarthy wrote that the film complements the scenes featuring music and dialog with a liberal use of silence and ambient sounds to augment the tension of certain moments, a significant departure from American scoring approaches. The musicology scholar Stacey Jocoy highlighted the emphatic use of brass instruments to accompany the film's epic story. Hisaishi employs Japanese pentatonic scales in conjunction with Western tonalities, and Jocoy analyzed the melody featuring this scale in San's theme as symbolic of her desire for \"peace and beauty\". The contrasting cluster chords\u2013 which she found similar to those of Igor Stravinsky's \"The Rite of Spring\"(1913)\u2013 are used to represent San's aggression.\nReception.\nCritical response.\nThe film was generally well received by critics in Japan, and Kan\u014d described a \"flurry of praise\" in the Japanese media following its box office success. \"The Asahi Shimbun\"'s Noboru Akiyama felt that the work displayed a \"strong artistic quality\" and a number of reviews in animation magazines highlighted its visual fidelity. Several publications featured articles from critics and academics covering several aspects of the film's production as well as interviews with key staff. According to Yoshioka, a variety of academics were attracted to write about the film due to themes such as Japanese cultural history being relatively \"easy topics\" to cover, as well as in response to Miyazaki's growing status as a public intellectual () within Japanese society. Some scholars speculated on the contributing factors to the film's success; a number commented on the reactions of younger audience members, who found the themes relatable to their personal struggles and empathized with its motifs of hope. Napier also wrote that the themes of conflict and coexistence with nature and the spirit world resonated strongly with Japanese viewers. Very few reviews directed criticism at the film, and among them Kan\u014d found many of the comments to be \"highly questionable\". Kenichiro Horii of the \"Sh\u016bkan Bunshun\" found the text difficult to parse, and others were disappointed by the fantasy that Miyazaki had constructed. A few critics also faulted the female characters' lack of sex appeal.\nDespite its poor performance in the American box office, the film received widespread praise from critics in the United States. On the review aggregator website Metacritic, the film was assigned a weighted average score of 76 out of 100 based on 29 critics, indicating \"generally favorable\" reviews. On Rotten Tomatoes, of the critics' reviews are positive, with an average rating of 8 out of 10. The website's consensus reads, \"With its epic story and breathtaking visuals, \"Princess Mononoke\" is a landmark in the world of animation.\" In 2018, Pett conducted a meta-analysis of 1065 critical reviews published in the United States and the United Kingdom. Initial reviews often discussed the cultural differences that the film would exhibit and the alterations that Miramax had made to the presentation; Ty Burr of \"Entertainment Weekly\" was generally appreciative but felt \"very curious to see if American audiences can handle it.\" While Janet Maslin of \"The New York Times\" felt that the film had been \"effectively translated[...] without losing its Japanese essence\", Michael Atkinson wrote in \"Mr. Showbiz\" that \"an enormous amount of something or other got lost in the translation.\"\nMany critics compared the film with the family-oriented works, primarily produced by Disney, which defined audience expectations for animations in the United States. \"Variety\"'s Leonard Klady wrote that the film \"[flies] in the face of popular Western animation\" by eschewing musical numbers or narratives written to appeal to children. Stephen Hunter commented in an article for \"The Washington Post\" that the animation is \"completely vivid and exquisitely detailed\", but lacks the fluidity of Disney's works. Critics also highlighted the violence and mature themes as aspects inappropriate for children. Burr and others favorably compared the film's fantasy elements with those of \"\"(1999)\u2013 which had been released a few months prior\u2013 and novels such as \"The Lord of the Rings\"(1954\u20131955) and \"The Chronicles of Narnia\"(1950\u20131956). Roger Ebert of the \"Chicago Sun-Times\" considered the film Miyazaki's best and recommended it for an Academy Award nomination. In the United Kingdom, however, the film received a very limited number of reviews and was largely panned by critics. Pett and the journalist Andrew Osmond ascribed this to a general negative perception of anime in British society at the time, rooted in controversies caused by some violent and sexually explicit animations.\nSeveral publications have featured \"Princess Mononoke\" in their lists of best films. \"Animage\" ranked it 47th in their list of the 100 best anime in 2001. \"Empire\" ranked it 488th on their list of the 500 greatest films and placed it 3rd on their 2024 list of the 50 greatest animated films. It also ranked 13th on \"Paste\"'s list of the 100 best anime films and 26th on \"Time Out\" and \"Total Film\"'s lists of the greatest animated films.\nAccolades.\nJapan submitted \"Princess Mononoke\" for Best Foreign Language Film at the 70th Academy Awards, but it was not nominated.\nLegacy.\nAccording to Napier, the film is commonly considered to be Miyazaki's most significant feature film. She wrote that it marked a \"new chapter\" in his filmography on account of its nuanced and intermingled themes and the unprecedented scope of its production. The film was longer and more expensive to produce than any Studio Ghibli film up to that point, which Napier reported induced a high level of stress and demanded \"almost superhuman efforts\" from the entire staff, including Miyazaki. Some senior employees, worn out from the film's production, left Studio Ghibli in its aftermath, with Miyazaki himself increasingly withdrawing from public relations. Suzuki recounted that Miyazaki was overtaxed from supervising the storyboards, music, and vocal recordings and had \"given his body and soul\" to the production. In an interview before the film's release, Miyazaki said that, \"Physically, I just can't go on.\" He resigned in 1998 but returned shortly after to direct \"Spirited Away\"(2001) following the death of Yoshifumi Kond\u014d, who was intended to be Miyazaki's successor at Studio Ghibli.\n\"Princess Mononoke\" was the first film in which Miyazaki directly referenced scholarly writing, which strongly contributed to his status in Japanese society as a and marked his works out for further academic inquiry. Alongside \"Neon Genesis Evangelion\"(1995\u20131996), the film laid the foundation for anime to become the subject of study by academics and critics. Yoshioka suggested that Miyazaki's growing reputation may have constrained his later creations\u2013 as he never wrote a feature film in the style of his earlier action-adventure works after \"Princess Mononoke\"\u2013 and motivated him to retire from the public eye. McCarthy, however, felt that the film provides a novel view of femininity that allows the female characters to express themselves without needing comparison to the men but writes that Miyazaki \"opened the gates of this marvelous possibility\" only to revert to traditional storytelling and character archetypes in later films.\nYoshioka felt the film's widespread success turned Miyazaki into an \"icon of contemporary Japanese cinema\" on the international stage and primed many of his subsequent works to become commercial successes in turn. It has since become a cult film due to its sustained popularity among fans, and Pett wrote that the film is now an \"established cultural touchstone\", identifying multiple other works that it had influenced. James Cameron, for example, cited the film as an influence on his science fiction film \"Avatar\"(2009). Critics have also named a number of video games that take influence from the film, including \"Ori and the Blind Forest\"(2015) and \"\"(2017). Pett identified a shift in critical writings that reinterpreted San as a feminist figure. In April 2013, Studio Ghibli partnered with the English production company Whole Hog Theatre to create a stage adaptation of the film. It premiered at the New Diorama Theatre in London after selling out a year ahead of time and moved to Tokyo later that year. In 2025, a newly discovered species of deepwater tilefish was named \"Branchiostegus sanae\" after the character San.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBook and journal sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nMagazine and news sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nOnline and other sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24654", "revid": "9267683", "url": "https://en.wikipedia.org/wiki?curid=24654", "title": "Premier of New South Wales", "text": "Head of government for the state of New South Wales, Australia\nThe premier of New South Wales is the head of government in the state of New South Wales, Australia. The Government of New South Wales follows the Westminster Parliamentary System, with a Parliament of New South Wales acting as the legislature. The premier is appointed by the Governor of New South Wales, and by modern convention holds office by their ability to command the support of a majority of members of the lower house of Parliament, the Legislative Assembly.\nBefore Federation in 1901, the term \"prime minister of New South Wales\" was also used. \"Premier\" has been used more or less exclusively from 1901, to avoid confusion with the federal prime minister of Australia.\nThe current premier is Chris Minns, the leader of the New South Wales Labor Party, who assumed office on 28 March 2023. Minns defeated Dominic Perrottet at the election held on 25 March 2023, after twelve years of Liberal/National Coalition rule.\nSee also.\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24655", "revid": "44141905", "url": "https://en.wikipedia.org/wiki?curid=24655", "title": "List of premiers of Victoria", "text": "Heads of government of Australian state\nThe premier of Victoria is the head of government of the Australian state of Victoria. The premier leads the Cabinet of Victoria and selects its ministers. The premier is appointed by the governor of Victoria and must be a member of the Victorian Legislative Assembly. To be appointed, the premier must command confidence in the Legislative Assembly, meaning that they must have the support of a majority of Legislative Assembly members. In practice, this is typically the leader of the political party who holds the support of a majority of lower house members.\nEach premier since 1933, apart from Ian Macfarlan, who only served for 51 days, has had a portrait commissioned for the Victorian Parliament's portrait collection. The tradition was initiated by Legislative Council President Fred Grimwade. Premiers who hold the office for 3,000 days are granted a statue as a commemoration of their legacy. Five premiers, Daniel Andrews, Henry Bolte, John Cain Jr, Albert Dunstan, and Rupert Hamer, have achieved this milestone and four have their statues near the premier's office at 1 Treasury Place. James McCulloch also served for over 3,000 days but he did so across four separate terms between 1863 and 1877 and has not been honoured with a statue; the prior five achieved 3,000 in a single term (Dunstan then served a second, shorter, term).\nThe longest-serving premier was Henry Bolte, who served from 7 June 1955 to 23 August 1972 for a total of 17 years, and 77 days in office. He was a member of the Liberal Party. By contrast, the shortest-serving premier was George Elmslie, who served from 9 December 1913 to 22 December 1913 for a total of 13 days in office. He was also the first premier from the Labor Party.&lt;ref name=\"HUN 21/4/22\"&gt;&lt;/ref&gt; The current premier is Jacinta Allan of the Labor Party, who assumed the office on 27 September 2023 following the resignation of Daniel Andrews. Allan is the second female to have held the office.\nList of premiers of Victoria.\nPolitical parties&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Independent\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Reform\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Commonwealth Liberal \n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Labor \n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Nationalist \n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Country \n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0United Australia \n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Liberal \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24657", "revid": "4871659", "url": "https://en.wikipedia.org/wiki?curid=24657", "title": "Standard Chinese", "text": "Standard form of Mandarin Chinese\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nStandard Chinese () is a modern standard form of Mandarin Chinese that was first codified during the republican era (1912\u20131949). It is designated as the national lingua franca of China, one of the official languages of the United Nations and of Singapore, and one of the national languages of Taiwan. It is largely based on the Beijing dialect. Standard Chinese is a pluricentric language with local standards in mainland China, Taiwan and Singapore that mainly differ in their lexicon. Hong Kong written Chinese, used for formal written communication in Hong Kong and Macau, is a form of Standard Chinese that is read aloud with the Cantonese reading of characters.\nLike other Sinitic languages, Standard Chinese is a tonal language with topic-prominent organization and subject\u2013verb\u2013object (SVO) word order. Compared with southern varieties, the language has fewer vowels, final consonants and tones, but more initial consonants. It is an analytic language, albeit with many compound words.\nIn the context of linguistics, the dialect has been labeled Standard Northern Mandarin or Standard Beijing Mandarin, and in common speech simply Mandarin, more specifically qualified as Standard Mandarin, Modern Standard Mandarin, or Standard Mandarin Chinese.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nNaming.\nIn English.\nAmong linguists, Standard Chinese has been referred to as \"Standard Northern Mandarin\" or \"Standard Beijing Mandarin\". It is colloquially referred to as simply \"Mandarin\", though this term may also refer to the Mandarin dialect group as a whole, or the late imperial form used as a lingua franca. \"Mandarin\" is a translation of \"Guanhua\" (), which referred to the late imperial lingua franca. The term \"Modern Standard Mandarin\" is used to distinguish it from older forms.\nIn Chinese.\n\"Guoyu\" and \"Putonghua\".\nThe word \"Guoyu\" () was initially used during the late Qing dynasty to refer to the Manchu language. The 1655 \"Memoir of Qing Dynasty, Volume: Emperor Nurhaci\" () says: \"(In 1631) as Manchu ministers do not comprehend the Han language, each ministry shall create a new position to be filled up by Han official who can comprehend the national language.\" However, the sense of \"Guoyu\" as a specific language variety promoted for general use by the citizenry was originally borrowed from Japan in the early 20th century. In 1902, the Japanese Diet had formed the National Language Research Council to standardize a form of the Japanese language dubbed (). Reformers in the Qing bureaucracy took inspiration and borrowed the term into Chinese, and in 1909 the Qing education ministry officially proclaimed imperial Mandarin to be the national language.\nThe term \"Putonghua\" () dates back to 1906 in writings by Zhu Wenxiong to differentiate the standard vernacular Mandarin from Literary Chinese and other varieties of Chinese.\nUsage concerns.\nSince 2000, the Chinese government has used the term \"Countrywide common spoken and written language\" (), while also making provisions for the use and protection of ethnic minority languages. The term is derived from the title of a 2000 law which defines \"Putonghua\" as the \"Countrywide Common Spoken and Written Language\".\nUse of the term \"Putonghua\" ('common tongue') deliberately avoids calling the dialect a 'national language', in order to mitigate the impression of coercing minority groups to adopt the language of the majority. Such concerns were first raised by the early Communist leader Qu Qiubai in 1931. His concern echoed within the Communist Party, which adopted the term \"Putonghua\" in 1955. Since 1949, usage of the word \"Guoyu\" was phased out in the PRC, only surviving in established compound nouns, e.g. 'Mandopop' (), or 'Chinese cinema' ().\nIn Taiwan, \"Guoyu\" is the colloquial term for Standard Chinese. In 2017 and 2018, the Taiwanese government introduced two laws explicitly recognizing the indigenous Formosan languages and Hakka as \"Languages of the nation\" () alongside Standard Chinese. Since then, there have been efforts to redefine \"Guoyu\" as encompassing all \"languages of the nation\", rather than exclusively referring to Standard Chinese.\n\"Hanyu\" and \"Zhongwen\".\nAmong Chinese people, \"Hanyu\" () refers to spoken varieties of Chinese. \"Zhongwen\" () refers to written Chinese. Among foreigners, the term \"Hanyu\" is most commonly used in textbooks and Standard Chinese education, such as in the Hanyu Shuiping Kaoshi (HSK) test.\n\"Huayu\".\nUntil the mid-1960s, \"Huayu\" () referred to all the language varieties used among the Chinese nation. For example, Cantonese, Mandarin, and Hokkien films produced in Hong Kong were imported into Malaysia and collectively known as \"\"Huayu\" cinema\" until the mid-1960s. Gradually, the term has been re-appropriated to refer specifically to Standard Chinese. The term is mostly used in Singapore, Malaysia, Indonesia, and the Philippines.\nHistory.\nThe Chinese language has had considerable dialectal variation throughout its history, including prestige dialects and linguae francae used throughout the territory controlled by the dynastic states of China. For example, Confucius is thought to have used a dialect known as \"yayan\" rather than regional dialects; during the Han dynasty, texts also referred to (). The rime books that were written starting in the Northern and Southern period may have reflected standard systems of pronunciation. However, these standard dialects were mostly used by the educated elite, whose pronunciation may still have possessed great variation. For these elites, the Chinese language was unified in Literary Chinese, a form that was primarily written, as opposed to spoken.\nLate empire.\nThe term \"Guanhua\" () was used during the Ming (1368\u20131644) and Qing (1644\u20131912) dynasties to refer to the lingua franca spoken within the imperial courts. The term \"Mandarin\" is borrowed directly from the Portuguese word , in turn derived from the Sanskrit word ('minister')\u2014and was initially used to refer to Chinese scholar-officials. The Portuguese then began referring to \"Guanhua\" as \"the language of the mandarins\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Chinese have different languages in different provinces, to such an extent that they cannot understand each other... [They] also have another language which is like a universal and common language; this is the official language of the mandarins and of the court; it is among them like Latin among ourselves... Two of our fathers [Michele Ruggieri and Matteo Ricci] have been learning this mandarin language...\u2014\u200a\nDuring the 17th century, the state had set up orthoepy academies () in an attempt to conform the speech of bureaucrats to the standard. These attempts had little success: as late as the 19th century, the emperor had difficulty understanding some of his ministers in court, who did not always follow a standard pronunciation.\nBefore the 19th century, the lingua franca was based on the Nanjing dialect, but later the Beijing dialect became increasingly influential, despite the mix of officials and commoners speaking various dialects in the capital, Beijing. By some accounts, as late as 1900 the position of the Nanjing dialect was considered by some to be above that of Beijing; the postal romanization standards established in 1906 included spellings that reflected elements of Nanjing pronunciation. The sense of \"Guoyu\" as a specific language variety promoted for general use by the citizenry was originally borrowed from Japan; in 1902 the Japanese Diet had formed the National Language Research Council to standardize a form of the Japanese language dubbed (). Reformers in the Qing bureaucracy took inspiration and borrowed the term into Chinese, and in 1909 the Qing education ministry officially proclaimed imperial Mandarin as \"Guoyu\" (), the 'national language'.\nRepublican era.\nAfter the Republic of China was established in 1912, there was more success in promoting a common national language. A Commission on the Unification of Pronunciation was convened with delegates from the entire country. A \"Dictionary of National Pronunciation\" () was published in 1919, defining a hybrid pronunciation that did not match any existing speech. Meanwhile, despite the lack of a workable standardized pronunciation, colloquial literature in written vernacular Chinese continued to develop.\nGradually, the members of the National Language Commission came to settle upon the Beijing dialect, which became the major source of standard national pronunciation due to its prestigious status. In 1932, the commission published the \"Vocabulary of National Pronunciation for Everyday Use\" (), with little fanfare or official announcement. This dictionary was similar to the previous published one except that it normalized the pronunciations for all characters into the pronunciation of the Beijing dialect. Elements from other dialects continue to exist in the standard language, but as exceptions rather than the rule.\nFollowing the end of the Chinese Civil War, the People's Republic of China (PRC) continued standardisation efforts on the mainland, and in 1955 officially began using \"Putonghua\" () instead of \"Guoyu\", which remains the name used in Taiwan. The forms of Standard Chinese used in China and Taiwan have diverged somewhat since the end of the Civil War, especially in newer vocabulary, and a little in pronunciation.\nIn 1956, the PRC officially defined Standard Chinese as \"the standard form of Modern Chinese with the Beijing phonological system as its norm of pronunciation, and Northern dialects as its base dialect, and looking to exemplary modern works in written vernacular Chinese for its grammatical norms.\" According to the official definition, Standard Chinese uses:\nProficiency in the new standard was initially limited, even among Mandarin speakers, but increased over the following decades.\nA 2007 survey conducted by the Chinese Ministry of Education indicated that 53.06% of the population were able to effectively communicate using Standard Chinese. By 2020, this figure had risen to over 80%.\nStatus.\nIn both mainland China and Taiwan, Standard Chinese is used in most official contexts, as well as the media and educational system, contributing to its proliferation. As a result, it is now spoken by most people in both countries, though often with some regional or personal variation in vocabulary and pronunciation.\nIn overseas Chinese communities outside Asia where Cantonese once dominated, such as the Chinatown in Manhattan, the use of Standard Chinese, which is the primary lingua franca of more recent Chinese immigrants, is rapidly increasing.\nMainland China.\nWhile Standard Chinese was made China's official language in the early 20th century, local languages continue to be the main form of everyday communication in much of the country. The language policy adopted by the Chinese government promotes the use of Standard Chinese while also making allowances for the use and preservation of local varieties. From an official point of view, Standard Chinese serves as a lingua franca to facilitate communication between speakers of mutually unintelligible varieties of Chinese and non-Sinitic languages. The name \"Putonghua\", or 'common speech', reinforces this idea. However, due to Standard Chinese being a \"public\" lingua franca, other Chinese varieties and even non-Sinitic languages have shown signs of losing ground to the standard dialect. In many areas, especially in southern China, it is commonly used for practical reasons, as linguistic diversity is so great that residents of neighboring cities may have difficulties communicating with each other without a lingua franca.\nAccording to the Chinese government, their language policy been largely successful, with over 80% of the Chinese population able to speak Standard Chinese as of 2020. The Chinese government's current goal is to have 85% of the country's population speak Standard Chinese by 2025, and virtually the entire country by 2035. Throughout the country, Standard Chinese has heavily influenced local languages through diglossia, replacing them entirely in some cases, especially among younger people in urban areas.\nThe Chinese government is keen to promote \"Putonghua\" as the national lingua franca: under the \"National Common Language and Writing Law\", the government is required to promote its use. Officially, the Chinese government has not stated its intent to replace regional varieties with Standard Chinese. However, regulations enacted by local governments to implement the national law have included measures to control the use of spoken dialects and traditional characters in writing. For example, the \"Guangdong National Language Regulations\" enacted in 2012 generally require broadcasts in the province to be in Standard Chinese, with programs and channels able to broadcast in other varieties if approved by the national or provincial government. Government employees, including teachers, conference holders, broadcasters, and TV staff are required to use Standard Chinese. In addition, public signage is to be written using simplified characters, with exceptions for historical sites, pre-registered logos, or when approved by the state. Public brands, seals, documents, websites, signs, and trade names are not to use traditional characters or character variants.\nSome Chinese speakers who are older or from rural areas cannot speak Standard Chinese fluently or at all, though most are able to understand it. Meanwhile, those from urban areas\u2014as well as younger speakers, who have received their education primarily in Standard Chinese\u2014are almost all fluent in it, with some being unable to speak their local dialect.\nThe Chinese government has disseminated public service announcements promoting the use of \"Putonghua\" on television and the radio, as well as on public buses. The standardization campaign has been challenged by local dialectical and ethnic populations, who fear the loss of their cultural identity and native dialect. In the summer of 2010, reports of a planned increase in the use of the \"Putonghua\" on local television in Guangdong led to demonstrations on the streets by thousands of Cantonese-speaking citizens. While the use of Standard Chinese is encouraged as the common working language in predominantly Han areas on the mainland, the PRC has been more sensitive to the status of non-Sinitic minority languages, and has generally not discouraged their social use outside of education.\nHong Kong and Macau.\nIn Hong Kong and Macau, which are special administrative regions of the PRC, there is diglossia between Cantonese () as the primary spoken language, alongside a local form of Standard Chinese () used in schools, local government, and formal writing. Written Cantonese may also be used in informal settings such as advertisements, magazines, popular literature, and comics. Mixture of formal and informal written Chinese occurs to various degrees. After the Hong Kong's handover from the United Kingdom and Macau's handover from Portugal, their governments use \"Putonghua\" to communicate with the PRC's Central People's Government. There has been significant effort to promote use of \"Putonghua\" in Hong Kong since the handover, including the training of police and teachers.\nTaiwan.\nStandard Chinese is the official language of Taiwan. Standard Chinese started being widely spoken in Taiwan following the end of the Chinese Civil War in 1949, with the relocation of the Kuomintang (KMT) to the island along with an influx of refugees from the mainland. The Standard Chinese used in Taiwan differs very little from that of mainland China, with differences largely being in technical vocabulary introduced after 1949.\nPrior to 1949, the varieties most commonly spoken by Taiwan's Han population were Taiwanese Hokkien, as well as Hakka to a lesser extent. Much of the Taiwanese Aboriginal population spoke their native Formosan languages. During the period of martial law between 1949 and 1987, the Taiwanese government revived the Mandarin Promotion Council, discouraging or in some cases forbidding the use of Hokkien and other non-standard varieties. This resulted in Standard Chinese replacing Hokkien as the country's lingua franca, and ultimately, a political backlash in the 1990s. Starting in the 2000s during the administration of President Chen Shui-Bian, the Taiwanese government began making efforts to recognize the country's other languages. They began being taught in schools, and their use increased in media, though Standard Chinese remains the country's lingua franca. Chen often used Hokkien in his speeches; later Taiwanese President Lee Teng-hui also openly spoke Hokkien. In an amendment to the Enforcement Rules of the Passport Act () passed on 9 August 2019, Taiwan's Ministry of Foreign Affairs announced that romanized spellings of names in Hoklo, Hakka and Aboriginal languages may be used in Taiwanese passports. Previously, only Mandarin names could be romanized.\nSingapore.\nMandarin is one of the four official languages of Singapore, along with English, Malay, and Tamil. Historically, it was seldom used by the Chinese Singaporean community, which primarily spoke the Southern Chinese languages of Hokkien, Teochew, Cantonese, or Hakka. Standard Singaporean Mandarin is nearly identical to the standards of China and Taiwan, with minor vocabulary differences. It is the Mandarin variant used in education, media, and official settings. Meanwhile, a colloquial form called Singdarin is used in informal daily life and is heavily influenced in terms of both grammar and vocabulary by local languages such as Cantonese, Hokkien, and Malay. Instances of code-switching with English, Hokkien, Cantonese, Malay, or a combination thereof are also common.\nIn Singapore, the government has heavily promoted a \"Speak Mandarin Campaign\" since the late 1970s, with the use of other Chinese varieties in broadcast media being prohibited and their use in any context officially discouraged until recently. This has led to some resentment amongst the older generations, as Singapore's migrant Chinese community is made up almost entirely of people of south Chinese descent. Lee Kuan Yew, the initiator of the campaign, admitted that to most Chinese Singaporeans, Mandarin was a \"stepmother tongue\" rather than a true mother language. Nevertheless, he saw the need for a unified language among the Chinese community not biased in favor of any existing group.\nMalaysia.\nIn Malaysia, Mandarin has been adopted by local Chinese-language schools as the medium of instruction with the standard shared with Singaporean Chinese. Together influenced by the Singaporean Speak Mandarin Campaign and Chinese culture revival movement in the 1980s, Malaysian Chinese started their own promotion of Mandarin too, and similar to Singapore, but to a lesser extent, experienced language shift from other Chinese variants to Mandarin. Today, Mandarin functions as lingua franca among Malaysian Chinese, while Hokkien and Cantonese are still retained in the northern part and central part of Peninsular Malaysia respectively.\nMyanmar.\nIn some regions controlled by insurgent groups in northern Myanmar, Mandarin serves as the lingua franca.\nEducation.\nIn both mainland China and Taiwan, Standard Chinese is taught by immersion starting in elementary school. After the second grade, the entire educational system is in Standard Chinese, except for local language classes that have been taught for a few hours each week in Taiwan starting in the mid-1990s.\nWith an increase in internal migration in China, the official Putonghua Proficiency Test (PSC) has become popular. Employers often require a level of Standard Chinese proficiency from applicants depending on the position, and many university graduates on the mainland take the PSC before looking for a job.\nPhonology.\nThe pronunciation of Standard Chinese is defined as that of the Beijing dialect.\nThe usual unit of analysis is the syllable, consisting of an optional initial consonant, an optional medial glide, a main vowel and an optional coda, and further distinguished by a tone.\nThe palatal initials , and pose a classic problem of phonemic analysis. Since they occur only before high front vowels, they are in complementary distribution with three other series, the dental sibilants, retroflexes and velars, which never occur in this position.\nThe final, which occurs only after dental sibilant and retroflex initials, is a syllabic approximant, prolonging the initial.\nThe rhotacized vowel forms a complete syllable.\nA reduced form of this syllable occurs as a sub-syllabic suffix, spelled \"-r\" in pinyin and often with a diminutive connotation. The suffix modifies the coda of the base syllable in a rhotacizing process called \"erhua\".\nEach full syllable is pronounced with a phonemically distinctive pitch contour. There are four tonal categories, marked in pinyin with diacritics, as in the words (; 'mother'), (; 'hemp'), (; 'horse') and (; 'curse'). The tonal categories also have secondary characteristics. For example, the third tone is long and murmured, whereas the fourth tone is relatively short. Statistically, vowels and tones are of similar importance in the language.\nThere are also weak syllables, including grammatical particles such as the interrogative \"ma\" () and certain syllables in polysyllabic words. These syllables are short, with their pitch determined by the preceding syllable. Such syllables are commonly described as being in the neutral tone.\nRegional accents.\nIt is common for Standard Chinese to be spoken with the speaker's regional accent, depending on factors such as age, level of education, and the need and frequency to speak in official or formal situations.\nDue to evolution and standardization, Mandarin, although based on the Beijing dialect, is no longer synonymous with it. Part of this was due to the standardization to reflect a greater vocabulary scheme and a more archaic and \"proper-sounding\" pronunciation and vocabulary.\nDistinctive features of the Beijing dialect are more extensive use of \"erhua\" in vocabulary items that are left unadorned in descriptions of the standard such as the \"Xiandai Hanyu Cidian\", as well as more neutral tones. An example of standard versus Beijing dialect would be the standard (door) and Beijing .\nWhile the Standard Chinese spoken in Taiwan is nearly identical to that of mainland China, the colloquial form has been heavily influenced by other local languages, especially Taiwanese Hokkien. Notable differences include: the merger of retroflex sounds (zh, ch, sh, r) with the alveolar series (z, c, s), frequent mergers of the \"neutral tone\" with a word's original tone, and absence of \"erhua\" (rhoticization). Code-switching between Mandarin and Taiwanese Hokkien is common, as the majority of the population continues to also speak the latter as a native language.\nThe stereotypical \"southern Chinese\" accent does not distinguish between retroflex and alveolar consonants, pronouncing pinyin \"zh\" [t\u0282], \"ch\" [t\u0282\u02b0], and \"sh\" [\u0282] in the same way as \"z\" [ts], \"c\" [ts\u02b0], and \"s\" [s] respectively. Southern-accented Standard Chinese may also interchange \"l\" and \"n\", final \"n\" and \"ng\", and vowels \"i\" and \"\u00fc\" [y]. Attitudes towards southern accents, particularly the Cantonese accent, range from disdain to admiration.\nGrammar.\nChinese is a strongly analytic language, having almost no inflectional morphemes, and relying on word order and particles to express relationships between the parts of a sentence.\nNouns are not marked for case and rarely marked for number.\nVerbs are not marked for agreement or grammatical tense, but aspect is marked using post-verbal particles.\nThe basic word order is subject\u2013verb\u2013object (SVO), as in English.\nNouns are generally preceded by any modifiers (adjectives, possessives and relative clauses), and verbs also generally follow any modifiers (adverbs, auxiliary verbs and prepositional phrases).\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\nThe predicate can be an intransitive verb, a transitive verb followed by a direct object, a copula (linking verb) () followed by a noun phrase, etc.\nIn predicative use, Chinese adjectives function as stative verbs, forming complete predicates in their own right without a copula. For example,\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\nChinese additionally differs from English in that it forms another kind of sentence by stating a topic and following it by a comment. To do this in English, speakers generally flag the topic of a sentence by prefacing it with \"as for\". For example:\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\nThe time when something happens can be given by an explicit term such as \"yesterday\", by relative terms such as \"formerly\", etc.\nAs in many east Asian languages, classifiers or measure words are required when using numerals, demonstratives and similar quantifiers.\nThere are many different classifiers in the language, and each noun generally has a particular classifier associated with it.\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\nThe general classifier \"ge\" (/) is gradually replacing specific classifiers.\nIn word formation, the language allows for compounds and for reduplication.\nVocabulary.\nMany honorifics used in imperial China are also used in daily conversation in modern Mandarin, such as (\u8ce4; ; '[my] humble') and (\u8cb4; ; '[your] honorable').\nAlthough Chinese speakers make a clear distinction between Standard Chinese and the Beijing dialect, there are aspects of Beijing dialect that have made it into the official standard. Standard Chinese has a T\u2013V distinction between the polite and informal \"you\" that comes from the Beijing dialect, although its use is quite diminished in daily speech. It also distinguishes between \" ('we', including the listener) and \" ('we', not including the listener). In practice, neither distinction is commonly used by most Chinese, at least outside the Beijing area.\nThe following samples are some phrases from the Beijing dialect which are not yet accepted into Standard Chinese:\nThe following samples are some phrases from Beijing dialect which have become accepted as Standard Chinese:\nWriting system.\nStandard Chinese is written with characters corresponding to syllables of the language, most of which represent a morpheme.\nIn most cases, these characters come from those used in Classical Chinese to write cognate morphemes of late Old Chinese, though their pronunciation, and often meaning, has shifted dramatically over two millennia.\nHowever, there are several words, many of them heavily used, which have no classical counterpart or whose etymology is obscure.\nTwo strategies have been used to write such words:\nThe PRC, as well as several other governments and institutions, has promulgated a set of simplified character forms. Under this system, the forms of the words ('here') and ('there') changed from and to and , among many other changes.\nChinese characters were traditionally read from top to bottom, right to left, but in modern usage it is more common to read from left to right.\nExamples.\nArticle 1 of the \"Universal Declaration of Human Rights\" in Standard Chinese:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24658", "revid": "42110591", "url": "https://en.wikipedia.org/wiki?curid=24658", "title": "Premier of Tasmania", "text": "Head of government for the state of Tasmania, Australia\nThe premier of Tasmania is the head of government of the state of the Tasmania, Australia. The premier is the leader of the cabinet of Tasmania, and nominates its ministers for appointment by the governor. The premier is appointed by the governor based on the premier's ability to command confidence within the House of Assembly. To this end, the governor usually appoints the leader of the party that controls a majority of seats within the House of Assembly. However, due to Tasmania's electoral system and proclivity to elect minority governments, the governor can appoint a premier on the basis that confidence is tested in the parliament.\nSince 8 April 2022, the premier of Tasmania has been Jeremy Rockliff, leader of the Liberal Party, which holds 14 of the 35 seats in the House of Assembly. Due to Rockliff not holding a majority since 2023, he has had to negotiate with crossbenchers to form a government. Since the 2024 state election, he has been supported intermittently by the Jacqui Lambie Network, the Greens, the SFF and various independents, including David O'Byrne whom Rockliff offered a ministerial position to. The current cabinet Rockliff leads is the third Rockliff ministry.\nThe premier of Tasmania is the lowest-paid Australian premier, and the second-lowest paid head of government nationwide. Incumbent premier Jeremy Rockliff turned down a 22% pay rise in 2025.\nList of premiers of Tasmania.\nBefore the 1890s, there was no formal party system in Tasmania. Party labels before that time indicate a general tendency only. The current convention of appointing the premier from the House of Assembly did not develop until the late 19th century, with eight premiers appointed from the Legislative Council (the last being Philip Fysh from 1887 to 1892).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24659", "revid": "41195652", "url": "https://en.wikipedia.org/wiki?curid=24659", "title": "Perihelion and aphelion", "text": ""}
{"id": "24660", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=24660", "title": "Perigee", "text": ""}
{"id": "24661", "revid": "525927", "url": "https://en.wikipedia.org/wiki?curid=24661", "title": "Privatization", "text": "Transferring something from the public sphere to the private\nPrivatization (rendered privatisation in British English) can mean several different things, most commonly referring to transitioning something from the public sector into the private sector. It is also sometimes used as a synonym for deregulation when a heavily regulated private company or industry becomes less regulated. Government functions and services may also be privatised (which may also be known as \"franchising\" or \"out-sourcing\"); in this case, private entities are tasked with the implementation of government programs or performance of government services that had previously been the purview of state-run agencies. Some examples include revenue collection, law enforcement, water supply, and prison management.\nAnother definition is that privatization is the sale of a state-owned enterprise or municipally owned corporation to private investors; in this case shares may be traded in the public market for the first time, or for the first time since an enterprise's previous nationalization. This type of privatization can include the demutualization of a mutual organization, cooperative, or public-private partnership in order to form a joint-stock company.\nSeparately, privatization can refer to the purchase of all outstanding shares of a publicly traded company by private equity investors, which is more often called \"going private\". Before and after this process the company is privately owned, but after the buyout its shares are withdrawn from being traded at a public stock exchange.\nEtymology.\nThe term \"privatizing\" first appeared in English, with quotation marks, in the \"New York Times\", in April 1923, in a translation of a German speech referring to the potential for German state railroads to be bought by American companies. In German, the word \"\" has been used since at least the 19th century. Ultimately, the word came to German through French from the Latin .\nThe term \"reprivatization\", again translated directly from German (), was used frequently in the mid-1930s as \"The Economist\" reported on Nazi Germany's sale of nationalized banks back to public shareholders following the 1931 economic crisis.\nThe word became common in the late 1970s and early 1980s as part of UK prime minister Margaret Thatcher's economic policies. She was drawing on the work of the pro-privatization Member of Parliament David Howell, who was himself drawing on the Austrian-American management expert Peter Drucker's 1969 book, \"The Age of Discontinuity\".\nDefinition.\nThe word \"privatization\" may mean different things depending on the context in which it is used. It can mean moving something from the public sphere into the private sphere, but it may also be used to describe something that was always private, but heavily regulated, which becomes less regulated through a process of deregulation. The term may also be used descriptively for something that has always been private, but could be public in other jurisdictions.\nThere are also private entities that may perform public functions. These entities could also be described as privatized. Privatization may mean the government sells state-owned businesses to private interests, but it may also be discussed in the context of the privatization of services or government functions, where private entities are tasked with the implementation of government programs or the performance of government services. Gillian E. Metzger has written that: \"Private entities [in the US] provide a vast array of social services for the government; administer core aspects of government programs; and perform tasks that appear quintessentially governmental, such as promulgating standards or regulating third-party activities.\" Metzger mentions an expansion of privatization that includes health and welfare programs, public education, and prisons.\n\"Privatization\" can also refer to the transfer of something out of other forms of collective or communal ownership besides state ownership, such as occurs in enclosure of manorial land.\nHistory.\nPre-20th century.\nThe history of privatization dates from Ancient Greece, when governments contracted out almost everything to the private sector. In the Roman Republic private individuals and companies performed the majority of services including tax collection (tax farming), army supplies (military contractors), religious sacrifices and construction. However, the Roman Empire also created state-owned enterprises\u2014for example, much of the grain was eventually produced on estates owned by the Emperor. David Parker and David S. Saal suggest that the cost of bureaucracy was one of the reasons for the fall of the Roman Empire.\nPerhaps one of the first ideological movements towards privatization came during China's golden age of the Han dynasty. Taoism came into prominence for the first time at a state level, and it advocated the laissez-faire principle of Wu wei (\u7121\u70ba), literally meaning \"do nothing\". The rulers were counseled by the Taoist clergy that a strong ruler was virtually invisible.\nDuring the Renaissance, most of Europe was still by and large following the feudal economic model. By contrast, the Ming dynasty in China began once more to practice privatization, especially with regards to their manufacturing industries. This was a reversal of the earlier Song dynasty policies, which had themselves overturned earlier policies in favor of more rigorous state control.\nIn Britain, the privatization of common lands is referred to as enclosure (in Scotland as the Lowland Clearances and the Highland Clearances). Significant privatizations of this nature occurred from 1760 to 1820, preceding the Industrial Revolution in that country.\n20th century onwards.\nThe first mass privatization of state property occurred in Nazi Germany between 1933 and 1937: \"It is a fact that the government of the National Socialist Party sold off public ownership in several state-owned firms in the middle of the 1930s. The firms belonged to a wide range of sectors: steel, mining, banking, local public utilities, shipyard, ship-lines, railways, etc. In addition to this, delivery of some public services produced by public administrations prior to the 1930s, especially social services and services related to work, was transferred to the private sector, mainly to several organizations within the Nazi Party.\"\nGreat Britain privatized its steel industry in the 1950s, and the West German government embarked on large-scale privatization, including sale of the majority stake in Volkswagen to small investors in public share offerings in 1961. However, it was in the 1980s under Margaret Thatcher in the United Kingdom and Ronald Reagan in the United States that privatization gained worldwide momentum. Notable privatizations in the UK included Britoil (1982), the radioactive-chemicals company Amersham International (1982), British Telecom (1984), Sealink ferries (1984), British Petroleum (gradually privatized between 1979 and 1987), British Aerospace (1985 to 1987), British Gas (1986), Rolls-Royce (1987), Rover Group (formerly British Leyland, 1988), British Steel Corporation (1988), Girobank (1989), and the regional water authorities of England and Wales (mostly in 1989). After 1979, council house tenants in the UK were given the right to buy their homes at a heavily discounted price; one million had purchased their residences by 1986.\nSuch efforts culminated in 1993 when British Rail was privatized under Thatcher's successor, John Major. British Rail had been formed by prior nationalization of private rail companies. The privatization was controversial, and its impact is still debated today, as doubling of passenger numbers and investment was balanced by an increase in rail subsidy.\nThese privatizations received mixed views from the public and the parliament. Even former Conservative prime minister Harold Macmillan was critical of the policy, likening it to \"selling the family silver\". There were around 3 million shareholders in Britain when Thatcher took office in 1979, but the subsequent sale of state-run firms saw the number of shareholders double by 1985. By the time of her resignation in 1990, there were more than 10 million shareholders in Britain.\nPrivatization in Latin America was extensive in the 1980s and 1990s, as a result of a Western liberal economic policy. Companies providing public services such as water management, transportation, and telecommunications were rapidly sold off to the private sector. In the 1990s, privatization revenue from 18 Latin American countries totaled 6% of gross domestic product. Private investment in infrastructure from 1990 and 2001 reached $360.5 billion, $150 billion more than in the next emerging economy.\nWhile economists generally give favorable evaluations of the impact of privatization in Latin America, opinion polls and public protests across the countries suggest that a large segment of the public is dissatisfied with or have negative views of privatization in the region.\nIn the 1990s, the governments in Eastern and Central Europe engaged in extensive privatization of state-owned enterprises in Eastern and Central Europe and Russia, with assistance from the World Bank, the U.S. Agency for International Development, the German Treuhand, and other governmental and non-governmental organization.\nNippon Telegraph and Telephone's privatization in 1987 involved the largest share offering in financial history at the time. 15 of the world's 20 largest public share offerings have been privatizations of telecoms.\nIn 1988, the perestroika policy of Mikhail Gorbachev started allowing privatization of the centrally planned economy. Large privatization of the Soviet economy occurred over the next few years as the country dissolved. Other Eastern Bloc countries followed suit after the Revolutions of 1989 introduced non-communist governments.\nFreedom House's privatization index, 1998 and 2002&lt;br&gt;\nFreedom House's privatization index rated transition countries from 1 (maximum progress) to 7 (no progress). The table below shows the privatization index for various Eastern European countries in 1998 and 2002:\nThe largest public shares offering in France involved France T\u00e9l\u00e9com.\nEgypt undertook widespread privatization under Hosni Mubarak. Following his overthrow in the 2011 revolution, most of the public began to call for re-nationalization, citing allegations of the privatized firms practicing crony capitalism under the old regime.\nReasons for privatization.\nThere are various reasons why a government may decide to privatize; commonly due to economic reasons. The economic factors that influence a government's decision to privatize assume this will lower government debt. Studies have shown that governments are more likely to privatise with higher public debt, typically because governments do not have the needed time to wait for a return. Another economic factor that influences this area is the resulting efficiency of SOEs once privatised. Commonly, governments aren\u2019t able to provide the required investments required to ensure profitability for various reasons. These factors may lead to a government deciding to privatize.\nForms of privatization.\nThere are several main methods of privatization:\nThe choice of sale method is influenced by the capital market and the political and firm-specific factors. Privatization through the stock market is more likely to be the method used when there is an established capital market capable of absorbing the shares. A market with high liquidity can facilitate the privatization. If the capital markets are insufficiently developed, however, it would be difficult to find enough buyers. The shares may have to be underpriced, and the sales may not raise as much capital as would be justified by the fair value of the company being privatized. Many governments, therefore, elect for listings in more sophisticated markets, for example, Euronext, and the London, New York and Hong Kong stock exchanges.\nGovernments in developing countries and transition countries more often resort to direct asset sales to a few investors, partly because those countries do not yet have a stock market with high capital.\nVoucher privatization occurred mainly in the transition economies in Central and Eastern Europe, such as Russia, Poland, the Czech Republic, and Slovakia. Additionally, privatization from below had made important contribution to economic growth in transition economies.\nIn one study assimilating some of the literature on \"privatization\" that occurred in Russian and Czech Republic transition economies, the authors identified three methods of privatization: \"privatization by sale\", \"mass privatization\", and \"mixed privatization\". Their calculations showed that \"mass privatization\" was the most effective method.\nHowever, in economies \"characterized by shortages\" and maintained by the state bureaucracy, wealth was accumulated and concentrated by \"gray/black market\" operators. Privatizing industries by sale to these individuals did not mean a transition to \"effective private sector owners [of former] state assets\". Rather than mainly participating in a market economy, these individuals could prefer elevating their personal status or prefer accumulating political power. Instead, outside foreign investment led to the efficient conduct of former state assets in the private sector and market economy.\nThrough privatization by direct asset sale or the stock market, bidders compete to offer higher prices, generating more revenue for the state. Voucher privatization, on the other hand, could represent a genuine transfer of assets to the general population, creating a sense of participation and inclusion. A market could be created if the government permits transfer of vouchers among voucher holders.\nSecured borrowing.\nSome privatization transactions can be interpreted as a form of a secured loan and are criticized as a \"particularly noxious form of governmental debt\". In this interpretation, the upfront payment from the privatization sale corresponds to the principal amount of the loan, while the proceeds from the underlying asset correspond to secured interest payments\u2014the transaction can be considered substantively the same as a secured loan, though it is structured as a sale. This interpretation is particularly argued to apply to recent municipal transactions in the United States, particularly for fixed term, such as the 2008 sale of the proceeds from Chicago parking meters for 75 years. It is argued that this is motivated by \"politicians' desires to borrow money surreptitiously\", due to legal restrictions on and political resistance to alternative sources of revenue, viz, raising taxes or issuing debt.\nResults of privatization.\nPrivatization had different outcomes around the world. Results of privatization may vary depending on the privatization model employed. According to Irwin Stelzer, \"it is somewhere between difficult and impossible to separate the effects of privatisation from the effects of such things as trends in the economy\".\nAccording to research performed by the World Bank and William L. Megginson in the early 2000s, privatization in competitive industries with well-informed consumers, consistently improved efficiency. According to APEC, the more competitive the industry, the greater the improvement in output, profitability, and efficiency. Such efficiency gains mean a one-off increase in GDP, but through improved incentives to innovate and reduce costs also tend to raise the rate of economic growth.\nMore recent research and literature review performed by Professor Saul Estrin and Adeline Pelletier concluded that \"the literature now reflects a more cautious and nuanced evaluation of privatization\" and that \"private ownership alone is no longer argued to automatically generate economic gains in developing economies\". According to a 2008 study published in \"Annals of Public and Cooperative Economics\", liberalization and privatization have produced mixed results.\nAlthough typically there are many costs associated with these efficiency gains,\nmany economists argue that these can be dealt with by appropriate government support through redistribution and perhaps retraining. Yet, some empirical literature suggests that privatization could also have very modest effects on efficiency and quite regressive distributive impact. In the first attempt at a social welfare analysis of the British privatization program under the Conservative governments of Margaret Thatcher and John Major during the 1980s and 1990s, Massimo Florio points to the absence of any productivity shock resulting strictly from ownership change. Instead, the impact on the previously nationalized companies of the UK productivity leap under the Conservatives varied in different industries. In some cases, it occurred prior to privatization, and in other cases, it occurred upon privatization or several years afterward.\nA 2012 study published by the European Commission argues that privatisation in Europe had mixed effects on service quality and has achieved only minor productivity gains, driven mainly by lower labour input combined with other cost cutting strategies that led to a deterioration of employment and working conditions. Meanwhile, a different study by the commission found that the UK rail network (which was privatized from 1994 to 1997) was most improved out of all the 27 EU nations from 1997 to 2012. The report examined a range of 14 different factors and the UK came top in four of the factors, second and third in another two and fourth in three, coming top overall. Nonetheless, the impact of the privatisation of British Rail has been the subject of much debate, with the stated benefits including improved customer service, and more investment; and stated drawbacks including higher fares, lower punctuality and increased rail subsidies.\nPrivatizations in Russia and Latin America were accompanied by large-scale corruption during the sale of the state-owned companies. Those with political connections unfairly gained large wealth, which has discredited privatization in these regions. While media have widely reported the grand corruption that accompanied those sales, according to research released by the World Bank there has been increased operating efficiency, daily petty corruption is, or would be, larger without privatization, and that corruption is more prevalent in non-privatized sectors. Furthermore, according to the World Bank extralegal and unofficial activities are more prevalent in countries that privatized less. Other research suggests that privatization in Russia resulted in a dramatic rise in the level of economic inequality and a collapse in GDP and industrial output.\nRussian president Boris Yeltsin's IMF-backed rapid privatization schemes saw half the Russian population fall into destitution in just several years as unemployment climbed to double digits by the early to mid 1990s. A 2009 study published in \"The Lancet\" medical journal has found that as many as a million working men died as a result of economic shocks associated with mass privatization in the former Soviet Union and in Eastern Europe during the 1990s, although a further study suggested that there were errors in their method and \"correlations reported in the original article are simply not robust.\" A subsequent body of scholarship, while still controversial, demonstrates that rapid privatization schemes associated with neoliberal economic reforms did result in poorer health outcomes in former Eastern Bloc countries during the transition to markets economies, with the World Health Organization contributing to the debate by stating \"IMF economic reform programs are associated with significantly worsened tuberculosis incidence, prevalence, and mortality rates in post-communist Eastern European and former Soviet countries.\" Historian Walter Scheidel, a specialist in ancient history, posits that economic inequality and wealth concentration in the top percentile \"had been made possible by the transfer of state assets to private owners.\"\nIn Latin America, on the one hand, according to John Nellis's research for Center for Global Development, economic indicators, including firm profitability, productivity, and growth, project positive microeconomic results. On the other hand, however, privatisation has been largely met with a negative criticism and citizen coalitions. This neoliberal criticism highlights the ongoing conflict between varying visions of economic development. Karl Polanyi emphasizes the societal concerns of self-regulating markets through a concept known as a \"double movement\". In essence, whenever societies move towards increasingly unrestrained, free-market rule, a natural and inevitable societal correction emerges to undermine the contradictions of capitalism. This was the case in the 2000 Cochabamba protests.\nPrivatization in Latin America has invariably experienced increasing push-back from the public. Mary Shirley from The Ronald Coase Institute suggests that implementing a less efficient but more politically mindful approach could be more sustainable.\nIn India, a survey by the National Commission for Protection of Child Rights (NCPCR) \u2013 Utilization of Free Medical Services by Children Belonging to the Economically Weaker Section (EWS) in Private Hospitals in New Delhi, 2011\u201312: A Rapid Appraisal \u2013 indicates under-utilization of the free beds available for EWS category in private hospitals in Delhi, though they were allotted land at subsidized rates.\nIn Australia a \"People's Inquiry into Privatisation\" (2016/17) found that the impact of privatisation on communities was negative. The report from the inquiry \"Taking Back Control\" made a range of recommendations to provide accountability and transparency in the process. The report highlighted privatisation in healthcare, aged care, child care, social services, government departments, electricity, prisons and vocational education featuring the voices of workers, community members and academics.\nSome reports show that the results of privatization are experienced differently between men and women for numerous reasons: when public services are privatized women are expected to take on the health and social care of dependents, women have less access to privatized goods, public sector employs a larger proportion of women than does the private sector, and the women in the public sector are more likely to be unionized than those in the private sector. In Chile, women are disproportionately affected by the privatization of the pension system because factors such as \"women's longer life expectancy, earlier retirement age, and lower rates of labor-force participation, lower salaries\" affect their ability to accumulate funds for retirement which leads to lower pensions. Low-income women face an even greater burden; Anjela Taneja, of Oxfam India says \"The privatization of public services...implies limited or no access to essential services for women living in poverty, who are often the ones more in need of these services.\"\nThe increase in privatization since the 1980s has been a factor in rising income and wealth inequality in the United States.\nForeign privatization.\nDue to low levels of native capital accumulation in the former Central and Eastern Europe, the rapid privatization preferred by international institutions (EBRD, IMF, World Bank) and other foreign banks was a \"de facto\" call for international bidding, reflecting the assumption that foreign investment would play a major role.\nContrasting cases in Eastern Europe: Romania and East Germany.\nIn post-reunification East Germany, by the end of June 1992, the \"Treuhandanstalt\" had privatized 8,175 companies, with 5,950 left on hand (4,340 remaining to be sold and the remainder to be liquidated). June 1992 was also when the last East German on the board of the \"Treuhand\" left. By the end of 1994, \"Treuhand\" had sold almost everything, having only 65 firms left to privatize as of December 1994. More than 80% of the privatized businesses were bought by foreigners (chiefly West Germans \u2013 75%).\nRomania's first privatization took place on 3 August 1992. There was \"very little\" privatization during 1992: only 22 state-owned enterprises were privatized. The pace picked up throughout the following year, with more than 260 companies privatized. Four of the 22 enterprises privatized in 1992 were sold to foreign investors. In 1993, 265 companies were privatized, followed by 604 in 1994. Two companies were sold to foreign investors during this period, one each in 1993 and 1994. At the start of 1999, 4,330 companies were left to be privatized, with 5,476 having been sold during 1993\u20131998. At the end of 1998, only 2.4% of privatized companies had foreign participation.\nOpinion.\nArguments for and against the controversial subject of privatization are presented here.\nSupport.\nProponents of privatization argue that, over time, this can lead to lower prices, improved quality, more choices, less corruption, less red tape, and/or quicker delivery. Many proponents do not argue that everything should be privatized. According to them, market failures and natural monopolies could be problematic. However, anarcho-capitalists prefer that every function of the state be privatized, including defense and dispute resolution.\nProponents of privatization make the following arguments:\nOpposition.\nOpponents of privatization in general\u2014or of certain privatizations in particular\u2014believe that public goods and services should remain primarily in the hands of government in order to ensure that everyone in society has access to them (such as law enforcement, basic health care, and basic education). There is a positive externality when the government provides society at large with public goods and services such as defense and disease control. Some national constitutions in effect define their governments' \"core businesses\" as being the provision of such things as justice, tranquility, defense, and general welfare. These governments' direct provision of security, stability, and safety, is intended to be done for the common good (in the public interest) with a long-term (for posterity) perspective. As for natural monopolies, opponents of privatization claim that they aren't subject to fair competition, and better administrated by the state.\nAlthough private companies may provide a similar good or service alongside the government, opponents of privatization are critical about completely transferring the provision of public goods, services and assets into private hands for the following reasons:\nEconomic theory.\nIn economic theory, privatization has been studied in the field of contract theory. When contracts are complete, institutions such as (private or public) property are difficult to explain, since every desired incentive structure can be achieved with sufficiently complex contractual arrangements, regardless of the institutional structure. All that matters is who are the decision makers and what is their available information. In contrast, when contracts are incomplete, institutions matter. A leading application of the incomplete contract paradigm in the context of privatization is the model by Hart, Shleifer, and Vishny (1997). In their model, a manager can make investments to increase quality (but they may also increase costs) and investments to decrease costs (but they may also reduce quality). It turns out that it depends on the particular situation whether private ownership or public ownership is desirable. The Hart-Shleifer-Vishny model has been further developed in various directions, e.g. to allow for mixed public-private ownership and endogenous assignments of the investment tasks.\nPrivatization of private companies.\nPrivatization can also refer to the purchase of all outstanding shares of a publicly traded private company by private equity investors, which is more often called \"going private\". The buyout withdraws the company's shares from being traded at a public stock exchange. Depending on the involvement of internal and external investors, it may occur through a leveraged buyout or a management buyout, tender offer, or hostile takeover."}
{"id": "24663", "revid": "1315895237", "url": "https://en.wikipedia.org/wiki?curid=24663", "title": "Passage grave", "text": "Type of megalithic tomb\nA passage grave or passage tomb consists of one or more burial chambers covered in earth or stone and having a narrow access passage made of large stones. These structures usually date from the Neolithic Age and are found largely in Western Europe. When covered in earth, a passage grave is a type of burial mound which is found in various forms all over the world. When a passage grave is covered in stone, it is a type of cairn.\nConstruction and design.\nThe building of passage graves was normally carried out with megaliths along with smaller stones. The earliest passage tombs seem to take the form of small dolmens, although not all dolmens are passage graves. The passage itself in a number of notable instances is aligned in such a way that the sun shines through the passage and into the chamber at a significant point in the year, often at sunrise on the winter solstice or at sunset on the equinox. Many later passage tombs were constructed at the tops of hills or mountains, indicating that their builders intended them to be seen from a great distance.\nThe interior of passage graves varies in number of burials, shape, and other aspects. Those with more than one chamber may have multiple sub-chambers leading off from the main burial chamber. One common interior layout, the cruciform passage grave, is cross-shaped, although prior to the Christian Era and thus having no Christian associations. Some passage tombs are covered with a cairn, especially those Passage tombs of the cairn type often have elaborate corbelled roofs rather than simple slabs. Megalithic art has been identified carved into the stones at some sites. Not all passage \"graves\" have been found to contain evidence that they were used for burial. One such example is Maeshowe.\nOrigins and distribution.\nThe passage tomb tradition is believed to have originated in the French region of Brittany. It was introduced to other regions such as Ireland by colonists from Brittany.\nIn a 1961 survey of megalithic tombs in Ireland, Irish scholars Se\u00e1n \u00d3 Nuall\u00e1in and R\u00faaidhr\u00ed de Valera describe four categories of megalithic tombs: court cairns, portal dolmens, wedge-shaped gallery graves, and passage tombs. This appears to be one of the first uses of the term. It is likely that the writers borrowed from the Spanish term \"tumbas de corredor\", \"corridor tombs\", which is used for tombs in Cantabria, Galicia and the Basque Country. Of the megalithic tombs in Ireland, only passage tombs appear to have widespread distribution throughout Europe.\nPassage graves are distributed extensively in lands along the Atlantic seaboard of Europe. They are found in Ireland, Britain, Scandinavia, northern Germany and the Drenthe area of the Netherlands. They are also found in Iberia, some parts of the Mediterranean, and along the northern coast of Africa. In Ireland and Britain, passage tombs are often found in large clusters, giving rise to the term passage tomb cemeteries.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24664", "revid": "11487766", "url": "https://en.wikipedia.org/wiki?curid=24664", "title": "P-group", "text": "Group in which the order of every element is a power of p\nIn mathematics, specifically group theory, given a prime number \"p\", a \"p\"-group is a group in which the order of every element is a power of \"p\". That is, for each element \"g\" of a \"p\"-group \"G\", there exists a nonnegative integer \"n\" such that the product of \"pn\" copies of \"g\", and not fewer, is equal to the identity element. The orders of different elements may be different powers of \"p\".\nAbelian \"p\"-groups are also called \"p\"-primary or simply primary.\nA finite group is a \"p\"-group if and only if its order (the number of its elements) is a power of \"p\". Given a finite group \"G\", the Sylow theorems guarantee the existence of a subgroup of \"G\" of order \"pn\" for every prime power \"pn\" that divides the order of \"G\". \nEvery finite \"p\"-group is nilpotent. \nThe remainder of this article deals with finite \"p\"-groups. For an example of an infinite abelian \"p\"-group, see Pr\u00fcfer group, and for an example of an infinite simple \"p\"-group, see Tarski monster group.\nProperties.\nEvery \"p\"-group is periodic since by definition every element has finite order.\nIf \"p\" is prime and \"G\" is a group of order \"p\"\"k\", then \"G\" has a normal subgroup of order \"p\"\"m\" for every 1 \u2264 \"m\" \u2264 \"k\". This follows by induction, using Cauchy's theorem and the Correspondence Theorem for groups. A proof sketch is as follows: because the center \"Z\" of \"G\" is non-trivial (see below), according to Cauchy's theorem \"Z\" has a subgroup \"H\" of order \"p\". Being central in \"G\", \"H\" is necessarily normal in \"G\". We may now apply the inductive hypothesis to \"G/H\", and the result follows from the Correspondence Theorem.\nNon-trivial center.\nOne of the first standard results using the class equation is that the center of a non-trivial finite \"p\"-group cannot be the trivial subgroup.\nThis forms the basis for many inductive methods in \"p\"-groups.\nFor instance, the normalizer \"N\" of a proper subgroup \"H\" of a finite \"p\"-group \"G\" properly contains \"H\", because for any counterexample with \"H\" = \"N\", the center \"Z\" is contained in \"N\", and so also in \"H\", but then there is a smaller example \"H\"/\"Z\" whose normalizer in \"G\"/\"Z\" is \"N\"/\"Z\" = \"H\"/\"Z\", creating an infinite descent. As a corollary, every finite \"p\"-group is nilpotent.\nIn another direction, every normal subgroup \"N\" of a finite \"p\"-group intersects the center non-trivially as may be proved by considering the elements of \"N\" which are fixed when \"G\" acts on \"N\" by conjugation. Since every central subgroup is normal, it follows that every minimal normal subgroup of a finite \"p\"-group is central and has order \"p\". Indeed, the socle of a finite \"p\"-group is the subgroup of the center consisting of the central elements of order \"p\".\nIf \"G\" is a \"p\"-group, then so is \"G\"/\"Z\", and so it too has a non-trivial center. The preimage in \"G\" of the center of \"G\"/\"Z\" is called the second center and these groups begin the upper central series. Generalizing the earlier comments about the socle, a finite \"p\"-group with order \"pn\" contains normal subgroups of order \"pi\" with 0 \u2264 \"i\" \u2264 \"n\", and any normal subgroup of order \"pi\" is contained in the \"i\"th center \"Z\"\"i\". If a normal subgroup is not contained in \"Z\"\"i\", then its intersection with \"Z\"\"i\"+1 has size at least \"p\"\"i\"+1.\nAutomorphisms.\nThe automorphism groups of \"p\"-groups are well studied. Just as every finite \"p\"-group has a non-trivial center so that the inner automorphism group is a proper quotient of the group, every finite \"p\"-group has a non-trivial outer automorphism group. Every automorphism of \"G\" induces an automorphism on \"G\"/\u03a6(\"G\"), where \u03a6(\"G\") is the Frattini subgroup of \"G\". The quotient G/\u03a6(\"G\") is an elementary abelian group and its automorphism group is a general linear group, so very well understood. The map from the automorphism group of \"G\" into this general linear group has been studied by Burnside, who showed that the kernel of this map is a \"p\"-group. \nExamples.\n\"p\"-groups of the same order are not necessarily isomorphic; for example, the cyclic group \"C\"4 and the Klein four-group \"V\"4 are both 2-groups of order 4, but they are not isomorphic.\nNor need a \"p\"-group be abelian; the dihedral group Dih4 of order 8 is a non-abelian 2-group. However, every group of order \"p\"2 is abelian.\nThe dihedral groups are both very similar to and very dissimilar from the quaternion groups and the semidihedral groups. Together the dihedral, semidihedral, and quaternion groups form the 2-groups of maximal class, that is those groups of order 2\"n\"+1 and nilpotency class \"n\".\nIterated wreath products.\nThe iterated wreath products of cyclic groups of order \"p\" are very important examples of \"p\"-groups. Denote the cyclic group of order \"p\" as \"W\"(1), and the wreath product of \"W\"(\"n\") with \"W\"(1) as \"W\"(\"n\"\u00a0+\u00a01). Then \"W\"(\"n\") is the Sylow \"p\"-subgroup of the symmetric group Sym(\"p\"\"n\"). Maximal \"p\"-subgroups of the general linear group GL(\"n\",Q) are direct products of various \"W\"(\"n\"). It has order \"p\"\"k\" where \"k\"\u00a0=\u00a0(\"p\"\"n\"\u00a0\u2212\u00a01)/(\"p\"\u00a0\u2212\u00a01). It has nilpotency class \"p\"\"n\"\u22121, and its lower central series, upper central series, lower exponent-\"p\" central series, and upper exponent-\"p\" central series are equal. It is generated by its elements of order \"p\", but its exponent is \"p\"\"n\". The second such group, \"W\"(2), is also a \"p\"-group of maximal class, since it has order \"p\"\"p\"+1 and nilpotency class \"p\", but is not a regular \"p\"-group. Since groups of order \"p\"\"p\" are always regular groups, it is also a minimal such example.\nGeneralized dihedral groups.\nWhen \"p\"\u00a0=\u00a02 and \"n\"\u00a0=\u00a02, \"W\"(\"n\") is the dihedral group of order 8, so in some sense \"W\"(\"n\") provides an analogue for the dihedral group for all primes \"p\" when \"n\"\u00a0=\u00a02. However, for higher \"n\" the analogy becomes strained. There is a different family of examples that more closely mimics the dihedral groups of order 2\"n\", but that requires a bit more setup. Let \u03b6 denote a primitive \"p\"th root of unity in the complex numbers, let Z[\u03b6] be the ring of cyclotomic integers generated by it, and let \"P\" be the prime ideal generated by 1\u2212\u03b6. Let \"G\" be a cyclic group of order \"p\" generated by an element \"z\". Form the semidirect product \"E\"(\"p\") of Z[\u03b6] and \"G\" where \"z\" acts as multiplication by \u03b6. The powers \"P\"\"n\" are normal subgroups of \"E\"(\"p\"), and the example groups are \"E\"(\"p\",\"n\")\u00a0=\u00a0\"E\"(\"p\")/\"P\"\"n\". \"E\"(\"p\",\"n\") has order \"p\"\"n\"+1 and nilpotency class \"n\", so is a \"p\"-group of maximal class. When \"p\"\u00a0=\u00a02, \"E\"(2,\"n\") is the dihedral group of order 2\"n\". When \"p\" is odd, both \"W\"(2) and \"E\"(\"p\",\"p\") are irregular groups of maximal class and order \"p\"\"p\"+1, but are not isomorphic.\nUnitriangular matrix groups.\nThe Sylow subgroups of general linear groups are another fundamental family of examples. Let \"V\" be a vector space of dimension \"n\" with basis { \"e\"1, \"e\"2, ..., \"e\"\"n\" } and define \"V\"\"i\" to be the vector space generated by { \"e\"\"i\", \"e\"\"i\"+1, ..., \"e\"\"n\" } for 1 \u2264 \"i\" \u2264 \"n\", and define \"V\"\"i\" = 0 when \"i\" &gt; \"n\". For each 1 \u2264 \"m\" \u2264 \"n\", the set of invertible linear transformations of \"V\" which take each \"V\"\"i\" to \"V\"\"i\"+\"m\" form a subgroup of Aut(\"V\") denoted \"U\"\"m\". If \"V\" is a vector space over Z/\"p\"Z, then \"U\"1 is a Sylow \"p\"-subgroup of Aut(\"V\") = GL(\"n\", \"p\"), and the terms of its lower central series are just the \"U\"\"m\". In terms of matrices, \"U\"\"m\" are those upper triangular matrices with 1s one the diagonal and 0s on the first \"m\"\u22121 superdiagonals. The group \"U\"1 has order \"p\"\"n\"\u00b7(\"n\"\u22121)/2, nilpotency class \"n\", and exponent \"p\"\"k\" where \"k\" is the least integer at least as large as the base \"p\" logarithm of \"n\".\nClassification.\nThe groups of order \"p\"\"n\" for 0 \u2264 \"n\" \u2264 4 were classified early in the history of group theory, and modern work has extended these classifications to groups whose order divides \"p\"7, though the sheer number of families of such groups grows so quickly that further classifications along these lines are judged difficult for the human mind to comprehend. For example, Marshall Hall Jr. and James K. Senior classified groups of order 2\"n\" for \"n\" \u2264 6 in 1964.\nRather than classify the groups by order, Philip Hall proposed using a notion of isoclinism of groups which gathered finite \"p\"-groups into families based on large quotient and subgroups.\nAn entirely different method classifies finite \"p\"-groups by their coclass, that is, the difference between their composition length and their nilpotency class. The so-called coclass conjectures described the set of all finite \"p\"-groups of fixed coclass as perturbations of finitely many pro-p groups. The coclass conjectures were proven in the 1980s using techniques related to Lie algebras and powerful p-groups. The final proofs of the coclass theorems are due to A. Shalev and independently to C. R. Leedham-Green, both in 1994. They admit a classification of finite \"p\"-groups in directed coclass graphs consisting of only finitely many coclass trees whose (infinitely many) members are characterized by finitely many parametrized presentations.\nEvery group of order \"p\"5 is metabelian.\nUp to \"p\"3.\nThe trivial group is the only group of order one, and the cyclic group C\"p\" is the only group of order \"p\". There are exactly two groups of order \"p\"2, both abelian, namely C\"p\"2 and C\"p\"\u00a0\u00d7\u00a0C\"p\". For example, the cyclic group C4 and the Klein four-group \"V\"4 which is C2\u00a0\u00d7\u00a0C2 are both 2-groups of order 4.\nThere are three abelian groups of order \"p\"3, namely C\"p\"3, C\"p\"2\u00a0\u00d7\u00a0C\"p\", and C\"p\"\u00a0\u00d7\u00a0C\"p\"\u00a0\u00d7\u00a0C\"p\". There are also two non-abelian groups.\nFor \"p\"\u00a0\u2260\u00a02, one is a semi-direct product of C\"p\"\u00a0\u00d7\u00a0C\"p\" with C\"p\", and the other is a semi-direct product of C\"p\"2 with C\"p\". The first one can be described in other terms as group UT(3,\"p\") of unitriangular matrices over finite field with \"p\" elements, also called the Heisenberg group mod \"p\".\nFor \"p\"\u00a0=\u00a02, both the semi-direct products mentioned above are isomorphic to the dihedral group Dih4 of order 8. The other non-abelian group of order 8 is the quaternion group Q8.\nPrevalence.\nAmong groups.\nThe Higman\u2013Sims asymptotic formula states that the number of isomorphism classes of groups of order \"pn\" grows as formula_1, and these are dominated by the classes that are two-step nilpotent. Because of this rapid growth, there is a folklore conjecture asserting that almost all finite groups are 2-groups: the fraction of isomorphism classes of 2-groups among isomorphism classes of groups of order at most \"n\" is thought to tend to 1 as \"n\" tends to infinity. For instance, of the 49 910 529 484 different groups of order at most 2000, , or just over 99%, are 2-groups of order 1024.\nWithin a group.\nEvery finite group whose order is divisible by \"p\" contains a subgroup which is a non-trivial \"p\"-group, namely a cyclic group of order \"p\" generated by an element of order \"p\" obtained from Cauchy's theorem. In fact, it contains a \"p\"-group of maximal possible order: if formula_2 where \"p\" does not divide \"m,\" then \"G\" has a subgroup \"P\" of order formula_3 called a Sylow \"p\"-subgroup. This subgroup need not be unique, but any subgroups of this order are conjugate, and any \"p\"-subgroup of \"G\" is contained in a Sylow \"p\"-subgroup. This and other properties are proved in the Sylow theorems.\nApplication to structure of a group.\n\"p\"-groups are fundamental tools in understanding the structure of groups and in the classification of finite simple groups. \"p\"-groups arise both as subgroups and as quotient groups. As subgroups, for a given prime \"p\" one has the Sylow \"p\"-subgroups \"P\" (largest \"p\"-subgroup not unique but all conjugate) and the \"p\"-core formula_4 (the unique largest \"normal\" \"p\"-subgroup), and various others. As quotients, the largest \"p\"-group quotient is the quotient of \"G\" by the \"p\"-residual subgroup formula_5 These groups are related (for different primes), possess important properties such as the focal subgroup theorem, and allow one to determine many aspects of the structure of the group.\nLocal control.\nMuch of the structure of a finite group is carried in the structure of its so-called local subgroups, the normalizers of non-identity \"p\"-subgroups.\nThe large elementary abelian subgroups of a finite group exert control over the group that was used in the proof of the Feit\u2013Thompson theorem. Certain central extensions of elementary abelian groups called extraspecial groups help describe the structure of groups as acting on symplectic vector spaces.\nRichard Brauer classified all groups whose Sylow 2-subgroups are the direct product of two cyclic groups of order 4, and John Walter, Daniel Gorenstein, Helmut Bender, Michio Suzuki, George Glauberman, and others classified those simple groups whose Sylow 2-subgroups were abelian, dihedral, semidihedral, or quaternion.\nFootnotes.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24666", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=24666", "title": "Pope Innocent XII", "text": "Head of the Catholic Church from 1691 to 1700\nPope Innocent XII (; ; 13 March 1615\u00a0\u2013 27 September 1700), born Antonio Pignatelli, was head of the Catholic Church and ruler of the Papal States from 12 July 1691 until his death in September 1700.\nHe took a hard stance against nepotism in the Church, continuing the policies of Pope Innocent XI, who started the battle against nepotism but which did not gain traction under Pope Alexander VIII. To that end, he issued a papal bull strictly forbidding it. The pope also used this bull to ensure that no revenue or land could be bestowed on relatives.\nBiography.\nEarly life.\nAntonio Pignatelli was born on 13 March 1615 in Spinazzola (now in Apulia) to one of the most aristocratic families of the Kingdom of Naples, which had included several Viceroys and ministers of the crown. He was the fourth of five children of Francesco Pignatelli, 4th Marquess of Spinazzola, and wife Porzia Carafa, 1st Princess of Minervino. His siblings were Marzio, Ludovico, Fabrizio and Paola Maria. His mother was related to Pope Paul IV.\nHe was educated at the Collegio Romano in Rome where he earned a doctorate in both canon and civil law.\nDiplomatic career.\nAt the age of 20 he became an official of the court of Pope Urban VIII. Pignatelli was the Referendary of the Apostolic Signatura and served as the governor of Fano and Viterbo. Later he went to Malta where he served as an inquisitor from 1646 to 1649, and then governor of Perugia. Shortly after this, he received his priestly ordination.\nEpiscopate and cardinalate.\nPignatelli was made Titular Archbishop of Larissa in 1652 and received episcopal consecration in Rome. He served as the Apostolic Nuncio to Poland from 1660 to 1668 and later to Austria from 1668 to 1671. He was transferred to Lecce in 1671. Pope Innocent XI appointed him as the Cardinal-Priest of San Pancrazio in 1681 and then moved him to the see of Faenza in 1682. He was moved to his final post before the papacy, as Archbishop of Naples in 1686.\nPapacy.\nPapal election.\nPope Alexander VIII died in 1691 and the College of Cardinals assembled to hold a conclave to select his successor. Factions loyal to the Kingdom of France, Spain and the broader Holy Roman Empire failed to agree on a consensus candidate.\nAfter five months, Cardinal Pignatelli emerged as a compromise candidate between the cardinals of France and those of the Holy Roman Empire, particularly after Cardinal Gregorio Barbarigo was no longer considered a viable candidate for the papacy. Having received 53 out of 61 votes, Pignatelli took his new name in honour of Pope Innocent XI and was crowned on 15 July 1691 by the protodeacon, Cardinal Urbano Sacchetti. He took possession of the Basilica of Saint John Lateran on 13 April 1692.\nActions.\nImmediately after his election on 12 July 1691, Innocent XII declared his opposition to the nepotism which had afflicted the reigns of previous popes. The following year he issued the papal bull, \"Romanum decet Pontificem\", banning the curial office of the Cardinal-Nephew and prohibiting popes from bestowing estates, offices, or revenues on any relative. Further, only one relative (and only \"if otherwise suitable\") was to be raised to the cardinalate.\nAt the same time he sought to check the simony in the practices of the Apostolic Chamber and to that end introduced a simpler and more economical manner of life into his court. Innocent XII said that \"the poor were his nephews\" and compared his public beneficence to the nepotism of many predecessors.\nThat same year he invited Marcello Malpighi to Rome to serve as his personal physician and offered him the position of Professor of Medicine at the Sapienza University of Rome. Malpighi introduced his Roman colleagues to the use of the microscope. \nInnocent XII also introduced various reforms into the States of the Church including the \"Forum Innocentianum\", designed to improve the administration of justice dispensed by the Church. In 1693 he compelled French bishops to retract the four propositions relating to the Gallican Liberties which had been formulated by the assembly of 1682.\nIn 1699, he decided in favour of Jacques-Benigne Bossuet in that prelate's controversy with F\u00e9nelon about the \"Explication des Maximes des Saints sur la Vie Int\u00e9rieure\" of the latter. Innocent XII's pontificate also differed greatly from his predecessors' because of his leanings towards France instead of the Habsburg monarchy; the first in the 20 years following France's failure to have its candidate elected in 1644 and 1655.\nConsistories.\nInnocent XII created 30 cardinals in four consistories; two of those he elevated were those he reserved \"in pectore\".\nCanonizations and beatifications.\nInnocent XII canonized Saint Zita of Lucca on 5 September 1696. He beatified Augustin Ka\u017eoti\u0107 on 17 July 1700 and approved the cultus of Angela of Foligno in 1693. He also beatified Osanna Andreasi on 24 November 1694, Mary de Cervellione on 13 February 1692, Jane of Portugal on 31 December 1692, Umiliana de' Cerchi on 24 July 1694, Helen Enselmini on 29 October 1695, and Delphine of Gland\u00e8ves in 1694.\nDeath.\nInnocent XII was already considerably ill on 25 December 1699 with gout (a rheumatic disease) and was therefore unable to attend the solemn opening of the Holy Door at Saint Peter's Basilica to mark the beginning of the Jubilee for 1700, hence, Cardinal Emmanuel-Th\u00e9odose de La Tour d'Auvergne represented the pontiff in the solemn celebration. On Easter Sunday in 1700, the seriously ill pontiff gave a blessing from his balcony to the large crowds outside of the Quirinal Palace. Despite his illness, he named three new cardinals in June 1700.\nInnocent died on 27 September 1700 and was succeeded in the next conclave by Pope Clement XI (1700\u201321). His tomb in Saint Peter's Basilica was sculpted by Filippo della Valle. Innocent is the most recent pope to not be clean shaven.\nIn fiction.\nInnocent appears as one of the narrators in Robert Browning's long poem \"The Ring and the Book\" (1869), based on the true story of the pope's intervention in a historical murder trial in Rome during his papacy.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24667", "revid": "43744280", "url": "https://en.wikipedia.org/wiki?curid=24667", "title": "Protein phosphatase", "text": "Class of enzymes\nA protein phosphatase is a phosphatase enzyme that removes a phosphate group from the phosphorylated amino acid residue of its substrate protein. Protein phosphorylation is one of the most common forms of reversible protein posttranslational modification (PTM), with up to 30% of all proteins being phosphorylated at any given time. Protein kinases (PKs) are the effectors of phosphorylation and catalyse the transfer of a \u03b3-phosphate from ATP to specific amino acids on proteins. Several hundred PKs exist in mammals and are classified into distinct super-families. Proteins are phosphorylated predominantly on Ser, Thr and Tyr residues, which account for 79.3, 16.9 and 3.8% respectively of the phosphoproteome, at least in mammals. In contrast, protein phosphatases (PPs) are the primary effectors of dephosphorylation and can be grouped into three main classes based on sequence, structure and catalytic function. The largest class of PPs is the phosphoprotein phosphatase (PPP) family comprising PP1, PP2A, PP2B, PP4, PP5, PP6 and PP7, and the protein phosphatase Mg2+- or Mn2+-dependent (PPM) family, composed primarily of PP2C. The protein Tyr phosphatase (PTP) super-family forms the second group, and the aspartate-based protein phosphatases the third. The protein pseudophosphatases form part of the larger phosphatase family, and in most cases are thought to be catalytically inert, instead functioning as phosphate-binding proteins, integrators of signalling or subcellular traps. Examples of membrane-spanning protein phosphatases containing both active (phosphatase) and inactive (pseudophosphatase) domains linked in tandem are known, conceptually similar to the kinase and pseudokinase domain polypeptide structure of the JAK pseudokinases. A complete comparative analysis of human phosphatases and pseudophosphatases has been completed by Manning and colleagues, forming a companion piece to the ground-breaking analysis of the human kinome, which encodes the complete set of ~536 human protein kinases.\nMechanism.\nPhosphorylation involves the transfer of phosphate groups from ATP to the enzyme, the energy for which comes from hydrolysing ATP into ADP or AMP. However, dephosphorylation releases phosphates into solution as free ions, because attaching them back to ATP would require energy input.\nCysteine-dependent phosphatases (CDPs) catalyse the hydrolysis of a phosphoester bond via a phospho-cysteine intermediate.\nThe free cysteine nucleophile forms a bond with the phosphorus atom of the phosphate moiety, and the P-O bond linking the phosphate group to the tyrosine is protonated, either by a suitably positioned acidic amino acid residue (Asp in the diagram below) or a water molecule. The phospho-cysteine intermediate is then hydrolysed by another water molecule, thus regenerating the active site for another dephosphorylation reaction.\nMetallo-phosphatases (e.g. PP2C) co-ordinate 2 catalytically essential metal ions within their active site. There is currently some confusion of the identity of these metal ions, as successive attempts to identify them yield different answers. There is currently evidence that these metals could be magnesium, manganese, iron, zinc, or any combination thereof. It is thought that a hydroxyl ion bridging the two metal ions takes part in nucleophilic attack on the phosphorus ion.\nSub-types.\nPhosphatases can be subdivided based upon their substrate specificity. \nSerine/threonine PP (PPM/PPP) families.\nProtein Ser/Thr phosphatases were originally classified using biochemical assays as either, type 1 (PP1) or type 2 (PP2), and were further subdivided based on metal-ion requirement (PP2A, no metal ion; PP2B, Ca2+ stimulated; PP2C, Mg2+ dependent) (Moorhead et al., 2007). The protein Ser/Thr phosphatases PP1, PP2A and PP2B of the PPP family, together with PP2C of the PPM family, account for the majority of Ser/Thr PP activity in vivo (Barford et al., 1998). In the brain, they are present in different subcellular compartments in neuronal and glial cells, and contribute to different neuronal functions.\nPPM.\nThe PPM family, which includes PP2C and pyruvate dehydrogenase phosphatase, are enzymes with Mn2+/Mg2+ metal ions that are resistant to classic inhibitors and toxins of the PPP family. Unlike most PPPs, PP2C exists in only one subunit but, like PTPs, it displays a wide variety of structural domains that confer unique functions. In addition, PP2C does not seem to be evolutionarily related to the major family of Ser/Thr PPs and has no sequence homology to ancient PPP enzymes. The current assumption is that PPMs evolved separately from PPPs but converged during evolutionary development.\nClass I: Cys-based PTPs.\nClass I PTPs constitute the largest family. They contain the well-known classical receptor (a) and non-receptor PTPs (b), which are strictly tyrosine-specific, and the DSPs (c) which target Ser/Thr as well as Tyr and are the most diverse in terms of substrate specificity.\nClass III: Cys-based PTPs.\nThe third class of PTPs contains three cell cycle regulators, CDC25A, CDC25B and CDC25C, which dephosphorylate CDKs at their N-terminal, a reaction required to drive progression of the cell cycle. They are themselves regulated by phosphorylation and are degraded in response to DNA damage to prevent chromosomal abnormalities.\nClass IV: Asp-based DSPs.\nThe haloacid dehalogenase (HAD) superfamily is a further PP group that uses Asp as a nucleophile and was recently shown to have dual-specificity. These PPs can target both Ser and Tyr, but are thought to have greater specificity towards Tyr. A subfamily of HADs, the Eyes Absent Family (Eya), are also transcription factors and can therefore regulate their own phosphorylation and that of transcriptional cofactor/s, and contribute to the control of gene transcription. The combination of these two functions in Eya reveals a greater complexity of transcriptional gene control than previously thought . A further member of this class is the RNA polymerase II C-terminal domain phosphatase. While this family remains poorly understood, it is known to play important roles in development and nuclear morphology.\nAlternative Structural Classification.\nMany phosphatases are promiscuous with respect to substrate type, or can evolve quickly to change substrate. An alternative structural classification notes that 20 distinct protein folds have phosphatase activity, and 10 of these contain protein phosphatases.\nPhysiological relevance.\nPhosphatases act in opposition to kinases/phosphorylases, which add phosphate groups to proteins. The addition of a phosphate group may activate or de-activate an enzyme (e.g., kinase signalling pathways) or enable a protein-protein interaction to occur (e.g., SH2 domains ); therefore phosphatases are integral to many signal transduction pathways. Phosphate addition and removal do not necessarily correspond to enzyme activation or inhibition, and that several enzymes have separate phosphorylation sites for activating or inhibiting functional regulation. CDK, for example, can be either activated or deactivated depending on the specific amino acid residue being phosphorylated. Phosphates are important in signal transduction because they regulate the proteins to which they are attached. To reverse the regulatory effect, the phosphate is removed. This occurs on its own by hydrolysis, or is mediated by protein phosphatases.\nProtein phosphorylation plays a crucial role in biological functions and controls nearly every cellular process, including metabolism, gene transcription and translation, cell-cycle progression, cytoskeletal rearrangement, protein-protein interactions, protein stability, cell movement, and apoptosis. These processes depend on the highly regulated and opposing actions of PKs and PPs, through changes in the phosphorylation of key proteins. Histone phosphorylation, along with methylation, ubiquitination, sumoylation and acetylation, also regulates access to DNA through chromatin reorganisation.\nOne of the major switches for neuronal activity is the activation of PKs and PPs by elevated intracellular calcium. The degree of activation of the various isoforms of PKs and PPs is controlled by their individual sensitivities to calcium. Furthermore, a wide range of specific inhibitors and targeting partners such as scaffolding, anchoring, and adaptor proteins also contribute to the control of PKs and PPs and recruit them into signalling complexes in neuronal cells. Such signalling complexes typically act to bring PKs and PPs in close proximity with target substrates and signalling molecules as well as enhance their selectivity by restricting accessibility to these substrate proteins. Phosphorylation events, therefore, are controlled not only by the balanced activity of PKs and PPs but also by their restricted localisation. Regulatory subunits and domains serve to restrict specific proteins to particular subcellular compartments and to modulate protein specificity. These regulators are essential for maintaining the coordinated action of signalling cascades, which in neuronal cells include short-term (synaptic) and long-term (nuclear) signalling. These functions are, in part, controlled by allosteric modification by secondary messengers and reversible protein phosphorylation.\nIt is thought that around 30% of known PPs are present in all tissues, with the rest showing some level of tissue restriction. While protein phosphorylation is a cell-wide regulatory mechanism, recent quantitative proteomics studies have shown that phosphorylation preferentially targets nuclear proteins. Many PPs that regulate nuclear events, are often enriched or exclusively present in the nucleus. In neuronal cells, PPs are present in multiple cellular compartments and play a critical role at both pre- and post-synapses, in the cytoplasm and in the nucleus where they regulate gene expression.\nPhosphoprotein phosphatase is activated by the hormone insulin, which indicates that there is a high concentration of glucose in the blood. The enzyme then acts to dephosphorylate other enzymes, such as phosphorylase kinase, glycogen phosphorylase, and glycogen synthase. This leads to phosphorylase kinase and glycogen phosphorylase's becoming inactive, while glycogen synthase is activated. As a result, glycogen synthesis is increased and glycogenolysis is decreased, and the net effect is for energy to enter and be stored inside the cell.\nLearning and memory.\nIn the adult brain, PPs are essential for synaptic functions and are involved in the negative regulation of higher-order brain functions such as learning and memory. Dysregulation of their activity has been linked to several disorders including cognitive ageing and neurodegeneration, as well as cancer, diabetes and obesity.\nExamples.\nHuman genes that encode proteins with phosphoprotein phosphatase activity include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24668", "revid": "17782002", "url": "https://en.wikipedia.org/wiki?curid=24668", "title": "Pentium (original)", "text": "Intel microprocessor\nThe Pentium (also referred to as the i586 or P5 Pentium) is a microprocessor introduced by Intel on March 22, 1993. It is the first CPU using the Pentium brand.\nConsidered the fifth generation in the x86 (8086) compatible line of processors, succeeding the i486, its implementation and microarchitecture was internally called \"P5\".\nLike the Intel i486, the Pentium is instruction set compatible with the 32-bit i386. It uses a very similar microarchitecture to the i486, but was extended enough to implement a dual integer pipeline design, as well as a more advanced floating-point unit (FPU) that was noted to be ten times faster than its predecessor.\nThe Pentium was succeeded by the Pentium Pro in November 1995. In October 1996, the Pentium MMX was introduced, complementing the same basic microarchitecture of the original Pentium with the MMX instruction set, larger caches, and some other enhancements. Intel discontinued the original Pentium (P5) processors, which were sold as a lower-cost option after the Pentium II's release in 1997, on December 31, 2001. This coincided with Microsoft ending support for classic versions of Windows such as Windows 95. The Pentium line was gradually replaced by the Celeron processor, which also took over the role of the 80486 brand.\nOverview.\nThe P5 Pentium is the first superscalar x86 processor, meaning it was often able to execute two instructions at the same time. Some techniques used to implement this were based on the earlier superscalar Intel i960 CA (1989), while other details were invented exclusively for the P5 design. Large parts were also copied from the i386 or i486, especially the strategies used to cope with the complicated x86 encodings in a pipelined fashion. Just like the i486, the Pentium used both an optimized microcode system and RISC-like techniques, depending on the particular instruction, or part of instruction. The dual integer pipeline design is something that had been argued being impossible to implement for a CISC instruction set, by certain academics and RISC competitors.\nOther central features include a redesigned and significantly faster floating-point unit, a wide 64-bit burst-mode data bus (external as well as internal), separate code and data caches, and many other techniques and features to enhance performance. It contains 256-bit internal data buses and write-back caches. It does contain System Management Mode that has been implemented since the Intel's SL architecture.\nThe 66-MHz Pentium processor operates at 112 V1.1 Dhrystone MIPS and has SPECint92 rating of 64.5, a SPECfp92 rating of 56.9 and an iCOMP index rating of 567. The performance difference between 60- and 66-MHz version is about 10%.\nThe P5 also has better support for multiprocessing compared to the i486, and is the first x86 CPU with hardware support for it similar to IBM mainframe computers. Intel worked with IBM to define this ability and also designed it into the P5 microarchitecture. This ability was absent in prior x86 generations and x86 processors from competitors.\nIn order to employ the dual pipelines at their full potential, certain compilers were optimized to better exploit instruction level parallelism, although not all applications would substantially gain from being recompiled. The faster FPU always enhanced floating point performance significantly though, compared to the i486 or i387. Intel spent resources working with development tool vendors, ISVs and operating system (OS) companies to optimize their products.\nCompetitors included the superscalar PowerPC 601 (1993), SuperSPARC (1992), DEC Alpha 21064 (1992), AMD 29050 (1990), Motorola MC88110 (1991) and Motorola 68060 (1994), most of which also used a superscalar in-order dual instruction pipeline configuration, and the non-superscalar Motorola 68040 (1990) and MIPS R4000 (1991).\nEtymology.\nThe name \"Pentium\" is originally derived from the Greek word \"pente\" (\"\u03c0\u03ad\u03bd\u03c4\u03b5\"), meaning \"five\", a reference to the prior numeric naming convention of Intel's 80x86 processors (8086\u201380486), with the Latin ending \"-ium\" since the processor would otherwise have been named 80586 using that convention.\nDevelopment.\nThe P5 microarchitecture was designed by the same Santa Clara team which designed the 386 and 486. Design work started in June 1989;88 the team decided to use a superscalar RISC architecture which would be a convergence of RISC and CISC technology, with on-chip cache, floating-point, and branch prediction. Vinod Dham then the Vice President of the Microprocessor Product Group and General Manager of Microprocessor Division 5/7 had the concept using this RISC technology into the existing x86 architecture that could compete from the other market. Their performance target could boost FPU by three times and five time over the existing Intel486 CPU. The preliminary design was first successfully simulated in 1990, followed by the laying-out of the design. By this time, the team had several dozen engineers. It took some 100 million clock cycles of pre-silicon verification test which includes major operating systems and many application were booted and running. They had to use the Quickturn Systems Inc. software to run pre-silicon simulation program which was 30,000 times quicker than the previous technique method available. By late 1990, they found that the planned feature could not fit into the die, they had to redesign the circuit feature that would slim down in order to fit what the intended design in place without sacrificing the performance. In spring of 1991, the die went another slimming procedure until Dham was happy with the size and its feature without affecting the performance. A group of engineers ran hundreds of tests to validate the designed features and ran 5000 different variables to validate its design. Out of the 14 circuit boards in collection and cables, they only found few bugs using every operating system they have it on hand including in development were used. By February 1992, the design was taped out in process which was completed by April 1992, at which point beta-testing began. The next few months the design was sent to the Intel's Mask Operation which it translate to mask layout for the Oregon's Fab 5 to be processed. By mid-1992, the P5 team had 200 engineers.89 Intel at first planned to demonstrate the P5 in June 1992 at the trade show PC Expo, and to formally announce the processor in September 1992, but design problems forced the demo to be cancelled, and the official introduction of the chip was delayed until the spring of 1993. The first computer systems featuring the Pentium appeared in the summer of 1993, the first being Advanced Logic Research and their Evolution V workstation, released in the first week of July 1993.\nJohn H. Crawford, chief architect of the original 386, co-managed the design of the P5, along with Donald Alpert, who managed the architectural team. Dror Avnon managed the design of the FPU. Vinod K. Dham was general manager of the P5 group.90\nIntel's Larrabee multicore architecture project uses a processor core derived from a P5 core (P54C), augmented by multithreading, 64-bit instructions, and a 16-byte wide vector processing unit. Intel's low-powered Bonnell microarchitecture employed in early Atom processor cores also uses an in-order dual pipeline similar to P5.\nIntel used the Pentium name instead of 586, because in 1991, it had lost a trademark dispute over the \"386\" trademark, when a judge ruled that the number was generic. The company hired Lexicon Branding to come up with a new, non-numeric name.\nImprovements over the i486.\nThe P5 microarchitecture brings several important advances over the prior i486 architecture.\nThe Pentium was designed to execute over 100\u00a0million instructions per second (MIPS), and the 75\u00a0MHz model was able to reach 126.5 MIPS in certain benchmarks. The Pentium architecture typically offered just under twice the performance of a 486 processor per clock cycle in common benchmarks. The fastest 80486 parts (with slightly improved microarchitecture and 100\u00a0MHz operation) were almost as powerful as the first-generation Pentiums, and the AMD Am5x86, which despite its name is actually a 486-class CPU, was roughly equal to the Pentium 75 regarding pure ALU performance.\nErrata.\nThe early versions of 60\u201366\u00a0MHz P5 Pentiums had a problem in the floating-point unit that resulted in incorrect (but predictable) results from some division operations. This flaw, discovered in 1994 by professor Thomas Nicely at Lynchburg College, Virginia, became widely known as the Pentium FDIV bug and caused embarrassment for Intel, which created an exchange program to replace the faulty processors.\nIn 1997, another erratum was discovered that could allow a malicious program to crash a system without any special privileges, the \"F00F bug\". All P5 series processors were affected and no fixed steppings were ever released, however contemporary operating systems were patched with workarounds to prevent crashes.\nCores and steppings.\nThe Pentium was Intel's primary microprocessor for personal computers during the mid-1990s. The original design was reimplemented in newer processes and new features were added to maintain its competitiveness, and to address specific markets such as portable computers. As a result, there were several variants of the P5 microarchitecture.\nP5.\nThe first Pentium microprocessor core was code-named \"P5\". Its product code was 80501 (80500 for the earliest steppings Q0399). There were two versions, specified to operate at 60\u00a0MHz and 66\u00a0MHz respectively, using Socket 4. This first implementation of the Pentium was released using a 273-pin PGA form factor and ran on a 5 V power supply. (descended from the usual transistor-transistor logic (TTL) compatibility requirements). It contained 3.1 million transistors and measured 16.7\u00a0mm by 17.6\u00a0mm for an area of 293.92\u00a0mm2. It was fabricated in a 800\u00a0nm three-layer metal bipolar complementary metal\u2013oxide\u2013semiconductor (BiCMOS) process. The 5-volt design resulted in relatively high energy consumption for its operating frequency when compared to the directly following models.\nP54C.\nThe P5 was followed by the P54C (80502) in 1994, with versions specified to operate at 75, 90, or 100\u00a0MHz using a 3.3 volt power supply. Marking the switch to Socket 5, this was the first Pentium processor to operate at 3.3 volts, reducing energy consumption, but necessitating voltage regulation on mainboards. As with higher-clocked 486 processors, an internal clock multiplier was employed from here on to let the internal circuitry work at a higher frequency than the external address and data buses, as it is more complicated and cumbersome to increase the external frequency, due to physical constraints. It also allowed two-way multiprocessing, and had an integrated local APIC and new power management features. It contained 3.3 million transistors and measured 163\u00a0mm2. It was fabricated in a BiCMOS process which has been described as both 500\u00a0nm and 600 nm due to differing definitions.\nP54CQS.\nThe P54C was followed by the P54CQS in early 1995, which operated at 120\u00a0MHz. It was fabricated in a 350\u00a0nm BiCMOS process and was the first commercial microprocessor to be fabricated in a 350\u00a0nm process. Its transistor count is identical to the P54C and, despite the newer process, it had an identical die area as well. The chip was connected to the package using wire bonding, which only allows connections along the edges of the chip. A smaller chip would have required a redesign of the package, as there is a limit on the length of the wires and the edges of the chip would be further away from the pads on the package. The solution was to keep the chip the same size, retain the existing pad-ring, and only reduce the size of the Pentium's logic circuitry to enable it to achieve higher clock frequencies.\nP54CS.\nThe P54CQS was quickly followed by the P54CS, which operated at 133, 150, 166 and 200\u00a0MHz, and introduced Socket 7. It contained 3.3 million transistors, measured 90\u00a0mm2 and was fabricated in a 350\u00a0nm BiCMOS process with four levels of interconnect.\nP24T.\nThe P24T Pentium OverDrive for 486 systems were released in 1995, which were based on 3.3\u00a0V 600\u00a0nm versions using a 63 or 83\u00a0MHz clock. Since these used Socket 2/3, some modifications had to be made to compensate for the 32-bit data bus and slower on-board L2 cache of 486 motherboards. They were therefore equipped with a 32\u00a0KB L1 cache (double that of pre-P55C Pentium CPUs).\nP55C.\nThe P55C (or 80503) was developed by Intel's Research &amp; Development Center in Haifa, Israel. It was sold as Pentium with MMX Technology (usually just called Pentium MMX); although it was based on the P5 core, it featured a new set of 57 \"MMX\" instructions intended to improve performance on multimedia tasks, such as encoding and decoding digital media data. The Pentium MMX line was introduced on October 22, 1996, and released in January 1997.\nThe new instructions worked on new data types: 64-bit packed vectors of either eight 8-bit integers, four 16-bit integers, two 32-bit integers, or one 64-bit integer. So, for example, the PADDUSB (Packed ADD Unsigned Saturated Byte) instruction adds two vectors, each containing eight 8-bit unsigned integers together, elementwise; each addition that would overflow \"saturates\", yielding 255, the maximal unsigned value that can be represented in a byte. These rather specialized instructions generally require special coding by the programmer for them to be used.\nOther changes to the core include a 6-stage pipeline (vs. 5 on P5) with a return stack (first done on Cyrix 6x86) and better parallelism, an improved instruction decoder, 16KB L1 data cache + 16KB L1 instruction cache with Both 4-way associativity (vs. 8KB L1 Data/instruction with 2-way on P5), 4 write buffers that could now be used by either pipeline (vs. one corresponding to each pipeline on P5) and an improved branch predictor taken from the Pentium Pro, with a 512-entry buffer (vs. 256 on P5).\nIt contained 4.5 million transistors and had an area of 140\u00a0mm2. It was fabricated in a 280\u00a0nm CMOS process with the same metal pitches as the previous 350\u00a0nm BiCMOS process, so Intel described it as \"350\u00a0nm\" because of its similar transistor density. The process has four levels of interconnect.\nWhile the P55C remained compatible with Socket 7, the voltage requirements for powering the chip differ from the standard Socket 7 specifications. Most motherboards manufactured for Socket 7 before the establishment of the P55C standard are not compliant with the dual voltage rail required for proper operation of this CPU (2.8 volt core voltage, 3.3 volt input/output (I/O) voltage). Intel addressed the issue with OverDrive upgrade kits that featured an interposer with its own voltage regulation.\nTillamook.\nPentium MMX notebook CPUs used a \"mobile module\" that held the CPU. This module was a printed circuit board (PCB) with the CPU directly attached to it in a smaller form factor. The module snapped to the notebook motherboard, and typically a heat spreader was installed and made contact with the module. However, with the 250\u00a0nm \"Tillamook\" Mobile Pentium MMX (named after a city in Oregon), the module also held the 430TX chipset along with the system's 512 KB static random-access memory (SRAM) cache memory.\nCompetitors.\nAfter the introduction of the Pentium, competitors such as NexGen, AMD, Cyrix, and Texas Instruments announced Pentium-compatible processors in 1994. \"CIO magazine\" identified NexGen's Nx586 as the first Pentium-compatible CPU, while \"PC Magazine\" described the Cyrix 6x86 as the first. These were followed by the AMD K5, which was delayed due to design difficulties. AMD later bought NexGen to help design the AMD K6, and Cyrix was bought by National Semiconductor. Later processors from AMD and Intel retain compatibility with the original Pentium.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nIntel manuals.\nThese official manuals provide an overview of the Pentium processor and its features:"}
{"id": "24669", "revid": "49845758", "url": "https://en.wikipedia.org/wiki?curid=24669", "title": "Pauli exclusion principle", "text": "Quantum mechanics principle\nIn quantum mechanics, the Pauli exclusion principle (German: Pauli-Ausschlussprinzip) states that two or more identical particles with half-integer spins (i.e. fermions) cannot simultaneously occupy the same quantum state within a system that obeys the laws of quantum mechanics. This principle was formulated by Austrian physicist Wolfgang Pauli in 1925 for electrons, and later extended to all fermions with his spin\u2013statistics theorem of 1940.\nIn the case of electrons in atoms, the exclusion principle can be stated as follows: in a poly-electron atom it is impossible for any two electrons to have the same two values of \"all\" four of their quantum numbers, which are: \"n\", the principal quantum number; \"\u2113\", the azimuthal quantum number; \"m\u2113\", the magnetic quantum number; and \"ms\", the spin quantum number. For example, if two electrons reside in the same orbital, then their values of \"n\", \"\u2113\", and \"m\u2113\" are equal. In that case, the two values of \"m\"s (spin) pair must be different. Since the only two possible values for the spin projection \"m\"s are +1/2 and \u22121/2, it follows that one electron must have \"m\"s = +1/2 and one \"m\"s = \u22121/2.\nParticles with an integer spin (bosons) are not subject to the Pauli exclusion principle. Any number of identical bosons can occupy the same quantum state, such as photons produced by a laser, or atoms found in a Bose\u2013Einstein condensate.\nA rigorous statement which justifies the exclusion principle is: under the exchange of two identical particles, the total (many-particle) wave function is antisymmetric for fermions and symmetric for bosons. This means that if the space \"and\" spin coordinates of two identical particles are interchanged, then the total wave function changes sign (from positive to negative or vice versa) for fermions, but does not change sign for bosons. So, if hypothetically two fermions were in the same state\u2014for example, in the same atom in the same orbital with the same spin\u2014then interchanging them would change nothing and the total wave function would be unchanged. However, the only way a total wave function can both change sign (which is required for fermions), and also remain unchanged, is that such a function must be zero everywhere, which means such a state cannot exist. This reasoning does not apply to bosons because the sign does not change.\nOverview.\nThe Pauli exclusion principle describes the behavior of all fermions (particles with half-integer spin), while bosons (particles with integer spin) are subject to other principles. Fermions include elementary particles such as quarks, electrons and neutrinos. Additionally, baryons such as protons and neutrons (subatomic particles composed from three quarks) and some atoms (such as helium-3) are fermions, and are therefore described by the Pauli exclusion principle as well. Atoms can have different overall spin, which determines whether they are fermions or bosons: for example, helium-3 has spin 1/2 and is therefore a fermion, whereas helium-4 has spin 0 and is a boson. The Pauli exclusion principle underpins many properties of everyday matter, from its large-scale stability to the chemical behavior of atoms.\nHalf-integer spin means that the intrinsic angular momentum value of fermions is formula_1 (reduced Planck constant) times a half-integer (1/2, 3/2, 5/2, etc.). In the theory of quantum mechanics, fermions are described by antisymmetric states. In contrast, particles with integer spin (bosons) have symmetric wave functions and may share the same quantum states. Bosons include the photon, the Cooper pairs which are responsible for superconductivity, and the W and Z bosons. Fermions take their name from the Fermi\u2013Dirac statistical distribution, which they obey, and bosons take theirs from the Bose\u2013Einstein distribution.\nHistory.\nIn the early 20th century it became evident that atoms and molecules with even numbers of electrons are more chemically stable than those with odd numbers of electrons. In the 1916 article \"The Atom and the Molecule\" by Gilbert N. Lewis, for example, the third of his six postulates of chemical behavior states that the atom tends to hold an even number of electrons in any given shell, and especially to hold eight electrons, which he assumed to be typically arranged symmetrically at the eight corners of a cube. In 1919 chemist Irving Langmuir suggested that the periodic table could be explained if the electrons in an atom were connected or clustered in some manner. Groups of electrons were thought to occupy a set of electron shells around the nucleus. In 1922, Niels Bohr updated his model of the atom by assuming that certain numbers of electrons (for example 2, 8 and 18) corresponded to stable \"closed shells\".\nPauli looked for an explanation for these numbers, which were at first only empirical. At the same time he was trying to explain experimental results of the Zeeman effect in atomic spectroscopy and in ferromagnetism. He found an essential clue in a 1924 paper by Edmund C. Stoner, which pointed out that, for a given value of the principal quantum number (\"n\"), the number of energy levels of a single electron in the alkali metal spectra in an external magnetic field, where all degenerate energy levels are separated, is equal to the number of electrons in the closed shell of the noble gases for the same value of \"n\". This led Pauli to realize that the complicated numbers of electrons in closed shells can be reduced to the simple rule of \"one\" electron per state if the electron states are defined using four quantum numbers. For this purpose he introduced a new two-valued quantum number, identified by Samuel Goudsmit and George Uhlenbeck as electron spin.\nConnection to quantum state symmetry.\nIn his Nobel lecture, Pauli clarified the importance of quantum state symmetry to the exclusion principle:\nAmong the different classes of symmetry, the most important ones (which moreover for two particles are the only ones) are the symmetrical class, in which the wave function does not change its value when the space and spin coordinates of two particles are permuted, and the antisymmetrical class, in which for such a permutation the wave function changes its sign...[The antisymmetrical class is] the correct and general wave mechanical formulation of the exclusion principle.\nThe Pauli exclusion principle with a single-valued many-particle wavefunction is equivalent to requiring the wavefunction to be antisymmetric with respect to exchange. If formula_2 and formula_3 range over the basis vectors of the Hilbert space describing a one-particle system, then the tensor product produces the basis vectors formula_4 of the Hilbert space describing a system of two such particles. Any two-particle state can be represented as a superposition (i.e. sum) of these basis vectors:\n formula_5\nwhere each \"A\"(\"x\", \"y\") is a (complex) scalar coefficient. Antisymmetry under exchange means that \"A\"(\"x\", \"y\") = \u2212\"A\"(\"y\", \"x\"). This implies \"A\"(\"x\", \"y\") = 0 when \"x\" = \"y\", which is Pauli exclusion. It is true in any basis since local changes of basis keep antisymmetric matrices antisymmetric.\nConversely, if the diagonal quantities \"A\"(\"x\", \"x\") are zero \"in every basis\", then the wavefunction component\n formula_6\nis necessarily antisymmetric. To prove it, consider the matrix element\n formula_7\nThis is zero, because the two particles have zero probability to both be in the superposition state formula_8. But this is equal to\n formula_9\nThe first and last terms are diagonal elements and are zero, and the whole sum is equal to zero. So the wavefunction matrix elements obey:\n formula_10\nor\n formula_11\nFor a system with \"n\" &gt; 2 particles, the multi-particle basis states become \"n\"-fold tensor products of one-particle basis states, and the coefficients of the wavefunction formula_12 are identified by \"n\" one-particle states. The condition of antisymmetry states that the coefficients must flip sign whenever any two states are exchanged: formula_13 for any formula_14. The exclusion principle is the consequence that, if formula_15 for any formula_16 then formula_17 This shows that none of the \"n\" particles may be in the same state.\nAdvanced quantum theory.\nAccording to the spin\u2013statistics theorem, particles with integer spin occupy symmetric quantum states, and particles with half-integer spin occupy antisymmetric states; furthermore, only integer or half-integer values of spin are allowed by the principles of quantum mechanics.\nIn relativistic quantum field theory, the Pauli principle follows from applying a rotation operator in imaginary time to particles of half-integer spin.\nIn one dimension, bosons, as well as fermions, can obey the exclusion principle. A one-dimensional Bose gas with delta-function repulsive interactions of infinite strength is equivalent to a gas of free fermions. The reason for this is that, in one dimension, the exchange of particles requires that they pass through each other; for infinitely strong repulsion this cannot happen. This model is described by a quantum nonlinear Schr\u00f6dinger equation. In momentum space, the exclusion principle is valid also for finite repulsion in a Bose gas with delta-function interactions, as well as for interacting spins and Hubbard model in one dimension, and for other models solvable by Bethe ansatz. The ground state in models solvable by Bethe ansatz is a Fermi sphere.\nApplications.\nAtoms.\nThe Pauli exclusion principle helps explain a wide variety of physical phenomena. One particularly important consequence of the principle is the elaborate electron shell structure of atoms and the way atoms share electrons, explaining the variety of chemical elements and their chemical combinations. An electrically neutral atom contains bound electrons equal in number to the protons in the nucleus. Electrons, being fermions, cannot occupy the same quantum state as other electrons, so electrons have to \"stack\" within an atom, i.e. have different spins while at the same electron orbital as described below.\nAn example is the neutral helium atom (He), which has two bound electrons, both of which can occupy the lowest-energy (1s) states by acquiring opposite spin; as spin is part of the quantum state of the electron, the two electrons are in different quantum states and do not violate the Pauli principle. However, the spin can take only two different values (eigenvalues). In a lithium atom (Li), with three bound electrons, the third electron cannot reside in a 1s state and must occupy a higher-energy state instead. The lowest available state is 2s, so that the ground state of Li is 1s22s. Similarly, successively larger elements must have shells of successively higher energy. The chemical properties of an element largely depend on the number of electrons in the outermost shell; atoms with different numbers of occupied electron shells but the same number of electrons in the outermost shell have similar properties, which gives rise to the periodic table of the elements.\nTo test the Pauli exclusion principle for the helium atom, Gordon Drake of the University of Windsor carried out very precise calculations for hypothetical states of the He atom that violate it, which are called paronic states. Later, K. Deilamian et al. used an atomic beam spectrometer to search for the paronic state 1s2s 1S0 calculated by Drake. The search was unsuccessful and showed that the statistical weight of this paronic state has an upper limit of . (The exclusion principle implies a weight of zero.)\nSolid state properties.\nIn conductors and semiconductors, there are very large numbers of molecular orbitals which effectively form a continuous band structure of energy levels. In strong conductors (metals) electrons are so degenerate that they cannot even contribute much to the thermal capacity of a metal. Many mechanical, electrical, magnetic, optical and chemical properties of solids are the direct consequence of Pauli exclusion.\nStability of matter.\nThe stability of each electron state in an atom is described by the quantum theory of the atom, which shows that close approach of an electron to the nucleus necessarily increases the electron's kinetic energy, an application of the uncertainty principle of Heisenberg. However, stability of large systems with many electrons and many nucleons is a different question, and requires the Pauli exclusion principle.\nIt has been shown that the Pauli exclusion principle is responsible for the fact that ordinary bulk matter is stable and occupies volume. This suggestion was first made in 1931 by Paul Ehrenfest, who pointed out that the electrons of each atom cannot all fall into the lowest-energy orbital and must occupy successively larger shells. Atoms, therefore, occupy a volume and cannot be squeezed too closely together.\nThe first rigorous proof was provided in 1967 by Freeman Dyson and Andrew Lenard (), who considered the balance of attractive (electron\u2013nuclear) and repulsive (electron\u2013electron and nuclear\u2013nuclear) forces and showed that ordinary matter would collapse and occupy a much smaller volume without the Pauli principle.\nA much simpler proof was found later by Elliott H. Lieb and Walter Thirring in 1975. They provided a lower bound on the quantum energy in terms of the Thomas-Fermi model, which is stable due to a theorem of Teller. The proof used a lower bound on the kinetic energy which is now called the Lieb\u2013Thirring inequality.\nThe consequence of the Pauli principle here is that electrons of the same spin are kept apart by a repulsive exchange interaction, which is a short-range effect, acting simultaneously with the long-range electrostatic or Coulombic force. This effect is partly responsible for the everyday observation in the macroscopic world that two solid objects cannot be in the same place at the same time.\nAstrophysics.\nDyson and Lenard did not consider the extreme magnetic or gravitational forces that occur in some astronomical objects. In 1995 Elliott Lieb and coworkers showed that the Pauli principle still leads to stability in intense magnetic fields such as in neutron stars, although at a much higher density than in ordinary matter. It is a consequence of general relativity that, in sufficiently intense gravitational fields, matter collapses to form a black hole.\nAstronomy provides a spectacular demonstration of the effect of the Pauli principle, in the form of white dwarf and neutron stars. In both bodies, the atomic structure is disrupted by extreme pressure, but the stars are held in hydrostatic equilibrium by \"degeneracy pressure\", also known as Fermi pressure. This exotic form of matter is known as degenerate matter. The immense gravitational force of a star's mass is normally held in equilibrium by thermal pressure caused by heat produced in thermonuclear fusion in the star's core. In white dwarfs, which do not undergo nuclear fusion, an opposing force to gravity is provided by electron degeneracy pressure. In neutron stars, subject to even stronger gravitational forces, electrons have merged with protons to form neutrons. Neutrons are capable of producing an even higher degeneracy pressure, neutron degeneracy pressure, albeit over a shorter range. This can stabilize neutron stars from further collapse, but at a smaller size and higher density than a white dwarf. Neutron stars are the most \"rigid\" objects known; their Young modulus (or more accurately, bulk modulus) is 20 orders of magnitude larger than that of diamond. However, even this enormous rigidity can be overcome by the gravitational field of a neutron star mass exceeding the Tolman\u2013Oppenheimer\u2013Volkoff limit, leading to the formation of a black hole.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24670", "revid": "47033785", "url": "https://en.wikipedia.org/wiki?curid=24670", "title": "Pasipha\u00eb", "text": "Queen of Crete in Greek mythology\nIn Greek mythology, Pasipha\u00eb (; , derived from \u03c0\u1fb6\u03c3\u03b9 (dative plural) \"for all\" and \u03c6\u03ac\u03bf\u03c2/\u03c6\u1ff6\u03c2 \"phaos/phos\" \"light\") was a queen of Crete. The daughter of Helios and the Oceanid nymph Perse, Pasipha\u00eb is notable as the mother of the Minotaur. Her husband, Minos, failed to sacrifice the Cretan Bull to Poseidon as he had promised. Poseidon then cursed Pasipha\u00eb to fall in love with the bull. Athenian inventor Daedalus built a hollow cow for her to hide in so she could mate with the bull, which resulted in her conceiving the Minotaur.\nFamily.\nParentage.\nPasipha\u00eb was the daughter of god of the Sun, Helios, and the Oceanid nymph Perse. She was thus the sister of Ae\u00ebtes, Circe and Perses of Colchis. In some accounts, Pasipha\u00eb's mother was identified as the island-nymph Crete herself. Like her doublet Europa, the consort of Zeus, her origins were in the East, in her case at the earliest-known Kartvelian-speaking polity of Colchis (\"Egrisi\" (Georgian: ), now in western Georgia).\nMarriage and children.\nPasipha\u00eb was given in marriage to King Minos of Crete. With Minos, she was the mother of Acacallis, Ariadne, Androgeus, Glaucus, Deucalion, Phaedra, Xenodice, and Catreus.\nAfter having sex with the Cretan Bull, she gave birth to the \"star-like\" Asterion, who became known as the Minotaur.\nMythology.\nBirth of the Minotaur.\nMinos was required to sacrifice \"the fairest bull born in its herd\" to Poseidon each year. One year, an extremely beautiful snow-white bull was born: the Cretan Bull. Minos refused to sacrifice the animal, and sacrificed another, inferior bull instead. As punishment, Poseidon cursed Pasipha\u00eb to experience lust for the Cretan bull.\nUltimately, Pasipha\u00eb went to Daedalus and asked him to help her mate with the bull. Daedalus then created a hollow wooden cow covered with real cow-skin, so realistic that it fooled the Cretan Bull. Pasipha\u00eb climbed into the structure, allowing the bull to mate with her. Pasipha\u00eb fell pregnant and gave birth to a half-human half-bull creature that fed solely on human flesh. The child was named Asterius, after the previous king, but was commonly called the Minotaur (\"the bull of Minos\").\nThe myth of Pasipha\u00eb's coupling with the bull and the subsequent birth of the Minotaur was the subject of Euripides's lost play the \"Cretans\", of which few fragments survive. Sections include a chorus of priests presenting themselves and addressing Minos, someone (perhaps a wetnurse) informing Minos of the newborn infant's nature (informing Minos and the audience, among others, that Pasipha\u00eb breastfeeds the Minotaur like an infant), and a dialogue between Pasipha\u00eb and Minos where they argue over which between them is responsible. Pasipha\u00eb's speech defending herself is preserved, an answer to Minos's accusations (not preserved) in which she excuses herself on account of acting under the constraint of divine power, and insists that the one to blame is actually Minos, who angered the sea-god.\nPASIPHA\u00cb:\nIf I had sold the gifts of Kypris,&lt;br&gt;\ngiven my body in secret to some man,&lt;br&gt;\nyou would have every right to condemn me&lt;br&gt;\nas a whore. But this was no act of the will;&lt;br&gt;\nI am suffering from some madness brought on&lt;br&gt;\nby a god.&lt;br&gt;\nIt\u2019s not plausible!&lt;br&gt;\nWhat could I have seen in a bull&lt;br&gt;\nto assault my heart with this shameful passion?&lt;br&gt;\nDid he look too handsome in his robe?&lt;br&gt;\nDid a sea of fire smoulder in his eyes?&lt;br&gt;\nWas it the red tint of his hair, his dark beard?\nMythological scholars and authors Ruck and Staples remarked that \"the Bull was the old pre-Olympian Poseidon\".\nVariations on the myth.\n\"Pseudo-Apollodorus\" mentions a slightly differing reason for why Poseidon cursed Pasipha\u00eb; citing that Minos wanted to be king, and he called upon Poseidon to send him a bull in order to prove to the kingdom that he had received sovereignty from the gods. Upon calling on Poseidon, Minos failed to sacrifice the bull, as Poseidon wished, causing the god to grow angry with him.\nAccording to sixth century BC author Bacchylides, the curse was instead sent by Aphrodite and Hyginus says this was because Pasipha\u00eb had neglected Aphrodite's worship for years. In yet another version, Aphrodite cursed Pasipha\u00eb (as well as several of her sisters) with unnatural desires as a revenge against her father Helios, for he had revealed to Aphrodite's husband Hephaestus her secret affair with Ares, the god of war, earning Aphrodite's eternal hatred for himself and his whole race.\nIn some more obscure traditions, it was not Poseidon's bull but Minos's father Zeus disguised as one who made love to Pasipha\u00eb and sired the Minotaur. An ancient Greek lexicon mentions a tradition where Zeus and Pasipha\u00eb are the parents of the Egyptian god Amun, who was identified with Zeus.\nPasipha\u00eb's curse.\nIn other aspects, Pasipha\u00eb, like her niece Medea, was a mistress of magical herbal arts in the Greek imagination. The author of \"Bibliotheke\" records the fidelity charm she placed upon Minos that caused him to ejaculate serpents, scorpions, and centipedes whenever he laid with another woman, killing them. However, Procris, after consuming a protective circean herb, lay with Minos with impunity.\nIn another version, this unexplained disease that tormented Minos killed all his concubines and prevented him and Pasipha\u00eb from having any children (the scorpions and serpents did not otherwise harm Pasipha\u00eb, as she was an immortal child of the Sun). Procris then inserted a goat's bladder into a woman, told Minos to ejaculate the scorpions in there, and then sent him to Pasipha\u00eb. The couple was thus able to conceive eight children. Records indicate, this became the first modern documentation of a sheath or condom, though working to promote fertility.\nDaedalus and Icarus.\nIn one version of the story, Pasipha\u00eb supplied Daedalus and his son Icarus with a ship in order to escape Minos and Crete. In another, she helped him hide until he fashioned wings made of wax and bird feathers.\nVariations about Pasipha\u00eb's death.\nWhile Pasipha\u00eb is an immortal goddess in some texts, other authors treated her as a mortal woman, like Euripides who in his play \"Cretans\" has Minos sentence her to death (her eventual fate is unclear, as no relevant fragment survives). In Virgil's \"Aeneid\", Aeneas sees her when he visits the Underworld, describing Pasiphae residing in the Mournful Fields, a place inhabited by sinful lovers.\nPersonae of Pasipha\u00eb.\nIn the general understanding of the Minoan myth, Pasipha\u00eb and Daedalus' construction of the wooden cow allowed her to satisfy her desire for the Cretan Bull. Through this interpretation she was reduced from a near-divine figure (daughter of the Sun) to a stereotype of grotesque bestiality and the shocking excesses of lust and deceit.\nPasipha\u00eb appeared in Virgil's \"Eclogue VI\" (45\u201360), in Silenus's list of suitable mythological subjects, on which Virgil lingers in such detail that he gives the sixteen-line episode the weight of a brief inset myth.\nIn Ovid's \"Ars Amatoria\", Pasipha\u00eb is framed in zoophilic terms:\n\"Pasiphae fieri gaudebat adultera tauri\"\u2014\"Pasipha\u00eb took pleasure in becoming an adulteress with a bull.\"\nPasipha\u00eb is often included on lists among mythical women ruled by lust; other women include Phaedra, Byblis, Myrrha, Scylla and Semiramis. Scholars see her as a personified sin of bestiality.\n\"Ars Amatoria\" shows Pasipha\u00eb's jealousy of the cows; she's primping in front of a mirror while she laments that she is not a cow and killing her rivals.\nCult of Pasipha\u00eb.\nOn divination.\nIn mainland Greece, Pasipha\u00eb was worshipped as an oracular goddess at Thalamae, one of the original \"koine\" of Sparta. The geographer Pausanias describes the shrine as small, situated near a clear stream, and flanked by bronze statues of Helios and Pasipha\u00eb. His account also equates Pasipha\u00eb with Ino and the lunar goddess Selene.\nCicero writes in \"De Divinatione\" 1.96 that the Spartan ephors would sleep at the shrine of Pasipha\u00eb, seeking prophetic dreams to aid them in governance. According to Plutarch, Spartan society twice underwent major upheavals sparked by the ephors' dreams at the shrine during the Hellenistic era. In one case, an ephor dreamed that some of his colleagues' chairs were removed from the agora, and that a voice called out \"this is better for Sparta\"; inspired by this, King Cleomenes acted to consolidate royal power. Again during the reign of King Agis, several ephors brought the people into revolt with oracles from Pasipha\u00eb's shrine promising remission of debts and redistribution of land.\nCelestial deity.\nIn \"Description of Greece\", Pausanias equates Pasipha\u00eb with Selene, implying that the figure was worshipped as a lunar deity. However, further studies on Minoan religion indicate that the sun was a female figure, suggesting instead that Pasipha\u00eb was originally a solar goddess, an interpretation consistent with her depiction as Helios's daughter. Poseidon's bull may in turn be vestigial of the lunar bull prevalent in Ancient Mesopotamian religion.\nNowadays, Pasipha\u00eb and her son, the Minotaur, are associated with the astrological sign of Taurus.\nOther representations.\nIn art.\nThe myth of Pasipha\u00eb and the Cretan Bull became widely depicted in art throughout history. Pasipha\u00eb was most often depicted with a bull near her, signifying the connection to the myth.\nScientific representation.\nOne of Jupiter's 79 moons, discovered in 1908, is named after Pasipha\u00eb, the woman of the myth of the Minotaur.\nLiterary representation.\nPasipha\u00e9 is mentioned in Canto 12 of Dante Alighieri's \"Inferno\". When Dante encounters the Minotaur, he describes the unnatural and deceptive manner of the beast's conception.\nFiona Benson's third collection of poetry, \"Ephemeron\", contains a long section entitled \"Translations from the Pasipha\u00eb\" in which she retells the Minotaur myth from the point of view of the bull-child's mother.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24672", "revid": "51003634", "url": "https://en.wikipedia.org/wiki?curid=24672", "title": "Primate (bishop)", "text": "High-ranking bishop in certain Christian churches\nPrimate (; ) is a title or rank bestowed on some important archbishops in certain Christian churches. Depending on the particular tradition, it can denote either jurisdictional authority (title of authority) or (usually) ceremonial precedence (title of honour).\nCatholic Church.\nIn the Latin Church, a primate is an archbishop\u2014or, rarely, a suffragan or exempt bishop\u2014of a specific (mostly metropolitan) episcopal see (called a \"primatial see\") who has precedence over the bishoprics of one or more ecclesiastical provinces of a particular historical, political or cultural area. Historically, primates of particular sees were granted privileges including the authority to call and preside at national synods, jurisdiction to hear appeals from metropolitan tribunals, the right to crown the sovereign of the nation, and presiding at the investiture (installation) of archbishops in their sees.\nThe office is generally found only in older Catholic countries, and is now purely honorific, enjoying no effective powers under canon law\u2014except for the archbishop of Esztergom (Gran) in Hungary. Thus, e.g., the primate of Poland holds no jurisdictional authority over other Polish bishops or their dioceses, but is \"durante munere\" a member of the standing committee of the episcopal conference, and has honorary precedence among Polish bishops (e.g., in liturgical ceremonies). The Holy See has also granted Polish primates the privilege of wearing cardinal's crimson attire, except for the skullcap and biretta, even if they have not been made cardinals.\nWhere the title of primate exists, it may be vested in one of the oldest archdioceses in a country, often based in a city other than the present capital, but which was the capital when the country was first Christianized. The city may no longer have the prominence it had when the title was granted. The political area over which primacy was originally granted may no longer exist: for example, the Archbishop of Toledo was designated \"Primate of the Visigothic Kingdom\", and the Archbishop of Lyon is the \"Primate of the Gauls\". The title of Primate can, therefore, also be disputed between different Archdioceses who, at some point, held proeminence over a shifting territory; such is the dispute over the Primacy of the Spains that was fought over by the Archdioceses of Braga, Toledo and Santiago de Compostela. After the founding of Portugal, the Archbishop of Braga held precedence over all other archbishops in the country, though his role declined under the rise of the Archdiocese of Lisbon, which culminated in 1716, when Archbishop Tom\u00e1s de Almeida (1670\u20131754) was elevated to Patriarch.\nSome of the leadership functions once exercised by Primates, specifically presiding at meetings of the bishops of a nation or region, are now exercised by the president of the conference of bishops: \"The president of the Conference or, when he is lawfully impeded, the vice-president, presides not only over the general meetings of the Conference but also over the permanent committee.\" The president is generally elected by the conference, but by exception the President of the Italian Episcopal Conference is appointed by the Pope, and the Irish Catholic Bishops' Conference has the Primate of All Ireland as president and the Primate of Ireland as vice-president. Other former functions of primates, such as hearing appeals from metropolitan tribunals, were reserved to the Holy See by the early 20th century. Soon after, by the norm of the Code of Canon Law of 1917, confirmed in the 1983 Code, the tribunal of second instance for appeals from a metropolitan tribunal is \"the tribunal which the metropolitan has designated in a stable manner with the approval of the Apostolic See\".\nThe closest equivalent position in the Eastern Churches in 1911 was an Exarch.\nThe Holy See has continued in modern times to grant the title of Primate. With the papal decree \"Sollicitae Romanis Pontificibus\" of 24 January 1956 it granted the title of Primate of Canada to the Archbishop of Quebec. As stated above, this is merely an honorary title involving no additional power.\nA right of precedence over other bishops and similar privileges can be granted even to a bishop who is not a Primate. Thus, in 1858, the Holy See granted the Archbishop of Baltimore precedence in meetings of the United States bishops. The Archbishop of Westminster has not been granted the title of Primate of England and Wales, which is sometimes applied to him, but his position has been described as that of \"Chief Metropolitan\" and as \"similar to\" that of the Archbishop of Canterbury.\nThe title of Primate is sometimes applied loosely to the Archbishop of a country's capital, as in the case of the Archbishops of Seoul in South Korea and of Edinburgh in Scotland.\nThe pre-reformation metropolitan Archbishop of Nidaros was sometimes referred to as Primate of Norway, even though it is unlikely that this title ever was officially granted to him by the Holy See.\nCatholic primatial sees.\nThe heads of certain sees have at times been referred to, at least by themselves, as primates: \n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nAt the First Vatican Council.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nRegular clergy equivalent.\nIn the modern confederation of the Benedictine Order, all the Black Monks of St. Benedict were united under the presidency of an Abbot Primate (Leo XIII, \"Summum semper\", 12 July 1893); but the unification, fraternal in its nature, brought no modification to the abbatial dignity, and the various congregations preserved their autonomy intact. The loose structure of the Benedictine Confederation is claimed to have made Pope Leo XIII exclaim that the Benedictines were \"ordo sine ordine\" (\"an order without order\"). The powers of the Abbot Primate are specified, and his position defined, in a decree of the Sacred Congregation of Bishops and Regulars dated 16 September 1893. The primacy is attached to the global Benedictine Confederation whose Primate resides at Sant'Anselmo in Rome. He takes precedence of all other abbots, is empowered to pronounce on all doubtful matters of discipline, to settle difficulties arising between monasteries, to hold a canonical visitation, if necessary, in any congregation of the order, and to exercise a general supervision for the regular observance of monastic discipline. The Primatial powers are only vested in the Abbot Primate to act by virtue of the proper law of its autonomous Benedictine congregation, which at the present is minimal to none. However, certain branches of the Benedictine Order seem to have lost their original autonomy to some extent.\nIn a similar way the Confederation of Canons Regular of St. Augustine, elects an Abbot Primate as figurehead of the Confederation and indeed the whole Canonical Order. The Abbots and Superiors General of the nine congregations of confederated congregations of Canons Regular elect a new Abbot Primate for a term of office lasting six years. The Current Abbot Primate is Rt Rev. Fr Jean-Michel Girard, CRB, Abbot General of the Canons Regular of the Grand St Bernard.\nAnglicanism.\nAnglican usage styles the bishop who heads an independent church as its \"primate\", though commonly they hold some other title (e.g. archbishop, presiding bishop, or moderator). The primates' authority within their churches varies considerably: some churches give the primate some executive authority, while in others they may do no more than preside over church councils and represent the church ceremonially.\nAnglican Communion.\nIn the context of the Anglican Communion Primates' Meeting, the chief bishop of each of the thirty-nine churches (also known as provinces) that compose the Anglican Communion acts as its primate, though this title may not necessarily be used within their own provinces. Thus the United Churches of Bangladesh, of North India, of Pakistan and of South India, which are united with other originally non-Anglican churches, are represented at the meetings by their moderators.\nIn both the Church of England and the Church of Ireland, two bishops have the title of primate: the archbishops of Canterbury and York in England and of Armagh and Dublin in Ireland. Only the bishop of the senior primatial see of each of these two churches participates in the meetings.\nThe archbishop of Canterbury, who is considered \"primus inter pares\" of all the participants, convokes the meetings and issues the invitations.\nPrimates and archbishops are styled \"The Most Reverend\". All other bishops are styled \"The Right Reverend\", with the exception of the Bishop of Meath and Kildare in the Church of Ireland.\nEastern Orthodox equivalent.\nHistorically, the primatial title in Western Christianity corresponded to the title and office of supra-metropolitan exarch in Eastern Christianity. Such exarchs, or primates, were archbishops of Ephesus (for the Diocese of Asia), Heraclea (for the Diocese of Thrace) and Caesarea (for the Diocese of Pontus).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24673", "revid": "36727272", "url": "https://en.wikipedia.org/wiki?curid=24673", "title": "Penny Arcade", "text": "Webcomic by Holkins and Krahulik and its related products\nPenny Arcade is a webcomic focused on video games and video game culture, written by Jerry Holkins and illustrated by Mike Krahulik. The comic debuted in 1998 on the website \"loonygames.com\". Since then, Holkins and Krahulik have established their own site, which is typically updated with a new comic strip each Monday, Wednesday, and Friday. The comics are accompanied by regular updates on the site's blog.\nBy 2005, \"Penny Arcade\" was among the most popular and longest running webcomics online, listed in 2010 as having 3.5 million readers. Holkins and Krahulik were among the first webcomic creators successful enough to make a living from their work. In addition to the comic, Holkins and Krahulik also created Child's Play, a children's charity; PAX, a gaming convention; Penny Arcade TV, a YouTube channel; Pinny Arcade, a pin exchange; and the episodic video game \"\" with Hothead Games and Zeboyd Games.\nOverview.\nThe strip features Krahulik and Holkins' cartoon alter egos, John \"Gabe\" Gabriel and Tycho Brahe, respectively. While often borrowing from the authors' experiences, Holkins and Krahulik do not treat them as literal avatars or caricatures of themselves. The two characters spend much of their time playing and commenting on both computer and video games, which forms the basis of the humor in the strip. Most of the time Gabe serves the purpose of the comic and Tycho the comic foil. The strip can feature in-jokes that are explained in the news posts accompanying each comic, written by the authors.\nBoth Krahulik and Holkins make a living from \"Penny Arcade\", placing them in a small group of professional webcomic artists devoted to their creations full-time. Originally, like many webcomics, \"Penny Arcade\" was supported solely by donations. A graph on the main page indicated how much people had donated that month. After hiring Robert Khoo as their business manager, Holkins and Krahulik switched to a different income stream based on advertising and merchandise revenue alone. According to Holkins, the website handled more than two million pageviews daily (excluding forum traffic) in 2006. On November 13, 2005, the website was redesigned in celebration of their seventh year running and to match the designs of the Child's Play Charity and Penny Arcade Expo websites. Afterwards, the site has been redesigned multiple times.\nAttributes of the comic strip.\nAs a (primarily) topical video gaming news comic, there is little plot or general continuity in \"Penny Arcade\" strips. Any story sustained for longer than a single strip is referred to as \"dreaded continuity\", something of a running gag in the newsposts. A character who dies a violent death in one strip will come back in the next, perfectly whole, though occasionally these deaths have an effect on later comics. For example, often, when Gabe kills Tycho or vice versa, the killer takes a certain Pac-Man watch off the dead character, but only if he currently has the watch. Profanity and violence are common in \"Penny Arcade\" and the strip is known for its surrealism; zombies, a talking alcoholic DIVX player called Div, Santa Claus, a robotic juicer called the \"Fruit Fucker 2000\", and Jesus, among others, are known to drop in often and for petty reasons. Other such occurrences are implied, if not shown, such as mentioning Dante from \"Devil May Cry\" living in the building next door. However, the comic does occasionally expand into more serious issues; one even had Krahulik, in the guise of the character Gabe, proposing to his girlfriend of two years, while another had both Gabe and Tycho praising Casey Heynes for standing up to bullying.\nSome of the strips are drawn from the perspective of fictional characters within a game or movie. Occasionally, Gabe and Tycho are featured as they would be as characters or players in the game themselves, often having some sarcastic remark to make about some feature or bug in the game. At times the comic also depicts meetings between game developers or business people, and features or mocks the reporters of a news article that is commented on in Holkins' newspost.\n\"Penny Arcade\" has a theme song, \"Penny Arcade Theme\", written and performed by nerdcore artist MC Frontalot. It was written as a thank-you by Frontalot for the creators of the webcomic linking his website to their front page and declaring him their \"rapper laureate\" in 2002. The song appears in the dance game \"In the Groove\", released in 2004.\nProtagonists.\nJonathan \"Gabe\" Gabriel.\nMike Krahulik's comic alter ego is energetic and free-spirited, but has a propensity to become extremely angry. As a contrast to Tycho's expansive vocabulary, Gabe usually speaks using only simple, common words. He almost always wears a yellow Pac-Man shirt, and has a Pac-Man tattoo on his right arm. His eyes are a shade of slate blue. \nHe has a fascination with unicorns, a secret love of Barbies, is a dedicated fan of Spider-Man and \"Star Wars\", and has proclaimed \"Jessie's Girl\" to be the greatest song of all time. He has a wife and son. Gabe is a diabetic, though he continues to consume large quantities of sugar products. \nKrahulik named his son \"Gabriel\" in honor of the character.\nTycho Brahe.\nJerry Holkins' comic alter ego (named after the astronomer Tycho Brahe) is bitter and sarcastic. His eyes are burnt sienna, and he's almost invariably clad in a blue-striped sweater. Tycho enjoys books, role-playing video games, using large and uncommon words in conversation, and deflating Gabe's ego. He is an enthusiastic fan of \"Harry Potter\" and \"Doctor Who\". He also plays \"Dungeons &amp; Dragons\" often (the website's previous banner illustrated him holding a 20-sided die), and adopts a wildly theatrical style when acting as a dungeon master.\nTycho occasionally makes reference to his scarring childhood, during which his mother physically abused him. Tycho also has a drinking problem.\nIn \"Poker Night at the Inventory\", Tycho is voiced by Kid Beyond.\nPodcast.\nKrahulik and Holkins had a podcast that they produced from 2006 until 2018, releasing new episodes irregularly. They began to record and release audio content on March 20, 2006, titled \"Downloadable Content.\" The podcasts specifically captured the creative process that goes into the creation of a \"Penny Arcade\" comic, usually starting with a perusal of recent gaming news, with conversational tangents and digressions to follow. As well as being a behind-the-scenes look at the creation of \"Penny Arcade\", Krahulik and Holkins discussed possible subjects for the comic.\nThe format of the show was mostly \"fly-on-the-wall\" style, in that the hosts rarely acknowledged the existence of the microphone. There was no theme music, intro, or outro. The podcasts were of varying lengths, beginning abruptly and ending with the idea for the current comic. New episodes were released irregularly, with six month gaps not uncommon.\nAlthough the shows were initially published weekly, Holkins stated in a May 2006 blog post that they found difficulties when trying to produce the podcasts on a regular basis. The duo planned to keep recording podcasts occasionally.\nSince airing the first episode of the new PATV in February 2010, the podcast has not been updated. A new segment has since appeared on PATV called \"The Fourth Panel,\" which presents a fly-on-the-wall look at comics creation much as the podcast did.\nOn May 8, 2013 Penny Arcade launched a Kickstarter campaign to fund the continuation of \"Downloadable Content\". The kickstarter was successful, with new Podcasts being added each Wednesday. \"Downloadable Content\" is \"currently on hiatus,\" with the latest episode dated August 23, 2018.\nGames.\n\"\" is an episodic video game based on the strip. The first two episodes were developed by Hothead Games, and were built on a version of the Torque Game Engine. The first episode was released worldwide on May 21, 2008, and the second on October 29, 2008. They were self-published via the PlayStation Network and Xbox Live as well as the PlayGreenhouse.com service created by \"Penny Arcade\" to distribute independent games. The game features many elements of the \"Penny Arcade\" universe in a 1920s steampunk setting. In 2010, Krahulik and Holkins announced that the remainder of the series had been cancelled, to allow Hothead to focus on other projects. At PAX Prime 2011, however, it was announced that the series would be revived and developed by Zeboyd Games, with a retro style similar to Zeboyd's past titles. The third episode was released on Steam and on Penny Arcade's web store June 25, 2012. The fourth and final episode was announced in January 2013, and released to Steam and Xbox Live in June 2013.\nA teaser trailer released by Telltale Games on August 28, 2010, revealed that Tycho would appear in an upcoming game alongside \"Team Fortress 2's\" Heavy, \"Homestar Runner's\" Strong Bad and \"Sam &amp; Max's\" Max. The game, called \"Poker Night at the Inventory\", was officially revealed on September 2, 2010.\nTwo stories that were published on the site were released as motion comics for iOS developed by SRRN Games, \"The Last Christmas\" in 2010 and \"The Hawk and the Hare\" in 2011.\nThe 2008 North American release of \"Tekken 6\" has a skin for Yoshimitsu based on the Cardboard Tube Samurai. In 2012, an official DLC skin pack was released for Dungeon Defenders featuring Tycho, Cardboard Tube Samurai Gabe, Annarchy and Jim Darkmagic skins.\nCryptozoic Entertainment released the licensed deck-building card game \"Penny Arcade The Game: Gamers Vs. Evil\" in 2011, and followed it with the expansion pack \"Penny Arcade The Game: Rumble in R'lyeh\" in 2012. Playdek released a digital conversion of \"Penny Arcade The Game: Gamers Vs. Evil\" for iOS in 2012.\n\"Penny Arcade: The Series\".\n\"Penny Arcade: The Series\" first aired online on February 20, 2010. It is a multi-season documentary series based on the exploits of the Penny Arcade company and its founders Krahulik and Holkins. The last episode of the series was posted in September 2015.\nOther works.\nPenny Arcade Presents.\nUnder the banner of \"Penny Arcade Presents\", Krahulik and Holkins are sometimes commissioned to create promotional artwork/comic strips for new video games, with their signature artistic style and humor. They are usually credited simply as \"Penny Arcade\" rather than by their actual names. Some of these works have been included with the distribution of the game, and others have appeared on pre-launch official websites. An official list could be found on the Penny Arcade website. The last of these commissions was posted in 2012.\nCollectible Card Game.\nOn August 8, 2005, Krahulik announced that \"Penny Arcade\", in partnership with Sabertooth Games, would be producing a collectible card game based on the \"Penny Arcade\" franchise. The resulting \"Penny Arcade\" \"battle box\" was released in February 2006 as part of the Universal Fighting System.\nThere are also a few spinoffs from the main comic that have gained independent existences. An example is \"\" (ELotH:TES), a parody of the written-by-committee fantasy fiction used as back-story for a wide variety of games: originally a one-off gag in the \"Penny Arcade\" comic, in late 2005 this was expanded into a complete fantasy universe, documented on a hoax \"fan-wiki\". ELotH:TES first appeared in the webcomic of February 7, 2005, and has subsequently been featured in the comics of November 7, 2005 and November 30, 2005. Several elements of the ELotH:TES universe are featured on the cover of their second comics collection, \"Epic Legends of the Magic Sword Kings\".\nESRB ad campaigns.\nOn May 31, 2006 Krahulik announced a new advertising campaign for the Entertainment Software Rating Board. According to Krahulik, the ESRB \"wanted a campaign that would communicate to gamers why the ESRB is important even if they don't think it directly affects them.\" Among the reasons he listed for \"Penny Arcade\"'s accepting the job was that he and Holkins are both fathers and are concerned about the games their children might play. The ad campaign was rolled out in the summer and fall of 2006 and a second campaign was released in 2012 featuring a mother, a father and a gamer describing the tools employed by the ESRB.\n\"Acquisitions Incorporated\".\nIn 2008, the creators of \"Penny Arcade\" partnered with Wizards of the Coast to create a podcast of a few 4th Edition \"Dungeons &amp; Dragons\" adventures which led to the creation of the \"Acquisitions Incorporated\". After the podcast was well-received, the players began livestreaming games starting in 2010 at the PAX festival. \"Polygon noted\" that \"these shows became more elaborate over time, moving from two cameras in a hotel ballroom to a livestreamed multi-camera setup with costumed players at PAX Prime in 2012\". Prerecorded, edited actual play series, such as \"AI: The Series\" (2016\u20132017) and \"The \"C\" Team\" (2017\u20132021), were also released. Academic Emily Friedman commented that many incorrectly attribute \"Acquisitions Incorporated\" as the start of the actual play genre.&lt;ref name=\"Friedman/Torner 2025 Interview\"&gt;&lt;/ref&gt; \"Acquisitions Incorporated\" went on to be described by \"Inverse\" in 2019 as the \"longest-running live play game\". In 2019, this work led to an official 5th Edition \"Dungeons &amp; Dragons\" sourcebook featuring the \"Acquisitions Incorporated\" concept and characters. At PAX Unplugged 2025, \"Acquisitions Incorporated Daggerheart\" was announced. The series will be rebooted with a new campaign and setting and will use \"Daggerheart\" instead of \"Dungeons &amp; Dragons\" as its tabletop role-playing game.\n\"The New Kid\" film script.\nAnnounced on June 2, 2011, Paramount Pictures had acquired the rights to produce an animated film, via Paramount Animation to make this, of the one-off strip \"The New Kid\" which was published on October 29, 2010. The strip was one of three mini-strips which featured a cinematic opening to a larger story left unexplored. \"The New Kid\" is about a boy who's moving to a new planet with his family because of his father's career. The script was written by Gary Whitta and would have been produced by Mary Parent and Cale Boyter.\nAt PAX Australia in 2016, during a Q&amp;A session, Holkins revealed that changes at Paramount resulted in the movie rights being returned to Penny Arcade and the project canceled. He did note, however, that Whitta's script was complete and the project could move forward with another production company in the future.\n\"The Trenches\".\n\"The Trenches\" was a 2011-2015 comic series by Krahulik and Holkins in collaboration with webcomic \"PvP\"'s creator Scott Kurtz. The comic followed a man named Issac and his life as a game tester. The series was launched on August 9, 2011 and featured new strips every Tuesday and Thursday, usually accompanied by a \"Tale from the Trenches\", which was a short piece submitted by a reader detailing their own experiences in the game industry.\nIn September 2012, Kurtz stopped illustrating the webcomic, due to lack of time, and was replaced by Mary Cagle, a former intern of his, and the creator of the webcomic Kiwi Blitz. Kurtz still continued to collaborate with Krahulik and Holkins in writing the comic. In late August 2013, illustration was taken over by Ty Halley (\"Secret Life of a Journal Writer\") and Monica Ray (\"Phuzzy Comics\"), former contestants of the Penny Arcade series \"Strip Search\".\n\"The Trenches\" was ultimately abandoned. The last comic was posted January 5, 2016, while the last \"Tales\" is from September 10, 2015.\nThe Decideotron.\nIn 2011, Krahulik and Holkins released an application for iOS devices called \"The Decide-o-tron\", presented by Eedar and developed by The Binary Mill. The app worked as a recommendation engine for video games; users would input games they'd enjoyed and the app attempted to predict their ratings of titles they had not yet played. Holkins described it as \"Pandora for games\". By 2014, the decideotron.com website was dead.\nKickstarter.\nIn 2012, Penny Arcade created two Kickstarter projects. The first, in July 2012, was the \"Penny Arcade's Paint the Line\" card game which was used as an alternative to pre-ordering it and came with an exclusive comic. 259 backers pledged $9,025 to this project. The second, running from July to August 2012, was entitled \"Penny Arcade Sells Out\" and was intended to replace advertising revenue with crowd funding. The leaderboard ad on the home page of Penny Arcade would be removed if the minimum goal of $250,000 were reached, whereas the entire site would become completely ad-free for a year at $999,999. 9,069 backers pledged $528,144 to the project. The reality web series described as \"our version of America's Next Top Webcomic\" titled \"Strip Search\" arose from the $450,000 stretch goal.\n\"I Come in Peace, With Console Advice\".\nKrahulik and Holkins created a comic strip which compares the 7th generation consoles that appears in the December 2006 issue of \"Wired\" magazine.\n\"Penny Arcade\" events.\nEvery Christmas since 2003, \"Penny Arcade\" hosts a charity called Child's Play to buy new toys for children's hospitals. As of 2025, Child's Play had processed over $67 million in donations since its inception. They have also sponsored a three-day gaming festival called the Penny Arcade Expo, later renamed to PAX, every August since 2004.\nLegal issues and controversy.\nStrawberry Shortcake.\nKrahulik and Holkins received a cease-and-desist letter from American Greetings Corporation over the use of American Greetings' Strawberry Shortcake and Plum Puddin' characters in the April 14, 2003 \"Penny Arcade\" strip entitled \"Tart as a Double Entendre\".\nThe duo chose not to enter into a legal battle over whether or not the strip was a protected form of parody, and they complied with the cease-and-desist by replacing it with an image directing their audience to send a letter to a lawyer for American Greetings. They later lampooned the incident by portraying an American Greetings employee as a Nazi.\nJack Thompson.\nOn October 17, 2005 Krahulik and Holkins donated US$10,000 to the Entertainment Software Association foundation in the name of Jack Thompson, a disbarred attorney and activist against violence in video games. Earlier, Thompson himself had promised to donate $10,000 if a video game was created in which the player kills video game developers (\"A Modest Video Game Proposal\"), but after a mod to the game \"Grand Theft Auto\" was pointed out to already exist, Thompson called his challenge satire (referring to the title of the letter as a reference to \"A Modest Proposal\") and refused to donate the money. He claimed these games were not going to be manufactured, distributed, or sold like retail games, as his Modest Proposal stated, and therefore, the deal went unfulfilled. His refusal was met with disdain, given that multiple games were created or in the process of being created under Thompson's criteria. Krahulik and Holkins donated the money in his place, with a check containing the memo: \"For Jack Thompson, Because Jack Thompson Won't\".\nThompson proceeded to phone Krahulik, as related by Holkins in the corresponding news post.\nOn October 18, 2005 it was reported that Jack Thompson had faxed a letter to Seattle Police Chief Gil Kerlikowske claiming that \"Penny Arcade\" \"employs certain personnel who have decided to commence and orchestrate criminal harassment of me by various means\". Holkins defended the site by saying that the \"harassment\" Thompson referred to was simply \"the natural result of a public figure making statements that people disagree with, and letting him know their thoughts on the matter via his publicly available contact information\".\nOn October 21, 2005 Thompson claimed to have sent a letter to John McKay, U.S. Attorney for the Western District of Washington, in an attempt to get the FBI involved. Thompson re-iterated his claims of \"extortion\" and accused \"Penny Arcade\" of using \"their Internet site and various other means to encourage and solicit criminal harassment\". Penny Arcade denied the charge of \"extortion\", noting that they paid the $10,000 to charity, and asked nothing in return.\nThompson claimed the harassment of him is a direct result of Mike Krahulik's posts, which listed links to the Florida Bar Association. Thompson accused \"Penny Arcade\" of soliciting complaints to the Bar against him, even though Krahulik actually posted the opposite, asking fans to cease sending letters to the Bar, as the Bar acknowledged that it is aware of Thompson's actions, thanks to previous letters.\nThe Seattle PD eventually acknowledged receiving a complaint from Thompson, but have commented that they believe the issue to be a civil, rather than criminal, matter. They noted that this was from initial impressions of the letter they received, and their criminal investigations bureau is reviewing the letter to make sure that there were not any criminal matters that they missed.\nOn the same day, Scott Kurtz, creator of the webcomic \"PvP (webcomic)\" and a longtime friend of Krahulik and Holkins, used the image of the letter Thompson sent to the Seattle PD to create a parody letter in which Jack attempts to enlist the aid of the Justice League of America by claiming Gabe and Tycho to be villains of some description.\nThe \"Penny Arcade\" shop had at the time sold an \"I hate Jack Thompson\" T-shirt, claiming that every living creature, including Thompson's own mother, hates Jack Thompson.\nOn March 21, 2007 Thompson filed a countersuit to the lawsuit brought against him by Take Two Interactive claiming that they are at the center of a RICO conspiracy. \"Penny Arcade\" was named as one of the co-conspirators. At Sakura-Con 2007, Krahulik announced that the suit had been dropped.\nDickwolves controversy.\nIn an August 11, 2010 comic entitled \"The Sixth Slave\", an NPC pleads with a player who then refuses to save him: \"Every morning, we are roused by savage blows. Every night, we are raped to sleep by the dickwolves\". The strip drew criticism from many commentators, including from \"The American Prospect\" and \"The Boston Phoenix\". Krahulik and Holkins dismissed these criticisms, later selling \"Team Dickwolves\" T-shirts based on the strip. They later removed the \"Team Dickwolves\" shirt from their store due to complaints that it made potential PAX attendees uncomfortable. After the removal, Krahulik posted online that removing the shirts was only partly caving to pressure but mainly due to people who had personally emailed him and were reasonable with their concerns. Krahulik also stated that anyone still hesitant about going to PAX even after removal of the shirts should not come to PAX. In September 2013, on the last day of PAX, Krahulik told a panel that he thought that \"pulling the dickwolves merchandise was a mistake\", to cheers from the crowd. However, Krahulik later apologized on the \"Penny Arcade\" website, stating that he regretted contributing to the furor that had followed the original comic. Both critics of the comic strip and Krahulik and Holkins, made claims of receiving verbal abuse through social media and death threats.\nIn a 2012 article in the \"Journal of Broadcasting &amp; Electronic Media\", academics Salter &amp; Blodgett used the Dickwolves incident as a case study into \"hypermasculinity and sexism within the gaming community\", and argued that \"this case highlights how the hypermasculine discourse encourages the overt privileging of masculinity over femininity and discourages women from engaging in gendered discourse within the community.\"\n\"Greater Internet Fuckwad Theory\".\n\"John Gabriel's Greater Internet Fuckwad Theory\" was posted in the \"Penny Arcade\" strip published March 19, 2004. It regards the online disinhibition effect, in which Internet users exhibit unsociable tendencies while interacting with other Internet users. Krahulik and Holkins suggest that, given both anonymity and an audience, an otherwise regular person becomes aggressively antisocial. In 2013, Holkins gave the corollary that \"Normal Person - \"Consequences\" + Audience = Total Fuckwad\".\nClay Shirky, an adjunct professor at New York University who studies social and economic effects of Internet technologies, explains: \"There\u2019s a large crowd and you can act out in front of it without paying any personal price to your reputation,\u201d which \"creates conditions most likely to draw out the typical Internet user\u2019s worst impulses.\" In an \"Advocate\" article about online homophobia, this theory was used to account for behavior on online forums where one can remain anonymous in front of an audience: for instance, posting comments on popular YouTube videos.\nReception.\nOn December 13, 2006, \"Next Generation Magazine\" rated Krahulik and Holkins among its \"Top 25 People of the Year\". Also appearing on the list were Nintendo of America President Reggie Fils-Aim\u00e9 and former Xbox corporate vice-president Peter Moore. Krahulik made a post about the honor, in which he explained that \"Penny Arcade\" was created only because Next Gen rejected the duo's entry to a comic contest many years before. \"Entertainment Weekly\" listed \"Penny Arcade\" on their \"100 Sites to Bookmark Now,\" calling it \"a hilarious and smart webcomic for gamers.\" MTV Online named Holkins and Krahulik two of the world's most influential gamers, saying \"they have become the closest the medium has to leaders of a gamers' movement.\" Time.com named \"Penny Arcade\" as one of its \"50 Best Websites\" for 2008 \"...for the way it pokes fun at the high-tech industry and the people who love it.\"\n1UP.com described it as \"the One True Gaming Webcomic.\" \"Penny Arcade\" was used along with \"American Elf\", \"Fetus-X\", and \"Questionable Content\" as an example of comics using the web to create \"an explosion of diverse genres and styles\" in Scott McCloud's 2006 book \"Making Comics\".\nAwards and recognition.\nOn March 5, 2009, the Washington State Senate honored Holkins and Krahulik, both originally from Spokane, for the contribution that they had made to the state, the video game industry, and to children's charities from around the world courtesy of their Child's Play initiative. Later in March, \"Penny Arcade\" won the category \"Best Webcomic\" in the fan voted Project Fanboy Awards for 2008.\nIn 2010, Holkins, Krahulik, and Khoo were awarded the annual \"Ambassador Award\" at GDC's Game Developers Choice Awards for contributions they had made to the industry. The same year, \"Time\" included Holkins and Krahulik in the annual \"Time 100\", the magazine's listing of the world's 100 most influential people.\nIn July 2015, Holkins and Krahulik were recognized as \"Multimedia Empire Builders\" in Ad Week's 10 Visual Artists Changing the Way We See Advertising issue.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24675", "revid": "4145", "url": "https://en.wikipedia.org/wiki?curid=24675", "title": "Permanent Way Institution", "text": "British professional institution for railway engineering\nThe Permanent Way Institution is a technical Institution which aims to provide technical knowledge, advice and support to all those engaged in rail infrastructure systems worldwide.\nPermanent Way is used to describe the course of a railway line, including the components that form the track, aggregate that supports the track and the civil engineering assets covering bridges, tunnels, viaducts and earthworks.\nSections.\nThe Permanent Way Institution is split up into a number of sections throughout the United Kingdom and also has internationally located sections across the world.\nMembership is open to anyone who is either actively involved in the rail industry, retired or just has a general interest in rail infrastructure engineering.\nHome Sections are:\nAshford, \nCroydon &amp; Brighton, \nGlasgow, \nLondon, \nNorth Wales, \nWessex, \nBirmingham, \nDarlington &amp; NE, \nManchester &amp; Liverpool, \nNottingham &amp; Derby, \nSouth &amp; West Wales, \nWest Yorkshire, \nBristol &amp; West of England, \nEdinburgh, \nLancaster, Barrow &amp; Carlisle, \nMilton Keynes, \nSheffield &amp; Doncaster, \nThames Valley, \nYork\nMembership Grades.\nThe Permanent Way Institution has been a licensed member of the Engineering Council since 2019, and can assess and register candidates with Engineering Technician (EngTech), Incorporated Engineer (IEng) and Chartered Engineer (CEng) status.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24676", "revid": "12608568", "url": "https://en.wikipedia.org/wiki?curid=24676", "title": "President of Ireland", "text": "Head of state of Ireland\nThe president of Ireland () is the head of state of Ireland and the supreme commander of the Irish Defence Forces. The presidency was established by the Constitution of Ireland in 1937. The first president assumed office in 1938, and became recognised internationally as head of state in 1949 after the coming into effect of the Republic of Ireland Act. The president's official residence and principal workplace is in Phoenix Park, Dublin.\nThe presidency is a predominantly ceremonial institution, serving as the representative of the Irish state both at home and abroad. Nevertheless, the office of president is endowed with certain powers which have constitutional importance. While \u00c9amon de Valera described his intentions for the office as being 'mainly to guard the Constitution', such a description is depricated by academic commentators, with the leading constitutional text noting \"the Constitution is extremely sparing in its attribution of any independent functions to the office at all\".\nPresidents hold office for seven years, and may serve a maximum of two terms. The president is elected directly by the people, although there is no poll if only one candidate is nominated, which has occurred on six occasions, most recently in 2004. Catherine Connolly has served as president since her inauguration on 11 November 2025, having won the 2025 Irish presidential election. She is the tenth person to hold the office, as well as the third woman, following the successive tenures of Mary Robinson and Mary McAleese. Upon taking up the role, the president makes a solemn oath to \"...maintain the Constitution of Ireland and uphold its laws...\".\nHistory.\nThe office of president was established in 1937, in part as a replacement for the office of governor-general that existed during the 1922\u20131937 Irish Free State. The seven-year term of office of the president was inspired by that of the presidents of Weimar Germany. At the time the office was established critics warned that the post might lead to the emergence of a dictatorship. However, these fears were not borne out as successive presidents played a limited, largely apolitical role in national affairs.\nHead of state from 1937 to 1949.\nDuring the period of 1937 to 1949 it was unclear whether the Irish head of state was actually the president of Ireland or George VI, the king of Ireland. This period of confusion ended in 1949 when the state was declared to be a republic. The 1937 constitution did not mention the king, but neither did it state that the president was head of state, saying rather that the president \"shall take precedence over all other persons in the State\". The president exercised some powers that could be exercised by heads of state but which could also be exercised by governors or governors-general, such as appointing the government and promulgating the law.\nHowever, upon his accession to the throne in 1936, George VI had been proclaimed, as previous monarchs had been, \"King of Ireland\" and, under the External Relations Act of the same year, it was this king who represented the state in its foreign affairs. Treaties, therefore, were signed in the name of the King of Ireland, who also accredited ambassadors and received the letters of credence of foreign diplomats. This role meant, in any case, that George VI was the Irish head of state in the eyes of foreign nations. The Republic of Ireland Act 1948, which came into force in April 1949, proclaimed a republic and transferred the role of representing the state abroad from the monarch to the president. No change was made to the constitution.\nAccording to Desmond Oulton (owner of Clontarf Castle), his father John George Oulton had suggested to \u00c9amon de Valera towards the end of the Irish Free State, that Ireland should have its own king again, as it was in the times of Gaelic Ireland. He suggested to him, a member of the O'Brien Clan, descended in the paternal line from Brian Boru, a previous High King of Ireland: the most senior representative at the time was Donough O'Brien, 16th Baron Inchiquin. Oulton said that Donough's nephew Conor O'Brien, 18th Baron Inchiquin, confirmed that De Valera did offer Donough O'Brien the title of Prince-President of the Irish Republic, but this was turned down and so a President of Ireland was instituted instead.\nEvolving role.\nAfter the inaugural presidency of Douglas Hyde, who was an interparty nominee for the office, the nominees of the Fianna F\u00e1il political party won every presidential election until 1990. The party traditionally used the nomination as a reward for its most senior and prominent members, such as party founder and longtime Taoiseach \u00c9amon de Valera and European Commissioner Patrick Hillery. Most of its occupants to that time followed Hyde's precedent-setting conception of the presidency as a conservative, low-key institution that used its ceremonial prestige and few discretionary powers sparingly. In fact, the presidency was such a quiet position that Irish politicians sought to avoid contested presidential elections as often as possible, feeling that the attention such elections would bring to the office was an unnecessary distraction, and office-seekers facing economic austerity would often suggest the elimination of the office as a money-saving measure.\nDespite the historical meekness of the presidency, however, it has been at the centre of some high-profile controversies. In particular, the fifth president, Cearbhall \u00d3 D\u00e1laigh, faced a contentious dispute with the government in 1976 over the signing of a bill declaring a state of emergency, which ended in \u00d3 D\u00e1laigh's resignation. His successor, Patrick Hillery, was also involved in a controversy in 1982, when then-Taoiseach Garret FitzGerald requested a dissolution of the D\u00e1il \u00c9ireann. Hillery was bombarded with phone calls from opposition members urging him to refuse the request, an action that Hillery saw as highly inappropriate interference with the president's constitutional role and resisted the political pressure.\nThe presidency began to be transformed in the 1990s. Hillery's conduct regarding the dissolution affair in 1982 came to light in 1990, imbuing the office with a new sense of dignity and stability. However, it was Hillery's successor, seventh president Mary Robinson, who ultimately revolutionised the presidency. The winner of an upset victory in the highly controversial election of 1990, Robinson was the Labour nominee, the first president to defeat Fianna F\u00e1il in an election and the first female president. Upon election, however, Robinson took steps to de-politicise the office. She also sought to widen the scope of the presidency, developing new economic, political and cultural links between the state and other countries and cultures, especially those of the Irish diaspora. Robinson used the prestige of the office to activist ends, placing emphasis during her presidency on the needs of developing countries, linking the history of the Great Irish Famine to today's nutrition, poverty and policy issues, attempting to create a bridge of partnership between developed and developing countries. Since 2019, the president has attended annual meetings of the Arraiolos Group of European non-executive presidents.\nMode of selection and term of office.\nElection.\nThe president is directly elected by secret ballot using the instant-runoff voting, the single-winner analogue of the single transferable vote. Under the Presidential Elections Act, 1993 a candidate's election formally takes place in the form of a 'declaration' by the returning officer. Where more than one candidate is nominated, the election is 'adjourned' so that a ballot can take place, allowing the electors to choose between candidates. A presidential election is held in time for the winner to take office the day after the end of the incumbent's seven-year term. In the event of premature vacancy, an election must be held within sixty days.\nOnly resident Irish citizens aged eighteen or more may vote; a 1983 bill to extend the right to resident British citizens was ruled unconstitutional.\nCandidates must be Irish citizens and over 35 years old. There is a discrepancy between the English- and Irish-language texts of Article 12.4.1\u00b0. According to the English text, an eligible candidate \"has reached his thirty-fifth year of age\", whereas the Irish text states \" (has completed his thirty-five years)\". Because a person's thirty-fifth year of life begins on their thirty-fourth birthday, this means there is a year's difference between the minimum ages as stated in the two texts. However, the Irish version of the subsection prevails in accordance with the rule stated in Article 25.5.4\u00b0. Various proposals have been made to amend the Constitution so as to eliminate this discrepancy. The 29th government introduced the Thirty-fifth Amendment of the Constitution (Age of Eligibility for Election to the Office of President) Bill 2015 to reduce the age of candidacy from 35 to 21, which was put to referendum in May 2015; the bill was heavily defeated, with approximately 73% of voters voting against.\nPresidents can serve a maximum of two terms, consecutive or otherwise. They must be nominated by one of the following:\nWhere only one candidate is nominated, the candidate is deemed elected without the need for a ballot. For this reason, where there is a consensus among political parties not to have a contest, the president may be 'elected' without the occurrence of an actual ballot. Since the establishment of the office this has occurred on six occasions.\nThe 2nd most recent presidential election was held on 26 October 2018.\nThe most recent presidential election was held on 24 October 2025.\nAbsence of a president.\nThere is no office of vice president of Ireland. In the event of a premature vacancy in the presidency, a successor must be elected within sixty days. In a vacancy or where the president is unavailable, the duties and functions of the office are carried out by a Presidential Commission, consisting of the chief justice, the ceann comhairle (speaker) of the D\u00e1il, and the cathaoirleach (chairperson) of the Seanad. Routine functions, such as signing bills into law, have often been fulfilled by the Presidential Commission when the president is abroad on a state visit. The Government's power to prevent the president leaving the state is relevant in aligning the diplomatic and legislative calendars.\nTechnically, each president's term of office expires at midnight on the day of the new president's inauguration. Therefore, between midnight and the swearing-in of a new president, official duties and functions of the presidency are carried out by the Presidential Commission. The constitution also empowers the Council of State, acting by a majority of its members, to \"make such provision as to them may seem meet\" for the exercise of the duties of the president in any contingency the constitution does not foresee. However, to date, it has never been necessary for the Council to take up this role. Although an outgoing president who has been re-elected is usually described in the media as \"president\" before the taking of the Declaration of Office, that is actually incorrect. Technically, the outgoing president is a \"former\" president and, if re-elected, \"president-elect\".\nVacancies in the presidency have occurred three times: on the death in office of Erskine Hamilton Childers in 1974, and on the resignations of Cearbhall \u00d3 D\u00e1laigh in 1976 and Mary Robinson in 1997.\nImpeachment and removal from office.\nThe president can be removed from office in two ways, neither of which has ever been invoked. The Supreme Court, in a sitting of at least five judges, may find the president \"permanently incapacitated\", while the Oireachtas may remove the president for \"stated misbehaviour\". Either house of the Oireachtas may instigate the latter process by passing an impeachment resolution, provided at least thirty members move it and at least two-thirds support it. The other house will then either investigate the stated charges or commission a body to do so; following which at least two-thirds of members must agree both that the president is guilty and that the charges warrant removal.\nOrdinary duties and functions.\nThe Constitution of Ireland provides for a parliamentary system of government, by which the role of the head of state is largely a ceremonial one. The president is formally one of three parts of the Oireachtas (national parliament), which also comprises D\u00e1il \u00c9ireann (the Assembly of Ireland or lower house) and Seanad \u00c9ireann (the Senate of Ireland or upper house).\nUnlike most parliamentary republics, the president is not designated as the \"nominal\" chief executive. Rather, executive authority in Ireland is expressly vested in the Government (informally known as \"Cabinet\"). The Government is nevertheless obliged by Article 28.5 to keep the president generally informed on matters of foreign and domestic policy. Most of the functions of the president may be performed only in accordance with the strict instructions of the Constitution, or on the binding \"advice\" of the Government. The president does, however, possess certain personal powers that may be exercised discretionarily.\nConstitutional functions.\nThe ministerial duties mandated by the Constitution are as follows:\nStatutory functions.\nIn additional to constitutional mandates, the president:\nCivic functions.\nConstitutional and statutory functions aside, the president also:\nReserve powers.\nPowers exercised in absolute discretion.\nThe president possesses the following powers exercised \"in his absolute discretion\" according to the English version of the Constitution. The Irish version states that these powers are exercised \"as a chomhairle f\u00e9in\" which is usually translated as \"under his own counsel\". Lawyers have suggested that a conflict may exist in this case between the two versions of the constitution. In the event of a clash between the Irish and English versions of the constitution, the Irish one is given supremacy. While \"absolute discretion\" appears to leave some freedom for manoeuvre for a president in deciding whether to initiate contact with the opposition, \"own counsel\" has been interpreted by some lawyers as suggesting that \"no\" contact whatsoever can take place. As a result, it is considered controversial for the president to be contacted by the leaders of any political parties in an effort to influence a decision made using the discretionary powers.\nRefusal of a D\u00e1il dissolution.\nA taoiseach who has \"ceased to retain the support of a majority in D\u00e1il Eireann\" is required to resign, unless the taoiseach asks the president to dissolve the D\u00e1il. The president has the right to refuse such a request, in which case the taoiseach must resign immediately. This power has never been invoked. However, the necessary circumstances existed in 1944, 1982 and 1994. The apparent discrepancy, referred to above, between the Irish and English versions of the Constitution has discouraged presidents from contemplating the use of the power. On the three occasions when the necessary circumstances existed, this same discrepancy has led presidents to adopt an ultra-strict policy of non-contact with the opposition. The most notable instance of this was in January 1982, when Patrick Hillery instructed an aide, Captain Anthony Barber, to ensure that no telephone calls from the opposition were to be passed on to him. Nevertheless, three opposition figures, including Fianna F\u00e1il leader Charles Haughey, demanded to be connected to Hillery, with Haughey threatening to end Barber's career if the calls weren't put through. Hillery considered such pressure as gross misconduct. As Supreme Commander of the Defence Forces, Hillery recorded the threat in Barber's military personnel file and noted that Barber had been acting on his instructions in refusing the call. Even without this consideration, refusing such a request would arguably create a constitutional crisis, as it is considered a fairly strong constitutional convention that the head of state always grants a parliamentary dissolution.\nAppointees to the Council of State.\nThe president appoints up to seven members of the Council of State, and may remove or replace such appointed members.\nPowers exercised after consulting the Council of State.\nIt is required that, before exercising certain reserve powers, the president consult the Council of State. However, the president is not compelled to act in accordance with the Council's advice. Indeed, the president may act contrary to its advice. Those powers are as follows:\nRefer bills to the Supreme Court.\nThe president may refer a bill, in whole or part, to the Supreme Court to test its constitutionality. If the Supreme Court finds any referred part unconstitutional, the entire bill falls. This power may not be applied to a money bill, a bill to amend the Constitution, or an urgent bill the time for the consideration of which has been abridged in the Seanad. This is the most widely used reserve power; a full list is at Council of State (Ireland)#Referring of bills. In a 1982 judgment delivered under such a referral, Chief Justice Tom O'Higgins bemoaned the crude strictures of the prescribed process; especially the fact that, if the court finds that a bill does not violate the Constitution, this judgment can never subsequently be challenged.\nRefer bills to the people.\nIf requested to do so by a petition signed by a majority of the membership of the Seanad and one-third of the membership of the D\u00e1il, the president may, after consultation with the Council of State, decline to sign into law a bill (other than a bill to amend the constitution) they consider to be of great \"national importance\" until it has been approved by either the people in a referendum or the D\u00e1il reassembling after a general election, held within eighteen months. This power has never been used, and no such petition has been invoked. Of the 60 senators, 11 are nominated by the Taoiseach, so there is rarely a majority opposed to a Government bill.\nMaintain parliamentary democracy.\nAside from assuring the constitutionality of primary legislation and facilitating the referendum process, the presidency is endowed with powers concerning the institutional stability and continuity of the Oireachtas. The president may, at the request of the D\u00e1il, impose a time-limit on the period during which the Seanad may consider a bill. The effect of this power is to restrict the power of the Seanad to delay a bill that the Government considers urgent. Conversely, the president may, if requested to do so by the Seanad, establish a Committee of Privileges to resolve a dispute between the two Houses of the Oireachtas as to whether or not a bill is a money bill. In practice, this power guarantees the Seanad is able to exercise its rights as an upper house. Likewise, the president may convene a meeting of either or both Houses of the Oireachtas. This power allows the president to step in if, in extraordinary circumstances, the ordinary procedures for convening the houses had broken down.\nCommunicate with Ireland's parliament and people.\nThe presidency's remaining reserve powers embrace formal communications of a legislative or historically significant nature. The president may address, or send a message to, either or both Houses of the Oireachtas. Four such addresses have been made: one by de Valera, two by Robinson, and one by McAleese. The approval of the Government is needed for the message; in practice, the entire text is submitted. The president may also \"address a message to the Nation\" subject to the same conditions as an address to the Oireachtas. This power has never been used. Commonplace messages, such as Christmas greetings or communications of a purely civic or charitable character, are not considered to qualify.\nPrivileges of office.\nResidence and honours.\nThe official residence of the president is \u00c1ras an Uachtar\u00e1in, located in the Phoenix Park in Dublin. The ninety-two-room building formerly served as the 'out-of-season' residence of the Irish Lord Lieutenant and the residence of two of the three Irish Governors-General: Tim Healy and James McNeill. In 2025, while \u00c1ras an Uachtar\u00e1in was being renovated, President Catherine Connolly lived elsewhere in Phoenix Park, in the Steward's Lodge. The president is normally referred to as 'President' or 'Uachtar\u00e1n', rather than 'Mr/Madam President' or similar forms. The style used is normally \"His Excellency/Her Excellency\" (); sometimes people may orally address the president as 'Your Excellency' ( ), or simply 'President' ( (vocative case)). The Presidential Salute is taken from the National Anthem, \"\". It consists of the first four bars followed by the last five, without lyrics.\nOffice of the President.\nThe Office of the President is a part of the Civil Service of the State headed by the Secretary-General to the President. Much of the protocol and convention surrounding the presidency was developed by Michael McDunphy, the first Secretary-General (then called Secretary). The budget estimate for 2026 for the office is \u20ac6.2 million, including \u20ac2.8 million for the staff of \u00c1ras an Uachtar\u00e1in. Oireachtas debate on this budget item is curtailed due to the president's constitutional independence. The Office of the President liaises with the government via the Government Secretariat in the Department of the Taoiseach. Maintenance of the official residence is by the Office of Public Works. A president is entitled to choose non\u2013civil servants to employ as special adviser, head of communications, speech writer and personal assistant.\nInauguration.\nThe inauguration ceremony takes place on the day following the expiry of the term of office of the preceding president. No location is specified in the constitution, but all inaugurations have taken place in Saint Patrick's Hall in the State Apartments in Dublin Castle. The ceremony is transmitted live by national broadcaster RT\u00c9 on its principal television and radio channels, typically from around 11 am. To highlight the significance of the event, all key figures in the executive (the government of Ireland), the legislature (Oireachtas) and the judiciary attend, as do members of the diplomatic corps and other invited guests.\nDuring the period of the Irish Free State (1922 to 1937), the governor-general had been installed into office as the representative of the Crown in a low-key ceremony, twice in Leinster House (the seat of the Oireachtas), but in the case of the last governor-general, Domhnall Ua Buachalla, in his brother's drawing room. By contrast, the Constitution of Ireland adopted in 1937 requires the president's oath of office be taken in public.\nRemuneration and expenses.\nAfter the 2018 presidential election the official salary or \"personal remuneration\" of the president will be \u20ac249,014. The incumbent, Michael D. Higgins, chooses to receive the same salary although he is entitled to a higher figure of \u20ac325,507. The president's total \"emoluments and allowances\" includes an additional \u20ac317,434 for expenses. The Office of the President's total budget estimate for 2017 was \u20ac3.9 million, of which \u20ac2.6 million was for pay and running costs, and the balance for the \"President's Bounty\" paid to centenarians on their hundredth birthday.\nThe salary was fixed at IR\u00a35000 from 1938 to 1973, since when it has been calculated as 10% greater than that of the chief justice. After the post-2008 Irish economic downturn most public-sector workers took significant pay cuts, but the Constitution prohibited a reduction in the salary of the president and the judiciary during their terms of office, in order to prevent such a reduction being used by the government to apply political pressure on them. While a 2011 Constitutional amendment allows judges' pay to be cut, it did not extend to the president, although incumbent Mary McAleese offered to take a voluntary cut in solidarity.\nSecurity and transport.\nAs head of state of Ireland, the president receives the highest level of protection in the state. \u00c1ras an Uachtar\u00e1in is protected by armed guards from the Garda S\u00edoch\u00e1na and Defence Forces at all times, and is encircled by security fencing and intrusion detection systems. At all times the president travels with an armed security detail in Ireland and overseas, which is provided by the Special Detective Unit (SDU), an elite wing of the Irish police force. Protection is increased if there is a known threat. The presidential limousine is a Mercedes-Benz S-Class LWB. The Presidential Limousine is dark navy blue and carries the presidential standard on the left front wing and the tricolour on the right front wing. When travelling the presidential limousine is always accompanied by support cars (normally BMW 5 Series, Audi A6 and Volvo S60 driven by trained drivers from the SDU) and several Garda motorcycle outriders from the Garda Traffic Corps which form a protective convoy around the car.\nThe president-elect is usually escorted to and from the ceremony by the Presidential Motorcycle Escort ceremonial outriders. Until 1947 they were a cavalry mounted escort, known as the Blue Hussars (due to wearing light blue hussar-style uniforms). However to save money the First Inter-Party Government replaced the Irish horses by Japanese motorbikes, which the then Minister for Defence believed would be \"much more impressive\".\nAt the presidential inauguration in 1945, alongside the mounted escort on horseback, president-elect Se\u00e1n T. O'Kelly rode in the old state landau of Queen Alexandra. The use of the state carriage was highly popular with crowds. However an accident with a later presidential carriage at the Royal Dublin Society Horse show led to the abolition of the carriage and its replacement by a Rolls-Royce Silver Wraith landaulette in 1947. This distinctive car is still the Presidential State Car, which is used only for ceremonial occasions, as to bring the president to and from the inauguration.\nThe president also has the full use of all Irish Air Corps aircraft at his/her disposal if so needed, including helicopters and private jets.\nIssues of controversy.\nPresidential role in Northern Ireland.\nThe text of the Constitution of Ireland, as originally enacted in 1937, made reference in its Articles 2 and 3 to two geopolitical entities: a thirty-two county 'national territory' (i.e., the island of Ireland), and a twenty-six county 'state' formerly known as the Irish Free State. The implication behind the title 'president of Ireland' was that the president would function as the head of all Ireland. However, this implication was challenged by the Ulster Unionists and the United Kingdom of Great Britain and Northern Ireland which was the state internationally acknowledged as having sovereignty over Northern Ireland. Articles 2 and 3 were substantially amended in consequence of the 1998 Good Friday Agreement.\nIreland in turn challenged the proclamation in the United Kingdom of Queen Elizabeth II in 1952 as '[Queen] of the United Kingdom of Great Britain and Northern Ireland'. The Irish government refused to attend royal functions as a result; for example, Patrick Hillery declined on government advice to attend the wedding of the Prince of Wales to Lady Diana Spencer in 1981, to which he had been invited by Queen Elizabeth, just as Se\u00e1n T. O'Kelly had declined on government advice to attend the 1953 Coronation Garden Party at the British Embassy in Dublin. Britain in turn insisted on referring to the president as 'president of the Republic of Ireland' or 'president of the Irish Republic'. Letters of Credence from Queen Elizabeth, on the British government's advice, appointing United Kingdom ambassadors to Ireland were not addressed to the 'president of Ireland' but to the president personally (for example: 'President Hillery').\nThe naming dispute and consequent avoidance of contact at head of state level has gradually thawed since 1990. President Robinson (1990\u201397) chose unilaterally to break the taboo by regularly visiting the United Kingdom for public functions, frequently in connection with Anglo-Irish relations or to visit the Irish emigrant community in Great Britain. In another breaking of precedent, she accepted an invitation to Buckingham Palace by Queen Elizabeth II. Palace accreditation supplied to journalists referred to the \"visit of the president of Ireland\". Between 1990 and 2010, both Robinson and her successor President McAleese (1997\u20132011) visited the Palace on numerous occasions, while senior members of the British royal family \u2013 the then-Prince of Wales (later Charles III); the then-Duke of York (later Andrew Mountbatten-Windsor); Prince Edward, then-Earl of Wessex; and Prince Philip, Duke of Edinburgh \u2013 all visited both presidents of Ireland at \u00c1ras an Uachtar\u00e1in. The presidents also attended functions with the Princess Royal. President Robinson jointly hosted a reception with the queen at St. James's Palace, London, in 1995, to commemorate the one hundred and fiftieth anniversary of the foundation of the Queen's Colleges in 1845 (the Queen's Colleges are now known as Queen's University Belfast, University College Cork, and the University of Galway). These contacts eventually led to a state visit of Elizabeth II to Ireland in 2011.\nThough the president's title implicitly asserted authority in Northern Ireland, in reality the Irish president needed government permission to visit there. (The Constitution of Ireland in Article 3 explicitly stated that \"[p]ending the re-integration of the national territory\" the authority of the Irish state did not extend to Northern Ireland. Presidents prior to the presidency of Mary Robinson were regularly refused permission by the Irish government to visit Northern Ireland.)\nHowever, since the 1990s and in particular since the Good Friday Agreement of 1998, the president has regularly visited Northern Ireland. President McAleese, who was the first president to have been born in Northern Ireland, continued on from President Robinson in this regard. In a sign of the warmth of modern British-Irish relations, she has even been warmly welcomed by most leading unionists. At the funeral for a child murdered by the Real IRA in Omagh she symbolically walked up the main aisle of the church hand-in-hand with the Ulster Unionist Party leader and then First Minister of Northern Ireland, David Trimble. But in other instances, Mary McAleese had been criticised for certain comments, such as a reference to the way in which Protestant children in Northern Ireland had been brought up to hate Catholics just as German children had been encouraged to hate Jews under the Nazi regime, on 27 January 2005, following her attendance at the ceremony commemorating the sixtieth anniversary of the liberation of Auschwitz concentration camp. These remarks caused outrage among Northern Ireland's unionist politicians, and McAleese later apologised and conceded that her statement had been unbalanced.\nSuggestions for reform.\nThere have been many suggestions for reforming the office of president over the years. In 1996, the Constitutional Review Group recommended that the office of president should remain largely unchanged. However, it suggested that the Constitution should be amended to explicitly declare the president to be head of state (at present that term does not appear in the text), and that consideration be given to the introduction of a constructive vote of no confidence system in the D\u00e1il, along the lines of that in Germany. If this system were introduced then the power of the president to refuse a D\u00e1il dissolution would be largely redundant and could be taken away. The All-party Oireachtas Committee on the Constitution's 1998 Report made similar recommendations.\nIn an October 2009 poll, concerning support for various potential candidates in the 2011 presidential election conducted by the \"Sunday Independent\", a \"significant number\" of people were said to feel that the presidency is a waste of money and should be abolished.\nList of presidents of Ireland.\nThe functions of the president were exercised by the Presidential Commission from the coming into force of the Constitution on 29 December 1937 until the election of Douglas Hyde in 1938, and during the vacancies of 1974, 1976, and 1997.\nFormer presidents who are able and willing to act are members of the Council of State.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24677", "revid": "43931369", "url": "https://en.wikipedia.org/wiki?curid=24677", "title": "Premier of Queensland", "text": "Head of government of the Australian state of Queensland\nThe premier of Queensland is the head of government in the Australian state of Queensland.\nBy convention, the premier is the leader of the party with a parliamentary majority in the Legislative Assembly of Queensland. The premier is appointed by the governor of Queensland.\nThe incumbent premier is David Crisafulli.\nConstitutional role.\nUnder section 43 of the Constitution of Queensland the premier and other members of Cabinet are appointed by the governor. They are collectively responsible to Parliament in accordance with responsible government. The text of the Constitution assigns to the premier certain powers, such as the power to assign roles (s 25) to assistant ministers (formerly known as parliamentary secretaries), and to appoint ministers as acting ministers (s 45) for a period of 14 days.\nIn practice, under the conventions of the Westminster System followed in Queensland, the premier's power is derived from two sources: command of a majority in the Legislative Assembly, and the premier's role as chair of Cabinet, determining the appointment and roles of ministers. Although ministerial appointments are the prerogative of the governor of Queensland, in normal circumstances the governor will make these appointments on the advice of the premier.\nImmediately following an election for the Legislative Assembly, the governor will call on the leader of the party which commands a majority in the Legislative Assembly to become premier and ask them to commission a government. A re-elected government will be resworn, with adjustments to the ministry as determined by the premier.\nPrior to the existence of political parties within the Leglislative Assembly, to become premier, that member had to be able to command the support of a majority of the individual members of the assembly; this group of members were known informally as \"Ministerialists\", while those who did not support the member who became premier were known informally as \"Oppositionists\" (or the Opposition).\nPremier's office.\nThe premier has an office in the Executive Annexe of Parliament House, Brisbane, which is normally used while Parliament is sitting. Their main office is located in 1 William Street, a skyscraper across the road from Parliament House. The office faces south-west, with floor to ceilings windows granting an impressive view of the Brisbane and its surrounds.\nList of premiers of Queensland.\nBefore the 1890s, there was no developed party system in Queensland. Political affiliation labels before that time indicate a general tendency only. Before the end of the first decade of the twentieth century, political parties were more akin to parliamentary factions, and were fluid, informal and disorganised by modern standards.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24678", "revid": "21910232", "url": "https://en.wikipedia.org/wiki?curid=24678", "title": "Premier of South Australia", "text": "Head of government for the state of South Australia\nThe Premier of South Australia is the head of government in the Australian state of South Australia. The Government of South Australia follows the Westminster system, with the Parliament of South Australia acting as the legislature. The Premier is appointed by the Governor of South Australia, and by modern convention holds office by virtue of their ability to command the support of a majority of members of the lower house of Parliament, the House of Assembly.\nPeter Malinauskas is the current Premier, having served since 21 March 2022. Thomas Playford IV is the longest serving Premier, and the longest serving head of government in Australian history, serving for over 26 years from 1938 until 1965, holding on to power thanks the Playmander.\nHistory.\nThe office of Premier of South Australia was established upon the commencement of responsible government with the passage of the \"Constitution Act 1856\". The role was based upon that of the prime minister of the United Kingdom, with the premier requiring the support of a majority of the members of the lower house to remain head of government. For the early years of responsible government, the office was held in conjunction with that of Chief Secretary of South Australia, a role that had existed since colonisation, but by the 1890's, this was no longer a convention.\nNo parties or solid groupings would be formed until after the 1890 election, which resulted in frequent changes of the premier of South Australia. If for any reason the incumbent premier lost sufficient support through a successful motion of no confidence at any time on the floor of the house, he would tender his resignation to the governor of South Australia, which would result in another member deemed to have the support of the House of Assembly being sworn in by the governor as the next premier.\nInformal groupings began and increased government stability occurred from the 1887 election. The United Labor Party would be formed in 1891, while the National Defence League would be formed later in the same year.\nBefore the 1890s when there was no formal party system in South Australia, MPs tended to have historical liberal or conservative beliefs. The liberals dominated government from the 1893 election to 1905 election with the support of the South Australian United Labor Party, with the conservatives mostly in opposition. Labor took government with the support of eight dissident liberals in 1905 when Labor won the most seats for the first time. The rise of Labor saw non-Labor politics start to merge into various party incarnations.\nThe two independent conservative parties, the Australasian National League (formerly the National Defence League) and the Farmers and Producers Political Union merged with the Liberal and Democratic Union to become the Liberal Union in 1910. Labor formed South Australia's first majority government after winning the 1910 state election, triggering the merger. The 1910 election came two weeks after federal Labor formed Australia's first elected majority government at the 1910 federal election.\nNo \"Country\" or rural conservative parties emerged as serious long-term forces in South Australian state politics, the majority folding into the main non-Labor party.\nList of premiers of South Australia.\nThe first six governors of South Australia oversaw governance from proclamation in 1836 until self-government and an elected Parliament of South Australia was enacted in the year prior to the inaugural 1857 election.\nPolitical parties\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Independent\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Liberalism\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Conservatism\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Liberal Federation/Union\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Liberal &amp; Country\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Liberal\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Labor\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24680", "revid": "40428319", "url": "https://en.wikipedia.org/wiki?curid=24680", "title": "Premier of Western Australia", "text": "Head of the executive branch of the state government of Western Australia\nThe premier of Western Australia is the head of government of the state of Western Australia. The role of premier at a state level is similar to the role of the prime minister of Australia at a federal level. The premier leads the executive branch of the Government of Western Australia and is accountable to the Parliament of Western Australia. The premier is appointed by the governor of Western Australia. By convention, the governor appoints as premier whoever has the support of the majority of the Western Australian Legislative Assembly, the lower house of the Parliament of Western Australia. In practice, this means that the premier is the leader of the political party or group of parties with a majority of seats in the Legislative Assembly. Since Western Australia achieved self-governance in 1890, there have been 31 premiers. Roger Cook is the current premier, having been appointed to the position on 8 June 2023.\nHistory.\nThe position of premier is not mentioned in the constitution of Western Australia. From 1890 to 1917, the premier was not an official position, rather, it was the title unofficially given, but widely used to refer, to the head of the government. When Western Australia became a self-governing colony in 1890, Governor William Robinson initially indicated he would use the title \"prime minister\" to refer to the head of the government. However, after he appointed John Forrest, the title \"premier\" was used for consistency with the other Australian colonies. The position was first officially mentioned when the governor appointed Henry Lefroy as premier on 28 June 1917. However, when the governor designated and declared the six executive offices of the government on 2 July 1917, the position of premier was not listed, creating an ambiguity. It was not until 3 April 1947 that the premier became one of the executive offices of the government.\nThe most common cause for a change of premier is an election. Since the 1990s, elections have occurred roughly every four years. Before then, elections were at most three years apart, except for during World War II. A less common cause for a change of premier is the ruling party changing its leader. This can occur as a result of a resignation, death or leadership spill. In this case, the new premier is whoever the party elects as its new leader. Another cause for a change of premier is a loss of majority support in the Legislative Assembly. This commonly occurred in the first three decades of self-governance, but has not occurred since 1916. If this occurs, the premier must either resign or be dismissed by the governor.\nPowers and function.\nThe powers of the premier are set out by convention and by legislation. By convention, the premier advises the Monarch of Australia as to who to appoint as governor. The premier advises the governor as to who to appoint to cabinet and which portfolios should be given to each cabinet minister. The premier sets out the responsibilities of ministers and the acts that they would administer. The premier leads the cabinet and chairs cabinet meetings. They communicate with the governor, the cabinet, the state government, other state and territory governments, the federal government, and overseas governments. The premier advises the governor on when state elections should be held. They oversee the Department of the Premier and Cabinet. While premier, they stay as a member of parliament and they retain their responsibility for representing their electoral district.\nCharacteristics.\nAs of 2023, there have been 31 premiers of Western Australia. Carmen Lawrence, who was appointed on 12 February 1990, is the first and only woman to be premier of Western Australia. She is also the first woman to be premier of an Australian state. By convention, the premier is a member of the Legislative Assembly. However, the premier can be a member of either house of parliament. Hal Colebatch is the only premier to be a member of the Legislative Council (upper house). He served for 30 days in 1919, making him the shortest serving premier of Western Australia. David Brand is the longest serving premier, serving for 11 years and 335 days between 1959 and 1971. The youngest premier is John Scaddan, who was 35 years, 2 months and 3 days old when he was sworn in in 1911. The oldest premier is John Tonkin, who was 69 years, 1 month and 1 day old when he was sworn in in 1971. Newton Moore became premier after two years in parliament, the least time aside from Forrest. Tonkin became premier after almost 38 years in parliament, the most time in parliament before becoming premier. The only father and son pair to have both been premier is Charles Court and his son Richard Court. George Leake, who died of pneumonia on 24 June 1902, is the only premier to have died in office. Moore, Philip Collier, John Willcock and Geoff Gallop are the only premiers to have resigned due to ill health.\nForrest, Colebatch and Lawrence are the only premiers to have served in the Parliament of Australia as well. Forrest and Lawrence are the only premiers to have been ministers in the Government of Australia as well. Moore is the only premier to have served in the House of Commons of the United Kingdom. The only premier to subsequently serve as governor is James Mitchell. George Leake, Frank Wilson, Phillip Collier and Mitchell are the only people to have been premier more than once. There are currently eight living former premiers. The most recent premier to die is Ray O'Connor, who was premier from 1982 to 1983 and died in 2013.\nTwo former premiers have been sentenced to jail. In 1994, Brian Burke was sentenced to two years in jail for defrauding the state by $17,000 by making false claims on the parliamentary imprest account. He was released on parole after serving seven months. In 1995, O'Connor served six months in jail for stealing a $25,000 cheque from the Bond Corporation during his time as premier. In 1997, Burke was sentenced to three years jail for stealing $122,585 in Labor Party campaign donations. He served six months before this conviction was quashed upon appeal.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24681", "revid": "1316746318", "url": "https://en.wikipedia.org/wiki?curid=24681", "title": "Pigeonhole sort", "text": "Sorting algorithm\nPigeonhole sorting is a sorting algorithm that is suitable for sorting lists of elements where the number \"n\" of elements and the length \"N\" of the range of possible key values are approximately the same. It requires O(\"n\" + \"N\") time. It is similar to counting sort, but differs in that it \"moves items twice: once to the bucket array and again to the final destination [whereas] counting sort builds an auxiliary array then uses the array to compute each item's final destination and move the item there.\"\nThe pigeonhole algorithm works as follows:\nImplementation.\nBelow is an implementation of Pigeonhole sort in pseudocode. This function sorts the array in-place and modifies the supplied array. \n function pigeonhole(array arr) is \n min \u2190 min(arr)\n max \u2190 max(arr) \n index \u2190 0\n range \u2190 max - min + 1\n array tmp \u2190 new array of length range\n for i = 0 to range STEP 1\n tmp[i] = 0\n for i = 0 to length(arr) STEP 1\n tmp[arr[i] - min] = tmp[arr[i] - min] + 1 \n for i = 0 to range STEP 1\n while tmp[i] &gt; 0 do\n tmp[i] = tmp[i] - 1\n arr[index] = i + min\n index = index + 1\nExample.\nSuppose one were sorting these value pairs by their first element:\nFor each value between 3 and 8 we set up a pigeonhole, then move each element to its pigeonhole:\nThe pigeonhole array is then iterated over in order, and the elements are moved back to the original list.\nThe difference between pigeonhole sort and counting sort is that in counting sort, the auxiliary array does not contain lists of input elements, only counts:\nFor arrays where \"N\" is much larger than \"n\", bucket sort is a generalization that is more efficient in space and time."}
{"id": "24682", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=24682", "title": "Prime Ministers of Japan", "text": ""}
{"id": "24683", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=24683", "title": "Pope Innocent XIII", "text": "Head of the Catholic Church from 1721 to 1724\nPope Innocent XIII (; ; 13 May 1655\u00a0\u2013 7 March 1724), born as Michelangelo dei Conti, was head of the Catholic Church and ruler of the Papal States from 8 May 1721 to his death in March 1724. He remains the most recent pope to take the pontifical name \"Innocent\".\nPope Innocent XIII was reform-oriented, and imposed new standards of frugality, abolishing excessive spending. He took steps to end the practice of nepotism by issuing a decree which forbade his successors from granting land, offices or income to any relatives \u2013 something opposed by many cardinals who hoped they might become pope and benefit their families.\nBiography.\nEarly life.\nMichelangelo dei Conti was born on 13 May 1655 in Poli, near Rome as the son of Carlo II, Duke of Poli, and Isabella d'Monti. Like Pope Innocent III (1198\u20131216), Pope Gregory IX (1227\u20131241) and Pope Alexander IV (1254\u20131261), he was a member of the aristocratic landowning family of the Conti, who held the titles of counts and dukes of Segni. He included the family shield in his pontifical coats of arms.\nConti commenced his studies in Ancona and then with the Jesuits in Rome at the Collegio Romano and then later at La Sapienza University. After he received his doctorate in canon law and civil law, he was ordained to the priesthood. Conti also served as the Referendary of the Apostolic Signatura in 1691, later to be appointed as the Governor of Ascoli until 1692. Conti was also the Governor of Campagna and Marittima from 1692 to 1693 and the Governor of Viterbo from 1693 to 1695.\nPope Innocent XII selected Conti as the Titular Archbishop of Tarsus on 13 June 1695 and he received his episcopal consecration on 16 June 1695 in Rome. Conti was also the nuncio to both Switzerland and Portugal.\nCardinalate.\nOn 7 June 1706, Conti was elevated to the cardinalate under Pope Clement XI (1700\u201321) and was made the Cardinal-Priest of Santi Quirico e Giulitta. His appointment came about as the replacement of Gabriele Filippucci who resigned the cardinalate. He would receive his titular church on 23 February 1711. From 1697 to 1710 he acted as papal nuncio to the Kingdom of Portugal, where he is believed to have formed those unfavourable impressions of the Jesuits which afterwards influenced his conduct towards them. While in Portugal, he was witness to Father Bartolomeu de Gusm\u00e3o's early aerostat experiments.\nHe was also transferred to Osimo as its archbishop in 1709 and was later translated one last time to Viterbo e Toscanella in 1712. He resigned his position in his diocese due to illness in 1719.\nPontificate.\nPapal election.\nAfter the death of Pope Clement XI in 1721, a conclave was called to choose a new pope. It took 75 ballots just to reach a decision and choose Conti as the successor of Clement XI. After all candidates seemed to slip, support turned to Conti. The curial factions also turned their attention to him. His high reputation for ability, learning, purity, and a kindly disposition secured his election, which occurred the morning of 8 May 1721. He chose the name of Innocent XIII in honour of Pope Innocent III. On the following 18 May, he was solemnly crowned by the protodeacon, Cardinal Benedetto Pamphili.\nActions.\nHis pontificate was prosperous, but comparatively uneventful. He held two consistories that saw three new cardinals elevated on 16 June 1721 and 16 July 1721.\nThe Chinese Rites controversy that started under his predecessor continued during his reign. Innocent XIII prohibited the Jesuits from prosecuting their mission in China, and ordered that no new members should be received into the order. This indication of his sympathies encouraged some French bishops to approach him with a petition for the recall of the papal bull \"Unigenitus\" by which Jansenism had been condemned; the request, however, was peremptorily denied.\nThe Pope also assisted Hospitaller Malta in its struggles against the Barbary pirates.\nInnocent XIII, like his predecessor, showed much favour to James Francis Edward Stuart, the \"Old Pretender\" to the British throne and liberally supported him. The pope's cousin, Francesco Maria Conti, from Siena, became chamberlain of James' little court in the Roman Muti Palace.\nConsistories.\nInnocent XIII held two consistories in which he named three cardinals. One of those new cardinals was his own brother, Bernardo Maria.\nBeatifications.\nInnocent XIII beatified three individuals during his pontificate: John of Nepomuk (31 May 1721), Dalmazio Moner (13 August 1721), and Andrea dei Conti (11 December 1723).\nDoctor of the Church.\nOn 25 April 1722, he named Saint Isidore of Seville as a Doctor of the Church.\nDeath and legacy.\nInnocent XIII fell ill in 1724. He was tormented by a hernia of which he spoke to nobody but his valet. At one point, it had burst and caused inflammation and fever. Innocent XIII asked for the last rites, made his profession of faith, and died on 7 March 1724, at the age of 68. His pontificate was unremarkable, given that he was hampered by physical suffering. He was interred in the grotto at Saint Peter's Basilica.\nInnocent XIII had suffered from a hernia about three to four months after his election but also suffered from acute attacks of pain due to kidney stones. But Innocent XIII did himself no favors with his excessive appetite and no exercise. He also suffered from lethargy that caused him to sleep a great deal. In mid-February 1724, his suffering grew worse to the point that he could no longer get up, suffering from an accumulation of water in his lower limbs in what was an indication of severe kidney problems. This led to his doctors fearing that he could develop congestive heart failure. On 3 March, despite his failing health, Innocent XIII set to work signing documents, though he suffered poor sleep that night and had a better day on 4 March. In the morning on 5 March, one of the papal doctors fed Innocent XIII a purgative, however, this backfired and only aggravated the hernia. An attempted reduction was only partially successful, resulting in a strangulated hernia, while the pope experienced great pain in the night between 5 and 6 March. However, a serious inflammation quickly set in, causing the pope to contract a fever. Innocent XIII, now very well aware of his state of health, immediately asked for the Viaticum, receiving it on 6 March as his family gathered to see him. However, there had been attempts to get the pope to name new cardinals, simply to create stronger factions in the conclave. At 4:00pm on 6 March, he signed a codicil to his will, and that night asked for and received the Extreme Unction. Innocent XIII died on 7 March.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24684", "revid": "49869292", "url": "https://en.wikipedia.org/wiki?curid=24684", "title": "Pope Julius I", "text": "Head of the Catholic Church from 337 to 352\nPope Julius I was the bishop of Rome from 6 February 337 to his death on 12 April 352. He was appealed to by Athanasius when the latter was deposed from his position as patriarch by Arian bishops, Julius then supported Athanasius and condemned his deposition as unjust. He was notable for asserting the authority of the pope over the Arian Eastern bishops, as well as being attributed with the setting of December 25 as the official birthdate of Jesus.\nPontificate.\nJulius was a native of Rome and was chosen as successor of Pope Mark after the Roman seat had been vacant for four months.\nArianism.\nJulius is chiefly known by the part he took in the Arian controversy. After the followers of Eusebius of Nicomedia, who had become the patriarch of Constantinople, renewed their deposition of Athanasius of Alexandria at a synod held in Antioch in 341, they resolved to send delegates to Constans, emperor of the West, and also to Julius, setting forth the grounds on which they had proceeded. Julius, after expressing an opinion favourable to Athanasius, adroitly invited both parties to lay the case before a synod to be presided over by himself. This proposal, however, the Arian Eastern bishops declined to accept.\nOn this second banishment from Alexandria, Athanasius came to Rome, and was recognised as a regular bishop by the synod presided over by Julius in 342. Julius sent a letter to the Eastern bishops that is an early instance of the claims of primacy for the bishop of Rome. Even if Athanasius and his companions were somewhat to blame, the letter runs, the Alexandrian Church should first have written to the pope. \"Can you be ignorant,\" writes Julius, \"that this is the custom, that we should be written to first, so that from here what is just may be defined\" (Epistle of Julius to Antioch, c. xxii).\nIt was through the influence of Julius that, at a later date, the council of Sardica in Illyria was held, which was attended by only seventy-six Eastern bishops, who speedily withdrew to Philippopolis and deposed Julius at the council of Philippopolis, along with Athanasius and others. The three hundred Western bishops who remained, confirmed the previous decisions of the Roman synod and issued a number of decrees regarding church discipline. The first canon forbade the transfer of bishops from one see to another, for if frequently made, it was seen to encourage covetousness and ambition.\nBy its 3rd, 4th, and 5th decrees relating to the rights of revision claimed by Julius, the council of Sardica perceptibly helped forward the claims of the bishop of Rome. Julius built several basilicas and churches.\nChristmas.\nSome have stated that, around 350 AD, Julius I declared December 25 as the official date of the birth of Jesus; this is based on a letter quoted only in a 9th-century source, and this letter is spurious. At the time this was one of the commonly believed dates for Jesus' birth and was used by Hippolytus of Rome in his Commentary on Daniel around 200 AD. It is claimed \u2013 falsely \u2013 that Pope Julius declared December 25 as Christmas after patriarch Cyril of Jerusalem asked for clarification on what date historical records stored in Rome indicate as Jesus' birth. It was also believed that Jesus and John the Baptist were born around the same time from reading the Gospel of Luke.\nThe actual date of Jesus's birth is unknown. It has been noted that 25 December is two days after the end of the Roman festival of Saturnalia. Some have speculated that part of the reason this date was chosen may have been because Julius was trying to create a Christian alternative to Saturnalia. Another reason for the decision may have been because, in 274 AD, the Roman emperor Aurelian had allegedly declared 25 December the birthdate of Sol Invictus and that Julius I allegedly may have thought that he could attract more converts to Christianity by allowing them to continue to celebrate on the same day, but this cannot be historically verified. He may have also been influenced by the idea that Jesus had died on the anniversary of his conception; because Jesus died during Passover and, in the third century AD, Passover was celebrated on 25 March, he may have assumed that Jesus's birthday must have come nine months later, on 25 December.\nDeath and veneration.\nJulius I died in Rome on 12 April 352. He was succeeded by Liberius. Julius is venerated as a saint by the Catholic Church. His feast day is on 12 April.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n\u00a0This article incorporates text from a publication now in the public domain:\u00a0\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24685", "revid": "998182", "url": "https://en.wikipedia.org/wiki?curid=24685", "title": "Pope Julius III", "text": "Head of the Catholic Church from 1550 to 1555\nPope Julius III (; ; 10 September 1487\u00a0\u2013 23 March 1555), born Giovanni Maria Ciocchi del Monte, was head of the Catholic Church and ruler of the Papal States from 22 February 1550 to his death, in March 1555.\nAfter a career as a distinguished and effective diplomat, Julius was elected to the papacy as a compromise candidate after the death of Paul III. As pope, he made only reluctant and short-lived attempts at reform, mostly devoting himself to a life of personal pleasure. His reputation, and that of the Catholic Church, were greatly harmed by his scandal-ridden relationship with his adopted nephew, Innocenzo Ciocchi Del Monte. He is the most recent pope to take the pontifical name \"Julius\".\nEducation and early career.\nGiovanni Maria Ciocchi del Monte was born in Monte San Savino, the son of a distinguished Roman jurist. He was educated by the humanist Raffaele Brandolini Lippo, and later studied law at Perugia and Siena. During his career, he distinguished himself as a brilliant canonist rather than as a theologian.\nDel Monte was the nephew of Antonio Maria Ciocchi del Monte, Archbishop of Manfredonia (1506\u20131511). His uncle exchanged this see for a position as a Cardinal in 1511; Giovanni Maria Ciocchi del Monte succeeded to Manfredonia in 1513. In 1520, del Monte also became Bishop of Pavia. Popular for his affable manner and respected for his administrative skills, he was twice Prefect of Rome and was entrusted by the papal curia with several duties. At the Sack of Rome (1527) he was one of the hostages given by Pope Clement VII to the Emperor's forces, and barely escaped execution. Pope Paul III created him Cardinal-Priest of San Vitale on 22 December, 1536; and raised him to the dignity of cardinal-bishop with the Diocese of Palestrina on 5 October, 1543. He was employed him in several important legations, notably as papal legate and first president of the Council of Trent (1545/47) and then at Bologna (1547/48).\nPapacy.\nElection.\nPaul III died on 10 November 1549, and in the ensuing conclave the forty-eight cardinals were divided into three factions: of the primary factions, the Imperial faction wished to see the Council of Trent reconvened, the French faction wished to see it dropped. The Farnese faction, loyal to the family of the previous Pope, supported the election of Paul III's grandson, Cardinal Alessandro Farnese, and also the family's claim to the Duchy of Parma, which was contested by Charles V, Holy Roman Emperor.\nNeither the French nor the Germans favoured del Monte, and the Emperor had expressly excluded him from the list of acceptable candidates, but the French were able to block the other two factions, allowing del Monte to promote himself as a compromise candidate and be elected on 7 February 1550. Ottavio Farnese, whose support had been crucial to the election, was immediately confirmed as Duke of Parma. But, when Farnese applied to France for aid against the emperor, Julius allied himself with the emperor, declared Farnese deprived of his fief, and sent troops under the command of his nephew Giambattista del Monte to co-operate with governor Ferrante Gonzaga of Milan in the capture of Parma.\nChurch reforms.\nAt the start of his reign Julius had seriously desired to bring about a reform of the Catholic Church and to reconvene the Council of Trent, but very little was actually achieved during his five years in office. In 1551, at the request of Emperor Charles V, he consented to the reopening of the Council of Trent and entered into a league against the duke of Parma and Henry II of France (1547\u201359), causing the War of Parma. However, Julius soon came to terms with the duke and France and in 1553 suspended the meetings of the council.\nHenry had threatened to withdraw recognition from the Pope if the new Pope was pro-Habsburg in orientation, and when Julius III reconvened the Council of Trent, Henry blocked French bishops from attending and did not enforce the papal decrees in France. Even after Julius III suspended the council again he proceeded to bully the pope into taking his side against the Habsburgs by threatening schism.\nJulius increasingly contented himself with Italian politics and retired to his luxurious palace at the Villa Giulia, which he had built for himself close to the Porta del Popolo. From there he passed the time in comfort, emerging from time to time to make timid efforts to reform the Church through the reestablishment of the reform commissions. He was a friend of the Jesuits, to whom he granted a fresh confirmation in 1550; and through the papal bull, \"Dum sollicita\" of August 1552, he founded the Collegium Germanicum, and granted an annual income.\nDuring his pontificate, Catholicism was restored in England under Queen Mary in 1553. Julius sent Cardinal Reginald Pole as legate with powers that he could use at his discretion to help the restoration succeed. In February 1555, an envoy was dispatched from the English Parliament to Julius to inform him of the country's formal submission, but the pope died before the envoy reached Rome.\nShortly before his death, Julius dispatched Cardinal Giovanni Morone to represent the interests of the Holy See at the Peace of Augsburg. His inactivity during the last three years of his pontificate may have been caused by the frequent and severe attacks of gout.\nArtistic endeavors.\nThe pope's lack of interest in political or ecclesiastical affairs caused dismay among his contemporaries. When his efforts at church reform proved ineffective, Julius III focused his attentions instead on artistic and architectural commissions as well as his lavish Villa Giulia. He spent the bulk of his time, and a great deal of papal money, on entertainments at the Villa Giulia, created for him by Vignola. Bartolomeo Ammannati designed a number of garden features under the general direction of Giorgio Vasari, with guidance from the knowledgeable pope and Michelangelo, who worked there. Today the Villa Giulia houses the National Etruscan Museum, a collection of Etruscan art and artifacts. \nMore significant and lasting was his patronage of the great Renaissance composer Giovanni Pierluigi da Palestrina, whom he brought to Rome as his \"maestro di cappella\". \nThe Innocenzo scandal.\nJulius' papacy was marked by scandals, the most notable of which is centered around the pope's adoptive nephew, Innocenzo Ciocchi Del Monte. Innocenzo del Monte was a teenaged beggar found in the streets of Parma who was hired by the family as a lowly hall boy in their primary residence, the boy's age being variously given as 14, 15, or 17 years. After the elevation of Julius to the papacy, Innocenzo Del Monte was adopted into the family by the pope's brother and was then promptly created cardinal-nephew by Julius. The pope showered his favourite with benefices, including the \"commendatario\" of the abbeys of Mont Saint-Michel in Normandy and Saint Zeno in Verona, and, later, of the abbeys of Saint Saba, Miramondo, Grottaferrata and Frascati, among others. As rumours began to circle about the particular relationship between the pope and his adoptive nephew, Julius refused to take advice. The cardinals Reginald Pole and Giovanni Carafa (who would be elected pope in 1559) warned Julius of the \"evil suppositions to which the elevation of a fatherless young man would give rise\".\nThe courtier and poet Girolamo Muzio, in a 1550 letter to Ferrante Gonzaga (governor of Milan), wrote: \"They write many bad things about this new pope; that he is vicious, proud, and odd in the head.\"\nThe poet Joachim du Bellay, who lived in Rome through this period in the retinue of his relative, Cardinal Jean du Bellay, expressed his scandalised opinion of Julius in two sonnets in his series Les regrets (1558), which alluded to the beautiful young Innocenzo's appointment by referencing \"a Ganymede with the red hat on his head\". \nThe Pope's political enemies likewise made hay with the scandal. In Italy, it was said that Julius showed the impatience of a \"lover awaiting a mistress\" while awaiting Innocenzo's arrival in Rome \u2014 and that he boasted of the boy's prowess in bed. The Venetian ambassador reported that Innocenzo Del Monte shared the pope's bed \"as if he [Innocenzo] were his [Julius'] own son or grandson.\" \"The charitably-disposed told themselves the boy might after all be simply his bastard son.\"\nFor some time afterwards, Protestants, too, seized upon the rumours in the cause of polemic. As late as 1597, in his work \"The Theatre of God's judgement\", the English Puritan clergyman Thomas Beard, asserted that it was Julius' \"custome ... to promote none to ecclesiastical livings, save only his buggerers\". \nDespite the damage which the scandal was inflicting on the church, it was not until after Julius' death in 1555 that anything could be done to reduce Innocenzo's visibility. He underwent temporary banishment following the murder of two men who had insulted him, and then again following the rape of two women. He tried to use his connections in the College of Cardinals to plead his cause, but his influence waned, and he died in obscurity. He was buried in Rome in the del Monte family chapel. One outcome of the cardinal-nephew scandal, however, was the upgrading of the position of Papal Secretary of State, as the incumbent had to take over the duties Innocenzo Del Monte was unfit to perform: the Secretary of State eventually replaced the cardinal-nephew as the most important official of the Holy See.\nOther activities.\nConsistories.\nThroughout his pontificate, Julius III named twenty new cardinals in four consistories, including one cardinal whom he nominated \"in pectore\" in 1551 and revealed in the following year.\nBeatifications.\nWhile he did not canonize any saints during his papacy, Julius III did beatify the Basilian monk and hermit Silvester of Troina.\nDeath.\nJulius III died at 7:00pm on 23 March 1555. Having suffered from gout in his later years (which he tried to cure simply by fasting), he died as a result of stomach ailments. As he was dying, he had difficulties in swallowing to the point that he ate little, having found it uncomfortable. It was believed after his death that the pope had died from stomach or esophageal cancer.\nIn fiction.\nIn the novel \"Q\" by Luther Blissett, Julius appears toward the end of the book as a moderate cardinal favouring religious tolerance, in the upheavals caused by the Reformation and the Roman Church's response during the 16th century. His election as pope and the subsequent unleashing of the Inquisition form the last chapters of the novel.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24686", "revid": "1294642163", "url": "https://en.wikipedia.org/wiki?curid=24686", "title": "Pope Eugene I", "text": "Head of the Catholic Church from 654 to 657\nPope Eugene I (; died 2 June 657) was the bishop of Rome from 10 August 654 to his death on 2 June 657. He was chosen to become Pope after the deposition and banishment of Martin I by Emperor Constans II over the dispute about Monothelitism.\nUnusual election.\nEugene was a Roman from the Aventine, son of Rufinianus. He was brought up in the Church's ministry, and was already an elderly priest when a dispute flared up between the papacy in Rome, which opposed the monothelite teachings, and the imperial government in Constantinople, which supported it. As a result, Pope Martin I was deposed by Emperor Constans II and carried off from Rome on 18 June 653, eventually ending up banished to Cherson. Little is known about what happened in Rome after Martin's departure, but it was typical in those days for the Holy See to be governed by the archpriest and archdeacon. Martin hoped that a successor would not be elected while he lived, but the imperial court exerted pressure on Rome through the exarch of Ravenna. On 10 August 654, Eugene was appointed the new pope, to which Martin acceded. The imperial government believed that Eugene would be cooperative and ratified his election.\nPontificate.\nAs pope, Eugene consecrated twenty-one bishops for different parts of the world and received the youthful Wilfrid on the occasion of his first visit to Rome (c. 654).\nEugene I showed greater deference than his predecessor to the emperor's wishes and made no public stand against the Monothelitism of the patriarchs of Constantinople. One of the first acts of the new pope was to send legates to Constantinople with letters to Emperor Constans II informing him of his election and professing his faith. The legates were deceived, or bribed, and brought back a synodical letter from Patriarch Peter of Constantinople (656\u2013666), while the emperor's envoy, who accompanied them, brought offerings for Saint Peter and a request from the emperor that the pope would enter into communion with the patriarch of Constantinople. Peter's letter proved to be written in a difficult and obscure style and avoided making any specific declaration as to the number of \"wills or operations\" in Christ. When its contents were read to the clergy and people in the church of St. Mary Major in 656, they not only rejected the letter with indignation, but would not allow the pope to leave the basilica until he had promised that he would not on any account accept it.\nThe imperial officials were furious at this harsh rejection of the wishes of the emperor and patriarch. Constans threatened to dispose of Eugene just as he had disposed of Martin, but was preoccupied by defending the empire from the Muslim conquests.\nDeath and legacy.\nEugene I died on 2 June 657, before Constans II could act against him. He was buried in Old St. Peter's Basilica. He was acclaimed a saint, his feast day being 2 June. He is commemorated as the patron and namesake of the Cathedral of Saint Eugene in the Diocese of Santa Rosa in California.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24687", "revid": "1318716708", "url": "https://en.wikipedia.org/wiki?curid=24687", "title": "Pope Eugene II", "text": "Head of the Catholic Church from 824 to 827\nPope Eugene II (; died 27 August 827) was the bishop of Rome and ruler of the Papal States from 6 June 824 to his death on 27 August 827. A native of Rome, he was chosen by nobles to succeed Paschal I as pope despite the clergy and the people favoring Zinzinnus. The influence of the Carolingian Franks on the selection of popes was then firmly established. Pope Eugene convened a council at Rome in 826 to condemn simony and suspend untrained clergy. It was decreed that schools were to be established at cathedral churches and other places to give instruction in sacred and secular literature. His involvement in the Byzantine Iconoclasm controversy was largely inconsequential.\nEarly career.\nIn earlier editions of the \"Liber Pontificalis\" Eugene is said to have been the son of Boemund, but in the more recent and more accurate editions, his father's name is not given. While he was archpriest of St Sabina on the Aventine, and was said to have fulfilled most conscientiously the duties of his position. Eugene is described by his biographer as simple and humble, learned and eloquent, handsome and generous, a lover of peace, and wholly occupied with the thought of doing what was pleasing to God.\nAccession.\nEugene was elected pope on 6 June 824, after the death of Paschal I. Paschal had attempted to curb the rapidly increasing power of the Roman nobility, who had turned for support to the Franks to strengthen their positions against him. When Paschal died, these nobles made strenuous efforts to replace him with a candidate of their own. The clergy put forward Zinzinnus, a candidate likely to continue the policy of Paschal. Even though the Roman Council of 769 under Stephen III had decreed that the nobles had no right to a real share in a papal election, the nobles were successful in securing the consecration of Eugene. Eugene's candidacy was endorsed by Abbot Walla, who was then in Rome and served as a councilor to both the current emperor, Louis the Pious, and his predecessor, Charlemagne.\nThe election of Eugene II was a triumph for the Franks, and they subsequently resolved to improve their position. Emperor Louis the Pious accordingly sent his son Lothair I to Rome to strengthen the Frankish influence. The Roman nobles who had been banished during the preceding reign and fled to France were recalled, and their property was restored to them. A \"Constitutio Romana\" was then agreed upon between the pope and the emperor in 824 which advanced the imperial pretensions in the city of Rome, but also checked the power of the nobles. This constitution included the statute that no pope should be consecrated until his election had the approval of the Frankish emperor. It decreed that those who were under the special protection of the pope or emperor were to be inviolable, and that church property not be plundered after the death of a pope.\nPontificate.\nSeemingly before Lothair left Rome, there arrived ambassadors from Emperor Louis and from the Greeks concerning the controversy of Byzantine Iconoclasm. At first the iconoclast Eastern Roman Emperor Michael II showed himself tolerant towards the icon worshippers, and their great champion, Theodore the Studite, wrote to him to exhort him \"to unite us (the Church of Constantinople) to the head of the Churches of God, Rome, and through it with the three patriarchs\" and to refer any doubtful points to the decision of Old Rome in accordance with ancient custom. But Michael soon forgot his tolerance, bitterly persecuted the icon worshippers, and endeavoured to secure the co-operation of Louis the Pious. He also sent envoys to the pope to consult him on certain points connected with the worship of icons. Before taking any steps to meet the wishes of Michael, Louis asked the pope's permission for a number of his bishops to assemble and make a selection of passages from the Fathers to elucidate the question that the Greeks had put before them. The leave was granted, but the bishops who met at Paris in 825 were incompetent for the task. Their collection of extracts from the Fathers was a mass of confused and ill-digested lore, and both their conclusions and the letters they wished the pope to forward to the Greeks were based on a complete misunderstanding of the decrees of the Second Council of Nicaea. Their labours do not appear to have accomplished much; nothing is known of the result of their researches.\nIn 826 Eugene held an important council at Rome of 62 bishops, in which 38 disciplinary decrees were issued. The council passed several enactments for the restoration of church discipline, and took measures for the foundation of schools or chapters. The decrees are noteworthy as showing that Eugene had at heart the advancement of learning. Not only were ignorant bishops and priests to be suspended till they had acquired sufficient learning to perform their sacred duties, but it was decreed that, as in some localities there were neither masters nor zeal for learning, masters were to be attached to the episcopal palaces, cathedral churches and other places to give instruction in sacred and polite literature. It also ruled against priests wearing secular dress or engaging in secular occupations. Simony was forbidden. Eugene also adopted various provisions for the care of the poor, widows and orphans, and on that account received the name of \"father of the people\".\nTo help in the work of the conversion of the North, Eugene wrote commending St. Ansgar, the Apostle of the Scandinavians, and his companions \"to all the sons of the Catholic Church\".\nDeath and legacy.\nEugene II died on 27 August 827. It is supposed that he was buried in St. Peter's in accordance with the custom of the time, even though there is no documentary record to confirm it. He was succeeded by Valentine, with whom he had been so close that rumours circulated that Eugene was Valentine's father or lover.\nCoins of Eugene II are extant bearing his name and that of Emperor Louis. As pope, Eugene beautified his ancient church of St. Sabina with mosaics and metalwork bearing his name that were still intact as late as the 16th century.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n\u00a0This article incorporates text from a publication now in the public domain:\u00a0"}
{"id": "24688", "revid": "9023670", "url": "https://en.wikipedia.org/wiki?curid=24688", "title": "Pope Eugene III", "text": "Head of the Catholic Church from 1145 to 1153\nPope Eugene III (; c. 1080 \u2013 8 July 1153), born Bernardo, called Bernardo da Pisa, was head of the Catholic Church and ruler of the Papal States from 15 February 1145 to his death in 1153. He was the first Cistercian to become pope. In response to the fall of Edessa to the Muslims in 1144, Eugene proclaimed the Second Crusade. The crusade failed to recapture Edessa, which was the first of many failures by the Christians in the crusades to recapture lands won in the First Crusade. He was beatified in 1872 by Pope Pius IX.\nEarly life.\nBernardo was born in the vicinity of Pisa. Little is known about his origins and family except that he was son of a certain Godius. From the 16th century he is commonly identified as member of the family of Paganelli di Montemagno, which belonged to the Pisan aristocracy, but this has not been proven and contradicts earlier testimonies that suggest he was a man of rather humble origins. In 1106 he was a canon of the cathedral chapter in Pisa and from 1115 is attested as subdeacon. 1133\u20131138 he acted as \"vicedominus\" of the archdiocese of Pisa.\nBetween May 1134 and February 1137 he was ordained to the priesthood by Pope Innocent II, who resided at that time in Pisa. Under the influence of Bernard of Clairvaux he entered the Cistercian Order in the monastery of Clairvaux in 1138. A year later he returned to Italy as leader of the Cistercian community in Scandriglia. In Autumn 1140, Innocent II named him abbot of the monastery of S. Anastasio alle Tre Fontane outside Rome. Some chronicles indicate that he was also elevated to the College of Cardinals, but these testimonies probably resulted from a confusion because Bernardo is not attested as cardinal in any document and from the letter of Bernard of Clairvaux addressed to the cardinals shortly after his election it clearly appears that he was not a cardinal.\nPapal election.\nBernardo was elected pope on 15 February 1145, the same day as the death of his predecessor Lucius II. Lucius had unwisely decided to take the offensive against the Roman Senate and was killed by a \"heavy stone\" thrown at him during an attack on the Capitol. Bernardo took the pontifical name Eugene III. He was \"a simple character, gentle and retiring - not at all, men thought, the material of which Popes are made\". He owed his elevation partly to the fact that no one was eager to accept an office the duties of which were at the time so difficult and dangerous and because the election was \"held on safe Frangipani territory\".\nBernardo's election was assisted by his being a pupil and friend of Bernard of Clairvaux, the most influential ecclesiastic of the Western Church and a strong promoter of the temporal authority of the popes. The choice did not have the approval of Bernard, however, who remonstrated against the election, writing to the entire Curia:\"May God forgive you what you have done! ... What reason or counsel, when the Supreme Pontiff was dead, made you rush upon a mere rustic, lay hands on him in his refuge, wrest from his hands the axe, pick or hoe, and raise him to a throne?\"Bernard was equally forthright in his views directly to Eugene, writing:\"Thus does the finger of God raise up the poor out of the dust and lift up the beggar from the dunghill that he may sit with princes and inherit the throne of glory.\"Despite these criticisms, Eugene seems to have borne no resentment against Bernard and his initial reaction, once the choice had been made, it has been claimed that Bernard took advantage of the very qualities in Eugene III that he had criticised so as virtually to rule in the pope's name.\nFor their part, the cardinals resented Bernard's influence over the pope, stating \"You should know that, having been elevated to the rule of entire church by us, around whom, like pivots [\"cardines\"] the axis of the church universal swings, and having been made by us from a private person into the father of the universal church, it is necessary from now on that you belong not just to yourself but to us; that you do not rank particular and recent friendships before those which are general and of ancient standing\".\nBernard reacted strongly to the cardinals' assertions, writing to Pope Eugenius that the cardinals had \"no power except that which you grant them or permit them to exercise\" and that their claims \"make no sense... [are] derived from no tradition... [and] had the support of authority\".\nThe issue remained unresolved for the whole of Eugenius' pontificate.\nPontificate.\nDuring nearly the whole of his pontificate, Eugene III was unable to reside in Rome. Hardly had he left the city to be consecrated in the Farfa Abbey (about 40\u00a0km north of Rome), when the citizens, under the influence of Arnold of Brescia, the great opponent of the Pope's temporal power, established the old Roman constitution, the Commune of Rome and elected Giordano Pierleoni to be patrician. Eugene III appealed for help to Tivoli, Italy, to other cities at feud with Rome, and to King Roger II of Sicily (who sent his general Robert of Selby), and with their aid was successful in making such conditions with the Roman citizens as enabled him for a time to hold the semblance of authority in his capital. But as he would not agree to a treacherous compact against Tivoli, he was compelled to leave the city in March 1146. He stayed for some time at Viterbo, and then at Siena, but went ultimately to France.\nOn hearing of the fall of Edessa (now the modern day city of Urfa, the first of the Crusader states established in the Levant) to the Turks, which occurred in 1144, he had, in December 1145, addressed the bull \"Quantum praedecessores\" to Louis VII of France, calling on him to take part in another crusade. Earlier the same year, Eugenius issued the Militia Dei, allowing the Templar Order to charge tithes and fees for burials. At a great diet held at Speyer in 1146, King Conrad III of Germany and many of his nobles were also incited to dedicate themselves to the crusade by the eloquence of Bernard of Clairvaux, preached to an enormous crowd at V\u00e9zelay. The Second Crusade turned out to be \"an ignominious fiasco\" and, after travelling for a year, the army abandoned their campaign after just five days of siege \"having regained not one inch of Muslim territory.\" The crusaders suffered immense losses in both men and materiel and suffered, in the view of one modern historian, \"the ultimate humiliation which neither they, nor their enemies, would forget\".\nOn 11 April 1147, Eugene III issued a papal bull known as the \"Divina dispensatione\". As part of the bull, Eugene fulfilled and validated a promise made by Bernard of Clairvaux that the same indulgences would be offered to those who crusaded against the Wends in Mecklenburg as those who went to fight in the Middle East. According to Bernard of Clairvaux, the goal of the crusade was to battle the pagan Slavs \"until such a time as, by God's help, they shall either be converted or deleted\".\nEugene III held synods in northern Europe at Paris, Rheims (March 1148), and Trier in 1147 that were devoted to the reform of clerical life. He also considered and approved the works of Hildegard of Bingen.\nIn June 1148, Eugene III returned to Italy and took up his residence at Viterbo. He was unable to return to Rome due to the popularity of Arnold of Brescia, who opposed papal temporal authority, in the city. He established himself at Ptolemy II's fortress in Tusculum, the closest town to Rome at which he could safely install himself, on 8 April 1149. There he met the returning Crusader couple Louis VII of France and Eleanor of Aquitaine, who were by then barely on speaking terms given the strains of the failed Crusade and the rumors of Eleanor's incestuous adultery during the Crusade. Eugene, \"a gentle, kind-hearted man who hated to see people unhappy\" attempted to assuage the pain of the failed Crusade and their failing marriage by insisting that they slept in the same bed and \"by daily converse to restore the love between them\". His efforts were unsuccessful, and two years later Eugene agreed to annul the marriage on the grounds of consanguinity.\nEugene stayed at Tusculum until 7 November. At the end of November 1149, through the aid of the king of Sicily, he was again able to enter Rome, but the atmosphere of open hostility from the Comune soon compelled him to retire (June 1150). Emperor Frederick I Barbarossa promised to aid Eugene against his subjects who had revolted but the support never came. Eugene III died at Tivoli on 8 July 1153. Though the citizens of Rome resented Eugene III's effort to assert his temporal authority, they recognized him as their spiritual lord. Until the day of his death he continued to wear the coarse habit of a Cistercian monk under his robe. He was buried in the Vatican with every mark of respect.\nVeneration.\nThe people of Rome were quick to recognize Eugene III as a pious figure who was meek and spiritual. His tomb acquired considerable fame owing to the miracle purported to have occurred there and his cause for sainthood commenced. Pope Pius IX beatified him in 1872.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24689", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=24689", "title": "Persistence", "text": "Persistence or Persist may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "24690", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=24690", "title": "Plaintiff", "text": "Party which initiates a court case\nA plaintiff (\u03a0 in legal shorthand) is the party who initiates a lawsuit (also known as an \"action\") before a court. By doing so, the plaintiff seeks a legal remedy. If this search is successful, the court will issue judgment in favor of the plaintiff and make the appropriate court order (e.g., an order for damages). Plaintiff is the term used in civil cases in most English-speaking jurisdictions, the notable exceptions being England and Wales, where a plaintiff has, since the introduction of the Civil Procedure Rules in 1999, been known as a \"claimant\" and Scotland, where the party has always been known as the \"pursuer\". In criminal cases, the prosecutor brings the case against the defendant, but the key complaining party is often called the \"complainant\".\nIn some jurisdictions, a lawsuit is commenced by filing a summons, claim form or a complaint. These documents are known as pleadings, that set forth the alleged wrongs committed by the defendant or defendants with a demand for relief. In other jurisdictions, the action is commenced by service of legal process by delivery of these documents on the defendant by a process server; they are only filed with the court subsequently with an affidavit from the process server that they had been given to the defendant according to the rules of civil procedure.\nTerminology.\nIn most English-speaking jurisdictions, including Hong Kong, Nigeria, Australia (except in federal jurisdiction), Canada, the United States, Northern Ireland and the Republic of Ireland, the legal term \"plaintiff\" is used as a general term for the party taking action in a civil case.\nThe word \"plaintiff\" can be traced to the year 1278, and stems from the Anglo-French word \"pleintif\" meaning \"complaining\". It was identical to \"plaintive\" at first and receded into legal usage with the -iff spelling in the 15th century.\nA plaintiff identified by name in a class action is called a named plaintiff.\nIn most common-law jurisdictions, the term \"claimant\" used in England and Wales since 1999 (see below) is used only in specific, often non-judicial contexts. In particular, in American usage, terms such as \"claimant\" and \"claim form\" are limited to extrajudicial process in insurance and administrative law. After exhausting remedies available through an insurer or government agency, an American claimant in need of further relief would turn to the courts, file a complaint (thus establishing a real court case under judicial supervision) and become a plaintiff.\nIn England and Wales, the term \"claimant\" replaced \"plaintiff\" after the Civil Procedure Rules came into force on 26 April 1999. The move, which brings England and Wales out of line with general usage in English-speaking jurisdictions, was reportedly based on an assessment that the word \"claimant\" is more acceptable as \"plain English\" than the word \"plaintiff\". In Scottish law a plaintiff is referred to as a \"pursuer\" and a defendant as a \"defender\".\nThe similar term \"complainant\" denotes the complaining witness in a criminal proceeding.\nIn the Federal Court of Australia, most plaintiffs are called \"applicants\", but in admiralty and corporations law matters they are called \"plaintiffs\".\nIn case names.\nCase names are usually given with the plaintiff first, as in \"Plaintiff v. Defendant\" (orally, \"Plaintiff and Defendant\"). The party against whom the complaint is made is the defendant; or, in the case of a petition, a respondent. Subsequent references to a case may use only one of the names, typically that of the first nongovernmental party.\nCriminal cases are usually brought by the prosecution, not a plaintiff. The prosecution may bring the case formally in the name of the monarch, state or government. In many Commonwealth realms, this is the king (or queen, when the monarch is female), named \"the Crown,\" abbreviated \"R\", thus \"R v Defendant\" (orally, \"R against (versus) Defendant\"). In several U.S. states, including California, Illinois, Michigan, and New York, the prosecution of a criminal case is captioned as \"The People of the State of\", followed by the name of the state, or \"People\" for short.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24692", "revid": "11952314", "url": "https://en.wikipedia.org/wiki?curid=24692", "title": "Plea of temporary insanity", "text": ""}
{"id": "24694", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=24694", "title": "Philosophy of law", "text": ""}
{"id": "24695", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=24695", "title": "Personal property", "text": "Property which can be moved from one location to another\nPersonal property is property that is movable. In common law systems, personal property may also be called chattels or personalty. In civil law systems, personal property is often called movable property or movables\u2014any property that can be moved from one location to another.\nPersonal property can be understood in comparison to real estate, immovable property or real property (such as land and buildings).\nMovable property on land (larger livestock, for example) was not automatically sold with the land; it was \"personal\" to the owner and moved with the owner.\nThe word \"cattle\" is the Old Norman variant of Old French \"chatel\", chattel (derived from Latin \"capitalis\", \"of the head\"), which was once synonymous with general movable personal property.\nClassifications.\nPersonal property may be classified in a variety of ways.\nIntangible.\nIntangible personal property or \"intangibles\" refers to personal property that cannot actually be moved, touched or felt, but instead represents something of value such as negotiable instruments, securities, service (economics), and intangible assets including chose in action.\nTangible.\nTangible personal property refers to any type of property that can generally be moved (i.e., it is not attached to real property or land), touched or felt. These generally include items such as furniture, clothing, jewelry, sunglasses, eyeglasses, art, writings, or household goods. In some cases, there can be formal title documents that show the ownership and transfer rights of that property after a person's death (for example, motor vehicles, boats, etcetera) In many cases, however, tangible personal property will not be \"titled\" in an owner's name and is presumed to be whatever property he or she was in possession of at the time of his or her death.\nOther distinctions.\nAccountants distinguish personal property from real property because personal property can be depreciated faster than improvements (while land is not depreciable at all). It is an owner's right to get tax benefits for chattel, and there are businesses that specialize in appraising personal property, or chattel.\nThe distinction between these types of property is significant for a variety of reasons. Usually, one's rights on movables are more attenuated than one's rights on immovables (or real property). The statutes of limitations or prescriptive periods are usually shorter when dealing with personal or movable property. Real property rights are usually enforceable for a much longer period of time and in most jurisdictions real estate and immovables are registered in government-sanctioned land registers. In some jurisdictions, rights (such as a lien or other security interest) can be registered against personal or movable property.\nIn common law, it is possible to place a mortgage upon real property. Such a mortgage requires payment, or the owner of the mortgage can seek foreclosure. Personal property can often be secured with a similar kind of device, variously called a \"chattel mortgage\", a \"trust receipt\", or a \"security interest\". In the United States, Article 9 of the Uniform Commercial Code governs the creation and enforcement of security interests in most (but not all) types of personal property.\nThere is no similar institution to the mortgage in the civil law, however a hypothec is a device to secure real rights against property. These real rights follow the property along with the ownership. In common law a lien also remains on the property, and it is not extinguished by alienation of the property; liens may be real or equitable.\nMany jurisdictions levy a personal property tax, an annual tax on the privilege of owning or possessing personal property within the boundaries of the jurisdiction. Automobile and boat registration fees are a subset of this tax. Most household goods are exempt as long as they are kept or used within the household.\nThe distinction between tangible and intangible personal property is also significant in some of the jurisdictions which impose sales taxes. In Canada, for example, provincial and federal sales taxes were imposed primarily on sales of tangible personal property whereas sales of intangibles tended to be exempt. The move to value added taxes, under which almost all transactions are taxable, has diminished the significance of the distinction.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24696", "revid": "11677590", "url": "https://en.wikipedia.org/wiki?curid=24696", "title": "Prima facie", "text": "Latin expression meaning \"at first sight\"\nPrima facie (; from la \" pr\u012bm\u0101 faci\u0113\") is a Latin expression meaning \"at first sight\", or \"based on first impression\". The literal translation would be \"at first face\" or \"at first appearance\", from the feminine forms of \"primus\" (\"first\") and \"facies\" (\"face\"), both in the ablative case. In modern, colloquial, and conversational English, a common translation would be \"on the face of it\". \nThe term \"prima facie\" is used in modern legal English (including both civil law and criminal law) to signify that upon initial examination, sufficient corroborating evidence appears to exist to support a case. In common law jurisdictions, a reference to \"prima facie evidence\" denotes evidence that, unless rebutted, would be sufficient to prove a particular proposition or fact. The term is used similarly in academic philosophy. Most legal proceedings, in most jurisdictions, require a \"prima facie\" case to exist, following which proceedings may then commence to test it, and create a ruling.\nThe similar ex facie, Latin for \"on the face [of it],\" is a legal term typically used to note that a document's explicit terms are defective without further investigation. For example, a contract between two parties would be void \"ex facie\" if, under a legal system where it was a binding requirement for validity, the document did not require party A to give consideration to party B for services rendered.\nBurden of proof.\nIn most legal proceedings, one party has a burden of proof, which requires it to present \"prima facie\" evidence for all of the essential facts in its case. If it cannot, its claim may be dismissed without any need for a response by other parties. A \"prima facie\" case might not stand or fall on its own; if an opposing party introduces other evidence or asserts an affirmative defense, it can be reconciled only with a full trial. Sometimes the introduction of \"prima facie\" evidence is informally called \"making a case\" or \"building a case\". For example, in a trial under criminal law, the prosecution has the burden of presenting \"prima facie\" evidence of each element of the crime charged against the defendant. In a murder case, this would include evidence that the victim was in fact dead, that the defendant's act caused the death, and that the defendant acted with malice aforethought. If no party introduces new evidence, the case stands or falls just by the \"prima facie\" evidence or lack thereof, respectively.\n\"Prima facie\" evidence does not need to be conclusive or irrefutable: at this stage, evidence rebutting the case is not considered, only whether any party's case has enough merit to take it to a full trial. In common law jurisdictions such as the United Kingdom and the United States, the prosecution in a criminal trial must disclose all evidence to the defense. This includes the \"prima facie\" evidence. An aim of the doctrine of \"prima facie\" is to prevent litigants from bringing spurious charges which simply waste all other parties' time.\n\"Res ipsa loquitur\".\n\"Prima facie\" is often confused with \"res ipsa loquitur\" ('the thing speaks for itself', or literally 'the thing itself speaks'), the common law doctrine that when the facts make it self-evident that negligence or other responsibility lies with a party, it is not necessary to provide extraneous details, since any reasonable person would immediately find the facts of the case. The difference between the two is that \"prima facie\" is a term meaning there is enough evidence for there to be a case to answer, while \"res ipsa loquitur\" means that the facts are so obvious a party does not need to explain any more. For example: \"There is a \"prima facie\" case that the defendant is liable. They controlled the pump. The pump was left on and flooded the plaintiff's house. The plaintiff was away and had left the house in the control of the defendant. \"Res ipsa loquitur\".\" In Canadian tort law, this doctrine has been subsumed by general negligence law.\nUse in academic philosophy.\nThe phrase is also used in academic philosophy. Among its most notable uses is in the theory of ethics first proposed by W. D. Ross in his 1930 book \"The Right and the Good\", often called the \"Ethic of Prima Facie Duties\", as well as in epistemology, as used, for example, by Robert Audi. It is generally used in reference to an obligation. \"I have a \"prima facie\" obligation to keep my promise and meet my friend\" means that I am under an obligation, but this may yield to a more pressing duty. A more modern usage prefers the title \"pro tanto obligation\": an obligation that may be later overruled by another more pressing one; it exists only \"pro tempore\".\nOther uses and references.\nThe phrase \"prima facie\" is sometimes misspelled \"prima facia\" in the mistaken belief that \"facia\" is the actual Latin word; however, \"faci\u0113\" is in fact the ablative case of \"faci\u0113s\", a fifth declension Latin noun. In policy debate theory, \"prima facie\" is used to describe the mandates or planks of an affirmative case, or, in some rare cases, a negative counterplan. When the negative team appeals to \"prima facie\", it appeals to the fact that the affirmative team cannot add or amend anything in its plan after being stated in the first affirmative constructive.\nA common usage of the phrase is the concept of a \"\"prima facie\" speed limit\", which has been used in Australia and the United States. A \"prima facie\" speed limit is a default speed limit that applies when no other specific speed limit is posted, and may be exceeded by a driver; however, if the driver is detected, and cited by police for exceeding the limit, the onus of proof is on the driver to show that the speed at which the driver was travelling was safe under the circumstances. In most jurisdictions, this type of speed limit has been replaced by absolute speed limits.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24697", "revid": "95921", "url": "https://en.wikipedia.org/wiki?curid=24697", "title": "Product liability", "text": "Area of law in which product manufacturers are held responsible for damages caused\nProduct liability is the area of law in which manufacturers, distributors, suppliers, retailers, and others who make products available to the public are held responsible for the injuries those products cause. Although the word \"product\" has broad connotations, product liability as an area of law is traditionally limited to products in the form of tangible personal property.\nProduct liability by country.\nThe overwhelming majority of countries have strongly preferred to address product liability through legislative means. In most countries, this occurred either by enacting a separate product liability act, adding product liability rules to an existing civil code, or including strict liability within a comprehensive Consumer Protection Act. In the United States, product liability law was developed primarily through case law from state courts as well as the \"Restatements of the Law\" produced by the American Law Institute (ALI).\nThe United States and the European Union's product liability regimes are the two leading models for how to impose strict liability for defective products, meaning that \"[v]irtually every product liability regime in the world follows one of these two models.\"\nUnited States.\nThe United States was the birthplace of modern product liability law during the 20th century, due to the 1963 \"Greenman\" decision which led to the emergence of product liability as a distinct field of private law. In 1993, it was reported that \"[n]o other country can match the United States for the number and diversity of its product liability cases, nor for the prominence of the subject in the eyes of the general public and legal practitioners.\" This was still true as of 2015: \"In the United States, product liability continues to play a big role: litigation is much more frequent there than anywhere else in the world, awards are higher, and publicity is significant.\"\nIn the United States, the majority of product liability laws are determined at the state level and vary widely from state to state. Each type of product liability claim requires proof of different elements in order to present a valid claim.\nHistory.\nFor a variety of complex historical reasons beyond the scope of this article, personal injury lawsuits in tort for monetary damages were virtually nonexistent before the Second Industrial Revolution of the 19th century. As a subset of personal injury cases, product liability cases were extraordinarily rare, but it appears that in the few that were brought, the general rule at early common law was probably what modern observers would call no-fault or strict liability. In other words, the plaintiff only needed to prove causation and damages.\nCommon law courts began to shift towards a no-liability regime for products (except for cases of fraud or breach of express warranty) by developing the doctrine of \"caveat emptor\" (buyer beware) in the early 1600s. As personal injury and product liability claims began to slowly increase during the early First Industrial Revolution (due to increased mobility of both people and products), common law courts in both England and the United States in the 1840s erected further barriers to plaintiffs by requiring them to prove negligence on the part of the defendant (i.e., that the defendant was at fault because its conduct had failed to meet the standard of care expected of a reasonable person), and to overcome the defense of lack of privity of contract in cases where the plaintiff had not dealt directly with the manufacturer (as exemplified by \"Winterbottom v. Wright\" (1842)). During the Second Industrial Revolution of the mid-to-late 19th century, consumers increasingly became several steps removed from the original manufacturers of products and the unjust effects of all these doctrines became widely evident.\nState courts in the United States began to look for ways to ameliorate the harsh effects of such legal doctrines, as did the British Parliament. For example, one method was to find implied warranties implicit in the nature of certain contracts; by the end of the 19th century, enough U.S. states had adopted an implied warranty of merchantable quality that this warranty was restated in statutory form in the U.S. Uniform Sales Act of 1906, which drew inspiration from the British Sale of Goods Act 1893.\nDuring the 1940s, 1950s, and 1960s, American law professors Fleming James Jr. and William Prosser published competing visions for the future of the nascent field of product liability. James acknowledged that traditional negligence and warranty law were inadequate solutions for the problems presented by defective products, but argued in 1955 those issues could be resolved by a modification of warranty law \"tailored to meet modern needs,\" while Prosser argued in 1960 that strict liability in tort ought to be \"declared outright\" without \"an illusory contract mask.\" James's analysis was badly weakened by the fact that he did not actually understand how insurance works. Ultimately, it was Prosser's view which prevailed.\nLandmark legal cases.\nThe first step towards modern product liability law occurred in the landmark New York case of \"MacPherson v. Buick Motor Co.\" (1916), which demolished the privity bar to recovery in negligence actions. By 1955, James was citing \"MacPherson\" to argue that \"[t]he citadel of privity has crumbled,\" although Maine, the last holdout, would not adopt \"MacPherson\" until 1982.\nThe second step was the landmark New Jersey case of \"Henningsen v. Bloomfield Motors, Inc.\" (1960), which demolished the privity bar to recovery in actions for breach of implied warranty. Prosser cited \"Henningsen\" in 1960 as the \"fall of the citadel of privity.\" The \"Henningsen\" court helped articulate the rationale for the imminent shift from breach of warranty (sounding in contract) to strict liability (sounding in tort) as the dominant theory in product liability cases, but did not actually impose strict liability for defective products.\nThe third step was the landmark California case of \"Greenman v. Yuba Power Products, Inc.\" (1963), in which the Supreme Court of California openly articulated and adopted the doctrine of strict liability in tort for defective products. \"Greenman\" heralded a fundamental shift in how Americans thought about product liability towards a theory of enterprise liability\u2014instead of basing liability on the defendant's \"fault\" or \"warranty\", the defendant's liability should be predicated, as a matter of public policy, on the simple question of whether it was part of a business enterprise responsible for inflicting injuries on human beings. The theoretical foundation for enterprise liability had been laid by James as well as another law professor, Leon Green. As noted above, it was \"Greenman\" which led to the actual emergence of product liability as a distinct field of private law in its own right. Before this point, products had appeared in case law and scholarly literature only in connection with the application of existing doctrines in contract and tort.\nThe \"Greenman\" majority opinion was authored by then-Associate Justice Roger J. Traynor, who cited to his own earlier concurring opinion in \"Escola v. Coca-Cola Bottling Co.\" (1944). In \"Escola\", now also widely recognized as a landmark case, Justice Traynor laid the foundation for \"Greenman\" with these words:\nEven if there is no negligence, however, public policy demands that responsibility be fixed wherever it will most effectively reduce the hazards to life and health inherent in defective products that reach the market. It is evident that the manufacturer can anticipate some hazards and guard against the recurrence of others, as the public cannot. Those who suffer injury from defective products are unprepared to meet its consequences. The cost of an injury and the loss of time or health may be an overwhelming misfortune to the person injured, and a needless one, for the risk of injury can be insured by the manufacturer and distributed among the public as a cost of doing business. It is to the public interest to discourage the marketing of products having defects that are a menace to the public. If such products nevertheless find their way into the market it is to the public interest to place the responsibility for whatever injury they may cause upon the manufacturer, who, even if he is not negligent in the manufacture of the product, is responsible for its reaching the market. However intermittently such injuries may occur and however haphazardly they may strike, the risk of their occurrence is a constant risk and a general one. Against such a risk there should be general and constant protection and the manufacturer is best situated to afford such protection.\nTraynor's argument for imposing strict liability in \"Escola\" \"has had an enormous impact on the way legal scholars have understood products liability and tort law more generally\". The year after \"Greenman\", the Supreme Court of California proceeded to extend strict liability to \"all\" parties involved in the manufacturing, distribution, and sale of defective products (including retailers). In 1969, the court then held that such defendants were liable not only to direct customers and users, but also to any innocent bystanders randomly injured by defective products.\nNationwide adoption of product liability.\nIn turn, Prosser was able to propagate the \"Greenman\" holding to a nationwide audience because the American Law Institute had appointed him as the official reporter of the Restatement of Torts, Second. The Institute approved the Restatement's final draft in 1964 and published it in 1965; the Restatement codified the \"Greenman\" doctrine in Section 402A. \"Greenman\" and Section 402A \"spread like wildfire across America\". The highest courts of nearly all U.S. states and territories (and a few state legislatures) embraced this \"bold new doctrine\" during the late 1960s and 1970s. By 1971, the doctrine had been adopted in 28 states; by 1976, it had been adopted in 41 states. As of 2018, the five exceptions who have rejected strict liability are Delaware, Massachusetts, Michigan, North Carolina, and Virginia. In four of those states, warranty law has been so broadly construed in favor of plaintiffs that only North Carolina truly lacks anything resembling strict liability in tort for defective products. North Carolina's judiciary never attempted to adopt the doctrine, and the state legislature enacted a statute expressly banning strict liability for defective products in 1995. \nBefore the product liability revolution, it was unheard of in American case law, for example, for a consumer to sue a ladder manufacturer after falling off a ladder or to sue a diving board manufacturer for diving injuries. After the 1960s, these kinds of lawsuits became very common. \nIn a landmark 1986 decision, \"East River S. S. Corp. v. Transamerica Delaval Inc.\", the U.S. Supreme Court also embraced strict liability for defective products by adopting it as part of federal admiralty law, holding that admiralty law \"incorporates principles of product liability, including strict liability\".\nFactors behind nationwide adoption.\nIn the conventional narrative, there are two main factors that explain the rapid embrace of \"Greenman\" and Section 402A. First, they came along just as Americans were coalescing around a consensus in favor of consumer protection, which would eventually cause Congress to enact several landmark federal product safety and vehicle safety statutes. Between 1960 and 1977, Congress passed at least forty-two laws dealing with consumer and worker safety. Second, American academic experts in the field of law and economics developed new theories that helped to justify strict liability, such as those articulated by Guido Calabresi in \"The Costs of Accidents\" (1970).\nTo this, Kyle Graham adds three more factors: (3) the rise of attorneys specializing exclusively in plaintiffs' personal injury cases and their professional associations like the organization now known as the American Association for Justice; (4) the ubiquity of so-called \"bottle cases\" (personal injury cases arising from broken glass bottles) before aluminum cans and plastic bottles displaced glass bottles as the primary beverage container during the 1970s; and (5) the resistance of the Uniform Commercial Code's editorial board to extending warranties to bystander victims before 1966\u2014in states whose legislatures had not already acted, state courts were more receptive to extending the common law to grant bystanders a strict liability tort claim.\nProsser inexplicably imposed in Section 402A a requirement that a product defect must be \"unreasonably dangerous.\" Since the \"unreasonably dangerous\" qualifier implicitly connotes some sense of the idea of \"fault\" which Traynor was trying to exorcise from product liability, it was subsequently rejected as incompatible with strict liability for defective products by Alaska, California, Georgia, New Jersey, New York, Puerto Rico and West Virginia.\nThe mass tort product liability explosion.\nEarly proponents of strict liability believed its economic impact would be minor because they were focused on manufacturing defects. They failed to foresee the logical implications of applying the rule to other types of product defects. Only in the late 1960s did Americans begin to draw a clear analytical distinction between manufacturing and design defects, and since the early 1980s, defective design claims \"have formed the overwhelming bulk\" of American product liability lawsuits. It was \"the unintended application of [Section] 402A to the design context\" which resulted in the explosion of mass tort product liability cases during the 1980s throughout the United States. In the federal judicial system, the number of product liability civil actions filed per year increased from 2,393 in 1975 to 13,408 in 1989, and product liability's percentage of all federal civil cases increased from 2.0% to 5.7% during the same period. These numbers reflect only a small portion of the 1980s explosion in product liability cases; the vast majority of American lawsuits are heard in state courts and not federal courts.\nThe explosion in product liability cases was widely blamed for causing a 1986 crisis in the availability of liability insurance for American businesses. Self-insurance costs as a proportion of total liability insurance expenditures had already skyrocketed from 4.9 percent in 1970 to 51.7 percent in 1979 (meaning that more and more companies were insuring themselves because no one else would). American aircraft manufacturers blamed the liability insurance crisis for the collapse of general aviation in the United States during the 1980s. In the decade after 1976, total aggregate liability payouts by aircraft manufacturers to crash victims skyrocketed by over 800% from the 1976 baseline number, even as the number of deaths each year in plane crashes continued to slowly decline. In 1986, \"liability insurance costs added $80,000 to the cost of each Beech aircraft and $75,000 to each Piper aircraft\", and U.S. aircraft production declined from 17,048 planes in 1979 to 1,143 in 1988.\nIn subsequent decades, American federal judges began to heavily rely upon the multidistrict litigation (MDL) statute (\u00a0https://) to manage an ever-increasing number of complex civil cases. For the first time, by the end of 2018 more than half (51.9%) of all pending American federal civil cases had been centralized into MDLs, with 156,511 cases in 248 MDLs out of a total of 301,766 civil cases. Product liability was the dominant category both in terms of percentage of total active MDLs (32.9%) and percentage of total civil cases centralized into MDLs (91%).\nAmong the factors which led to the large numbers of product liability cases seen today in the United States are relatively low fees for filing lawsuits, the availability of class actions, the strongest right to a jury trial in the world, the highest awards of monetary damages in the world (frequently in the millions of dollars for pain and suffering noneconomic damages and in rare cases soaring into the billions for punitive damages), and the most extensive right to discovery in the world. No other country has adopted the U.S. standard of disclosure of information that is \"reasonably calculated to lead to the discovery of admissible evidence.\" American reported cases are replete with plaintiffs whose counsel artfully exploited this standard to obtain so-called \"smoking gun\" evidence of product defects and made defendants pay \"a tremendous price\" for their callous disregard for product safety.\nTort reform and the neo-conservative reaction.\nIn response to these developments, a tort reform movement appeared in the 1980s which persuaded many state legislatures to enact various limitations like damage caps and statutes of repose. However, the majority of states left untouched the basic rule of strict liability for defective products, and all efforts at the federal level to enact a uniform federal product liability regime were unsuccessful.\nFrom the mid-1960s onward, state courts struggled for over four decades to develop a coherent test for design defects, either phrased in terms of consumer expectations or whether risks outweigh benefits or both (i.e., a hybrid test in which the first does not apply to defects that are too complex). Risk-benefit analysis, of course, can be seen as a way of measuring the reasonableness of the defendant's conduct\u2014or in other words, negligence. A neo-conservative turn among many American courts and tort scholars during the 1980s led to a recognition that liability in design defect and failure-to-warn cases had never been entirely strict, or had been operating in some respects as a \"de facto\" fault-based regime all along, and the American Law Institute expressly backed a return to tests associated with negligence for design and warning defects with the 1998 publication of the \"Restatement of Torts, Third: Products Liability\". This attempt to resurrect negligence and to limit strict liability to its original home in manufacturing defects \"has been highly controversial among courts and scholars.\" In arguing in 2018 that U.S. product liability law as restated in 1998 had come full circle back to where it started in 1964, two law professors also conceded that \"some courts\" continue to \"tenaciously cling[] to the rationale and doctrine of [Section] 402A.\"\nTypes of liability.\nSection 2 of the \"Restatement (Third) of Torts: Products Liability\" distinguishes between three major types of product liability claims:\nHowever, in most states, these are not legal claims in and of themselves, but are pleaded in terms of the legal theories mentioned above. For example, a plaintiff might plead negligent failure to warn or strict liability for defective design.\nThe three types of product liability claims are defined as follows:\nTheories of liability.\nIn the United States, the claims most commonly associated with product liability are negligence, strict liability, breach of warranty, and various consumer protection claims.\nBreach of warranty.\nWarranties are statements by a manufacturer or seller concerning a product during a commercial transaction. Warranty claims historically required privity between the injured party and the manufacturer or seller; in plain English, they must be dealing directly with one another. As noted above, this requirement was demolished in the landmark \"Henningsen\" case.\nBreach of warranty-based product liability claims usually focus on one of three types:\nExpress warranty claims focus on express statements by the manufacturer or the seller concerning the product (e.g., \"This chainsaw is useful to cut turkeys\").\nThe various implied warranties cover those expectations common to all products (e.g., that a tool is not unreasonably dangerous when used for its proper purpose), unless specifically disclaimed by the manufacturer or the seller. They are implied by operation of law from the act of manufacturing, distributing, or selling the product. Claims involving real estate (especially mass-produced tract housing) may also be brought under a theory of implied warranty of habitability.\nNegligence.\nA basic negligence claim consists of proof of\nAs demonstrated in cases such as \"Winterbottom v. Wright\", the scope of the duty of care was limited to those with whom one was in privity. Later cases like \"MacPherson v. Buick Motor Co.\" broadened the duty of care to all who could be foreseeably injured by one's conduct.\nOver time, negligence concepts have arisen to deal with certain specific situations, including negligence \"per se\" (using a manufacturer's violation of a law or regulation, in place of proof of a duty and a breach) and res ipsa loquitur (an inference of negligence under certain conditions).\nStrict liability.\nRather than focus on the behavior of the manufacturer (as in negligence), strict liability claims focus on the product itself. Under strict liability, the manufacturer is liable if the product is defective, even if the manufacturer was not negligent in making that product defective.\nUnder a strict liability theory, the plaintiff merely needs to prove:\nConsumer protection.\nIn addition to common law remedies, many states have enacted consumer protection statutes that provide specific remedies for certain specific types of product defects. One reason for the appearance of such statutes is that under the \"economic loss rule\", strict liability in tort is unavailable for products that cause damage only to themselves. In other words, strict liability is unavailable for defects that merely render the product unusable (or less useful), and hence cause only economic injury, but do not cause personal injury or damage to other property. Breach of warranty actions governed by Article 2 of the Uniform Commercial Code also often fail to provide adequate remedies in such situations.\nThe best-known examples of consumer protection statutes for product defects are lemon laws, which provide protection to purchasers of defective new vehicles and, in a small number of states, used vehicles. In the United States, \"cars are typically the second most valuable asset most people own, outranked only by their home.\"\nEurope.\nAlthough European observers followed \"Greenman\" and Section 402A \"with great interest\", European countries did not initially adopt such a doctrine. For example, after the landmark case of \"Donoghue v Stevenson\" [1932] (which followed \"MacPherson\"), UK product liability law did not change any further for many decades, despite \"trenchant academic criticism\". Strict liability for defective products finally came to Europe as a result of the thalidomide scandal and the victims' ensuing struggle during the 1960s to obtain adequate compensation, especially in the UK and West Germany.\nThe thalidomide scandal highlighted the need for a strict product liability claim sounding in tort because the affected infants were mere bystander victims, as distinguished from product buyers or users. After the UK formed the National Health Service (NHS) in 1948, 80% of pharmaceuticals were provided to patients through the NHS. By assuming financial responsibility for the provision of drugs, the government had thereby barred the majority of mothers (the actual product users) and their infants from bringing breach of warranty claims sounding in contract. For such victims, their only possible claim was a negligence claim sounding in tort, but it is so difficult under English law to prove the standard of care of a reasonable drug manufacturer that as of late 1993, none had ever been held liable in an English court under a negligence theory (although there had been a number of out-of-court settlements).\nThe first international effort in Europe to harmonize product liability resulted in the Council of Europe Convention on Products Liability in regard to Personal Injury and Death (the Strasbourg Convention) in 1977, which never entered into force: while it was signed by Austria, Belgium, France and Luxembourg, it was ratified by none of them.\nOn July 25, 1985, the then-European Economic Community adopted the Product Liability Directive. In language resembling what Traynor wrote in \"Escola\" and \"Greenman\", the Directive's preface states that \"liability without fault on the part of the producer is the sole means of adequately solving the problem, peculiar to our age of increasing technicality, of a fair apportionment of the risks inherent in modern technological production.\" The Directive gave each member state the option of imposing a liability cap of 70 million euros per defect. Unlike the United States, the Directive only imposed strict liability upon \"producers\"\u2014that is, manufacturers of raw materials, component parts, and finished products, as well as importers\u2014and deviated significantly from the American model by deciding not to impose strict liability on purely domestic distributors or retailers. By using the 20-year-old Section 402A as their model, the Directive's drafters decided not to include a number of changes such as the subsequent differentiation between three major types of product defects used in the US.\nAs of 2003, on the one hand, product liability had expanded around the world within the past two decades to become a \"global phenomenon,\" and therefore, \"the United States is no longer the only country with tough product liability rules.\" On the other hand, the picture looked very different when one \"turn[ed] from the law on the books to the law in action.\" In the real world, the actual protection afforded to consumers by product liability law \"depends heavily on whether claims are realistically enforceable,\" and that depends upon whether the procedural law of the forum state is actually able to facilitate access to justice.\nTraditionally, European courts have provided no discovery or rather minimal discovery (by American standards). Where available, European discovery is rarely self-executing (that is, automatically effective by operation of law), meaning that the defendant and third parties have no obligation to disclose anything unless and until the plaintiff obtains a court order. Civil law countries strongly dislike and oppose the American principle of broad discovery in civil litigation. For example, since 1968, it has been a crime for a French company to produce commercial information in foreign legal proceedings without express authorization from a French court, and in turn, this has been raised as a defense to discovery by French defendants in American product liability cases. Since the defendant usually possesses most of the extant evidence of a product defect, in most European countries it is \"very difficult, if not impossible, for a victim or her lawyer to investigate a product liability case.\"\nOther obstacles\u2014especially in civil law countries\u2014include high filing fees, no right to a jury trial, low damages for pain and suffering, the unavailability of punitive damages, and the unavailability (before the 2010s) of class actions. As of 2003, there was \"no\" country outside of the United States where plaintiffs were able to recover noneconomic damages above US$300,000 for even the most catastrophic injuries. As of 2015, product liability in Europe \"has remained a fairly minor field which generates fewer cases, more modest awards, and rarely makes it into the headlines\" (in comparison to its American cousin). In July 2018, European Commission staff reported that from 2000 to 2016, a total of only 798 product liability claims had been filed in the national courts of EU member states. As of 2020, the much smaller number of cases in the UK meant that \"English case law ha[d] barely begun to consider\" many of the product liability issues already explored thoroughly by American courts, which therefore required an English legal treatise to cite to a \"significant proportion\" of American cases in order to illustrate where English product liability law could go in the future.\nDuring the late 2010s, the comparative outcomes for consumers affected by the Volkswagen emissions scandal vividly highlighted the deficiencies of European civil procedure as applied to a defendant who had already publicly admitted to violations of U.S. environmental laws. In the United States, Volkswagen quickly settled the consolidated consumer class action and agreed to pay US$11.2 billion directly to consumers affected by its allegedly defective diesel vehicles. In contrast, consumers in Europe and elsewhere around the world had to fight much longer and harder for less compensation. Many of them were unimpressed with Volkswagen's vigorous advocacy of legal defenses based on technical differences between different nations' environmental laws; from their perspective, they had paid for a \"clean diesel\" car, they did not get a \"clean diesel\" car, and did not understand why they deserved far less compensation than American consumers for what they perceived to be the same defect. This embarrassed Germany into dropping its longstanding opposition to European collective redress proposals, and the country also made reforms to its domestic civil procedure. As a result, on 25 November 2020, the European Parliament and Council adopted the Directive on Representative Actions. Paragraph 1 of Article 1 of the Directive states that it is intended \"to improve consumers' access to justice.\"\nIn 2024, Directive (EU) 2024/2853 on the liability for defective products repealed Council Directive 85/374/EEC and provided an expanded scope on product liability, now including components of products as well as software.\nOther nations.\nThe legislatures of many other countries outside the EU (then: EEC) subsequently enacted strict liability regimes based on the European model (that is, generally applying only to manufacturers and importers), including Israel (March 1980, based on an early proposed draft of the Directive), Brazil (September 1990), Peru (November 1991), Australia (July 1992), Russia (February 1992), Switzerland (December 1992), Argentina (October 1993), Japan (June 1994), Taiwan (June 1994), Malaysia (August 1999), South Korea (January 2000), Thailand (December 2007), and South Africa (April 2009).\nAs of 2015, in most countries outside of the United States and European Union, \"product liability remains largely a regime of paper rules with little practical impact[.]\"\nApplicable law.\nThe law that needs to be applied in product liability cases is governed by the Convention on the Law Applicable to Products Liability of 1971 for the 11 countries that are party to it. The country where the damage occurred determines the applicable law, if that country is also the residence of the person suffering damage, the principal place of business of the person held liable or the place where the product was bought. If that is not the case, the law of the country of residence is used, provided the product was bought there, or it was the principal place of business of the person held liable.\nDebate over strict liability laws.\nAdvocates of strict liability laws argue that strict products liability causes manufacturers to internalize costs they would normally externalize. Strict liability thus requires manufacturers to evaluate the full costs of their products. In this way, strict liability provides a mechanism for ensuring that a product's absolute good outweighs its absolute harm. Empirical data has shown that increased liability can force manufacturers to actively confront the risks imposed by their products. For example, at the peak of the liability insurance crisis in 1986, a survey of manufacturers found that because of expanding liability, 47 percent had withdrawn products, 39 percent had decided against introducing new products, and 25 percent had discontinued new product research. \nBetween two parties who are not negligent (manufacturer and consumer), one will necessarily shoulder the costs of product defects. Proponents say it is preferable to place the economic costs on the manufacturer because it can better absorb them and pass them on to other consumers. The manufacturer thus becomes a de facto insurer against its defective products, with premiums built into the product's price.\nStrict liability also seeks to diminish the impact of information asymmetry between manufacturers and consumers. Manufacturers have better knowledge of their own products' dangers than do consumers. Therefore, manufacturers properly bear the burden of finding, correcting, and warning consumers of those dangers.\nStrict liability reduces litigation costs, because a plaintiff need only prove causation, not imprudence. Where causation is easy to establish, parties to a strict liability suit will most likely settle, because only damages are in dispute.\nCritics charge that strict liability creates risk of moral hazard. They claim that strict liability causes consumers to under invest in care even when they are the least-cost avoiders. This, they say, results in a lower aggregate level of care than under a negligence standard. Proponents counter that people have enough natural incentive to avoid inflicting serious harm on themselves to mitigate this concern.\nCritics charge that the requiring manufacturers to internalize costs they would otherwise externalize increases the price of goods. Critics claim that in elastic, price-sensitive markets, price increases cause some consumers to seek substitutes for that product. As a result, they say, manufacturers may not produce the socially optimal level of goods. Proponents respond that these consumer opt outs reflect a product whose absolute harm outweighs its absolute value; products that do more harm than good ought not be produced.\nIn the law and economics literature, there is a debate about whether liability and regulation are substitutes or complements. If they are substitutes, then either liability or regulation should be used. If they are complements, then the joint use of liability and regulation is optimal.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24698", "revid": "15881234", "url": "https://en.wikipedia.org/wiki?curid=24698", "title": "Proximate cause", "text": "Event deemed by law to be the effective cause of an injury\nIn law and insurance, a proximate cause is an event sufficiently related to an injury that the courts deem the event to be the cause of that injury. There are two types of causation in the law: cause-in-fact, and proximate (or legal) cause. Cause-in-fact is determined by the \"but for\" test: But for the action, the result would not have happened. (For example, but for running the red light, the collision would not have occurred.) The action is a necessary condition, but may not be a sufficient condition, for the resulting injury. A few circumstances exist where the but-for test is ineffective (see But-for test below). Since but-for causation is very easy to show (but for stopping to tie your shoe, you would not have missed the train and would not have been mugged), a second test is used to determine if an action is close enough to a harm in a \"chain of events\" to be legally valid. This test is called proximate cause. Proximate cause is a key principle of insurance and is concerned with how the loss or damage actually occurred. There are several competing theories of proximate cause (see Other factors). For an act to be deemed to cause a harm, both tests must be met; proximate cause is a legal limitation on cause-in-fact.\nThe formal Latin term for \"but for\" (cause-in-fact) causation, is sine qua non causation.\nBut-for test.\nA few circumstances exist where the \"but for\" test is complicated, or the test is ineffective. The primary examples are:\nSince but-for causation is very easy to show and does not assign culpability (but for the rain, you would not have crashed your car\u00a0\u2013 the rain is not morally or legally culpable but still constitutes a cause), there is a second test used to determine if an action is close enough to a harm in a \"chain of events\" to be a legally culpable cause of the harm. This test is called proximate cause, from the Latin \"causa proxima.\" \nOther factors.\nThere are several competing theories of proximate cause.\nForeseeability.\nThe most common test of proximate cause under the American legal system is foreseeability. It determines if the harm resulting from an action could reasonably have been predicted. The test is used in most cases only in respect to the type of harm. It is foreseeable, for example, that throwing a baseball at someone could cause them a blunt-force injury. But proximate cause is still met if a thrown baseball misses the target and knocks a heavy object off a shelf behind them, which causes a blunt-force injury.\nThis is also known as the \"extraordinary in hindsight\" rule.\nIn the United Kingdom, a \"threefold test\" of foreseeability of damage, proximity of relationship and reasonableness was established in the case of Caparo v Dickman (1990) and adopted in the litigation between Lungowe and others and Vedanta Resources plc (Supreme Court ruling 2019).\nDirect causation.\nDirect causation is a minority test, which addresses only the metaphysical concept of causation. It does not matter how foreseeable the result as long as what the negligent party's physical activity can be tied to what actually happened. The main thrust of direct causation is that there are no intervening causes between an act and the resulting harm. An intervening cause has several requirements: it must 1) be independent of the original act, 2) be a voluntary human act or an abnormal natural event, and 3) occur in time between the original act and the harm.\nDirect causation is the only theory that addresses only causation and does not take into account the culpability of the original actor.\nRisk enhancement/causal link.\nThe plaintiff must demonstrate that the defendant's action increased the risk that the particular harm suffered by the plaintiff would occur. If the action were repeated, the likelihood of the harm would correspondingly increase. This is also called foreseeable risk.\nHarm within the risk.\nThe harm within the risk (HWR) test determines whether the victim was among the class of persons who could foreseeably be harmed, and whether the harm was foreseeable within the class of risks. It is the strictest test of causation, made famous by Benjamin Cardozo in \"Palsgraf v. Long Island Railroad Co.\" case under New York state law.\nThe first element of the test is met if the injured person was a member of a class of people who could be expected to be put at risk of injury by the action. For example, a pedestrian, as an expected user of sidewalks, is among the class of people put at risk by driving on a sidewalk, whereas a driver who is distracted by another driver driving on the sidewalk, and consequently crashes into a utility pole, is not.\nThe HWR test is no longer much used, outside of New York law. When it is used, it is used to consider the class of people injured, not the type of harm. The main criticism of this test is that it is preeminently concerned with culpability, rather than actual causation.\nThe \"Risk Rule\".\nReferred to by the Reporters of the Second and Third Restatements of the Law of Torts as the \"scope-of-the-risk\" test, the term \"Risk Rule\" was coined by the University of Texas School of Law's Dean Robert Keeton. The rule is that \u201c[a]n actor\u2019s liability is limited to those physical harms that result from the risks that made the actor\u2019s conduct tortious.\u201d Thus, the operative question is \"what were the particular risks that made an actor's conduct negligent?\" If the injury suffered is not the result of one of those risks, there can be no recovery. Two examples will illustrate this principle:\nThe notion is that it must be the risk associated with the negligence of the conduct that results in an injury, not some other risk invited by aspects of the conduct that in of themselves would not be negligent.\nControversy.\nThe doctrine of proximate cause is notoriously confusing. The doctrine is phrased in the language of causation, but in most of the cases in which proximate cause is actively litigated, there is not much real dispute that the defendant but-for caused the plaintiff's injury. The doctrine is actually used by judges in a somewhat arbitrary fashion to limit the scope of the defendant's liability to a subset of the total class of potential plaintiffs who may have suffered some harm from the defendant's actions.\nFor example, in the two famous \"Kinsman Transit\" cases from the 2nd Circuit (exercising admiralty jurisdiction over a New York incident), it was clear that mooring a boat improperly could lead to the risk of that boat drifting away and crashing into another boat, and that both boats could crash into a bridge, which collapsed and blocked the river, and in turn, the wreckage could flood the land adjacent to the river, as well as prevent any traffic from traversing the river until it had been cleared. But under proximate cause, the property owners adjacent to the river could sue (\"Kinsman I\"), but not the owners of the boats or cargoes which could not move until the river was reopened (\"Kinsman II\").\nTherefore, in the final version of the \"Restatement (Third), Torts: Liability for Physical and Emotional Harm\", published in 2010, the American Law Institute argued that proximate cause should be replaced with scope of liability. Chapter 6 of the Restatement is titled \"Scope of Liability (Proximate Cause).\" It begins with a special note explaining the institute's decision to reframe the concept in terms of \"scope of liability\" because it does not involve true causation, and to also include \"proximate cause\" in the chapter title in parentheses to help judges and lawyers understand the connection between the old and new terminology. The Institute added that it \"fervently hopes\" the parenthetical will be unnecessary in a future fourth Restatement of Torts.\nEfficient proximate cause.\nA related doctrine is the insurance law doctrine of efficient proximate cause. Under this rule, in order to determine whether a loss resulted from a cause covered under an insurance policy, a court looks for the predominant cause which sets into motion the chain of events producing the loss, which may not necessarily be the \"last\" event that immediately preceded the loss. Many insurers have attempted to contract around efficient proximate cause through the use of \"anti-concurrent causation\" (ACC) clauses, under which if a covered cause and a noncovered cause join to cause a loss, the loss is not covered.\nACC clauses frequently come into play in jurisdictions where property insurance does not normally include flood insurance and expressly excludes coverage for floods. The classic example of how ACC clauses work is where a hurricane hits a building with wind and flood hazards \"at the same time.\" If the evidence later shows that the wind blew off a building's roof and then water damage resulted only because there was no roof to prevent rain from entering, there would be coverage, but if the building was simultaneously flooded (i.e., because the rain caused a nearby body of water to rise or simply overwhelmed local sewers), an ACC clause would completely block coverage for the \"entire\" loss (even if the building owner could otherwise attribute damage to wind v. flood).\nA minority of jurisdictions have ruled ACC clauses to be unenforceable as against public policy, but they are generally enforceable in the majority of jurisdictions.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24702", "revid": "50809006", "url": "https://en.wikipedia.org/wiki?curid=24702", "title": "Peace", "text": "State of harmony in the absence of hostility and violence\nPeace is a state of harmony in the absence of hostility and violence. In a societal sense, peace is commonly used to mean a lack of conflict (such as war) and freedom from fear of violence between individuals or groups. \nPromotion of peace is a core tenet of many philosophies, religions, and ideologies, many of which consider it a core tenet of their philosophy. Some examples are: religions such as Buddhism and Christianity, important figures like Gandhi, and throughout literature like \"\" by Immanuel Kant, \"The Art of Peace\" by Morihei Ueshiba, or ideologies that strictly adhere to it such as Pacifism within a sociopolitical scope. It is a frequent subject of symbolism and features prominently in art and other cultural traditions.\nThe representation of peace has taken many shapes, with a variety of symbols pertaining to it based on culture, context, and history; each with their respective symbolism whose nature can be very complex. An example, being during post-violence, in contexts where intense emotions, these symbols can form to evoke unity and cooperation, described as to fill groups of people with pride and connection, yet the symbolism could also possibly form to convey oppression, hatred, or else.\nAs such, a universal definition for peace does not concretely exist but gets expanded and defined proactively based on context and culture, in which it can serve many meanings not particularly benevolent in its symbolism.\n\"Psychological peace\" (such as peaceful thinking and emotions) is less relatively well-defined, yet perhaps a necessary precursor to establishing \"behavioural peace\". Peaceful behaviour sometimes results from a \"peaceful inner disposition\". It has been argued by some that inner qualities such as tranquility, patience, respect, compassion, kindness, self-control, courage, moderation, forgiveness, equanimity, and the ability to see the big picture can promote peace within an individual, regardless of the external circumstances of their life.\nEtymology.\nThe term 'peace' originates from the Anglo-French , and the Old French , meaning \"peace, reconciliation, silence, agreement\" (11th century). The Anglo-French term itself comes from the Latin , meaning \"peace, compact, agreement, treaty of peace, tranquility, absence of hostility, harmony.\"\nThe English word came into use in various personal greetings from c.\u20091300 as a translation of the Hebrew word , which, according to Jewish theology, comes from a Hebrew verb meaning 'to be complete, whole'. Although \"peace\" is the usual translation, it is an incomplete one, because , which is also cognate with the Arabic , has multiple other meanings in addition to peace, including justice, good health, safety, well-being, prosperity, equity, security, good fortune, and friendliness, as well as simply the greetings, \"hello\" and \"goodbye\".\nOn a personal level, peaceful behaviours are kind, considerate, respectful, just, and tolerant of others' beliefs and behaviors \u2013 tending to manifest goodwill. This understanding of peace can also pertain to an individual's introspective sense or concept of her/himself, as in being \"at peace\" in one's own mind, as found in European references from c.\u20091200. The early English term is also used in the sense of \"quiet\", reflecting calm, serene, and meditative approaches to family or group relationships that have an absence of quarreling, disturbances and agitation; but seek clarity of conversation, and tranquility.\nIn many languages, the word 'peace' is also used as a greeting or a farewell, for example the Hawaiian word , as well as the Arabic word . In English the word peace is occasionally used as a farewell, especially for the dead, as in the phrases \"rest in peace\" or \"peace out\".\nHistory.\nPeace was forged through diplomacy in the form of royal marriages, both in the distant past and in modern times. Two early examples of royal marriages being used to establish diplomatic relations are Hermodike I, who married the king of Phrygia around 800 BCE, and Hermodike II, who married the king of Lydia around 600 BCE. Both marriages involved Greek princesses from the house of Agamemnon and kings from what is now Turkey. The marriages between the Greek princesses and the kings of Phrygia and Lydia had a significant impact on the region, leading to the transfer of important technological innovations from Anatolia to Greece. In particular, the Phrygians introduced the Greek alphabet, while the Lydians pioneered the use of coinage as a form of currency. Both inventions were rapidly adopted by surrounding nations through further trade and cooperation.\nPeace has not always been achieved through peaceful means; in many cases, it has been enforced by the victors of war, often through the use of violence and coercion. In his work \"Agricola\", the Roman historian Tacitus, writes passionately and critically about the greed and arrogance of the Roman Empire, portraying it as a ruthless and self-serving power. One, that Tacitus says is by the Caledonian chieftain Calgacus, ends with: \"\" (\"To ravage, to slaughter, to usurp under false titles, they call empire; and where they make a desert, they call it peace.\" \u2014Oxford Revised Translation).\nDiscussion of peace is therefore at the same time an inquiry into its form. Societal peace can be seen at least in two forms:\nSince 1945, the United Nations and the United Nations Security Council have operated under the aim to resolve conflicts without war. Nonetheless, nations have entered numerous military conflicts since then.\nOrganizations and prizes.\nUnited Nations.\nThe United Nations (UN) is an international organization whose stated aims are to facilitate cooperation in international law, international security, economic development, social progress, human rights, and achieving world peace. The UN was founded in 1945 after World War II to replace the League of Nations, to stop wars between countries, and to provide a platform for dialogue.\nAfter authorization by the Security Council, the UN sends peacekeepers to regions where armed conflict has recently ceased or paused to enforce the terms of peace agreements and to discourage combatants from resuming hostilities. Since the UN does not maintain its own military, peacekeeping forces are voluntarily provided by member states of the UN. The forces, also called the \"Blue Helmets\", who enforce UN accords are awarded United Nations Medals, which are considered international decorations instead of military decorations. The peacekeeping force as a whole received the Nobel Peace Prize in 1988.\nPolice.\n \nThe obligation of the state to provide for domestic peace within its borders is usually charged to the police and other general domestic policing activities. The police are a constituted body of persons empowered by a state to enforce the law, to protect the lives, liberty and possessions of citizens, and to prevent crime and civil disorder. Their powers include the power of arrest and the legitimized use of force. The term is most commonly associated with the police forces of a sovereign state that are authorized to exercise the police power of that state within a defined legal or territorial area of responsibility. Police forces are often defined as being separate from the military and other organizations involved in the defense of the state against foreign aggressors; however, gendarmerie are military units charged with civil policing. Police forces are usually public sector services, funded through taxes.\nNational security.\nThe national security apparatus of a nation is responsible for providing peace and security against foreign threats and aggression. National security can be threatened by a range of factors, including actions by other states (such as military or cyber attacks), violent non-state actors (such as terrorist attacks), organized criminal groups (such as narcotic cartels), and natural disasters (such as floods and earthquakes). Systemic drivers of insecurity, which may be transnational, include economic inequality and marginalisation, political exclusion, climate change, and nuclear proliferation. In view of the wide range of risks, the preservation of peace and the security of a nation state have several dimensions, including economic security, energy security, physical security, environmental security, food security, border security, and cyber security. These dimensions correlate closely with elements of national power.\nLeague of Nations.\nThe principal forerunner of the United Nations was the League of Nations. It was created at the Paris Peace Conference of 1919, and emerged from the advocacy of Woodrow Wilson and other idealists during World War I. The Covenant of the League of Nations was included in the Treaty of Versailles in 1919, and the League was based in Geneva until its dissolution as a result of World War II and replacement by the United Nations. The high hopes widely held for the League in the 1920s, for example amongst members of the League of Nations Union, gave way to widespread disillusion in the 1930s as the League struggled to respond to challenges from Nazi Germany, Fascist Italy, and Japan.\nThe prominent scholar, Sir Alfred Eckhard Zimmern, who is widely regarded as one of the most influential intellectuals of the League of Nations, drew inspiration for his studies from the classics, along with other British scholars such as Gilbert Murray and Florence Stawell. This group of scholars is often referred to as the \"Greece and peace\" set, due to their shared interest in ancient Greek civilization and the promotion of peace.\nThe creation of the League of Nations, and the hope for informed public opinion on international issues (expressed for example by the Union for Democratic Control during World War I), also saw the creation after World War I of bodies dedicated to understanding international affairs, such as the Council on Foreign Relations in New York and the Royal Institute of International Affairs at Chatham House in London. At the same time, the academic study of international relations started to professionalise, with the creation of the first professorship of international politics, named for Woodrow Wilson, at Aberystwyth, Wales, in 1919.\nOlympic Games.\nThe late 19th century idealist advocacy of peace which led to the creation of the Nobel Peace Prize, the Rhodes Scholarships, the Carnegie Endowment for International Peace, and ultimately the League of Nations, also saw the re-emergence of the ancient Olympic ideal. Led by Pierre de Coubertin, this culminated in the holding in 1896 of the first of the modern Olympic Games.\nNobel Peace Prize.\nSince 1901, the Nobel Peace Prize has been the world's most prestigious honor given to individuals or organizations who have made significant contributions to peace. The prize is awarded by the Norwegian Nobel Committee, a group of five individuals chosen by the Norwegian parliament. Nominees for the prize come from around the world, and are often those who have worked to end conflict, protect human rights, or promote humanitarian efforts. It is awarded annually to internationally notable persons following the prize's creation in the will of Alfred Nobel. According to Nobel's will, the Peace Prize shall be awarded to the person who \"...shall have done the most or the best work for fraternity between nations, for the abolition or reduction of standing armies, and for the holding and promotion of peace congresses.\"\nRhodes, Fulbright and Schwarzman scholarships.\nIn creating the Rhodes Scholarships for outstanding students from the United States, Germany and much of the British Empire, Cecil Rhodes wrote in 1901 that 'the object is that an understanding between the three great powers will render war impossible and educational relations make the strongest tie'. This peace purpose of the Rhodes Scholarships was very prominent in the first half of the 20th century, and became prominent again in recent years under Warden of the Rhodes House Donald Markwell, a historian of thought about the causes of war and peace. This vision greatly influenced Senator J. William Fulbright in the goal of the Fulbright fellowships to promote international understanding and peace, and has guided many other international fellowship programs, including the Schwarzman Scholars to China created by Stephen A. Schwarzman in 2013.\nGandhi Peace Prize.\nThe International Gandhi Peace Prize, named after Mahatma Gandhi, is awarded annually by the Government of India. It was launched as a tribute to the ideals espoused by Gandhi in 1995 on the occasion of the 125th anniversary of his birth. This is an annual award given to individuals and institutions for their contributions towards social, economic and political transformation through non-violence and other Gandhian methods. The award carries Rs. 10 million in cash, convertible in any currency in the world, a plaque and a citation. It is open to all persons regardless of nationality, race, creed or sex.\nStudent Peace Prize.\nThe Student Peace Prize is awarded biennially to a student or a student organization that has made a significant contribution to promoting peace and human rights.\nAhmadiyya Muslim Peace Prize.\nThe Ahmadiyya Muslim Peace Prize, is awarded annually \"in recognition of an individual's or an organisation's contribution for the advancement of the cause of peace\". The prize was first launched in 2009 by the Ahmadiyya Muslim Peace Prize Committee under the directive of the caliph of the Ahmadiyya Muslim Community, Mirza Masroor Ahmad.\nCulture of Peace News Network.\nThe Culture of Peace News Network, otherwise known simply as CPNN, is a UN authorized interactive online news network, committed to supporting the global movement for a culture of peace.\nSydney Peace Prize.\nEvery year in the first week of November, the Sydney Peace Foundation presents the Sydney Peace Prize. The Sydney Peace Prize is awarded to an organization or an individual whose life and work has demonstrated significant contributions to:\nThe achievement of peace with justice locally, nationally or internationally\nThe promotion and attainment of human rights\nThe philosophy, language and practice of non-violence\nMuseums.\nA peace museum is a museum that documents historical peace initiatives. Many provide advocacy programs for nonviolent conflict resolution. This may include conflicts at the personal, regional or international level.\nSmaller institutions include the Randolph Bourne Institute, the McGill Middle East Program of Civil Society and Peace Building and the International Festival of Peace Poetry.\nReligious beliefs.\nReligious beliefs often seek to identify and address the basic problems of human life, including conflicts between, among, and within persons and societies. In ancient Greek-speaking areas, the virtue of peace was personified as the goddess Eirene, and in Latin-speaking areas as the goddess Pax. Her image was typically represented by ancient sculptors as a full-grown woman, usually with a horn of plenty and scepter and sometimes with a torch or olive leaves.\nChristianity.\nChristians, who believe Jesus of Nazareth to be the Jewish Messiah called Christ (meaning Anointed One), interpret as a messianic prophecy of Jesus in which he is called the \"Prince of Peace\". In the Gospel of Luke, Zechariah celebrates his son John: \"And you, child, will be called the prophet of the Most High; for you will go before the Lord to prepare his ways, to give knowledge of salvation to his people by the forgiveness of their sins. By the tender mercy of our God, the dawn from on high will break upon us, to give light to those who sit in darkness and in the shadow of death, to guide our feet into the way of peace.\"\nAs a testimony of peace, Peace Churches in the Anabaptist Christian tradition (such as the Mennonites and Quakers), as well Holiness Methodist Pacifists (such as the Immanuel Missionary Church), practice nonresistance and do not participate in warfare.\nIn the Catholic Church, numerous pontifical documents on the Holy Rosary document a continuity of views of the Popes to have confidence in the Holy Rosary as a means to foster peace. In the Encyclical \"Mense maio\", 1965, in which he urged the practice of the Holy Rosary, and as reaffirmed in the encyclical \"Christi Matri\", 1966, to implore peace, Pope Paul VI stated in the apostolic \"https://\", October 1969, that the Rosary is a prayer that favors the great gift of peace.\nHinduism.\nHindu texts contain the following passages:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;May there be peace in the heavens, peace in the atmosphere, peace on the earth. Let there be coolness in the water, healing in the herbs and peace radiating from the trees. Let there be harmony in the planets and in the stars, and perfection in eternal knowledge. May everything in the universe be at peace. Let peace pervade everywhere, at all times. May I experience that peace within my own heart.\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Let us have concord with our own people, and concord with people who are strangers to us. Ashwins (Celestial Twins) create between us and the strangers a unity of hearts. May we unite in our minds, unite in our purposes, and not fight against the heavenly spirit within us. Let not the battle-cry rise amidst many slain, nor the arrows of the war-god fall with the break of day\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;A superior being does not render evil for evil. This is a maxim one should observe... One should never harm the wicked or the good or even animals meriting death. A noble soul will exercise compassion even towards those who enjoy injuring others or cruel deeds... Who is without fault?\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The chariot that leads to victory is of another kind.\nValour and fortitude are its wheels;\nTruthfulness and virtuous conduct are its banner;\nStrength, discretion, self-restraint and benevolence are its four horses,\nHarnessed with the cords of forgiveness, compassion and equanimity...\nWhoever has this righteous chariot, has no enemy to conquer anywhere.\u2014\u200a\nBuddhism.\nBuddhists believe that peace is attained by ending pain and suffering. They regard pain and suffering is stemming from cravings (in the extreme, greed), aversions (fears), and delusions and suffering is attachments to outcomes. To eliminate such pain and suffering and achieve personal peace, followers in the path of the Buddha adhere to a set of teachings called the Four Noble Truths \u2014 a central tenet in Buddhist philosophy.\nIslam.\nIslam derived from the root word which literally means peace. Quran states \"those who believe and whose hearts find comfort in the remembrance of Allah. Surely in the remembrance of Allah do hearts find comfort.\" and stated \"O believers! When you are told to make room in gatherings, then do so. Allah will make room for you \u02f9in His grace\u02fa. And if you are told to rise, then do so. Allah will elevate those of you who are faithful, and \u02f9raise\u02fa those gifted with knowledge in rank. And Allah is All-Aware of what you do.\"\nJudaism.\nThe Judaic tradition associates God with peace, as evidenced by various principles and laws in Judaism.\n, the biblical and modern Hebrew word for peace, is one of the names for God according to the Judaic law and tradition. For instance, in traditional Jewish law, individuals are prohibited from saying \"\" when they are in the bathroom as there is a prohibition on uttering any of God's names in the bathroom, out of respect for the divine name.\nJewish liturgy and prayer is replete with prayers asking God to establish peace in the world. The \u05e9\u05de\u05d5\u05e0\u05d4 \u05e2\u05e9\u05e8\u05d4, a key prayer in Judaism that is recited three times each day, concludes with a blessing for peace. The last blessing of the \u05e9\u05de\u05d5\u05e0\u05d4 \u05e2\u05e9\u05e8\u05d4, also known as the Amida (\"standing\" as the prayer is said while standing), is focused on peace, beginning and ending with supplications for peace and blessings.\nPeace is central to Judaism's core principle of \u05de\u05b8\u05e9\u05b4\u05c1\u05d9\u05d7\u05b7 (\"messiah\") which connotes a time of universal peace and abundance, a time when weapons will be turned into plowshares and lions will sleep with lambs. As it is written in the Book of Isaiah:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;They shall beat their swords into plowshares and their spears into pruning hooks; nation will not lift sword against nation and they will no longer study warfare.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The wolf will live with the lamb, the leopard will lie down with the goat, the calf and the lion and the yearling together; and a little child will lead them. The cow will feed with the bear, their young will lie down together, and the lion will eat straw like the ox. The infant will play near the hole of the cobra, and the young child put his hand into the viper's nest. They will neither harm nor destroy on all my holy mountain, for the earth will be full of the knowledge of the Lord as the waters cover the sea.\nThis last metaphor from Tanakh (Hebrew bible) symbolizes the peace by which a longed-for messianic age will be characterized, a peace in which natural enemies, the strong and the weak, predator and prey, will live in harmony.\nJews pray for the messianic age of peace every day in the \u05de\u05b8\u05e9\u05b4\u05c1\u05d9\u05d7\u05b7, in addition to faith in the coming of the messianic age constituting one of the thirteen core principles of faith in Judaism, according to Maimonides.\nIdeological beliefs.\nPacifism.\nPacifism is the categorical opposition to the behaviors of war or violence as a means of settling disputes or of gaining advantage. Pacifism covers a spectrum of views ranging from the belief that international disputes can and should all be resolved via peaceful behaviors; to calls for the abolition of various organizations which tend to institutionalize aggressive behaviors, such as the military, or arms manufacturers; to opposition to any organization of society that might rely in any way upon governmental force. Groups that sometimes oppose the governmental use of force include anarchists and libertarians. Absolute pacifism opposes violent behavior under all circumstance, including defense of self and others.\nPacifism may be based on moral principles (a deontological view) or pragmatism (a consequentialist view). Principled pacifism holds that all forms of violent behavior are inappropriate responses to conflict, and are morally wrong. Pragmatic pacifism holds that the costs of war and inter-personal violence are so substantial that better ways of resolving disputes must be found.\nInner peace, meditation and prayerfulness.\nPsychological or inner peace (i.e. peace of mind) refers to a state of being internally or spiritually at peace, with sufficient clarity of knowledge and understanding to remain calm in the face of apparent discord, stress and discomfort. Being internally \"at peace\" is considered to be a healthy playable mental state, a homeostasis of emotions and to be the opposite of feeling stressful, mentally anxious, or emotionally unstable. Within meditative traditions, the achievement of \"peace of mind\" is often associated with bliss and happiness.\nPeace of mind, serenity, and calmness are descriptions of a disposition free from the effects of stress. In some meditative traditions, inner peace is believed to be a state of consciousness or enlightenment that may be cultivated by various types of meditation, prayer, tai chi, yoga, or other various types of mental or physical disciplines. Many such practices refer to this peace as an experience of knowing oneself. An emphasis on finding inner peace is often associated with traditions such as Buddhism, Hinduism, and some traditional Christian contemplative practices such as monasticism, as well as with the New Age movement.\nNon-aggression principle.\nThe non-aggression principle asserts that aggression against an individual or an individual's property is always an immoral violation of life, liberty, and property rights. Utilizing deceit instead of consent to achieve ends is also a violation of the Non-Aggression Principle. Therefore, under the framework of this principle, rape, murder, deception, involuntary taxation, government regulation, and other behaviors that initiate aggression against otherwise peaceful individuals are considered violations. A common elevator pitch for this principle is, \"Good ideas don't require force.\"\nSatyagraha.\nSatyagraha is a philosophy and practice of nonviolent resistance developed by Mahatma Gandhi. He deployed satyagraha techniques in campaigns for Indian independence and also during his earlier struggles in South Africa.\nThe word \"satyagraha\" itself was coined through a public contest that Gandhi sponsored through the newspaper he published in South Africa, \"Indian Opinion\", when he realized that neither the common, contemporary Hindu language nor the English language contained a word which fully expressed his own meanings and intentions when he talked about his nonviolent approaches to conflict. According to Gandhi's autobiography, the contest winner was Maganlal Gandhi (presumably no relation), who submitted the entry 'sadagraha', which Gandhi then modified to 'satyagraha'. Etymologically, this Hindic word means 'truth-firmness', and is commonly translated as 'steadfastness in the truth' or 'truth-force'.\nSatyagraha theory also influenced Martin Luther King Jr., James Bevel, and others during the campaigns they led during the civil rights movement in the United States. The theory of satyagraha sees means and ends as inseparable. Therefore, it is contradictory to try to use violence to obtain peace. As Gandhi wrote: \"They say, 'means are, after all, means'. I would say, 'means are, after all, everything'. As the means so the end...\" A quote sometimes attributed to Gandhi, but also to A. J. Muste, sums it up: \"There is no way to peace; peace is the way\".\nMonuments.\nThe following are monuments to peace:\nTheories.\nMany different theories of \"peace\" exist in the world of peace studies, which involves the study of de-escalation, conflict transformation, disarmament, and cessation of violence. The definition of \"peace\" can vary with religion, culture, or subject of study.\nBalance of power.\nThe classical \"realist\" position is that the key to promoting order between states, and so of increasing the chances of peace, is the maintenance of a balance of power between states \u2013 a situation where no state is so dominant that it can \"lay down the law to the rest\". Exponents of this view have included Metternich, Bismarck, Hans Morgenthau, and Henry Kissinger. A related approach \u2013 more in the tradition of Hugo Grotius than Thomas Hobbes \u2013 was articulated by the so-called \"English school of international relations theory\" such as Martin Wight in his book \"Power Politics\" (1946, 1978) and Hedley Bull in \"The Anarchical Society\" (1977).\nAs the maintenance of a balance of power could in some circumstances require a willingness to go to war, some critics saw the idea of a balance of power as promoting war rather than promoting peace. This was a radical critique of those supporters of the Allied and Associated Powers who justified entry into World War I on the grounds that it was necessary to preserve the balance of power in Europe from a German bid for hegemony.\nIn the second half of the 20th century, and especially during the Cold War, a particular form of balance of power \u2013 mutual nuclear deterrence \u2013 emerged as a widely held doctrine on the key to peace between the great powers. Critics argued that the development of nuclear stockpiles increased the chances of war rather than peace, and that the \"nuclear umbrella\" made it \"safe\" for smaller wars (e.g. the Vietnam War and the Soviet invasion of Czechoslovakia to end the Prague Spring), so making such wars more likely. Similarly, other critics such as Robert L. Holmes utilize a reductio ad absurdum argument to note that any reliance upon a strategy of mutual nuclear deterrence as a means to prevent nuclear war itself is irrational at best in so far as it requires the utilization of the very instruments of war which it seeks to avoid implementing, while also failing to demonstrate an inherent effectiveness in preventing war in either the past, present or future frames of reference.\nAppeasement and deterrence.\nAppeasement is a strategy to achieve peace by making political, material, or territorial concessions to an aggressive power. Deterrence is a strategy to achieve peace by using threats or limited force to dissuade an actor from escalating conflict, typically because the prospective attacker believes that the probability of success is low and the costs of attack are high.\nSpeaking truth to power.\nSpeaking truth to power is a non-violent political tactic, employed by dissidents against the received wisdom or propaganda of governments they regard as oppressive, authoritarian or an ideocracy. Practitioners who have campaigned for a more just and truthful world have included Apollonius of Tyana, Vaclav Havel, Nelson Mandela, Archbishop Desmond Tutu, Mahatma Gandhi, Bacha Khan, and the Dalai Lama.\nThe phrase originated with a pamphlet, \"Speak Truth to Power: a Quaker Search for an Alternative to Violence\", published by the American Friends Service Committee in 1955. A contributor of the pamphlet's contents was civil rights activist Bayard Rustin.\nFree trade and interdependence.\nIt was a central tenet of classical liberalism, for example among English liberal thinkers of the late 19th and early 20th century, that free trade promoted peace. For example, the Cambridge economist John Maynard Keynes (1883\u20131946) said that he was \"brought up\" on this idea and held it unquestioned until at least the 1920s. During the economic globalization in the decades leading up to World War I, writers such as Norman Angell argued that the growth of economic interdependence between the great powers made war between them futile and therefore unlikely. He made this argument in 1913. A year later Europe's economically interconnected states were embroiled in what would later become known as the First World War.\nDemocratic peace theory.\nThe democratic peace theory posits that democracy causes peace (between democracies) because of the accountability, institutions, values, and norms of democratic countries.\nTerritorial peace theory.\nThe territorial peace theory posits that peace causes democracy because territorial wars between neighbor countries lead to authoritarian attitudes and disregard for democratic values. \nThis theory is supported by historical studies showing that countries rarely become democratic until after their borders have been settled by territorial peace with neighbor countries.\nWar game.\nThe \"Peace and War Game\" is an approach in game theory to understand the relationship between peace and conflicts.\nThe iterated game hypotheses was originally used by academic groups and computer simulations to study possible strategies of cooperation and aggression.\nAs peace makers became richer over time, it became clear that making war had greater costs than initially anticipated. One of the well studied strategies that acquired wealth more rapidly was based on Genghis Khan, i.e. a constant aggressor making war continually to gain resources. This led, in contrast, to the development of what's known as the \"provokable nice guy strategy\", a peace-maker until attacked, improved upon merely to win by occasional forgiveness even when attacked. By adding the results of all pairwise games for each player, one sees that multiple players gain wealth cooperating with each other while bleeding a constantly aggressive player.\nSocialism and managed capitalism.\nSocialist, communist, and left-wing liberal writers of the 19th and 20th centuries (e.g., Lenin, J.A. Hobson, John Strachey) argued that capitalism caused war (e.g. through promoting imperial or other economic rivalries that lead to international conflict). This led some to argue that international socialism was the key to peace.\nHowever, in response to such writers in the 1930s who argued that capitalism caused war, the economist John Maynard Keynes (1883\u20131946) argued that managed capitalism could promote peace. This involved international coordination of fiscal/monetary policies, an international monetary system that did not pit the interests of countries against each other, and a high degree of freedom of trade. These ideas underlay Keynes's work during World War II that led to the creation of the International Monetary Fund and the World Bank at Bretton Woods in 1944, and later of the General Agreement on Tariffs and Trade (subsequently the World Trade Organization).\nInternational organization and law.\nOne of the most influential theories of peace, especially since Woodrow Wilson led the creation of the League of Nations at the Paris Peace Conference of 1919, is that peace will be advanced if the intentional anarchy of states is replaced through the growth of international law promoted and enforced through international organizations such as the League of Nations, the United Nations, and other functional international organizations. One of the most important early exponents of this view was Alfred Eckhart Zimmern, for example in his 1936 book \"The League of Nations and the Rule of Law\".\nTrans-national solidarity.\nMany \"idealist\" thinkers about international relations \u2013 e.g. in the traditions of Kant and Karl Marx \u2013 have argued that the key to peace is the growth of some form of solidarity between peoples (or classes of people) spanning the lines of cleavage between nations or states that lead to war.\nOne version of this is the idea of promoting international understanding between nations through the international mobility of students \u2013 an idea most powerfully advanced by Cecil Rhodes in the creation of the Rhodes Scholarships, and his successors such as J. William Fulbright.\nAnother theory is that peace can be developed among countries on the basis of active management of water resources.\nDay.\nWorld Peace Day, celebrated on 21 September, was founded as a day to recognize, honour and promote peace.\nStudies, rankings, and periods.\nPeace and conflict studies.\n\"Peace and conflict studies\" is an academic field which identifies and analyses violent and nonviolent behaviours, as well as the structural mechanisms attending violent and non-violent social conflicts. This is to better understand the processes leading to a more desirable human condition. One variation,\n\"Peace studies\" (irenology), is an interdisciplinary effort aiming at the prevention, de-escalation, and solution of conflicts. This contrasts with war studies (polemology), directed at the efficient attainment of victory in conflicts. Disciplines involved may include political science, geography, economics, psychology, sociology, international relations, history, anthropology, religious studies, and gender studies, as well as a variety of other disciplines.\nMeasurement and ranking.\nAlthough peace is widely perceived as something intangible, various organizations have been making efforts to quantify and measure it. The Global Peace Index produced by the Institute for Economics and Peace is a known effort to evaluate peacefulness in countries based on 23 indicators of the absence of violence and absence of the fear of violence.\nThe 2015 edition of the Index ranked 163 countries on their internal and external levels of peace. According to the 2017 Global Peace Index, Iceland is the most peaceful country in the world while Syria is the least peaceful one. Fragile States Index (formerly known as the Failed States Index) created by the Fund for Peace focuses on risk for instability or violence in 178 nations. This index measures how fragile a state is by 12 indicators and subindicators that evaluate aspects of politics, social economy, and military facets in countries. The 2015 Failed State Index reports that the most fragile nation is South Sudan, and the least fragile one is Finland. University of Maryland publishes the Peace and Conflict Instability Ledger in order to measure peace. It grades 163 countries with 5 indicators, and pays the most attention to risk of political instability or armed conflict over a three-year period. The most recent ledger shows that the most peaceful country is Slovenia on the contrary Afghanistan is the most conflicted nation. Besides indicated above reports from the Institute for Economics and Peace, Fund for Peace, and University of Maryland, other organizations including George Mason University release indexes that rank countries in terms of peacefulness.\nLong periods.\nThe longest continuing period of peace and neutrality among currently existing states is observed in Sweden since 1814 and in Switzerland, which has had an official policy of neutrality since 1815. This was made possible partly by the periods of relative peace in Europe and the world known as Pax Britannica (1815\u20131914), Pax Europaea/Pax Americana (since 1950s), and Pax Atomica (also since the 1950s).\nOther examples of long periods of peace are:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24703", "revid": "9267683", "url": "https://en.wikipedia.org/wiki?curid=24703", "title": "Portland Vase", "text": "Roman cameo glass vase\nThe Portland Vase is a Roman cameo glass vase, which is dated between AD 1 and AD 25, though low BC dates have some scholarly support. It is the best known piece of Roman cameo glass and has served as an inspiration to many glass and porcelain makers from about the beginning of the 18th century onwards. It was first recorded in Rome in 1600\u20131601, and since 1810 has been in the British Museum in London. The museum held it on loan from the dukes of Portland until 1945, and bought it from them that year (GR 1945,0927.1). It is normally on display in Room 70.\nThe vase measures about high and in diameter. It is made of violet-blue glass, and surrounded with a single continuous white glass cameo making two distinct scenes, depicting seven human figures, plus a large snake, and two bearded and horned heads below the handles, marking the break between the scenes.\nThe bottom of the vase was a cameo glass disc, also in blue and white, showing a head, presumed to be of Paris or Priam based on the Phrygian cap it wears. This roundel clearly does not belong to the vase and has been displayed separately since 1845. It may have been added in antiquity or later, or is the result of a conversion from an original amphora form (paralleled by a similar blue-glass cameo vessel from Pompeii). It was attached to the bottom from at least 1826.\nIconography.\nThe meaning of the images on the vase is unclear, and none of the many theories put forward have been found generally satisfactory. They fall into two main groups: mythological and historical, though a historical interpretation of a myth is also a possibility. Historical interpretations focus on Augustus, his family and his rivals, especially given the quality and expense of the object, and the somewhat remote neo-classicism of the style, which compares with some Imperial gemstone cameos featuring Augustus and his family with divine attributes, such as the Gemma Augustea, the Great Cameo of France and the Blacas Cameo (the last also in the British Museum). Interpretations of the portrayals have included that of a marine setting (due to the presence of a ketos or sea-snake), and of a marriage theme/context, as the vase may have been a wedding gift. Many scholars (including Charles Towneley) have concluded that the figures do not fit into a single iconographic set.\nScene 1.\nInterpretations include:\nScene 2.\nInterpretations include:\nOctavian theory.\nAnother variant theory is that the vase dates back to circa 32 BC, and was commissioned by Octavian (later Caesar Augustus), as an attempt to promote his case against his fellow triumvirs, Mark Antony and Marcus Lepidus in the period after the death of Julius Caesar. It is based on the skill of the famous Greek carver of engraved gems Dioskourides, who is recorded as active and at his peak circa 40\u201315 BC and three of whose attributed cameos bear a close resemblance in line and quality to the Portland vase figures. This theory proposes that the first two figures are Gaius Octavius, father of the future emperor, and Atia, his mother (hence Cupid with the arrow) who had a dream of being impregnated by Apollo in the form of a sea serpent (ketos), note the snake's prominent teeth. The onlooker with his staff, could be Aeneas, a hero of the Trojan Wars who saved his father by carrying him over his back (hence his hunched position, and his Trojan beard) and who is believed to have founded Rome, and from whom the Julian gens, including Julius Caesar and Attia, claimed descent, witnessing the conception of Rome's future savior as an Empire, and the greatest of all the Emperors.\nOn the reverse is Octavian, Octavia his sister, widow of Mark Antony (downcast flambeau, broken tablets) and Livia, Octavian's third wife who outlived him. These two are looking directly at each other. Octavian commanded she divorce her then husband and marry him with a few weeks of meeting, she was mother to the future Emperor Tiberius.\nThis vase suggests Octavian was descended partly from Apollo (thus partly divine, shades of Achilles), whom he worshiped as a god, gave private parties in his honor together with Minerva, Roman Goddess of War, from the founder of Rome, and his connection to his uncle Julius Caesar, for whom as a young man he gave a remarkable funeral oratory, and who adopted him on his father's death, when he was only four. All the pieces and people fit in this theory and it explains most mysteries (apart from who actually made it). It would have been a fabulously expensive piece to commission, so that few men of the period could have afforded it. Several attempts at creating the vase must have been made, as modern reproduction trials show today (see below). Historians and archeologists dismiss this modern theory as gods and goddesses with mythical allegories were usually portrayed.\nManufacture.\nCameo glass vessels were probably all made within about two generations, as experiments when the blowing technique (discovered in about 50 BC) was still in its infancy. Recent research suggests that the Portland Vase, like most cameo glass vessels, was made by the dip-overlay method, whereby an elongated bubble of glass was partially dipped into a crucible of white glass before the two were blown together. After cooling the white layer was cut away to form the design.\nMaking a 19th-century copy required painstaking work. This experience suggests that creation of the original Portland Vase required two years of work. Cutting was probably performed by a skilled gem-cutter, possibly Dioskourides. Engraved gems are extant which are of a similar period and are signed and thought to be cut by him (Vollenweider 1966, see Gem in the collection of the duke of Devonshire \"Diomedes stealing the Palladium\"). This is supported by the Corning Museum in their 190-page study of the vase.\nAccording to a controversial theory by Rosemarie Lierke, the vase, along with the rest of Roman cameo glass, was moulded rather than cold-cut, probably using white glass powder for the white layer.\nJerome Eisenberg has argued in \"Minerva\" that the vase was produced in the 16th century AD and not in antiquity, because the iconography is incoherent, but this theory has not been widely accepted.\nRediscovery and provenance.\nOne story suggests that it was discovered by Fabrizio Lazzaro in what was then thought to be the sarcophagus of the Emperor Alexander Severus (died 235) and his mother, at Monte del Grano near Rome, and excavated some time around 1582.\nThe first historical reference to the vase is in a letter of 1601 from the French scholar Nicolas-Claude Fabri de Peiresc to the painter Peter Paul Rubens, where it is recorded as in the collection of Cardinal Francesco Maria Del Monte in Italy. In 1626, it passed into the Barberini family collection (which also included sculptures such as the \"Barberini Faun\" and \"Barberini Apollo\") where it remained for some two hundred years, being one of the treasures of Maffeo Barberini, later Pope Urban VIII (1623\u20131644). It was at this point that the Severan connection is first recorded. The vase was known as the \"Barberini Vase\" in this period.\n1778 to present.\nBetween 1778 and 1780, Sir William Hamilton, British ambassador in Naples, bought the vase from James Byres, a Scottish art dealer, who had acquired it after it was sold by Cornelia Barberini-Colonna, Princess of Palestrina. She had inherited the vase from the Barberini family. Hamilton brought it to England on his next leave, after the death of his first wife, Catherine. In 1784, with the assistance of his niece, Mary, he arranged a private sale of the vase to Margaret Cavendish-Harley, Dowager Duchess of Portland. It was sold at auction in 1786 and passed into the possession of the duchess's son, William Cavendish-Bentinck, 3rd Duke of Portland.\nThe 3rd duke lent the original vase to Josiah Wedgwood and then to the British Museum for safe-keeping, by which point it was known as the \"Portland Vase\". It was deposited there permanently by the fourth duke in 1810, after a friend of his broke its base. It has remained in the British Museum ever since 1810, apart from 1929 to 1932, when the 6th duke put it up for sale at Christie's (where it failed to reach its reserve). It was finally purchased by the museum from the 7th duke in 1945 with the aid of a bequest from James Rose Vallentin.\nCopies.\nWedgwood had already had it described to him by the sculptor John Flaxman as \"the finest production of Art that has been brought to England and seems to be the very apex of perfection to which you are endeavoring\" and devoted four years of painstaking trials at duplicating the vase \u2013 not in glass but in black and white jasperware. He had problems with his copies ranging from cracking and blistering (clearly visible on the example at the Victoria and Albert Museum) to the sprigged reliefs 'lifting' during the firing, and in 1786 he feared that he could never apply the Jasper relief thinly enough to match the glass original's subtlety and delicacy. He finally managed to perfect it in 1790, with the issue of the \"first-edition\" of copies (with some of this edition, including the V&amp;A one, copying the cameo's delicacy by a combination of undercutting and shading the reliefs in grey), and it marks his last major achievement.\nWedgwood put the first edition on private show between April and May 1790, with that exhibition proving so popular that visitor numbers had to be restricted by only printing 1,900 tickets, before going on show in his public London showrooms. (One ticket to the private exhibition, illustrated by Samuel Alkin and printed with \"Admission to see Mr Wedgwood's copy of The Portland Vase, Greek Street, Soho, between 12 o'clock and 5\", was bound into the Wedgwood catalogue on view in the Victoria and Albert Museum's British Galleries.) As well as the V&amp;A copy (said to have come from the collection of Wedgwood's grandson, the naturalist Charles Darwin), others are held at the Fitzwilliam Museum (this is the copy sent by Wedgwood to Erasmus Darwin which his descendants lent to the Museum in 1963 and later sold to them); the Department of Britain, Europe and Prehistory at the British Museum, and the Indianapolis Museum of Art. The Auckland War Memorial Museum has a 19th-century jasperware https:// in their collections. The soap magnate William Hesketh Lever, who has one of the finest collections of Wedgwood Jasperware in existence today, purchased two of Wedgwood's Portland vases. One of them is on display in the Wedgwood rooms of the Lady Lever Art Gallery in Port Sunlight\nThe vase also inspired a 19th-century competition to duplicate its cameo-work in glass, with Benjamin Richardson offering a \u00a31,000 prize to anyone who could achieve that feat. Taking three years, glass maker Philip Pargeter made a copy and John Northwood engraved it, to win the prize. This copy is in the Corning Museum of Glass in Corning, New York.\nThe Wedgwood Museum collection is now branded the V&amp;A Wedgwood Collection. Displays at Barlaston, near Stoke-on-Trent, are now branded World of Wedgwood, described on its website as \u201cHome to Stoke-on-Trent's most prestigious brand, Wedgwood\u201d, and include the galleries of the V&amp;A Wedgwood Collection.\nVandalism and reconstruction.\nAt 3:45\u00a0p.m. on 7 February 1845, the vase was shattered by William Lloyd, who, after drinking all the previous week, threw a nearby sculpture on top of the case, smashing both it and the vase. He was arrested and charged with the crime of willful damage. When his lawyer said that an error in the wording of the act seemed to limit its application to the destruction of objects worth no more than \u00a35, he was convicted instead of the destruction of the glass case in which the vase had sat. He was sentenced to either pay a fine of \u00a33 (approximately \u00a3350 equivalent in 2017) or spend two months in prison. He remained in prison until an anonymous benefactor paid the fine by mail. The name William Lloyd is thought to be a pseudonym. Investigators hired by the British Museum concluded that he was actually William Mulcahy, a student who had gone missing from Trinity College Dublin. Detectives reported that the Mulcahy family was impoverished. The owner of the vase declined to bring a civil action against William Mulcahy because he did not want his family to suffer for \"an act of folly or madness which they could not control\".\nThe vase was pieced together with fair success in 1845 by British Museum restorer John Doubleday. At the time, the restoration was termed \"masterly\" and Doubleday was lauded by \"The Gentleman's Magazine\" for demonstrating \"skilful ingenuity\" and \"cleverness ... sufficient to establish his immortality as the prince of restorers\".\nHowever, Doubleday was unable to replace thirty-seven small fragments of the vase, which had been put into a box and apparently forgotten. On 5 October 1948, the keeper Bernard Ashmole received them in a box from G. A. Croker of Putney, who did not know what they were. After Doubleday's death, a fellow restorer from the British Museum took them to G. H. Gabb, a box maker, who was asked to make a box with thirty seven compartments, one for each fragment. However, the restorer also died and the box was never collected. After Gabb's death, the executor of his estate, Amy Reeves, brought in Croker to assess Gabb's effects. This was how Croker came to bring them to the museum to ask for help in identifying them.\nBy November 1948, the restoration appeared aged and it was decided to restore the vase again. It was dismantled by conservator J. W. R. Axtell in mid-November 1948. The pieces were examined by D. B. Harden and W. A. Thorpe, who confirmed that the circular glass base removed in 1845 was not original. Axtell then carried out a reconstruction, completed by 2 February 1949, in which he was only successful in replacing three of the 37 loose fragments. He reportedly used \"new adhesives\" for this restoration, which some thought might be epoxy resins or shellac, but were later discovered to simply be the same type of animal glue that Doubleday used in 1845. He also filled some areas with wax. No documentation of his work was produced.\nBy the late 1980s, the adhesive was again yellowing and brittle. Although the vase was shown at the British Museum as part of the \"Glass of the Caesars\" exhibition (November 1987 \u2013 March 1988), it was too fragile to travel to other locations afterwards. Instead, another reconstruction was performed between 1 June 1988 and 1 October 1989 by Nigel Williams and Sandra Smith. The pair were overseen by David Akehurst (CCO of Glass and Ceramics) who had assessed the vase's condition during the \"Glass of the Caesars\" exhibition and decided to go ahead with reconstruction and stabilization. The treatment had scholarly attention and press coverage. The vase was photographed and drawn to record the position of fragments before dismantling; the BBC filmed the conservation process. Conservation scientists at the museum tested many adhesives for long-term stability, choosing an epoxy resin with excellent ageing properties. Reassembly revealed some fragments had been filed down during the restorations, complicating the process. All but a few small splinters were integrated. Gaps were filled with blue or white resin.\nLittle sign of the original damage is visible, and, except for light cleaning, it is hoped that the vase should not require major conservation work for at least another century.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24704", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=24704", "title": "PostScript programming language", "text": ""}
{"id": "24705", "revid": "27335766", "url": "https://en.wikipedia.org/wiki?curid=24705", "title": "Patrimony", "text": "Patrimony may refer to:\nPolitics.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "24706", "revid": "326243", "url": "https://en.wikipedia.org/wiki?curid=24706", "title": "Paulus Aegineta", "text": ""}
{"id": "24707", "revid": "24902", "url": "https://en.wikipedia.org/wiki?curid=24707", "title": "Pyrenees", "text": "Range of mountains in southwest Europe\nThe Pyrenees are a mountain range straddling the border of France and Spain. They extend nearly from their union with the Cantabrian Mountains to Cap de Creus on the Mediterranean coast, reaching a maximum elevation of at the peak of Aneto.\nFor the most part, the main crest forms a political divide between the states of Spain and France, with the microstate of Andorra sandwiched in between. Historically, the Crown of Aragon and the Kingdom of Navarre extended on both sides of the mountain range.\nEtymology.\nIn Greek mythology, Pyrene is a princess who gave her name to the Pyrenees. The Greek historian Herodotus says Pyrene is the name of a town in Celtic Europe. According to Silius Italicus, she was the virgin daughter of Bebryx, a king in Mediterranean Gaul by whom the hero Hercules was given hospitality during his quest to steal the cattle of Geryon during his famous Labours. Hercules, characteristically drunk and lustful, violates the sacred code of hospitality and rapes his host's daughter. Pyrene gives birth to a serpent and runs away to the woods, afraid that her father will be angry. Alone, she pours out her story to the trees, attracting the attention of wild beasts who tear her to pieces.\nAfter his victory over Geryon, Hercules passes through the kingdom of Bebryx again, finding the girl's lacerated remains. As is often the case in stories of this hero, the sober Hercules responds with heartbroken grief and remorse at the actions of his darker self, and lays Pyrene to rest tenderly, demanding that the surrounding geography join in mourning and preserve her name: \"struck by Herculean voice, the mountaintops shudder at the ridges; he kept crying out with a sorrowful noise 'Pyrene!' and all the rock-cliffs and wild-beast haunts echo back 'Pyrene!' ... The mountains hold on to the wept-over name through the ages.\" Pliny the Elder connects the story of Hercules and Pyrene to Lusitania, but rejects it as \"fabulosa\", highly fictional.\nOther classical sources derived the name from the Greek word for fire, (IPA: ). According to Greek historian Diodorus Siculus \"in ancient times, we are told, certain herdsmen left a fire and the whole area of the mountains was entirely consumed; and due to this fire, since it raged continuously day after day, the surface of the earth was also burned and the mountains, because of what had taken place, were called the Pyrenees.\"\nGeography.\nPolitical divisions.\nThe Spanish Pyrenees are part of the following provinces, from east to west: Girona, Barcelona, Lleida (all in Catalonia), Huesca (in Aragon), Navarra (in Navarre) and Gipuzkoa (in the Basque Country).\nThe French Pyrenees are part of the following \"d\u00e9partements\", from east to west: Pyr\u00e9n\u00e9es-Orientales (also known as Northern Catalonia), Aude, Ari\u00e8ge, Haute-Garonne, Hautes-Pyr\u00e9n\u00e9es, and Pyr\u00e9n\u00e9es-Atlantiques (the latter two of which include the Pyrenees National Park).\nThe independent principality of Andorra is sandwiched in the eastern portion of the mountain range between the Spanish Pyrenees and French Pyrenees.\nPhysiographical divisions.\nPhysiographically, the Pyrenees may be divided into three sections: the Atlantic (or Western), the Central, and the Eastern Pyrenees. Together, they form a distinct physiographic province of the larger Alpine System division.\nIn the Western Pyrenees, from the Basque Mountains near the Bay of Biscay of the Atlantic Ocean, the average elevation gradually increases from west to east.\nThe Central Pyrenees extend eastward from the Somport pass to the Aran Valley, and they include the highest summits of this range:\nIn the Eastern Pyrenees, with the exception of one break at the eastern extremity of the \"Pyr\u00e9n\u00e9es Ari\u00e9geoises\" in the Ari\u00e8ge area, the mean elevation is remarkably uniform until a sudden decline occurs in the easternmost portion of the chain known as the Alb\u00e8res.\nFoothills.\nMost foothills of the Pyrenees are on the Spanish side, where there is a large and complex system of ranges stretching from Spanish Navarre, across northern Aragon and into Catalonia, almost reaching the Mediterranean coast with summits reaching . At the eastern end on the southern side lies a distinct area known as the Sub-Pyrenees.\nOn the French side the slopes of the main range descend abruptly and there are no foothills except in the Corbi\u00e8res Massif in the northeastern corner of the mountain system.\nGeology.\nThe Pyrenees are older than the Alps: their sediments were first deposited in coastal basins during the Paleozoic and Mesozoic eras. During Ediacaran to Ordovician times, Pyrenees were located at the Northwest margin of Gondwana, where they formed a lateral continuity of neighbouring areas, such as the Montagne Noire and the Mouthoumet massifs and Southwestern territory of Sardinia. Between 100 and 150\u00a0million years ago, during the Early Cretaceous Period, the Bay of Biscay fanned out, pushing present-day Spain against France and applying intense compressional pressure to large layers of sedimentary rock. The intense pressure and uplifting of the Earth's crust first affected the eastern part and moved progressively to the entire chain, culminating in the Eocene Epoch.\nThe eastern part of the Pyrenees consists largely of granite and gneissose rocks, while in the western part the granite peaks are flanked by layers of limestone. The massive and unworn character of the chain comes from its abundance of granite, which is particularly resistant to erosion, as well as weak glacial development.\nThe upper parts of the Pyrenees contain low-relief surfaces forming a peneplain. This peneplain originated no earlier than in Late Miocene times. Presumably it formed at height as extensive sedimentation raised the local base level considerably.\nLandscape.\nConspicuous features of Pyrenean scenery are:\nThe highest waterfall is Gavarnie (462\u00a0m or 1,515\u00a0ft), at the head of the Gave de Pau; the Cirque de Gavarnie, in the same valley, together with the nearby Cirque de Troumouse and Cirque d'Estaub\u00e9, are notable examples of the cirque formation.\nLow passes are lacking, and the principal roads and the railroads between France and Spain run only in the lowlands at the western and eastern ends of the Pyrenees, near sea level. The main passes of note are:\nBecause of the lack of low passes a number of tunnels have been created, beneath the passes at Somport, Envalira, and Puymorens and new routes in the center of the range at Bielsa and Vielha.\nA notable visual feature of this mountain range is La Br\u00e8che de Roland, a gap in the ridge line, which\u00a0\u2013 according to legend\u00a0\u2013 was created by Roland.\nNatural resources.\nThe metallic ores of the Pyrenees are not in general of much importance now, though there were iron mines at several locations in Andorra, as well as at Vicdessos in Ari\u00e8ge, and the foot of Canig\u00f3 in Pyr\u00e9n\u00e9es-Orientales long ago. Coal deposits capable of being profitably worked are situated chiefly on the Spanish slopes, but the French side has beds of lignite. The open pit of Trimoun near the commune of Luzenac (Ari\u00e8ge) is one of the greatest sources of talc in Europe.\nThere are many marble quarries in the Pyrenees, most of which were opened by the Romans in ancient times. Quarried intermittently, they provided prestigious marbles such as Grand Antique (used in Rome and Constantinople by the Romans), statuary white marbles as well as coloured marbles used to decorate the royal palaces of the Louvre and Versailles in France and the Royal Palace of Madrid in Spain.\nMineral springs are abundant and remarkable, and especially noteworthy are the hot springs. The hot springs, among which those of Les Escaldes in Andorra, Panticosa and Lles in Spain, Ax-les-Thermes, Bagn\u00e8res-de-Luchon and Eaux-Chaudes in France may be mentioned, are sulfurous and mostly situated high, near the contact of the granite with the stratified rocks. The lower springs, such as those of Bagn\u00e8res-de-Bigorre (Hautes-Pyr\u00e9n\u00e9es), Rennes-les-Bains (Aude), and Campagne-sur-Aude (Aude), are mostly selenitic and not hot.\nClimate.\nThe amount of precipitation the range receives, including rain and snow, is much greater in the western than in the eastern Pyrenees because of the moist air that blows in from the Atlantic Ocean over the Bay of Biscay. After dropping its moisture over the western and central Pyrenees, the air is left dry over the eastern Pyrenees. The winter average temperature is .\nSections of the mountain range vary in more than one respect. There are some glaciers in the western and snowy central Pyrenees, but there are no glaciers in the eastern Pyrenees because there is insufficient snowfall to cause their development. Glaciers are confined to the northern slopes of the central Pyrenees, and do not descend, like those of the Alps, far down into the valleys but rather have their greatest lengths along the direction of the mountain chain. They form, in fact, in a narrow zone near the crest of the highest mountains. Here, as in the other great mountain ranges of central Europe, there is substantial evidence of a much wider expanse of glaciation during the glacial periods. The best evidence of this is in the valley of Argeles Gazost, between Lourdes and Gavarnie, in the \"\" of Hautes-Pyr\u00e9n\u00e9es.\nThe annual snow-line varies in different parts of the Pyrenees from about above sea level. In average the seasonal snow is observed at least 50% of the time above between December and April.\nFlora and fauna.\nFlora.\nA still more marked effect of the preponderance of rainfall in the western half of the chain is seen in the vegetation. The lower mountains in the extreme west are wooded, but the extent of forest declines as one moves eastwards. The eastern Pyrenees are peculiarly wild and barren, all the more since it is in this part of the chain that granitic masses prevail. Also moving from west to east, there is a change in the composition of the flora, with the change becoming most evident as one passes the centre of the mountain chain from which point the Corbi\u00e8res Massif stretch north-eastwards towards the central plateau of France. Though the difference in latitude is only about 1\u00b0, in the west the flora resembles that of central Europe while in the east it is distinctly Mediterranean in character. The Pyrenees are nearly as rich in endemic species as the Alps, and among the most remarkable instances of that endemism is the occurrence of the monotypic genus \"Xatardia\" (family Apiaceae), which grows only on a high alpine pass between the Val d'Eynes and Catalonia. Other examples include \"Arenaria montana\", \"Bulbocodium vernum\", and \"Ranunculus glacialis\". The genus most abundantly represented in the range is that of the saxifrages, several species of which are endemic here.\nFauna.\nIn their fauna the Pyrenees present some striking instances of endemism. The Pyrenean desman is found only in some of the streams of the northern slopes of these mountains; the only other desman, the Russian desman, is confined to the Volga river basin in southern Russia, Kazakhstan and Ukraine. The Pyrenean brook salamander (\"Calotriton asper\"), an endemic amphibian, also lives in streams and lakes located at high altitudes. Among other peculiarities of Pyrenean fauna are blind insects in the caverns of Ari\u00e8ge, the principal genera of which are \"Anophthalmus\" and \"Adelops\".\nThe Pyrenean ibex, an endemic subspecies of the Iberian ibex, became extinct in January 2000; another subspecies, the western Spanish ibex, was introduced into the area, with the population numbering over 400 individuals as of 2020. The native brown bear population was hunted to near-extinction in the 1990s, but its numbers rebounded in 1996 when three bears were brought from Slovenia. The bear population has bred successfully, and there are now believed to be about 15 brown bears in the central region around Fos, with only four native ones still living in the Aspe Valley.\nProtected areas.\nPrincipal nature reserves and national parks:\nIn 1997, part of the Pyrenees (including Ordesa y Monte Perdido National Park and Pyrenees National Park) was inscribed on the UNESCO World Heritage List for its spectacular geologic landforms and testimony to the unique \"transhumance\" agricultural system.\nDemographics and culture.\nThe Pyrenean region possesses a varied ethnology, folklore and history: see Andorra; Aragon; Ari\u00e8ge; Basque Country; B\u00e9arn; Catalonia; Navarre; Roussillon. For their history, see also Almogavars, Marca Hispanica.\nThe principal languages spoken in the area are Spanish, French, Aragonese, Catalan (in Andorra and in Northern and Southern Catalonia), and Basque. Also spoken, to a lesser degree, is the Occitan language, consisting of the Gascon and Languedocien dialects in France and the Aranese dialect in the Aran Valley.\nAn important feature of rural life in the Pyrenees is 'transhumance', the moving of livestock from the farms in the valleys up to the higher grounds of the mountains for the summer. In this way the farming communities could keep larger herds than the lowland farms could support on their own. The principal animals moved were cows and sheep, but historically most members of farming families also moved to the higher pastures along with their animals, so they also took with them pigs, horses and chickens. Transhumance thus took the form of a mass biannual migration, moving uphill in May or June and returning to the farms in September or October. During the summer period, the families would live in basic stone cabins in the high mountains.\nNowadays, industrialisation and changing agriculture practices have diminished the custom. However, the importance of transhumance continues to be recognised through its celebration in popular festivals.\nScientific facilities.\nPic du Midi Observatory.\nThe Pic du Midi Observatory is an astronomical observatory located at 2877 metres on top of the Pic du Midi de Bigorre in the French Pyrenees. Construction of the observatory began in 1878 and the 8-metre dome was completed in 1908.\nThe observatory housed a powerful mechanical equatorial reflector which was used in 1909 to formally discredit the Martian canal theory. A telescope was installed in 1963, funded by NASA and was used to take detailed photographs of the surface of the Moon in preparation for the Apollo missions. Other studies conducted in 1965 provided a detailed analysis of the composition of the atmospheres on Mars and Venus, this served as a basis for Jet Propulsion Laboratory scientists to predict that these planets had no life.\nSince 1980, the observatory has had a 2-metre telescope, which is the largest telescope in France. Overtaken by the giant telescopes built in recent decades, today the observatory is widely open to amateur astronomy.\nOdeillo solar furnace.\nThe Odeillo solar furnace is the world's largest solar furnace. It is situated in Font-Romeu-Odeillo-Via, in the department of Pyr\u00e9n\u00e9es-Orientales, in south of France. Built between 1962 and 1968, it is and wide, and includes 63 heliostats. The site was chosen because of the length and the quality of sunshine with direct light (more than 2,500 h/year) and the purity of its atmosphere (high elevation and low average humidity).\nThis furnace serves as a science research site studying materials at very high temperatures. Temperatures above can be obtained in a few seconds; in addition, it provides rapid temperature changes and therefore allows studying the effect of thermal shocks.\nUrban areas.\nThere are two roads each side of the mountains: the E15 road (parallel with the Perthus railway tunnel) near the Mediterranean end and the E5/E70/E80 road on the opposite Atlantic end, both having opened in the 1970s. No big cities are in the range itself. The largest urban area close to the Pyrenees is Toulouse (Haute-Garonne), France with a population of 1,330,954 in its metropolitan area. On the Spanish side Pamplona (Navarre) is the closest city, with a population of 319,208 in its metropolitan area. Inside the Pyrenees the main towns are Andorra la Vella (22,256) and Escaldes-Engordany (14,367) in Andorra, Jaca (12,813), La Seu d'Urgell (12,252) and Ripoll (10,773) in Spain, and Lourdes (13,976), Saint-Gaudens (11,869) and Foix (10,046) in France.\nHighest summits.\nThe following is the complete list of the summits of the Pyrenees above 3,000 metres:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotable summits below 3,000 metres.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSports and leisure.\nBoth sides of the Pyrenees are popular spots for winter sports such as alpine skiing and mountaineering. The Pyrenees are also a good place for athletes to do high-elevation training in the summer, such as by bicycling and cross-country running.\nIn the summer and the autumn, the Pyrenees are usually featured in two of cycling's grand tours, the Tour de France held annually in July and the Vuelta a Espa\u00f1a held in September. The stages held in the Pyrenees are often crucial legs of both tours, drawing hundreds of thousands of spectators to the region.\nThree main long-distance footpaths run the length of the mountain range: the GR 10 across the northern slopes, the GR 11 across the southern slopes, and the HRP which traverses peaks and ridges along a high elevation route. In addition, there are numerous marked and unmarked trails throughout the region.\n\"Pirena\" is a dog-mushing competition held in the Pyrenees.\nSki resorts.\nSki resorts in the Pyrenees include:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24709", "revid": "28903366", "url": "https://en.wikipedia.org/wiki?curid=24709", "title": "Planetary nomenclature", "text": "System of uniquely identifying features on the surface of a planet or natural satellite\nPlanetary nomenclature, like terrestrial nomenclature, is a system of uniquely identifying features on the surface of a planet or natural satellite so that the features can be easily located, described, and discussed. Since the invention of the telescope, astronomers have given names to the surface features they have discerned, especially on the Moon and Mars. To found an authority on planetary nomenclature, the International Astronomical Union (IAU) was organized in 1919 to designate and standardize names for features on Solar System bodies.\nIAU approval procedure.\nWhen images are first obtained of the surface of a planet or satellite, a theme for naming features is chosen and a few important features are named, usually by members of the appropriate IAU task group (a commonly accepted planet-naming group). Later, as higher resolution images and maps become available, additional features are named at the request of investigators mapping or describing specific surfaces, features, or geologic formations. Anyone may suggest that a specific name be considered by a task group. If the members of the task group agree that the name is appropriate, it can be retained for use when there is a request from a member of the scientific community for a name of a specific feature. Names that pass review by a task group are submitted to the IAU Working Group for Planetary System Nomenclature (WGPSN). Once approved by the WGPSN, names are considered official and can be used on maps and in publications. They are also listed in the Gazetteer of Planetary Nomenclature.\nIAU rules and conventions.\nNames adopted by the IAU must follow various rules and conventions established and amended through the years by the Union. These include:\nIn addition to these general rules, each task group develops additional conventions as it formulates an interesting and meaningful nomenclature for individual planetary bodies.\nNaming conventions.\nNames for all planetary features include a descriptor term, with the exception of two feature types. For craters, the descriptor term is implicit. Some features named on Io and Triton do not carry a descriptor term because they are ephemeral.\nIn general, the naming convention for a feature type remains the same regardless of its size. Exceptions to this rule are valleys and craters on Mars and Venus; naming conventions for these features differ according to size.\nOne feature classification, \"regio\", was originally used on early maps of the Moon and Mercury (drawn from telescopic observations) to describe vague albedo features. It is now used to delineate a broad geographic region.\nNamed features on bodies so small that coordinates have not yet been determined are identified on drawings of the body that are included in the IAU Transactions volume of the year when the names were adopted. Satellite rings and gaps in the rings are named for scientists who have studied these features; drawings that show these names are also included in the pertinent Transactions volume. Names for atmospheric features are informal at present; a formal system will be chosen in the future.\nThe boundaries of many large features (such as \"terrae, regiones, planitiae\" and \"plana\") are not topographically or geomorphically distinct; the coordinates of these features are identified from an arbitrarily chosen center point. Boundaries (and thus coordinates) may be determined more accurately from geochemical and geophysical data obtained by future missions.\nDuring active missions, small surface features are often given informal names. These may include landing sites, spacecraft impact sites, and small topographic features, such as craters, hills, and rocks. Such names will not be given official status by the IAU, except as provided for by Rule 2 above. As for the larger objects, official names for any such small features would have to conform to established IAU rules and categories.\nCategories for naming features on planets and satellites.\nVenus.\nAll but three features on Venus are named after female personages (goddesses and historical or mythological women). These three exceptions were named before the convention was adopted, being respectively Alpha Regio, Beta Regio, and Maxwell Montes which is named after James Clerk Maxwell.\nMars and martian satellites.\nMars.\nWhen space probes have landed on Mars, individual small features such as rocks, dunes, and hollows have often been given informal names. Many of these are frivolous: features have been named after ice cream (such as Cookies N Cream); cartoon characters (such as SpongeBob SquarePants and Patrick); and 1970s music acts (such as ABBA and the Bee Gees).\nDeimos.\nFeatures on Deimos are named after authors who wrote about Martian satellites. There are currently two named features on Deimos\u00a0\u2013 Swift crater and Voltaire crater\u00a0\u2013 after Jonathan Swift and Voltaire who predicted the presence of Martian moons.\nPhobos.\nAll features on Phobos are named after scientists involved with the discovery, dynamics, or properties of the Martian satellites or people and places from Jonathan Swift's \"Gulliver's Travels\".\nSatellites of Jupiter.\nAmalthea.\nPeople and places associated with the Amalthea myth.\nThebe.\nFeatures on Thebe are named after people and places associated with the Thebe myth. There is only one named feature on Thebe\u00a0\u2013 Zethus Crater.\nSatellites of Saturn.\nJanus.\nPeople from myth of Castor and Pollux (twins)\nEpimetheus.\nPeople from myth of Castor and Pollux (twins)\nMimas.\nPeople and places from Malory's \"Le Morte d'Arthur\" legends (Baines translation)\nEnceladus.\nPeople and places from Burton's \"Arabian Nights\"\nTethys.\nPeople and places from Homer's \"Odyssey\"\nDione.\nLocations from Roman mythology, or people and places from Virgil's \"Aeneid\"\nRhea.\nPeople and places from creation myths\nHyperion.\nSun and Moon deities\nIapetus.\nPeople and places from Sayers' translation of \"Chanson de Roland\"; the only exception is Cassini Regio, which is named after its discoverer, Giovanni Cassini.\nSatellites of Uranus.\nSatellites of Uranus are named for characters from the works of William Shakespeare or from \"The Rape of the Lock\".\nPuck.\nMischievous (Pucklike) spirits (class)\nMiranda.\nMale Shakespearean characters, places\nAriel.\nLight spirits (individual and class)\nUmbriel.\nDark spirits (individual)\nTitania.\nFemale Shakespearean characters, places\nOberon.\nShakespearean tragic heroes and places\nSmall satellites.\nThere are currently no named features on Uranian small satellites, however the naming convention is heroines from plays by Shakespeare and Pope.\nSatellites of Neptune.\nProteus.\nFeatures on Proteus are to be named after water-related spirits, gods or goddesses who are neither Greek nor Roman. The only named feature on Proteus is crater Pharos.\nTriton.\nGeological features on Triton should be assigned aquatic names, excluding those which are Roman and Greek in origin. Possible themes for individual descriptor terms include worldwide aquatic spirits, famous terrestrial fountains or fountain locations, terrestrial aquatic features, famous terrestrial geysers or geyser locations and terrestrial islands.\nNereid.\nThere are currently no named features on Nereid. When features are discovered, they are to be named after individual nereids.\nSmall satellites.\nFeatures on other satellites of Neptune, once discovered, should be named after gods and goddesses associated with Neptune/Poseidon mythology or generic mythological aquatic beings.\nPluto and satellites.\nIn February 2017, the IAU approved the following themes for surface features on Pluto and its satellites:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24710", "revid": "49618147", "url": "https://en.wikipedia.org/wiki?curid=24710", "title": "North American P-51 Mustang", "text": "American WWII-era fighter aircraft\nThe North American Aviation P-51 Mustang is an American long-range, single-seat fighter and fighter-bomber used during World War II and the Korean War, among other conflicts. The Mustang was designed in 1940 by a team headed by James H. Kindelberger of North American Aviation (NAA) in response to a requirement of the British Purchasing Commission. The commission approached NAA to build Curtiss P-40 fighters under license for the Royal Air Force (RAF). Rather than build an old design from another company, NAA proposed the design and production of a more modern fighter. The prototype NA-73X airframe was completed on 9 September 1940, 102 days after contract signing, achieving its first flight on 26 October.\nThe Mustang was designed to use the Allison V-1710 engine without an export-sensitive turbosupercharger or a multi-stage supercharger, resulting in limited high-altitude performance. The aircraft was first flown operationally by the RAF as a tactical-reconnaissance aircraft and fighter-bomber (Mustang Mk I). In mid 1942, a development project known as the Rolls-Royce Mustang X, replaced the Allison engine with a Rolls-Royce Merlin 65 two-stage inter-cooled supercharged engine. During testing at Rolls-Royce's airfield at Hucknall in England, it was clear the engine dramatically improved the aircraft's performance at altitudes above without sacrificing range. Following receipt of the test results and after further flights by USAAF pilots, the results were so positive that North American began work on converting several aircraft developing into the P-51B/C (Mustang Mk III) model, which became the first long-range fighter to be able to compete with the Luftwaffe's fighters. The definitive version, the P-51D, was powered by the Packard V-1650-7, a license-built version of the two-speed, two-stage-supercharged Merlin 66, and was armed with six .50 caliber (12.7\u00a0mm) AN/M2 Browning machine guns.\nFrom late 1943 into 1945, P-51Bs and P-51Cs (supplemented by P-51Ds from mid-1944) were used by the USAAF's Eighth Air Force to escort bombers in raids over Germany, while the RAF's Second Tactical Air Force and the USAAF's Ninth Air Force used the Merlin-powered Mustangs as fighter-bombers, roles in which the Mustang helped ensure Allied air superiority in 1944. The P-51 was also used by Allied air forces in the North African, Mediterranean, Italian, and Pacific theaters. During World War II, Mustang pilots claimed to have destroyed 4,950 enemy aircraft.\nAt the start of the Korean War, the Mustang, by then redesignated F-51, was the main fighter of the United States until jet fighters, including North American's F-86 Sabre, took over this role; the Mustang then became a specialized fighter-bomber. Despite the advent of jet fighters, the Mustang remained in service with some air forces until the early 1980s. After the Korean War, Mustangs became popular civilian warbirds and air racing aircraft.\nDesign and development.\nIn 1938, the British government established a purchasing commission in the United States, headed by Sir Henry Self. Self was given overall responsibility for RAF production, research, and development, and also served with Sir Wilfrid Freeman, the Air Member for Development and Production. Self also sat on the British Air Council Subcommittee on Supply (or \"Supply Committee\"), and one of his tasks was to organize the manufacturing and supply of American fighter aircraft for the RAF. At the time, the choice was very limited, as no US aircraft then in production or flying met European standards, with only the Curtiss P-40 Tomahawk coming close. The Curtiss-Wright plant was running at capacity, so P-40s were in short supply.\nNorth American Aviation (NAA) was already supplying its T-6 Texan (known in British service as the \"Harvard\") trainer to the RAF, but was otherwise underused. NAA President \"Dutch\" Kindelberger approached Self to sell a new medium bomber, the North American B-25 Mitchell. Instead, Self asked if NAA could manufacture P-40s under license from Curtiss. Kindelberger said NAA could have a better aircraft with the same Allison V-1710 engine in the air sooner than establishing a production line for the P-40.\nJohn Attwood of NAA spent much time from January to April 1940 at the British Purchasing Commission's offices in New York discussing the British specifications of the proposed aircraft with British engineers. The discussions consisted of free-hand conceptual drawings of an aircraft with the British officials. Self was concerned that NAA had not ever designed a fighter, insisting they obtain the drawings and study the wind-tunnel test results for the P-40, before presenting them with detailed design drawings based on the agreed concept. NAA purchased the drawings and data from Curtiss for \u00a356,000, confirming the purchase with the British Purchasing Commission. The commission approved the resulting detailed design drawings, signing the commencement of the Mustang project on 4 May 1940, and firmly ordering 320 on 29 May 1940. Prior to this, NAA only had a letter of intent for an order of 320 aircraft. Curtiss engineers accused NAA of plagiarism.\nThe British Purchasing Commission stipulated armament of four .303 in (7.7 mm) machine guns (as used on the Tomahawk), a unit cost of no more than $40,000, and delivery of the first production aircraft by January 1941. In March 1940, 320 aircraft were ordered by Freeman, who had become the executive head of the Ministry of Aircraft Production (MAP) and the contract was promulgated on 24 April.\nThe \"NA-73X\", which was designed by a team led by lead engineer Edgar Schmued, followed the best conventional practice of the era, designed for ease of mass manufacturing. The design included several new features. One was a wing designed using laminar flow airfoils, which were developed co-operatively by NAA and the National Advisory Committee for Aeronautics (NACA). These airfoils generated low drag at high speeds. During the development of the NA-73X, a wind-tunnel test of two wings, one using NACA five-digit airfoils and the other using the new NAA/NACA 45\u2013100 airfoils, was performed in the University of Washington Kirsten Wind Tunnel. The results of this test showed the superiority of the wing designed with the NAA/NACA 45\u2013100 airfoils.\nThe other feature was a new cooling arrangement positioned aft (single ducted water and oil radiators assembly) that reduced the fuselage drag and effects on the wing. Later, after much development, they discovered that the cooling assembly could take advantage of the Meredith effect, in which heated air exited the radiator with a slight amount of jet thrust. Because NAA lacked a suitable wind tunnel to test this feature, it used the GALCIT wind tunnel at the California Institute of Technology. This led to some controversy over whether the Mustang's cooling system aerodynamics were developed by NAA's engineer Schmued or by Curtiss, as NAA had purchased the complete set of P-40 wind tunnel data and flight test reports. The NA-73X was also one of the first aircraft to have a fuselage lofted mathematically using conic sections; this resulted in smooth, low-drag surfaces. To aid production, the airframe was divided into five main sections\u2014forward, center, rear fuselage, and two wing halves\u2014all of which were fitted with wiring and piping before being joined.\nThe prototype NA-73X was rolled out in September 1940, just 102 days after the order had been placed; it first flew on 26 October 1940, 149 days into the contract, an uncommonly short development period even during the war. With test pilot Vance Breese at the controls, the prototype handled well and accommodated an impressive fuel load. The aircraft's three-section, semi-monocoque fuselage was constructed entirely of 24S aluminum alloy (a type of Duralumin) to save weight. It was armed with four .30 caliber (7.62\u00a0mm) AN/M2 Browning machine guns in the wings and two .50 caliber (12.7\u00a0mm) AN/M2 Browning machine guns mounted under the engine and firing through the propeller arc using a gun-synchronizing gear.\nWhile the USAAC could block any sales it considered detrimental to the interests of the US, the NA-73 was considered to be a special case because it had been designed at the behest of the British and all dealings were directly between the BPC and NAA, and did not involve the US Army or Wright Field in any way. In September 1940, a further 300 NA-73s were ordered by the MAP. To ensure uninterrupted delivery, Colonel Oliver P. Echols arranged with the Anglo-French Purchasing Commission to deliver the aircraft and NAA gave two examples (41-038 and 41-039) to the USAAC for evaluation.\nIt is important to note that the Mustang I (NA-73 and NA-83) and the Ia (NA-91), produced for the British, were not equivalent to the P-51A which was a later model (NA-99). Two British Mustang Is were held back by the USAAF and given the provisional model number XP-51. The USAAF held back 57 Mustang Ia aircraft armed with 4 x 20mm Hispano cannon, from the third British order, converting most of them to tactical reconnaissance aircraft and designating them P-51-2/F6A. North American retained the second aircraft of this batch to help develop the P-51A.\nThe Allison engine in the Mustang I had a single-stage supercharger that caused power to drop off rapidly above . This made it unsuitable for use at the altitudes where combat was taking place in Europe. Allison's attempts at developing a high-altitude engine were underfunded, but produced the V-1710-45, which featured a variable-speed auxiliary supercharger and developed at . In November 1941, NAA studied the possibility of using it, but fitting its excessive length in the Mustang would require extensive airframe modifications and cause long production delays. In May 1942, following positive reports from the RAF on the Mustang I's performance below 15,000\u00a0ft, Ronald Harker, a test pilot for Rolls-Royce, suggested fitting a Merlin 61, as fitted to the Spitfire Mk IX. The Merlin 61 had a two-speed, two-stage, intercooled supercharger, designed by Stanley Hooker of Rolls-Royce. Both the Merlin 61 and V-1710-39 were capable of about war emergency power at relatively low altitudes, but the Merlin developed at versus the Allison's at , delivering an increase in top speed from at ~ to an estimated at . In the end the Merlin 61 was never fitted to the Mustang X, (or any other Mustang). The 65 series (a medium altitude engine) was fitted to all Mustang X prototypes.\nInitially, the Mustang's steadfast champion, USAAC/F Assistant Air Attach\u00e9 Major Thomas Hitchcock, was concerned that the USAAF had little or no interest in the potential of the P-51A and its development with the Merlin engine. He wrote: \"Its development in this theatre has suffered for various reasons. Sired by the English out of an American mother, the Mustang has no parent in the Army Air Corps to appreciate and push its good points. It does not fully satisfy good people on both sides of the Atlantic who seem more interested in pointing with pride to the development of a 100% national product...\"\nNevertheless, during the British service development program of the Mustang I at Rolls-Royce's airfield at Hucknall, a close relationship was developed between NAA, the RAF Air Fighting Development Unit and Rolls-Royce Flight Test Establishment at Hucknall.\nFollowing extensive communication between Hitchcock (based in England), Rolls Royce engineers and Phillip Legarra at NAA regarding the promising outlook of a Merlin Mustang, along with the subsequent work in progress by Rolls Royce on the Mustang X, NAA representatives including Mustang designer Schmued visited the UK to examine and discuss the project in detail.\nThe promising calculations and modification progress by Rolls Royce led in July 1942 to a contract being let for two NAA Merlin prototypes, briefly designated XP-78, but soon to become the XP-51B. Based on the Packard V-1650-3 duplicating the Merlin 61's performance, NAA estimated for the XP-78 a top speed of at , and a service ceiling of .\nInitial flights of what was known to Rolls-Royce as the Mustang X were completed at Hucknall in October 1942.\nThe first flight of the US version, designated XP-51B took place in November 1942, but the USAAF had become so interested in the Merlin Mustang project that an initial contract for 400 aircraft was placed three months beforehand in August. The conversion led to production of the P-51B beginning at NAA's Inglewood, California, plant in June 1943, and P-51s started to become available to the 8th and 9th air forces in the winter of 1943\u20131944. Conversion to the two-stage supercharged and intercooled Merlin 60 series, over heavier than the single-stage Allison, driving a four-bladed Hamilton Standard propeller, required moving the wing slightly forward to correct the aircraft's center of gravity. After the USAAF, in July 1943, directed fighter aircraft manufacturers to maximize internal fuel capacity, NAA calculated the P-51B's center of gravity to be forward enough to include an additional fuel tank in the fuselage behind the pilot, greatly increasing the aircraft's range over that of the earlier P-51A. NAA incorporated the tank in the production of the P-51B-10, and supplied kits to retrofit it to all existing P-51Bs.\nOperational history.\nUnited Kingdom operational service.\nThe Mustang was initially developed for the RAF, which was its first user. As the first Mustangs were built to British requirements, these aircraft used factory numbers and were not P-51s; the order comprised 320 NA-73s, followed by 300 NA-83s, all of which were designated Mustang Mark I by the RAF. The first RAF Mustangs supplied under Lend-Lease were 93 Mk Ia designated as P-51s by the USAAF, followed by 50 P-51As used as Mustang Mk IIs. Aircraft supplied to Britain under Lend-Lease were required for accounting purposes to be on the USAAC's books before they could be supplied to Britain, but the British Aircraft Purchasing Commission signed its first contract for the North American NA-73 on 24 April 1940, before Lend-Lease was in effect. Thus, the initial order for the P-51 Mustang (as it was later known) was placed by the British under the \"cash and carry\" program, as required by the US Neutrality Acts of the 1930s.\nAfter the arrival of the initial aircraft in the UK in October 1941, the first squadron of Mustang Mk Is entered service in January 1942, the first being No. 26 Squadron RAF. Due to poor high-altitude performance, the Mustangs were used by Army Co-operation Command, rather than Fighter Command, and were used for tactical reconnaissance and ground-attack duties. On 10 May 1942, Mustangs first flew over France, near Berck-sur-Mer. On 27 July 1942, 16 RAF Mustangs undertook their first long-range reconnaissance mission over Germany. During the amphibious Dieppe Raid on the French coast (19 August 1942), four British and Canadian Mustang squadrons, including 26 Squadron, saw action covering the assault on the ground. By 1943\u20131944, British Mustangs were used extensively to seek out V-1 flying bomb sites. The last RAF Mustang Mk I and Mustang Mk II aircraft were struck off charge in 1945.\nArmy Co-operation Command used the Mustang's superior speed and long range to conduct low-altitude \"Rhubarb\" raids over continental Europe, sometimes penetrating German airspace. The V-1710 engine ran smoothly at 1,100 rpm, versus 1,600 for the Merlin, enabling long flights over water at altitude before approaching the enemy coastline. Over land, these flights followed a zig-zag course, turning every six minutes to foil enemy attempts at plotting an interception. During the first 18 months of Rhubarb raids, RAF Mustang Mk.Is and Mk.Ias destroyed or heavily damaged 200 locomotives, over 200 canal barges, and an unknown number of enemy aircraft parked on the ground, for a loss of eight Mustangs. At sea level, the Mustangs were able to outrun all enemy aircraft encountered. The RAF gained a significant performance enhancement at low altitude by removing or resetting the engine's manifold pressure regulator to allow overboosting, raising output as high as 1,780 horsepower at 70 in Hg. In December 1942, Allison approved only 1,570 horsepower at 60 in Hg manifold pressure for the V-1710-39.\nThe RAF later operated 308 P-51Bs and 636 P-51Cs, which were known in RAF service as Mustang Mk IIIs; the first units converted to the type in late 1943 and early 1944. Mustang Mk III units were operational until the end of World War II, though many units had already converted to the Mustang Mk IV (P-51D) and Mk IVa (P-51K) (828 in total, comprising 282 Mk IV and 600 Mk IVa). As all except the earliest aircraft were obtained under Lend-Lease, all Mustang aircraft still on RAF charge at the end of the war were either returned to the USAAF \"on paper\" or retained by the RAF for scrapping. The last RAF Mustangs were retired from service in 1947.\nUS operational service.\nPrewar theory.\nPrewar doctrine was based on the idea \"the bomber will always get through\". Despite RAF and Luftwaffe experience with daylight bombing, the USAAF still incorrectly believed in 1942 that tightly packed formations of bombers would have so much firepower that they could fend off fighters on their own. Fighter escort was a low priority, but when the concept was discussed in 1941, the Lockheed P-38 Lightning was considered to be most appropriate, as it had the speed and range. Another school of thought favored a heavily up-armed \"gunship\" conversion of a strategic bomber. A single-engined, high-speed fighter with the range of a bomber was thought to be an engineering impossibility.\nEighth Air Force bomber operations 1942\u20131943.\nThe 8th Air Force started operations from Britain in August 1942. At first, because of the limited scale of operations, no conclusive evidence showed American doctrine was failing. In the 26 operations flown to the end of 1942, the loss rate had been under 2%.\nIn January 1943, at the Casablanca Conference, the Allies formulated the Combined Bomber Offensive (CBO) plan for \"round-the-clock\" bombing \u2013 USAAF daytime operations complementing the RAF nighttime raids on industrial centers. In June 1943, the Combined Chiefs of Staff issued the Pointblank Directive to destroy the Luftwaffe's capacity before the planned invasion of Europe, putting the CBO into full implementation. German daytime fighter efforts were, at that time, focused on the Eastern Front and several other distant locations. Initial efforts by the 8th met limited and unorganized resistance, but with every mission, the Luftwaffe moved more aircraft to the west and quickly improved their battle direction. In late 1943, the 8th Air Force's heavy bombers conducted a series of deep penetration raids into Germany, beyond the range of escort fighters. The Schweinfurt\u2013Regensburg mission in August lost 60 B-17s of a force of 376, the 14 October attack lost 77 of a force of 291\u201426% of the attacking force.\nFor the US, the very concept of self-defending bombers was called into question, but instead of abandoning daylight raids and turning to night bombing, as the RAF suggested, they chose other paths; at first, bombers converted to gunships (the Boeing YB-40) were believed to be able to escort the bomber formations, but when the concept proved to be unsuccessful, thoughts then turned to the Lockheed P-38 Lightning. In early 1943, the USAAF also decided that the Republic P-47 Thunderbolt and P-51B be considered for the roles of smaller escort fighters, and in July, a report stated that the P-51B was \"the most promising plane\" with an endurance of 4 hours 45 minutes with the standard internal fuel of 184 gallons plus 150 gallons carried externally. In August, a P-51B was fitted with an extra internal 85-gallon tank, but problems with longitudinal stability occurred, so some compromises in performance with the full tank were made. Since the fuel from the fuselage tank was used during the initial stages of a mission, the fuel tank would be fitted in all Mustangs destined for VIII Fighter Command.\nP-51 introduction.\nThe P-51 Mustang was a solution to the need for an effective bomber escort. It used a common, reliable engine and had internal space for a larger-than-average fuel load. With external fuel tanks, it could accompany the bombers from England to Germany and back.\nBy the time the Pointblank offensive resumed in early 1944, matters had changed. Bomber escort defenses were initially layered, using the shorter-range P-38s and P-47s to escort the bombers during the initial stages of the raid before handing over to the P-51s when they were forced to turn for home. This provided continuous coverage during the raid. The Mustang was so clearly superior to earlier US designs that the 8th Air Force began to steadily switch its fighter groups to the Mustang, first swapping arriving P-47 groups to the 9th Air Force in exchange for those that were using P-51s, then gradually converting its Thunderbolt and Lightning groups. By the end of 1944, 14 of its 15 groups flew Mustangs.\nThe Luftwaffe's twin-engined Messerschmitt Bf 110 heavy fighters brought up to deal with the bombers proved to be easy prey for the Mustangs, and had to be quickly withdrawn from combat. The Focke-Wulf Fw 190A, already suffering from poor high-altitude performance, was outperformed by the Mustang at the B-17's altitude, and when laden with heavy bomber-hunting weapons as a replacement for the more vulnerable twin-engined \"Zerst\u00f6rer\" heavy fighters, it suffered heavy losses. The Messerschmitt Bf 109 had comparable performance at high altitudes, but its lightweight airframe was even more greatly affected by increases in armament. The Mustang's much lighter armament, tuned for antifighter combat, allowed it to overcome these single-engined opponents.\nFighting the \"Luftwaffe\".\nAt the start of 1944, Major General James Doolittle, the new commander of the 8th Air Force, released most fighters from the requirement of flying in close formation with the bombers, allowing them free rein to attack the Luftwaffe wherever it could be found. The aim was to achieve air supremacy. Mustang groups were sent far ahead of the bombers in a \"fighter sweep\" to intercept German fighters. Bomber crews complained, but by June, supremacy was achieved.\nThe \"Luftwaffe\" answered with the \"Gefechtsverband\" (\"battle formation\"). This consisted of a \"Sturmgruppe\" of heavily armed and armored Fw 190As escorted by two \"Begleitgruppen\" of Bf 109s, whose task was to keep the Mustangs away from the Fw 190s as they attacked the bombers. This strategy proved to be problematic, as the large German formation took a long time to assemble and was difficult to maneuver. It was often intercepted by the P-51 \"fighter sweeps\" before it could attack the bombers. However, German attacks against bombers could be effective when they did occur; the bomber-destroyer Fw 190As swept in from astern and often pressed their attacks to within .\nWhile not always able to avoid contact with the escorts, the threat of mass attacks and later the \"company front\" (eight abreast) assaults by armored \"Sturmgruppe\" Fw 190As brought an urgency to attacking the \"Luftwaffe\" wherever it could be found, either in the air or on the ground. Beginning in late February 1944, 8th Air Force fighter units began systematic strafing attacks on German airfields with increasing frequency and intensity, with the objective of gaining air supremacy over the Normandy battlefield. In general, these were conducted by units returning from escort missions, but beginning in March, many groups also were assigned airfield attacks instead of bomber support. The P-51, particularly with the advent of the K-14 gyro gunsight and the development of \"Clobber Colleges\" for the training of fighter pilots in late 1944, was a decisive element in Allied countermeasures against the \"Jagdverb\u00e4nde\".\nThe numerical superiority of the USAAF fighters, superb flying characteristics of the P-51, and pilot proficiency helped cripple the \"Luftwaffe\"'s fighter force. As a result, the fighter threat to the US, and later British, bombers was greatly diminished by July 1944. The RAF, long proponents of night bombing for protection, were able to reopen daylight bombing in 1944 as a result of the crippling of the \"Luftwaffe\" fighter arm. Reichsmarschall Hermann G\u00f6ring, commander of the \"Luftwaffe\" during the war, was quoted as saying, \"When I saw Mustangs over Berlin, I knew the jig was up.\"\nBeyond Pointblank.\nOn 15 April 1944, VIII Fighter Command began \"Operation Jackpot\", attacks on Luftwaffe fighter airfields. As the efficacy of these missions increased, the number of fighters at the German airbases fell to the point where they were no longer considered worthwhile targets. On 21 May, targets were expanded to include railways, locomotives, and other rolling stock used by the Germans to transport materiel and troops, in missions dubbed \"Chattanooga\". The P-51 excelled at this mission, although losses were much higher on strafing missions than in air-to-air combat, partially because the Mustang's Merlin engine, being liquid cooled, was vulnerable to radiator and coolant line damage from small-arms gunfire.\u00a0 On the other hand, the Mustang\u2019s stablemate, the Republic P-47 Thunderbolt, being powered by an air-cooled radial engine, could usually shrug off small-arms fire, and thus was regularly tasked with ground-strafing missions.\nGiven the overwhelming Allied air superiority, the Luftwaffe put its effort into the development of aircraft of such high performance that they could operate with impunity, but which also made bomber attack much more difficult, merely from the flight velocities they achieved. Foremost among these were the Messerschmitt Me 163B point-defense rocket interceptors, which started their operations with JG 400 near the end of July 1944, and the longer-endurance Messerschmitt Me 262A jet fighter, first flying with the \"Gruppe\"-strength Kommando Nowotny unit by the end of September 1944. In action, the Me 163 proved to be more dangerous to the Luftwaffe than to the Allies and was never a serious threat. The Me 262A was a serious threat, but attacks on their airfields neutralized them. The pioneering Junkers Jumo 004 axial-flow jet engines of the Me 262As needed careful nursing by their pilots, and these aircraft were particularly vulnerable during takeoff and landing. Lt. Chuck Yeager of the 357th Fighter Group was one of the first American pilots to shoot down an Me 262, which he caught during its landing approach. On 7 October 1944, Lt. Urban L. Drew of the 361st Fighter Group shot down two Me 262s that were taking off, while on the same day, Lt. Col. Hubert Zemke, who had transferred to the Mustang-equipped 479th Fighter Group, shot down what he thought was a Bf 109, only to have his gun camera film reveal that it may have been an Me 262. On 25 February 1945, Mustangs of the 55th Fighter Group surprised an entire \"Staffel\" of Me 262As at takeoff and destroyed six jets.\nThe Mustang also proved useful against the V-1s launched toward London. P-51B/Cs, using 150-octane fuel, were fast enough to catch the V-1 and operated in concert with shorter-range aircraft such as advanced marks of the Supermarine Spitfire and Hawker Tempest.\nBy 8 May 1945, the 8th, 9th, and 15th Air Force's P-51 groups claimed some 4,950 aircraft shot down (about half of all USAAF claims in the European theater, the most claimed by any Allied fighter in air-to-air combat) and 4,131 destroyed on the ground. Losses were about 2,520 aircraft. The 8th Air Force's 4th Fighter Group was the top-scoring fighter group in Europe, with 1,016 enemy aircraft claimed destroyed. This included 550 claimed in aerial combat and 466 on the ground.\nIn air combat, the top-scoring P-51 units (both of which exclusively flew Mustangs) were the 357th Fighter Group of the 8th Air Force with 565 air-to-air combat victories and the 9th Air Force's 354th Fighter Group with 664, which made it one of the top-scoring fighter groups. The top Mustang ace was the USAAF's George Preddy, whose final tally stood at 26.83 victories (a number that includes shared one half- and one third victory credits), 23 of which were scored with the P-51. Preddy was shot down and killed by friendly fire on Christmas Day 1944 during the Battle of the Bulge.\nIn China and the Pacific Theater.\nIn early 1945, P-51C, D, and K variants also joined the Chinese Nationalist Air Force. These Mustangs were provided to the 3rd, 4th, and 5th Fighter Groups and used to attack Japanese targets in occupied areas of China. The P-51 became the most capable fighter in China, while the Imperial Japanese Army Air Force used the Nakajima Ki-84 \"Hayate\" against it.\nThe P-51 was a relative latecomer to the Pacific theater, due largely to the need for the aircraft in Europe, although the P-38's twin-engined design was considered a safety advantage for long, over-water flights. The first P-51s were deployed in the Far East later in 1944, operating in close-support and escort missions, as well as tactical photoreconnaissance. As the war in Europe wound down, the P-51 became more common. With the capture of Iwo Jima, USAAF P-51\u00a0Mustang fighters of the VII\u00a0Fighter Command were stationed on that island starting in March 1945, being initially tasked with escorting Boeing B-29 Superfortress missions against the Japanese homeland.\nThe command's last major raid of May was a daylight incendiary attack on Yokohama on 29 May conducted by 517 B-29s escorted by 101 P-51s. This force was intercepted by 150 A6M Zero fighters, sparking an intense air battle in which five B-29s were shot down and another 175 damaged. In return, the P-51 pilots claimed 26 \"kills\" and 23 \"probables\" for the loss of three fighters. The 454 B-29s that reached Yokohama struck the city's main business district and destroyed of buildings; over 1000 Japanese were killed. Overall, the attacks in May destroyed of buildings, which was equivalent to one-seventh of Japan's total urban area. The minister of home affairs, Iwao Yamazaki, concluded after these raids that Japan's civil defense arrangements were \"considered to be futile\". On the first day of June, 521 B-29s escorted by 148 P-51s were dispatched in a daylight raid against Osaka. While en route to the city, the Mustangs flew through thick clouds, and 27 of the fighters were destroyed in collisions. Nevertheless, 458 heavy bombers and 27 P-51s reached the city, and the bombardment killed 3,960 Japanese and destroyed of buildings. On 5 June 473 B-29s struck Kobe by day and destroyed of buildings for the loss of 11 bombers. A force of 409 B-29s attacked Osaka again on 7 June; during this attack, of buildings were burnt out and the Americans did not suffer any losses. Osaka was bombed for the fourth time that month, on 15 June, when 444 B-29s destroyed of the city and another of nearby Amagasaki; 300,000 houses were destroyed in Osaka. This attack marked the end of the first phase of XXI\u00a0Bomber Command's attack on Japan's cities. During May and June, the bombers had destroyed much of the country's six largest cities, killing between 112,000 and 126,762 people and rendering millions homeless. The widespread destruction and high number of casualties from these raids caused many Japanese to realize that their country's military was no longer able to defend the home islands. American losses were low compared to Japanese casualties; 136 B-29s were downed during the campaign. In Tokyo, Osaka, Nagoya, Yokohama, Kobe, and Kawasaki, \"over 126,762 people were killed\u00a0... and a million and a half dwellings and over of urban space were destroyed.\" In Tokyo, Osaka and Nagoya, \"the areas leveled (almost ) exceeded the areas destroyed in all German cities by both the American and British air forces (about ).\"\nP-51s also conducted a series of independent ground-attack missions against targets in the home islands. The first of these operations took place on 16 April, when 57 P-51s strafed Kanoya Air Field in Kyushu. In operations conducted between 26 April and 22 June, the American fighter pilots claimed the destruction of 64 Japanese aircraft and damage to another 180 on the ground, as well as a further 10 shot down in flight; these claims were lower than the American planners had expected, however, and the raids were considered unsuccessful. USAAF losses were 11 P-51s to enemy action and seven to other causes.\nDue to the lack of Japanese air opposition to the American bomber raids, VII\u00a0Fighter Command was solely tasked with ground-attack missions from July. These raids were frequently made against airfields to destroy aircraft being held in reserve to attack the expected Allied invasion fleet. While the P-51 pilots only occasionally encountered Japanese fighters in the air, the airfields were protected by antiaircraft batteries and barrage balloons. By the end of the war, VII\u00a0Fighter Command had conducted 51 ground-attack raids, of which 41 were considered successful. The fighter pilots claimed to have destroyed or damaged 1,062 aircraft and 254 ships, along with large numbers of buildings and railway rolling stock. American losses were 91 pilots killed and 157 Mustangs destroyed.\nMedal of Honor recipients.\nTwo P-51 pilots received the Medal of Honor during World War II:\nPilot observations.\nChief Naval Test Pilot and C.O. Captured Enemy Aircraft Flight Capt. Eric Brown, RN, tested the Mustang at RAE Farnborough in March 1944 and noted:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Mustang was a good fighter and the best escort due to its incredible range, make no mistake about it. It was also the best American dogfighter. But the laminar-flow wing fitted to the Mustang could be a little tricky. It could not by any means out-turn a Spitfire. No way. It had a good rate-of-roll, better than the Spitfire, so I would say the plusses to the Spitfire and the Mustang just about equate. If I were in a dogfight, I'd prefer to be flying the Spitfire. The problem was I wouldn't like to be in a dogfight near Berlin, because I could never get home to Britain in a Spitfire!\nThe US Air Forces, Flight Test Engineering, assessed the Mustang B on 24 April 1944 thus:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nKurt B\u00fchligen, the third-highest scoring German fighter pilot of World War II's Western Front (with 112 confirmed victories, three against Mustangs), later stated:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nGerman fighter ace Heinz B\u00e4r said that the P-51:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nAfter World War II.\nIn the aftermath of World War II, the USAAF consolidated much of its wartime combat force and selected the P-51 as a \"standard\" piston-engined fighter, while other types, such as the P-38 and P-47, were withdrawn or given substantially reduced roles. As the more advanced (P-80 and P-84) jet fighters were introduced, the P-51 was also relegated to secondary duties.\nIn 1947, the newly formed USAF Strategic Air Command employed Mustangs alongside F-6 Mustangs and F-82 Twin Mustangs, due to their range capabilities. In 1948, the designation P-51 (P for pursuit) was changed to \"F-51\" (\"F\" for fighter) and the existing \"F\" designator for photographic reconnaissance aircraft was dropped because of a new designation scheme throughout the USAF. Aircraft still in service in the USAF or Air National Guard (ANG) when the system was changed included: \"F-51B\", \"F-51D\", \"F-51K\", \"RF-51D\" (formerly \"F-6D\"), \"RF-51K\" (formerly \"F-6K\") and \"TRF-51D\" (two-seat trainer conversions of F-6Ds). They remained in service from 1946 through 1951. By 1950, although Mustangs continued in service with the USAF after the war, the majority of the USAF's Mustangs had become surplus to requirements and placed in storage, while some were transferred to the Air Force Reserve and the ANG.\nFrom the start of the Korean War, the Mustang once again proved useful. A \"substantial number\" of stored or in-service F-51Ds were shipped, via aircraft carriers, to the combat zone, and were used by the USAF, the South African Air Force, and the Republic of Korea Air Force (ROKAF). The F-51 was used for ground attack, fitted with rockets and bombs, and photo reconnaissance, rather than being as interceptors or \"pure\" fighters, where it was already surpassed by early jets. After the first North Korean invasion, USAF units were forced to fly from bases in Japan and the F-51Ds, with their long range and endurance, could attack targets in Korea that short-ranged F-80 jets could not. Because of the vulnerable liquid cooling system, however, the F-51s sustained heavy losses to ground fire. Due to its lighter structure and a shortage of spare parts, the newer, faster F-51H was not used in Korea. On 5 August 1950, Major Louis J. Sebille of the 67th Fighter-Bomber Squadron attacked a North Korean armored column advancing on United Nations military units during the Battle of Pusan Perimeter. Though his aircraft was heavily damaged and he was wounded during the first pass on the column, he turned his F-51 around and deliberately crashed into the convoy at the cost of his life, and was posthumously awarded the Medal of Honor.\nMustangs continued flying with USAF and ROKAF fighter-bomber units on close support and interdiction missions in Korea until 1953 when they were largely replaced as fighter-bombers by USAF F-84s and by United States Navy (USN) Grumman F9F Panthers. Other air forces and units using the Mustang included the Royal Australian Air Force's 77 Squadron, which flew Australian-built Mustangs as part of British Commonwealth Forces Korea. The Mustangs were replaced by Gloster Meteor F8s in 1951. The South African Air Force's 2 Squadron used US-built Mustangs as part of the US 18th Fighter Bomber Wing and had suffered heavy losses by 1953, after which 2 Squadron converted to the F-86 Sabre.\nF-51s flew in the Air Force Reserve and ANG throughout the 1950s. The last American USAF Mustang was F-51D-30-NA AF serial no. 44-74936, which was finally withdrawn from service with the West Virginia Air National Guard's 167th Fighter Interceptor Squadron in January 1957 and retired to what was then called the Air Force Central Museum, although it was briefly reactivated to fly at the 50th anniversary of the Air Force Aerial Firepower Demonstration at the Air Proving Ground, Eglin AFB, Florida, on 6 May 1957. This aircraft, painted as P-51D-15-NA serial no. 44-15174, is on display at the National Museum of the United States Air Force, Wright-Patterson AFB, in Dayton, Ohio.\nThe final withdrawal of the Mustang from USAF dumped hundreds of P-51s onto the civilian market. The rights to the Mustang design were purchased from North American by the Cavalier Aircraft Corporation, which attempted to market the surplus Mustang aircraft in the US and overseas. In 1967 and again in 1972, the USAF procured batches of remanufactured Mustangs from Cavalier, most of them destined for air forces in South America and Asia that were participating in the Military Assistance Program (MAP). These aircraft were remanufactured from existing original F-51D airframes fitted with new V-1650-7 engines, a new radio, tall F-51H-type vertical tails, and a stronger wing that could carry six machine guns and a total of eight underwing hardpoints. Two bombs and six rockets could be carried. They all had an original F-51D-type canopy but carried a second seat for an observer behind the pilot. One additional Mustang was a two-seat, dual-control TF-51D (67-14866) with an enlarged canopy and only four wing guns. Although these remanufactured Mustangs were intended for sale to South American and Asian nations through the MAP, they were delivered to the USAF with full USAF markings. They were, however, allocated new serial numbers (67-14862/14866, 67-22579/22582 and 72-1526/1541).\nThe last US military use of the F-51 was in 1968 when the US Army employed a vintage F-51D (44-72990) as a chase aircraft for the Lockheed YAH-56 Cheyenne armed helicopter project. This aircraft was so successful that the Army ordered two F-51Ds from Cavalier in 1968 for use at Fort Rucker as chase planes. They were assigned the serials 68-15795 and 68-15796. These F-51s had wingtip fuel tanks and were unarmed. Following the end of the Cheyenne program, these two chase aircraft were used for other projects. One of them (68-15795) was fitted with a 106\u00a0mm recoilless rifle for evaluation of the weapon's value in attacking fortified ground targets. Cavalier Mustang 68-15796 survives at the Air Force Armament Museum, Eglin AFB, Florida, displayed indoors in World War II markings.\nThe F-51 was adopted by many foreign air forces and continued to be an effective fighter into the mid-1980s with smaller air arms. The last Mustang ever downed in battle occurred during Operation Power Pack in the Dominican Republic in 1965, with the last aircraft finally being retired by the Dominican Air Force in 1984.\nService with other air forces.\nAfter World War II, the P-51 Mustang served in the air arms of more than 25 nations. During the war, a Mustang cost about $51,000, while many hundreds were sold postwar for the nominal price of one dollar to signatories of the Inter-American Treaty of Reciprocal Assistance, ratified in Rio de Janeiro in 1947.\nThese countries used the P-51 Mustang:\nIn November 1944, 3 Squadron RAAF became the first Royal Australian Air Force unit to use Mustangs. At the time of its conversion from the P-40 to the Mustang, the squadron was based in Italy with the RAF's Desert Air Force.\n3 Squadron was renumbered 4 Squadron after returning to Australia from Italy, and converted to P-51Ds. Several other Australian or Pacific-based squadrons converted to either CAC-built Mustangs or to imported P-51Ks from July 1945, having been equipped with P-40s or Boomerangs for wartime service; these units were: 76, 77, 82, 83, 84 and 86 squadrons. Only 17 Mustangs reached the RAAF's First Tactical Air Force front-line squadrons by the time World War II ended in August 1945.\n76, 77 and 82 squadrons were formed into 81 Fighter Wing of the British Commonwealth Air Force, which was part of the British Commonwealth Occupation Force stationed in Japan from February 1946. 77 Squadron used its P-51s extensively during the first months of the Korean War, before converting to Gloster Meteor jets.\nFive reserve units from the Citizen Air Force also operated Mustangs. 21 \"City of Melbourne\" Squadron, based in the state of Victoria; 22 \"City of Sydney\" Squadron, based in New South Wales; 23 \"City of Brisbane\" Squadron, based in Queensland; 24 \"City of Adelaide\" Squadron, based in South Australia; and 25 \"City of Perth\" Squadron, based in Western Australia; all of these units were equipped with CAC Mustangs, rather than P-51D or Ks. The last Mustangs were retired from these units in 1960 when CAF units adopted a nonflying role.\n Nine Cavalier F-51D (including the two TF-51s) were given to Bolivia, under a program called Peace Condor.\nCanada had five squadrons equipped with Mustangs during World War II. RCAF 400, 414, and 430 squadrons flew Mustang Mk Is (1942\u20131944) and 441 and 442 squadrons flew Mustang Mk IIIs and IVAs in 1945. Postwar, a total of 150 Mustang P-51Ds were purchased and served in two regular (416 \"Lynx\" and 417 \"City of Windsor\") and six auxiliary fighter squadrons (402 \"City of Winnipeg\", 403 \"City of Calgary\", 420 \"City of London\", 424 \"City of Hamilton\", 442 \"City of Vancouver\" and 443 \"City of New Westminster\"). The Mustangs were declared obsolete in 1956, but special-duty versions served on into the early 1960s.\n The Chinese Nationalist Air Force obtained the P-51 during the late Sino-Japanese War to fight against the Japanese. After the war, Chiang Kai-shek's Nationalist government used the planes against insurgent Communist forces. The Nationalists retreated to Taiwan in 1949. Pilots supporting Chiang brought most of the Mustangs with them, where the aircraft became part of the island's defense arsenal.\n The Communist Chinese captured 39 P-51s from the Nationalists while they were retreating to Taiwan. In August 1949, the People's Liberation Army Air Force formed its first P-51 squadron at Beijing Nanyuan Airport and were tasked of the defending Beijing's airspace from Nationalist Air Force aircraft. On 1 October 1949, when Mao Zedong proclaimed the founding of the People's Republic of China, nine P-51s conducted a fly-past during the military parade in Beijing. By 1950, when Soviet Union began supplying modern military equipment to China, surviving P-51s were relegated to PLAAF's aviation school and 13 P-51s were modified as two-seat trainers. By September 1953, most P-51s were retired from service and only eight P-51s remained in service to teach Ilyushin Il-10 pilots on how to taxi aircraft.\nThe Costa Rican Air Force flew four P-51Ds from 1955 to 1964. \n In November 1958, three US-registered civilian P-51D Mustangs were illegally flown separately from Miami to Cuba, on delivery to the rebel forces of the 26th of July Movement, then headed by Fidel Castro during the Cuban Revolution. One of the Mustangs was damaged during delivery and none of them were used operationally. After the success of the revolution in January 1959, with other rebel aircraft plus those of the existing Cuban government forces, they were adopted into the Fuerza A\u00e9rea Revolucionaria. Due to increasing US restrictions and lack of spares and maintenance experience, they never achieved operational status. At the time of the Bay of Pigs invasion, the two intact Mustangs were already effectively grounded at Campo Columbia and at Santiago. After the failed invasion, they were placed on display with other symbols of \"revolutionary struggle\" and one remains on display at the Museo del Aire.\n The Dominican Republic was the largest Latin American air force to employ the P-51D, with six aircraft acquired in 1948, 44 ex-Swedish F-51Ds purchased in 1948, and a further Mustang obtained from an unknown source. It was the last nation to have any Mustangs in service, with some remaining in use as late as 1984. Nine of the final 10 aircraft were sold back to American collectors in 1988.\n The Salvadoran Air Force (\"Fuerza A\u00e9rea Salvadore\u00f1a\" or FAS) purchased five Cavalier Mustang IIs (and one dual-control Cavalier TF-51) that featured wingtip fuel tanks to increase combat range and up-rated Merlin engines. Seven P-51D Mustangs were also in service. They were used during the 1969 Football War against Honduras, the last time the P-51 was used in combat. One of them, FAS-404, was shot down by a Vought F4U-5 Corsair flown by Captain Fernando Soto in the last aerial combat between piston-engined fighters in the world.\n In late 1944, the first French unit began its transition to reconnaissance Mustangs. In January 1945, the Tactical Reconnaissance Squadron 2/33 of the French Air Force took their F-6Cs and F-6Ds over Germany on photographic mapping missions. The Mustangs remained in service until the early 1950s, when they were replaced by jet fighters.\n Several P-51s were captured by the Luftwaffe as \"Beuteflugzeug\" (\"captured aircraft\") following crash landings. These aircraft were subsequently repaired and test-flown by the \"Zirkus Rosarius\", or \"Rosarius Staffel\", the official \"Erprobungskommando\" of the Luftwaffe High Command, for combat evaluation at G\u00f6ttingen. The aircraft were repainted with German markings and bright yellow noses, tails, and bellies for identification. P-51B/P-51Cs \u2013 including examples marked with Luftwaffe \"Geschwaderkennung\" codes T9+CK, T9+FK, T9+HK, and T9+PK (with the \"T9\" prefix not known to be officially assigned to any existing Luftwaffe formation from their own records, outside of the photos of \"Zirkus Rosarius\"\u2013flown aircraft)\u2014with a total of three captured P-51Ds were also flown by the unit. Some of these P-51s were found by Allied forces at the end of the war; others crashed during testing. The Mustang is also listed in the appendix to the novel \"KG 200\" as having been flown by the German secret operations unit KG 200, which tested, evaluated, and sometimes clandestinely operated captured enemy aircraft during World War II.\n The Guatemalan Air Force had 30 P-51D Mustangs in service from 1954 to the early 1970s.\n Haiti had four P-51D Mustangs when President Paul Eug\u00e8ne Magloire was in power from 1950 to 1956, with the last retired in 1973\u20131974 and sold for spares to the Dominican Republic.\n Indonesia acquired 26 P-51D/Ks from the departing Netherlands East Indies Air Force in 1949\u20131950 and later received 35 P-51Ds from the United States in 1960\u20131961. The Mustangs were used against numerous rebellions during the 1950s, such as the CIA-backed Permesta rebels in 1958\u20131961. During this period, the Mustang scored the first and (as of 2022) the only aerial victory of the Indonesian Air Force, when on 18 May 1958, a P-51D Mustang piloted by Capt. Ignatius Dewanto shot down a Permesta's Revolutionary Air Force B-26 Invader piloted by Allen Lawrence Pope near Ambon. They were also used against Commonwealth (RAF, RAAF, and RNZAF) forces during the Indonesia\u2013Malaysia confrontation in the early 1960s. Indonesia received a shipment of five or seven Cavalier II Mustangs and one TF-51D (without tip tanks) delivered in 1972\u20131973 as part of \"Peace Pony\" program under the Mutual Defense Assistance Act. The last time Mustangs were deployed for military purposes was during the \"Wibawa V\" exercise at Mount Lawu, Magetan in February 1975. The Indonesian Mustangs were also used for filming \"Janur Kuning\", which was released in 1980. The Mustangs were replaced in 1976.\n A few P-51 Mustangs were illegally bought by Israel in 1948, crated, and smuggled into the country as agricultural equipment for use in the 1947\u20131949 Palestine war, serving alongside upwards of 23 Avia S-199 fighters (Czech-built Messerschmitt Bf 109Gs) in Israeli service, with the Mustangs quickly establishing themselves as the best fighter in the Israeli inventory. Further aircraft were bought from Sweden and were replaced by jets at the end of the 1950s, but not before the type was used in the Suez Crisis, at the opening of Operation Kadesh. In conjunction with a surprise parachute drop at the Mitla Pass, four P-51s were specially detailed to cut telephone and telegraph wires using their wings in extreme low level runs, which resulted in major interruptions to Egyptian communications.\n Italy was a postwar operator of P-51Ds; deliveries were slowed by the Korean War, but between September 1947 and January 1951, by MDAP count, 173 examples were delivered. They were used in all the AMI fighter units: 2, 3, 4, 5, 6 and 51 \"Stormo\" (wing), plus some employed in schools and experimental units. Considered a \"glamorous\" fighter, P-51s were even used as personal aircraft by several Italian commanders. Some restrictions were placed on its use due to unfavorable flying characteristics. Handling had to be done with much care when fuel tanks were fully used, and several aerobatic maneuvers were forbidden. Overall, the P-51D was highly rated even compared to the other primary postwar fighter in Italian service, the Supermarine Spitfire, partly because these P-51Ds were in very good condition in contrast to all other Allied fighters supplied to Italy. Phasing out of the Mustang began in mid-1958.\n The P-51C-11-NT \"Evalina\", marked as \"278\" (former USAAF serial: 44-10816) and flown by 26th FS, 51st FG, was hit by gunfire on 16 January 1945 and belly-landed on Suchon Airfield in China, which was held by the Japanese. The Japanese repaired the aircraft, roughly applied Hinomaru roundels and flew the aircraft to the Fussa evaluation center (now Yokota Air Base) in Japan.\n The Royal Netherlands East Indies Army Air Force received 40 P-51Ds and flew them in the course of the Indonesian National Revolution, particularly during the two Dutch police actions: Operation Product in 1947 and Operation Kraai in 1948\u20131949. When the conflict was over, Indonesia received 26 of these Mustangs.\nNew Zealand ordered 370 P-51 Mustangs to supplement its F4U Corsairs in the Pacific Ocean Areas theater. Scheduled deliveries were for an initial batch of 30 P-51Ds, followed by 137 more P-51Ds and 203 P-51Ms. The original 30 were being shipped as the war ended in August 1945; these were stored in their packing cases, and the order for the additional Mustangs was canceled. In 1951, the stored Mustangs entered service in 1 (Auckland), 2 (Wellington), 3 (Canterbury), and 4 (Otago) squadrons of the Territorial Air Force (TAF). The Mustangs remained in service until they were prematurely retired in August 1955 following a series of problems with undercarriage and coolant-system corrosion problems. Four Mustangs served on as target tugs until the TAF was disbanded in 1957. RNZAF pilots in the Royal Air Force also flew the P-51 and at least one New Zealand pilot scored victories over Europe while on loan to a USAAF P-51 squadron.\n The Nicaraguan National Guard purchased 26 P-51D Mustangs from Sweden in 1954 and later received 30 P-51D Mustangs from the US together with two TF-51 models from MAP after 1954. All aircraft of this type were retired from service by 1964.\nThe Philippines acquired 103 P-51D Mustangs after World War II, operated by the 6th \"Cobras\", 7th \"Bulldogs\" and 8th \"Scorpions\" tactical fighter squadrons of the 5th Fighter Wing. These became the backbone of the postwar Philippine Army Air Corps and Philippine Air Force, and were used extensively during the Huk campaign, fighting against communist insurgents, as well as the suppression of Moro rebels led by Hadji Kamlon in southern Philippines until 1955. The Mustangs were also the first aircraft of the Philippine air demonstration team, which was formed in 1953 and given the name the Blue Diamonds the following year. The Mustangs were replaced by 56 F-86 Sabres in the late 1950s, but some were still in service for COIN roles up to the early 1980s.\nDuring World War II, five Polish Air Force in Great Britain squadrons used Mustangs. The first Polish unit equipped (7 June 1942) with Mustang Mk Is was \"B\" Flight of 309 \"Ziemi Czerwie\u0144skiej\" Squadron (an Army Co-Operation Command unit), followed by \"A\" Flight in March 1943. Subsequently, 309 Squadron was redesignated a fighter/reconnaissance unit and became part of Fighter Command. On 13 March 1944, 316 \"\"Warszawski\" Squadron received their first Mustang Mk IIIs; rearming of the unit was completed by the end of April. By 26 March 1944, 306 \"Toru\u0144ski\" Sqn and 315 \"D\u0119bli\u0144ski\" Sqn received Mustangs Mk IIIs (the whole operation took 12\u00a0days). On 20 October 1944, Mustang Mk Is in 309 Squadron were replaced by Mk IIIs. On 11 December 1944, the unit was again renamed, becoming 309 \"Dywizjon My\u015bliwski\" \"Ziemi Czerwie\u0144skiej\"\" or 309 \"Land of Czerwien\" Polish Fighter Squadron. In 1945, 303 \"Ko\u015bciuszko\" Sqn received 20 Mustangs Mk IV/Mk IVA replacements. Postwar, between 6 December 1946 and 6 January 1947, all five Polish squadrons equipped with Mustangs were disbanded. Poland returned about 80 Mustang Mk IIIs and 20 Mustangs Mk IV/IVAs to the RAF, which transferred them to the US government.\n The Somalian Air Force operated eight P-51Ds in post-World War II service.\nNo.5 Squadron South African Air Force operated Mustang Mk IIIs (P-51B/C) and Mk IVs (P-51D/K) in Italy during World War II, beginning in September 1944, when the squadron converted to the Mustang Mk III from Kittyhawks. The Mk IV and Mk IVA came into SA service in March 1945. These aircraft were generally camouflaged in the British style, having been drawn from RAF stocks; all carried RAF serial numbers and were struck off charge and scrapped in October 1945. In 1950, 2 Squadron SAAF was supplied with F-51D Mustangs by the United States for Korean War service. The type performed well in South African hands before being replaced by the F-86 Sabre in 1952 and 1953.\nWithin a month of the outbreak of the Korean War, 10 F-51D Mustangs were provided to the badly depleted Republic of Korea Air Force as a part of the Bout One Project. They were flown by both South Korean airmen, several of whom were veterans of the Imperial Japanese Army and Navy air services during World War II, as well as by US advisers led by Major Dean Hess. Later, more were provided both from US and from South African stocks, as the latter were converting to F-86 Sabres. They formed the backbone of the South Korean Air Force until they were replaced by Sabres.\nIt also served with the ROKAF Black Eagles aerobatic team, until retired in 1954.\nSweden's \"Flygvapnet\" first recuperated four of the P-51s (two P-51Bs and two early P-51Ds) that had been diverted to Sweden during missions over Europe. In February 1945, Sweden purchased 50 P-51Ds designated J 26, which were delivered by American pilots in April and assigned to the Uppland Wing (F 16) at Uppsala as interceptors. In early 1946, the J\u00e4mtland Wing (F 4) at \u00d6stersund was equipped with a second batch of 90 P-51Ds. A final batch of 21 Mustangs was purchased in 1948. In all, 161 J 26s served in the Swedish Air Force during the late 1940s. About 12 were modified for photo reconnaissance and redesignated S 26. Some of these aircraft participated in the secret Swedish mapping of new Soviet military installations at the Baltic coast in 1946\u201347 (\"Operation Falun\"), an endeavor that entailed many intentional violations of Soviet airspace. However, the Mustang could outdive any Soviet fighter of that era, so no S 26s were lost in these missions. The J 26s were replaced by De Havilland Vampires around 1950. The S 26s were replaced by S 29Cs in the early 1950s.\nThe Swiss Air Force operated a few USAAF P-51s that had been impounded by Swiss authorities during World War II after the pilots were forced to land in neutral Switzerland. After the war, Switzerland also bought 130 P-51s for $4,000 each. They served until 1958.\n The Soviet Union received at least 10 early-model ex-RAF Mustang Mk Is and tested them, but found them to \"under-perform\" compared to contemporary USSR fighters, relegating them to training units. Later Lend-Lease deliveries of the P-51B/C and D series, along with other Mustangs abandoned in Russia after the famous \"shuttle missions\", were repaired and used by the Soviet Air Force, but not in front-line service.\n The Uruguayan Air Force used 25 P-51D Mustangs from 1950 to 1960; some were subsequently sold to Bolivia.\nP-51s and civil aviation.\nMany P-51s were sold as surplus after the war, often for as little as $1,500. Some were sold to former wartime fliers or other aficionados for personal use, while others were modified for air racing.\nOne of the most significant Mustangs involved in air racing was serial number 44-10947, a surplus P-51C-10-NT purchased by film stunt pilot Paul Mantz. He modified the wings, sealing them to create a giant fuel tank in each one; these \"wet wings\" reduced the need for fuel stops or drag-inducing drop tanks. Named \"Blaze of Noon\" after the film \"Blaze of Noon\", the aircraft won the 1946 and 1947 Bendix Air Races, took second in the 1948 Bendix, and placed third in the 1949 Bendix. Mantz also set a US coast-to-coast record in 1947. He sold the Mustang to Charles F. Blair Jr (future husband of Maureen O'Hara), who renamed it \"Excalibur III\" and used it to set a New York-to-London (about ) record in 1951: 7 hr 48 min from takeoff at Idlewild to overhead London Airport. Later that year, Blair flew from Norway to Fairbanks, Alaska, via the North Pole (about ), proving that navigation via sun sights was possible over the magnetic North Pole region. For this feat, he was awarded the Harmon Trophy and the Air Force was forced to change its thoughts on a possible Soviet air strike from the north. This Mustang now sits in the National Air and Space Museum's Steven F. Udvar-Hazy Center.\nIn 1958, the RCAF retired its 78 remaining Mustangs. RCAF pilot Lynn Garrison ferried them from their various storage locations to Canastota, New York, where the American buyers were based. Garrison flew each of the surviving aircraft at least once. These aircraft make up a large percentage of the aircraft presently flying worldwide.\nThe most prominent firm to convert Mustangs to civilian use was Trans-Florida Aviation, later renamed Cavalier Aircraft Corporation, which produced the Cavalier Mustang. Modifications included a taller tailfin and wingtip tanks. Conversions included a Cavalier Mustang specialty: a \"tight\" second seat added in the space formerly occupied by the military radio and fuselage fuel tank.\nIn the late 1960s and early 1970s, when the United States Department of Defense wished to supply aircraft to South American countries and later Indonesia for close air support and counterinsurgency, it paid Cavalier to return some of their civilian conversions back to updated military specifications.\nIn the 21st century, a P-51 can command a price of more than $1\u00a0million, even for only partially restored aircraft. There were 204 privately owned P-51s in the US on the FAA registry in 2011, most of which are still flying, often associated with organizations such as the Commemorative Air Force (formerly the Confederate Air Force).\nIn May 2013, Doug Matthews set an altitude record of in a P-51 named \"The Rebel\" for piston-powered aircraft weighing . Flying from a grass runway at Florida's Indiantown airport and over Lake Okeechobee, Matthews set world records for time to reach altitudes of , 18 minutes and , 31 minutes. He set a level-flight altitude record of in level flight and an absolute altitude record of , breaking the previous record of set in 1954.\nVariants.\nOver 20 variants of the P-51 Mustang were produced from 1940 to after the war.\nProduction.\nExcept for the small numbers assembled or produced in Australia, all Mustangs were built by North American initially at Inglewood, California, but then additionally in Dallas, Texas.\nSpecifications (P-51D Mustang).\n\"Data from\" Erection and Maintenance Manual for P-51D and P-51K, P-51 Tactical Planning Characteristics &amp; Performance Chart, The Great Book of Fighters, \"and\" Quest for PerformanceGeneral characteristics* Crew: 1* Aspect ratio: 5.83\nPerformance* Lift-to-drag: 14.6\nArmament\nNotable appearances in media.\n[[File:P-51C-18.jpg|thumb|The restored P-51C Mustang associated with the [[Tuskegee Airmen]] now flown by [[Red Tail Project]] as described in \"[[Red Tail Reborn]]\"]]\nScale replicas.\nAs indicative of the iconic nature of the P-51, manufacturers within the hobby industry have created scale plastic model kits of the P-51 Mustang, with varying degrees of detail and skill levels. The aircraft have also been the subject of numerous scale flying replicas. Aside from the popular model aircraft, several [[kitplane]] manufacturers offer &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;2\u20443, and &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3\u20444-scale replicas capable of comfortably seating one (or even two) and offering high performance combined with more forgiving flight characteristics. Such aircraft include the [[Titan T-51 Mustang]], [[W.A.R. P-51 Mustang]], [[Linn Mini Mustang]], [[Jurca Gnatsum]], [[Thunder Mustang]], [[Stewart S-51D Mustang]], [[Loehle 5151 Mustang]] and [[ScaleWings SW51 Mustang]].\nSee also.\nRelated development\nAircraft of comparable role, configuration, and era\nRelated lists\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n[[Category:North American P-51 Mustang| ]]\n[[Category:1940s United States fighter aircraft]]\n[[Category:North American Aviation aircraft|P-51 Mustang]]\n[[Category:Single-engined tractor aircraft]]\n[[Category:Low-wing aircraft]]\n[[Category:Aircraft first flown in 1940]]\n[[Category:Aircraft with retractable conventional landing gear]]\n[[Category:Single-engined piston aircraft]]"}
{"id": "24711", "revid": "23645052", "url": "https://en.wikipedia.org/wiki?curid=24711", "title": "Plasma membrane", "text": ""}
{"id": "24714", "revid": "56299", "url": "https://en.wikipedia.org/wiki?curid=24714", "title": "Precession", "text": "Periodic change in the direction of a rotation axis\nPrecession is a change in the orientation of the rotationalaxis of a rotatingbody. In an appropriate referenceframe it can be defined as a change in the first Eulerangle, whereas the third Eulerangle defines the rotation itself. In other words, if the axis of rotation of a body is itself rotating about a second axis, that body is said to be precessing about the secondaxis. A motion in which the second Eulerangle changes is called \"nutation\". In physics, there are two types of precession: torque-free and torque-induced.\nIn astronomy, precession refers to any of several slow changes in an astronomicalbody's rotational or orbital parameters. An important example is the steady change in the orientation of the axis of rotationof the Earth, known as the precessionof the equinoxes.\nTorque-free or torque neglected.\nTorque-free precession implies that no external moment (torque) is applied to the body. In torque-free precession, the angular momentum is a constant, but the angular velocity vector changes orientation with time. What makes this possible is a time-varying momentof inertia, or more precisely, a time-varying inertia matrix. The inertia matrix is composed of the momentsof inertia of a body calculated with respect to separate coordinateaxes (e.g.\"x\", \"y\", \"z\"). If an object is asymmetric about its principal axisof rotation, the momentof inertia with respect to each coordinate direction will change with time, while preserving angular momentum. The result is that the component of the angular velocities of the body about each axis will vary inversely with each axis' momentof inertia.\nThe torque-free precession rate of an object with an axis of symmetry, such as a disk, spinning about an axis not aligned with that axisof symmetry can be calculated as follows:\nformula_1\nwhere \u03c9p is the precession rate, \u03c9s is the spin rate about the axis of symmetry, Is is the moment of inertia about the axis of symmetry, Ip is moment of inertia about either of the other two equal perpendicular principal axes, and \u03b1 is the angle between the moment of inertia direction and the symmetry axis.\nWhen an object is not perfectly rigid, inelastic dissipation will tend to damp torque-free precession, and the rotation axis will align itself with one of the inertia axes of the body.\nFor a generic solid object without any axis of symmetry, the evolution of the object's orientation, represented (for example) by a rotation matrix R that transforms internal to external coordinates, may be numerically simulated. Given the object's fixed internal moment of inertia tensor I0 and fixed external angular momentum L, the instantaneous angular velocity is\nformula_2\nPrecession occurs by repeatedly recalculating \u03c9 and applying a small rotation vector \"\u03c9 dt\" for the short time \"dt\"; e.g.:\nformula_3\nfor the skew-symmetric matrix [\u03c9]\u00d7. The errors induced by finite time steps tend to increase the rotational kinetic energy:\nformula_4\nthis unphysical tendency can be counteracted by repeatedly applying a small rotation vector v perpendicular to both \u03c9 and L, noting that\nformula_5\nTorque-induced.\nTorque-induced precession (gyroscopic precession) is the phenomenon in which the axis of a spinning object (e.g., a gyroscope) describes a cone in space when an external torque is applied to it. The phenomenon is commonly seen in a spinning toy top, but all rotating objects can undergo precession. If the speed of the rotation and the magnitude of the external torque are constant, the spin axis will move at right angles to the direction that would intuitively result from the external torque. In the case of a toy top, its weight is acting downwards from its centerof mass and the normalforce (reaction) of the ground is pushing up on it at the point of contact with the support. These two opposite forces produce a torque which causes the top to precess.\nThe device depicted on the right is gimbal-mounted. From inside to outside there are three axes of rotation: the hub of the wheel, the gimbal axis, and the vertical pivot.\nTo distinguish between the two horizontal axes, rotation around the wheel hub will be called \"spinning\", and rotation around the gimbal axis will be called \"pitching\". Rotation around the vertical pivot axis is called \"rotation\".\nFirst, imagine that the entire device is rotating around the (vertical) pivot axis. Then, spinning of the wheel (around the wheelhub) is added. Imagine the gimbal axis to be locked, so that the wheel cannot pitch. The gimbal axis has sensors, that measure whether there is a torque around the gimbal axis.\nIn the picture, a section of the wheel has been named \"dm\"1. At the depicted moment in time, section \"dm\"1 is at the perimeter of the rotating motion around the (vertical) pivot axis. Section \"dm\"1, therefore, has a lot of angular rotating velocity with respect to the rotation around the pivot axis, and as \"dm\"1 is forced closer to the pivot axis of the rotation (by the wheel spinning further), because of the Coriolis effect, with respect to the vertical pivot axis, \"dm\"1 tends to move in the direction of the top-left arrow in the diagram (shown at 45\u00b0) in the direction of rotation around the pivot axis. Section \"dm\"2 of the wheel is moving away from the pivot axis, and so a force (again, a Coriolis force) acts in the same direction as in the case of \"dm\"1. Note that both arrows point in the same direction.\nThe same reasoning applies for the bottom half of the wheel, but there the arrows point in the opposite direction to that of the top arrows. Combined over the entire wheel, there is a torque around the gimbal axis when some spinning is added to rotation around a vertical axis.\nIt is important to note that the torque around the gimbal axis arises without any delay; the response is instantaneous.\nIn the discussion above, the setup was kept unchanging by preventing pitching around the gimbal axis. In the case of a spinning toy top, when the spinning top starts tilting, gravity exerts a torque. However, instead of rolling over, the spinning top just pitches a little. This pitching motion reorients the spinning top with respect to the torque that is being exerted. The result is that the torque exerted by gravity\u00a0\u2013 via the pitching motion\u00a0\u2013 elicits gyroscopic precession (which in turn yields a counter torque against the gravity torque) rather than causing the spinning top to fall to its side.\nPrecession or gyroscopic considerations have an effect on bicycle performance at high speed. Precession is also the mechanism behind gyrocompasses.\nClassical (Newtonian).\nPrecession is the change of angular velocity and angular momentum produced by a torque. The general equation that relates the torque to the rate of change of angular momentum is:\nformula_6\nwhere formula_7 and formula_8 are the torque and angular momentum vectors respectively.\nDue to the way the torque vectors are defined, it is a vector that is perpendicular to the plane of the forces that create it. Thus it may be seen that the angular momentum vector will change perpendicular to those forces. Depending on how the forces are created, they will often rotate with the angular momentum vector, and then circular precession is created.\nUnder these circumstances the angular velocity of precession is given by: \nformula_9\nwhere \"I\"s is the moment of inertia, \u03c9s is the angular velocity of spin about the spin axis, m is the mass, \"g\" is the acceleration due to gravity, \u03b8 is the angle between the spin axis and the axis of precession and \"r\" is the distance between the center of mass and the pivot. The torque vector originates at the center of mass. Using \u03c9 =, we find that the period of precession is given by:\nformula_10\nWhere \"I\"s is the moment of inertia, \"T\"s is the period of spin about the spin axis, and \u03c4 is the torque. In general, the problem is more complicated than this, however.\nRelativistic (Einsteinian).\nThe special and general theories of relativity give three types of corrections to the Newtonian precession, of a gyroscope near a large mass such as Earth, described above. They are:\nThe geodesics (sometimes precession) are used in the prediction of the anomalous perihelion precession of the planets, most notably for the accurate prediction of the apsidal precession of Mercury.\nAstronomy.\nIn astronomy, precession refers to any of several gravity-induced, slow and continuous changes in an astronomical body's rotational axis or orbital path. Precessionof the equinoxes, perihelion precession, changes in the tiltof Earth's axis to its orbit, and the eccentricity of its orbit over tensof thousands of years are all important parts of the astronomical theory of iceages. &lt;templatestyles src=\"Crossreference/styles.css\" /&gt;\nAxial precession (precession of the equinoxes).\nAxial precession is the movement of the rotational axis of an astronomical body, whereby the axis slowly traces out a cone. In the case of Earth, this type of precession is also known as the \"precessionof the equinoxes\", \"lunisolar precession\", or \"precessionof the equator\". Earth goes through one such complete precessional cycle in a period of approximately 26,000years or 1\u00b0 every 72years, during which the positions of stars will slowly change in both equatorial coordinates and ecliptic longitude. Over this cycle, Earth's north axial pole moves from where it is now, within 1\u00b0 of Polaris, in a circle around the eclipticpole, with an angular radius of about23.5\u00b0.\nThe ancient Greek astronomer (c.) is generally accepted to be the earliest known astronomer to recognize and assess the precessionof the equinoxes at about 1\u00b0 percentury (which is not far from the actual value for antiquity, 1.38\u00b0), although there is some minor dispute about whether he was. In ancient China, the Jin dynasty scholar-official (fl.) made a similar discovery centuries later, noting that the position of the Sun during the winter solstice had drifted roughly one degree over the course of fifty years relative to the position of the stars. The precession of Earth's axis was later explained by Newtonian physics. Being an oblate spheroid, Earth has a non-spherical shape, bulging outward at the equator. The gravitational tidal forces of the Moon and Sun apply torque to the equator, attempting to pull the equatorial bulge into the plane of the ecliptic, but instead causing it to precess. The torque exerted by the planets, particularly Jupiter, also plays a role.\nApsidal precession.\nThe orbits of planets around the Sun do not really follow an identical ellipse each time, but actually trace out a flower-petal shape because the major axis of each planet's elliptical orbit also precesses within its orbital plane, partly in response to perturbations in the form of the changing gravitational forces exerted by other planets. This is called perihelion precession or apsidal precession.\nIn the adjunct image, Earth's apsidal precession is illustrated. As the Earth travels around the Sun, its elliptical orbit rotates gradually over time. The eccentricity of its ellipse and the precession rate of its orbit are exaggerated for visualization. Most orbits in the Solar System have a much smaller eccentricity and precess at a much slower rate, making them nearly circular and nearly stationary.\nDiscrepancies between the observed perihelion precession rate of the planet Mercury and that predicted by classical mechanics were prominent among the forms of experimental evidence leading to the acceptance of Einstein's Theory of Relativity (in particular, his General Theory of Relativity), which accurately predicted the anomalies. Deviating from Newton's law, Einstein's theory of gravitation predicts an extra term of , which accurately gives the observed excess turning rate of percentury.\nNodal precession.\nOrbital nodes also precess over time.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24717", "revid": "39032753", "url": "https://en.wikipedia.org/wiki?curid=24717", "title": "Punjab", "text": "Geographical region in South Asia\nPunjab ( ; , ) is a geographical, ethnolinguistic, and historical region in South Asia, located in its northwestern part, comprising areas of modern-day Pakistan and northwestern India. It is primarily inhabited by the Punjabi people. Lahore is its largest city and historic capital, with other major cities including Faisalabad, Rawalpindi, Gujranwala, Multan, Sialkot, Sargodha, and Bahawalpur in Pakistan; alongside Ludhiana, Amritsar, Chandigarh, Jalandhar, Patiala, Mohali, Bathinda, Firozpur, and Fazilka in India.\nPunjab grew out of the settlements along the five rivers, which served as an important route to the Near East as early as the ancient Indus Valley civilization, dating back to \u00a0BCE, followed by migrations of the Indo-Aryan peoples. Agriculture has been the chief economic feature of the Punjab and formed the foundation of Punjabi culture. The Punjab emerged as an important agricultural region, especially following the Green Revolution during the mid-1960s to the mid-1970s, and has been described as the \"breadbasket of both India and Pakistan.\"\nPunjab's history is a tapestry of conflict, marked by the rise of indigenous dynasties and empires. Following Alexander the Great's invasion in the 4th century BCE, Chandragupta Maurya allied with Punjabi republics to establish the Maurya Empire. Successive reigns of the Indo-Greek Kingdom, Kushan Empire, and Indo-Scythians followed, but were ultimately defeated by Eastern Punjab Janapadas such as the Yaudheya, Trigarta Kingdom, Audumbaras, Arjunayanas, and Kuninda Kingdom. In the 5th and 6th centuries CE, Punjab faced devastating Hunnic invasions, yet the Vardhana dynasty emerged triumphant, ruling over Northern India. The 8th century CE witnessed the Hindu Shahis rise, known for defeating the Persianate Saffarid dynasty and the Samanid Empire. Concurrently, the Tomara dynasty and Katoch Dynasty controlled eastern Punjab, resisting Ghaznavid invasions. Islam took hold in Western Punjab under Ghaznavid rule. The Delhi Sultanate then succeeded the Ghaznavids in which the Tughlaq dynasty and Sayyid dynasty Sultans are described as Punjabi origin. The 15th century saw the emergence of the Langah Sultanate in south Punjab, acclaimed for its victory over the Lodi dynasty. After the Mughal Empire's decline in the 18th century, Punjab experienced a period of anarchy. 12 Sikh Misls along with Muslim Chattha, Sial, Tarar, Chisti and Gakhar States fought for political acedency. In 1799 CE, the Sikh Empire established its rule, undertaking conquests into the Kashmir- and Durrani Empire-held territories, shaping the diverse and complex history of Punjab.\nThe boundaries of the region are ill-defined and focus on historical accounts and thus the geographical definition of the term \"Punjab\" has changed over time. In the 16th century Mughal Empire the Punjab region was divided into three, with the Lahore Subah in the west, the Delhi Subah in the east and the Multan Subah in the south. Under the British Raj until the Partition of India in 1947, the Punjab Province encompassed the present Indian states and union territories of Punjab, Haryana, Himachal Pradesh, Chandigarh, and Delhi, and the Pakistani regions of Punjab, and Islamabad Capital Territory.\nThe predominant ethnolinguistic group of the Punjab region are the Punjabi people, who speak the Indo-Aryan Punjabi language. Punjabi Muslims are the majority in West Punjab (Pakistan), while Punjabi Sikhs are the majority in East Punjab (India). Other religious groups include Hinduism, Christianity, Jainism, Zoroastrianism, Buddhism, and Ravidassia.\nEtymology.\nThe name Punjab is of Persian origin, with its two parts ( and ) being cognates of the Sanskrit words and , of the same meaning. The word \"pa\u00f1j\u0101b\" is thus calque of Indo-Aryan \"pa\u00f1ca-\u00e1p\" and means \"The Land of Five Waters\", referring to the rivers Jhelum, Chenab, Ravi, Sutlej, and Beas. All are tributaries of the Indus River, the Sutlej being the largest. References to a land of five rivers may be found in the \"Mahabharata\", in which one of the regions is named as \"Panchanada\" (). Earlier, the Punjab was known as Sapta Sindhu in the Rigveda or \"Hapta Hendu\" in Avesta, translating into \"The Land of Seven Rivers\", with the other two being Indus and Kabul. The ancient Greeks referred to the region as \"Pentapotam\u00eda\" (), which has the same meaning as that of Punjab.\nHistory.\nAncient period.\nThe Punjab region is noted as the site of one of the earliest urban societies, the Indus Valley Civilization which flourished from about \u00a0BCE and declined rapidly 1,000 years later, following the Indo-Aryan migrations that overran the region in waves between \u00a0BCE and \u00a0BCE. Frequent intertribal wars stimulated the growth of larger groupings ruled by chieftains and kings, who ruled local kingdoms known as Mahajanapadas. The rise of kingdoms and dynasties in the Punjab is chronicled in the ancient Hindu epics, particularly the Mahabharata. The epic battles described in the \"Mahabharata\" are chronicled as being fought in what is now the state of Haryana and historic Punjab. The Gandharas, Kambojas, Trigartas, Andhra, Pauravas, Bahlikas (Bactrian settlers of the Punjab), Yaudheyas, and others sided with the Kauravas in the great battle fought at Kurukshetra. According to Fauja Singh and L.M. Joshi: \"There is no doubt that the Kambojas, Daradas, Kaikayas, Andhra, Pauravas, Yaudheyas, Malavas, Saindhavas, and Kurus had jointly contributed to the heroic tradition and composite culture of ancient Punjab.\"\nInvasions of Alexander the Great (c.\u00a04th century BCE).\nThe earliest known notable local king of this region was known as King Porus, who fought the famous Battle of the Hydaspes against Alexander the Great. His kingdom spanned between rivers \"Hydaspes\" (Jhelum) and \"Acesines\" (Chenab); Strabo had held the territory to contain almost 300 cities. He (alongside Abisares) had a hostile relationship with the Kingdom of Taxila which was ruled by his extended family. When the armies of Alexander crossed the Indus in its eastward migration, probably in Udabhandapura, he was greeted by the ruler of Taxila, Omphis. Omphis had hoped to force both Porus and Abisares into submission leveraging the might of Alexander's forces and diplomatic missions were mounted, but while Abisares accepted the submission, Porus refused. This led Alexander to seek for a face-off with Porus. Thus began the Battle of the Hydaspes in 326 BCE; the exact site remains unknown. The battle is thought to be resulted in a decisive Greek victory; however, A. B. Bosworth warns against an uncritical reading of Greek sources that were exaggerated.\nAlexander later founded two cities\u2014\"Nicaea\" at the site of victory and \"Bucephalous\" at the battle-ground, in memory of his horse, who died soon after the battle. Later, tetradrachms would be minted depicting Alexander on horseback, armed with a \"sarissa\" and attacking a pair of Indians on an elephant. Porus refused to surrender and wandered about atop an elephant, until he was wounded and his force routed. When asked by Alexander how he wished to be treated, Porus replied \"Treat me as a king would treat another king\". Despite the apparently one-sided results, Alexander was impressed by Porus and chose to not depose him. Not only was his territory reinstated but also expanded with Alexander's forces annexing the territories of Glausaes, who ruled to the northeast of Porus' kingdom.\nAfter Alexander's death in \u00a0BCE, Perdiccas became the regent of his empire, and after Perdiccas's murder in \u00a0BCE, Antipater became the new regent. According to Diodorus, Antipater recognized Porus's authority over the territories along the Indus River. However, Eudemus, who had served as Alexander's satrap in the Punjab region, treacherously killed Porus.\nMauryan Empire (c. 320\u2013180 BCE).\nChandragupta Maurya, with the aid of Kautilya, had established his empire around \u00a0BCE. The early life of Chandragupta Maurya is not clear. Kautilya enrolled the young Chandragupta in the university at Taxila to educate him in the arts, sciences, logic, mathematics, warfare, and administration. Megasthenes' account, as it has survived in Greek texts that quote him, states that Alexander the Great and Chandragupta met, which if true would mean his rule started earlier than \u00a0BCE. As Alexander never crossed the Beas River, so his territory probably lay in the Punjab region. With the help of the small Janapadas of Punjab, he had gone on to conquer much of the North West Indian subcontinent. He then defeated the Nanda rulers in Pataliputra to capture the throne. Chandragupta Maurya fought Alexander's successor in the east, Seleucus when the latter invaded. In a peace treaty, Seleucus ceded all territories west of the Indus and offered a marriage, including a portion of Bactria, while Chandragupta granted Seleucus 500 elephants. The chief of the Mauryan military was also always a Yaudheyan warrior according to the Bijaygadh Pillar inscription, which states that the Yaudheyas elected their own chief who also served as the general for the Mauryans. The Mauryan military was also made up vastly of men from the Punjab Janapadas.\nChandragupta's rule was very well organised. The Mauryans had an autocratic and centralised administration system, aided by a council of ministers, and also a well-established espionage system. Much of Chandragupta's success is attributed to Chanakya, the author of the \"Arthashastra.\" Much of the Mauryan rule had a strong bureaucracy that had regulated tax collection, trade and commerce, industrial activities, mining, statistics and data, maintenance of public places, and upkeep of temples.\nMedieval period.\nHindu Shahis (c. 820\u20131022 CE).\nIn the 9th century, the Hindu Shahi dynasty originating from the region of Oddiyana, replaced the Taank kingdom, ruling Western Punjab along with eastern Afghanistan. The tribe of the Gakhars/Khokhars, formed a large part of the Hindu Shahi army according to the Persian historian Firishta. The most notable rulers of the empire were Lalliya, Bhimadeva and Jayapala who were accredited for military victories.\nLalliya had reclaimed the territory at and around Kabul between 879 and 901 CE after it had been lost under his predecessor to the Saffarid dynasty. He was described as a fearsome Shahi. Two of his ministers reconstructed by Rahman as Toramana and Asata are said to of have taken advantage of Amr al-Layth's preoccupation with rebellions in Khorasan, by successfully raiding Ghazna around 900 CE.\nAfter a defeat in Eastern Afghanistan suffered on the Shahi ally Lawik, Bhimadeva mounted a combined attack around 963 CE. Abu Ishaq Ibrahim was expelled from Ghazna and Shahi-Lawik strongholds were restored in Kabul and adjacent areas. This victory appears to have been commemorated in the Hund Slab Inscription (HSI).\nTurkic rule (c. 1030\u20131320 CE).\nThe Turkic Ghaznavids in the tenth century overthrew the Hindu Shahis and consequently ruled for 157 years in Western Punjab, gradually declining as a power until the Ghurid conquest of Lahore by Muhammad of Ghor in 1186, deposing the last Ghaznavid ruler Khusrau Malik. Following the death of Muhammad of Ghor in 1206 by Punjabi assassins near the Jhelum river, the Ghurid state fragmented and was replaced in northern India by the Delhi Sultanate.\nTughlaq dynasty (c. 1320\u20131410 CE).\nThe Tughlaq dynasty's reign formally started in 1320 in Delhi when Ghazi Malik assumed the throne under the title of Ghiyath al-Din Tughluq after defeating Khusrau Khan at the Battle of Lahrawat.\nDuring Ghazi Malik's reign, in 1321 he sent his eldest son Jauna Khan, later known as Muhammad bin Tughlaq, to Deogir to plunder the Hindu kingdoms of Arangal and Tilang (now part of Telangana). His first attempt was a failure. Four months later, Ghiyasuddin Tughlaq sent large army reinforcements for his son asking him to attempt plundering Arangal and Tilang again. This time Jauna Khan succeeded and Arangal fell, it was renamed to Sultanpur, and all plundered wealth, state treasury and captives were transferred from the captured kingdom to the Delhi Sultanate.The Muslim aristocracy in Lukhnauti (Bengal) invited Ghiyasuddin Tughlaq to extend his coup and expand eastwards into Bengal by attacking Shamsuddin Firoz Shah, which he did over 1324\u20131325 CE, after placing Delhi under control of his son Ulugh Khan, and then leading his army to Lukhnauti. Ghiyasuddin Tughlaq succeeded in this campaign.\nAfter his father's death in 1325 CE, Muhammad bin Tughlaq assumed power and his rule saw the empire expand to most of the Indian subcontinent, its peak in terms of geographical reach. He attacked and plundered Malwa, Gujarat, Lakhnauti, Chittagong, Mithila and many other regions in India. His distant campaigns were expensive, although each raid and attack on non-Muslim kingdoms brought new looted wealth and ransom payments from captured people. The extended empire was difficult to retain, and rebellions became commonplace all over the Indian subcontinent. Muhammad bin Tughlaq died in March 1351 while trying to chase and punish people for rebellion and their refusal to pay taxes in Sindh and Gujarat.\nAfter Muhammad bin Tughlaq's death, the Tughlaq empire was in a state of disarray with many regions assuming independence; it was at this point that Firuz Shah Tughlaq, Ghazi Malik's nephew, took reign. His father's name was Rajab (the younger brother of Ghazi Malik) who had the title \"Sipahsalar\". His mother Naila was a Punjabi Bhatti princess (daughter of Rana Mal) from Dipalpur and Abohar according to the historian William Crooke. The southern states had drifted away from the Sultanate and there were rebellions in Gujarat and Sindh, while \"Bengal asserted its independence.\" He led expeditions against Bengal in 1353 and 1358. He captured Cuttack, desecrated the Jagannath Temple, Puri, and forced Raja Gajpati of Jajnagar in Orissa to pay tribute. He also laid siege to the Kangra Fort and forced Nagarkot to pay tribute. During this time, Tatar Khan of Greater Khorasan attacked Punjab, but he was defeated and his face slashed by the sword given by Feroz Shah Tughlaq to Raja Kailas Pal who ruled the Nagarkot region in Punjab.\nSayyid dynasty (c. 1410\u20131450 CE).\nKhizr Khan established the Sayyid dynasty, the fourth dynasty of the Delhi Sultanate after the fall of the Tughlaqs.\nFollowing Timur's 1398 sack of Delhi, he appointed Khizr Khan as deputy of Multan (Punjab). He held Lahore, Dipalpur, Multan and Upper Sindh. Khizr Khan captured Delhi on 28 May 1414 thereby establishing the Sayyid dynasty. Khizr Khan did not take up the title of sultan, but continued the fiction of his allegiance to Timur as \"Rayat-i-Ala\"(vassal) of the Timurids - initially that of Timur, and later his son Shah Rukh. After the accession of Khizr Khan, the Punjab, Uttar Pradesh and Sindh were reunited under the Delhi Sultanate, where he spent his time subduing rebellions. Punjab was the powerbase of Khizr Khan and his successors as the bulk of the Delhi army during their reigns came from Multan and Dipalpur.\nKhizr Khan was succeeded by his son Mubarak Shah after his death on 20 May 1421. Mubarak Shah referred to himself as \"Muizz-ud-Din Mubarak Shah\" on his coins, removing the Timurid name with the name of the Caliph, and declared himself a Shah. He defeated the advancing Hoshang Shah Ghori, ruler of Malwa Sultanate and forced him to pay heavy tribute early in his reign. Mubarak Shah also put down the rebellion of Jasrath Khokhar and managed to fend off multiple invasions by the Timurids of Kabul.\nThe last ruler of the Sayyids, Ala-ud-Din, voluntarily abdicated the throne of the Delhi Sultanate in favour of Bahlul Khan Lodi on 19 April 1451, and left for Badaun, where he died in 1478.\nLangah Sultanate (c. 1450\u20131530 CE).\nIn 1445, Sultan Qutbudin, chief of \"Langah\" (a Jat Zamindar tribe), established the Langah Sultanate in Multan after the fall of the Sayyid dynasty. Husseyn Langah I (reigned 1456\u20131502) was the second ruler of Langah Sultanate. He undertook military campaigns in Punjab and captured Chiniot and Shorkot from the Lodis. Shah Husayn successfully repulsed attempted invasion by the Lodis led by Tatar Khan and Barbak Shah, as well as his daughter Zeerak Rumman.\nEarly modern period.\nMughal Empire (c. 1530\u20131700 CE).\nThe Mughals came to power in the early 16th century and gradually expanded to control all of the Punjab from their capital at Lahore. During the Mughal era, Saadullah Khan, born into a family of Punjabi agriculturalists belonging to the Thaheem tribe from Chiniot remained grand vizier (or Prime Minister) of the Mughal Empire in the period 1645\u20131656. Other prominent Muslims from Punjab who rose to nobility during the Mughal Era include Wazir Khan, Adina Beg Arain, and Shahbaz Khan Kamboh. The Mughal Empire ruled the region until it was severely weakened in the eighteenth century. As Mughal power weakened, Afghan rulers took control of the region. Contested by the Marathas and Afghans, the region was the center of the growing influence of the misls, who expanded and established the Sikh Confederacy as the Mughals and Afghans weakened, ultimately ruling the Punjab, Khyber Pakhtunkhwa, and territories north into the Himalayas.\nPakpattan state (c. 1700\u20131730 CE).\nFollowing the disintegration of the Mughal Empire, the shrine's \"D\u012bw\u0101n\" was able to forge a political independent state centered on Pakpattan. In 1757, \"D\u012bw\u0101n\" 'Abd as-Sub\u1e25\u0101n gathered an army of his Jat mur\u012bds, attacked the Raja of Bikaner, and thereby expanded the shrine's territorial holdings for the first time east of the Sutlej. Around 1776, the \"D\u012bw\u0101n\", supported mainly by his Wattu mur\u012bds, successfully repelled an attack by the Sikh Nakai Misl, resulting in the death of the Nakai leader, Heera Singh Sandhu.\nSial dynasty (c. 1730\u20131799 CE).\nThe Sial dynasty was established by the 13 Sial Chief Nawab Walidad Khan Sial in 1723. He gradually gained control of the lower Rachna doab, including the cities of Chiniot, Pindi Bhattian, Jhang and Mankera.\nNext chief, Inayatullah Khan (r.\u20091747\u2013 1787) was a successful general who won 22 battles against Bhangi Misl and the Multan chiefs.\nThe Sikh Empire invaded Jhang multiple times from 1801 to 1816 and annexed by the dynasty; Ahmad Khan Sial was awarded a Jagir by Ranjit Singh.\nModern period.\nSikh Empire (c. 1799\u20131849 CE).\nIn the 19th century, Maharajah Ranjit Singh established the Sikh Empire based in the Punjab. The empire existed from 1799, when Ranjit Singh captured Lahore, to 1849, when it was defeated and conquered in the Second Anglo-Sikh War. It was forged on the foundations of the Khalsa from a collection of autonomous Sikh \"misls\". At its peak in the 19th century, the Empire extended from the Khyber Pass in the west to western Tibet in the east, and from Mithankot in the south to Kashmir in the north. It was divided into four provinces: Lahore, in Punjab, which became the Sikh capital; Multan, also in Punjab; Peshawar; and Kashmir from 1799 to 1849. Religiously diverse, with an estimated population of 3.5\u00a0million in 1831 (making it the 19th most populous country at the time), it was the last major region of the Indian subcontinent to be annexed by the British Empire.\nBritish Punjab (c. 1849\u20131947 CE).\nThe Sikh Empire ruled the Punjab until the British annexed it in 1849 following the First and Second Anglo-Sikh Wars. Most of the Punjabi homeland formed a province of British India, though a number of small princely states retained local rulers who recognized British authority. The Punjab with its rich farmlands became one of the most important colonial assets. Lahore was a noted center of learning and culture, and Rawalpindi became an important military installation. Most Punjabis supported the British during World War I, providing men and resources to the war effort even though the Punjab remained a source of anti colonial activities. Disturbances in the region increased as the war continued. At the end of the war, high casualty rates, heavy taxation, inflation, and a widespread influenza epidemic disrupted Punjabi society. In 1919, Colonel Reginald Dyer ordered troops under command to fire on a crowd of demonstrators, mostly Sikhs in Amritsar. The Jallianwala massacre fueled the Indian independence movement. Nationalists declared the independence of India from Lahore in 1930 but were quickly suppressed. When the Second World War broke out, nationalism in British India had already divided into religious movements. Many Sikhs and other minorities supported the Hindus, who promised a secular multicultural and multireligious society, and Muslim leaders in Lahore passed a resolution to work for a Muslim Pakistan, making the Punjab region a center of growing conflict between Indian and Pakistani nationalists. At the end of the war, the British granted separate independence to India and Pakistan, setting off massive communal violence as Muslims fled to Pakistan and Hindu and Sikh Punjabis fled east to India.\nThe British Raj had major political, cultural, philosophical, and literary consequences in the Punjab, including the establishment of a new system of education. During the independence movement, many Punjabis played a significant role, including Madan Lal Dhingra, Sukhdev Thapar, Ajit Singh Sandhu, Bhagat Singh, Udham Singh, Kartar Singh Sarabha, Bhai Parmanand, Choudhry Rahmat Ali, and Lala Lajpat Rai. At the time of partition in 1947, the province was split into East and West Punjab. East Punjab (48%) became part of India, while West Punjab (52%) became part of Pakistan. The Punjab bore the brunt of the civil unrest following partition, with casualties estimated to be in the millions.\nAnother major consequence of partition was the sudden shift towards religious homogeneity occurred in all districts across Punjab owing to the new international border that cut through the province. This rapid demographic shift was primarily due to wide scale migration but also caused by large-scale religious cleansing riots which were witnessed across the region at the time. According to historical demographer Tim Dyson, in the eastern regions of Punjab that ultimately became Indian Punjab following independence, districts that were 66% Hindu in 1941 became 80% Hindu in 1951; those that were 20% Sikh became 50% Sikh in 1951. Conversely, in the western regions of Punjab that ultimately became Pakistani Punjab, all districts became almost exclusively Muslim by 1951.\nGeography.\nThe geographical definition of the term \"Punjab\" has changed over time. In the 16th century Mughal Empire it referred to a relatively smaller area between the Indus and the Sutlej rivers.\nSikh Empire.\nAt its height in the first half of the 19th century, the Sikh Empire spanned a total of over .\nThe Punjab was a region straddling India and the Afghan Durrani Empire. The following modern-day political divisions made up the historical Punjab region during the Sikh Empire:\nAfter Ranjit Singh's death in 1839, the empire was severely weakened by internal divisions and political mismanagement. This opportunity was used by the East India Company to launch the First and Second Anglo-Sikh Wars. The country was finally annexed and dissolved at the end of the Second Anglo-Sikh War in 1849 into separate princely states and the province of Punjab. Eventually, a Lieutenant Governorship was formed in Lahore as a direct representative of the Crown.\nPunjab (British India).\nIn British India, until the Partition of India in 1947, the Punjab Province was geographically a triangular tract of country of which the Indus River and its tributary the Sutlej formed the two sides up to their confluence, the base of the triangle in the north being the Lower Himalayan Range between those two rivers. Moreover, the province as constituted under British rule also included a large tract outside these boundaries. Along the northern border, Himalayan ranges divided it from Kashmir and Tibet. On the west it was separated from the North-West Frontier Province by the Indus, until it reached the border of Dera Ghazi Khan District, which was divided from Baluchistan by the Sulaiman Range. To the south lay Sindh and Rajputana, while on the east the rivers Jumna and Tons separated it from the United Provinces. In total Punjab had an area of approximately 357 000\u00a0km square about the same size as modern day Germany, being one of the largest provinces of the British Raj.\nIt encompassed the present day Indian states of Punjab, Haryana, Chandigarh, Delhi, and some parts of Himachal Pradesh which were merged with Punjab by the British for administrative purposes (but excluding the former princely states which were later combined into the Patiala and East Punjab States Union) and the Pakistani regions of the Punjab, Islamabad Capital Territory and Khyber Pakhtunkhwa.\nIn 1901 the frontier districts beyond the Indus were separated from Punjab and made into a new province: the North-West Frontier Province. Subsequently, Punjab was divided into four natural geographical divisions by colonial officials on the decadal census data:\nPartition of British Punjab.\nThe struggle for Indian independence witnessed competing and conflicting interests in the Punjab. The landed elites of the Muslim, Hindu and Sikh communities had loyally collaborated with the British since annexation, supported the Unionist Party and were hostile to the Congress party\u2013led independence movement. Amongst the peasantry and urban middle classes, the Hindus were the most active National Congress supporters, the Sikhs flocked to the Akali movement whilst the Muslims eventually supported the Muslim League.\nSince the partition of the sub-continent had been decided, special meetings of the Western and Eastern Section of the Legislative Assembly were held on 23 June 1947 to decide whether or not the Province of the Punjab be partitioned. After voting on both sides, partition was decided and the existing Punjab Legislative Assembly was also divided into West Punjab Legislative Assembly and the East Punjab Legislative Assembly. This last Assembly before independence, held its last sitting on 4 July 1947.\nMajor cities.\nHistorically, Lahore has been the capital of the Punjab region and continues to be the most populous city in the region, with a population of 11 million for the city proper. Faisalabad is the 2nd most populous city and largest industrial hub in this region. Other major cities are Rawalpindi, Gujranwala, Multan, Ludhiana, Amritsar, Jalandhar, and Chandigarh are the other cities in Punjab with a city-proper population of over a million.\nClimate.\nThe climate has significant impact on the economy of Punjab, particularly for agriculture in the region. Climate is not uniform over the whole region, as the areas adjacent to the Himalayas generally receive heavier rainfall than those at a distance. The K\u00f6ppen climate classification generally classifies Punjab as having either a monsoon-influenced humid subtropical climate (K\u00f6ppen: Cwa) or a hot semi-arid climate (K\u00f6ppen: BSh).\nThere are three main seasons and two transitional periods. During summer, from mid-April to the end of June, the temperature may reach . The monsoon season, from July to September, is a period of heavy rainfall, providing water for crops in addition to the supply from canals and irrigation systems. The transitional period after the monsoon season is cool and mild, leading to the winter season, when the temperature in January falls to at night and by day. During the transitional period from winter to summer, sudden hailstorms and heavy showers may occur, causing damage to crops.\nDemographics.\nLanguages.\nThe major language is Punjabi, which is written in India with the Gurmukhi script, and in Pakistan using the Shahmukhi script. The Punjabi language has official status and is widely used in education and administration in Indian Punjab, whereas in Pakistani Punjab these roles are instead fulfilled by the Urdu language and Punjabi is seen as a vernacular language\nSeveral languages closely related to Punjabi are spoken in the various parts of the region. Dogri, Kangri, and other western Pahari dialects are spoken in the north-central and northeastern parts of the region, while Bagri is spoken in south-central and southeastern sections. Meanwhile, Saraiki is generally spoken across a wide belt covering the southwest, while in the northwest there are large pockets containing speakers of Hindko and Pahari-Pothwari.\nReligions.\nBackground.\nThe Punjab is predominantly Muslim though Hinduism is the oldest of the religions practised by Punjabi people, however, the term \"Hindu\" was also applied over a vast territory with much regional diversity. The historical Vedic religion constituted the religious ideas and practices in the Punjab during the Vedic period (\u00a0BCE), centered primarily in the worship of Indra. The bulk of the Rigveda was composed in the Punjab region between circa 1500 and 1200 BCE, while later Vedic scriptures were composed more eastwards, between the Yamuna and Ganges rivers. An ancient Indian law book called the Manusmriti, developed by Brahmin Hindu priests, shaped Punjabi religious life from 200 BCE onward.\nLater, the spread of Buddhisim and Jainism in the Indian subcontinent saw the growth of Buddhism and Jainism in the Punjab. Islam was introduced via southern Punjab in the 8th century, becoming the majority by the 16th century, via local conversion. There was a small Jain community left in Punjab by the 16th century, while the Buddhist community had largely disappeared by the turn of the 10th century. The region became predominantly Muslim due to missionary Sufi saints whose dargahs dot the landscape of the Punjab region.\nThe rise of Sikhism in the 1700s saw some Punjabis, both Hindu and Muslim, accepting the new Sikh faith. A number of Punjabis during the colonial period of India became Christians, with all of these religions characterizing the religious diversity now found in the Punjab region.\nColonial era.\nA number of Punjabis during the colonial period of India became Christians, with all of these religions characterizing the religious diversity now found in the Punjab region. Additionally during the colonial era, the practice of religious syncretism among Punjabi Muslims and Punjabi Hindus was noted and documented by officials in census reports:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Excerpts from the Census of India (Punjab Province)\u2014\u200a\nThe \"Indo\u2212Gangetic Plain West geographical division\" included Hisar district, Loharu State, Rohtak district, Dujana State, Gurgaon district, Pataudi State, Delhi, Karnal district, Jalandhar district, Kapurthala State, Ludhiana district, Malerkotla State, Firozpur district, Faridkot State, Patiala State, Jind State, Nabha State, Lahore District, Amritsar district, Gujranwala District, and Sheikhupura District.\nThe \"Himalayan geographical division\" included Sirmoor State, Simla District, Simla Hill States, Bilaspur State, Kangra district, Mandi State, Suket State, and Chamba State.\nThe \"Sub\u2212Himalayan geographical division\" included Ambala district, Kalsia State, Hoshiarpur district, Gurdaspur district, Sialkot District, Gujrat District, Jhelum District, Rawalpindi District, and Attock District.\nThe \"North\u2212West Dry Area geographical division\" included Montgomery District, Shahpur District, Mianwali District, Lyallpur District, Jhang District, Multan District, Bahawalpur State, Muzaffargarh District, Dera Ghazi Khan District, and the Biloch Trans\u2013Frontier Tract.\nPost-partition.\nIn the present-day, the vast majority of Pakistani Punjabis are Sunni Muslim by faith, but also include significant minority faiths, such as Shia Muslims, Ahmadi Muslims, Hindus, Sikhs and Christians.\nSikhism, founded by Guru Nanak is the main religion practised in the post-1966 Indian Punjab state. About 57.7% of the population of Punjab state is Sikh, 38.5% is Hindu, with the remaining population including Muslims, Christians, and Jains. Punjab state contains the holy Sikh cities of Amritsar, Anandpur Sahib, Tarn Taran Sahib, Fatehgarh Sahib and Chamkaur Sahib.\nThe Punjab was home to several Sufi saints, and Sufism is well established in the region. Also, Kirpal Singh revered the Sikh Gurus as saints.\nTribes.\nThe Punjab region is diverse. Historic census reports taken in the colonial era details the main castes are represented, alongside numerous subcastes and tribes (also known as \"J\u0101ti\" or \"Bar\u0101dar\u012b\"), formed parts of the various ethnic groups in the region, contemporarily known as Punjabis, Haryanvis, Hindkowans, Saraikis, Dogras, Paharis, and more.\nEconomy.\nThe historical region of Punjab produces a relatively high proportion of the food output from India and Pakistan. The region has been used for extensive wheat farming. In addition, rice, cotton, sugarcane, fruit, and vegetables are also grown.\nThe agricultural output of the Punjab region in Pakistan contributes significantly to Pakistan's GDP. Both Indian and Pakistani Punjab is considered to have the best infrastructure of their respective countries. The Indian state of Punjab is currently the 16th richest state or the eighth richest large state of India. Pakistani Punjab produces 68% of Pakistan's foodgrain production. Its share of Pakistan's GDP has historically ranged from 51.8% to 54.7%. and has the highest per capita of any province.\nCalled \"The Granary of India\" or \"The Bread Basket of India\", Indian Punjab produces 1% of the world's rice, 2% of its wheat, and 2% of its cotton. In 2001, it was recorded that farmers made up 39% of Indian Punjab's workforce. In the Punjab region of Pakistan, 42.3% of the labour force is engaged in the agriculture sector.\nAlternatively, Punjab is also adding to the economy with the increase in employment of Punjab youth in the private sector. Government schemes such as 'Ghar Ghar Rozgar and Karobar Mission' have brought enhanced employability in the private sector. As of \u00a02019[ [update]], more than 32,000 youths have been placed in different jobs and 12,000 have been skill-trained.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24718", "revid": "49863756", "url": "https://en.wikipedia.org/wiki?curid=24718", "title": "Ring system", "text": "Ring of cosmic dust orbiting an astronomical object\nA ring system is a disc or torus orbiting an astronomical object that is composed of numerous solid bodies such as dust particles, meteoroids, minor planets, moonlets, or stellar objects.\nRing systems are best known as planetary rings, common components of satellite systems around giant planets such as the rings of Saturn, or circumplanetary disks. But they can also be galactic rings and circumstellar discs, belts of minor planets, such as the asteroid belt or Kuiper belt, or rings of interplanetary dust, such as around the Sun at distances of Mercury, Venus, and Earth, in mean motion resonance with these planets. Evidence suggests that ring systems may also be found around other types of astronomical objects, including moons and brown dwarfs.\nIn the Solar System, all four giant planets (Jupiter, Saturn, Uranus, and Neptune) have ring systems. Ring systems around minor planets have also been discovered via occultations. Some studies even theorize that the Earth may have had a ring system during the mid-late Ordovician period.\nFormation.\nThere are three ways that thicker planetary rings have been proposed to have formed: from material originating from the protoplanetary disk that was within the Roche limit of the planet and thus could not coalesce to form moons, from the debris of a moon that was disrupted by a large impact, or from the debris of a moon that was disrupted by tidal stresses when it passed within the planet's Roche limit. Most rings were thought to be unstable and to dissipate over the course of tens or hundreds of millions of years, but it now appears that Saturn's rings might be quite old, dating to the early days of the Solar System.\nFainter planetary rings can form as a result of meteoroid impacts with moons orbiting around the planet or, in the case of Saturn's E-ring, the ejecta of cryovolcanic material.\nRing systems may form around centaurs when they are tidally disrupted in a close encounter (within 0.4 to 0.8 times the Roche limit) with a giant planet. For a differentiated body approaching a giant planet at an initial relative velocity of 3\u22126\u00a0km/s with an initial rotational period of 8 hours, a ring mass of 0.1%\u221210% of the centaur's mass is predicted. Ring formation from an undifferentiated body is less likely. The rings would be composed mostly or entirely of material from the parent body's icy mantle. After forming, the ring would spread laterally, leading to satellite formation from whatever portion of it spreads beyond the centaur's Roche Limit. Satellites could also form directly from the disrupted icy mantle. This formation mechanism predicts that roughly 10% of centaurs will have experienced potentially ring-forming encounters with giant planets.\nRing systems of planets.\nThe composition of planetary ring particles varies, ranging from silicates to icy dust. Larger rocks and boulders may also be present, as seen in 2007 when tidal effects from eight moonlets only a few hundred meters across were detected within Saturn's rings. The maximum size of a ring particle is determined by the specific strength of the material it is made of, its density, and the tidal force at its altitude. The tidal force is proportional to the average density inside the radius of the ring, or to the mass of the planet divided by the radius of the ring cubed. It is also inversely proportional to the square of the orbital period of the ring.\nSome planetary rings are influenced by \"shepherd moons\", small moons that orbit near the inner or outer edges of a ringlet or within gaps in the rings. The gravity of shepherd moons serves to maintain a sharply defined edge to the ring; material that drifts closer to the shepherd moon's orbit is either deflected back into the body of the ring, ejected from the system, or accreted onto the moon itself.\nIt is also predicted that Phobos, a moon of Mars, will break up and form into a planetary ring in about 50 million years. Its low orbit, with an orbital period that is shorter than a Martian day, is decaying due to tidal deceleration.\nJupiter.\nJupiter's ring system was the third to be discovered, when it was first observed by the \"Voyager 1\" probe in 1979, and was observed more thoroughly by the \"Galileo\" orbiter in the 1990s. Its four main parts are a faint thick torus known as the \"halo\"; a thin, relatively bright main ring; and two wide, faint \"gossamer rings\". The system consists mostly of dust.\nSaturn.\nSaturn's rings are the most extensive ring system of any planet in the Solar System, and thus have been known to exist for quite some time. Galileo Galilei first observed them in 1610, but they were not accurately described as a disk around Saturn until Christiaan Huygens did so in 1655. The rings are not a series of tiny ringlets as many think, but are more of a disk with varying density. They consist mostly of water ice and trace amounts of rock, and the particles range in size from micrometers to meters.\nUranus.\nUranus's ring system lies between the level of complexity of Saturn's vast system and the simpler systems around Jupiter and Neptune. They were discovered in 1977 by James L. Elliot, Edward W. Dunham, and Jessica Mink. In the time between then and 2005, observations by \"Voyager 2\" and the Hubble Space Telescope led to a total of 13 distinct rings being identified, most of which are opaque and only a few kilometers wide. They are dark and likely consist of water ice and some radiation-processed organics. The relative lack of dust is due to aerodynamic drag from the extended exosphere-corona of Uranus.\nNeptune.\nThe system around Neptune consists of five principal rings that, at their densest, are comparable to the low-density regions of Saturn's rings. However, they are faint and dusty, much more similar in structure to those of Jupiter. The very dark material that makes up the rings is likely organics processed by radiation, like in the rings of Uranus. 20 to 70 percent of the rings are dust, a relatively high proportion. Hints of the rings were seen for decades prior to their conclusive discovery by \"Voyager 2\" in 1989.\nPrehistoric ring systems.\nEarth.\nA 2024 study suggests that Earth may have had a ring system for a period of 40 million years, starting from the middle of the Ordovician period (around 466 million years ago). This ring system may have originated from a large asteroid that passed by Earth at this time and had a significant amount of debris stripped by Earth's gravitational pull, forming a ring system. Evidence for this ring comes from impact craters from the Ordovician meteor event appearing to cluster in a distinctive band around the Earth's equator at that time. The presence of this ring may have led to significant shielding of Earth from sun's rays and a severe cooling event, thus causing the Hirnantian glaciation, the coldest known period of the last 450 million years.\nRings systems of minor planets and moons.\nReports in March 2008 suggested that Saturn's moon Rhea may have its own tenuous ring system, which would make it the only moon known to have a ring system. A later study published in 2010 revealed that imaging of Rhea by the \"Cassini\" spacecraft was inconsistent with the predicted properties of the rings, suggesting that some other mechanism is responsible for the magnetic effects that had led to the ring hypothesis.\nPrior to the arrival of \"New Horizons\", some astronomers hypothesized that Pluto and Charon might have a circumbinary ring system created from dust ejected off of Pluto's small outer moons in impacts. A dust ring would have posed a considerable risk to the \"New Horizons\" spacecraft. However, this possibility was ruled out when \"New Horizons\" failed to detect any dust rings around Pluto.\nChariklo.\n10199 Chariklo, a centaur, was the first minor planet discovered to have rings. It has two rings, perhaps due to a collision that caused a chain of debris to orbit it. The rings were discovered when astronomers observed Chariklo passing in front of the star UCAC4 248-108672 on June 3, 2013 from seven locations in South America. While watching, they saw two dips in the star's apparent brightness just before and after the occultation. Because this event was observed at multiple locations, the conclusion that the dip in brightness was in fact due to rings is unanimously the leading hypothesis. The observations revealed what is likely a ring system that is about 1,000 times closer than the Moon is to Earth. In addition, astronomers suspect there could be a moon orbiting amidst the ring debris. If these rings are the leftovers of a collision as astronomers suspect, this would give fodder to the idea that moons (such as the Moon) form through collisions of smaller bits of material. Chariklo's rings have not been officially named, but the discoverers have nicknamed them Oiapoque and Chu\u00ed, after two rivers near the northern and southern ends of Brazil.\nChiron.\nA second centaur, 2060 Chiron, has a constantly evolving disk of rings. Based on stellar-occultation data that were initially interpreted as resulting from jets associated with Chiron's comet-like activity, the rings are proposed to be in radius, though their evolution does change the radius somewhat. Their changing appearance at different viewing angles can explain the long-term variation in Chiron's brightness over time. Chiron's rings are suspected to be maintained by orbiting material ejected during seasonal outbursts, as a third partial ring detected in 2018 had become a full ring by 2022, with an outburst in between in 2021.\nHaumea.\nA ring around Haumea, a dwarf planet and resonant Kuiper belt member, was revealed by a stellar occultation observed on 21 January 2017. This makes it the first trans-Neptunian object found to have a ring system. The ring has a radius of about , a width of \u2248 and an opacity of 0.5. The ring plane coincides with Haumea's equator and the orbit of its larger, outer moon Hi\u2019iaka (which has a semimajor axis of \u2248). The ring is close to the 3:1 resonance with Haumea's rotation, which is located at a radius of . It is well within Haumea's Roche limit, which would lie at a radius of about if Haumea were spherical (being nonspherical pushes the limit out farther).\nQuaoar.\nIn 2023, astronomers announced the discovery of a widely separated ring around the dwarf planet and Kuiper belt object Quaoar. Further analysis of the occultation data uncovered a second inner, fainter ring.\nBoth rings display unusual properties. The outer ring orbits at a distance of , approximately 7.5 times the radius of Quaoar and more than double the distance of its Roche limit. The inner ring orbits at a distance of , approximately 4.6 times the radius of Quaoar and also beyond its Roche limit. The outer ring appears to be inhomogeneous, containing a thin, dense section as well as a broader, more diffuse section.\nRings around exoplanets.\nBecause all giant planets of the Solar System have rings, the existence of exoplanets with rings is plausible. Although particles of ice, the material that is predominant in the rings of Saturn, can only exist around planets beyond the frost line, within this line rings consisting of rocky material can be stable in the long term. Such ring systems can be detected for planets observed by the transit method by additional reduction of the light of the central star if their opacity is sufficient. As of 2024, two candidate extrasolar ring systems have been found by this method, around HIP 41378 f and K2-33b.\nFomalhaut b was found to be large and unclearly defined when detected in 2008. This was hypothesized to either be due to a cloud of dust attracted from the dust disc of the star, or a possible ring system, though in 2020 Fomalhaut b itself was determined to very likely be an expanding debris cloud from a collision of asteroids rather than a planet. Similarly, Proxima Centauri c has been observed to be far brighter than expected for its low mass of 7 Earth masses, which may be attributed to a ring system of about 5 RJ.\nA 56-day-long sequence of dimming events in the star V1400 Centauri observed in 2007 was interpreted as a substellar object with a circumstellar disk or massive rings transiting the star. This substellar object, dubbed \"J1407b\", is most likely a free-floating brown dwarf or rogue planet several times the mass of Jupiter. The circumstellar disk or ring system of J1407b is about in radius. J1407b's transit of V1400 Centauri revealed gaps and density variations within its disk or ring system, which has been interpreted as hints of exomoons or exoplanets forming around J1407b."}
{"id": "24719", "revid": "753121484", "url": "https://en.wikipedia.org/wiki?curid=24719", "title": "Pornografic film", "text": ""}
{"id": "24721", "revid": "20155832", "url": "https://en.wikipedia.org/wiki?curid=24721", "title": "Phoebe", "text": "Phoebe or Ph\u0153be may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "24722", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=24722", "title": "P-code machine", "text": "Programming virtual machine\nIn computer programming, a P-code machine (portable code machine) is a virtual machine designed to execute \"P-code,\" the assembly language or machine code of a hypothetical central processing unit (CPU). The term \"P-code machine\" is applied generically to all such machines (such as the Java virtual machine (JVM) and MATLAB pre-compiled code), as well as specific implementations using those machines. One of the most notable uses of P-Code machines is the P-Machine of the Pascal-P system. The developers of the UCSD Pascal implementation within this system construed the \"P\" in \"P-code\" to mean \"pseudo\" more often than \"portable;\" they adopted a unique label for \"pseudo-code\" meaning instructions for a pseudo-machine.\nAlthough the concept was first implemented circa 1966 as O-code for the Basic Combined Programming Language (BCPL) and P code for the language Euler, the \"term\" P-code first appeared in the early 1970s. Two early compilers generating P-code were the Pascal-P compiler in 1973, by Kesav V. Nori, Urs Ammann, Kathleen Jensen, Hans-Heinrich N\u00e4geli, and Christian Jacobi, and the Pascal-S compiler in 1975, by Niklaus Wirth.\nPrograms that have been translated to P-code can either be interpreted by a software program that emulates the behaviour of the hypothetical CPU, or translated into the machine code of the CPU on which the program is to run and then executed. If there is sufficient commercial interest, a hardware implementation of the CPU specification may be built (e.g., the Pascal MicroEngine or a version of a Java processor).\nP-code versus machine code.\nWhile a typical compiler model is aimed at translating a program code into machine code, the idea of a P-code machine follows a two-stage approach involving translation into P-code and execution by interpreting or just-in-time compilation (JIT) through the P-code machine.\nThis separation makes it possible to detach the development of a P-code interpreter from the underlying machine code compiler, which has to consider machine-dependent behaviour in generating its bytecode. This way a P-code interpreter can also be implemented quicker, and the ability to interpret the code at runtime allows for additional run-time checks which might not be similarly available in native code. Further, as P-code is based on an ideal virtual machine, a P-code program can often be smaller than the same program translated to machine code. Conversely, the two-step interpretation of a P-code-based program leads to a slower execution speed, though this can sometimes be addressed with just-in-time compilation, and its simpler structure is easier to reverse-engineer than native code.\nImplementations of P-code.\nIn the early 1980s, at least two operating systems achieved machine independence through extensive use of P-code . The Business Operating System (BOS) was a cross-platform operating system designed to run P-code programs exclusively. The UCSD p-System, developed at The University of California, San Diego, was a self-compiling and self-hosting operating system based on P-code optimized for generation by the Pascal language.\nIn the 1990s, translation into p-code became a popular strategy for implementations of languages such as Python, Microsoft P-Code in Visual Basic and Java bytecode in Java.\nThe language Go uses a generic, portable assembly as a form of p-code, implemented by Ken Thompson as an extension of the work on Plan 9 from Bell Labs. Unlike Common Language Runtime (CLR) bytecode or JVM bytecode, there is no stable specification and the Go build tools do not emit a bytecode format to be used at a later time. The Go assembler uses the generic assembly language as an intermediate representation and the Go executables are machine-specific statically linked binaries.\nUCSD P-Machine.\nArchitecture.\nLike many other P-code machines, the UCSD P-Machine is a stack machine, which means that most instructions take their operands from a stack, and place results back on the stack. Thus, the codice_1 instruction replaces the two topmost elements of the stack with their sum. A few instructions take an immediate argument. Like Pascal, the P-code is strongly typed, supporting Boolean (b), character (c), integer (i), real (r), set (s), and pointer (a) data types natively.\nSome simple instructions:\n Insn. Stack Stack Description\n before after\n adi i1 i2 i1+i2 add two integers\n adr r1 r2 r1+r2 add two reals\n inn i1 s1 b1 set membership; b1 = whether i1 is a member of s1\n ldi i1 i1 i1 load integer constant\n mov a1 a2 a2 move\n not b1 b1 -b1 Boolean negation\nEnvironment.\nSimilar to a real target CPU, the P-System has only one stack shared by procedure stack frames (providing return address, etc.) and the arguments to local instructions. Three of the machine's registers point into the stack (which grows upwards):\nAlso present is a constant area, and, below that, the heap growing down towards the stack. The NP (the new pointer) register points to the top (lowest used address) of the heap. When EP gets greater than NP, the machine's memory is exhausted.\nThe fifth register, PC, points at the current instruction in the code area.\nCalling conventions.\nStack frames look like this:\n EP -&gt;\n local stack\n SP -&gt; ...\n locals\n parameters\n return address (previous PC)\n previous EP\n dynamic link (previous MP)\n static link (MP of surrounding procedure)\n MP -&gt; function return value\nThe procedure calling sequence works as follows: The call is introduced with\n mst n\nwhere codice_2 specifies the difference in nesting levels (remember that Pascal supports nested procedures). This instruction will \"mark\" the stack, i.e. reserve the first five cells of the above stack frame, and initialize previous EP, dynamic, and static link. The caller then computes and pushes any parameters for the procedure, and then issues\n cup n, p\nto call a user procedure (codice_2 being the number of parameters, codice_4 the procedure's address). This will save the PC in the return address cell, and set the procedure's address as the new PC.\nUser procedures begin with the two instructions\n ent 1, i\n ent 2, j\nThe first sets SP to MP + codice_5, the second sets EP to SP + codice_6. So codice_5 essentially specifies the space reserved for locals (plus the number of parameters plus 5), and codice_6 gives the number of entries needed locally for the stack. Memory exhaustion is checked at this point.\nReturning to the caller is accomplished via\n retC\nwith codice_9 giving the return type (i, r, c, b, a as above, and p for no return value). The return value has to be stored in the appropriate cell previously. On all types except p, returning will leave this value on the stack.\nInstead of calling a user procedure (cup), standard procedure codice_10 can be called with\n csp q\nThese standard procedures are Pascal procedures like codice_11 (codice_12), codice_13 (codice_14), etc. Peculiarly codice_15 is a p-Code instruction instead.\nExample machine.\nNiklaus Wirth specified a simple p-code machine in the 1976 book \"Algorithms + Data Structures = Programs\". The machine had 3 registers - a program counter \"p\", a base register \"b\" and a top-of-stack register \"t\". There were 8 instructions:\nThis is the code for the machine, written in Pascal:\nconst\ntype\n fct=(lit,opr,lod,sto,cal,int,jmp,jpc);\n instruction=packed record\n f:fct;\n l:0..levmax;\n a:0..amax;\n end;\nvar\n code: array [0..cxmax] of instruction;\nprocedure interpret;\n const stacksize = 500;\n var\n function base(l: integer): integer;\n var b1: integer;\n begin\n while l &gt; 0 do begin\n b1 := s[b1];\n l := l - 1\n end;\n base := b1\n end {base};\nbegin\n writeln(' start pl/0');\n t := 0; b := 1; p := 0;\n s[1] := 0; s[2] := 0; s[3] := 0;\n repeat\n i := code[p]; p := p + 1;\n with i do\n case f of\n lit: begin t := t + 1; s[t] := a end;\n opr:\n 0:\n t := b - 1; p := s[t + 3]; b := s[t + 2];\n end;\n 1: s[t] := -s[t];\n 2: begin t := t - 1; s[t] := s[t] + s[t + 1] end;\n 3: begin t := t - 1; s[t] := s[t] - s[t + 1] end;\n 4: begin t := t - 1; s[t] := s[t] * s[t + 1] end;\n 5: begin t := t - 1; s[t] := s[t] div s[t + 1] end;\n 6: s[t] := ord(odd(s[t]));\n 8: begin t := t - 1; s[t] := ord(s[t] = s[t + 1]) end;\n 9: begin t := t - 1; s[t] := ord(s[t] &lt;&gt; s[t + 1]) end;\n 10: begin t := t - 1; s[t] := ord(s[t] &lt; s[t + 1]) end;\n 11: begin t := t - 1; s[t] := ord(s[t] &gt;= s[t + 1]) end;\n 12: begin t := t - 1; s[t] := ord(s[t] &gt; s[t + 1]) end;\n 13: begin t := t - 1; s[t] := ord(s[t] &lt;= s[t + 1]) end;\n end;\n lod: begin t := t + 1; s[t] := s[base(l) + a] end;\n sto: begin s[base(l)+a] := s[t]; writeln(s[t]); t := t - 1 end;\n cal:\n s[t + 1] := base(l); s[t + 2] := b; s[t + 3] := p;\n b := t + 1; p := a\n end;\n int: t := t + a;\n jmp: p := a;\n jpc: begin if s[t] = 0 then p := a; t := t - 1 end\n until p = 0;\n writeln(' end pl/0');\nend {interpret};\nThis machine was used to run Wirth's PL/0, a Pascal subset compiler used to teach compiler development.\nMicrosoft P-code.\nAs the goal of the company was to release software for all the major platforms and architectures that existed then. Between 1980 and 1982, Microsoft developed an early C compiler that produced P-Code (the C language itself was not standardized and wouldn't be until later in the 80s). The P-Code allowed software to run on most platforms with minimal code change. UCSD Pascal was using a similar approach. This C to P-Code was a success but was very slow. In 1983, Microsoft released the Microsoft C Compiler, MSC, based on a license of the Lattice C compiler for versions 1.0 and 2.0; then, from version 3.0 onward, the MSC was a complete rewrite by Microsoft.\nP-code is a name later used by some of Microsoft's intermediate languages. They provided an alternate binary format to machine code. At various times, Microsoft has said P-code is an abbreviation for either \"packed code\" or \"pseudo code\".\nSome Microsoft P-code flavor, quite different from the one used by the C compiler, was widely used with Visual Basic which had a runtime that included a VM or could be directly compiled to native code. Like other P-code implementations, Microsoft P-code enabled a more compact executable at the expense of slower execution.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24723", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=24723", "title": "Proton-pump inhibitor", "text": "Class of drugs for reducing stomach acid\nProton-pump inhibitors (PPIs) are a class of medications that cause a profound and prolonged reduction of stomach acid production. They do so by irreversibly inhibiting the stomach's H+/K+ ATPase proton pump. The body eventually synthesizes new proton pumps to replace the irreversibly inhibited ones, a process driven by normal cellular turnover, which gradually restores acid production.\nProton-pump inhibitors have largely superseded the H2-receptor antagonists, a group of medications with similar effects but a different mode of action, and heavy use of antacids. A potassium-competitive acid blocker (PCAB) revaprazan was marketed in Korea as an alternative to a PPI. A newer PCAB vonoprazan with a faster and longer lasting action than revaprazan, and PPIs has been marketed in Japan (2013), Russia (2021), and the US (2023).\nPPIs are among the most widely sold medications in the world. The class of proton-pump inhibitor medications is on the World Health Organization's List of Essential Medicines. Omeprazole is the specific listed example.\nMedical uses.\nThese medications are used in the treatment of many conditions, such as:\nSpecialty professional organizations recommend that people take the lowest effective PPI dose to achieve the desired therapeutic result when used to treat gastroesophageal reflux disease long-term. In the United States, the Food and Drug Administration (FDA) has advised that over-the-counter PPIs, such as Prilosec OTC, should be used no more than three 14-day treatment courses over one year.\nDespite their extensive use, the quality of the evidence supporting their use in some of these conditions is variable. The effectiveness of PPIs has not been demonstrated for every case. For example, although they reduce the incidence of esophageal adenocarcinoma in Barrett's oesophagus, they do not change the length affected. In addition, research in the UK has suggested that PPIs are not effective at treating persistent throat symptoms.\nIndications for stopping PPIs.\nPPIs are often used longer than necessary. In about half of people who are hospitalized or seen at a primary care clinic there is no documented reason for their long-term use of PPIs. Some researchers believe that, given the little evidence of long-term effectiveness, the cost of the medication and the potential for harm means that clinicians should consider stopping PPIs in many people.\nAdverse effects.\nIn general, proton pump inhibitors are well tolerated, and the incidence of short-term adverse effects is relatively low. The range and occurrence of adverse effects are similar for all of the PPIs, though they have been reported more frequently with omeprazole. This may be due to its longer availability and, hence, clinical experience.\nCommon adverse effects include headache, nausea, diarrhea, abdominal pain, fatigue, and dizziness. Infrequent adverse effects include rash, itch, flatulence, constipation, anxiety, and depression. Also infrequently, PPI use may be associated with occurrence of myopathies, including the serious reaction rhabdomyolysis.\nLong-term use of PPIs requires assessment of the balance of the benefits and risks of the therapy. As of March 2017, various adverse outcomes have been associated with long-term PPI use in several primary reports, but reviews assess the overall quality of evidence in these studies as \"low\" or \"very low\". They describe inadequate evidence to establish causal relationships between PPI therapy and many of the proposed associations, due to study design and small estimates of effect size. \nAs of March 2017, benefits outweighed risks when PPIs are used appropriately, but when used inappropriately, modest risks become important. They recommend that PPIs should be used at the lowest effective dose in people with a proven indication, but discourage dose escalation and continued chronic therapy in people unresponsive to initial empiric therapy.\nWith regard to iron and vitamin B12, the data is weak and several confounding factors have been identified. Low levels of magnesium can be found in people on PPI therapy and these can be reversed when they are switched to H2-receptor antagonist medications.\nBone.\nHigh dose or long-term use of PPIs carries an increased risk of bone fractures which was not found with short-term, low dose use; the FDA included a warning regarding this on PPI drug labels in 2010.\nIn infants, acid suppression therapy is frequently prescribed to treat symptomatic gastroesophageal reflux in otherwise healthy infants (\"i.e.\", infants without gastroesophageal reflux disease). A study from 2019 showed that PPI use alone and together with histamine H2-receptor antagonists was associated with an increased bone fracture hazard, which was amplified by days of use and earlier initiation of therapy. The reason is not clear; increased bone breakdown by osteoclasts has been suggested.\nA recent 2024 study published in the \"Journal of Clinical Endocrinology &amp; Metabolism\" found that chronic use of PPIs in men is linked to lower trabecular bone quality. Specifically, PPI use was associated with reduced lumbar spine trabecular bone score (TBS), as well as lower bone mineral density (BMD) T-scores in the lumbar spine, total hip, and femoral neck. There are associations with an increased risk of stroke, but this appears to be more likely to occur in people who already have an elevated risk.\nOne suggested mechanism for cardiovascular effects is because PPIs bind and inhibit dimethylargininase, the enzyme that degrades asymmetric dimethylarginine (ADMA), resulting in higher ADMA levels and a decrease in bioavailable nitric oxide.\nCancer.\nA 2022 umbrella review of 21 meta-analyses shows an association between proton-pump inhibitor use and an increased risk of gastric cancer, pancreatic cancer, colorectal cancer, and liver cancer.\nOther.\nAssociations have been shown between PPI use and an increased risk of pneumonia, particularly in the 30 days after starting therapy, where it was found to be 50% higher in community use. Other very weak associations of PPI use have been found, such as with chronic kidney disease, dementia and Hepatocellular carcinoma (HCC).\nAs of 2016, results were derived from observational studies, it remained uncertain whether such associations were causal relationships.\nMechanism of action.\nProton pump inhibitors act by irreversibly blocking the hydrogen/potassium adenosine triphosphatase enzyme system (the H+/K+ ATPase, or, more commonly, the gastric proton pump) of the gastric parietal cells. The proton pump is the terminal stage in gastric acid secretion, being directly responsible for secreting H+ ions into the gastric lumen, making it an ideal target for inhibiting acid secretion. Because the H,K-ATPase is the final step of acid secretion, an inhibitor of this enzyme is more effective than receptor antagonists in suppressing gastric acid secretion. All of these drugs inhibit the gastric H,K-ATPase by covalent binding, so the duration of their effect is longer than expected from their levels in the blood.\nTargeting the terminal step in acid production, as well as the irreversible nature of the inhibition, results in a class of medications that are significantly more effective than H2 antagonists and reduce gastric acid secretion by up to 99%.\nIn \"H. pylori\" eradication, PPIs help by increasing the stomach pH, causing the bacterium to shift out of its coccoid form which is resistant to both acids and antibiotics. PPIs also show some weaker additional effects in eradication.\nPharmacokinetics.\nThe rate of omeprazole absorption is decreased by concomitant food intake. In addition, the absorption of lansoprazole and esomeprazole is decreased and delayed by food. It has been reported, however, that these pharmacokinetic effects have no significant impact on efficacy.\nIn healthy humans, the half-life of PPIs is about 1 hour (9 hours for tenatoprazole), but the duration of acid inhibition is 48 hours because of irreversible binding to the H,K-ATPase. All the PPIs except tenatoprazole are rapidly metabolized in the liver by CYP enzymes (mostly by CYP2C19 and 3A4). Dissociation of the inhibitory complex is probably due to the effect of the endogenous antioxidant glutathione which leads to the release of omeprazole sulfide and reactivation of the enzyme.\nHistory.\nPPIs were developed in the 1980s, with omeprazole being launched in 1988. Most of these medications are benzimidazole derivatives, related to omeprazole, but imidazopyridine derivatives such as tenatoprazole have also been developed. Potassium-competitive inhibitors such as revaprazan reversibly block the potassium-binding site of the proton pump, acting more quickly, but are not available in most countries.\nSociety and culture.\nEconomics.\nIn British Columbia, Canada the cost of the PPIs varies significantly from CA$ to CA$ per dose while all agents in the class appear more or less equally effective.\nRegulatory approval.\nA comparative table of FDA-approved indications for PPIs is shown below.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24724", "revid": "46010350", "url": "https://en.wikipedia.org/wiki?curid=24724", "title": "Pan-Slavism", "text": "Political ideology emphasising unity of Slavic peoples\nPan-Slavism is a political ideology that originated in the mid-19th century, emphasizing integrity and unity among the Slavic peoples. Its main impact occurred in the Balkans, where non-Slavic empires had ruled the South Slavs for centuries. These were mainly the Byzantine Empire, Austria-Hungary, the Ottoman Empire, and Venice.\nOrigins.\nExtensive pan-Slavism emerged much like Pan-Germanism; both movements flourished from the sense of unity and nationalism experienced by members of many European ethnic groups in the aftermath of the French Revolution and the consequent Napoleonic Wars, as a pushback against traditional European monarchies. As in other Romantic nationalist movements, Slavic intellectuals and scholars in the developing fields of history, philology, and folklore actively encouraged Slavs' interest in their shared identity and ancestry. Pan-Slavism co-existed with the Southern Slavic drive towards independence.\nCommonly used symbols of the Pan-Slavic movement were the Pan-Slavic colours (blue, white, and red) and the Pan-Slavic anthem, \"Hey, Slavs\".\nThe first pan-Slavists were the 16th-century Croatian writer Vinko Pribojevi\u0107, the Dalmatian Aleksandar Komulovi\u0107 (1548\u20131608), the Croat Bartol Ka\u0161i\u0107 (1575\u20131650), the Ragusan Ivan Gunduli\u0107 (1589\u20131638), and the Croatian Catholic missionary Juraj Kri\u017eani\u0107 (c.\u20091618 \u2013 1683). Additionally, scholars such as Tomasz Kamusella have attributed early manifestations of Pan-Slavic thought within the Habsburg monarchy to the Slovaks Adam Franz Koll\u00e1r (1718\u20131783) and Pavel Jozef \u0160af\u00e1rik (1795\u20131861).\nThe Pan-Slavism movement grew rapidly following the end of the Napoleonic Wars in 1815. In the aftermath of the wars, the leaders of Europe sought to restore the pre-war \"status quo\". At the Congress of Vienna of 1814\u20131815, Austria's representative, Prince von Metternich, detected a threat to this \"status quo\" in the Austrian Empire through nationalists' demands for independence from the empire.\nWhile Vienna's subjects included numerous ethnic groups (such as Germans, Italians, Romanians, Hungarians, etc.), the Slav proportion of the population (Poles, Ruthenians, Ukrainians, Czechs, Slovaks, Slovenes, Serbs, Bosniaks, and Croats) together formed a substantial\u2014if not the largest\u2014ethnic grouping.\nFirst Pan-Slav Congress, Prague, 1848.\nThe First Pan-Slav congress was held in Prague, Bohemia, in June 1848, during the revolutionary movement of 1848. The Czechs had refused to send representatives to the Frankfurt Assembly, feeling that Slavs had a distinct interest from the Germans. The Austroslav, Franti\u0161ek Palack\u00fd, presided over the event. Most of the delegates were Czech and Slovak. Palack\u00fd called for the cooperation of the Habsburgs and had also endorsed the Habsburg monarchy as the political formation most likely to protect the peoples of central Europe. When the Germans asked him to declare himself in favour of their desire for national unity, he replied that he would not, as this would weaken the Habsburg state: \u201cTruly, if it were not that Austria had long existed, it would be necessary, in the interest of Europe, in the interest of humanity itself, to create it.\u201d\nThe Pan-Slav congress met during the revolutionary turmoil of 1848. Young inhabitants of Prague had taken to the streets and in the confrontation, a stray bullet had killed the wife of Field Marshal Alfred I, Prince of Windisch-Gr\u00e4tz, the commander of the Austrian forces in Prague. Enraged, Windischgr\u00e4tz seized the city, disbanded the congress, and established martial law throughout Bohemia.\nAccording to Slovak intellectuals J\u00e1n Koll\u00e1r and Andrej \u013dudov\u00edt Radlinsk\u00fd, along with the prevailing Pan-Slavic views of the time, the Slavic nation consisted of four tribes, the Czechoslovak, the Polish, the Russian (East Slavs), and the Illyrian (Southern Slavs).\nPan-Slavism in the Czech lands and Slovakia.\nThe first Pan-Slavic convention was held in Prague on June 2 through 16, 1848. The delegates at the Congress were specifically both anti-Austrian and anti-Russian. Still \"the Right\"\u2014the moderately liberal wing of the Congress\u2014under the leadership of Franti\u0161ek Palack\u00fd (1798\u20131876), a Czech historian and politician, and Pavol Jozef \u0160af\u00e1rik (1795\u20131861), a Slovak philologist, historian and archaeologist, favored autonomy of the Slav lands within the framework of Austrian (Habsburg) monarchy. In contrast \"the Left\"\u2014the radical wing of the Congress\u2014under the leadership of Karel Sabina (1813\u20131877), a Czech writer and journalist, Josef V\u00e1clav Fri\u010d, a Czech nationalist, Karol Libelt (1817\u20131861), a Polish writer and politician, and others, pressed for a close alliance with the revolutionary-democratic movement going on in Germany and Hungary in 1848.\nA national rebirth in the Hungarian \"Upper Land\" (now Slovakia) awoke in a completely new light, both before the Slovak Uprising in 1848 and after. The driving force of this rebirth movement were Slovak writers and politicians who called themselves \u0160t\u00farovci, the followers of \u013dudov\u00edt \u0160t\u00far. As the Slovak nobility was Magyarized and most Slovaks were merely farmers or priests, this movement failed to attract much attention. Nonetheless, the campaign was successful as brotherly cooperation between the Croats and the Slovaks brought its fruit throughout the war. Most of the battles between Slovaks and Hungarians however, did not turn out in favor for the Slovaks who were logistically supported by the Austrians, but not sufficiently. The shortage of manpower proved to be decisive as well.\nDuring the war, the Slovak National Council brought its demands to the young Austrian Emperor, Franz Joseph I, who seemed to take a note of it and promised support for the Slovaks against the revolutionary radical Hungarians. However the moment the revolution was over, Slovak demands were forgotten. These demands included an autonomous land within the Austrian Empire called \"Slovensk\u00fd kraj\" which would be eventually led by a Serbian prince. This act of ignorance from the Emperor convinced the Slovak and the Czech elite who proclaimed the concept of Austroslavism as dead.\nDisgusted by the Emperor's policy, in 1849, \u013dudov\u00edt \u0160t\u00far, the person who codified the first largely used Slovak language, wrote a book he would name \"Slavdom and the World of the Future\". This book served as a manifesto where he noted that Austroslavism was not the way to go anymore. He also wrote a sentence that often serves as a quote until this day: \"Every nation has its time under God's sun, and the linden [a symbol of the Slavs] is blossoming, while the oak [a symbol of the Teutons] bloomed long ago.\"\nHe expressed confidence in the Russian Empire however, as it was the only country of Slavs that was not dominated by anybody else, yet it was one of the most powerful nations in the world. He often symbolized Slavs as being a tree, with \"minor\" Slavic nations being branches while the trunk of the tree was Russian. His Pan-Slavic views were unleashed in this book, where he stated that the land of Slovaks should be annexed by the Tsar's empire and that eventually, the population could be not only Russified, but also converted into the rite of Orthodoxy, religion originally spread by Cyril and Methodius during the times of Great Moravia, which served as an opposition to the Catholic missionaries from the Franks. After the Hungarian invasion of Pannonia, Hungarians converted into Catholicism, which effectively influenced the Slavs living in Pannonia and in the land south of the Lechs.\nHowever, the Russian Empire often claimed Pan-Slavism as a justification for its aggressive moves in the Balkan Peninsula of Europe against the Ottoman Empire, which conquered and held the land of Slavs for centuries. This eventually led to the Balkan campaign of the Russian Empire, which resulted in the entire Balkan being liberated from the Ottoman Empire, with the help and the initiative of the Russian Empire. Pan-Slavism has some supporters among Czech and Slovak politicians, especially among the nationalistic and far-right ones, such as People's Party \u2013 Our Slovakia.\nThe creation of an independent Czechoslovakia made the old ideals of Pan-Slavism anachronistic. Relations with other Slavic states varied, sometimes being so tense it escalated into an armed conflict, such as with the Second Polish Republic where border clashes over Silesia resulted in a short hostile conflict, the Polish\u2013Czechoslovak War. Even tensions between Czechs and Slovaks had appeared before and during World War II.\nPan-Slavism among South Slavs.\nPan-Slavism in the south, largely advocated by Serbs, would often turn to Russia for support. The Southern Slavic movement advocated the independence of the Slavic peoples in the Austro-Hungarian Empire, Republic of Venice and the Ottoman Empire. Most Serbian intellectuals sought to unite all of the Southern, Balkan Slavs, whether Catholic (Croats, Slovenes), Muslim (Bosniaks, Pomaks), or Orthodox (Serbs, Macedonians, Bulgarians) as a \"Southern-Slavic nation of three faiths\".\nAustria feared that Pan-Slavists would endanger the empire. In Austria-Hungary Southern Slavs were distributed among several entities: Slovenes in the Austrian part (Carniola, Styria, Carinthia, Gorizia and Gradisca, Trieste, Istria), Croats and Serbs in the Hungarian part within the autonomous Kingdom of Croatia-Slavonia and in the Austrian part within the autonomous Kingdom of Dalmatia, and in Bosnia and Herzegovina, under direct control from Vienna. Owing to a different position within Austria-Hungary, several different goals were prominent among the Southern Slavs of Austria-Hungary. A strong alternative to Pan-Slavism was Austroslavism, especially among the Croats and Slovenes. Because the Serbs were dispersed among several regions, and the fact that they had ties to the independent nation state of Kingdom of Serbia, they were among the strongest supporters of independence of South-Slavs from Austria-Hungary and uniting into a common state under Serbian monarchy.\nWhen in 1863 the Association of Serbian Philology commemorated the death of Cyril a thousand years earlier, its president Dimitrije Mati\u0107 talked of the creation of an \"ethnically pure\" Slavonic people, \"With God\u2019s help, there should be a whole Slavonic people with purely Slavonic faces and of purely Slavonic character.\"\nAfter World War I the creation of the Kingdom of Yugoslavia, under Serbian royalty of the Kara\u0111or\u0111evi\u0107 dynasty, united most Southern Slavic-speaking nations regardless of religion and cultural background. The only ones they did not unite with were the Bulgarians. Still, in the years after the Second World War, there were proposals to incorporate Bulgaria into a Greater Yugoslavia thus uniting all south Slavic-speaking nations into one state. The idea was abandoned after the split between Josip Broz Tito and Joseph Stalin in 1948. This led to some bitter sentiment between the people of Yugoslavia and Bulgaria in the aftermath.\nAt the end of the Second World War, the Partisans' mixed heritage leader Josip Broz Tito became Yugoslav president, and the country become a socialist republic, with the motto of \"Brotherhood and Unity\" between its various Slavic peoples.\nPan-Slavism in Poland.\nWith the exception of Russia, the Polish nation has the distinction among other Slavic peoples of having enjoyed independence as a part of various entities for several centuries prior to the advent of Pan-Slavism.\nAfter 1795, Revolutionary and Napoleonic France had influenced many Poles who sought the reconstitution of their existing country\u2014particularly since France was a mutual enemy of Austria, Prussia, and also Russia. Russia's Pan-Slavic rhetoric had alarmed the Poles. Pan-Slavism was not fully embraced among Poles after the early period. Poland did nevertheless express solidarity with those of its fellow Slavic nations that had suffered oppression and were seeking independence.\nWhile Pan-Slavism as an ideology was inimical to Austro-Hungarian interests, Poles instead embraced the wide autonomy within the state and assumed a loyalist position towards the Habsburgs. Within the Austro-Hungarian polity, they were able to develop their national culture and preserve the Polish language, both of which were under threat in both German and Russian Empires. A Pan-Slavic federation was proposed, but on the condition that the Russian Empire would be excluded from such an entity. After Poland regained its independence (from Germany, Austria and Russia) in 1918, no internal faction considered Pan-Slavism as a serious alternative, viewing Pan-Slavism as \"Russification\". During Poland's communist era, the USSR used Pan-Slavism as a propaganda tool to justify its control over the country. The issue of Pan-Slavism was not part of current mainstream politics and is widely seen as an ideology of Russian imperialism.\nPan-Slavism in Russia.\nDuring the time of the Soviet Union, Bolshevik teachings viewed Pan-Slavism as a reactionary element associated to the Russian Empire. As a result, Bolsheviks viewed it as contrary to their Marxist ideology. Pan-Slavists even faced persecution during the Stalinist repressions in the Soviet Union (see Slavists case). Nowadays, ultranationalist parties like the Russian National Unity party advocate for a Russian-dominated 'Slavic Union'.\nModern-day developments.\nThe authentic idea of the unity of the Slavic people was all but gone after World War I, described with the maxim \"Versailles and Trianon have put an end to all Slavisms\". During the Cold War, all Slavic peoples were in union under the dominance of the USSR, but pan-Slavism was rejected as reactionary to Communist ideals, and this unity was largely put to rest with the fall of communism in Central and Eastern Europe in the late 1980s, leading to the breakup of federal states such as Czechoslovakia and Yugoslavia.\nVarying relations between the Slavic countries exist nowadays; they range from mutual respect on equal footing and sympathy towards one another through traditional dislike and enmity, to indifference. No forms, other than culture and heritage oriented organizations, are currently considered forms of rapprochement among the countries with Slavic origins. The political parties which include Pan-Slavism as part of their program usually live on the fringe of the political spectrum, or are part of controlled and systemic opposition in Belarus, Russia and occupied territories, as part of an irredentist pan-slavist campaign by Russia.\nA political concept of Euro-Slavism evolved from the idea that European integration will solve issues of Slavic peoples and promote peace, unity and cooperation on equal terms within the European Union. The concept seeks to resist strong multicultural tendencies from Western Europe, the dominant position of Germany, opposes Slavophilia, and typically encourages democracy and democratic values. Many Euroslavists believe it is possible to unite Slavic communities without exclusion of Russia from the European cultural area, but are also opposed to Russophilia and concepts of Slavs under Russian domination and irredentism. It is considered a modern form of Austro-Slavist and Neo-Slavist movements. Their origins date back to the middle of the 19th century, being first proposed by Czech liberal politician Karel Havl\u00ed\u010dek Borovsk\u00fd in 1846, when it was refined into a provisional political program by Czech politician Franti\u0161ek Palack\u00fd and completed by the first President of Czechoslovakia Tom\u00e1\u0161 Garrigue Masaryk in his work \"New Europe: Slavic Viewpoint\".\nContemporary views.\nWhile Pan-Slavism remains popular in moderate and extremist political circles, its popularity subsided in the public. After the failure of Yugoslavism and Czechoslovakism, nationalism in Slavic nations now focus on self-definition and non-ethnic relations (like Hungary and Poland). The Russo-Ukrainian War had a divisive role, and pro-Russian sentiment became less popular. Tensions also rose on the Ukrainian side, and for economic reasons Ukrainian grain exports had to be banned for a time in multiple Slavic countries such as Poland and Slovakia, after the protest of farmers in multiple European countries.\nCreation of pan-Slavic languages.\nSimilarities of Slavic languages inspired many to create zonal auxiliary Pan-Slavic languages for all Slavic people to communicate with one another. Several such languages were constructed in the past, but many more were created in the Internet Age. The most prominent modern example is Interslavic.\nPopular culture.\nPan-Slavic countries, organisations, and alliances appear in various works of fiction.\nIn the 2014 turn-based strategy 4X game \"\" there is a playable faction called the Slavic Federation \u2013 a science fiction vision of Eastern Europe and Western Asia, reformed into a powerful unified state with a focus on aerospace, technological research, and terrestrial engineering. Its leader, a former cosmonaut named Vadim Kozlov voiced by Mateusz Pawluczuk, speaks a mixture of Russian and Ukrainian with a heavy Polish accent. In the historical grand strategy games of \"Crusader Kings II\" and \"Europa Universalis IV\", the player is able to unite Slavonic territories via political alliances and multi-ethnic kingdoms. The real-time strategy games \"Ancestors Legacy\" and the HD edition of \"Age of Empires II\" feature fictionalised versions of the early Slavs that incorporate and fuse elements from different Slavic nations.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24727", "revid": "9529274", "url": "https://en.wikipedia.org/wiki?curid=24727", "title": "Pan-Germanism", "text": "Pan-nationalist political idea\nPan-Germanism ( or '), also occasionally known as Pan-Germanicism, is a pan-nationalist political idea. Pan-Germanism seeks to unify all ethnic Germans, German-speaking people, and possibly also non-German Germanic peoples \u2013 into a single nation-state known as Greater Germany.\nPan-Germanism was highly influential in German politics in the 19th century during the unification of Germany when the German Empire was proclaimed as a nation-state in 1871 but without Germanophone Switzerland, Austria-Hungary, Luxembourg and Liechtenstein (Kleindeutsche L\u00f6sung/Lesser Germany) and the first half of the 20th century in Austria-Hungary and the German Empire. From the late 19th century, many Pan-Germanist thinkers, since 1891 organized in the Pan-German League, had adopted openly ethnocentric and racist ideologies, and ultimately gave rise to the foreign policy \"Heim ins Reich\" pursued by Nazi Germany under Adolf Hitler from 1938, one of the primary factors leading to the outbreak of World War II. The concept of a Greater Germany was attempted to be put into practice as the Greater Germanic Reich (), fully styled the Greater Germanic Reich of the German Nation (). As a result of the Second World War, there was a clear backlash against Pan-Germanism and other related ideologies. Today, pan-Germanism is mainly limited to a few nationalist groups, mainly on the political right in Germany and Austria.\nEtymology.\nThe word \"pan\" is a Greek word element meaning \"all, every, whole, all-inclusive\". The word \"German\" in this context derives from Latin \"Germani\" originally used by Julius Caesar referring to tribes or a single tribe in northeastern Gaul. In the Late Middle Ages, it acquired a loose meaning referring to the speakers of Germanic languages some of whom spoke dialects ancestral to modern German. In English, \"Pan-German\" was first attested in 1892.\nIn German various concepts can be included under the heading of Pan-Germanism, though often with slight or significant differences in meaning. For example adjectives such as \"alldeutsch\" or \"gesamtdeutsch\", which can be translated as \"pan-german\", typically refer to the Alldeutsche Bewegung, a political movement which sought to unite all German speaking people in one country, whereas \"Pangermanismus\" can refer to both the pursuit of uniting all the German-speaking people and movements which sought to unify all speakers of Germanic languages.\nOrigins (before 1860).\nThe origins of Pan-Germanism began with the birth of Romantic nationalism during the Napoleonic Wars, with Friedrich Ludwig Jahn and Ernst Moritz Arndt being early proponents. Germans, for the most part, had been a loose and disunited people since the Reformation, when the Holy Roman Empire was shattered into a patchwork of states following the end of the Thirty Years' War with the Peace of Westphalia.\nAdvocates of the (Greater Germany) solution sought to unite all the German-speaking people in Europe, under the leadership of the German Austrians from the Austrian Empire. Pan-Germanism was widespread among the revolutionaries of 1848, notably among Richard Wagner and the Brothers Grimm. Writers such as Friedrich List and Paul Anton Lagarde argued for German hegemony in Central and Eastern Europe, where German domination in some areas had begun as early as the 9th century AD with the , Germanic expansion into Slavic and Baltic lands. For the Pan-Germanists, this movement was seen as a Drang nach Osten, in which Germans would be naturally inclined to seek Lebensraum by moving eastwards to reunite with the German minorities there.\nThe (\"Song of Germany\"), written in 1841 by Hoffmann von Fallersleben, in its first stanza defines \"Deutschland\" as reaching \"From the Meuse to the Memel / From the Adige to the Belt\", i.e. as including East Prussia and South Tyrol.\nReflecting upon the First Schleswig War in 1848, Karl Marx noted in 1853 that \"by quarrelling amongst themselves, instead of confederating, Germans and Scandinavians, both of them belonging to the same great race, only prepare the way for their hereditary enemy, the Slav.\"\nThe German Question.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"There is, in political geography, no Germany proper to speak of. There are Kingdoms and Grand Duchies, and Duchies and Principalities, inhabited by Germans, and each separately ruled by an independent sovereign with all the machinery of State. Yet there is a natural undercurrent tending to a national feeling and toward a union of the Germans into one great nation, ruled by one common head as a national unit.\"\u2014\u200a\nBy the 1860s Prussia and Austria had become the two most powerful states dominated by German-speaking elites. Both sought to expand their influence and territory. The Austrian Empire\u2014like the Holy Roman Empire\u2014was a multi-ethnic state, but the German-speaking people there did not have an absolute numerical majority; its re-shaping into the Austro-Hungarian Empire was one result of the growing nationalism of other ethnicities\u2014especially the Hungarians. Under Prussian leadership, Otto von Bismarck would ride on the coattails of nationalism to unite all of the northern German lands. After Bismarck excluded Austria and the German Austrians from Germany in the German war of 1866 and (following a few other events over the next few years), the unification of Germany, established the Prussian-dominated German Empire in 1871 with the proclamation of Wilhelm I as head of a union of German-speaking states, while disregarding millions of its non-German subjects (Poles, Danes, Sorbs, etc.) who desired self-determination from German rule. After World War I the Pan-Germanist philosophy changed drastically during Adolf Hitler's rise to power. Pan-Germanists originally sought to unify all the German-speaking populations of Europe in a single nation-state known as (Greater Germany), where \"German-speaking\" was sometimes taken as synonymous with Germanic-speaking, to the inclusion of the Frisian- and Dutch-speaking populations of the Low Countries, and Scandinavia.\nAlthough Bismarck had excluded Austria and the German Austrians from his creation of the Kleindeutschland state in 1871, integrating the German Austrians nevertheless remained a strong desire for many people of both Austria and Germany. The most radical Austrian pan-German Georg Sch\u00f6nerer (1842\u20131921) and (1862\u20131941) articulated Pan-Germanist sentiments in the Austro-Hungarian Empire. There was also a rejection of Roman Catholicism with the Away from Rome! movement (ca 1900 onwards) calling for German-speakers to identify with Lutheran or Old Catholic churches. The Pan-German Movement gained an institutional format in 1891, when , a professor at the University of Leipzig and a member of the Reichstag, organized the Pan-German League, an ultra-nationalist political-interest organization which promoted imperialism, antisemitism, and support for ethnic German minorities in other countries.\nThe organization achieved great support among the educated middle and upper class; it promoted German nationalist consciousness, especially among ethnic Germans outside Germany. In his three-volume work, \"Deutsche Politik\" (1905\u201307), Hasse called for German imperialist expansion in Europe. The Munich professor Karl Haushofer, , and Hans Grimm (author of the novel \"Volk ohne Raum\") preached similar expansionist policies.\nDuring the German entry into World War I, Chancellor Theobald von Bethmann Hollweg authorized the Septemberprogramm proposing that the German Empire use the First World War to seek territorial annexations similar to the ones demanded by pan-German nationalists. The West German historian Fritz Fischer argued in his 1962 thesis \"Germany's Aims in the First World War\" that this and other documents indicated that Germany was responsible for World War I and intended to fulfill pan-German aims, although other historians have since disputed this conclusion. After Naval Minister Alfred von Tirpitz resigned from the Cabinet under pressure from Chancellor Bethmann Hollweg over Tirpitz's push to introduce unrestricted submarine warfare, Tirpitz united pan-German nationalists under the German Fatherland Party in the Reichstag.\nAustria.\nAfter the Revolutions of 1848 in the Habsburg areas, in which the liberal nationalistic revolutionaries advocated the Greater German solution, the Austrian defeat in the Austro-Prussian War (1866) with the effect that Austria was now excluded from Germany, and increasing ethnic conflicts in the multinational Habsburg monarchy, a German national movement evolved in Austria. Led by the radical German nationalist and Austrian antisemite Georg Ritter von Sch\u00f6nerer, organisations such as the \"Pan-German Society\" demanded the annexation of all German-speaking territories under the rule of the Habsburg monarchy to the German Empire, and fervently rejected Austrian nationalism and a pan-Austrian identity. Sch\u00f6nerer's v\u00f6lkisch and racist German nationalism was an inspiration to Adolf Hitler's Nazi ideology.\nIn 1933, Austrian Nazis and the national-liberal Greater German People's Party formed an action group, fighting together against the Austrofascist Federal State of Austria which imposed a distinct Austrian national identity and in accordance said that Austrians were \"better Germans.\" Kurt Schuschnigg adopted a policy of appeasement towards Nazi Germany and called Austria the \"better German state\", but he still struggled to keep Austria independent. With \"Anschluss\" of Austria in 1938, the historic aim of Austria's German nationalists was achieved.\nAfter the end of Nazi Germany and the events of World War II in 1945, the ideas of pan-Germanism and an \"Anschluss\" fell out of favour due to their association with Nazism and allowed Austrians to develop their own national identity. Nevertheless, such notions were revived with the German national camp in the Federation of Independents and the early Freedom Party of Austria.\nScandinavia.\nThe idea of including the North Germanic-speaking Scandinavians into a Pan-German state, sometimes referred to as Pan-Germanicism, was promoted alongside mainstream pan-German ideas. Jacob Grimm adopted Munch's anti-Danish Pan-Germanism and argued that the entire peninsula of Jutland had been populated by Germans before the arrival of the Danes and that thus it could justifiably be reclaimed by Germany, whereas the rest of Denmark should be incorporated into Sweden. This line of thinking was countered by Jens Jacob Asmussen Worsaae, an archaeologist who had excavated parts of Danevirke, who argued that there was no way of knowing the language of the earliest inhabitants of Danish territory. He also pointed out that Germany had more solid historical claims to large parts of France and England, and that Slavs\u2014by the same reasoning\u2014could annex parts of Eastern Germany. Regardless of the strength of Worsaae's arguments, pan-Germanism spurred on the German nationalists of Schleswig and Holstein and led to the First Schleswig War in 1848. In turn, this likely contributed to the fact that Pan-Germanism never caught on in Denmark as much as it did in Norway. Pan-Germanic tendencies were particularly widespread among the Norwegian independence movement. Prominent supporters included Peter Andreas Munch, Christopher Bruun, Knut Hamsun, Henrik Ibsen and Bj\u00f8rnstjerne Bj\u00f8rnson. Bj\u00f8rnson, who wrote the lyrics for the Norwegian national anthem, proclaimed in 1901:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I'm a Pan-Germanist, I'm a Teuton, and the greatest dream of my life is for the South Germanic peoples and the North Germanic peoples and their brothers in diaspora to unite in a fellow confederation. In the 20th century the German Nazi Party sought to create a Greater Germanic Reich that would include most of the Germanic peoples of Europe within it under the leadership of Germany, including peoples such as the Danes, the Dutch, the Swedes, the Norwegians, and the Flemish within it.\nAnti-German Scandinavism surged in Denmark in the 1930s and 1940s in response to the pan-Germanic ambitions of Nazi Germany.\n1918 to 1945.\nWorld War I became the first attempt to carry out the Pan-German ideology in practice, and the Pan-German movement argued forcefully for expansionist imperialism.\nFollowing the defeat in World War I, the influence of German-speaking elites over Central and Eastern Europe was greatly limited. At the Treaty of Versailles, Germany was substantially reduced in size. Alsace-Lorraine was also influenced by the Francization after it returned to France. Austria-Hungary was split up. A rump Austria, which to a certain extent corresponded to the German-speaking areas of Austria-Hungary (a complete split into language groups was impossible due to multi-lingual areas and language-exclaves) adopted the name \"German Austria\" () in hope for union with Germany. Union with Germany and the name \"German Austria\" was forbidden by the Treaty of St. Germain and the name had to be changed back to Austria.\nIt was in the Weimar Republic that the Austrian-born Adolf Hitler, under the influence of the stab-in-the-back myth, first took up German nationalist ideas in his \"Mein Kampf\". Hitler met Heinrich Class in 1918, and Class provided Hitler with support for the 1923 Beer Hall Putsch. Hitler and his supporters shared most of the basic pan-German visions with the Pan-German League, but differences in political style led the two groups to open rivalry. The German Workers Party of Bohemia cut its ties to the pan-German movement, which was seen as being too dominated by the upper classes, and joined forces with the German Workers' Party led by Anton Drexler, which later became the Nazi Party (National Socialist German Workers' Party, NSDAP) that was to be headed by Adolf Hitler from 1921.\nNazi propaganda also used the political slogan \"Ein Volk, ein Reich, ein F\u00fchrer\" (\"One people, one Reich, one leader\"), to enforce pan-German sentiment in Austria for an \"Anschluss\".\nThe chosen name for the projected empire was a deliberate reference to the Holy Roman Empire (of the German Nation) that existed in the Middle Ages, known as the \"First Reich\" in Nazi historiography. Different aspects of the legacy of this medieval empire in German history were both celebrated and derided by the Nazi government. Hitler admired the Frankish Emperor Charlemagne for his \"cultural creativity\", his powers of organization, and his renunciation of the rights of the individual. He criticized the Holy Roman Emperors however for not pursuing an \"Ostpolitik\" (Eastern Policy) resembling his own, while being politically focused exclusively on the south. After the \"Anschluss\", Hitler ordered the old imperial regalia (the Imperial Crown, Imperial Sword, the Holy Lance and other items) residing in Vienna to be transferred to Nuremberg, where they were kept between 1424 and 1796. Nuremberg, in addition to being the former unofficial capital of the Holy Roman Empire, was also the place of the Nuremberg rallies. The transfer of the regalia was thus done to both legitimize Hitler's Germany as the successor of the \"Old Reich\", but also weaken Vienna, the former imperial residence.\nAfter the 1939 German occupation of Bohemia, Hitler declared that the Holy Roman Empire had been \"resurrected\", although he secretly maintained his own empire to be better than the old \"Roman\" one. Unlike the \"uncomfortably internationalist Catholic empire of Barbarossa\", the Germanic Reich of the German Nation would be racist and nationalist. Rather than a return to the values of the Middle Ages, its establishment was to be \"a push forward to a new golden age, in which the best aspects of the past would be combined with modern racist and nationalist thinking\".\nThe historical borders of the Holy Roman Empire were also used as grounds for territorial revisionism by the NSDAP, laying claim to modern territories and states that were once part of it. Even before the war, Hitler had dreamed of reversing the Peace of Westphalia, which had given the territories of the Empire almost complete sovereignty. On November 17, 1939, Reich Minister of Propaganda Joseph Goebbels wrote in his diary that the \"total liquidation\" of this historic treaty was the \"great goal\" of the Nazi regime, and that since it had been signed in M\u00fcnster, it would also be officially repealed in the same city.\nThe \"Heim ins Reich\" (\"Back Home to the Reich\") initiative was a policy pursued by the Nazis which attempted to convince the ethnic Germans living outside of Nazi Germany (such as in Austria and Sudetenland) that they should strive to bring these regions \"home\" into a Greater Germany. This notion also led the way for an even more expansive state to be envisioned, the Greater Germanic Reich, which Nazi Germany tried to establish. This pan-Germanic empire was expected to assimilate practically all of Germanic Europe into an enormously expanded Greater Germanic Reich. Territorially speaking, this encompassed the already-enlarged Reich itself (consisting of pre-1938 Germany plus the areas annexed into the \"Gro\u00dfdeutsche Reich\"), the Netherlands, Belgium, areas in north-eastern France considered to be historically and ethnically Germanic, Denmark, Norway, Sweden, Iceland, at least the German-speaking parts of Switzerland, and Liechtenstein. The most notable exception was the predominantly Anglo-Saxon United Kingdom, which was not projected as having to be reduced to a German province but to instead become an allied seafaring partner of the Germans.\nThe eastern \"Reichskommissariats\" in the vast stretches of Ukraine and Russia were also intended for future integration, with plans for them stretching to the Volga or even beyond the Urals. They were deemed of vital interest for the survival of the German nation, as it was a core tenet of Nazi ideology that it needed \"living space\" (\"Lebensraum\"), creating a \"pull towards the East\" (\"Drang nach Osten\") where that could be found and colonized, in a model that the Nazis explicitly derived from the American Manifest Destiny in the Far West and its clearing of native inhabitants.\nAs the foreign volunteers of the Waffen-SS were increasingly of non-Germanic origin, especially after the Battle of Stalingrad, among the organization's leadership (e.g. Felix Steiner) the proposition for a Greater Germanic Empire gave way to a concept of a European union of self-governing states, unified by German hegemony and the common enemy of Bolshevism. The Waffen-SS was to be the eventual nucleus of a common European army where each state would be represented by a national contingent. Himmler himself, however, gave no concession to these views, and held on to his Pan-Germanic vision in a speech given in April 1943 to the officers of the 1st SS Division Leibstandarte SS Adolf Hitler, the 2nd SS Panzer Division \"Das Reich\" and the 3rd SS Division \"Totenkopf\":&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We do not expect you to renounce your nation. [...] We do not expect you to become German out of opportunism. We do expect you to subordinate your national ideal to a greater racial and historical ideal, to the Germanic Reich.\nHistory since 1945.\nThe defeat of Germany in World War II brought about the decline of Pan-Germanism, much as World War I had led to the demise of Pan-Slavism. Parts of Germany itself were devastated, and the country was divided, firstly into Soviet, French, American, and British zones and then into West Germany and East Germany. Austria was separated from Germany and the German identity in Austria was also weakened. The end of World War II in Europe brought even larger territorial losses for Germany than the First World War, with vast portions of eastern Germany directly annexed by the Soviet Union and Poland. The scale of the Germans' defeat was unprecedented; Pan-Germanism became taboo because it had been tied to racist concepts of the \"master race\" and \"Nordicism\" by the Nazi party. However, the reunification of Germany in 1990 revived the old debates.\nSee also.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nReferences.\nNotes\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading"}
{"id": "24729", "revid": "45416752", "url": "https://en.wikipedia.org/wiki?curid=24729", "title": "Porsche Boxster", "text": ""}
{"id": "24730", "revid": "16185737", "url": "https://en.wikipedia.org/wiki?curid=24730", "title": "Patrick Abercromby", "text": "Scottish physician and antiquarian\nPatrick Abercromby (1656\u00a0\u2013 c.\u20091716) was a Scottish physician and antiquarian, noted for being physician to King James VII (II of England) and his fervent opposition to the Act of Union between Scotland and England.\nEarly life.\nPatrick Abercromby was the third son of Alexander Abercromby of Fetterneir in Aberdeenshire, and brother of Francis Abercromby, who was created Lord Glasford by King James II. He was born at Forfar in 1656 apparently of a Roman Catholic family.\nIntending to become a doctor of medicine he entered the University of St Andrews, where he took his degree of M.D. in 1685, but apparently he spent most of his youthful years abroad. It has been stated that he attended the university of Paris, France. \"A Discourse of Wit\" (1685), sometimes assigned to him, belongs to Dr David Abercromby.\nReturn to Scotland.\nOn his return to Scotland, Patrick Abercromby is found practising as a physician in Edinburgh, where, besides his professional duties, he gave himself with characteristic zeal to the study of antiquities. He was appointed physician to James II in 1685, but the revolution deprived him of the post. Living during the agitations for the union of England and Scotland, he took part as a Jacobite in the war of pamphlets inaugurated and sustained by prominent men on both sides of the Border, and he crossed swords with no less redoubtable a foe than Daniel Defoe in his \"Advantages of the Act of Security compared with those of the intended Union\" (Edinburgh, 1707), and \"A Vindication of the Same against Mr De Foe\" (ibid.).\nContinued work.\nA minor literary work of Abercromby's was a translation of Jean de Beaugu\u00e9's \"Histoire de la guerre d'\u00c9cosse\" (1556) which appeared in 1707. But the work with which his name is permanently associated is his \"Martial Atchievements \"[sic]\" of the Scots Nation\", issued in two large folios, vol. i. 1711, vol. ii. 1715. In the title-page and preface to vol. i. he disclaims the ambition of being an historian, but in vol. ii., in title-page and preface alike, he is no longer a simple biographer, but an historian. He was a laborious and accomplished reader and investigator of all available authorities, as well manuscript as printed; while the roll of names of those who aided him includes every man of note in Scotland at the time, from Sir Thomas Craig and Sir George Mackenzie to Alexander Nisbet and Thomas Ruddiman.\nDeath.\nThe date of Abercromby's death is uncertain. It has been variously assigned to 1715, 1716, 1720, and 1726, and it is usually added that he left a widow in great poverty. The Memoirs of the Abercrombys, commonly attributed to him, do not appear to have been published.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24731", "revid": "39619725", "url": "https://en.wikipedia.org/wiki?curid=24731", "title": "Positron", "text": "Anti-particle to the electron\nThe positron or antielectron is the particle with an electric charge of +1\"e\", a spin of 1/2 (the same as the electron), and approximately the same mass as an electron. It is the antiparticle (antimatter counterpart) of the electron. When a positron collides with an electron, annihilation occurs. If this collision occurs at low energies, it results in the production of two or more photons.\nPositrons can be created by positron emission radioactive decay (through weak interactions), or by pair production from a sufficiently energetic photon which is interacting with an atom in a material.\nHistory.\nTheory.\nIn 1928, Paul Dirac published a paper proposing that electrons can have both a positive and negative charge. This paper introduced the Dirac equation, a unification of quantum mechanics, special relativity, and the then-new concept of electron spin to explain the Zeeman effect. The paper did not explicitly predict a new particle but did allow for electrons having either positive or negative energy as solutions. Hermann Weyl then published a paper discussing the mathematical implications of the negative energy solution. The positive-energy solution explained experimental results, but Dirac was puzzled by the equally valid negative-energy solution that the mathematical model allowed. Quantum mechanics did not allow the negative energy solution to simply be ignored, as classical mechanics often did in such equations; the dual solution implied the possibility of an electron spontaneously jumping between positive and negative energy states. However, no such transition had yet been observed experimentally.\nDirac wrote a follow-up paper in December 1929 that attempted to explain the unavoidable negative-energy solution for the relativistic electron. He argued that \"... an electron with negative energy moves in an external [electromagnetic] field as though it carries a positive charge.\" He further asserted that all of space could be regarded as a \"sea\" of negative energy states that were filled, so as to prevent electrons jumping between positive energy states (negative electric charge) and negative energy states (positive charge). The paper also explored the possibility of the proton being an island in this sea, and that it might actually be a negative-energy electron. Dirac acknowledged that the proton having a much greater mass than the electron was a problem, but expressed \"hope\" that a future theory would resolve the issue.\nRobert Oppenheimer argued strongly against the proton being the negative-energy electron solution to Dirac's equation. He asserted that if it were, the hydrogen atom would rapidly self-destruct. Weyl in 1931 showed that the negative-energy electron must have the same mass as that of the positive-energy electron. Persuaded by Oppenheimer's and Weyl's argument, Dirac published a paper in 1931 that predicted the existence of an as-yet-unobserved particle that he called an \"anti-electron\" that would have the same mass and the opposite charge as an electron and that would mutually annihilate upon contact with an electron.\nErnst Stueckelberg, and later Richard Feynman, proposed an interpretation of the positron as an electron moving backward in time, reinterpreting the negative-energy solutions of the Dirac equation. Electrons moving backward in time would have a positive electric charge. John Archibald Wheeler invoked this concept to explain the identical properties shared by all electrons, suggesting that \"they are all the same electron\" with a complex, self-intersecting worldline. Yoichiro Nambu later applied it to all production and annihilation of particle-antiparticle pairs, stating that \"the eventual creation and annihilation of pairs that may occur now and then is no creation or annihilation, but only a change of direction of moving particles, from the past to the future, or from the future to the past.\" The backwards in time point of view is nowadays accepted as completely equivalent to other pictures, but it does not have anything to do with the macroscopic terms \"cause\" and \"effect\", which do not appear in a microscopic physical description.\nExperimental clues and discovery.\nBeginning in 1923, while using a Wilson cloud chamber to study the Compton effect, Dmitri Skobeltsyn observed tracks that acted like electrons but curved in the opposite direction in an applied magnetic field. Skobeltsyn presented photographs with this phenomenon in a conference in the University of Cambridge, on 23\u201327 July 1928.\nSimilar photographic evidence had been seen by Irene and Frederic Joliot-Curie and others but no one at the time had an explanation for these anomalous tracks. Skobeltsyn paved the way for the eventual discovery of the positron by two important contributions: adding a magnetic field to his cloud chamber (in 1925), and by discovering charged particle cosmic rays, for which he is credited in Carl David Anderson's Nobel lecture.\nLikewise, in 1929 Chung-Yao Chao, a Chinese graduate student at Caltech, noticed some anomalous results that indicated particles behaving like electrons, but with a positive charge, though the results were inconclusive and the phenomenon was not pursued. Fifty years later, Anderson acknowledged that his discovery was inspired by the work of his Caltech classmate Chung-Yao Chao. Anderson used the same radioactive source but adopted a magnet cloud chamber which allowed him to see the anti-electron tracks.\nAnderson discovered the positron on 2 August 1932, for which he won the Nobel Prize for Physics in 1936. Anderson did not coin the term \"positron\", but allowed it at the suggestion of the \"Physical Review\" journal editor to whom he submitted his discovery paper in late 1932. The positron was the first evidence of antimatter and was discovered when Anderson allowed cosmic rays to pass through a cloud chamber and a lead plate. A magnet surrounded this apparatus, causing particles to bend in different directions based on their electric charge. The ion trail left by each positron appeared on the photographic plate with a curvature matching the mass-to-charge ratio of an electron, but in a direction that showed its charge was positive.\nAnderson wrote in retrospect that the positron could have been discovered earlier based on Chung-Yao Chao's work, if only it had been followed up on. Fr\u00e9d\u00e9ric and Ir\u00e8ne Joliot-Curie in Paris had evidence of positrons in old photographs when Anderson's results came out, but they had dismissed them as protons.\nThe positron had also been contemporaneously discovered by Patrick Blackett and Giuseppe Occhialini at the Cavendish Laboratory in 1932. Blackett and Occhialini had delayed publication to obtain more solid evidence, so Anderson was able to publish the discovery first.\nNatural production.\nPositrons are produced, together with neutrinos naturally in \u03b2+ decays of naturally occurring radioactive isotopes (for example, potassium-40) and in interactions of gamma quanta (emitted by radioactive nuclei) with matter. Antineutrinos are another kind of antiparticle produced by natural radioactivity (\u03b2\u2212 decay). Many different kinds of antiparticles are also produced by (and contained in) cosmic rays. In research published in 2011 by the American Astronomical Society, positrons were discovered originating above thunderstorm clouds; positrons are produced in gamma-ray flashes created by electrons accelerated by strong electric fields in the clouds. Antiprotons have also been found to exist in the Van Allen Belts around the Earth by the PAMELA module.\nAntiparticles, of which the most common are antineutrinos and positrons due to their low mass, are also produced in any environment with a sufficiently high temperature (mean particle energy greater than the pair production threshold). During the period of baryogenesis, when the universe was extremely hot and dense, matter and antimatter were continually produced and annihilated. The presence of remaining matter, and absence of detectable remaining antimatter, also called baryon asymmetry, is attributed to CP-violation: a violation of the CP-symmetry relating matter to antimatter. The exact mechanism of this violation during baryogenesis remains a mystery.\nPositron production from radioactive decay can be considered both artificial and natural production, as the generation of the radioisotope can be natural or artificial. Perhaps the best known naturally occurring radioisotope which produces positrons is potassium-40, a long-lived isotope of potassium which occurs as a primordial isotope of potassium. Even though it is a small percentage of potassium (0.0117%), it is the single most abundant radioisotope in the human body. In a human body of mass, about 4,400 nuclei of 40K decay per second. The activity of natural potassium is 31 Bq/g. About 0.001% of these 40K decays produce about 4,000 natural positrons per day in the human body. These positrons soon find an electron, undergo annihilation, and produce pairs of 511 keV photons, in a process similar (but much lower intensity) to that which happens during a PET scan nuclear medicine procedure.\nRecent observations indicate black holes and neutron stars produce vast amounts of positron-electron plasma in astrophysical jets. Large clouds of positron-electron plasma have also been associated with neutron stars.\nObservation in cosmic rays.\nSatellite experiments have found evidence of positrons (as well as a few antiprotons) in primary cosmic rays, amounting to less than 1% of the particles in primary cosmic rays. However, the fraction of positrons in cosmic rays has been measured more recently with improved accuracy, especially at much higher energy levels, and the fraction of positrons has been seen to be greater in these higher energy cosmic rays.\nThese do not appear to be the products of large amounts of antimatter from the Big Bang, or indeed complex antimatter in the universe (evidence for which is lacking, see below). Rather, the antimatter in cosmic rays appear to consist of only these two elementary particles. Recent theories suggest the source of such positrons may come from annihilation of dark matter particles, acceleration of positrons to high energies in astrophysical objects, and production of high energy positrons in the interactions of cosmic ray nuclei with interstellar gas.\nPreliminary results from the presently operating Alpha Magnetic Spectrometer (\"AMS-02\") on board the International Space Station show that positrons in the cosmic rays arrive with no directionality, and with energies that range from 0.5 to 500 GeV. Positron fraction peaks at a maximum of about 16% of total electron+positron events, around an energy of 275 \u00b1 32 GeV. At higher energies, up to 500 GeV, the ratio of positrons to electrons begins to fall again. The absolute flux of positrons also begins to fall before 500 GeV, but peaks at energies far higher than electron energies, which peak about 10 GeV. These results on interpretation have been suggested to be due to positron production in annihilation events of massive dark matter particles.\nPositrons, like anti-protons, do not appear to originate from any hypothetical \"antimatter\" regions of the universe. On the contrary, there is no evidence of complex antimatter atomic nuclei, such as antihelium nuclei (i.e., anti-alpha particles), in cosmic rays. These are actively being searched for. A prototype of the \"AMS-02\" designated \"AMS-01\", was flown into space aboard the Space Shuttle \"Discovery\" on STS-91 in June 1998. By not detecting any antihelium at all, the \"AMS-01\" established an upper limit of 1.1\u00d710\u22126 for the antihelium to helium flux ratio.\nArtificial production.\nPhysicists at the Lawrence Livermore National Laboratory in California have used a short, ultra-intense laser to irradiate a millimeter-thick gold target and produce more than 100\u00a0billion positrons. Presently significant lab production of 5\u00a0MeV positron-electron beams allows investigation of multiple characteristics such as how different elements react to 5\u00a0MeV positron interactions or impacts, how energy is transferred to particles, and the shock effect of gamma-ray bursts.\nIn 2023, a collaboration between CERN and University of Oxford performed an experiment at the HiRadMat facility in which nano-second duration beams of electron-positron pairs were produced containing more than 10 trillion electron-positron pairs, so creating the first 'pair plasma' in the laboratory with sufficient density to support collective plasma behavior. Future experiments offer the possibility to study physics relevant to extreme astrophysical environments where copious electron-positron pairs are generated, such as gamma-ray bursts, fast radio bursts and blazar jets.\nApplications.\nCertain kinds of particle accelerator experiments involve colliding positrons and electrons at relativistic speeds. The high impact energy and the mutual annihilation of these matter/antimatter opposites create a fountain of diverse subatomic particles. Physicists study the results of these collisions to test theoretical predictions and to search for new kinds of particles.\nThe ALPHA experiment combines positrons with antiprotons to study properties of antihydrogen.\nGamma rays, emitted indirectly by a positron-emitting radionuclide (tracer), are detected in positron emission tomography (PET) scanners used in hospitals. PET scanners create detailed three-dimensional images of metabolic activity within the human body.\nAn experimental tool called positron annihilation spectroscopy (PAS) is used in materials research to detect variations in density, defects, displacements, or even voids, within a solid material.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24733", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=24733", "title": "Phencyclidine", "text": "Dissociative hallucinogenic drug, mostly used recreationally\n&lt;templatestyles src=\"Infobox drug/styles.css\"/&gt;\nPhencyclidine or phenylcyclohexyl piperidine (PCP), also known in its use as a street drug as angel dust among other names, is a dissociative anesthetic mainly used recreationally for its significant mind-altering effects. PCP may cause hallucinations, distorted perceptions of sounds, and psychotic behavior. As a recreational drug, it is typically smoked, but may be taken by mouth, snorted, or injected. It may also be mixed with cannabis or tobacco.\nAdverse effects may include paranoia, addiction, and an increased risk of suicide, as well as seizures and coma in cases of overdose. Flashbacks may occur despite stopping usage. Chemically, PCP is a member of the arylcyclohexylamine class. PCP works primarily as an NMDA receptor antagonist.\nPCP is most commonly used in the US. While usage peaked in the US in the 1970s, between 2005 and 2011, an increase in visits to emergency departments as a result of the drug occurred. As of 2022, in the US, about 0.7% of 12th-grade students reported using PCP in the prior year, while 1.7% of people in the US over age 25 reported using it at some point in their lives.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nRecreational uses.\nPhencyclidine is used for its ability to induce a dissociative state.\nEffects.\nBehavioral effects can vary by dosage. Low doses produce numbness in the extremities and intoxication, characterized by staggering, unsteady gait, slurred speech, bloodshot eyes, and loss of balance. Moderate doses (5\u201310\u00a0mg intranasal, or 0.01\u20130.02\u00a0mg/kg intramuscular or intravenous) will produce analgesia and anesthesia. High doses may lead to convulsions. The drug is often illegally produced under poorly controlled conditions; this means that users may be unaware of the actual dose they are taking.\nPsychological effects include severe changes in body image, loss of ego boundaries, paranoia, and depersonalization. Psychosis, agitation and dysphoria, hallucinations, blurred vision, euphoria, and suicidal impulses are also reported, as well as occasional aggressive behavior. PCP may induce feelings of strength, power, and invulnerability as well as a numbing effect on the mind.\nStudies by the Drug Abuse Warning Network in the 1970s show that media reports of PCP-induced violence are greatly exaggerated and that incidents of violence are unusual and often limited to individuals with reputations for aggression regardless of drug use. Although uncommon, events of PCP-intoxicated individuals acting in an unpredictable fashion, possibly driven by their delusions or hallucinations, have been publicized. Other commonly cited types of incidents include inflicting property damage and self-mutilation of various types, such as pulling out one's teeth. These effects were not noted in its medicinal use in the 1950s and 1960s, however, reports of physical violence on PCP have often been shown to be unfounded.\nRecreational doses of the drug also occasionally appear to induce a psychotic state, with emotional and cognitive impairment that resembles a schizophrenic episode. Users generally report feeling detached from reality.\nSymptoms are summarized by the mnemonic device RED DANES: rage, erythema (redness of skin), dilated pupils, delusions, amnesia, nystagmus (oscillation of the eyeball when moving laterally), excitation, and skin dryness.\nAddiction.\nPCP is self-administered and induces \u0394FosB expression in the D1-type medium spiny neurons of the nucleus accumbens, and accordingly, excessive PCP use is known to cause addiction. PCP's rewarding and reinforcing effects are at least partly mediated by blocking the NMDA receptors in the glutamatergic inputs to D1-type medium spiny neurons in the nucleus accumbens. PCP has been shown to produce conditioned place aversion and conditioned place preference in animal studies.\nSchizophrenia.\nA 2019 review found that the transition rate from a diagnosis of hallucinogen-induced psychosis (which included PCP) to that of schizophrenia was 26%. This was lower than cannabis-induced psychosis (34%) but higher than amphetamine- (22%), opioid- (12%), alcohol- (10%), and sedative-induced (9%) psychoses. In comparison, the transition rate to schizophrenia for \"brief, atypical and not otherwise specified\" psychosis was found to be 36%.\nMethods of administration.\nPCP has multiple routes of administration. Most commonly, the powder form of the drug is snorted. PCP can also be orally ingested, injected subcutaneously or intravenously, or smoked laced with marijuana or cigarettes.\nManagement of intoxication.\nManagement of PCP intoxication mostly consists of supportive care \u2013 controlling breathing, circulation, and body temperature \u2013 and, in the early stages, treating psychiatric symptoms. Benzodiazepines, such as lorazepam, are the drugs of choice to control agitation and seizures (when present). Typical antipsychotics such as phenothiazines and haloperidol have been used to control psychotic symptoms, but may produce many undesirable side effects \u2013 such as dystonia \u2013 and their use is therefore no longer preferred; phenothiazines are particularly risky, as they may lower the seizure threshold, worsen hyperthermia, and boost the anticholinergic effects of PCP. If an antipsychotic is given, intramuscular haloperidol has been recommended.\nForced acid diuresis (with ammonium chloride or, more safely, ascorbic acid) may increase the clearance of PCP from the body, and was somewhat controversially recommended in the past as a decontamination measure. However, it is now known that only around 10% of a dose of PCP is removed by the kidneys, which would make increased urinary clearance of little consequence; furthermore, urinary acidification is dangerous, as it may induce acidosis and worsen rhabdomyolysis (muscle breakdown), a not-unusual manifestation of PCP toxicity.\nPharmacology.\nPharmacodynamics.\nPCP is well known for its primary action on the NMDA receptor, an ionotropic glutamate receptor. As such, PCP is a non-competitive NMDA receptor antagonist. The role of NMDAR antagonism in the effect of PCP, ketamine, and related dissociative agents was first published in the early 1980s by David Lodge and colleagues. Other NMDA receptor antagonists include ketamine, tiletamine, dextromethorphan, nitrous oxide, and dizocilpine (MK-801).\nResearch also indicates that PCP inhibits nicotinic acetylcholine receptors (nAChRs) among other mechanisms. Analogues of PCP exhibit varying potency at nACh receptors and NMDA receptors. Findings demonstrate that presynaptic nAChRs and NMDA receptor interactions influence the postsynaptic maturation of glutamatergic synapses and consequently impact synaptic development and plasticity in the brain. These effects can lead to inhibition of excitatory glutamate activity in certain brain regions such as the hippocampus and cerebellum thus potentially leading to memory loss as one of the effects of prolonged use. Acute effects on the cerebellum manifest as changes in blood pressure, breathing rate, pulse rate, and loss of muscular coordination during intoxication.\nPCP, like ketamine, also acts as a potent dopamine D2High receptor partial agonist in rat brain homogenate and has affinity for the human cloned D2High receptor. This activity may be associated with some of the other more psychotic features of PCP intoxication, which is evidenced by the successful use of D2 receptor antagonists (such as haloperidol) in the treatment of PCP psychosis.\nIn addition to its well-explored interactions with NMDA receptors, PCP has also been shown to inhibit dopamine reuptake, and thereby leads to increased extracellular levels of dopamine and hence increased dopaminergic neurotransmission. However, PCP has little affinity for the human monoamine transporters, including the dopamine transporter (DAT). Instead, its inhibition of monoamine reuptake may be mediated by interactions with allosteric sites on the monoamine transporters. PCP is notably a high-affinity ligand of the PCP site 2 (Ki = 154\u00a0nM), a not-well-characterized site associated with monoamine reuptake inhibition.\nStudies on rats indicate that PCP interacts indirectly with opioid receptors (endorphin and enkephalin) to produce analgesia.\nA binding study assessed PCP at 56\u00a0sites including neurotransmitter receptors and transporters and found that PCP had Ki values of &gt;10,000\u00a0nM at all sites except the dizocilpine (MK-801) site of the NMDA receptor (Ki = 59\u00a0nM), the \u03c32 receptor (PC12) (Ki = 136\u00a0nM), and the serotonin transporter (Ki = 2,234\u00a0nM). The study notably found Ki values of &gt;10,000\u00a0nM for the D2 receptor, the opioid receptors, the \u03c31 receptor, and the dopamine and norepinephrine transporters. These results suggest that PCP is a highly selective ligand of the NMDAR and \u03c32 receptor. However, PCP may also interact with allosteric sites on the monoamine transporters to produce inhibition of monoamine reuptake.\nMechanism of action.\nPhencyclidine is a noncompetitive NMDA receptor antagonist that blocks the activity of the NMDA receptor to cause anaesthesia and analgesia without causing cardiorespiratory depression. NMDA is an excitatory receptor in the brain, when activated normally the receptor acts as an ion channel and there is an influx of positive ions through the channel to cause nerve cell depolarisation. Phencyclidine inhibits the NMDA receptor by binding to the specific PCP binding site located within the ion channel. The PCP binding site is near the magnesium blocking site, which may explain the similar inhibitory effects. Binding at the PCP site is mediated by two non-covalent interactions within the receptor: hydrogen bonding and hydrophobic interaction. Binding is also controlled by the gating mechanism of the ion channel. Because the PCP site is located within the ion channel, a coagonist such as glycine must bind and open the channel for PCP to enter, bind to the PCP site, and block the channel.\nNeurotoxicity.\nSome studies found that, like other NMDA receptor antagonists, PCP can cause a kind of brain damage called Olney's lesions in rats. Studies conducted on rats showed that high doses of the NMDA receptor antagonist dizocilpine caused reversible vacuoles to form in certain regions of the rats' brains. All studies of Olney's lesions have only been performed on non-human animals and may not apply to humans. One unpublished study by Frank Sharp reportedly showed no damage by the NMDA antagonist ketamine, a structurally similar drug, far beyond recreational doses, but due to the study never having been published, its validity is controversial.\nPCP has also been shown to cause schizophrenia-like changes in \"N\"-acetylaspartate and \"N\"-acetylaspartylglutamate levels in the rat brain, which are detectable both in living rats and upon necropsy examination of brain tissue. It also induces symptoms in humans that mimic schizophrenia. PCP not only produced symptoms similar to schizophrenia, it also yielded electroencephalogram changes in the thalamocortical pathway (increased delta decreased alpha) and in the hippocampus (increase theta bursts) that were similar to those in schizophrenia. PCP-induced augmentation of dopamine release may link the NMDA and dopamine hypotheses of schizophrenia.\nPharmacokinetics.\nPCP is both water- and lipid-soluble and is therefore distributed throughout the body quickly. PCP is metabolized into PCHP, PPC and PCAA. The drug is metabolized 90% by oxidative hydroxylation in the liver during the first pass. Metabolites are glucuronidated and excreted in the urine. Nine percent of ingested PCP is excreted in its unchanged form.\nWhen smoked, some of the compound is broken down by heat into 1-phenylcyclohexene (PC) and piperidine.\nThe time taken before the effects of PCP manifest is dependent on the route of administration. The onset of action for inhalation occurs in 2\u20135 minutes, whereas the effects may take 15 to 60 minutes when ingested orally.\nChemistry.\nPCP is an arylcyclohexylamine.\nAnalogues.\nFewer than 30 different analogs of PCP were reported as being used as a street drug during the 1970s and 1980s, mainly in the United States. Only a few of these compounds were widely used, including rolicyclidine (PCPy), eticyclidine (PCE), and tenocyclidine (TCP). Less common analogs include 3-HO-PCP, 3-MeO-PCMo, and 3-MeO-PCP.\nThe generalized structural motif required for PCP-like activity is derived from structure-activity relationship studies of PCP derivatives. All of these derivatives are likely to share some of their psychoactive effects with PCP itself, although a range of potencies and varying mixtures of anesthetic, dissociative, and stimulant effects are known, depending on the particular drug and its substituents. In the United States, all of these compounds would be considered controlled substance analogs of PCP under the Federal Analog Act and are hence illegal drugs if sold for human consumption.\nHistory.\nPhencyclidine was initially discovered in 1926 by Arthur K\u00f6tz and his student Paul Merkel as a product of a Grignard reaction of 1-piperidinocyclohexancarbonitrile.\nIt was again synthesized in 1956 by chemist H Victor Maddox and brought to market as an anesthetic medication by pharmaceutical company Parke-Davis, now a subsidiary of Pfizer. Its use in humans was disallowed in the US in 1965 due to the high rates of side effects, while its use in animals was disallowed in 1978. Moreover, ketamine was discovered and was better tolerated as an anesthetic. \nPCP is classified as a schedule II drug in the US. Derivatives of PCP have been sold for recreational and non-medical use.\nSociety and culture.\nRegulation.\nPCP is a Schedule II substance in the US. The Administrative Controlled Substances Code Number (ACSCN) for PCP is 7471. Its manufacturing quota for 2014 was . It is a Schedule I drug by the Controlled Drugs and Substances act in Canada, a List I drug of the Opium Law in the Netherlands, and a Class A substance in the UK.\nFrequency of use.\nPCP began to emerge as a recreational drug in major cities in the US in the 1960s. In 1978, \"People\" magazine and Mike Wallace of the TV news program \"60 Minutes\" called PCP the country's \"number one drug problem\". Although recreational use of the drug had always been relatively low, it began declining significantly in the 1980s. In surveys, the number of high school students admitting to trying PCP at least once fell from 13% in 1979 to less than 3% in 1990.\nCultural depictions.\nJean-Michel Basquiat depicted two angel dust users in his 1982 painting \"Dustheads\".\nTsukasa Hojo's 1985 manga \"City Hunter\" features a drug, Angel Dust, presumably a reference to PCP's street name. The related 2023 animated film, \"\", more directly moved the franchise's angel dust into the realm of fantasy, as it is portrayed as a science fiction nanomachine serum developed by a biotech company to create super-soldiers with a tendency to drive them berserk, side-stepping the real-life PCP. \nIn Vivienne Medrano's adult animated musical comedy television series \"Hazbin Hotel\", Angel Dust is an adult film star in Hell and one of the main protagonists, who in Hell took on the name \"Angel Dust\" as his chosen all-encompassing persona name, and one he uses exclusively in place of his actual name. It is intended as multipurpose for both his drag queen persona and his sex-work persona.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24734", "revid": "32423925", "url": "https://en.wikipedia.org/wiki?curid=24734", "title": "Product of group subsets", "text": "Operation in group theory\nIn mathematics, one can define a product of group subsets in a natural way. If \"S\" and \"T\" are subsets of a group \"G\", then their product is the subset of \"G\" defined by\nformula_1\nThe subsets \"S\" and \"T\" need not be subgroups for this product to be well defined. The associativity of this product follows from that of the group product. The product of group subsets therefore defines a natural monoid structure on the power set of \"G\".\nA lot more can be said in the case where \"S\" and \"T\" are subgroups. The product of two subgroups \"S\" and \"T\" of a group \"G\" is itself a subgroup of \"G\" if and only if \"ST\" = \"TS\".\nProduct of subgroups.\nIf \"S\" and \"T\" are subgroups of \"G\", their product need not be a subgroup (for example, two distinct subgroups of order 2 in the symmetric group on 3 symbols). This product is sometimes called the \"Frobenius product\". In general, the product of two subgroups \"S\" and \"T\" is a subgroup if and only if \"ST\" = \"TS\", and the two subgroups are said to permute. (Walter Ledermann has called this fact the \"Product Theorem\", but this name, just like \"Frobenius product\" is by no means standard.) In this case, \"ST\" is the group generated by \"S\" and \"T\"; i.e., \"ST\" = \"TS\" = \u27e8\"S\" \u222a \"T\"\u27e9.\nIf either \"S\" or \"T\" is normal then the condition \"ST\" = \"TS\" is satisfied and the product is a subgroup. If both \"S\" and \"T\" are normal, then the product is normal as well.\nIf \"S\" and \"T\" are finite subgroups of a group \"G\", then \"ST\" is a subset of \"G\" of size \"|ST|\" given by the \"product formula\":\nformula_2\nNote that this applies even if neither \"S\" nor \"T\" is normal.\nModular law.\nThe following modular law (for groups) holds for any \"Q\" a subgroup of \"S\", where \"T\" is any other arbitrary subgroup (and both \"S\" and \"T\" are subgroups of some group \"G\"):\n\"Q\"(\"S\" \u2229 \"T\") = \"S\" \u2229 (\"QT\").\nThe two products that appear in this equality are not necessarily subgroups.\nIf \"QT\" is a subgroup (equivalently, as noted above, if \"Q\" and \"T\" permute) then \"QT\" = \u27e8\"Q\" \u222a \"T\"\u27e9 = \"Q\" \u2228 \"T\"; i.e., \"QT\" is the join of \"Q\" and \"T\" in the lattice of subgroups of \"G\", and the modular law for such a pair may also be written as \"Q\" \u2228 (\"S\" \u2229 \"T\") = \"S\" \u2229 (\"Q \u2228 T\"), which is the equation that defines a modular lattice if it holds for any three elements of the lattice with \"Q\" \u2264 \"S\". In particular, since normal subgroups permute with each other, they form a modular sublattice.\nA group in which every subgroup permutes is called an Iwasawa group. The subgroup lattice of an Iwasawa group is thus a modular lattice, so these groups are sometimes called \"modular groups\" (although this latter term may have other meanings.)\nThe assumption in the modular law for groups (as formulated above) that \"Q\" is a subgroup of \"S\" is essential. If \"Q\" is \"not\" a subgroup of \"S\", then the tentative, more general distributive property that one may consider \"S\" \u2229 (\"QT\") = (\"S\" \u2229 \"Q\")(\"S\" \u2229 \"T\") is \"false\".\nProduct of subgroups with trivial intersection.\nIn particular, if \"S\" and \"T\" intersect only in the identity, then every element of \"ST\" has a unique expression as a product \"st\" with \"s\" in \"S\" and \"t\" in \"T\". If \"S\" and \"T\" also commute, then \"ST\" is a group, and is called a Zappa\u2013Sz\u00e9p product. Even further, if \"S\" or \"T\" is normal in \"ST\", then \"ST\" coincides with the semidirect product of \"S\" and \"T\". Finally, if both \"S\" and \"T\" are normal in \"ST\", then \"ST\" coincides with the direct product of \"S\" and \"T\".\nIf \"S\" and \"T\" are subgroups whose intersection is the trivial subgroup (identity element) and additionally \"ST\" = \"G\", then \"S\" is called a complement of \"T\" and vice versa.\nBy a (locally unambiguous) abuse of terminology, two subgroups that intersect only on the (otherwise obligatory) identity are sometimes called disjoint.\nProduct of subgroups with non-trivial intersection.\nA question that arises in the case of a non-trivial intersection between a normal subgroup \"N\" and a subgroup \"K\" is what is the structure of the quotient \"NK\"/\"N\". Although one might be tempted to just \"cancel out\" \"N\" and say the answer is \"K\", that is not correct because a homomorphism with kernel \"N\" will also \"collapse\" (map to 1) all elements of \"K\" that happen to be in \"N\". Thus the correct answer is that \"NK\"/\"N\" is isomorphic with \"K\"/(\"N\"\u2229\"K\"). This fact is sometimes called the second isomorphism theorem, (although the numbering of these theorems sees some variation between authors); it has also been called the \"diamond theorem\" by I. Martin Isaacs because of the shape of subgroup lattice involved, and has also been called the \"parallelogram rule\" by Paul Moritz Cohn, who thus emphasized analogy with the parallelogram rule for vectors because in the resulting subgroup lattice the two sides assumed to represent the quotient groups (\"SN\")\u00a0/\u00a0\"N\" and \"S\"\u00a0/\u00a0(\"S\"\u00a0\u2229\u00a0\"N\") are \"equal\" in the sense of isomorphism.\nFrattini's argument guarantees the existence of a product of subgroups (giving rise to the whole group) in a case where the intersection is not necessarily trivial (and for this latter reason the two subgroups are not complements). More specifically, if \"G\" is a finite group with normal subgroup \"N\", and if \"P\" is a Sylow \"p\"-subgroup of \"N\", then \"G\" = \"N\"\"G\"(\"P\")\"N\", where \"N\"\"G\"(\"P\") denotes the normalizer of \"P\" in \"G\". (Note that the normalizer of \"P\" includes \"P\", so the intersection between \"N\" and \"N\"\"G\"(\"P\") is at least \"P\".)\nGeneralization to semigroups.\nIn a semigroup S, the product of two subsets defines a structure of a semigroup on P(S), the power set of the semigroup S; furthermore P(S) is a semiring with addition as union (of subsets) and multiplication as product of subsets.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24736", "revid": "49376051", "url": "https://en.wikipedia.org/wiki?curid=24736", "title": "PCHP", "text": "&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\n1-(1-Phenylcyclohexyl)-4-hydroxypiperidine (PCHP) is a metabolite of phencyclidine (PCP). PCHP can be detected in the hair, urine, stool, sweat, and saliva of PCP users.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24737", "revid": "49376051", "url": "https://en.wikipedia.org/wiki?curid=24737", "title": "4-Phenyl-4-(1-piperidinyl)cyclohexanol", "text": "&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\n4-Phenyl-4-(1-piperidinyl)cyclohexanol, also known as PPC, is an organic chemical which is a metabolite of phencyclidine (PCP). It can be detected in the hair of PCP users.\nPPC has been shown to cause increases in locomotor activity in lab mice.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24738", "revid": "49376051", "url": "https://en.wikipedia.org/wiki?curid=24738", "title": "PCAA", "text": "Metabolite of phencyclidine (PCP)\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nPCAA, or 5-[\"N\"-(1-phenylcyclohexyl)amino]pentanoic acid, is a metabolite of phencyclidine (PCP). It can be detected in the urine of PCP users by mass spectrometry as means of drug screening.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24739", "revid": "14213219", "url": "https://en.wikipedia.org/wiki?curid=24739", "title": "Piperidine", "text": "&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nPiperidine is an organic compound with the molecular formula (CH2)5NH. This heterocyclic amine consists of a six-membered ring containing five methylene bridges (\u2013CH2\u2013) and one amine bridge (\u2013NH\u2013). It is a colorless liquid with an odor described as objectionable, typical of amines. The name comes from the genus name \"Piper\", which is the Latin word for pepper. Although piperidine is a common organic compound, it is best known as a representative structure element within many pharmaceuticals and alkaloids, such as natural-occurring solenopsins.\nProduction.\nPiperidine was first reported in 1850 by the Scottish chemist Thomas Anderson and again, independently, in 1852 by the French chemist Auguste Cahours, who named it. Both of them obtained piperidine by reacting piperine with nitric acid.\nIndustrially, piperidine is produced by the hydrogenation of pyridine, usually over a molybdenum disulfide catalyst:\n C5H5N + 3\u00a0H2 \u2192 C5H10NH\nPyridine can also be reduced to piperidine via a modified Birch reduction using sodium in ethanol.\nNatural occurrence of piperidine and derivatives.\nPiperidine itself has been obtained from black pepper, from \"Psilocaulon absimile\" (Aizoaceae), and in \"Petrosimonia monandra\".\nThe piperidine structural motif is present in numerous natural alkaloids. These include piperine, which gives black pepper its spicy taste. This gave the compound its name. Other examples are the fire ant toxin solenopsin, the nicotine analog anabasine of tree tobacco (\"Nicotiana glauca\"), lobeline of Indian tobacco, and the toxic alkaloid coniine from poison hemlock, which was used to put Socrates to death.\nConformation.\nPiperidine prefers a chair conformation, similar to cyclohexane. Unlike cyclohexane, piperidine has two distinguishable chair conformations: one with the N\u2013H bond in an axial position, and the other in an equatorial position. After much controversy during the 1950s\u20131970s, the equatorial conformation was found to be more stable by 0.72\u00a0kcal/mol in the gas phase. In nonpolar solvents, a range between 0.2 and 0.6\u00a0kcal/mol has been estimated, but in polar solvents the axial conformer may be more stable. The two conformers interconvert rapidly through nitrogen inversion; the free energy activation barrier for this process, estimated at 6.1\u00a0kcal/mol, is substantially lower than the 10.4\u00a0kcal/mol for ring inversion. In the case of \"N\"-methylpiperidine, the equatorial conformation is preferred by 3.16\u00a0kcal/mol, which is much larger than the preference in methylcyclohexane, 1.74\u00a0kcal/mol.\nReactions.\nPiperidine is widely used to convert ketones to enamines. Enamines derived from piperidine are substrates in the Stork enamine alkylation reaction.\nUpon treatment with calcium hypochlorite, piperidine converts to N-chloropiperidine, a chloramine with the formula C5H10NCl. The resulting chloramine undergoes dehydrohalogenation to afford the cyclic imine.\nUses.\nPiperidine is used as a solvent and as a base. The same is true for certain derivatives: \"N\"-formylpiperidine is a polar aprotic solvent with better hydrocarbon solubility than other amide solvents, and 2,2,6,6-tetramethylpiperidine is a highly sterically hindered base, useful because of its low nucleophilicity and high solubility in organic solvents.\nA significant industrial application of piperidine is for the production of dipiperidinyl dithiuram tetrasulfide, which is used as an accelerator of the sulfur vulcanization of rubber.\nList of piperidine medications.\nPiperidine and its derivatives are ubiquitous building blocks in pharmaceuticals and fine chemicals. The piperidine structure is found in, for example:\nPiperidine is also commonly used in chemical degradation reactions, such as the sequencing of DNA in the cleavage of particular modified nucleotides. Piperidine is also commonly used as a base for the deprotection of Fmoc-amino acids used in solid-phase peptide synthesis.\nPiperidine is listed as a Table II precursor under the United Nations Convention Against Illicit Traffic in Narcotic Drugs and Psychotropic Substances due to its use (peaking in the 1970s) in the clandestine manufacture of phencyclidine.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24740", "revid": "274040", "url": "https://en.wikipedia.org/wiki?curid=24740", "title": "Political question", "text": "Legal doctrine of political matters' justiciability\nIn United States constitutional law, the political question doctrine holds that a constitutional dispute requiring knowledge of a non-legal character, techniques not suitable for a court, or matters explicitly assigned by the Constitution to Legislative or Executive branches lies within the political realm, rather than the judiciary. Judges customarily refuse to address such matters as a matter of justiciability, questioning whether their courts are an appropriate forum for the case. Legal questions are deemed justiciable, while political questions are nonjusticiable. One scholar explained:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The political question doctrine holds that some questions, in their nature, are fundamentally political, and not legal, and if a question is fundamentally political ... then the court will refuse to hear that case. It will claim that it doesn't have jurisdiction. And it will leave that question to some other aspect of the political process to settle out.\nA ruling of nonjusticiability prevents a case's core issue from being resolved in a court of law. When the issue involves duties not addressed by the Constitution, courts leave it to the democratic process, rather than resolving political disputes themselves.\nOrigin.\nThe doctrine can be traced to the landmark Supreme Court ruling in \"Marbury v. Madison\" (1803). In that case, Chief Justice John Marshall distinguished between the US Secretary of State's legal work and purely discretionary political tasks, only the former of which involves legally identifiable standards that can be reviewed by a court of law. Marshall argued that courts should generally not hear cases that involve political questions without implicating individual rights, though later decisions allowed the doctrine's application in cases that do implicate individual rights.\nFormer Associate Justice Stephen Breyer further traces this doctrine to the Roman statesman Cicero's observation that \"when the cannons roar, the laws fall silent,\" such that politicians are granted leeway to violate the written law amid political emergencies like internal rebellion and external warfare. In Breyer's view, rather than making such political acts non-reviewable, the Constitution of the United States delegates that authority to Congress by empowering it to impeach presidents for violating their oath of office.\nDoctrine.\nUnlike the rules of standing, ripeness, and mootness, when the political question doctrine applies, a particular question is beyond judicial competence no matter who raises it, how immediate the interests it affects, or how burning the controversy. The doctrine is grounded in the separation of powers, as well as the federal judiciary's desire to avoid inserting itself into conflicts between branches of the federal government. It is justified as leaving political questions to the political process, in which voters can indirectly approve or reject the challenged action through voting.\nThe leading Supreme Court case on the political question doctrine is \"Baker v. Carr\" (1962). In that case, the Supreme Court held that an unequal apportionment of a state legislature may have denied equal protection and presented a justiciable issue. In \"Baker\", the Court outlined six characteristics \"[p]rominent on the surface of any case held to involve a political question\":\nThe first factor\u2014a textually demonstrable commitment to another branch\u2014is the classical view that the Court must decide all cases and issues before it unless, as a matter of constitutional interpretation, the Constitution itself commits the issue to another branch of government. The second and third factors\u2014lack of judicially discoverable standards and involvement of the judiciary in nonjudicial policy determinations\u2014suggest a functional approach, based on practical considerations of how government ought to work. The final three factors\u2014lack of respect for other branches, need for adherence to a political decision already made, and possibility of embarrassment\u2014are based on the Court's prudential consideration against overexertion or aggrandizement.\nOther applications.\nWhile the scope of the political question doctrine is still unsettled, its application has been mostly settled in a few decided areas. These areas are:\nGuarantee Clause.\nThe Guarantee Clause of the US Constitution requires the federal government to \"guarantee to every State in this Union a Republican Form of Government.\" The Supreme Court has ruled that this clause does not imply any set of \"judicially manageable standards which a court could utilize independently in order to identify a State's lawful government.\" On this ground, the Court refused to identify the legitimate government of Rhode Island during the Dorr Rebellion in \"Luther v. Borden\" (1849). Since then, the Court has consistently refused to resort to the Guarantee Clause as a constitutional source for invalidating state action, such as whether it is lawful for states to adopt laws through referendums.\nImpeachment.\nArticle I, Section 2 of the Constitution states that the House \"shall have the sole power of Impeachment,\" and Article I, Section 3 provides that the \"Senate shall have the sole Power to try all Impeachments.\" Since the Constitution placed the sole power of impeachment in two political bodies, it is qualified as a political question. As a result, neither the decision of the House to impeach, nor of the Senate to remove a President or any other official, can be appealed to any court.\nForeign policy, national security and war.\nA court will not usually decide if a treaty has been terminated because \"governmental action [...] must be regarded as of controlling importance.\" However, courts sometimes do rule on the issue. One example of this is native American tribes who have been officially terminated do not lose their treaty concessions without explicit text from Congress that the treaty is also abrogated.\nIn the case of \"bin Ali Jaber v. United States\" (2017), the plaintiffs filed a lawsuit under the Torture Victim Protection Act of 1991 after a 2012 US drone strike killed five civilians. The District of Columbia Court of Appeals dismissed the plaintiffs' claims on the basis that the \"plaintiffs challenged the type of executive decision found nonjusticiable in \"El-Shifa Pharmaceutical Industries Co. v. United States\" (2010).\" In \"El-Shifa\", the court distinguished \"between claims questioning the wisdom of military action, 'a policy choice . . . constitutionally committed' to the political branches, and 'legal issues such as whether the government had legal authority to act.'\" Thus, the court held that the plaintiffs' argument required the court to make a policy decision.\nGerrymandering.\nIn cases like \"Davis v. Bandemer\" (1986), \"Vieth v. Jubelirer\" (2004), and \"Gill v. Whitford\" (2018), the Supreme Court had repeatedly treated partisan gerrymandering as judiciable, but it remained unable to agree on a majority standard for deciding such cases. In \"Rucho v. Common Cause\" (2019), the Supreme Court ultimately reversed itself, deciding that partisan gerrymandering was a purely political question.\nPrivate military contractors.\nIn the case of \"Ghane v. Mid-South\" (January 16, 2014), the Mississippi Supreme Court held that a wrongful death action against a private military company by the family of a deceased United States Navy SEAL could proceed under Mississippi law since the plaintiff's claims did not present a non-justiciable political question under \"Baker v. Carr\" (1962).\nCourt cases.\nUS Supreme Court cases discussing the political question doctrine:\nInternational use.\nFrance.\nA type of act by the French government, the \"\", avoids judicial review as it is too politically sensitive. While the scope of the concept has been reduced over time, there are still acts that the courts do not have jurisdiction over, such as matters that are deemed to be unseverable from France's diplomatic acts, like the President's decision to conduct tests of nuclear weapons or end foreign aid. Other acts include the President's decision to dissolve Parliament, award honors, or grant amnesty. Such \"actes de gouvernement\" need to be politically-based and also concern domains in which the courts are not competent to judge.\nJapan.\nThe postwar constitution gave the Supreme Court of Japan the power of judicial review. The court developed its own political question doctrine (; t\u014dchik\u014di), in part to avoid interpreting Article 9 of the post-war pacifist constitution, which renounces war and the threat or use of force. Issues arising under Article 9 have included include the legitimacy of Japan's Self-Defense Force, the Treaty of Mutual Cooperation and Security between the United States and Japan, and the stationing of American forces in Japan.\nThe \"Sunagawa case\" is considered the leading precedent on the political question doctrine in Japan. In 1957, demonstrators entered a then-American military base in the Tokyo suburb of Sunagawa, violating a special Japanese criminal law based on the US-Japan Security Treaty. A Tokyo District Court found that the US military's presence in Japan were unconstitutional under Article 9 of the Constitution and acquitted the defendants. The Japanese Supreme Court overturned the district court in a fast-track appeal, implicitly developing the political question doctrine in the ruling. The Court found it inappropriate for the judiciary to judge the constitutionality of highly political matters like the US-Japan Security Treaty, unless they expressly violate the Constitution. On the Security Treaty, the Court saw \"an extremely high degree of political consideration,\" and \"there is a certain element of incompatibility in the process of judicial determination of its constitutionality by a court of law which has as its mission the exercise of the purely judicial function.\" It therefore found that the question should be resolved by the Cabinet, Diet, and people through elections. The presence of American forces was held to not violate Article 9 because they were not under Japanese command. The political question doctrine has remained a barrier for challenges under Article 9. Under the \"clear mistake\" rule developed by the Court, it defers to the political branches on Article 9 issues so long as the act is \"not obviously unconstitutional and void.\"\nOther notable cases on the political question doctrine in Japan include the \"Tomabechi case\", which concerned whether the dissolution of the Diet was valid. In the \"Tomabechi\" case, the Court also decided against judicial review by implicitly invoking the political question doctrine, citing the separation of powers as justification. In addition, the Court announced that in political question cases not related to Article 9, the clear mistake rule does not apply and judicial review is categorically prohibited.\nSwitzerland.\nIn 2007, Taiwan filed a lawsuit before a Swiss civil court against the International Organization for Standardization, arguing that the ISO's use of the United Nations name \"Taiwan, Province of China\" rather than \"Republic of China (Taiwan)\" violated Taiwan's name rights. On 9 September 2010, a panel of the Federal Supreme Court of Switzerland decided, by three votes to two, to dismiss the suit as presenting a political question not subject to Swiss civil jurisdiction.\nTaiwan.\nIn November 1993, the Judicial Yuan, the judicial branch of Taiwan, interpreted that the delimitation of national territory would be a significant political question beyond the reach of judicial review.\nInternational law.\nThe International Court of Justice has dealt with the doctrine in its advisory function, and the European Court of Human Rights has engaged with the doctrine through the margin of appreciation. The Court of Justice of the European Union has never explicitly addressed the political question doctrine in its jurisprudence, yet it has been argued that there are traces of the doctrine present in its rulings.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24741", "revid": "33145", "url": "https://en.wikipedia.org/wiki?curid=24741", "title": "Planetary sciences", "text": ""}
{"id": "24742", "revid": "38498667", "url": "https://en.wikipedia.org/wiki?curid=24742", "title": "Paul Dirac", "text": "British theoretical physicist (1902\u20131984)\nPaul Adrien Maurice Dirac ( ; 8 August 1902 \u2013 20 October 1984) was a British theoretical physicist who is considered to be one of the founders of quantum mechanics. Dirac laid the foundations for both quantum electrodynamics and quantum field theory. He was the Lucasian Professor of Mathematics at the University of Cambridge from 1932 to 1969, and a professor of physics at Florida State University from 1970 to 1984. Dirac shared the 1933 Nobel Prize in Physics with Erwin Schr\u00f6dinger \"for the discovery of new productive forms of atomic theory.\"\nDirac graduated from the University of Bristol with a First Class Honours Bachelor of Science degree in electrical engineering in 1921, and a first class honours Bachelor of Arts degree in mathematics in 1923. Dirac then graduated from St John's College, Cambridge, with a Ph.D. in Physics in 1926, writing the first ever thesis on quantum mechanics.\nDirac made fundamental contributions to the early development of both quantum mechanics and quantum electrodynamics, coining the latter term. Among other discoveries, he formulated the Dirac equation in 1928. It connected special relativity and quantum mechanics and predicted the existence of antimatter. The Dirac equation is one of the most important results in physics, regarded by some physicists as the \"real seed of modern physics\". He wrote a famous paper in 1931, which further predicted the existence of antimatter. Dirac also contributed greatly to the reconciliation of general relativity with quantum mechanics. He contributed to Fermi\u2013Dirac statistics, which describes the behaviour of fermions, particles with half-integer spin. His 1930 monograph, \"The\" \"Principles of Quantum Mechanics\", is one of the most influential texts on the subject.\nIn 1987, Abdus Salam declared that \"Dirac was undoubtedly one of the greatest physicists of this or any century ... No man except Einstein has had such a decisive influence, in so short a time, on the course of physics in this century.\" In 1995, Stephen Hawking stated that \"Dirac has done more than anyone this century, with the exception of Einstein, to advance physics and change our picture of the universe.\" Antonino Zichichi asserted that Dirac had a greater impact on modern physics than Einstein, while Stanley Deser remarked that \"We all stand on Dirac's shoulders.\"\nEarly life.\nPaul Adrien Maurice Dirac was born on 8 August 1902 at his parents' home in Bristol, England, and grew up in the Bishopston area of the city. His father, Charles Adrien Ladislas Dirac, was an immigrant from Saint-Maurice, Switzerland, of French descent, who worked in Bristol as a French teacher. His mother, Florence Hannah Holten, was born to a Cornish Methodist family in Liskeard, Cornwall. She was named after Florence Nightingale by her father, a ship's captain, who had met Nightingale while he was a soldier during the Crimean War. His mother moved to Bristol as a young woman, where she worked as a librarian at the Bristol Central Library; despite this she still considered her identity to be Cornish rather than English. Paul had a younger sister, B\u00e9atrice Isabelle Marguerite, known as Betty, and an older brother, Reginald Charles F\u00e9lix, known as Felix, who died by suicide in March 1925. Dirac later recalled: \"My parents were terribly distressed. I didn't know they cared so much ... I never knew that parents were supposed to care for their children, but from then on I knew.\"\nCharles and the children were officially Swiss nationals until they became naturalised on 22 October 1919. Dirac's father was strict and authoritarian, although he disapproved of corporal punishment. Dirac had a strained relationship with his father, so much so that after his father's death, Dirac wrote, \"I feel much freer now, and I am my own man.\" Charles forced his children to speak to him only in French so that they might learn the language. When Dirac found that he could not express what he wanted to say in French, he chose to remain silent.\nEducation.\nDirac was educated first at Bishop Road Primary School and then at the all-boys Merchant Venturers' Technical College (later Cotham School), where his father was a French teacher. The school was an institution attached to the University of Bristol, which shared grounds and staff. It emphasised technical subjects like bricklaying, shoemaking and metalwork, and modern languages. This was unusual at a time when secondary education in Britain was still dedicated largely to the classics, and something for which Dirac would later express his gratitude. One of his peers at Bishop Road School was Archibald Leach, later famous as Cary Grant.\nDirac studied electrical engineering on a City of Bristol University Scholarship at the University of Bristol's engineering faculty, which was co-located with the Merchant Venturers' Technical College. Shortly before he completed his degree in 1921, he sat for the entrance examination for St John's College, Cambridge. He passed and was awarded a \u00a370 scholarship, but this fell short of the amount of money required to live and study at Cambridge. Despite having graduated with a first class honours B.Sc. in electrical engineering, the economic climate of the post-war depression was such that he was unable to find work as an engineer. Instead, he took up an offer to study for a B.A. in mathematics at the University of Bristol free of charge. He was permitted to skip the first year of the course owing to his engineering degree. Under the influence of Peter Fraser, whom Dirac called the best mathematics teacher, he had the most interest in projective geometry, and began applying it to the geometrical version of relativity Hermann Minkowski developed.\nIn 1923, Dirac graduated, once again with first class honours, and received a \u00a3140 scholarship from the Department of Scientific and Industrial Research. Along with his \u00a370 scholarship from St John's College, this was enough to live at Cambridge. There, Dirac pursued his interests in the theory of general relativity, an interest he had gained earlier as a student in Bristol, and in the nascent field of quantum physics, under the supervision of Ralph Fowler. From 1925 to 1928, he held an 1851 Research Fellowship from the Royal Commission for the Exhibition of 1851. He completed his Ph.D. in June 1926 with the first thesis on quantum mechanics to be submitted anywhere. He then continued his research in Copenhagen and G\u00f6ttingen. In the spring of 1929, he was a visiting professor at the University of Wisconsin\u2013Madison.\nPersonal life.\nFamily.\nIn 1937, Dirac married Margit Wigner, the sister of physicist Eugene Wigner and a divorcee. Dirac raised Margit's two children, Judith and Gabriel, as if they were his own. Paul and Margit Dirac also had two daughters together, Mary Elizabeth and Florence Monica.\nMargit, known as Manci, had visited her brother in 1934 in Princeton, New Jersey, from their native Hungary and, while at dinner at the Annex Restaurant, met the \"lonely-looking man at the next table\". This account from a Korean physicist, Y. S. Kim, who met and was influenced by Dirac, also says: \"It is quite fortunate for the physics community that Manci took good care of our respected Paul A. M. Dirac. Dirac published eleven papers during the period 1939\u201346. Dirac was able to maintain his normal research productivity only because Manci was in charge of everything else\".\nPersonality.\nDirac was regarded by his friends and colleagues as unusual in character. In a 1926 letter to Paul Ehrenfest, Albert Einstein wrote of a Dirac paper, \"I am toiling over Dirac. This balancing on the dizzying path between genius and madness is awful.\" In another letter concerning the Compton effect he wrote, \"I don't understand the details of Dirac at all.\"\nDirac was known among his colleagues for his precise and taciturn nature. His colleagues in Cambridge jokingly defined a unit called a \"dirac\", which was one word per hour. When Niels Bohr complained that he did not know how to finish a sentence in a scientific article he was writing, Dirac replied, \"I was taught at school never to start a sentence without knowing the end of it.\" He criticised the physicist J. Robert Oppenheimer's interest in poetry: \"The aim of science is to make difficult things understandable in a simpler way; the aim of poetry is to state simple things in an incomprehensible way. The two are incompatible.\" Bohr called Dirac \"a complete logical genius\" and also the \"strangest man\" who had ever visited his Institute.\nDirac himself wrote in his diary during his postgraduate years that he concentrated solely on his research, and stopped only on Sunday when he took long strolls alone.\nAn anecdote recounted in a review of the 2009 biography tells of Werner Heisenberg and Dirac sailing on an ocean liner to a conference in Japan in August 1929. \"Both still in their twenties, and unmarried, they made an odd couple. Heisenberg was a ladies' man who constantly flirted and danced, while Dirac\u2014'an Edwardian geek', as biographer Graham Farmelo puts it\u2014suffered agonies if forced into any kind of socializing or small talk. 'Why do you dance?' Dirac asked his companion. 'When there are nice girls, it is a pleasure,' Heisenberg replied. Dirac pondered this notion, then blurted out: 'But, Heisenberg, how do you know beforehand that the girls are nice?'\"\nMargit Dirac told both George Gamow and Anton Capri in the 1960s that her husband had said to a house visitor, \"Allow me to present Wigner's sister, who is now my wife.\"\nAnother story told of Dirac is that when he first met the young Richard Feynman at a conference, he said after a long silence, \"I have an equation. Do you have one too?\"\nAfter he presented a lecture at a conference, one colleague raised his hand and said: \"I don't understand the equation on the top-right-hand corner of the blackboard\". After a long silence, the moderator asked Dirac if he wanted to answer the question, to which Dirac replied: \"That was not a question, it was a comment.\"\nDirac was also noted for his personal modesty. He called the equation for the time evolution of a quantum-mechanical operator, which he was the first to write down, the \"Heisenberg equation of motion\". Most physicists speak of Fermi\u2013Dirac statistics for half-integer-spin particles (fermions) and Bose\u2013Einstein statistics for integer-spin particles (bosons). While lecturing later in life, Dirac always insisted on calling the former \"Fermi statistics\". He referred to the latter as \"Bose statistics\" for reasons, he explained, of \"symmetry\".\nPhilosophy of physics.\nWhile visiting Moscow State University in 1956, Dirac was asked to summarize his philosophy of physics. He wrote on the blackboard \"Physical laws should have mathematical beauty.\" As is traditional with inscriptions left by distinguished visitors, the http:// has never been erased.\nDirac repeatedly emphasized the role of mathematical beauty in physics. For Dirac, mathematical beauty was both a quality of nature and a useful methodological guide for the physicist. When trying to mathematically formulate a law of nature, he thought that physicists should aim for beauty. When evaluating whether a theory should be accepted, he thought that mathematical beauty could and did play a role. For example, in a 1939 lecture, he argued that the mathematically beautiful statement of the general theory of relativity was one of the reasons it was accepted.\nDirac was famously not bothered by issues of interpretation in quantum theory. In fact, in a paper published in a book in his honour, he wrote: \"The interpretation of quantum mechanics has been dealt with by many authors, and I do not want to discuss it here. I want to deal with more fundamental things.\"\nViews on religion.\nWerner Heisenberg recollected a conversation among young participants at the 1927 Solvay Conference about Einstein and Max Planck's views on religion between Wolfgang Pauli, Heisenberg and Dirac. Dirac's contribution was a criticism of the political purpose of religion, which Bohr regarded as quite lucid when hearing it from Heisenberg later. Heisenberg's view was tolerant. Pauli, raised as a Catholic, had kept silent after some initial remarks, but when finally he was asked for his opinion, said: \"Well, our friend Dirac has got a religion and its guiding principle is 'There is no God, and Paul Dirac is His prophet.'\" Everybody, including Dirac, burst into laughter.\nLater in life, in an article mentioning God that appeared in the May 1963 edition of \"Scientific American\", Dirac wrote:\nIt seems to be one of the fundamental features of nature that fundamental physical laws are described in terms of a mathematical theory of great beauty and power, needing quite a high standard of mathematics for one to understand it. You may wonder: Why is nature constructed along these lines? One can only answer that our present knowledge seems to show that nature is so constructed. We simply have to accept it. One could perhaps describe the situation by saying that God is a mathematician of a very high order, and He used very advanced mathematics in constructing the universe. Our feeble attempts at mathematics enable us to understand a bit of the universe, and as we proceed to develop higher and higher mathematics we can hope to understand the universe better.\nIn 1971, at a conference meeting, Dirac described the possibilities for scientifically answering the question of God.\n Dirac explained that \n... if physical laws are such that to start off life involves an excessively small chance so that it will not be reasonable to suppose that life would have started just by blind chance, then there must be a god... On the other hand, if life can start very easily and does not need any divine influence, then I will say that there is no god.\nResearch.\nDirac discovered the relativistic equation for the electron, which now bears his name. The remarkable notion of an antiparticle to each fermion particle \u2013 e.g. the positron as antiparticle to the electron \u2013 stems from his equation. He is credited as being the one to create quantum field theory, which underlies all theoretical work on sub-atomic or \"elementary\" particles today, work that is fundamental to our understanding of the forces of nature, alongside creating quantum electrodynamics and coining the term. He proposed and investigated the concept of a magnetic monopole, an object not yet known empirically, as a means of bringing even greater symmetry to James Clerk Maxwell's equations of electromagnetism. Dirac also coined the terms \"fermion\" (particles with half-integer spin) and \"boson\" (particles with whole-integer spin).\nThroughout his career, Dirac was motivated by the principles of mathematical beauty, with Peter Goddard stating that \"Dirac cited mathematical beauty as the ultimate criterion for selecting the way forward in theoretical physics\". Dirac was recognised for being mathematically gifted, as during his time in university, academics had affirmed that Dirac had an \"ability of the highest order in mathematical physics\", with Ebenezer Cunningham stating that Dirac was \"quite the most original student I have met in the subject of mathematical physics\". Therefore, Dirac was known for his \"astounding physical intuition combined with the ability to invent new mathematics to create new physics\". During his career, Dirac made numerous important contributions to mathematical subjects, including the Dirac delta function, Dirac algebra and the Dirac operator.\nQuantum theory.\nDirac's first step into a new quantum theory was taken late in September 1925. Ralph Fowler, his research supervisor, had received a proof copy of an exploratory paper by Werner Heisenberg in the framework of the old quantum theory of Bohr and Sommerfeld. Heisenberg leaned heavily on Bohr's correspondence principle but changed the equations so that they involved directly observable quantities, leading to the matrix formulation of quantum mechanics. Fowler sent Heisenberg's paper on to Dirac, who was on vacation in Bristol, asking him to look into this paper carefully.\nDirac's attention was drawn to a mysterious mathematical relationship, at first sight unintelligible, that Heisenberg had established. Several weeks later, back in Cambridge, Dirac suddenly recognised that this mathematical form had the same structure as the Poisson brackets that occur in the classical dynamics of particle motion. At the time, his memory of Poisson brackets was rather vague, but he found E. T. Whittaker's \"Analytical Dynamics of Particles and Rigid Bodies\" illuminating. From his new understanding, he developed a quantum theory based on non-commuting dynamical variables. This led him to the most profound and significant general formulation of quantum mechanics to date. His novel formulation using Dirac brackets allowed him to obtain the quantisation rules in a novel and more illuminating manner. For this work, published in 1926, Dirac received a PhD from Cambridge.\nFermi\u2013Dirac statistics.\nShortly after Wolfgang Pauli proposed his Pauli exclusion principle (that two electrons cannot occupy the same quantum energy level), Enrico Fermi and Dirac both realized the principle would dramatically alter the statistical mechanics of electron systems. This work became the basis for Fermi\u2013Dirac statistics. This applies to systems consisting of many identical spin-1/2 particles, or fermions (i.e. that obey the Pauli exclusion principle), e.g. electrons in solids and liquids, and importantly to the field of conduction in semiconductors.\nDirac equation.\nIn 1928, building on 2\u00d72 spin matrices which he purported to have discovered independently of Wolfgang Pauli's work on non-relativistic spin systems (Dirac told Abraham Pais, \"I believe I got these [matrices] independently of Pauli and possibly Pauli got these independently of me.\"), he proposed the Dirac equation as a relativistic equation of motion for the wave function of the electron. This work led Dirac to predict the existence of the positron, the electron's antiparticle, which he interpreted in terms of what came to be called the \"Dirac sea\". The positron was observed by Carl Anderson in 1932. Dirac's equation also contributed to explaining the origin of quantum spin as a relativistic phenomenon.\nThe necessity of fermions (matter) being created and destroyed in Enrico Fermi's 1934 theory of beta decay led to a reinterpretation of Dirac's equation as a \"classical\" field equation for any point particle of spin \"\u0127\"/2, itself subject to quantisation conditions involving anti-commutators. Thus reinterpreted, in 1934 by Werner Heisenberg, as a (quantum) field equation accurately describing all elementary matter particles \u2013 today quarks and leptons \u2013 this Dirac field equation is as central to theoretical physics as the Maxwell, Yang\u2013Mills and Einstein field equations. Dirac is regarded as the founder of quantum electrodynamics, being the first to use that term. He also introduced the idea of vacuum polarisation in the early 1930s. This work was key to the development of quantum mechanics by the next generation of theorists, in particular Julian Schwinger, Richard Feynman, Sin-Itiro Tomonaga and Freeman Dyson in their formulation of quantum electrodynamics.\nDirac's \"The\" \"Principles of Quantum Mechanics\", published in 1930, is a landmark in the history of science. It quickly became one of the standard textbooks on the subject and is still used today. In that book, Dirac incorporated the previous work of Heisenberg on matrix mechanics and of Erwin Schr\u00f6dinger on wave mechanics into a single mathematical formalism that associates measurable quantities to operators acting on the Hilbert space of vectors that describe the state of a physical system. The book also introduced the Dirac delta function. Following his 1939 article, he also included the bra\u2013ket notation in the third edition of his book, thereby contributing to its universal use nowadays.\nQuantum electrodynamics.\nDirac's quantum electrodynamics (QED) included terms with infinite self-energy. A workaround known as renormalisation was developed, but Dirac never accepted this. \"I must say that I am very dissatisfied with the situation\", he said in 1975, \"because this so-called 'good theory' does involve neglecting infinities which appear in its equations, neglecting them in an arbitrary way. This is just not sensible mathematics. Sensible mathematics involves neglecting a quantity when it is small \u2013 not neglecting it just because it is infinitely great and you do not want it!\" His refusal to accept renormalisation resulted in his work on the subject moving increasingly out of the mainstream. Shin'ichir\u014d Tomonaga, Schwinger and Feynman mastered this approach, producing a QED with unprecedented accuracy, resulting in formal recognition by being awarded the 1965 Nobel Prize in Physics.\nIn the 1950s in his search for a better QED, Paul Dirac developed the Hamiltonian theory of constraints based on lectures that he delivered at the 1949 International Mathematical Congress in Canada. Dirac had also solved the problem of putting the Schwinger\u2013Tomonaga equation into the Schr\u00f6dinger representation and given explicit expressions for the scalar meson field (spin zero pion or pseudoscalar meson), the vector meson field (spin one rho meson), and the electromagnetic field (spin one massless boson, photon).\nMagnetic monopoles.\nIn 1931, Dirac proposed that the existence of a single magnetic monopole in the universe would suffice to explain the quantisation of electrical charge. \nNo such monopole has been detected, despite numerous attempts and preliminary claims. (See also: Searches for magnetic monopoles.)\nWar work.\nDirac contributed to the Tube Alloys project, the British programme to research and construct atomic bombs during World War II. Dirac made fundamental contributions to the process of uranium enrichment and the gas centrifuge. This work was deemed to be \"probably the most important theoretical result in centrifuge technology\".\nGravity.\nDirac quantised the gravitational field. His work laid the foundations for canonical quantum gravity. \nIn his 1959 lecture at the Lindau Meetings, Dirac discussed why gravitational waves have \"physical significance\". Dirac predicted gravitational waves would have well defined energy density in 1964. Dirac reintroduced the term \"graviton\" in a number of lectures in 1959, noting that the energy of the gravitational field should come in quanta.\nCosmology.\nDirac contributed to cosmology, putting forth his large numbers hypothesis.\nString theory.\nDirac is seen as having anticipated string theory, with his work on the Dirac membrane and Dirac\u2013Born\u2013Infeld action, both of which he proposed in a 1962 paper, along with other contributions. He also developed a general theory of the quantum field with dynamical constraints, which forms the basis of the gauge theories and superstring theories of today.\nOther work.\nDirac wrote an influential paper in 1933 regarding the Lagrangian in quantum mechanics. The paper served as the basis for Julian Schwinger and his quantum action principle, and laid the foundations for Richard Feynman's development of a completely new approach to quantum mechanics, the path integral formulation.\nIn a 1963 paper, Dirac initiated the study of field theory on anti-de Sitter space (AdS). The paper contains the mathematics of combining special relativity with the quantum mechanics of quarks inside hadrons, and lays the foundations of two-mode squeezed states that are essential to modern quantum optics, though Dirac did not realize it at the time. Dirac previously worked on AdS during the 1930s, publishing a paper in 1935.\nIn 1930, Victor Weisskopf and Eugene Wigner published their famous and now standard calculation of spontaneous radiation emission in atomic and molecular physics. Remarkably, in a letter to Niels Bohr in February 1927, Dirac had come to the same calculation, but he did not publish it.\nIn 1938, Dirac renormalized the mass in the theory of Abraham-Lorentz electron, leading to the Abraham\u2013Lorentz\u2013Dirac force, which is the relativistic-classical electron model; however, this model has solutions that suggest force increase exponentially with time.\nFermi's golden rule, the formula for computing quantum transitions in time dependent systems, declared a \"golden rule\" by Enrico Fermi, was derived by Dirac. Dirac was the one to initiate the development of time-dependent perturbation theory in his early work on semi-classical atoms interacting with an electromagnetic field. Dirac, with Werner Heisenberg, John Archibald Wheeler, Richard Feynman, and Freeman Dyson ultimately developed this concept into an invaluable tool for modern physics, used in the calculation of the properties of any physical system and a wide array of phenomena.\nCareer.\nFrom 1932 to 1969, Dirac was Lucasian Professor of Mathematics at the University of Cambridge. In 1934, He conceived the Helikon vortex isotope separation process. In 1937, he proposed a speculative cosmological model based on the large numbers hypothesis. During World War II, he conducted important theoretical work on uranium enrichment by gas centrifuge. He introduced the separative work unit (SWU) in 1941. He contributed to the Tube Alloys project, the British programme to research and construct atomic bombs during World War II.\nThe Hamiltonian of constrained systems is one of Dirac's many masterpieces. It is a powerful generalisation of Hamiltonian theory that remains valid for curved spacetime. The equations for the Hamiltonian involve only six degrees of freedom described by formula_1,formula_2 for each point of the surface on which the state is considered. The formula_3 (\"m\" = 0, 1, 2, 3) appear in the theory only through the variables formula_4, formula_5 which occur as arbitrary coefficients in the equations of motion.\nThere are four constraints or weak equations for each point of the surface formula_6 = constant. Three of them formula_7 form the four vector density in the surface. The fourth formula_8 is a 3-dimensional scalar density in the surface \"H\"L \u2248 0; \"Hr\" \u2248 0 (\"r\" = 1, 2, 3).\nIn the late 1950s, Dirac applied the Hamiltonian methods he had developed to cast Einstein's general relativity in Hamiltonian form and to bring to a technical completion the quantisation problem of gravitation and bring it also closer to the rest of physics according to Salam and DeWitt. In 1959 he also gave an invited talk on \"Energy of the Gravitational Field\" at the New York Meeting of the American Physical Society. In 1964 he published his \"Lectures on Quantum Mechanics\" (London: Academic) which deals with constrained dynamics of nonlinear dynamical systems including quantisation of curved spacetime. He also published a paper entitled \"Quantization of the Gravitational Field\" in the 1967 ICTP/IAEA Trieste Symposium on Contemporary Physics.\nThe 1963\u20131964 lectures Dirac gave on quantum field theory at Yeshiva University were published in 1966 as the Belfer Graduate School of Science, Monograph Series Number, 3.\nStudents.\nAmongst his many students were Homi J. Bhabha, Fred Hoyle, John Polkinghorne and Freeman Dyson. In 1930, Subrahmanyan Chandrasekhar attended Dirac's course on quantum mechanics four times, describing it as \"just like a piece of music you want to hear over and over again.\"\nLater life.\nIn 1969, Dirac was forced to retire from his chair at Cambridge, due to his age (67). Before his retirement, he was offered a visiting position at the University of Miami in Coral Gables, Florida; he accepted, joining its newly formed Center for Theoretical Studies. In September 1970 he also accepted a visiting professor position at Florida State University in Tallahassee, Florida, and moved his family to Tallahassee. He accepted a position at FSU as a full professor in 1972.\nContemporary accounts of his time in Tallahassee describe it as happy, except that he apparently found the summer heat oppressive and liked to escape from it to Cambridge. He would walk about a mile to work each day and was fond of swimming in one of the two nearby lakes (Silver Lake and Lost Lake), and was also more sociable than he had been at the University of Cambridge, where he mostly worked at home apart from giving classes and seminars. At Florida State, he would usually eat lunch with his colleagues before taking a nap.\nDirac published over 60 papers at FSU during those last twelve years of his life, including a short book on general relativity. His last paper (1984), entitled \"The inadequacies of quantum field theory,\" contains his final judgment on quantum field theory: \"These rules of renormalisation give surprisingly, excessively good agreement with experiments. Most physicists say that these working rules are, therefore, correct. I feel that is not an adequate reason. Just because the results happen to be in agreement with observation does not prove that one's theory is correct.\" The paper ends with the words: \"I have spent many years searching for a Hamiltonian to bring into the theory and have not yet found it. I shall continue to work on it as long as I can and other people, I hope, will follow along such lines.\"\nIn 1975, Dirac gave a series of five lectures at the University of New South Wales which were subsequently published as a book, \"Directions in Physics\" (1978). He donated the royalties from this book to the University for the establishment of Dirac Lecture Series. The Silver Dirac Medal for the Advancement of Theoretical Physics is awarded by the University of New South Wales to commemorate the lecture.\nDirac died on 20 October 1984 in Tallahassee, Florida, at the age of 82, and was buried at Tallahassee's Roselawn Cemetery.\nCommemorations.\nDirac's childhood home in Bishopston, Bristol, is commemorated with a blue plaque, and the nearby Dirac Road is named in recognition of his links with the city of Bristol. A commemorative stone was erected in a garden in Saint-Maurice, Switzerland, the town of origin of his father's family, on 1 August 1991. On 13 November 1995 a commemorative marker, made from Burlington green slate and inscribed with the Dirac equation, was unveiled in Westminster Abbey. The Dean of Westminster, Edward Carpenter, had initially refused permission for the memorial, thinking Dirac to be anti-Christian, but was eventually (over a five-year period) persuaded to relent.\nAfter his death, two organisations of professional physicists established annual awards in Dirac's memory. The Institute of Physics, the United Kingdom's professional body for physicists, awards the Paul Dirac Medal for \"outstanding contributions to theoretical (including mathematical and computational) physics\". The first three recipients were Stephen Hawking (1987), John Stewart Bell (1988), and Roger Penrose (1989). Since 1985, the International Centre for Theoretical Physics awards the Dirac Medal of the ICTP each year on Dirac's birthday (8 August).\nThe Dirac\u2013Hellman Award at Florida State University was endowed by Bruce P. Hellman in 1997 to reward outstanding work in theoretical physics by FSU researchers. The Paul A.M. Dirac Science Library at Florida State University, which Manci opened in December 1989, is named in his honour, and his papers are held there. Outside is a statue of him by Gabriella Bollob\u00e1s. The street on which the National High Magnetic Field Laboratory in Innovation Park of Tallahassee, Florida, is located is named Paul Dirac Drive. As well as in his hometown of Bristol, there is also a road named after him, Dirac Place, in Didcot, Oxfordshire. The Dirac-Higgs Science Centre in Bristol is also named in his honour.\nThe BBC named a video codec, Dirac, in his honour. An asteroid discovered in 1983 was named after Dirac. The Distributed Research utilising Advanced Computing (DiRAC) and Dirac software are named in his honour.\nPraise.\nDirac is widely considered to be on par with Isaac Newton, James Clerk Maxwell, and Albert Einstein. Einstein wrote that to Dirac \"we owe the most logically perfect presentation of [quantum mechanics].\"\nOn the occasion of the 100th anniversary of Dirac's birth, Richard Dalitz wrote \"The influence and importance of Dirac's work have increased with the decades, and physicists use daily the concepts and equations that he developed.\"\nIn Lev Landau's logarithmic scale of physicists from 0 to 5 based on productivity and genius, (0 being the highest and 5 the lowest) he ranked Dirac a 1, along with other fathers of quantum mechanics such as Schr\u00f6dinger and Werner Heisenberg.\nJohn Polkinghorne wrote: \"Not only was Dirac the greatest theoretical physicist known to me personally, his purity of spirt and modesty of demeanour (he never emphasized in the slightest degree his own immense contributions to the fundamentals of the subject) made him an inspiring figure and a kind of scientific saint.\"\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24743", "revid": "46526274", "url": "https://en.wikipedia.org/wiki?curid=24743", "title": "Pessimism", "text": "Negative mental attitude\nPessimism is a mental attitude in which an undesirable outcome is anticipated from a given situation. Pessimists tend to focus on the negatives of life in general. A common question asked to test for pessimism is \"Is the glass half empty or half full?\"; in this situation, a pessimist is said to see the glass as half empty, or in extreme cases completely empty, while an optimist is said to see the glass as half full. Throughout history, the pessimistic disposition has had effects on all major areas of thinking.\nEtymology.\nThe term \"pessimism\" derives from the Latin word \"pessimus\", meaning 'the worst'. It was first used by Jesuit critics of Voltaire's 1759 novel \"Candide, ou l'Optimisme\". Voltaire was satirizing the philosophy of Leibniz who maintained that this was the 'best (optimum) of all possible worlds'. In their attacks on Voltaire, the Jesuits of the \"Revue de Tr\u00e9voux\" accused him of \"pessimisme\".\nAs a psychological disposition.\nIn the ancient world, psychological pessimism was associated with melancholy, and was believed to be caused by an excess of black bile in the body. The study of pessimism has parallels with the study of depression. Psychologists trace pessimistic attitudes to emotional pain or even biology. Aaron Beck argues that depression is due to unrealistic negative views about the world. Beck starts treatment by engaging in conversation with clients about their unhelpful thoughts. Pessimists, however, are often able to provide arguments that suggest that their understanding of reality is justified; as in Depressive realism or (pessimistic realism). Deflection is a common method used by those who are depressed. They let people assume they are revealing everything which proves to be an effective way of hiding. The pessimism item on the Beck Depression Inventory has been judged useful in predicting suicides. The Beck Hopelessness Scale has also been described as a measurement of pessimism.\nWender and Klein point out that pessimism can be useful in some circumstances: \"If one is subject to a series of defeats, it pays to adopt a conservative game plan of sitting back and waiting and letting others take the risks. Such waiting would be fostered by a pessimistic outlook. Similarly if one is raking in the chips of life, it pays to adopt an expansive risk-taking approach, and thus maximize access to scarce resources.\"\nThe leading causes of pessimism are genetics, past experience, and social and environmental factors. One study of 5,187 teenage twins and their siblings suggests that genetics may account for one-third of the variance in whether someone leans toward pessimism vs. optimism, with the remaining variance due to their environment, and twin studies suggest that, when it comes to personality, about half the differences between us are because of genetic factors. But Spector points out that throughout our lives, in response to environmental factors, our genes are constantly being dialled up and down as with a dimmer switch, a process known as epigenetics.\nCriticism.\nPragmatic criticism.\nThrough history, some have concluded that a pessimistic attitude, although justified, must be avoided to endure. Optimistic attitudes are favored and of emotional consideration. Al-Ghazali and William James rejected their pessimism after suffering psychological, or even psychosomatic illness. Criticisms of this sort however assume that pessimism leads inevitably to a mood of darkness and utter depression. Many philosophers would disagree, claiming that the term \"pessimism\" is being abused. The link between pessimism and nihilism is present, but the former does not necessarily lead to the latter, as philosophers such as Albert Camus believed. Happiness is not inextricably linked to optimism, nor is pessimism inextricably linked to unhappiness. One could easily imagine an unhappy optimist, and a happy pessimist. Accusations of pessimism may be used to silence legitimate criticism.\nNouriel Roubini, an economist who introduces himself as Dr. Doom, was largely dismissed as a pessimist in 2006 for his dire but to some extent accurate predictions of a financial crisis, ahead of the 2008 financial crisis. However, financial journalist Justin Fox observed in the \"Harvard Business Review\" in 2010 that the crisis Roubini predicted was not at all like the 2008 financial crisis; it involved a currency crisis and run on the dollar and dismissed Roubini's predictions as inaccurate. Others noted that \"The problem is that even though he was spectacularly right on this one, he went on to predict time and time again, as the markets and the economy recovered in the years following the collapse, that there would be a follow-up crisis and that more extreme crashes were inevitable. His calls, after his initial pronouncement, were consistently wrong. Indeed, if you had listened to him, and many investors did, you would have missed the longest bull market run in US market history.\" Another observed: \"For a prophet, he's wrong an awful lot of the time.\" Tony Robbins wrote: \"Roubini warned of a recession in 2004 (wrongly), 2005 (wrongly), 2006 (wrongly), and 2007 (wrongly)\" ... and he \"predicted (wrongly) that there'd be a 'significant' stock market correction in 2013.\" Speaking about Roubini, economist Anirvan Banerji told \"The New York Times\": \"Even a stopped clock is right twice a day.\" Economist Nariman Behravesh said: \"Nouriel Roubini has been singing the doom-and-gloom story for 10 years. Eventually something was going to be right.\"\n\"Personality Plus\" opines that pessimistic temperaments (\"e.g.\", melancholy and phlegmatic) can be useful inasmuch as pessimists' focus on the negative helps them spot problems that people with more optimistic temperaments (\"e.g.\", choleric and sanguine) miss.\nOther forms of pessimism.\nPhilosophical pessimism.\nPhilosophical pessimism is not a state of mind or a psychological disposition, but rather it is a worldview or philosophical position that assigns a negative value to life or existence. Philosophical pessimists commonly argue that the world contains an empirical prevalence of pains over pleasures, that existence is ontologically or metaphysically adverse to living beings, and that life is fundamentally meaningless or without purpose.\nPolitical and cultural.\nPhilosophical pessimism stands opposed to the optimism or even utopianism of Hegelian philosophies. Emil Cioran claimed \"Hegel is chiefly responsible for modern optimism. How could he have failed to see that consciousness changes only its forms and modalities, but never progresses?\" Philosophical pessimism is differentiated from other political philosophies by having no ideal governmental structure or political project, rather pessimism generally tends to be an anti-systematic philosophy of individual action. This is because philosophical pessimists tend to be skeptical that any politics of social progress can actually improve the human condition. As Cioran states, \"every step forward is followed by a step back: this is the unfruitful oscillation of history\". Cioran also attacks political optimism because it creates an \"idolatry of tomorrow\" which can be used to authorize anything in its name. This does not mean however, that the pessimist cannot be politically involved, as Camus argued in \"The Rebel\" (1951). Pessimism about the human condition was also expressed by Hobbes (1588\u20131679).\nThere is another strain of thought generally associated with a pessimistic worldview, this is the pessimism of cultural criticism and social decline. Anthony Trollope summarised the attitude with gentle mockery in 1880: \"Everything is going wrong. [...] Farmers are generally on the verge of ruin. Trade is always bad. The Church is in danger. The House of Lords isn't worth a dozen years' purchase. The throne totters.\"\nOswald Spengler's \"The Decline of the West\" (1918\u20131922) popularised pessimism. Spengler promoted a cyclic model of history similar to the theories of Giambattista Vico (1668\u20131744). Spengler believed that modern western civilization was in a \"winter\" age of decline (). Spenglerian theory was immensely influential in interwar Europe, especially in Weimar Germany. Similarly, traditionalist Julius Evola (1898\u20131974) thought that the world was in the Kali Yuga, a Dark Age of moral decline.\nIntellectuals such as Oliver James correlate economic progress with economic inequality, the stimulation of artificial needs, and affluenza. Anti-consumerists identify rising trends of conspicuous consumption and self-interested, image-conscious behavior in culture. Post-modernists like Jean Baudrillard (1929\u20132007) have even argued that culture (and therefore our lives) now has no basis in reality whatsoever.\nConservative thinkers, especially social conservatives, often perceive politics in a generally pessimistic way. William F. Buckley famously remarked that he was \"standing athwart history yelling 'stop!'\", and Whittaker Chambers (1901-1961) was convinced that capitalism was bound to fall to communism, though he himself became staunchly anti-communist. Social conservatives often see the West as a decadent and nihilistic civilization which has abandoned its roots in Christianity and/or Greek philosophy, leaving it doomed to fall into moral and political decay. Robert Bork's \"Slouching Toward Gomorrah\" and Allan Bloom's \"The Closing of the American Mind\" are famous expressions of this point of view.\nMany economic conservatives and libertarians believe that the expansion of the state and the role of government in society is inevitable, and that they are at best fighting a holding action against it.\nThey hold that the natural tendency of people is to be ruled and that freedom is an exceptional state of affairs which is now being abandoned in favor of social and economic security provided by the welfare state. Political pessimism has sometimes found expression in dystopian novels such as George Orwell's \"Nineteen Eighty-Four\". Political pessimism about one's country often correlates with a desire to emigrate.\nDuring the 2008 financial crisis in the United States, the neologism \"pessimism porn\" came to describe the alleged eschatological and survivalist thrill some people derive from predicting, reading, and fantasizing about the collapse of civil society through the destruction of the world's economic system.\nPuolanka, a municipality located in the Kainuu region in the northern Finland, has been called the \"most pessimistic municipality in Finland\", and in 2019, the municipality gained worldwide publicity when the \"BBC\" published a video about Puolanka, describing it as the \"most pessimistic town in the world\". Pessimism has a long tradition in the Kainuu region, mostly because Kainuu was a poor region that had often suffered from famines in the late 19th century and early 20th century, which is why the region is also called a \"hunger land\".\nTechnological and environmental.\nTechnological pessimism is the belief that advances in science and technology do not lead to an improvement in the human condition. Technological pessimism can be said to have originated during the Industrial Revolution with the Luddite movement. Luddites blamed the rise of industrial mills and advanced factory machinery for the loss of their jobs and set out to destroy them. The Romantic movement was also pessimistic towards the rise of technology and longed for simpler and more natural times. Poets like William Wordsworth and William Blake believed that industrialization was polluting the purity of nature.\nSome social critics and environmentalists believe that globalization, overpopulation and the economic practices of modern capitalist states over-stress the planet's ecological equilibrium. They warn that unless something is done to slow this, climate change will worsen eventually leading to some form of social and ecological collapse. James Lovelock believes that the ecology of the Earth has already been irretrievably damaged, and even an unrealistic shift in politics would not be enough to save it. According to Lovelock, the Earth's climate regulation system is being overwhelmed by pollution and the Earth will soon jump from its current state into a dramatically hotter climate. Lovelock blames this state of affairs on what he calls \"polyanthroponemia\", which is when: \"humans overpopulate until they do more harm than good.\" Lovelock states:\nThe presence of 7 billion people aiming for first-world comforts\u2026is clearly incompatible with the homeostasis of climate but also with chemistry, biological diversity and the economy of the system.\nSome radical environmentalists, anti-globalization activists, and Neo-luddites can be said to hold to this type of pessimism about the effects of modern \"progress\". A more radical form of environmental pessimism is anarcho-primitivism which faults the agricultural revolution with giving rise to social stratification, coercion, and alienation. Some anarcho-primitivists promote deindustrialization, abandonment of modern technology and rewilding.\nAn infamous anarcho-primitivist is Theodore Kaczynski, also known as the Unabomber, who engaged in a nationwide mail bombing campaign. In his 1995 \"Unabomber Manifesto\", he called attention to the erosion of human freedom by the rise of the modern \"industrial-technological system\". The manifesto begins thus: The Industrial Revolution and its consequences have been a disaster for the human race. They have greatly increased the life-expectancy of those of us who live in \"advanced\" countries, but they have destabilized society, have made life unfulfilling, have subjected human beings to indignities, have led to widespread psychological suffering (in the Third World to physical suffering as well) and have inflicted severe damage on the natural world. The continued development of technology will worsen the situation. It will certainly subject human beings to greater indignities and inflict greater damage on the natural world, it will probably lead to greater social disruption and psychological suffering, and it may lead to increased physical suffering even in \"advanced\" countries.\nOne of the most radical pessimist organizations is the voluntary human extinction movement, which argues for the extinction of the human race through antinatalism.\nPope Francis' controversial 2015 encyclical on ecological issues is rife with pessimistic assessments of the role of technology in the modern world.\nEntropy pessimism.\n\"Entropy pessimism\" represents a special case of technological and environmental pessimism, based on thermodynamic principles. According to the first law of thermodynamics, matter and energy is neither created nor destroyed in the economy. According to the second law of thermodynamics\u2014also known as the entropy law\u2014what happens in the economy is that all matter and energy is transformed from states available for human purposes (valuable natural resources) to states unavailable for human purposes (valueless waste and pollution). In effect, all of man's technologies and activities are only speeding up the general march against a future planetary \"heat death\" of degraded energy, exhausted natural resources and a deteriorated environment\u2014a state of maximum entropy locally on earth; \"locally\" on earth, that is, when compared to the heat death of the universe, taken as a whole.\nThe term \"entropy pessimism\" was coined to describe the work of Romanian American economist Nicholas Georgescu-Roegen, a progenitor in economics and the paradigm founder of ecological economics. Georgescu-Roegen made extensive use of the entropy concept in his magnum opus on \"The Entropy Law and the Economic Process\". Since the 1990s, leading ecological economist and steady-state theorist Herman Daly\u2014a student of Georgescu-Roegen\u2014had been the economic profession's most influential proponent of entropy pessimism prior to his death in 2022.\nAmong other matters, the entropy pessimism position is concerned with the existential impossibility of allocating Earth's finite stock of mineral resources evenly among an unknown number of present and future generations. This number of generations is likely to remain unknown to us, as there is no way\u2014or only little way\u2014of knowing in advance if or when humankind will ultimately face extinction. In effect, \"any\" conceivable intertemporal allocation of the stock will inevitably end up with universal economic decline at some future point. \nEntropy pessimism is a widespread view in ecological economics and in the degrowth movement.\nLegal.\nBibas writes that some criminal defense attorneys prefer to err on the side of pessimism: \"Optimistic forecasts risk being proven disastrously wrong at trial, an embarrassing result that makes clients angry. On the other hand, if clients plead based on their lawyers' overly pessimistic advice, the cases do not go to trial and the clients are none the wiser.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24744", "revid": "50689456", "url": "https://en.wikipedia.org/wiki?curid=24744", "title": "Peter Wessel Zapffe", "text": "Norwegian philosopher (1899\u20131990)\nPeter Wessel Zapffe (; ; 18 December 1899\u00a0\u2013 12 October 1990) was a Norwegian philosopher, author, artist, lawyer and mountaineer. He is often noted for his philosophically pessimistic and fatalistic view of human existence. His system of philosophy was inspired by the German philosopher Arthur Schopenhauer, as well as his firm advocacy of antinatalism. His thoughts regarding the error of human life are presented in the essay \"The Last Messiah\" (\"Den sidste Messias\", 1933). This essay is a shorter version of his best-known work, the philosophical treatise \"On the Tragic\" (\"Om det tragiske\", 1941).\nPhilosophical work.\nZapffe's view is that humans are born with an overdeveloped consciousness (self-reflection, self-knowledge) which does not fit into nature's design. The human craving for justification on matters such as life, death and meaning cannot be satisfied, hence humanity has a need that life cannot fully satisfy. The tragedy, following this theory, is that humans spend their time trying to dull their consciousness, to escape the burdens of existential reflection. The human being is thus a paradox, given that self-reflection is one of the prime attributes associated with human consciousness. Death anxiety is a major part of this reflection, according to Zapffe, and the human being is unique among living beings in the ability to reflect on their own forthcoming death.\nIn \"The Last Messiah\", Zapffe described four principal defense mechanisms that humankind uses to avoid facing this paradox:\nOn the occasion of the 65th birthday of the Norwegian\u2013Canadian philosopher Herman T\u00f8nnessen, the book \"I Choose the Truth. A Dialogue Between Peter Wessel Zapffe and Herman T\u00f8nnessen\" (1983) was published. The two had known each other already for many years. T\u00f8nnessen had studied at the University of Oslo together with Arne N\u00e6ss.\nOther interests and works.\nZapffe was a prolific mountaineer and took a very early interest in environmentalism; this form of nature conservationism sprung from the intent, not of protecting nature, but to avoid human culturalization of nature.\nZapffe was the author of many humorous short stories about climbing and other adventures in nature.\nPersonal life.\nSon of the apothecary Fritz Gottlieb Zapffe and Gudrun Wessel, Zapffe was related on his maternal side to the Danish-Norwegian vice-admiral Peter Tordenskjold.\nIn Kristiania, in 1921, Zapffe learned for the first time about mountaineering, beginning with climbing challenges in B\u00e6rum, in Kols\u00e5s, the first mountain he climbed. In 1924 he was the first person to climb the top of Tommeltott in Ullsfjorden; in 1925, the Sm\u00e5tind (south side) in Kval\u00f8ya; and the Bentsjordtind between Malangen and Balsfjorden. And in the same year: Okshorn, Snekollen and Mykkjetind were climbed. In 1926 it was a summit in Senja and also the Hollenderan summit in Kval\u00f8ya, first trodden by him: in 1987 the highest peak of the Hollenderan in Kval\u00f8ya was named after him. Today the summit is called \"Zapffes tind\" ('the top of Zapffe'). In 1928, Zapffe climbed the first summit of Skamtinden and was also the first to climb the front side of Svolv\u00e6rgeita.\nIn 1940 Zapffe applied to the Norsk Tindeklubb but was rejected. However, in 1965 he was accepted into a mountaineering society but as an honorary member, and again in 1987 in a mountaineering club from Troms\u00f8.\nIn 1928, due to a storm, Umberto Nobile's zeppelin, the \"Italia\", crashed on the way back to Italy. Roald Amundsen (a friend of the Zapffe family) and Zapffe assisted in the rescue of the zeppelin crew. There, Zappfe served as interpreter for the expedition. Later on the icebreaker DS \u00abIsbj\u00f8rn\u00bb, Zapffe served as German interpreter, his father was also on board: the expedition was then to search for the missing Amundsen, but was unsuccessful.\nZapffe left Troms\u00f8 on June 5, 1929. He found a room on Erling Skjalgss\u00f8ns street in Kristiania, living quite frugally and in a mentally catastrophic state: \"The idea of death as the greatest consolation and escape, and which is always at hand, penetrates me with even greater force\".\nSimilar to Emil Cioran, he lived from 1978 on a state pension. In 1987 he received the Honor Award from the Fritt Ord Foundation for \"the original and versatile character of his literary work\".\nIn his last years of life, when he was frequently visited by journalists, he had an interview with \"Asker og B\u00e6rum Budstikke\", in which he described himself as a nihilist: \"I am not a pessimist. I am a nihilist. Namely, not a pessimist in the sense that I have upsetting apprehensions, but a nihilist in a sense that is not moral\".\nZapffe's hobbies were varied, showing an early enthusiasm for painting. However, photography occupied him since the age of 12 through his father (himself a photographer), who lent his photographic equipment to his son. This also meant a kind of compensation for his myopia. The impact of his work as a photographer can be seen reflected in his work \"Rough Joys\" (1969), where it seems that he reconstructs ekphrase from his photographic documentation during his trips to the mountains. Much of his photographic production is currently cultural heritage.\nZapffe married Bergljot Espolin Johnsen in 1935; they divorced in 1941. He married Berit Riis Christensen in 1952, they remained together until his death in 1990; Berit died in May 2008. Zapffe remained childless by choice. He was lifelong friends with the Norwegian philosopher and fellow mountaineer, Arne N\u00e6ss.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24745", "revid": "248739", "url": "https://en.wikipedia.org/wiki?curid=24745", "title": "Franc Poincar\u00e9", "text": "Historic unit of account for international settlements\nThe Franc Poincar\u00e9 is a unit of account that was used in the international regulation of liability. It was introduced on June 25, 1928, as a replacement for the Germinal franc, which had been established by Napoleon Bonaparte in 1803. It was defined as 65.5 milligrams of gold of millesimal fineness .900. Formerly it was identical to the French franc, although it has not been so since the 1920s.\nPractice on its conversion to national currencies varies from state to state; in most states the conversion factor is based not on the market price of gold, but on an official price (a remnant of the gold standard, frequently far below its market price today). The Franc Poincar\u00e9 has been replaced for most purposes by special drawing rights.\nConventions which used the Franc Poincar\u00e9 included the Convention for the Unification of Certain Rules Relating to International Carriage by Air, the International Convention on Civil Liability for Oil Pollution Damage and the International Convention on the Establishment of an International Fund for Compensation for Oil Pollution Damage.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24746", "revid": "1299323147", "url": "https://en.wikipedia.org/wiki?curid=24746", "title": "PCX", "text": "Image file format\nPCX, standing for \"PiCture eXchange\", is an image file format developed by the now-defunct ZSoft Corporation of Marietta, Georgia, United States. It was the native file format for PC Paintbrush and became one of the first widely accepted DOS imaging standards, although it has since been succeeded by more sophisticated image formats, such as BMP, JPEG, and PNG. PCX files commonly store palette-indexed images ranging from 2 or 4 colors to 16 and 256 colors, although the format has been extended to record true-color (24-bit) images as well.\nPCX image formats.\nPCX was designed during the early development of PC display hardware and most of the formats it supported are no longer used. The table below shows a list of the most commonly used PCX formats. Contemporary image editing programs may not read PCX files that match older hardware.\nPCX is supported by common image processing software including ACDSee, FastStone, GIMP, ImageMagick, IrfanView, LView, Netpbm, PaintShop Pro, Photoshop, Visio, PMview, XnView and GraphicConverter. In version 2.1.4 FFmpeg could encode and decode the PCX pixel formats \"rgb24, rgb8, bgr8, rgb4_byte, bgr4_byte, gray, pal8,\" and \"monob\".\nThere is a multi-page version of PCX, used by some computer fax and document management programs, with file extension codice_1. A DCX file consists of a header introducing a set of following PCX files.\nPCX file format.\nPCX files were designed for use on IBM-compatible PCs and always use little endian byte ordering. A PCX file has three main sections, in the following order\nThe PCX file header contains an identifier byte (value 10), a version number, image dimensions, 16 palette colors, number color planes, bit depth of each plane, and a value for compression method. PCX version numbers range from 0 to 5, this originally denoted the version of the PC Paintbrush program used to create the PCX file. The header always has space for 16 colors though the number of colors used depends upon the bit depth of the image. The header is composed of 18 fields:\nAll PCX files use the same compression scheme and the compression value is always 1. No other values have been defined and there are no uncompressed PCX files. One source claims that 0 (uncompressed) is \"allowed, but not much software supports it\".\nImage data layout.\nPCX image data is stored in rows or scan lines in top-down order. If the image has multiple planes, these are stored by plane within row, such that all the red data for row 0 are followed by all the green data for row 0, then all the blue data, then alpha data. This pattern is repeated for each line as shown in the next table:\nWhen an image is less than 8 bits per pixel, each line is padded to the next even byte boundary. For example, if an image has 1 plane of 1-bit data (monochrome) with a width of 22 pixels, each row will be 4 bytes long, having 32 bits per row with 10 bits unused.\nImage data compression.\nPCX image data are compressed using run-length encoding (RLE), a simple lossless compression algorithm that collapses a series of three or more consecutive bytes with identical values into a two-byte pair. The two most-significant bits of a byte are used to determine whether the given data represent a single pixel of a given palette index or color value, or an RLE pair representing a series of several pixels of a single value:\nDue to the use of the two most-significant bits as flags, pixel values from 192 to 255 (with their most-significant bit already set) must be stored in an RLE byte pair, even when they only occur one or two pixels in succession, whereas color indexes 0 to 191 can be stored directly or in RLE byte pairs (whichever is more space-efficient); therefore, the actual compression ratio could be optimized with proper sorting of palette entries, though this is not feasible where the file must share its color palette with other images. For example, a palette could be optimized with the most commonly used colors occurring in palette positions 0 to 191 and the least common colors allocated to the remaining quarter of the palette.\nAnother \"inefficiency\" with the RLE algorithm is that it is possible to store chunks with a length of 0, which allows whitespace in the file. This is because otherwise the length would have to be incremented once which would slow down decompression slightly, this allowed PCX files to be decompressed faster on the processors it was originally intended for.\nThe PCX compression algorithm requires very little processor power or memory to apply, a significant concern with computer systems when it was designed. Compression algorithms used by newer image formats are more efficient when compressing images such as photographs, and dithered or otherwise complex graphics.\nColor palette.\nA PCX file has space in its header for a 16 color palette. When 256-color VGA hardware became available there was not enough space for the palette in a PCX file; even the 54 unused bytes after the header would not be enough. The solution chosen was to put the palette at the end of the file, along with a marker byte to confirm its existence.\nIf a PCX file has a 256-color palette, it is found 768 bytes from the end of the file. In this case the value in the byte preceding the palette should be 12 (0x0C). The palette is stored as a sequence of RGB triples; its usable length is defined by the number of colors in the image. Color values in a PCX palette always use 8 bits, regardless of the bit depth of the image.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24748", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=24748", "title": "Phoenecian", "text": ""}
{"id": "24749", "revid": "17216044", "url": "https://en.wikipedia.org/wiki?curid=24749", "title": "Permian\u2013Triassic extinction event", "text": "Earth's most severe extinction event\n &lt;imagemap&gt;\nImage:Extinction intensity.svg\nMarine extinction intensity during Phanerozoic\nMillions of years ago\nK\u2013Pg\nTr\u2013J\nP\u2013Tr\nCap\nLate D\nO\u2013S\n&lt;imagemap&gt;\nImage:Extinction intensity.svg\nPlot of extinction intensity (percentage of marine genera that are present in each interval of time but do not exist in the following interval) vs time in the past. Geological periods are annotated (by abbreviation and colour) above. The Permian\u2013Triassic extinction event is the most significant event for marine genera, with just over 50% (according to this source) perishing. \"()\"\nThe Permian\u2013Triassic extinction event, colloquially known as the Great Dying, was an extinction event that occurred approximately 251.9 million years ago (mya), at the boundary between the Permian and Triassic geologic periods, and with them the Paleozoic and Mesozoic eras. It is Earth's most severe known extinction event, with the extinction of 57% of biological families, 62% of genera, 81% of marine species, and 70% of terrestrial vertebrate species. It is also the greatest known mass extinction of insects. It is the greatest of the \"Big Five\" mass extinctions of the Phanerozoic. There is evidence for one to three distinct pulses, or phases, of extinction.\nThe scientific consensus is that the main cause of the extinction was the flood basalt volcanic eruptions that created the Siberian Traps, which released sulfur dioxide and carbon dioxide, resulting in euxinia (oxygen-starved, sulfurous oceans), elevated global temperatures,\nand acidified oceans.\nThe level of atmospheric carbon dioxide rose from around 400 ppm to 2,500 ppm with approximately 3,900 to 12,000 gigatonnes of carbon being added to the ocean-atmosphere system during this period. \nSeveral other contributing factors have been proposed, including the emission of carbon dioxide from the burning of oil and coal deposits ignited by the eruptions;&lt;ref name=\"lava/coal fires\"&gt;&lt;/ref&gt;\nemissions of methane from the gasification of methane clathrates; emissions of methane by novel methanogenic microorganisms nourished by minerals dispersed in the eruptions; longer and more intense El\u00a0Ni\u00f1o events; and an extraterrestrial impact that created the Araguainha crater and caused seismic release of methane and the destruction of the ozone layer with increased exposure to solar radiation.\nDating.\nPreviously, it was thought that rock sequences spanning the Permian\u2013Triassic boundary were too few and contained too many gaps for scientists to reliably determine its details. However, it is now possible to date the extinction with millennial precision. U\u2013Pb zircon dates from five volcanic ash beds from the Global Stratotype Section and Point for the Permian\u2013Triassic boundary at Meishan, China, establish a high-resolution age model for the extinction \u2013 allowing exploration of the links between global environmental perturbation, carbon cycle disruption, mass extinction, and recovery at millennial timescales. The first appearance of the conodont \"Hindeodus parvus\" has been used to delineate the Permian-Triassic boundary.\nThe extinction occurred between 251.941 \u00b1 0.037 and 251.880 \u00b1 0.031 million years ago, a duration of 60 \u00b1 48 thousand years. A large, abrupt global decrease in \u03b413C, the ratio of the stable isotope carbon-13 to that of carbon-12, coincides with this extinction, and is sometimes used to identify the Permian\u2013Triassic boundary and the Permian-Triassic Mass Extinction event (PTME) in rocks that are unsuitable for radiometric dating. The negative carbon isotope excursion's magnitude was 4\u20137% and lasted for approximately 500 kyr, though estimating its exact value is challenging due to diagenetic alteration of many sedimentary facies spanning the boundary.\nFurther evidence for environmental change around the Permian-Triassic boundary suggests an rise in temperature, and an increase in CO2 levels to (for comparison, the concentration immediately before the Industrial Revolution was , and the amount today is about 426\u00a0ppm). There is also evidence of increased ultraviolet radiation reaching the Earth, causing the mutation of plant spores.\nIt has been suggested that the Permian\u2013Triassic boundary is associated with a sharp increase in the abundance of marine and terrestrial fungi, caused by the sharp increase in the amount of dead plants and animals fed upon by the fungi. This \"fungal spike\" has been used by some paleontologists to identify a lithological sequence as being on or very close to the Permian\u2013Triassic boundary in rocks that are unsuitable for radiometric dating or have a lack of suitable index fossils. However, even the proposers of the fungal spike hypothesis pointed out that \"fungal spikes\" may have been a repeating phenomenon created by the post-extinction ecosystem during the earliest Triassic. The very idea of a fungal spike has been criticized on several grounds, including: \"Reduviasporonites\", the most common supposed fungal spore, may be a fossilized alga; the spike did not appear worldwide; and in many places it did not fall on the Permian\u2013Triassic boundary. The \"Reduviasporonites\" may even represent a transition to a lake-dominated Triassic world rather than an earliest Triassic zone of death and decay in some terrestrial fossil beds. Newer chemical evidence agrees better with a fungal origin for \"Reduviasporonites\", diluting these critiques.\nUncertainty exists regarding the duration of the overall extinction and about the timing and duration of various groups' extinctions within the greater process. Some evidence suggests that there were multiple extinction pulses or that the extinction was long and spread out over a few million years, with a sharp peak in the last million years of the Permian. Statistical analyses of some highly fossiliferous strata in Meishan, Zhejiang Province in southeastern China, suggest that the main extinction was clustered around one peak, while a study of the Liangfengya section found evidence of two extinction waves, MEH-1 and MEH-2, which varied in their causes, and a study of the Shangsi section showed two extinction pulses with different causes too. Recent research shows that different groups became extinct at different times; for example, while difficult to date absolutely, ostracod and brachiopod extinctions were separated by around 670,000 to 1.17 million years. Paleoenvironmental analysis of Lopingian strata in the Bowen Basin of Queensland indicates numerous intermittent periods of marine environmental stress from the middle to late Lopingian leading up to the end-Permian extinction proper, supporting aspects of the gradualist hypothesis. The decline in marine species richness and the structural collapse of marine ecosystems may have been decoupled as well, with the former preceding the latter by about 61,000 years according to one study.\nWhether the terrestrial and marine extinctions were synchronous or asynchronous is another point of controversy. Evidence from a well-preserved sequence in east Greenland suggests that the terrestrial and marine extinctions began simultaneously. In this sequence, the decline of animal life is concentrated in a period approximately 10,000 to 60,000 years long, with plants taking an additional several hundred thousand years to show the full impact of the event. Many sedimentary sequences from South China show synchronous terrestrial and marine extinctions. Research in the Sydney Basin of the PTME's duration and course also supports a synchronous occurrence of the terrestrial and marine biotic collapses. Other scientists believe the terrestrial mass extinction began between 60,000 and 370,000 years before the onset of the marine mass extinction. Chemostratigraphic analysis from sections in Finnmark and Tr\u00f8ndelag shows the terrestrial floral turnover occurred before the large negative \u03b413C shift during the marine extinction. Dating of the boundary between the \"Dicynodon\" and \"Lystrosaurus\" assemblage zones in the Karoo Basin indicates that the terrestrial extinction occurred earlier than the marine extinction. The Sunjiagou Formation of South China also records a terrestrial ecosystem demise predating the marine crisis. Other research still has found that the terrestrial extinction occurred after the marine extinction in the tropics.\nStudies of the timing and causes of the Permian-Triassic extinction are complicated by the often-overlooked Capitanian extinction (also called the Guadalupian extinction), just one of perhaps two mass extinctions in the late Permian that closely preceded the Permian-Triassic event. In short, when the Permian-Triassic starts it is difficult to know whether the end-Capitanian had finished, depending on the factor considered. Many of the extinctions once dated to the Permian-Triassic boundary have more recently been re-dated to the end-Capitanian. Further, it is unclear whether some species who survived the prior extinction(s) had recovered well enough for their final demise in the Permian-Triassic event to be considered separate from Capitanian event. A minority point of view considers the sequence of environmental disasters to have effectively constituted a single, prolonged extinction event, perhaps depending on which species is considered. This older theory, still supported in some recent papers, proposes that there were two major extinction pulses 9.4 million years apart, separated by a period of extinctions that were less extensive, but still well above the background level, and that the final extinction killed off only about 80% of marine species alive at that time, whereas the other losses occurred during the first pulse or the interval between pulses. According to this theory, one of these extinction pulses occurred at the end of the Guadalupian epoch of the Permian. For example, all dinocephalian genera died out at the end of the Guadalupian, as did the Verbeekinidae, a family of large-size fusuline foraminifera. The impact of the end-Guadalupian extinction on marine organisms appears to have varied between locations and between taxonomic groups \u2013 brachiopods and corals had severe losses.\nExtinction patterns.\nMarine organisms.\nMarine invertebrates suffered the greatest losses during the P\u2013Tr extinction. (Previous estimates of 90\u201396% marine species extinction were due to historical conflation with the end-Capitanian mass extinction which occurred 7\u201310 million years earlier.) Evidence of this was found in samples from south China sections at the P\u2013Tr boundary. Here, 286 out of 329 marine invertebrate genera disappear within the final two sedimentary zones containing conodonts from the Permian. The decrease in diversity was probably caused by a sharp increase in extinctions, rather than a decrease in speciation.\nThe extinction primarily affected organisms with calcium carbonate skeletons, especially those reliant on stable CO2 levels to produce their skeletons. These organisms were susceptible to the effects of the ocean acidification that resulted from increased atmospheric CO2. Organisms that relied on haemocyanin or haemoglobin for transporting oxygen were more resistant to extinction than those utilizing hemerythrin or oxygen diffusion. There is also evidence that endemism was a strong risk factor influencing a taxon's likelihood of extinction. Bivalve taxa that were endemic and localized to a specific region were more likely to go extinct than cosmopolitan taxa. There was little latitudinal difference in the survival rates of taxa. Organisms that inhabited refugia less affected by global warming experienced lesser or delayed extinctions.\nAmong benthic organisms the extinction event multiplied background extinction rates, and therefore caused maximum species loss to taxa that had a high background extinction rate (by implication, taxa with a high turnover). The extinction rate of marine organisms was catastrophic. Bioturbators were extremely severely affected, as evidenced by the loss of the sedimentary mixed layer in many marine facies during the end-Permian extinction.\nSurviving marine invertebrate groups included articulate brachiopods (those with a hinge), which had undergone a slow decline in numbers since the P\u2013Tr extinction; the Ceratitida order of ammonites; and crinoids (\"sea lilies\"), which very nearly became extinct but later became abundant and diverse. The groups with the highest survival rates generally had active control of circulation, elaborate gas exchange mechanisms, and light calcification; more heavily calcified organisms with simpler breathing apparatuses suffered the greatest loss of species diversity. In the case of the brachiopods, at least, surviving taxa were generally small, rare members of a formerly diverse community.\nConodonts were severely affected both in terms of taxonomic and morphological diversity, although not as severely as during the Capitanian mass extinction.\nThe ammonoids, which had been in a long-term decline for the 30\u00a0million years since the Roadian (middle Permian), suffered a selective extinction pulse 10\u00a0million years before the main event, at the end of the Capitanian stage. In this preliminary extinction, which greatly reduced disparity, or the range of different ecological guilds, environmental factors were apparently responsible. Diversity and disparity fell further until the P\u2013Tr boundary; the extinction here (P\u2013Tr) was non-selective, consistent with a catastrophic initiator. During the Triassic, diversity rose rapidly, but disparity remained low. The range of morphospace occupied by the ammonoids, that is, their range of possible forms, shapes or structures, became more restricted as the Permian progressed. A few million years into the Triassic, the original range of ammonoid structures was once again reoccupied, but the parameters were now shared differently among clades.\nOstracods experienced prolonged diversity perturbations during the Changhsingian before the PTME proper, when immense proportions of them abruptly vanished. At least 74% of ostracods died out during the PTME itself.\nBryozoans had been on a long-term decline throughout the Late Permian epoch before they suffered even more catastrophic losses during the PTME, being the most severely affected clade among the lophophorates.\nDeep water sponges suffered a significant diversity loss and exhibited a decrease in spicule size over the course of the PTME. Shallow water sponges were affected much less strongly; they experienced an increase in spicule size and much lower loss of morphological diversity compared to their deep water counterparts.\nForaminifera suffered a severe bottleneck in diversity. Evidence from South China indicates the foraminiferal extinction had two pulses. Foraminiferal biodiversity hotspots shifted into deeper waters during the PTME. Approximately 93% of latest Permian foraminifera became extinct, with 50% of the clade Textulariina, 92% of Lagenida, 96% of Fusulinida, and 100% of Miliolida disappearing. Foraminifera that were calcareous suffered an extinction rate of 91%. The reasons why lagenides survived while fusulinoidean fusulinides went completely extinct may have been the greater range of environmental tolerance and greater geographic distribution of the former compared to the latter.\nCladodontomorph sharks likely survived the extinction by surviving in refugia in the deep oceans, a hypothesis based on the discovery of Early Cretaceous cladodontomorphs in deep, outer shelf environments. Ichthyosaurs, which evolved immediately before the PTME, were also PTME survivors.\nThe Lilliput effect, the phenomenon of dwarfing of species during and immediately following a mass extinction event, has been observed across the Permian-Triassic boundary, notably occurring in foraminifera, brachiopods, bivalves, and ostracods. Though gastropods that survived the cataclysm were smaller in size than those that did not, it remains debated whether the Lilliput effect truly took hold among gastropods. Some gastropod taxa, termed \"Gulliver gastropods\", ballooned in size during and immediately following the mass extinction, exemplifying the Lilliput effect's opposite, which has been dubbed the Brobdingnag effect.\nTerrestrial invertebrates.\nThe Permian had great diversity in insect and other invertebrate species, including the largest insects ever to have existed. The end-Permian is the largest known mass extinction of insects; according to some sources, it may well be the only mass extinction to significantly affect insect diversity. Eight or nine insect orders became extinct and ten more were greatly reduced in diversity. Palaeodictyopteroids (insects with piercing and sucking mouthparts) began to decline during the mid-Permian; these extinctions have been linked to a change in flora. The greatest decline occurred in the Late Permian and was probably not directly caused by weather-related floral transitions. However, some observed entomofaunal declines in the PTME were biogeographic changes rather than outright extinctions.\nTerrestrial plants.\nThe geological record of terrestrial plants is sparse and based mostly on pollen and spore studies. Floral changes across the Permian-Triassic boundary are highly variable depending on the location and preservation quality of any given site. Plants are relatively immune to mass extinction, with the impact of all the major mass extinctions \"insignificant\" at a family level. Floral diversity losses were more superficial than those of marine animals. Even the reduction observed in species diversity (of 50%) may be mostly due to taphonomic processes. However, a massive rearrangement of ecosystems does occur, with plant abundances and distributions changing profoundly and all the forests virtually disappearing. The dominant floral groups changed, with many groups of land plants entering abrupt decline, such as \"Cordaites\" (gymnosperms) and \"Glossopteris\" (seed ferns). The severity of plant extinction has been disputed.\nThe \"Glossopteris\"-dominated flora that characterized high-latitude Gondwana collapsed in Australia around 370,000 years before the Permian-Triassic boundary, with this flora's collapse being less constrained in western Gondwana but still likely occurring a few hundred thousand years before the boundary. The collapse of this flora is indirectly marked by an abrupt change in river morphology from meandering to braided river systems, signifying the widespread demise of rooted plants.\nPalynological or pollen studies from East Greenland of sedimentary rock strata laid down during the extinction period indicate dense gymnosperm woodlands before the event. At the same time that marine invertebrate macrofauna declined, these large woodlands died out and were followed by a rise in diversity of smaller herbaceous plants including Lycopodiophyta, both Selaginellales and Isoetales. Data from Kap Stosch suggest that floral species richness was not significantly affected during the PTME.\nThe \"Cordaites\" flora, which dominated the Angaran floristic realm corresponding to Siberia, collapsed over the course of the extinction. In the Kuznetsk Basin, the aridity-induced extinction of the regional humid-adapted forest flora dominated by cordaitaleans occurred approximately 252.76 Ma, around 820,000 years before the end-Permian extinction in South China, suggesting that the end-Permian biotic catastrophe may have started earlier on land and that the ecological crisis may have been more gradual and asynchronous on land compared to its more abrupt onset in the marine realm.\nIn North China, the transition between the Upper Shihhotse and Sunjiagou Formations and their lateral equivalents marked a very large extinction of plants in the region. Those plant genera that did not go extinct still experienced a great reduction in their geographic range. Following this transition, coal swamps vanished. The North Chinese floral extinction correlates with the decline of the \"Gigantopteris\" flora of South China.\nIn South China, the subtropical Cathaysian gigantopterid dominated rainforests abruptly collapsed. The floral extinction in South China is associated with bacterial blooms in soil and nearby lacustrine ecosystems, with soil erosion resulting from the die-off of plants being their likely cause. Wildfires too likely played a role in the fall of \"Gigantopteris\".\nA conifer flora in what is now Jordan, known from fossils near the Dead Sea, showed unusual stability over the Permian-Triassic transition, and appears to have been only minimally affected by the crisis.\nTerrestrial vertebrates.\nThe tempo of the terrestrial vertebrate extinction is disputed. Some evidence from the Karoo Basin indicates a protracted extinction lasting a million years. Other evidence from the Karoo deposits suggest it took 50,000 years or less, while a study of coprolites in the Vyazniki fossil beds in Russia suggests it took only a few thousand years. Aridification induced by global warming was the chief culprit behind terrestrial vertebrate extinctions. High herbivore mortality in turn drove carnivore extinctions. There is evidence that over two thirds of terrestrial labyrinthodont amphibians, sauropsid (\"reptile\") and therapsid (\"proto-mammal\") taxa became extinct. Large herbivores suffered the heaviest losses.\nAll Permian anapsid reptiles died out except the procolophonids (although testudines have \"morphologically\"-anapsid skulls, they are now thought to have separately evolved from diapsid ancestors). Pelycosaurs died out before the end of the Permian. Too few Permian diapsid fossils have been found to support any conclusion about the effect of the Permian extinction on diapsids (the \"reptile\" group from which lizards, snakes, crocodilians, and dinosaurs (including birds) evolved). Tangasaurids were largely unaffected. Gorgonopsians are conventionally thought to have gone extinct during the PTME, but some tentative evidence suggests they may have survived into the Triassic. Freshwater and euryhaline fishes, having experienced minimal diversity losses before the PTME, were unaffected during the PTME and actually appear to have increased in diversity across the Permian-Triassic boundary. However, faunal turnovers in freshwater fish communities occurred in areas like the Kuznetsk Basin.\nThe groups that survived suffered extremely heavy losses of species and some terrestrial vertebrate groups very nearly became extinct at the end of the Permian. Some of the surviving groups did not persist for long past this period, but others that barely survived went on to produce diverse and long-lasting lineages. However, it took 30million years for the terrestrial vertebrate fauna to fully recover both numerically and ecologically.\nIt is difficult to estimate extinction and survival rates of land organisms because few terrestrial fossil beds span the Permian\u2013Triassic boundary. The best-known record of vertebrate changes across the Permian\u2013Triassic boundary occurs in the Karoo Supergroup of South Africa, but statistical analyses have so far not produced clear conclusions. One study of the Karoo Basin found that 69% of terrestrial vertebrates went extinct over 300,000 years leading up to the Permian-Triassic boundary, followed by a minor extinction pulse involving four taxa that survived the previous extinction interval. Another study of latest Permian vertebrates in the Karoo Basin found that 54% of them went extinct due to the PTME.\nBiotic recovery.\nIn the wake of the extinction event, the ecological structure of present-day biosphere evolved from the stock of surviving taxa. In the sea, the \"Paleozoic evolutionary fauna\" declined while the \"modern evolutionary fauna\" achieved greater dominance; the Permian-Triassic mass extinction marked a key turning point in this ecological shift that began after the Capitanian mass extinction and culminated in the Late Jurassic. Typical taxa of shelly benthic faunas were now bivalves, snails, sea urchins and Malacostraca, whereas bony fishes and marine reptiles diversified in the pelagic zone. On land, dinosaurs and mammals arose in the course of the Triassic. The profound change in the taxonomic composition was partly a result of the selectivity of the extinction event, which affected some taxa (e.g., brachiopods) more severely than others (e.g., bivalves). However, recovery was also differential between taxa. Some survivors became extinct some million years after the extinction event without having rediversified (dead clade walking, e.g. the snail family Bellerophontidae), whereas others rose to dominance over geologic times (e.g., bivalves).\nMarine ecosystems.\nA cosmopolitanism event began immediately after the end-Permian extinction event. Marine post-extinction faunas were mostly species-poor and were dominated by few disaster taxa such as the bivalves \"Claraia\", \"Unionites\", \"Eumorphotis\", and \"Promyalina\", the conodonts \"Clarkina and Hindeodus,\" the inarticulate brachiopod \"Lingularia\", and the foraminifera \"Earlandia\" and \"Rectocornuspira kalhori\", the latter of which is sometimes classified under the genus \"Ammodiscus\". Their guild diversity was also low. Post-PTME faunas had a flat, insignificant latitudinal diversity gradient.\nThe speed of recovery from the extinction is disputed. Some scientists estimate that it took 10\u00a0million years (until the Middle Triassic) due to the severity of the extinction. However, studies in Bear Lake County, near Paris, Idaho, and nearby sites in Idaho and Nevada showed a relatively quick rebound in a localized Early Triassic marine ecosystem (Paris biota), taking around 1.3\u00a0million years to recover, while an unusually diverse and complex ichnobiota is known from Italy less than a million years after the end-Permian extinction. Additionally, the complex Guiyang biota found near Guiyang, China also indicates life thrived in some places just a million years after the mass extinction, as does a fossil assemblage known as the Shanggan fauna found in Shanggan, China, the Wangmo biota from the Luolou Formation of Guizhou, and a gastropod fauna from the Al Jil Formation of Oman. Regional differences in the pace of biotic recovery existed, which suggests that the impact of the extinction may have been felt less severely in some areas than others, with differential environmental stress and instability being the source of the variance. High latitude ecosystems may have recovered faster due to high post-extinction primary productivity. In addition, it has been proposed that although overall taxonomic diversity rebounded rapidly, functional ecological diversity took much longer to return to its pre-extinction levels; one study concluded that marine ecological recovery was still ongoing 50 million years after the extinction, during the latest Triassic, even though taxonomic diversity had rebounded in a tenth of that time.\nThe pace and timing of recovery also differed based on clade and mode of life. Seafloor communities maintained a comparatively low diversity until the end of the Early Triassic, approximately 4\u00a0million years after the extinction event. Epifaunal benthos took longer to recover than infaunal benthos. This slow recovery stands in remarkable contrast with the quick recovery seen in nektonic organisms such as ammonoids, which exceeded pre-extinction diversities already two million years after the crisis, and conodonts, which diversified considerably over the first two million years of the Early Triassic.\nRecent work suggests that the pace of recovery was intrinsically driven by the intensity of competition among species, which drives rates of niche differentiation and speciation. That recovery was slow in the Early Triassic can be explained by low levels of biological competition due to the paucity of taxonomic diversity, and that biotic recovery explosively accelerated in the Anisian can be explained by niche crowding, a phenomenon that would have drastically increased competition, becoming prevalent by the Anisian. Biodiversity rise thus behaved as a positive feedback loop enhancing itself as it took off in the Spathian and Anisian. Accordingly, low levels of interspecific competition in seafloor communities that are dominated by primary consumers correspond to slow rates of diversification and high levels of interspecific competition among nektonic secondary and tertiary consumers to high diversification rates. Other explanations state that life was delayed in its recovery because grim conditions returned periodically over the course of the Early Triassic, causing further extinction events, such as the Smithian-Spathian boundary extinction. Continual episodes of extremely hot climatic conditions during the Early Triassic have been held responsible for the delayed recovery of oceanic life, in particular skeletonized taxa that are most vulnerable to high carbon dioxide concentrations. The relative delay in the recovery of benthic organisms has been attributed to widespread anoxia, but high abundances of benthic species contradict this explanation. A 2019 study attributed the dissimilarity of recovery times between different ecological communities to differences in local environmental stress during the biotic recovery interval, with regions experiencing persistent environmental stress post-extinction recovering more slowly, supporting the view that recurrent environmental calamities were culpable for retarded biotic recovery. Recurrent Early Triassic environmental stresses also acted as a ceiling limiting the maximum ecological complexity of marine ecosystems until the Spathian. Recovery biotas appear to have been ecologically uneven and unstable into the Anisian, making them vulnerable to environmental stresses.\nWhereas most marine communities were fully recovered by the Middle Triassic, global marine diversity reached pre-extinction values no earlier than the Middle Jurassic, approximately 75\u00a0million years after the extinction event.\nPrior to the extinction, about two-thirds of marine animals were sessile and attached to the seafloor. During the Mesozoic, only about half of the marine animals were sessile while the rest were free-living. Analysis of marine fossils from the period indicated a decrease in the abundance of sessile epifaunal suspension feeders such as brachiopods and sea lilies and an increase in more complex mobile species such as snails, sea urchins and crabs. Before the Permian mass extinction event, both complex and simple marine ecosystems were equally common. After the recovery from the mass extinction, the complex communities outnumbered the simple communities by nearly three to one, and the increase in predation pressure and durophagy led to the Mesozoic Marine Revolution.\nMarine vertebrates recovered relatively quickly, with complex predator-prey interactions with vertebrates at the top of the food web being known from coprolites five million years after the PTME. Post-PTME hybodonts exhibited extremely rapid tooth replacement. Ichthyopterygians appear to have ballooned in size extremely rapidly following the PTME.\nBivalves rapidly recolonized many marine environments in the wake of the catastrophe. Bivalves were fairly rare before the P\u2013Tr extinction but became numerous and diverse in the Triassic, taking over niches that were filled primarily by brachiopods before the mass extinction event. Bivalves were once thought to have outcompeted brachiopods, but this outdated hypothesis about the brachiopod-bivalve transition has been disproven by Bayesian analysis. The success of bivalves in the aftermath of the extinction event may have been a function of them possessing greater resilience to environmental stress compared to the brachiopods that they coexisted with, whilst other studies have emphasised the greater niche breadth of the former. The rise of bivalves to taxonomic and ecological dominance over brachiopods was not synchronous, however, and brachiopods retained an outsized ecological dominance into the Middle Triassic even as bivalves eclipsed them in taxonomic diversity. Some researchers think the brachiopod-bivalve transition was attributable not only to the end-Permian extinction but also the ecological restructuring that began as a result of the Capitanian extinction. Infaunal habits in bivalves became more common after the PTME.\nLinguliform brachiopods were commonplace immediately after the extinction event, their abundance having been essentially unaffected by the crisis. Adaptations for oxygen-poor and warm environments, such as increased lophophoral cavity surface, shell width/length ratio, and shell miniaturization, are observed in post-extinction linguliforms. The surviving brachiopod fauna was very low in diversity and exhibited no provincialism whatsoever. Brachiopods began their recovery around 250.1 \u00b1 0.3 Ma, as marked by the appearance of the genus \"Meishanorhynchia\", believed to be the first of the progenitor brachiopods that evolved after the mass extinction. Major brachiopod rediversification only began in the late Spathian and Anisian in conjunction with the decline of widespread anoxia and extreme heat and the expansion of more habitable climatic zones. Brachiopod taxa during the Anisian recovery interval were only phylogenetically related to Late Permian brachiopods at a familial taxonomic level or higher; the ecology of brachiopods had radically changed from before in the mass extinction's aftermath.\nOstracods were extremely rare during the basal-most Early Triassic. Taxa associated with microbialites were disproportionately represented among ostracod survivors. Ostracod recovery began in the Spathian. Despite high taxonomic turnover, the ecological life modes of Early Triassic ostracods remained rather similar to those of pre-PTME ostracods.\nXiphosurans survived the extinction and played important roles as predators in the immediate aftermath of the extinction, as evidenced by the limulid \"Guangyuanolimulus\" that existed immediately after the PTME's main extinction pulse.\nBryozoans in the Early Triassic were restricted to the Boreal realm. They were also not diverse, represented mainly by members of Trepostomatida. During the Middle Triassic, there was a rise in bryozoan diversity, which peaked in the Carnian. However, bryozoans took until the Late Cretaceous to recover their full diversity.\nCrinoids (\"sea lilies\") suffered a selective extinction, resulting in a decrease in the variety of their forms. Though clade analyses suggest the beginning of their recovery to have taken place in the Induan, the recovery of their diversity as measured by fossil evidence was far less rapid, showing up in the late Ladinian. Their adaptive radiation after the extinction event resulted in forms possessing flexible arms becoming widespread; motility, predominantly a response to predation pressure, also became far more prevalent. Though their taxonomic diversity remained relatively low, crinoids regained much of their ecological dominance by the Middle Triassic epoch. Stem-group echinoids survived the PTME. The survival of miocidarid echinoids such as \"Eotiaris\" is likely attributable to their ability to thrive in a wide range of environmental conditions.\nConodonts saw a rapid recovery during the Induan, with anchignathodontids experiencing a diversity peak in the earliest Induan. Gondolellids diversified at the end of the Griesbachian; this diversity spike was most responsible for the overall conodont diversity peak in the Smithian. Segminiplanate conodonts again experienced a brief period of domination in the early Spathian, probably related to a transient oxygenation of deep waters. Neospathodid conodonts survived the crisis but underwent proteromorphosis.\nIn the PTME's aftermath, disaster taxa of benthic foraminifera filled many of their vacant niches. The recovery of benthic foraminifera was very slow and frequently interrupted until the Spathian. In the Tethys, foraminiferal communities remained low in diversity into the Middle Triassic, with the exception of a notable Ladinian fauna from the Catalonian Basin.\nMicrobial reefs were common across shallow seas for a short time during the earliest Triassic, predominating in low latitudes while being rarer in higher latitudes, occurring both in anoxic and oxic waters. \"Polybessurus\"-like microfossils often dominated these earliest Triassic microbialites. Microbial-metazoan reefs appeared very early in the Early Triassic; and they dominated many surviving communities across the recovery from the mass extinction. Microbialite deposits appear to have declined in the early Griesbachian synchronously with a significant sea level drop that occurred then. Metazoan-built reefs reemerged during the Olenekian, mainly being composed of sponge biostrome and bivalve buildups. Keratinous sponges were particularly noteworthy in their integral importance to Early Triassic microbial-metazoan reef communities, and they helped to create stability in heavily damaged ecosystems during early phases of biotic recovery. \"Tubiphytes\"-dominated reefs appeared at the end of the Olenekian, representing the earliest platform-margin reefs of the Triassic, though they did not become abundant until the late Anisian, when reefs' species richness increased. The first scleractinian corals appear in the late Anisian as well, although they would not become the dominant reef builders until the end of the Triassic period. Bryozoans, after sponges, were the most numerous organisms in Tethyan reefs during the Anisian. Metazoan reefs became common again during the Anisian because the oceans cooled down then from their overheated state during the Early Triassic. Biodiversity amongst metazoan reefs did not recover until well into the Anisian, millions of years after non-reef ecosystems recovered their diversity. Microbially induced sedimentary structures (MISS) from the earliest Triassic have been found to be associated with abundant opportunistic bivalves and vertical burrows, and it is likely that post-extinction microbial mats played a vital, indispensable role in the survival and recovery of various bioturbating organisms. The microbialite refuge hypothesis has been criticised as reflecting a taphonomic bias due to the greater preservation potential of microbialite deposits, however, rather than a genuine phenomenon.\nIchnoconoses show that marine ecosystems recovered to pre-extinction levels of ecological complexity by the late Olenekian. Anisian ichnoconoses show slightly lower diversity than Spathian ichnoconoses, although this was likely a taphonomic consequence of increased and deeper bioturbation erasing evidence of shallower bioturbation.\nIchnological evidence suggests that recovery and recolonization of marine environments may have taken place by way of outward dispersal from refugia that suffered relatively mild perturbations and whose local biota were less strongly affected by the mass extinction compared to the rest of the world's oceans. Although complex bioturbation patterns were rare in the Early Triassic, likely reflecting the inhospitability of many shallow water environments in the extinction's wake, complex ecosystem engineering managed to persist locally in some places, and may have spread from there after harsh conditions across the global ocean were ameliorated over time. Wave-dominated shoreface settings (WDSS) are believed to have served as refugium environments because they appear to have been unusually diverse in the mass extinction's aftermath.\nTerrestrial plants.\nThe proto-recovery of terrestrial floras took place from a few tens of thousands of years after the end-Permian extinction to around 350,000 years after it, with the exact timeline varying by region. Furthermore, severe extinction pulses continued to occur after the Permian-Triassic boundary, causing additional floral turnovers. Gymnosperms recovered within a few thousand years after the Permian-Triassic boundary, but around 500,000 years after it, the Dominant gymnosperm genera were replaced by lycophytes\u00a0\u2013 extant lycophytes are recolonizers of disturbed areas\u00a0\u2013 during an extinction pulse at the Griesbachian-Dienerian boundary. The particular post-extinction dominance of lycophytes, which were well adapted for coastal environments, can be explained in part by global marine transgressions during the Early Triassic. The worldwide recovery of gymnosperm forests took approximately 4\u20135\u00a0million years. However, this trend of prolonged lycophyte dominance during the Early Triassic was not universal, as evidenced by the much more rapid recovery of gymnosperms in certain regions, and floral recovery likely did not follow a congruent, globally universal trend but instead varied by region according to local environmental conditions.\nIn East Greenland, lycophytes replaced gymnosperms as the dominant plants. Later, other groups of gymnosperms again become dominant but again suffered major die-offs. These cyclical flora shifts occurred a few times over the course of the extinction period and afterward. These fluctuations of the dominant flora between woody and herbaceous taxa indicate chronic environmental stress resulting in a loss of most large woodland plant species. The successions and extinctions of plant communities do not coincide with the shift in \u03b413C values but occurred many years after.\nIn what is now the Barents Sea of the coast of Norway, the post-extinction flora is dominated by pteridophytes and lycopods, which were suited for primary succession and recolonization of devastated areas, although gymnosperms made a rapid recovery, with the lycopod dominated flora not persisting across most of the Early Triassic as postulated in other regions.\nIn Europe and North China, the interval of recovery was dominated by the lycopsid \"Pleuromeia\", an opportunistic pioneer plant that filled ecological vacancies until other plants were able to expand out of refugia and recolonize the land. Conifers became common by the early Anisian, while pteridosperms and cycadophytes only fully recovered by the late Anisian.\nDuring the survival phase in the terrestrial extinction's immediate aftermath, from the latest Changhsingian to the Griesbachian, South China was dominated by opportunistic lycophytes. Low-lying herbaceous vegetation dominated by the isoetalean \"Tomiostrobus\" was ubiquitous following the collapse of the gigantopterid-dominated forests of before. In contrast to the highly biodiverse gigantopterid rainforests, the post-extinction landscape of South China was near-barren and had vastly lower diversity. Plant survivors of the PTME in South China experienced extremely high rates of mutagenesis induced by heavy metal poisoning. From the late Griesbachian to the Smithian, conifers and ferns began to rediversify. After the Smithian, the opportunistic lycophyte flora declined, as the newly radiating conifer and fern species permanently replaced them as the dominant components of South China's flora.\nOn the Tibetan plateau, China, the early Dienerian \"Endosporites papillatus\"\u2013\"Pinuspollenites thoracatus\" assemblages closely resemble late Changhsingian Tibetan floras, suggesting that the widespread, dominant latest Permian flora repopulated easily after the PTME. However, in the late Dienerian, a major shift towards assemblages dominated by cavate trilete spores took place, heralding widespread deforestation and a rapid change to hotter, more humid conditions. Quillworts and spike mosses dominated Tibetan flora for about a million years after this shift.\nIn Pakistan, then the northern margin of Gondwana, the flora was rich in lycopods associated with conifers and pteridosperms. Floral turnovers continued to occur due to repeated perturbations arising from recurrent volcanic activity until terrestrial ecosystems stabilized around 2.1 Myr after the PTME.\nIn southwestern Gondwana, the post-extinction flora was dominated by bennettitaleans and cycads, with members of Peltaspermales, Ginkgoales, and Umkomasiales being less common constituents of this flora. Around the Induan-Olenekian boundary, as paleocommunities recovered, a new \"Dicroidium\" flora was established, in which Umkomasiales continued to be prominent and in which Equisetales and Cycadales were subordinate forms. The \"Dicroidium\" flora further diversified in the Anisian to its peak, wherein Umkomasiales and Ginkgoales constituted most of the tree canopy and Peltaspermales, Petriellales, Cycadales, Umkomasiales, Gnetales, Equisetales, and Dipteridaceae dominated the undergrowth.\nCoal gap.\nNo coal deposits are known from the Early Triassic, and those in the Middle Triassic are thin and low-grade. This \"coal gap\" has been explained in many ways. It has been suggested that new, more aggressive fungi, insects, and vertebrates evolved and killed vast numbers of trees. These decomposers themselves suffered heavy losses of species during the extinction and are not considered a likely cause of the coal gap. It could simply be that all coal-forming plants were rendered extinct by the P\u2013Tr extinction and that it took 10\u00a0million years for a new suite of plants to adapt to the moist, acid conditions of peat bogs. Abiotic factors (factors not caused by organisms), such as decreased rainfall or increased input of clastic sediments, may also be to blame.\nOn the other hand, the lack of coal may simply reflect the scarcity of all known sediments from the Early Triassic. Coal-producing ecosystems, rather than disappearing, may have moved to areas where we have no sedimentary record for the Early Triassic. For example, in eastern Australia a cold climate had been the norm for a long period, with a peat mire ecosystem adapted to these conditions. Approximately 95% of these peat-producing plants went \"locally\" extinct at the P\u2013Tr boundary; coal deposits in Australia and Antarctica disappear well \"before\" the P\u2013Tr boundary.\nTerrestrial vertebrates.\nLand vertebrates took an unusually long time to recover from the P\u2013Tr extinction; paleontologist Michael Benton estimated the recovery was not complete until after the extinction, i.e. not until the Late Triassic, when the first dinosaurs had risen from bipedal archosaurian ancestors and the first mammals from small cynodont ancestors. A tetrapod gap may have existed from the Induan until the early Spathian between ~30 \u00b0N and ~ 40 \u00b0S due to extreme heat making these low latitudes uninhabitable for these animals. During the hottest phases of this interval, the gap would have spanned an even greater latitudinal range. East-central Pangaea, with its relatively wet climate, served as a dispersal corridor for PTME survivors during their Early Triassic recolonization of the supercontinent. In North China, tetrapod body and ichnofossils are extremely rare in Induan facies, but become more abundant in the Olenekian and Anisian, showing a biotic recovery of tetrapods synchronous with the decreasing aridity during the Olenekian and Anisian. In Russia, even after 15 Myr of recovery, during which ecosystems were rebuilt and remodeled, many terrestrial vertebrate guilds were absent, including small insectivores, small piscivores, large herbivores, and apex predators. Lacustrine ecosystems took about 10 Myr to recover. Coprolitic evidence indicates that freshwater food webs had recovered by the early Ladinian, with a lacustrine coprolite assemblage from the Ordos Basin of China providing evidence of a trophically multileveled ecosystem containing at least six different trophic levels. The highest trophic levels were filled by vertebrate predators. Geochemical evidence has further bolstered this finding. Overall, terrestrial faunas after the extinction event tended to be more variable and heterogeneous across space than those of the Late Permian, which exhibited less provincialism, being much more geographically homogeneous.\nSynapsids.\n\"Lystrosaurus\", a pig-sized herbivorous dicynodont therapsid, constituted as much as 90% of some earliest Triassic land vertebrate fauna, although some recent evidence has called into question its status as a post-PTME disaster taxon. The dicynodont genus is often used as a biostratigraphic marker for the PTME. The evolutionary success of \"Lystrosaurus\" in the aftermath of the PTME is believed to be attributable to the dicynodont taxon's grouping behaviour and tolerance for extreme and highly variable climatic conditions. Other likely factors behind the success of \"Lystrosaurus\" included extremely fast growth rate exhibited by the dicynodont genus, along with its early onset of sexual maturity. Antarctica may have served as a refuge for dicynodonts during the PTME from which surviving dicynodonts spread out of in its aftermath. Ichnological evidence from the earliest Triassic of the Karoo Basin shows dicynodonts were abundant in the immediate aftermath of the biotic crisis. Smaller carnivorous cynodont therapsids also survived, a group that included the ancestors of mammals. As with dicynodonts, selective pressures favoured endothermic epicynodonts. Therocephalians likewise survived; burrowing may have been a key adaptation that helped them make it through the PTME. In the Karoo region of southern Africa, the therocephalians \"Tetracynodon\", \"Moschorhinus\" and \"Promoschorhynchus\" (the latter based on specimens originally assigned to \"Ictidosuchoides\") survived, but do not appear to have been abundant in the Triassic. Early Triassic therocephalians were mostly survivors of the PTME rather than newly evolved taxa that originated during the evolutionary radiation in its aftermath. Both therocephalians and cynodonts, known collectively as eutheriodonts, decreased in body size from the Late Permian to the Early Triassic. This decrease in body size has been interpreted as an example of the Lilliput effect.\nSauropsids.\nArchosaurs (which included the ancestors of dinosaurs and crocodilians) were initially rarer than therapsids, but they began to displace therapsids in the mid-Triassic. Olenekian tooth fossil assemblages from the Karoo Basin indicate that archosauromorphs were already highly diverse by this point in time, though not very ecologically specialised. In the mid to late Triassic, the dinosaurs evolved from one group of archosaurs, and went on to dominate terrestrial ecosystems during the Jurassic and Cretaceous. This \"Triassic Takeover\" may have contributed to the evolution of mammals by forcing the surviving therapsids and their mammaliform successors to live as small, mainly nocturnal insectivores; nocturnal life probably forced at least the mammaliforms to develop fur, better hearing and higher metabolic rates, while losing part of the differential color-sensitive retinal receptors reptilians and birds preserved. Archosaurs also experienced an increase in metabolic rates over time during the Early Triassic. The archosaur dominance would end again due to the Cretaceous\u2013Paleogene extinction event, after which both birds (only extant dinosaurs) and mammals (only extant synapsids) would diversify and share the world.\nTemnospondyls.\nTemnospondyl amphibians made a quick recovery; the appearance in the fossil record of so many temnospondyl clades suggests they may have been ideally suited as pioneer species that recolonised decimated ecosystems. During the Induan, tupilakosaurids in particular thrived as disaster taxa, including \"Tupilakosaurus\" itself, though they gave way to other temnospondyls as ecosystems recovered. Temnospondyls were reduced in size during the Induan, but their body size rebounded to pre-PTME levels during the Olenekian. \"Mastodonsaurus\" and trematosaurians were the main aquatic and semiaquatic predators during most of the Triassic, some preying on tetrapods and others on fish.\nTerrestrial invertebrates.\nMost fossil insect groups found after the Permian\u2013Triassic boundary differ significantly from those before: Of Paleozoic insect groups, only the Glosselytrodea, Miomoptera, and Protorthoptera have been discovered in deposits from after the extinction. The caloneurodeans, paleodictyopteroids, protelytropterans, and protodonates became extinct by the end of the Permian. Though Triassic insects are very different from those of the Permian, a gap in the insect fossil record spans approximately 15\u00a0million years from the late Permian to early Triassic. In well-documented Late Triassic deposits, fossils overwhelmingly consist of modern insect groups.\nMicrobially induced sedimentary structures (MISS) dominated North Chinese terrestrial fossil assemblages in the Early Triassic. In Arctic Canada as well, MISS became a common occurrence following the Permian-Triassic extinction. The prevalence of MISS in many Early Triassic rocks shows that microbial mats were an important feature of post-extinction ecosystems that were denuded of bioturbators that would have otherwise prevented their widespread occurrence. The disappearance of MISS later in the Early Triassic likely indicated a greater recovery of terrestrial ecosystems and specifically a return of prevalent bioturbation.\nHypotheses about cause.\nExplaining an event from 250 million years ago is inherently difficult, with much of the evidence on land eroded or deeply buried, while the spreading seafloor is completely recycled over 200\u00a0million years, leaving no useful indications beneath the ocean.\nYet, scientists have gathered significant evidence for causes, and several mechanisms have been proposed. The proposals include both catastrophic and gradual processes (similar to those theorized for the Cretaceous\u2013Paleogene extinction event, but with much less current consensus).\nAny hypothesis about the cause must explain the selectivity of the event, which affected organisms with calcium carbonate skeletons most severely; the long period (4 to 6\u00a0million years) before recovery started, and the minimal extent of biological mineralization (despite inorganic carbonates being deposited) once the recovery began.\nVolcanism.\nSiberian Traps.\nThe flood basalt eruptions that produced the large igneous province of the Siberian Traps were among the largest known volcanic events, extruding lava over , roughly the size of Saudi Arabia, producing a catastrophic impact. The date of the Siberian Traps eruptions matches well with the extinction event. A study of the Norilsk and Maymecha-Kotuy regions of the northern Siberian platform indicates that volcanic activity occurred during a few enormous pulses of magma, as opposed to more regular flows.\nThe Siberian Traps caused one of the most rapid rises of atmospheric carbon dioxide levels in the geologic record, with the rate of carbon dioxide emissions estimated as five times faster than during the preceding catastrophic Capitanian mass extinction during the eruption of the Emeishan Traps. Overwhelming inorganic carbon sinks, carbon dioxide levels might have jumped from between 500 and 4,000 ppm prior to the extinction to around 8,000 ppm after, according to one estimate. Another study estimated pre-extinction carbon dioxide levels at 400 ppm, which then rose to 2,500 ppm, with 3,900 to 12,000 gigatonnes of carbon added to the ocean-atmosphere system. Extreme temperature rise would have followed, though some evidence suggests a lag of 12,000 to 128,000 years between the rise in volcanic carbon dioxide emissions and global warming. Although this discrepancy could be also attributed to a incorrect biochronology. During the latest Permian before the extinction, global average surface temperatures were about 18.2\u00a0\u00b0C, which shot up to as much as 35\u00a0\u00b0C, this hyperthermal condition lasting as long as 500,000 years. Air temperatures at Gondwana's high southern latitudes experienced a warming of ~10\u201314\u00a0\u00b0C. According to oxygen isotope shifts from conodont apatite in South China, low latitude surface water temperatures surged about 8\u00a0\u00b0C. In present-day Iran, tropical sea surface temperatures were between 27 and 33\u00a0\u00b0C during the Changhsingian but jumped to over 35\u00a0\u00b0C during the PTME. The increased mean state temperatures also brought stronger El Nino events, heightening short-term climate variability.\nThese extremely high atmospheric carbon dioxide concentrations persisted over a long period. The position and alignment of Pangaea at the time made the inorganic carbon cycle very inefficient at burying carbon. In a 2020 paper, scientists reconstructed the mechanisms that led to the extinction event in a biogeochemical model, showed the consequences of the greenhouse effect on the marine environment, and concluded that the mass extinction can be traced back to volcanic CO2 emissions. Evidence also points to volcanic combustion of underground fossil fuel deposits, based on paired coronene-mercury spikes coinciding with geographically widespread mercury anomalies and the rise in isotopically light carbon. Te/Th values increase twentyfold over the PTME, further indicating it was concomitant with extreme volcanism. A major volcanogenic influx of isotopically light zinc from the Siberian Traps has also been recorded, further confirming that volcanism was contemporary with the PTME.\nThe Siberian Traps eruptions had unusual features that made them even more dangerous. The Siberian lithosphere is rich in halogens extremely destructive to the ozone layer, and evidence from subcontinental lithospheric xenoliths indicates that as much as 70% of their halogen content was released into the atmosphere. Around 18 teratonnes of hydrochloric acid were emitted, along with sulphur-rich volatiles that caused dust clouds and acid aerosols, which would have blocked out sunlight and disrupted photosynthesis on land and in the photic zone of the ocean, causing food chains to collapse. These volcanic outbursts of sulphur also induced brief but severe global cooling punctuating the broader trend of rapid global warming, with glacio-eustatic sea level fall. However, the briefness of these cold events makes them unlikely to have been a significant kill mechanism.\nThe eruptions may also have caused acid rain as the aerosols washed out of the atmosphere. That may have killed land plants and mollusks and planktonic organisms with calcium carbonate shells. Pure flood basalts produce fluid, low-viscosity lava, and do not hurl debris into the atmosphere. It appears, however, that 20% of the output of the Siberian Traps eruptions was pyroclastic ash thrown high into the atmosphere, increasing the short-term cooling effect. When this had washed out of the atmosphere, the excess carbon dioxide would have remained and global warming would have proceeded unchecked.\nBurning of hydrocarbon deposits may have exacerbated the extinction. The Siberian Traps are underlain by thick sequences of Early-Mid Paleozoic aged carbonate and evaporite deposits, as well as Carboniferous-Permian aged coal bearing clastic rocks. When heated, such as by igneous intrusions, these rocks may emit large amounts of greenhouse and toxic gases. The unique setting of the Siberian Traps over these deposits is likely the reason for the severity of the extinction. The basalt lava erupted or intruded into carbonate rocks and sediments in the process of forming large coal beds, which would have emitted large amounts of carbon dioxide, leading to stronger global warming after the dust and aerosols settled. The change of the eruptions from flood basalt to sill dominated emplacement, liberating even more trapped hydrocarbon deposits, coincides with the main onset of the extinction and is linked to a major negative \u03b413C excursion. The intermediate temperature of the Siberian Traps magmas optimised the extremely voluminous release of CO2 by way of heating of evaporites and carbonates.\nVenting of coal-derived methane was accompanied by explosive combustion of coal and discharge of coal-fly ash. A 2011 study led by Stephen E. Grasby reported evidence that volcanism caused massive coal beds to ignite, possibly releasing more than 3\u00a0trillion tons of carbon. They found ash deposits in deep rock layers near what is now the Buchanan Lake Formation: \"coal ash dispersed by the explosive Siberian Trap eruption would be expected to have an associated release of toxic elements in impacted water bodies where fly ash slurries developed. ... Mafic megascale eruptions are long-lived events that would allow significant build-up of global ash clouds.\" Grasby said, \"In addition to these volcanoes causing fires through coal, the ash it spewed was highly toxic and was released in the land and water, potentially contributing to the worst extinction event in Earth history.\" However, some researchers propose that these supposed fly ashes were actually the result of wildfires not related to massive coal combustion by intrusive magmatism. A 2013 study led by Q.Y. Yang reported that the total amounts of important volatiles emitted from the Siberian Traps consisted of 8.5 \u00d7 107 Tg CO2, 4.4 \u00d7 106 Tg CO, 7.0 \u00d7 106 Tg H2S, and 6.8 \u00d7 107 Tg SO2.\nThe sill-dominated emplacement of the Siberian Traps prolonged their warming effects; whereas extrusive volcanism generates an abundance of subaerial basalts that efficiently sequester carbon dioxide via the silicate weathering process, underground sills cannot sequester atmospheric carbon dioxide and mitigate global warming. Additionally, enhanced reverse weathering and depletion of siliceous carbon sinks enabled extreme warmth to persist for much longer than expected if the excess carbon dioxide was sequestered by silicate rock.\nThe reduction in marine primary productivity diminished emissions of dimethyl sulphate and dimethylsulphoniopropionate, enhancing warming. Also, the decline in biological silicate deposition resulting from the mass extinction of siliceous organisms acted as a positive feedback loop wherein mass death of marine life exacerbated and prolonged extreme hothouse conditions by depleting yet another siliceous carbon sink.\nMercury anomalies corresponding to the time of Siberian Traps activity have been found in many geographically disparate sites, indicating that these volcanic eruptions released significant quantities of toxic mercury into the atmosphere and ocean, causing even larger terrestrial and marine die-offs. A series of surges raised terrestrial and marine environmental mercury concentrations by orders of magnitude above normal background levels and caused mercury poisoning over periods of a thousand years each. Mutagenesis in surviving plants after the PTME coeval with mercury and copper loading confirms volcanically induced heavy metal toxicity. Increased bioproductivity may have sequestered mercury and party mitigated poisoning. Immense volumes of nickel aerosols and cobalt and arsenic emissions, were also released, further contributing to metal poisoning.\nThe devastation wrought by the Siberian Traps did not end following the Permian-Triassic boundary. Carbon isotope fluctuations suggest that massive Siberian Traps activity recurred many times during the Early Triassic, a finding corroborated by mercury spikes, causing further extinction events during the epoch.\nChoiyoi Silicic Large Igneous Province.\nA second flood basalt event that produced the Choiyoi Silicic Large Igneous Province in southwestern Gondwana between around 286 Ma and 247 Ma has also been suggested as a significant additional extinction mechanism. At 1,300,000 cubic kilometres in volume and 1,680,000 square kilometres in area, this event was 40% the size of the Siberian Traps. Specifically, this flood basalt has been implicated in the regional demise of the Gondwanan \"Glossopteris\" flora.\nIndochina\u2013South China subduction-zone volcanic arc.\nMercury anomalies preceding the end-Permian extinction have been discovered in what was then the boundary between the South China craton and the Indochinese plate, a subduction zone with a volcanic arc. Hafnium isotopes from syndepositional magmatic zircons found in ash beds created by this volcanic pulse confirm its origin in subduction-zone volcanism rather than large igneous province activity. The enrichment of copper samples from these deposits in isotopically light copper provide additional confirmation. This volcanism has been speculated to have caused local biotic stress among radiolarians, sponges, and brachiopods over the 60,000 years preceding the end-Permian marine extinction, as well as an ammonoid crisis with decreased morphological complexity and size and increased rate of turnover beginning in the lower \"C. yini\" biozone, around 200,000 years before the extinction.\nMethane clathrate gasification.\nMethane clathrates, also known as methane hydrates, consist of molecules of methane trapped in the crystal lattice of ice. This methane, produced by methanogen microbes, has a 13C \"\u2044\" 12C isotope ratio about 6% below normal (\u03b413C \u22126.0%). At the right combination of pressure and temperature, clathrates form near the surface of permafrost and in large quantities on continental shelves and nearby seabed at water depths of at least , buried in sediments up to below the sea floor.\nMassive release of methane from these clathrates may have contributed to the PTME, as scientists have found worldwide evidence of a swift decrease of about 1% in the13C \"\u2044\" 12C ratioin carbonate rocks from the end-Permian. This is the first, largest, and fastest of a series of excursions (decreases and increases) in the ratio, until it abruptly stabilised in the middle Triassic, followed soon afterwards by the recovery of calcifying shelled sealife. The seabed probably contained methane hydrate deposits, and the lava caused the deposits to dissociate, releasing vast quantities of methane.\nA vast release of methane might cause significant global warming since methane is a very powerful greenhouse gas. Strong evidence suggests the global temperatures increased by about 6\u00a0\u00b0C (10.8\u00a0\u00b0F) near the equator and therefore by more at higher latitudes: a sharp decrease in oxygen isotope ratios (18O \"\u2044\" 16O); the extinction of \"Glossopteris\" flora (\"Glossopteris\" and plants that grew in the same areas), which needed a cold climate, with its replacement by floras typical of lower paleolatitudes. It was also suggested that a large-scale release of methane and other greenhouse gases from the ocean into the atmosphere was connected to the anoxic events and euxinic (sulfidic) events at the time, with the exact mechanism compared to the 1986 Lake Nyos disaster.\nThe clathrate hypothesis seemed the only proposed mechanism sufficient to cause a global 1% reduction in the 13C \"\u2044\" 12C ratio. While a variety of factors may have contributed to the ratio drop, a 2002 review found most of them insufficient to account for the observed amount: \nHowever, the clathrate hypothesis has also been criticized. Carbon-cycle models that include consideration of roasting carbonate sediments by volcanism confirm that it would have had enough effect to produce the observed reduction. Also, the pattern of isotope shifts expected to result from a massive release of methane does not match the patterns seen throughout the Early Triassic. Not only would such a cause require the release of five times as much methane as postulated for the PETM, but would it also have to be reburied at an unrealistically high rate to account for the rapid increases in the 13C \"\u2044\" 12C ratio (episodes of high positive \u03b413C) throughout the early Triassic before it was released several times again. The latest research suggests that greenhouse gas release during the extinction event was dominated by volcanic carbon dioxide, and while methane release had to have contributed, isotopic signatures show that thermogenic methane released from the Siberian Traps had consistently played a larger role than methane from clathrates and any other biogenic sources such as wetlands during the event.\nAdding to the evidence against methane clathrate release as the central driver of warming, the main rapid warming event is also associated with marine transgression rather than regression; the former would not normally have initiated methane release, which would have instead required a decrease in pressure, something that would be generated by a retreat of shallow seas. The configuration of the world's landmasses into one supercontinent would also mean that the global gas hydrate reservoir was lower than today, further damaging the case for methane clathrate dissolution as a major cause of the carbon cycle disruption.\nHypercapnia and acidification.\nMarine organisms are more sensitive to changes in CO2 (carbon dioxide) levels than terrestrial organisms for a variety of reasons. CO2 is 28 times more soluble in water than oxygen. Marine animals normally function with lower concentrations of CO2 in their bodies than land animals, as the removal of CO2 in air-breathing animals is impeded by the need for the gas to pass through the respiratory system's membranes (lungs' alveolus, tracheae, and the like), even when CO2 diffuses more easily than oxygen. In marine organisms, relatively modest but sustained increases in CO2 concentrations hamper the synthesis of proteins, reduce fertilization rates, and produce deformities in calcareous hard parts. Higher concentrations of CO2 also result in decreased activity levels in many active marine animals, hindering their ability to obtain food. An analysis of marine fossils from the Permian's final Changhsingian stage found that marine organisms with a low tolerance for hypercapnia (high concentration of carbon dioxide) had high extinction rates, and the most tolerant organisms had very slight losses. The most vulnerable marine organisms were those that produced calcareous hard parts (from calcium carbonate) and had low metabolic rates and weak respiratory systems, notably calcareous sponges, rugose and tabulate corals, calcite-depositing brachiopods, bryozoans, and echinoderms; about 81% of such genera became extinct. Close relatives without calcareous hard parts suffered only minor losses, such as sea anemones, from which modern corals evolved. Animals with high metabolic rates, well-developed respiratory systems, and non-calcareous hard parts had negligible losses except for conodonts, in which 33% of genera died out. This pattern is also consistent with what is known about the effects of hypoxia, a shortage but not total absence of oxygen. However, hypoxia cannot have been the only killing mechanism for marine organisms. Nearly all of the continental shelf waters would have had to become severely hypoxic to account for the magnitude of the extinction, but such a catastrophe would make it difficult to explain the very selective pattern of the extinction. Mathematical models of the Late Permian and Early Triassic atmospheres show a significant but protracted decline in atmospheric oxygen levels, with no acceleration near the P\u2013Tr boundary. Minimum atmospheric oxygen levels in the Early Triassic are never less than present-day levels and so the decline in oxygen levels does not match the temporal pattern of the extinction.\nIn addition, an increase in CO2 concentration is inevitably linked to ocean acidification, consistent with the preferential extinction of heavily calcified taxa and other signals in the rock record that suggest a more acidic ocean, such as a carbonate production crisis that occurred a few thousand years after volcanic greenhouse gas emissions began. The decrease in ocean pH is calculated to be up to 0.7 units. An extreme aragonite sea formed. Ocean acidification was most extreme at mid-latitudes, and the major marine transgression associated with the end-Permian extinction is believed to have devastated shallow shelf communities in conjunction with anoxia. Evidence from paralic facies spanning the Permian-Triassic boundary in western Guizhou and eastern Yunnan, however, shows a local marine transgression dominated by carbonate deposition, suggesting that ocean acidification did not occur across the entire globe and was likely limited to certain regions of the world's oceans. One study, published in \"Scientific Reports\", concluded that widespread ocean acidification, if it did occur, was not intense enough to impede calcification and only occurred during the beginning of the extinction event. The relative success of many marine organisms that were very vulnerable to acidification has further been used to argue that acidification was not a major extinction contributor. The persistence of highly elevated carbon dioxide concentrations in the atmosphere and ocean during the Early Triassic would have impeded the recovery of biocalcifying organisms after the PTME.\nAcidity generated by increased carbon dioxide concentrations in soil and sulphur dioxide dissolution in rainwater was also a kill mechanism on land. The increasing acidification of rainwater caused increased soil erosion as a result of the increased acidity of forest soils, evidenced by the increased influx of terrestrially derived organic sediments found in marine sedimentary deposits during the end-Permian extinction. Further evidence of an increase in soil acidity comes from elevated Ba/Sr ratios in earliest Triassic soils. A positive feedback loop further enhancing and prolonging soil acidification may have resulted from the decline of infaunal invertebrates like tubificids and chironomids, which remove acid metabolites from the soil. The increased abundance of vermiculitic clays in Shansi, South China coinciding with the Permian-Triassic boundary strongly suggests a sharp drop in soil pH causally related to volcanogenic emissions of carbon dioxide and sulphur dioxide. Hopane anomalies have also been interpreted as evidence of acidic soils and peats. As with many other environmental stressors, acidity on land episodically persisted well into the Triassic, stunting the recovery of terrestrial ecosystems.\nAnoxia and euxinia.\nEvidence for widespread ocean anoxia (severe deficiency of oxygen) and euxinia (presence of hydrogen sulfide) is found from the Late Permian to the Early Triassic. Throughout most of the Tethys and Panthalassic Oceans, evidence for anoxia appears at the extinction event, including small pyrite framboids, negative \u03b4238U excursions, negative \u03b415N excursions, positive \u03b482/78Se isotope excursions, relatively positive \u03b413C ratios in polycyclic aromatic hydrocarbons, high Th/U ratios, positive Ce/Ce* anomalies, depletions of molybdenum, uranium, and vanadium from seawater, and fine laminations in sediments. However, evidence for anoxia precedes the extinction at some other sites, including Spiti, India, Shangsi, China, Meishan, China, Opal Creek, Alberta, and Kap Stosch, Greenland. Biogeochemical evidence also points to the presence of euxinia during the PTME. Biomarkers for green sulfur bacteria, such as isorenieratane, the diagenetic product of isorenieratene, are widely used as indicators of photic zone euxinia because green sulfur bacteria require both sunlight and hydrogen sulfide to survive. Their abundance in sediments from the P\u2013T boundary indicates euxinic conditions were present even in the shallow waters of the photic zone. Negative mercury isotope excursions further bolster evidence for extensive euxinia during the PTME. The disproportionate extinction of high-latitude marine species provides further evidence for oxygen depletion as a killing mechanism; low-latitude species living in warmer, less oxygenated waters are naturally better adapted to lower levels of oxygen and are able to migrate to higher latitudes during periods of global warming, whereas high-latitude organisms are unable to escape from warming, hypoxic waters at the poles. Evidence of a lag between volcanic mercury inputs and biotic turnovers provides further support for anoxia and euxinia as the key killing mechanism, because extinctions would be expected to be synchronous with volcanic mercury discharge if volcanism and hypercapnia was the primary driver of extinction. The sequence of extinctions in some sections, with deep water organisms being affected first followed by shallow water and then by bottom water organisms, is believed to reflect the migration of oxygen minimum zones. Models of ocean chemistry suggest that anoxia and euxinia were closely associated with hypercapnia. This suggests that poisoning from hydrogen sulfide, anoxia, and hypercapnia acted together as a killing mechanism. Hypercapnia best explains the selectivity of the extinction, but anoxia and euxinia probably contributed to the high mortality of the event.\nThe sequence of events leading to anoxic oceans may have been triggered by carbon dioxide emissions from the eruption of the Siberian Traps. In that scenario, warming from the enhanced greenhouse effect would reduce the solubility of oxygen in seawater, causing the concentration of oxygen to decline. Increased coastal evaporation would have caused the formation of warm saline bottom water (WSBW) depleted in oxygen and nutrients, which spread across the world through the deep oceans. The influx of WSBW caused thermal expansion of water that raised sea levels, bringing anoxic waters onto shallow shelfs and enhancing the formation of WSBW in a positive feedback loop. The flux of terrigeneous material into the oceans increased as a result of soil erosion, which would have facilitated increased eutrophication; marine regression likewise enhanced terrigeneous material inputs. Increased chemical weathering of the continents due to warming and the acceleration of the water cycle would increase the riverine flux of nutrients to the ocean. Additionally, the Siberian Traps directly fertilised the oceans with iron and phosphorus as well, triggering bioblooms and marine snowstorms. Increased phosphate levels would have supported greater primary productivity in the surface oceans. The increase in organic matter production would have caused more organic matter to sink into the deep ocean, where its respiration would further decrease oxygen concentrations. Once anoxia became established, it would have been sustained by a positive feedback loop because deep water anoxia tends to increase the recycling efficiency of phosphate, leading to even higher productivity. Along the Panthalassan coast of South China, oxygen decline was also driven by large-scale upwelling of deep water enriched in various nutrients, causing this region of the ocean to be hit by especially severe anoxia. Convective overturn helped facilitate the expansion of anoxia throughout the water column. A severe anoxic event at the end of the Permian would have allowed sulfate-reducing bacteria to thrive, causing the production of large amounts of hydrogen sulfide in the anoxic ocean, turning it euxinic. In some regions, anoxia briefly disappeared when transient cold snaps resulting from volcanic sulphur emissions occurred.\nThe persistence of anoxia through the Early Triassic may explain the slow recovery of marine life and low levels of biodiversity after the extinction, particularly that of benthic organisms. Anoxia disappeared from shallow waters more rapidly than the deep ocean. Reexpansions of oxygen-minimum zones did not cease until the late Spathian, periodically setting back and restarting the biotic recovery process. The decline in continental weathering towards the end of the Spathian at last began ameliorating marine life from recurrent anoxia. In some regions of Panthalassa, pelagic zone anoxia continued to recur as late as the Anisian, probably due to increased productivity and a return of aeolian upwelling. Some sections show a rather quick return to oxic water column conditions, however, so for how long anoxia persisted remains debated. The volatility of the Early Triassic sulphur cycle suggests marine life continued to face returns of euxinia as well.\nSome scientists have challenged the anoxia hypothesis on the grounds that long-lasting anoxic conditions could not have been supported if Late Permian thermohaline ocean circulation conformed to the \"thermal mode\" characterised by cooling at high latitudes. Anoxia may have persisted under a \"haline mode\" in which circulation was driven by subtropical evaporation, although the \"haline mode\" is highly unstable and was unlikely to have represented Late Permian oceanic circulation.\nOxygen depletion via extensive microbial blooms also played a role in the biological collapse of not just marine ecosystems but freshwater ones as well. Persistent lack of oxygen after the extinction event itself helped delay biotic recovery for much of the Early Triassic epoch.\nAridification.\nIncreasing continental aridity, a trend well underway even before the PTME as a result of the coalescence of the supercontinent Pangaea, was drastically exacerbated by terminal Permian volcanism and global warming. The combination of global warming and drying generated an increased incidence of wildfires. Tropical coastal swamp floras such as those in South China may have been very detrimentally impacted by the increase in wildfires, though it is ultimately unclear if an increase in wildfires played a role in driving taxa to extinction.\nAridification trends varied widely in their tempo and regional impact. Analysis of the fossil river deposits of the floodplains of the Karoo Basin indicate a shift from meandering to braided river patterns, indicating a very abrupt drying of the climate. The climate change may have taken as little as 100,000 years, prompting the extinction of the unique \"Glossopteris\" flora and its associated herbivores, followed by the carnivorous guild. A pattern of aridity-induced extinctions that progressively ascended up the food chain has been deduced from Karoo Basin biostratigraphy. Evidence for aridification in the Karoo across the Permian-Triassic boundary is not, however, universal, as some palaeosol evidence indicates a wettening of the local climate during the transition between the two geologic periods. Evidence from the Sydney Basin of eastern Australia, on the other hand, suggests that the expansion of semi-arid and arid climatic belts across Pangaea was not immediate but was instead a gradual, prolonged process. Apart from the disappearance of peatlands, there was little evidence of significant sedimentological changes in depositional style across the Permian-Triassic boundary. Instead, a modest shift to amplified seasonality and hotter summers is suggested by palaeoclimatological models based on weathering proxies from the region's Late Permian and Early Triassic deposits. In the Kuznetsk Basin of southwestern Siberia, an increase in aridity led to the demise of the humid-adapted \"Cordaites\" forests in the region a few hundred thousand years before the Permian-Triassic boundary. Drying of this basin has been attributed to a broader poleward shift of drier, more arid climates during the late Changhsingian before the more abrupt main phase of the extinction at the Permian-Triassic boundary that disproportionately affected tropical and subtropical species.\nThe persistence of hyperaridity varied regionally as well. In the North China Basin, highly arid climatic conditions are recorded during the latest Permian, near the Permian-Triassic boundary, with a swing towards increased precipitation during the Early Triassic, the latter likely assisting biotic recovery following the mass extinction. Elsewhere, such as in the Karoo Basin, episodes of dry climate recurred regularly in the Early Triassic, with profound effects on terrestrial tetrapods.\nThe types and diversity of ichnofossils in a locality has been used as an indicator measuring aridity. Nurra, an ichnofossil site on the island of Sardinia, shows evidence of major drought-related stress among crustaceans. Whereas the Permian subnetwork at Nurra displays extensive horizontal backfilled traces and high ichnodiversity, the Early Triassic subnetwork is characterised by an absence of backfilled traces, an ichnological sign of aridification.\nOzone depletion.\nA collapse of the atmospheric ozone shield has been invoked as an explanation for the mass extinction, particularly that of terrestrial plants. Ozone production may have been reduced by 60\u201370%, increasing the flux of ultraviolet radiation by 400% at equatorial latitudes and 5,000% at polar latitudes. The hypothesis has the advantage of explaining the mass extinction of plants, which would have added to the methane levels and should otherwise have thrived in an atmosphere with a high level of carbon dioxide. Fossil spores from the end-Permian further support the theory; many spores show deformities that could have been caused by ultraviolet radiation, which would have been more intense after hydrogen sulfide emissions weakened the ozone layer. Malformed plant spores from the time of the extinction event show an increase in ultraviolet B absorbing compounds, confirming that increased ultraviolet radiation played a role in the environmental catastrophe and excluding other possible causes of mutagenesis, such as heavy metal toxicity, in these mutated spores. Extremely positive \u039433S anomalies provide evidence of photolysis of volcanic SO2, indicating increased ultraviolet radiation flux. Sulphur isotope data from North China are inconsistent with a total collapse of the ozone layer, however, suggesting it may have not been as major a kill mechanism as others.\nMultiple mechanisms could have reduced the ozone shield and rendered it ineffective. Computer modelling shows high atmospheric methane levels are associated with ozone shield decline and may have contributed to its reduction during the PTME. Volcanic emissions of sulphate aerosols into the stratosphere would have dealt significant destruction to the ozone layer. As mentioned previously, the rocks in the region where the Siberian Traps were emplaced are extremely rich in halogens. The intrusion of Siberian Traps volcanism into deposits rich in organohalogens, such as methyl bromide and methyl chloride, would have been another source of ozone destruction. An uptick in wildfires, a natural source of methyl chloride, would have had further deleterious effects still on the atmospheric ozone shield. Upwelling of euxinic water may have released massive hydrogen sulphide emissions into the atmosphere and would poison terrestrial plants and animals and severely weaken the ozone layer, exposing much of the life that remained to fatal levels of UV radiation, although other modelling work has found that the release of this gas would not have significantly damaged the ozone layer. Indeed, biomarker evidence for anaerobic photosynthesis by Chlorobiaceae (green sulfur bacteria) from the Late-Permian into the Early Triassic indicates that hydrogen sulphide did upwell into shallow waters because these bacteria are restricted to the photic zone and use sulfide as an electron donor.\nAsteroid impact.\nEvidence that an impact event may have caused the Cretaceous\u2013Paleogene extinction has led to speculation that similar impacts may have been the cause of other extinction events, including the P\u2013Tr extinction, and thus to a search for evidence of impacts at the times of other extinctions, such as large impact craters of the appropriate age. However, suggestions that an asteroid impact was the trigger of the Permian-Triassic extinction are now largely rejected.\nReported evidence for an impact event from the P\u2013Tr boundary level includes rare grains of shocked quartz in Australia and Antarctica; fullerenes trapping extraterrestrial noble gases; meteorite fragments in Antarctica; and grains rich in iron, nickel, and silicon, which may have been created by an impact. However, the accuracy of most of these claims has been challenged. For example, quartz from Graphite Peak in Antarctica, once considered \"shocked\", has been re-examined by optical and transmission electron microscopy. The observed features were concluded to be due not to shock, but rather to plastic deformation, consistent with formation in a tectonic environment such as volcanism. Iridium levels in many sites straddling the Permian-Triassic boundaries are not anomalous, providing evidence against an extraterrestrial impact as the PTME's cause.\nAn impact crater on the seafloor would be evidence of a possible cause of the P\u2013Tr extinction, but such a crater would by now have disappeared. As 70% of the Earth's surface is currently sea, an asteroid or comet fragment is now perhaps more than twice as likely to hit the ocean as it is to hit land. However, Earth's oldest ocean-floor crust is only 200\u00a0million years old as it is continually being destroyed and renewed by spreading and subduction. Furthermore, craters produced by very large impacts may be masked by extensive flood basalting from below after the crust is punctured or weakened. Yet, subduction should not be entirely accepted as an explanation for the lack of evidence: as with the K-T event, an ejecta blanket stratum rich in siderophilic elements (such as iridium) would be expected in formations from the time.\nA large impact might have triggered other mechanisms of extinction described above, such as the Siberian Traps eruptions at either an impact site or the antipode of an impact site. The abruptness of an impact also explains why more species did not rapidly evolve to survive, as would be expected if the Permian\u2013Triassic event had been slower and less global than a meteorite impact.\nBolide impact claims have been criticised on the grounds that they are unnecessary as explanations for the extinctions, and they do not fit the known data compatible with a protracted extinction spanning thousands of years. Additionally, many sites spanning the Permian-Triassic boundary display a complete lack of evidence of an impact event.\nPossible impact sites.\nPossible impact craters proposed as the site of an impact causing the P\u2013Tr extinction include the Bedout structure off the northwest coast of Australia and the hypothesized Wilkes Land crater of East Antarctica. An impact has not been proved in either case, and the idea has been widely criticized. The Wilkes Land geophysical feature is of very uncertain age, possibly later than the Permian\u2013Triassic extinction.\nAnother impact hypothesis postulates that the impact event that formed the Araguainha crater, whose formation has been dated to 254.7 \u00b1 2.5 million, a possible temporal range overlapping with the end-Permian extinction, precipitated the mass extinction. The impact occurred around extensive deposits of oil shale in the shallow marine Paran\u00e1\u2013Karoo Basin, whose perturbation by the seismicity resulting from impact likely discharged about 1.6 teratonnes of methane into Earth's atmosphere, buttressing the already rapid warming caused by hydrocarbon release due to the Siberian Traps. The large earthquakes generated by the impact would have additionally generated massive tsunamis across much of the globe. Despite this, most palaeontologists reject the impact as being a significant driver of the extinction, citing the relatively low energy (equivalent to 105 to 106 megatons of TNT, around two orders of magnitude lower than the impact energy believed to be required to induce mass extinctions) released by the impact.\nA 2017 paper noted the discovery of a circular gravity anomaly near the Falkland Islands that might correspond to an impact crater with a diameter of , as supported by seismic and magnetic evidence. Estimates for the age of the structure range up to 250\u00a0million years old. This would be substantially larger than the well-known Chicxulub impact crater associated with a later extinction. However, Dave McCarthy and colleagues from the British Geological Survey illustrated that the gravity anomaly is not circular and also that the seismic data presented by Rocca, Rampino and Baez Presser did not cross the proposed crater or provide any evidence for an impact crater.\nMethanogens.\nA hypothesis published in 2014 posits that a genus of anaerobic methanogenic archaea known as \"Methanosarcina\" was responsible for the event. Three lines of evidence suggest that these microbes acquired a new metabolic pathway via gene transfer at about that time, enabling them to efficiently metabolize acetate into methane. That would have led to their exponential reproduction, allowing them to rapidly consume vast deposits of organic carbon that had accumulated in marine sediment. The result would have been a sharp buildup of methane and carbon dioxide in the oceans and atmosphere, in a manner that may be consistent with the 13C/12C isotopic record. Massive volcanism facilitated this process by releasing large amounts of nickel, a scarce metal that is a cofactor for enzymes involved in producing methane. Chemostratigraphic analysis of Permian-Triassic boundary sediments in Chaotian demonstrates a methanogenic burst could be responsible for some percentage of the carbon isotopic fluctuations. On the other hand, in the canonical Meishan sections, the nickel concentration increases somewhat after the \u03b413C concentrations have begun to fall.\nInterstellar dust.\nJohn Gribbin argues that the Solar System last passed through a spiral arm of the Milky Way around 250\u00a0million years ago and that the resultant dusty gas clouds may have caused a dimming of the Sun, which combined with the effect of Pangaea to produce an ice age.\nComparison to present global warming.\nThe PTME has been compared to the current anthropogenic global warming situation and Holocene extinction due to sharing the common characteristic of rapid rates of carbon dioxide release. Though the current rate of greenhouse gas emissions is more than an order of magnitude greater than the rate measured over the course of the PTME, the discharge of greenhouse gases during the PTME is poorly constrained geo-chronologically and was most likely pulsed and constrained to a few key, short intervals, rather than continuously occurring at a constant rate for the whole extinction interval; the rate of carbon release within these intervals was likely to have been similar in timing to modern anthropogenic emissions. As they did during the PTME, oceans in the present day are experiencing drops in pH and in oxygen levels, prompting further comparisons between modern anthropogenic ecological conditions and the PTME. Another biocalcification event similar in its effects on modern marine ecosystems is predicted to occur if carbon dioxide levels continue to rise. The changes in plant-insect interactions resulting from the PTME have also been invoked as possible indicators of the world's future ecology. The similarities between the two extinction events have led to warnings from geologists about the urgent need for reducing carbon dioxide emissions if an event similar to the PTME is to be prevented from occurring.\nJust as during the PTME, contemporary oceans experience their extreme change-change in the form of a decline in pH and oxygen levels, which further strengthens the pull between the two events. This is emphasised by geologist Lee Kump:\"The Permian-Triassic mass extinction provides a stark reminder of the consequences of rapid carbon dioxide emissions. During the PTME, volcanic activity unleashed massive amounts of CO\u2082, leading to ocean acidification, deoxygenation, and widespread ecological collapse. Today, we see human activities driving similar processes at an even faster rate. The geological record shows that once these tipping points are reached, the cascading effects on ecosystems can last for millions of years.\" If it continues to rise, the consequence could be another bio-calcification crisis, as seems to have occurred in the fossil record, which would have disastrous consequences for modern marine ecosystems.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24750", "revid": "2842084", "url": "https://en.wikipedia.org/wiki?curid=24750", "title": "Porter Blanchard", "text": "American silversmith\nPorter George Blanchard (February 28, 1886 \u2013 November 1, 1973) was an American silversmith living and working in Pacoima, California. He is considered to have been part of the Arts and Crafts Movement.\nCareer.\nBlanchard learned the trade of the silversmith from his father, George Porter Blanchard in Gardner, Massachusetts. In 1923, Blanchard moved to Burbank, California, where he established a studio for silversmithing. Between the 1930s and 1950, he operated a shop in Hollywood. He then worked from his home in Pacoima from the 1940s until his death in 1973.\nHis daughter Alice Blanchard married Lewis Wise, who conducted business as Porter Blanchard Silversmiths in Calabasas, California. After 1955, all Porter Blanchard flatware was made at the Calabasas shop, while the holloware was made at Blanchard's Pacoima home. His daughter Rebecca married Allan Adler, who continued designing as a silversmith in the Arts and Crafts tradition.\nBlanchard was a member of the Boston Society of Arts and Crafts and was awarded their title of medalist in 1944.\nLegacy.\nMany of his papers, including photographs of his shop, are collected in the Archives of American Art at the Smithsonian Institution in Washington, D.C. They were donated to the Archives by his daughters, Rebecca Adler and Alice E. Wise.\nBlanchard's works are in the collections of various museums, including the Cooper-Hewitt National Design Museum, the Los Angeles County Museum of Art, and the Oakland Museum of California.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24751", "revid": "49645270", "url": "https://en.wikipedia.org/wiki?curid=24751", "title": "Punjab, Pakistan", "text": "Province of Pakistan\nPunjab ( ; , ) is a province of Pakistan. With a population of over 127 million, it is the most populous province in Pakistan and the second most populous subnational polity in the world. Located in the central-eastern region of the country, it has the largest economy, contributing the most to national GDP in Pakistan. Lahore is the capital and largest city of the province. Other major cities include Faisalabad, Rawalpindi, Gujranwala and Multan.\nIt is bordered by the Pakistani provinces of Khyber Pakhtunkhwa to the north-west, Balochistan to the south-west and Sindh to the south, as well as Islamabad Capital Territory to the north-west and Azad Kashmir to the north. It shares an international border with the Indian states of Rajasthan and Punjab to the east and Indian-administered Kashmir to the north-east. Punjab is the most fertile province of the country as the Indus River and its four major tributaries Ravi, Jhelum, Chenab, and Sutlej flow through it.\nThe province forms the bulk of the transnational Punjab region, partitioned in 1947 between Pakistan and India. The province is represented in the federal parliament through 173, out of 336, seats in National Assembly, the lower house; and 23, out of 96, seats in Senate, the upper house.\nPunjab is Pakistan's most industrialised province, with the industrial sector comprising 24 per cent of the province's gross domestic product. It is known for its relative prosperity, and has the lowest rate of poverty among all Pakistani provinces. However, a clear divide is present between the northern and southern regions of the province; with northern Punjab being relatively more developed than southern Punjab. Punjab is also one of the most urbanised regions of South Asia, with approximately 40 percent of its population being concentrated in urban areas.\nPunjabi Muslims form majority of the province. Their culture has been strongly influenced by Islamic culture and Sufism, with a number of Sufi shrines spread across the province. Guru Nanak, the founder of Sikhism, was born in the town of Nankana Sahib. Punjab hosts several of the UNESCO World Heritage Sites, including the Shalimar Gardens, the Lahore Fort, the archaeological excavations at Taxila, and the Rohtas Fort, among others.\nEtymology.\nThe name \"Punjab\" consists of two parts ( and ), of Persian origin which are cognates of the Sanskrit words ( and ). The word \"pa\u00f1j-\u0101b\" is the calque of Indo-Aryan \"pa\u00f1ca-\u00e1p\" and means \"The Land of Five Waters\", referring to the rivers Jhelum, Chenab, Ravi, Sutlej, and Beas. All are tributaries of the Indus River, the Sutlej being the largest. References to a land of five rivers are found in the \"Mahabharata\", in which one of the regions is named as \"Panchanada\" (). The ancient Greeks referred to the region as \"Pentapotam\u00eda\" (), of the same meaning as that of Punjab. Earlier, Punjab was also known as \"Sapta Sindhu\" in the Rigveda and \"Hapta Hendu\" in the Avesta, translating into \"The Land of Seven Rivers\"; the other two being Indus and Kabul which are included in the greater Punjab region. The current name gained currency during the Mughal period.\nHistory.\nAncient period.\nIt is believed that the earliest evidence of human habitation in Punjab traces to the Soan Valley of the Pothohar, between the Indus and the Jhelum rivers, where Soanian culture developed between 774,000 BC and 11,700 BC. This period goes back to the first interglacial period in the second Ice Age, from which remnants of stone and flint tools have been found. The Punjab region was the site of one of the earliest cradle of civilisations, the Bronze Age Harrapan civilisation that flourished from about 3000 B.C. and declined rapidly 1,000 years later, following the Indo-Aryan migrations that overran the region in waves between 1500 and 500 B.C. The migrating Indo-Aryan tribes gave rise to the Iron Age Vedic civilisation, which lasted till 500 BC. During this era, the Rigveda was composed in Punjab, laying the foundation of Hinduism. Frequent intertribal wars in the post-Vedic period stimulated the growth of larger groupings ruled by chieftains and kings, who ruled local kingdoms known as Mahajanapadas. Achaemenid emperor Darius the Great, in 518 BCE crossed the Indus and annex the regions up to the Jhelum River. Taxila is considered to be the site of one of the oldest education centre of South Asia and was part of the Achaemenid province of Hindush.\nOne of the early kings in Punjab was Porus, who fought the famous Battle of the Hydaspes against Alexander the Great. The battle is thought to have resulted in a decisive Greek victory; however, A. B. Bosworth warns against an uncritical reading of Greek sources who were obviously exaggerative. Porus refused to surrender and wandered about atop an elephant, until he was wounded and his force routed. When asked by Alexander how he wished to be treated, Porus replied \"Treat me as a king would treat another king\". Despite the apparently one-sided results, Alexander was impressed by Porus and chose to not depose him. Not only was his territory reinstated but also expanded with Alexander's forces annexing the territories of Glausaes, who ruled to the northeast of Porus' kingdom. The battle is historically significant because it resulted in the syncretism of ancient Greek political and cultural influences on the Indian subcontinent, yielding works such as Greco-Buddhist art, which continued to have an impact for the ensuing centuries.\nMultan was the noted center of excellence of the region, which was attacked by the Greek army during the era of Alexander the Great. The Malli tribe, together with nearby tribes, gathered an army of 90,000-100,000 personnel to face the Greek army. This was perhaps the largest army faced by the Greeks in the entire Indian subcontinent. During the siege of the city's citadel, Alexander leaped into the inner area of the citadel, where he faced the Mallians' leader. Alexander was wounded by an arrow that had penetrated his lung, leaving him severely injured. The city was conquered after a fierce battle.\nThe region was then divided between the Maurya Empire and the Greco-Bactrian kingdom in 302 B.C.E. Menander I Soter conquered Punjab and made Sagala (present-day Sialkot) the capital of the Indo-Greek Kingdom. Menander is noted for becoming a patron and converting to Greco-Buddhism and he is widely regarded as the greatest of the Indo-Greek kings.\nMedieval period.\nFollowing the Muslim conquests in the Indian subcontinent at the beginning of the 8th century, Arab armies of the Umayyad Caliphate penetrated South Asia, introducing Islam into the Punjab. First, Islam was introduced into the Southern Punjab in the opening decades of the eighth century. By the 16th century, Muslims were the majority in the region and an elaborate network of mosques and mausoleums marked the landscape. Local Punjabi Muslim converts constituted the majority of this Muslim community, and as far for the mechanisms of conversion, the sources of the period emphasise the recitation of the Islamic confession of faith (\"shahada\"), the performance of the circumcision, and the ingestion of cow-meat.\nIslam emerged as the major power in Punjab after the Umayyad army led by Muhammad ibn al-Qasim conquered the region in 711 AD. The city of Multan became a centre of Islam. After the Umayyads conquered the key cities of Uch and Multan, they ruled the far areas of Punjab and included Kashmir. Islam spread rapidly.\nAccording to local traditions, Baba Ratan Hindi was a trader from Punjab who was one of the non-Arab companions of Prophet Muhammad. He was reportedly a trader who used to take goods to Arabia. There is also a dargah named after him, the Haji Ratan Dargah, in Bathinda, where he settled after his conversion to Islam. Muslims who migrated to Pakistan during the partition of India in 1947 still venerate him as Baba Haji Ratan.\nIn the ninth century, the Hindu Shahi dynasty originating from the region of Oddiyana replaced the Taank kingdom in the Punjab, ruling much of Punjab along with eastern Afghanistan. In the 10th century, the tribe of the Gakhars/Khokhars, formed a large part of the Hindu Shahi army according to the Persian historian Firishta.\nGhaznavid\nThe Turkic Ghaznavids in the tenth century attacked the regions of Punjab. Multan and Uch were conquered after 3 attacks, and Multan's ruler, Abul Fateh Daud was defeated, famous Sun Temple was destroyed. Ghaznavids overthrew the Hindu Shahis and consequently ruled for 157 years, gradually declining as a power until the Ghurid conquests of key Punjab cities of Uch, Multan and Lahore by Muhammad of Ghor in 1186, deposing the last Ghaznavid ruler Khusrau Malik.\nFollowing the death of Muhammad of Ghor in 1206, the Ghurid state fragmented and was replaced in northern India by the Delhi Sultanate, and for some time, independent sultanates ruled by various Sultans. The Delhi Sultanate ruled Punjab for the next three hundred years, led by five unrelated dynasties, the Mamluks, Khalajis, Tughlaqs, Sayyids and Lodis.\nDelhi Sultanate\nTughlaqs\nGhiyath al-Din Tughlaq, the former governor of Multan and Dipalpur founded the Tughlaq dynasty in Delhi and ruled the subcontinent region. Earlier, he served as the governor of Multan and fought 28 battles against Mongols from there and saved Punjab and Sindh regions from the advances of Mongols and survived. After his death, his son Muhammad Tughlaq became the emperor.\nSayyid Dynasty\nThe 15th century saw the rise of many prominent Muslims from Punjab. Khizr Khan established the Sayyid dynasty, the fourth dynasty of the Delhi Sultanate, with four rulers ruling from 1414 to 1451 for 37 years. The first ruler of the dynasty, Khizr Khan, who was the Timurid vassal of Multan, conquered Delhi in 1414, while the rulers proclaimed themselves the Sultans of the Delhi Sultanate under Mubarak Shah, which succeeded the Tughlaq dynasty and ruled the Sultanate until they were displaced by the Lodi dynasty in 1451.\nKhizr Khan was originally a noble in the Delhi Sultanate during the Tughlaq Dynasty and was the governor of Multan under Sultan Firuz Shah. He was expelled from the city by the Muin tribes under Sarang Khan who occupied Multan in 1395, an Indian Muslim and the brother of Mallu Iqbal Khan, who was the de facto ruler of Delhi. Sarang Khan was aided by the servants of Malik Mardan Bhatti, a former governor of Multan and the grandfather of Khizr Khan by adoption.\nIn 1398, Timur attacked the Punjab region. After his invasion, Khizr Khan established the fourth dynasty of the Delhi Sultanate. According to Richard M. Eaton, Khizr Khan was the son of a Punjabi chieftain. He was a Khokhar chieftain who travelled to Samarkand and profited from the contacts he made with the Timurid society.\nFollowing Timur's 1398 Sack of Delhi, he appointed Khizr Khan as deputy of Multan (Punjab). He held Lahore, Dipalpur, Multan and Upper Sindh. Collecting his forces in Multan, Khizr Khan defeated and killed Mallu Iqbal Khan in Delhi in 1405. He then captured Delhi on 28 May 1414 thereby establishing the Sayyid dynasty. Khizr Khan did not take up the title of Sultan, but continued the fiction of his allegiance to Timur as \"Rayat-i-Ala\" (vassal) of the Timurids - initially that of Timur, and later his son Shah Rukh. After the accession of Khizr Khan, the Punjab, Uttar Pradesh and Sindh were reunited under the Delhi Sultanate, where he spent his time subduing rebellions.\nKhizr Khan was succeeded by his son Sayyid Mubarak Shah after his death on 20 May 1421. Mubarak Shah referred to himself as \"Muizz-ud-Din Mubarak Shah\" on his coins, removing the Timurid name with the name of the Caliph, and declared himself a Shah. A detailed account of his reign is available in the \"Tarikh-i-Mubarak Shahi\" written by Yahya-bin-Ahmad Sirhindi. After the death of Mubarak Shah, his nephew, Muhammad Shah ascended the throne and styled himself as Sultan Muhammad Shah. Just before his death, he called his son Sayyid Ala-ud-Din Shah from Badaun, and nominated him as successor.\nThe last ruler of the Sayyids, Ala-ud-Din, voluntarily abdicated the throne of the Delhi Sultanate in favour of Bahlul Khan Lodi on 19 April 1451, and left for Badaun, where he died in 1478.Langah Sultanate\nIn 1445, Sultan Qutbudin, chief of \"Langah tribe\", established the Langah Sultanate in Multan. The Sultanate included regions of southern and central Punjab and some areas of present-day Khyber. A large number of Baloch settlers arrived and the towns of Dera Ghazi Khan and Dera Ismail Khan were founded.\nDuring the most of 15th century, the Khokhars and Gakhars tribes were in general revolt in the Pothohar region. Jasrath Khokhar was one of their major chiefs who helped Sultan Zain Ul Abideen of Kashmir Sultanate to gain his throne and ruled over vast tracts of Jammu and North Punjab. He also conquered Delhi for a brief period in 1431 but was driven out by Mubarak Shah.\nModern period.\nMughal Era\nThe Mughals came to power in the early sixteenth century and gradually expanded to control all of Punjab. During Mughal period Punjab region was divided into two provinces; Province of Multan and Province of Lahore. The Subah of Lahore was one of the three \"subahs\" (provinces) of the Mughal Empire in the Punjab region, alongside Multan and Delhi subahs, encompassing the northern, central and eastern Punjab. It was created as one of the original 12 Subahs of the Mughal Empire under the administrative reforms carried by Akbar in 1580. The province ceased to exist after the death of its last viceroy, Adina Beg in 1758, with large parts being incorporated into Durrani Empire. Collectively, Lahore and Multan subahs, and parts of Delhi subah, comprised \"Mughal Punjab\".\nDuring the Mughal era, Saadullah Khan, born into a family of Punjabi Muslim agriculturalist from Chiniot remained the Grand vizier and Vakil-i-Mutlaq of the Mughal Empire in the period 1645\u20131656, during the reign of Shah Jahan. Other prominent Muslims from Punjab who rose to nobility during the Mughal Era include Wazir Khan, Adina Beg Arain, and Shahbaz Khan Kamboh.\nThe Mughal Empire ruled the region until it was severely weakened in the eighteenth century. As Mughal power weakened, Afghan rulers of Durrani dynasty took control of the region.\nThe Sikh Empire ruled Punjab from 1799 until the British annexed it in 1849 following the First and Second Anglo-Sikh Wars.\n18th Century Punjabi Muslim states.\nChattha State (1750 - 1797).\nThe Chatthas under their leader Nur Muhammad Chattha declared independence from Mughal Empire in 1750 and formed the Chattha State.After Pir Muhammad Chattha's death his son Ghulam Muhammad Chattha inherited the Chattha state and the hatred of Sukerchakias. The rivalry was passed down to Mahan Singh and Ghulam Muhammad Chattha.\nUnder his leadership the Chathas gained several successes over the Sikhs,and it at one time looked as if the progress of the Sikh arms had been arrested and their dominion in the Doab annihilated.\nChattha State was annexed when Jan muhammad Chattha was killed in a siege led by Ranjit Singh when the latter recovered the lost Chattha state with Afghan aid.\nFollowing the disintegration of the Mughal Empire, the shrine's \"D\u012bw\u0101n\" was able to forge a political independent state centered on Pakpattan. In 1757, \"D\u012bw\u0101n\" 'Abd as-Sub\u1e25\u0101n gathered an army of his Jat mur\u012bds, attacked the Raja of Bikaner, and thereby expanded the shrine's territorial holdings for the first time east of the Sutlej. Around 1776, the \"D\u012bw\u0101n\", supported mainly by his Wattu mur\u012bds, successfully repelled an attack by the Sikh Nakai Misl, resulting in the death of the Nakai leader, Heera Singh Sandhu.\nSial State (1723 - 1816).\nSial state was established by the 13 Sial Chief Nawab Walidad Khan Sial in 1723. He gradually gained control of the lower Rachna doab, including the cities of Chiniot, Pindi Bhattian, Jhang and Mankera.\nNext chief, Inayatullah Khan (r.\u20091747\u2013 1787) was a successful general who won 22 battles against Bhangi Misl and the Multan chiefs.\nSikh Empire invaded Jhang multiple times from 1801 to 1816. Sial state was annexed by Sikh Empire and Ahmad Khan Sial was awarded a Jagir by Ranjit Singh.\nBritish Rule\nMost of the Punjabi homeland formed a province of British India, though a number of small princely states retained local rulers who recognised British authority. The Punjab with its rich farmlands became one of the most important colonial assets. Lahore was a noted center of learning and culture, and Rawalpindi became an important military installation.\nMost Punjabis supported the British during World War I, providing men and resources to the war effort even though the Punjab remained a source of anti-colonial activities. Disturbances in the region increased as the war continued. At the end of the war, high casualty rates, heavy taxation, inflation, and a widespread influenza epidemic disrupted Punjabi society. In 1919 a British officer ordered his troops to fire on a crowd of demonstrators, mostly Sikhs in Amritsar. The Jallianwala massacre fuelled the Indian independence movement. Nationalists declared the independence of India from Lahore in 1930 but were quickly suppressed.\nWhen the Second World War broke out, nationalism in British India had already divided into religious movements. Many Sikhs and other minorities supported the Hindus, who promised a secular multicultural and multireligious society, and Muslim leaders in Lahore passed a resolution to work for a Muslim Pakistan, making the Punjab region a center of growing conflict between Indian and Pakistani nationalists. At the end of the war, the British granted separate independence to India and Pakistan, setting off massive communal violence as Muslims fled to Pakistan and Hindu and Sikh Punjabis fled east to India.\nThe British Raj had major political, cultural, philosophical, and literary consequences in the Punjab, including the establishment of a new system of education. During the independence movement, many Punjabis played a significant role, including Madan Lal Dhingra, Sukhdev Thapar, Ajit Singh Sandhu, Bhagat Singh, Udham Singh, Kartar Singh Sarabha, Bhai Parmanand, Choudhry Rahmat Ali, and Lala Lajpat Rai.\nAfter Independence\nAt the time of partition in 1947, the province was split into East and West Punjab. East Punjab (48%) became part of India, while West Punjab (52%) became part of Pakistan. The Punjab bore the brunt of the civil unrest following partition, with casualties estimated to be in the millions.\nAnother major consequence of partition was the sudden shift towards religious homogeneity that occurred in all districts across Punjab owing to the new international border that cut through the province. This rapid demographic shift was primarily due to wide-scale migration but also caused by large-scale religious cleansing riots which were witnessed across the region at the time. According to historical demographer Tim Dyson, in the eastern regions of Punjab that ultimately became Indian Punjab following independence, districts that were 66% Hindu in 1941 became 80% Hindu in 1951; those that were 20% Sikh became 50% Sikh in 1951. Conversely, in the western regions of Punjab that ultimately became Pakistani Punjab, all districts became almost exclusively Muslim by 1951.\nGeography.\nPunjab is Pakistan's second largest province by area after Balochistan with an area of . It occupies 25.8% of the total landmass of Pakistan. Punjab province is bordered by Sindh to the south, the province of Balochistan to the southwest, the province of Khyber Pakhtunkhwa to the west, and the Islamabad Capital Territory and Azad Kashmir in the north. Punjab borders Jammu and Kashmir in the north, and the Indian states of Punjab and Rajasthan to the east.\nThe capital and largest city is Lahore which was the capital of the wider Punjab region since 17th century. Other important cities include Faisalabad, Rawalpindi, Gujranwala, Sargodha, Multan, Sialkot, Bahawalpur, Gujrat, Sheikhupura, Jhelum, Rahim Yar Khan and Sahiwal. The undivided Punjab region was home to six rivers, of which five flow through Pakistan's Punjab province. From west to east, the rivers are: the Indus, Jhelum, Chenab, Ravi and Sutlej. It is the nation's only province that touches every other province; it also surrounds the federal enclave of the national capital city of Islamabad.\nTopography.\nPunjab's landscape mostly consists of fertile alluvial plains of the Indus River and its four major tributaries in Pakistan, the Jhelum, Chenab, Ravi, and Sutlej rivers which traverse Punjab north to south \u2013 the fifth of the \"five waters\" of Punjab, the Beas River, lies exclusively in the Indian state of Punjab. The landscape is amongst the most heavily irrigated on earth and canals can be found throughout the province. Punjab also includes several mountainous regions, including the Sulaiman Mountains in the southwest part of the province, the Margalla Hills in the north near Islamabad, and the Salt Range which divides the most northerly portion of Punjab, the Pothohar Plateau, from the rest of the province. Sparse deserts can be found in southern Punjab near the border with Rajasthan and the Sulaiman Range. Punjab also contains part of the Thal and Cholistan deserts. In the South, Punjab's elevation reaches near the hill station of Fort Munro in Dera Ghazi Khan.\nClimate.\nMost areas in Punjab experience extreme weather with foggy winters, often accompanied by rain. By mid-February the temperature begins to rise; springtime weather continues until mid-April, when the summer heat sets in.\nThe onset of the southwest monsoon is anticipated to reach Punjab by May, but since the early 1970s, the weather pattern has been irregular. The spring monsoon has either skipped over the area or has caused it to rain so hard that floods have resulted. June and July are oppressively hot. Although official estimates rarely place the temperature above 46\u00a0\u00b0C, newspaper sources claim that it reaches 51\u00a0\u00b0C and regularly carry reports about people who have succumbed to the heat. Heat records were broken in Multan in June 1993, when the mercury was reported to have risen to 54\u00a0\u00b0C. In August the oppressive heat is punctuated by the rainy season, referred to as \"barsat\", which brings relief in its wake. The hardest part of the summer is then over, but cooler weather does not come until late October.\nIn early 2007, the province experienced one of the coldest winters in the last 70 years.\nPunjab's region temperature ranges from \u22122\u00b0 to 45\u00a0\u00b0C, but can reach 50\u00a0\u00b0C (122\u00a0\u00b0F) in summer and can touch down to \u221210\u00a0\u00b0C in winter.\nClimatically, Punjab has three major seasons:\nWeather extremes are notable from the hot and barren south to the cool hills of the north. The foothills of the Himalayas are found in the extreme north as well, and feature a much cooler and wetter climate, with snowfall common at higher altitudes.\nDemographics.\nPopulation.\nThe province is home to over half the population of Pakistan, and is the world's second-most populous subnational entity, and the most populous outside of India and China.\nLanguages.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nThe major native language spoken in Punjab is Punjabi, representing the largest language spoken in the country. The Punjabi language is spoken in the form of many dialects across the province, including Majhi, Pothwari, Thali, Jhangvi, Dhanni, Shahpuri, and Doabi. In addition to Punjabi, other closely related languages such as Saraiki in the south (including Multani, Derawali, and Riasti dialects) and Hindko in the northwest (including Chachhi, Ghebi, and Awankari dialects) are also spoken widely. Both Saraiki and Hindko have been enumerated separately from Punjabi in the Pakistani censuses of 1981 and 2017.\nReligions.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nAccording to the 2023 census, the population of Punjab, Pakistan was 127,688,922. With 124,462,897 adherents, Muslims comprise the largest religious group, with a Sunni Hanafi majority and a Shia Ithna 'ashariyah minority, forming approximately 97.75 percent of the population. The largest non-Muslim minority is Christians with 2,458,924 adherents, forming roughly 1.93 percent of the population. Hindus form 249,716 people, comprising approximately 0.20 percent of the population. The other minorities include Sikhs and Parsis.\nGovernment and administration.\nThe Government of Punjab is a provincial government in the federal structure of Pakistan, is based in Lahore, the capital of the Punjab Province. The Chief Minister of Punjab (CM) is elected by the Provincial Assembly of the Punjab to serve as the head of the provincial government in Punjab, Pakistan. The current Chief Minister is Maryam Nawaz Sharif, who is also the first ever woman Chief Minister of any province in Pakistan. The Provincial Assembly of the Punjab is a unicameral legislature of elected representatives of the province of Punjab, which is located in Lahore in eastern Pakistan. The Assembly was established under Article 106 of the Constitution of Pakistan as having a total of 371 seats, with 66 seats reserved for women and eight reserved for non-Muslims.\nThere are 48 departments in Punjab government. Each Department is headed by a Provincial Minister (Politician) and a Provincial Secretary (A civil servant of usually BPS-20 or BPS-21). All Ministers report to the Chief Minister, who is the Chief Executive. All Secretaries report to the Chief Secretary of Punjab, who is usually a BPS-22 Civil Servant. The Chief Secretary in turn, reports to the Chief Minister. In addition to these departments, there are several Autonomous Bodies and Attached Departments that report directly to either the Secretaries or the Chief Secretary.\nEconomy.\nPunjab has the largest economy in Pakistan, contributing most to the national GDP. The province's economy has quadrupled since 1972. Its share of Pakistan's GDP was 54.7% in 2000 and 59% as of 2010. It is especially dominant in the service and agriculture sectors of Pakistan's economy. With its contribution ranging from 52.1% to 64.5% in the Service Sector and 56.1% to 61.5% in the agriculture sector. It is also a major manpower contributor because it has the largest pool of professionals and highly skilled (technically trained) manpower in Pakistan. It is also dominant in the manufacturing sector, though the dominance is not as huge, with historical contributions ranging from a low of 44% to a high of 52.6%. In 2007, Punjab achieved a growth rate of 7.8% and during the period 2002\u201303 to 2007\u201308, its economy grew at a rate of between 7% and 8% per year. and during 2008\u201309 grew at 6% against the total GDP growth of Pakistan at 4%.\nDespite the lack of a coastline, Punjab is the most industrialised province of Pakistan; its manufacturing industries produce textiles, sports goods, heavy machinery, electrical appliances, surgical instruments, vehicles, auto parts, metals, sugar mill plants, aircraft, cement, agricultural machinery, bicycles and rickshaws, floor coverings, and processed foods. In 2003, the province manufactured 90% of the paper and paper boards, 71% of the fertilisers, 69% of the sugar and 40% of the cement of Pakistan.\nLahore and Gujranwala Divisions have the largest concentration of small light engineering units. The district of Sialkot excels in sports goods, surgical instruments and cutlery goods. Industrial estates are being developed by Punjab government to boost industrialisation in province, Quaid e Azam Business Park Sheikhupura is one of the industrial areas which is being developed near Sheikhupura on Lahore-Islamabad motorway.\nPunjab has the lowest poverty rates in Pakistan, although a divide is present between the northern and southern parts of the province. Sialkot District in the prosperous northern part of the province has a poverty rate of 5.63%, while Rajanpur District in the poorer south has a poverty rate of 60.05%.\nEducation.\nThe literacy rate has increased greatly over the last 40 years (see the table below). Punjab has the highest Human Development Index out of all of Pakistan's provinces at 0.550.\nSources:\nCulture.\nThe culture in Punjab grew out of the settlements along the five rivers, which served as an important route to the Near East as early as the ancient Indus Valley civilisation, dating back to 3000 BCE. Agriculture has been the major economic feature of the Punjab and has therefore formed the foundation of Punjabi culture, with one's social status being determined by landownership. Punjab emerged as an important agricultural region, especially following the Green Revolution during the mid-1960s to the mid-1970s, has been described as the \"breadbasket of both India and Pakistan\".\nFairs and festivals.\nThe Islamic festivals are typically observed. Non-Islamic festivals include Lohri, Basant and Vaisakhi, which are usually celebrated as seasonal festivals. The Islamic festivals are set according to the lunar Islamic calendar (Hijri), and the date falls earlier by 10 to 13 days from year to year.\nSome Islamic clerics and some politicians have attempted to ban the participation of non-Islamic festivals because of the religious basis, and they being declared haram (forbidden in Islam).\nTourism.\nTourism in Punjab is regulated by the \"Tourism Development Corporation of Punjab\". The province has a number of large cosmopolitan cities, including the provincial capital Lahore. Major visitor attractions there include Lahore Fort and Shalimar Gardens, which are now recognised World Heritage Sites. The Walled City of Lahore, Badshahi Mosque, Wazir Khan Mosque, Tomb of Jahangir and Nur Jahan, Tomb of Asaf Khan, Chauburji and other major sites are visited by tourists each year.\nMurree is a famous hill station stop for tourists. The Pharwala Fort, which was built by an ancient Hindu civilisation, is on the outskirts of the city. The city of Sheikhupura also has a number of sites from the Mughal Empire, including the World Heritage-listed Rohtas Fort near Jhelum. The Katasraj temple in the city of Chakwal is a major destination for Hindu devotees. The Khewra Salt Mines is one of the oldest mines in South Asia. Faisalabad's clock tower and eight bazaars were designed to represent the Union Jack.\nThe province's southward is arid. Multan is known for its mausoleums of saints and Sufi pirs. The Multan Museum, Multan fort, DHA 360\u00b0 zoo and Nuagaza tombs are significant attractions in the city. The city of Bahawalpur is located near the Cholistan and Thar deserts. Derawar Fort in the Cholistan Desert is the site for the annual Cholistan Jeep Rally. The city is also near the ancient site of Uch Sharif which was once a Delhi Sultanate stronghold. The Noor Mahal, Sadiq Ghar Palace, and Darbar Mall were built during the reign of the Nawabs. The Lal Suhanra National Park is a major zoological garden on the outskirts of the city.\nSocial issues.\nThe use of Urdu and English as the near exclusive languages of broadcasting, the public sector, and formal education have led some to fear that the Punjabi language in the province is being relegated to a low-status language and that it is being denied an environment where it can flourish.\nIn August 2015, the Pakistan Academy of Letters, International Writer's Council (IWC) and World Punjabi Congress (WPC) organised the \"Khawaja Farid Conference\" and demanded that a Punjabi-language university should be established in Lahore and that Punjabi language should be declared as the medium of instruction at the primary level. In September 2015, a case was filed in Supreme Court of Pakistan against Government of Punjab, Pakistan as it did not take any step to implement the Punjabi language in the province. Additionally, several thousand Punjabis gather in Lahore every year on International Mother Language Day.\nHafiz Saeed, chief of Jama'at-ud-Da'wah (JuD), has questioned Pakistan's decision to adopt Urdu as its national language in a country where majority of people speak Punjabi language, citing his interpretation of Islamic doctrine as encouraging education in the mother-tongue. Some of the organisations and activists that demand the promotion of the Punjabi language include:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24752", "revid": "7196877", "url": "https://en.wikipedia.org/wiki?curid=24752", "title": "Politburo", "text": "Executive committee of a communist party\nA politburo () or political bureau is the highest organ of the central committee in communist parties. The term is also sometimes used to refer to similar organs in socialist and Islamist parties, such as the Political Bureau of Hamas. Politburos are part of the governing structure in most former and existing communist states.\nNames.\nThe term \"politburo\" in English comes from the Russian \"politbyuro\" (), itself an abbreviation of \"politicheskoye byuro\" ( 'political bureau'). The Spanish term \"Politbur\u00f3\" is directly loaned from Russian, as is the German \"Politb\u00fcro\". Chinese uses a calque (), from which the Vietnamese ( ), and Korean ( \"Jeongchiguk\") terms derive.\nHistory.\nThe first politburo was created in Russia by the Bolshevik Party in 1917 during the Russian Revolution that occurred during that year. The first Politburo had seven members: Vladimir Lenin, Grigory Zinoviev, Lev Kamenev, Leon Trotsky, Joseph Stalin, Grigori Sokolnikov, and Andrei Bubnov.\nDuring the 20th century, politburos were established in most Communist states. They included the politburos of the USSR, East Germany, Afghanistan, and Czechoslovakia. Today, there are five countries that have a politburo system: China, North Korea, Laos, Vietnam, and Cuba.\nMarxist\u2013Leninist states.\nIn Marxist\u2013Leninist states, the communist party is the vanguard of the people, therefore the legitimate body to lead the state. The party selects officials to serve in its politburo, which decides party policy. As a one-party state, party policy invariably becomes national policy.\nEach Party Congress elects a Central Committee which, in turn, elects the members of the politburo, secretariat, and a general secretary. This process is termed democratic centralism. In theory, the politburo is answerable to the Central Committee, however in practice all the authority lies with the politburo.\nTrotskyist parties.\nIn Trotskyist parties, the Politburo is a bureau of the Central Committee tasked with making day-to-day political decisions, which must later be ratified by the Central Committee. Its members are chosen by the Central Committee, who appoints it. The post of General Secretary carries far less weight in this model. See, for example, the Lanka Sama Samaja Party.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24755", "revid": "41769342", "url": "https://en.wikipedia.org/wiki?curid=24755", "title": "Pope Julius II", "text": "Head of the Catholic Church from 1503 to 1513\nPope Julius II (; ; born Giuliano della Rovere; 5 December 1443\u00a0\u2013 21 February 1513) was head of the Catholic Church and ruler of the Papal States from 1503 to his death, in February 1513. Nicknamed the Warrior Pope, the Battle Pope or the Fearsome Pope, it is often speculated that he had chosen his papal name not in honor of Pope Julius I but in emulation of Julius Caesar. One of the most powerful and influential popes, Julius II was a central figure of the High Renaissance and left a significant cultural and political legacy. As a result of his policies during the Italian Wars, the Papal States increased their power and centralization, and the office of the papacy continued to be crucial, diplomatically and politically, during the entirety of the 16th century in Italy and Europe.\nIn 1506, Julius II established the Vatican Museums and initiated the rebuilding of the St. Peter's Basilica. The same year he organized the famous Swiss Guard for his personal protection and commanded a successful campaign in Romagna against local lords. The interests of Julius II lay also in the New World, as he ratified the Treaty of Tordesillas, establishing the first bishoprics in the Americas and beginning the Catholicization of Latin America. In 1508, he commissioned the Raphael Rooms and Michelangelo's paintings in the Sistine Chapel.\nPope Julius II allowed people seeking indulgences to donate money to the Church, which would be used for the construction of Saint Peter's Basilica. He was fiercely satirized after his death by Erasmus of Rotterdam in \"Julius Excluded from Heaven\", in which the drunken pope, denied entry to heaven by St. Peter, justifies his worldly life and plots to create a rival abode from which to conquer heaven.\nOverview of the Italian politics of his reign.\nJulius II became pope in the context of the Italian Wars, a period in which the major powers of Europe fought for primacy in the Italian Peninsula. Louis XII of France controlled the Duchy of Milan, previously held by the Sforzas, and French influence had replaced that of the Medici in the Republic of Florence. The Kingdom of Naples was under Spanish rule. Maximilian I of Austria was hostile to France and Venice, and desired to descend into Italy in order to be crowned Holy Roman Emperor by the pope. The conclave capitulation preceding his election included several terms, such as the opening of an ecumenical council and the organization of a crusade against the Ottoman Turks. Once crowned, Julius II proclaimed instead his goal to centralize the Papal States (in large part a patchwork of communes and \"signorie\") and \"free Italy from the barbarians\".\nIn his early years as pope, Julius II targeted the members of the House of Borgia (the Spanish family of the previous Pope, Alexander VI), exiling them or destroying their influence. Cesare Borgia, Duke of Romagna, shared the same fate and lost his possessions.\nHe joined an anti-Venetian League of Cambrai, formed in December 1508, with the goal of capturing the coast of Romagna from the Venetian Republic. Having achieved this goal during the early stages of the War of the League of Cambrai, he reconciled with Venice (1510), and formed the Holy League (1511) in order to eliminate the French presence in Italy. His main goal was now again to \"expel the barbarians\" (\"Fuori i Barbari!\"). Julius II brought king Ferdinand II of Aragon into the alliance, declaring Naples a papal fief and promising a formal investiture.\nHaving previously declared that the imperial election was sufficient for Maximilian to style himself as Holy Roman Emperor, he succeeded in distancing the emperor from the king of France. Julius II personally led the papal armed forces at the victorious Siege of Mirandola and, despite subsequent defeats and great losses at the Battle of Ravenna, he ultimately forced the French troops of Louis XII to retreat behind the Alps after the arrival of Swiss mercenaries from the Holy Roman Empire.\nAt the Congress of Mantua in 1512, Julius II ordered the restoration of Italian families to power in the vacuum of French rule: the Imperial Swiss led by Massimiliano Sforza restored Sforza rule in Milan, and a Spanish army led by Giovanni de Medici restored Medici rule in Florence. The Venetians regained their territories lost to France, and the Papal States annexed Parma and Modena. The conciliarist movement promoted by foreign monarchs was crushed, and Julius II affirmed ultramontanism at the Fifth Lateran Council. This is often presented in traditional historiography as the moment in which Renaissance Italy came the closest to unification after the end of the Italic League of the 15th century. However, Julius II was far away from the possibility to form a single Italian kingdom, if that was his goal at all, since foreign armies were largely involved in his wars and the French were preparing new campaigns against the Swiss for Milan. Naples, even if recognized as a papal fief, was still under Aragon and in fact Julius II was planning to end Spanish presence in the south. Nevertheless, by the end of his pontificate, the papal objective to make the Church the main force in the Italian Wars was achieved. At the Roman Carnival of 1513, Julius II presented himself as the \"liberator of Italy\".\nJulius planned to call for a crusade against the Ottoman Empire in order to retake Constantinople, but died before making official announcements. His successor, Pope Leo X, along with Emperor Maximilian, would re-establish the status quo ante bellum in Italy by ratifying the treaties of Brussels and Noyon in 1516; France regained control of Milan after the victory of Francis I at the Battle of Marignano.\nEarly life.\nGiuliano della Rovere was born in Albisola near Savona in the Republic of Genoa. He was of the House of della Rovere, a noble but impoverished family, the son of Raffaello della Rovere and Theodora Manerola, a woman of Greek ancestry. He had three brothers: Bartolomeo, a Franciscan friar who then became Bishop of Ferrara (1474\u20131494); Leonardo; and Giovanni, Prefect of the City of Rome (1475\u20131501) and Prince of Sora and Senigallia. He also had a sister, Lucina (later the mother of Cardinal Sisto Gara della Rovere). Giuliano was educated by his uncle, Fr. Francesco della Rovere, O.F.M., among the Franciscans, who took him under his special charge. He was later sent by this same uncle (who by that time had become Minister General of the Franciscans (1464\u20131469)), to the Franciscan friary in Perugia, where he could study the sciences at the university.\nDella Rovere, as a young man, showed traits of being rough, coarse and inclined to bad language. During the late 1490s, he became more closely acquainted with Cardinal de\u2019 Medici and his cousin Giulio de\u2019 Medici, both of whom would later become Pope, (i.e. Leo X and Clement VII, respectively). The two dynasties became uneasy allies in the context of papal politics. Both houses desired an end to the occupation of Italian lands by the armies of France. He seemed less enthused by theology; rather, Paul Strathern argues, his imagined heroes were military leaders such as Frederic Colonna.\nCardinalate.\nAfter his uncle was elected Pope Sixtus IV on 10 August 1471, Giuliano was appointed Bishop of Carpentras in the Comtat Venaissin on 16 October 1471. In an act of overt nepotism he was immediately raised to the cardinalate on 16 December 1471, and assigned the same titular church as that formerly held by his uncle, San Pietro in Vincoli. Guilty of serial simony and pluralism, he held several powerful offices at once: in addition to the archbishopric of Avignon he held no fewer than eight bishoprics, including Lausanne from 1472, Coutances (1476\u20131477), Catania (1473\u20131474).\nIn 1474, Giuliano led an army to Todi, Spoleto, and Citt\u00e0 di Castello as papal legate. He returned to Rome in May in the company of Duke Federigo of Urbino, who promised his daughter in marriage to Giuliano's brother Giovanni, who was subsequently named Lord of Senigallia and of Mondov\u00ec. On 22 December 1475, Pope Sixtus IV created the new Archdiocese of Avignon, assigning to it as suffragan dioceses the Sees of Vaison, Cavaillon, and Carpentras. He appointed Giuliano as the first archbishop. Giuliano held the archdiocese until his later election to the papacy. In 1476 the office of Legate was added, and he left Rome for France in February. On 22 August 1476 he founded the \"Collegium de Ruvere\" in Avignon. He returned to Rome on 4 October 1476.\nIn 1479, Cardinal Giuliano served his one-year term as Chamberlain of the College of Cardinals. In this office he was responsible for collecting all the revenues owed to the cardinals as a group (from \"ad limina\" visits, for example) and for the proper disbursements of appropriate shares to cardinals who were in service in the Roman Curia.\nGiuliano was again named Papal Legate to France on 28 April 1480, and left Rome on 9 June. As Legate, his mission was threefold: to make peace between King Louis XI and the Archduke Maximilian of Austria; to raise funds for a war against the Ottoman Turks; and to negotiate the release of Cardinal Jean Balue and Bishop Guillaume d'Haraucourt (who by then had been imprisoned by Louis for eleven years on charges of treason). He reached Paris in September, and finally, on 20 December 1480, Louis gave orders that Balue be handed over to the Archpriest of Loudun, who had been commissioned by the Legate to receive him in the name of the Pope. He returned to Rome on 3 February 1482. Shortly thereafter the sum of 300,000 ecus of gold was received from the French in a subsidy of the war.\nOn 31 January 1483 Cardinal della Rovere was promoted suburbicarian Bishop of Ostia, in succession to Cardinal Guillaume d'Estouteville who had died on 22 January. It was the privilege of the Bishop of Ostia to consecrate an elected pope a bishop, if he were not already a bishop. This actually occurred in the case of Pius III (Francesco Todeschini-Piccolomini), who was ordained a priest on 30 September 1503 and consecrated a bishop on 1 October 1503 by Cardinal Giuliano della Rovere.\nAround this time, in 1483, an illegitimate daughter was born, Felice della Rovere.\nOn 3 November 1483, Cardinal della Rovere was named Bishop of Bologna and Papal Legate, succeeding Cardinal Francesco Gonzaga, who had died on 21 October. He held the diocese until 1502. On 28 December 1484, Giuliano participated in the investiture of his brother Giovanni as Captain-General of the Papal Armies by Pope Innocent VIII.\nBy 1484 Giuliano was living in the new palazzo which he had constructed next to the Basilica of the Twelve Apostles, which he had also restored. Pope Sixtus IV paid a formal visit to the newly restored building on 1 May 1482, and it may be that Giuliano was already in residence then.\nWar with Naples.\nSixtus IV died on 12 August 1484 and was succeeded by Innocent VIII. After the ceremonies of the election of Pope Innocent were completed, the cardinals were dismissed to their own homes, but Cardinal della Rovere accompanied the new Pope to the Vatican Palace and was the only one to remain with him. Ludwig Pastor quotes the Florentine ambassador as remarking, \"[Pope Innocent] gives the impression of a man who is guided rather by the advice of others than by his own lights.\" The ambassador of Ferrara stated, \"While with his uncle [Della Rovere] had not the slightest influence, he now obtains whatever he likes from the new Pope.\" Della Rovere was one of the five cardinals named to the committee to make the arrangements for the Coronation.\nIn 1485 Pope Innocent and Cardinal della Rovere (as the Pope's new principal advisor) decided to involve themselves in the political affairs of the Kingdom of Naples, in what was called the \"Conspiracy of the Barons\". On Palm Sunday, 20 March, Cardinal della Rovere, concealing his activities from his principal rival, Cardinal Rodrigo Borgia (later Pope Alexander VI), rode out of Rome and departed by sea from Ostia, intending to head for Genoa and Avignon to prepare to wage war between the Church and the King of Naples, Ferdinand I (Ferrante). On 28 June the Pope sent back to Naples the token gift of a palfrey which symbolized the King of Naples' submission and demanded the full feudal submission of the Kingdom of Naples to the Roman Church according to long-standing tradition. In a second attempt to overthrow the Aragonese monarchy, the Prince of Salerno Antonello II di Sanseverino, on the advice of Antonello Petrucci and Francesco Coppola, gathered together several feudal families belonging to the Guelph faction and supporting the Angevin claim to Naples. Antonello de Sanseverino was the brother-in-law of Cardinal della Rovere's brother Giovanni, who was a noble of Naples because of his fief of Sora. The principal complaints of the barons were the heavy taxation imposed by Ferdinand to finance his war against the Ottomans, who had occupied Bari in 1480; and the vigorous efforts of Ferrante to centralize the administrative apparatus of the kingdom, moving it away from a feudal to a bureaucratic system. The barons seized L'Aquila and appealed to the Pope for assistance as their feudal overlord. Genoa and Venice supported the Papacy, while Florence and Milan opted for Naples. In Rome, the Orsini family allied themselves with Ferrante's son Alfonso, and therefore their rivals the Colonna family supported the Pope in the street fighting that ensued. Ferrante reacted by seizing the fiefs of the barons, and, when the two parties met to negotiate a settlement, Ferrante had them arrested, and eventually executed. The prestige of the della Rovere family was seriously damaged, and in an attempt to exculpate himself Pope Innocent began to withdraw his support for them. Peace was restored in 1487, but Innocent VIII's papacy was discredited.\nPapal ambassador.\nOn 23 March 1486, the pope sent Giuliano as Papal Legate to the Court of King Charles VIII of France to ask for help. A French entourage arrived in Rome on 31 May, but immediately relations broke down with the pro-Spanish Cardinal Borgia. But Ferrante's army decided the pope's humiliation, Innocent backed down and on 10 August signed a treaty. Innocent looked for new allies and settled on the Republic of Florence.\nOn 2 March 1487, Giuliano was appointed legate in the March of Ancona and to the Republic of Venice. He encouraged trade with the sizable Turkish community at these ports. But urgent reports arrived from King Matthias Corvinus of Hungary that the Ottoman Sultan Bayezid II was threatening Italy. He returned on 8 April 1488, and again took up his residence in the Palazzo Colonna next to the Basilica of the XII Apostles.\nConclave of 1492.\nIn the Conclave of 1492, following the death of Innocent VIII, Cardinal della Rovere was supported for election by both King Charles VIII of France and by Charles' enemy King Ferrante of Naples. It was reported that France had deposited 200,000 ducats into a bank account to promote della Rovere's candidature, while the Republic of Genoa had deposited 100,000 ducats to the same end. Della Rovere, however, had enemies, both because of the influence he had exercised over Pope Sixtus IV and because of his French sympathies. His rivals included Cardinal Ardicio della Porta and Cardinal Ascanio Sforza, both patronized by the Milanese. Kellogg, Baynes &amp; Smith, continue, a \"rivalry had, however, gradually grown up between [della Rovere] and [then-Cardinal] Rodrigo Borgia, and on the death of Innocent VIII in 1492 Borgia by means of a secret agreement and simony with Ascanio Sforza succeeded in being elected by a large majority, under the name of Pope Alexander VI.\" Della Rovere, jealous and angry, hated Borgia for being elected over him.\nOn 31 August 1492 the new Pope, Alexander VI, held a consistory in which he named six cardinal legates, one of whom was Giuliano della Rovere, who was appointed Legate in Avignon. Cardinal Giuliano was increasingly alarmed by the powerful position assumed by Cardinal Ascanio Sforza and the Milanese faction in the Court of Alexander VI, and after Christmas Day in December 1492 chose to withdraw to his fortress in the town and diocese of Ostia, at the mouth of the Tiber River. In that same month, Federico of Altamura, the second son of King Ferdinando (Ferrante) of Naples was in Rome to pay homage to the new pope, and he reported back to his father that Alexander and Cardinal Sforza were working on establishing new alliances, which would upset Ferrante's security arrangements. Ferrante, therefore, decided to use della Rovere as the center of an anti-Sforza party at the papal court, a prospect made easier since Ferrante had prudently repaired his relations with Cardinal Giuliano after the War of the Barons. He also warned King Ferdinand and Queen Isabella of Spain that Alexander was intriguing with the French, which brought an immediate visit of a Spanish ambassador to the Pope. In June Federico of Altamura was back in Rome and held conversations with della Rovere, assuring him of Neapolitan protection. On 24 July 1493, Cardinal della Rovere returned to Rome (despite the warnings of Virginio Orsini) and dined with the Pope.\nCharles VIII and the French war over Naples.\nDella Rovere at once determined to take refuge from Borgia's wrath at Ostia. On 23 April 1494, the Cardinal took ship, having placed his fortress at Ostia in the hands of his brother Giovanni della Rovere, and traveled to Genoa and then to Avignon. He was summoned by King Charles VIII to Lyons, where the two met on 1 June 1494. He made an agreement with Charles VIII, who undertook to take Italy back from the Borgias by military force. The King entered Rome with his army on 31 December 1494, with Giuliano della Rovere riding on one side and Cardinal Ascanio Sforza riding on the other. The King made several demands of Pope Alexander, one of which was that the Castel Sant'Angelo be turned over to French forces. This Pope Alexander refused to do, claiming that Cardinal della Rovere would occupy it and become master of Rome. Charles soon conquered Naples, making his triumphal entry on 22 February 1495, but he was forced to remove most of his army. As he was returning to the north, his army was defeated at the Battle of Fornovo on 5 July 1495, and his Italian adventure came to an end. The last remnants of the French invasion were gone by November 1496. Ostia, however, remained in French hands until March 1497, causing difficulties in the provisioning of the city of Rome.\nBack in Lyon in 1496, Charles VIII and Giuliano della Rovere were planning another war. Giuliano was traveling back and forth from Lyon to Avignon, raising troops. It was being reported in France by June 1496, moreover, that King Charles intended to have a papal election in France and to have Cardinal della Rovere elected pope.\nIn March 1497 Pope Alexander deprived Cardinal della Rovere of his benefices as an enemy of the Apostolic See, and Giovanni della Rovere of the Prefecture of Rome. His action against the Cardinal was done not only without the consent of the cardinals in consistory, but in fact over their vigorous objections. By June, however, the Pope was in negotiations with the Cardinal for reconciliation and return to Rome. His benefices were restored to him after an apparent reconciliation with the Pope in August 1498.\nLouis XII and his Italian War.\nKing Charles VIII of France, the last of the senior branch of the House of Valois, died on 7 April 1498 after accidentally striking his head on the lintel of a door at the Ch\u00e2teau d'Amboise. When Cesare Borgia passed through southern France in October 1498 on his way to meet King Louis XII for his investiture as Duke of Valentinois, he stopped in Avignon and was magnificently entertained by Cardinal della Rovere. They then moved on to meet the King at Chinon, where Cesare Borgia fulfilled one of the terms of the treaty between Louis and Alexander by producing the red hat of a cardinal, which had been promised for the Archbishop of Rouen, Georges d'Amboise. It was Cardinal della Rovere, the Papal Legate, who placed the hat on Amboise's head.\nLouis wanted an annulment from Queen Joan so he could marry Anne of Brittany, in the hope of annexing the Duchy of Brittany; Alexander, in turn, wanted a French princess as wife for Cesare. Della Rovere, who was trying to repair his relations with the House of Borgia, was also involved in another clause of the treaty, the marriage between Cesare Borgia and Carlotta, the daughter of the King of Naples, who had been brought up at the French Court. Della Rovere was in favor of the marriage, but, according to Pope Alexander, King Louis XII was not, and, most especially, Carlotta was stubbornly refusing her consent. Alexander's plan of securing a royal throne for his son fell through, and he was very angry. Louis offered Cesare another of his relatives, the \"beautiful and rich\" Charlotte d'Albret, whom Cesare married at Blois on 13 May 1499.\nThe marriage produced a complete \"volta facie\" in Pope Alexander. He became an open partisan of the French and Venice, and accepted their goal, the destruction of the Sforza hold on Milan. On 14 July, Cardinal Ascanio Sforza, della Rovere's sworn enemy, fled Rome with all his property and friends. Meanwhile, the French army crossed the Alps and captured Alessandria in Piedmont. On 1 September 1499 Lodovico \"Il Moro\" fled Milan, and on 6 September the city surrendered to the French. Cardinal Giuliano was in the King's entourage when he entered Milan on 6 October.\nPope Alexander then turned his attention, stimulated by the Venetians, to the threat of the Ottoman Turks. In the autumn of 1499, he called for a crusade and sought aid and money from all Christendom. The rulers of Europe paid little attention, but to show his sincerity Alexander imposed a tithe on all the residents of the Papal States and a tithe on the clergy of the entire world. A list of cardinals and their incomes, drawn up for the occasion, shows that Cardinal della Rovere was the second-richest cardinal, with an annual income of 20,000 ducats.\nAnother break in relations between Pope Alexander and Cardinal Giuliano came at the end of 1501 or the beginning of 1502 when Giuliano was transferred from the Bishopric of Bologna to the diocese of Vercelli.\nOn 21 June 1502, Pope Alexander sent his secretary, Francesco Troche (Trochia), and Cardinal Amanieu d'Albret (brother-in-law of Cesare Borgia) to Savona to seize Cardinal della Rovere by stealth and bring him back to Rome as quickly as possible and turn him over to the Pope. The kidnapping party returned to Rome on 12 July, without having accomplished its mission. On 20 July 1502, Cardinal Giovanni Battista Ferrari died in his rooms at the Vatican Palace; he had been poisoned, and his property was claimed by the Borgia. On 3 January 1503, Cardinal Orsini was arrested and sent to the Castel Sant'Angelo; on 22 February he died there, poisoned on the orders of Alexander VI.\nElection.\nA veteran of the Sacred College, della Rovere had won influence for the election of Pope Pius III with the help of Florentine ruler, Lorenzo de' Medici. In spite of a violent temper della Rovere succeeded by dexterous diplomacy in winning the support of Cesare Borgia, whom he won over by his promise of money and continued papal backing for Borgia policies in the Romagna. This election was, in Ludwig von Pastor's view, certainly achieved by means of bribery with money, but also with promises. \"Giuliano, whom the popular voice seemed to indicate as the only possible pope, was as unscrupulous as any of his colleagues in the means which he employed. Where promises and persuasions were unavailing, he did not hesitate to have recourse to bribery.\" Indeed, his election on 1 November 1503 took only a few hours, and the only two votes he did not receive were his own and the one of Georges d'Amboise, his most vigorous opponent and the favourite of the French monarchy. In the end, as in all papal elections, the vote is made unanimous after the leading candidate has achieved the required number of votes for election.\nA Renaissance pope.\nGiuliano della Rovere took the name Julius, only used by a single fourth-century predecessor, Julius I, and was pope for nine years, from 1503 to 1513. From the beginning, Julius II set out to defeat the various powers that challenged his temporal authority; in a series of complicated stratagems, he first succeeded in rendering it impossible for the Borgias to retain their power over the Papal States. Indeed, on the day of his election, he issued a \"damnatio memoriae\", declaring:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I will not live in the same rooms as the Borgias lived. He [Alexander VI] desecrated the Holy Church as none before. He usurped the papal power by the devil's aid, and I forbid under the pain of excommunication anyone to speak or think of Borgia again. His name and memory must be forgotten. It must be crossed out of every document and memorial. His reign must be obliterated. All paintings made of the Borgias or for them must be covered over with black crepe. All the tombs of the Borgias must be opened and their bodies sent back to where they belong \u2013 to Spain. Others indicate that his decision was taken on 26 November 1507, not in 1503. The Borgia Apartments were turned to other uses. The \"Sala de Papi\" was redecorated by two pupils of Raphael by order of Pope Leo X. The rooms were used to accommodate Emperor Charles V on his visit to the Vatican after the Sack of Rome (1527), and subsequently, they became the residence of the Cardinal-nephew and then the Cardinal Secretary of State.\nJulius used his influence to reconcile two powerful Roman families, the Orsini and Colonna. Decrees were made in the interests of the Roman nobility, in whose shoes the new pope now stepped. Being thus secure in Rome and the surrounding country, he set himself the task to expel the Republic of Venice from Faenza, Rimini, and the other towns and fortresses of Italy which it occupied after the death of Pope Alexander. In 1504, finding it impossible to succeed with the Doge of Venice by remonstrance, he brought about a union of the conflicting interests of France and the Holy Roman Empire, and sacrificed temporarily to some extent the independence of Italy to conclude with them an offensive and defensive alliance against Venice. The combination was, however, at first little more than nominal, and was not immediately effective in compelling the Venetians to deliver up more than a few unimportant places in the Romagna. With a campaign in 1506, he personally led an army to Perugia and Bologna, freeing the two papal cities from their despots, Gian Paolo Baglioni and Giovanni II Bentivoglio.\nIn December 1503, Julius issued a dispensation allowing the future Henry VIII of England to marry Catherine of Aragon; Catherine had previously been briefly married to Henry's older brother Prince Arthur, who had died, but Henry later argued that she had remained a virgin for the five months of the marriage. Some twenty years later, when Henry was attempting to wed Anne Boleyn (since his son by Catherine of Aragon survived only a few days, and two of her sons were stillborn, and therefore he had no male heir), he sought to have his marriage annulled, claiming that the dispensation of Pope Julius should never have been issued. The retraction of the dispensation was refused by Pope Clement VII.\nThe Bull entitled \"Ea quae pro bono pacis\", issued on 24 January 1506, confirmed papal approval of the \"mare clausum\" policy being pursued by Spain and Portugal amid their explorations, and approved the changes of the 1494 Treaty of Tordesillas to previous papal bulls. In the same year, Julius II founded the Swiss Guard to provide a constant corps of soldiers to protect the pope. As part of the Renaissance program of reestablishing the glory of antiquity for the Christian capital, Rome, Julius II took considerable effort to present himself as a sort of emperor-pope, capable of leading a Latin-Christian empire. On Palm Sunday, 1507, \"Julius II entered Rome ... both as a second Julius Caesar, heir to the majesty of Rome's imperial glory, and in the likeness of Christ, whose vicar the pope was, and who in that capacity governed the universal Roman Church.\" Julius, who modeled himself after his namesake Caesar, would personally lead his army across the Italian peninsula under the imperial war-cry, \"Drive out the barbarians.\" Yet, despite the imperial rhetoric, the campaigns were highly localized. Perugia voluntarily surrendered in March 1507 to direct control, as it had always been within the Papal States; it was in these endeavors he had enlisted French mercenaries.\nUrbino's magnificent Ducal Palace was infiltrated by French soldiers in the pay of the Margrave of Mantua; the Montefeltro Conspiracy against his loyal cousins earned the occupying armies the Pope's undying hatred. Julius relied upon Guidobaldo's help to raise his nephew and heir Francesco Maria della Rovere; the intricate web of nepotism helped secure the Italian Papacy. Moreover, the Pope's interest in Urbino was widely known in the French court. Julius left a spy at the Urbino Palace, possibly Galeotto Franciotti della Rovere, Cardinal of San Pietro, to watch the Mantua stables in total secret; the secular progress of the Papal Curia was growing in authority and significance. In Rome, the Pope watched from his private chapel to see how his court behaved. This was an age of Renaissance conspiracy.\nLeague of Cambrai and Holy League.\nIn addition to an active military policy, the new pope personally led troops into battle on at least two occasions, the first to expel Giovanni Bentivoglio from Bologna (17 August 1506 \u2013 23 March 1507), which was achieved successfully with the assistance of the Duchy of Urbino. The second was an attempt to recover the Duchy of Ferrara for the Papal States (1 September 1510 \u2013 29 June 1512). In 1508, Julius was fortuitously able to form the League of Cambrai with King Louis XII of France, Maximilian I, Holy Roman Emperor (proclaimed without coronation as emperor by Pope Julius II at Trent in 1508) and King Ferdinand II of Aragon. The League fought against the Republic of Venice. Among other things, Julius wanted possession of Venetian Romagna; Emperor Maximilian I wanted Friuli and Veneto; Louis XII wanted Cremona, and Ferdinand II desired the Apulian ports. This war was a conflict in what was collectively known as the \"Italian Wars\". In the spring of 1509, the Republic of Venice was placed under an interdict by Julius, In May 1509 Julius sent troops to fight against the Venetians who had occupied parts of the Romagna, winning back the Papal States in the decisive Battle of Agnadello near Cremona.\nThe achievements of the League soon outstripped the primary intention of Julius. In one single battle, the Battle of Agnadello on 14 May 1509, the dominion of Venice in Italy was practically lost to the pope. Neither the King of France nor the Holy Roman Emperor was satisfied with merely effecting the purposes of the Pope; the latter found it necessary to enter into an arrangement with the Venetians to defend himself from those who immediately before had been his allies. The Venetians, on making humble submission, were absolved at the beginning of 1510, and shortly afterward France was placed under papal interdict.\nAttempts to cause a rupture between France and England proved unsuccessful; on the other hand, at a synod convened by Louis at Tours in September 1510, the French bishops withdrew from papal obedience and resolved, with the Emperor's co-operation, to seek dethronement of the pope. With some courage Julius marched his army to Bologna and then against the French to Mirandola. In November 1511, a council met at Pisa, called by rebel cardinals with support from the French king and the Empire; they demanded the deposition of Julius II. He refused to shave, showing utter contempt for the hated French occupation. \"per vendicarsi et diceva ... anco fuora scazato el re Ludovico Franza d'Italia.\"\nOn 4 October 1511, Julius succeeded in creating the anti-French Holy League, that also included the Venetians and king Ferdinand II of Aragon. In a short time, king Henry VIII of England also joined the Holy League, unlike emperor Maximilan who was still reluctant to break his alliance with the French king. Ferdinand of Aragon was invested of Naples as a papal fief, and on 6 April 1512, by Pope's mediation, the truce was concluded in Rome between the emperor and the Venetians. Maximilian ratified the truce on 20 May, thus ending his participation in the anti-Venetian war, but still avoiding Pope's proposals to officially join the anti-French Holy League. \nJulius II regarded France as the main foreign power in the Italian peninsula hostile to Papal interests. Louis XII defeated the alliance at Battle of Ravenna on 11 April 1512. When a desperate battle felled over 20,000 men in a bloodbath the Pope commanded his protege, a newly released young Cardinal Medici to re-take Florence with a Spanish army. The rescue of the city on 1 September 1512 saved Rome from another invasion, ousting Piero Soderini, and returning the dynastic rule of the Medici. Julius had seemingly restored \"fortuna\" or control by exercising his manly \"vertu\", just as Machiavelli wrote. This re-asserted a strong relation between Florence and Rome, a lasting legacy of Julius II. Yet Machiavelli and his methods would not outlast Julius' Papacy.\nJulius hired Swiss mercenaries to fight against the French in Milan in May 1512, causing the French army to withdraw across the Alps into Savoy. The papacy gained control of Parma and Piacenza in central Italy. With the French out of Italy, a Congress was held in Mantua by Julius II to declare the liberation of the peninsula. Nevertheless, although Julius had centralized and expanded the Papal States, he was far from realizing his dream of an independent Italian kingdom. Italy was not at peace either. The French were preparing new campaigns to reconquer Milan, and Julius II confessed to a Venetian ambassador a plan to invest his counselor Luigi d'Aragona with the Kingdom of Naples in order to end Spanish presence in the south. \nOn 10 November 1512, the Pope proposed the conclusion of a final and comprehensive peace treaty between the emperor Maximilian and the Venetians, that would resolve the ongoing political conflicts by favoring Maximilian's interests in northern Italy, mainly on the Venetian expense. Finding the Pope's peace proposals too demanding and also excessively favorable towards the emperor, particularly in the contested regions of Terraferma, the Venetian government decided on 23 December (1512) to initiate peace negotiations with the king of France, thus laying foundation for a major shift in alliances. \nThe Pope did not live to see the result of those negotiations, since he died on 21 February 1513, and already on 23 March of the same year, a Franco-Venetian treaty was signed at Blois, thus marking the collapse of the Holy League.\nLateran Council.\nIn May 1512 a general or ecumenical council, the Fifth Council of the Lateran, was held in Rome. According to an oath taken on his election to observe the Electoral Capitulations of the Conclave of October 1503, Julius had sworn to summon a general council, but it had been delayed, he affirmed, because of the occupation of Italy by his enemies. The real stimulus came from a false council which took place in 1511, later called the \"Conciliabulum Pisanum\", inspired by Louis XII and Maximilian I as a tactic to weaken Julius, threatening to depose him. Julius' reply was the issuing of the bull \"Non-sini gravi\" of 18 July 1511, which fixed the date of 19 April 1512 for the opening of his own council. The Council actually convened on 3 May 1512, and Paris de Grassis reports that the crowd at the basilica was estimated at 50,000. It held its first working session on 10 May. In the third plenary session, on 3 December 1512, Julius attended, though ill; but he wanted to witness and receive the formal adhesion of Emperor Maximilian to the Lateran Council and his repudiation of the \"Conciliabulum Pisanum\". This was one of Julius' great triumphs. The Pope was again in attendance at the fourth session on 10 December, this time to hear the accrediting of the Venetian Ambassador as the Serene Republic's representative at the council; he then had the letter of King Louis XI (of 27 November 1461), in which he announced the revocation of the Pragmatic Sanction, read out to the assembly, and demanded that all persons who accepted the Pragmatic Sanction appear before the Council within sixty days to justify their conduct. This was directed against the current French King Louis XII.\nThe fifth session was held on 16 February, but Pope Julius was too ill to attend. Cardinal Raffaele Riario, the Dean of the College of Cardinals and Bishop of Ostia, presided. The Bishop of Como, Scaramuccia Trivulzio, then read from the pulpit a papal bull, \"Si summus rerum\", dated that very day and containing within its text the complete bull of 14 January 1505, \"Cum tam divino\". The bull was submitted to the Council fathers for their consideration and ratification. Julius wanted to remind everyone of his legislation on papal conclaves, in particular against simony, and to fix his regulations firmly in canon law so that they could not be dispensed or ignored. Julius was fully aware that his death was imminent, and wished to establish a major reform in his final days. Though he had been a witness to a good deal of simony at papal conclaves and had been a practitioner himself, he was determined to stamp out this abuse. The reading of the bull \"Cum tam divino\" became a regular feature of the first day of every conclave.\nDeath.\nOn the Vigil of Pentecost in May 1512, Pope Julius, aware that he was seriously ill and that his health was failing, despite comments on the part of some cardinals about how well he looked, remarked to Paris de Grassis, \"They are flattering me; I know better; my strength diminishes from day to day and I cannot live much longer. Therefore I beg you not to expect me at Vespers or at Mass from henceforth.\" Nonetheless, he continued his restless activities, including Masses, visits to churches, and audiences. On the morning of 24 June Paris found the Pope to be very weak. On Christmas Eve, Julius ordered Paris to summon the College of Cardinals and the Sacristan of the Apostolic Palace, since he was so ill that he did not expect to be able to stay alive very long. From then until 6 January he was confined to bed, and most of the time with a fever; he had lost his appetite, but the doctors were unable to diagnose his languor. On 4 February he had an extensive conversation with Paris concerning the arrangements for his funeral.\nPope Julius was reported to be seriously ill in a dispatch received in Venice on 10 February 1513. He received Holy Communion and was granted the plenary indulgence on the morning of 19 February, according to the Venetian Ambassador. On the 20th, according to Paris de Grassis, he received Holy Communion from the hands of Cardinal Raffaele Riario, the Camerlengo. He died of a fever in the night of 20\u201321 February 1513.\nOn the evening of 21 February, Paris de Grassis conducted the funeral of Julius II, even though the Canons of the Vatican Basilica and the \"beneficiati\" refused to cooperate. The body was placed for a time at the Altar of Saint Andrew in the Basilica and was then carried by the Imperial Ambassador, the papal Datary, and two of Paris' assistants to the altar of the Chapel of Pope Sixtus, where the Vicar of the Vatican Basilica performed the final absolution. At the third hour of the evening, the body was laid in a sepulcher between the altar and the wall of the tribune.\nDespite the fact that the so-called \"Tomb of Pope Julius II\" by Michelangelo is in San Pietro in Vincoli in Rome, Julius is in fact buried in St. Peter's Basilica. Michelangelo's tomb was not completed until 1545 and represents a much-abbreviated version of the planned original, which was initially intended for the new St. Peter's Basilica. His remains lay alongside his uncle, Pope Sixtus IV, but were later desecrated during the Sack of Rome in 1527. Today both men lie in St. Peter's Basilica on the floor in front of the monument to Pope Clement X. A simple marble tombstone marks the site. Julius II was succeeded by Pope Leo X.\nLegacy.\nPatronage of the arts.\nIn 1484 Cardinal Giuliano della Rovere had begun negotiations to persuade Marquis Francesco Gonzaga of Mantua to allow Andrea Mantegna to come to Rome, which finally bore fruit in 1488; Mantegna was given the commission to decorate the chapel of the Belvedere for Pope Innocent VIII, on which he spent two years.\nBeyond Julius II's political and military achievements, he enjoys a title to honor in his patronage of art, architecture, and literature. He did much to improve and beautify the city.\nEarly in his papacy, Julius decided to revive the plan for replacing the dilapidated Constantinian basilica of St. Peter's. The idea was not his, but originally that of Pope Nicholas V, who had commissioned designs from Bernardo Rossellino. Other more pressing problems distracted the attention of Nicholas and subsequent popes, but Julius was not the sort of person to be distracted once he had settled on an idea, in this case, for the greatest building on earth, for the glory of Saint Peter and himself. In the competition for a building plan, the design of Rossellino was immediately rejected as being out of date. A second design was submitted by Giuliano da Sangallo, an old friend of Julius, who had worked on several projects for him before, including the palazzo at S. Pietro in Vincoli, and who had left Rome with Julius when he fled the wrath of Alexander VI in 1495. Through Cardinal della Rovere, Sangallo had presented Charles VIII a plan for a palace, and in 1496 he had made a tour of the architectural monuments of Provence, returning to his native Florence in 1497. His proposals for S. Peter's, however, were not accepted despite what he believed to be a promise, and he retired in anger to Florence.\nOn 18 April 1506 Pope Julius II laid the foundation stone of the new St. Peter's Basilica for the successful architect, Donato Bramante. However, he also began the demolition of the old St. Peter's Basilica, which had stood for more than 1,100 years. He was a friend and patron of Bramante and Raphael, and a patron of Michelangelo. Several of Michelangelo's greatest works (including the painting of the ceiling of the Sistine Chapel) were commissioned by Julius. In the framework of Rome's urban renewal (\"Renovatio Romae\"), the pope commissioned to Bramante the creation of two new straight streets respectively on the left and right bank of the Tiber: the Via Giulia and the Via della Lungara.\nCharacter.\nLong before he became Pope, Julius had a violent temper. He often treated subordinates and people who worked for him very badly. His manner was gruff and coarse, just as his peasant-like sense of humour. Others suggest that Julius had little sense of humor. Ludwig von Pastor wrote, \"Paris de Grassis, his Master of Ceremonies, who has handed on to us so many characteristic features of his master's life, says that he hardly ever jested. He was generally absorbed in deep and silent thought.\"\nTo most historians Julius was manly and virile, an energetic man of action, whose courage saved the Papacy. There was a sense that war caused him serious illness, exhaustion, and fatigue, that most other popes would have been unlikely to have endured. To many Julius II has been described as the best in an era of exceptionally bad popes: Alexander VI was widely perceived as evil and despotic, exposing the future Julius II to a number of assassination attempts that required tremendous fortitude.\nPhysical appearance.\nJulius II is usually depicted with a beard, after his appearance in the celebrated portrait by Raphael, the artist whom he first met in 1509. However, the pope only wore his beard from 27 June 1511 to March 1512, as a sign of mourning at the loss of the city of Bologna by the Papal States. He was nevertheless the first pope since antiquity to grow facial hair, a practice otherwise forbidden by canon law since the 13th century. The pope's hirsute chin may have raised severe, even vulgar criticism, as at one Bologna banquet held in 1510 at which papal legate Marco Cornaro was present. In overturning the ban on beards Pope Julius challenged Gregorian conventional wisdom in dangerous times. Julius shaved his beard again before his death, and his immediate successors were clean-shaven; nonetheless Pope Clement VII sported a beard when mourning the sack of Rome. Thenceforward, all popes were bearded until the death of Pope Innocent XII in 1700.\nThe frescoes on the ceiling of Stanza d'Eliodoro in the stanze of Raphael depict the traumatic events in 1510\u201311 when the Papacy regained its freedom. Although Raphael's original was lost, it was thought to relate closely to the personal iconography of Stanza della Segnatura, commissioned by Pope Julius himself. The Lateran Council that formed the Holy League marked a high point in his personal success. Saved by an allegory to the Expulsion of Heliodorus, the French gone, Julius collapsed once again in late 1512, very seriously ill once more.\nPersonal relationships and sexuality.\nJulius was not the first pope to have fathered children before being elevated to high office, and had a daughter born to Lucrezia Normanni in 1483 \u2013 after he had been made a cardinal. Felice della Rovere survived into adulthood. Shortly after Felice was born, Julius arranged for Lucrezia to marry Bernardino de Cupis, Chamberlain to Julius's cousin, Cardinal Girolamo Basso della Rovere. In addition to producing an illegitimate daughter (and having at least one mistress), it was suggested that Julius may have had homosexual lovers \u2013 although it is not possible to confirm this claim. His confrontational style inevitably created enemies and sodomy was the \"common currency of insult and innuendo\". Such accusations were made to discredit him, but perhaps in so doing his accusers were exploiting a generally \"perceived weakness\".\nThe Venetians, who were implacably opposed to the pope's new military policy, were among the most vociferous opponents; notable among them was the diarist Girolamo Priuli. Erasmus also implied sexual misconduct in his 1514 dialogue \"Julius Excluded from Heaven\"; a theme picked up in the denunciation made at the conciliabulum of Pisa. Criticism was furthermore made of the sinister influence exerted by his advisor, Francesco Alidosi, whom Julius had made a cardinal in 1505. However, it is likely that the closeness was down to the fact that he simply knew how to handle him well. This sexual reputation survived Julius, and the accusation continued to be made without reservation by Protestant opponents in their polemics against \"papism\" and Catholic decadence. The French writer Philippe de Mornay (1549\u20131623) accused all Italians of being sodomites, but added specifically: \"This horror is ascribed to good Julius.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24758", "revid": "38207151", "url": "https://en.wikipedia.org/wiki?curid=24758", "title": "Primary sex characteristics", "text": ""}
{"id": "24759", "revid": "1313263801", "url": "https://en.wikipedia.org/wiki?curid=24759", "title": "Proteus", "text": "Prophetic god of bodies of water in Greek mythology\nIn Greek mythology, Proteus ( ; ) is an early prophetic sea god or god of rivers and oceanic bodies of water, one of several deities whom Homer calls the \"Old Man of the Sea\" (\"h\u00e1lios g\u00e9r\u00f4n\"). Some who ascribe a specific domain to Proteus call him the god of \"elusive sea change\", which suggests the changeable nature of the sea or the liquid quality of water. He can foretell the future, but, in a mytheme familiar to several cultures, will change his shape to avoid doing so; he answers only to those who are capable of capturing him. From this feature of Proteus comes the adjective protean, meaning \"versatile\", \"mutable\", or \"capable of assuming many forms\". \"Protean\" has positive connotations of flexibility, versatility and adaptability.\nName origin.\nProteus's name suggests the \"first\" (from Greek \"\" , \"first\"), as () is the \"primordial\" or the \"firstborn\". It is not certain to what this refers, but in myths where he is the son of Poseidon, it possibly refers to his being Poseidon's eldest son, older than Poseidon's other son, the sea-god Triton. The first attestation of the name is in Mycenaean Greek, although it is not certain whether it refers to the god or just a person; the attested form, in Linear B, is , .\nFamily.\nProteus was generally regarded as the son of the sea-god Poseidon and Phoenice, a daughter of King Phoenix of Phoenicia.\nThe children of Proteus by Torone (Chrysonoe) of Phlegra were Polygonus (Tmolus) and Telegonus. They both challenged Heracles at the behest of Hera and were killed by the hero. Another son of Proteus, Eioneus, became the father of Dymas, king of Phrygia, father of Hecuba. By the Nereid Psamathe, Proteus fathered Theoclymenos and Theonoe (Eidothea or Eurynome). Cabeiro, mother of the Cabeiri and the three Cabeirian nymphs by Hephaestus, was also called the daughter of Proteus. Other daughters were Rhoiteia who gave her name to the city of Rhoiteion in Troad, Thebe who became the eponym of Thebes in Egypt and Thaicrucia who mothered Nympheus by Zeus.\nMythology.\nProteus, prophetic sea-god.\nAccording to Homer (\"Odyssey\" iv: 365), the sandy island of Pharos situated off the coast of the Nile Delta was the home of Proteus, the oracular Old Man of the Sea and herdsman of the sea-beasts. In the \"Odyssey\", Menelaus relates to Telemachus that he had been becalmed here on his journey home from the Trojan War. He learned from Proteus's daughter Eidothea (\"the very image of the Goddess\"), that if he could capture her father, he could force him to reveal which of the gods he had offended and how he could propitiate them and return home. Proteus emerged from the sea to sleep among his colony of seals, but Menelaus was successful in holding him, though Proteus took the forms of a lion, a serpent, a leopard, a pig, even of water or a tree. Proteus then answered truthfully, further informing Menelaus that his brother Agamemnon had been murdered on his return home, that Ajax the Lesser had been shipwrecked and killed, and that Odysseus was stranded on Calypso's Isle Ogygia.\nAccording to Virgil in the fourth Georgic, at one time the bees of Aristaeus, son of Apollo, all died of a disease. Aristaeus went to his mother, Cyrene, for help; she told him that Proteus could tell him how to prevent another such disaster, but would do so only if compelled. Aristaeus had to seize Proteus and hold him, no matter what he would change into. Aristaeus did so, and Proteus eventually gave up and told him that the bees' death was a punishment for causing the death of Eurydice. To make amends, Aristaeus needed to sacrifice 12 animals to the gods, leave the carcasses in the place of sacrifice, and return three days later. He followed these instructions, and upon returning, he found in one of the carcasses a swarm of bees which he took to his apiary. The bees were never again troubled by disease.\nThere are also legends concerning Apollonius of Tyana that say Proteus incarnated himself as the 1st-century philosopher. These legends are mentioned in the 3rd-century biographical work \"Life of Apollonius of Tyana\".\nProteus, king of Egypt.\nIn the \"Odyssey\" (iv.430ff) Menelaus wrestles with \"Proteus of Egypt, the immortal old man of the sea who never lies, who sounds the deep in all its depths, Poseidon's servant\" (Robert Fagles's translation). Proteus of Egypt is mentioned in an alternative version of the story of Helen of Troy in the tragedy \"Helen\" of Euripides (produced in 412 BC). The often unconventional playwright introduces a \"real\" Helen and a \"phantom\" Helen (who caused the Trojan War), and gives a backstory that makes the father of his character Theoclymenus, Proteus, a king in Egypt who had been wed to a Nereid Psamathe. In keeping with one of his themes in \"Helen\", Euripides mentions in passing \"Eido\" (\"image\"), a daughter of the king and therefore sister of Theoclymenus who underwent a name-change after her adolescence and became \"Theono\u00eb\", \"god-minded\", since she was as it turned out capable of foreseeing the future\u2014as such, she is a prophet who appears as a crucial character in the play. The play's king Proteus is already dead at the start of the action, and his tomb is present onstage. It appears that he is only marginally related to the \"Old Man of the Sea\" and should not be confused with the sea god Proteus, although it is tempting to see Euripides as playing a complex literary game with the sea god's history\u2014both Proteuses, for example, are protectors of the house of Menelaus, both are connected with the sea, both dwell in Egypt, and both are \"grandfatherly\" or \"ancient\" figures.\nAt Pharos a king of Egypt named Proteus welcomed the young god Dionysus in his wanderings. In Hellenistic times, Pharos was the site of the Lighthouse of Alexandria, one of the seven wonders of the ancient world.\nCultural references.\nProteus as a cultural reference has been used in various contexts with different nuances according to each of the aspects of the myth: a shepherd of sea-creatures, a prophet who does not reveal their knowledge, a shape-changing god, the power to transform matter, or the primary matter that can become different materials. The adjective \"protean\" has come to mean versatile, ever-changing, or varied in nature.\nIn alchemy and psychology.\nThe German mystical alchemist Heinrich Khunrath wrote of the shape-changing sea-god who, because of his relationship to the sea, is both a symbol of the unconscious as well as the perfection of the art. Alluding to the \"scintilla\", the spark from \u2018the light of nature\u2019 and symbol of the , Khunrath in Gnostic vein stated of the Protean element Mercury:\nIn modern times, the Swiss psychologist Carl Jung defined the mythological figure of Proteus as a personification of the unconscious, who, because of his gift of prophecy and shape-changing, has much in common with the central but elusive figure of alchemy, Mercurius. The quote below gives further elaboration.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Our Catholick Mercury, by virtue of his universal fiery spark of the light of nature, is beyond doubt Proteus, the sea god of the ancient pagan sages, who hath the key to the sea and\u00a0... power over all things.\u2014\u200a\nIn literature.\nThe poet John Milton, aware of the association of Proteus with the Hermetic art of alchemy, wrote in \"Paradise Lost\" of alchemists who sought the philosopher's stone:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200a\nShakespeare uses the image of Proteus to establish the character of his great royal villain Richard III in the play \"Henry VI, Part Three\", in which the future usurper boasts:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200a\nShakespeare also names one of the main characters of his play \"The Two Gentlemen of Verona\" Proteus.\nIn 1806, William Wordsworth finished his sonnet on the theme of a modernity deadened to Nature, which opens \"The world is too much with us\", with a sense of nostalgia for the lost richness of a world numinous with deities: \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nJames Joyce's \"Ulysses\" uses Protean transformations of matter in time for self-exploration. \"Proteus\" is the title provided for the third chapter in the Linati schema for Ulysses.\nIn biology.\nA cave-dwelling aquatic salamander in Europe is called Proteus anguinus (referred simply as proteus or olm), and is the only species in the genus Proteus of the family Proteidae. \nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24760", "revid": "25128593", "url": "https://en.wikipedia.org/wiki?curid=24760", "title": "Pope Eusebius", "text": "Head of the Catholic Church in 310\nPope Eusebius (died 21 October 310) was the bishop of Rome from 18 April 309 until his exile on 17 August 310.\nBiography.\nNot much is known about Eusebius's early life, but he was probably a Greek.\nAs in the case of his predecessor, Marcellus I, difficulty arose out of Eusebius's attitude toward the lapsi. Eusebius maintained the attitude of the Roman Church, adopted after the Decian persecutions (250\u201351), that the apostates should not be forever debarred from ecclesiastical communion, but readmitted after doing proper penance. This view was opposed by a faction of Christians in Rome under the leadership of Heraclius. Johann Peter Kirsch believes it likely that Heraclius was the chief of a party made up of apostates and their followers, who demanded immediate restoration to the Roman Church. Emperor Maxentius intervened and exiled them both on 17 August 310 (N.S..\nEusebius died in exile in Sicily on 21 October 310 N.S. and was buried in the catacomb of Callixtus. Pope Damasus I placed an epitaph over his tomb because of his firm defence of ecclesiastical discipline and the banishment which he suffered thereby. His feast is celebrated on 17 August. The feast had previously been observed on 26 September.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24761", "revid": "42627654", "url": "https://en.wikipedia.org/wiki?curid=24761", "title": "Persian Gulf", "text": "Arm of the Indian Ocean in West Asia\nThe Persian Gulf, sometimes called the Arabian Gulf, is a mediterranean sea in West Asia. The body of water is an extension of the Arabian Sea and the larger Indian Ocean located between the Arabian Peninsula and Iran (Persia). It is connected to the Gulf of Oman in the east by the Strait of Hormuz. The river delta of the Shatt al-Arab forms the north-west shoreline.\nThe Persian Gulf has many fishing grounds, extensive reefs (mostly rocky, but also coral), and abundant pearl oysters; however, its ecology has been damaged by industrialization and oil spills.\nThe Persian Gulf is in the Persian Gulf Basin, which is of Cenozoic origin and related to the subduction of the Arabian plate under the Zagros Mountains. The current flooding of the basin started 15,000 years ago due to rising sea levels of the Holocene glacial retreat.\nGeography.\nThe International Hydrographic Organization defines the Persian Gulf's southern limit as \"The Northwestern limit of Gulf of Oman\". This limit is defined as \"A line joining R\u00e0s Limah (25\u00b057'N) on the coast of Arabia and R\u00e0s al Kuh (25\u00b048'N) on the coast of Iran (Persia)\".\nThis inland sea of some is connected to the Gulf of Oman in the east by the Strait of Hormuz; and its western end is marked by the major river delta of the Shatt al-Arab, which carries the waters of the Euphrates and the Tigris. In Iran, this is called \"Arvand Rud\" (lit.\u2009'Swift River'). Its length is , with Iran covering most of the northern coast and Saudi Arabia most of the southern coast. The Persian Gulf is about wide at its narrowest, in the Strait of Hormuz. Overall, the waters are very shallow, with a maximum depth of and an average depth of .\nCountries with a coastline on the Persian Gulf are (clockwise, from north): Iran; Oman's Musandam exclave; the United Arab Emirates; Saudi Arabia; Qatar, on a peninsula off the Saudi coast; Bahrain, an island nation; Kuwait; and Iraq in the northwest. Various small islands also lie within the Persian Gulf, some of which are the subject of territorial disputes between the states in the region.\nExclusive economic zone.\nExclusive economic zones in the Persian Gulf:\nCoastlines.\nCountries by coastline length:\nIslands.\nThe Persian Gulf is home to many islands such as Bahrain, an Arab state. Geographically, the biggest island in the Persian Gulf is Qeshm island, belonging to Iran and located in the Strait of Hormuz. Other significant islands in the Persian Gulf include Greater Tunb, Lesser Tunb and Kish administered by Iran, Bubiyan administered by Kuwait, Tarout administered by Saudi Arabia, and Dalma administered by UAE. In recent years, there has also been the addition of artificial islands for tourist attractions, such as The World Islands in Dubai and The Pearl Island in Doha. Persian Gulf islands are often also historically significant, having been used in the past by colonial powers such as the Portuguese and the British in their trade or as acquisitions for their empires.\nOceanography.\nThe Persian Gulf is connected to the Indian Ocean through the Strait of Hormuz. Writing the water balance budget for the Persian Gulf, the inputs are river discharges from Iran and Iraq (estimated to be per second), as well as precipitation over the sea which is around /year in Qeshm Island. The evaporation of the sea is high, so that after considering river discharge and rain contributions, there is still a deficit of per year. This difference is supplied by currents at the Strait of Hormuz. The water from the Persian Gulf has a higher salinity, and therefore exits from the bottom of the Strait, while ocean water with less salinity flows in through the top. Another study revealed the following numbers for water exchanges for the Persian Gulf: evaporation = \u2013/year, precipitation = /year, inflow from the Strait = /year, outflow from the Strait = -/year, and the balance is 0\u00a0m (0\u00a0ft)/year. Data from different 3D computational fluid mechanics models, typically with spatial resolution of and depth each element equal to are predominantly used in computer models.\nName.\nHistorical names.\nBefore being given its present name, the Persian Gulf was called many different names. The Assyrians called it the \"Bitter Sea\". In 550 BC, the Achaemenid Empire established the first ancient empire in Persis (\"Pars\", or modern \"Fars\", also known as Persia), in the southwestern region of the Iranian plateau. Consequently, in the Greek sources, the body of water that bordered this province came to be known as the \"Persian Gulf\". In the book of Nearchus known as \"Indik\u00ea\" (300 BC), the word \"Persikon kolpos\" is mentioned for multiple times meaning \"Persian gulf\".\nDuring the years 550 to 330 BC, coinciding with the sovereignty of the Achaemenid Persian Empire over the Middle East area, especially the whole part of the Persian Gulf and some parts of the Arabian Peninsula, the name of \"Persian (\"Pars\") Sea\" is widely found in the compiled written texts.\nAt the same period, there is the inscription and engraving of Darius the Great, which belongs to the fifth century BC: King Darius says:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I ordered to dig this (Canal of the Pharaohs) canal from the river that is called Nile (\"Pir\u00e2va\") and flows in Egypt (\"Mudr\u00e2y\u00e2\"), to the sea that begins in Persia (\"P\u00e2rsa\"). Therefore, when this canal had been dug as I had ordered, ships went from Egypt through this canal to Persia, as I had intended.\u2014\u200a\nIn Sassanian times, the Persian Gulf was called \"P\u016bd\u012bg\", which comes from , a name mentioned in Bundahishn.\nModern naming dispute.\nThe body of water is historically and internationally known as the Persian Gulf. It is listed in the third edition of Limits of Oceans and Seas as \"Gulf of Iran (Persian Gulf) and, as of 2002[ [update]], in the draft fourth edition as \"Persian Gulf\". Arab governments refer to it as the Arabian Gulf or The Gulf, and other countries and organizations have begun using Arabian Gulf. The name Gulf of Iran is used by the International Hydrographic Organization.\nThe dispute in naming has become especially prevalent since the 1960s. Rivalry between Iran and some Arab states, along with the emergence of pan-Arabism and Arab nationalism, has seen the name \"Arabian Gulf\" become predominant in most Arab countries.\nHistory.\nAncient history.\nThe region of the Persian Gulf has been inhabited since the Paleolithic. During most of the Last Glacial Period (115,000\u201311,700 years Before Present), due to lowered sea levels (reaching around metres below present values during the Last Glacial Maximum) combined with the shallow depth of the Gulf (on average around and at max around metres depth) most of the Persian Gulf was exposed as dry land, forming a flat floodplain where a number of rivers converged. This region may have served as an environmental refuge for early humans during periodic hyperarid climate oscillations. The modern marine Gulf was formed when sea level rose during the early Holocene, from around 12,000 to 6,000 years ago. The flooding of the Gulf may have stimulated the development of Neolithic farming cultures in regions of the Middle East adjacent to the Gulf.\nThe world's oldest known civilization (Sumer) developed along the Persian Gulf and southern Mesopotamia. The oldest evidence in the world for seagoing vessels has been found at H3 in Kuwait, dating to the mid-sixth millennium BC, when the Gulf was part of an extensive trade network that involved the Ubaid settlements in Mesopotamia and communities along the entire Gulf coast.\nFor most of the early history of the settlements in the Persian Gulf, the southern shores were ruled by a series of nomadic tribes. During the end of the fourth millennium BC, the southern part of the Persian Gulf was dominated by the Dilmun civilization. For a long time, the most important settlement on the southern coast of the Persian Gulf was Gerrha. In the second century the Lakhum tribe, who lived in what is now Yemen, migrated north and founded the Lakhmid Kingdom along the southern coast. Occasional ancient battles took place along the Persian Gulf coastlines, between the Sassanid Persian empire and the Lakhmid Kingdom, the most prominent of which was the invasion led by Shapur II against the Lakhmids, leading to Lakhmids' defeat, and advancement into Arabia, along the southern shorelines. During the seventh century the Sassanid Persian empire conquered the whole of the Persian Gulf, including southern and northern shores.\nBetween 625 BC and 226 AD, the northern side was dominated by a succession of Persian empires including the Median, Achaemenid, Seleucid and Parthian empires. Under the leadership of the Achaemenid king Darius the Great (Darius I), Persian ships found their way to the Persian Gulf. Persians were not only stationed on islands of the Persian Gulf, but also had ships often of 100 to 200 capacity patrolling empire's various rivers including Shatt-al-Arab, Tigris, and the Nile in the west, as well as Sind waterway, in India.\nThe Achaemenid high naval command had established major naval bases located along Shatt al-Arab river, Bahrain, Oman, and Yemen. The Persian fleet would soon not only be used for peacekeeping purposes along the Shatt al-Arab but would also open the door to trade with India via Persian Gulf.\nFollowing the fall of Achaemenid Empire, and after the fall of the Parthian Empire, the Sassanid Empire ruled the northern half and at times the southern half of the Persian Gulf. The Persian Gulf, along with the Silk Road, were important trade routes in the Sassanid Empire. Many of the trading ports of the Persian empires were located in or around Persian Gulf. Siraf, an ancient Sassanid port that was located on the northern shore of the Persian Gulf, located in what is now the Iranian province of Bushehr, is an example of such commercial port. Siraf, was also significant in that it had a flourishing commercial trade with China by the fourth century, having first established connection with the far east in 185 AD.\nColonial era.\nPortuguese influence in the Persian Gulf lasted for 250 years; however, since the beginning of the 16th century, Portuguese dominance contended with the local powers and the Ottoman Empire. Following the arrival of the English and the Dutch, the Safavid Empire allied with the newcomers to contest Portuguese dominance of the seas in the 17th century.\nPortuguese expansion into the Indian Ocean in the early 16th century following Vasco da Gama's voyages of exploration saw them battle the Ottomans up the coast of the Persian Gulf. In 1521, a Portuguese force led by commander Antonio Correia invaded Bahrain to take control of the wealth created by its pearl industry. On 29 April 1602, Sh\u0101h Abb\u0101s, the Persian emperor of the Safavid Persian Empire, expelled the Portuguese from Bahrain, and that date is commemorated as National Persian Gulf day in Iran. With the support of the British fleet, in 1622 'Abb\u0101s took the island of Hormuz from the Portuguese; much of the trade was diverted to the town of Bandar 'Abb\u0101s, which he had taken from the Portuguese in 1615 and had named after himself. The Persian Gulf was therefore opened to a flourishing commerce with the Portuguese, Dutch, French, Spanish and the British merchants, who were granted particular privileges. The Ottoman Empire reasserted itself into Eastern Arabia in 1871. Under military and political pressure from the governor of the Ottoman Vilayet of Baghdad, Midhat Pasha, the ruling Al Thani tribe submitted peacefully to Ottoman rule. The Ottomans were forced to withdraw from the area with the start of World War I and the need for troops in various other frontiers. In World War II, the Western Allies used Iran as a conduit to transport military and industrial supply to the USSR, through a pathway known historically as the \"Persian Corridor\". Britain utilized the Persian Gulf as the entry point for the supply chain in order to make use of the Trans-Iranian Railway. The Persian Gulf therefore became a critical maritime path through which the Allies transported equipment to Soviet Union against the Nazi invasion. The piracy in the Persian Gulf was prevalent until the 19th century. Many of the most notable historical instances of piracy were perpetrated by the Al Qasimi tribe. This led to the British mounting the Persian Gulf campaign of 1819. The campaign led to the signing of the General Maritime Treaty of 1820 between the British and the Sheikhs of what was then known as the \"Pirate Coast\". From 1763 until 1971, the British Empire maintained varying degrees of political control over some of the Persian Gulf states, including the United Arab Emirates (originally called the Trucial States) and at various times Bahrain, Kuwait, Oman, and Qatar through the British Residency of the Persian Gulf.\nModern history.\nThe Persian Gulf was a battlefield of the 1980\u20131988 Iran\u2013Iraq War, in which each side attacked the other's oil tankers. It is the namesake of the 1991 Gulf War, the largely air- and land-based conflict that followed Iraq's invasion of Kuwait. The United States' role in the Persian Gulf grew in the second half of the 20th century. On 3 July 1988, Iran Air Flight 655 was shot down by the U.S. military (which had mistaken the Airbus A300 operating the flight for an Iranian F-14 Tomcat) while it was flying over the Persian Gulf, killing all 290 people on board. The United Kingdom maintains a profile in the region; in 2006 alone, over 1\u00a0million British nationals visited Dubai. In 2018, the UK opened a permanent military base, , in the Persian Gulf, the first since it withdrew from East of Suez in 1971 and is developing a support facility in Oman.\nCities and population.\nEight nations have coasts along the Persian Gulf: Bahrain, Iran, Iraq, Kuwait, Oman, Qatar, Saudi Arabia, and the United Arab Emirates. The Persian gulf's strategic location has made it an ideal place for human development over time. Today, many major cities of the Middle East are located in this region.\nWildlife.\nThe wildlife of the Persian Gulf is diverse, and entirely unique because of the Persian Gulf's geographic distribution and its isolation from the international waters only breached by the narrow Strait of Hormuz. The Persian Gulf has hosted some of the most magnificent marine fauna and flora, some of which are near extirpation or at serious environmental risk. From corals, to dugongs, Persian Gulf is a diverse cradle for many species who depend on each other for survival. However, the Persian Gulf is not as biologically diverse as the Red Sea.\nOverall, the wildlife of the Persian Gulf is endangered from both global factors, and regional, local negligence. Most pollution is from ships; land generated pollution counts as the second most common source of pollution.\nAquatic mammals.\nAlong the mediterranean regions of the Arabian Sea, including the Persian Gulf, the Red Sea, the Gulf of Kutch, the Gulf of Suez, the Gulf of Aqaba, the Gulf of Aden, and the Gulf of Oman, dolphins and finless porpoises are the most common marine mammals in the waters, while larger whales and orcas are rarer today. Historically, whales had been abundant in the Persian Gulf before commercial hunts wiped them out. Whales were reduced even further by illegal mass hunts by the Soviet Union and Japan in the 1960s and 1970s. Along with Bryde's whales, these once common residents can still can be seen in deeper marginal seas such as Gulf of Aden, Israel coasts, and in the Strait of Hormuz. Other species such as the critically endangered Arabian humpback whale, (also historically common in Gulf of Aden and increasingly sighted in the Red Sea since 2006, including in the Gulf of Aqaba), omura's whale, minke whale, and orca also swim into the Persian Gulf, while many other large species such as blue whale, sei, and sperm whales were once migrants into the Gulf of Oman and off the coasts in deeper waters, and still migrate into the Red Sea, but mainly in deeper waters of outer seas. In 2017, waters of the Persian Gulf along Abu Dhabi were revealed to hold the world's largest population of Indo-Pacific humpbacked dolphins.\nOne of the more unusual marine mammals living in the Persian Gulf is the dugong (\"Dugong dugon\"). Also called \"sea cows\", for their grazing habits and mild manner resembling livestock, dugongs have a life expectancy similar to that of humans and they can grow up to in length. These gentle mammals feed on sea grass and are closer relatives of certain land mammals than are dolphins and whales. Their simple grass diet is negatively affected by new developments along the Persian Gulf coastline, particularly the construction of artificial islands by Arab states and pollution from oil spills caused during the \"Persian Gulf war\" and various other natural and artificial causes. Uncontrolled hunting has also had a negative impact on the survival of dugongs. After Australian waters, which are estimated to contain some 80,000 dugong inhabitants, the waters off Qatar, Bahrain, UAE, and Saudi Arabia make the Persian Gulf the second most important habitat for the species, hosting some 7,500 remaining dugongs. However, the current number of dugongs is dwindling, and it is not clear how many are currently alive or what their reproductive trend is. Ambitious and uncalculated construction schemes, political unrest, ever-present international conflict, the most lucrative world supply of oil, and the lack of cooperation between Arab states and Iran, have had a negative impact on the survival of many marine species, including dugongs.\nBirds.\nThe Persian Gulf is also home to many migratory and local birds. There is great variation in color, size, and type of the bird species that call the Persian Gulf home. Concerns regarding the endangerment of the \"kalbaensis\" subspecies of the collared kingfishers were raised by conservationists over real estate development by the United Arab Emirates and Oman. Estimates from 2006 showed that only three viable nesting sites were available for this ancient bird, one located from Dubai, and two smaller sites in Oman. Such real estate expansion could prove devastating to this subspecies. A UN plan to protect the mangroves as a biological reserve was ignored by the emirate of Sharjah, which allowed the dredging of a channel that bisects the wetland and construction of an adjacent concrete walkway. Environmental watchdogs in Arabia are few, and those that do advocate the wildlife are often silenced or ignored by developers of real estate many of whom have governmental connections.\nReal estate development in the Persian Gulf by the United Arab Emirates and Oman also raised concerns that habitats of species such as the hawksbill turtle, greater flamingo, and booted warbler may be destroyed. The dolphins that frequent the Persian Gulf in northern waters around Iran are also at risk. Recent statistics and observations show that dolphins are at danger of entrapment in purse seine fishing nets and exposure to chemical pollutants; perhaps the most alarming sign is the \"mass suicides\" committed by dolphins off Iran's Hormozgan province, which are not well understood, but are suspected to be linked with a deteriorating marine environment from water pollution from oil, sewage, and industrial run offs.\nA 2009 study of ten Iranian islands in the Persian Gulf recorded more than 100,000 breeding pairs of waterbirds from 11 species, including the Bridled Tern (Sterna anaethetus), Lesser Crested Tern (Thalasseus bengalensis), and Crab Plover (Dromas ardeola). These islands provide critical nesting habitat, and fluctuations in seabird populations have been proposed as biological indicators of regional ecological health.\nFish and reefs.\nThe Persian Gulf is home to over 700 species of fish, most of which are native. Of these 700 species, more than 80% are reef associated. These reefs are primarily rocky, but there are also a few coral reefs. Compared to the Red Sea, the coral reefs in the Persian Gulf are relatively few and far between. This is primarily connected to the influx of major rivers, especially the Shatt al-Arab (Euphrates and Tigris), which carry large amounts of sediment (most reef-building corals require strong light) and causes relatively large variations in temperature and salinity (corals in general are poorly suited to large variations). Nevertheless, coral reefs have been found along sections of coast of all countries in the Persian Gulf. Corals are vital ecosystems that support multitude of marine species, and whose health directly reflects the health of the Persian Gulf. Recent years have seen a drastic decline in the coral population in the Persian Gulf, partially owing to global warming but mostly to irresponsible dumping by Arab states like the UAE and Bahrain. Construction garbage such as tires, cement, and chemical by products have found their way to the Persian Gulf in recent years. Aside from direct damage to the coral, the construction waste creates \"traps\" for marine life in which they are trapped and die. The result has been a dwindling population of the coral, and as a result a decrease in number of species that rely on the corals for their survival.\nFlora.\nA great example of this symbiosis are the mangroves in the Persian Gulf, which require tidal flow and a combination of fresh and salt water for growth, and act as nurseries for many crabs, small fish, and insects; these fish and insects are the source of food for many of the marine birds that feed on them. Mangroves are a diverse group of shrubs and trees belonging to the genus \"Avicennia\" or \"Rhizophora\" that flourish in the salt water shallows of the Persian Gulf, and are the most important habitats for small crustaceans that dwell in them. They are as crucial an indicator of biological health on the surface of the water, as the corals are to biological health of the Persian Gulf in deeper waters. Mangroves' ability to survive the salt water through intricate molecular mechanisms, their unique reproductive cycle, and their ability to grow in the most oxygen-deprived waters have allowed them extensive growth in hostile areas of the Persian Gulf. However, with the advent of artificial island development, most of their habitat is destroyed, or occupied by man-made structures. This has had a negative impact on the crustaceans that rely on the mangrove, and in turn on the species that feed on them.\nOil and gas.\nThe Persian Gulf and its coastal areas are the world's largest single source of petroleum, and related industries dominate the region. Safaniya Oil Field, the world's largest offshore oilfield, is located in the Persian Gulf. Large gas finds have also been made, with Qatar and Iran sharing a giant field across the territorial median line (North Field in the Qatari sector; South Pars Field in the Iranian sector). Using this gas, Qatar has built up a substantial liquefied natural gas (LNG) and petrochemical industry.\nIn 2002, the Persian Gulf nations of Bahrain, Iran, Iraq, Kuwait, Qatar, Saudi Arabia, and the UAE produced about 25% of the world's oil, held nearly two-thirds of the world's crude oil reserves, and about 35% of the world's natural gas reserves. The oil-rich countries (excluding Iraq) that have a coastline on the Persian Gulf are referred to as the \"Persian Gulf States\". Iraq's egress to the Persian Gulf is narrow and easily blockaded, consisting of the marshy river delta of the Shatt al-Arab, which carries the waters of the Euphrates and the Tigris rivers, where the east bank is held by Iran.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24762", "revid": "5846", "url": "https://en.wikipedia.org/wiki?curid=24762", "title": "P53", "text": "Mammalian protein found in humans\np53, also known as tumor protein p53, TP53, cellular tumor antigen p53 (UniProt name), or transformation-related protein 53 (TRP53) is a regulatory transcription factor protein that is often mutated in human cancers. The p53 proteins (originally thought to be, and often spoken of as, a single protein) are crucial in vertebrates, where they prevent cancer formation. As such, p53 has been described as \"the guardian of the genome\" because of its role in conserving stability by preventing genome mutation. Hence \"TP53\" is classified as a tumor suppressor gene.\nThe \"TP53\" gene is the most frequently mutated gene (&gt;50%) in human cancer, indicating that the \"TP53\" gene plays a crucial role in preventing cancer formation. \"TP53\" gene encodes proteins that bind to DNA and regulate gene expression to prevent mutations of the genome. In addition to the full-length protein, the human \"TP53\" gene encodes at least 12 protein isoforms.\nGene.\nIn humans, the \"TP53\" gene is located on the short arm of chromosome 17 (17p13.1). The gene spans 20 kb, with a non-coding exon 1 and a very long first intron of 10 kb, overlapping the Hp53int1 gene. The coding sequence contains five regions showing a high degree of conservation in vertebrates, predominantly in exons 2, 5, 6, 7 and 8, but the sequences found in invertebrates show only distant resemblance to mammalian TP53. \"TP53\" orthologs have been identified in most mammals for which complete genome data are available. Elephants, with 20 genes for TP53, rarely get cancer.\nStructure.\nThe full-length p53 protein (p53\u03b1) comprises seven distinct protein domains:\nMost cancer-associated mutations in \"TP53\" occur in the DBD, impairing DNA binding and transcriptional activation. These are typically recessive loss-of-function mutations. By contrast, mutations in the OD can exert dominant negative effects by forming inactive complexes with wild-type p53.\nWild-type p53 is a labile protein containing both folded and intrinsically disordered regions that act synergistically.\nAlthough designated as a 53\u00a0kDa protein by SDS-PAGE, the actual molecular weight of p53\u03b1 is 43.7\u00a0kDa. The discrepancy is due to its high proline content, which slows electrophoretic migration.\nTetramerization.\np53 initially forms dimers cotranslationally during protein synthesis on ribosomes. Each dimer consists of two p53 monomers joined through their oligomerization domains.\nThe dimerization interface spans residues 325\u2013356 and includes a beta-strand (residues 325\u2013333), a alpha-helix (residues 335\u2013356), and a sharp turn at the conserved hinge residue Gly334. This configuration links the beta-strand and alpha-helix to form a V-shaped monomer topology. The beta-strand contributes to the formation of an antiparallel intermolecular beta-sheet between two p53 monomers, stabilized by hydrophobic interactions involving Phe328, Leu330, and Ile332. The alpha-helix forms an antiparallel coiled-coil between the two monomers, with a packing angle of 156\u00b0. Helix\u2013helix interactions are stabilized by hydrophobic contacts (e.g., Phe338, Phe341, Leu344) and electrostatic interactions, such as the Arg337\u2013Asp352 salt bridge.\nFollowing dimer formation, p53 dimers associate posttranslationally to form tetramers (dimers of dimers). The tetramerization domain (residues 325\u2013356) plays a central role in stabilizing the tetrameric structure.\nIn the tetramer, the two primary dimers associate at an angle described as \"roughly orthogonal,\" with a helix bundle packing angle (\u03b8) of approximately 80\u00b0.\nTetramers represent the active form of p53 for DNA binding and transcriptional regulation.\nIsoforms.\nLike 95% of human genes, \"TP53\" encodes multiple proteins, collectively known as the p53 isoforms. These vary in size from 3.5 to 43.7\u00a0kDa. Since their initial discovery in 2005, 12 human p53 isoforms have been identified: p53\u03b1, p53\u03b2, p53\u03b3, \u220640p53\u03b1, \u220640p53\u03b2, \u220640p53\u03b3, \u2206133p53\u03b1, \u2206133p53\u03b2, \u2206133p53\u03b3, \u2206160p53\u03b1, \u2206160p53\u03b2, and \u2206160p53\u03b3. Isoform expression is tissue-dependent, and p53\u03b1 is never expressed alone.\nThe isoforms differ by the inclusion or exclusion of specific domains. Some, such as \u0394133p53\u03b2/\u03b3 and \u0394160p53\u03b1/\u03b2/\u03b3, lack the transactivation or proline-rich domains and are deficient in apoptosis induction, illustrating the functional diversity of \"TP53\".\nIsoforms are generated through multiple mechanisms:\nFunction.\nDNA damage and repair.\np53 regulates cell cycle progression, apoptosis, and genomic stability through multiple mechanisms:\np53 functions as a transcription factor by binding DNA as a tetramer, a structure that is essential for its stability and effective DNA binding activity. Once bound to DNA, p53 induces the transcription of numerous genes involved in DNA repair pathways. This includes components of base excision repair (BER) such as OGG1 and MUTYH, nucleotide excision repair (NER) factors like DDB2 and XPC, mismatch repair (MMR) genes such as MSH2 and MLH1, and elements of homologous recombination (HR) and non-homologous end-joining (NHEJ) repair. These transcriptional responses are crucial for the DNA damage response (DDR), allowing cells to efficiently repair damaged DNA and maintain genomic integrity. While p53's role is most clearly defined in transcriptional activation of repair genes, it also participates in non-transcriptional regulation of DNA repair processes, particularly in HR and NHEJ, by modulating protein interactions and chromatin accessibility.\np53 binds specific elements in the promoter of target genes, including CDKN1A, which encodes p21. Upon activation by p53, p21 inhibits cyclin-dependent kinases, leading to cell cycle arrest and contributing to tumor suppression. However, p21 can also be induced independently of p53 during processes such as differentiation, development, and in response to serum stimulation.\np21 (WAF1) binds to cyclin-CDK complexes (notably CDK2, CDK1, CDK4, and CDK6), inhibiting their activity and blocking the G1/S transition. This inhibition enforces a cell cycle pause that allows DNA repair to occur. In cells with functional p53, p21 is upregulated in response to DNA damage, ensuring this checkpoint control. In contrast, p53 mutations impair p21 induction and compromise this control.\nIn human embryonic stem cells (hESCs), although p21 mRNA is upregulated following DNA damage, the protein is not detectable. This reflects a nonfunctional p53-p21 axis at the G1/S checkpoint. This discrepancy is largely due to post-transcriptional repression, particularly by the miR-302 family of microRNAs, which inhibit p21 translation. Although p53 binds the CDKN1A promoter in hESCs, it does not regulate miR-302, which is constitutively expressed and suppresses p21 expression.\nThe p53 pathway is interconnected with the RB1 pathway via p14^ARF, which links the regulation of these key tumor suppressors.\np53 expression can be induced by UV radiation, which also causes DNA damage. In this context, p53 activation can initiate processes that lead to melanin production and tanning.\nStem cells.\nLevels of p53 play an important role in the maintenance of stem cells throughout development and the rest of human life.\nIn human embryonic stem cells (hESCs)s, p53 is maintained at low inactive levels. This is because activation of p53 leads to rapid differentiation of hESCs. Studies have shown that knocking out p53 delays differentiation and that adding p53 causes spontaneous differentiation, showing how p53 promotes differentiation of hESCs and plays a key role in cell cycle as a differentiation regulator. When p53 becomes stabilized and activated in hESCs, it increases p21 to establish a longer G1. This typically leads to abolition of S-phase entry, which stops the cell cycle in G1, leading to differentiation. Work in mouse embryonic stem cells has recently shown however that the expression of P53 does not necessarily lead to differentiation. p53 also activates miR-34a and miR-145, which then repress the hESCs pluripotency factors, further instigating differentiation.\nIn adult stem cells, p53 regulation is important for maintenance of stemness in adult stem cell niches. Mechanical signals such as hypoxia affect levels of p53 in these niche cells through the hypoxia inducible factors, HIF-1\u03b1 and HIF-2\u03b1. While HIF-1\u03b1 stabilizes p53, HIF-2\u03b1 suppresses it. Suppression of p53 plays important roles in cancer stem cell phenotype, induced pluripotent stem cells and other stem cell roles and behaviors, such as blastema formation. Cells with decreased levels of p53 have been shown to reprogram into stem cells with a much greater efficiency than normal cells. Papers suggest that the lack of cell cycle arrest and apoptosis gives more cells the chance to be reprogrammed. Decreased levels of p53 were also shown to be a crucial aspect of blastema formation in the legs of salamanders. p53 regulation is very important in acting as a barrier between stem cells and a differentiated stem cell state, as well as a barrier between stem cells being functional and being cancerous.\nOther.\nApart from the cellular and molecular effects above, p53 has a tissue-level anticancer effect that works by inhibiting angiogenesis. As tumors grow they need to recruit new blood vessels to supply them, and p53 inhibits that by (i) interfering with regulators of tumor hypoxia that also affect angiogenesis, such as HIF1 and HIF2, (ii) inhibiting the production of angiogenic promoting factors, and (iii) directly increasing the production of angiogenesis inhibitors, such as arresten.\np53 by regulating Leukemia Inhibitory Factor has been shown to facilitate implantation in the mouse and possibly human reproduction.\nThe immune response to infection also involves p53 and NF-\u03baB. Checkpoint control of the cell cycle and of apoptosis by p53 is inhibited by some infections such as Mycoplasma bacteria, raising the specter of oncogenic infection.\nRegulation.\nBasal regulation.\nUnder normal, unstressed conditions, p53 is maintained at low levels through continuous degradation mediated by the E3 ubiquitin ligase MDM2 (HDM2 in humans). MDM2 binds p53, exports it from the nucleus, and targets it for proteasomal degradation. Notably, p53 transcriptionally activates \"MDM2\", establishing a classic negative feedback loop.\nThis feedback loop gives rise to damped oscillations in p53 levels, as demonstrated both experimentally and in mathematical models. These oscillations may determine cell fate decisions between survival and apoptosis.\nActivation by cellular stress.\np53 is activated in response to a range of cellular stressors, including DNA damage (from ultraviolet or ionizing radiation, or oxidative chemicals), osmotic shock, ribonucleotide depletion, oncogene activation, and viral pneumonia.\nActivation involves two main steps: stabilization of the protein, leading to its accumulation in the nucleus, and a conformational change that allows DNA binding and transcriptional activation. This process is initiated by phosphorylation of the N-terminal transactivation domain by stress-responsive kinases.\nStress-responsive kinases.\nKinases that regulate p53 phosphorylation fall into two major categories. One group includes MAPK pathway members such as JNK1\u20133, ERK1/2, and p38 MAPK, which respond to oxidative stress, membrane damage, and heat shock. The second group comprises DNA damage response kinases, including ATM, ATR, CHK1, CHK2, DNA-PK, CAK, and TP53RK, which respond to genomic instability. Oncogene-induced activation of p53 occurs via p14ARF, which inhibits MDM2 and thereby stabilizes p53.\nDeubiquitination.\nSeveral deubiquitinating enzymes (DUBs) modulate p53 stability by removing ubiquitin chains. USP7, also known as HAUSP, can deubiquitinate both p53 and MDM2. In unstressed cells, HAUSP preferentially stabilizes MDM2, and its depletion may paradoxically increase p53 levels. USP42 is another DUB that stabilizes p53 and enhances its ability to respond to stress. USP10 operates primarily in the cytoplasm, where it counteracts MDM2 by directly deubiquitinating p53. After DNA damage, USP10 translocates to the nucleus and further stabilizes p53. It does not interact with MDM2.\nPost-translational modifications and cofactors.\nPhosphorylation of the N-terminus not only prevents MDM2 binding but also facilitates the recruitment of cofactors. Pin1 enhances conformational changes in p53, while p300 and PCAF acetylate the C-terminus, exposing the DNA-binding domain and enhancing transcriptional activation. Conversely, deacetylases such as Sirt1 and Sirt7 remove these modifications, suppressing apoptosis and promoting cell survival. Some oncogenes can also activate p53 indirectly by inhibiting MDM2.\nDynamics.\nBoth experimental evidence and mathematical modeling indicate that p53 levels oscillate over time in response to cellular signals. These oscillations become more pronounced in the presence of DNA damage, such as double-stranded breaks or UV exposure. Modeling approaches also help illustrate how mutations in p53 isoforms affect oscillatory behavior, potentially informing tissue-specific therapeutic development.\nEpigenetics.\np53 function is also influenced by chromatin environment. The corepressor TRIM24 restricts p53 binding to epigenetically repressed loci by recognizing methylated histones. This interaction enables p53 to interpret local chromatin context and regulate gene expression in a locus-specific manner.\nRole in disease.\nIf the \"TP53\" gene is damaged, its ability to suppress tumors is severely compromised. Individuals who inherit only one functional copy of \"TP53\" are predisposed to developing tumors in early adulthood, a condition known as Li\u2013Fraumeni syndrome.\nThe \"TP53\" gene can also be altered by mutagens\u2014such as chemicals, radiation, or certain viruses\u2014thereby increasing the likelihood of uncontrolled cell division. More than 50 percent of human tumors harbor a mutation or deletion of the \"TP53\" gene. Loss of p53 function leads to genomic instability, frequently resulting in an aneuploidy phenotype.\nCertain pathogens can also disrupt p53 activity. For example, human papillomavirus (HPV) produces the viral protein E6, which binds to and inactivates p53. In conjunction with the HPV protein E7, which inactivates the cell cycle regulator pRb, this promotes repeated cell division, clinically presenting as warts. High-risk HPV types, particularly types 16 and 18, can drive the progression from benign warts to low- or high-grade cervical dysplasia, reversible precancerous lesions. Persistent cervical infection can lead to irreversible changes, including carcinoma in situ and invasive cervical cancer. These outcomes are primarily driven by viral integration into the host genome and the continued expression of the E6 and E7 oncoproteins.\nMutations.\nMost p53 mutations are detected by DNA sequencing. However, it is known that single missense mutations can have a large spectrum from rather mild to very severe functional effects.\nThe large spectrum of cancer phenotypes due to mutations in the \"TP53\" gene is also supported by the fact that different isoforms of p53 proteins have different cellular mechanisms for prevention against cancer. Mutations in \"TP53\" can give rise to different isoforms, preventing their overall functionality in different cellular mechanisms and thereby extending the cancer phenotype from mild to severe. Recent studies show that p53 isoforms are differentially expressed in different human tissues, and the loss-of-function or gain-of-function mutations within the isoforms can cause tissue-specific cancer or provide cancer stem cell potential in different tissues. TP53 mutation also hits energy metabolism and increases glycolysis in breast cancer cells.\nA common human polymorphism in \"TP53\" involves a substitution of arginine for proline at codon 72 of exon 4. Numerous studies have explored the relationship between this variation and cancer susceptibility, yielding mixed results. For instance, a 2009 meta-analysis found no association between the codon 72 polymorphism and cervical cancer risk.\nOther studies have identified possible associations between the codon 72 polymorphism and various cancers. A 2011 study reported that the proline variant significantly increased pancreatic cancer risk in males. Another study found that proline homozygosity was associated with decreased breast cancer risk in Arab women. Additional research suggested that \"TP53\" codon 72 polymorphisms, in combination with MDM2 SNP309 and A2164G, may affect susceptibility and age of onset for non-oropharyngeal cancers in women. A separate 2011 study linked the polymorphism to an increased risk of lung cancer in a Korean population.\nHowever, meta-analyses published in 2011 found no significant associations between the codon 72 variant and risks of either colorectal or endometrial cancer. A study of a Brazilian birth cohort found an association between the arginine variant and individuals without a family history of cancer. Meanwhile, another study reported that individuals with the homozygous Pro/Pro genotype had a significantly increased risk of renal cell carcinoma.\nTherapeutic reactivation and gene therapy.\nWhile increasing p53 levels might appear beneficial for treating cancer, sustained p53 activation can cause premature aging. A more promising approach involves restoring normal, endogenous p53 function. In some tumor types, this leads to regression via apoptosis or normalization of cell growth.\nThe first commercial gene therapy, Gendicine, was approved in China in 2003 for head and neck squamous cell carcinoma. It delivers a functional copy of the \"TP53\" gene using a modified adenovirus.\nThe small-molecule inhibitor MI-63 can bind to MDM2, blocking its interaction with p53 and reactivating p53 in cancers where its function is suppressed.\nDiscovery.\np53 was identified in 1979 by Lionel Crawford, David P. Lane, Arnold Levine, and Lloyd Old, working at Imperial Cancer Research Fund (UK), Princeton University/UMDNJ (Cancer Institute of New Jersey), and Memorial Sloan Kettering Cancer Center, respectively. It had been hypothesized to exist before as the target of the SV40 virus, a strain that induced development of tumors. The name p53 is in fact a misnomer, as it describes the apparent molecular mass measured when it was first discovered, though it was later realised this was an overestimate: the correct molecular mass is only 43.7 kDa.\nThe \"TP53\" gene from the mouse was first cloned by Peter Chumakov of The Academy of Sciences of the USSR in 1982, and independently in 1983 by Moshe Oren in collaboration with David Givol (Weizmann Institute of Science). The human \"TP53\" gene was cloned in 1984 and the full length clone in 1985.\nIt was initially presumed to be an oncogene due to the use of mutated cDNA following purification of tumor cell mRNA. Its role as a tumor suppressor gene was revealed in 1989 by Bert Vogelstein at the Johns Hopkins School of Medicine and Arnold Levine at Princeton University. p53 went on to be identified as a transcription factor by Guillermina Lozano working at MD Anderson Cancer Center.\nWarren Maltzman, of the Waksman Institute of Rutgers University first demonstrated that TP53 was responsive to DNA damage in the form of ultraviolet radiation. In a series of publications in 1991\u201392, Michael Kastan of Johns Hopkins University, reported that TP53 was a critical part of a signal transduction pathway that helped cells respond to DNA damage.\nIn 1993, p53 was voted \"molecule of the year\" by \"Science\" magazine.\nInteractions.\np53 has been shown to interact with:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24763", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=24763", "title": "Punks", "text": ""}
{"id": "24764", "revid": "20733806", "url": "https://en.wikipedia.org/wiki?curid=24764", "title": "Pointless topology", "text": "Mathematical approach\nIn mathematics, pointless topology, also called point-free topology (or pointfree topology) or topology without points and locale theory, is an approach to topology where lattices of open sets are the primitive notion, and are not required to consist of subsets of points. In this approach it becomes possible to construct \"topologically interesting\" spaces from purely algebraic data. Points are then a derived notion rather than primitive, and there are non-trivial spaces that have no points.\nHistory.\nThe first approaches to topology were geometrical, where one started from Euclidean space and patched things together. But Marshall Stone's work on Stone duality in the 1930s showed that topology can be viewed from an algebraic point of view (lattice-theoretic). Karl Menger was an early pioneer in the field, and his work on topology without points was inspired by Whitehead's point-free geometry and used shrinking regions of the plane to simulate points.\nApart from Stone, Henry Wallman also exploited this idea. Others continued this path till Charles Ehresmann and his student Jean B\u00e9nabou (and simultaneously others), took a major step in the late fifties. Their insights arose from the study of \"topological\" and \"differentiable\" categories.\nEhresmann's approach involved using a category whose objects were complete lattices that satisfied a distributive law and whose morphisms were maps that preserved finite meets and arbitrary joins. He called such lattices \"local lattices\"; today they are called \"frames\" to avoid ambiguity with other notions in lattice theory.\nThe theory of frames and locales in the contemporary sense was developed through the following decades (John Isbell, Peter Johnstone, Harold Simmons, , , Till Plewe, Japie Vermeulen, Steve Vickers) into a lively branch of topology, with application in various fields, in particular also in theoretical computer science. For more on the history of locale theory see Johnstone's overview.\nIntuition.\nTraditionally, a topological space consists of a set of points together with a \"topology\", a system of subsets called open sets that with the operations of union (as join) and intersection (as meet) forms a lattice with certain properties. Specifically, the union of any family of open sets is again an open set, and the intersection of finitely many open sets is again open. In pointless topology we take these properties of the lattice as fundamental, without requiring that the lattice elements be sets of points of some underlying space and that the lattice operation be intersection and union. Rather, point-free topology is based on the concept of a \"realistic spot\" instead of a point without extent. These \"spots\" can be joined (symbol formula_1), akin to a union, and we also have a meet operation for spots (symbol formula_2), akin to an intersection. Using these two operations, the spots form a complete lattice. If a spot meets a join of others it has to meet some of the constituents, which, roughly speaking, leads to the distributive law\nformula_3\nwhere the formula_4 and formula_5 are spots and the index family formula_6 can be arbitrarily large. This distributive law is also satisfied by the lattice of open sets of a topological space.\nIf formula_7 and formula_8 are topological spaces with lattices of open sets denoted by formula_9 and formula_10, respectively, and formula_11 is a continuous map, then, since the pre-image of an open set under a continuous map is open, we obtain a map of lattices in the opposite direction: formula_12. Such \"opposite-direction\" lattice maps thus serve as the proper generalization of continuous maps in the point-free setting.\nFormal definitions.\nThe basic concept is that of a frame, a complete lattice satisfying the general distributive law above. Frame homomorphisms are maps between frames that respect all joins (in particular, the least element of the lattice) and finite meets (in particular, the greatest element of the lattice). Frames, together with frame homomorphisms, form a category.\nThe opposite category of the category of frames is known as the category of locales. A locale formula_7 is thus nothing but a frame; if we consider it as a frame, we will write it as formula_14. A locale morphism formula_15 from the locale formula_7 to the locale formula_8 is given by a frame homomorphism formula_18.\nEvery topological space formula_19 gives rise to a frame formula_20 of open sets and thus to a locale. A locale is called spatial if it isomorphic (in the category of locales) to a locale arising from a topological space in this manner.\nformula_28\nformula_29\nformula_30\n(where formula_31 denotes the greatest element and formula_32 the smallest element of the frame.) The resulting locale is known as the \"locale of surjective functions formula_33\". The relations are designed to suggest the interpretation of formula_27 as the set of all those surjective functions formula_35 with formula_36. Of course, there are no such surjective functions formula_33, and this is not a spatial locale.\nThe theory of locales.\nWe have seen that we have a functor formula_38 from the category of topological spaces and continuous maps to the category of locales. If we restrict this functor to the full subcategory of sober spaces, we obtain a full embedding of the category of sober spaces and continuous maps into the category of locales. In this sense, locales are generalizations of sober spaces.\nIt is possible to translate most concepts of point-set topology into the context of locales, and prove analogous theorems. Some important facts of classical topology depending on choice principles become choice-free (that is, constructive, which is, in particular, appealing for computer science). Thus for instance, arbitrary products of compact locales are compact constructively (this is Tychonoff's theorem in point-set topology), or completions of uniform locales are constructive. This can be useful if one works in a topos that does not have the axiom of choice. Other advantages include the much better behaviour of paracompactness, with arbitrary products of paracompact locales being paracompact, which is not true for paracompact spaces, or the fact that subgroups of localic groups are always closed.\nAnother point where topology and locale theory diverge strongly is the concepts of subspaces versus sublocales, and density: given any collection of dense sublocales of a locale formula_7, their intersection is also dense in formula_7. This leads to Isbell's density theorem: every locale has a smallest dense sublocale. These results have no equivalent in the realm of topological spaces.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\nA general introduction to pointless topology is\nThis is, in its own words, to be read as a trailer for Johnstone's monograph and which can be used for basic reference:\nThere is a recent monograph\nFor relations with logic:\nFor a more concise account see the respective chapters in:"}
{"id": "24766", "revid": "25859633", "url": "https://en.wikipedia.org/wiki?curid=24766", "title": "Protestants", "text": ""}
{"id": "24767", "revid": "1152308", "url": "https://en.wikipedia.org/wiki?curid=24767", "title": "Phobos", "text": "Phobos (Greek for \"fear\") most commonly refers to:\nPhobos may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "24768", "revid": "18481282", "url": "https://en.wikipedia.org/wiki?curid=24768", "title": "Pizza", "text": "Italian dish with a flat dough-based base and toppings\nPizza is an Italian dish typically consisting of a flat base of leavened wheat-based dough topped with tomato, cheese, and other ingredients, baked at a high temperature, traditionally in a wood-fired oven.\nThe term \"pizza\" was first recorded in 997AD, in a Latin manuscript from the southern Italian town of Gaeta, in Lazio, on the border with Campania. Raffaele Esposito is often credited for creating the modern pizza in Naples. In 2009, Neapolitan pizza was registered with the European Union as a traditional speciality guaranteed (TSG) dish. In 2017, the art of making Neapolitan pizza was included on UNESCO's list of intangible cultural heritage.\nPizza and its variants are among the most popular foods in the world. Pizza is sold at a variety of restaurants, including pizzerias, Mediterranean restaurants, via delivery, and as street food. In Italy, pizza served in a restaurant is presented unsliced, and is eaten with the use of a knife and fork. In casual settings, however, it is typically cut into slices to be eaten while held in the hand. Pizza is also sold in grocery stores in a variety of forms, including frozen or as kits for self-assembly. Store-bought pizzas are then cooked using a home oven.\nIn 2017, the world pizza market was US$128 billion; in the US, it was $44 billion spread over 76,000 pizzerias. Overall, 13% of the US population aged two years and over consumed pizza on any given day. Furthermore, pizza is the most eaten food in the world after rice, followed by pasta.\nEtymology.\nThe oldest recorded usage of the word \"pizza\" is thought to be from May 997CE, appearing in the \"Codex diplomaticus Caietanus\", a notarial Latin document from the town of Gaeta, then still part of the Byzantine Empire. The text states that a tenant of certain property is to give the bishop of Gaeta \"duodecim pizze\" (lit.\u2009'twelve pizzas'), a pork shoulder and kidney annually on Christmas Day, and twelve pizzas and a couple of chickens annually on Easter Sunday.\nSuggested etymologies include:\nA small pizza is sometimes called \"pizzetta\". A person who makes pizza is known as a \"pizzaiolo\".\nThe word \"pizza\" was borrowed from Italian into English in the 1930s; before it became well known, pizza was called \"tomato pie\" by English speakers. Some regional pizza variations still use the name tomato pie.\nHistory.\nRecords of pizza-like foods can be found throughout ancient history. In the 6th century BC, the Persian soldiers of the Achaemenid Empire during the rule of Darius the Great baked flatbreads with cheese and dates on top of their battle shields and the ancient Greeks supplemented their bread with oils, herbs, and cheese. An early reference to a pizza-like food occurs in the \"Aeneid\", when Celaeno, queen of the Harpies, foretells that the Trojans would not find peace until they are forced by hunger to eat their tables (Book III). In Book VII, Aeneas and his men are served a meal that includes round cakes (such as pita bread) topped with cooked vegetables. When they eat the bread, they realize that these are the \"tables\" prophesied by Celaeno. In 2023, archeologists discovered a fresco in Pompeii appearing to depict a pizza-like dish among other foodstuffs and staples on a silver platter. Italy's culture minister said it \"may be a distant ancestor of the modern dish\". The first mention of the word \"pizza\" seemingly comes from a notarial document written in Latin and dating to 997CE from Gaeta, demanding a payment of \"twelve pizzas, a pork shoulder, and a pork kidney on Christmas Day, and 12 pizzas and a couple of chickens on Easter Day\".\nModern pizza evolved from similar flatbread dishes in Naples, Italy, in the 18th or early 19th century. Before that time, flatbread was often topped with ingredients such as garlic, salt, lard, and cheese. It is uncertain when tomatoes were first added and there are many conflicting claims, although it certainly could not have been before the 16th century and the Columbian Exchange. Pizza was sold from open-air stands and out of pizza bakeries until about 1830, when pizzerias in Naples started to have \"stanze\" with tables where clients could sit and eat their pizzas on the spot.\nA popular legend holds that the archetypal pizza, pizza Margherita, was invented in 1889, when the Royal Palace of Capodimonte commissioned the Neapolitan \"pizzaiolo\" ('pizza maker') Raffaele Esposito to create a pizza in honor of the visiting Queen Margherita. Of the three different pizzas he created, the queen strongly preferred a pizza swathed in the colors of the Italian flag\u2014red (tomato), white (mozzarella), and green (basil). Supposedly, this type of pizza was then named after the queen, with an official letter of recognition from the queen's \"head of service\" remaining to this day on display in Esposito's shop, now called the Pizzeria Brandi. Later research cast doubt on this legend, undermining the authenticity of the letter of recognition, pointing that no media of the period reported about the supposed visit and that both the story and name Margherita were first promoted in the 1930s\u20131940s.\nPizza was taken to the United States by Italian immigrants in the late 19th century and first appeared in areas where they concentrated. The country's first pizzeria, Lombardi's, opened in New York City in 1905. Italian Americans migrating from East to West brought the dish with them, and from there, the American version was exported to the rest of the world.\nThe Associazione Verace Pizza Napoletana (lit.\u2009'True Neapolitan Pizza Association') is a non-profit organization founded in 1984 with headquarters in Naples that aims to promote traditional Neapolitan pizza. In 2009, upon Italy's request, Neapolitan pizza was registered with the European Union as a traditional speciality guaranteed (TSG) dish, and in 2017 the art of its making was included on UNESCO's list of intangible cultural heritage.\nPreparation.\nPizza is sold fresh or frozen, whole or in portion-size slices. Methods have been developed to overcome challenges such as preventing the sauce from combining with the dough, and producing a crust that can be frozen and reheated without becoming rigid. There are frozen pizzas with raw ingredients and self-rising crusts.\nIn the US, another form of pizza is available from take and bake pizzerias. This pizza is assembled in the store, then sold unbaked to customers to bake in their own ovens. Some grocery stores sell fresh dough along with sauce and basic ingredients, to assemble at home before baking in an oven.\nBaking.\nIn restaurants, pizza can be baked in an oven with fire bricks above the heat source, an electric deck oven, a conveyor belt oven, or in traditional style in a wood or coal-fired brick oven. The pizza is slid into the oven on a long paddle, called \"peel\", and baked directly on hot bricks, a screen (a round metal grate, typically aluminum), or whatever the oven surface is. Before use, a peel is typically sprinkled with cornmeal to allow the pizza to easily slide on and off it. When made at home, a pizza can be baked on a pizza stone in a regular oven to reproduce some of the heating effect of a brick oven. Cooking directly on a metal surface results in too rapid heat transfer to the crust, burning it. Some home chefs use a wood-fired pizza oven, usually installed outdoors. As in restaurants, these are often dome-shaped, as pizza ovens have been for centuries, in order to achieve even heat distribution. Another variation is grilled pizza, in which the pizza is baked directly on a barbecue grill. Some types, such as Sicilian pizza, are baked in a pan rather than directly on the bricks of the pizza oven.\nMost restaurants use standard and purpose-built pizza preparation tables to assemble their pizzas. Mass production of pizza by chains can be completely automated.\nCrust.\nThe bottom of the pizza, called the \"crust\", may vary widely according to style\u2014thin as in a typical hand-tossed Neapolitan pizza or thick as in a deep-dish Chicago-style. It is traditionally plain, but may also be seasoned with garlic or herbs, or stuffed with cheese. The outer edge of the pizza is sometimes referred to as the \"cornicione\". Some pizza dough contains sugar, to help its yeast rise and enhance browning of the crust.\nCheese.\nMozzarella is commonly used on pizza, with the buffalo mozzarella produced in the surroundings of Naples. Other cheeses are also used, particularly burrata, Gorgonzola, provolone, \"pecorino romano\", ricotta, and \"scamorza\". Less expensive processed cheeses or cheese analogues have been developed for mass-market pizzas to produce desirable qualities such as browning, melting, stretchiness, consistent fat and moisture content, and stable shelf life. This quest to create the ideal and economical pizza cheese has involved many studies and experiments analyzing the impact of vegetable oil, manufacturing and culture processes, denatured whey proteins, and other changes in manufacture. In 1997, it was estimated that annual production of pizza cheese was in the US and in Europe.\nVarieties and styles.\nA great number of pizza varieties exist, defined by the choice of toppings and sometimes also crust. There are also several styles of pizza, defined by their preparation method. The following lists feature only the notable ones.\nBy region of origin.\nItaly.\nAuthentic Neapolitan pizza (Italian: \"pizza napoletana\") is made with San Marzano tomatoes, grown on the volcanic plains south of Mount Vesuvius, and either \"mozzarella di bufala campana\", made with milk from water buffalo raised in the marshlands of Campania and Lazio, or \"fior di latte\". Buffalo mozzarella is protected with its own European protected designation of origin (PDO). Other traditional pizzas include pizza marinara, supposedly the most ancient tomato-topped pizza, and pizza capricciosa, which is prepared with mozzarella cheese, baked ham, mushroom, artichoke, and tomato.\nA popular variant of pizza in Italy is Sicilian pizza, a thick-crust or deep-dish pizza originating during the 17th century in Sicily: it is essentially a focaccia that is typically topped with tomato sauce and other ingredients. Until the 1860s, Sicilian pizza was the type of pizza usually consumed in Sicily, especially in the Western portion of the island. Other variations of pizzas are also found in other regions of Italy, for example \"pizza al padellino\" or \"pizza al tegamino\", a small-sized, thick-crust, deep-dish pizza typically served in Turin, Piedmont.\nUnited States.\nThe first pizzeria in the US was opened in New York City's Little Italy in 1905. Common toppings for pizza in the United States include anchovies, ground beef, chicken, ham, mushrooms, olives, onions, peppers, pepperoni, pineapple, salami, sausage, spinach, steak, and tomatoes. A pizza with no toppings is called a \"cheese pizza\" or a \"plain pizza\". Distinct regional types developed in the 20th century, including Buffalo, California, Chicago, Detroit, Greek, New Haven, New York, and St. Louis styles. These regional variations include deep-dish, stuffed, pockets, turnovers, rolled, and pizza-on-a-stick, each with seemingly limitless combinations of sauce and toppings.\nThirteen percent of the United States population consumes pizza on any given day. Pizza chains such as Domino's Pizza, Pizza Hut, and Papa John's, pizzas from take and bake pizzerias, and chilled or frozen pizzas from supermarkets make pizza readily available nationwide.\nArgentina.\nArgentine pizza is a mainstay of the country's cuisine, especially of its capital Buenos Aires, where it is regarded as a cultural heritage and icon of the city. Argentina is the country with the most pizzerias per inhabitant in the world and, although they are consumed throughout the country, the highest concentration of pizzerias and customers is Buenos Aires, the city with the highest consumption of pizzas in the world (estimated in 2015 to be 14 million per year). As such, the city has been considered as one of the world capitals of pizza. The dish was introduced to Buenos Aires in the late 19th century with the massive Italian immigration, as part of a broader great European immigration wave to the country. Thus, around the same time that the iconic pizza Margherita was being invented in Italy, pizza were already being cooked in the Argentine capital. The impoverished Italian immigrants that arrived to the city transformed the originally modest dish into a much more hefty meal, motivated by the abundance of food in Argentina. In the 1930s, pizza was cemented as a cultural icon in Buenos Aires, with the new pizzerias becoming a central space for sociability for the working class people who flocked to the city.\nThe most characteristic style of Argentine pizza\u2014which almost all the classic pizzerias in Buenos Aires specialize in\u2014is the so-called \"pizza de molde\" (Spanish for 'pizza in the pan'), characterized by having a \"thick, spongy base and elevated bready crust\". This style, which today is identified as the typical style of Argentine pizza\u2014characterized by a thick crust and a large amount of cheese\u2014arose when impoverished Italian immigrants found a greater abundance of food in then-prosperous Argentina, which motivated them to transform the originally modest dish into a much more hefty meal suitable for a main course. The name \"pizza de molde\" emerged because there were no pizza ovens in the city, so bakers resorted to baking them in pans. Since they used bakery plates, Argentine pizzas were initially square or rectangular, a format associated with the 1920s that is still maintained in some classic pizzerias, especially for vegetable pizzas, \"fugazzetas\" or \"fugazzas\".\nOther styles of Argentine pizza include the iconic \"fugazza\" and its derivative \"fugazzeta\" or \"fugazza con queso\" (a terminology that varies depending on the pizzeria), or the \"pizza de cancha\" or \"canchera\" (a cheese-less variant). Most pizza menus include standard flavor combinations, including the traditional plain mozzarella, nicknamed \"\"muza\" or \"musa\"; the \"napolitana\" or \"napo\"\", with \"cheese, sliced tomatoes, garlic, dried oregano and a few green olives\", not to be confused with Neapolitan pizza; \"calabresa\", with slices of \"longaniza\"; \"jamon y morrones\", with sliced ham and roasted bell peppers; as well as versions with provolone, with anchovies, with hearts of palm, or with chopped hard boiled egg. A typical custom that is unique to Buenos Aires is to accompany pizza with \"fain\u00e1\", a pancake made from chickpea flour.\nDessert pizza.\nThe terms \"dessert pizza\" and \"sweet pizza\" are used for a variety of dishes resembling a pizza, including chocolate pizza and fruit pizza. Some are based on a traditional yeast dough pizza base, while others have a cookie-like base and resemble a traditional pizza solely in having a flat round shape with a distinct base and topping. Some pizza restaurants offer dessert pizzas.\nNutrition.\nMany mass-produced pizzas by American pizza chains have been criticized as having an unhealthy balance of ingredients. Pizza can be high in salt and fat, and is high in calories. The USDA reports an average sodium content of 5,100\u00a0mg per pizza in fast food chains.\nSee also.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24772", "revid": "8855946", "url": "https://en.wikipedia.org/wiki?curid=24772", "title": "Phase modulation", "text": "Electronic method of transmitting information with a carrier wave\nPhase modulation (PM) is a signal modulation method for conditioning communication signals for transmission. It encodes a message signal as variations in the instantaneous phase of a carrier wave. Phase modulation is one of the two principal forms of angle modulation, together with frequency modulation.\nIn phase modulation, the instantaneous amplitude of the baseband signal modifies the phase of the carrier signal keeping its amplitude and frequency constant. The phase of a carrier signal is modulated to follow the changing signal level (amplitude) of the message signal. The peak amplitude and the frequency of the carrier signal are maintained constant, but as the amplitude of the message signal changes, the phase of the carrier changes correspondingly.\nPhase modulation is an integral part of many digital transmission coding schemes that underlie a wide range of technologies like Wi-Fi, GSM and satellite television. However, it is not widely used for transmitting analog audio signals via radio waves, because of the relative complexity needed in the receiver, for no added benefit with audio signals. It is also used for signal and waveform generation in digital synthesizers, such as the Yamaha DX7, to implement FM synthesis. A related type of sound synthesis called phase distortion is used in the Casio CZ synthesizers.\nFoundation.\nIn general form, an analog modulation process of a sinusoidal carrier wave may be described by the following equation:\nformula_1.\n\"A(t)\" represents the time-varying amplitude of the sinusoidal carrier wave and the cosine-term is the carrier at its angular frequency formula_2, and the instantaneous phase deviation formula_3. This description directly provides the two major groups of modulation, amplitude modulation and angle modulation. In amplitude modulation, the angle term is held constant, while in angle modulation the term \"A(t)\" is constant and the second term of the equation has a functional relationship to the modulating message signal.\nThe functional form of the cosine term, which contains the expression of the instantaneous phase formula_4 as its argument, provides the distinction of the two types of angle modulation, frequency modulation (FM) and phase modulation (PM).\nIn FM the message signal causes a functional variation of the carrier frequency. These variations are controlled by both the frequency and the amplitude of the modulating wave.\nIn phase modulation, the instantaneous phase deviation formula_3 (phase angle) of the carrier is controlled by the modulating waveform, such that the principal frequency remains constant.\nIn principle, the modulating signal in both frequency and phase modulation may either be analog in nature, or it may be digital.\nThe mathematics of the spectral behaviour reveals that there are two regions of particular interest:\nModulation index.\nAs with other modulation indices, this quantity indicates by how much the modulated variable varies around its unmodulated level. It relates to the variations in the phase of the carrier signal:\n formula_6\nwhere formula_7 is the peak phase deviation. Compare to the modulation index for frequency modulation.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24774", "revid": "46230917", "url": "https://en.wikipedia.org/wiki?curid=24774", "title": "Phosphodiesterase inhibitor", "text": "Drug\nA phosphodiesterase inhibitor is a drug that blocks one or more of the five subtypes of the enzyme phosphodiesterase (PDE), thereby preventing the inactivation of the intracellular second messengers, cyclic adenosine monophosphate (cAMP) and cyclic guanosine monophosphate (cGMP) by the respective PDE subtype(s). The ubiquitous presence of this enzyme means that non-specific inhibitors have a wide range of actions, with those in the heart and lungs being some of the first to find therapeutic use.\nHistory.\nThe different forms or subtypes of phosphodiesterase were initially isolated from rat brains in the early 1970s and were soon afterward shown to be selectively inhibited in the brain and in other tissues by a variety of drugs. The potential for selective phosphodiesterase inhibitors as therapeutic agents was predicted as early as 1977 by Weiss and Hait. This prediction meanwhile has proved to be true in a variety of fields.\nClassification.\nNonselective PDE inhibitors.\nMethylated xanthines and derivatives:\nMethylated xanthines act as both\nBut different analogues show varying potency at the numerous subtypes, and a wide range of synthetic xanthine derivatives (some nonmethylated) have been developed in the search for compounds with greater selectivity for phosphodiesterase enzyme or adenosine receptor subtypes.\nPDE3 selective inhibitors.\nPDE3 is sometimes referred to as cGMP-inhibited phosphodiesterase.\nPDE4 selective inhibitors.\nPDE4 is the major cAMP-metabolizing enzyme found in inflammatory and immune cells. PDE4 inhibitors have proven potential as anti-inflammatory drugs, especially in inflammatory pulmonary diseases such as asthma, COPD, and rhinitis. They suppress the release of cytokines and other inflammatory signals, and inhibit the production of reactive oxygen species. PDE4 inhibitors may have antidepressive effects and have also been proposed for use as antipsychotics.\nOn October 26, 2009, the University of Pennsylvania reported that researchers at their institution had discovered a link between elevated levels of PDE4 (and therefore decreased levels of cAMP) in sleep deprived mice. Treatment with a PDE4 inhibitor raised the deficient cAMP levels and restored some functionality to hippocampus-based memory functions.\nPDE7 selective inhibitors.\nRecent studies have shown quinazoline type PDE7 inhibitor to be potent anti-inflammatory and neuroprotective agents.\nPDE9 selective inhibitors.\nParaxanthine, the main metabolite of caffeine (84% in humans), is another cGMP-specific phosphodiesterase inhibitor which inhibits PDE9, a cGMP preferring phosphodiesterase. PDE9 is expressed as high as PDE5 in the corpus cavernosum.\nPDE10 selective inhibitors.\nPapaverine, an opium alkaloid, has been reported to act as a PDE10 inhibitor. \nPDE10A is almost exclusively expressed in the striatum and subsequent increase in cAMP and cGMP after PDE10A inhibition (e.g. by papaverine) is \"a novel therapeutic avenue in the discovery of antipsychotics\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24775", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=24775", "title": "P.s.i.", "text": ""}
{"id": "24776", "revid": "635492", "url": "https://en.wikipedia.org/wiki?curid=24776", "title": "Piston", "text": "Machine component used to compress or contain expanding fluids in a cylinder\nA piston is a component of reciprocating engines, reciprocating pumps, gas compressors, hydraulic cylinders and pneumatic cylinders, among other similar mechanisms. It is the moving component that is contained by a cylinder and is made gas-tight by piston rings. In an engine, its purpose is to transfer force from expanding gas in the cylinder to the crankshaft via a piston rod and/or connecting rod. In a pump, the function is reversed and force is transferred from the crankshaft to the piston for the purpose of compressing or ejecting the fluid in the cylinder. In some engines, the piston also acts as a valve by covering and uncovering ports in the cylinder.\nPiston engines.\nInternal combustion engines.\nAn internal combustion engine is acted upon by the pressure of the expanding combustion gases in the combustion chamber space at so the top of the cylinder. This force then acts downwards through the connecting rod and onto the crankshaft. The connecting rod is attached to the piston by a swivelling gudgeon pin (US: wrist pin). This pin is mounted within the piston: unlike the steam engine, there is no piston rod or crosshead (except big two stroke engines).\nThe typical piston design is on the picture. This type of piston is widely used in car diesel engines. According to purpose, supercharging level and working conditions of engines the shape and proportions can be changed.\nHigh-power diesel engines work in difficult conditions. Maximum pressure in the combustion chamber can reach 20 MPa and the maximum temperature of some piston surfaces can exceed 450\u00a0\u00b0C. It is possible to improve piston cooling by creating a special cooling cavity. Injector supplies this cooling cavity \u00abA\u00bb with oil through oil supply channel \u00abB\u00bb. For better temperature reduction construction should be carefully calculated and analysed. Oil flow in the cooling cavity should be not less than 80% of the oil flow through the injector.\nThe pin itself is of hardened steel and is fixed in the piston, but free to move in the connecting rod. A few designs use a 'fully floating' design that is loose in both components. All pins must be prevented from moving sideways and the ends of the pin digging into the cylinder wall, usually by circlips.\nGas sealing is achieved by the use of piston rings. These are a number of narrow iron rings, fitted loosely into grooves in the piston, just below the crown. The rings are split at a point in the rim, allowing them to press against the cylinder with a light spring pressure. Two types of ring are used: the upper rings have solid faces and provide gas sealing; lower rings have narrow edges and a U-shaped profile, to act as oil scrapers. There are many proprietary and detail design features associated with piston rings.\nPistons are usually cast or forged from aluminium alloys. For better strength and fatigue life, some racing pistons may be forged instead. Billet pistons are also used in racing engines because they do not rely on the size and architecture of available forgings, allowing for last-minute design changes. Although not commonly visible to the naked eye, pistons themselves are designed with a certain level of ovality and profile taper, meaning they are not perfectly round, and their diameter is larger near the bottom of the skirt than at the crown.\nEarly pistons were of cast iron, but there were obvious benefits for engine balancing if a lighter alloy could be used. To produce pistons that could survive engine combustion temperatures, it was necessary to develop new alloys such as Y alloy and Hiduminium, specifically for use as pistons.\nA few early gas engines had double-acting cylinders, but otherwise effectively all internal combustion engine pistons are single-acting. During World War II, the US submarine \"Pompano\" was fitted with a prototype of the infamously unreliable H.O.R. double-acting two-stroke diesel engine. Although compact, for use in a cramped submarine, this design of engine was not repeated.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons\nTrunk pistons.\nTrunk pistons are long relative to their diameter. They act both as a piston and cylindrical crosshead. As the connecting rod is angled for much of its rotation, there is also a side force that reacts along the side of the piston against the cylinder wall. A longer piston helps to support this.\nTrunk pistons have been a common design of piston since the early days of the reciprocating internal combustion engine. They were used for both petrol and diesel engines, although high speed engines have now adopted the lighter weight slipper piston.\nA characteristic of most trunk pistons, particularly for diesel engines, is that they have a groove for an oil ring below the gudgeon pin, in addition to the rings between the gudgeon pin and crown.\nThe name 'trunk piston' derives from the 'trunk engine', an early design of marine steam engine. To make these more compact, they avoided the steam engine's usual piston rod with separate crosshead and were instead the first engine design to place the gudgeon pin directly within the piston. Otherwise these trunk engine pistons bore little resemblance to the trunk piston; they were extremely large diameter and double-acting. Their 'trunk' was a narrow cylinder mounted in the centre of the piston.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons\nCrosshead pistons.\nLarge slow-speed Diesel engines may require additional support for the side forces on the piston. These engines typically use crosshead pistons. The main piston has a large piston rod extending downwards from the piston to what is effectively a second smaller-diameter piston. The main piston is responsible for gas sealing and carries the piston rings. The smaller piston is purely a mechanical guide. It runs within a small cylinder as a trunk guide and also carries the gudgeon pin.\nLubrication of the crosshead has advantages over the trunk piston as its lubricating oil is not subject to the heat of combustion: the oil is not contaminated by combustion soot particles, it does not break down owing to the heat and a thinner, less viscous oil may be used. The friction of both piston and crosshead may be only half of that for a trunk piston.\nBecause of the additional weight of these pistons, they are not used for high-speed engines.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons\nSlipper pistons.\nA slipper piston is a piston for a petrol engine that has been reduced in size and weight as much as possible. In the extreme case, they are reduced to the piston crown, support for the piston rings, and just enough of the piston skirt remaining to leave two lands so as to stop the piston rocking in the bore. The sides of the piston skirt around the gudgeon pin are reduced away from the cylinder wall. The purpose is mostly to reduce the reciprocating mass, thus making it easier to balance the engine and so permit high speeds. In racing applications, slipper piston skirts can be configured to yield extremely light weight while maintaining the rigidity and strength of a full skirt. Reduced inertia also improves mechanical efficiency of the engine: the forces required to accelerate and decelerate the reciprocating parts cause more piston friction with the cylinder wall than the fluid pressure on the piston head. A secondary benefit may be some reduction in friction with the cylinder wall, since the area of the skirt, which slides up and down in the cylinder is reduced by half. However, most friction is due to the piston rings, which are the parts which actually fit the tightest in the bore and the bearing surfaces of the wrist pin, and thus the benefit is reduced.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons\nDeflector pistons.\nDeflector pistons are used in two-stroke engines with crankcase compression, where the gas flow within the cylinder must be carefully directed in order to provide efficient scavenging. With cross scavenging, the transfer (inlet to the cylinder) and exhaust ports are on directly facing sides of the cylinder wall. To prevent the incoming mixture passing straight across from one port to the other, the piston has a raised rib on its crown. This is intended to deflect the incoming mixture upwards, around the combustion chamber.\nMuch effort, and many different designs of piston crown, went into developing improved scavenging. The crowns developed from a simple rib to a large asymmetric bulge, usually with a steep face on the inlet side and a gentle curve on the exhaust. Despite this, cross scavenging was never as effective as hoped. Most engines today use Schnuerle porting instead. This places a pair of transfer ports in the sides of the cylinder and encourages gas flow to rotate around a vertical axis, rather than a horizontal axis.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons\nRacing pistons.\nIn racing engines, piston strength and stiffness is typically much higher than that of a passenger car engine, while the weight is much less, to achieve the high engine RPM necessary in racing.\nHydraulic cylinders.\nHydraulic cylinders can be both single-acting or double-acting. A hydraulic actuator controls the movement of the piston back and/or forth. Guide rings guides the piston and rod and absorb the radial forces that act perpendicularly to the cylinder and prevent contact between sliding the metal parts.\nSteam engines.\nSteam engines are usually double-acting (i.e. steam pressure acts alternately on each side of the piston) and the admission and release of steam is controlled by slide valves, piston valves or poppet valves. Consequently, steam engine pistons are nearly always comparatively thin discs: their diameter is several times their thickness. (One exception is the trunk engine piston, shaped more like those in a modern internal-combustion engine.) Another factor is that since almost all steam engines use crossheads to translate the force to the drive rod, there are few lateral forces acting to try and \"rock\" the piston, so a cylinder-shaped piston skirt isn't necessary.\nPumps.\nPiston pumps can be used to move liquids or compress gases.\nAir cannons.\nThere are two special type of pistons used in air cannons: close tolerance pistons and double pistons. In close tolerance pistons O-rings serve as a valve, but O-rings are not used in double piston types.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24778", "revid": "50252119", "url": "https://en.wikipedia.org/wiki?curid=24778", "title": "PK", "text": "PK or pk may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "24779", "revid": "6675779", "url": "https://en.wikipedia.org/wiki?curid=24779", "title": "Psi", "text": "Psi, PSI or \u03a8 may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
