{"id": "29469", "revid": "62058", "url": "https://en.wikipedia.org/wiki?curid=29469", "title": "Sapphire", "text": "Gem variety of corundum\nSapphire is a precious gemstone, a variety of the mineral corundum, consisting of aluminium oxide (\u03b1-Al2O3) with trace amounts of elements such as iron, titanium, cobalt, lead, chromium, vanadium, magnesium, boron, and silicon. The name \"sapphire\" is derived from the Latin word \"sapphirus\", itself from the Greek word (), which referred to lapis lazuli. It is typically blue, but natural \"fancy\" sapphires also occur in yellow, purple, orange, and green colors; \"parti sapphires\" show two or more colors. Red corundum stones also occur, but are called rubies rather than sapphires. Pink-colored corundum may be classified either as ruby or sapphire depending on the locale. Commonly, natural sapphires are cut and polished into gemstones and worn in jewelry. They also may be created synthetically in laboratories for industrial or decorative purposes in large crystal boules. Because of the remarkable hardness of sapphires\u00a0\u2013 9 on the Mohs scale (the third-hardest mineral, after diamond at 10 and moissanite at 9.5)\u00a0\u2013 sapphires are also used in some non-ornamental applications, such as infrared optical components, high-durability windows, wristwatch crystals and movement bearings, and very thin electronic wafers, which are used as the insulating substrates of special-purpose solid-state electronics such as integrated circuits and GaN-based blue LEDs. It occurs in association with ruby, zircon, biotite, muscovite, calcite, dravite and quartz.\nNatural sapphires.\nSapphire is one of the two gem-varieties of corundum, the other being ruby (defined as corundum in a shade of red). Although blue is the best-known sapphire color, it occurs in other colors, including gray and black, and also can be colorless. A pinkish orange variety of sapphire is called padparadscha.\nSignificant sapphire deposits are found in Australia, Afghanistan, Cambodia, Cameroon, China (Shandong), Colombia, Ethiopia, India (Jammu and Kashmir), Kenya, Laos, Madagascar, Malawi, Mozambique, Myanmar (Burma), Nigeria, Rwanda, Sri Lanka, Tanzania, Thailand, United States (Montana) and Vietnam. Sapphire and rubies are often found in the same geographical settings, but they generally have different geological formations. For example, both ruby and sapphire are found in Myanmar's Mogok Stone Tract, but the rubies form in marble, while the sapphire forms in granitic pegmatites or corundum syenites.\nEvery sapphire mine produces a wide range of quality, and origin is not a guarantee of quality. For sapphire, Jammu and Kashmir receives the highest premium, although Burma, Sri Lanka, and Madagascar also produce large quantities of fine quality gems.\nThe cost of natural sapphires varies depending on their color, clarity, size, cut, and overall quality. Sapphires that are completely untreated are worth far more than those that have been treated. Geographical origin also has a major impact on price. For most gems of one carat or more, an independent report from a respected laboratory such as GIA, Lotus Gemology, or SSEF, is often required by buyers before they will make a purchase.\nColors.\nSapphires in colors other than blue are called \"fancy\" sapphires. \"Parti sapphire\" is used for multicolor stones with zoning of different colors (hues), but not different shades.\nFancy sapphires are found in yellow, orange, green, brown, purple, violet, and practically any other hue.\nGemstone color can be described in terms of hue, saturation, and tone. Hue is commonly understood as the \"color\" of the gemstone. Saturation refers to the vividness or brightness of the hue, and tone is the lightness to darkness of the hue.\nBlue sapphire.\nBlue sapphire exists in various mixtures of its primary (blue) and secondary hues, various tonal levels (shades) and at various levels of saturation (vividness).\nBlue sapphires are evaluated based upon the purity of their blue hue. Violet and green are the most common secondary hues found in blue sapphires. The highest prices are paid for gems that are pure blue and of vivid saturation. Gems that are of lower saturation, or are too dark or too light in tone are of less value. However, color preferences are a personal taste.\nThe Logan sapphire in the National Museum of Natural History, in Washington, D.C., is one of the largest faceted gem-quality blue sapphires in existence.\nParti sapphires.\nParticolored sapphires (or bi-color sapphires) are those stones that exhibit two or more colors within a single stone. The desirability of particolored or bi-color sapphires is usually judged based on the zoning or location of their colors, the colors' saturation, and the contrast of their colors. Australia is the largest source of particolored sapphires; they are not commonly used in mainstream jewelry and remain relatively unknown. Particolored sapphires cannot be created synthetically and only occur naturally.\nPink sapphires.\nPink sapphires occur in shades from light to dark pink, and deepen in color as the quantity of chromium increases. The deeper the pink color, the higher their monetary value. In the United States, a minimum color saturation must be met to be called a ruby, otherwise the stone is referred to as a \"pink sapphire\".\nPadparadscha.\n\"Padparadscha\" is a delicate, light to medium toned, pink-orange to orange-pink hued corundum, originally found in Sri Lanka, but also found in deposits in Vietnam and parts of East Africa. Padparadscha sapphires are rare; the rarest of all is the totally natural variety, with no sign of artificial treatment.\nThe name is derived from the Sanskrit \"padma ranga\" (lit.\u2009'lotus color'), a color akin to the lotus flower (\"Nelumbo nucifera\").\nAmong the fancy (non-blue) sapphires, natural padparadscha fetch the highest prices. Since 2001, more sapphires of this color have appeared on the market as a result of artificial lattice diffusion of beryllium.\nStar sapphire.\nA \"star sapphire\" is a type of sapphire that exhibits a star-like phenomenon known as asterism; red stones are known as \"star rubies\". Star sapphires contain intersecting needle-like inclusions following the underlying crystal structure that causes the appearance of a six-rayed \"star\"-shaped pattern when viewed with a single overhead light source. The inclusion is often the mineral rutile, a mineral composed primarily of titanium dioxide. The stones are cut \"en cabochon\", typically with the center of the star near the top of the dome. Occasionally, twelve-rayed stars are found, typically because two different sets of inclusions are found within the same stone, such as a combination of fine needles of rutile with small platelets of hematite; the first results in a whitish star and the second results in a golden-colored star. During crystallization, the two types of inclusions become preferentially oriented in different directions within the crystal, thereby forming two six-rayed stars that are superimposed upon each other to form a twelve-rayed star. Misshapen stars or 12-rayed stars may also form as a result of twinning.\nThe inclusions can alternatively produce a cat's eye effect if the girdle plane of the cabochon is oriented parallel to the crystal's c-axis rather than perpendicular to it. To get a cat's eye, the planes of exsolved inclusions must be extremely uniform and tightly packed. If the dome is oriented in between these two directions, an off-center star will be visible, offset away from the high point of the dome.\nAt 1404.49 carats, The Star of Adam is the largest known blue star sapphire. The gem was mined in the city of Ratnapura, southern Sri Lanka. The Black Star of Queensland, the second largest star sapphire in the world, weighs 733 carats. The Star of India mined in Sri Lanka and weighing 563.4 carats is thought to be the third-largest star sapphire, and is currently on display at the American Museum of Natural History in New York City. The 182-carat Star of Bombay, mined in Sri Lanka and located in the National Museum of Natural History in Washington, D.C., is another example of a large blue star sapphire. The value of a star sapphire depends not only on the weight of the stone, but also the body color, visibility, and intensity of the asterism. The color of the stone has more impact on the value than the visibility of the star. Since more transparent stones tend to have better colors, the most expensive star stones are semi-transparent \"glass body\" stones with vivid colors.\nOn 28 July 2021, the world's largest cluster of star sapphires, weighing , was unearthed from Ratnapura, Sri Lanka. This star sapphire cluster was named \"Serendipity Sapphire\".\nColor-change sapphire.\nA rare variety of natural sapphire, known as color-change sapphire, exhibits different colors in different light. Color change sapphires are blue in outdoor light and purple under incandescent indoor light, or green to gray-green in daylight and pink to reddish-violet in incandescent light. Color-change sapphires come from a variety of locations, including Madagascar, Myanmar, Sri Lanka and Tanzania. Two types exist. The first features the chromium chromophore that creates the red color of ruby, combined with the iron + titanium chromophore that produces the blue color in sapphire. A rarer type, which comes from the Mogok area of Myanmar, features a vanadium chromophore, the same as is present in Verneuil synthetic color-change sapphire.\nVirtually all gemstones that show the \"alexandrite effect\" (color change or 'metamerism') show similar absorption/transmission features in the visible spectrum. This is an absorption band in the yellow (~590\u00a0nm), along with valleys of transmission in the blue-green and red. Thus the color one sees depends on the spectral composition of the light source. Daylight is relatively balanced in its spectral power distribution (SPD) and since the human eye is most sensitive to green light, the balance is tipped to the green side. However incandescent light (including candle light) is heavily tilted to the red end of the spectrum, thus tipping the balance to red.\nColor-change sapphires colored by the Cr + Fe/Ti chromophores generally change from blue or violet-blue to violet or purple. Those colored by the V chromophore can show a more pronounced change, moving from blue-green to purple.\nCertain synthetic color-change sapphires have a similar color change to the natural gemstone alexandrite and they are sometimes marketed as \"alexandrium\" or \"synthetic alexandrite\". However, the latter term is a misnomer: synthetic color-change sapphires are, technically, not synthetic alexandrites but rather alexandrite \"simulants\". This is because genuine alexandrite is a variety of chrysoberyl: not sapphire, but an entirely different mineral from corundum.\nLarge rubies and sapphires.\nLarge rubies and sapphires of poor transparency are frequently used with suspect appraisals that vastly overstate their value. This was the case of the \"Life and Pride of America Star Sapphire\". Circa 1985, Roy Whetstine claimed to have bought the 1905-ct stone for $10 at the Tucson gem show, but a reporter discovered that L.A. Ward of Fallbrook, California, who appraised it at the price of $1200/ct, had appraised another stone of the exact same weight several years before Whetstine claimed to have found it.\nBangkok-based Lotus Gemology maintains an updated listing of world auction records of ruby, sapphire, and spinel. As of November 2019, no sapphire has ever sold at auction for more than $17,295,796.\nCause of color.\nRubies are corundum with a dominant red body color. This is generally caused by traces of chromium (Cr3+) substituting for the (Al3+) ion in the corundum structure. The color can be modified by both iron and trapped hole color centers.\nUnlike localized (\"intra-atomic\") absorption of light, which causes color for chromium and vanadium impurities, blue color in sapphires comes from intervalence charge transfer, which is the transfer of an electron from one transition-metal ion to another via the conduction or valence band. The iron can take the form Fe2+ or Fe3+, while titanium generally takes the form Ti4+. If Fe2+ and Ti4+ ions are substituted for Al3+, localized areas of charge imbalance are created. An electron transfer from Fe2+ and Ti4+ can cause a change in the valence state of both. Because of the valence change, there is a specific change in energy for the electron, and electromagnetic energy is absorbed. The wavelength of the energy absorbed corresponds to yellow light. When this light is subtracted from incident white light, the complementary color blue results. Sometimes when atomic spacing is different in different directions, there is resulting blue-green dichroism.\nPurple sapphires contain trace amounts of chromium and iron plus titanium and come in a variety of shades. Corundum that contains extremely low levels of chromophores is near colorless. Completely colorless corundum generally does not exist in nature. If trace amounts of iron are present, a very pale yellow to green color may be seen. However, if both titanium and iron impurities are present together, and in the correct valence states, the result is a blue color.\nIntervalence charge transfer is a process that produces a strong colored appearance at a low percentage of impurity. While at least 1% chromium must be present in corundum before the deep red ruby color is seen, sapphire blue is apparent with the presence of only 0.01% of titanium and iron.\nColorless sapphires, which are uncommon in nature, were once used as diamond substitutes in jewelry, and are presently used as accent stones.\nThe most complete description of the causes of color in corundum extant can be found in Chapter\u00a04 of \"Ruby &amp; Sapphire: A Gemologist's Guide\" (chapter authored by John Emmett, Emily Dubinsky and Richard Hughes).\nMining.\nSapphires are mined from alluvial deposits or from primary underground workings. Commercial mining locations for sapphire and ruby include (but are not limited to) the following countries: Afghanistan, Australia, Myanmar/Burma, Cambodia, China, Colombia, India, Kenya, Laos, Madagascar, Malawi, Nepal, Nigeria, Pakistan, Sri Lanka, Tajikistan, Tanzania, Thailand, United States, and Vietnam. Sapphires from different geographic locations may have different appearances or chemical-impurity concentrations, and tend to contain different types of microscopic inclusions. Because of this, sapphires can be divided into three broad categories: classic metamorphic, non-classic metamorphic or magmatic, and classic magmatic.\nSapphires from certain locations, or of certain categories, may be more commercially appealing than others, particularly classic metamorphic sapphires from Kashmir, Burma, or Sri Lanka that have not been subjected to heat-treatment.\nThe Logan sapphire, the Star of India, The Star of Adam and the Star of Bombay originate from Sri Lankan mines. Madagascar is the world leader in sapphire production (as of 2007) specifically its deposits in and around the town of Ilakaka. Prior to the opening of the Ilakaka mines, Australia was the largest producer of sapphires (such as in 1987). In 1991 a new source of sapphires was discovered in Andranondambo, southern Madagascar. The exploitation started in 1993, but was practically abandoned just a few years later because of the difficulties in recovering sapphires in their bedrock.\nIn North America, sapphires have been mined mostly from deposits in Montana: facies along the Missouri River near Helena, Montana, Dry Cottonwood Creek near Deer Lodge, Montana, and Rock Creek near Philipsburg, Montana. Fine blue Yogo sapphires are found at Yogo Gulch west of Lewistown, Montana. A few gem-grade sapphires and rubies have also been found in the area of Franklin, North Carolina.\nThe sapphire deposits of Kashmir are well known in the gem industry, although their peak production took place in a relatively short period at the end of the nineteenth and early twentieth centuries. These deposits are located in the Paddar Valley of the Jammu region of Jammu and Kashmir in India. They have a superior vivid blue hue, coupled with a mysterious and almost sleepy quality, described by some gem enthusiasts as \u2018blue velvet\u201d. Kashmir-origin contributes meaningfully to the value of a sapphire, and most corundum of Kashmir origin can be readily identified by its characteristic silky appearance and exceptional hue. The unique blue appears lustrous under any kind of light, unlike non-Kashmir sapphires which may appear purplish or grayish in comparison. Sotheby's has been in the forefront overseeing record-breaking sales of Kashmir sapphires worldwide. In October 2014, Sotheby's Hong Kong achieved consecutive per-carat price records for Kashmir sapphires \u2013 first with the 12.00 carat Cartier sapphire ring at US$193,975 per carat, then with a 17.16 carat sapphire at US$236,404, and again in June 2015 when the per-carat auction record was set at US$240,205. At present, the world record price-per-carat for sapphire at auction is held by a sapphire from Kashmir in a ring, which sold in October 2015 for approximately US$242,000 per carat (HK$52,280,000 in total, including buyer's premium, or more than US$6.74 million).\nTreatments.\nSapphires can be treated by several methods to enhance and improve their clarity and color. It is common practice to heat natural sapphires to improve or enhance their appearance. This is done by heating the sapphires in furnaces to temperatures between for several hours, or even weeks at a time. Different atmospheres may be used. Upon heating, the stone becomes bluer in color, but loses some of the rutile inclusions (silk). When high temperatures (1400\u00a0\u00b0C+) are used, exsolved rutile silk is dissolved and it becomes clear under magnification. The titanium from the rutile enters solid solution and thus creates with iron the blue color. The inclusions in natural stones are easily seen with a jeweler's loupe. Evidence of sapphire and other gemstones being subjected to heating goes back at least to Roman times. Un-heated natural stones are somewhat rare and will often be sold accompanied by a certificate from an independent gemological laboratory attesting to \"no evidence of heat treatment\".\nYogo sapphires do not need heat treating because their cornflower blue color is attractive out of the ground; they are generally free of inclusions, and have high uniform clarity. When Intergem Limited began marketing the Yogo in the 1980s as the world's only guaranteed untreated sapphire, heat treatment was not commonly disclosed; by the late 1980s, heat treatment became a major issue. At that time, much of all the world's sapphires were being heated to enhance their natural color. Intergem's marketing of guaranteed untreated Yogos set them against many in the gem industry. This issue appeared as a front-page story in \"The Wall Street Journal\" on 29 August 1984 in an article by Bill Richards, \"Carats and Schticks: Sapphire Marketer Upsets The Gem Industry\". However, the biggest problem the Yogo mine faced was not competition from heated sapphires, but the fact that the Yogo stones could never produce quantities of sapphire above one carat after faceting. As a result, it has remained a niche product, with a market that largely exists in the US.\nLattice ('bulk') diffusion treatments are used to add impurities to the sapphire to enhance color. This process was originally developed and patented by Linde Air division of Union Carbide and involved diffusing titanium into synthetic sapphire to even out the blue color. It was later applied to natural sapphire. Today, titanium diffusion often uses a synthetic colorless sapphire base. The color layer created by titanium diffusion is extremely thin (less than 0.5\u00a0mm). Thus repolishing can and does produce slight to significant loss of color. Chromium diffusion has been attempted, but was abandoned due to the slow diffusion rates of chromium in corundum.\nIn the year 2000, beryllium diffused \"padparadscha\" colored sapphires entered the market. Typically beryllium is diffused into a sapphire under very high heat, just below the melting point of the sapphire. Initially (c.\u20092000) orange sapphires were created, although now the process has been advanced and many colors of sapphire are often treated with beryllium. Due to the small size of the beryllium ion, the color penetration is far greater than with titanium diffusion. In some cases, it may penetrate the entire stone. Beryllium-diffused orange sapphires may be difficult to detect, requiring advanced chemical analysis by gemological labs (e.g., G\u00fcbelin, SSEF, GIA, American Gemological Laboratories (AGL), and Lotus Gemology).\nAccording to United States Federal Trade Commission guidelines, disclosure is required of any mode of enhancement that has a significant effect on the gem's value.\nThere are several ways of treating sapphire. Heat-treatment in a reducing or oxidizing atmosphere (but without the use of any other added impurities) is commonly used to improve the color of sapphires, and this process is sometimes known as \"heating only\" in the gem trade. In contrast, however, heat treatment combined with the deliberate addition of certain specific impurities (e.g. beryllium, titanium, iron, chromium or nickel, which are absorbed into the crystal structure of the sapphire) is also commonly performed, and this process can be known as \"diffusion\" in the gem trade. However, despite what the terms \"heating only\" and \"diffusion\" might suggest, both of these categories of treatment actually involve diffusion processes.\nThe most complete description of corundum treatments extant can be found in Chapter 6 of \"Ruby &amp; Sapphire: A Gemologist's Guide\" (chapter authored by John Emmett, Richard Hughes and Troy R. Douthit).\nSynthetic sapphire.\nIn 1902, the French chemist Auguste Verneuil announced a process for producing synthetic ruby crystals. In the flame-fusion (Verneuil process), fine alumina powder is added to an oxyhydrogen flame, and this is directed downward against a ceramic pedestal. Following the successful synthesis of ruby, Verneuil focused his efforts on sapphire. Synthesis of blue sapphire came in 1909, after chemical analyses of sapphire suggested to Verneuil that iron and titanium were the cause of the blue color. Verneuil patented the process of producing synthetic blue sapphire in 1911.\nThe key to the process is that the alumina powder does not melt as it falls through the flame. Instead it forms a sinter cone on the pedestal. When the tip of that cone reaches the hottest part of the flame, the tip melts. Thus the crystal growth is started from a tiny point, ensuring minimal strain.\nNext, more oxygen is added to the flame, causing it to burn slightly hotter. This expands the growing crystal laterally. At the same time, the pedestal is lowered at the same rate that the crystal grows vertically. The alumina in the flame is slowly deposited, creating a teardrop-shaped \"boule\" of sapphire material. This step is continued until the desired size is reached, the flame is shut off and the crystal cools. The now elongated crystal contains a lot of strain due to the high thermal gradient between the flame and surrounding air. To release this strain, the now finger-shaped crystal will be tapped with a chisel to split it into two halves.\nDue to the vertical layered growth of the crystal and the curved upper growth surface (which starts from a drop), the crystals will display curved growth lines following the top surface of the boule. This is in contrast to natural corundum crystals, which feature angular growth lines expanding from a single point and following the planar crystal faces.\nDopants.\nChemical dopants can be added to create artificial versions of the ruby, and all the other natural colors of sapphire, and in addition, other colors never seen in geological samples. Artificial sapphire material is identical to natural sapphire, except it can be made without the flaws that are found in natural stones. The disadvantage of the Verneuil process is that the grown crystals have high internal strains. Many methods of manufacturing sapphire today are variations of the Czochralski process, which was invented in 1916 by Polish chemist Jan Czochralski. In this process, a tiny sapphire seed crystal is dipped into a crucible made of the precious metal iridium or molybdenum, containing molten alumina, and then slowly withdrawn upward at a rate of 1 to 100\u00a0mm per hour. The alumina crystallizes on the end, creating long carrot-shaped boules of large size up to 200\u00a0kg in mass. One popular variant of the Czochralski method is the Kyropoulos method which has the advantage of using all of the feedstock material such as aluminum oxide to create sapphire and crucibles do not have to be replaced. This is one of the main production methods for synthetic sapphire. However, the original Czochralski method can also be used.\nOther growth methods.\nSynthetic sapphire is also produced industrially from agglomerated aluminum oxide, sintered and fused (such as by hot isostatic pressing) in an inert atmosphere, yielding a transparent but slightly porous polycrystalline product. Another popular method is the Heat Exchanger Method (HEM), in which aluminum oxide is placed in a molybdenum crucible and heated until melting at 2200\u00b0C. It allows for very large crystals over 30 cm wide to be produced. The process takes place in a vacuum. A sapphire seed crystal sits at the bottom of the crucible and is kept from melting by heat exchange (cooling) with helium gas or liquid helium which is shielded from the vacuum. The furnace is kept at a temperature just above melting, but the heat exchanger is at a temperature just below melting. Then the heat exchanger temperature is lowered to start crystalization, and then the aluminum oxide is cooled over a period of at least 72 hours to 17 days to crystalize it into sapphire. The crucibles are single use, the process is similar to the Bridgman technique and the St\u00f6ber methods for crystal growth, and was used for iPhone screens. The crystal grows upward from the bottom of the crucible. Another method is the Edge-defined Film-fed Growth (EFG) method, very similar to the Czochralski method but the material passes through a die before cooling, which shapes the crystal. The crystal does not rotate. Chemical Vapor Deposition (CVD), gradient furnace or vertical bridgman processes can be used for sapphire crystal growth.\nIn 2003, the world's production of synthetic sapphire was 250 tons (1.25 billion carats), mostly by the United States and Russia. The availability of cheap synthetic sapphire unlocked many industrial uses for this unique material.\nApplications.\nEquipment windows.\nSynthetic sapphire\u2014also referred to as \"sapphire glass\"\u2014is commonly used for small windows, because it is both highly transparent to wavelengths of light between 150\u00a0nm (UV) and 5500\u00a0nm (IR) (the visible spectrum extends about 380\u00a0nm to 750\u00a0nm), and extraordinarily scratch-resistant.\nThe key benefits of sapphire windows are:\nSome sapphire-glass windows are made from pure sapphire boules that have been grown in a specific crystal orientation, typically along the optical axis, the \"c\"\u00a0axis, for minimum birefringence for the application.\nThe boules are sliced up into the desired window thickness and finally polished to the desired surface finish. Sapphire optical windows can be polished to a wide range of surface finishes due to its crystal structure and its hardness. The surface finishes of optical windows are normally called out by the scratch-dig specifications in accordance with the globally adopted MIL-O-13830 specification.\nSapphire windows are used in both high-pressure and vacuum chambers for spectroscopy, crystals for watches, and windows in grocery-store barcode scanners, since the material's exceptional hardness and toughness makes it very resistant to scratching.\nIn 2014 Apple consumed \"one-fourth of the world's supply of sapphire to cover the iPhone's camera lens and fingerprint reader\".\nSeveral attempts have been made to make sapphire screens for smartphones viable. Apple contracted GT Advanced Technologies, Inc. to manufacture sapphire screens for iPhones, but the venture failed, causing the bankruptcy of GTAT. The Kyocera Brigadier was the first production smartphone with a sapphire screen.\nSapphire is used for end windows on some high-powered laser tubes, as its wide-band transparency and thermal conductivity allow it to handle very high power densities in the infrared and UV spectrum without degrading due to heating.\nOne type of xenon arc lamp\u00a0\u2013 originally called the \"Cermax\" and now known generically as the \"ceramic-body xenon lamp\"\u00a0\u2013 uses sapphire crystal output windows that tolerate higher thermal loads and consequently can provide higher output powers than conventional Xe lamps with pure silica windows.\nSapphire window was used for the F-35 Lightning 2 Electro Optical Targeting System window, due to its high strength.\nAlong with zirconia and aluminum oxynitride, synthetic sapphire is used for shatter-resistant windows in armored vehicles and various military body armor suits, in association with composites.\nAs substrate for semiconducting circuits.\nThin sapphire wafers were the first successful use of an insulating substrate upon which to deposit silicon to make the integrated circuits known as silicon on sapphire or \"SOS\"; now other substrates can also be used for the class of circuits known more generally as silicon on insulator. Besides its excellent electrical insulating properties, sapphire has high thermal conductivity. CMOS chips on sapphire are especially useful for high-power radio-frequency (RF) applications such as those found in cellular telephones, public-safety band radios, and satellite communication systems. \"SOS\" also allows for the monolithic integration of both digital and analog circuitry all on one IC chip, and the construction of extremely low power circuits.\nIn one process, after single crystal sapphire boules are grown, they are core-drilled into cylindrical rods, and wafers are then sliced from these cores.\nWafers of single-crystal sapphire are also used in the semiconductor industry as substrates for the growth of devices based on gallium nitride (GaN). The use of sapphire significantly reduces the cost, because it has about one-seventh the cost of germanium. Gallium nitride on sapphire is commonly used in blue light-emitting diodes (LEDs).\nIn lasers.\nThe first laser was made in 1960 by Theodore Maiman with a rod of synthetic ruby. Titanium-sapphire lasers are popular due to their relatively rare capacity to be tuned to various wavelengths in the red and near-infrared region of the electromagnetic spectrum. They can also be easily mode-locked. In these lasers a synthetically produced sapphire crystal with chromium or titanium impurities is irradiated with intense light from a special lamp, or another laser, to create stimulated emission.\nIn endoprostheses.\nMonocrystalline sapphire is fairly biocompatible and the exceptionally low wear of sapphire\u2013metal pairs has led to the introduction (in Ukraine) of sapphire monocrystals for hip joint endoprostheses.\nNotable sapphires.\nExtensive tables listing over a hundred important and famous rubies and sapphires can be found in Chapter 10 of \"Ruby &amp; Sapphire: A Gemologist's Guide\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29471", "revid": "12517593", "url": "https://en.wikipedia.org/wiki?curid=29471", "title": "Slack voice", "text": "Type of pronunciation\nSlack voice (or lax voice) is the pronunciation of consonant or vowels with a glottal opening slightly wider than that occurring in modal voice. Such sounds are often referred to informally as lenis or half-voiced in the case of consonants. In some Chinese varieties, such as Wu, and in a few Austronesian languages, the 'intermediate' phonation of slack stops confuses listeners of languages without these distinctions, so that different transcription systems may use \u27e8p\u27e9 or \u27e8b\u27e9 for the same consonant. In Xhosa, slack-voiced consonants have usually been transcribed as breathy voice. Although the IPA has no dedicated diacritic for slack voice, the voiceless diacritic (the under-ring) may be used with a voiced consonant letter, though this convention is also used for partially voiced consonants in languages such as English.\nWu Chinese \"muddy\" consonants are slack voice word-initially, the primary effect of which is a slightly breathy quality of the following vowel.\nJavanese contrasts slack and stiff voiced bilabial, dental, retroflex, and velar stops.\nParauk contrasts slack voicing in its vowels. The contrast is between \"slightly stiff\" and \"slightly breathy\" vowels; the first are between modal and stiff voice, while the latter are captured by slack voice.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29472", "revid": "1301043141", "url": "https://en.wikipedia.org/wiki?curid=29472", "title": "SADC", "text": "SADC may refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "29473", "revid": "169132", "url": "https://en.wikipedia.org/wiki?curid=29473", "title": "Salvation", "text": "Concept in religion and theology\nSalvation (from Latin: \"salvatio\", from \"salva\", 'safe, saved') is the state of being saved or protected from harm or a dire situation. In religion and theology, \"salvation\" generally refers to the deliverance of the soul from sin and its consequences. The academic study of salvation is called \"soteriology\".\nMeaning.\nIn Abrahamic religions and theology, \"salvation\" is the saving of the soul from sin and its consequences. It may also be called \"deliverance\" or \"redemption\" from sin and its effects. Depending on the religion or even denomination, salvation is considered to be caused either only by the grace of God (i.e. unmerited and unearned), or by faith, good deeds (works), or a combination thereof. Religions often emphasize that man is a sinner by nature and that the penalty of sin is death (physical death, spiritual death: spiritual separation from God and eternal punishment in hell).\nJudaism.\nIn contemporary Judaism, redemption (Hebrew: &lt;templatestyles src=\"Script/styles_hebrew.css\" /&gt;\u05d2\u05b0\u05bc\u05d0\u05d5\u05bc\u05dc\u05b8\u05bc\u05d4\u200e ), refers to God redeeming the people of Israel from their various exiles. This includes the final redemption from the present exile.\nJudaism holds that adherents do not need personal salvation as Christians believe. Jews do not subscribe to the doctrine of original sin. Instead, they place a high value on individual morality as defined in the law of God\u2014embodied in what Jews know as the Torah or The Law, given to Moses by God on biblical Mount Sinai.\nIn Judaism, salvation is closely related to the idea of redemption, a saving from the states or circumstances that destroy the value of human existence. God, as the universal spirit and Creator of the World, is the source of all salvation for humanity, provided that an individual honours God by observing His precepts. So redemption or salvation depends on the individual. Judaism stresses that salvation cannot be obtained through anyone else or by just invoking a deity or believing in any outside power or influence.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nWhen examining Jewish intellectual sources throughout history, there is clearly a spectrum of opinions regarding death versus the afterlife. Possibly an over-simplification, one source says salvation can be achieved in the following manner: Live a holy and righteous life dedicated to Yahweh, the God of Creation. Fast, worship, and celebrate during the appropriate holidays.\nBy origin and nature, Judaism is an ethnic religion. Therefore, salvation has been primarily conceived in terms of the destiny of Israel as the elect people of Yahweh (often referred to as \"the Lord\"), the God of Israel.\nIn the biblical text of Psalms, there is a description of death, when people go into the earth or the \"realm of the dead\" and cannot praise God. The first reference to resurrection is collective in Ezekiel's vision of the dry bones, when all the Israelites in exile will be resurrected. There is a reference to individual resurrection in the Book of Daniel. A belief in the afterlife, in which the dead would be resurrected and undergo divine judgment, is not recorded until after the exile.\nThe salvation of the individual Jew was connected to the salvation of the entire people. This belief stemmed directly from the teachings of the Torah. In the Torah, God taught his people sanctification of the individual. However, he also expected them to function together (spiritually) and be accountable to one another. The concept of salvation was tied to that of restoration for Israel.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;During the Second Temple Period, the Sadducees, High Priests, denied any particular existence of individuals after death because it wasn't written in the Torah, while the Pharisees, ancestors of the rabbis, affirmed both bodily resurrection and immortality of the soul, most likely based on the influence of Hellenistic ideas about body and soul and the Pharisaic belief in the Oral Torah. The Pharisees maintained that after death, the soul is connected to God until the messianic era when it is rejoined with the body in the land of Israel at the time of resurrection.\nChristianity.\nChristianity's primary premise is that the incarnation and death of Jesus Christ formed the climax of a divine plan for humanity's salvation. This plan was conceived by God before the creation of the world, achieved at the cross, and it would be completed at the Last Judgment, when the Second Coming of Christ would mark the catastrophic end of the world and the creation of a new world.\nFor Christianity, salvation is only possible through Jesus Christ. Christians believe that Jesus' death on the cross was the once-for-all sacrifice that atoned for the sin of humanity.\nThe Christian religion, though not the exclusive possessor of the idea of redemption, has given to it a special definiteness and a dominant position. Taken in its widest sense, as deliverance from dangers and ills in general, most religions teach some form of it. It assumes an important position, however, only when the ills in question form part of a great system against which human power is helpless.\nAccording to Christian belief, sin as the human predicament is considered to be universal. For example, in the Apostle Paul declared everyone to be under sin\u2014Jew and Gentile alike. Salvation is made possible by the life, death, and resurrection of Jesus, which in the context of salvation is referred to as the \"atonement\". Christian soteriology ranges from exclusive salvation to universal reconciliation concepts. While some of the differences are as widespread as Christianity itself, the overwhelming majority agree that salvation is made possible by the work of Jesus Christ, the Son of God, dying on the cross.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;At the heart of Christian faith is the reality and hope of salvation in Jesus Christ. Christian faith is faith in the God of salvation revealed in Jesus of Nazareth. The Christian tradition has always equated this salvation with the transcendent, eschatological fulfillment of human existence in a life freed from sin, finitude, and mortality and united with the triune God. This is perhaps \"the\" non-negotiable item of Christian faith. What has been a matter of debate is the relation between salvation and our activities in the world.\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Bible presents salvation in the form of a story that describes the outworking of God's eternal plan to deal with the problem of human sin. The story is set against the background of the history of God's people and reaches its climax in the person and work of Christ. The Old Testament part of the story shows that people are sinners by nature, and describes a series of covenants by which God sets people free and makes promises to them. His plan includes the promise of blessing for all nations through Abraham and the redemption of Israel from every form of bondage. God showed his saving power throughout Israel's history, but he also spoke about a Messianic figure who would save all people from the power, guilt, and penalty of sin. This role was fulfilled by Jesus, who will ultimately destroy all the devil's work, including suffering, pain, and death.\u2014\u200a\nVariant views on salvation are among the main fault lines dividing the various Christian denominations: Roman Catholicism, Eastern Orthodoxy, and Protestantism. A few examples are found within Protestantism, notably in the Calvinist\u2013Arminian debate, and between Roman Catholicism and Protestantism, notably when dealing with \"sola fide\" during the Protestant Reformation. The fault lines can include conflicting definitions of depravity, predestination, atonement, but most pointedly justification.\nSalvation, according to most denominations, is believed to be a process that begins when a person first becomes a Christian, continues through that person's life, and is completed when they stand before Christ in judgment. Therefore, according to Catholic apologist James Akin, the faithful Christian can say in faith and hope, \"I \"have been\" saved; I \"am being\" saved; and I \"will be\" saved.\"\nChristian salvation concepts are varied and complicated by certain theological concepts, traditional beliefs, and dogmas. Scripture is subject to individual and ecclesiastical interpretations. While some of the differences are as widespread as Christianity itself, the overwhelming majority agrees that salvation is made possible by the work of Jesus Christ, the Son of God, dying on the cross.\nThe purpose of salvation is debated, but in general most Christian theologians agree that God devised and implemented his plan of salvation because he loves them and regards human beings as his children. Since human existence on Earth is said to be \"given to sin,\" salvation also has connotations that deal with the liberation of human beings from sin, and the sufferings associated with the punishment of sin\u2014i.e., \"the wages of sin are death.\"\nChristians believe that salvation depends on the grace of God. Stagg writes that a fact assumed throughout the Bible is that humanity is in, \"serious trouble from which we need deliverance\u2026. The fact of sin as the human predicament is implied in the mission of Jesus, and it is explicitly affirmed in that connection.\" By its nature, salvation must answer to the plight of humankind as it actually is. Each individual's plight as a sinner is the result of a fatal choice involving the whole person in bondage, guilt, estrangement, and death. Therefore, salvation must be concerned with the total person. \"It must offer redemption from bondage, forgiveness for guilt, reconciliation for estrangement, renewal for the marred image of God.\"\nLatter-Day Saints.\nAccording to doctrine of the Church of Jesus Christ of Latter-day Saints, the plan of salvation is God's plan to save, redeem, and exalt all humankind who chose, either in this life, or in the world of spirits of the dead, to accept the grace of Jesus Christ by faith in him, repenting of their sins, and by making and keeping sacred covenants (including baptism). Since most people die without doing these things, the LDS preaches to them that if they accept Christ, sincerely repent of their sins, and accept ordinances done on their behalf, they can receive salvation on the same terms as the living. Members of the Church of Jesus Christ of Latter-day Saints do vicarious work for the dead in sacred temples, drawing from various sources, including the Bible, Book of Mormon, Doctrine &amp; Covenants, Pearl of Great Price, and statements by LDS leaders.\nIslam.\nIn Islam, salvation refers to the eventual entrance to Paradise. Islam teaches that only those who die believing in the one God in Islam receive salvation.\nNarrated Anas, that Islamic prophet Muhammad said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Whoever said \"None has the right to be worshipped but Allah and has in his heart good (faith) equal to the weight of a barley grain will be taken out of Hell. And whoever said: \"None has the right to be worshipped but Allah and has in his heart good (faith) equal to the weight of a wheat grain will be taken out of Hell. And whoever said, \"None has the right to be worshipped but Allah and has in his heart good (faith) equal to the weight of an atom will be taken out of Hell.\u2014\u200a\nAccording to Islam:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Whoever seeks a way other than Islam, it will never be accepted from them, and in the Hereafter they will be among the losers.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Indeed, the believers, Jews, Christians, and Sabians\u2014whoever truly believes in Allah and the Last Day and does good will have their reward with their Lord. And there will be no fear for them, nor will they grieve.\nTawhid.\nBelief in the \"One God\", also known as the \"Tawhid\" () in Arabic, consists of two parts (or principles):\nSin and repentance.\nIslam also stresses that in order to gain salvation, one must avoid sin and perform good deeds. Islam acknowledges the inclination of humanity towards sin. Therefore, Muslims are constantly commanded to seek God's forgiveness and repent. Islam teaches that no one can gain salvation simply by virtue of their belief or deeds but by the mercy of God. However, repentance must not be used to sin any further. Islam teaches that God is merciful.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Allah only accepts the repentance of those who commit evil ignorantly or recklessly then repent soon after\u2014Allah will pardon them. And Allah is All-Knowing, All-Wise.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Indeed, Allah does not forgive associating others with Him \u02f9in worship\u02fa, but forgives anything else of whoever He wills. And whoever associates others with Allah has indeed committed a grave sin.\nIslam describes a true believer to have Love of God and Fear of God. Islam also teaches that every person is responsible for their own sins. The Quran states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If you disbelieve, then \u02f9know that\u02fa Allah is truly not in need of you, nor does He approve of disbelief from His servants. But if you become grateful \u02f9through faith\u02fa, He will appreciate that from you. No soul burdened with sin will bear the burden of another. Then to your Lord is your return, and He will inform you of what you used to do. He certainly knows best what is \u02f9hidden\u02fa in the heart.\nAl-Agharr al-Muzani who was from amongst the companions of Muhammad reported that Ibn 'Umar stated to him that Allah's Messenger said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;O people, seek repentance from Allah. Verily, I seek repentance from Him a hundred times a day.\u2014\u200a\nSin in Islam is an action (a bad deed), not a state; Islam teaches that a child is born sinless, regardless of the belief of their parents, dies a Muslim, and enters heaven, and does not enter hell.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Narrated `Aisha: The Prophet said, \"Do good deeds properly, sincerely and moderately, and receive good news because one's good deeds will not make him enter Paradise.\" They asked, \"Even you, O Allah's Messenger?\" He said, \"Even I, unless and until Allah bestows His pardon and Mercy on me.\"\u2014\u200a\nFive Pillars.\nIslam is built on five principles, acts of worship that Islam teaches to be mandatory. Not performing the mandatory acts of worship may deprive Muslims of the chance of salvation. According to Ibn 'Umar, Muhammad said that Islam is based on the following five principles:\nIndian religions.\nHinduism, Buddhism, Jainism and Sikhism share certain key concepts, which are interpreted differently by different groups and individuals. In these religions one is not liberated from sin and its consequences, but from the \"sa\u1e43s\u0101ra\" (cycle of rebirth) perpetuated by passions and delusions and its resulting karma. They differ however on the exact nature of this liberation.\nSalvation is always self-attained in Indian religions, and a more appropriate term would be \"moksha\" ('liberation') or \"mukti\" ('release'). This state and the conditions considered necessary for its realization is described in early texts of Indian religion such as the Upanishads and the P\u0101li Canon, and later texts such the Yoga Sutras of Patanjali and the Vedanta tradition. \"Moksha\" can be attained by \"s\u0101dhan\u0101\", literally 'means of accomplishing something'. It includes a variety of disciplines, such as yoga and \"dhyana\" (meditation).\nNirvana is the profound peace of mind that is acquired with \"moksha\". In Buddhism and Jainism, it is the state of being free from suffering. In Hindu philosophy, it is union with the Brahman (Supreme Being). The word literally means 'blown out' (as in a candle) and refers, in the Buddhist context, to the blowing out of the fires of desire, aversion, and delusion, and the imperturbable stillness of mind acquired thereafter.\nIn Theravada Buddhism the emphasis is on one's own liberation from samsara. The Mahayana traditions emphasize the \"bodhisattva\" path, in which \"each Buddha and Bodhisattva is a redeemer,\" assisting the Buddhist in seeking to achieve the redemptive state. The assistance rendered is a form of self-sacrifice on the part of the teachers, who would presumably be able to achieve total detachment from worldly concerns, but have instead chosen to remain engaged in the material world to the degree that this is necessary to assist others in achieving such detachment.\nJainism.\nIn Jainism, \"salvation\", \"moksha\", and \"nirvana\" are one and the same. When a soul (\"atman\") achieves \"moksha\", it is released from the cycle of births and deaths, and achieves its pure self. It then becomes a \"siddha\" ('one who has accomplished his ultimate objective'). Attaining Moksha requires annihilation of all \"karmas\", good and bad, because if karma is left, it must bear fruit.\nTaoism.\nWhile early Taoism had no understanding of the concept of salvation, later in Taoist history, salvation became a major part of beliefs about it. Things one could do to be saved was to pray, offer sacrifices, and/or become a \"xian\" () immortal.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral and cited references.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "29475", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=29475", "title": "Lockheed S-3 Viking", "text": "Carrier-based anti-submarine and aerial refueling aircraft\nThe Lockheed S-3 Viking is a four-crew, twin-engine turbofan-powered subsonic anti-submarine jet aircraft designed and produced by the American aerospace manufacturer Lockheed Corporation. Because of its characteristic sound, it was nicknamed the \"War Hoover\" after the vacuum cleaner brand.\nThe S-3 was developed in response to the VSX program conducted by the U.S. Navy (USN) to procure a successor anti-submarine warfare (ASW) aircraft to the Grumman S-2 Tracker. It was designed, with assistance from Ling-Temco-Vought (LTV), to be a carrier-based, subsonic, all-weather, long-range, multi-mission aircraft.\nOn 21 January 1972, the prototype \"YS-3A\" performed the type's maiden flight. Upon entering regular service during February 1974, it proved to be a reliable workhorse. In the ASW role, the S-3 carried automated weapons and in-flight refueling gear. Further variants, such as the \"ES-3A Shadow\" carrier-based electronic intelligence (ELINT) platform, and the \"US-3A\" carrier-based utility and cargo transport, arrived during the 1980s and 1990s. In the late 1990s, the S-3B's mission focus shifted to surface warfare and aerial refueling a carrier battle group. It saw combat during the Gulf War of the early 1990s, the Yugoslav Wars of the mid-to-late 1990s, and the War in Afghanistan during the 2000s.\nThe S-3 was removed from front-line fleet service aboard aircraft carriers in January 2009, its missions having been taken over by the P-3C Orion, P-8 Poseidon, SH-60 Seahawk, and F/A-18E/F Super Hornet. For more than a decade after that, some S-3s were flown by Air Test and Evaluation Squadron Thirty (VX-30) at Naval Base Ventura County / NAS Point Mugu, California, for range clearance and surveillance operations at the NAVAIR Point Mugu Range. These final examples in U.S. Navy service were retired in early 2016. The last operational S-3 was used by the National Aeronautics and Space Administration (NASA) at its Glenn Research Center until NASA retired it in mid-2021. Most retired S-3s were placed into storage while options for their future were investigated. During the 2010s, Lockheed Martin proposed to refurbish them for carrier onboard delivery. The Republic of Korea Navy also had plans to operate revived S-3s for ASW; these plans were cancelled in 2017.\nDevelopment.\nIn the mid-1960s, the United States Navy (USN) formulated the \"VSX\" (Heavier-than-air, Anti-submarine, Experimental) requirement, which sought a dedicated anti-submarine aircraft capable of flying off of its aircraft carriers as a replacement for its existing inventory of piston-engined Grumman S-2 Trackers. The service issued a request for proposals to industry. During August 1968, a team led by Lockheed, as well as a rival team comprising Convair and Grumman, were requested to further develop their proposals to meet this requirement.\nAt this stage, Lockheed recognised that it had little experience in designing carrier based aircraft, thus the company reached out to the industrial conglomerate Ling-Temco-Vought (LTV), which joined the team. LTV assumed responsibility for the design of various elements of the airframe, such as the folding wings and tail, the engine nacelles, and the landing gear, some of which had been derived from the earlier LTV A-7 Corsair II and Vought F-8 Crusader. Sperry Univac Federal Systems was assigned the task of developing the aircraft's onboard computers which integrated input from sensors and sonobuoys.\nOn 4 August 1969, Lockheed's design was selected as the winner of the VSX contest; an order for eight prototypes, designated \"YS-3A\", was promptly received by the company. On 21 January 1972, the first prototype performed its maiden flight in the hands of military test pilot John Christiansen. Flight testing proceeded quickly with no major issues; two years later, the S-3 entered operational service with the U.S. Navy. During the type's production run, which ran from 1974 to 1978, a total of 186 S-3As were constructed. The majority of the surviving S-3As were later upgraded to the improved \"S-3B\" variant, while 16 aircraft were also converted into \"ES-3A Shadow\" electronic intelligence (ELINT) collection aircraft.\nDesign.\nThe Lockheed S-3 Viking is a conventional monoplane with a cantilever shoulder wing, very slightly swept with a leading edge angle of 15\u00b0 and an almost straight trailing edge. Its twin GE TF-34 high-bypass turbofan engines mounted in nacelles under the wings provide excellent fuel efficiency, providing the Viking with the required long range and endurance, while also maintaining relatively docile engine-out characteristics.\nThe aircraft can seat four crew members (three officers and one enlisted) with pilot and copilot/tactical coordinator (COTAC) in the front of the cockpit and the tactical coordinator (TACCO) and sensor operator (SENSO) in the back. Entry is via a hatch/ladder folding down out of the lower starboard side of the fuselage behind the cockpit, in between the rear and front seats on the starboard side. When the aircraft's anti-submarine warfare (ASW) role ended in the late 1990s, the enlisted SENSOs were removed from the crew. In tanker crew configuration, the S-3B typically flew with a pilot and co-pilot/COTAC. The wing is fitted with leading edge and Fowler flaps. Spoilers are fitted to both the upper and the lower surfaces of the wings. All control surfaces are actuated by dual hydraulically boosted irreversible systems. In the event of dual hydraulic failures, an Emergency Flight Control System (EFCS) permits manual control with greatly increased stick forces and reduced control authority.\nUnlike many tactical jets which required ground service equipment, the S-3 was equipped with an auxiliary power unit (APU) and capable of unassisted starts. The aircraft's original APU could provide only minimal electric power and pressurized air for both aircraft cooling and for the engines' pneumatic starters. A newer, more powerful APU could provide full electrical service to the aircraft. The APU itself was started from a hydraulic accumulator by pulling a handle in the cockpit. The APU accumulator was fed from the primary hydraulic system, but could also be pumped up manually (with much effort) from the cockpit.\nAll crew members sit on forward-facing, upward-firing Douglas Escapac zero-zero ejection seats. In \"group eject\" mode, initiating ejection from either of the front seats ejects the entire crew in sequence, with the back seats ejecting 0.5 seconds before the front in order to provide safe separation (this was to prevent the pilots, who were more aware of what was happening outside the aircraft from ejecting without the rest of the crew, or being forced to delay ejection to order the crew to eject in an emergency; ejection from either rear seat would not eject the pilots, who had to initiate their own ejections, to prevent loss of the aircraft if a rear crewmember ejected prematurely. If a pilot ejected prematurely, the plane was lost anyway, and automatic ejection prevented the crew from crashing with a pilot-less aircraft before they were aware of what had happened). The rear seats are capable of self ejection and the ejection sequence includes a pyrotechnic charge that stows the rear keyboard trays out of the occupants' way immediately before ejection. Safe ejection requires the seats to be weighted in pairs, and when flying with a single crewman in the back the unoccupied seat is fitted with ballast.\nAt the time it entered the fleet, the S-3 introduced an unprecedented level of systems integration. Previous ASW aircraft like the Lockheed P-3 Orion and S-3's predecessor, the Grumman S-2 Tracker, featured separate instrumentation and controls for each sensor system. Sensor operators often monitored paper traces, using mechanical calipers to make precise measurements and annotating data by writing on the scrolling paper. Beginning with the S-3, all sensor systems were integrated through a single General Purpose Digital Computer (GPDC). Each crew station had its own display, the co-pilot/COTAC, TACCO and SENSO displays were Multi-Purpose Displays (MPD) capable of displaying data from any of a number of systems. This new level of integration allowed the crew to consult with each other by examining the same data at multiple stations simultaneously, to manage workload by assigning responsibility for a given sensor from one station to another and to easily combine clues from each sensor to classify faint targets. As a consequence of this integration, the four-crew S-3 was considered roughly equivalent in terms of capability to the much larger P-3, operated by a crew of 12.\nThe aircraft has two underwing hardpoints that can be used to carry fuel tanks, general purpose and cluster bombs, missiles, rockets, and storage pods. It also has four internal bomb bay stations that can be used to carry general-purpose bombs, aerial torpedoes, and special stores (B57 and B61 nuclear weapons). Fifty-nine sonobuoys are carried, as well as a dedicated Search and Rescue (SAR) chute. The S-3 is fitted with the ALE-39 countermeasure system and can carry up to 90 rounds of chaff, flares, and expendable jammers (or a combination of all) in three dispensers. A retractable magnetic anomaly detector (MAD) Boom is fitted in the tail.\nIn the late 1990s, the S-3B's role was changed from anti-submarine warfare (ASW) to anti-surface warfare (ASuW). As a consequence of this role change, the MAD Boom was removed, along with several hundred pounds of submarine detection electronics. As there was no remaining sonobuoy processing capability, most of the sonobuoy chutes were faired over with a blanking plate.\nOperational history.\nOn 20 February 1974, the S-3A officially became operational with the Air Antisubmarine Squadron FORTY-ONE (VS-41), the \"Shamrocks,\" at NAS North Island, California, which served as the initial S-3 Fleet Replacement Squadron (FRS) for both the Atlantic and Pacific Fleets until a separate Atlantic Fleet FRS, VS-27, was established in the 1980s. The first operational cruise of the S-3A took place in 1975 with the VS-21 \"Fighting Redtails\" aboard .\nInitial operations of the Viking were somewhat troubled in the carrier environment, its sophisticated mission systems were largely dependent on the mission computer, which would often \"dump\" during the stress of a catapult-assisted take-off, requiring the crew to restart it and reload the software. The U.S. Navy had also purchased an insufficient number of spare parts, which negatively impacted the aircraft's mission readiness. Performance improved considerably once an ample supply of spares was provisioned, allowing the S-3 to become a valuable ASW asset as well as a good surface-surveillance platform.\nStarting in 1987, the majority of S-3As were progressively upgraded to the improved \"S-3B\" standard; this involved the addition of several new sensors, avionics, and weapons systems, which included the capability to launch the AGM-84 Harpoon anti-ship missile. The S-3B could also be fitted with \"buddy stores\", external fuel tanks that allowed the Viking to refuel other aircraft. During July 1988, VS-30 became the first fleet squadron to receive the enhanced capability Harpoon/ISAR equipped S-3B, based at NAS Cecil Field in Jacksonville, Florida.\nAdditional, often more specialised variants, were also produced. 16 S-3As were converted to \"ES-3A Shadow\"s for carrier-based electronic intelligence (ELINT) duties. Six aircraft, designated \"US-3A\", were converted for a specialized utility and limited cargo Carrier onboard delivery (COD) requirement. This model played a key role in US military efforts to relieve the Iran hostage crisis of 1979\u20131981. Plans were also made to develop the \"KS-3A\" carrier-based tanker aircraft, but this program was ultimately cancelled after the conversion of just one early development S-3A.\nAs a consequence of the collapse of the Soviet Union and the breakup of the Warsaw Pact in the early 1990s, the Soviet-Russian submarine threat was perceived as much reduced, and the Vikings had the majority of their antisubmarine warfare equipment removed. The aircraft's mission subsequently changed to sea surface search, sea and ground attack, over-the-horizon targeting, and aircraft refueling. As a result, the S-3B after 1997 was typically crewed by a single pilot along with a copilot [NFO]; the additional seats remained in place in the S-3B and could be used by additional crew members for certain missions. To reflect these new missions, the Viking squadrons were redesignated from \"Air Antisubmarine Warfare Squadrons\" to \"Sea Control Squadrons\".\nPrior to the aircraft's retirement from front-line fleet use aboard US aircraft carriers, a number of upgrade programs were implemented. These include the Carrier Airborne Inertial Navigation System II (CAINS II) upgrade, which replaced older inertial navigation hardware with ring laser gyroscopes with a Honeywell EGI (Enhanced GPS Inertial Navigation System) and added digital electronic flight instruments (EFI). The Maverick Plus System (MPS) added the capability to employ the AGM-65E laser-guided or AGM-65F infrared-guided air-to-surface missile, and the AGM-84H/K Stand-off Land Attack Missile Expanded Response (SLAM/ER). The SLAM/ER is a GPS/inertial/infrared guided cruise missile derived from the AGM-84 Harpoon that can be controlled by the aircrew in the terminal phase of flight if an AWW-13 data link pod is carried by the aircraft.\nThe S-3B saw extensive service during the 1991 Gulf War, performing attack, tanker, and ELINT duties, and launching ADM-141 TALD decoys. One such aircraft, launched from the aircraft carrier , was responsible for the destruction of an Iraqi Silkworm anti-ship missile site, having fired AGM-84 SLAM missiles at it. It was commonly deployed to hunt for Scud missile launcher. The Vikings also identified and targeted numerous Iraqi naval vessels, and even destroyed anti-aircraft gun emplacements and coastal radars. The Gulf War was the first event in which the type had been employed overland in offensive air strike capacity.\nThe Viking also participated in the Yugoslav wars in the 1990s, and in Operation Enduring Freedom in the 2000s. For the latter, the opening phase of the War in Afghanistan in October 2001, many Vikings were deployed as tankers to continuously undertake refueling sorties to support various fighters stationed aboard U.S. carriers, giving them the necessary endurance to fly to and from the conflict zone.\nElectronic surveillance.\nThe first ES-3A was delivered during 1991 and entered front-line service after two years of testing. The U.S. Navy established two squadrons, each equipped with eight ES-3As, stationed in both the Atlantic and Pacific Fleets to provide detachments of typically two aircraft, ten officers, and 55 enlisted aircrew, maintenance and support personnel (which comprised/supported four complete aircrews) to deploying carrier air wings. The Pacific Fleet squadron, Fleet Air Reconnaissance Squadron FIVE (VQ-5), the \"Sea Shadows,\" was originally based at the former NAS Agana, Guam but later relocated to NAS North Island in San Diego, California, with the Pacific Fleet S-3 Viking squadrons when NAS Agana closed in 1995 as a result of a 1993 Base Realignment and Closure (BRAC) decision. The Atlantic Fleet squadron, the VQ-6 \"Black Ravens,\" were originally based with all Atlantic Fleet S-3 Vikings at the former NAS Cecil Field in Jacksonville, Florida, but later moved to NAS Jacksonville, approximately to the east, when NAS Cecil Field was closed in 1999 as a result of the same 1993 BRAC decision that closed NAS Agana.\nThe ES-3A operated primarily with carrier battle groups, providing organic 'Indications and Warning' support to the group and joint theater commanders. In addition to their warning and reconnaissance roles, and their extraordinarily stable handling characteristics and range, Shadows were a preferred recovery tanker (aircraft that provide refueling for returning aircraft). They were also deployed to active combat zones, seeing use over Yugoslavia to identify targets, as well as to enforce the no-fly zone over Iraq. The Shadows reportedly averaged over 100 flight hours per month while deployed. Excessive utilization caused earlier than expected equipment replacement when Naval aviation funds were limited, making them an easy target for budget-driven decision makers. The type was also deemed by some officials to be too costly to continue operating. In 1999, both ES-3A squadrons and all 16 aircraft were decommissioned and the ES-3A inventory placed in Aerospace Maintenance and Regeneration Group (AMARG) storage at Davis-Monthan AFB, Arizona.\nIraq War.\nThe S-3 was an active participant in Operation Iraqi Freedom, the US invasion of Iraq; it largely performed intelligence and reconnaissance missions in support of other coalition assets. On one occasion, in March 2003 a single S-3B Viking from Sea Control Squadron 38 (The \"Red Griffins\"), piloted by Richard McGrath Jr., from the aircraft carrier successfully executed a time-sensitive strike, firing a laser-guided Maverick missile that neutralized a significant Iraqi naval and leadership target in the port city of Basra, Iraq. This was the first time an S-3 launched a laser-guided Maverick missile in combat. As the conflict progressed, S-3s were regularly used as surveillance aircraft, often to identify improvised explosive devices (IEDs) and the insurgents who planted them.\nOn 1 May 2003, US President George W. Bush flew in the co-pilot seat of a VS-35 Viking from NAS North Island, California, to the aircraft carrier off the California coast; while the carrier was well within range of helicopters, it is believed that the S-3 was used as a means of setting a desired tone. Aboard the carrier, he delivered his \"Mission Accomplished\" speech announcing the end of major combat in the 2003 invasion of Iraq. During the flight, the aircraft used the presidential callsign of \"Navy One\". The aircraft that President Bush flew in was retired shortly thereafter and on 15 July 2003 was accepted as an exhibit at the National Museum of Naval Aviation at NAS Pensacola, Florida.\nBetween July and December 2008, the VS-22 Checkmates, the last sea control squadron, operated a detachment of four S-3Bs from the Al Asad Airbase in Al Anbar Province, west of Baghdad. The planes were fitted with LANTIRN pods and they performed non-traditional intelligence, surveillance, and reconnaissance. After more than 350 missions, the Checkmates returned to NAS Jacksonville, Florida, on 15 December 2008. The squadron was disestablished on 29 January 2009.\nFinal years and retirement.\nA proposed airframe known as the Common Support Aircraft was advanced as a successor to the S-3, E-2, and C-2, but this initiative failed to materialize. In 1998, the U.S. Navy awarded a $40 million contract for Lockheed Martin to perform a full-scale Fatigue testing of the existing S-3s; these tests, which commenced in June 2001, were aimed at extending the viable service life of each remaining aircraft, which had originally been certified for a structural life of 13,000 flight-hours. It was hoped that this could be extended to as much as 17,750 hours.\nThe final carrier-based S-3B squadron, VS-22, was decommissioned at NAS Jacksonville on 29 January 2009. Sea Control Wing Atlantic was decommissioned the following day, along with the last S-3s in frontline fleet service.\nIn June 2010, the first of three S-3s to patrol the Pacific Missile Test Center's range areas off of California was reactivated and delivered. The jet aircraft's higher speed, ten-hour endurance, modern radar, and a LANTIRN targeting pod allowed it to quickly confirm the test range being clear of wayward ships and aircraft before tests commence. These S-3Bs are flown by Air Test and Evaluation Squadron Thirty (VX-30) based out of NAS Point Mugu, California. By late 2015, the U.S. Navy were operating a total of three Vikings in support roles. One was relocated to The Boneyard in November 2015, while the final two were retired, one being stored and the other transferred to NASA, on 11 January 2016, officially retiring the S-3 from Navy service.\nDuring 2004, NASA acquired four of the withdrawn S-3Bs for use at its Glenn Research Center. In 2009, one of these aircraft (USN BuNo 160607) was given the civil registration \"N601NA\", it was involved in numerous tests conducted by the agency. For over a decade, this aircraft was flying almost every day in support for various research programs; one such initiative was the definition of new Federal Aviation Administration communication standards for unmanned aerial vehicles operating in US airspace. However, a lack of spare parts and increasing difficulty supporting the type meant their use could not continue in the long term. The last of the NASA's S-3Bs, which were the final working members of the type in existence with any operator at that point, were retired on 13 July 2021.\nNaval analysts have suggested that the U.S. Navy return to service an unspecified quantity of the stored S-3s in order to fill gaps that were left in the carrier air wing when it was retired. This move was promoted as a response to the realization that the Chinese navy is producing increasingly capable weapons that can threaten carriers beyond the range their aircraft can strike them. Against the DF-21D anti-ship ballistic missile, carrier-based F/A-18 Super Hornets and F-35C Lightning IIs have about half the unrefueled strike range, so bringing the S-3 back to aerial tanking duties would extend their range against it, as well as free up Super Hornets forced into tanking. Against submarines armed with anti-ship cruise missiles like the Klub and YJ-18, the S-3 would restore area coverage for ASW duties. Bringing the S-3 out of retirement could at least be a stop-gap measure to increase the survivability and capabilities of aircraft carriers until new aircraft can be developed for such purposes.\nPotential revival and proposals.\nIn October 2013, the Republic of Korea Navy expressed its interest in acquiring up to 18 ex-USN S-3s to augment their fleet of 16 Lockheed P-3 Orion aircraft. In August 2015, a military program review group approved a proposal to incorporate 12 mothballed S-3s to perform ASW duties; the Viking plan was sent onto the Defense Acquisition Program Administration for further assessment before final approval decision by the national defense system committee. Although the planes are relatively old, being in storage has supposedly kept them serviceable, and using them is an affordable means of fulfilling short-range airborne ASW capabilities that were vacated by the retirement of the S-2 Tracker. Refurbished S-3s could have been returned to use by 2019. In 2017, the Republic of Korea Navy canceled plans to purchase refurbished and upgraded Lockheed S-3 Viking aircraft for maritime patrol and anti-submarine duties, leaving offers by Airbus, Boeing, Lockheed Martin, and Saab on the table.\nDuring April 2014, Lockheed Martin announced that they would offer refurbished and remanufactured S-3s, dubbed the \"C-3\", as a replacement for the Northrop Grumman C-2A Greyhound for carrier onboard delivery. The requirement for 35 aircraft would be met from the 91 S-3s currently in storage. In February 2015, the Navy announced that the Bell Boeing V-22 Osprey had been selected to replace the C-2 for the COD mission. A SV-22 was a proposed anti-submarine warfare variant the U.S. Navy studied in the 1980s to replace S-3 Viking and late model SH-2 Seasprite ASW helicopters.\nFirst production version, 187 built.\nUpgraded avionics, AN/APS-137 inverse synthetic aperture radar, Joint Tactical Information Distribution System, AGM-84 Harpoon launch capability, first flight 13 September 1984, 119 converted from S-3As.\nDesigned as a carrier-based, subsonic, all-weather, long-range, electronic reconnaissance (ELINT) aircraft. 16 aircraft were modified to replace the EA-3B Skywarrior, entering fleet service in 1993. The ES-3A carried an extensive suite of electronic sensors and communications gear, replacing the S-3's submarine detection, armament, and maritime surveillance equipment with avionics racks accommodating the ES-3A's sensors. These modifications had minor impact on airspeed, reducing its top rated speed from but had no noticeable impact on the aircraft's range and actually increased its rated loiter time. Because these aircraft were standoff indications and warnings platforms and were never intended to be part of an ingress strike package, this new speed limitation was considered insignificant.\nProposed dedicated air tanker with fuel capacity of 4,382\u00a0US gal (16,600\u00a0L), one converted from YS-3A, later converted to US-3A.\nProposed air tanker based on S-3B and utilizing the buddy refueling system, not built.\nS-3A modified for carrier onboard delivery, capacity for six passengers or of cargo, retired in 1998.\nConversion of six aircraft for overland surveillance and Elint missions. May have dropped ground sensors in the Bosnian War.\nS-3Bs fitted with still-classified modifications.\nProposed anti-smuggling variant, not built.\nOne aircraft fitted with AN/APG-76 radar in a modified cargo pod under the wing. Also dubbed SeaSTARS in reference to E-8 Joint STARS.\nAvionics testbed.\nOne S-3B fitted with Over-the-horizon Airborne Sensor Information System (OASIS III), returned to regular S-3B in 1998. This particular Viking is now on display at the USS \"Midway\" Museum, located on the decommissioned .\nOne aircraft was extensively rebuilt into a state-of-the-art NASA research aircraft. The Navy's Fleet Readiness Center Southeast and a Boeing facility in Florida modified it, adding commercial satellite communications, global positioning navigation, and weather radar systems. They also installed research equipment racks in what was once the plane's bomb bay. NASA's S-3B Viking was equipped to conduct science and aeronautics missions, such as environmental monitoring, satellite communications testing, and aviation safety research.\nSpecifications (S-3A).\n\"Data from\" \"Standard Aircraft Characteristics\"General characteristics* Crew: 4 (pilot, co-pilot, TACCO, sensor operator)* Aspect ratio: 7.73* Airfoil: root: NACA 0016.3-1.03 32.7/100 mod; tip: NACA 0012-1.10 40/1.00 mod* Fuel capacity: \nPerformance* Maximum speed: Mach 0.79* Endurance: * g limits: * Roll rate: * Thrust/weight: 0.353\nArmament\nAvionics\nSee also.\nAircraft of comparable role, configuration, and era\nRelated lists\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "29476", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=29476", "title": "Kaman SH-2 Seasprite", "text": "1959 anti-submarine helicopter family by Kaman\nThe Kaman SH-2 Seasprite is a ship-based helicopter originally developed and produced by American manufacturer Kaman Aircraft Corporation. It has been typically used as a compact and fast-moving rotorcraft for utility and anti-submarine warfare (ASW) missions. Early on it was modest sized single-engined naval utility helicopter, and progressed to twin-engine ASW and SAR, and the latest model served well into the 21st century, with G model in active service in the 2020s with Egypt, New Zealand, Peru, and Poland.\nThe Seasprite, with the internal Kaman designation \"K-20\", was developed in the late 1950s in response to a United States Navy (USN) requirement for a suitably fast and compact naval utility helicopter. The USN found the Seasprite attractive, and ordered four prototypes and an initial batch of 12 production helicopters as the \"HU2K-1\". Under the 1962 United States Tri-Service aircraft designation system, the \"HU2K\" and \"HU2K-1\" were re-designated as \"H-2\" and \"UH-2A\" respectively. Kaman also pursued foreign sales; after showing interest, the Royal Canadian Navy (RCN) rejected the Seasprite due to an unexpected price increase and underperformance during sea trials. The USN addressed the poor performance by converting the single-engine Seasprites into a more powerful twin-engine configuration from 1968.\nIn October 1970, the USN selected the Seasprite as the interim Light Airborne Multi-Purpose System (LAMPS) helicopter, resulting in the \"SH-2D/F\" variant with enhanced ASW and anti-surface warfare sensors. Most UH-2s were converted into SH-2Fs.\nUSN Seasprites were used for ASW, search and rescue (SAR), utility and plane guard for aircraft carriers. In the Vietnam War they were mainly used for combat search and rescue (CSAR), and combat support and surface warfare during the Gulf War. The SH-2G Super Seasprite was the last variant and \u2014 in 2001 \u2014 the last Seasprite to leave USN service. Retired USN Seasprites were offered as foreign aid in the 1990s and 2000s; this led to quite some interest and F and/or G models served with New Zealand, Poland, and Egypt. Retired models were also sent to aviation museums, and a number have been put on display. However, the latest upgraded models are still in frontline service with several navies around the world.\nDesign and development.\nOrigins.\nIn 1956, the USN launched a competition for a compact, all-weather multipurpose naval helicopter, and encouraged submissions from private companies. Kaman responded with its \"K-20\" design, a relatively conventional helicopter with a General Electric T58-8F turboshaft engine droving a 44-foot four-bladed main rotor and a four-bladed tail rotor. Kaman won the competition and was awarded a contract to construct four prototypes and an initial batch of 12 production helicopters, designated as the \"HU2K-1\".\nIn 1960, the HU2K was the RCN's preferred option for its ASW helicopter program, and the Government of Canada approved the purchase of 12 Seasprites for $14.5 million. However, the purchase was disrupted by Kaman suddenly raising the price to $23 million, and concerns that the helicopter's designed weight and performance criteria were overoptimistic. The RCN delayed making a decision until after the USN sea trials which confirmed that the HU2K was overweight and underpowered for their needs. In late-1961, Canada selected the competing Sikorsky CH-124 Sea King instead.\nIn the late-1960s, without further orders Kaman decided to terminate production after completing the USN order of 184 H-2s. However, in 1971, production was restarted for the improved SH-2F to operate from older frigates. This ability meant it stayed in service to the end of the century, as even with the introduction of the newer, larger and overall more capable Sikorsky SH-60 Sea Hawk which entered service starting in the mid-1980s, but it could not operate safety from the smaller flight decks like the smaller Seasprite.\nFurther developments.\nThe HU2K-1 and HU2K-1U were re-designated as the UH-2A and UH-2B respectively under the 1962 United States Tri-Service aircraft designation system. The Seasprite continued to receive modifications and improvements, including external stores mounts. Beginning in 1968, the USN's remaining UH-2s underwent a major conversion into a more powerful two-engine configuration.\nIn the 1960s, the US Army commissioned a gunship version, which was called the Kaman H-2 Tomahawk, and featured multiple M-60 machine guns (7.62) and options for rocket launchers, however, it was passed over in favor of the AH-1 Cobra.\nIn 1968 two UH-2Bs, were converted to NUH-2B. These were experimental versions for the U.S. Army, which attached a J85 turbojet to the helicopter, and achieved speeds over 220s mph, and the second prototype had wings attached. Both prototypes were returned to SH2-D after the trials.\nIn October 1970, the UH-2 was selected as the interim Light Airborne Multi-Purpose System (LAMPS) helicopter. LAMPS evolved during the 1960s from an urgent requirement to provide non-aviation ships with manned support and ASW helicopters. The \"LAMPS Mark I\" suite included advanced sensors, processors, and display capabilities. H-2s upgraded with LAMPS were called SH-2Ds, and became mobile radar and sonar platforms that enhanced the situational awareness of ships.\nThe SH-2D first flew on 16 March 1971. Deliveries of the SH-2F began in 1973; the SH-2F included LAMPS I and other improvements, such as upgraded engines, an extended life main rotor, and an heavier take-off weight. During 1981, the USN ordered 60 SH-2Fs. From 1987, 16 SH-2Fs were upgraded with a chin-mounted forward-looking infrared (FLIR) sensor, chaff/flare launchers, dual rear-mounted infrared countermeasures, and missile/mine detecting equipment.\nAll but two USN H-2s were converted into SH-2Fs. Fiscal Year 1986 was the last time SH-2F were ordered; the final six were converted into SH-2G Super Seasprites.\nOperational history.\nUnited States.\nThe UH-2 entered operational service with the USN in 1962. The single engine greatly restricted performance. Kaman was ordered to convert all of the Seasprites to a twin-engine configuration. The upgraded helicopters had a airspeed and a operating range. The USN operated nearly 200 Seasprites in multiple roles, including ASW, SAR, and utility transport. Under typical operational conditions, USN aircraft carrier deployed with several UH-2s in the plane guard and SAR roles.\nThe UH-2 was introduced in time to see action in the Tonkin Gulf incident in August 1964. The Seasprite's main role in the Vietnam War was CSAR of downed aircrews at sea and overland, reliance on the Seasprite in this role increased as the conflict intensified, such as during Operation Rolling Thunder in 1965. During October 1966, helicopter-based SAR teams recovered 103 out of 269 downed pilots.\nDuring the 1970s, the conversion of UH-2s to the SH-2 anti-submarine configuration provided the U.S. Navy with its first dedicated ASW helicopter capable of operating from vessels other than its aircraft carriers. The compact size of the SH-2 allowed the type to be operated from flight decks that were too small for the majority of helicopters; this factor would later play a role in the U.S. Navy's decision to acquire the improved SH-2F during the early 1980s.\nThe SH-2F fleet was utilized to enforce and support Operation Earnest Will in July 1987, Operation Praying Mantis in April 1988, and Operation Desert Storm during January 1991 in the Persian Gulf region. The countermeasures and additional equipment present upon the SH-2F allowed the type to conduct combat support and surface warfare missions within these hostile environments, which had an often-minimal submarine threat. In April 1994, the SH-2F was retired from active service with the U.S. Navy; the timing corresponded with the retirement of the last of the Vietnam-era Knox-class frigates that were unable to accommodate the new and larger SH-60 Sea Hawks, which were used to replace the aging Seasprites.\nIn 1991, the U.S. Navy had begun to receive deliveries of the new SH-2G Super Seasprite; a total of 18 converted SH-2Fs and 6 new-built SH-2Gs were produced. These were assigned to Naval Reserve squadrons, the SH-2G entered service with HSL-84 in 1993. The SH-2 served in some 600 deployments and flew 1.5 million flight hours before the last of the type were finally retired from US Navy service in mid-2001.\nNew Zealand.\nThe Royal New Zealand Navy (RNZN) replaced its Westland Wasps with an initial batch of four interim SH-2F Seasprites (formerly operated by the U.S. Navy), operated and maintained by a mix of Navy and Air Force personnel known as No. 3 Squadron RNZAF Naval Support Flight, to operate with ANZAC class frigates until the fleet of five new SH-2G(NZ) Super Seasprites were delivered. In October 2005, the Navy air element was transferred to No. 6 Squadron RNZAF at RNZAF Base Auckland in Whenuapai. RNZN Seasprites have seen service in East Timor. 10 of the 11 SH-2G(A)s rejected by the Royal Australian Navy were purchased in 2014 to replace the five RNZN SH-2G(NZ) Seasprites that had required either a MLU (Mid Life Upgrade) or replacement due to corrosion issues, maintenance problems and obsolescence. Kaman modified the ex-Australian aircraft and renamed them SH-2G(I), with the last one being delivered to New Zealand in early 2016. Eight of the aircraft are flying with the ninth and tenth aircraft being attritional aircraft used for spares etc. The 11th aircraft is held by Kaman as a prototype and test aircraft. The five SH-2G(NZ) have been sold to Peru. A SH-2F (ex-RNZN, NZ3442) is preserved in the Royal New Zealand Air Force Museum, donated to the museum by Kaman Aircraft Corporation after an accident while in service with the RNZN.\nRNAF uses the FN Mag 58 machine gun firing 7.62 mm, and it was fielded by 2008.\nExports.\nDuring the late 1990s, the United States decided to offer the surplus U.S. Navy SH-2Fs as foreign aid to a number of overseas countries. Among those to be offered the type included Greece, which had been offered six, and Turkey, which had been offered 14, but they rejected the offer.\nEgypt opted to acquire four SH-2F under this aid program, they were mainly used for spares in to support of their existing fleet of ten SH-2Gs. In the early 2000s, Australia acquired the SH-2G model, with ten delivered by 2007, 11 had been ordered in the late 1990s, but they only served from 2003 to 2008; the RAN consolidated on using the SH-60 Seahawk and was launching the MRH-90 Taipan program at the time. Poland chose to acquire the later SH-2G variant. Peru acquired Ex-RNZAF SH-2Gs and they entered service in the late 2010s.\n Anti-submarine warfare helicopter, powered by two 1,723 shp (1,285 kW) General Electric T700-GE-401 turboshaft engines.\nSpecifications (SH-2F Seasprite).\n\"Data from\" Jane's all the World's Aircraft 1976\u201377, Encyclopedia of world military aircraft : Volume OneGeneral characteristics* Crew: 3 (Pilot, Co-pilot/Tactical Coordinator (TACCO), Sensor Operator (SENSO))* Capacity: 1 pax with litter patient (with LAMPS installed) / 4 pax and two litter patients (with Sonobuoy launcher removed)* Fuel capacity: internal fuel tanks; auxiliary external fuel tanks.\nPerformance* Endurance: 5 hours with 2 external tanks\nArmament\nAvionics\nSee also.\nRelated development\nAircraft of comparable role, configuration, and era\nRelated lists\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "29477", "revid": "15756", "url": "https://en.wikipedia.org/wiki?curid=29477", "title": "Schlesien", "text": ""}
{"id": "29479", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=29479", "title": "Special Operations Forces", "text": ""}
{"id": "29480", "revid": "46271059", "url": "https://en.wikipedia.org/wiki?curid=29480", "title": "Plosive", "text": "Consonant in which the vocal tract is blocked so that all airflow ceases\nIn phonetics, a plosive, also known as an occlusive or simply a stop, is a pulmonic consonant in which the vocal tract is blocked so that all airflow ceases.\nThe occlusion may be made with the tongue tip or blade (, ), tongue body (, ), lips (, ), or glottis (). Plosives contrast with nasals, where the vocal tract is blocked but airflow continues through the nose, as in and , and with fricatives, where partial occlusion impedes but does not block airflow in the vocal tract.\nTerminology.\nThe terms \"stop, occlusive,\" and \"plosive\" are often used interchangeably. Linguists who distinguish them may not agree on the distinction being made. \"Stop\" refers to the stopping of the airflow, \"occlusive\" to the articulation which occludes (blocks) the vocal tract, and \"plosive\" to the plosion (release burst) of the consonant. Some object to the use of \"plosive\" for inaudibly released stops, which may then instead be called \"applosives\". The International Phonetic Association and the International Clinical Phonetics and Linguistics Association use the term \"plosive\".\nEither \"occlusive\" or \"stop\" may be used as a general term covering the other together with nasals. That is, 'occlusive' may be defined as oral occlusive (plosives and affricates) plus nasal occlusives (nasals such as , ), or 'stop' may be defined as oral stops (plosives) plus nasal stops (nasals). Ladefoged and Maddieson (1996) prefer to restrict 'stop' to oral non-affricated occlusives. They say,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;what we call simply nasals are called nasal stops by some linguists. We avoid this phrase, preferring to reserve the term 'stop' for sounds in which there is a complete interruption of airflow.\nIn addition, they restrict \"plosive\" for pulmonic consonants; \"stops\" in their usage include ejective and implosive consonants.\nIf a term such as \"plosive\" is used for oral non-affricated obstruents, and nasals are not called nasal stops, then a \"stop\" may mean the glottal stop; \"plosive\" may even mean non-glottal stop. In other cases, however, it may be the word \"plosive\" that is restricted to the glottal stop. Generally speaking, plosives do not have plosion (a release burst). In English, for example, there are plosives with no audible release, such as the in \"apt\". However, English plosives do have plosion in other environments.\nIn Ancient Greek, the term for plosive was (\"\u00e1ph\u014dnon\"), which means \"unpronounceable\", \"voiceless\", or \"silent\", because plosives could not be pronounced without a vowel. This term was calqued into Latin as , and from there borrowed into English as \"mute\". \"Mute\" was sometimes used instead for voiceless consonants, whether plosives or fricatives, a usage that was later replaced with \"surd\", from Latin \"deaf\" or \"silent\", a term still occasionally seen in the literature. For more information on the Ancient Greek terms, see .\nArticulation.\nA plosive is typically analysed as having up to three phases:\nOnly the hold phase is requisite. A plosive may lack an approach when it is preceded by a consonant that involves an occlusion at the same place of articulation, as in in \"end\" or \"old\". In many languages, such as Malay and Vietnamese, word-final plosives lack a release burst, even when followed by a vowel, or have a nasal release. See no audible release.\nCommon plosives.\nAll spoken natural languages in the world have plosives, and most have at least the voiceless plosives , , and . However, there are exceptions: Colloquial Samoan lacks the coronal , and several North American languages, such as the Iroquoian languages (e.g., Mohawk and Cherokee), and Arabic lack the labial . In fact, the labial is the least stable of the voiceless plosives in the languages of the world, as the unconditioned sound change \u2192 (\u2192 \u2192 ) is quite common in unrelated languages, having occurred in the history of Classical Japanese, Classical Arabic, and Proto-Celtic, for instance. Formal Samoan has only one word with velar ; colloquial Samoan conflates and to . Ni\u02bbihau Hawaiian has for to a greater extent than Standard Hawaiian, but neither distinguish a from a . It may be more accurate to say that Hawaiian and colloquial Samoan do not distinguish velar and coronal plosives than to say they lack one or the other. \nOntena Gadsup has only 1 phonemic plosive . Yanyuwa distinguishes plosives in 7 places of articulations (it does not have voiceless plosives) which is the most out of all languages.\nSee Common occlusives for the distribution of both plosives and nasals.\nClassification.\nVoice.\nVoiced plosives are pronounced with vibration of the vocal cords, voiceless plosives without. Plosives are commonly voiceless, and many languages, such as Mandarin Chinese and Hawaiian, have only voiceless plosives. Others, such as most Australian languages, are indeterminate: plosives may vary between voiced and voiceless without distinction, some of them like Yanyuwa and Yidiny have only voiced plosives.\nAspiration.\nIn aspirated plosives, the vocal cords (vocal folds) are abducted at the time of release. In a prevocalic aspirated plosive (a plosive followed by a vowel or sonorant), the time when the vocal cords begin to vibrate will be delayed until the vocal folds come together enough for voicing to begin, and will usually start with breathy voicing. The duration between the release of the plosive and the voice onset is called the \"voice onset time\" (VOT) or the \"aspiration interval\". Highly aspirated plosives have a long period of aspiration, so that there is a long period of voiceless airflow (a phonetic ) before the onset of the vowel. In tenuis plosives, the vocal cords come together for voicing immediately following the release, and there is little or no aspiration (a voice onset time close to zero). In English, there may be a brief segment of breathy voice that identifies the plosive as voiceless and not voiced. In voiced plosives, the vocal folds are set for voice before the release, and often vibrate during the entire hold, and in English, the voicing after release is not breathy. A plosive is called \"fully voiced\" if it is voiced during the entire occlusion. In English, however, initial voiced plosives like or may have no voicing during the period of occlusion, or the voicing may start shortly before the release and continue after release, and word-final plosives tend to be fully devoiced: In most dialects of English, the final /b/, /d/ and /g/ in words like \"rib\", \"mad\" and \"dog\" are fully devoiced. Initial voiceless plosives, like the \"p\" in \"pie\", are aspirated, with a palpable puff of air upon release, whereas a plosive after an \"s\", as in \"spy\", is tenuis (unaspirated). When spoken near a candle flame, the flame will flicker more after the words \"par, tar,\" and \"car\" are articulated, compared with \"spar, star,\" and \"scar\". In the common pronunciation of \"papa\", the initial \"p\" is aspirated whereas the medial \"p\" is not.\nLength.\nIn a geminate or long consonant, the occlusion lasts longer than in simple consonants. In languages where plosives are only distinguished by length (e.g., Arabic, Ilwana, Icelandic), the long plosives may be held up to three times as long as the short plosives. Italian is well known for its geminate plosives, as the double \"t\" in the name \"Vittoria\" takes just as long to say as the \"ct\" does in English \"Victoria\". Japanese also prominently features geminate consonants, such as in the minimal pair \u6765\u305f \"kita\" 'came' and \u5207\u3063\u305f \"kitta\" 'cut'. Estonian is unusual for contrasting three lengths, as in the minimal triplet \"kabi\" 'hoof', \"kapi\" 'wardrobe [gen. sg.]', and \"kappi\" 'wardrobe [ill. sg.]'.\nThere are many languages where the features voice, aspiration, and length reinforce each other, and in such cases it may be hard to determine which of these features predominates. In such cases, the terms fortis is sometimes used for aspiration or gemination, whereas lenis is used for single, tenuous, or voiced plosives. However, the terms \"fortis\" and \"lenis\" are poorly defined, and their meanings vary from source to source.\nNasalization.\nSimple nasals are differentiated from plosives only by a lowered velum that allows the air to escape through the nose during the occlusion. Nasals are acoustically sonorants, as they have a non-turbulent airflow and are nearly always voiced, but they are articulatorily obstruents, as there is complete blockage of the oral cavity. The term occlusive may be used as a cover term for both nasals and plosives.\nA prenasalized stop starts out with a lowered velum that raises during the occlusion. The closest examples in English are consonant clusters such as the [nd] in \"candy\", but many languages have prenasalized stops that function phonologically as single consonants. Swahili is well known for having words beginning with prenasalized stops, as in \"ndege\" 'bird', and in many languages of the South Pacific, such as Fijian, these are even spelled with single letters: \"b\" [mb], \"d\" [nd].\nA postnasalized plosive begins with a raised velum that lowers during the occlusion. This causes an audible nasal \"release\", as in English \"sudden\". This could also be compared to the /dn/ cluster found in Russian and other Slavic languages, which can be seen in the name of the Dnieper River.\nThe terms \"prenasalization\" and \"postnasalization\" are normally used only in languages where these sounds are phonemic: that is, not analyzed into sequences of plosive plus nasal.\nAirstream mechanism.\nStops may be made with more than one airstream mechanism. The normal mechanism is pulmonic egressive, that is, with air flowing outward from the lungs. All spoken languages have pulmonic stops. Some languages have stops made with other mechanisms as well: ejective stops (glottalic egressive), implosive stops (glottalic ingressive), or click consonants (lingual ingressive).\nTenseness.\nA fortis plosive is produced with more muscular tension than a lenis plosive. However, this is difficult to measure, and there is usually debate over the actual mechanism of alleged fortis or lenis consonants.\nThere are a series of plosives in the Korean language, sometimes written with the IPA symbol for ejectives, which are produced using \"stiff voice\", meaning there is increased contraction of the glottis than for normal production of voiceless plosives. The indirect evidence for stiff voice is in the following vowels, which have a higher fundamental frequency than those following other plosives. The higher frequency is explained as a result of the glottis being tense. Other such phonation types include breathy voice, or murmur; slack voice; and creaky voice.\nTranscription.\nThe following plosives have been given dedicated symbols in the IPA.\nVariations.\nMany subclassifications of plosives are transcribed by adding a diacritic or modifier letter to the IPA symbols above.\nExternal links.\n&lt;templatestyles src=\"IPA common/styles.css\" /&gt;&lt;templatestyles src=\"IPA pulmonic consonants/styles.css\" /&gt;&lt;templatestyles src=\"IPA co-articulated consonants/styles.css\" /&gt;&lt;templatestyles src=\"IPA vowels/styles.css\" /&gt;"}
{"id": "29482", "revid": "1316031161", "url": "https://en.wikipedia.org/wiki?curid=29482", "title": "Stayman convention", "text": "Bidding convention in contract bridge\nStayman is a bidding convention in the card game contract bridge. It is used by a partnership to find a 4-4 or 5-3 trump fit in a major suit after making a one notrump (1NT) opening bid and it has been adapted for use after a 2NT opening, a 1NT overcall, and many other natural notrump bids.\nThe convention is named for Sam Stayman, who wrote the first published description in 1945, but its inventors were two other players: the British expert Jack Marx in 1939, who published it only in 1946, and Stayman's regular partner George Rap\u00e9e in 1944.\nRationale.\nA game contract bid and made in a major suit (i.e. 4&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665 or 4 &lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660) scores better than a game contract bid and made in a minor suit (i.e. 5&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 or 5 &lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666) or in notrump (i.e. 3NT). Also, the success rate for a game contract in a major suit when a partnership has a combined holding of 26 points and eight cards in the major is about 80%, whereas a game contract in 3NT with 26 high card points (HCP) has a success rate of only 60%, or 50% with 25 HCP; the success rate for a minor suit game contract when holding 26 points is about 30%.\nAccordingly, partnership priority is to find an eight card or better major suit fit when jointly holding sufficient values for a game contract. 5-3 and 6-2 fits are easy to find in basic methods as responder can bid 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665 or 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 over 1NT, and opener will not normally have a 5 card major to bid 1NT. However, finding 4-4 fits presents a problem. The 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665 and 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 bids cannot be used for this as they are weak takeouts, a sign-off bid.\nStandard Stayman.\nAfter an opening bid or an overcall of 1NT (2NT), responder or advancer bids an artificial 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 (3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663) to ask opener or overcaller if he holds a four- or five-card major suit; some partnership agreements may require the major to be headed by an honor of at least a specified rank, such as the queen. The artificial club bid typically promises four cards in at least one of the major suits (promissory Stayman) and, \"in standard form\", enough strength to continue bidding after partner's response (8 HCP for an invitational bid opposite a standard strong 1NT opening or overcall showing 15-17 HCP, 11 HCP opposite a weak notrump of 12-14 HCP, or 5 HCP to go to game opposite a standard 2NT showing 20-21 points). It also promises distribution that is not 4333. By invoking the Stayman convention, the responder takes control of the bidding since strength and distribution of the opener's hand is already known within a limited range. The opener responds with the following rebids.\nA notrump opener should have neither a suit longer than five cards nor more than one 5-card suit since an opening notrump bid shows a balanced hand. A notrump bidder who has at least four cards in each major suit normally responds in hearts, as this can still allow a spade fit to be found. Variant methods are to bid the longer or stronger major, with a preference given to spades, or to use 2NT to show both majors.\nIn the standard form of Stayman over 1NT, the responder has a number of options depending on his partner's answer:\nOver these bids, the notrump bidder (1) with a maximum hand (17 HCP), goes to game over an invitational bid and (2) with four (or more) cards in each major suit, corrects to the previously unbid major suit.\nIn the standard form of Stayman over 2NT, the responder has only two normal rebids.\nIn either case, a responder who rebids notrump over a response in a major suit promises four cards of the other major suit. Thus, a notrump opener who holds at least four cards in each major suit should \"correct\" by bidding the other major suit at the lowest level.\nOf course, once a fit is found, responder who has sufficient strength also may bid 4&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 (Gerber) or 4NT (Blackwood), or cue bid aces, depending upon partnership agreement, to explore slam in any of the above sequences. Some partnerships also admit responder's rebids of a major suit that the notrump bidder did not name.\nA bid of 4&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 over an opening bid of 3NT may be either Stayman or Gerber, depending upon the partnership agreement.\nIf an adverse suit bid is inserted immediately after a 1NT opening, Stayman may be employed via a double (by partnership agreement) or a cue bid, depending on the strength of his hand. The cue bid, which is conventional, is completely artificial and means nothing other than invoking Stayman. For example, if South opens 1NT, and West overcalls 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666, North, if he has adequate values, may call 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666, invoking Stayman. South would then show his major or bid game in notrump. Alternatively, North, if his hand lacks the values for game in notrump, may double, which by partnership agreement employs Stayman. This keeps the Stayman bidding at second level.\nPartnerships who have not yet learned Stayman but choose to adopt Stayman (without having yet learned or having chosen not to use Jacoby Transfers) will need to adjust their use of normal two-level responses after a 1NT opening, because the availability of this convention changes the nature of what had been normal 1NT responses. When the notrump bidder's partner does not invoke Stayman but instead calls 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665 or 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660, it is a sign of relative weakness (since if responder held 8 HCP or more, he would have invoked Stayman). These bids are commonly referred to as \"drop dead bids\", as the opening notrump bidder is requested to withdraw from the auction. If opener has maximum values, a fit, and strong support, he may raise to the 3-level, but under no circumstances may he take any other action. This provides the partnership with an advantage that the non-Stayman partnership doesn't enjoy. For example, a responder may have no honors at all; that is, a total of zero HCP. His partner is likely to be set if he passes. A non-Stayman responder would have to pass, because to bid would provoke a rebid. But a Stayman responder can respond to his partner's 1NT opening at level 2 if he has a 6-card non-club suit. The responder with 3 HCP and a singleton can make a similar call with a 5-card non-club suit. This gives the partnership a better than even chance of success in making the contract, whereas without a response (and without Stayman), the contract would likely be set.\nSimilarly, a response of 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 indicates less than 8 HCP and should usually be passed. In rare cases, when the opener has maximum values and a fit in diamonds with at least two of the top three honors, he may raise diamonds, and responder may see a chance for game in notrump.\nThere are many variations on this basic theme, and partnership agreement may alter the details of its use. It is one of the most widely used conventions in bridge.\nNon-promissory Stayman and 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 checkback by responder.\nSome partnerships play that 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 Stayman does not absolutely promise a four-card major (non promissory Stayman). For example, if responder has a short suit and wishes to know if opener has four-card cover in it, so as to play in no-trumps. If opener shows hearts initially, 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 can be used to find a fit in spades when the 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 does not promise a four-card major.\n1NT - 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663, 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665 -\nAlternatively 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 can be used for all hands with four spades and not four hearts, either invitational or game values, while 3NT denies four spades.\nUsing Jacoby transfers with Stayman.\nToday, most players use Stayman in conjunction with Jacoby transfers. With Stayman in effect, the responder practically denies having a five-card major, as otherwise he would transfer to the major immediately. The only exception is when responder has 5-4 in the majors; in that case, he could use Stayman, and in the case of a 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 response, bid the five-card major at the two level (weakness take-out / Garbage Stayman) or at the three level (forcing to game). However, the latter hand can also be bid by first using a transfer and then showing the second suit naturally. The Smolen convention provides an alternative method to show a five-card major and game-going values. A minor drawback of Jacoby transfers is that a 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 contract is not possible.\nSmolen convention.\nThe Smolen convention is an adjunct to Stayman for situations in which the notrump opener has denied holding a four-card major and responder has a five-card major and a four-card major with game-going values.\nIf the notrump opener responds to the Stayman 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 asking bid with 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666, denying a four-card major, responder initiates the Smolen Transfer with a jump shift to three of his four-card major. The jump shift shows which is the four-card major and promises five in the other major. The notrump opener then bids four of the other major with three cards in the suit or 3NT with fewer than three.\nSmolen may also be used when responder has a six-card major and a four-card major with game-going values; after the 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 negative response by opener, responder double jump shifts to four in the suit just below his six-card major and the notrump opener transfers to four of his partner's six-card major.\nThis convention allows a partnership to find either a 5-3 fit, 6-3 and 6-2 fit while ensuring that the notrump opener, who has the stronger hand, will be declarer.\nGarbage Stayman and crawling Stayman.\n\"Garbage\" Stayman (or \"Weak Stayman\" or \"Rescue Stayman\") and \"Crawling\" Stayman are adaptations of Stayman frequently used for damage control when holding a weak hand opposite a 1NT opening bid. For example, on the following hand.\nPartner opens 1NT (15-17), and right hand opponent passes. Opponents have 23-25 HCP. Thus, 1NT is virtually certain to go down by at least three or four tricks. Indeed, in No-trumps, this dummy will be completely worthless.\nIn \"Garbage Stayman\", you bid 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 Stayman with this \"garbage\" hand rather than passing on the first round, and then \"pass opener's response\". If opener rebids a major suit you have found a 4-4 fit and ability to trump club losers. Likewise, a response of 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 guarantees no worse than a 5-2 fit in diamonds and, with a fifth trump, a potential additional ruff. Declarer can also reach dummy with ruffs and may then be able to take finesses or execute a squeeze that otherwise would not be possible. The result is a contract that will go down fewer tricks or may even make, rather than a contract that is virtually certain to go down at least three or four tricks. However the hand must be able to tolerate any rebid from opener.\n\"Crawling Stayman\" is an optional extension of \"Garbage Stayman\" for situations in which the responder's diamond suit is short. In \"Crawling Stayman\", the responder rebids 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665 over the Notrump bidder's 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 reply. This conventional bid shows a weak hand with at least four cards in each major suit, asking the Notrump bidder to choose between the major suits at the cheapest level by either passing the 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665 bid or correcting to 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660. The name \"Crawling Stayman\" comes from the fact that the bidding \"crawls\" at the slowest possible pace: (pass) \u2013 1NT \u2013 (pass) \u2013 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663; (pass) \u2013 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 \u2013 (pass) \u2013 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665; (pass) \u2013 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660; (pass) \u2013 pass \u2013 (pass).\nAlternatively, responder's 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665 and 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 bids after the 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 rebid can be weak sign-offs. This allows responder to effectively bid hands which are 5-4 in the majors, by looking first for a 4-4 fit and, if none is found, signing off in his 5 card suit.\n\"Garbage Stayman\" is even more useful opposite a weak NT opening (12-14) as it occurs more frequently and can mitigate very expensive penalties if responder is weak. It is in frequent use in Acol.\n\"Garbage Stayman\" and \"Crawling Stayman\" bids over a 2NT bid work the same way, but occur at the \"three\" level.\nDisadvantage is that it tells the opponents the opener\u2019s distribution.\nDon\u2019t apply 2NT as showing both majors. Instead use 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665.\nForcing and non-forcing Stayman.\nIf Jacoby transfers are not played, there are two approaches to resolve the situation when responder has a 5-card major but only invitational values. In one, more common, referred to as \"non-forcing Stayman\", in the sequence:\n1NT \u2013 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663; 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 \u2013 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660\nresponder's simple rebid of a major suit is invitational, showing 8-9 points and a 5-card spade suit. In the \"forcing Stayman\" variant, the bid is one-round forcing.\nIn the original Precision Club system, forcing and non-forcing Stayman are differentiated in the start: 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 by responder shows only invitational values (and the continuation is the same as in basic Stayman), while 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 is forcing to game (responder bids 2NT without majors).\nNon promissory game forcing Stayman.\nThis allows responder to find exact shape of 1NT opener. Developed for use with weak 1 NT opening. Relay bids over opener's rebids of 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666, 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665, 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660, 2NT, 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 allow shape to be defined further if attempting to find 5-3 major fits. Advantages are responder's shape, which may be any distribution, is undisclosed, and responder is able to locate suit shortage holdings not suitable for no trumps.\n1NT \u2013 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663\nDeveloped to be used in combination with following other responses to 1NT: 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666, 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665 Jacoby transfers to majors; 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 range finder/transfer to minors (opener's rebids: 2NT 12-13 HCP, 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 14 HCP. Responder passes or corrects to 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 or 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 sign off if weak. After opener's 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 rebid responder bids 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665 to show 4 hearts or 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 to show 4 spades both game forcing. Responder's rebid of 3NT denies 4 card major); 2NT invitational hand with both 4 card majors (opener's rebids: no bid no 4 card major 12-13 HCP, 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 4 hearts 12-13 HCP, 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 4 spades 12-13 HCP, 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665 4 hearts 14 HCP, 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 4 spades 14 HCP, 3NT 14 HCP no 4 card major).\nDisadvantage is that it tells the opponents the opener\u2019s distribution.\nFour card major non promissory relay Stayman.\nThis allows responder to find exact shape of 1NT opener that may only contain a four-card major. Developed for use with weak 1 NT opening. Relay bids over opener's rebids of 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666, 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665, 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 allow shape to be defined further if attempting to find 5-3 major fits. Advantages are responder's shape, which may be any distribution, is undisclosed, and responder is able to locate suit shortage holdings not suitable for notrumps. May be also used as a damage control bid, and for both invitational, and game forcing hands.\n1NT \u2013 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663\n1NT \u2013 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 weak sign off.\nOpener's rebids of 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666, 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665, 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 may all be passed if responder is weak.\nDeveloped to be used in combination with following other responses to 1NT: 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666, 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665 Jacoby transfers to majors; 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 five spades four hearts 10-11 HCP; 2NT invitational hand with 5,5 minors 10-11 HCP.\nFive card major non promissory relay Stayman.\nThis allows responder to find exact shape of 1NT opener that may contain a 5 card major. Developed for use with weak 1NT opening. Relay bids over opener's rebids of 2D, 2H, 2S allow shape to be defined further if attempting to find 5-3 major fits. Advantages are responder's shape, which may be any distribution, is undisclosed, and responder is able to locate suit shortage holdings not suitable for no trumps. May be also used as a damage control bid, and for both invitational, and game forcing hands.\n1NT \u2013 2C\nOpener's rebids of 2D, 2H, 2S may all be passed if responder is weak.\nDeveloped to be used in combination with following other responses to 1NT: 2D, 2H Jacoby transfers to majors; 2S range finder/transfer C; 2NT invitational hand with 5,5 minors 10-11 HCP.\nFive-card major Stayman.\nThis allows responder to check for 5-3 major fits where it is possible that opener's 1NT or 2NT might include a five-card major. As described by Australian Ron Klinger, it can be played with a weak or strong 1NT.\n1NT - 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663\n1NT - 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663; 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666/2NT\nAfter a transfer, accept it with any 4333, bid 3NT with only two trumps, otherwise bid 4M.\n1NT - 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663; 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666/2NT - 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 = Stayman\n1NT - 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663; 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666/2NT - 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663, 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666\nAn alternative, simpler version of five-card Stayman is:\n1NT - 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663\nThis structure permits use by weak hands with 5+ diamonds and 2+ cards in each major.\nAfter 1NT - 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663; 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666\nIf responder has a five-card major, he begins with a transfer. After completion of the transfer, bidding the other major at the three level shows four cards in it and a game forcing hand, in line with the 1NT - 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663, 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 structure above (1NT - 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666, 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665 - 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 = invitational 5&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665-4&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660).\nSimilarly after 2NT - 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663; 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666\nA drawback of Five-Card Major Stayman (particularly the simpler version) is that the weaker hand may become declarer in a 4-4 major fit.\nPuppet Stayman.\nPuppet Stayman is similar to Five-Card Stayman. It is more complex but has the major advantage that the strong hand virtually always becomes declarer.\nInitially developed by Neil Silverman and refined by Kit Woolsey and Steve Robinson in 1977-78, is a variation of the Stayman convention designed to find a 5-3 fit in a major, augmenting the search for a 4-4 major fit by standard Stayman. In 1977, Woolsey wrote that Puppet Stayman has several advantages over standard Stayman:\nResponder's rebids.\nAs in standard Stayman, Puppet Stayman begins with a 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 response to a 1NT opening and is at least game invitational; this asks opener to bid a 5-card major if he has one and otherwise to bid 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666. Over a 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 response, rebids by responder are intended to disclose his distributional features in the majors as well as his strength. The original 1977 and 1978 revised rebids described by Woolsey are tabulated below: \nOpener and responder continue the bidding having a clearer understanding of each other's distributional features and are better positioned to select the ultimate denomination and level of the contract.\nModern applications.\nMany variations to the Puppet Stayman bidding structure have been devised since Woolsey's 1978 summary; partnership review and agreement on the preferred modern treatment is required.\nSome no longer advocate use of Puppet Stayman over a 1NT opening preferring to use the concept exclusively over a 2NT opening and reserving other Stayman variations and conventions such Jacoby Transfers and Smolen Transfers in search of major-suit fits after a 1NT opening.\nResponses to a 2NT opening or rebid.\nPuppet Stayman is more commonly used after a 2NT opening than after a 1NT opening. Responses to a 2NT opening or very strong 2NT rebid (20-22 or 23-24):\nResponder bids 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 seeking information about opener's major suit holding. Opener replies:\nBy this means all 5-3 and 4-4 major suit fits can be found.\nAn alternative pattern frees up the 2NT-3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 sequence as a slam try in the minors. To allow 3-5 spade fits to be found when responder holds 5 spades and 4 hearts, some of the responses change:\nCheckback Stayman.\n2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 Checkback Stayman (or simply Checkback) is used after a 1NT rebid by opener rather than a 1NT opening. It is used to \"check back\" if opener has major suit support, saying nothing additional about the club suit. It can find 3-5 fits, 4-4 fits (in Standard American) and 5-3 fits (in Acol), and also shows whether opener was maximum or minimum strength for his notrump bid. In five-card major systems, bidding Checkback implies that the responder has five cards in his major, and may have four in the other.\n1m \u2013 1M; 1NT \u2013 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663\nThe 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 is \"Checkback Stayman\". Responses by opener shows the following:\n2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666: No three-card support for partner's major, no four-card holding in the other major and a minimum hand.\n2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665/&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660: Bidding responder's major shows three-card support and a minimum hand; bidding the other major shows four cards and a minimum hand.\n2NT: No three-card support for partner's major, no four-card holding in the other major and a maximum hand.\n3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665/&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660: Bidding responder's major shows three-card support and a maximum hand; bidding the other major shows four cards and a maximum hand.\nPartnership agreement is required on how to handle the case of holding four of the other major and three of partner's suit. One could agree to bid up the line, or support partner's suit first. If partner cannot support your first suit, he will invite with 2NT or bid game with 3NT and you will then correct to your other suit.\nIn Acol, if the opening bid was a major, opener can rebid his major after a Checkback inquiry to show that it has five cards rather than four and find 5-3 fits. Moreover, 1M \u2013 2m; 2NT \u2013 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 can also be used as Checkback Stayman. It is useful also to include an indication of range, particularly if opener's 2NT rebid is forcing to game and shows a wide points range (15-19). This is achieved by using 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 for minimum hands and 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665/3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660/3NT for maximum hands, or vice versa. After 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666, responder can still bid 3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2665/3&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2660 to look for a 5-3 fit.\nNew Minor Forcing is an alternative to Checkback Stayman where either 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2663 or 2&lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;\u2666 can be used as the checkback bid. It can be used by responder with invitational values or better to find three-card support for his major or to find a 4-4 heart fit if holding five spades and four hearts; it also allows a return to the minor to play.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29483", "revid": "1319282476", "url": "https://en.wikipedia.org/wiki?curid=29483", "title": "Saks Fifth Avenue", "text": "American international department store chain\nSaks Fifth Avenue (colloquially Saks) is an upmarket American department store chain founded in 1867 by Andrew Saks. The first store opened in the F Street shopping district of Washington, D.C., and expanded into Manhattan with its Herald Square store in 1902. Saks was bought by the Gimbels department store chain in 1923 and expanded nationwide during this ownership, and opened its flagship store on Fifth Avenue in 1924. Gimbels and Saks were acquired by Brown &amp; Williamson in 1973, and transferred to sister company Batus Inc. in 1980. While Gimbels was liquidated in 1987, Saks was sold to Investcorp in 1990. Saks Off 5th was established as a Saks clearance store the same year, and has since evolved into an off-price store chain. Saks was acquired by Proffitt's, Inc. (renamed Saks, Inc.) in 1998.\nSaks, Inc. was acquired by the Hudson's Bay Company in 2013. Saks and Saks Off 5th were spun-off into Saks Global, and consequently became sister brands with department stores Bergdorf Goodman and Neiman Marcus, in 2024. Current expansions beyond the United States include the Middle East, while previous expansions include Mexico through a franchising agreement with Grupo Sanborns from 2007 until 2023, and Canada through whole ownership from 2016 until 2025.\nEarly history.\nAndrew Saks was born to a German Jewish family, in Baltimore, Maryland. He worked as a peddler and paper boy before moving to Washington, D.C., where at the age of only 20, and in the still-chaotic and tough economic times of 1867, two years after the United States prevailed in the American Civil War, he established a men's clothing store with his brother Isadore. A. Saks &amp; Co. occupied a storefront in the Avenue House Hotel building at 517 (300\u2013308) 7th Street, N.W., in what is still Washington's downtown shopping district. Saks offered his goods at one price only, no bargaining, and offered refunds on merchandise returns, neither of which were the more common practice at that place and time. Saks was also known for its \"forceful and interesting, but strictly truthful\" newspaper advertising, according to the Washington \"Evening Star\", including a two-page spread, large for that time, in that newspaper on April 4, 1898. Saks annexed the store next door, and in 1887 started building a large new store on the site of the old Avenue Hotel Building at 7th and Market Space (now United States Navy Memorial Plaza).\nBy 1896, Saks and Co. had stores in Norfolk and Richmond, Virginia; New York City; and Indianapolis, in addition to Washington, D.C., where, Saks called itself \"Washington's Wonderful Store\".\n20th century history.\nSaks opened a very large store in 1902 in New York City's Herald Square on 34th Street and Broadway. Andrew Saks ran the New York store as a family business with his brother Isadore, and his sons Horace and William. Andrew Saks died in 1912 and his son Horace took over the company's management.\nGimbels ownership.\nIn 1923, Saks &amp; Co. merged with Gimbel Brothers, Inc., which was owned by a cousin of Horace Saks, Bernard Gimbel, operating as a separate autonomous subsidiary. On September 15, 1924, Horace Saks and Bernard Gimbel opened in the Saks Fifth Avenue Building at 611 Fifth Avenue, with a full-block avenue frontage south of St. Patrick's Cathedral, facing what would become Rockefeller Center. The architects were Starrett &amp; van Vleck, who developed a design derived from classical architecture.\nWhen Bernard's cousin, Adam Gimbel, became president of Saks Fifth Avenue in 1926 after Horace Saks's sudden death, the company expanded, opening seasonal resort branches in Palm Beach (1926), Atlantic City (1927), Lincoln Road in Miami Beach (1929), Southampton on Long Island (1931), Newport, Rhode Island (1935), Sun Valley, Idaho and Westbury, L.I. (1936), and Greenwich, Connecticut (1937).\nIn 1929, Saks opened its first full-line, year-round flagship store in Chicago, and only six years later moved to a larger location. By the end of the 1930s, Saks Fifth Avenue had a total of 10 stores \u2013 the 2 large urban flagships in New York and Chicago, and 8 resort stores.\nDuring World War Two, Saks opened Navy and Army shops in New Haven, Connecticut and Princeton, New Jersey, and after the war turned the small branches into University Shops, catering to the Ivy League communities there. More University Shops would open, one near Harvard in Cambridge, Mass., another in Ann Arbor, Michigan (1960). Saks had already opened two urban flagship stores before the U.S. joined the war: its now-legendary store in Beverly Hills, and in Detroit (1940). After the war, three more downtown stores opened, albeit smaller in scale: Pittsburgh (1949), Philadelphia (1952), and San Francisco (1952) where Saks competed head-on with local luxury champion I. Magnin.\nDuring the 1950s, the shift from downtown shopping to suburban shopping malls gained momentum. Saks Fifth Avenue's first anchor department store in a mall in 1954, at Sunrise Center, now The Galleria at Fort Lauderdale. A few of the new suburban stores were freestanding in suburbs that had a significant downtown shopping district, such as in White Plains, New York (1954) and both Garden City, Long Island and Surfside, near Miami in 1962. A few were in malls built in downtowns, such as New Orleans, Boston, and Minneapolis. But most new Saks stores, dozens, opened in malls over the decades through the 1990s.\nAcquisition by Brown &amp; Williamson and Batus.\nMore expansion followed through in the 1990s particularly into Texas, Florida and California. Plans to open in Mexico City were also scrapped following the Mexican peso crisis in 1995. the store was set to open at the Moli\u00e8re222 mall in Polanco, El Palacio de Hierro then took over the site where they still operate. California-based I. Magnin closed in 1995, allowing Saks to acquire some of their locations and open in San Diego's Fashion Valley and expand in Carmel. As in the 1950s, the company opened a wave of smaller \"Main Street\" stores in suburbs with downtown shopping, such as Pasadena, Santa Barbara, and San Diego's La Jolla in California, and in Greenwich, Connecticut, and Charleston, South Carolina. In Texas, Saks acquired three Texas locations where Marshall Field's was exiting. In 1997 Saks moved its main Houston store from the Saks Pavilion to The Galleria and added a new location at Town &amp; Country. In the Dallas Galleria, Saks moved within the mall to a larger location. In addition to the former Field's locations, Saks Austin opened in 1997 and Fort Worth in 2000.\nIn Florida in the 1990s, 7 Saks Fifth Avenue stores opened, for a total of 11 stores by the end of the decade, adding Palm Beach Gardens, Naples, Fort Myers, Orlando, Sarasota, Tampa and doubled the size of its Boca Raton store.\nAcquisition by Investcorp and Proffitt's.\nAlso in 1990, the company launched \"Saks Off 5th\", an outlet store offshoot of the main brand, with 107 stores worldwide by 2016.\nIn 1998, Proffitt's, Inc. the parent company of Proffitt's and other department stores, acquired Saks Holdings Inc. Upon completing the acquisition, Proffitt's, Inc. changed its name to Saks, Inc.\n21st century history.\nIn 2004, Saks was enjoying an annual sales growth rate of 7.7% on a same-store basis, but was underperforming Neiman Marcus (+17%) and Nordstrom (+10%). In Southern California, analysts said that Saks was \"struggling to maintain its cachet\" against the two competitors and Bloomingdales. On October 1, Saks announced the closing of 8 underperforming, mostly smaller Saks stores: Pasadena, Palos Verdes, Mission Viejo, La Jolla and Carmel in California, Garden City NY, Hilton Head SC, and Downtown Minneapolis.\nIn August 2007, the United States Postal Service began an experimental program selling the plus ZIP code extension to businesses. The first company to do so was Saks Fifth Avenue, which received the ZIP code of 10022-7463 (\"SHOE\", on a U.S. touch-tone keypad) for the eighth-floor shoe department in its flagship Fifth Avenue store.\nDuring the 2007\u20132009 recession, Saks had to cut prices and profit margins, thus according to Reuters \"training shoppers to expect discounts. It took three years before it could start selling at closer to full price\".\nAs of 2013, the New York flagship store, whose real estate value was estimated between $800 million and over $1 billion at the time, generated around 20% of Saks' annual sales at $620 million, with other stores being less profitable according to analysts.\nUnder Hudson's Bay Company (2013\u20132024).\nOn July 29, 2013, Canada-based Hudson's Bay Company (HBC), the oldest commercial corporation in North America and owner of the competing chain Lord &amp; Taylor, announced it would acquire Saks Fifth Avenue's parent company for US$2.9 billion.\nIn 2015 Saks began a $250 million, three-year restoration of its Fifth Avenue flagship store. In October 2015, Saks announced a new location in Greenwich, Connecticut. In autumn 2015, Saks announced it would replace its existing store at the Houston Galleria with a new store.\nOn January 15, 2021, Saks Fifth Avenue unveiled a space on the fifth floor of its New York flagship, branded \"Barneys at Saks\". The collaboration is aimed at continuing Barneys New York tradition of unearthing and promoting emerging designers. On January 25, Saks launched the first standalone Barneys at Saks store in a location in Greenwich, Connecticut. This marked the first time Saks had offered men's clothing and furnishings in that market. In March, HBC and growth capital investor, Insight Partners, established Saks Fifth Avenue's ecommerce business as a stand-alone entity, known as \"Saks\". Insight Partners made a $500 million minority equity investment in Saks. The retailer's 39-store fleet operates separately as an entity referred to as \"SFA,\" which remains wholly owned by HBC. At the time of the separation, HBC named Marc Metrick, CEO of Saks, the ecommerce business. Metrick was previously president of Saks Fifth Avenue since 2015.\nIn April, Saks announced that it would close all 27 of its fur salons, among which New York, Boston, Philadelphia and Beverly Hills, by the end of January 2022. The company also said that by January 2023, it would stop sales of products made from fur of wild animals or from animals raised for their fur. In August, the company announced a collaboration with WeWork to convert some Saks spaces to co-working locations. In June 2022, Saks announced that it would convert the original 1938 store building in Beverly Hills, 9600 Wilshire, into offices and apartments. Saks Beverly Hills continues to operate from the former I. Magnin and Barneys buildings, which had previously been incorporated into the store complex.\nUnder Saks Global (2024\u2013present).\nIn July 2024 Saks announced that it planned to acquire rival retailer Neiman Marcus in a reported $2.65 billion merger. The acquisition was finalised in December 2024 and Saks Fifth Avenue became part of the new holding company Saks Global.\nInternational expansions.\nCanada.\nCanada expansion plans were drafted with the acquisition by HBC in 2013, calling for up to seven Saks stores across the country, of which three eventually opened. In February 2016, it opened a Saks Fifth Avenue in downtown Toronto, in a section carved out of the building housing the flagship of its namesake department store, Hudson's Bay Company, connected by sky bridge to the largest downtown mall, Eaton Centre. A second Greater Toronto location opened at Sherway Gardens shortly thereafter. And in February 2018, its third Canadian store opened in Calgary at Chinook Centre.\nOn March 14, 2025, shortly after the bankruptcy and collapse of Hudson's Bay, it was announced that Hudson's Bay would be liquidating and shuttering two of the three Saks Fifth Avenue locations in Canada and all 13 Saks Off 5th locations in Canada. Liquidation sales are set to begin as soon as the following week, with locations to be permanently shuttered by June 2025. The Calgary store also eventually shut down.\nIndia.\nA franchise agreement was signed with Reliance Industries in early 2025 to open Saks Fifth Avenue and Saks Off 5th stores in India.\nMexico.\nIn November 2007, Grupo Sanborns, part of billionaire Carlos Slim's corporate empire, secured a franchise and opened the first Saks store in Mexico, on the affluent far west side of Mexico City at Centro Santa Fe, that country's largest mall. The store closed in 2022. Another store opened in the affluent urban neighborhood of Polanco at Plaza Carso in 2010, but it closed in October 2020.\nIn August 2023, Grupo Sanborns announced that in 2023, it would close its Saks franchise store at Centro Santa Fe in Mexico City, the only store still operating in Mexico after the closure of the Polanco store two years earlier. A branch of Sears Mexico, also part of Grupo Sanborns, was to replace it, and staff were to be retained.\nMiddle East.\nIn November 2001 the first Middle East Saks opened at Kingdom Centre in Riyadh, Saudi Arabia. The store closed in 2012. In 2003 plans for stores in Bahrain, Kuwait, Qatar and the United Arab Emirates were announced following the signing of licensing agreements, along with plans for 5 to 10 stores across Japan. Saks was also looking at sites in Bahrain and Beirut for new stores. In 2012, the Riyadh franchise store, owned by Prince Al Waleed bin Talal Al Saud, closed after the licensing agreement expired.\nIn 2005, Saks opened a 80,000 square foot store at the BurJuman Centre in Dubai which closed in 2016; the store was Saks last store in the UAE after failed attempts at expansion. The store was originally scheduled to open in early 2004. A Doha store was scheduled to open in 2005 at Landmark Mall however plans never came to fruition. A Tokyo store was also planned to open in 2005.\nIn 2008, Saks opened its third Middle East store at City Centre Bahrain in Manama, Bahrain. The store has two floors and is in size. After closing Riyadh and its 2 Dubai stores, it remains Saks' sole store in the Middle East.\nIn 2012, Saks licensed its first store in Central Asia, in Almaty, Kazakhstan, at the then-new Esentai Mall, together with boutiques of international luxury brands. Saks Almaty is 3 floors tall and in size.\nControversies.\nIn 2005, vendors filed against Saks alleging unlawful chargebacks. The U.S. Securities and Exchange Commission (SEC) investigated the complaint for years and, according to the \"New York Times\", \"exposed a tangle of illicit tactics that let Saks... keep money it owed to clothing makers\", inflating Saks' yearly earnings up to 43% and abusively collecting around $30 million from suppliers over seven years. Saks settled with the SEC in 2007, after firing three or more executives involved in the fraudulent activities.\nIn 2014, Saks fired transgender employee Leyth Jamal after she was allegedly \"belittled by coworkers, forced to use the men's room and repeatedly referred to by male pronouns (he and him)\". After Jamal submitted a lawsuit for unfair dismissal, the company stated in a motion to dismiss that \"it is well settled that transsexuals are not protected by Title VII of the Civil Rights Act of 1964.\" In a court filing, the United States Department of Justice rebuked Saks' argument, stating that \"discrimination against an individual based on gender identity is discrimination because of sex.\" The Human Rights Campaign removed the company from its list of \"allies\" during the controversy. The lawsuit was settled out of court with undisclosed terms.\nIn 2017, following the events of Hurricane Maria in Puerto Rico, Saks's San Juan store in Mall of San Juan suffered major damages along with its neighboring anchor store Nordstrom. Taubman Centers, the company which owns the mall, filed a lawsuit against Saks for failing to provide an estimated reopening date and failing to restore damages after the hurricane due to a binding contract. Although Nordstrom reopened on November 9, 2018, Saks Fifth Avenue vacated The Mall of San Juan after two years of litigation.\nNotable locations.\nSaks\u201334th Street.\nSaks-34th Street was a fashion-focused middle market department store at 1293-1311 Broadway on Herald Square. The building, built in 1902, had seven stories and was designed by Buchman &amp; Fox. The store was spun off from Saks &amp; Company when that upscale retailer moved to Fifth Avenue, a location that Saks Fifth Avenue maintains to this day. The newly renamed Saks-34th Street was sold to Bernard F. Gimbel, and became a part of the New York division of Gimbels (later Manhattan Mall), and a sky bridge across 33rd Street connected the second floors of both flagship buildings. In the 1947 movie \"Miracle on 34th Street\" the facade of Saks-34th Street is shown in a scene that focuses on the Gimbel's flagship store. Branch locations were opened around the greater New York area. The store closed in 1965, citing poor layouts, no escalators, a confused identity, and outdated facade. After Gimbels decided to close the division, the first floor of the building was used as a Christmas season annex for Gimbel's before being sold to the E. J. Korvettes chain. After the demise of the Korvette's chain the building was remodeled into the Herald Center, in 1985. As of 2016[ [update]] the primary tenant is H&amp;M, following another remodel.\nBeverly Hills.\nThe original Saks Fifth Avenue store in Beverly Hills, California, at 9600 Wilshire Boulevard, was designed by the architectural firm Parkinson and Parkinson, with interiors by Paul R. Williams. The store opened in 1938. The store was immediately successful upon opening and it would subsequently expand to almost and employ 500 people. Williams created an interior reminiscent of his designs for luxurious private residences, with rooms lit by indirect lamps and footlights focused on the clothes. New departments for furs, corsets, gifts and debutante dresses were added in the 1940 expansion.\nThe store relocated to the adjacent 9570 Wilshire Boulevard in 2024, and the original location will be converted into a mixed-use development by Hudson's Bay Company.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29484", "revid": "6326132", "url": "https://en.wikipedia.org/wiki?curid=29484", "title": "Seabee", "text": "Member of the US Naval Construction Forces\nMilitary unit\nUnited States Naval Construction Battalions, better known as the Navy Seabees, form the U.S. Naval Construction Forces (NCF). The Seabee nickname is a heterograph of the initial letters \"CB\" from the words \"Construction Battalion\". Depending upon context, \"Seabee\" can refer to all enlisted personnel in the USN's occupational field 7 (OF-7), all personnel in the Naval Construction Force (NCF), or Construction Battalion. Seabees serve both in and outside the NCF. During World War II they were plank-holders of both the Naval Combat Demolition Units and the Underwater Demolition Teams (UDTs). The men in the NCF considered these units to be \"Seabee\". In addition, Seabees served as elements of Cubs, Lions, Acorns and the United States Marine Corps. They also provided the manpower for the top secret CWS . Today the Seabees have many special task assignments starting with Camp David and the Naval Support Unit at the Department of State. Seabees serve under both Commanders of the Naval Surface Forces Atlantic/Pacific fleets as well as on many base Public Works and USN diving commands.\nNaval Construction Battalions were conceived of as replacements for civilian construction companies in combat zones after the attack on Pearl Harbor. At the time civilian contractors had roughly 70,000 men working U.S.N. contracts overseas. International law made it illegal for civilian workers to resist an attack. Doing so would classify them as guerrillas and could lead to summary execution. The formation of the Seabees amidst the aftermath of the Battle of Wake Island inspired the backstory for the World War II movie \"The Fighting Seabees\". They also feature prominently in the wartime musical drama (and subsequent film) \"South Pacific\".\nAdm. Moreell's concept model CB was a USMC trained military equivalent of those civilian companies: able to work anywhere, under any conditions or circumstances. They have a storied legacy of creative field ingenuity, stretching from Normandy and Okinawa to Iraq and Afghanistan. Adm. Ernest King wrote to the Seabees on their second anniversary, \"Your ingenuity and fortitude have become a legend in the naval service.\" They were unique at conception and remain unchanged from Adm. Moreell's model today. In the October 1944 issue of \"Flying\", the Seabees are described as \"a phenomenon of WWII\".\nNaval construction history.\nCB Conceptual Formation\nIn the 1930s Bureau of Yards and Docks (BuDocks) began providing for \"Navy Construction Battalions\" (CB) in contingency war plans. In 1934, Capt. Carl Carlson's version of the CB was approved by Chief of Naval Operations In 1935, RADM. Norman Smith, head of BuDocks, selected Captain Walter Allen, War Plans Officer, to represent BuDocks on the War Plans Board. Capt. Allen presented the bureau's CB concept with the Board including it in the Rainbow war plans. The Seabees named their first training center for Capt. Allen. A criticism of the proposal was CBs would have a dual command; military control administrated by fleet line Officers while construction operations would be administrated by Civil Engineer Corps officers. Additional criticisms were no provisions for the military organization or military training necessary to provide unit structure, discipline, and esprit de corps. In December 1937, RADM. Ben Moreell became BuDocks Chief and the lead proponent of the CB proposal.\nIn 1941, the Navy and BuDocks decided to improve project oversight of civilian contractors by creating \"Headquarters Construction Companies\". These companies would have 2 officers and 99 enlisted, but would do no actual construction. On 31 October 1941, RADM. Chester Nimitz, Chief of the Bureau of Navigation, authorized the formation of the 1st Headquarters Construction Company. Recruiting began in November while boot training began 7 December 1941 at Naval Station Newport. By 16 December, four additional companies had been authorized, but Pearl Harbor changed everything.\nThe Seabee skillset became multi-faceted with all advanced military training being USMC instruction. That training led to CBs being tasked as USMC Pioneers (Shore party) in multiple landings. They added pontoon development, fabrication, and combat utilization. The military training added frontline combat with both the Marine Corps and the Army during WWII and the Marines and Army Special forces during Vietnam. It also led to combat as machine gunners on USN LCVP and PT boats during WWII. On the construction side of their toolbox the NCF CBs were formed with skilled tradesmen making the NCF competent in all types of vertical and horizontal civil construction as well as the associated engineering. The newly formed Naval Construction Force (NCF) toolbox quickly focused on airfield and harbor construction. The toolbox was expanded to include underwater construction, demolition, as well as the related combat applications used by the Seabees that comprised the NCDU's and UDTs. The toolbox was further expanded by the creation of Public works units to maintain the facilities they constructed. In addition mosquito/malaria control was added to their Public works skillset. The NCF added traditional fleet salvage, repair, and maintenance as needed. Combat engineering was added to the toolbox when CBs were transferred to the Marine Corps as elements of USMC engineering regiments. War demands added stevedoring to the toolbox both in USMC assault operations and at forward operating facilities. Weapons development and manufacture were added by the USA Chemical Warfare Service. Polar petroleum exploration and construction were specialties that were also added. Postwar the National Science Foundation would take advantage of those skillsets. Ingenuity and resourcefulness were tools they became famous for. Postwar assignments with the CIA and State Department added further to the toolbox in electronic fields related to national security.\nTheir official motto is \"We build, we fight.\" The NCF also adopted the motto \"Can Do\" as the force believed it could do anything it was tasked with. The Seabees boasted of this by posting signs reading: \"The difficult we Can Do now, The impossible takes a little longer\".\nWorld War II.\nOn 28 December 1941, Adm. Moreell requested authority to commission three Naval Construction Battalions. His request was approved on 5 January 1942 by Admiral Nimitz. The 1st HQ Construction Company was used to commission the 1st Naval Construction Detachment, which was assigned to Operation Bobcat. They were sent to Bora Bora and are known in Seabee history as \"Bobcats\".\nConcurrently, the other requested companies had been approved. BuDocks took Companies 2 &amp; 3 to form the 1st Naval Construction Battalion at Charleston, South Carolina. HQ Companies 4 &amp; 5 were used for the 2nd CB. All four companies deployed independently. CBs 3, 4, &amp; 5 were deployed the same way. CB 6 was the first battalion to deploy as a Battalion.\nBefore all this could happen, BuDocks had to address the dual command issue. Naval regs stated unit command was strictly limited to line officers. BuDocks deemed it essential that CBs be commanded by CEC officers trained in construction. The Bureau of Naval Personnel (BuPers) was strongly opposed. Adm. Moreell took the issue directly to the Secretary of the Navy, Frank Knox. On 19 March 1942, Knox gave the CEC complete command of all NCF personnel. Almost 11,400 would become CEC during WWII with 7,960 doing CB service. Two weeks earlier, on 5 March all CB personnel were officially named \"Seabees\".\nThe first volunteers were tradesmen that received advanced rank for their trade skills. This resulted in the Seabees being the highest-paid group in uniform. To recruit these men, age and physical standards were waived up to age 50. Until November 1942 the average Seabee was 37, even so, all received the same physical training. In December, FDR ordered the Selective Service System to provide CB recruits. Enlistees could request CB service with a written statement certifying that they were trade qualified. This lasted until October 1943 when voluntary enlistment in the Seabees ceased until December 1944. By war's end, 258,872 officers and enlisted had served in the Seabees. They never reached the Navy's authorized quota of 321,056.\nIn 1942, initial CB boot was at Camp Allen in Norfolk, Virginia, which moved to Camp Bradford, which moved to Camp Peary and finally moved to Camp Endicott in Quonset Point, Rhode Island. CBs 1\u20135 were sent directly overseas for urgent projects. CBs that followed were sent to Advance Base Depots (ABDs) for deployment. Camp Rousseau at Port Hueneme became operational first and was the ABD to the Pacific. The Davisville ABD became operational in June with NTC Camp Endicott commissioned that August. Other CB Camps were Camp Parks, Livermore, Ca., and Camp Lee-Stephenson, Quoddy Village, Eastport, Maine and Camp Holliday, Gulfport, Mississippi.\nCBs sent to the Pacific were attached to one of the four Amphibious Corps: I, III, and V were USMC. The VII Amphibious Force was under General Douglas MacArthur, Supreme Commander. MacArthur said the only problem he had with the Seabees was that he didn't have enough of them.\nAdvance Bases\nThe Office of Naval Operations created a code identifying Advance Base (AB) construction as a numbered metaphor for the size/type of base. That code was also used to identify the \"unit\" that would be the administration for that base. These were Lion, Cub, Oak and Acorn with a Lion being a main Fleet Base (numbered 1\u20136). Cubs were Secondary Fleet Bases 1/4 the size of a Lion (numbered 1\u201312). Oak and Acorn were the names given air installations, new or captured (airfield or airstrip). Cubs quickly gained status. The speed with which the Seabees could make one operational led the Marines to consider them a tactical component. Camp Bedilion shared a common fence-line with Camp Rousseau at Port Hueneme and was home to the Acorn Assembly and Training Detachment (AATD) As the war progressed, BuDocks realized that logistics required that Advance Base Construction Depots (ABCDs) be built and CBs built seven. When the code was first created, BuDocks foresaw two CBs constructing a Lion. By 1944 an entire Regiment was being used. The invasion of Okinawa took four Construction Brigades of 55,000 men. The Seabees built the infrastructure needed to take the war to Japan. By war's end CBs had, served on six continents, constructed over 300 bases on as many islands. They built everything: airfields, airstrips, piers, wharves, breakwaters, PT &amp; seaplane bases, bridges, roads, com-centers, fuel farms, hospitals, barracks and anything else.\nIn the Atlantic the Seabees biggest job was the preparations for the Normandy landing. After which CBMUs 627, 628, and 629 were tasked to facilitate the crossing of the Rhine. For CBMU 629 it was front-line work. The Pacific is where 80% of the NCF deployed.\nAfrican American Service: the Seabee stevedores.\nIn February 1942 CNO Admiral Harold Rainsford Stark recommended African Americans for ratings in the construction trades. In April the Navy announced it would enlist African Americans in the Seabees. Even so, there were just two CBs that were \"colored\" units, the 34th and 80th. Both had white Southern officers and black enlisted. Both battalions experienced problems with that arrangement that led to the replacement of the officers. The men of the 34th went on a hunger strike which made national news. The Commander of the 80th had 19 enlisted dishonorably discharged for sedition. The NAACP and Thurgood Marshall got 14 of those reversed.\nIn early 1943 the Navy commissioned its first African American officers. The first to enter the Seabees officer corps was MIT graduate Edward S. Hope. In May 1943 he completed CEC training at Camp Endicott and was posted as the Public Works officer at Manana barracks Hawaii Territory. That same year, the Navy drew up a proposal to raise the number of colored CBs to 5 and require that all non-rated men in the next 24 CBs be colored. The proposal was approved, but not acted on.\nThe lack of stevedores in combat zones was a huge issue for the Navy. Authorization for the formation of cargo handling CBs or \"Special CBs\" happened mid-September 1942. By wars end 41 Special CBs had been commissioned of which 15 were \"colored\". Neither the Navy or NCF used that label, the units were simply segregated in the men assigned to them. The Special CBs were the first fully integrated units in the U.S. Navy. V-J Day brought the decommissioning of all of them. The Special CBs were forerunners of today's Navy Cargo Handling Battalions of the Navy Expeditionary Logistics Support Group (United States). The arrival of 15 African American Special CBs in Pearl Harbor made segregation an issue for the 14th Naval District. For a protracted period the men lived in tents, but the disparity of treatment was obvious even to the Navy. The 14th Naval District Command felt they deserved proper shelter with at least separate but equal barracks. Manana Barracks and Waiawa Gulch became the United States' largest \"colored\" installation with over 4,000 Seabee stevedores barracked there. It was the site of racial strife to the point that the camp was fenced in and placed under armed guard. The Seabees were trucked to and from the docks in cattle trucks. Two naval supply depots were located at Waiawa Gulch. At wars end 12,500 African Americans would serve in the Construction Battalions.\nThe 17th Special CB was one of the segregated Specials and was at Peleliu in September 1944. The unit is not listed in the USMC order of battle at Peleliu despite being attached to the 1st Marine Pioneers. On D-day, the 7th Marines had a situation where they did not have the men to man the lines and get the wounded to safety. Coming to their aid were the 2 companies of the 16th Marine Field Depot (segregated) and the 17th Special CB. The Japanese mounted a banzai counter-attack at 0200 hours that night. By the time it was over, nearly the entire 17th had volunteered to carry ammunition to the front lines on the stretchers they brought the wounded back on. They filled the line where the wounded had been, manned 37mm guns that had lost crews and volunteered for anything the Marines needed. The 17th remained with the 7th Marines until the right flank had been secured D+3. There is nothing comparable in USMC history. According to the Military History Encyclopedia on the Web, \"were it not for the Black Marine shore party---the (banzai) on the 7th Marines would not have been repulsed\". The 17th had five men killed in action and 28 Purple Hearts awarded by Vice Admiral J.H. Hoover and Brig. General H.D. Campbell USMC. \nSeabee North Slope Oil Exploration 1944.\nConstruction Battalion Detachment (CBD) 1058 was formed from \"screening Camp Peary and the NCF for geologists, petroleum engineers, oil drillers, tool pushers, roustabouts and roughnecks\" and later designated 1058. Additional personnel were chosen for their arctic experience with CBs 12 and 66. They mustered at Camp Lee Stephenson for Operation Pet 4. Congress put $1,000,000 aside to wildcat for oil in U.S. Navy Petroleum Reserve No. 4 (NPR-4) in 1944. NPR-4 had been created and placed in the oil reserve in 1923. Today NPR-4 is the National Petroleum Reserve in Alaska. The detachment's mission was:\nOn 19 July the USS \"Spica\" headed north with the SS \"Jonathan Harrington\" for Point Barrow and Cape Simpson. The det's base camp was constructed at Point Barrow. Four D-8s with twenty sleds of supplies were prepped for the 330-mile trek to Umiat once the tundra had frozen. The first tractor train delivered supplies, the second, heavy well equipment. The D8s would make eight trips total. When summer arrived a wildcat was drilled to 1,816' before the cold shut down operations. The hole was designated Seabee#1 It was near four known seeps at Umiat in the very south-east of NPR 4. The rock strata there was from the Upper Cretaceous and a stratum of it was named the \"Seabee Formation\". On the coast the Seabees drilled test holes at Cape Simpson and Point Barrow. Once the runways were completed additional supplies were flown in. In March 1946 civilians took over the project. Some Seabees of CBD 1058 were hired immediately upon discharge to continue doing the work they had been doing\" The Navy applied the cold weather experience from CBD 1058 for Operation Highjump and Operation Deep Freeze. Seabee #1 remains a USGS monitor well today.\nLand surveys\nTwice the Seabees have been tasked with large-scale land surveys. The first was done by CBD 1058 for a proposed NPR 4 pipeline route to Fairbanks. The Trans-Alaskan pipeline follows a portion of their survey from roughly the Arctic Circle to Fairbanks. The second would be done by a Seabee team from MCB 10. They went to Vietnam in 1956 to survey and map the existing road network. That survey was extensively used during the Vietnam War.\nMalaria and Epidemic Control Group\nNavy Medicine created the Malaria and Epidemic Control Group to deal with insect-borne diseases. Between August 1942, and February 1943, American troops in the Pacific averaged 10 malaria cases for every combat injury. Seabees oiled, drained and sprayed mosquito breeding areas and inspected and fumigated ships and aircraft transiting malaria-infested areas. It was an important task that absolutely needed to be done in order for the United States to field an effective combat force. On Guadalcanal the 63rd CB had malaria control as its primary task. At Gulfport a school was established to train Battalions for the Malaria and Epidemic Control Group.\nWorld War II Seabees outside the NCF.\nDuring World War II Seabees were tasked outside the NCF in the USMC, NCDUs, and UDTs.\nMarine Corps.\nUSMC historian Gordon L. Rottman wrote \"that one of the biggest contributions the Navy made to the Marine Corps during WWII was the creation of the Seabees\". In exchange, the Corps would be influential upon the CB organization and its history. After the experience of Guadalcanal the Department of War decided that the Marines and Seabees would make all subsequent landings together. That arrangement led to numerous Seabee claims that they had landed first, even leaving signs on the beach asking the Marines \"What took you so long?\" The Seabees in the UDTs made an effort of this of which their mates in the CBs approved.\nWhen the first three CBs were formed the Seabees did not have a base of their own. Upon leaving boot the recruits were sent to National Youth Administration camps in Illinois, New Jersey, New York, and Virginia to receive military training from the Marine Corps. The Marine Corps listed CBs on their Table of organization: \"D-Series Division\" for 1942, \"E-Series Division\" for 1943, and \"Amphibious Corps\" for 1944\u201345.\nWhen CBs were created the Marine Corps wanted one for each of the three Marine Divisions, but were told no because of war priorities. Even so, early Seabee units were connected with Marine Corps ops. The 1st Naval Construction Detachment (Bobcats) together with and A Co CB 3 was transferred to the Marines and redesignated 3rd Battalion 22nd Marines. The Bobcats had deployed without receiving advanced military training. The 22nd Marines took care of that. The 4th Construction Detachment was attached to the 5th Marine Defense Battalion for two years.\nBy autumn, the 18th, 19th and 25th CBs had been transferred to the Corps as combat engineers. Each was attached to a composite engineer regiment, redesignated as 3rd Battalion: 17th Marine Regiment, 18th Marine Regiment, 19th Marine Regiment, and 20th Marine Regiment. The 18th and 19th CBs each claim to have been the first CBs authorized to wear standard USMC issue. Both received their military training and USMC duffle bag at MTC New River, NC. There is no record of how many CBs received USMC issue. It is known that the 31st, 43rd, 76th, 121st and 133rd CBs received partial or complete issues. On 15 January 1944 the 142nd CB was commissioned at New River, Camp Lejeune. On 2 February that Battalion arrived at Camp Pendelton for further training, mounting out 19 April.\nAfter Guadalcanal amphibious operations became joint USMC/Seabee pairings. The 6th CB joined the 1st Marine Division after combat had started on Guadalcanal. The 18th CB was sent to join them from Fleet Marine Force depot Norfolk. Many more would follow. The 6th Special CB was tasked to the 4th Marines Depot in the Russells. November saw the 14th CB tasked to the 2nd Raider Bn on Guadalcanal. In June, the 24th CB had been tasked to the 9th Marine Defense Bn on Rendova. The 33rd and 73rd CBs had dets tasked to the 1st Pioneers as shore party on Peleliu as was the 17th Special CB colored. At Enogi Inlet on Munda, a 47th det was shore party to the 1st and 4th Marine Raiders. The 3rd Marine Div. made the Commander of the 71st CB shore party commander on Bougainville. His 71st had support from the 25th, 53rd, and 75th CBs. At Cape Torokina the 75th had 100 men volunteer to make the assault of the 3rd Marines. Also at Bougainville, the 53rd provided shore parties to the 2nd Raiders on green beach and the 3rd Raiders on Puruata Island. The 121st was formed at the CB Training Center of MTC Camp Lejuene as 3rd Bn 20th Marines. They would be shore party to the 23rd Marines on Roi-Namur, Saipan, and Tinian.\nWhen the Marine Engineer Regiments were inactivated in 1944, CBs were then tasked to Marine Divisions. For Iwo Jima, the 31st and 133rd were attached to the 4th and 5th Marine Divisions. The 133rd was shore party to the 23rd Marines. while the 31st CB was in the 5th Shore Party Regiment. The 31st demolitionsmen attached directly to the Division. The 8th Marine Field Depot was the shore party command eschelon for Iwo Jima. They requested 26 heavy equipment operators and received volunteers from CB 8. Okinawa saw the 58th, 71st, 130th, and 145th CBs detached from the Navy and tasked to the Marine Corps 6th, 2nd, and 1st Marine Divisions respectively.\nFrom Iwo Jima the 5th Marine Div. returned to Camp Tarawa to have the 116th CB attached. When Japan fell the 116th CB was part of the occupation force. V-J Day left thousands of Japanese troops in China and the III Marine Amphibious Corps was sent there to get them home. The 33rd NCR was assigned to III Marine Amphib. Corps for this mission.\nCBs were also tasked individually to the three USMC Amphibious Corps. The 19th CB started out with the I MAC prior to joining the 17th Marines. The 53rd CB was attached to I MAC as Naval Construction Battalion I M.A.C. When I MAC was redesignated III Amphibious Corps the battalion became an element of the 1st Provisional Marine Brigade. For Guam, III Amphibious Corps had the 2nd Special CB, 25th, and 53rd CBs. The CO 25 CB was shore party commander for the 3rd Marines on beaches Red 1 and Red 2. The 3rd Marines would award 25's shore party 17 bronze stars. V Amphibious Corps (VAC) had the 23rd Special and 62nd CBs on Iwo Jima. On Tinian the 6th Construction Brigade was attached to V Amphibious Corps.\nWhen the war ended the Seabees had a unique interservice standing with the U.S. Marine Corps. Seabee historian William Bradford Huie wrote \"that the two have a camaraderie unknown else-wheres in the U.S. military\". Even though they are \"Navy\" the Seabees adopted USMC fatigues with a Seabee insignia in place of the EGA. At least 10 CB units incorporated USMC insignia into theirs. Admiral Moreell wrote, tongue in cheek, that the Marines were the best fighting men in the Pacific, but one had to serve 90 days with the Seabees to qualify to as a \"Junior Bee\".\nNaval Combat Demolition Units.\nIn early May 1943, a two-phase \"Naval Demolition Project\" was ordered by the Chief of Naval Operations \"to meet a present and urgent requirement\" for the invasion of Sicily. Phase-1 began at Amphibious Training Base (ATB) Solomons, Maryland with the creation of Operational Naval Demolition Unit # 1. Six Officers led by Lt. Fred Wise CEC and eighteen enlisted reported from Camp Peary dynamiting and demolition school. Seabees called them \"Demolitioneers\".\nNaval Combat Demolition Units (NCDUs) consisted of one junior CEC officer, five enlisted, and were numbered 1\u2013216. After that first group had been trained, Lt. Commander Draper Kauffman was selected to command the program. It had been set up in Camp Peary's \"Area E\"(explosives) at the dynamiting and demolition school. Between May and mid-July, the first six NCDU classes graduated at Camp Peary. While the program was at Camp Peary the men were given head-of-the-line privileges at the mess hall. The program was moved to Fort Pierce where the first class began mid-July. Despite the move, Camp Peary remained Kauffman's primary recruit center. \"He would go back to the dynamite school, assemble the (Seabees) in the auditorium and say, 'I need volunteers for hazardous, prolonged and distant duty.'\" Fort Pierce had two CB units assigned, CBD 1011 and CBMU 570. They were tasked with the construction and maintenance of obstacles needed for demolition training.\nThe invasion of Normandy had 34 NCDUs. When the first ten arrived in England they had no CO. Lt. Smith (CEC) assumed the role, splitting them up to train with the 146th, 277th and 299th Combat Engineers. As more NCDUs arrived they did the same, with 5 combat engineers attached to each NCDU. Group III (Lt. Smith) did research and development and is credited with developing the Hagensen Pack. NCDUs had a 53% casualty rate at Normandy. Four from Utah beach later took part in Operation Dragoon.\nWith Europe invaded, Admiral Turner requisitioned all available NCDUs from Fort Pierce for integration into the UDTs for the Pacific. That netted him 20 NCDUs that had received Presidential Unit Citations and another 11 that had gotten Navy Unit Commendations. Prior to Normandy 30 NCDUs had embarked to the Pacific and another three had gone to the Mediterranean. NCDUs 1\u201310 were staged at Turner City on Florida Island in the beginning of 1944. NCDU 1 was briefly in the Aleutians in 1943. The first NCDUs in combat were 4 and 5 with the 4th Marines on Green Island, Papua New Guinea and Emirau Island. Later, NCDUs 1\u201310 were combined to form the short-lived UDT Able. NCDUs 2, 3, 19, 20, 21 and 24 were assigned to MacArthur's 7th Amphibious Force and were the only NCDUs remaining at the war's end.\nsee Notes\nUnderwater Demolition Teams (UDT)s.\nPrior to Operation Galvanic and Tarawa, V Amphibious Corps had identified coral as an issue for future amphibious operations. RADM Kelly Turner, commander V Amphibious Corps had ordered a review to get a grip on the problem. VAC found that the only people having any applicable experience with the material were men in the Naval Construction Battalions. Lt. Thomas C. Crist, of CB 10, was in Pearl Harbor from Canton Island where he had been in charge of clearing coral heads. His being in Pearl Harbor was pivotal in UDT history. While there he learned of the Adm. Turner's interest in coral blasting and met with him. The Admiral tasked Lt. Crist to develop a method for blasting coral under combat conditions and putting together a team to do it. Lt. Crist started by getting men from CB 10, but got the remainder from the 7th Construction Regiment. By 1 December 1943 he had close to 30 officers and 150 enlisted at Waipio Amphibious Operating Base on Oahu.\nIn November the Navy had a hard lesson with coral and tides at Tarawa. It prompted Adm. Turner to request the creation of nine Underwater Demolition Teams to address those issues. Six teams for VAC in the Central Pacific while the other three would go to III Amphibious Corps in the South Pacific. UDTs 1 &amp; 2 were formed from the 180 men Lt. Crist had staged. Seabees make up the majority of the men in teams 1\u20139, 13 and 15. How many Seabees were in UDTs 10 and 12 is not listed, for UDT 11 they composed 20% of the team.\nUDT officers were mainly CEC. UDT 10 had 5 officers and 24 enlisted originally trained as OSS Maritime Unit: Operational Swimmer Group II, but the OSS was not allowed to operate in the Pacific Theater. Adm. Nimitz needed swimmers and approved their transfer from the OSS to his control. The MU men brought with the swimfins they had trained with and the Seabees made them a part of UDT attire as quickly as the Supply dept. could get them. In the Seabee dominated teams the next largest group of UDT volunteers came from the joint Army-Navy Scouts and Raiders school that was also in Fort Pierce. Additional volunteers came from the Navy's Bomb disposal School, Marine Corps and U.S. Fleet.\nThe first team commanders were Cmdr. E.D. Brewster (CEC) UDT 1 and Lt. Crist (CEC) UDT 2. Both Teams were \"provisional\" totaling the 180 men Lt Crist had put together from the 7th NCR. Those men were put through five weeks of training by a Marine Corps Amphibious Reconnaissance Battalion. They wore fatigues, life-vests and were expected to stay in their rubber boats like the NCDUs. At Kwajalein Adm.Turner ordered daylight recon. It was apparent to the Seabees that staying in the boats would not get the Admiral the intel he wanted. Cmdr. Brewester's men all wore swim trucks under their fatigues. Ensign Lewis F. Luehrs, and Charp. Bill Acheson spent 45 minutes in the water in broad daylight and were the first team members recovered. Still wet and in their trunks they reported directly to Adm. Turner. He concluded what they had done was the only way to get accurate intelligence on submerged obstacles and conveyed that opinion to Adm. Nimitz. At Engebi Cmdr. Brewster was wounded. The success of UDT-1 not following USMC Recon protocol rewrote the UDT mission model and training regimen. Ens. Luehrs and Charp. Acheson were each awarded a Silver Star for their initiative while unintentionally creating the UDT \"naked warrior\" image. Diving masks were uncommon in 1944 and some men had tried using goggles at Kwajalein. Diving masks were a rare item in Hawaii so Lt. Crist and CB Chief Howard Roeder had requested supply get them. A fortuitous observation by one of the men spotted a magazine advertisement for diving masks. A priority dispatch was made to the States that appropriated the store's entire stock. The UDTs adopted goggles independent of the OSS. When UDTs 1 and 2 returned to Hawaii Chief Acheson and three other UDT Officers were transferred to the 301st dredging CB. The 301st had 12 dredges saving Teams from blasting channels, but needed divers to get the job done. Ensign Leuhrs made Lt. and was a member of UDT 3 until he was made XO of team 18. Commander Brewster's purple heart got him out of the UDTs and elevated to Commander 7th NCR instead of back to CB 10.\nAdm. Turner also requested the formation of a Demolition Training Center at Kihei. It was approved. The actions of UDT 1 provided the training model, making UDT training distinctly different from Fort Pierce's NCDU program. Lt. Crist was briefly the first training officer and emphasized swimming and recon until he was made CO of UDT 3. When UDT 3 returned from Leyte in the fall of 1944 it became the school instructors with Lt. Crist again OIC of training. The classes now included: night ops, weapons, bivouacking, small unit tactics, along with coral and lava blasting. In April 1945, team 3 was sent to Fort Priece to instruct there. Lt. Crist was promoted to Lt. Cmdr. and sent back to Kihei. Team 3 would train teams 12\u201322. UDT 14 is called the first \"all fleet team\" even though it had Seabees from Team Able and the CO and XO were both CEC. UDT 15 was the last team formed of NCDUs. Teams 12\u201315 were sent to Iwo Jima. Three cleared the shoreline for five days, D+2-D+7. After July 1944 new UDTs were only USN. In 1945, CBMU 570 was tasked to the UDT coldwater training center at ATB Oceanside, CA.\nOn Guam team 8 requested permission to build a base. It was approved by AdComPhibsPac, but disapproved by Island Command. Team 8 turned to the CBs on the island and got everything needed. Coral paving got placed the night before Admiral Nimitz inspected, giving teams 8 &amp; 10 a glowing review.\nBy V-J day 34 teams had been formed.\nTeams 1\u201321 saw actual deployment with the Seabees providing over half of the men in those teams. The Navy did not publicize the existence of the UDTs until post-war and when they did they gave credit to Lt. Cmdr. Kauffman and the Seabees. During World War II the Navy did not have a rating for the UDTs nor did they have an insignia. Those men with the CB rating on their uniforms considered themselves Seabees that were doing underwater demolition. They did not call themselves \"UDTs\" or \"Frogmen\", but rather \"Demolitioneers\" reflecting where Lt. Cmdr. Kauffman had recruited them from, the CB dynamiting and demolition school.\nUDTs had to be of standard recruiting age, Seabees older could not volunteer. Mid-year 1945, in preparation for the cooler waters around Japan, a cold water training center was created. With it came a more demanding physical. Team 9 lost 70% of the team to this change.\nPostwar, MCB 7 was tasked with projects at the UDT training facility on St. Thomas, Virgin Islands\nsee Notes\nCold War.\nWhen World War II ended the Cold War began. Seabee service during this period supported a broad spectrum of the national interest; nuclear testing, two wars, embassy security, space race, CIA, military communications, international relations, pure science, and Camp David.\nPostwar interlude: Siberia-China.\nOn V-J-Day CB 114 was in the Aleutians. In September 1945 the battalion sent a detachment to the USSR to build a Fleet Weather Central. It was located outside Petropavlovsk-Kamchatsky on the Kamchatka Peninsula. The original agreement gave the Seabees 3 weeks to complete the base. Upon arrival the Russians told them they had 10 days and were amazed it was done in 10. It was one of two that Stalin agreed to.\nV-J-Day brought about Operation Beleaguer and the repatriation of the Japanese Army from China. Elements of the 33rd CB Regiment were involved: CBs 83, 96, 122 and 32nd Special. These units landed at Qingdao and Tanggu in November 1945 attached to the 6th Marine Division. CB 42 and A Co. 33rd Special landed at Shanghai with Naval Advance Base Unit 13. With the war over, the ongoing discharge men eligible left only enough for one CB and the two CB Specials. The men were consolidated in the 96th with the other CBs decommissioned. In December the 96th started airfields at Qingdao and Qinhuangdao in support of III Marine Amphibious Corps operations. May 1946 CB III Marine Amphibious Corps was ordered to inactivate the 96th CB on 1 August. The 96th was transferred to the 4th Marines, 1st Marine Division and deactivated from them.\nNuclear tests.\nIn early 1946 the 53rd NCB was deployed with Operation Crossroads for the nuclear testing at Bikini Atoll. It was designated Task Unit TU 1.8.6. 53's project list included observation, instrument and communication towers, radio beacons, seismic huts, photo reference crosses, general base and recreational facilities, as well as dredging the lagoon. In addition, recreational facilities were constructed on Japtan Island for the ships crews of the Operation. The Battalion also assisted the relocation of the natives. They disassembled both the Community center and church for reassembly on Rongerik Atoll. In August the battalion was decommissioned with men transferred to CBD 1156 that was then commissioned on Bikini. The TU 1.8.6 designation transferred to the CBD. CBD 1156 remained for nine days after the second test.\nUDT 3 was designated TU 1.1.3 for the operation. On 27 April 1946, seven officers and 51 enlisted embarked at CBC Port Hueneme for Bikini. Their assignment was to retrieve water samples from ground zero of the Baker blast. In 1948, the displaced bikinians put in a request that a channel to the island Kili where they had been relocated be made. This was given to the Seabee detachment on Kwajelin who requested UDT 3 assist.\nThe 121st CB was decommissioned in December and re-designated CBD 1504. In January 1947 CBs 104 and 105 were reactivated. The 30th NCR was home-ported on Guam composed of CBDs 1501-13 and NCB 103. In 1949, the 103rd was made a Mobile Construction Battalion (MCB) while CBs 104 and 105 were made Amphibious Construction Battalions(ACBs). From 1949 until 1968 CBs were designated MCBs. In 1949, MCB 1 was reactivated at Naval Amphibious Base Little Creek, VA. In June 1950 the NCF totaled a few thousand.\nKorean War.\nThe outbreak of the Korean War led to a call-up of 10,000 from the Seabee Reserve. Seabees landed at Inchon during the assault, installing causeways dealing with enormous tides and enemy fire. Their actions there and elsewheres underscored the necessity of having CBs. During that war the authorized size of a CB was 550 men. When the truce was declared there was no CB demobilization as there had been at the end of World War II.\nDuring the Korean War, the U.S. realized the need of an air station in the region. Cubi Point in the Philippines was selected. Civilian contractors were approached for bids. After seeing the Zambales Mountains and the maze of jungle, they claimed it could not be done. The Navy then turned to the Seabees. The first to arrive was CBD 1802 to do the surveying. MCB 3 arrived on 2 October 1951 to get the project going and was joined by MCB 5 in November. Over the next five years, MCBs 2, 7, 9, 11 and CBD 1803 all contributed to the effort. They leveled a mountain to make way for a nearly runway. NAS Cubi Point turned out to be one of the largest earth-moving projects in the world, equivalent to the construction of the Panama Canal. Seabees there moved of dry fill plus another 15 million that was hydraulic fill. The $100\u00a0million facility ($ in 2024 dollars) was commissioned on 25 July 1956, and comprised an air station and an adjacent pier that was capable of docking the Navy's largest carriers.\nSeabee Teams\nThe World War II precursor to Seabee teams was the PT Advance base Detachment of the 113th CB. Each man was cross-trained in at least three trades with some qualified as corpsmen and divers. During Vietnam the requirement of being skilled in three trades was continued. The first Seabees referred to as \"Seabee Teams\" were CBDs 1802 and 1803. They were followed by Detachments Able and Baker. The U.S. State Department learned of the teams and concluded they could have a Cold War purpose. They could be U.S. \"Good Will Ambassadors\" to third world countries to counter the spread of Communism, a military version of the Peace Corps. These 13-man teams would construct schools, drill wells or build clinics creating a positive image for the U.S. They were utilized by the United States Agency for International Development and were in S.E. Asia by the mid-1950s. Then in the early sixties, the U.S. Army Special Forces were being sent into rural areas of South Vietnam to develop a self-defense force to counter the Communist threat and making use of the Seabee teams at these same places made sense to the CIA. To start, twelve \"Seabee teams, with Secret Clearances, were sent with the Army's Special Forces in the CIA funded Civilian Irregular Defense Group program (CIDG)\" in the years 1963\u20131965. By 1965 the U.S. Army had enough engineers in theater to end Seabee involvement with Special Forces. At first teams were called Seabee Technical Assistance Teams (STAT) and were restricted to two in theater at a time. Teams after STAT 1104 were renamed Seabee Teams and by 1969 there were 17 in theater. As a military force Seabee Teams received many awards for heroism. Teams were sent to other nations as well. The Royal Thai government requested STATs in 1963 and ever since the Seabees have continued to deploy teams.\nConstruction Civic Action Details or CCAD\nCCADs or \"See-Kads\" are larger civic action units of 20\u201325 Seabees with the same purpose as Seabee Teams. The CCAD designation is not found in the record prior to 2013.\nCamp David.\nCamp David is officially known as Naval Support Facility Thurmont, as it is technically a military installation. The base is staffed by the CEC, Seabees, and Marines. \"In the early 1950s, Seabee BUs, UTs and CEs took over routine maintenance of the base and additional rates were added for administrative functions. Today Seabees still man the base public works and see that the grounds are in an impeccable condition.\" \"Selectees undergo a single scope background investigation to determine if they qualify for a Top Secret Sensitive Yankee White (YW) clearance. All personnel in Presidential support activities are required a \"Yankee White\" security clearance. The tour lasts 36 months.\" When the base has a larger construction project a Construction Battalion from the fleet can be tasked. NMCBs 5 and 133 have drawn these assignments.\nAntarctica: Science.\nOperation Highjump\nIn December 1946, 166 Seabees sailed from Port Hueneme on the USS \"Yancey\" and USS \"Merrick\" assigned to Operation Highjump. They were part of Admiral Richard E. Byrd's Antarctic expedition. The U.S. Navy was in charge with \"Classified\" orders \"to do all it could to establish a basis for a (U.S.) land claim in Antarctica\". The Navy sent the Seabees to do the job starting with the construction of Little America (exploration base) IV as well as a runway for aerial mapping flights. This Operation was vastly larger than IGY Operation Deep Freeze that followed.\nOperation Deep Freeze\nIn 1955, Seabees were assigned to Operation Deep Freeze making Antarctica an annual deployment site. Their task was the construction and maintenance of scientific bases for the National Science Foundation. The first \"wintering over\" crew included 200 Seabees. They cleared an ice runway at Mcmurdo for\nthe advance party of Deep Freeze II to fly to South Pole Station. MCB 1 was assigned for Deep Freeze II.\nAntarctica added to the Seabee's list of accomplishments:\nVietnam War.\nSeabees were in Vietnam twice in the 1950s. First in June 1954, as elements of Operation Passage to Freedom and then two years later to survey and map the roads. Seabee teams 501 and 502 arrived January 1963 as the first Seabees of the Vietnam War. They went to Dam Pau and Tri Ton to build Special Forces camps. In 1964 small 14 man Seabee groups were tasked to the U.S. Army advisors in the Special Operations Group. ACB 1 was the first CB in the theater that year. In 1965 the Marines arrived, making an amphibious landing at Chu Lai, with Seabees attached. Entire Naval Construction Regiments followed. Seabees supported the Marines at Khe Sanh and Chu Lai combat bases. The U.S. had many civilian contractors in the country, however the Seabee construction included numerous aircraft-support facilities, roads, and bridges. For every mile of road they improved, they built 100' of bridge-deck. They also worked civic action projects throughout the country. In June 1965, Construction Mechanic 3rd Class Marvin G. Shields of Seabee Team 1104 was at the Battle of Dong Xoai. He was posthumously awarded the Medal of Honor and is the only Seabee to receive the award. Seabee Teams were part of a propaganda program to promote support for the RVN through positive community engagement, typically building schools, clinics, or drilling wells. In 1966, Seabees repaired the airfield at Khe Sahn covering an area of 3,900'x60' with aluminum matting in four days. General Westmoreland \"called it one of the most outstanding military engineering feats of the war.\" MCB 4 had a det at Con Thien whose actions were a near repeat of Dong Xoai.\nIn 1968, the Marine Corps requested that the Navy make a change. The Marines were using \"MCB\" for \"Marine Corps Base\" while the Navy was using \"MCB\" for \"Mobile Construction Battalion\", it was causing confusion in logistics. The Navy agreed and added \"Naval\" to MCB creating the NMCBs that now exist. During that year the 30th NCR had five battalions in the Da Nang area and two at Chu Lai. The 32nd NCR had three battalions tasked near Phu Bai and one at Dong Ha. In May 1968 two reserve battalions RNMCB 12 and 22 were activated, bring the total number of battalions in Vietnam to 21. Both ACBs were in theater as well as CBMUs 301 and 302. In 1968, NMCB 10 drew an atypical Seabee \"task\" supporting the 101st Airborne. It happened again in 1969 when CBs 10, 40 and 121 sent EOs to Fire base Fury. During 1969 the number of Seabees in theater reached 29,000, from there their draw-down began. The last battalion withdrew late 1971 with the last Seabee teams out a year later. When it was over they had sent 137 Seabee teams, built 15 CB camps, and deployed 22 battalions. CBMU 302 became the largest CB ever at over 1400 men and was homeported at Cam Rahn Bay. On 23 April 1975 it was announced that U.S. involvement in Vietnam was over.\nThat day CB 4 started construction of a temporary camp for Operation New Life on Guam. In seven days 2,000 squad tents were erected and numbered 3,500 when done.\nDuring Vietnam the Seabees had a few uniform variations. One was the stenciling of unit numbers across the back of the field jacket M-65. Another was the collar and cover devices for enlisted E4-E6. The Navy authorized that the \"crow\" be replaced by the rating insignia of each trade. Nametags were another, they started out white with a multicolored seabee. In 1968, the USMC OD green pattern was copied. The NAVCATs became the only Seabees to ever be authorized to wear a shoulder patch.\nNAVCATs Naval Construction Action Teams\nCBMU 302 had 23 NAVCATS(Naval Construction Action Teams) total with 15 the most active at one time. Teams were numbered 1-23. They were Vice Admiral Elmo Zumwalt's expansion of the Seabee Team concept. He submitted it in November 1968 to General Creighton Abrams commander of Military Assistance Command, Vietnam.\nAgent Orange\nMany Seabees were exposed to the defoliant herbicide while in Vietnam. NCBC Gulfport was the largest storage depot in the United States for Agent Orange. From there it was shipped to Vietnam. In 1968, the NCBC received 68,000 barrels to forward. Long term barrel storage began in 1969. That lasted until 1977. The site covered 30 acres and was still being cleaned up in 2013.\nSpace race: NASA/Tektite I.\nIn 1960, a MCB 10 detachment built a Project Mercury telemetry and ground instrumentation station on Canton island.\nOn 28 January 1969 a detachment of 50 men from Amphibious Construction Battalion 2 plus 17 Seabee divers began installation of the Tektite habitat in Great Lameshur Bay at Lameshur, U.S. Virgin Islands. The Tektite program was funded by NASA and was the first scientists-in-the-sea program sponsored by the U.S. government. The Seabees also constructed a 12-hut base camp at Viers that is used today as the Virgin Islands Environmental Resource Station. The project was a by product of the Space Race. It caused the U.S. Navy to realize the need for a permanent Underwater Construction capability that led to the formation the Seabee Underwater Construction Teams\".\nAt present NASA is working on the Moon to Mars program. In 2015, ACB 1 was involved in moving the Orion's Boilerplate Test Article (BTA). ACB 1 was tasked in August 2019 in a test recovery exercise of the Orion spacecraft. ACB 2 was put through the same task a year later in August 2020.\nCIA and Naval Intelligence/Communication support.\nNaval Intelligence: NAVFACs\nThe Navy built 22 Naval Facilities (NAVFACs) for its Sound Surveillance System (SOSUS) to track Soviet submarines. They were in service 1954\u201379 with Seabees staffing all the Public works. In the 1980s the number of tracking stations was halved with the advent of the Integrated Underwater Surveillance System (IUSS). The NAVFACs were decommissioned by further advances in technology, the end of the Cold War and disclosures by John Walker to the Soviets.\nThe Seabees have also been tasked building Naval Communication facilities. One at Nea Makri Greece was built by MCB 6 in 1962 and upgraded by NMCB 133. Naval Comm Station Sidi Yahya was first built in World War II another is NavCommSta Guam. It started out on the island as the Joint Communications Agency (JCA) in 1945.\nNaval Support Unit: Department of State/Embassy security.\nIn 1964, at the height of the Cold War, Seabees were assigned to the State Department because listening devices were found in the Embassy of the United States in Moscow. Those initial Seabees were \"Naval Mobile Construction Battalion FOUR, Detachment November\". The U.S. had just constructed a new embassy in Warsaw. After what had been found in Moscow Seabees were dispatched and found many \"bugs\" there also. This led to the creation of the Naval Support Unit in 1966 as well as the decision to make it permanent two years later. That year William Darrah, a Seabee of the support unit, is credited with saving the U.S. Embassy in Prague, Czechoslovakia from a potentially disastrous fire. In 1986, \"as a result of reciprocal expulsions ordered by Washington and Moscow\" Seabees were sent to \"Moscow and Leningrad to help keep the embassy and the consulate functioning\".\nThe Support Unit has a limited number of special billets for select NCOs, E-5 and above. These Seabees are assigned to the Department of State and attached to Diplomatic Security. Those chosen can be assigned to the Regional Security Officer of a specific embassy or be part of a team traveling from one embassy to the next. Duties include the installation of alarm systems, CCTV cameras, electromagnetic locks, safes, vehicle barriers, and securing compounds. They can also assist with the security engineering in sweeping embassies (electronic counter-intelligence). They are tasked with new construction or renovations in security sensitive areas and supervise private contractors in non-sensitive areas. Due to Diplomatic protocol the Support Unit is required to wear civilian clothes most of the time they are on duty and receive a supplemental clothing allowance for this. The information regarding this assignment is very scant, but State Department records in 1985 indicate department security had 800 employees, plus 1,200 Marines and 115 Seabees. That Seabee number is roughly the same today.\nCold War winds down.\nAs the Cold War wound down, new challenges and changes came for the Seabees starting with the increased incidence of terrorism. This was in addition to ongoing Seabee support missions for USN/USMC bases worldwide. Cold War Facilities still required support, like the Polaris and Poseidon submarines at Holy Loch, Rota. In 1971, the Seabees began the huge project on Diego Garcia in the Indian Ocean. It was completed in 1987 at a cost of $200\u00a0million. With the extended construction timeline, it is difficult to inflation-adjust that cost into today's dollars. The complex accommodates the Navy's largest ships and cargo planes. The base served as a staging facility for Operations Desert Shield and Desert Storm. Additionally, Seabees were also tasked upgrading and expanding Naval Air Station Sigonella, Sicily for the United States Sixth Fleet.\nIn 1983, a truck bomb demolished the Marine's barracks in Beirut, Lebanon. From the Beirut International Airport Druze militia artillery harassed the Marines. NMCB-1 was in Rota and sent its AirDet to construct bunkers for the Marines. EO2 Kirt May became the first Seabee post-Vietnam to receive a Purple Heart while on this mission.\nCN Carmella Jones became the first female Seabee when she cross-rated to Equipment Operator during the summer of 1972.\nInternational terrorism.\nThe Cold war did not end until 1991 and 9/11 was further off yet, but SW2 Robert Stethem was executed by the Lebanese Shia militia Hezbollah when they hijacked TWA Flight 847 in 1985. Stethem was a diver in UCT 1. The Navy named in his honor. On 24 August 2010, during a shipboard ceremony, Stethem was posthumously honored to the rank of Master Chief Constructionman (CUCM) by the Master Chief Petty Officer of the Navy and given the Prisoner of War Medal.\nPersian Gulf War.\nOver 5,000 Seabees served in the Gulf War. In August 1990 the 1st Marine Expeditionary Force (I MEF) was assigned NMCBs 4, 5, 7, and 40. The first Seabees in theater were a Det from ABC 1, followed by a Det from ACB 2 and then CBUs 411 and 415. Mid September Air-Dets from the four battalions deployed to construct air fields for Marine Air Groups (MAG) 11, 13, 16, and 25 of the 3rd Marine Air Wing. NMCB 7 was the first Battalion to arrive. Camp Nomad was a NMBC-74 project at Ras Al Mishab for MAG 26. Camps were constructed for both the 1st and 2nd Marine Divisions as well as Hq complexes for MEF I and II. In Saudi Arabia, Seabees built numerous camps, galleys, runways, aprons, helo zones, plus two 500-bed Fleet Hospitals near Al-Jubayl. The 3rd NCR was activated to provide a command echelon. NMCBs 24 and 74 also deployed in support of the Marines.\nIraq, Afghanistan, and the war on terrorism.\nSeabees deployed in both initial invasions of the Afghanistan War and Iraq War. All active and reserve NMCBs and NCRs were deployed to building to work on civil infrastructure. One of the most visible tasks assigned to the NCF was the removal of statues of Saddam Hussein in Baghdad.\nIn Afghanistan, the Seabees' main task was the construction of multiple forward operating bases. NMCB 133 deployed to FOB Camp Rhino and help build Kandahar Airfield where a detention facility was constructed as well.\nSince 2002, Seabees have provided civic action support in the Philippines, most notably near Abu Sayyaf's jungle training area in the southern Philippines. Seabees work with Army, Marines, and Air Force under the Joint Special Operations Task Force - Philippines.\nSeabees have supported the war on terrorism ever since the invasion with numerous deployments over the years.\nNaval Construction Force (NCF).\nAt present, there are six active-duty Naval Mobile Construction Battalions (NMCBs) in the United States Navy, split between the Pacific Fleet and the Atlantic Fleet.\n30th Naval Construction Regiment is located on Guam. Naval Construction Battalion Center Port Hueneme, CA is homeport to the Regiment's battalions.\n22nd Naval Construction Regiment is stationed at Naval Construction Battalion Center (Gulfport, Mississippi) the homeport to the Atlantic fleet CBs.\nNCF Reserve\nFrom the 1960s through 1991, reserve battalions were designated as \"Reserve Naval Mobile Construction Battalions\" (RNMCBs). After 1991 \"Reserve\" was dropped with the integration of reserve units within the NCF making all battalions NMCBs\nDetachment: A construction crew that is \"detached\" from the battalion's \"main body\" deployment site. The size is determined by the project scale and timeline.\nBattalion: The battalion is the basic NCF unit with a HQ Company plus four Construction Companies: A, B, C, &amp; D. CBs are organized to function as independent self sufficient units.\nRegiment: Naval Construction Regiments (NCRs) provide a higher echelon command to three or four CBs operating on close proximity.\nNaval Construction Groups 1 and 2: In 2013, Seabee Readiness Groups (SRGs) were decommissioned, and re-organized as NCG-1 and NCG-2. They are regimental-level command groups tasked with administrative and operational control of CBs, as well as conducting pre deployment training for all assigned units. NCG-2 is based at CBC Gulfport while NCG-1 is at CBC Port Hueneme.\nSeabee Engineer Reconnaissance Team (SERTs)\nSERTs are the Special operations capable element of the NCF developed by the First Naval Construction Division (1st NCD) in Operation Iraqi Freedom. They are intended to provide engineering assessments in the field in support of the United States Marine Corps Reconnaissance Battalions. A team has two CEC officers and eight enlisted Seabees, augmented by additional personnel as needed. A team has three elements: liaison, security, and reconnaissance. The liaison (LNO) element has an officer and two communications specialists responsible for communicating the assessments and intelligence. Reconnaissance has the other officer, who is the Officer-in-Charge (OIC), a BU or SW cpo with bridge construction experience. The team has a corpsman or medically trained member, the remainder are selected for being the most qualified in their trade. All are required to have the Seabee Warfare pin. In 2013, 1st Naval Construction Division along with SERT's were decommissioned. Today, UCTs performance demonstrate the SERT concept for NECC.\nSeabees outside the NCF.\nAmphibious Construction Battalions (PHIBCBs)\nACBs (or PHIBCB) were preceded by the pontoon assembly CBs formed during World War II. On 31 October 1950, MCBs 104 and 105 were re-designated ACB 1 and ACB 2, and assigned to Naval Beach Groups. ACBs report to surface TYCOMs. Additionally, in an ACB half the enlisted are a construction rate while the other half are fleet.\nConstruction Battalion Maintenance Units\nWhen during World War II these units had 1/4 the personnel of a CB. Their task was to assume maintenance of bases once CBs had completed construction. Today, CBMU's provide public works support at Naval Support Activities, Forward Operating Bases, and Fleet Hospital/Expeditionary Medical Facilities during wartime or contingency operations for a Marine Expeditionary Force (MEF), Marine Expeditionary Group (MEG), or NSW. They also provide disaster recovery support to Naval Regional Commanders in CONUS.\nNAVFAC Engineering &amp; Expeditionary Warfare Center Ocean Facilities Department. Gives support to the Fleet through the support of Underwater Construction Teams. UCTs deploy worldwide to conduct underwater construction, inspection, repair, and underwater demolition.\nUnderwater Construction Teams (UCT)\nUCTs deploy worldwide tasked with underwater construction, inspections, repairs, and demolition operations. They can support a Fleet Marine Force amphibious operation or provide combat service support ashore. UCT1 is home ported at Little Creek, Virginia, while UCT2 is at Port Hueneme, California.\nAfter basic UCT training a diver is qualified as a 2nd Class Diver. Training is 26 weeks at the Dive school at Panama City, Florida.\nIt includes a tactical training phase for advanced combat and demolitions skills.\nThe training qualifies divers as Underwater Construction Technicians skilled in: seafloor excavation, hydrographic surveys, search and recovery, engineering reconnaissance, and precision demolitions. Senior NCOs are schooled for their supervisory positions whether construction or demolition.\nUCT divers can apply for selection to support the Naval Special Warfare Development Group.\nPublic Works: U.S. Naval Bases\nThese units have CEC officers leading them and enlisted Seabees for the various crews. About one-third of new Seabees are assigned to Public Works Departments (PWD) at naval installations both within the United States and overseas. While stationed at a Public Works Department, a Seabee can get specialized training and experience in multiple facets of their rating. Many bases have civilians that augment Public Works, but the department is a military operation.\nCombat Service Support Detachments (CSSD) / Naval Special Warfare (NSW)\nThe Seabee detachments have several hundred supporting Naval Special Warfare (NSW) units based out of Coronado, CA, and Virginia Beach, VA. Field support can include camp construction, camp and vehicle maintenance, power generation, transportation logistics, and water purification. The assignment requires additional training in first aid, small arms, driving, specialized equipment, and qualifying as Expeditionary Warfare Specialists. With that qualification a Seabee can be classified as 5306 \u2013 Naval Special Warfare (Combat Service Support) or 5307 \u2013 Naval Special Warfare (Combat Support). They also can apply for selection to support the Naval Special Warfare Development Group.\nTraining and rates.\nTrainees begin \"A\" School (trade school) upon completion of boot: 4 weeks classroom, 8 weeks hands-on. From \"A\" School, trainees most often report to a NMCB or ACB. There, recruits go through four-weeks of Expeditionary Combat Skills (ECS), which is also required for those who report to a Navy Expeditionary Combat Command. ECS provides basic training in map reading, combat first aid, recon and other combat-related skills. Half of each course is spent on basic marksmanship to qualify with the M4 carbine and the M9 service pistol. Those posted to Alfa Company of an NMCB may be assigned to a crew-served weapon, like the MK 19 40\u00a0mm grenade launcher, the M2 Browning .50-caliber machine gun or the M240 machine gun. Many reserve units still field the M60 machine gun. Seabees were last in the U.S. military to wear the U.S. Woodland camouflage uniform and the Desert Camouflage Uniform. They now have the Navy Working Uniform Type III and use ALICE field gear. Some units with the Marines will use USMC-issue Improved load-bearing equipment (ILBE).\nCurrent rates: The current ratings were adopted by the Navy in 1948.\nThe Seabee \"constructionman\" ranks of E-1 through E-3 are designated by sky-blue stripes on uniforms. The color was adopted in 1899 as a uniform trim color designating the Civil Engineer Corps, but was later given up. Its continued use is a bit of Naval Heritage in the NCF.\nAt paygrade E-8, the Builder, Steelworker, and Engineering Aid rates combine into a single rate: Senior Chief Constructionman (CUCS). Before NAVADMIN 054/21, at the E-9 paygrade they were referred to as a Master Chief Constructionman (CUCM).\nBefore NAVADMIN 054/21, the remaining Seabee rates combined only at the E-9 paygrade:\nPer NAVADMIN 054/21: Constructionman Master Chief (CUCM), Equipmentman Master Chief (EQCM) and Utilities Constructionman Master Chief (UCCM) renamed Seabee Master Chief (CBCM). Those Master Chiefs already in CUCM, EQCM or UCCM ratings were to be automatically converted to CBCM on 15 March 2021, but current source ratings badges were to be retained.\nDiver is a qualification that the various rates can obtain with three grades: Basic Underwater Construction Technician/ NEC B17A (2nd Class Diver), Advanced Underwater Construction Technician/ NEC B18A (1st Class Diver), and Master Underwater Construction Technician/ NEC B16A (Master diver). Seabee divers are attached to five principal commands outside the NCF:\nThe \"Seabee\" and Unit insignias.\nOn 1 March 1942 the RADM Moreell recommended that an insignia be created to promote \"esprit de corps\" in the new CBs to ID their equipment as the Air corps did to ID squadrons. It was not intended for uniforms. Frank J. Iafrate, a civilian file clerk at Quonset Point Advance Naval Base, Davisville, Rhode Island, who created the original \"Disney Style\" Seabee. In early 1942 his design was sent to RADM Moreell who made a single request: that the Seabee being set inside a letter Q, for Quonset Point, be changed to a hawser rope and it would be officially adopted.\nThe Seabees had a second Logo. It was of a shirtless constructionman holding a sledge hammer with a rifle strapped across his back standing upon the words \"Construimus Batuimus USN\". The figure was on a shield with a blue field across the top and vertical red and white stripes. A small CEC logo is left of the figure and a small anchor is to the right. This logo was incorporated into many CB Unit insignias.\nDuring World War II, artists working for Disney Insignia Department designed logos for about ten Seabee units including the: 60th NCB, 78th NCB 112th NCB, and the 133rd NCB. There are two Disney published Seabee logos that are not identified with any unit.\nQualification badges and Unit awards.\nThe military qualification badge for the Seabees is known as the Seabee combat warfare specialist insignia (SCW). It was created in 1993 for both officers and enlisted personnel attached to qualifying units: NMCBs, ACBs, UCTs, or NCRs. Its designer, Commander Ross S. Selvidge, CEC, USNR, was the first to wear the insignia.\nThe Fleet Marine Force Insignia or Fleet Marine Force pin (FMF pin), is for USN officers or enlisted trained and qualified to support the USMC. It comes in three classes : enlisted, officer, and chaplain. For requirements, see: Fleet Marine Force Warfare Specialist (EFMFWS) Program per OPNAV Instruction 1414.4B.\nThe Peltier Award is given annually to the \"Best of Type\" active duty Construction Battalion. It was instituted by Rear Admiral Eugene J. Peltier CEC in 1960. He was Commander of BuDocks 1959\u20131962.\nSeabee barge carriers.\nThere were six \"Seabee\" ships built: the SS \"Cape Mendocino\" (T-AKR-5064), the , and three operated by Lykes Brothers Steamship Company. (the SS Doctor Lykes, the SS Tillie Lykes, and the SS Almeria Lykes). The NCF is the principal user of Seabee barges. Barges are shuttled to and from the mother ship, facilitating the unloading of containerized cargo wherever needed. These ships have an elevator system for lifting the barges out of the water at the stern onto the vessel. Barges, loaded or not are elevated to one of the three decks and then moved forward towards the bow on a track to be stored. The ship can carry 38 barges, 12 each on the lower decks and 14 on the upper. The 38 barges have a total capacity for 160 shipping containers. They have a draft of 2.5', and measure 97'x35'. Besides the barges, the ship has a fuel storage capacity of nearly 36000 m3 (9,510,194 gal.) built in its sides and double hull, allowing it to double as a fuel transport. The ships were purchased by the Military Sealift Command.\nMuseums.\nThe U.S. Navy Seabee Museum is located outside the main gate of Naval Base Ventura County in Port Hueneme, California. In July 2011, the new facility opened with galleries, a grand hall, a theater, storage, and research areas.\nThe Seabee Heritage Center is the Atlantic Coast Annex of the Seabee Museum in Port Hueneme. It opened in 1995. Exhibits at the Gulfport Annex are provided by the Seabee Museum in Port Hueneme.\nThe Seabee Museum and Memorial Park in Davisville, Rhode Island was opened in the late 1990s. A Fighting Seabee Statue is located there.\nSee also.\nOther U.S. military construction/engineering units:\nNotes.\nWorld War II\nMarine Corps, Seabees outside the NCF\nNCDUs, Seabees outside the NCF\nUDTs, Seabees outside the NCF\nSeabee North Slope Oil Exploration 1944\nCold War: Korea \u2013 Seabee Teams\nCold War: Antarctica\nCold War: Vietnam\nCold War: CIA\nIraq Afghanistan\nSeabee insignia\nNaval Support Unit\nSEABEE Barge Carriers\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29485", "revid": "44120587", "url": "https://en.wikipedia.org/wiki?curid=29485", "title": "Skyscraper", "text": "Tall habitable building\nA skyscraper is a tall building with many habitable floors. Most modern sources define skyscrapers as being at least or in height, though there is no universally accepted definition, other than being very tall high-rise buildings. Skyscrapers may host offices, hotels, residential spaces, and retail spaces. Skyscrapers are a common feature of large cities, often due to a high demand for space and limited availability of land. \nOne common feature of skyscrapers is having a steel frame that supports curtain walls. These curtain walls either bear on the framework below or are suspended from the framework above, rather than resting on load-bearing walls of conventional construction. Some early skyscrapers have a steel frame that enables the construction of load-bearing walls taller than those made of reinforced concrete. Modern skyscraper walls are not load-bearing, and most skyscrapers are characterized by large surface areas of windows made possible by steel frames and curtain walls. However, skyscrapers can have curtain walls that mimic conventional walls with a small surface area of windows. Modern skyscrapers often have a tubular structure, and are designed to act like a hollow cylinder to resist wind, seismic, and other lateral loads. To appear more slender, allow less wind exposure and transmit more daylight to the ground, many skyscrapers have a design with setbacks, which in some cases is also structurally required.\nSkyscrapers first appeared in the United States at the end of the 19th century, especially in the cities of Chicago and New York City. Following a building boom across the western world in the early 20th century, skyscraper development was halted in the 1930s by the Great Depression, and did not resume until the 1950s. A skyscraper boom in the downtowns of many American cities took place during the 1960s to 1980s. Towards the second half of the 20th century, skyscrapers began to be built more frequently outside the United States, particularly in East Asia and Southeast Asia during the 1990s. China has since overtaken the United States as the country with the most skyscrapers. Skyscrapers are an increasingly global phenomenon, and can be found in over 70 countries.\nThere are over 7 thousand skyscrapers over in height worldwide, most of which were built in the 21st century. Over three-quarters of skyscrapers taller than 150 m (492 ft) are located in Asia. Eighteen cities in the world have more than 100 skyscrapers that are taller than , most recently Toronto and Singapore in 2025. The city with the most skyscrapers in the world is Hong Kong, with 569 skyscrapers, followed by Shenzhen in China with 444, New York City with 317, and Dubai in the United Arab Emirates with 270. Dubai is home to the tallest skyscraper in the world, the Burj Khalifa. \nDefinition.\nThe term \"skyscraper\" was first applied to buildings of steel-framed construction of at least 10 stories in the late 19th century, a result of public amazement at the tall buildings being built in major American cities like New York City, Philadelphia, Boston, Chicago, Detroit, and St. Louis.\nThe first steel-frame skyscraper was the Home Insurance Building, originally 10 stories with a height of , in Chicago in 1885; two additional stories were added. Some point to Philadelphia's 10-story Jayne Building (1849\u201350) as a proto-skyscraper, or to New York's seven-floor Equitable Life Building, built in 1870. Steel skeleton construction has allowed for today's supertall skyscrapers now being built worldwide. The nomination of one structure versus another being the first skyscraper, and why, depends on what factors are stressed.\nThe structural definition of the word \"skyscraper\" was refined later by architectural historians, based on engineering developments of the 1880s that had enabled construction of tall multi-story buildings. This definition was based on the steel skeleton\u2014as opposed to constructions of load-bearing masonry, which passed their practical limit in 1891 with Chicago's Monadnock Building.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;What is the chief characteristic of the tall office building? It is lofty. It must be tall. The force and power of altitude must be in it, the glory and pride of exaltation must be in it. It must be every inch a proud and soaring thing, rising in sheer exaltation that from bottom to top it is a unit without a single dissenting line.\n\u2014\u00a0Louis Sullivan's \"The Tall Office Building Artistically Considered\" (1896)\nSome structural engineers define a high-rise as any vertical construction for which wind is a more significant load factor than earthquake or weight. Note that this criterion fits not only high-rises but some other tall structures, such as towers.\nDifferent organizations from the United States and Europe define skyscrapers as buildings at least in height or taller, with \"supertall\" skyscrapers for buildings higher than and \"megatall\" skyscrapers for those taller than .\nThe tallest structure in ancient times was the Great Pyramid of Giza in ancient Egypt, built in the 26th century BC. It was not surpassed in height for thousands of years, the Lincoln Cathedral having exceeded it in 1311\u20131549, before its central spire collapsed. The latter in turn was not surpassed until the Washington Monument in 1884, which was surpased by the Eiffel Tower in 1889, the first ever supertall structure. However, being uninhabited, none of these structures actually comply with the modern definition of a skyscraper, only in 1930 the Chrysler Building surpassed the Eiffel Tower by pinnacle height, becoming the first skyscraper being the tallest structure built until then and the first supertall skyscraper by pinnacle height, only to be surpassed a year later in every regard by the Empire State Building as the first supertall skyscraper also by roof height.\nHigh-rise apartments flourished in classical antiquity. Ancient Roman insulae in imperial cities reached 10 and more stories. Beginning with Augustus (r. 30\u00a0BC-14\u00a0AD), several emperors attempted to establish limits of for multi-stories buildings, but were met with only limited success. Lower floors were typically occupied by shops or wealthy families, with the upper rented to the lower classes. Surviving Oxyrhynchus Papyri indicate that seven-stories buildings existed in provincial towns such as in 3rd century AD Hermopolis in Roman Egypt.\nThe skylines of many important medieval cities had large numbers of high-rise urban towers, built by the wealthy for defense and status. The residential Towers of 12th century Bologna numbered between 80 and 100 at a time, the tallest of which is the high Asinelli Tower. A Florentine law of 1251 decreed that all urban buildings be immediately reduced to less than . Even medium-sized towns of the era are known to have proliferations of towers, such as the 72 towers that ranged up to height in San Gimignano.\nThe medieval Egyptian city of Fustat housed many high-rise residential buildings, which Al-Muqaddasi in the 10th century described as resembling minarets. Nasir Khusraw in the early 11th century described some of them rising up to 14 stories, with roof gardens on the top floor complete with ox-drawn water wheels for irrigating them. Cairo in the 16th century had high-rise apartment buildings where the two lower floors were for commercial and storage purposes and the multiple stories above them were rented out to tenants. An early example of a city consisting entirely of high-rise housing is the 16th-century city of Shibam in Yemen. Shibam was made up of over 500 tower houses, each one rising 5 to 11 stories high, with each floor being an apartment occupied by a single family. The city was built in this way in order to protect it from Bedouin attacks. Shibam still has the tallest mudbrick buildings in the world, with many of them over high.\nAn early modern example of high-rise housing was in 17th-century Edinburgh, Scotland, where a defensive city wall defined the boundaries of the city. Due to the restricted land area available for development, the houses increased in height instead. Buildings of 11 stories were common, and there are records of buildings as high as 14 stories. Many of the stone-built structures can still be seen today in the old town of Edinburgh. The oldest iron framed building in the world, although only partially iron framed, is The Flaxmill in Shrewsbury, England. Built in 1797, it is seen as the \"grandfather of skyscrapers\", since its fireproof combination of cast iron columns and cast iron beams developed into the modern steel frame that made modern skyscrapers possible. In 2013 funding was confirmed to convert the derelict building into offices.\nEarly skyscrapers.\nIn 1857, Elisha Otis introduced the safety elevator at the E. V. Haughwout Building in New York City, allowing convenient and safe transport to buildings' upper floors. Otis later introduced the first commercial passenger elevators to the Equitable Life Building in 1870, considered by some architectural historians to be the first skyscraper. Another crucial development was the use of a steel frame instead of stone or brick, otherwise the walls on the lower floors on a tall building would be too thick to be practical. An early development in this area was Oriel Chambers in Liverpool, England, built in 1864. It was only five floors high. The Royal Academy of Arts states, \"critics at the time were horrified by its 'large agglomerations of protruding plate glass bubbles'. In fact, it was a precursor to Modernist architecture, being the first building in the world to feature a metal-framed glass curtain wall, a design element which creates light, airy interiors and has since been used the world over as a defining feature of skyscrapers\".\nFurther developments led to what many individuals and organizations consider the world's first skyscraper, the ten-story Home Insurance Building in Chicago, built from 1884 to 1885. While its original height of 42.1\u00a0m (138\u00a0ft) does not qualify as a skyscraper today, it was record setting for the day. The building of tall buildings in the 1880s gave the skyscraper its first architectural movement, broadly termed the Chicago School, which developed what has been called the Commercial Style.\nThe architect, Major William Le Baron Jenney, created a load-bearing structural frame. In this building, a steel frame supported the entire weight of the walls, instead of load-bearing walls carrying the weight of the building. This was then draped with a stone curtain for aesthetic purposes. This development led to the \"Chicago skeleton\" form of construction. In addition to the steel frame, the Home Insurance Building also utilized fireproofing, elevators, and electrical wiring, key elements in most skyscrapers today.\nBurnham and Root's Rand McNally Building in Chicago, 1889, was the first all-steel framed skyscraper, while Louis Sullivan's Wainwright Building in St. Louis, Missouri, 1891, was the first steel-framed building with soaring vertical bands to emphasize the height of the building and is therefore considered to be the first early skyscraper. In 1889, the Mole Antonelliana in Italy was 197\u00a0m (549\u00a0ft) tall.\nMost early skyscrapers emerged in the land-strapped areas of New York City and Chicago toward the end of the 19th century. A land boom in Melbourne, Australia between 1888 and 1891 spurred the creation of a significant number of early skyscrapers, though none of these were steel reinforced and few remain today. Height limits and fire restrictions were later introduced. In the late 1800s, London builders found building heights limited due to issues with existing buildings. High-rise development in London is restricted at certain sites if it would obstruct protected views of St Paul's Cathedral and other historic buildings. This policy, 'St Paul's Heights', has officially been in operation since 1927.\nConcerns about aesthetics and fire safety had likewise hampered the development of skyscrapers across continental Europe for the first half of the 20th century. By 1940, there were around 100 high-rise buildings in Europe (List of early skyscrapers). Some examples of these are the tall 1898 Witte Huis \"(White House)\" in Rotterdam; the tall PAST Building (1906\u20131908) in Warsaw; the Royal Liver Building in Liverpool, completed in 1911 and high; the tall 1924 Marx House in D\u00fcsseldorf, the tall in Berlin, built in 1924, the tall Hansahochhaus in Cologne, Germany, built in 1925; the Kungstornen \"(Kings' Towers)\" in Stockholm, Sweden, which were built 1924\u201325; the in Berlin, Germany, built in 1927; the Edificio Telef\u00f3nica in Madrid, Spain, built in 1929; the Boerentoren in Antwerp, Belgium, built in 1932; the Prudential Building in Warsaw, Poland, built in 1934; and the Torre Piacentini in Genoa, Italy, built in 1940.\nAfter an early competition between New York City and Chicago for the world's tallest building, New York took the lead by 1895 with the completion of the tall American Surety Building, leaving New York with the title of the world's tallest building for many years. America by far produced the most skyscrapers in this period. \nModern skyscrapers.\nModern skyscrapers are built with steel or reinforced concrete frameworks and curtain walls of glass or polished stone. They use mechanical equipment such as water pumps and elevators. Since the 1960s, according to the CTBUH (Council on Tall Buildings and Urban Habitat) the skyscraper has been reoriented away from a symbol for North American corporate power to instead communicate a city or nation's place in the world.\nThe construction of very tall skyscrapers entered a three-decades-long era of stagnation in 1930 due to the Great Depression and then World War\u00a0II. Shortly after the war ended, Russia began construction on a series of skyscrapers in Moscow. Seven, dubbed the \"Seven Sisters\", were built between 1947 and 1953; and one, the Main building of Moscow State University, was the tallest building in Europe for nearly four decades (1953\u20131990). Other skyscrapers in the style of Socialist Classicism were erected in East Germany (Frankfurter Tor), Poland (PKiN), Ukraine (Hotel Moscow), Latvia (Academy of Sciences), and other Eastern Bloc countries. Western European countries also began to permit taller skyscrapers during the years immediately following World War II. Early examples include Edificio Espa\u00f1a (Spain) and Torre Breda (Italy).\nFrom the 1930s onward, skyscrapers began to appear in various cities in East and Southeast Asia as well as in Latin America. Finally, they also began to be constructed in cities in Africa, the Middle East, South Asia, and Oceania from the late 1950s.\nSkyscraper projects after World War II typically rejected the classical designs of the early skyscrapers, instead embracing the uniform international style; many older skyscrapers were redesigned to suit contemporary tastes or even demolished\u2014such as New York's Singer Building, once the world's tallest skyscraper.\nGerman-American architect Ludwig Mies van der Rohe became one of the world's most renowned architects in the second half of the 20th century. He conceived the glass fa\u00e7ade skyscraper and, along with Norwegian Fred Severud, designed the Seagram Building in 1958, a skyscraper that is often regarded as the pinnacle of modernist high-rise architecture.\nSkyscraper construction surged throughout the 1960s. The impetus behind the upswing was a series of transformative innovations which made it possible for people to live and work in \"cities in the sky\".\nIn the early 1960s Bangladeshi-American structural engineer Fazlur Rahman Khan, considered the \"father of tubular designs\" for high-rises, discovered that the dominating rigid steel frame structure was not the only system apt for tall buildings, marking a new era of skyscraper construction in terms of multiple structural systems. His central innovation in skyscraper design and construction was the concept of the \"tube\" structural system, including the \"framed tube\", \"trussed tube\", and \"bundled tube\". His \"tube concept\", using all the exterior wall perimeter structure of a building to simulate a thin-walled tube, revolutionized tall building design. These systems allow greater economic efficiency, and also allow skyscrapers to take on various shapes, no longer needing to be rectangular and box-shaped. The first building to employ the tube structure was the Chestnut De-Witt apartment building, considered to be a major development in modern architecture. These new designs opened an economic door for contractors, engineers, architects, and investors, providing vast amounts of real estate space on minimal plots of land. Over the next fifteen years, many towers were built by Fazlur Rahman Khan and the \"Second Chicago School\", including the hundred-story John Hancock Center and the massive Willis Tower. Other pioneers of this field include Hal Iyengar, William LeMessurier, and Minoru Yamasaki, the architect of the World Trade Center.\nMany buildings designed in the 1970s lacked a particular style and recalled ornamentation from earlier buildings designed before the 1950s. These design plans ignored the environment and loaded structures with decorative elements and extravagant finishes. This approach to design was opposed by Fazlur Khan and he considered the designs to be whimsical rather than rational. Moreover, he considered the work to be a waste of precious natural resources. Khan's work promoted structures integrated with architecture and the least use of material resulting in the smallest impact on the environment. The next era of skyscrapers will focus on the environment including performance of structures, types of material, construction practices, absolute minimal use of materials/natural resources, embodied energy within the structures, and more importantly, a holistically integrated building systems approach.\nModern building practices regarding supertall structures have led to the study of \"vanity height\". Vanity height, according to the CTBUH, is the distance between the highest floor and its architectural top (excluding antennae, flagpole or other functional extensions). Vanity height first appeared in New York City skyscrapers as early as the 1920s and 1930s but supertall buildings have relied on such uninhabitable extensions for on average 30% of their height, raising potential definitional and sustainability issues. The current era of skyscrapers focuses on sustainability, its built and natural environments, including the performance of structures, types of materials, construction practices, absolute minimal use of materials and natural resources, energy within the structure, and a holistically integrated building systems approach. LEED is a current green building standard.\nArchitecturally, with the movements of Postmodernism, New Urbanism and New Classical Architecture, that established since the 1980s, a more classical approach came back to global skyscraper design, that remains popular today. Examples are the Wells Fargo Center, NBC Tower, Parkview Square, 30 Park Place, the Messeturm, the iconic Petronas Towers and Jin Mao Tower.\nOther contemporary styles and movements in skyscraper design include organic, sustainable, neo-futurist, structuralist, high-tech, deconstructivist, blob, digital, streamline, novelty, critical regionalist, vernacular, Neo Art Deco and neohistorist, also known as revivalist.\n3 September is the global commemorative day for skyscrapers, called \"Skyscraper Day\".\nNew York City developers competed among themselves, with successively taller buildings claiming the title of \"world's tallest\" in the 1920s and early 1930s, culminating with the completion of the Chrysler Building in 1930 and the Empire State Building in 1931, the world's tallest building for forty years. The first completed tall World Trade Center tower became the world's tallest building in 1972. However, it was overtaken by the Sears Tower (now Willis Tower) in Chicago within two years. The tall Sears Tower stood as the world's tallest building for 24 years, from 1974 until 1998, until it was edged out by Petronas Twin Towers in Kuala Lumpur, which held the title for six years.\nDesign and construction.\nThe design and construction of skyscrapers involves creating safe, habitable spaces in very tall buildings. The buildings must support their weight, resist wind and earthquakes, and protect occupants from fire. Yet they must also be conveniently accessible, even on the upper floors, and provide utilities and a comfortable climate for the occupants. The problems posed in skyscraper design are considered among the most complex encountered given the balances required between economics, engineering, and construction management.\nOne common feature of skyscrapers is a steel framework from which curtain walls are suspended, rather than load-bearing walls of conventional construction. Most skyscrapers have a steel frame that enables them to be built taller than typical load-bearing walls of reinforced concrete. Skyscrapers usually have a particularly small surface area of what are conventionally thought of as walls. Because the walls are not load-bearing most skyscrapers are characterized by surface areas of windows made possible by the concept of steel frame and curtain wall. However, skyscrapers can also have curtain walls that mimic conventional walls and have a small surface area of windows.\nThe concept of a skyscraper is a product of the industrialized age, made possible by cheap fossil fuel derived energy and industrially refined raw materials such as steel and concrete. The construction of skyscrapers was enabled by steel frame construction that surpassed brick and mortar construction starting at the end of the 19th century and finally surpassing it in the 20th century together with reinforced concrete construction as the price of steel decreased and labor costs increased.\nThe steel frames become inefficient and uneconomic for supertall buildings as usable floor space is reduced for progressively larger supporting columns. Since about 1960, tubular designs have been used for high rises. This reduces the usage of material (more efficient in economic terms \u2013 Willis Tower uses a third less steel than the Empire State Building) yet allows greater height. It allows fewer interior columns, and so creates more usable floor space. It further enables buildings to take on various shapes.\nElevators are characteristic to skyscrapers. In 1852 Elisha Otis introduced the safety elevator, allowing convenient and safe passenger movement to upper floors. Today major manufacturers of elevators include Otis, ThyssenKrupp, Schindler, and KONE.\nAdvances in construction techniques have allowed skyscrapers to narrow in width, while increasing in height. Some of these new techniques include mass dampers to reduce vibrations and swaying, and gaps to allow air to pass through, reducing wind shear.\nBasic design considerations.\nGood structural design is important in most building design, but particularly for skyscrapers since even a small chance of catastrophic failure is unacceptable given the tremendous damage such failure would cause. This presents a paradox to civil engineers: the only way to assure a lack of failure is to test for all modes of failure, in both the laboratory and the real world. But the only way to know of all modes of failure is to learn from previous failures. Thus, no engineer can be absolutely sure that a given structure will resist all loadings that could cause failure; instead, one can only have large enough margins of safety such that a failure is acceptably unlikely. When buildings do fail, engineers question whether the failure was due to some lack of foresight or due to some unknown factor.\nLoading and vibration.\nThe load a skyscraper experiences is largely from the force of the building material itself. In most building designs, the weight of the structure is much larger than the weight of the material that it will support beyond its own weight. In technical terms, the dead load, the load of the structure, is larger than the live load, the weight of things in the structure (people, furniture, vehicles, etc.). As such, the amount of structural material required within the lower levels of a skyscraper will be much larger than the material required within higher levels. This is not always visually apparent. The Empire State Building's setbacks are actually a result of the building code at the time (1916 Zoning Resolution), and were not structurally required. On the other hand, John Hancock Center's shape is uniquely the result of how it supports loads. Vertical supports can come in several types, among which the most common for skyscrapers can be categorized as steel frames, concrete cores, tube within tube design, and shear walls.\nThe wind loading on a skyscraper is also considerable. In fact, the lateral wind load imposed on supertall structures is generally the governing factor in the structural design. Wind pressure increases with height, so for very tall buildings, the loads associated with wind are larger than dead or live loads.\nOther vertical and horizontal loading factors come from varied, unpredictable sources, such as earthquakes.\nSteel frame.\nBy 1895, steel had replaced cast iron as skyscrapers' structural material. Its malleability allowed it to be formed into a variety of shapes, and it could be riveted, ensuring strong connections. The simplicity of a steel frame eliminated the inefficient part of a shear wall, the central portion, and consolidated support members in a much stronger fashion by allowing both horizontal and vertical supports throughout. Among steel's drawbacks is that as more material must be supported as height increases, the distance between supporting members must decrease, which in turn increases the amount of material that must be supported. This becomes inefficient and uneconomic for buildings above 40 stories tall as usable floor spaces are reduced for supporting column and due to more usage of steel.\nTube structural systems.\nA new structural system of framed tubes was developed by Fazlur Rahman Khan in 1963. The framed tube structure is defined as \"a three dimensional space structure composed of three, four, or possibly more frames, braced frames, or shear walls, joined at or near their edges to form a vertical tube-like structural system capable of resisting lateral forces in any direction by cantilevering from the foundation\". Closely spaced interconnected exterior columns form the tube. Horizontal loads (primarily wind) are supported by the structure as a whole. Framed tubes allow fewer interior columns, and so create more usable floor space, and about half the exterior surface is available for windows. Where larger openings like garage doors are required, the tube frame must be interrupted, with transfer girders used to maintain structural integrity. Tube structures cut down costs, at the same time allowing buildings to reach greater heights. Concrete tube-frame construction was first used in the DeWitt-Chestnut Apartment Building, completed in Chicago in 1963, and soon after in the John Hancock Center and World Trade Center.\nThe tubular systems are fundamental to tall building design. Most buildings over 40 stories constructed since the 1960s now use a tube design derived from Khan's structural engineering principles, examples including the construction of the World Trade Center, Aon Center, Petronas Towers, Jin Mao Building, and most other supertall skyscrapers since the 1960s. The strong influence of tube structure design is also evident in the construction of the current tallest skyscraper, the Burj Khalifa, which uses a Buttressed core.\nTrussed tube and X-bracing:\nKhan pioneered several other variations of the tube structure design. One of these was the concept of X-bracing, or the trussed tube, first employed for the John Hancock Center. This concept reduced the lateral load on the building by transferring the load into the exterior columns. This allows for a reduced need for interior columns thus creating more floor space. This concept can be seen in the John Hancock Center, designed in 1965 and completed in 1969. One of the most famous buildings of the structural expressionist style, the skyscraper's distinctive X-bracing exterior is actually a hint that the structure's skin is indeed part of its 'tubular system'. This idea is one of the architectural techniques the building used to climb to record heights (the tubular system is essentially the spine that helps the building stand upright during wind and earthquake loads). This X-bracing allows for both higher performance from tall structures and the ability to open up the inside floorplan (and usable floor space) if the architect desires.\nThe John Hancock Center was far more efficient than earlier steel-frame structures. Where the Empire State Building (1931), required about 206 kilograms of steel per square metre and 28 Liberty Street (1961) required 275, the John Hancock Center required only 145. The trussed tube concept was applied to many later skyscrapers, including the Onterie Center, Citigroup Center and Bank of China Tower.\nBundled tube:\nAn important variation on the tube frame is the bundled tube, which uses several interconnected tube frames. The Willis Tower in Chicago used this design, employing nine tubes of varying height to achieve its distinct appearance. The bundled tube structure meant that \"buildings no longer need be boxlike in appearance: they could become sculpture.\"\nTube in tube:\nTube-in-tube system takes advantage of core shear wall tubes in addition to exterior tubes. The inner tube and outer tube work together to resist gravity loads and lateral loads and to provide additional rigidity to the structure to prevent significant deflections at the top. This design was first used in One Shell Plaza. Later buildings to use this structural system include the Petronas Towers.\nOutrigger and belt truss:\nThe outrigger and belt truss system is a lateral load resisting system in which the tube structure is connected to the central core wall with very stiff outriggers and belt trusses at one or more levels. BHP House was the first building to use this structural system followed by the First Wisconsin Center, since renamed U.S. Bank Center, in Milwaukee. The center rises 601 feet, with three belt trusses at the bottom, middle and top of the building. The exposed belt trusses serve aesthetic and structural purposes. Later buildings to use this include Shanghai World Financial Center.\nConcrete tube structures:\nThe last major buildings engineered by Khan were the One Magnificent Mile and Onterie Center in Chicago, which employed his bundled tube and trussed tube system designs respectively. In contrast to his earlier buildings, which were mainly steel, his last two buildings were concrete. His earlier DeWitt-Chestnut Apartments building, built in 1963 in Chicago, was also a concrete building with a tube structure. Trump Tower in New York City is also another example that adapted this system.\nShear wall frame interaction system:\nKhan developed the shear wall frame interaction system for mid high-rise buildings. This structural system uses combinations of shear walls and frames designed to resist lateral forces. The first building to use this structural system was the 35-stories Brunswick Building. The Brunswick building (today known as the \"Cook County Administration Building\") was completed in 1965 and became the tallest reinforced concrete structure of its time. The structural system of Brunswick Building consists of a concrete shear wall core surrounded by an outer concrete frame of columns and spandrels. Apartment buildings up to 70 stories high have successfully used this concept.\nThe elevator conundrum.\nThe invention of the elevator was a precondition for the invention of skyscrapers, given that most people would not (or could not) climb more than a few flights of stairs at a time. The elevators in a skyscraper are not simply a necessary utility, like running water and electricity, but are in fact closely related to the design of the whole structure: a taller building requires more elevators to service the additional floors, but the elevator shafts consume valuable floor space. If the service core, which contains the elevator shafts, becomes too big, it can reduce the profitability of the building. Architects must therefore balance the value gained by adding height against the value lost to the expanding service core.\nMany tall buildings use elevators in a non-standard configuration to reduce their footprint. Buildings such as the former World Trade Center Towers and Chicago's John Hancock Center use sky lobbies, where express elevators take passengers to upper floors which serve as the base for local elevators. This allows architects and engineers to place elevator shafts on top of each other, saving space. Sky lobbies and express elevators take up a significant amount of space, however, and add to the amount of time spent commuting between floors.\nOther buildings, such as the Petronas Towers, use double-deck elevators, allowing more people to fit in a single elevator, and reaching two floors at every stop. It is possible to use even more than two levels on an elevator, although this has never been done. The main problem with double-deck elevators is that they cause everyone in the elevator to stop when only person on one level needs to get off at a given floor.\nBuildings with sky lobbies include the World Trade Center, Petronas Twin Towers, Willis Tower and Taipei 101. The 44th-floor sky lobby of the John Hancock Center also featured the first high-rise indoor swimming pool, which remains the highest in the United States.\nEconomic rationale.\nSkyscrapers are usually situated in city centres where the price of land is high. Constructing a skyscraper becomes justified if the price of land is so high that it makes economic sense to build upward as to minimize the cost of the land per the total floor area of a building. Thus the construction of skyscrapers is dictated by economics and results in skyscrapers in a certain part of a large city unless a building code restricts the height of buildings.\nSkyscrapers are rarely seen in small cities and they are characteristic of large cities, because of the critical importance of high land prices for the construction of skyscrapers. Usually only office, commercial and hotel users can afford the rents in the city center and thus most tenants of skyscrapers are of these classes.\nToday, skyscrapers are an increasingly common sight where land is expensive, as in the centres of big cities, because they provide such a high ratio of rentable floor space per unit area of land.\nAnother disadvantage of very high skyscrapers is the loss of usable floorspace, as many elevator shafts are needed to enable performant vertical travelling. This led to the introduction of express lifts and sky lobbies where transfer to slower distribution lifts can be done.\nEnvironmental impact.\nConstructing a single skyscraper requires large quantities of materials like steel, concrete, and glass, and these materials represent significant embodied energy. Skyscrapers are thus material and energy intensive buildings.\nSkyscrapers have considerable mass, requiring a stronger foundation than a shorter, lighter building. In construction, building materials must be lifted to the top of a skyscraper during construction, requiring more energy than would be necessary at lower heights. Furthermore, a skyscraper consumes much electricity because potable and non-potable water have to be pumped to the highest occupied floors, skyscrapers are usually designed to be mechanically ventilated, elevators are generally used instead of stairs, and electric lights are needed in rooms far from the windows and windowless spaces such as elevators, bathrooms and stairwells.\nSkyscrapers can be artificially lit and the energy requirements can be covered by renewable energy or other electricity generation with low greenhouse gas emissions. Heating and cooling of skyscrapers can be efficient, because of centralized HVAC systems, heat radiation blocking windows and small surface area of the building. There is Leadership in Energy and Environmental Design (LEED) certification for skyscrapers. For example, the Empire State Building received a gold Leadership in Energy and Environmental Design rating in September 2011 and the Empire State Building is the tallest LEED certified building in the United States, proving that skyscrapers can be environmentally friendly. The Gherkin in London, the United Kingdom is another example of an environmentally friendly skyscraper.\nIn the lower levels of a skyscraper a larger percentage of the building floor area must be devoted to the building structure and services than is required for lower buildings:\nIn low-rise structures, the support rooms (chillers, transformers, boilers, pumps and air handling units) can be put in basements or roof space\u2014areas which have low rental value. There is, however, a limit to how far this plant can be located from the area it serves. The farther away it is the larger the risers for ducts and pipes from this plant to the floors they serve and the more floor area these risers take. In practice this means that in highrise buildings this plant is located on 'plant levels' at intervals up the building.\nOperational energy.\nThe building sector accounts for approximately 50% of greenhouse gas emissions, with operational energy accounting for 80-90% of building related energy use. Operational energy use is affected by the magnitude of conduction between the interior and exterior, convection from infiltrating air, and radiation through glazing. The extent to which these factors affect the operational energy vary depending on the microclimate of the skyscraper, with increased wind speeds as the height of the skyscraper increases, and a decrease in the dry bulb temperature as the altitude increases. For example, when moving from 1.5 meters to 284 meters, the dry bulb temperature decreased by 1.85\u00a0\u00b0C while the wind speeds increased from 2.46 meters per seconds to 7.75 meters per second, which led to a 2.4% decrease in summer cooling in reference to the Freedom Tower in New York City. However, for the same building it was found that the annual energy use intensity was 9.26% higher because of the lack of shading at high altitudes which increased the cooling loads for the remainder of the year while a combination of temperature, wind, shading, and the effects of reflections led to a combined 13.13% increase in annual energy use intensity.\nIn a study performed by Leung and Ray in 2013, it was found that the average energy use intensity of a structure with between 0 and 9 floors was approximately 80 kBtu/ft/yr, while the energy use intensity of a structure with more than 50 floors was about 117 kBtu/ft/yr. The slight decrease in energy use intensity over 30-39 floors can be attributed to the fact that the increase in pressure within the heating, cooling, and water distribution systems levels out at a point between 40 and 49 floors and the energy savings due to the microclimate of higher floors are able to be seen. There is a gap in data in which another study looking at the same information but for taller buildings is needed.\nElevators.\nA portion of the operational energy increase in tall buildings is related to the usage of elevators because the distance traveled and the speed at which they travel increases as the height of the building increases. Between 5 and 25% of the total energy consumed in a tall building is from the use of elevators. As the height of the building increases it is also more inefficient because of the presence of higher drag and friction losses.\nEmbodied energy.\nThe embodied energy associated with the construction of skyscrapers varies based on the materials used. Embodied energy is quantified per unit of material. Skyscrapers inherently have higher embodied energy than low-rise buildings due to the increase in material used as more floors are built. For all floor types except for steel-concrete floors, it was found that after 60 stories, there was a decrease in unit embodied energy but when considering all floors, there was exponential growth due to a double dependence on height. The first of which is the relationship between an increase in height leading to an increase in the quantity of materials used, and the second being the increase in height leading to an increase in size of elements to increase the structural capacity of the building. A careful choice in building materials can likely reduce the embodied energy without reducing the number of floors constructed within the bounds presented.\nEmbodied carbon.\nSimilar to embodied energy, the embodied carbon of a building is dependent on the materials chosen for its construction. Both methods of measuring the embodied carbon show that there is a point where the embodied carbon is lowest before increasing again as the height increases. For the total embodied carbon it is dependent on the structure type, but is either around 40 stories, or approximately 60 stories. For the square meter of gross floor area, the lowest embodied carbon was found at either 40 stories, or approximately 70 stories.\nAir pollution.\nIn urban areas, the configuration of buildings can lead to exacerbated wind patterns and an uneven dispersion of pollutants. When the height of buildings surrounding a source of air pollution is increased, the size and occurrence of both \"dead-zones\" and \"hotspots\" were increased in areas where there were almost no pollutants and high concentrations of pollutants, respectively. This progression shows how as the height of Building F increases, the dispersion of pollutants decreases, but the concentration within the building cluster increases. The variation of velocity fields can be affected by the construction of new buildings as well, rather than solely the increase in height.\nAs urban centers continue to expand upward and outward, the present velocity fields will continue to trap polluted air close to the tall buildings within the city. Specifically within major cities, a majority of air pollution is derived from transportation, whether it be cars, trains, planes, or boats. As urban sprawl continues and pollutants continue to be emitted, the air pollutants will continue to be trapped within these urban centers. Different pollutants can be detrimental to human health in different ways. For example, particulate matter from vehicular exhaust and power generation can cause asthma, bronchitis, and cancer, while nitrogen dioxide from motor engine combustion processes can cause neurological disfunction and asphyxiation.\nLEED/green building rating.\nLike with all other buildings, if special measures are taken to incorporate sustainable design methods early on in the design process, it is possible to obtain a green building rating, such as a Leadership in Energy and Environmental Design (LEED) certification. An integrated design approach is crucial in making sure that design decisions that positively impact the whole building are made at the beginning of the process. Because of the massive scale of skyscrapers, the decisions made by the design team must take all factors into account, including the buildings impact on the surrounding community, the effect of the building on the direction in which air and water move, and the impact of the construction process, must be taken into account. There are several design methods that could be employed in the construction of a skyscraper that would take advantage of the height of the building.\nThe microclimates that exist as the height of the building increases can be taken advantage of to increase the natural ventilation, decrease the cooling load, and increase daylighting. Natural ventilation can be increased by utilizing the stack effect, in which warm air moves upward and increases the movement of the air within the building. If utilizing the stack effect, buildings must take extra care to design for fire separation techniques, as the stack effect can also exacerbate the severity of a fire. Skyscrapers are considered to be internally dominated buildings because of their size as well as the fact that a majority are used as some sort of office building with high cooling loads. Due to the microclimate created at the upper floors with the increased wind speed and the decreased dry bulb temperatures, the cooling load will naturally be reduced because of infiltration through the thermal envelope. By taking advantage of the naturally cooler temperatures at higher altitudes, skyscrapers can reduce their cooling loads passively. On the other side of this argument, is the lack of shading at higher altitudes by other buildings, so the solar heat gain will be larger for higher floors than for floors at the lower end of the building. Special measures should be taken to shade upper floors from sunlight during the overheated period to ensure thermal comfort without increasing the cooling load.\nHistory of the tallest skyscrapers.\nAt the beginning of the 20th century, New York City was a center for the Beaux-Arts architectural movement, attracting the talents of such great architects as Stanford White and Carrere and Hastings. As better construction and engineering technology became available as the century progressed, New York City and Chicago became the focal point of the competition for the tallest building in the world. Each city's striking skyline has been composed of numerous and varied skyscrapers, many of which are icons of 20th-century architecture:\nMomentum in setting records passed from the United States to other nations with the opening of the Petronas Twin Towers in Kuala Lumpur, Malaysia, in 1998. The record for the world's tallest building has remained in Asia since the opening of Taipei 101 in Taipei, Taiwan, in 2004. A number of architectural records, including those of the world's tallest building and tallest free-standing structure, moved to the Middle East with the opening of the Burj Khalifa in Dubai, United Arab Emirates.\nThis geographical transition is accompanied by a change in approach to skyscraper design. For much of the 20th century large buildings took the form of simple geometrical shapes. This reflected the \"international style\" or modernist philosophy shaped by Bauhaus architects early in the century. The last of these, the Willis Tower and World Trade Center towers in New York, erected in the 1970s, reflect the philosophy. Tastes shifted in the decade which followed, and new skyscrapers began to exhibit postmodernist influences. This approach to design avails itself of historical elements, often adapted and re-interpreted, in creating technologically modern structures. The Petronas Twin Towers recall Asian pagoda architecture and Islamic geometric principles. Taipei 101 likewise reflects the pagoda tradition as it incorporates ancient motifs such as the ruyi symbol. The Burj Khalifa draws inspiration from traditional Islamic art. Architects in recent years have sought to create structures that would not appear equally at home if set in any part of the world, but that reflect the culture thriving in the spot where they stand.\nThe following list measures height of the roof, not the pinnacle. The more common gauge is the \"highest architectural detail\"; such ranking would have included Petronas Towers, built in 1996.\nFuture developments.\nProposals for such structures have been put forward, including the Burj Mubarak Al Kabir in Kuwait and Azerbaijan Tower in Baku. Kilometer-plus structures present architectural challenges that may eventually place them in a new architectural category. The first building under construction and planned to be over one kilometre tall is the Jeddah Tower.\nWooden skyscrapers.\nSeveral wooden skyscraper designs have been designed and built. A 14-story housing project in Bergen, Norway known as 'Treet' or 'The Tree' became the world's tallest wooden apartment block when it was completed in late 2015. The Tree's record was eclipsed by Brock Commons, an 18-story wooden dormitory at the University of British Columbia in Canada, when it was completed in September 2016.\nA 40-story residential building 'Tr\u00e4toppen' has been proposed by architect Anders Berensson to be built in Stockholm, Sweden. Tr\u00e4toppen would be the tallest building in Stockholm, though there are no immediate plans to begin construction. The tallest currently-planned wooden skyscraper is the 70-story W350 Project in Tokyo, to be built by the Japanese wood products company Sumitomo Forestry Co. to celebrate its 350th anniversary in 2041. An 80-story wooden skyscraper, the River Beech Tower, has been proposed by a team including architects Perkins + Will and the University of Cambridge. The River Beech Tower, on the banks of the Chicago River in Chicago, Illinois, would be 348 feet shorter than the W350 Project despite having 10 more storys.\nWooden skyscrapers are estimated to be around a quarter of the weight of an equivalent reinforced-concrete structure as well as reducing the building carbon footprint by 60\u201375%. Buildings have been designed using cross-laminated timber (CLT) which gives a higher rigidity and strength to wooden structures. CLT panels are prefabricated and can therefore save on building time.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29486", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=29486", "title": "Sagas of Icelanders", "text": "Group of narratives\nThe sagas of Icelanders (, modern ), also known as family sagas, are a subgenre, or text group, of Icelandic sagas. They are prose narratives primarily based on historical events that mostly took place in Iceland in the ninth, tenth, and early eleventh centuries, during the Saga Age. They were written in Old Icelandic, a western dialect of Old Norse, primarily on calfskin. They are the best-known specimens of Icelandic literature.\nThey are focused on history, especially genealogical and family history. They reflect the struggle and conflict that arose within the societies of the early generations of Icelandic settlers. The Icelandic sagas are valuable and unique historical sources about medieval Scandinavian societies and kingdoms, in particular regarding pre-Christian religion and culture and the heroic age.\nEventually, many of these Icelandic sagas were recorded, mostly in the 13th and 14th centuries. The 'authors', or rather recorders, of these sagas are largely unknown. One saga, \"Egil's Saga\", is believed by some scholars to have been written by Snorri Sturluson, a descendant of the saga's hero, but this remains uncertain. The standard modern edition of Icelandic sagas is produced by Hi\u00f0 \u00edslenzka fornritaf\u00e9lag ('The Old Icelandic Text Society'), or \u00cdslenzk fornrit for short.\nHistorical time frame.\nAmong the several literary reviews of the sagas is the \"Sagalitteraturen\" by Sigur\u00f0ur Nordal, which divides the sagas into five chronological groups (depending on when they were written not their subject matters) distinguished by the state of literary development:\nThis framework has been severely criticised as based on a presupposed attitude to the fantastic and an over-estimation on the precedence of \"Landn\u00e1mab\u00f3k\".\nList of sagas.\nIt is thought that a number of sagas are now lost, including the supposed \"Gauks saga Trandilssonar\" \u2013 The saga of Gaukur \u00e1 St\u00f6ng. In addition to these, the texts often referred to as the \"Tales of Icelanders\" (\"\u00cdslendinga\u00fe\u00e6ttir\") such as \"Hrei\u00f0ars \u00fe\u00e1ttr\" and \"Sneglu-Halla \u00fe\u00e1ttr\" of the kings' saga \"Morkinskinna\" could be included in this corpus, as well as the contemporary sagas (written in the 13th century and dealing with the same period) incorporated into \"Sturlunga saga\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29487", "revid": "665998", "url": "https://en.wikipedia.org/wiki?curid=29487", "title": "September 11 Terrorist Attack", "text": ""}
{"id": "29489", "revid": "40943757", "url": "https://en.wikipedia.org/wiki?curid=29489", "title": "Staind", "text": "American rock band\nStaind ( ) is an American rock band from Springfield, Massachusetts, formed in 1995. The original lineup consisted of lead vocalist and rhythm guitarist Aaron Lewis, lead guitarist Mike Mushok, bassist and backing vocalist Johnny April, and drummer Jon Wysocki. The lineup has been stable outside of the 2011 departure of Wysocki, who was replaced by Sal Giancarelli. Staind has recorded and released eight studio albums: \"Tormented\" (1996), \"Dysfunction\" (1999), \"Break the Cycle\" (2001), \"14 Shades of Grey\" (2003), \"Chapter V\" (2005), \"The Illusion of Progress\" (2008), \"Staind\" (2011), and \"Confessions of the Fallen\" (2023). \nThe band was most successful in the early 2000s, with \"Break the Cycle\" going five times platinum in the United States and producing a top-five \"Billboard\" Hot 100 hit with its lead single \"It's Been Awhile\". \"Break the Cycle\", along with the band's following two full-length albums, also topped the \"Billboard\" 200, and the two after peaked within the top five. Several of their other singles also became rock and crossover hits, including \"Fade\", \"For You\", \"Price to Play\", \"So Far Away\", and \"Right Here\". The band's activity became more sporadic into the 2010s, with Lewis pursuing a solo country music career and Mushok subsequently joining the band Saint Asonia.\nHistory.\nEarly years and \"Tormented\" (1995\u20131998).\nIn 1993, vocalist Aaron Lewis and guitarist Mike Mushok met at a Christmas party in Springfield, Massachusetts. Mushok introduced drummer Jon Wysocki while Lewis brought in bassist Johnny April to form the band in 1995. Their first public performance was in February 1995, playing a heavy, dark, and introspective style of metal. Extensive touring in the Northeast helped Staind acquire a regional following over the next few years.\nThe band started covering Korn, Rage Against the Machine, Pearl Jam, Tool, and Alice in Chains, among others, and played at local clubs (most commonly playing at Infinity, a live music venue located in Springfield) for a year and a half. Staind self-released their debut album, \"Tormented\", in November 1996, citing Tool, Faith No More, and Pantera as their influences. In October 1997, Staind acquired a concert slot through Aaron's cousin Justin Cantor with Limp Bizkit. Just prior to the performance, Limp Bizkit frontman Fred Durst was appalled by Staind's grotesque album cover and unsuccessfully attempted to remove them from the bill. Durst thought that Staind were Theistic Satanists. After being persuaded to let them perform, however, Durst was so impressed that he signed them to Flip Records by February 1998.\n\"Dysfunction\" (1999\u20132000).\nOn April 13, 1999, Staind released their major label debut \"Dysfunction\" on Flip Records. The album, which was co-produced by Fred Durst and Terry Date (who also produced acts like Soundgarden, Deftones, and Pantera), received comparisons to alternative metal giants Tool and Korn. In particular, Aaron Lewis was lauded for his vocals, which were likened to those of Pearl Jam's Eddie Vedder.\nThe album achieved slow success, reaching the No. 1 spot on Billboard's Heatseeker Charts almost six months after its debut. In the same week, the record jumped to No.\u00a074 on Billboard's Top 200 Album Charts. The nine-track LP (with one hidden track, \"Excess Baggage\") produced three singles, \"Just Go\", \"Mudshovel\", and \"Home\". \"Mudshovel\" and \"Home\" both received radio play, cracking the Top 20 of Billboard's Modern Rock and Mainstream Rock charts. In promotion of \"Dysfunction\", Staind went on several tours, including the Family Values Tour with acts like Limp Bizkit and The Crystal Method, as well as opening for Sevendust's headlining tour.\n\"Break the Cycle\" (2001\u20132002).\nStaind toured with Limp Bizkit for the Family Values Tour during the fall of 1999, where Aaron Lewis performed an early version of \"Outside\" with Fred Durst at the Mississippi Coast Coliseum. Staind released their third studio album, \"Break the Cycle\", on May 22, 2001. Propelled by the success of the first single, \"It's Been Awhile\", the album debuted at No.\u00a01 on Billboard's Top 200 Album charts, selling 716,000 copies in its first week. The record's first-week sales were the second highest of any album that year, behind Creed's \"Weathered\".\n\"Break the Cycle\" saw the band retaining the nu metal sound from their previous album. Despite this, the album saw the band going further into a post-grunge sound which is evident in the smash hit song \"It's Been Awhile\", and the song led critics to compare the band to several other post-grunge bands at the time. The record spawned the singles \"It's Been Awhile\" (which hit the Billboard Top 10), \"Fade\", \"Outside\", \"For You\", and the acoustic ballad \"Epiphany\". \"It's Been Awhile\" spent a total of 16 and 14 weeks on top of the modern and mainstream rock charts respectively, making it one of the highest joint numbers of all time. In 2001, \"Break the Cycle\" sold four million copies worldwide, making it one of the best selling albums that year. \"Break the Cycle\" would go on to sell seven million copies worldwide, making this Staind's bestselling album.\n\"14 Shades of Grey\" (2003\u20132004).\nIn early 2003, Staind embarked on a worldwide tour to promote the release of the follow-up to \"Break the Cycle\", \"14 Shades of Grey\", which sold two million copies and debuted at number 1 on the Billboard 200. The album saw a departure from their previous nu metal sound as it mostly contained a lighter and more melodic post-grunge sound. \"14 Shades of Grey\" produced two mainstream hits, \"Price to Play\" and \"So Far Away\", which spent 14 weeks on top of the rock chart. In addition, two other singles were released: \"How About You\" and \"Zoe Jane\". The band's appearance at the Reading Festival during their 2003 tour had another impromptu acoustic set, this time due to equipment failure. The singles \"So Far Away\" and \"Price to Play\" came with two unreleased tracks, \"Novocaine\" and \"Let It Out\", which were released for the special edition of the group's subsequent album \"Chapter V\", which came out in late 2005. In 2003, Staind unsuccessfully sued their logo designer Jon Stainbrook in New York Federal Court for attempting to re-use the logo he had sold to the band. They re-opened the case in mid-2005.\n\"Chapter V\" and \"The Singles\" (2005\u20132007).\nStaind's fifth album, titled \"Chapter V\", was released on August 9, 2005, and became their third consecutive album to top the \"Billboard\" 200. The album opened to sales of 185,000 and has since been certified platinum in the U.S. The first single, \"Right Here\", was the biggest success from the album, garnering much mainstream radio play and peaking at number 1 on the mainstream rock chart. \"Falling\" was released as the second single, followed by \"Everything Changes\" and \"King of All Excuses\". Staind went on the road when the album came out, doing live shows and promoting it for a full year, including participating in the Fall Brawl tour with P.O.D., Taproot, and Flyleaf; they also had a solo tour across Europe and a mini-promotional tour in Australia for the first time. Other live shows included a cover of Pantera's \"This Love\", a tribute to Dimebag Darrell. Staind appeared on \"The Howard Stern Show\" on August 10, 2005 to promote \"Chapter V\". They performed acoustic renditions of the single \"Right Here\" and Beetlejuice's song \"This is Beetle\". In early November 2005, Staind released the limited edition 2-CD/DVD set of \"Chapter V\". On September 6, 2006, they performed an acoustic show in the Hiro Ballroom, New York City, that was recorded for their singles collection. The band played sixteen songs, including three covers: Tool's \"Sober\", Pink Floyd's \"Comfortably Numb\", and Alice in Chains's \"Nutshell\".\nThe collection \"\" was released on November 14, 2006. It included all the band's singles, the three covers performed at the New York show, and a remastered version of \"Come Again\" from Staind's first independent release \"Tormented\".\n\"The Illusion of Progress\" (2008\u20132009).\nOn August 19, 2008, Staind released their sixth album, \"The Illusion of Progress\". Prior to the album's release, the track \"This Is It\" was available for download on the iTunes Store, as well as for \"Rock Band\". The album debuted at No.\u00a03 on the U.S. Billboard 200, No.\u00a01 on the Top Modern Rock/Alternative Albums Chart, No.\u00a01 on the Top Digital Albums Chart, and also No.\u00a01 on the Top Internet Albums Chart, with first-week sales of 91,800 units. The first single on the album, \"Believe\", topped Billboard's Top 10 Modern Rock Tracks on September 5, 2008. The band also supported Nickelback on their 2008 European tour. The second single was \"All I Want\", and came out on November 24. The single also became Staind's 13th top 20 hit on the rock charts. In Europe, the second single was \"The Way I Am\", released on January 26, 2009. The final single released from the album, \"This Is It\", was sent to radio stations across the country on May 4, 2009. The track was also included on the successful \"\" released in late June 2009. The same year, Staind embarked on a fall tour with the newly reunited Creed.\n\"Staind\" and departure of Jon Wysocki (2010\u20132012).\nIn March 2010, Aaron Lewis stated the band would start working on their seventh studio album by the end of the year. Lewis had finished recording his country music solo EP and had started a nonprofit organization to reopen his daughter's elementary school in Worthington, Massachusetts. Guitarist Mike Mushok stated in a Q&amp;A session with fans that the band was looking to make a heavy record, but still \"explore some of the things we did on the last record and take them somewhere new for us\". In a webisode posted on the band's website, Lewis stated that eight songs were written and that \"every one of them is as heavy or heavier than the heaviest song on the last record\". The band originally planned on recording with Nick Raskulinecz, but ended up working with \"The Illusion of Progress\" producer Johnny K, much to Wysocki's dismay.\nIn December 2010, Staind posted three webisodes from the studio, which featured the band members discussing the writing and recording process of their new album. They announced that as of April 20, they had completed the recording of their seventh and would release it later that year. Wysocki said that the album's production was rushed as the band had waited until the last minute\u2014before they would be in breach of their record contract\u2014to record the album. He later said that whilst \"some [of the album's] songs came out pretty good\", it was not as well-rounded as the band's previous efforts. Due to his frustration with the album's production and \"distractions\" afflicting the band, Wysocki decided to quit Staind. \"I was very frustrated with it all, so I said to the guys, 'As much as I love this band and I love you guys, I gotta go. This is not the Staind we started out being.'\" Staind announced Wysocki's departure on May 20, 2011. Following his departure, Wysocki joined Soil.\nDrummer Will Hunt filled in for a few dates, while Wysocki's drum tech Sal Giancarelli filled in for the rest of the tour. On May 23, 2011, it was reported that Staind's new album would be a self-titled release. It was released on September 13, 2011. The first single, \"Not Again\", was released to active radio stations on July 18. The song \"The Bottom\" appeared on the \"\" soundtrack. On June 30, Staind released a song called \"Eyes Wide Open\" from their new record. \"Eyes Wide Open\" would later be released on November 29 as the album's second single.\nIn November 2011, the band announced through their YouTube page that Sal Giancarelli was now an official member. The band continued to perform into 2012, embarking on an April and May tour with Godsmack and Halestorm, and they played the Uproar Festival in August and September with Shinedown and a number of other artists.\nIt was announced in July 2012 that the band was to be taking a hiatus. In an interview with Billboard, Aaron Lewis stated that \"We're not breaking up. We're not gonna stop making music. We're just going to take a little hiatus that really hasn't ever been taken in our career. We put out seven records in 14 years. We've been pretty busy.\" Lewis also had plans to release his first solo album \"The Road\". During this time, Mike Mushok auditioned, and was selected, to play guitar for former Metallica bassist Jason Newsted's new band Newsted. He featured on their debut album \"Heavy Metal Music\".\nHiatus, \"Confessions of the Fallen\" and death of Jon Wysocki (2013\u2013present).\nStaind played their first show in two years at the Welcome to Rockville festival on April 27, 2014. They also played the Carolina Rebellion and Rock on the Range festivals in May 2014.\nIn late 2014, the band went on a hiatus. Aaron Lewis continued to play solo shows and work on his next solo album. He also confirmed that the hiatus would last \"for a while\". Mike Mushok teamed up with former Three Days Grace singer Adam Gontier, former Finger Eleven drummer Rich Beddoe, and Eye Empire bassist Corey Lowery to form Saint Asonia.\nOn August 4, 2017, the band performed for the first time since November 2014 for an acoustic performance at Aaron Lewis' 6th annual charity golf tournament and concert when bassist Johnny April and drummer Sal Giancarelli joined Aaron Lewis and Mike Mushok to perform \"Outside\", \"Something to Remind You\", and \"It's Been Awhile\". Three days later, Lewis announced that Staind would never tour extensively again, with Lewis explaining:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The touring machine, as you call it, of Staind will never be again. Not like that, no. Never. I could never go back to playing six shows [a week] eight weeks in a row. I can't do that. I have grown in my age and become very accustomed to playing Thursday, Friday and Saturday and being able to go home for a few days and unwind and try to kind of have a life aside from doing this.\nIn April 2019, the band announced they would reform in September 2019 for some live performances. The band was scheduled to play at Epicenter Festival on May 3, 2020 at Charlotte Motor Speedway, but the COVID-19 pandemic led to the festival being cancelled. Amid the pandemic, the band released a live album titled \"Live: It's Been Awhile\" on May 7, 2021. The recorded performance took place at the Foxwoods Resort Casino in Mashantucket, Connecticut.\nIn April 2022, the band announced a September tour, dubbed the Evening with Staind tour. In September, Mushok confirmed that a new Staind album would be released in 2023.\n\"Confessions of the Fallen\" was released in September 2023. The album's lead single was \"Lowest in Me\".\nOriginal Staind drummer Jon Wysocki died on May 18, 2024, at the age of 53, due to \"issues with his liver that required him to be under the care of medical professionals\".\nMusical style, influences, and lyrical themes.\nThe topics of Staind's lyrics cover issues of depression, relationships, death, addiction, finding one's self, betrayal, and Lewis's thoughts about becoming a father in the song \"Zoe Jane\" from \"14 Shades of Grey\", as well as reflecting on his upbringing in the song \"The Corner\" from \"The Illusion of Progress\". Also from \"14 Shades of Grey\", the track titled \"Layne\" was written about Alice in Chains frontman Layne Staley in response to his death in 2002. The song is also about Staley's legacy and the effect his music had on the members of Staind, especially Aaron Lewis. Staind has been categorized as alternative metal, nu metal, post-grunge, and hard rock. \nIn 2001, \"Rolling Stone\" outlined the band's relationship to the nu metal label:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Staind got their first break in 1998 when [Fred] Durst signed the band to his Flip Records. That association has linked the group with \"new metal,\" though \"Break the Cycle\"'s sound is neither particularly new nor metal. The band doesn't rap, and though Mushok has adopted new-metal's minor-key guitar riffs, Lewis' dramatic voice and the anthemic quality of such songs as \"Open Your Eyes\" and \"Fade\" are more akin to Alice in Chains than to Korn. Aggressive yet reflective, \"Break the Cycle\" doesn't require a poisonous abundance of testosterone to be appreciated and is better suited to solitary listening than to the mosh pit.\nStaind's influences include Pantera, the Doors, Suicidal Tendencies, Kiss, Van Halen, Slayer, Led Zeppelin, Sepultura, Whitesnake, the Beatles, Alice in Chains, Faith No More, Deftones, Black Sabbath, Pearl Jam, Tool, Rage Against the Machine, Nirvana, Stone Temple Pilots, James Taylor, Korn, and Crosby, Stills &amp; Nash.\nBand members.\nCurrent line-up\nFormer members\nDiscography.\nStudio albums\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29490", "revid": "44840730", "url": "https://en.wikipedia.org/wiki?curid=29490", "title": "Saddam Hussein", "text": "President of Iraq from 1979 to 2003\nSaddam Hussein (28 April 1937 \u2013 30 December 2006) was an Iraqi politician and revolutionary who served as the president of Iraq from 1979 until he was overthrown in 2003 during the U.S. invasion of Iraq. He previously served as the vice president from 1968 to 1979 and also as the prime minister from 1979 to 1991 and later from 1994 to 2003. A leading member of the Arab Socialist Ba'ath Party, he was a proponent of Ba'athism, a mix of Arab nationalism and Arab socialism. The policies and ideologies he championed are collectively known as Saddamism.\nBorn near the city of Tikrit to a Sunni Arab family, Saddam Hussein joined the revolutionary Ba'ath Party in 1957. He played a key role in the 17 July Revolution that brought the Ba'athists to power in Iraq and made him vice president under Ahmed Hassan al-Bakr. During his tenure as vice president, Saddam nationalized the Iraq Petroleum Company, diversified the economy, introduced free healthcare and education, and supported women's rights. He also presided over the defeat of the Kurdish insurgency in the Second Iraqi\u2013Kurdish War and signed the Algiers Agreement with Iran in 1975, thereby settling territorial disputes along the Iran\u2013Iraq border. Following al-Bakr's resignation in 1979, Saddam formally took power. During his presidency, positions of power in the country were mostly filled with Sunni Arabs, a minority that made up only about a fifth of the Iraqi population.\nUpon taking office as president in 1979, Saddam purged rivals within his party. In 1980, he ordered the invasion of Iran, purportedly to capture Iran's Arab-majority Khuzestan province, and end Iranian attempts to export its Islamic Revolution to the Arab world. In 1988, as the war with Iran ended in a stalemate, he ordered the Anfal campaign against Kurdish rebels who had sided with Iran. Later, he accused his former ally Kuwait of slant-drilling Iraq's oil reserves and subsequently invaded the country in 1990. This ultimately led to the Gulf War in 1991, which ended in Iraq's defeat by a United States-led coalition. In the war's aftermath, Saddam's forces suppressed the 1991 Iraqi uprisings launched by Kurds and Shi'as seeking regime change, as well as further uprisings in 1999. After reconsolidating his hold on power, Saddam pursued an Islamist agenda for Iraq through the Faith Campaign. In 2003, a US-led coalition invaded Iraq, incorrectly accusing him of developing weapons of mass destruction and of having ties with al-Qaeda. Coalition forces toppled Saddam's regime and captured him. During his trial, Saddam was convicted by the Iraqi High Tribunal of crimes against humanity and sentenced to death by hanging. He was executed on 30 December 2006.\nA polarizing and controversial figure, Saddam dominated Iraqi politics for 35 years and was the subject of a cult of personality. Many Arabs regard Saddam as a resolute leader who challenged Western imperialism, opposed the Israeli occupation of Palestine, and resisted foreign intervention in the region. Conversely, many Iraqis, particularly Shi'as and Kurds, perceive him as a tyrant responsible for acts of repression, mass killing and other injustices. Human Rights Watch estimated that Saddam's regime was responsible for the murder or disappearance of 250,000 to 290,000 Iraqis. Saddam's government has been described by several analysts as authoritarian and totalitarian, and by some as fascist, although the applicability of those labels has been contested.\nEarly life and education.\nSaddam Hussein Al-Majid Al-Tikriti was born on 28 April 1937, in al-Awja, a small village near Tikrit, to a Sunni Arab family from the Al-Bejat clan of the Bedouin Al-Bu Nasir tribe. His father, Hussein Abd al-Majid, was from the Al-Majid branch of the Al-Bejat clan, while his mother Subha Tulfah al-Mussalat was granddaughter of Mussallat bin Omar Al-Nasiri, a tribal leader of the Al-Bu Nasir tribe and an opponent of the Ottoman rule in Iraq.\nSaddam's name means \"the fighter who stands steadfast\". His father died before his birth. This made Saddam's mother, Subha, so depressed that she unsuccessfully attempted to abort her pregnancy and commit suicide. Saddam's mother did not want anything to do with him, and Saddam was eventually taken in by an uncle. His stepfather, Ibrahim al-Hassan, treated Saddam harshly after his return, and (according to a psychological profile created by the CIA) beat him regularly, sometimes to wake him up. At around the age of 10, Saddam fled the family and returned to live in Baghdad with his uncle Khairallah Talfah, who became a fatherly figure to Saddam. Talfah, the father of Saddam's future wife, was a devout Sunni Muslim and a veteran of the 1941 Anglo-Iraqi War between Iraqi nationalists and the United Kingdom, which remained a major colonial power in the region. Talfah was appointed the mayor of Baghdad during Saddam's time in power, until his notorious corruption compelled Saddam to force him out of office.\nLater in his life, relatives from his native city became some of his closest advisors and supporters. Under the guidance of his uncle, he attended a nationalistic high school in Baghdad. After secondary school, Saddam studied at an Iraqi law school for three years, dropping out in 1957 at the age of 20 to join the revolutionary pan-Arab Ba'ath Party, of which his uncle was a supporter. During this time, Saddam apparently saw himself as a secondary school teacher. Ba'athist ideology originated in Syria and the Ba'ath Party had a large following in Syria at the time, but in 1955 there were fewer than 300 Ba'ath Party members in Iraq, and it is believed that Saddam's primary reason for joining the party as opposed to the more established Iraqi nationalist parties was his familial connection to Ahmed Hassan al-Bakr and other leading Ba'athists through his uncle. The pan-Arab nationalism of Gamal Abdel Nasser in Egypt profoundly influenced young Ba'athists like Saddam. The rise of Nasser foreshadowed a wave of revolutions throughout the Middle East in the 1950s and 1960s, with the collapse of the monarchies of Iraq, Egypt, and Libya. Nasser inspired nationalists throughout the Middle East by fighting the British and the French during the Suez Crisis of 1956, modernizing Egypt, and uniting the Arab world politically. Saddam's father-in-law, Khairallah Talfah, was reported to have served five years in prison for his role in fighting against Great Britain in the 1941 Iraqi coup d'\u00e9tat and Anglo-Iraqi War, and often mentored and told tales of his exploits to the young Saddam.\nRise to power.\nAssassination attempt on Qasim.\nThe Ba'ath Party was originally represented in Qasim's cabinet; however, Qasim\u2014reluctant to join Nasser's newly formed union between Egypt and Syria\u2014sided with various groups within Iraq (notably the social democrats and the Iraqi Communist Party) that told him such an action would be dangerous. Instead, Qasim adopted a \"wataniyah\" policy of \"Iraq First\". To strengthen his own position within the government, Qasim also had an alliance with the Iraqi Communist Party (ICP), which was opposed to the notion of pan-Arabism. His policies angered several pan-Arab organizations, including the Ba'ath Party, which later began plotting to assassinate Qasim at Al-Rashid Street on 7 October 1959 and take power. Saddam was recruited to the assassination conspiracy by its ring-leader, Abdul Karim al-Shaikhly, after one of the would-be assassins left. During the ambush, Saddam (who was only supposed to provide cover) began shooting prematurely, which disorganised the whole operation. Qasim's chauffeur was killed and Qasim was hit in the arm and shoulder. The assassins thought they had killed Qasim and quickly retreated to their headquarters, but Qasim survived. Saddam himself is not believed to have received any training outside of Iraq, as he was a late addition to the assassination team.\nRichard Sale of \"United Press International\" (UPI), citing former United States diplomat and intelligence officials, Adel Darwish, and other experts, reported that the unsuccessful assassination attempt on Qasim was a collaboration between the United States Central Intelligence Agency (CIA) and Egyptian intelligence. Pertinent contemporary records relating to CIA operations in Iraq have remained classified or heavily redacted, thus \"allow[ing] for plausible deniability.\" It is generally accepted that Egypt, in some capacity, was involved in the assassination attempt, and that \"[t]he United States was working with Nasser on some level.\"\nAt the time of the attack, the Ba'ath Party had fewer than 1,000 members; however, the failed assassination attempt led to widespread exposure for Saddam and the Ba'ath within Iraq, where both had previously languished in obscurity, and later became a crucial part of Saddam's public image during his tenure as president of Iraq. Kanan Makiya recounts:\nThe man and the myth merge in this episode. His biography\u2014and Iraqi television, which stages the story ad nauseam\u2014tells of his familiarity with guns from the age of ten; his fearlessness and loyalty to the party during the 1959 operation; his bravery in saving his comrades by commandeering a car at gunpoint; the bullet that was gouged out of his flesh under his direction in hiding; the iron discipline that led him to draw a gun on weaker comrades who would have dropped off a seriously wounded member of the hit team at a hospital; the calculating shrewdness that helped him save himself minutes before the police broke in leaving his wounded comrades behind; and finally the long trek of a wounded man from house to house, city to town, across the desert to refuge in Syria.\nExile to the United Arab Republic.\nMichel Aflaq, the leader of the Ba'athist movement, organized the expulsion of leading Iraqi Ba'athist members, such as Fuad al-Rikabi, on the grounds that the party should not have initiated the attempt on Qasim's life. At the same time, Aflaq secured seats in the Iraqi Ba'ath leadership for his supporters, one of them being Saddam.\nThe assassins, including Saddam, all eventually escaped to Cairo, United Arab Republic, \"where they enjoyed Nasser's protection for the remainder of Qasim's tenure in power.\" Saddam initially escaped to Syria and then to Egypt itself in February 1960, and he continued to live there until 1963, graduating from high school in 1961 and unsuccessfully pursuing a law degree at Cairo Law School (1962\u20131963). It is possible that Saddam visited the U.S. embassy in Cairo during his exile, and some evidence suggests that he was \"in frequent contact with US officials and intelligence agents.\" A former high-ranking U.S. official told historians Marion Farouk\u2013Sluglett and Peter Sluglett that Iraqi Ba'athists, including Saddam, \"had made contact with the American authorities in the late 1950s and early 1960s.\"\nArmy officers with ties to the Ba'ath Party overthrew and killed Qasim in the Ramadan Revolution coup of February 1963; long suspected to be supported by the CIA, however, pertinent contemporary documents relating to the CIA's operations in Iraq have remained classified by the U.S. government, although the Ba'athists are documented to have maintained supportive relationships with U.S. officials before, during, and after the coup. Ba'athist leaders were appointed to the cabinet and Abdul Salam Arif became president. Arif dismissed and arrested the Ba'athist leaders later that year in the November 1963 Iraqi coup d'\u00e9tat. Being exiled in Egypt at the time, Saddam played no role in the 1963 coup or the brutal anti-communist purge that followed; although he returned to Iraq after the coup, becoming a key organizer within the Ba'ath Party's civilian wing upon his return. Unlike during the Qasim years, Saddam remained in Iraq following Arif's anti-Ba'athist purge in November 1963, and became involved in planning to assassinate Arif. In marked contrast to Qasim, Saddam knew that he faced no death penalty from Arif's government and knowingly accepted the risk of being arrested rather than fleeing to Syria again. Saddam was arrested in October 1964 and served approximately two years in prison before escaping in 1966. In 1966, Ahmed Hassan al-Bakr appointed him Deputy Secretary of the Regional Command. Saddam, who would prove to be a skilled organizer, revitalized the party. He was elected to the Regional Command, as the story goes, with help from Michel Aflaq\u2014the founder of Ba'athist thought. In September 1966, Saddam initiated an extraordinary challenge to Syrian domination of the Ba'ath Party in response to the Marxist takeover of the Syrian Ba'ath earlier that year, resulting in the Party's formalized split into two separate factions. Saddam then created a Ba'athist security service, which he alone controlled.\n1968 coup.\nIn July 1968, Saddam participated in a bloodless coup led by Ahmed Hassan al-Bakr that overthrew Abdul Rahman Arif, Salam Arif's brother and successor. While Saddam's role in the coup was not hugely significant (except in the official account), Saddam planned and carried out the subsequent purge of the non-Ba'athist faction led by Prime Minister Abdul Razzaq an-Naif, whose support had been essential to the coup's success. According to a semi-official biography, Saddam personally led Naif at gunpoint to the plane that escorted him out of Iraq. Arif was given refuge in London and then Istanbul. Al-Bakr was named president and Saddam was named his deputy, and deputy chairman of the Ba'athist Revolutionary Command Council. According to biographers, Saddam never forgot the tensions within the first Ba'athist government, which formed the basis for his measures to promote Ba'ath party unity as well as his resolve to maintain power and programs to ensure social stability. Although Saddam was al-Bakr's deputy, he was a strong behind-the-scenes party politician. Al-Bakr was the older and more prestigious of the two, but by 1969 Saddam had become the moving force behind the party.\nVice Presidency (1968\u20131979).\nPolitical program.\nIn the late 1960s and early 1970s, as vice chairman of the Revolutionary Command Council, formally al-Bakr's second-in-command, Saddam built a reputation as a progressive, effective politician. At this time, he moved up the ranks in the new government by aiding attempts to strengthen and unify the Ba'ath party and taking a leading role in addressing the country's major domestic problems and expanding the party's following.\nAt the center of this strategy was Iraq's oil. On 1 June 1972, Saddam oversaw the seizure of international oil interests, which, at the time, dominated the country's oil sector. A year later, world oil prices rose dramatically as a result of the 1973 energy crisis, and skyrocketing revenues enabled Saddam to expand his agenda. Saddam subsequently implemented a national infrastructure campaign that made progress in building roads, promoting mining, and developing other industries. Electricity was brought to nearly every city in Iraq, and many outlying areas. Before the 1970s, most of Iraq's people lived in the countryside and roughly two-thirds were peasants. This number would decrease quickly during the 1970s. He nationalized independent banks, eventually leaving the banking system insolvent due to inflation and bad loans.\nSaddam focused on fostering loyalty to the Ba'athists in the rural areas. After nationalizing foreign oil interests, Saddam supervised the modernization of the countryside, mechanizing agriculture on a large scale, and distributing land to peasant farmers. The Ba'athists established farm cooperatives and the government also doubled expenditures for agricultural development in 1974\u20131975.\nBy the late 1970s, Iraq had experienced significant economic growth, with a budget reserve surpassing US$35 billion. The value of 1 Iraqi dinar was worth more than 3 dollars, making it one of the most notable economic expansions in the region. Saddam Hussein's regime aimed to diversify the Iraqi economy beyond oil. The government invested in various industries, including petrochemicals, fertilizer production, and textile manufacturing, to reduce dependence on oil revenues and promote economic self-sufficiency.\nThe oil revenue benefited Saddam politically. According to \"The Economist\", \"Much as Adolf Hitler won early praise for galvanizing German industry, ending mass unemployment and building autobahns, Saddam earned admiration abroad for his deeds. He had a good instinct for what the \"Arab street\" demanded, following the decline in Egyptian leadership brought about by the trauma of Israel's six-day victory in the 1967 war, the death of the pan-Arabist hero, Gamal Abdel Nasser, in 1970, and the \"traitorous\" drive by his successor, Anwar Sadat, to sue for peace with the Jewish state. Saddam's self-aggrandizing propaganda, with himself posing as the defender of Arabism against Zionist or Persian intruders, was heavy-handed, but consistent as a drumbeat. It helped, of course, that his mukhabarat (secret police) put dozens of Arab news editors, writers and artists on the payroll.\"\nForeign relations.\nSaddam sought to have Iraq play a leading role in the Middle East. In 1972, Saddam signed a 15-year Treaty of Friendship and Cooperation with the Soviet Union. Arms were sent along with several thousand advisers. According to historian Charles R. H. Tripp, the treaty upset \"the US-sponsored security system established as part of the Cold War in the Middle East. It appeared that any enemy of the Baghdad regime was a potential ally of the United States.\" In response, the US covertly financed Kurdish rebels led by Mustafa Barzani during the Second Iraqi\u2013Kurdish War; the Kurds were defeated in 1975, leading to the forcible relocation of hundreds of thousands of Kurdish civilians. A 1978 crackdown on Iraqi Communists and a shift of trade toward the West strained Iraqi relations with the Soviet Union; Iraq then took on a more Western orientation until the Gulf War in 1991.\nAfter the oil crisis of 1973, France had changed to a more pro-Arab policy and was accordingly rewarded by Saddam with closer ties. Saddam's rare trips abroad included many Western countries. His visit to Spain took place in December 1974, when the Caudillo of Spain, Francisco Franco, invited him to Madrid and he visited Granada, C\u00f3rdoba and Toledo. In September 1975 he met with Prime Minister Jacques Chirac in Paris, France. Saddam's 1975 visit further cemented close ties with French business and ruling political circles.Iraq's relations with the Arab world have been extremely varied. Relations between Iraq and Egypt violently ruptured in 1977, when the two nations broke relations with each other following Iraq's criticism of Egyptian President Anwar Sadat's peace initiatives with Israel. In 1978, Baghdad hosted an Arab League summit that condemned and ostracized Egypt for accepting the Camp David Accords. Saddam led Arab opposition to the Camp David Accords.\nPeace treaty with Iran.\nIran and Iraq had been engaged in a long-standing territorial dispute over the Shatt al-Arab waterway, which serves as the border between the two countries. Iran had backed Kurdish separatists in northern Iraq. A peace treaty, which aimed to address the Shatt al-Arab dispute, was signed in 1975. The 1975 Algiers Agreement, also known as the Algiers Accord, was a significant diplomatic agreement signed between Iran and Iraq on 6 March 1975, to settle border disputes and improve bilateral relations. It was mediated by the then president of Algeria, Houari Boumediene. Under the accord, Iraq was granted sovereignty over the eastern bank of the waterway, while Iran retained control over the western bank. Following the agreement, Iraq and Iran restored full diplomatic relations and exchanged ambassadors, representing a significant diplomatic breakthrough. The Shah withdrew support of the Kurds, who were promptly defeated by the Iraqis during the Second Iraqi-Kurdish War.\nSuccession.\nIn 1976, Saddam rose to the position of general in the Iraqi armed forces, and rapidly became the strongman of the government. As the ailing, elderly al-Bakr became unable to execute his duties, Saddam took on an increasingly prominent role as the face of the government both internally and externally. He was the \"de facto\" leader of Iraq some years before he formally came to power in 1979.\nIn 1979, al-Bakr started to make treaties with Syria, also under Ba'athist leadership, that would lead to unification between the two countries. Syrian President Hafez al-Assad would become deputy leader in a union, and this would drive Saddam to obscurity. Saddam acted to secure his grip on power by forcing the ailing al-Bakr to resign on 16 July 1979, and formally assumed the presidency.\nPresidency (1979\u20132003).\nConsolidation of power.\nThe first sign of consolidation of power came, when Muhyi Abd al-Hussein Mashhadi, the secretary-general of the Ba'ath Party, was replaced by someone closer to Saddam. Many officers during al-Bakr's time were removed. Few survived such as Adnan Khairallah and Sa'dun Hammadi. Saddam convened an assembly of Ba'ath party leaders on 22 July 1979. During the assembly, which he ordered videotaped, Saddam claimed to have found a fifth column within the ruling party and directed Muhyi Abdul-Hussein to read out a confession and the names of 68 alleged co-conspirators. These members were labelled \"disloyal\" and were removed from the room one by one and taken into custody. After the list was read, Saddam congratulated those still seated in the room for their past and future loyalty. The 68 people arrested at the meeting were subsequently tried together and found guilty of treason; 22 were sentenced to execution. Other high-ranking members of the party formed the firing squad.\nA second round of purges took place in June 1982, when half of the sixteen RCC members who had survived the 1979 \"countercoup\" were removed from power. Large number of Shi'as were removed from the regime. Later the government invited back Shi'as to hold posts within the government, to gain support. Under Saddam's administration, senior government, military, and security roles were predominantly filled by Arab Sunni Muslims, a minority that made up about a fifth of the population. While key security posts were often reserved for close relatives, he also appointed members of various religious and ethnic minorities to high-ranking positions and as representatives based on loyalty to his regime.\nParamilitary and police organizations.\nIraq faced the prospect of r\u00e9gime change from two Shi'a factions \u2014 Dawa and SCIRI which aspired to model Iraq on its neighbour Iran as a Shi'a theocracy. A separate threat to Iraq came from parts of the ethnic Kurdish population of northern Iraq which opposed being part of an Iraqi state and favored independence, an ongoing ideology which had preceded Ba'ath Party rule. To alleviate the threat of revolution, Saddam afforded certain benefits to potentially hostile population. Membership in the Ba'ath Party remained open to all Iraqi citizens regardless of background, and repressive measures were taken against its opponents.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"There is a feeling that at least three million Iraqis are watching the eleven million others.\"\n \u2014\"A European diplomat\", quoted in \"The New York Times\", April 3, 1984.\nThe major instruments for accomplishing this control were the paramilitary and police organizations. Beginning in 1974, Taha Yassin Ramadan, a close associate of Saddam, commanded the Popular Army, which had responsibility for internal security. As the Ba'ath Party's paramilitary, the People's Army acted as a counterweight against any coup attempts by the regular armed forces. In addition to the People's Army, the Department of General Intelligence was the most notorious arm of the state-security system, feared for its use of torture and assassination. Barzan Ibrahim al-Tikriti, Saddam's younger half-brother, commanded Mukhabarat. Foreign observers believed that from 1982 this department operated both at home and abroad in its mission to seek out and eliminate Saddam's perceived opponents.\nSaddam was notable for using terror against his own people. \"The Economist\" described Saddam as \"one of the last of the 20th century's great dictators, but not the least in terms of egotism, or cruelty, or morbid will to power.\" Saddam's regime brought about the deaths of at least 250,000 Iraqis and committed war crimes in Iran, Kuwait, and Saudi Arabia. Human Rights Watch and Amnesty International issued regular reports of widespread imprisonment and torture. Conversely, Saddam used Iraq's oil wealth to develop an extensive patronage system for the regime's supporters. Although Saddam is often described as a totalitarian leader, Joseph Sassoon notes that there are important differences between Saddam's repression and the totalitarianism practiced by Adolf Hitler and Joseph Stalin, particularly with regard to freedom of movement and freedom of religion.\nEconomy and infrastructure.\nAlthough initially committed to centralized planning and nationalization\u2014particularly in the oil sector\u2014Saddam experimented with privatization, partial deregulation, and limited market liberalization in the late 1980s. The Iran\u2013Iraq War devastated Iraq's economy, causing an estimated US$120 billion in damages and leaving the country with around $90 billion in debt, including approximately $40 billion owed to Saudi Arabia and Kuwait alone. Following the Gulf War and the imposition of UN sanctions in the 1990s, the Iraqi economy had sharply declined, and the system increasingly shifted toward crony capitalism.\nOverall, Saddam's government invested heavily in infrastructure projects, such as roads, bridges, and public buildings. Saddam implemented a national infrastructure campaign that made progress in building roads, promoting mining, and developing other industries. Electricity was also brought to nearly every city in Iraq, and many outlying areas. Iraq created one of the most modernized public-health systems in the Middle East, earning Saddam an award from the United Nations Educational, Scientific and Cultural Organization (UNESCO). He established one hospital, specially for treatment of children with Cerebral palsy. Saddam's government also underwent a large campaign to beautify Baghdad by erecting statues and monuments. The government also supported families of soldiers, granted free hospitalization to everyone, and gave subsidies to farmers.\nThe government invested in building schools, and literacy rates in Iraq increased significantly during his rule. Saddam established and controlled the \"National Campaign for the Eradication of Illiteracy\" and the campaign for \"Compulsory Free Education in Iraq,\" and largely under his auspices, the government established universal free schooling up to the highest education levels and hundreds of thousands learned to read in the years following the initiation of the program.\nWomen's rights.\nSaddam personally emphasized his full support for women's emancipation. Women were strongly encouraged to pursue education and join the workforce, and many rose to high-ranking positions in government, medicine, and academia. The Ba'ath Party is also known to have \"popularized women's education\" during their rule, leading Iraq to achieve one of the highest female literacy rates among Muslim-majority countries at the time. Saddam's government passed labor and employment laws that guaranteed equal pay, six months of fully paid maternity leave, and legal protections against sexual harassment. According to PeaceWomen, the rights of female workers in Ba'athist Iraq rivaled those of the United States during the same period.\nIn 1980, Saddam's government granted women full suffrage and the right to run for office. By the late 1970s and into the 1980s, women in Iraq held significant roles in society, accounting for 46% of all teachers, 29% of doctors, 46% of dentists and 70% of pharmacists. Women also constituted 40% of the civil service at one point in the 1980s. Legal reforms were enacted to grant equal rights in marriage, divorce, inheritance, and child custody, and Iraqi women could pass citizenship to their children even if married to non-Iraqis. Access to higher education was expanded, and women were given the same academic opportunities as men.\nUnlike other Arab or Muslim majority country, women in Iraq played an important role in the society. According to a report in 1985 by The New York Times: \"Iraqi women, historically among the most emancipated in the Arab world, hold jobs in all the professions, dress as they please, vote and hold more than 10 percent of the seats in the National Assembly. At the University of Baghdad, 55 percent of the enrollment is female. Day care is provided by the state free of charge, and with the war, women have taken on more traditional men's jobs and now make up 25 percent of the entire work force.\"\nIran\u2013Iraq War: 1980\u20131988.\nBackground.\nIn early 1979, Iran's Shah Mohammad Reza Pahlavi's Pahlavi dynasty were overthrown by the Islamic Revolution, thus giving way to an Islamic republic led by Ayatollah Ruhollah Khomeini. The influence of revolutionary Shi'a Islam grew apace in the region, particularly in countries with large Shi'a populations, especially Iraq. Saddam feared that the radical Islamic ideas\u2014hostile to his secular rule\u2014were rapidly spreading inside his country among the majority Shi'a population. Despite Saddam's fears of massive unrest, Iran's attempts to export its Islamic Revolution were largely unsuccessful in rallying support from Shi'as in Iraq and the Gulf states. Most Iraqi Shi'as, who comprised the majority of the Iraqi Armed Forces, chose their own country over their Shi'a Iranian coreligionists during the war that ensued.\nThere had also been bitter enmity between Saddam and Khomeini since the 1970s. Khomeini, having been exiled from Iran in 1964, took up residence in Iraq, at the Shi'a holy city of Najaf. There he involved himself with Iraqi Shi'as and developed a strong religious and political following against the Iranian government, which Saddam tolerated. When Khomeini began to urge the Shi'as there to overthrow Saddam and under pressure from the Shah, who had agreed to a rapprochement between Iraq and Iran in 1975, Saddam agreed to expel Khomeini in 1978 to France. Here, Khomeini gained media connections and collaborated with a much larger Iranian community, to his advantage. After Khomeini gained power, skirmishes between Iraq and revolutionary Iran occurred for ten months over the sovereignty of the disputed Shatt al-Arab waterway, which divides the two countries. During this period, Saddam publicly maintained that it was in Iraq's interest not to engage with Iran, and that it was in the interests of both nations to maintain peaceful relations.\nThe outbreak of the war in September 1980 was preceded by a long period of tension between the two countries throughout 1979 and 1980, including frequent border skirmishes, calls by Khomeini for the Shi'a Muslims in Iraq to revolt against the ruling Ba'ath Party, and allegations of Iraqi support for ethnic separatists in Iran. There were frequent clashes along the Iran\u2013Iraq border throughout 1980, with Iraq publicly complaining of at least 544 incidents and Iran citing at least 797 violations of its border and airspace. On 1 April 1980, the Islamic Dawa Party, an Iraqi Islamist group with supportive ties to Iran, attempted to assassinate Tariq Aziz, Iraq's then deputy prime minister at the University of Baghdad campus, in retaliation for a 30 March decree declaring \"membership of Dawa [to be] a capital offense\". On 30 April, Iraq organized an attack on the Iranian embassy in London. On 10 September 1980, Iraq forcibly reclaimed territories in Zain al-Qaws and Saif Saad that it had been promised under the terms of the 1975 Algiers Agreement but that Iran had never handed over, leading to both Iran and Iraq voiding the treaty, on 14 September and 17 September, respectively.\nWarfare.\nIraq invaded Iran on 22 September 1980, first launching airstrikes on numerous targets in Iran, including the Mehrabad Airport of Tehran, before occupying the oil-rich Iranian province of Khuzestan, which also has a sizable Arab minority. The invasion was initially successful, as Iraq captured more than 25,900\u00a0km2 of Iranian territory by 5 December 1980. Khuzestan and Basra were the main focus of the war, and the primary source of their economies. With the support of other Arab states, the United States, and Europe, and with major financial support from the Arab states of the Persian Gulf, Saddam became \"defender of the Arab world\" against a revolutionary, fundamentalist Shi'a Iran. Consequently, many viewed Iraq as \"an agent of the civilized world.\" He fought Iran mainly to prevent the expansion of Shi'a radicalism.\nThe blatant disregard of international law and violations of international borders were ignored. Instead Iraq received economic and military support from its allies, who overlooked Saddam's use of chemical warfare against the Kurds and the Iranians, in addition to Iraq's efforts to develop nuclear weapons. In the first days of the war, there was heavy ground fighting around strategic ports as Iraq launched an attack on Khuzestan. After making some initial gains, Iraq's troops began to suffer losses from human wave attacks by Iran. Meanwhile, Saddam's efforts to develop nuclear weapons faced a setback when Iraq's nuclear reactor was destroyed on 7 June 1981 by an Israeli air attack. By 1982, Iraq was on the defensive and looking for ways to end the war. Iraq quickly found itself bogged down in one of the longest and most destructive wars of attrition of the 20th century.\nDuring the war, Iraq used chemical weapons against Iranian forces fighting on the southern front and Kurdish separatists who were attempting to open up a northern front in Iraq with the help of Iran. Tariq Aziz later acknowledged Iraq's use of chemical weapons against Iran, but said that Iran had used them against Iraq first. The Iranians, demanding that the international community should force Iraq to pay war reparations to Iran, refused any suggestions for a cease-fire. Despite several calls for a ceasefire by the United Nations Security Council, hostilities continued until 20 August 1988. It was not until 20 July 1988 that Iran accepted Resolution 598, mainly due to poor morale, economic collapse, and Iraq's highly successful Tawakalna ala Allah Operations, which reversed all of Iran's territorial gains and effectively brought the war to an end. Encyclop\u00e6dia Britannica states: \"Estimates of total casualties range from 1,000,000 to twice that number. The number killed on both sides was perhaps 500,000, with Iran suffering the greatest losses.\" Neither side had achieved what they had originally desired and the borders were left nearly unchanged.\nThe southern, oil rich and prosperous areas were almost completely destroyed and were left at pre-1979 border, while Iran managed to make some small gains on its borders in the Northern Kurdish area. Both economies, previously healthy and expanding, were left in ruins. Saddam borrowed tens of billions of dollars from other Arab states and a few billions from elsewhere. This backfired on Iraq and Arab states, as Khomeini was widely perceived as a hero by his supporters for managing to defend Iran and maintain the war with little foreign support against the heavily backed Iraq and only managed to boost Islamic radicalism not only within the Arab states, but within Iraq itself, creating new tensions between the Sunni Ba'ath Party and the majority Shi'a population. Faced with rebuilding Iraq's infrastructure and internal resistance, Saddam desperately re-sought cash, this time for postwar reconstruction.\nAnfal campaign: 1986\u20131989.\nThe Anfal campaign was a campaign that took place during the war against the Kurdish people and many others in Kurdish regions of Iraq led by the government and headed by Ali Hassan al-Majid. The campaign takes its name from Qur'anic chapter 8 (\"al-\u02beanf\u0101l\"), which was used as a code name by the administration for a series of attacks against the \"peshmerga\" rebels and the mostly Kurdish civilian population of rural Northern Iraq, conducted between 1986 and 1989 culminating in 1988. The campaign was in retaliation to Kurd's support for Iran and their rebellion. This campaign also targeted Shabaks and Yazidis, Assyrians, Turkoman people and many villages belonging to these ethnic groups were also destroyed. Human Rights Watch estimates that between 50,000 and 100,000 people were killed. It considers the campaign as an act of genocide. Some Kurdish sources put the number higher, estimating that 182,000 Kurds were killed.\nOn 16 March 1988, the Kurdish town of Halabja was attacked with a mix of mustard gas and nerve agents, killing between 3,200 and 5,000 people, and injuring 7,000 to 10,000 more, mostly civilians. The attack occurred in conjunction with the Anfal campaign designed to reassert central control of the mostly Kurdish population of areas of northern Iraq and defeat the Kurdish peshmerga rebel forces. Following the incident, the U.S. State Department took the official position that Iran was partly to blame for the Halabja massacre. A study by the Defense Intelligence Agency held Iran responsible for the attack, an assessment that was subsequently used by the Central Intelligence Agency for much of the early 1990s. Despite this, few observers today doubt that it was Iraq that executed the Halabja massacre. According to Joost Hiltermann: \"Analysis of thousands of captured Iraqi secret police documents and declassified U.S. government documents, as well as interviews with scores of Kurdish survivors, senior Iraqi defectors and retired U.S. intelligence officers, show (1) that Iraq carried out the attack on Halabja, and (2) that the United States, fully aware it was Iraq, accused Iran, Iraq's enemy in a fierce war, of being partly responsible for the attack.\"\nInternational support and opposition.\nBacked by the United States, the United Kingdom, several European nations, and heavily financed by the Arab states of the Persian Gulf, Saddam positioned himself as \"the defender of the Arab world\" against a revolutionary, fundamentalist and Shi'a Islamist Iran. The only exception was the Soviet Union. It initially refused to supply Iraq on the basis of neutrality in the conflict. In his memoirs, Mikhail Gorbachev claimed that Brezhnev initially refused to aid Saddam due to anger over the regime's treatment of Iraqi communists. However, by 1982, the Soviet Union began supplying Iraq with military aid, and in the final years (1986\u20131988), it actively supported Iraq.\nIn a U.S. bid to open full diplomatic relations with Iraq, the country was removed from the U.S list of State Sponsors of Terrorism in February 1982. Ostensibly, this was because of improvement in the regime's record, although former U.S. Assistant Secretary of Defense Noel Koch later stated, \"No one had any doubts about [the Iraqis'] continued involvement in terrorism ... The real reason was to help them succeed in the war against Iran.\" Middle East special envoy Donald Rumsfeld met Saddam on 19\u201320 December 1983 at Baghdad. After which, Saddam sent his deputy Aziz to visit the United States in 1984. He met with President Ronald Reagan and then vice-president George H. W. Bush at the White House and secured further U.S support for Iraq.\nThe Soviet Union, France, and China together accounted for over 90% of the value of Iraq's arms imports between 1980 and 1988. While the U.S. supplied Iraq with arms, dual-use technology and economic aid, it was also involved in a covert and controversial illegal arms deal, providing sanctioned Iran with weaponry. This political scandal became known as the Iran\u2013Contra affair. Saddam reached out to other Arab governments for cash and political support during the war, particularly after Iraq's oil industry severely suffered at the hands of the Iranian navy in the Persian Gulf.\nChemical weapons were developed by Iraq from materials and technology supplied primarily by West German companies as well as using dual-use technology imported following the Reagan administration's lifting of export restrictions. The United States government also supplied Iraq with \"satellite photos showing Iranian deployments.\" This satellite imagery may have played a crucial role in blocking the Iranian invasion of Iraq in 1982. However, Saddam's government later blamed the Iraqi defeat in the First Battle of al-Faw in February 1986 on \"misinformation from the U.S.\"\nGulf War: 1990\u20131991.\nTensions with Kuwait: 1988\u20131990.\nThe end of the war with Iran served to deepen latent tensions between Iraq and its wealthy neighbor Kuwait. Saddam urged the Kuwaitis to waive the Iraqi debt accumulated in the war, some $30 billion, but they refused. Saddam pushed oil-exporting countries to raise oil prices by cutting back production; Kuwait refused, then led the opposition in OPEC to the cuts that Saddam had requested. Kuwait was pumping large amounts of oil, and thus keeping prices low, when Iraq needed to sell high-priced oil from its wells to pay off its huge debt.\nSaddam had consistently argued that Kuwait had historically been an integral part of Iraq, and had only come into being as a result of interference from the British government; echoing a belief that Iraqi nationalists had supported for the past fifty years. This belief was one of the few articles of faith uniting the political scene in a nation rife with sharp social, ethnic, religious, and ideological divides. The extent of Kuwaiti oil reserves also intensified tensions in the region. The oil reserves of Kuwait (with a population of 2\u00a0million next to Iraq's 25) were roughly equal to those of Iraq. Taken together, Iraq and Kuwait sat on top of some 20 percent of the world's known oil reserves; Saudi Arabia held another 25 percent. Saddam still had an experienced and well-equipped army, which he used to influence regional affairs. He later ordered troops to the Iraq\u2013Kuwait border.\nAs Iraq\u2013Kuwait relations rapidly deteriorated, Saddam was receiving conflicting information about how the US would respond to the prospects of an invasion. For one, Washington had been taking measures to cultivate a constructive relationship with Iraq for roughly a decade. The Reagan administration gave Iraq roughly $4\u00a0billion in agricultural credits to bolster it against Iran. Saddam's Iraq became \"the third-largest recipient of US assistance.\" Reacting to Western criticism in April 1990, Saddam threatened to destroy half of Israel if it moved against Iraq. In May 1990, he criticized US support for Israel warning that \"the US cannot maintain such a policy while professing friendship towards the Arabs.\" In July 1990 he threatened force against Kuwait and the UAE saying \"The policies of some Arab rulers are American ... They are inspired by America to undermine Arab interests and security.\" The US sent warplanes and combat ships to the Persian Gulf in response to these threats.\nOn 25 July 1990, Saddam summoned the US ambassador to Iraq, April Glaspie, for an emergency meeting where the Iraqi leader attacked American policy with regards to Kuwait and the United Arab Emirates. During the meeting, Glaspie stated that \"we have no opinion on the Arab-Arab conflicts, like your border disagreement with Kuwait,\" which was interpreted as tacit approval for the invasion of Kuwait.\nSaddam stated that he would attempt last-ditch negotiations with the Kuwaitis but Iraq \"would not accept death.\" U.S. officials attempted to maintain a conciliatory line with Iraq, indicating that while George H. W. Bush and James Baker did not want force used, they would not take any position on the Iraq\u2013Kuwait boundary dispute and did not want to become involved. Later, Iraq and Kuwait met for a final negotiation session, which failed. Saddam then sent his troops into Kuwait. As tensions between Washington and Saddam began to escalate, the Soviet Union, under Mikhail Gorbachev, strengthened its military relationship with the Iraqi leader, providing him military advisers, arms and aid.\nInvasion of Kuwait.\nOn 2 August 1990, Saddam invaded Kuwait, initially claiming assistance to \"Kuwaiti revolutionaries\", thus sparking an international crisis. On 4 August an Iraqi-backed \"Provisional Government of Free Kuwait\" was proclaimed, but a total lack of legitimacy and support for it led to an 8 August announcement of a \"merger\" of the two countries. On 28 August Kuwait formally became the 19th Governorate of Iraq. Just two years after the 1988 Iraq and Iran truce, \"Saddam did what his Gulf patrons had earlier paid him to prevent.\" Having removed the threat of Iranian fundamentalism he \"overran Kuwait and confronted his Gulf neighbors in the name of Arab nationalism and Islam.\" Saddam justified the invasion of Kuwait in 1990 by claiming that Kuwait had always been an integral part of Iraq and only became an independent nation due to the interference of the British Empire.\nWhen later asked why he invaded Kuwait, Saddam first claimed that it was because Kuwait was rightfully Iraq's 19th province and then said \"When I get something into my head I act. That's just the way I am.\" As per observers, Saddam could pursue such military aggression with a \"military machine paid for in large part by the tens of billions of dollars Kuwait and the Gulf states had poured into Iraq and the weapons and technology provided by the Soviet Union, Germany, and France.\" It was revealed during his 2003\u20132004 interrogation that in addition to economic disputes, an insulting exchange between the Kuwaiti emir Jaber al-Ahmd Al Sabah and Iraq's foreign minister \u2013 during which Saddam claimed that the emir stated his intention to turn \"every Iraqi woman into a $10 prostitute\" by ruining Iraq financially \u2013 was a decisive factor in triggering the invasion. Shortly before he invaded Kuwait, Saddam shipped 100 new Mercedes cars 200 Series cars to top editors in Egypt and Jordan. Two days before the first attacks, Saddam reportedly offered Egypt's Hosni Mubarak $50 million in cash, \"ostensibly for grain.\"\nGeorge H. W. Bush responded cautiously for the first several days. On one hand, Kuwait, prior to this point, had been a virulent enemy of Israel and was the Persian Gulf monarchy that had the most friendly relations with the Soviets. On the other hand, Washington foreign policymakers, along with Middle East experts, military critics, and firms heavily invested in the region, were extremely concerned with stability in this region. The invasion immediately triggered fears that the world's price of oil, and therefore control of the world economy, was at stake. The United Kingdom profited heavily from billions of dollars of Kuwaiti investments and bank deposits. Bush was perhaps swayed while meeting with British prime minister Margaret Thatcher, who happened to be in the U.S. at the time.\nYasser Arafat supported Saddam during the war. During the period of negotiations and threats following the invasion, Saddam focused renewed attention on the Palestinian problem by promising to withdraw his forces from Kuwait if Israel would relinquish its occupation over Palestine and the Syrian Golan Heights. Saddam's proposal further split the Arab world, pitting US- and Western-supported Arab states against the Palestinians. The allies ultimately rejected any linkage between the Kuwait crisis and Palestinian issues.\nOperation Desert Storm.\nCooperation between the United States and the Soviet Union made possible the passage of resolutions in the United Nations Security Council giving Iraq a deadline to leave Kuwait and approving the use of force if Saddam did not comply with the timetable. The United States officials feared that the Iraqi retaliation against oil-rich Saudi Arabia, since the 1940s a close ally of Washington, for the Saudis' opposition to the invasion of Kuwait. Accordingly, the United States and a group of allies, including countries as diverse as Egypt, Syria and Czechoslovakia, deployed a massive number of troops along the Saudi border with Kuwait and Iraq in order to encircle the Iraqi army, which was the largest in the Middle East.\nSaddam's officers looted Kuwait, stripping even the marble from its palaces to move it to Saddam's own palace. Saddam ignored the Security Council deadline. Backed by the Security Council, a U.S-led coalition launched round-the-clock missile and aerial attacks on Iraq, beginning 16 January 1991. Israel, though subjected to attacks by Iraqi missiles, refrained from retaliating in order not to provoke Arab states into leaving the coalition. A ground force consisting largely of U.S. and British armored and infantry divisions ejected Saddam's army from Kuwait in February 1991 and occupied the southern portion of Iraq as far as the Euphrates.\nOn 6 March 1991, Bush announced \"What is at stake is more than one small country, it is a big idea\u2014a new world order, where diverse nations are drawn together in common cause to achieve the universal aspirations of mankind: peace and security, freedom, and the rule of law.\" In the end, the Iraqi army proved unable to compete on the battlefield with the highly mobile coalition land forces and their overpowering air support. Some 175,000 Iraqis were taken prisoner and casualties were estimated at over 85,000. As part of the cease-fire agreement, Iraq agreed to scrap all poison gas and germ weapons and allow UN observers to inspect the sites. UN trade sanctions would remain in effect until Iraq complied with all terms. Saddam publicly claimed victory at the end of the war.\nLater years: 1990s to 2003.\nIraq's ethnic and religious divisions, together with the brutality of the conflict that this had engendered, laid the groundwork for postwar rebellions. In the aftermath of the fighting, social and ethnic unrest among Shi'a Muslims, Kurds, and dissident military units threatened the stability of Saddam's government. Uprisings erupted in the north, south and central parts of Iraq, but were ruthlessly repressed. The uprisings led to the death of 100,000\u2013180,000 people, mostly civilians. The U.S., which had urged Iraqi people to rise up against Saddam, did nothing to assist the rebellions. Despite the widespread Shi'a rebellions, Iran had no interest in provoking another war, while Turkey opposed any prospect of Kurdish independence, and the Saudi Arabia and other conservative Arab states feared an Iran-style Shi'a revolution. Saddam, having survived the immediate crisis in the wake of defeat, was left firmly in control of Iraq, although the country never recovered either economically or militarily from the Gulf War, until a modest recovery recorded in the early 2000s. \nSaddam routinely cited his survival as \"proof\" that Iraq had in fact won the war against the U.S. This message earned Saddam a great deal of popularity in many sectors of the Arab world. John Esposito wrote, \"Arabs and Muslims were pulled in two directions. That they rallied not so much to Saddam Hussein as to the bipolar nature of the confrontation (the West versus the Arab Muslim world) and the issues that Saddam proclaimed: Arab unity, self-sufficiency, and social justice.\" As a result, Saddam appealed to many people for the same reasons that attracted more and more followers to Islamic revivalism and also for the same reasons that fueled anti-Western feelings.\nTo gain support from religious communities, Saddam initiated the Faith Campaign in 1993, which was under the supervision of vice president Izzat Ibrahim al-Douri. Some elements of Sharia law were introduced, and the phrase \"Allahu Akbar\" (\"God is great\"), in Saddam's handwriting, was added to the national flag. Saddam also commissioned the production of a \"Blood Quran\", written using 27 litres of his own blood, to thank God for saving him from various dangers and conspiracies. Under the campaign, numerous mosques and Islamic institutes were built across Iraq. The United Nations-placed sanctions against Iraq for invading Kuwait were not lifted, blocking Iraqi oil exports. Economic hardship followed within the country as GDP plummeted from US$44.36 billion in 1990 to US$9 billion by 1995. Iraq had lost around US$170 billion of oil revenues. Sanctions also restricted basic-medical equipment and supplies from getting into Iraq. During the mid-1990s, the UN considered relaxing the sanctions imposed because of the hardships suffered by ordinary Iraqis. Studies dispute the number of people who died in south and central Iraq during the years of the sanctions. On 9 December 1996, Saddam's government accepted the Oil-for-Food Programme that the UN had first offered in 1992.\nRelations with the U.S. remained tense following the war. The U.S. launched a missile attack aimed at Iraq's intelligence headquarters in Baghdad on 26 June 1993, citing evidence of repeated violations of the \"no fly zones\" imposed after the war and for incursions into Kuwait. American officials continued to accuse Saddam of violating the terms of the Gulf War's ceasefire, by developing weapons of mass destruction and other banned weaponry, and violating the UN-imposed sanctions. Bill Clinton maintained sanctions and ordered air strikes in the \"Iraqi no-fly zones\", in the hope that Saddam would be overthrown by political enemies inside Iraq. Western charges of Iraqi resistance to U.N access to suspected weapons were the pretext for crises between 1997 and 1998, culminating in intensive U.S. and British missile strikes on Iraq, 16\u201319 December 1998. After two years of intermittent activity, U.S. and British warplanes struck harder at sites near Baghdad in February 2001. Former CIA case officer Robert Baer reports that he \"tried to assassinate\" Saddam in 1995, amid \"a decade-long effort to encourage a military coup in Iraq.\"\nBy the end of the 1990s, diplomatic isolation of Iraq with Arab states was gradually dissipating, and the economy of Iraq had improved by 2000, with its GDP increasing to $23.73 billion. Saddam later decided to use euros, instead of U.S. dollars for Iraqi oil. Almost all of Iraq's oil exports under the Oil-for-food program were paid in euros since 2001. Approximately 26 billion euros (\u00a317.4bn) was paid for 3.3 billion barrels of oil into an escrow account in New York.\nArab\u2013Israeli conflict.\nSaddam was widely known for his pro-Palestinian and anti-Israel stance. He appeared on television threatening to burn and destroy Israel. However, Saddam's official position was that the relations of Iraq with Israel will be determined by the solution accepted by Palestinians. Relations between Iraq and Egypt deteriorated in 1977, as a result of Egyptian President Anwar Sadat's peace initiatives with Israel. Relations improved after Egypt supported Iraq in the 1980\u20131988 war. During the Iran\u2013Iraq War, Israel was one of the main suppliers of military and intelligence support to Iran. In 1981, it carried out Operation Opera, a surprise attack on Iraq's unfinished Osirak nuclear reactor, with Iranian intelligence support. Amid the 1991 Gulf War, Iraq initiated a missile campaign against Israel.\nSaddam supported various Palestinian guerrilla movements, provided financial support to Palestinians, and allowed Palestinian refugees in Iraq to obtain full citizenship rights, unlike the situation of Palestinians in other countries. Saddam maintained close relations with Palestinian leaders such as Yasser Arafat. In May 2000, Saddam and his representatives allegedly had secret meetings with the Israeli government. He supposedly offered that Iraq will end its anti-Israel foreign policy if the issue of Palestinian refugees in Lebanon was resolved. However, this was later denied by the government.\nFollowing the outbreak of the Second Intifada in the Palestinian territories, Saddam openly expressed solidarity with the Palestinians, and established the Jerusalem Army, a volunteer force in solidarity with the Palestinians. Saddam also provided financial assistance from Iraq's oil revenue, to the families of the Palestinian victims and militants. Around 20% of Iraq's oil revenue was directed to Palestinians. Contrary to the claims of the United States and the Israel, the financial support was not exclusively used to support suicide bombing. On the eve of Christmas in 2000, Saddam wrote a public letter urging Muslims and Christians in Iraq to lead jihad against the Zionist movement. In 2001, Saddam declared on the state Iraqi television:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Palestine is Arab and must be liberated from the river to the sea and all the Zionists who emigrated to the land of Palestine must leave.\u2014\u200a\nIn 2002, following an Israeli incursions into Palestinian territory, Saddam stopped supplying oil to Western countries in order to force Israel to abandon its incursions, a move supported by Iran and Libya.\n2003 invasion and war.\nBackground.\nMany members of the international community, especially the U.S., continued to view Saddam as a bellicose tyrant who was a threat to the stability of the region. In his January 2002 state of the union address to Congress, President George W. Bush spoke of an \"axis of evil\" consisting of Iran, North Korea, and Iraq. Moreover, Bush announced that he would possibly take action to topple the Iraqi government, because of the threat of its weapons of mass destruction. Bush stated that \"The Iraqi regime has plotted to develop anthrax, and nerve gas, and nuclear weapons for over a decade\u00a0... Iraq continues to flaunt its hostility toward America and to support terror.\"\nAfter the passing of UN Security Council Resolution 1441, which demanded that Iraq give \"immediate, unconditional and active cooperation\" with UN and IAEA inspections, Saddam allowed U.N. weapons inspectors led by Hans Blix to return to Iraq. During the renewed inspections beginning in November 2002, Blix found no stockpiles of WMD and noted the \"proactive\" but not always \"immediate\" Iraqi cooperation as called for by Resolution 1441.\nWith war still looming on 24 February 2003, Saddam took part in an interview with CBS News reporter Dan Rather. Talking for more than three hours, he denied possessing any weapons of mass destruction, or any other weapons prohibited by the UN guidelines. He also expressed a wish to have a live televised debate with George W. Bush, which was declined. It was his first interview with an American reporter in over a decade. CBS aired the taped interview later that week. Saddam later told an FBI interviewer that he once left open the possibility that Iraq possessed weapons of mass destruction in order to appear strong against Iran.\nInvasion and overthrow.\nThe United States-led coalition forces initiated the invasion of Iraq on 20 March 2003. The Iraqi government and military collapsed within three weeks of the beginning of the invasion. By the beginning of April, the coalition forces occupied much of Iraq. The resistance of the much-weakened Iraqi Armed Forces either crumbled or shifted to guerrilla tactics, and it appeared that Saddam had lost control of Iraq. He was last seen in a video which purported to show him in the Baghdad suburbs surrounded by supporters. When Baghdad fell to US-led forces on 9 April, marked symbolically by the toppling of his statue, Saddam was nowhere to be found and his government was completely overthrown.\nCapture and interrogation.\nIn April 2003, Saddam's whereabouts remained in question during the weeks following the fall of Baghdad and the conclusion of the major fighting of the war. Various sightings of Saddam were reported in the weeks following the war, but none were authenticated. At various times he released audio tapes promoting popular resistance to his ousting. On 22 July 2003, his sons Uday and Qusay and 14-year-old grandson Mustafa were killed in a three-hour gunfight with the U.S. forces in Mosul. Upon their deaths, he commemorated them as \"martyrs\" on radio. Saddam was placed at the top of the US list of most-wanted Iraqis, which included officials of his government and the party members.\nOn 13 December 2003, in Operation Red Dawn, Saddam was captured by American forces after being found hiding in a hole in the ground near a farmhouse in ad-Dawr, near Tikrit. Following his capture, Saddam was transported to a US base near Tikrit, and later taken to the American base near Baghdad Airport. Documents obtained and released by the National Security Archive detail FBI interviews and conversations with Saddam while he was in US custody. On 14 December, US administrator in Iraq Paul Bremer confirmed that Saddam had indeed been captured at a farmhouse in ad-Dawr near Tikrit. Bremer presented video footage of Saddam in custody. He was shown with a full beard and hair longer than his familiar appearance. He was described by US officials as being in good health. Bremer reported plans to put Saddam on trial, but claimed that the details of such a trial had not yet been determined. Iraqis and Americans who spoke with Saddam after his capture generally reported that he remained self-assured, describing himself as a \"firm, but just leader.\"\nBritish tabloid newspaper \"The Sun\" posted a picture of Saddam wearing white briefs on the front cover of a newspaper. Other photographs inside the paper show Saddam washing his trousers, shuffling, and sleeping. The U.S. government stated that it considered the release of the pictures a violation of the Geneva Convention and that it would investigate the photographs. During this period Saddam was interrogated by FBI agent George Piro.\nThe guards at the Baghdad detention facility called their prisoner \"Vic\", which stands for \"Very Important Criminal\" and let him plant a small garden near his cell. The nickname and the garden are among the details about the former Iraqi leader that emerged during a March 2008 tour of the Baghdad prison and cell where Saddam slept, bathed, kept a journal, and wrote poetry in the final days before his execution; he was concerned to ensure his legacy and how the history would be told. The tour was conducted by US Marine Maj. Gen. Doug Stone, overseer of detention operations for the US military in Iraq at the time. During his imprisonment he exercised and was allowed to have his personal garden; he also smoked his cigars and wrote his diary in the courtyard of his cell.\nTrial.\nOn 30 June 2004, Saddam, held in custody by US forces at the US base \"Camp Cropper\", along with 11 other senior Ba'athist leaders, was handed over to the interim Iraqi government to stand trial for crimes against humanity and other offences.\nA few weeks later, he was charged by the Iraqi Special Tribunal with crimes committed against residents of Dujail in 1982, following a failed assassination attempt against him. Specific charges included the murder of 148 people, torture of women and children and the illegal arrest of 399 others. Numerous challenges came during his trial. Saddam and his lawyers contested the court's authority and maintained that he was still the President of Iraq. There were assassinations and attempted assassinations of several of Saddam's lawyers. The replacement of the chief presiding judge midway through the trial had impact on the trial.\nOn 5 November 2006, Saddam was found guilty of crimes against humanity \u2014 the killing of 148 Shi'a residents in the town of Dujail in 1982, and was sentenced to death by hanging. His half-brother, Barzan Ibrahim, and Awad Hamed al-Bandar, head of Iraq's Revolutionary Court in 1982, were convicted of similar charges and were themselves sentenced to death. The verdict and sentencing were both appealed, but subsequently affirmed by Iraq's Supreme Court of Appeals.\nExecution.\nSaddam was executed by hanging on the first day of Eid ul-Adha, 30 December 2006, despite his request to be executed by firing squad, which he argued was the most appropriate method due to his role as commander-in-chief of the Iraqi military. The execution was carried out at Camp Justice, an Iraqi army base in Baghdad's Kadhimiya neighborhood.\nSaudi Arabia condemned the Iraqi authorities for carrying out the execution on a holy day. A presenter from the Al-Ikhbariya television station officially stated: \"There is a feeling of surprise and disapproval that the verdict has been applied during the holy months and the first days of Eid al-Adha. Leaders of Islamic countries should show respect for this blessed occasion ... not demean it.\"\nAn unofficial video of the execution was recorded on a mobile phone and his captors could be heard insulting Saddam. The execution video was leaked and widely circulated online within hours, sparking global controversy. It was later claimed by the head guard at the tomb where his remains lay that Saddam's body had been stabbed six times after the execution. Saddam's demeanor while being led to the gallows has been discussed by two witnesses, Iraqi Judge Munir Haddad and Iraqi national security adviser Mowaffak al-Rubaie. The accounts of the two witnesses are contradictory as Haddad describes Saddam as being strong in his final moments whereas al-Rubaie says Saddam was clearly afraid, but the common view is not of the latter. Not long before the execution, Saddam's lawyers released his last letter.\nSaddam spoke his last words during the execution, \"May God's blessings be upon Muhammad and his household. And may God hasten their appearance and curse their enemies.\" Then one of the crowd repeatedly said the name of the Iraqi Shi'a cleric Muqtada al-Sadr. Saddam laughed and later said, \"Do you consider this manhood?\" The crowd shouted, \"go to Hell.\" Saddam replied, \"To the hell that is Iraq!?\" Again, one of the crowd asked those who shouted to keep quiet for God. Saddam started recitation of final Muslim prayers, \"I bear witness that there is no god but Allah and I testify that Muhammad is the Messenger of Allah.\" One of the crowd shouted, \"The tyrant has collapsed!\" Saddam said, \"May God's blessings be upon Muhammad and his household\". He recited the shahada one and a half times, as while he was about to say 'Muhammad' on the second shahada, the trapdoor opened, cutting him off mid-sentence. The rope broke his neck, killing him instantly. A second unofficial video, apparently showing Saddam's body on a trolley, emerged several days later. It sparked speculation that the execution was carried out incorrectly as Saddam had a gaping hole in his neck.\nSaddam was buried at his birthplace of Al-Awja in Tikrit, Iraq, on 31 December 2006. He was buried from his sons Uday and Qusay Hussein. His tomb was reported to have been destroyed in March 2015. Before it was destroyed, a Sunni tribal group reportedly removed his body to a secret location, fearful of what might happen.\nPersonal life and family.\nIn August 1995, Raghad and her husband, Hussein Kamel al-Majid, and Rana and her husband, Saddam Kamel al-Majid, defected to Jordan with their children. They returned to Iraq after receiving assurances that Saddam would pardon them. Within three days of their return in February 1996, the Kamel brothers were killed in a gunfight with clan members who considered them traitors.\nIn August 2003, Saddam's daughters Raghad and Rana were granted sanctuary in Jordan. That month, they spoke with CNN and the Arab satellite station Al-Arabiya in Amman. When asked about her father, Raghad told CNN, \"He was a very good father, loving, has a big heart.\" Asked if she wanted to give a message to her father, she said: \"I love you and I miss you.\" Her sister Rana also remarked, \"He had so many feelings and he was very tender with all of us.\"\nSaddam was known for his lavish tastes, including wearing a diamond-coated Rolex wristwatch, which he reportedly gifted to political allies and friends.\nOn 28 April 2001, Saddam marked his 64th birthday with a large state-sponsored celebration.\nHonors and awards.\nIn 1991, the Iraqi government awarded Saddam the Order of the Two Rivers, the country's highest honor, as a recognition of his \"historic role\" and \"noble services to Iraq\". This announcement was made following a Cabinet meeting, and Information Minister Hamid Youssef Hummadi stated that the decision was unanimous. The award was bestowed on Saddam, during his 54th birthday, in appreciation of his exceptional contributions and significant impact on Iraq.\nHe was honored by titles such as \"Field Marshal\" and \"Comrade\". Saddam Hussein is one of the recipients of the Key to the City. In 1980, Saddam received a ceremonial key to the city of Detroit after making a donation of nearly half a million dollars to a local church. Saddam successfully turned Iraq into a leading hub for healthcare and education. This improved the quality of life in Iraq. For this reason, Saddam was honored by an award from UNESCO.\nA collection of medals attributed to Saddam was once displayed in a museum in Johannesburg, South Africa. He received the Order of Merit (\"Wisam al-Jadara\"), which is rare and was awarded to only a few Iraqi rulers. Order of the Mother of Battles was awarded to Saddam Hussein for his role in the 1991 Gulf War against Kuwait and the United States. He received numerous medals from the Iraqi state commemorating his involvement or leadership during various events.\nPolitical and cultural image.\nThe political ideas and policies pursued by Saddam became known as Saddamism. This doctrine was officially endorsed by his government and promoted by the Iraqi daily newspaper \"Babil\" owned by his son Uday Hussein.\nDuring his leadership, Saddam promoted the idea of dual nationalism that combined Iraqi nationalism and Arab nationalism, linking Iraq's identity to wider matters that impact Arabs as a whole. Saddam viewed Iraq's ancient Mesopotamian heritage as compatible with his vision of Arab nationalism. In the course of his reign, the government adopted the historic Muslim leader Saladin as a national symbol, while Saddam styled himself as the modern successor of Babylonian King Nebuchadnezzar and had stamped the bricks of ancient Babylon with his name and titles next to him. During the Gulf War, Saddam claimed the historic roles of Nebuchadnezzar, Saladin, and Gamal Abdel Nasser.\nSaddam often emphasized his nomadic Bedouin roots, framing them as a source of honor and traditional values. Following the death of Ayatollah Khomeini, his long-time adversary, Saddam instructed media outlets not to gloat, stating that it was part of Arab cultural tradition to show restraint in speaking about the dead and that \"when he is dead, that's it. You don't talk ill of the dead.\"\nHe organized two show elections in 1995 and 2002. In the 1995 referendum, he reportedly received 99.96% of the votes with 99.47% turnout, gaining 3,052 negative votes among an electorate of 8.4 million. In the 2002 referendum, he officially achieved 100% of approval votes and 100% turnout, as the electoral commission reported the next day that every one of the 11,445,638 eligible voters cast a \"Yes\" vote for the president.\nReception and legacy.\nThroughout the Arab world, many Arabs praise Saddam as a resolute leader who stood up to Western imperialism, Israeli occupation of Palestine, and foreign intervention in the region, while many Iraqis, especially Shi'as and Kurds, view him negatively as a dictator responsible for brutal authoritarianism, repression and injustices.\nSupporters noted that under Saddam, the government invested heavily in infrastructure projects, such as roads, bridges, and public buildings. The government invested in building schools and hospitals, and literacy rates in Iraq increased significantly during his rule. Women were encouraged to participate in education and the workforce, and many held high-ranking positions in government and public institutions. Saddam's regime was secular in character. Religion did not play a dominant role in the government's policies. Saddam's regime later placed greater emphasis on Islam in all sectors of Iraqi life from 1993 through the Faith Campaign. In 1977, Saddam stated \"our Party does not take a neutral stance between faith and atheism; it is always on the side of faith.\"\nBy contrast, critics described Saddam as a repressive totalitarian leader. His regime was notorious for its repressive tactics. These included widespread surveillance, torture, and extrajudicial killings. Numerous cases of human rights abuses committed by his government were documented by human rights organizations. Saddam's regime suppressed political opposition through a combination of violence, intimidation, and censorship. Freedom of speech and freedom of the press were severely curtailed, and political opponents were often executed or imprisoned. He initiated three military conflicts, including the Iran\u2013Iraq War, the Iraqi invasion of Kuwait, and the Gulf War. These actions led to heavy casualties and widespread regional instability. While there were economic development initiatives, Saddam's regime was also marked by mismanagement and widespread corruption, particularly during the final years of his regime. The economic sanctions imposed on Iraq during his rule further exacerbated hardships for the country's population. Saddamism has been described by critics as a mix of \"Sunni Arab nationalism, confused Stalinism, and fascist zeal for the fatherland and its leader\".\nIn July 2016, then US presidential candidate Donald Trump praised Saddam for militant suppression and stability during his presidency in Iraq. Libyan politician and commander of the Libyan National Arab Army, Khalifa Haftar, named his son Saddam Haftar after Saddam Hussein.\nCultural depictions of Saddam can be found in various movies, including three documentary movies made about Saddam. Saddam's Tribe, released in 2007, explores the complex relationship between Saddam Hussein and the Al-Bu Nasir, a powerful Arab tribe in Iraq to which Saddam belongs. In 2008, a TV series based on his life \u2014 House of Saddam \u2014 was released. Irish actor Barry Keoghan will appear in a new movie about Saddam which was announced in 2024.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29491", "revid": "41219559", "url": "https://en.wikipedia.org/wiki?curid=29491", "title": "Sonja Henie", "text": "Norwegian figure skater and American film star (1912\u20131969)\nSonja Henie (8 April 1912 \u2013 12 October 1969) was a Norwegian figure skater and film star. She was a three-time Olympic champion (1928, 1932, 1936) in women's singles, a ten-time World champion (1927\u20131936) and a six-time European champion (1931\u20131936). Henie won more Olympic and World titles than any other ladies' figure skater. She is one of only two skaters to defend a ladies' singles Olympic title, the other being Katarina Witt, and her six consecutive European titles have only been matched by Witt.\nAt the height of Henie's American acting career, she was one of the highest-paid stars in Hollywood and starred in a series of box-office hits, including \"Thin Ice\" (1937), \"Happy Landing\" (1938), \"My Lucky Star\" (1938), \"Second Fiddle\" (1939), and \"Sun Valley Serenade\" (1941).\nBiography.\nEarly life.\nHenie was born on 8 April 1912 in Kristiania (now Oslo), Norway; she was the only daughter of Wilhelm Henie (1872\u20131937), a prosperous Norwegian furrier, and his wife, Selma Lochmann-Nielsen (1888\u20131961). In addition to the income from the fur business, both of Henie's parents had inherited wealth. Wilhelm Henie had been a one-time World Cycling Champion and the Henie children were encouraged to take up a variety of sports at a young age. Henie initially showed talent at skiing, then followed her older brother, Leif, to take up figure skating. As a girl Henie also was a nationally ranked tennis player, and a skilled swimmer and equestrian. Once Henie began serious training as a figure skater, her formal schooling ended. She was educated by tutors, and her father hired the best experts in the world, including the famous Russian ballerina, Tamara Karsavina, to transform his daughter into a sporting celebrity.\nHenie began skating at the age of 5. She enjoyed music and dance from an early age, studying ballet and after starting her competitive skating career, admired the Russian ballet dancer Anna Pavlova after seeing her perform in London.\nCompetitive career.\nHenie placed eighth in a field of eight at the 1924 Winter Olympics, at the age of eleven. Henie won the first of an unprecedented ten consecutive World Figure Skating Championships in 1927 at the age of fourteen. The results of 1927 World Championships, where Henie won in 3\u20132 decision (or 7 vs. 8 ordinal points) over the defending Olympic and World Champion Herma Szabo of Austria, was \"controversial\", as three of the five judges that gave Henie first-place ordinals were Norwegian (1 + 1 + 1 + 2 + 2 = 7 points) while Szabo received first-place ordinals from an Austrian and a German Judge (1 + 1 + 2 + 2 + 2 = 8 points). Henie went on to win first of her three Olympic gold medals the following year, becoming one of the youngest figure skating Olympic champions. She defended her Olympic titles in 1932 and in 1936, and her world titles annually until 1936. Henie and Gillis Grafstr\u00f6m from Sweden are the only skaters to win three Olympic gold medals in single skating. She also won six consecutive European championships from 1931 to 1936.\nHenie's unprecedented three Olympic gold medals have not been matched by any ladies' single skater since, nor have her achievements as ten-time consecutive World champion. While Irina Slutskaya of Russia has held the record for most European titles among ladies' skaters since 2006, Henie still retains the record of most consecutive titles, sharing it with Katarina Witt of East Germany/Germany (1983\u20131988).\nTowards the end of her career, she began to be strongly challenged by younger skaters including Cecilia Colledge, Megan Taylor, and Hedy Stenuf. However, she held off these competitors and went on to win her third Olympic title at the 1936 Winter Olympics, albeit in very controversial circumstances with Cecilia Colledge finishing a very close second. Indeed, after the school figures section at the 1936 Olympic competition, Colledge and Henie were virtually neck and neck with Colledge trailing by just a few points. As Sandra Stevenson recounted in \"The Independent\", \"the closeness [of the competition] infuriated Henie, who, when the result for that section was posted on a wall in the competitors' lounge, swiped the piece of paper and tore it into little pieces.\nThe draw for the free skating [then] came under suspicion after Henie landed the plum position of skating last, while Colledge had to perform second of the 26 competitors. The early start was seen as a disadvantage, with the audience not yet whipped into a clapping frenzy and the judges known to become freer with their higher marks as the event proceeded. Years later, a fairer, staggered draw was adopted to counteract this situation\".\nDuring her competitive career, Henie traveled widely and worked with a variety of foreign coaches. At home in Oslo, she trained at Frogner Stadium, where her coaches included Hj\u00f8rdis Olsen and Oscar Holte. During the latter part of her competitive career she was coached primarily by the American Howard Nicholson in London.\nIn addition to traveling to train and compete, she was much in demand as a performer at figure skating exhibitions in both Europe and North America. Henie became so popular with the public that police had to be called out for crowd control on her appearances in various disparate cities such as Prague and New York City.\nIt was an open secret that, in spite of the strict amateurism requirements of the time, Wilhelm Henie demanded \"expense money\" for his daughter's skating appearances. Both of Henie's parents had given up their own pursuits in Norway\u2014leaving Leif to run the fur business\u2014in order to accompany Sonja on her travels and act as her managers.\nProfessional and film career.\nAfter the 1936 World Figure Skating Championships, Henie gave up her amateur status and took up a career as a professional performer in acting and live shows. While still a girl, Henie had decided that she wanted to move to California and become a movie star when her competitive days were over, without considering that her strong accent might hinder her acting ambitions.\nHenie opened up opportunities for figure skaters to use their skills to earn a living. In addition to appearing in Hollywood films, she toured North America with her own professional shows, thus amassing a great deal of personal wealth and by popularizing the ice show, opened up professional skating opportunities for other lesser-known figure skaters.\nIn 1936, following a successful ice show in Los Angeles orchestrated by her father to launch her film career, Hollywood studio chief Darryl Zanuck signed her to a long-term contract at Twentieth Century Fox, which made her one of the highest-paid actresses of the time. After the success of her first film, \"One in a Million\" (1936), Henie's position was assured and she became increasingly demanding in her business dealings with Zanuck. Henie also insisted on having total control of the skating numbers in her films such as \"Second Fiddle\" (1939).\nHenie tried to break the musical comedy mould with the anti-Nazi film \"Everything Happens at Night\" (1939) and \"It's a Pleasure\" (1945), a skating variation of the often-told \"A Star Is Born\" tale about alcoholic-star-in-decline-helps-newcomer-up. It was her only film shot in Technicolor, but it was not as huge at the box office as her other films and also proved her limitations as a dramatic actress in her only dramatic film.\nWhen Zanuck realized this, he cast her in more musical comedies; \"Sun Valley Serenade\" (1941) with Glenn Miller, John Payne, The Nicholas Brothers, and hit songs such as \"In the Mood\", \"Chattanooga Choo Choo\", \"It Happened in Sun Valley\", and \"I Know Why (And So Do You)\"; followed by \"Iceland\" (1942) with Jack Oakie, Payne, and the hit song \"There Will Never Be Another You\"; and finally \"Wintertime\" (1943) with Cesar Romero, Carole Landis, Cornel Wilde, and Oakie. Sonja had by now developed a comedy flair and these films were all among the top box-office hits for 20th Century-Fox the respective years. Adjusted for 2017 dollars, eight Henie movies crossed the $100 million domestic gross mark. \"Happy Landing\" (1938) was her biggest box office hit.\nIn her film \"Everything Happens at Night\" (1939), Ray Milland and Robert Cummings star as rival reporters hot on the trail of Hugo Norden (Maurice Moscovich). Norden, a Nobel Prize winner, was supposedly murdered by the Gestapo, but is rumoured to be in hiding and writing anonymous dispatches advocating world peace. When Geoffrey and Ken track Norden to a small village in the Swiss Alps, they soon find themselves competing over the affections of beautiful Louise (Henie), who has a deeper connection to the missing Nobel laureate than the reporters realize. When Geoffrey and Ken get so distracted by romance that they begin to neglect their assignments, it almost leads to disaster as the Gestapo sets out to silence Norden once and for all. Released on 22 December 1939, it was banned in Nazi Germany.\nIn addition to her film career at Fox from 1936 to 1943, Henie formed a business arrangement with Arthur Wirtz, who produced her touring ice shows under the name of \"Hollywood Ice Revue\". Wirtz also acted as Henie's financial advisor. At the time, figure skating and ice shows were not yet an established form of entertainment in the United States. Henie's popularity as a film actress attracted many new fans and instituted skating shows as a popular new entertainment. Throughout the 1940s, Henie and Wirtz produced lavish musical ice skating extravaganzas at Rockefeller Center's Center Theatre attracting millions of ticket buyers.\nHenie broke off her arrangement with Wirtz in 1950 and for the next three seasons produced her own tours under the name \"Sonja Henie Ice Revue\". It was an ill-advised decision to set herself up in competition with Wirtz, whose shows now featured the new Olympic champion Barbara Ann Scott. Since Wirtz controlled the best arenas and dates, Henie was left playing smaller venues and markets already saturated by other touring ice shows such as Ice Capades. The collapse of a section of bleachers during a show in Baltimore, Maryland, in 1952 compounded the tour's legal and financial woes.\nIn 1953, Henie formed a new partnership with Morris Chalfen to appear in his European \"Holiday On Ice\" tour, which proved to be a great success. She produced her own show at New York's Roxy Theatre in January 1956. However, a subsequent South American tour in 1956 was a disaster. Henie was drinking heavily at that time and could no longer keep up with the demands of touring, and this marked her retirement from skating.\nShe did try to make a film series at her own expense; a series that would serve as a travelogue to several cities. Paris and London were mentioned, but only \"Hello London\" (1958) was made with her own backing, co-starring Michael Wilding and special guest star Stanley Holloway. While her ice show numbers were still worth watching, the film received few distributors and poor reviews, ending her film career.\nHer autobiography \"Mitt livs eventyr\" was published in 1938. An English translation, \"Wings on My Feet\", was released in 1940 and republished in a revised edition in 1954. At the time of her death, the 57-year-old Henie was planning a comeback for a television special that would have aired in January 1970. She was to have danced to \"Lara's Theme\" from \"Doctor Zhivago\".\nAs international celebrity.\nHenie's connections with Adolf Hitler and other high-ranking Nazi officials made her the subject of controversy before, during, and after World War II. During her amateur skating career, she performed often in Germany and was a favorite of German audiences and of Hitler personally. As a wealthy celebrity, she moved in the same social circles as royalty and heads of state and made Hitler's acquaintance as a matter of course.\nThrough the years, her shows and later art exhibitions drew the attention of such people as Princess Margaret, Countess of Snowdon and Gustaf VI Adolf of Sweden and she met with them. During the shooting of \"Second Fiddle\" (1939), she greeted the then Crown-Prince couple of Norway Olav and M\u00e4rtha during their US tour.\nControversy appeared first when Henie greeted Hitler with a Nazi salute at the 1936 Winter Olympics in Garmisch-Partenkirchen and after the Games she accepted an invitation to lunch with Hitler at his resort home in Berchtesgaden in far southeastern Bavaria, where Hitler presented Henie with an autographed photo with a lengthy inscription. She was strongly denounced in the Norwegian press for this.\nIn her revised 1954 biography, she states that no Norwegian judge was in the panel for the 1936 Olympics\u2014as she was entitled to as a Norwegian. She therefore made the best of it and won her third Olympic medal. When she\u2014as a gold medal winner\u2014passed Hitler's tribune with silver medalist Cecilia Colledge and bronze medalist Vivi-Anne Hult\u00e9n, neither she nor the others honored Hitler with the Nazi salute. The 1936 European Figure Skating Championships also took place in Berlin and neither Henie, Colledge, nor Megan Taylor paid obeisance to Hitler.\nInfluence.\nHenie is credited with being the first figure skater to use dance choreography, to adopt the short skirt in figure skating, and to wear white boots, which deemphasized the heaviness of skates and produced a lighter and longer appearance of the skater's legs that was \"a focal point for judges' and spectators' gaze\". When white boots quickly became standard for female skaters, Henie began wearing beige boots because she wanted to remain unique.\nHer innovative skating techniques and glamorous demeanor transformed the sport permanently and confirmed its acceptance as a legitimate sport in the Winter Olympics. Figure skating writer and historian Ellyn Kestnbaum credits Henie with transforming figure skating into what she calls \"a spectacle of the skater's body\" and for \"shifting [the sport's] meanings firmly in the direction of femininity\". Kestnbaum argues that Henie influenced female skaters' costumes that emphasized their wealth, especially her fur-trimmed outfits, which were emulated at the 1930 World Championships, held for the first time in North America, in New York City. Henie incorporated dance elements into her figure skating, through the placement of spins, jumps, and choreography to reflect the mood of the music she used.\nKestnbaum argues that although Henie's skating was \"athletic and powerful for her day\", she added elements,such as using the toepicks of her skates to run or pose on the ice, in movements similar to the use of pointe technique in ballet. Kestnbaum argues that although toe steps are used as \"occasional couterpoints to the legato flow of skating movement\", Henie might have overused them, calling them \"mincing and ineffective\".\nAlso according to Kestnbaum, \"Henie's largest contribution to public images of skating\" was in her professional ice shows and in her Hollywood films, which were often the first time audiences were exposed to figure skating through the mass media. As a result, the image of the figure skater was linked to \"the image of the glamorous movie star\", within the conventions of film and stage musicals of the 1930s. Kestnbaum argues that the costumes Henie wore in her shows and films, which were short, revealing, full of sequins and feathers, and more reminiscent of the costumes of female entertainers than of the clothes worn in the more conservative world of competitive figure skating of the time, most likely contributed to the \"showiness\" that influenced the costume choices of later generations of female competitive figure skaters.\nPersonal life.\nHenie was married three times: to Dan Topping (1940\u20131946), Winthrop Gardiner Jr. (1949\u20131956), and Niels Onstad (1956\u20131969), a Norwegian shipping magnate and art patron. After her retirement in 1956, Henie and Onstad settled in Oslo and accumulated a large collection of modern art that formed the basis for the Henie Onstad Art Centre at H\u00f8vikodden in B\u00e6rum near Oslo.\nShe studied in Oslo together with Martin Stixrud and Erna Andersen who was her competitor and skate club member.\nHenie was diagnosed with chronic lymphocytic leukemia in the mid-1960s. She died of the disease at age 57 in 1969 in an ambulance plane flight from Paris to Oslo. She is buried with Onstad in Oslo on the hilltop overlooking the Henie Onstad Art Centre.\nIn popular culture.\nHenie was portrayed by Ine Marie Wilmann in the 2018 Anne Sewitsky film \"Sonja \u2013 The White Swan\", shown at the 2019 Sundance Film Festival.\nHer name and likeness were mentioned and portrayed by an ice skating Donald Duck in Walt Disney's 1939 \"The Hockey Champ\".\nHer name and appearance was shown in episode 285 of MASH 4077.\nHer animated counterpart appeared in the Disney short, \"The Autograph Hound\" when Donald asked for her autograph.\nShe is mentioned by Ty Webb, Chevy Chase's character in \"Caddyshack\", as a possible but unavailable substitute for Rodney Dangerfield's character (Al Czervik) in the final \u201cgolf wager\u201d round before Michael O\u2019Keefe's Danny Noonan is chosen.\n\"Sonja Henie's tutu!\" was a frequent exclamatory utterance by Tom and Ray Magliozzi on the National Public Radio show Car Talk.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29493", "revid": "24198", "url": "https://en.wikipedia.org/wiki?curid=29493", "title": "Science &amp; Environmental Policy Project", "text": "Advocacy group\nThe Science &amp; Environmental Policy Project (SEPP) is an advocacy group financed by private contributions based in Arlington County, Virginia. It was founded in 1990 by atmospheric physicist S. Fred Singer.\nSEPP disputes the prevailing scientific views on several scientific issues including climate change, ozone depletion, and the health risks of secondhand smoke.\nSEPP's former chairman of the Board of Directors is listed as Rockefeller University president emeritus Frederick Seitz, a former president of the National Academy of Sciences, now deceased.\nSEPP's views.\nSEPP listed the following key issues in 2010: https://\nOn September 2, 1997, Singer said that \"The possibility that global temperatures could rise because of an increase in carbon dioxide in the atmosphere is a concern that needs to be monitored...But there has been no indication in the last century that we've seen anything other than natural climate fluctuations. Both greenhouse theory and computer models predict that global warming should be more rapid in the polar regions than anywhere else,\" he says, \"but in July the Antarctic experienced the coldest weather on record.\"https://\nSEPP was the author of the Leipzig Declaration, which was based on the conclusions drawn from a November 1995 conference in Leipzig, Germany, which SEPP organized with the European Academy for Environmental Affairs.\nNIPCC.\nIn 2008, The Science and Environmental Policy Project completed the organization of the Nongovernmental International Panel on Climate Change (NIPCC) as the culmination of a process that began in 2003. The NIPCC calls itself \"an international coalition of scientists convened to provide an independent examination of the evidence available on the causes and consequences of climate change in the published, peer-reviewed literature \u2013 examined without bias and selectivity.\"\nThe 2008 NIPCC document titled \"Nature, Not Human Activity Rules the Climate: Summary for Policymakers of the Report of the Nongovernmental International Panel of Climate Change\", published by The Heartland Institute, was released in February\u2013March 2008. Singer served as General Editor and also holds the copyright.\nUnnamed climate scientists from NASA, Stanford University and Princeton who were contacted by ABC News dismissed the same report as \"fabricated nonsense.\". In response, Singer objected to the ABC News piece, calling it \"an appalling display of bias, unfairness, journalistic misbehavior, and a breakdown of ethical standards\" which used \"prejudicial language, distorted facts, libelous insinuations, and anonymous smears.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\nIn 2004 Singer was coauthor of two papers published in Geophysical Research Letters:\nScientific criticism of SEPP's views:"}
{"id": "29494", "revid": "11096", "url": "https://en.wikipedia.org/wiki?curid=29494", "title": "Abbey of Saint Gall", "text": "The Abbey of Saint Gall () is a dissolved abbey (747\u20131805) in a Catholic religious complex in the city of St. Gallen in Switzerland. The Carolingian-era monastery existed from 719, founded by Saint Othmar on the spot where Saint Gall had erected his hermitage. It became an independent principality between 9th and 13th centuries, and was for many centuries one of the chief Benedictine abbeys in Europe. The library of the Abbey is one of the oldest monastic libraries in the world.\nThe city of St. Gallen originated as an adjoining settlement of the abbey. The abbey was secularized around 1800, and in 1848 its former church became St. Gallen Cathedral, the seat of the Diocese of Saint Gallen. Since 1983 the abbey precinct has been a UNESCO World Heritage Site.\nHistory.\nFoundation.\nAround 612 Gallus, according to tradition an Irish monk and disciple and companion of Saint Columbanus, established a hermitage on the site that would become the monastery. He lived in his cell until his death in 646, and was buried there in Arbon (Canton of Thurgau). Afterwards, the people venerated him as a saint and prayed at his tomb for his intercession in times of danger.\nFollowing Gallus' death, his disciples remained living together in his cell and followed the rule of St. Columban, which combined prayer, work of the hands, reading, and teaching. They aided and taught virtue to the many pilgrims who came to St. Gall's tomb. St. Magnus was the first successor of St. Gallen, but he soon left on a mission to Allg\u00e4u, Swabia. His successors were the deacon Stephen and the priest Magulfe, under whom the news of St. Gallen's miracles spread throughout most of Germany.\nSeveral different dates are given for the foundation of the monastery, including 719, 720, 747 and the middle of the 8th century. A gentleman and judge of Thurgau, Waltraf (possibly, Waltram or Gaudran), in order to use the alms and collections that were being given at St. Gall's tomb to found a more regular monastery, attracted a local Alemannic pastor Otmar. Waltraf went to see Charles Martel, gave him the property of the hermitage, and asked him to give the administration of it to Otmar. Charles agreed and sent Otmar the finances to build a monastery. After the death of Charles Martel, his son Pepin continued to support them. On the recommendation of his brother Carloman, who had visited this monastery on his way to Italy, Pepin gave the monastery privileges, letters of protection, and an assured income. Pepin placed the rule of St. Benedict in the hands of St. Otmar (to be substituted for that of St. Columban).\nOtmar (or Othmar) is named as the founder and the first abbot of the Abbey of St. Gall. During his abbacy the St. Gall School was founded. Otmar extended St. Gall's original hermit cell and adopted the Carolingian style for his building projects. The abbey grew quickly; many Alemannic noblemen entered to become monks and arts, letters and sciences flourished. The register of monastic professions, at the end of abbot Otmar's rule makes mentions of 53 names. Two monks of the Abbey of St Gall, Magnus of F\u00fcssen and Theodor, founded the monasteries in Kempten and F\u00fcssen in the Allg\u00e4u. With the growth in the number of monks the abbey also grew economically stronger. Much land in Thurgau, Z\u00fcrichgau and in the rest of Alemannia as far as the Neckar was donated to the abbey by means of \"Stiftungen\". Under abbot Waldo of Reichenau (740\u2013814) copying of manuscripts was undertaken and a famous library was gathered. Numerous Anglo-Saxon and Irish monks came to copy manuscripts. At Charlemagne's request Pope Adrian I sent distinguished cantors from Rome, who instructed the monks in the use of the Gregorian chant. In 744, the Alemannic nobleman Beata sold several properties to the abbey in order to finance his journey to Rome.\nGolden Age.\nIn the subsequent century, St. Gall came into conflict with the nearby Bishopric of Constance which had recently acquired jurisdiction over the Abbey of Reichenau on Lake Constance. It was not until Emperor Louis the Pious (ruled 814\u2013840) confirmed in 813 the imperial immediacy (\"Reichsunmittelbarkeit\") of the abbey, that this conflict ceased. The abbey became an Imperial Abbey (\"Reichsabtei\"). King Louis the German confirmed in 833 the immunity of the abbey and allowed the monks the free choice of their abbot. In 854 finally, the Abbey of St Gall reached its full autonomy by King Louis the German releasing the abbey from the obligation to pay tithes to the Bishop of Constance.\nFrom this time until the 10th century, the abbey flourished. It was home to several famous scholars, including Notker of Li\u00e8ge, Notker the Stammerer, Notker Labeo, Tuotilo and Hartker (who developed the antiphonal liturgical books for the abbey). During the 9th century a new, larger church was built and the library was expanded. Manuscripts on a wide variety of topics were purchased by the abbey and copies were made. Over 400 manuscripts from this time have survived and are still in the library today.\nSilver Age.\nBetween 924 and 933 the Magyars threatened the abbey and the books had to be removed to Reichenau for safety. Not all the books were returned.\nOn 26 April 937 a fire broke out and destroyed much of the abbey and the adjoining settlement, though the library was undamaged. About 954 they started to protect the monastery and buildings by a surrounding wall. Around 971/974 abbot Notker (about whom almost nothing is known; nephew of Notker Physicus) finalized the walling and the adjoining settlements started to become the town of St\u00a0Gall. In 1006, the abbey was the northernmost place where a sighting of the 1006 supernova was recorded.\nThe death of abbot Ulrich II on 9 December 1076 terminated the cultural silver age of the monastery.\nUnder the Prince-Abbots.\nIn 1207, abbot Ulrich von Saxwas raised to the rank of Prince (\"Reichsf\u00fcrst\", or simply \"F\u00fcrst\") of the Holy Roman Empire by King Philip of Germany. The abbey became a Princely Abbey (\"Reichsabtei\"). As the abbey became more involved in local politics, it entered a period of decline. \nThe city of St. Gallen proper progressively freed itself from the rule of the abbot, acquiring Imperial immediacy, and by the late 15th century was recognized as a Free imperial city.\nBy about 1353 the guilds, headed by the cloth-weavers guild, gained control of the civic government. In 1415 the city bought its liberty from the German king King Sigismund.\nDuring the 14th century Humanists were allowed to carry off some of the rare texts from the abbey library.\nIn the late 14th and early 15th centuries, the farmers of the abbot's personal estates (known as \"Appenzell\", from meaning \"cell (i.e. estate) of the abbot\") began seeking independence. In 1401, the first of the Appenzell Wars broke out, and following the Appenzell victory at Stoss in 1405 they became allies of the Swiss Confederation in 1411. During the Appenzell Wars, the town of St.\u00a0Gallen often sided with Appenzell against the abbey. So when Appenzell allied with the Swiss, the town of St.\u00a0Gallen followed just a few months later. The abbot became an ally of several members of the Swiss Confederation (Z\u00fcrich, Lucerne, Schwyz and Glarus) in 1451, while Appenzell and St.\u00a0Gallen became full members of the Swiss Confederation in 1454. Then, in 1457, the town of St.\u00a0Gallen became officially free from the abbot.\nIn 1468 the abbot, Ulrich R\u00f6sch, bought the County of Toggenburg from the representatives of its counts, after the family died out in 1436. In 1487 he built a monastery at Rorschach on Lake Constance, to which he planned to move. However, he encountered stiff resistance from the St.\u00a0Gallen citizenry, other clerics, and the Appenzell nobility in the Rhine Valley who were concerned about their holdings. The town of St.\u00a0Gallen wanted to restrict the increase of power in the abbey and simultaneously increase the power of the town. The mayor of St. Gallen, Ulrich Varnb\u00fcler, established contact with farmers and Appenzell residents (led by the fanatical Hermann Schwendiner) who were seeking an opportunity to weaken the abbot. Initially, he protested to the abbot and the representatives of the four sponsoring Confederate cantons (Z\u00fcrich, Lucerne, Schwyz, and Glarus) against the construction of the new abbey in Rorschach. Then on July 28, 1489, he had armed troops from St.\u00a0Gallen and Appenzell destroy the buildings already under construction. When the abbot complained to the Confederates about the damages and demanded full compensation, Varnb\u00fcler responded with a counter suit and in cooperation with Schwendiner rejected the arbitration efforts of the non-partisan Confederates. He motivated the clerics from Wil to Rorschach to discard their loyalty to the abbey and spoke against the abbey at the town meeting at Waldkirch, where the popular league was formed. He was confident that the four sponsoring cantons would not intervene with force, due to the prevailing tensions between the Confederation and the Swabian League. He was strengthened in his resolve by the fact that the people of St.\u00a0Gallen elected him again to the highest magistrate in 1490.\nAn associate of the Swiss Confederation.\nHowever, in early 1490 the four cantons decided to carry out their duty to the abbey and to invade the St. Gallen canton with an armed force. The people of Appenzell and the local clerics submitted to this force without noteworthy resistance, while the city of St. Gallen braced for a fight to the finish. However, when they learned that their compatriots had given up the fight, they lost confidence; the result was that they concluded a peace pact that greatly restricted the city's powers and burdened the city with serious penalties and reparations payments. Varnb\u00fcler and Schwendiner fled to the court of King Maximilian and lost all their property in St. Gallen and Appenzell. However, the abbot's reliance on the Swiss to support him reduced his position almost to that of a \"subject district\".\nThe town adopted the Reformation in 1524, while the abbey remained Catholic, which damaged relations between the town and abbey. Both the abbot and a representative of the town were admitted to the Swiss Tagsatzung or Diet as the closest associates of the Confederation.\nIn the 16th century the abbey was raided by Calvinist groups, which scattered many of the old books. In 1530, abbot Diethelm began a restoration that stopped the decline and led to an expansion of the schools and library.\nUnder abbot Pius Reher (1630\u201354) a printing press was started. In 1712 during the Toggenburg war, also called the second war of Villmergen, the Abbey of St. Gall was pillaged by the Swiss. They took most of the books and manuscripts to Z\u00fcrich and Bern. For security, the abbey was forced to request the protection of the townspeople of St. Gallen. Until 1457 the townspeople had been serfs of the abbey, but they had grown in power until they were protecting the abbey.\nEnd of the Prince-Abbots.\nFollowing the disturbances, the abbey was still the largest religious city-state in Switzerland, with over 77,000 inhabitants. A final attempt to expand the abbey resulted in the demolition of most of the medieval monastery. The new structures, including the cathedral by architect Peter Thumb (1681\u20131766), were designed in the late Baroque style and constructed between 1755 and 1768. The large and ornate new abbey did not remain a monastery for very long. In 1798 the Prince-Abbot's secular power (the last to hold the title was Pankraz Vorster) was suppressed, and the abbey was secularized. The monks were driven out and moved into other abbeys. The abbey became a separate See in 1846, with the abbey church as its cathedral and a portion of the monastic buildings for the bishop.\nCultural treasures.\nThe Abbey library of Saint Gall is recognized as one of the richest medieval libraries in the world. It is home to one of the most comprehensive collections of early medieval books in the German-speaking part of Europe. As of 2005[ [update]], the library consists of over 160,000 books, of which 2100 are handwritten. Nearly half of the handwritten books are from the Middle Ages and 400 are over 1000 years old. Lately the \"Stiftsbibliothek\" has launched a project for the digitisation of the priceless manuscript collection, which currently (December 2009) contains 355 documents that are available on the \"Codices Electronici Sangallenses\" webpage.\nThe library interior is exquisitely realised in the Rococo style with carved polished wood, stucco and paint used to achieve its overall effect. It was designed by the architect Peter Thumb and is open to the public. In addition it holds exhibitions as well as concerts and other events.\nOne of the more interesting documents in the Stiftsbibliothek is a copy of Priscian's \"Institutiones grammaticae\" which contains the poem \"Is acher in ga\u00edth in-nocht...\" written in Old Irish.\nThe library also preserves a unique 9th-century document, known as the Plan of St. Gall, the only surviving major architectural drawing from the roughly 700-year period between the fall of the Western Roman Empire and the 13th century. The Plan drawn sometime between AD 820\u2013830 AD was never actually built, and was so named because it was dedicated to the then-abbot of Saint Gall and kept at the famous medieval monastery library, where it remains to this day. The plan was an ideal of what a well-designed and well-supplied monastery should have, as envisioned by one of the synods held at Aachen for the reform of monasticism in the Frankish empire during the early years of emperor Louis the Pious (between 814 and 817).\nA late 9th-century drawing of Paul lecturing an agitated crowd of Jews and gentiles, part of a copy of a Pauline epistles produced at and still held by the monastery, was included in a medieval-drawing show at the Metropolitan Museum of Art in New York the summer of 2009. A reviewer noted that the artist had \"a special talent for depicting hair, ... with the saint's beard ending in curling droplets of ink.\"\nSt. Gall is noted for its early use of the neume, the basic element of Western and Eastern systems of musical notation prior to the invention of five-line staff notation. The earliest extant manuscripts are from the 9th or 10th century.\nIn 1983, the Convent of St. Gall was inscribed on the UNESCO World Heritage List as \"a perfect example of a great Carolingian monastery\".\nPeople of the abbey.\nList of abbots.\nThere were a total of 73 ruling abbots (including six anti-abbots) between 719 and 1805.\nA complete collection of abbots' biographies was published \nby Henggeler (1929). A table of abbots' names complete with their coats of arms was printed by Beat Jakob Anton Hiltensperger in 1778.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes and references.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29498", "revid": "33133279", "url": "https://en.wikipedia.org/wiki?curid=29498", "title": "Secondary education", "text": "Education between primary and higher education\nSecondary education or post-primary education covers two phases on the International Standard Classification of Education scale: Level 2 (\"lower secondary education\", less commonly \"junior secondary education\") is the second and final phase of basic education, and Level 3 (\"upper secondary education\" or \"senior secondary education\") is the phase immediately preceding tertiary education. Every country aims to provide basic education, but the systems and terminology remain unique to them. Secondary education typically takes place after six years of primary education and is followed by higher education, vocational education or employment. In most countries secondary education is compulsory, at least until the age of 16. Children typically enter the lower secondary phase around age 12. Compulsory education sometimes extends to age 20 and further.\nSince 1989, education has been seen as a basic human right for a child; Article 28, of the Convention on the Rights of the Child states that primary education should be free and compulsory while different forms of secondary education, including general and vocational education, should be available and accessible to every child. The terminology has proved difficult, and there was no universal definition before ISCED divided the period between primary education and university into junior secondary education and upper secondary education.\nIn classical and medieval times, secondary education was provided by the church for the sons of nobility and to boys preparing for universities and the priesthood. As trade required navigational and scientific skills, the church expanded the curriculum and widened the intake. With the Reformation the state began taking control of learning from the church, and with Comenius and John Locke education changed from being repetition of Latin text to building up knowledge in the child. Education was for the few. Up to the middle of the 19th century, secondary schools were organised to satisfy the needs of different social classes with the labouring classes getting four years, the merchant class five years, and the elite getting seven years. The rights to a secondary education were codified after 1945, and some countries are moving to mandatory and free secondary education for all youth under 19.\nDefinition.\nSecondary education refers to the stage of formal education that follows primary education and precedes higher education. It is typically offered to students between the ages of 12 and 18, although the specific age range may vary depending on the educational system and country. The purpose of secondary education is to provide students with a well-rounded education that prepares them for higher education or the workforce. It aims to develop their intellectual, social, and emotional skills, while also fostering critical thinking, creativity, and independence.\nThe 1997 International Standard Classification of Education (ISCED) describes seven levels that can be used to compare education internationally. Within a country these can be implemented in different ways, with different age levels and local denominations. The seven levels are:\nWithin this system, Levels 1 and 2 \u2013 that is, primary education and lower secondary \u2013 together form basic education. Beyond that, national governments may attach the label of secondary education to Levels 2 through 4 together, Levels 2 and 3 together, or Level 2 alone. These level definitions were put together for statistical purposes, and to allow the gathering of comparative data nationally and internationally. They were approved by the UNESCO General Conference at its 29th session in November 1997. Though they may be dated, they do provide a universal set of definitions and remain unchanged in the 2011 update.\nThe start of lower secondary education is characterised by the transition from the single-class-teacher, who delivers all content to a cohort of pupils, to one where content is delivered by a series of subject specialists. Its educational aim is to complete provision of basic education (thereby completing the delivery of basic skills) and to lay the foundations for lifelong learning.\nLower secondary education is likely to show these criteria:\nThe end of lower secondary education often coincides with the end of compulsory education in countries where that exists.\n(Upper) secondary education starts on the completion of basic education, which also is defined as completion of lower secondary education. The educational focus is varied according to the student's interests and future direction. Education at this level is usually voluntary.\n(Upper) secondary education is likely to show these criteria:\nMore subjects may be dropped, and increased specialism occurs. Completion of (upper) secondary education provides the entry requirements to Level 5 tertiary education, the entry requirements to technical or vocational education (Level 4, non tertiary course), or direct entry into the workplace.\nIn 2012 the ISCED published further work on education levels where it codified particular paths and redefined the tertiary levels. Lower secondary education and (upper) secondary education could last between two and five years, and the transition between two often would be when students were allowed some subject choice.\nTerminology around secondary education systems varies by country. Secondary schools may also be called \"academies\", \"colleges\", \"gymnasiums\", \"high schools\", \"lyceums\", \"middle schools\", \"preparatory schools\", \"sixth-form colleges\", \"upper schools\", or \"vocational schools\", among other names. For further information about these terms and their definitions, see the section below, organized by country.\nHistory.\nA form of education for adolescents became necessary in all societies that had an alphabet and engaged in commerce. In Western Europe, formal secondary education can be traced back to the Athenian educational reforms of 320BC. Though their civilisation was eclipsed and they were enslaved, Hellenistic Athenian teachers were valued in the Roman system. The Roman and Hellenistic schools of rhetoric taught the seven liberal arts and sciences \u2013 \"grammar, rhetoric, logic, arithmetic, geometry, music\" and \"astronomy\" \u2013 which were regarded as a preparation for the study at a tertiary level of theology, law and medicine. Boys would have been prepared to enter these schools by private tutors at home. Girls would have only received tuition at home.\nEngland provides a good case study. When Augustine of Canterbury brought Christianity there in 597, no schools existed. He needed trained priests to conduct church services and boys to sing in the choir. He had to create both the grammar schools that taught Latin, to enable the English to study for the priesthood, and song schools (choir schools) that trained the 'sons of gentlefolk' to sing in cathedral choirs. In the case of Canterbury (597) and Rochester (604), both still exist. Bede in his \"Ecclesiastical History of the English People\" (732) tells that the Canterbury school taught more than the 'intended reading and understanding of Latin', but 'the rules of metric, astronomy and the computus as well as the works of the saints' Even at this stage, there was tension, as the church was worried that knowledge of Latin would give the student access to non-Christian texts that it would not wish them to read.\nOver the centuries leading to the renaissance and reformation the church was the main provider of secondary education. Various invasions and schisms within the controlling church challenged the focus of the schools, and the curriculum and language of instruction waxed and waned. From 1100, With the growth of the towns, grammar schools 'free' of the church were founded, and some church grammar schools were handed over to the la\u00efty. Universities were founded that did not just train students for the priesthood.\nRenaissance and Reformation.\nWhereas in mainland Europe the Renaissance preceded the Reformation, local conditions in England caused the Reformation to come first. The Reformation was about, among other things, allowing the la\u00efty to interpret the Bible in their own way without the intervention of priests, and preferably in the vernacular. This stimulated the foundation of free grammar schools - who searched for a less constrained curriculum. Colonialisation required navigation, mensuration, languages and administrative skills. The la\u00efty wanted these taught to their sons. After Gutenberg in 1455 had mastered moveable metal type printing and Tyndale had translated the Bible into English (1525), Latin became a skill reserved for the catholic church and sons of conservative nobility. Schools started to be set up for the sons of merchants in Europe and the colonies too- for example Boston Latin Grammar School (1635).\nComenius (1592\u20131670), a Moravian protestant proposed a new model of education- where ideas were developed from the familiar to the theoretical rather than through repetition, where languages were taught in the vernacular and supported universal education. In his \"Didactica Magna\" (Great Didactic), he outlined a system of schools that is the exact counterpart of many western school systems: kindergarten, elementary school, secondary school, six-form college, university.\nLocke's \"Some Thoughts Concerning Education\" (1693) stressed the importance of a broader intellectual training, moral development and physical hardening. \nThe grammar schools of the period can be categorised in three groups: the nine leading schools, seven of them boarding institutions which maintained the traditional curriculum of the classics, and mostly served 'the aristocracy and the squirearchy'; most of the old endowed grammar schools serving a broad social base in their immediate localities which also stuck to the old curriculum; the grammar schools situated in the larger cities, serving the families of merchants and tradesmen who embraced change.\nIndustrialisation.\nDuring the 18th century their social base widened and their curriculum developed, particularly in mathematics and the natural sciences. But this was not universal education and was self-selecting by wealth. The industrial revolution changed that. Industry required an educated workforce where all workers needed to have completed a basic education. In France, Louis XIV, wrestled the control of education from the Jesuits, Condorcet set up Coll\u00e8ges for universal lower secondary education throughout the country, then Napoleon set up a regulated system of Lycee. In England, Robert Peel's Factory Act 1802 required an employer to provide instruction in reading, writing and arithmetic during at least the first four years of the seven years of apprenticeship. The state had accepted responsibility for the basic education of the poor.\nThe provision of school places remained inadequate, so an Order in Council dated 10 April 1839 created the Committee of the Privy Council on Education.\nUniversal education.\nThere was considerable opposition to the idea that children of all classes should receive basic education, all the initiatives such as industrial schools and Sunday schools were initially a private or church initiative. With the Great Exhibition of 1851, it became clear just how far behind the English education system had fallen.\nThree reports were commissioned to examine the education of upper, middle and labouring class children. The Clarendon Commission sought to improve the nine Great Public Schools. The Taunton Commission looked at the 782 endowed grammar schools (private and public). They found varying quality and a patchy geographical coverage, with two thirds of all towns not having any secondary school. There was no clear conception of the purpose of secondary education. There were only thirteen girls' schools and their tuition was superficial, unorganised and unscientific. They recommended a system of first-grade schools targeted at a leaving age of 18 as preparation for upper and upper-middle-class boys entering university, second-grade targeted at a leaving age of 16 for boys preparing for the army or the newer professions, and third-grade targeted at a leaving age of 14 for boys of small tenant farmers, small tradesmen, and superior artisans. This resulted in the Endowed Schools Act 1869 which advocated that girls should enjoy the same education as boys.\nThe Newcastle Commission inquired \"into the state of public education in England and to consider and report what measures, if any, are required for the extension of sound and cheap elementary instruction to all classes of the people\". It produced 1861 Newcastle Report and this led to the Elementary Education Act 1870 (33 &amp; 34 Vict. c. 75) (Forster Act).\nThe school boards set up by the Elementary Education Act 1870 were stopped from providing secondary education by the Cockerton Judgement of 1899. The school leaving age at this time was 10. The Judgement prompted the Education Act 1902 (Balfour Act). Compulsory education was extended to 12. The new local education authorities (LEA)s that were formed from the school boards; started to open higher grade elementary schools (ISCED Level2) or county schools to supplement the endowed grammar schools. These LEAs were allowed to build second-grade secondary schools that in the main became the future secondary modern schools.\nIn the \"1904 Regulations for Secondary Schools\", the Board of Education determined that secondary schools should offer :\na four year subject-based course leading to a certificate in English language and literature, geography, history, a foreign language, mathematics, science, drawing, manual work, physical training, and, for girls, housewifery.\nThe Education Act 1918 (Fisher Act) extended compulsory full-time education to 14, and recommended compulsory part-time education from 14 to 18.\nThe Hadlow report, \"Education the Adolescent\" (1926) proposed that there should be a break point at eleven, establishing primary schools and secondary schools.\nThe United Nations, founded in 1947, was committed to education for all but the definition was difficult to formulate.\nThe Universal Declaration of Human Rights (1948) declared that elementary and fundamental education, which it did not define, was a right to be enjoyed by all. The Education Act 1944 (Butler Act) made sweeping changes to the funding of state education using the tripartite system, but was not allowed to tackle private schools. It introduced the GCE 'O'level at 16, and the 'A' at 18, but only raised the school leaving age until 15, making the exam inaccessible to the majority. But one year of ISCED Level 3 (Upper) secondary education was mandatory and free.\nIn 1972 the school leaving was raised to 16. The Education and Skills Act 2008, when it came into force in the 2013 academic year, initially required participation in some form of education or training until the school year in which the child turned 17, followed by the age being raised to the young person's 18th birthday in 2015. This was referred to as raising the \"participation age\" to distinguish it from the school leaving age which remains at 16. Thus the UK is following the ISCED Level 3 (Upper) secondary education guideline.\nRight to a secondary education.\nThe United Nations was strong in its commitment to education for all but fell into linguistic difficulty defining that right.\n\"Article I: Purposes and functions\n1. The purpose of the Organization is to contribute to peace and security by promoting collaboration among the nations through education, science and culture in order to further universal respect for justice, for the rule of law and for the human rights and fundamental freedoms which are affirmed for the peoples of the world, without distinction of race, sex, language or religion, by the Charter of the United Nations.\"\nThe Universal Declaration of Human Rights (1948) declared that elementary and fundamental education was a right to be enjoyed by all, but again could not define either elementary and fundamental education.\nArticle 26 :(1) Everyone has the right to education. Education shall be free, at least in the elementary and fundamental stages. Elementary education shall be compulsory. Technical and professional education shall be made generally available and higher education shall be equally accessible to all on the basis of merit.\nIt was assumed that elementary education was basic education\u2014the entitlement for children\u2014and fundamental education was a right for working people, but for a lawyer the definition is neither qualitative (stating what education means) or quantitative saying when it starts and when it is completed. The term secondary is not defined or mentioned. Together this has enabled countries to terminate free, compulsory, basic education at 11 or only continue education past eleven to boys.\nArticle 28, of the Convention on the Rights of the Child (1989) stated that primary education should be free and compulsory while different forms of secondary education, including general and vocational education, should be available and accessible to every\nchild. Free education should be provided and financial assistance offered in case of need.\nIn 1990, at Jomtien again tried to define the content basic education and how it should be delivered. 'Basic education' is defined as 'action designed to meet 'basic learning needs'. 'primary schooling' is considered as 'the main delivery system of basic education'.\n Which is explained in Principals for Action that:\naddressing the basic learning needs of all means: early childhood care and development opportunities; relevant, quality primary schooling or equivalent out-of-school education for children; and literacy, basic knowledge and life skills training for youth and adults.'\nThe assumption being made that basic knowledge and life skills training for youth was the function of secondary education. This was codified by the ISCED documents. The Dakar Framework for Action 2010 goal 2 states: Ensuring that by 2015 all children, particularly girls, children in difficult circumstances and those belonging to ethnic minorities, have access to and complete free and compulsory (primary in the sense basic) education of good quality. The Dakar Framework for Action 2010 goal 5 states: Eliminating gender disparities in primary and secondary education by 2005, and achieving gender equality in education by 2015, with a focus on ensuring girls' full and equal access to and achievement in basic education of good quality.\nIn 1996, the Council of Europe adopted the Revised European Social Charter, which guarantees secondary education.\nMalala Yousafzai, Nobel Peace Prize winner in a said in a 2017 interview that:\n\"My goal is to make sure every child, girl and boy, they get the opportunity to go to school.\" \"It is their basic human right, so I will be working on that and I will never stop until I see the last child going to school.\"\nIn 2017, Human Rights Watch adopted a policy calling on states to take immediate measures to ensure that secondary education is accessible to all free of charge, and compulsory through the end of lower-secondary school. This was a call for secondary education to be included as part of the minimum core of the right to education, and seen as an immediate obligation.\nFuture directions for secondary education.\nUNESCO believes that in order to prepare young people for life and work in a rapidly changing world, secondary-level education systems need to be re-oriented to impart a broad repertoire of life-skills. These skills should include the key generic competencies, non occupation-specific practical capabilities, information and communications technology, the ability to learn independently, to work in teams, entrepreneurship and civic responsibility.\nThey may be best instilled through a shared foundational learning period and by deferring the directing of students into academic and vocational streams for as long as possible, and then there should be flexibility to ensure the free movement of students between the streams depending on their aptitudes and inclinations. Accreditation in one stream should have equal recognition in the other as well as for access to higher education. This will equip young people with multiple skills so that they are prepared to enter and re-enter the workforce several times in their working lives, as wage employees or self-employed entrepreneurs, and to re-train themselves when their skills become obsolete.\nIt recognizes that there is no single model that will suit all countries, or even all communities in a given country. Secondary-level education policy should be under continuous review to keep in step with scientific and technological, economic and societal change.\nPromoting the Rule of Law.\nAdolescence is associated with a time of significant growth where identity, belongingness, and socialization, especially among peer groups is particularly important. Secondary schools play an important role in youth's socialization, development and forming their ideas and approach to justice, democracy and human rights.\nEducation systems that promote education for justice, that is, respect for the rule of law (RoL) together with international human rights and fundamental freedoms strengthen the relationship between learners and public institutions with the objective of empowering young people to become champions of peace and justice. Teachers are on the front line of this work and, along with families, play a formative role in shaping the future of youth's attitudes and behaviours.\nCareer and Life Planning Education.\nCareer and Life Planning Education (CLPE) activities as well as (Career) Development Education take place at secondary schools in Hong Kong. Students' transition from study to work is important in Hong Kong and career education in senior secondary schooling in this country is hence provided. Job shadowing is not yet done in their secondary schools however.\nBy country.\nEach country has developed the form of education most appropriate for them. There is an attempt to compare the effectiveness by using the results from the PISA that, each third year, assesses the scholastic performance on mathematics, science, and reading of a representative sample of 5000 fifteen year olds from each country.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29500", "revid": "31235887", "url": "https://en.wikipedia.org/wiki?curid=29500", "title": "Serotonin syndrome", "text": "Symptoms caused by an excess of serotonin in the central nervous system\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nSerotonin syndrome (SS) consists of a group of symptoms that may occur with the use of certain serotonergic medications or drugs. The symptoms can range from mild to severe, and are potentially fatal. Symptoms in mild cases include high blood pressure and a fast heart rate, usually without a fever. Symptoms in moderate cases include high body temperature, agitation, increased reflexes, tremor, sweating, dilated pupils, and diarrhea. In severe cases, body temperature can increase to greater than . Complications may include seizures and extensive muscle breakdown.\nSerotonin syndrome is typically caused by the use of two or more serotonergic medications or drugs. These may include selective serotonin reuptake inhibitors (SSRIs), serotonin norepinephrine reuptake inhibitors (SNRIs), monoamine oxidase inhibitors (MAOIs), tricyclic antidepressants (TCAs), amphetamines, pethidine (meperidine), tramadol, dextromethorphan, buspirone, L-tryptophan, 5-hydroxytryptophan, St.\u00a0John's wort, triptans, MDMA, metoclopramide, or cocaine. It occurs in about 15% of SSRI overdoses. It is a predictable consequence of excess serotonin on the central nervous system. Onset of symptoms is typically within a day of the extra serotonin.\nDiagnosis is based on a person's symptoms and history of medication use. Other conditions that can produce similar symptoms such as neuroleptic malignant syndrome, malignant hyperthermia, anticholinergic toxicity, heat stroke, and meningitis should be ruled out. As of 2013, no laboratory tests exist that can confirm the diagnosis.\nInitial treatment consists of discontinuing medications which may be contributing. In those who are agitated, benzodiazepines may be used. If this is not sufficient, a serotonin antagonist such as cyproheptadine may be used. In those with a high body temperature, active cooling measures may be needed. The number of cases of serotonin syndrome that occur each year is unclear. With appropriate medical intervention the risk of death is low, likely less than 1%. The high-profile case of Libby Zion, who is generally accepted to have died from serotonin syndrome, resulted in changes to graduate medical school education in New York State.\nSigns and symptoms.\nSymptom onset is usually relatively rapid, and serotonin syndrome encompasses a wide range of clinical findings. Mild symptoms may consist of increased heart rate, shivering, sweating, dilated pupils, and myoclonus (intermittent jerking or twitching), as well as hyperreflexia (overresponsive reflexes). Many of these symptoms may be side effects of the drug or drug interaction causing excessive levels of serotonin rather than an effect of elevated serotonin itself.\nTremor is a common side effect of MDMA's action on dopamine, whereas hyperreflexia is symptomatic of exposure to serotonin agonists. Moderate intoxication includes additional abnormalities such as hyperactive bowel sounds, high blood pressure and hyperthermia; a temperature as high as . The overactive reflexes and clonus in moderate cases may be greater in the lower limbs than in the upper limbs. Mental changes include hypervigilance or insomnia and agitation. Severe symptoms include severe increases in heart rate and blood pressure. Temperature may rise to above in life-threatening cases. Other abnormalities include metabolic acidosis, rhabdomyolysis, seizures, kidney failure, and disseminated intravascular coagulation; these effects usually arising as a consequence of hyperthermia.\nThe symptoms are often present as a clinical triad of abnormalities and can be used to assess the severity of serotonin syndrome:\nCauses.\nNumerous medications and street drugs can cause serotonin syndrome when taken alone at high doses or in combination with other serotonergic agents. The table below lists some of these.\nMany cases of serotonin toxicity occur in people who have ingested drug combinations that synergistically increase synaptic serotonin. It may also occur due to an overdose of a single serotonergic agent. The combination of monoamine oxidase inhibitors (MAOIs) with precursors such as L-tryptophan or 5-hydroxytryptophan pose a particularly acute risk of life-threatening serotonin syndrome. The case of combination of MAOIs with tryptamine agonists (commonly known as ayahuasca) can present similar dangers as their combination with precursors, but this phenomenon has been described in general terms as the cheese effect. Many MAOIs irreversibly inhibit monoamine oxidase. It can take at least four weeks for this enzyme to be replaced by the body in the instance of irreversible inhibitors. With respect to tricyclic antidepressants (TCAs), only clomipramine and imipramine have a risk of causing serotonin syndrome.\nMany medications may have been incorrectly thought to cause serotonin syndrome. For example, some case reports have implicated atypical antipsychotics in serotonin syndrome, but it appears based on their pharmacology that they are unlikely to cause the syndrome. It has also been suggested that mirtazapine has no significant serotonergic effects and is therefore not a dual action drug. Bupropion has also been suggested to cause serotonin syndrome, although as there is no evidence that it has any significant serotonergic activity, it is thought unlikely to produce the syndrome. In 2006 the US Food and Drug Administration (FDA) issued an alert suggesting that the combined use of either SSRIs or SNRIs with triptan medications or sibutramine could potentially lead to severe cases of serotonin syndrome. This has been disputed by other researchers, as none of the cases reported by the FDA met the Hunter criteria for serotonin syndrome. The condition has however occurred in surprising clinical situations, and because of phenotypic variations among individuals, it has been associated with unexpected drugs, including mirtazapine.\nDespite acting as non-selective serotonin receptor agonists, major serotonergic psychedelics like lysergic acid diethylamide (LSD) and psilocybin do not cause serotonin syndrome even in the context of extreme overdose. This is thought to be due to the fact that they act as partial agonists of serotonin receptors like the serotonin 5-HT2A receptor, in contrast to serotonin itself which is a full agonist. Combination of psychedelics like LSD and psilocybin with antidepressants such as SSRIs is also not thought to pose a risk of serotonin syndrome. A 2018 retrospective analysis of 3,554 LSD-only exposures reported to poison control centers in the United States between 2000 and 2016 found that serious toxicity was infrequent. On the other hand, NBOMe psychedelics like 25I-NBOMe are more efficacious at the serotonin 5-HT2A receptor and have been uniquely associated with serotonin syndrome-like toxicity. In addition, serotonergic psychedelics additionally acting as serotonin releasing agents like methylenedioxyamphetamine (MDA) and \u03b1-methyltryptamine (AMT) or additionally acting as MAOIs like ayahuasca or AMT can cause serotonin syndrome.\nThe relative risk and severity of serotonergic side effects and serotonin toxicity, with individual drugs and combinations, is complex. Serotonin syndrome has been reported in patients of all ages, including the elderly, children, and even newborn infants due to in utero exposure. The serotonergic toxicity of SSRIs increases with dose, but even in overdose, it is insufficient to cause fatalities from serotonin syndrome in healthy adults. Elevations of central nervous system (CNS) serotonin will typically only reach potentially fatal levels when drugs with different mechanisms of action are mixed together. Various drugs, other than SSRIs, also have clinically significant potency as serotonin reuptake inhibitors, (such as tramadol, amphetamine, and MDMA) and are associated with severe cases of the syndrome. Severe and life-threatening serotonin syndrome has been said to almost exclusively be due to a combination of antidepressants, for instance an MAOI with an SSRI. However, combination of an MAOI and a serotonin releasing agent (SRA) like MDMA can also consistently result in severe and life-threatening serotonin syndrome.\nAlthough the most significant health risk associated with opioid overdoses is respiratory depression, it is still possible for an individual to develop serotonin syndrome from certain opioids without the loss of consciousness. However, most cases of opioid-related serotonin syndrome involve the concurrent use of a serotergenic drug such as antidepressants. Nonetheless, it is not uncommon for individuals taking opioids to also be taking antidepressants due to the comorbidity of pain and depression. Cases where opioids alone are the cause of serotonin syndrome are typically seen with tramadol, because of its dual mechanism as a serotonin-norepinephrine reuptake inhibitor. Serotonin syndrome caused by tramadol can be particularly problematic if an individual taking the drug is unaware of the risks associated with it and attempts to self-medicate symptoms such as headache, agitation, and tremors with more opioids, further exacerbating the condition.\nPathophysiology.\nSerotonin is a neurotransmitter involved in multiple complex biological processes including aggression, pain, sleep, appetite, anxiety, depression, migraine, and vomiting. In humans the effects of excess serotonin were first noted in 1960 in patients receiving an MAOI and tryptophan. The syndrome is caused by increased serotonin in the CNS. It was originally suspected that agonism of serotonin 5-HT1A receptors in central grey nuclei and the medulla oblongata was responsible for the development of the syndrome. Further study has determined that overstimulation of primarily the serotonin 5-HT2A receptors appears to contribute substantially to the condition, while the serotonin 5-HT1A receptor seems to play little role. However, the serotonin 5-HT1A receptor may still contribute through a pharmacodynamic interaction in which increased synaptic concentrations of a serotonin agonist saturate all receptor subtypes. Additionally, noradrenergic CNS hyperactivity may play a role as CNS norepinephrine concentrations are increased in serotonin syndrome and levels appear to correlate with the clinical outcome. Other neurotransmitters may also play a role; NMDA receptor antagonists and \u03b3-aminobutyric acid have been suggested as affecting the development of the syndrome. Serotonin toxicity is more pronounced following supra-therapeutic doses and overdoses, and they merge in a continuum with the toxic effects of overdose.\nSpectrum concept.\nA postulated \"spectrum concept\" of serotonin toxicity emphasises the role that progressively increasing serotonin levels play in mediating the clinical picture as side effects merge into toxicity. The dose-response relationship is the effect of progressive elevation of serotonin, either by raising the dose of one drug, or combining it with another serotonergic drug which may produce large elevations in serotonin levels. Some experts prefer the terms serotonin toxicity or serotonin toxidrome, to more accurately reflect that it is a form of poisoning.\nDiagnosis.\nThere is no specific test for serotonin syndrome. Diagnosis is by symptom observation and investigation of the person's history. Several criteria have been proposed. The first evaluated criteria were introduced in 1991 by Harvey Sternbach. Researchers later developed the Hunter Toxicity Criteria Decision Rules, which have better sensitivity and specificity, 84% and 97%, respectively, when compared with the gold standard of diagnosis by a medical toxicologist. As of 2007, Sternbach's criteria were still the most commonly used.\nThe most important symptoms for diagnosing serotonin syndrome are tremor, extreme aggressiveness, akathisia, or clonus (spontaneous, inducible and ocular). Physical examination of the patient should include assessment of deep tendon reflexes and muscle rigidity, the dryness of the mucosa of the mouth, the size and reactivity of the pupils, the intensity of bowel sounds, skin color, and the presence or absence of sweating. The patient's history also plays an important role in diagnosis, investigations should include inquiries about the use of prescription and over-the-counter drugs, illicit substances, and dietary supplements, as all these agents have been implicated in the development of serotonin syndrome. To fulfill the Hunter Criteria, a patient must have taken a serotonergic agent and meet one of the following conditions:\nDifferential diagnosis.\nSerotonin toxicity has a characteristic picture which is generally hard to confuse with other medical conditions, but in some situations it may go unrecognized because it may be mistaken for a viral illness, anxiety disorders, neurological disorder, anticholinergic poisoning, sympathomimetic toxicity, or worsening psychiatric condition. The condition most often confused with serotonin syndrome is neuroleptic malignant syndrome (NMS). The clinical features of neuroleptic malignant syndrome and serotonin syndrome share some features which can make differentiating them difficult. In both conditions, autonomic dysfunction and altered mental status develop. However, they are actually very different conditions with different underlying dysfunction (serotonin excess vs dopamine blockade). Both the time course and the clinical features of NMS differ significantly from those of serotonin toxicity. Serotonin toxicity has a rapid onset after the administration of a serotonergic drug and responds to serotonin blockade such as drugs like chlorpromazine and cyproheptadine. Dopamine receptor blockade (NMS) has a slow onset, typically evolves over several days after administration of a neuroleptic drug, and responds to dopamine agonists such as bromocriptine.\nDifferential diagnosis may become difficult in patients recently exposed to both serotonergic and neuroleptic drugs. Bradykinesia and extrapyramidal \"lead pipe\" rigidity are classically present in NMS, whereas serotonin syndrome causes hyperkinesia and clonus; these distinct symptoms can aid in differentiation.\nManagement.\nManagement is based primarily on stopping the usage of the precipitating drugs, the administration of serotonin antagonists such as cyproheptadine (with a regimen of 12\u00a0mg for the initial dose followed by 2\u00a0mg every 2\u2009hours until clinical, while some claim that a higher initial dose up to 32\u00a0mg has more benefit), and supportive care including the control of agitation, the control of autonomic instability, and the control of hyperthermia. Additionally, those who ingest large doses of serotonergic agents may benefit from gastrointestinal decontamination with activated charcoal if it can be administered within an hour of overdose. The intensity of therapy depends on the severity of symptoms. If the symptoms are mild, treatment may only consist of discontinuation of the offending medication or medications, offering supportive measures, giving benzodiazepines for myoclonus, and waiting for the symptoms to resolve. Moderate cases should have all thermal and cardiorespiratory abnormalities corrected and can benefit from serotonin antagonists. The serotonin antagonist cyproheptadine is the recommended initial therapy, although there have been no controlled trials demonstrating its efficacy for serotonin syndrome. Despite the absence of controlled trials, there are a number of case reports detailing apparent improvement after people have been administered cyproheptadine. Animal experiments also suggest a benefit from serotonin antagonists. Cyproheptadine is only available as tablets and therefore can only be administered orally or via a nasogastric tube; it is unlikely to be effective in people administered activated charcoal and has limited use in severe cases. Cyproheptadine can be stopped when the person is no longer experiencing symptoms and the half life of serotonergic medications already passed.\nAdditional pharmacological treatment for severe case includes administering atypical antipsychotic drugs with serotonin antagonist activity such as olanzapine or asenapine. Critically ill people should receive the above therapies as well as sedation or neuromuscular paralysis. People who have autonomic instability such as low blood pressure require treatment with direct-acting sympathomimetics such as epinephrine, norepinephrine, or phenylephrine. Conversely, hypertension or tachycardia can be treated with short-acting antihypertensive drugs such as nitroprusside or esmolol; longer acting drugs such as propranolol should be avoided as they may lead to hypotension and shock. The cause of serotonin toxicity or accumulation is an important factor in determining the course of treatment. Serotonin is catabolized by monoamine oxidase\u00a0A in the presence of oxygen, so if care is taken to prevent an unsafe spike in body temperature or metabolic acidosis, oxygenation will assist in dispatching the excess serotonin. The same principle applies to alcohol intoxication. In cases of serotonin syndrome caused by MAOIs, oxygenation will not help to dispatch serotonin. In such instances, hydration is the main concern until the enzyme is regenerated.\nAgitation.\nSpecific treatment for some symptoms may be required. One of the most important treatments is the control of agitation due to the extreme possibility of injury to the person themselves or caregivers, benzodiazepines should be administered at first sign of this. Physical restraints are not recommended for agitation or delirium as they may contribute to mortality by enforcing isometric muscle contractions that are associated with severe lactic acidosis and hyperthermia. If physical restraints are necessary for severe agitation they must be rapidly replaced with pharmacological sedation. The agitation can cause a large amount of muscle breakdown. This breakdown can cause severe damage to the kidneys through a condition called rhabdomyolysis.\nHyperthermia.\nTreatment for hyperthermia includes reducing muscle overactivity via sedation with a benzodiazepine. More severe cases may require muscular paralysis with vecuronium, intubation, and artificial ventilation. Suxamethonium is not recommended for muscular paralysis as it may increase the risk of cardiac dysrhythmia from hyperkalemia associated with rhabdomyolysis. Antipyretic agents are not recommended as the increase in body temperature is due to muscular activity, not a hypothalamic temperature set point abnormality.\nPrognosis.\nUpon the discontinuation of serotonergic drugs, most cases of serotonin syndrome resolve within 24 hours, although in some cases delirium may persist for a number of days. Symptoms typically persist for a longer time frame in patients taking drugs which have a long elimination half-life, active metabolites, or a protracted duration of action.\nCases have reported persisting chronic symptoms, and antidepressant discontinuation may contribute to ongoing features. Following appropriate medical management, serotonin syndrome is generally associated with a favorable prognosis.\nEpidemiology.\nEpidemiological studies of serotonin syndrome are difficult as many physicians are unaware of the diagnosis or they may miss the syndrome due to its variable manifestations. In 1998 a survey conducted in England found that 85% of the general practitioners that had prescribed the antidepressant nefazodone were unaware of serotonin syndrome. The incidence may be increasing as a larger number of pro-serotonergic drugs (drugs which increase serotonin levels) are now being used in clinical practice. One postmarketing surveillance study identified an incidence of 0.4 cases per 1000 patient-months for patients who were taking nefazodone. Additionally, around 14 to 16% of persons who overdose on SSRIs are thought to develop serotonin syndrome.\nHistory.\nSerotonin syndrome, or serotonin toxicity, was first reported in humans in 1982. It had previously been observed in animals. However, serotonin syndrome-like toxicity had previously been reported as early as the 1960s, but these cases were not recognized as serotonin toxicity. Serotonin syndrome was first defined as a distinct clinical entity and formally given the name \"serotonin syndrome\" in 1991.\nNotable cases.\nThe most widely recognized example of serotonin syndrome was the death of Libby Zion in 1984. Zion was a freshman at Bennington College at her death on March 5, 1984, at age 18. She died within 8 hours of her emergency admission to the New York Hospital Cornell Medical Center. She had an ongoing history of depression, and came to the Manhattan hospital on the evening of March 4, 1984, with a fever, agitation and \"strange jerking motions\" of her body. She also seemed disoriented at times. The emergency room physicians were unable to diagnose her condition definitively but admitted her for hydration and observation. Her death was caused by a combination of pethidine and phenelzine. A medical intern prescribed the pethidine. The case influenced graduate medical education and residency work hours. Limits were set on working hours for medical postgraduates, commonly referred to as interns or residents, in hospital training programs, and they also now require closer senior physician supervision.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29501", "revid": "14650386", "url": "https://en.wikipedia.org/wiki?curid=29501", "title": "Sustainable development", "text": "Mode of human development\nSustainable development is an approach to growth and human development that aims to meet the needs of the present without compromising the ability of future generations to meet their own needs. The aim is to have a society where living conditions and resources meet human needs without undermining planetary integrity. Sustainable development aims to balance the needs of the economy, environment, and society. The Brundtland Report in 1987 helped to make the concept of sustainable development better known.\nSustainable development overlaps with the idea of sustainability which is a normative concept. UNESCO formulated a distinction between the two concepts as follows: \"\"Sustainability\" is often thought of as a long-term goal (i.e. a more sustainable world), while \"sustainable development\" refers to the many processes and pathways to achieve it.\"\nThe \"Rio Process\" that began at the 1992 Earth Summit in Rio de Janeiro has placed the concept of sustainable development on the international agenda. Sustainable development is the foundational concept of the Sustainable Development Goals (SDGs). These global goals for the year 2030 were adopted in 2015 by the United Nations General Assembly (UNGA). They address the global challenges, including poverty, climate change, biodiversity loss, and peace.\nThere are some problems with the concept of sustainable development. Some scholars say it is an oxymoron because according to them, \"development\" is inherently unsustainable. Other commentators are disappointed in the lack of progress that has been achieved so far. Scholars have stated that \"sustainable development\" is open-ended, ambiguous, and incoherent, so it can be easily appropriated.\"\" Furthermore, while digitalization is often promoted as a tool for sustainable development, recent scholarly analysis has introduced a more complex view, indicating that the rapid reliance on digital technologies can have a negative overall impact on environmental sustainability, despite positive influences on economic and social development aspects.&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt; Therefore, it is important that there is increased funding for research on sustainability in order to better understand sustainable development and address its vagueness and shortcomings.\nDefinition.\nIn 1987, the United Nations World Commission on Environment and Development released the report \"Our Common Future\", commonly called the Brundtland Report. The report included a definition of \"sustainable development\" which is now widely used:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Sustainable development is a development that meets the needs of the present without compromising the ability of future generations to meet their own needs. It contains two key concepts within it:\nScholars note that sustainable development is understood in many different ways.\"\" They also highlight inconsistencies in the current market-driven system of social, economic and political organization. Efforts toward global sustainability must consider the diverse challenges, conditions, and choices that affect prospects and prosperity for all, everywhere.\nSustainability means different things to different people, and the concept of sustainable development has led to a diversity of discourses that legitimize competing sociopolitical projects.\nDevelopment of the concept.\nSustainable development has its roots in ideas regarding sustainable forest management, which were developed in Europe during the 17th and 18th centuries. In response to a growing awareness of the depletion of timber resources in England, John Evelyn argued, in his 1662 essay \"Sylva\", that \"sowing and planting of trees had to be regarded as a national duty of every landowner, in order to stop the destructive over- exploitation of natural resources.\" In 1713, Hans Carl von Carlowitz, a senior mining administrator in the service of Elector Frederick Augustus I of Saxony published \"Sylvicultura economics\", a 400-page work on forestry. Building upon the ideas of Evelyn and French minister Jean-Baptiste Colbert, von Carlowitz developed the concept of managing forests for sustained yield. His work influenced others, including Alexander von Humboldt and Georg Ludwig Hartig, eventually leading to the development of the science of forestry. This, in turn, influenced people like Gifford Pinchot, the first head of the US Forest Service, whose approach to forest management was driven by the idea of wise use of resources, and Aldo Leopold whose land ethic was influential in the development of the environmental movement in the 1960s.\nFollowing the publication of Rachel Carson's \"Silent Spring\" in 1962, the developing environmental movement drew attention to the relationship between economic growth and environmental degradation. Kenneth E. Boulding, in his influential 1966 essay \"The Economics of the Coming Spaceship Earth\", identified the need for the economic system to fit itself to the ecological system with its limited pools of resources. Another milestone was the 1968 article by Garrett Hardin that popularized the term \"tragedy of the commons\".\nThe direct linking of sustainability and development in a contemporary sense can be traced to the early 1970s. \"Strategy of Progress\", a 1972 book (in German) by Ernst Basler, explained how the long-acknowledged sustainability concept of preserving forests for future wood production can be directly transferred to the broader importance of preserving environmental resources to sustain the world for future generations. That same year, the interrelationship of environment and development was formally demonstrated in a systems dynamic simulation model reported in the classic report on \"Limits to Growth\". This was commissioned by the Club of Rome and written by a group of scientists led by Dennis and Donella Meadows of the Massachusetts Institute of Technology. Describing the desirable \"state of global equilibrium\", the authors wrote: \"We are searching for a model output that represents a world system that is sustainable without sudden and uncontrolled collapse and capable of satisfying the basic material requirements of all of its people.\" The year 1972 also saw the publication of the influential book, \"A Blueprint for Survival\".\nIn 1975, an MIT research group prepared ten days of hearings on \"Growth and Its Implication for the Future\" for the US Congress, the first hearings ever held on sustainable development.\nIn 1980, the International Union for Conservation of Nature published a world conservation strategy that included one of the first references to sustainable development as a global priority and introduced the term \"sustainable development\". Two years later, the United Nations World Charter for Nature raised five principles of conservation by which human conduct affecting nature is to be guided and judged.\nSince the Brundtland Report, the concept of sustainable development has developed beyond the initial intergenerational framework to focus more on the goal of \"socially inclusive and environmentally sustainable economic growth\". In 1992, the UN Conference on Environment and Development published the Earth Charter, which outlines the building of a just, sustainable, and peaceful global society in the 21st century. The action plan Agenda 21 for sustainable development identified information, integration, and participation as key building blocks to help countries achieve development that recognizes these interdependent pillars. Furthermore, Agenda 21 emphasizes that broad public participation in decision-making is a fundamental prerequisite for achieving sustainable development.\nThe Rio Protocol was a huge leap forward: for the first time, the world agreed on a sustainability agenda. In fact, a global consensus was facilitated by neglecting concrete goals and operational details.\nWhilst the discussions about (or discourse of) sustainable development are highly influential in global and national governance frameworks, its meaning and operationalization are context-dependent and have evolved over time. This evolution can for example be seen in the transition from the Millennium Development Goals (years 2000 to 2015) to the Sustainable Development Goals (years 2015 to 2030).\nGlobal governance framework.\nThe most comprehensive global governance framework for sustainable development is the \"2030 Agenda for Sustainable Development\" with its 17 Sustainable Development Goals (SDGs). This agenda was a follow-up to the Millennium Declaration from the year 2000 with its eight Millennium Development Goals (MDGs), the first comprehensive global governance framework for sustainable development. The SDGs have concrete targets (unlike the results from the Rio Process) but no methods for sanctions. They contain goals, targets and indicators for example in the areas of poverty reduction, environmental protection, human prosperity and peace.\nScholars who are investigating global environmental governance have identified a set of discourses within the public space that mostly convey four sustainability frames: mainstream sustainability, progressive sustainability, a limits discourse, and radical sustainability. First, \"mainstream sustainability\" is a conservative approach on both economic and political terms. Second, \"progressive sustainability\" is an economically conservative, yet politically reformist approach. Under this framing, sustainable development is still centered on economic growth but human well-being and development can only be achieved through a redistribution of power to even out inequalities between developed and developing countries. Third, a \"limits discourse\" is an economically reformist, yet politically conservative approach to sustainability. Fourth, \"radical sustainability\" is a transformative approach seeking to break with existing global economic and political structures.\nDimensions.\nSustainable development, like sustainability, is regarded to have three \"dimensions\": the environment, economy and society. The idea is that a good balance between the three dimensions should be achieved. Instead of calling them \"dimensions\", other terms commonly used are \"pillars\", \"domains\", \"aspects\", \"spheres\".\nPathways.\nSix interdependent capacities are deemed to be necessary for the successful pursuit of sustainable development. These are the capacities to measure progress towards sustainable development; promote equity within and between generations; adapt to shocks and surprises; transform the system onto more sustainable development pathways; link knowledge with action for sustainability; and to devise governance arrangements that allow people to work together.\nDuring the MDG era (year 2000 to 2015), the key objective of sustainable development was poverty reduction to be reached through economic growth and participation in the global trade system. The SDGs take a much more comprehensive approach to sustainable development than the MDGs did. They offer a more people-centered development agenda. Out of the 17 SDGs, for example, 11 goals contain targets related to equity, equality or inclusion, and SDG 10 is solely devoted to addressing inequality within and among countries.\nImproving on environmental sustainability.\n An unsustainable situation occurs when natural capital (the total of nature's resources) is used up faster than it can be replenished. Sustainability requires that human activity only uses nature's resources at a rate at which they can be replenished naturally. The concept of sustainable development is intertwined with the concept of carrying capacity. Theoretically, the long-term result of environmental degradation is the inability to sustain human life.\nImportant operational principles of sustainable development were published by Herman Daly in 1990: renewable resources should provide a sustainable yield (the rate of harvest should not exceed the rate of regeneration); for non-renewable resources there should be equivalent development of renewable substitutes; waste generation should not exceed the assimilative capacity of the environment.\nIn 2019, a summary for policymakers of the largest, most comprehensive study to date of biodiversity and ecosystem services was published by the Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services. It recommended that human civilization will need a transformative change, including sustainable agriculture, reductions in consumption and waste, fishing quotas and collaborative water management.\nEnvironmental problems associated with industrial agriculture and agribusiness are now being addressed through approaches such as sustainable agriculture, organic farming and more sustainable business practices. At the local level there are various movements working towards sustainable food systems which may include less meat consumption, local food production, slow food, sustainable gardening, and organic gardening. The environmental effects of different dietary patterns depend on many factors, including the proportion of animal and plant foods consumed and the method of food production. \nAs global population and affluence have increased, so has the use of various materials increased in volume, diversity, and distance transported. By 2050, humanity could consume an estimated 140 billion tons of minerals, ores, fossil fuels and biomass per year (three times its current amount) unless the economic growth rate is decoupled from the rate of natural resource consumption.\nSustainable use of materials has targeted the idea of dematerialization, converting the linear path of materials (extraction, use, disposal in landfill) to a circular material flow that reuses materials as much as possible, much like the cycling and reuse of waste in nature. This way of thinking is expressed in the concept of circular economy, which employs reuse, sharing, repair, refurbishment, remanufacturing and recycling to create a closed-loop system, minimizing the use of resource inputs and the creation of waste, pollution and carbon emissions. The European Commission has adopted an ambitious Circular Economy Action Plan in 2020, which aims at making sustainable products the norm in the EU.\nImproving on economic and social aspects.\nIt has been suggested that because of the rural poverty and overexploitation, environmental resources should be treated as important economic assets, called natural capital. Economic development has traditionally required a growth in the gross domestic product. This model of unlimited personal and GDP growth may be over. Sustainable development may involve improvements in the quality of life for many but may necessitate a decrease in resource consumption. \"Growth\" generally ignores the direct effect that the environment may have on social welfare, whereas \"development\" takes it into account.\nAs early as the 1970s, the concept of sustainability was used to describe an economy \"in equilibrium with basic ecological support systems\". Scientists in many fields have highlighted \"The Limits to Growth\", and economists have presented alternatives, for example a 'steady-state economy', to address concerns over the impacts of expanding human development on the planet. In 1987, the economist Edward Barbier published the study \"The Concept of Sustainable Economic Development\", where he recognized that goals of environmental conservation and economic development are not conflicting and can be reinforcing each other.\nA World Bank study from 1999 concluded that based on the theory of genuine savings (defined as \"traditional net savings less the value of resource depletion and environmental degradation plus the value of investment in human capital\"), policymakers have many possible interventions to increase sustainability, in macroeconomics or purely environmental. Several studies have noted that efficient policies for renewable energy and pollution are compatible with increasing human welfare, eventually reaching a golden-rule steady state.\nA meta review in 2002 looked at environmental and economic valuations and found a \"lack of concrete understanding of what \"sustainability policies\" might entail in practice\". A study concluded in 2007 that knowledge, manufactured and human capital (health and education) has not compensated for the degradation of natural capital in many parts of the world. It has been suggested that intergenerational equity can be incorporated into a sustainable development and decision making, as has become common in economic valuations of climate economics.\nThe World Business Council for Sustainable Development published a Vision 2050 document in 2021 to show \"How business can lead the transformations the world needs\". The vision states that \"we envision a world in which 9+billion people can live well, within planetary boundaries, by 2050.\" This report was highlighted by \"The Guardian\" as \"the largest concerted corporate sustainability action plan to date \u2013 include reversing the damage done to ecosystems, addressing rising greenhouse gas emissions and ensuring societies move to sustainable agriculture.\"\nAssessments and reactions.\nThe concept of sustainable development has been and still is, subject to criticism, including the question of what is to be sustained in sustainable development. It has been argued that there is no such thing as sustainable use of a non-renewable resource, since any positive rate of exploitation will eventually lead to the exhaustion of earth's finite stock; this perspective renders the Industrial Revolution as a whole unsustainable.\nThe sustainable development debate is based on the assumption that societies need to manage three types of capital (economic, social, and natural), which may be non-substitutable and whose consumption might be irreversible. Natural capital can not necessarily be substituted by economic capital. While it is possible that we can find ways to replace some natural resources, it is much less likely that they will ever be able to replace ecosystem services, such as the protection provided by the ozone layer, or the climate stabilizing function of the Amazonian forest.\nThe concept of sustainable development has been criticized from different angles. While some see it as paradoxical (or an oxymoron) and regard development as inherently unsustainable, others are disappointed in the lack of progress that has been achieved so far. Part of the problem is that \"development\" itself is not consistently defined.\nThe vagueness of the Brundtland definition of sustainable development has been criticized as follows: The definition has \"opened up the possibility of downplaying sustainability. Hence, governments spread the message that we can have it all at the same time, i.e. economic growth, prospering societies and a healthy environment. No new ethic is required. This so-called weak version of sustainability is popular among governments, and businesses, but profoundly wrong and not even weak, as there is no alternative to preserving the earth's ecological integrity.\"\nScholars have stated that \"sustainable development\" is open-ended, much critiqued as ambiguous, incoherent, and therefore easily appropriated.\"\"\nSociety and culture.\nSustainable development goals.\nSustainable development is the foundational concept of the Sustainable Development Goals (SDGs). Policies to achieve the SDGs are meant to cohere around this concept.\"\"\nEducation for sustainable development.\nEducation for sustainable development (ESD) is a term officially used by the United Nations. It is defined as education practices that encourage changes in knowledge, skills, values, and attitudes to enable a more sustainable and just society for humanity. ESD aims to empower and equip current and future generations to meet their needs using a balanced and integrated approach to sustainable development's economic, social, and environmental dimensions.\nAgenda 21 was the first international document that identified education as an essential tool for achieving sustainable development and highlighted areas of action for education. ESD is a component of measurement in an indicator for Sustainable Development Goal 12 (SDG) for \"responsible consumption and production\". SDG 12 has 11 targets, and target 12.8 is \"By 2030, ensure that people everywhere have the relevant information and awareness for sustainable development and lifestyles in harmony with nature.\" 20 years after the Agenda 21 document was declared, the 'Future we want' document was proclaimed in the Rio+20 UN Conference on Sustainable Development, stating that \"We resolve to promote education for sustainable development and to integrate sustainable development more actively into education beyond the Decade of Education for Sustainable Development.\"\nOne version of education for Sustainable Development recognizes modern-day environmental challenges. It seeks to define new ways to adjust to a changing biosphere, as well as engage individuals to address societal issues that come with them. In the International Encyclopedia of Education, this approach to education is seen as an attempt to \"shift consciousness toward an ethics of life-giving relationships that respects the interconnectedness of man to his natural world\" to equip future members of society with environmental awareness and a sense of responsibility to sustainability.\nFor UNESCO, education for sustainable development involves:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe Thessaloniki Declaration, presented at the \"International Conference on Environment and Society: Education and Public Awareness for Sustainability\" by UNESCO and the Government of Greece (December 1997), highlights the importance of sustainability not only with regards to the natural environment, but also with \"poverty, health, food security, democracy, human rights, and peace\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29504", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=29504", "title": "Six Day War", "text": ""}
{"id": "29507", "revid": "1318841987", "url": "https://en.wikipedia.org/wiki?curid=29507", "title": "Scientific American", "text": "American monthly science magazine\nScientific American, informally abbreviated SciAm or sometimes SA, is an American popular science magazine. Many scientists, including Albert Einstein and Nikola Tesla, have contributed articles to it, with more than 150 Nobel Prize-winners having been featured since its inception.\nIn print since 1845, it is the oldest continuously published magazine in the United States. \"Scientific American\" is owned by Springer Nature, which is a subsidiary of Holtzbrinck Publishing Group.\nHistory.\n\"Scientific American\" was founded by inventor and publisher Rufus Porter in 1845 as a four-page weekly newspaper. The first issue of the large-format New York City newspaper was released on August 28, 1845.\nThroughout its early years, much emphasis was placed on reports of what was going on at the U.S. Patent Office. It also reported on a broad range of inventions including perpetual motion machines, an 1860 device for buoying vessels by Abraham Lincoln, and the universal joint, which now can be found in nearly every automobile manufactured. Current issues include a \"this date in history\" section, featuring excerpts from articles originally published 50, 100, and 150 years earlier. Topics include humorous incidents, wrong-headed theories, and noteworthy advances in the history of science and technology. It started as a weekly publication in August 1845 before turning into a monthly in November 1921.\nPorter sold the publication to Alfred Ely Beach, son of media magnate Moses Yale Beach, and Orson Desaix Munn, a mere ten months after founding it. Editors and co-owners from the Yale family included Frederick C. Beach and his son, Stanley Yale Beach, and from the Munn family, Charles Allen Munn and his nephew, Orson Desaix Munn II. Until 1948, it remained owned by the families under Munn &amp; Company. Under Orson Munn's grandson, Orson Desaix Munn III, it had evolved into something of a \"workbench\" publication, similar to the 20th-century incarnation of \"Popular Science\".\nIn the years after World War II, the magazine fell into decline. In 1948, three partners who were planning on starting a new popular science magazine, to be called \"The Sciences\", purchased the assets of the old \"Scientific American\" instead and put its name on the designs they had created for their new magazine. Thus the partners\u2014publisher Gerard Piel, editor Dennis Flanagan, and general manager Donald H. Miller Jr. essentially created a new magazine. Miller retired in 1979, Flanagan and Piel in 1984, when Gerard Piel's son Jonathan became president and editor; circulation had grown fifteen-fold since 1948. In 1986, it was sold to the Holtzbrinck Publishing Group of Germany, which has owned it until the Springer-Nature merger. In the fall of 2008, \"Scientific American\" was put under the control of Holtzbrinck's Nature Publishing Group division.\nDonald Miller died in December 1998, Gerard Piel in September 2004 and Dennis Flanagan in January 2005. Mariette DiChristina became editor-in-chief after John Rennie stepped down in June 2009, and stepped down herself in September 2019. In April 2020, Laura Helmuth assumed the role of editor-in-chief.\nThe magazine is the oldest continuously published magazine in the United States.\nIn 2009, the publisher notified collegiate libraries that yearly subscription prices for the magazine would increase by nearly 500% for print and 50% for online access to $1,500 yearly.\nOffices of the \"Scientific American\" have included 37 Park Row in Manhattan and the Woolworth Building in 1915 when it was just finished two years earlier in 1913. The Woolworth Building was at the time one of the first skyscrapers in the city and the tallest one in the world.\nInternational editions.\n\"Scientific American\" published its first foreign-language edition in 1890 in Spanish, titled \"La Am\u00e9rica Cient\u00edfica \u00e9 Industrial\", but ended sometime in the early 1900s. In 1968, the Italian-language edition\", Le Scienze\", was launched followed by the Japanese edition, \"\u65e5\u7d4c\u30b5\u30a4\u30a8\u30f3\u30b9\" (transliteration: \"Nikkei Science\") in 1971.\nSubsequent international editions included the Spanish-language revival for Spain, \"Inveestigaci\u00f3n y Ciencia\" (\"Investigation and Science\") in 1976, the French \"Pour la Science\" (\"For Science\") in 1977, the German \"Spektrum der Wissenschaft\" (\"Spectrum of Science\") in 1978, as well as the Russian \"V Mire Nauki\" (Russian: \u0412 \u043c\u0438\u0440\u0435 \u043d\u0430\u0443\u043a\u0438; \"In the world of science\").\nThe Polish edition, published by Pr\u00f3szy\u0144ski Media, began in 1991 under the name \"\u015awiat Nauki\" (\"World of Science\").\nIn 2002, the Taiwanese edition, \"Scientist\" (traditional Chinese: \u79d1\u5b78\u4eba), was established in Taipei.That same year, the German-language edition, \"Spektrum der Wissenschaft\", introduced \"Gehirn &amp; Geist\" (\"Brain &amp; Mind\"), focusing on psychology and neuroscience.\nIn Italy, \"Mente &amp; Cervello\" (\"Mind &amp; Brain\") launched in 2003, complementing the older \"Le Scienze\". The Dutch edition debuted in 2003, published by Cascade in Antwerp.\nEditors.\nEditorial controversy.\nIn 2013, Danielle N. Lee, a female scientist who blogged at \"Scientific American\", was called a \"whore\" in an email by an editor at the science website \"Biology Online\" after refusing to write professional content without compensation. Lee wrote a response to the email and posted it on the \"Scientific American\" blog. Then editor-in-chief Mariette DiChristina removed Lee's post, citing legal reasons for removing the blog. The editor at \"Biology Online\" was fired after the incident.\nThe controversy widened in the ensuing days. The magazine's blog editor, Bora Zivkovic, was the subject of allegations of sexual harassment by another blogger, Monica Byrne. Although the alleged incident had occurred about a year earlier, editor Mariette DiChristina informed readers that the incident had been investigated and resolved to Byrne's satisfaction. However, the incident involving Lee had prompted Byrne to reveal the identity of Zivkovic, following the latter's support of Lee. Zivkovic admitted the incident with Byrne had taken place. He apologized to Byrne, and referred to the incident as \"singular\", stating that his behavior was not \"engaged in before or since.\"\nZivkovic resigned from the board of Science Online, the popular science blogging conference that he co-founded with Anton Zuiker. Following Zivkovic's admission, several female bloggers, including other bloggers for the magazine, wrote their own accounts, alleging additional incidents of sexual harassment, although none of these accounts were independently investigated. A day after these new revelations, Zivkovic resigned from his position at \"Scientific American\".\nSpecial issues.\nScientific American has published numerous special editions over the years, focusing on various scientific topics. These editions are typically released quarterly and cover themes such as space settlement by humans, evolution, economics, and climate change. For example, the March 2024, (volume 33, issue 1s), included articles with themes about space exploration as well as human sexual division of labor and differentiation among early-human hunter-gatherers.\u201d Similarly, the June 2024 edition, (volume 33, issue 2s), featured pieces on analyzing the \"cosmic nothing\" and issues in physics raised often by the cosmological constant.\nThese special editions are available to subscribers and can be accessed through Scientific American\u2019s archives. The magazine\u2019s archive provides a comprehensive list of past issues, including special editions, dating back to its inception in 1845.\nScientific American 50 award.\nThe Scientific American 50 award was started in 2002 to recognize contributions to science and technology during the magazine's previous year. The magazine's 50 awards cover many categories including agriculture, communications, defense, environment, and medical diagnostics. The complete list of each year's winners appear in the December issue of the magazine, as well as on the magazine's web site.\nWebsite.\nIn March 1996, Scientific American launched its own website that included articles from current and past issues, online-only features, daily news, special reports, and trivia, among other things. The website introduced a paywall in April 2019, with readers able to view a few articles for free each month.\nColumns.\nNotable features have included:\nTelevision.\nFrom 1990 to 2005 \"Scientific American\" produced a television program on PBS called \"Scientific American Frontiers\" with hosts Woodie Flowers and Alan Alda.\nBooks.\nFrom 1983 to 1997, \"Scientific American\" has produced an encyclopedia set of volumes from their publishing division, the Scientific American Library. These books were not sold in retail stores, but as a Book of the Month Club selection priced from $24.95 to $32.95.\nTopics covered dozens of areas of scientific knowledge and included in-depth essays on: The Animal Mind; Atmosphere, Climate, and Change; Beyond the Third Dimension; Cosmic Clouds; Cycles of Life \u2022 Civilization and the Biosphere; The Discovery of Subatomic Particles; Diversity and the Tropical Rain Forest; Earthquakes and Geological Discovery; Exploring Planetary Worlds; Gravity's Fatal Attraction; Fire; Fossils and the History of Life; From Quarks to the Cosmos; A Guided Tour of the Living Cell; Human Diversity; Perception; The Solar System; Sun and Earth; The Science of Words (Linguistics); The Science of Musical Sound; The Second Law (of Thermodynamics); Stars; Supercomputing and the Transformation of Science.\n\"Scientific American\" launched a publishing imprint in 2010 in partnership with Farrar, Straus and Giroux.\nScientific and political debate.\nIn April 1950, the U.S. Atomic Energy Commission ordered \"Scientific American\" to cease publication of an issue containing an article by Hans Bethe that appeared to reveal classified information about the thermonuclear hydrogen bomb. Subsequent review of the material determined that the AEC had overreacted. The incident was important for the \"new\" \"Scientific American\"'s history, as the AEC's decision to burn 3,000 copies of an early press-run of the magazine containing the offending material appeared to be \"book burning in a free society\" when publisher Gerard Piel leaked the incident to the press.\nIn the October 2020 issue of the magazine, it endorsed Joe Biden for the 2020 presidential election, citing Donald Trump's rejection of scientific evidence, especially during the COVID-19 pandemic in the United States. In the column reporting the endorsement, the magazine's editors said, \"\"Scientific American\" has never endorsed a presidential candidate in its 175-year history. This year we are compelled to do so. We do not do this lightly.\" In September 2024 and for the second time in its history, for the same reason, \"Scientific American\" endorsed Kamala Harris for the 2024 United States presidential election.\nIn November 2024, editor-in-chief Laura Helmuth resigned from \"Scientific American\" following an apology for a social media post in which she characterized some supporting Trump as fascists. Journalist Jesse Singal objected to what he viewed as the magazine's shift towards social justice politics at the expense of its scientific credibility.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29508", "revid": "4", "url": "https://en.wikipedia.org/wiki?curid=29508", "title": "Serotonin specific reuptake inhibitors", "text": ""}
{"id": "29509", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=29509", "title": "Serotonin-specific reuptake inhibitor", "text": ""}
{"id": "29511", "revid": "36389", "url": "https://en.wikipedia.org/wiki?curid=29511", "title": "Siouxsie and the Banshees", "text": "British rock band\nSiouxsie and the Banshees ( ) were a British rock band formed in London in 1976 by vocalist Siouxsie Sioux and bass guitarist Steven Severin. Post-punk pioneers, they were widely influential, both over their contemporaries and later acts. \"The Times\" called the group \"one of the most audacious and uncompromising musical adventurers of the post-punk era\".\nInitially associated with the punk scene, the band \u2013 including guitarist John McKay and drummer Kenny Morris \u2013 rapidly evolved to create \"a form of post-punk discord full of daring rhythmic and sonic experimentation\". Their debut album \"The Scream\" was released to widespread critical acclaim in 1978. Following membership changes, including the addition of guitarist John McGeoch and drummer Budgie, they changed their musical direction and became one of the most successful alternative pop groups of the 1980s. Their third album \"Kaleidoscope\" (1980) peaked at number 5 on the UK Albums Chart. With \"Juju\" (1981) which also reached the top 10, they became an influence on the emerging gothic scene.\nIn 1988, the band made a breakthrough in North America with the multifaceted album \"Peepshow\", which received critical praise. With substantial support from alternative rock radio stations, they achieved a mainstream hit in the US in 1991 with the pop single \"Kiss Them for Me\".\nDuring their career, Siouxsie and the Banshees released 11 studio albums and 30 singles. The band experienced several line-up changes, with Siouxsie and Severin being the only constant members. They disbanded in 1996, with Siouxsie and Budgie continuing to record music as the Creatures, a second band they had formed in the early 1980s. In 2004, Siouxsie began a solo career.\nHistory.\nFormation (1976\u20131977).\nSiouxsie Sioux and Steven Severin met at a Roxy Music concert in September 1975, at a time when glam rock had faded and there was nothing new coming through with which they could identify. From February 1976, Siouxsie, Severin and some friends began to follow an unsigned band, the Sex Pistols. Journalist Caroline Coon dubbed them the \"Bromley Contingent\", as most of them came from the Bromley area of south-east London, a label Severin came to despise. \"There was no such thing, it was just a bunch of people drawn together by the way they felt and they looked\". They were all inspired by the Sex Pistols and their uncompromising attitude. When they learned that one of the bands scheduled to play the 100 Club Punk Festival, organised by Sex Pistols manager Malcolm McLaren, was pulling out from the bill at the last minute, Siouxsie suggested that she and Severin play, even though they had no band name or additional members. Two days later, the pair appeared at the festival held in London on 20 September 1976. With two borrowed musicians at their side, Marco Pirroni on guitar and Sid Vicious on drums, their set consisted of a 20-minute improvisation based on \"The Lord's Prayer\".\nThe band intended to split up after the gig, but they were asked to play again. Over the next few months, Siouxsie and Severin recruited drummer Kenny Morris and guitarist Peter Fenton. After playing several gigs in early 1977, they realised that Fenton did not fit in because he was \"a real rock guitarist\". John McKay took his place in July. Their first live appearance on television took place in November on Granada Television (based in Manchester), on Tony Wilson's TV show \"So It Goes\". In that month they also recorded their first John Peel session for BBC radio, in which they premiered a new song, \"Metal Postcard\"; this introduced a \"motorik austerity\" in the drum patterns, along with \"space in the sound\" and \"serrated guitars\". The band described their music as \"cold, machine-like and passionate at the same time\". When they appeared on the cover of \"Sounds\" magazine, Vivien Goldman wrote: \"they sound like a 21st century industrial plant\".\n\"The Scream\" and \"Join Hands\" (1978\u20131979).\nThe band sold out venues in London in early 1978, but still had problems getting the right recording contract that could give them \"complete artistic control\". Polydor offered this guarantee and signed them in June. Their first single, \"Hong Kong Garden\", featuring a xylophone motif, reached the top 10 in the UK shortly after. An \"NME\" review hailed it as \"a bright, vivid narrative, something like snapshots from the window of a speeding Japanese train, power charged by the most original, intoxicating guitar playing I heard in a long, long time\".\nThe band released their debut album, \"The Scream\", in November 1978. Nick Kent of \"NME\" said of the record: \"The band sounds like some unique hybrid of the Velvet Underground mated with much of the ingenuity of \"Tago Mago\"-era Can, if any parallel can be drawn\". At the end of the article, he added this remark: \"Certainly, the traditional three-piece sound has never been used in a more unorthodox fashion with such stunning results\".\nThe Banshees' second album, \"Join Hands\", was released in 1979. In \"Melody Maker\", Jon Savage described \"Poppy Day\" as \"a short, powerful evocation of the Great War graveyards\", and \"Record Mirror\" described the whole record as a dangerous work that \"should be heard\". The Banshees embarked on a major tour to promote the album. A few dates into the tour in September, Morris and McKay left an in-store signing after an argument and quit the band. In need of replacements to fulfil tour dates, the Banshees' manager called drummer Budgie, formerly with the Slits, and asked him to audition. Budgie was hired, but Siouxsie and Severin had no success auditioning guitarists. Robert Smith of the Cure offered his services in case they could not find a guitarist (his group were already the support band on the tour); having already seen too many \"rock virtuosos\", the band accepted his assistance. The tour resumed in September; after the last concert, Smith returned to the Cure.\n\"Kaleidoscope\", \"Juju\" and \"A Kiss in the Dreamhouse\" (1980\u20131982).\nBudgie became a permanent member, and the band entered the studios to record the single \"Happy House\" with guitarist John McGeoch, then still a member of Magazine. Their third album, \"Kaleidoscope\", released in 1980, saw the Banshees exploring new musical territories with the use of other instruments like synthesizers, sitars and drum machines. The group initially had a concept of making each song sound completely different, without regard to whether or not the material could be performed live. \"Melody Maker\" described the result as \"a kaleidoscope of sound and imagery, new forms, and content, flashing before our eyes\". \"Kaleidoscope\" was a commercial success, peaking at number 5 on the UK albums chart. This line-up, featuring McGeoch on guitar, toured the United States for the first time in support of the album in November 1980.\nFor \"Juju\" (1981), the band took a different approach and practised the songs in concert first before recording them. \"Juju\", according to Severin, became an unintentional concept album that \"drew on darker elements\". \"Sounds\" hailed it as \"intriguing, intense, brooding and powerfully atmospheric\". The album later peaked at number 7 on the UK albums chart and became one of their biggest sellers. McGeoch's guitar contributions on \"Juju\" were later praised by Johnny Marr of the Smiths.\nDuring the 1981 accompanying tour, Siouxsie and Budgie became a couple. At the same time, they also began a drum-and-voice duo called the Creatures, releasing their first EP, \"Wild Things\".\nThe Banshees followed in 1982 with the psychedelic \"A Kiss in the Dreamhouse\". The record, featuring strings on several numbers, was an intentional contrast to their previous work, with Severin later describing it as a \"sexy album\". The British press greeted it enthusiastically. Richard Cook finished his \"NME\" review with this sentence: \"I promise...this music will take your breath away\". At that time, McGeoch was struggling with alcohol problems, and was hospitalised on his return to a promotional trip from Madrid. The band fired him shortly thereafter. Severin asked Robert Smith to take over guitarist duties again; Smith accepted and rejoined the group in November 1982.\n\"Hy\u00e6na\", \"Tinderbox\" and \"Through the Looking Glass\" (1983\u20131987).\nDuring 1983, the band members worked on several side projects; Siouxsie and Budgie composed the first Creatures album, \"Feast\", while Severin and Smith recorded as the Glove. Smith then insisted on documenting his time with the Banshees, so the group released a cover version of the Beatles' \"Dear Prudence\" in September 1983. It became their biggest UK hit, reaching number 3 on the Singles Chart. They also released a live double album and video, \"Nocturne\", and completed their sixth studio album, \"Hy\u00e6na\". Shortly before its release in May 1984, Smith left the group, citing health issues due to an overloaded schedule, being in two bands at once.\nWith ex-Clock DVA guitarist John Valentine Carruthers replacing Smith, the Banshees then reworked four numbers from their repertoire, augmented by a string section, for \"The Thorn\" EP. \"NME\" praised the project: \"The power of a classical orchestra is the perfect foil for the band's grindingly insistent sounds\". The new Banshees line-up spent much of 1985 working on a new record, \"Tinderbox\". The group finished the song \"Cities in Dust\" before the album, so they rushed its release as a single prior to their longest tour of the UK. \"Tinderbox\" was released in April 1986. \"Sounds\" magazine said: \"\"Tinderbox\" is a refreshing slant on the Banshees' disturbing perspective and restores their vivid shades to pop's pale palette\". Due to the length of time spent working on \"Tinderbox\", the group desired spontaneity and decided to record an album of cover songs, \"Through the Looking Glass\", in 1987. \"Mojo\" magazine later praised their version of \"Strange Fruit\". After the album's release, the band realised Carruthers was no longer fitting in and decided to work on new material as a trio.\n\"Peepshow\" (1988\u20131990).\nFollowing a lengthy break, the band recruited multi-instrumentalist Martin McCarrick and guitarist Jon Klein. The quintet recorded \"Peepshow\" in 1988, with non-traditional rock instrumentation including cello and accordion. \"Q\" magazine praised the album in its 5-star review: \"\"Peepshow\" takes place in some distorted fairground of the mind where weird and wonderful shapes loom\". The first single, \"Peek-a-Boo\", was seen by critics as a \"brave move\" with horns and dance elements. \"Sounds\" wrote: \"The snare gets slapped, Siouxsie's voice meanders all around your head and it all comes magically together\". \"Peek-a-Boo\" was their first real breakthrough in the United States. After the tour, the band decided to take a break, with Siouxsie and Budgie recording as the Creatures and releasing their most critically acclaimed album, \"Boomerang\", while Severin and McCarrick worked on material together.\n\"Superstition\", \"The Rapture\" and break-up (1991\u20131999).\nIn 1991, Siouxsie and the Banshees returned with the single \"Kiss Them for Me\", mixing strings over a dance rhythm laced with exotica. The group collaborated with the then unknown Indian tabla player Talvin Singh, who also sang during the bridge. The single received glowing reviews and later peaked at number 23 on the \"Billboard\" Hot 100, allowing them to reach a new audience. The album \"Superstition\" followed shortly afterwards, and the group toured the US as second headliners of the inaugural Lollapalooza tour. The following year, the Banshees were asked to compose \"Face to Face\" as a single for the film \"Batman Returns\", at director Tim Burton's request.\nIn 1993, the Banshees recorded new songs based on string arrangements, and then played them in festivals abroad. On their return home, they hired former Velvet Underground member John Cale to produce the rest of the record. Released in 1995, \"The Rapture\" was described by \"Melody Maker\" as \"a fascinating, transcontinental journey through danger and exotica\". A few weeks after its release, Polydor dropped the band from its roster and Klein was replaced on the band's last tour in 1995 by ex-Psychedelic Furs guitarist Knox Chandler.\nIn April 1996, the Banshees disbanded after 20 years of working together. Siouxsie blamed the split on \"the situation with Polydor\" and \"internal problems as well.\" Contrary to rumour at the time, she said it was not a reaction to the Sex Pistols 1996 reunion tour.. Siouxsie and Budgie announced that they would carry on recording as the Creatures. In 1999, they released the album \"Anima Animus\".\n2000s\u2013present.\nIn 2002, Universal Music kicked off the band's remastered back catalogue by releasing \"The Best of Siouxsie and the Banshees\". In April, Siouxsie, Severin, Budgie and Chandler reunited briefly for the Seven Year Itch tour, which spawned \"The Seven Year Itch\" live album and DVD. The day after their last concert in Tokyo, Japan, Siouxsie and Budgie stayed in town on their own and entered a recording studio as the Creatures. Their fourth and final studio album, \"H\u00e1i!\", came out in 2003.\nOn 4 March 2004, McGeoch died in his sleep after an epileptic seizure, at the age of 48. Siouxsie and Budgie had talked about inviting him to guest with them on stage, before hearing the news.\nIn November of the same year, \"Downside Up\", a box set that collected all of the Banshees' B-sides and \"The Thorn\" EP, was released. \"The Times\" wrote in its review: \"here is a group that never filled B-sides with inferior, throwaway tracks. Rather they saw them as an outlet for some of their most radical and challenging work\".\nIn 2006, the band's first four records were remastered and compiled with previously unreleased bonus tracks. Several recordings made for the John Peel radio show from 1978 to 1986 were also compiled on the CD \"\". AllMusic described the first session as \"a fiery statement of intent\" and qualified the other performances as \"excellent\". Eleven years after the split of the Banshees, Siouxsie released her debut solo album \"Mantaray\" in 2007. The second batch of the remasters, concerning the band's 1982\u20131986 era, was issued in April 2009. It included four other reissues (including \"A Kiss in the Dreamhouse\" from 1982). The \"At the BBC\" box set, containing a DVD with all of the band's UK live television performances and three CDs with in-concert recordings, was also released in June of the same year.\nIn April 2014, their debut single \"Hong Kong Garden\" was reissued on double 7-inch vinyl. It was announced that this would be part of a three-year plan with Universal. In October, their last four studio albums (1987's \"Through the Looking Glass\", 1988's \"Peepshow\", 1991's \"Superstition\" and 1995's \"The Rapture\") were reissued on CD in remastered versions with bonus tracks. Siouxsie and Severin curated a compilation CD called \"It's a Wonderfull Life\" for the monthly magazine \"Mojo\", issued in September with Siouxsie on the front cover. On this CD, the pair honoured several composers of film and classical music that had inspired them.\nIn 2015, after releasing another compilation called \"Spellbound: The Collection\", which included a selection of singles, album tracks and B-sides such as \"Tattoo\", the band reissued 1979's \"Join Hands\" on vinyl for Record Store Day, with different cover artwork.\nA vinyl reissue series on Polydor of all of the band's albums, remastered from the original \u00bc\" tapes in 2018 by Miles Showell and cut at half speed at Abbey Road Studios, began in August 2018. The eleven studio albums were reissued on black vinyl.\nA 10 track compilation titled \"All Souls\" was released in 2022. The album's track list was curated by Siouxsie and features \"Spellbound\" (licensed for season four of series \"Stranger Things\"), \"Fireworks\", \"Peek-a-Boo\", plus album tracks and rarities. It was released on black vinyl, and orange vinyl. In 2023 \"The Rapture\" was reissued on double colored vinyl. Siouxsie's solo album \"Mantaray\" was also remastered and reissued on vinyl and CD.\nIn October 2024 \"Through the Looking Glass\" including \"The Passenger\", was reissued on crystal clear vinyl with new artwork featuring a mirror effect sleeve. \nIn 2025, \"All Souls\" was released on CD in a limited edition with an obi strip. It was issued in the form of Japanese mini-LP replica in cardboard sleeve.\nAlso in 2025, John McKay released his debut solo album \"Sixes and Sevens\".\nArtistry.\nMusical style.\nSiouxsie and the Banshees are considered post-punk pioneers. They have been described as developing \"a form of post-punk discord full of daring rhythmic and sonic experimentation\". \"The Times\" wrote that \"The Banshees stand proudly [... as] one of the most audacious and uncompromising musical adventurers of the post-punk era\". With some of their darkest material, the band also helped spawn the gothic scene. The band is also considered a new wave act.\nThey were also one of the first alternative bands; music historian Peter Buckley pointed out that they were at \"the very front of the alternative-rock scene\". In 1988, \"Peek-a-Boo\" was the first track to top the US Modern Rock chart after \"Billboard\" launched this chart in the first week of September to list the most played songs on alternative and college radio stations. Simon Goddard wrote that the \"Banshees \u2013 Mk II would become one of the biggest alternative pop groups of the 1980s\". \"Spin\" described them as \"alternative rockers\" in 1991 when referring to their presence in the top 40 chart. Noting the band's participation in the first Lollapalooza festival, journalist Jim Gerr saw them as one of the \"elements of the alternative rock community\". \"Mojo\" retrospectively presented them as one of \"alternative rock's iconic groups\".\nWhen commenting on the lyrics of the first two Banshees albums, Severin said that they were about \"madness, and childhood, and escaping suburbia, which are themes that hadn't been dealt with at all in rock music or pop music before\".\nInfluences.\nSiouxsie and the Banshees' earliest influences included an interest for a \"glamorous art rock\" \u2013 David Bowie and Roxy Music \u2013 while also \"incorporating a love for Can, Kraftwerk and Neu!\".\nLegacy.\nSiouxsie and the Banshees impacted many genres including post-punk, new wave, synth pop, gothic rock, alternative music, shoegaze and trip hop, influencing a wide range of musicians including Joy Division, the Cure, the Smiths, Depeche Mode, PJ Harvey, Radiohead, Jeff Buckley, Tricky and LCD Soundsystem.\nJoy Division's Peter Hook, who saw the group in concert in Manchester in 1977, said: \"Siouxsie and the Banshees were one of our big influences... The Banshees first LP was one of my favourite ever records, the way the guitarist and the drummer played was a really unusual way of playing\". Joy Division drummer Stephen Morris was influenced by the Banshees Mk1 from their 1977's John Peel session because their \"first drummer Kenny Morris played mostly toms\" and \"the sound of cymbals was forbidden\". He added, \"The Banshees had that... foreboding sound, sketching out the future from the dark of the past\". Joy Division producer Martin Hannett saw a difference between the Banshees' first main line-up and the other bands of 1977: \"Any harmonies you got were stark, to say the least, except for the odd exception, like Siouxsie. They were interesting\". The Cure's leader, Robert Smith, declared in 2003: \"Siouxsie and the Banshees and Wire were the two bands I really admired. They meant something.\" He also pinpointed what the 1979 \"Join Hands\" tour brought him musically. \"On stage that first night with the Banshees, I was blown away by how powerful I felt playing that kind of music. It was so different to what we were doing with the Cure. Before that, I'd wanted us to be like the Buzzcocks or Elvis Costello, the punk Beatles. Being a Banshee really changed my attitude to what I was doing\". Killing Joke cited the band in their influences: guitarist Geordie Walker praised \"the Banshees on \"The Scream\"\" for bringing \"chord structures that I found very refreshing\".\nThe two songwriters of the Smiths cited them; singer Morrissey said that \"Siouxsie and the Banshees were excellent\", and that \"they were one of the great groups of the late 1970s, early 1980s\". He also said in 1994: \"If you study modern groups, those who gain press coverage and chart action, none of them are as good as Siouxsie and the Banshees at full pelt. That's not dusty nostalgia, that's fact\". When asked \"who do you regret not going to see live\", guitarist Johnny Marr replied \"Siouxsie and the Banshees mk 1. But mk 2 were even better\". Marr mentioned his liking for John McGeoch and his contribution to the single \"Spellbound\". Marr qualified it as \"clever\" with a \"really good picky thing going on which is very un-rock'n'roll\". Smiths' historian Goddard wrote that Marr \"praise[d] the McGeoch-era Banshees as a significant inspiration\". U2 cited Siouxsie and the Banshees as a major influence and selected \"Christine\" for a \"Mojo\" compilation. The Edge was the presenter of an award given to Siouxsie at the \"Mojo\" ceremony in 2005. In December 1981, Dave Gahan of Depeche Mode named the Banshees as one of his three favourite bands, along with Sparks and Roxy Music. Gahan later hailed the single \"Candyman\" at its release, saying, \"She always sounds exciting. She sings with a lot of sex \u2013 that's what I like. This is a great Banshees record..., I like their sound. I used to see them quite a lot when I was younger.\" Commenting on the original Banshees line-up and how they were different from other groups, Gahan said: \"Siouxsie And The Banshees, whom I adored, sang much more abstract, artistic about frustration. Colder and darker\". Jim Reid of the Jesus and Mary Chain selected \"Jigsaw Feeling\" from \"The Scream\" as being among his favourite songs. Jim Reid wrote that in 1978 bands were doing something new; \"The Banshees were one of them and their first record is one of my favourites\". Thurston Moore of Sonic Youth listed \"Hong Kong Garden\" in his top 25 all-time favourite songs, saying \"it was a completely new world\". Kevin Shields of My Bloody Valentine also mentioned them as being among his early influences. Dave Navarro of Jane's Addiction once noted a parallel between his band and the Banshees: \"There are so many similar threads: melody, use of sound, attitude, sex-appeal. I always saw Jane's Addiction as the masculine Siouxsie and the Banshees\". \nThe Banshees have been praised by other acts. Thom Yorke said that seeing Siouxsie on stage in concert in 1985 inspired him to become a performer. Radiohead cited McGeoch-era Siouxsie records when mentioning the recording of the song \"There There\", and rehearsed Banshees' material prior to their 2008 tour. Jeff Buckley, who said during a press conference in Lyon, France in March 1995, \"Siouxsie, I have much of her influence in my voice\", covered \"Killing Time\" (from the \"Boomerang\" album) on various occasions. Buckley also owned all the Banshees' albums. When asked what were his influences, Buckley replied: \"I grew up for the 1960s, early 1970s, 1980s, so I observed Joni Mitchell, I observed the Smiths and Siouxsie and the Banshees. That turns me on completely\". Suede singer Brett Anderson named \"Juju\" as one of his favourite records. Red Hot Chili Peppers performed \"Christine\" in concert, and their guitarist John Frusciante cited the Banshees in interviews. Garbage singer Shirley Manson stated, \"I learned how to sing listening to \"The Scream\" and \"Kaleidoscope\"\". Siouxsie has also been praised by other female singers including PJ Harvey and Courtney Love. PJ Harvey has stated, \"It's hard to beat Siouxsie Sioux, in terms of live performance. She is so exciting to watch, so full of energy and human raw quality\", and selected Siouxsie's album \"Anima Animus\" in her top 10 albums of 1999. The band had a strong effect on two important trip hop acts. Tricky covered \"Tattoo\" to open his second album, \"Nearly God\"; the original 1983 proto-trip-hop version of that song aided Tricky in the creation of his style. Massive Attack heavily sampled \"Metal Postcard\" on the song \"Superpredators (Metal Postcard)\", recorded prior to their \"Mezzanine\" album. Air's Jean-Beno\u00eet Dunckel cited the group as one of his three main influences. Billy Corgan of the Smashing Pumpkins cited the Banshees as an important influence on his music. Faith No More covered \"Switch\" in concert and cited \"The Scream\" as one of their influences.\nThe Banshees continue to influence younger musicians. Singer James Murphy was marked by certain Banshees albums during his childhood. His band LCD Soundsystem covered \"Slowdive\" as a B-side to the single \"Disco Infiltrator\". The Beta Band sampled \"Painted Bird\" on their track \"Liquid Bird\" from the \"Heroes to Zeros\" album. TV on the Radio said that they have always tried to make a song that begins like \"Kiss Them for Me\" where all of a sudden, there's an \"element of surprise\" with \"a giant drum coming in\". Santigold based one of her songs around the music of \"Red Light\". \"'My Superman' is an interpolation of 'Red Light'\". Indie folk group DeVotchKa covered the ballad \"The Last Beat of My Heart\" at the suggestion of Arcade Fire singer Win Butler; it was released on the \"Curse Your Little Heart\" EP. Gossip named the Banshees as one of their major influences during the promotion of their single \"Heavy Cross\". British indie band Bloc Party took inspiration from \"Peek-a-Boo\" and their singer Kele Okereke stated about that Banshees' single: \"it sounded like nothing else on this planet. This is... a pop song that they put out in the middle of their career... to me it sounded like the most current but most futuristic bit of guitar-pop music I've heard\". A Perfect Circle's Billy Howerdel said that the Banshees were \"top three favorite bands for me\". The Weeknd sampled different parts of \"Happy House\" for his song \"House of Balloons\", and also used the chorus of the initial version.\nIn 2022, guitarists John Frusciante, Johnny Marr, and Ed O'Brien gave interviews for a book about John McGeoch, particularly his work with the Banshees. \"The Light Pours Out Of Me: The Authorised Biography Of John McGeoch\" was released in April on Omnibus Press. It also included new interviews with Siouxsie and Severin.\nBand members.\nPrincipal members\nOther members\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29513", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=29513", "title": "Simula", "text": "Early object-oriented programming language\nSimula is the name of two simulation programming languages, Simula I and Simula 67, developed in the 1960s at the Norwegian Computing Center in Oslo, by Ole-Johan Dahl and Kristen Nygaard. Syntactically, it is an approximate superset of ALGOL 60,\nand was also influenced by the design of SIMSCRIPT.\nSimula 67 introduced \nobjects, classes, inheritance, subclasses and an implementation of the polymorphism, virtual procedures, coroutines, and discrete event simulation, and featured garbage collection. Other forms of subtyping (besides inheriting subclasses) were introduced in Simula derivatives.\nSimula is considered the first object-oriented programming language. As its name suggests, the first Simula version by 1962 was designed for doing simulations; Simula 67 though was designed to be a general-purpose programming language and provided the framework for many of the features of object-oriented languages today.\nSimula has been used in a wide range of applications such as simulating very-large-scale integration (VLSI) designs, process modeling, communication protocols, algorithms, and other applications such as typesetting, computer graphics, and education.\nComputer scientists such as Bjarne Stroustrup, creator of C++, and James Gosling, creator of Java, have acknowledged Simula as a major influence. Simula-type objects are reimplemented in C++, Object Pascal, Java, C#, and many other languages.\nHistory.\nThe following account is based on Jan Rune Holmevik's historical essay.\nKristen Nygaard started writing computer simulation programs in 1957. Nygaard saw a need for a better way to describe the heterogeneity and the operation of a system. To further develop his ideas for a computer language to describe a system, Nygaard realized that he needed someone with more computer programming skills than he had. Ole-Johan Dahl joined him on his work in January 1962. Shortly after, the decision was made to link the language to ALGOL 60. By May 1962, the main concepts for a simulation language were established; \"SIMULA I\", a specialized programming language designed for simulating discrete event systems, was born.\nKristen Nygaard was invited to visit the Eckert\u2013Mauchly Computer Corporation in late May 1962 in connection with the marketing of their new UNIVAC 1107 computer. At that visit, Nygaard presented the ideas of Simula to Robert Bemer, the director of systems programming at Univac. Bemer was a great ALGOL fan and found the Simula project compelling. Bemer was also chairperson of a session at the second international conference on information processing hosted by International Federation for Information Processing (IFIP). He invited Nygaard, who presented the paper \"SIMULA \u2013 An Extension of ALGOL to the Description of Discrete-Event Networks\".\nThe Norwegian Computing Center got a UNIVAC 1107 in August 1963 at a considerable discount, on which Dahl implemented the SIMULA I under contract with UNIVAC. The implementation was based on the UNIVAC ALGOL 60 compiler. SIMULA I was fully operational on the UNIVAC 1107 by January 1965. In the following few years, Dahl and Nygaard spent a lot of time teaching Simula. Simula spread to several countries around the world and SIMULA I was later implemented on other computers including the Burroughs B5500 and the Russian Ural-16.\nIn 1966 C. A. R. Hoare introduced the concept of record class construct, which Dahl and Nygaard extended with the concept of prefixing and other features to meet their requirements for a generalized process concept. Dahl and Nygaard presented their paper on class and subclass declarations at the IFIP Working Conference on simulation languages in Oslo, May 1967. This paper became the first formal definition of Simula 67. In June 1967, a conference was held to standardize the language and initiate a number of implementations. Dahl proposed to unify the type and the class concept. This led to serious discussions, and the proposal was rejected by the board. Simula 67 was formally standardized on the first meeting of the Simula Standards Group (SSG) in February 1968.\nSimula was influential in the development of Smalltalk and later object-oriented programming languages. It also helped inspire the actor model of concurrent computation although Simula only supports coroutines and not true concurrency.\nIn the late sixties and the early seventies, there were four main implementations of Simula:\nThese implementations were ported to a wide range of platforms. The TOPS-10 implemented the concept of public, protected, and private member variables and procedures, that later was integrated into Simula Standard in 1986.\nSimula Standard 1986 is the latest standard and is ported to a wide range of platforms. There are mainly four implementations:\nIn November 2001, Dahl and Nygaard were awarded the IEEE John von Neumann Medal by the Institute of Electrical and Electronics Engineers \"For the introduction of the concepts underlying object-oriented programming through the design and implementation of SIMULA 67\". In April 2002, they received the 2001 A. M. Turing Award by the Association for Computing Machinery (ACM), with the citation: \"For ideas fundamental to the emergence of object oriented programming, through their design of the programming languages Simula I and Simula 67.\" Dahl and Nygaard died in June and August of that year, respectively, before the ACM Turing Award Lecture that was scheduled to be delivered at the November 2002 OOPSLA conference in Seattle.\nSimula Research Laboratory is a research institute named after the Simula language, and Nygaard held a part-time position there from the opening in 2001. The new Computer Science building at the University of Oslo is named Ole Johan Dahl's House, in Dahl's honour, and the main auditorium is named Simula.\nSample code.\nMinimal program.\nThe empty computer file is the minimal program in Simula, measured by the size of the source code. It consists of one thing only; a dummy statement.\nHowever, the minimal program is more conveniently represented as an empty block:\n Begin\n End;\nIt begins executing and immediately terminates. The language lacks any return value from the program.\nClassic Hello world.\nAn example of a Hello world program in Simula:\n Begin\n OutText (\"Hello, World!\");\n Outimage;\n End;\nSimula is case-insensitive.\nClasses, subclasses and virtual procedures.\nA more realistic example with use of classes, subclasses and virtual procedures:\n Begin\n Class Glyph;\n Virtual: Procedure print Is Procedure print;;\n Begin\n End;\n Glyph Class Char (c);\n Character c;\n Begin\n Procedure print;\n OutChar(c);\n End;\n Glyph Class Line (elements);\n Ref (Glyph) Array elements;\n Begin\n Procedure print;\n Begin\n Integer i;\n For i:= 1 Step 1 Until UpperBound (elements, 1) Do\n elements (i).print;\n OutImage;\n End;\n End;\n Ref (Glyph) rg;\n Ref (Glyph) Array rgs (1 : 4);\n \"! Main program;\"\n rgs (1):- New Char ('A');\n rgs (2):- New Char ('b');\n rgs (3):- New Char ('b');\n rgs (4):- New Char ('a');\n rg:- New Line (rgs);\n rg.print;\n End;\nThe above example has one super class (Glyph) with two subclasses (codice_1 and codice_2). There is one virtual procedure with two implementations. The execution starts by executing the main program. Simula lacks the concept of abstract classes, since classes with pure virtual procedures can be instantiated. This means that in the above example, all classes can be instantiated. Calling a pure virtual procedure will however produce a run-time error.\nCall by name.\nSimula supports call by name so the Jensen's Device can easily be implemented. However, the default transmission mode for simple parameter is call by value, contrary to ALGOL which used call by name. The source code for the Jensen's Device must therefore specify call by name for the parameters when compiled by a Simula compiler.\nAnother much simpler example is the summation function formula_1 which can be implemented as follows:\n Real Procedure Sigma (k, m, n, u);\n Name k, u;\n Integer k, m, n; Real u;\n Begin\n Real s;\n k:= m;\n While k &lt;= n Do Begin s:= s + u; k:= k + 1; End;\n Sigma:= s;\n End;\nThe above code uses call by name for the controlling variable (codice_3) and the expression (codice_4).\nThis allows the controlling variable to be used in the expression.\nNote that the Simula standard allows for certain restrictions on the controlling variable\nin a for loop. The above code therefore uses a while loop for maximum portability.\nThe following:\nformula_2\ncan then be implemented as follows:\n Z:= Sigma (i, 1, 100, 1 / (i + a) ** 2);\nSimulation.\nSimula includes a simulation package for doing discrete event simulations. This simulation package is based on Simula's object-oriented features and its coroutine concept. Simula also was used for simulation proposes using procedural generation to generate pseudo-random numbers.\nSam, Sally, and Andy are shopping for clothes. They must share one fitting room. Each one of them is browsing the store for about 12 minutes and then uses the fitting room exclusively for about three minutes, each following a normal distribution. A simulation of their fitting room experience is as follows:\n Simulation Begin\n Class FittingRoom; Begin\n Ref (Head) door;\n Boolean inUse;\n Procedure request; Begin\n If inUse Then Begin\n Wait (door);\n door.First.Out;\n End;\n inUse:= True;\n End;\n Procedure leave; Begin\n inUse:= False;\n Activate door.First;\n End;\n door:- New Head;\n End;\n Procedure report (message); Text message; Begin\n OutFix (Time, 2, 0); OutText (\": \" &amp; message); OutImage;\n End;\n Process Class Person (pname); Text pname; Begin\n While True Do Begin\n Hold (Normal (12, 4, u));\n report (pname &amp; \" is requesting the fitting room\");\n fittingroom1.request;\n report (pname &amp; \" has entered the fitting room\");\n Hold (Normal (3, 1, u));\n fittingroom1.leave;\n report (pname &amp; \" has left the fitting room\");\n End;\n End;\n Integer u;\n Ref (FittingRoom) fittingRoom1;\n fittingRoom1:- New FittingRoom;\n Activate New Person (\"Sam\");\n Activate New Person (\"Sally\");\n Activate New Person (\"Andy\");\n Hold (100);\n End;\nThe main block is prefixed with codice_5 for enabling simulation. The simulation package can be used on any block and simulations can even be nested when simulating someone doing simulations.\nThe fitting room object uses a queue (codice_6) for getting access to the fitting room. When someone requests the fitting room and it's in use they must wait in this queue (codice_7). When someone leaves the fitting room the first one (if any) is released from the queue (codice_8) and accordingly removed from the door queue (codice_9).\nPerson is a subclass of codice_10 and its activity is described using hold (time for browsing the store and time spent in the fitting room) and calls procedures in the fitting room object for requesting and leaving the fitting room.\nThe main program creates all the objects and activates all the person objects to put them into the event queue. The main program holds for 100 minutes of simulated time before the program terminates.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29515", "revid": "48702738", "url": "https://en.wikipedia.org/wiki?curid=29515", "title": "SNOBOL", "text": "Text-string-oriented programming language\nSNOBOL (StriNg Oriented and symBOlic Language) is a series of programming languages developed between 1962 and 1967 at AT&amp;T Bell Laboratories by David J. Farber, Ralph Griswold and Ivan P. Polonsky, culminating in SNOBOL4. It was one of a number of text-string-oriented languages developed during the 1950s and 1960s; others included COMIT and TRAC. Despite the similar name, it is entirely unlike COBOL.\nSNOBOL4 stands apart from most programming languages of its era by having patterns as a first-class data type, a data type whose values can be manipulated in all ways permitted to any other data type in the programming language, and by providing operators for pattern concatenation and alternation. SNOBOL4 patterns are a type of object and admit various manipulations, much like later object-oriented languages such as JavaScript whose patterns are known as regular expressions. In addition SNOBOL4 strings generated during execution can be treated as programs and either interpreted or compiled and executed (as in the eval function of other languages).\nSNOBOL4 was quite widely taught in larger U.S. universities in the late 1960s and early 1970s and was widely used in the 1970s and 1980s as a text manipulation language in the humanities.\nIn the 1980s and 1990s, its use faded as newer languages such as AWK and Perl made string manipulation by means of regular expressions fashionable. SNOBOL4 patterns include a way to express BNF grammars, which are equivalent to context-free grammars and more powerful than regular expressions. \nThe \"regular expressions\" in current versions of AWK and Perl are in fact extensions of regular expressions in the traditional sense, but regular expressions, unlike SNOBOL4 patterns, are not recursive, which gives a distinct computational advantage to SNOBOL4 patterns. (Recursive expressions did appear in Perl 5.10, though, released in December 2007.)\nThe later SL5 (1977) and Icon (1978) languages were designed by Griswold to combine the backtracking of SNOBOL4 pattern matching with more standard ALGOL-like structuring.\nDevelopment.\nSNOBOL1.\nThe initial SNOBOL language was created as a tool to be used by its authors to work with the symbolic manipulation of polynomials. It was written in assembly language for the IBM 7090. It had a simple syntax, only one datatype, the string, no functions, and no declarations and very little error control. However, despite its simplicity and its \"personal\" nature its use began to spread to other groups. As a result, the authors decided to extend it and tidy it up.\nSNOBOL2.\nSNOBOL2 did exist but it was a short-lived intermediate development version without user-defined functions and was never released.\nSNOBOL3.\nSNOBOL was rewritten to add functions, both standard and user-defined, and the result was released as SNOBOL3. SNOBOL3 became quite popular and was rewritten for other computers than the IBM 7090 by other programmers. As a result, several incompatible dialects arose.\nSNOBOL4.\nAs SNOBOL3 became more popular, the authors received more and more requests for extensions to the language. They also began to receive complaints about incompatibility and bugs in versions that they hadn't written. To address this and to take advantage of the new computers being introduced in the late 1960s, the decision was taken to develop SNOBOL4 with many extra datatypes and features but based on a virtual machine to allow improved portability across computers. The SNOBOL4 language translator was still written in assembly language. However the macro features of the assembler were used to define the virtual machine instructions of the SNOBOL Implementation Language, the SIL. This very much improved the portability of the language by making it relatively easy to port the virtual machine which hosted the translator by recreating its virtual instructions on any machine which included a macro assembler or indeed a high level language.\nThe machine-independent language SIL arose as a generalization of string manipulation macros by Douglas McIlroy, which were used extensively in the initial SNOBOL implementation. In 1969, McIlroy influenced the language again by insisting on addition of the table type to SNOBOL4.\nSNOBOL4 features.\nSNOBOL is distinctive in format and programming style, which are radically different from contemporary procedural languages such as Fortran and ALGOL.\nSNOBOL4 supports a number of built-in data types, such as integers and limited precision real numbers, strings, patterns, arrays, and tables (associative arrays), and also allows the programmer to define additional data types and new functions. SNOBOL4's programmer-defined data type facility was advanced at the time\u2014it is similar to the records of the earlier COBOL and the later Pascal programming languages.\nAll SNOBOL command lines are of the form\n\"label subject pattern\" = \"object\" : \"transfer\"\nEach of the five elements is optional. In general, the \"subject\" is matched against the \"pattern\". If the \"object\" is present, any matched portion is replaced by the \"object\" via rules for replacement. The \"transfer\" can be an absolute branch or a conditional branch dependent upon the success or failure of the subject evaluation, the pattern evaluation, the pattern match, the object evaluation or the final assignment. It can also be a transfer to code created and compiled by the program itself during a run.\nA SNOBOL pattern can be very simple or extremely complex. A simple pattern is just a text string (e.g. \"ABCD\"), but a complex pattern may be a large structure describing, for example, the complete grammar of a computer language. It is possible to implement a language interpreter in SNOBOL almost directly from a Backus\u2013Naur form expression of it, with few changes. Creating a macro assembler and an interpreter for a completely theoretical piece of hardware could take as little as a few hundred lines, with a new instruction being added with a single line.\nComplex SNOBOL patterns can do things that would be impractical or impossible using the more primitive regular expressions used in most other pattern-matching languages. Some of this power derives from the so-called \"SPITBOL extensions\" (which have since been incorporated in basically all modern implementations of the original SNOBOL 4 language too), although it is possible to achieve the same power without them. Part of this power comes from the side effects that it is possible to produce during the pattern matching operation, including saving numerous intermediate/tentative matching results and the ability to invoke user-written functions during the pattern match which can perform nearly any desired processing, and then influence the ongoing direction the interrupted pattern match takes, or even to indeed change the pattern itself during the matching operation. Patterns can be saved like any other first-class data item, and can be concatenated, used within other patterns, and used to create very complex and sophisticated pattern expressions. It is possible to write, for example, a SNOBOL4 pattern which matches \"a complete name and international postal mailing address\", which is well beyond anything that is practical to even attempt using regular expressions.\nSNOBOL4 pattern-matching uses a backtracking algorithm similar to that used in the logic programming language Prolog, which provides pattern-like constructs via DCGs. This algorithm makes it easier to use SNOBOL as a logic programming language than is the case for most languages.\nSNOBOL stores variables, strings and data structures in a single garbage-collected heap.\nExample programs.\nThe \"Hello, World!\" program might be as follows...\n OUTPUT = \"Hello, World!\"\nEND\nA simple program to ask for a user's name and then use it in an output sentence...\n OUTPUT = \"What is your name?\"\n Username = INPUT\n OUTPUT = \"Thank you, \" Username\nEND\nUse :S (branch on successful match) to choose among three possible outputs...\n OUTPUT = \"What is your name?\"\n Username = INPUT\n Username \"J\" :S(LOVE)\n Username \"K\" :S(HATE)\nMEH OUTPUT = \"Hi, \" Username :(END)\nLOVE OUTPUT = \"How nice to meet you, \" Username :(END)\nHATE OUTPUT = \"Oh. It's you, \" Username\nEND\nTo continue requesting input until no more is forthcoming...\n OUTPUT = \"This program will ask you for personal names\"\n OUTPUT = \"until you press return without giving it one\"\n NameCount = 0 :(GETINPUT)\nAGAIN NameCount = NameCount + 1\n OUTPUT = \"Name \" NameCount \": \" PersonalName\nGETINPUT OUTPUT = \"Please give me name \" NameCount + 1 \n PersonalName = INPUT\n PersonalName LEN(1) :S(AGAIN)\n OUTPUT = \"Finished. \" NameCount \" names requested.\"\nEND\nImplementations.\nThe classic implementation was on the PDP-10; it has been used to study compilers, formal grammars, and artificial intelligence, especially machine translation and machine comprehension of natural languages. The original implementation was on an IBM 7090 at Bell Labs, Holmdel, N.J. SNOBOL4 was specifically designed for portability; the first implementation was started on an IBM 7094 in 1966 but completed on an IBM 360 in 1967. It was rapidly ported to many other platforms.\nIt is normally implemented as an interpreter because of the difficulty in implementing some of its very high-level features, but there is a compiler, the SPITBOL compiler, which provides nearly all the facilities that the interpreter provides.\nThe classic implementation on the PDP-10 was quite slow, and in 1972 James Gimpel of Bell Labs, Holmdel, N.J. designed a native implementation of SNOBOL4 for the PDP-10 that he named SITBOL. He used the design as the basis of a graduate class in string processing that he taught that year at Stevens Institute of Technology (which is why it was named SITBOL). Students were given sections to implement (in PDP-10 assembler) and the entire semester was focused on implementing SITBOL. It was over 80% complete by the end of the semester and was subsequently completed by Professor Gimpel and several students over the summer. SITBOL was a full-featured, high-performance SNOBOL4 interpreter.\nThe GNAT Ada Compiler comes with a package (GNAT.Spitbol) that implements all of the Spitbol string manipulation semantics. This can be called from within an Ada program.\nThe file editor for the Michigan Terminal System (MTS) provided pattern matching based on SNOBOL4 patterns.\nSeveral implementations are currently available. Macro SNOBOL4 in C written by Phil Budne is a free, open source implementation, capable of running on almost any platform. Catspaw, Inc provided a commercial implementation of the SNOBOL4 language for many different computer platforms, including DOS, Macintosh, Sun, RS/6000, and others, and these implementations are now available free from Catspaw. Minnesota SNOBOL4, by Viktors Berstis, the closest PC implementation to the original IBM mainframe version (even including Fortran-like FORMAT statement support) is also free.\nAlthough SNOBOL itself has no structured programming features, a SNOBOL preprocessor called Snostorm was designed and implemented during the 1970s by Fred G. Swartz for use under the Michigan Terminal System (MTS) at the University of Michigan. Snostorm was used at the eight to fifteen sites that ran MTS. It was also available at University College London (UCL) between 1982 and 1984.\nSnocone by Andrew Koenig adds block-structured constructs to the SNOBOL4 language. Snocone is a self-contained programming language, rather than a proper superset of SNOBOL4.\nThe SPITBOL implementation also introduced a number of features which, while not using traditional structured programming keywords, nevertheless can be used to provide many of the equivalent capabilities normally thought of as \"structured programming\", most notably nested if/then/else type constructs. These features have since been added to most recent SNOBOL4 implementations. After many years as a commercial product, in April 2009 SPITBOL was released as free software under the GNU General Public License.\nNaming.\nAccording to Dave Farber, he, Griswold and Polonsky \"finally arrived at the name Symbolic EXpression Interpreter SEXI.\"\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;All went well until one day I was submitting a batch job to assemble the system and as normal on my JOB card \u2014 the first card in the deck, I, in BTL standards, punched my job and my name \u2014 SEXI Farber.\nOne of the Comp Center girls looked at it and said, \"That's what you think\" in a humorous way.\nThat made it clear that we needed another name!! We sat and talked and drank coffee and shot rubber bands and after much too much time someone said \u2014 most likely Ralph \u2014 \"We don't have a Snowball's chance in hell of finding a name\". All of us yelled at once, \"WE GOT IT \u2014 SNOBOL\" in the spirit of all the BOL languages. We then stretched our mind to find what it stood for.\nCommon backronyms of \"SNOBOL\" are 'String Oriented Symbolic Language' or (as a quasi-initialism) 'StriNg Oriented symBOlic Language'.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29518", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=29518", "title": "Statistical physics", "text": ""}
{"id": "29519", "revid": "50860957", "url": "https://en.wikipedia.org/wiki?curid=29519", "title": "Side effect (computer science)", "text": "Of a function, an additional effect besides returning a value\nIn computer science, an operation, function or expression is said to have a side effect if it has any observable effect other than its primary effect of reading the value of its arguments and returning a value to the invoker of the operation. Example side effects include modifying a non-local variable, a static local variable or a mutable argument passed by reference; performing I/O; or calling other functions with side-effects. In the presence of side effects, a program's behaviour may depend on history; that is, the order of evaluation matters. Understanding and debugging a function with side effects requires knowledge about the context and its possible histories.\nSide effects play an important role in the design and analysis of programming languages. The degree to which side effects are used depends on the programming paradigm. For example, imperative programming is commonly used to produce side effects, to update a system's state. By contrast, declarative programming is commonly used to report on the state of system, without side effects. \nFunctional programming aims to minimize or eliminate side effects. The lack of side effects makes it easier to do formal verification of a program. The functional language Haskell eliminates side effects such as I/O and other stateful computations by replacing them with monadic actions. Functional languages such as Standard ML, Scheme and Scala do not restrict side effects, but it is customary for programmers to avoid them. \nEffect systems extend types to keep track of effects, permitting concise notation for functions with effects, while maintaining information about the extent and nature of side effects. In particular, functions without effects correspond to pure functions.\nAssembly language programmers must be aware of \"hidden\" side effects\u2014instructions that modify parts of the processor state which are not mentioned in the instruction's mnemonic. A classic example of a hidden side effect is an arithmetic instruction that implicitly modifies condition codes (a hidden side effect) while it explicitly modifies a register (the intended effect). One potential drawback of an instruction set with hidden side effects is that, if many instructions have side effects on a single piece of state, like condition codes, then the logic required to update that state sequentially may become a performance bottleneck. The problem is particularly acute on some processors designed with pipelining (since 1990) or with out-of-order execution. Such a processor may require additional control circuitry to detect hidden side effects and stall the pipeline if the next instruction depends on the results of those effects.\nReferential transparency.\nAbsence of side effects is a necessary, but not sufficient, condition for referential transparency. Referential transparency means that an expression (such as a function call) can be replaced with its value. This requires that the expression is pure, that is to say the expression must be deterministic (always give the same value for the same input) and side-effect free.\nTemporal side effects.\nSide effects caused by the time taken for an operation to execute are usually ignored when discussing side effects and referential transparency. There are some cases, such as with hardware timing or testing, where operations are inserted specifically for their temporal side effects e.g. codice_1 or codice_2. These instructions do not change state other than taking an amount of time to complete.\nIdempotence.\nA subroutine with side effects is idempotent if multiple applications of the subroutine have the same effect on the system state as a single application, in other words if the function from the system state space to itself associated with the subroutine is idempotent in the mathematical sense. For instance, consider the following Python program:\nx = 0\ndef setx(n):\n global x\n x = n\nsetx(3)\nassert x == 3\nsetx(3)\nassert x == 3\ncodice_3 is idempotent because the second application of codice_3 to 3 has the same effect on the system state as the first application: codice_5 was already set to 3 after the first application, and it is still set to 3 after the second application.\nA pure function is idempotent if it is idempotent in the mathematical sense. For instance, consider the following Python program:\ndef abs(n):\n return -n if n &lt; 0 else n\nassert abs(abs(-3)) == abs(-3)\ncodice_6 is idempotent because the second application of codice_6 to the return value of the first application to -3 returns the same value as the first application to -3.\nExample.\nOne common demonstration of side effect behavior is that of the assignment operator in C. The assignment codice_8 is an expression that evaluates to the same value as the expression codice_9, with the side effect of storing the R-value of codice_9 into the L-value of codice_11. This allows multiple assignment:\na = (b = 3); // b = 3 evaluates to 3, which then gets assigned to a\nBecause the operator right associates, this is equivalent to\na = b = 3;\nThis presents a potential hangup for novice programmers who may confuse\nwhile (b == 3) {} // tests if b evaluates to 3\nwith\nwhile (b = 3) {} // b = 3 evaluates to 3, which then casts to true so the loop is infinite\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29521", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=29521", "title": "Superheterodyne", "text": ""}
{"id": "29522", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=29522", "title": "Science fiction writers", "text": ""}
{"id": "29523", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=29523", "title": "List of science fiction editors", "text": "This is a list of science fiction editors, editors working for book and magazine publishing companies who have edited science fiction. Many have also edited works of fantasy and other related genres, all of which have been sometimes grouped under the name speculative fiction.\nEditors on this list should fulfill the conditions for in science fiction or related genres. Evidence for notability includes an existing wiki-biography, or evidence that one could be written. Borderline cases should be discussed on the article's talk page.\n&lt;templatestyles src=\"Hlist/styles.css\"/&gt;\n * See also* References* External links\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29525", "revid": "49724185", "url": "https://en.wikipedia.org/wiki?curid=29525", "title": "Square-free integer", "text": "Number without repeated prime factors\nIn mathematics, a square-free integer (or squarefree integer) is an integer that is divisible by no square number other than 1. That is, its prime factorization has exactly one factor for each prime that appears in it. For example, 10 = 2 \u22c5 5 is square-free, but 18 = 2 \u22c5 3 \u22c5 3 is not, because 18 is divisible by 9 = 32. The smallest positive square-free numbers are\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nSquare-free factorization.\nEvery positive integer formula_1 can be factored in a unique way as\nformula_2\nwhere the formula_3 different from one are square-free integers that are pairwise coprime.\nThis is called the \"square-free factorization\" of n.\nTo construct the square-free factorization, let\nformula_4 \nbe the prime factorization of formula_1, where the formula_6 are distinct prime numbers. Then the factors of the square-free factorization are defined as \nformula_7\nAn integer is square-free if and only if formula_8 for all formula_9. An integer greater than one is the formula_10th power of another integer if and only if formula_10 is a divisor of all formula_12 such that formula_13\nThe use of the square-free factorization of integers is limited by the fact that its computation is as difficult as the computation of the prime factorization. More precisely every known algorithm for computing a square-free factorization computes also the prime factorization. This is a notable difference with the case of polynomials for which the same definitions can be given, but, in this case, the square-free factorization is not only easier to compute than the complete factorization, but it is the first step of all standard factorization algorithms.\nSquare-free factors of integers.\nThe radical of an integer is its largest square-free factor, that is formula_14 with notation of the preceding section. An integer is square-free if and only if it is equal to its radical.\nEvery positive integer formula_1 can be represented in a unique way as the product of a powerful number (that is an integer such that is divisible by the square of every prime factor) and a square-free integer, which are coprime. In this factorization, the square-free factor is formula_16 and the powerful number is formula_17\nThe \"square-free part\" of formula_1 is formula_16 which is the largest square-free divisor formula_10 of formula_1 that is coprime with formula_22. The square-free part of an integer may be smaller than the largest square-free divisor, which is formula_23\nAny arbitrary positive integer formula_1 can be represented in a unique way as the product of a square and a square-free integer:\nformula_25\nIn this factorization, formula_26 is the largest divisor of formula_1 such that formula_28 is a divisor of formula_1.\nIn summary, there are three square-free factors that are naturally associated to every integer: the square-free part, the above factor formula_10, and the largest square-free factor. Each is a factor of the next one. All are easily deduced from the prime factorization or the square-free factorization: if\nformula_31\nare the prime factorization and the square-free factorization of formula_1, where formula_33 are distinct prime numbers, then the square-free part is\nformula_34\nThe square-free factor such the quotient is a square is \nformula_35\nand the largest square-free factor is \nformula_36\nFor example, if formula_37 one has formula_38 The square-free part is 7, the square-free factor such that the quotient is a square is 3 \u22c5 7 = 21, and the largest square-free factor is 2 \u22c5 3 \u22c5 5 \u22c5 7 = 210.\nNo algorithm is known for computing any of these square-free factors which is faster than computing the complete prime factorization. In particular, there is no known polynomial-time algorithm for computing the square-free part of an integer, or even for determining whether an integer is square-free. In contrast, polynomial-time algorithms are known for primality testing. This is a major difference between the arithmetic of the integers, and the arithmetic of the univariate polynomials, as polynomial-time algorithms are known for square-free factorization of polynomials (in short, the largest square-free factor of a polynomial is its quotient by the greatest common divisor of the polynomial and its formal derivative).\nEquivalent characterizations.\nA positive integer formula_1 is square-free if and only if in the prime factorization of formula_1, no prime factor occurs with an exponent larger than one. Another way of stating the same is that for every prime factor formula_41 of formula_1, the prime formula_41 does not evenly divide\u00a0formula_44. Also formula_1 is square-free if and only if in every factorization formula_46, the factors formula_47 and formula_48 are coprime. An immediate result of this definition is that all prime numbers are square-free.\nA positive integer formula_1 is square-free if and only if all abelian groups of order formula_1 are isomorphic, which is the case if and only if any such group is cyclic. This follows from the classification of finitely generated abelian groups.\nA integer formula_1 is square-free if and only if the factor ring formula_52 (see modular arithmetic) is a product of fields. This follows from the Chinese remainder theorem and the fact that a ring of the form formula_53 is a field if and only if formula_10 is prime.\nFor every positive integer formula_1, the set of all positive divisors of formula_1 becomes a partially ordered set if we use divisibility as the order relation. This partially ordered set is always a distributive lattice. It is a Boolean algebra if and only if formula_1 is square-free.\nA positive integer formula_1 is square-free if and only if formula_59, where formula_60 denotes the M\u00f6bius function.\nDirichlet series.\nThe absolute value of the M\u00f6bius function is the indicator function for the square-free integers \u2013 that is, is equal to 1 if n is square-free, and 0 if it is not. The Dirichlet series of this indicator function is\nformula_61\nwhere \"\u03b6\"(\"s\") is the Riemann zeta function. This follows from the Euler product\nformula_62\nwhere the products are taken over the prime numbers.\nDistribution.\nLet \"Q\"(\"x\") denote the number of square-free integers between 1 and \"x\" (OEIS:\u00a0 shifting index by 1). For large \"n\", 3/4 of the positive integers less than \"n\" are not divisible by 4, 8/9 of these numbers are not divisible by 9, and so on. Because these ratios satisfy the multiplicative property (this follows from Chinese remainder theorem), we obtain the approximation:\nformula_63\nThis argument can be made rigorous for getting the estimate (using big O notation)\nformula_64\n\"Sketch of a proof:\" the above characterization gives\nformula_65\nobserving that the last summand is zero for formula_66, it follows that\nformula_67\nBy exploiting the largest known zero-free region of the Riemann zeta function Arnold Walfisz improved the approximation to\nformula_68\nfor some positive constant \"c\".\nUnder the Riemann hypothesis, the error term can be reduced to\nformula_69\nIn 2015 the error term was further reduced (assuming also Riemann hypothesis) to\nformula_70\nThe asymptotic/natural density of square-free numbers is therefore\nformula_71\nTherefore over 3/5 of the integers are square-free.\nLikewise, if \"Q\"(\"x\",\"n\") denotes the number of \"n\"-free integers (e.g. 3-free integers being cube-free integers) between 1 and \"x\", one can show\nformula_72\nSince a multiple of 4 must have a square factor 4=22, it cannot occur that four consecutive integers are all square-free. On the other hand, there exist infinitely many integers \"n\" for which 4\"n\" +1, 4\"n\" +2, 4\"n\" +3 are all square-free. Otherwise, observing that 4\"n\" and at least one of 4\"n\" +1, 4\"n\" +2, 4\"n\" +3 among four could be non-square-free for sufficiently large \"n\", half of all positive integers minus finitely many must be non-square-free and therefore\nformula_73 for some constant \"C\",\ncontrary to the above asymptotic estimate for formula_74.\nThere exist sequences of consecutive non-square-free integers of arbitrary length. Indeed, for every tuple (\"p\"1, ..., \"p\"\"l\") of distinct primes, the Chinese remainder theorem guarantees the existence of an n that satisfies the simultaneous congruence\nformula_75\nEach \"n\" + \"i\" is then divisible by \"p\". On the other hand, the above-mentioned estimate formula_76 implies that, for some constant \"c\", there always exists a square-free integer between \"x\" and formula_77 for positive \"x\". Moreover, an elementary argument allows us to replace formula_77 by formula_79 The \"abc\" conjecture would allow formula_80.\nComputation of \"Q\"(\"x\").\nThe squarefree integers &amp;leq; \"x\" can be identified and counted in \"\u00d5\"(\"x\") time by using a modified Sieve of Eratosthenes. If only \"Q\"(\"x\") is desired, and not a list of the numbers that it counts, then (1) can be used to compute \"Q\"(\"x\") in \"\u00d5\"(\u221a\"x\") time. The largest known value of \"Q\"(\"x\"), for \"x\" = 1036, was computed by Jakub Pawlewicz in 2011 using an algorithm that achieves \"\u00d5\"(\"x\"2/5) time, and an algorithm taking \"\u00d5\"(\"x\"1/3) time has been outlined but not implemented.\u00a75.5\nTable of \"Q\"(\"x\"), \"x\", and \"R\"(\"x\").\nThe table shows how formula_81 and formula_82 (with the latter rounded to one decimal place) compare at powers of 10.\nformula_83 , also denoted as formula_84.\nformula_85 changes its sign infinitely often as formula_86 tends to infinity.\nThe absolute value of formula_85 is astonishingly small compared with formula_86.\nEncoding as binary numbers.\nIf we represent a square-free number as the infinite product\nformula_89\nthen we may take those formula_90 and use them as bits in a binary number with the encoding\nformula_91\nThe square-free number 42 has factorization 2 \u00d7 3 \u00d7 7, or as an infinite product 21 \u00b7 31 \u00b7 50 \u00b7 71 \u00b7 110 \u00b7 130 \u00b7\u00b7\u00b7 Thus the number 42 may be encoded as the binary sequence codice_1 or 11 decimal. (The binary digits are reversed from the ordering in the infinite product.)\nSince the prime factorization of every number is unique, so also is every binary encoding of the square-free integers.\nThe converse is also true. Since every positive integer has a unique binary representation it is possible to reverse this encoding so that they may be decoded into a unique square-free integer.\nAgain, for example, if we begin with the number 42, this time as simply a positive integer, we have its binary representation codice_2. This decodes to 20 \u00b7 31 \u00b7 50 \u00b7 71 \u00b7 110 \u00b7 131 \n 3 \u00d7 7 \u00d7 13 \n 273.\nThus binary encoding of squarefree numbers describes a bijection between the nonnegative integers and the set of positive squarefree integers.\nErd\u0151s squarefree conjecture.\nThe central binomial coefficient\n formula_92\nis never squarefree for \"n\" &gt; 4. This was proven in 1985 for all sufficiently large integers by Andr\u00e1s S\u00e1rk\u00f6zy, and for all integers &gt; 4 in 1996 by Olivier Ramar\u00e9 and Andrew Granville.\nSquarefree core.\nLet us call \"\"t\"-free\" a positive integer that has no \"t\"-th power in its divisors. In particular, the 2-free integers are the square-free integers.\nThe multiplicative function formula_93 maps every positive integer \"n\" to the quotient of \"n\" by its largest divisor that is a \"t\"-th power. That is, \n formula_94\nThe integer formula_93 is \"t\"-free, and every \"t\"-free integer is mapped to itself by the function formula_96\nThe Dirichlet generating function of the sequence formula_97 is\n formula_98.\nSee also OEIS:\u00a0 (\"t\"=2), OEIS:\u00a0 (\"t\"=3) and OEIS:\u00a0 (\"t\"=4).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29529", "revid": "16861812", "url": "https://en.wikipedia.org/wiki?curid=29529", "title": "Special function", "text": ""}
{"id": "29530", "revid": "34128202", "url": "https://en.wikipedia.org/wiki?curid=29530", "title": "Sentinel (comics)", "text": "Mutant-hunting robot in Marvel Comics\nThe Sentinels are a group of mutant-hunting robots appearing in American comic books published by Marvel Comics. They are typically depicted as antagonists to the X-Men.\nThe Sentinels played a large role in several \"X-Men\" animated series, and have been featured in several \"X-Men\" video games. The Sentinels are featured prominently in the 2014 film ', and made brief appearances in the 2006 film ' and the 2016 film \"\". In 2009, The Sentinels were ranked in \"IGN\" as the 38th Greatest Comic Book Villain of All Time.\nPublication history.\nCreated by Stan Lee and Jack Kirby, they first appeared in \"The X-Men\" #14 (Nov. 1965).\nSentinels are programmed to locate mutants and capture or kill them. Though several types of Sentinels have been introduced, the typical Sentinel is three stories tall, is capable of flight, projects energy blasts, and can detect mutants. Pursuing genocide as the means of dealing with a threat has made the Sentinels an analogy for racial hatred and other negative types of fanaticism in Marvel stories, represent the horrific consequences of humanity's actions based on hate and ignorance, along with a caution of the risks of AI takeover.\nCharacteristics.\nSentinels are designed to hunt mutants. While many are capable of tactical thought, only a handful are self-aware.\nSentinels are technologically advanced, and have exhibited a wide variety of abilities. They are armed (primarily with energy weapons and restraining devices), capable of flight, and can detect mutants at long range. They possess vast physical strength, and their bodies are highly resistant to damage. Some are able to alter their physical forms or re-assemble and reactivate themselves after they have been destroyed.\nSome Sentinel variants have the ability to learn from their experiences, developing their defenses during an engagement. Several groups of Sentinels have been created or led by a single massive Sentinel called Master Mold. Some Sentinels are also equipped with an inconspicuous logic loop in case they should go rogue to convince them that they are mutants.\nBecause of their power, sophistication, and high mass production, Sentinels are sold on the black market. Entities obtain them\u2014often in poor condition\u2014for their own purposes (not necessarily mutant-related).\nDuring the \"Iron Man 2020\" event, a Sentinel appears as a member of the A.I. Army.\nTypes of Sentinels.\nThere are different types of Sentinels that appear in the comics:\nOther versions.\nThe following are alternative versions of the Sentinels, which appear outside of regular Marvel canon.\nAge of Apocalypse.\nIn the \"Age of Apocalypse\" timeline, Bolivar Trask created the Sentinels with his wife Moira MacTaggert. These Sentinels are equipped with several body-mounted gun turrets, and their primary directive is to protect humans rather than to hunt mutants. They are capable of cooperating with mutants to further this mission.\nDays of Future Past.\nIn the \"Days of Future Past\" timeline, which takes place in an alternate future, the \"Omega Sentinels\" have advanced technologically and become the \"de facto\" rulers of the United States. The most powerful among them is Nimrod.\nHembeck.\nIn the joke comic \"Fred Hembeck Destroys the Marvel Universe\", the X-Men are killed by silent, black, man-sized \"Ninja Sentinels\".\nHere Comes Tomorrow.\nIn the \"Here Comes Tomorrow\" future timeline, a Sentinel named Rover is Tom Skylark's companion and protector. After more than 150 years of being active, Rover has become self-aware and, possibly, capable of emotion.\nHouse of M.\nIn the \"House of M\" storyline, Magneto is victorious in a mutant/human war. The Sentinels are adapted by Sebastian Shaw, now the director of S.H.I.E.L.D., to serve a reverse purpose, and now aid in the hunting of sapien rebels.\nMC2.\nIn the MC2 timeline, Wild Thing encounters a Prime Sentinel that has accidentally been activated by a faulty microwave.\nRonin.\nIn the alternate reality of \"X-Men: Ronin\", the story is played out in Japan. A police unit called \"Sentinel Force\" designs, builds and pilots the robots. These are aesthetically similar to regular Sentinels, but each is subtly different from the others.\nStar Trek.\nIn the comic crossover \"X-Men/Star Trek: Second Contact\", the X-Men work with the crew of the \"Enterprise\"-E to battle Kang the Conqueror. An away team composed of Captain Picard, Deanna Troi, Nightcrawler and Colossus encounter an approximation of the \"Days of Future Past\" timeline, in which the Sentinels have merged with the Borg.\nUltimate Marvel.\nThe \"Ultimate Marvel\" version of Sentinels were created by Bolivar Trask, were already in action in the \"Ultimate X-Men\" story arc, hunting down and killing mutants on the streets, in a program apparently openly and publicly acknowledged by the U.S. government. Later on, there were also the New Sentinels that were sixty of S.H.I.E.L.D.'s top agents in Sentinel battle armor and they were described to have enough hardware to take on a fleet of the old Sentinel models. A new breed of Sentinel robots, created by Trask under the Fenris twins' orders, was later created. After the events of the Ultimatum Wave, Nimrod Sentinels was deployed to hunt, capture or kill mutants that refused to turn themselves in. William Stryker, Jr., using Sentinel tech, later displayed an ability to summon a fleet of Sentinels after being attacked by the Shroud.\nIn other media.\nMusic.\nIn 2020, Brooklyn rapper Magneto Dayo unveiled \"The Sentinels\", a project that gained viral traction on Instagram reels in 2024, amassing over 5 million plays.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29532", "revid": "43272755", "url": "https://en.wikipedia.org/wiki?curid=29532", "title": "Sebastian Shaw", "text": "Sebastian Shaw is the name of:\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles about people with the same name. "}
{"id": "29533", "revid": "45364314", "url": "https://en.wikipedia.org/wiki?curid=29533", "title": "Savage Land", "text": "Fictional place on Marvel Comics\nThe Savage Land is a fictional prehistoric land that features in American comic books published by Marvel Comics. It is a tropical preserve, hidden in Antarctica. It has appeared in many story arcs in \"Uncanny X-Men\" as well as other related books.\nThe Savage Land has appeared in various media outside comics, including animated series and video games. It also makes a brief appearance in the 2022 Marvel Cinematic Universe film \"Doctor Strange in the Multiverse of Madness\".\nPublication history.\nThe Savage Land first appeared as 'The Land Where Time Stands Still' in \"Marvel Mystery Comics\" #22 (Aug. 1941), in the tale \"Khor, the Black Sorcerer\" by Joe Simon, Jack Kirby, and Syd Shores. It gained its familiar form and moniker in \"X-Men\" #10 (March 1965), courtesy of Stan Lee and Jack Kirby.\nFictional history.\nIn the \"X-Men\" series of comics, the Savage Land was created by the alien Nuwali at the behest of the other-dimensional, nigh-omnipotent aliens known as the Beyonders who sought to observe the process of evolution under relatively controlled conditions. In order to accomplish this, they had the Nuwali set up a number of game preserves on several planets. One of these planets was Earth during the Triassic period where the Nuwali chose a valley in Antarctica surrounded by active volcanoes. They proceeded to install a number of advanced technological devices in order to maintain a tropical climate. The aliens then stocked the area with all manner of Earth life over the following several millennia such as dinosaurs and prehistoric mammals. They also brought over the Man-Apes, earlier hominid ancestors of \"Homo sapiens\".\nThe Beyonders eventually grew bored with the experiment, and the Nuwali stopped maintaining the Savage Land during the Late Pleistocene era (the Ice Age era). However, the self-maintaining technology that allowed the pocket of tropical climate was left running, and many species which became extinct in other areas of the Earth continued to thrive within the Savage Land.\nLater on, a group of human survivors from Atlantis sailed to Antarctica before the \"Great Cataclysm\" which sank Atlantis into the ocean. There, they discovered a cavern where they found an immense climate-controlling device and harnessed the technology used to keep the Savage Land's volcanoes working. They named their location \"Pangea\", which is Atlantean for \"paradise\".\nThey mastered genetic engineering, which had been used on the Man-Apes when the Nuwali were still maintaining the Savage Land area. They used their genetic engineering techniques to transform other Savage Land inhabitants like the Golden People, the Lizard Men, the Reptile Men, the Tubantis, and others. The Atlanteans then forced them to work for them until these animal people revolted. After a time of war, the animal people demanded civil rights and the Atlanteans used technology to expand the Savage Land's surface area for the animal people to live in. When the Great Cataclysm struck, the Atlantean empire fell and thanks to the machines, the Savage Land locations were spared from sinking into the sea.\nIn more recent years, the Savage Land was rediscovered by Lord Robert Plunder, who took back a sample of the metal known as \"anti-metal\" or \"Antarctic vibranium\" with him. This mysterious metal had the ability to produce vibrations which would liquefy all other metals. Fleeing from those who sought to steal this discovery, Plunder took his eldest son Kevin with him for a second trip into the Savage Land. The elder Plunder was killed by a local tribe of Man-Apes.\nKevin survived, thanks to the timely intervention of the orphaned sabretooth tiger later known as Zabu. He grew to adulthood in the Savage Land, becoming the adventurer known as Ka-Zar. Ka-Zar had many team-ups with the X-Men, who first revealed the Savage Land's existence, Spider-Man, and many other superheroes who had visited the Savage Land. He later met and married Shanna the She-Devil.\nThe Savage Land's existence is common knowledge throughout the world. At one time, there were press junkets sponsored by the oil company Roxxon. \"Daily Bugle\" photographer Peter Parker was sent and helped uncover Roxxon's unethical and dangerous manipulation of the local resources.\nAt one point, Spider-Man teamed up with Ka-Zar to save Gwen Stacy from Kraven the Hunter and Gog at the time when her class and J. Jonah Jameson were visiting the Savage Land.\nMany villains have threatened the Savage Land, including Sauron, Garokk, Magneto, and Thanos.\nThe Savage Land was decimated by an evil alien named Terminus (or one of his pawns) when he destroyed the machines that maintained the tropical climate. Many of the Savage Land's native people were saved from the ensuing destruction by M'rin: The Warlord of The Skies who took them into her own native dimension to safety. Ka-Zar, Shanna, and Zabu wandered until the High Evolutionary (with help from the X-Men, M'rin, and Garokk) restored the region and its creatures, allowing them to return to the Savage Land with their newborn son. The other natives who had taken refuge in M'rin's dimension returned as well.\nSometime after that, Spider-Man had Devil Dinosaur and Moon-Boy emigrated to the Savage Land after rescuing them from Ringmaster.\nEvidence in the pages of the \"New Avengers\" suggests that S.H.I.E.L.D. is operating in the Savage Land, mining vibranium while using the indigenous population as slave labor, but these operations have been classified, and the operation was apparently decimated by a missile strike from the Helicarrier during an attack by the New Avengers. The team only survived thanks to Iron Man's force field.\nThe Savage Land is featured in the limited series \"Claws\", serving as a place of revenge for Wolverine and Black Cat on Arcade and White Rabbit. After defeating the two villains, the heroes left them stranded.\nIn \"\", Cyclops and Emma Frost were vacationing there until Archangel contacted them about San Francisco looking like the 1960s.\nAlyosha Kravinoff fled to the Savage Land after Punisher sabotaged his zoo.\nDuring the \"Secret Invasion\" storyline, Ka-Zar and Shanna discover Skrulls mining for vibranium. The New Avengers and the Mighty Avengers head toward the Savage Land where a downed Skrull ship was sighted. Luke Cage opens the downed Skrull ship and a large group of Marvel superheroes with older appearances and costumes come out, speaking as if they believe themselves to be authentic. It is later discovered that Skrulls have replaced several heroes, with Shanna and the Savage Land natives working to hunt them down.\nAfter the events of \"Second Coming\" during the \"Heroic Age\" storyline, Cyclops takes some time off to go hunting in the Savage Land during which he encounters Steve Rogers. Steve Rogers suggests to Cyclops that he brings the X-Men out of the shadows and into the light as heroes. Steve Rogers also arranges to have the president award Scott the Presidential Medal of Freedom which sways the people of San Francisco to welcome the X-Men back.\nAround the same time following their defeat after the hunt for \"spiders\" in the \"Grim Hunt\" storyline, the Kravinoff Family are also currently residing in the Savage Land.\nIt is later revealed that Miek and the other Imperials and Natives from Sakaar that came back with Hulk in \"World War Hulk\" had settled in the Savage Land. There they constructed a village called New Imperia.\nDuring the \"Avengers vs. X-Men\" storyline, Captain America ends up fighting Gambit in the Savage Land.\nAs part of the \"Marvel NOW!\" event, some of The Garden's evolution seeds had fallen into the Savage Land. While working to get it under control, the Avengers find that A.I.M. is also there where they test the extracted formula from one of the pods and tests it on their intern Dr. Jema. The formula puts a strain on Dr. Jema just as the Avengers arrive.\nAs part of the \"All-New, All-Different Marvel\", Magneto led a new team of X-Men to protect mutants at all costs with their base in the Savage Land.\nDuring the \"Empyre\" storyline, the Cotati have invaded the Savage Land.\nConservation status.\nThe United Nations considers the Savage Land an international wildlife preserve and forbids any commercial exploitation of its resources. Areas of the Savage Land are tame enough that the X-Men visit for recreation, including having a vacation home there.\nPoints of interest.\nThere are some famous locations in the Savage Land:\nSavage Land races.\nThere are many types of races in the Savage Land and Pangea. The Nuwali transported primitive man now known as the Man-Apes, which unlike the rest of the world thrived until the 21st century. The next arrivals were the Ancient Atlanteans who added the region as part of their empire. They used the Nuwali technology to mutate the Man-Apes into various Beast-Men to perform certain tasks. These slaves rebelled after the great Cataclysm and made Pangea their home. Many Atlanteans remained and their descendants became the various human tribes, with some clinging to the old ways and technology but most forget and resort to more primitive hunter-gatherer societies.\nIt was mentioned in Torran's narration that there are at least 1,000 races living in the Savage Land.\nSince then, the different races of the Savage Land have been sorted between the human tribes, the early hominids, the Beast-Men, and the miscellaneous.\nHuman tribes.\nThe following are the human tribes of the Savage Land:\nPrimitive hominids.\nThe following are the primitive hominids of the Savage Land:\nBeast-Men.\nThe following are the Beast-Men of the Savage Land:\nOthers.\nThe following do not fit in the categories above:\nOther versions.\nAge of Apocalypse.\nIn the \"Age of Apocalypse\" reality, the Savage Land houses Avalon, a secret haven for humans and mutants. A method to reach it exists, but it will only cost the refugee everything they own and even then, there is no guarantee of arriving alive. It is led by Destiny, a pacifist Juggernaut and Douglas Ramsey, the latter of whom provides a field that allows everybody to understand each other despite speaking different languages. Avalon was eventually found by Apocalypse forces and destroyed by the Shadow King who mind-controlled its inhabitants into killing each other. He was defeated, but casualties were high.\nAge of Ultron.\nDuring the \"Age of Ultron\" storyline, the superhero resistance against Ultron had relocated to the Savage Land to come up with a plan to defeat Ultron.\nMarvel Zombies Return.\nIn \"Marvel Zombies Return\", the Savage Land, like everywhere else on Earth, has been eaten by the superhuman zombies, with the surviving zombies musing that the Savage Land was their 'number one' meal in the aftermath, as it contained such an abundance of food that they were actually full for a full hour after eating there, as opposed to the usual ravenous hunger they feel. It is also the location of the final battle between the zombies and 'New Avengers' - three zombies who have beaten their hunger and the cyborg James Rhodes - at the storyline's conclusion, with Rhodes using one of his fingers to lure the zombies into an ambush.\nEarth X.\nIn the \"Earth X\" universe, the Savage Land is where Magneto built his sanctuary called Sentinel City.\nHouse of M.\nIn the \"House of M\" reality created by an insane Scarlet Witch, the Savage Land was known as \"Pangea\". It is also known that Kevin Plunder has been granted political asylum in the United States for his human rights activism in this prehistoric land.\nMarvel 2099.\nIn the alternate future depicted in Marvel 2099, an alien attack floods much of the earth rendering the Savage Land the only habitable space. Thousands of refugees (including Miguel O'Hara and most of X-Nation and X-Men) make new homes here. It is not without its own dangers.\nThe Transformers.\nIn the \"Transformers\" Marvel comics continuity, shortly after the \"Ark\" spacecraft crashed on Earth 4 million years before the present day, the computer aboard the Ark detected Shockwave landing on the prehistoric Savage Land. The \"Ark\" used the last of its capabilities to revive five Autobot warriors and rebuild them into the Dinobots, based on scans of the Savage Land's dominant lifeform: dinosaurs. The Dinobots fought Shockwave, a battle that ended in stalemate when Snarl brought down the mountain that Shockwave stood upon, knocking all of them into a tar pit. They remained deactivated until the year 1984. Since the Dinobots' alt-mode forms resemble creatures that were long-extinct by 4 million years ago, the Savage Land provided author Bob Budiansky a way to explain this within the canon timeline.\nSpider-Geddon.\nDuring the \"Spider-Geddon\" storyline, an alternate unidentified Earth has a version of Spider-Man that lives in the Savage Land and was raised by a tribe of giant spiders following an airplane crash. It was mentioned by Ka-Zar the Hunter to Wilson Fisk that his father killed the last of the Man-Apes.\nSquirrel Girl volume 8.\nIn the Squirrel Girl reality, the Savage Land was created by an unknown race of aliens that created dinosaurs as an experiment on earth biology. Eventually, the experiment was abandoned, and all dinosaurs, except the ones in the Savage Land were left to die. In modern times it belongs to scientists, who protect it as a Nature Reserve. The Savage Land harbors no other intelligent creatures, except Ultron, who has rebuilt himself in the form of a dinosaur and resides in the Savage Land.\nUltimate Marvel.\nIn the Ultimate Marvel universe, the Savage Land is a large island somewhere in the southern hemisphere. It was originally stated in \"Ultimate Origins\" to have been created by Magneto, using theories and methods developed by Professor X, as the site for genetic experiments. Magneto's goal there was to create a new human race who would be less trouble to rule than the current one. He decided to restart evolution from scratch, and control the process to his own specifications. As a result of this, at its current level of advancement it has dinosaurs, but Magneto has shown no further interest in advancing the evolution of the Savage Land. It has remained in its dinosaur state since the departure of Professor X. This story is later revealed as false.\nMagneto's original base was on the Savage Land, but when it was destroyed in the first arc of \"Ultimate X-Men\", the computer controlling the base gained self-awareness, and hijacked the genetic experiment project to create an army of nanotech-enhanced, zombie-like thralls. It planned to take over the world, but was stopped by Wolverine, Cyclops, and Kitty Pryde.\nThe Savage Land is now the home of Longshot, who managed to get there in a small boat which launched from Genosha. Longshot recently aided Magneto in breaking out of prison, and the two were alluded to be planning something, but Magneto later killed Longshot.\nIn \"Ultimates 3\", it is revealed that the dinosaurs were conjured by Scarlet Witch as a result of her reality warping abilities and not by Magneto's creation. The aboriginal inhabitants were wiped out and only a small tribe of survivors including Ka-Zar and Shanna remain.\nThe inhabitants help the Ultimates remove the last of Magneto's forces as of \"Ultimatum\".\nUltimate Universe.\nAn alternate universe variation of the Savage Land from Earth-6160 appears in the Ultimate Universe imprint. In \"The Ultimates\" (vol. 4), the Roxxon Energy Partners harvested much of its natural resources, turning it into a polluted wasteland and causing an extinction event. Additionally, they are stated to have taken it over during the 1970s.\nIn \"Ultimate Spider-Man\" (vol. 3), it is implied that an untouched part of the Savage Land is connected to Subterranea and under Mole Man's rule.\nWhat If?\nThe Savage Land appears in a \"What If\" story where the Savage Land was terraforming and has taken over New York. Both Ka-Zar and Parnival sacrifice themselves to return New York to normal, with Shanna the only survivor of his \"family\".\nAdditionally, in the \"What If\" issues involving alternative outcomes to the Age of Ultron, a group composed of Wolverine, the Hulk, Peter Parker and a Ghost Rider venture to the Savage Land in order to prevent a Master Mold under the control of a future version of Ezekiel Stane from unleashing a wave of Stark armors on the world.\nIn other media.\nFilm.\nThe Savage Land makes a cameo appearance in \"Doctor Strange in the Multiverse of Madness\" (2022).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29536", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=29536", "title": "Stephen Schneider (scientist)", "text": "American climatologist (1945\u20132010)\nStephen Henry Schneider (February 11, 1945\u00a0\u2013 July 19, 2010) was professor of environmental biology and global change at Stanford University, a co-director at the Center for Environment Science and Policy of the Freeman Spogli Institute for International Studies and a senior fellow in the Stanford Woods Institute for the Environment. Schneider served as a consultant to federal agencies and White House staff in the Richard Nixon, Jimmy Carter, Ronald Reagan, George H. W. Bush, Bill Clinton, George W. Bush and Barack Obama administrations.\nSchneider's research included modeling of the atmosphere, climate change, and the effect of global climate change on biological systems. Schneider was the founder and editor of the journal \"Climatic Change\" and authored or co-authored over 450 scientific papers and other publications. He was a coordinating lead author in Working Group II Intergovernmental Panel on Climate Change (IPCC) Third Assessment Report and was engaged as a co-anchor of the Key Vulnerabilities Cross-Cutting Theme for the Fourth Assessment Report (AR4) at the time of his death. During the 1980s, Schneider emerged as a leading public advocate of sharp reductions of greenhouse gas emissions to combat global warming. In 2006 Professor Schneider was an Adelaide Thinker in Residence advising the South Australian Government of Premier Mike Rann on climate change and renewable energy policies. In ten years South Australia went from zero to 31% of its electricity generation coming from renewables.\nAn annual award for outstanding climate science communication was created in Schneider's honor after his death, by the Commonwealth Club of California. The Stephen Schneider Memorial Lecture of the American Geophysical Union honors Schneider's life and work.\nEarly work.\nSchneider grew up on Long Island, New York. He studied engineering at Columbia University, receiving his bachelor's degree in mechanical engineering in 1966. In 1971, he earned a Ph.D. in mechanical engineering and plasma physics. Schneider studied the role of greenhouse gases and suspended particulate material on climate as a postdoctoral fellow at NASA's Goddard Institute for Space Studies. Schneider was awarded the Marshall Scholarship.\nIn 1971, Schneider was second author on a \"Science\" paper with S. Ichtiaque Rasool titled \"Atmospheric Carbon Dioxide and Aerosols: Effects of Large Increases on Global Climate\" (\"Science\" 173, 138\u2013141). This paper used a one-dimensional radiative transfer model to examine the competing effects of cooling from aerosols and warming from CO2. The paper concluded that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[I]t is projected that man's potential to pollute will increase six- to eightfold in the next 50 years. If this increased rate of injection of particulate matter in the atmosphere should raise the present background opacity by a factor of 4, our calculations suggest a decrease in global temperature by as much as 3.5 K. Such a large decrease in the average temperature of Earth, sustained over a period of few years, is believed to be sufficient to trigger an ice age. However, by that time, nuclear power may have largely replaced fossil fuels as a means of energy production.\nCarbon dioxide was predicted to have only a minor role. However, the model was very simple and the calculation of the CO2 effect was lower than other estimates by a factor of about three, as noted in a footnote to the paper.\nThe story made headlines in \"The New York Times\". Shortly afterwards, Schneider became aware that he had overestimated the cooling effect of aerosols, and underestimated the warming effect of CO2 by a factor of about three. He had mistakenly assumed that measurements of air particles he had taken near the source of pollution applied worldwide. He also found that much of the effect was due to natural aerosols which would not be affected by human activities, so the cooling effect of changes in industrial pollution would be much less than he had calculated. Having found that recalculation showed that global warming was the more likely outcome, he published a retraction of his earlier findings in 1974.\nIn a 1976 book \"The Genesis Strategy\" he discusses both long-term warming due to carbon dioxide and short-term cooling due to aerosols, and advocated for adopting policies that are resilient to future changes in climate.\nMedia contributions.\nSchneider was a frequent contributor to commercial and noncommercial print and broadcast media on climate and environmental issues, e.g., \"Nova\", \"Planet Earth\", \"Nightline\", \"Today Show\", \"The Tonight Show\", Bill Maher's shows, \"Good Morning America\", \"Dateline\", The Discovery Channel, as well as appearances on the British, Canadian and Australian Broadcasting Corporations.\nSchneider commented about the frustrations and difficulties involved with assessing and communicating scientific ideas. In a January 2002 \"Scientific American\" article, he wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"I readily confess a lingering frustration: uncertainties so infuse the issue of climate change that it is still impossible to rule out either mild or catastrophic outcomes, let alone provide confident probabilities for all the claims and counterclaims made about environmental problems. Even the most credible international assessment body, the Intergovernmental Panel on Climate Change (IPCC), has refused to attempt subjective probabilistic estimates of future temperatures. This has forced politicians to make their own guesses about the likelihood of various degrees of global warming.\"\nIn 1989, Schneider addressed the challenge scientists face trying to communicate complex, important issues without adequate time during media interviews. This citation sometimes was used by his critics to accuse him of supporting misuse of science for political goals:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"On the one hand, as scientists we are ethically bound to the scientific method, in effect promising to tell the truth, the whole truth, and nothing but \u2014 which means that we must include all the doubts, the caveats, the ifs, ands, and buts. On the other hand, we are not just scientists but human beings as well. And like most people we'd like to see the world a better place, which in this context translates into our working to reduce the risk of potentially disastrous climatic change. To do that we need to get some broadbased support, to capture the public's imagination. That, of course, entails getting loads of media coverage. So we have to offer up scary scenarios, make simplified, dramatic statements, and make little mention of any doubts we might have. This 'double ethical bind' we frequently find ourselves in cannot be solved by any formula. Each of us has to decide what the right balance is between being effective and being honest. I hope that means being both.\" (Quoted in \"Discover\", pp. 45\u201348, October 1989.)\nFor the original, together with Schneider's commentary on its misrepresentation, see also American Physical Society, \"APS News\" August/September 1996.\nPersonal life.\nSchneider was married to the biologist Terry Root. Schneider was a survivor of an aggressive cancer, mantle cell lymphoma. He documented his struggle to conquer the condition, including applying his own knowledge of science to design his own treatment regime, in a self-published 2005 book, \"The Patient from Hell\". He died unexpectedly on July 19, 2010, after suffering a pulmonary embolism while returning from a scientific meeting in K\u00e4ring\u00f6n, Sweden.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29537", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=29537", "title": "Scientific misconduct", "text": "Violation of codes of scholarly conduct and ethical behavior in scientific research\nScientific misconduct is the violation of the standard codes of scholarly conduct and ethical behavior in the publication of professional scientific research. It is the violation of scientific integrity: violation of the scientific method and of research ethics in science, including in the design, conduct, and reporting of research.\nBasic definitions and urgency of dealing with misconduct.\nA \"Lancet\" review on \"Handling of Scientific Misconduct in Scandinavian countries\" provides the following sample definitions, reproduced in The COPE report 1999:\nThe consequences of scientific misconduct can be damaging for perpetrators and journal audiences and for any individual who exposes it. In addition there are public health implications attached to the promotion of medical or other interventions based on false or fabricated research findings. Scientific misconduct can result in loss of public trust in the integrity of science.\nThree percent of the 3,475 research institutions that report to the US Department of Health and Human Services' Office of Research Integrity (ORI) indicate some form of scientific misconduct. However the ORI will only investigate allegations of impropriety where research was funded by federal grants. They routinely monitor such research publications for red flags and their investigation is subject to a statute of limitations. Other private organizations like the Committee of Medical Journal Editors (COJE) can only police their own members.\nA 2025 study from Northwestern University found that \"the publication of fraudulent science is outpacing the growth rate of legitimate scientific publications\". The study also discovered broad networks of organized scientific fraudsters.\nForms.\nThe U.S. National Science Foundation defines three types of research misconduct: fabrication, falsification, and plagiarism.\nOther types of research misconduct by authors are also recognized:\nMisconduct during scholarly peer review process:\nPhoto manipulation.\nCompared to other forms of scientific misconduct, image fraud (manipulation of images to distort their meaning) is of particular interest since it can frequently be detected by external parties. In 2006, the \"Journal of Cell Biology\" gained publicity for instituting tests to detect photo manipulation in papers that were being considered for publication. This was in response to the increased usage of programs such as Adobe Photoshop by scientists, which facilitate photo manipulation. Since then more publishers, including the Nature Publishing Group, have instituted similar tests and require authors to minimize and specify the extent of photo manipulation when a manuscript is submitted for publication. However, there is little evidence to indicate that such tests are applied rigorously. One \"Nature\" paper published in 2009 has subsequently been reported to contain around 20 separate instances of image fraud.\nAlthough the type of manipulation that is allowed can depend greatly on the type of experiment that is presented and also differ from one journal to another, in general the following manipulations are not allowed:\nImage manipulations are typically done on visually repetitive images such as those of blots and microscope images.\nMotivations.\nAccording to David Goodstein of Caltech, there are multiple motivators for scientists to commit misconduct, which are briefly summarised here. In many fields of scientific research, productivity and success is measured by the number of publications and related metrics such as impact factor and reputation of the journal an article is published in.\nRoles.\nScientists.\nAll authors of a scientific publication are expected to have made reasonable attempts to check findings submitted to academic journals for publication.\nSimultaneous submission of scientific findings to more than one journal or duplicate publication of findings is usually regarded as misconduct, under what is known as the Ingelfinger rule, named after the editor of The New England Journal of Medicine 1967\u20131977, Franz Ingelfinger.\nGuest authorship (where there is stated authorship in the absence of involvement, also known as gift authorship) and ghost authorship (where the real author is not listed as an author) are commonly regarded as forms of research misconduct. In some cases coauthors of faked research have been accused of inappropriate behavior or research misconduct for failing to verify reports authored by others or by a commercial sponsor. Examples include the case of Gerald Schatten who co-authored with Hwang Woo-Suk, the case of Professor Geoffrey Chamberlain named as guest author of papers fabricated by Malcolm Pearce, (Chamberlain was exonerated from collusion in Pearce's deception) \u2013 and the coauthors with Jan Hendrik Sch\u00f6n at Bell Laboratories. More recent cases include that of Charles Nemeroff, then the editor-in-chief of \"Neuropsychopharmacology\", and a well-documented case involving the drug Actonel.\nAuthors are expected to keep all study data for later examination even after publication. The failure to keep data may be regarded as misconduct. Some scientific journals require that authors provide information to allow readers to determine whether the authors might have commercial or non-commercial conflicts of interest. Authors are also commonly required to provide information about ethical aspects of research, particularly where research involves human or animal participants or use of biological material. Provision of incorrect information to journals may be regarded as misconduct. Financial pressures on universities have encouraged this type of misconduct. The majority of recent cases of alleged misconduct involving undisclosed conflicts of interest or failure of the authors to have seen scientific data involve collaborative research between scientists and biotechnology companies.\nResearch institution.\nIn general, defining whether an individual is guilty of misconduct requires a detailed investigation by the individual's employing academic institution. Such investigations require detailed and rigorous processes and can be extremely costly. Furthermore, the more senior the individual under suspicion, the more likely it is that conflicts of interest will compromise the investigation. In many countries (with the notable exception of the United States) acquisition of funds on the basis of fraudulent data is not a legal offence and there is consequently no regulator to oversee investigations into alleged research misconduct. Universities therefore have few incentives to investigate allegations in a robust manner, or act on the findings of such investigations if they vindicate the allegation.\nWell publicised cases illustrate the potential role that senior academics in research institutions play in concealing scientific misconduct. A King's College (London) internal investigation showed research findings from one of their researchers to be 'at best unreliable, and in many cases spurious' but the college took no action, such as retracting relevant published research or preventing further episodes from occurring.\nIn a more recent case an internal investigation at the National Centre for Cell Science (NCCS), Pune determined that there was evidence of misconduct by Gopal Kundu, but an external committee was then organised which dismissed the allegation, and the NCCS issued a memorandum exonerating the authors of all charges of misconduct. Undeterred by the NCCS exoneration, the relevant journal (\"Journal of Biological Chemistry\") withdrew the paper based on its own analysis.\nScientific peers.\nSome academics believe that scientific colleagues who suspect scientific misconduct should take informal action themselves, or report their concerns. This question is of great importance since much research suggests that it is very difficult for people to act or come forward when they see unacceptable behavior, unless they have help from their organizations. A written guide and the existence of a confidential organizational ombudsman may help people who are uncertain about what to do, or afraid of bad consequences for their speaking up.\nJournals.\nJournals are responsible for safeguarding the research record and hence have a critical role in dealing with suspected misconduct. This is recognised by the Committee on Publication Ethics (COPE), which has issued clear guidelines on the form (e.g. retraction) that concerns over the research record should take.\nEvidence emerged in 2012 that journals learning of cases where there is strong evidence of possible misconduct, with issues potentially affecting a large portion of the findings, frequently fail to issue an expression of concern or correspond with the host institution so that an investigation can be undertaken. In one case, \"Nature\" allowed a corrigendum to be published despite clear evidence of image fraud. Subsequent retraction of the paper required the actions of an independent whistleblower.\nThe cases of Joachim Boldt and Yoshitaka Fujii in anaesthesiology focussed attention on the role that journals play in perpetuating scientific fraud as well as how they can deal with it. In the Boldt case, the editors-in-chief of 18 specialist journals (generally anesthesia and intensive care) made a joint statement regarding 88 published clinical trials conducted without Ethics Committee approval. In the Fujii case, involving nearly 200 papers, the journal \"Anesthesia &amp; Analgesia\", which published 24 of Fujii's papers, has accepted that its handling of the issue was inadequate. Following publication of a letter to the editor from Kranke and colleagues in April 2000, along with a non-specific response from Dr. Fujii, there was no follow-up on the allegation of data manipulation and no request for an institutional review of Dr. Fujii's research. \"Anesthesia &amp; Analgesia\" went on to publish 11 additional manuscripts by Dr. Fujii following the 2000 allegations of research fraud, with Editor Steven Shafer stating in March 2012 that subsequent submissions to the journal by Dr. Fujii should not have been published without first vetting the allegations of fraud. In April 2012 Shafer led a group of editors to write a joint statement, in the form of an ultimatum made available to the public, to a large number of academic institutions where Fujii had been employed, offering these institutions the chance to attest to the integrity of the bulk of the allegedly fraudulent papers.\nConsequences.\nConsequences for scientific knowledge.\nThe consequences of scientific fraud vary based on the severity of the fraud, the level of notice it receives, and how long it goes undetected. For cases of fabricated evidence, the consequences can be wide-ranging, with others working to confirm (or refute) the false finding, or with research agendas being distorted to address the fraudulent evidence. The Piltdown Man fraud is a case in point: The significance of the bona-fide fossils that were being found was muted for decades because they disagreed with Piltdown Man and the preconceived notions that those faked fossils supported. In addition, the prominent paleontologist Arthur Smith Woodward spent time at Piltdown each year until he died, trying to find more Piltdown Man remains. The misdirection of resources kept others from taking the real fossils more seriously and delayed the reaching of a correct understanding of human evolution. (The Taung Child, which should have been the death knell for the view that the human brain evolved first, was instead treated very critically because of its disagreement with the Piltdown Man evidence.)\nIn the case of Prof. Don Poldermans, the misconduct occurred in reports of trials of treatment to prevent death and myocardial infarction in patients undergoing operations. The trial reports were relied upon to issue guidelines that applied for many years across North America and Europe.\nIn the case of Dr Alfred Steinschneider, two decades and tens of millions of research dollars were lost trying to find the elusive link between infant sleep apnea, which Steinschneider said he had observed and recorded in his laboratory, and sudden infant death syndrome (SIDS), of which he stated it was a precursor. The cover was blown in 1994, 22 years after Steinschneider's 1972 \"Pediatrics\" paper claiming such an association, when Waneta Hoyt, the mother of the patients in the paper, was arrested, indicted and convicted on five counts of second-degree murder for the smothering deaths of her five children. While that in itself was bad enough, the paper, presumably written as an attempt to save infants' lives, ironically was ultimately used as a defense by parents suspected in multiple deaths of their own children in cases of M\u00fcnchausen syndrome by proxy. The 1972 \"Pediatrics\" paper was cited in 404 papers in the interim and is still listed on PubMed without comment.\nRegulatory violations and consequences.\nhttps:// of the U.S. Nuclear Regulatory Commission (NRC) regulations, addresses the prohibition of certain activities by individual involved in NRC-licensed activities. 10 CFR 50.5 is designed to ensure the safety and integrity of nuclear operations. https://, focuses on the requirements for providing information and data to the NRC. The intent of 10 CFR 50.5 is to deter and penalize intentional wrongdoing (i.e., violations). 10 CFR 50.9 is crucial in maintaining transparency and reliability in the nuclear industry, which effectively emphasizes honesty and integrity in maintaining the safety and security of nuclear operations. Providing false or misleading information or data to the NRC is therefore a violation of 10 CFR 50.9.\nViolation of any of these rules can lead to severe penalties, including termination, fines and criminal prosecution. It can also result in the revocation of licenses or certifications, thereby barring individuals or entities from participating in any NRC-licensed activities in the future.\nConsequences for those who report misconduct.\nThe potentially severe consequences for individuals who are found to have engaged in misconduct also reflect on the institutions that host or employ them and also on the participants in any peer review process that has allowed the publication of questionable research. This means that a range of actors in any case may have a motivation to suppress any evidence or suggestion of misconduct. Persons who expose such cases, commonly called whistleblowers, find themselves open to retaliation by a number of different means. These negative consequences for exposers of misconduct have driven the development of whistle blowers charters \u2013 designed to protect those who raise concerns.\nIncidence.\nThe vast majority of cases of scientific misconduct may not be reported. The number of article retractions in 2022 was nearly 5,500, but Ivan Oransky and Adam Marcus, co-founders of \"Retraction Watch\", estimate that at least 100,000 retractions should occur every year, with only about one in five being due to \"honest error\". One survey of researchers found that 29% of researchers reported misusing authorship at least once during their career, such as giving \"gift authorship\" to people who were not involved in the research.\nA 2025 study by Northwestern university after reviewing aggregated data on the lists of deindexed journals from literature aggregators such as Web of Science, Scopus, Medline, data from Retraction Watch and PubPeer found that while the total number of research publications double every 15 years, articles from suspected research paper mills double every 1.5 years while the number of retracted articles double every 3.3 years and number of articles with PubPeer comments double every 3.6 years.\nRecent work by Ilka Agricola and colleagues has for the first time systematically documented fraudulent practices in mathematical publishing and proposed concrete measures to address them. In \"Fraudulent Publishing in the Mathematical Sciences,\" Agricola et al. analyze how predatory journals, paper mills, and citation cartels exploit bibliometric incentives, warning that unvetted \"proofs\" in low-quality outlets can mislead subsequent research. Published simultaneously on arXiv and in the October 2025 issue of the \"Notices of the American Mathematical Society\", the report highlights alarming patterns\u2014such as Clarivate's 2023 exclusion of mathematics from its Highly Cited Researchers list due to metric gaming\u2014and traces the emergence of systematic fraud in a field previously thought immune to such issues. A follow-up paper, \"How to Fight Fraudulent Publishing in the Mathematical Sciences,\" endorsed by the International Mathematical Union and International Council for Industrial and Applied Mathematics, offers joint recommendations for researchers, institutions, and funders, including discouraging reliance on raw publication and citation counts, promoting expert peer review over bibliometrics, and using curated databases (e.g., zbMATH Open) to vet journals. Commenting on these findings, Agricola emphasized that \"fraudulent publishing undermines trust in science and scientific results and therefore fuels antiscience movements\".\nNotable cases.\nIn 1998 Andrew Wakefield published a fraudulent research paper in \"The Lancet\" claiming links between the MMR vaccine, autism, and inflammatory bowel disease. In 2010, he was found guilty of dishonesty in his research and banned from medicine by the UK General Medical Council following an investigation by Brian Deer of the London \"Sunday Times\".\nThe claims in Wakefield's paper were widely reported, leading to a sharp drop in vaccination rates in the UK and Ireland and outbreaks of mumps and measles. Promotion of the claimed link continues to fuel the anti-vaccination movement.\nIn 2011 Diederik Stapel, a highly regarded Dutch social psychologist, was discovered to have fabricated data in dozens of studies on human behaviour. He has been called \"the biggest con man in academic science\".\nIn 2020, Sapan Desai and his coauthors published two papers in the prestigious medical journals \"The Lancet\" and \"The New England Journal of Medicine\", early in the COVID-19 pandemic. The papers were based on a very large dataset published by Surgisphere, a company owned by Desai. The dataset was exposed as a fabrication, and the papers were soon retracted.\nIn 2024, Eliezer Masliah, head of the Division of Neuroscience at the National Institute on Aging, was suspected of having manipulated and inappropriately reused images in over 100 scientific papers spanning several decades, including those that were used by the FDA to greenlight testing for the experimental drug prasinezumab as a treatment for Parkinson's.\nIn August 2025, a study published in the \"Proceedings of the National Academy of Sciences\" uncovered evidence of large-scale scientific publishing fraud involving networks of editors, authors, and paper mills. The investigation, reported by \"Science\" magazine, suggested that misconduct in academic publishing \"has become an industry\" due to the growing influence of paper mills and brokers.\nProposed responses.\nExposure.\nThere are several tools available to aid in the detection of plagiarism and multiple publication within biomedical literature. One tool developed in 2006 by researchers in Dr. Harold Garner's laboratory at the University of Texas Southwestern Medical Center at Dallas is D\u00e9j\u00e0 vu, an open-access database containing several thousand instances of duplicate publication. All of the entries in the database were discovered through the use of text data mining algorithm eTBLAST, also created in Dr. Garner's laboratory. The creation of D\u00e9j\u00e0 vu and the subsequent classification of several hundred articles contained therein have ignited much discussion in the scientific community concerning issues such as ethical behavior, journal standards, and intellectual copyright. Studies within this database have been published in journals such as \"Nature\" and \"Science\", among others.\nOther tools which may be used to detect fraudulent data include error analysis. Measurements generally have a small amount of error, and repeated measurements of the same item will generally result in slight differences in readings. These differences can be analyzed, and follow certain known mathematical and statistical properties. Should a set of data appear to be too faithful to the hypothesis, i.e., the amount of error that would normally be in such measurements does not appear, a conclusion can be drawn that the data may have been forged. Error analysis alone is typically not sufficient to prove that data have been falsified or fabricated, but it may provide the supporting evidence necessary to confirm suspicions of misconduct.\nData sharing.\nKirby Lee and Lisa Bero suggest, \"Although reviewing raw data can be difficult, time-consuming and expensive, having such a policy would hold authors more accountable for the accuracy of their data and potentially reduce scientific fraud or misconduct.\"\nChanging research valuation.\nSince 2012, the Declaration on Research Assessment (DORA), from San Francisco, gathered many institutions, publishers, and individuals committing to improving the metrics used to assess research and to stop focusing on the journal impact factor.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29538", "revid": "1318449803", "url": "https://en.wikipedia.org/wiki?curid=29538", "title": "Set (card game)", "text": "Pattern-finding real-time card game\nSet (stylized as SET or SET!) is a real-time card game designed by Marsha Falco in 1974 and published by Set Enterprises in 1991. The deck consists of 81 unique cards that vary in four features across three possibilities for each kind of feature: number of shapes (one, two, or three), shape (diamond, squiggle, oval), shading (solid, striped, or open), and color (red, green, or purple). Each possible combination of features (e.g. a card with three striped green diamonds) appears as a card precisely \"once\" in the deck.\nGameplay.\nIn the game, certain combinations of three cards are said to make up a \"set\". For each one of the four categories of features\u2014color, number, shape, and shading\u2014the three cards must display that feature as either a) all the same, or b) all different. Put another way: For each feature the three cards must \"avoid\" having two cards showing one version of the feature and the remaining card showing a different version.\nFor example, 3 solid red diamonds, 2 solid green squiggles, and 1 solid purple oval form a set, because the shadings of the three cards are all the same, while the numbers, the colors, and the shapes among the three cards are all different.\nFor any set, the number of features that are constant (the same on all three cards) and the number of features that differ (different on all three cards) may break down as: all 4 features differing; or 1 feature being constant and 3 differing; or 2 constant and 2 differing; or 3 constant and 1 differing. (All 4 features being constant would imply that the three cards in the set are identical, which is impossible since no cards in the Set deck are identical.)\nHistory.\nThe game evolved out of a coding system that the designer used in her job as a geneticist. The shapes are based on those in ISO 5807. \"Set\" won American Mensa's \"Mensa Select\" award in 1991 and placed 9th in the 1995 \"Deutscher Spiele Preis\".\nThe First Annual National \"Set\" Championship was hosted on January 8, 2025 at the Joint Mathematics Meeting in Seattle, Washington. Approximately 150 players competed, with Taiki Aiba winning first prize: a customized boxing style belt. The next tournament will be held at the Joint Mathematics Meeting 2026, in Washington DC.\nGames.\nSeveral games can be played with these cards, all involving the concept of a \"set\". A set consists of three cards satisfying \"all\" of these conditions:\nThe rules of \"Set\" are summarized by: If you can sort a group of three cards into \"two of ____ and one of ____\", then it is not a set.\nFor example, these three cards form a set:\nGiven any two cards from the deck, there is one and only one other card that forms a set with them.\nIn the standard \"Set\" game, the dealer lays out cards on the table until either twelve are laid down or someone sees a set and calls \"Set!\". The player who called \"Set\" takes the cards in the set, and the dealer continues to deal out cards until twelve are on the table. A player who sees a set among the twelve cards calls \"Set\" and takes the three cards, and the dealer lays three more cards on the table. (To call out \"set\" and not pick one up quickly enough results in a penalty.) There may be no set among the twelve cards; in this case, the dealer deals out three more cards to make fifteen dealt cards, or eighteen or more, as necessary. This process of dealing by threes and finding sets continues until the deck is exhausted and there are no more sets on the table. At this point, whoever has collected the most sets wins.\nVariants were included with the \"Set\" game that involve different mechanics to find sets, as well as different player interaction. Additional variants continue to be created by avid players of the game.\nComplexity.\nUsing a natural generalization of \"Set\", where the number of properties and values vary, it was shown that determining whether a set exists from a collection of dealt cards is NP-complete.\nReviews.\n\"Set\" appears in the February 1992 issue of \"Games\" magazine, where Eric Berlin describes the game as an \"addictive, highly original game of perception and logic,\" and a \"fascinating challenging for either solitaire or competitive play\". It has also appeared in the 1992 Games 100 and \"Family Games: The 100 Best\"."}
{"id": "29539", "revid": "1319084140", "url": "https://en.wikipedia.org/wiki?curid=29539", "title": "Silver Star", "text": "United States military medal for gallantry in action\nThe Silver Star Medal (SSM) is the United States Armed Forces' third-highest military decoration for valor in combat. The Silver Star Medal is awarded primarily to members of the United States Armed Forces for gallantry in action against an enemy of the United States.\nHistory.\nThe Silver Star Medal (SSM) is the successor award to the Citation Star which was established by an Act of Congress on 9 July 1918, during World War I. On 19 July 1932, the secretary of war approved the conversion of the Citation Star to the SSM with the original Citation Star incorporated into the center of the medal.\nAuthorization for the Silver Star Medal was placed into law by an Act of Congress for the U.S. Navy on 7 August 1942, and an Act of Congress for the U.S. Army on 15 December 1942. The current statutory authorization for the medal is Title 10 of the United States Code, \u00a0https:// for the U.S. Army, \u00a0https:// for the U.S. Navy and U.S. Marine Corps, and \u00a0https:// for the U.S. Air Force and U.S. Space Force.\nThe U.S. Army awards the medal as the \"Silver Star\". The U.S. Navy, Marine Corps, Air Force, Space Force, and Coast Guard award the medal as the \"Silver Star Medal\". Since 21 December 2016, the Department of Defense (DoD) refers to the decoration as the \"Silver Star Medal\".\nAward criteria.\nThe Silver Star Medal is awarded for gallantry, so long as the action does not justify the award of one of the next higher valor awards: the Distinguished Service Cross, the Navy Cross, the Air Force Cross, or the Coast Guard Cross. The gallantry displayed must have taken place while in action against an enemy of the United States, while engaged in military operations involving conflict with an opposing foreign force, or while serving with friendly foreign forces engaged in an armed conflict against an opposing armed force in which the United States is not a belligerent party.\nThe Silver Star Medal is awarded for singular acts of valor or heroism over a brief period, such as one or two days of a battle.\nAir Force pilots and combat systems officers and Navy/Marine Corps naval aviators and flight officers flying fighter aircraft, are often considered eligible to receive the Silver Star upon becoming an ace (i.e., having five or more confirmed aerial kills), which entails the pilot and, in multi-seat fighters, the weapons system officer or radar intercept officer, intentionally and successfully risking his life multiple times under combat conditions and emerging victorious. However, during the Vietnam War, the last conflict to produce U.S. fighter aces: an Air Force pilot and two navigators/weapon systems officers (who were later retrained as Air Force pilots), a naval aviator and a naval flight officer/radar intercept officer who had achieved this distinction, were eventually awarded the Air Force Cross and Navy Cross, respectively, in addition to SSMs previously awarded for earlier aerial kills.\nAppearance.\nThe Silver Star Medal is a gold five-pointed star, in circumscribing diameter with a laurel wreath encircling rays from the center and a diameter silver star superimposed in the center. The pendant is suspended from a rectangular shaped metal loop with rounded corners. The reverse has the inscription \"FOR GALLANTRY IN ACTION\". The ribbon is wide and consists of the following stripes: Old Glory red (center stripe); proceeding outward in pairs white; ultramarine blue; white; and ultramarine blue.\nSecond and subsequent awards of the Silver Star Medal are denoted by bronze or silver oak leaf clusters in the Army and Air Force and by gold or silver &lt;templatestyles src=\"Fraction/styles.css\" /&gt;5\u204416 inch stars in the Navy, Marine Corps, and Coast Guard.\nRecipients.\nThe Department of Defense does not keep extensive records for the Silver Star Medal. Independent groups estimate that between 100,000 and 150,000 SSMs have been awarded since the decoration was established. Colonel David Hackworth who was awarded ten SSMs while serving in the Army during the Korean War and Vietnam War, is likely to be the person awarded the most SSMs. General of the Army Douglas MacArthur was awarded seven SSMs for his service in France in World War I from February to November 1918 as a colonel and then brigadier general. Donald H. Russell, a civilian Vought F4U Corsair technical support engineer attached to a Marine Corps fighter wing, received the SSM for his actions aboard after the carrier was attacked by a Japanese dive bomber in March 1945. In the fall of 1944, President Roosevelt's close adviser Harry Hopkins, the U.S. Ambassador in Moscow W. Averell Harriman and a military attach\u00e9 presented the SSM to Soviet Red Army artillery officer Alexei Voloshin, who was the first to cross the Dnieper with his battery and was one of four junior Red Army officers who received the award.\nFemale recipients.\nThree Army nurses that served in World War I were cited in 1919 and 1920 with Citation Stars for gallantry in attending to the wounded while under artillery fire in July 1918. In 2007, it was discovered that they had never been awarded their Citation Stars. The three nurses (Army nurses served without rank until 1920) were awarded the Silver Star Medal posthumously:\nAn unknown number of servicewomen received the award in World War II. Four Army nurses serving in Italy during the war\u2014First Lieutenant Mary Roberts, Second Lieutenant Elaine Roe, Second Lieutenant Rita Virginia Rourke, and Second Lieutenant Ellen Ainsworth (posthumous)\u2014became the first women recipients of the Silver Star, all cited for their bravery in evacuating the 33rd Field Hospital at Anzio on 10 February 1944. Later that same year, Corporal Maggie Leones, a Filipino who later immigrated to the United States, received the medal for clandestine activities on Luzon; as of 2016[ [update]], she is the only female Asian to receive a Silver Star.\nThe next known servicewomen to receive the Silver Star were Army National Guard Sergeant Leigh Ann Hester in 2005, for gallantry during an insurgent ambush on a convoy in Iraq and Army Specialist Monica Lin Brown in March 2008, for extraordinary heroism as a combat medic in the War in Afghanistan.\nOn November 12, 2024, Capt Lacie \u201cSonic\u201d Hester, 494th Fighter Squadron, was awarded the Silver Star for her role in the shootdown of more than 80 Iranian drones launched at Israeli cities, becoming the first female airman and 10th female U.S. military recipient of the Silver Star.\nNotable recipients.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29540", "revid": "1126265", "url": "https://en.wikipedia.org/wiki?curid=29540", "title": "Single UNIX Specification", "text": "Standards for operating systems for using the UNIX trademark\nThe Single UNIX Specification (SUS) is a standard for computer operating systems, compliance with which is required to qualify for using the \"UNIX\" trademark. The standard specifies programming interfaces for the C language, a command-line shell, and user commands. The core specifications of the SUS known as \"Base Specifications\" are developed and maintained by the Austin Group, which is a joint working group of IEEE, ISO/IEC JTC 1/SC 22/WG 15 and The Open Group. If an operating system is submitted to The Open Group for certification and passes conformance tests, then it is deemed to be compliant with a UNIX standard such as UNIX\u00a098 or UNIX\u00a003.\nVery few BSD and Linux-based operating systems are submitted for compliance with the Single UNIX Specification, although system developers generally aim for compliance with POSIX standards, which form the core of the Single UNIX Specification.\nThe latest SUS consists of two parts: the \"base specifications\" technically identical to POSIX, and the X/Open Curses specification.\nSome parts of the SUS are optional.\nHistory.\n1980s: Motivation.\nThe SUS emerged from multiple 1980s efforts to standardize operating system interfaces for software designed for variants of the Unix operating system. The need for standardization arose because enterprises using computers wanted to be able to develop programs that could be used on the computer systems of different manufacturers without reimplementing the programs. Unix was selected as the basis for a standard system interface partly because it was manufacturer-neutral.\nIn 1984, the UNIX user group called /usr/group published the results of their standardization effort for programming interfaces in their 1984 /usr/group standard, which became basis for what would become the POSIX.1-1988 standard.\nIn 1985, AT&amp;T published System V Interface Definition (SVID), a specification of UNIX System V programming interfaces.\n1988: POSIX.\nIn 1988, standardization efforts resulted in IEEE 1003 (also registered as ISO/IEC 9945), or POSIX.1-1988, which loosely stands for Portable Operating System Interface.\n1980s and 1990s: X/Open Portability Guide.\nThe X/Open Portability Guide (XPG) was a precursor to the SUS, published by the X/Open Company, a consortium of companies established in 1984. The guides were published in the following years. \nXPG4 Base included the following documents:\n1990s: Spec 1170.\nIn the early 1990s, a separate effort known as the Common API Specification or Spec 1170 was initiated by several major vendors, who formed the COSE alliance in the wake of the Unix wars. In 1993, Spec 1170 was assigned by COSE to X/Open for fasttrack. In October 1993, a planned transfer of UNIX trademark from Novell to X/Open was announced; it was finalized in 2nd quarter of 1994. Spec 1170 would eventually become the Single Unix Specification.\n1994: Single UNIX Specification.\nIn 1994, the X/Open Company released the Single UNIX Specification. The SUS was made up of documents that were part of the X/Open Common Applications Environment (CAE):\nThis was a repackaging of the X/Open Portability Guide (XPG), Issue 4, Version 2.\nSources differ on whether X/Open Curses, Issue 4, Version 2 was part of this SUS; its copyright date is given as 1996. X/Open Curses, Issue 4 was published in 1995.\nIn October 1994, X/Open indicated they were going to refer to Spec 1170 as '\"Single-Unix\" specification'.\nThe SUS was at the core of the UNIX 95 brand.\nThis version had 1168 programming interfaces.\nThis version of SUS was drawn from the following sources:\n1997: Single UNIX Specification, version 2.\nIn 1996, X/Open merged with Open Software Foundation (OSF) to form The Open Group.\nIn 1997, the Open Group released the Single UNIX Specification, Version 2.\nThis specification consisted of:\nand was at the core of the UNIX 98 brand.\nThis version had 1434 programming interfaces.\n2001: Single UNIX Specification, version 3, POSIX.1-2001.\nBeginning in 1998, a joint working group of IEEE, ISO JTC 1 SC22 and The Open Group known as the Austin Group began to develop the combined standard that would be known as the core of Single UNIX Specification, Version 3 and as POSIX.1-2001. It was released on January 30, 2002.\nThis SUS consisted of:\nand is at the core of the UNIX 03 brand.\nThe Base Specifications are technically identical to POSIX.1-2001, which is IEEE Std 1003.1-2001.\nThis version had 1742 programming interfaces.\nAn authorized guide is available for the version.\n2004 Edition.\nIn 2004, a new edition of the POSIX.1-2001 standard was released, incorporating two technical corrigenda. It is called IEEE Std 1003.1, 2004 Edition. Some informally call it POSIX.1-2004, but this is not an official identification.\n2008: Single UNIX Specification, version 4, POSIX.1-2008.\nIn December 2008, the Austin Group published a new major revision of SUS and POSIX. This is the Single UNIX Specification, Version 4 (SUSv4).\nThis SUS consists of:\nThe Base Specifications are technically identical to POSIX.1-2008, which is IEEE Std 1003.1-2008.\nThis version had 1833 interfaces, of which 1191 were in the System Interfaces section.\n2013 Edition.\nTechnical Corrigendum 1 mostly targeted internationalization, and also introduced a role-based access model. A trademark \"UNIX V7\" (not to be confused with V7 UNIX, the version of Research Unix from 1979) was created to mark compliance with SUS Version 4.\n2016 Edition.\nTechnical Corrigendum 2 was published in September 2016, leading into \"IEEE Std 1003.1-2008, 2016 Edition\" and \"Single UNIX Specification, Version 4, 2016 Edition\".\n2018 Edition, POSIX.1-2017.\nIn January 2018, an \"administrative rollup\" edition was released. It incorporates Single UNIX Specification version 4 TC1 and TC2, and is technically identical to the 2016 edition.\nThe Base Specifications are technically identical to POSIX.1-2017, which is IEEE Std 1003.1-2017.\nSpecification.\nSUSv3 totals some 3700 pages, which are divided into four main parts:\nThe standard user command line and scripting interface is the POSIX shell, an extension of the Bourne Shell based on an early version of the Korn Shell. Other user-level programs, services and utilities include awk, echo, ed, vi, and hundreds of others. Required program-level services include basic I/O (file, terminal, and network) services. A test suite accompanies the standard. It is called PCTS or the POSIX Certification Test Suite.\nAdditionally, SUS includes CURSES (XCURSES) specification, which specifies 372 functions and 3 header files. All in all, SUSv3 specifies 1742 interfaces.\nNote that a system need not include source code derived in any way from AT&amp;T Unix to meet the specification. For instance, IBM OS/390, now z/OS, qualifies as UNIX despite having no code in common.\nMarks for compliant systems.\nThere are five official marks for conforming systems:\nCompliance.\nCurrently registered UNIX systems.\nAIX.\nAIX version 7, at either 7.1 TL5 (or later) or 7.2 TL2 (or later) are registered as UNIX 03 compliant. AIX version 7, at 7.2 TL5 (or later) are registered as UNIX V7 compliant. Older versions were previously certified to the UNIX 95 and UNIX 98 marks.\nHP-UX.\nHP-UX 11i V3 Release B.11.31 is registered as UNIX 03 compliant. Previous releases were registered as UNIX 95.\nmacOS.\nApple macOS (formerly known as Mac\u00a0OS\u00a0X and OS\u00a0X) is registered as UNIX 03 compliant. The first version registered was Mac\u00a0OS\u00a0X 10.5 Leopard, certified on October 26, 2007 (on x86 systems). All versions of macOS from Mac OS X Leopard to macOS 10.15 Catalina, except for OS X Lion, have been registered on Intel-based systems, and all versions from macOS 11 Big Sur, the successor to macOS Catalina, up to macOS 26 Tahoe have been registered on both x86-64 and ARM64 systems.\nXinuos.\nUnixWare 7.1.3 and later is registered as UNIX 95 compliant.\nOpenServer 5 and 6 are registered as UNIX 93 compliant.\nz/OS.\nIBM z/OS 1.2 and higher is registered as UNIX 95 compliant.\nz/OS 1.9, released on September 28, 2007, and subsequent releases \"better align\" with UNIX 03.\nPreviously registered UNIX systems.\nEulerOS.\nEulerOS 2.0 for the x86-64 architecture was registered as UNIX\u00a003 compliant. The UNIX\u00a003 conformance statement shows that the standard C compiler is from the GNU Compiler Collection (gcc), and that the system is a Linux distribution of the Red Hat Enterprise Linux family. The UNIX 03 certification expired in September 2022 and has not been renewed.\nFTX.\nStratus Technologies DNCP Series servers running FTX Release 3 were registered as UNIX 93 compliant.\nInspur K-UX.\nInspur K-UX 2.0 and 3.0 for the x86-64 architecture were certified as UNIX\u00a003 compliant. The UNIX\u00a003 conformance statement for Inspur K-UX 2.0 and 3.0 shows that the standard C compiler is from the GNU Compiler Collection (gcc), and that the system is a Linux distribution of the Red Hat family.\nIRIX.\nSGI IRIX 6.5 was registered as UNIX 95 compliant.\nOS/390.\nIBM OS/390 was registered as UNIX 95 compliant beginning with the V2R4 release.\nReliant UNIX.\nThe last Reliant UNIX versions were registered as UNIX 95 compliant (XPG4 hard branding).\nSolaris.\nSolaris 11.4 was previously registered as UNIX v7 compliant in 2018. Solaris 11 and Solaris 10 were registered as UNIX 03 compliant on 32-bit and 64-bit x86 (X86-64) and SPARC systems. Solaris 8 and 9 were registered as UNIX 98 compliant on 32-bit x86 and SPARC systems; 64-bit x86 systems were not supported. Solaris 2.4 and 2.6, on both x86 and SPARC, were certified to the UNIX 93 and UNIX 95 marks respectively.\nSolaris 2.5.1 was also registered as UNIX 95 compliant on the PReP PowerPC platform in 1996, but the product was withdrawn before more than a few dozen copies had been sold.\nTru64 UNIX.\nTru64 UNIX V5.1A and later were registered as UNIX 98 compliant.\nOther.\nOther operating systems previously registered as UNIX 95 or UNIX 93 compliant:\nNon-registered Unix-like systems.\nDevelopers and vendors of Unix-like operating systems such as Linux, FreeBSD, and MINIX typically do not certify their distributions and do not install full POSIX utilities by default.\nFor Linux, the pax command is usually not installed; furthermore, the pax command packages available for Linux often lack the pax file format support required by POSIX. Sometimes, SUS compliance can be improved by installing additional packages, but very few Linux systems can be configured to be completely conformant. The Linux Standard Base was formed in 2001 as an attempt to standardize the internal structures of Linux-based systems for increased compatibility. It is based on the POSIX specifications, the Single UNIX Specification, and other open standards, and also extends them in several areas; but there are some conflicts between the LSB and the POSIX standards. Few Linux distributions actually go through certification as LSB compliant.\nDarwin, the open source subset of macOS, has behavior that can be set to comply with UNIX\u00a003. Darwin uses a 4.4BSD-derived pax command, which lacks multibyte support for filenames.\nFreeBSD previously had a \"C99 and POSIX Conformance Project\" which aimed for compliance with a subset of the Single UNIX Specification, and documentation where there were differences. The FreeBSD pax command, derived from 4.4BSD, does not fully support the pax file format. pax and ustar in-archive format use the same with slightly different defaults (5120 block size vs 10240 block size); however, FreeBSD's pax lacks the extended PAX headers used for extended character set support. FreeBSD man pages sometimes indicate deviations from POSIX and thus SUS in their STANDARDS sections.\nOpenBSD man pages sometimes indicate deviations from POSIX and thus SUS in their STANDARDS sections.\nMINIX pax command does not support the pax file format and thereby fails POSIX.1-2001.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29544", "revid": "35238068", "url": "https://en.wikipedia.org/wiki?curid=29544", "title": "Scientific Revolution", "text": "Emergence of modern science in the early modern period\nThe Scientific Revolution was a series of events that marked the emergence of modern science during the early modern period, when developments in mathematics, physics, astronomy, biology (including human anatomy) and transformed the views of society about nature.\nIntroduction.\nGreat advances in science have been termed \"revolutions\" since the 18th century. For example, in 1747, the French mathematician Alexis Clairaut wrote that \"Newton was said in his own life to have created a revolution\". The word was also used in the preface to Antoine Lavoisier's 1789 work announcing the discovery of oxygen. \"Few revolutions in science have immediately excited so much general notice as the introduction of the theory of oxygen ... Lavoisier saw his theory accepted by all the most eminent men of his time, and established over a great part of Europe within a few years from its first promulgation.\"\nIn the 19th century, William Whewell described the revolution in science itself \u2013 the scientific method \u2013 that had taken place in the 15th\u201316th century. \"Among the most conspicuous of the revolutions which opinions on this subject have undergone, is the transition from an implicit trust in the internal powers of man's mind to a professed dependence upon external observation; and from an unbounded reverence for the wisdom of the past, to a fervid expectation of change and improvement.\" This gave rise to the common view of the Scientific Revolution today:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;A new view of nature emerged, replacing the Greek view that had dominated science for almost 2,000 years. Science became an autonomous discipline, distinct from both philosophy and technology, and came to be regarded as having utilitarian goals.\nThe Scientific Revolution is traditionally assumed to start with the Copernican Revolution (initiated in 1543) and to be complete in the \"grand synthesis\" of Isaac Newton's 1687 \"Principia\". Much of the change of attitude came from Francis Bacon whose \"confident and emphatic announcement\" in the modern progress of science inspired the creation of scientific societies such as the Royal Society, and Galileo Galilei, who championed Copernican heliocentrism and developed the science of motion.\nIn the 20th century, Alexandre Koyr\u00e9 introduced the term \"scientific revolution\", centering his analysis on Galileo. The term was popularized by Herbert Butterfield in his \"Origins of Modern Science\". Thomas Kuhn's 1962 work \"The Structure of Scientific Revolutions\" emphasizes that different theoretical frameworks\u2014such as Einstein's theory of relativity and Newton's theory of gravity, which it replaced\u2014cannot be directly compared without meaning loss.\nSignificance.\nThe period saw a fundamental transformation in scientific ideas across mathematics, physics, astronomy, and biology in institutions supporting scientific investigation and in the more widely held picture of the universe. The Scientific Revolution led to the establishment of several modern sciences. In 1984, Joseph Ben-David wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Rapid accumulation of knowledge, which has characterized the development of science since the 17th century, had never occurred before that time. The new kind of scientific activity emerged only in a few countries of Western Europe, and it was restricted to that small area for about two hundred years. (Since the 19th century, scientific knowledge has been assimilated by the rest of the world).\nMany contemporary writers and modern historians claim that there was a revolutionary change in world view. In 1611 English poet John Donne wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[The] new Philosophy calls all in doubt,\nThe Element of fire is quite put out;\nThe Sun is lost, and th'earth, and no man's wit\nCan well direct him where to look for it.\nButterfield was less disconcerted but nevertheless saw the change as fundamental:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Since that revolution turned the authority in English not only of the Middle Ages but of the ancient world\u2014since it started not only in the eclipse of scholastic philosophy but in the destruction of Aristotelian physics\u2014it outshines everything since the rise of Christianity and reduces the Renaissance and Reformation to the rank of mere episodes, mere internal displacements within the system of medieval Christendom... [It] looms so large as the real origin both of the modern world and of the modern mentality that our customary periodization of European history has become an anachronism and an encumbrance.\nHistorian Peter Harrison attributes Christianity to having contributed to the rise of the Scientific Revolution:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;historians of science have long known that religious factors played a significantly positive role in the emergence and persistence of modern science in the West. Not only were many of the key figures in the rise of science individuals with sincere religious commitments, but the new approaches to nature that they pioneered were underpinned in various ways by religious assumptions. ... Yet, many of the leading figures in the scientific revolution imagined themselves to be champions of a science that was more compatible with Christianity than the medieval ideas about the natural world that they replaced.\nDavid Wootton calls the Scientific Revolution \"the most important transformation in human history\" since the Neolithic Revolution. There continues to be scholarly engagement regarding the boundaries of the Scientific Revolution and its chronology. The subsequent Age of Enlightenment saw the concept of a scientific revolution emerge in the 18th-century work of Jean Sylvain Bailly, who described a two-stage process of sweeping away the old and establishing the new.\nAncient, medieval and Renaissance background.\nThe Scientific Revolution was built upon the foundation of ancient Greek learning and science in the Middle Ages, as it had been elaborated and further developed by Roman/Byzantine science and medieval Islamic science. Some scholars have noted a direct tie between \"particular aspects of traditional Christianity\" and the rise of science. The \"Aristotelian tradition\" was still an important intellectual framework in the 17th century, although by that time natural philosophers had moved away from much of it. Key scientific ideas dating back to classical antiquity had changed drastically over the years and in many cases had been discredited. The ideas that remained, which were transformed fundamentally during the Scientific Revolution, include:\nAncient precedent existed for alternative theories and developments which prefigured later discoveries in the area of physics and mechanics; but in light of the limited number of works to survive translation in a period when many books were lost to warfare, such developments remained obscure for centuries and are traditionally held to have had little effect on the re-discovery of such phenomena; whereas the invention of the printing press made the wide dissemination of such incremental advances of knowledge commonplace. Meanwhile, however, significant progress in geometry, mathematics, and astronomy was made in medieval times.\nThe Scientific Revolution was enabled by advances in book production. Before the advent of the printing press, introduced in Europe in the 1440s by Johannes Gutenberg, there was no mass market on the continent for scientific treatises, as there had been for religious books. Printing decisively changed the way scientific knowledge was created, as well as how it was disseminated. It enabled accurate diagrams, maps, anatomical drawings, and representations of flora and fauna to be reproduced, and printing made scholarly books more widely accessible, allowing researchers to consult ancient texts freely and to compare their own observations with those of fellow scholars. Although printers' blunders still often resulted in the spread of false data (for instance, in Galileo's \"Sidereus Nuncius\" (The Starry Messenger), published in Venice in 1610, his telescopic images of the lunar surface mistakenly appeared back to front), the development of engraved metal plates allowed accurate visual information to be made permanent, a change from previously, when woodcut illustrations deteriorated through repetitive use. The ability to access previous scientific research meant that researchers did not have to always start from scratch in making sense of their own observational data.\nIt is also true that many of the important figures of the Scientific Revolution shared in the general Renaissance respect for ancient learning and cited ancient pedigrees for their innovations. Nicolaus Copernicus, Galileo, Johannes Kepler and Newton all traced different ancient and medieval ancestries for the heliocentric system. In the Axioms Scholium of his \"Principia,\" Newton said its axiomatic three laws of motion were already accepted by mathematicians such as Christiaan Huygens, Wallace, Wren and others. While preparing a revised edition of his \"Principia\", Newton attributed his law of gravity and his first law of motion to a range of historical figures.\nDespite these qualifications, the standard theory of the history of the Scientific Revolution claims that the 17th century was a period of revolutionary scientific changes. Not only were there revolutionary theoretical and experimental developments, but that even more importantly, the way in which scientists worked was radically changed. For instance, although intimations of the concept of inertia are suggested sporadically in ancient discussion of motion, the salient point is that Newton's theory differed from ancient understandings in key ways, such as an external force being a requirement for violent motion in Aristotle's theory.\nScientific method.\nUnder the scientific method as conceived in the 17th century, natural and artificial circumstances were set aside as a research tradition of systematic experimentation was slowly accepted by the scientific community. The philosophy of using an inductive and mathematical approach to obtain knowledge\u2014to abandon assumption and to attempt to observe with an open mind was championed by Ren\u00e9 Descartes, Galileo, and Bacon\u2014in contrast with the earlier, Aristotelian approach of deduction, by which analysis of known facts produced further understanding. In practice, many scientists and philosophers believed that a healthy mix of both was needed\u2014the willingness to question assumptions, yet also to interpret observations assumed to have some degree of validity.\nBy the end of the Scientific Revolution, the qualitative world of book-reading philosophers had been changed into a mechanical, mathematical world to be known through experimental research. Though it is certainly not true that Newtonian science was like modern science in all respects, it conceptually resembled ours in many ways. Many of the hallmarks of modern science, especially with regard to its institutionalization and professionalization, did not become standard until the mid-19th century.\nEmpiricism.\nThe Aristotelian scientific tradition's primary mode of interacting with the world was through observation and searching for \"natural\" circumstances through reasoning. Coupled with this approach was the belief that rare events which seemed to contradict theoretical models were aberrations, telling nothing about nature as it \"naturally\" was. During the Scientific Revolution, changing perceptions about the role of the scientist in respect to nature, the value of evidence, experimental or observed, led towards a scientific methodology in which empiricism played a large role.\nBy the start of the Scientific Revolution, empiricism had already become an important component of science and natural philosophy. Prior thinkers, including the early-14th-century nominalist philosopher William of Ockham, had begun the intellectual movement toward empiricism. The term British empiricism came into use to describe philosophical differences perceived between two of its founders Francis Bacon, described as empiricist, and Ren\u00e9 Descartes, who was described as a rationalist. Thomas Hobbes, George Berkeley, and David Hume were the philosophy's primary exponents who developed a sophisticated empirical tradition as the basis of human knowledge.\nAn influential formulation of empiricism was John Locke's \"An Essay Concerning Human Understanding\" (1689), in which he maintained that the only true knowledge that could be accessible to the human mind was that which was based on experience. He wrote that the human mind was created as a \"tabula rasa\", a \"blank tablet,\" upon which sensory impressions were recorded and built up knowledge through a process of reflection.\nBacon's contributions.\nThe philosophical underpinnings of the Scientific Revolution were laid out by Francis Bacon, who has been called the father of empiricism. His works established and popularised inductive methodologies for scientific inquiry, often called the \"Baconian method\", or simply the scientific method. His demand for a planned procedure of investigating all things natural marked a new turn in the rhetorical and theoretical framework for science, much of which still surrounds conceptions of proper methodology today.\nBacon proposed a great reformation of all process of knowledge for the advancement of learning divine and human, which he called \"Instauratio Magna\" (The Great Instauration). For Bacon, this reformation would lead to a great advancement in science and a progeny of inventions that would relieve mankind's miseries and needs. His \"Novum Organum\" was published in 1620, in which he argues man is \"the minister and interpreter of nature,\" \"knowledge and human power are synonymous,\" \"effects are produced by the means of instruments and helps,\" \"man while operating can only apply or withdraw natural bodies; nature internally performs the rest,\" and \"nature can only be commanded by obeying her\". Here is an abstract of the philosophy of this work, that by the knowledge of nature and the using of instruments, man can govern or direct the natural work of nature to produce definite results. Therefore, that man, by seeking knowledge of nature, can reach power over it\u2014and thus reestablish the \"Empire of Man over creation,\" which had been lost by the Fall together with man's original purity. In this way, he believed, would mankind be raised above conditions of helplessness, poverty and misery, while coming into a condition of peace, prosperity and security.\nFor this purpose of obtaining knowledge of and power over nature, Bacon outlined in this work a new system of logic he believed to be superior to the old ways of syllogism, developing his scientific method, consisting of procedures for isolating the formal cause of a phenomenon (heat, for example) through eliminative induction. For him, the philosopher should proceed through inductive reasoning from fact to axiom to physical law. Before beginning this induction, though, the enquirer must free his or her mind from certain false notions or tendencies which distort the truth. In particular, he found that philosophy was too preoccupied with words, particularly discourse and debate, rather than actually observing the material world: \"For while men believe their reason governs words, in fact, words turn back and reflect their power upon the understanding, and so render philosophy and science sophistical and inactive.\"\nBacon considered that it is of greatest importance to science not to keep doing intellectual discussions or seeking merely contemplative aims, but that it should work for the bettering of mankind's life by bringing forth new inventions, even stating \"inventions are also, as it were, new creations and imitations of divine works\". He explored the far-reaching and world-changing character of inventions, such as the printing press, gunpowder and the compass. Despite his influence on scientific methodology, he rejected correct novel theories such as William Gilbert's magnetism, Copernicus's heliocentrism, and Kepler's laws of planetary motion.\nScientific experimentation.\nBacon first described the experimental method.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;There remains simple experience; which, if taken as it comes, is called accident, if sought for, experiment. The true method of experience first lights the candle [hypothesis], and then by means of the candle shows the way [arranges and delimits the experiment]; commencing as it does with experience duly ordered and digested, not bungling or erratic, and from it deducing axioms [theories], and from established axioms again new experiments.\u2014\u200a\nGilbert was an early advocate of this method. He passionately rejected both the prevailing Aristotelian philosophy and the scholastic method of university teaching. His book \"De Magnete\" was written in 1600, and he is regarded by some as the father of electricity and magnetism. In this work, he describes many of his experiments with his model Earth called the terrella. From these experiments, he concluded that the Earth was itself magnetic and that this was the reason compasses point north.\n\"De Magnete\" was influential because of the inherent interest of its subject matter as well as for the rigorous way in which Gilbert describes his experiments and his rejection of ancient theories of magnetism. According to Thomas Thomson, \"Gilbert['s]... book on magnetism published in 1600, is one of the finest examples of inductive philosophy that has ever been presented to the world. It is the more remarkable, because it preceded the \"Novum Organum\" of Bacon, in which the inductive method of philosophizing was first explained.\"\nGalileo Galilei has been called the \"father of modern observational astronomy,\" the \"father of modern physics,\" the \"father of science,\" and \"the Father of Modern Science.\" His original contributions to the science of motion were made through an innovative combination of experiment and mathematics. Galileo was one of the first modern thinkers to clearly state that the laws of nature are mathematical. In \"The Assayer\" he wrote \"Philosophy is written in this grand book, the universe\u00a0... It is written in the language of mathematics, and its characters are triangles, circles, and other geometric figures;...\" His mathematical analyses are a further development of a tradition employed by late scholastic natural philosophers, which Galileo learned when he studied philosophy. He ignored Aristotelianism. In broader terms, his work marked another step towards the eventual separation of science from both philosophy and religion; a major development in human thought. He was often willing to change his views in accordance with observation. In order to perform his experiments, Galileo had to set up standards of length and time, so that measurements made on different days and in different laboratories could be compared in a reproducible fashion. This provided a reliable foundation on which to confirm mathematical laws using inductive reasoning.\nGalileo showed an appreciation for the relationship between mathematics, theoretical physics, and experimental physics. He understood the parabola, both in terms of conic sections and in terms of the ordinate (y) varying as the square of the abscissa (x). Galilei further asserted that the parabola was the theoretically ideal trajectory of a uniformly accelerated projectile in the absence of friction and other disturbances. He conceded that there are limits to the validity of this theory, noting on theoretical grounds that a projectile trajectory of a size comparable to that of the Earth could not possibly be a parabola, but he nevertheless maintained that for distances up to the range of the artillery of his day, the deviation of a projectile's trajectory from a parabola would be only very slight.\nMathematization.\nScientific knowledge, according to the Aristotelians, was concerned with establishing true and necessary causes of things. To the extent that medieval natural philosophers used mathematical problems, they limited social studies to theoretical analyses of local speed and other aspects of life. The actual measurement of a physical quantity, and the comparison of that measurement to a value computed on the basis of theory, was largely limited to the mathematical disciplines of astronomy and optics in Europe.\nIn the 16th and 17th centuries, European scientists began increasingly applying quantitative measurements to the measurement of physical phenomena on the Earth. Galileo maintained strongly that mathematics provided a kind of necessary certainty that could be compared to God's: \"...with regard to those few [mathematical propositions] which the human intellect does understand, I believe its knowledge equals the Divine in objective certainty...\"\nGalileo anticipates the concept of a systematic mathematical interpretation of the world in his book \"Il Saggiatore\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Philosophy [i.e., physics] is written in this grand book\u2014I mean the universe\u2014which stands continually open to our gaze, but it cannot be understood unless one first learns to comprehend the language and interpret the characters in which it is written. It is written in the language of mathematics, and its characters are triangles, circles, and other geometrical figures, without which it is humanly impossible to understand a single word of it; without these, one is wandering around in a dark labyrinth.In 1591, Fran\u00e7ois Vi\u00e8te published \"In Artem Analyticem Isagoge\", which gave the first symbolic notation of parameters in algebra. In 1637, Ren\u00e9 Descartes greatly improved the scope and formalization of algebra in La G\u00e9om\u00e9trie. Newton's development of infinitesimal calculus opened up new applications of the methods of mathematics to science. Newton taught that scientific theory should be coupled with rigorous experimentation, which became the keystone of modern science.\nMechanical philosophy.\nAristotle recognized four kinds of causes, and where applicable, the most important of them is the \"final cause\". The final cause was the aim, goal, or purpose of some natural process or man-made thing. Until the Scientific Revolution, it was very natural to see such aims, such as a child's growth, for example, leading to a mature adult. Intelligence was assumed only in the purpose of man-made artifacts; it was not attributed to other animals or to nature.\nIn \"mechanical philosophy\" no field or action at a distance is permitted, particles or corpuscles of matter are fundamentally inert. Motion is caused by direct physical collision. Where natural substances had previously been understood organically, the mechanical philosophers viewed them as machines. As a result, Newton's theory seemed like some kind of throwback to \"spooky action at a distance\". According to Thomas Kuhn, Newton and Descartes held the teleological principle that God conserved the amount of motion in the universe:\nGravity, interpreted as an innate attraction between every pair of particles of matter, was an occult quality in the same sense as the scholastics' \"tendency to fall\" had been... By the mid eighteenth century that interpretation had been almost universally accepted, and the result was a genuine reversion (which is not the same as a retrogression) to a scholastic standard. Innate attractions and repulsions joined size, shape, position and motion as physically irreducible primary properties of matter.\nNewton had also specifically attributed the inherent power of inertia to matter, against the mechanist thesis that matter has no inherent powers. But whereas Newton vehemently denied gravity was an inherent power of matter, his collaborator Roger Cotes made gravity also an inherent power of matter, as set out in his famous preface to the \"Principia's\" 1713 second edition which he edited, and contradicted Newton. And it was Cotes's interpretation of gravity rather than Newton's that came to be accepted.\nInstitutionalization.\nThe first moves towards the institutionalization of scientific investigation and dissemination took the form of the establishment of societies where new discoveries were aired, discussed, and published. The first scientific society to be established was the Royal Society of London. This grew out of an earlier group, centered around Gresham College in the 1640s and 1650s. According to a history of the college:\nThe scientific network which centered on Gresham College played a crucial part in the meetings which led to the formation of the Royal Society.\nThese physicians and natural philosophers were influenced by the \"new science\", as promoted by Bacon in his \"New Atlantis\", from approximately 1645 onwards. A group known as \"The Philosophical Society of Oxford\" was run under a set of rules still retained by the Bodleian Library.\nOn 28 November 1660, the \"1660 committee of 12\" announced the formation of a \"College for the Promoting of Physico-Mathematical Experimental Learning\", which would meet weekly to discuss science and run experiments. At the second meeting, Robert Moray announced that King Charles approved of the gatherings, and a royal charter was signed on 15 July 1662 creating the \"Royal Society of London\", with Lord Brouncker serving as the first president. A second royal charter was signed on 23 April 1663, with the king noted as the founder and with the name of \"the Royal Society of London for the Improvement of Natural Knowledge\"; Robert Hooke was appointed as curator of experiments in November. This initial royal favour has continued, and since then every monarch has been the patron of the society.\nThe society's first secretary was Henry Oldenburg. Its early meetings included experiments performed first by Hooke and then by Denis Papin, who was appointed in 1684. These experiments varied in their subject area and were important in some cases and trivial in others. The society began publication of \"Philosophical Transactions\" from 1665, the oldest and longest-running scientific journal in the world, which established the important principles of scientific priority and peer review.\nThe French established the Academy of Sciences in 1666. In contrast to the private origins of its British counterpart, the academy was founded as a government body by Jean-Baptiste Colbert. Its rules were set down in 1699 by King Louis XIV, when it received the name of 'Royal Academy of Sciences' and was installed in the Louvre in Paris.\nNew ideas.\nAs the Scientific Revolution was not marked by any single change, the following new ideas contributed to what is called the Scientific Revolution. Many of them were revolutions in their own fields.\nAstronomy.\nHeliocentrism.\nFor almost five millennia, the geocentric model of the Earth as the center of the universe had been accepted by all but a few astronomers. In Aristotle's cosmology, Earth's central location was perhaps less significant than its identification as a realm of imperfection, inconstancy, irregularity, and change, as opposed to the \"heavens\" (Moon, Sun, planets, stars), which were regarded as perfect, permanent, unchangeable, and in religious thought, the realm of heavenly beings. The Earth was even composed of different material, the four elements \"earth\", \"water\", \"fire\", and \"air\", while sufficiently far above its surface (roughly the Moon's orbit), the heavens were composed of a different substance called \"aether\". The heliocentric model that replaced it involved the radical displacement of the Earth to an orbit around the Sun; sharing a placement with the other planets implied a universe of heavenly components made from the same changeable substances as the Earth. Heavenly motions no longer needed to be governed by a theoretical perfection, confined to circular orbits.\nCopernicus' 1543 work on the heliocentric model of the Solar System tried to demonstrate that the Sun was the center of the universe. Few were bothered by this suggestion, and the pope and several archbishops were interested enough by it to want more detail. His model was later used to create the calendar of Pope Gregory XIII. However, the idea that the Earth moved around the Sun was doubted by most of Copernicus' contemporaries. It contradicted not only empirical observation, due to the absence of an observable stellar parallax, but more significantly at the time, the authority of Aristotle. The discoveries of Kepler and Galileo gave the theory credibility. \nKepler was an astronomer who is best known for his laws of planetary motion, and Kepler\u00b4s books \"Astronomia nova\", \"Harmonice Mundi\", and \"Epitome Astronomiae Copernicanae\" influenced among others Isaac Newton, providing one of the foundations for his theory of universal gravitation. One of the most significant books in the history of astronomy, the Astronomia nova provided strong arguments for heliocentrism and contributed valuable insight into the movement of the planets. This included the first mention of the planets' elliptical paths and the change of their movement to the movement of free floating bodies as opposed to objects on rotating spheres. It is recognized as one of the most important works of the Scientific Revolution. Using the accurate observations of Tycho Brahe, Kepler proposed that the planets move around the Sun not in circular orbits but in elliptical ones. Together with Kepler\u00b4s other laws of planetary motion, this allowed him to create a model of the Solar System that was an improvement over Copernicus' original system. \nGalileo's main contributions to the acceptance of the heliocentric system were his mechanics, the observations he made with his telescope, as well as his detailed presentation of the case for the system. Using an early theory of inertia, Galileo could explain why rocks dropped from a tower fall straight down even if the Earth rotates. His observations of the moons of Jupiter, the phases of Venus, the spots on the Sun, and mountains on the Moon all helped to discredit the Aristotelian philosophy and the Ptolemaic theory of the Solar System. Through their combined discoveries, the heliocentric system gained support, and at the end of the 17th century it was generally accepted by astronomers.\nThis work culminated in the work of Newton, and his \"Principia\" formulated the laws of motion and universal gravitation which dominated scientists' view of the physical universe for the next three centuries. By deriving Kepler's laws of planetary motion from his mathematical description of gravity, and then using the same principles to account for the trajectories of comets, the tides, the precession of the equinoxes, and other phenomena, Newton removed the last doubts about the validity of the heliocentric model of the cosmos. This work also demonstrated that the motion of objects on Earth and of celestial bodies could be described by the same principles. His prediction that the Earth should be shaped as an oblate spheroid was later vindicated by other scientists. His laws of motion were to be the solid foundation of mechanics; his law of universal gravitation combined terrestrial and celestial mechanics into one great system that seemed to be able to describe the whole world in mathematical formulae.\nGravitation.\nNewton also developed the theory of gravitation. In 1679, Newton began to consider gravitation and its effect on the orbits of planets with reference to Kepler's laws of planetary motion. This followed stimulation by a brief exchange of letters in 1679\u201380 with Hooke, opened a correspondence intended to elicit contributions from Newton to Royal Society transactions. Newton's reawakening interest in astronomical matters received further stimulus by the appearance of a comet in the winter of 1680\u201381, on which he corresponded with John Flamsteed. After the exchanges with Hooke, Newton worked out proof that the elliptical form of planetary orbits would result from a centripetal force inversely proportional to the square of the radius vector. Newton communicated his results to Edmond Halley and to the Royal Society in \"De motu corporum in gyrum\" in 1684. This tract contained the nucleus that Newton developed and expanded to form the \"Principia\".\nThe \"Principia\" was published on 5 July 1687 with encouragement and financial help from Halley. In this work, Newton states the three universal laws of motion that contributed to many advances during the Industrial Revolution which soon followed and were not to be improved upon for more than 200 years. Many of these advancements continue to be the underpinnings of non-relativistic technologies in the modern world. He used the Latin word \"gravitas\" (weight) for the effect that would become known as gravity and defined the law of universal gravitation.\nNewton's postulate of an invisible force able to act over vast distances led to him being criticised for introducing \"occult agencies\" into science. Later, in the second edition of the \"Principia\" (1713), Newton firmly rejected such criticisms in a concluding \"General Scholium,\" writing that it was enough that the phenomena implied a gravitational attraction, as they did; but they did not so far indicate its cause, and it was both unnecessary and improper to frame hypotheses of things that were not implied by the phenomena. (Here Newton used what became his famous expression \"hypotheses non fingo\").\nBiology and medicine.\nThe writings of Greek physician Galen had dominated European medical thinking for over a millennium. The Flemish scholar Andreas Vesalius demonstrated mistakes in Galen's ideas. Vesalius dissected human corpses, whereas Galen dissected animal corpses. Published in 1543, Vesalius' \"De humani corporis fabrica\" was a groundbreaking work of human anatomy. It emphasized the priority of dissection and what has come to be called the \"anatomical\" view of the body, seeing human internal functioning as an essentially corporeal structure filled with organs arranged in three-dimensional space. This was in stark contrast to many of the anatomical models used previously, which had strong Galenic/Aristotelean elements, as well as elements of astrology.\nBesides the first good description of the sphenoid bone, Vesalius showed that the sternum consists of three portions and the sacrum of five or six; and he described accurately the vestibule in the interior of the temporal bone. He verified the observation of anatomist Charles Estienne on the valves of the hepatic veins, described the vena azygos, and discovered the canal which passes in the fetus between the umbilical vein and the vena cava, since named ductus venosus. He described the omentum and its connections with the stomach, the spleen and the colon; gave the first correct views of the structure of the pylorus; observed the small size of the caecal appendix in man; gave the first good account of the mediastinum and pleura and the fullest description of the anatomy of the brain yet advanced.\nBefore Vesalius, the anatomical notes by Alessandro Achillini demonstrate a detailed description of the human body and compare what he had found during his dissections to what others like Galen and Avicenna had found and notes their similarities and differences. Niccol\u00f2 Massa was an Italian anatomist who wrote an early anatomy text \"Anatomiae Libri Introductorius\" in 1536, described the cerebrospinal fluid and was the author of several medical works. Jean Fernel was a French physician who introduced the term \"physiology\" to describe the study of the body's function and was the first person to describe the spinal canal.\nFurther groundbreaking work was carried out by William Harvey, who published \"De Motu Cordis\" in 1628. Harvey made a detailed analysis of the overall structure of the heart, going on to an analysis of the arteries, showing how their pulsation depends upon the contraction of the left ventricle, while the contraction of the right ventricle propels its charge of blood into the pulmonary artery. He noticed that the two ventricles move together almost simultaneously and not independently like had been thought previously by his predecessors.\nHarvey estimated the capacity of the heart, how much blood is expelled through each pump of the heart, and the number of times the heart beats in half an hour. From these estimations, he demonstrated that according to Gaelen's theory that blood was continually produced in the liver, the absurdly large figure of 540 pounds of blood would have to be produced every day. Having this simple mathematical proportion at hand\u2014which would imply a seemingly impossible role for the liver\u2014Harvey went on to demonstrate how the blood circulated in a circle by means of countless experiments initially done on serpents and fish: tying their veins and arteries in separate periods of time, Harvey noticed the modifications which occurred; indeed, as he tied the veins, the heart would become empty, while as he did the same to the arteries, the organ would swell up. This process was later performed on the human body: the physician tied a tight ligature onto the upper arm of a person. This would cut off blood flow from the arteries and the veins. When this was done, the arm below the ligature was cool and pale, while above the ligature it was warm and swollen. The ligature was loosened slightly, which allowed blood from the arteries to come into the arm, since arteries are deeper in the flesh than the veins. When this was done, the opposite effect was seen in the lower arm. It was now warm and swollen. The veins were also more visible, since now they were full of blood.\nVarious other advances in medical understanding and practice were made. French physician Pierre Fauchard started dentistry science as we know it today, and he has been named \"the father of modern dentistry\". Surgeon Ambroise Par\u00e9 was a leader in surgical techniques and battlefield medicine, especially the treatment of wounds, and Herman Boerhaave is sometimes referred to as a \"father of physiology\" because of his exemplary teaching in Leiden and his textbook \"Institutiones medicae\" (1708).\nChemistry.\nChemistry, and its antecedent alchemy, became an increasingly important aspect of scientific thought in the course of the 16th and 17th centuries. The importance of chemistry is indicated by the range of important scholars who actively engaged in chemical research. Among them were the astronomer Tycho Brahe, the chemical physician Paracelsus, Robert Boyle, Thomas Browne and Isaac Newton. Unlike the mechanical philosophy, the chemical philosophy stressed the active powers of matter, which alchemists frequently expressed in terms of vital or active principles\u2014of spirits operating in nature.\nPractical attempts to improve the refining of ores and their extraction to smelt metals were an important source of information for early chemists in the 16th century, among them Georgius Agricola, who published his great work \"De re metallica\" in 1556. His work describes the highly developed and complex processes of mining metal ores, metal extraction and metallurgy of the time. His approach removed the mysticism associated with the subject, creating the practical base upon which others could build.\nChemist Robert Boyle is considered to have refined the modern scientific method for alchemy and to have separated chemistry further from alchemy. Although his research clearly has its roots in the alchemical tradition, Boyle is largely regarded today as the first modern chemist and therefore one of the founders of modern chemistry, and one of the pioneers of modern experimental scientific method. Although Boyle was not the original discoverer, he is best known for Boyle's law, which he presented in 1662: the law describes the inversely proportional relationship between the absolute pressure and volume of a gas, if the temperature is kept constant within a closed system.\nBoyle is also credited for his landmark publication \"The Sceptical Chymist\" in 1661, which is seen as a cornerstone book in the field of chemistry. In the work, Boyle presents his hypothesis that every phenomenon was the result of collisions of particles in motion. Boyle appealed to chemists to experiment and asserted that experiments denied the limiting of chemical elements to only the classic four: earth, fire, air, and water. He also pleaded that chemistry should cease to be subservient to medicine or to alchemy, and rise to the status of a science. Importantly, he advocated a rigorous approach to scientific experiment: he believed all theories must be tested experimentally before being regarded as true. The work contains some of the earliest modern ideas of atoms, molecules, and chemical reaction, and marks the beginning of modern chemistry.\nPhysical.\nOptics.\nIn 1604 Johannes Kepler published \"Astronomiae Pars Optica\" (\"The Optical Part of Astronomy\"). In it, he describes the inverse-square law governing the intensity of light, reflection by flat and curved mirrors, and principles of pinhole cameras, as well as the astronomical implications of optics such as parallax and the apparent sizes of heavenly bodies. \"Astronomiae Pars Optica\" is generally recognized as the foundation of modern optics.\nWillebrord Snellius found the mathematical law of refraction, now known as Snell's law, in 1621. It had been published earlier in 984 AD by Ibn Sahl. Subsequently Ren\u00e9 Descartes showed, by using geometric construction and the law of refraction (also known as Descartes' law), that the angular radius of a rainbow is 42\u00b0 (i.e. the angle subtended at the eye by the edge of the rainbow and the rainbow's centre is 42\u00b0). He also independently discovered the law of reflection, and his essay on optics was the first published mention of this law. Christiaan Huygens wrote several works in the area of optics. These included the \"Opera reliqua\" (also known as \"Christiani Hugenii Zuilichemii, dum viveret Zelhemii toparchae, opuscula posthuma\") and the \"Trait\u00e9 de la lumi\u00e8re\".\nNewton investigated the refraction of light, demonstrating that a prism could decompose white light into a spectrum of colours, and that a lens and a second prism could recompose the multicoloured spectrum into white light. He also showed that the coloured light does not change its properties by separating out a coloured beam and shining it on various objects. Newton noted that regardless of whether it was reflected or scattered or transmitted, it stayed the same colour. Thus, he observed that colour is the result of objects interacting with already-coloured light rather than objects generating the colour themselves. This is known as Newton's theory of colour. From this work he concluded that any refracting telescope would suffer from the dispersion of light into colours. The interest of the Royal Society encouraged him to publish his notes \"On Colour\". Newton argued that light is composed of particles or \"corpuscles\" and that are refracted by accelerating toward the denser medium, but he had to associate them with waves to explain the diffraction of light.\nIn his \"Hypothesis of Light\" of 1675, Newton posited the existence of the ether to transmit forces between particles. In 1704, Newton published \"Opticks\", in which he expounded his corpuscular theory of light. He considered light to be made up of extremely subtle corpuscles, that ordinary matter was made of grosser corpuscles and speculated that through a kind of alchemical transmutation \"Are not gross Bodies and Light convertible into one another, ...and may not Bodies receive much of their Activity from the Particles of Light which enter their Composition?\"\nAntonie van Leeuwenhoek constructed powerful single lens microscopes and made extensive observations that he published around 1660, paving the way for the science of microbiology.\nElectricity.\nWilliam Gilbert, in \"De Magnete\", invented the Neo-Latin word \"electricus\" from \"\" (\"elektron\"), the Greek word for \"amber\". Gilbert undertook a number of careful electrical experiments, in the course of which he discovered that many substances other than amber, such as sulphur, wax, glass, etc., were capable of manifesting electrical properties. Gilbert discovered that a heated body lost its electricity and that moisture prevented the electrification of all bodies. He noticed that electrified substances attracted all other substances indiscriminately, whereas a magnet only attracted iron. The many discoveries of this nature earned Gilbert the title \"founder of the electrical science\". By investigating the forces on a light metallic needle, balanced on a point, he extended the list of electric bodies and found that many substances, including metals and natural magnets, showed no attractive forces when rubbed. He noticed that dry weather with north or east wind was the most favourable atmospheric condition for exhibiting electric phenomena\u2014an observation liable to misconception until the difference between conductor and insulator was understood.\nRobert Boyle worked frequently at the new science of electricity and added several substances to Gilbert's list of electrics. He left a detailed account of his researches under the title of \"Experiments on the Origin of Electricity\". In 1675 Boyle stated that electric attraction and repulsion can act across a vacuum. One of his important discoveries was that electrified bodies in a vacuum would attract light substances, this indicating that the electrical effect did not depend upon the air as a medium.\nThis was followed in 1660 by Otto von Guericke, who invented an early electrostatic generator. By the end of the 17th century, researchers had developed practical means of generating electricity by friction with an electrostatic generator, but the development of electrostatic machines did not begin in earnest until the 18th century when they became fundamental instruments in the studies about the science of electricity. The first usage of the word \"electricity\" is ascribed to Thomas Browne in his 1646 work \"Pseudodoxia Epidemica\". In 1729 Stephen Gray demonstrated that electricity could be \"transmitted\" through metal filaments.\nMechanical devices.\nAs an aid to scientific investigation, various tools, measuring aids and calculating devices were developed in this period.\nCalculating devices.\nJohn Napier introduced logarithms as a powerful mathematical tool. With the help of Henry Briggs their logarithmic tables embodied a computational advance that made calculations by hand much quicker. His Napier's bones used a set of numbered rods as a multiplication tool using the system of lattice multiplication. The way was opened to later scientific advances, particularly in astronomy and dynamics.\nAt Oxford University, Edmund Gunter built the first analog device to aid computation. The 'Gunter's scale' was a large plane scale, engraved with various scales, or lines. Natural lines, such as the line of chords, the line of sines and tangents are placed on one side of the scale and the corresponding artificial or logarithmic ones were on the other side. This calculating aid was a predecessor of the slide rule. It was William Oughtred who first used two such scales sliding by one another to perform direct multiplication and division and thus is credited as the inventor of the slide rule in 1622.\nBlaise Pascal invented the mechanical calculator in 1642. The introduction of his Pascaline in 1645 launched the development of mechanical calculators first in Europe and then all over the world. Gottfried Leibniz, building on Pascal's work, became one of the most prolific inventors in the field of mechanical calculators; he was the first to describe a pinwheel calculator in 1685, and he invented the Leibniz wheel, used in the arithmometer, the first mass-produced mechanical calculator. He also refined the binary number system, the foundation of virtually all modern computer architectures.\nJohn Hadley was the inventor of the octant, the precursor to the sextant (invented by John Bird), which greatly improved the science of navigation.\nIndustrial machines.\nDenis Papin was best known for his pioneering invention of the steam digester, the forerunner of the steam engine. The first working steam engine was patented in 1698 by the English inventor Thomas Savery, as a \"...new invention for raising of water and occasioning motion to all sorts of mill work by the impellent force of fire, which will be of great use and advantage for drayning mines, serveing townes with water, and for the working of all sorts of mills where they have not the benefitt of water nor constant windes.\" The invention was demonstrated to the Royal Society on 14 June 1699, and the machine was described by Savery in his book \"The Miner's Friend; or, An Engine to Raise Water by Fire\" (1702), in which he claimed that it could pump water out of mines. Thomas Newcomen perfected the practical steam engine for pumping water, the Newcomen steam engine. Consequently, Newcomen can be regarded as a forefather of the Industrial Revolution.\nAbraham Darby I was the first, and most famous, of three generations of the Darby family who played an important role in the Industrial Revolution. He developed a method of producing high-grade iron in a blast furnace fueled by coke rather than charcoal. This was a major step forward in the production of iron as a raw material for the Industrial Revolution.\nTelescopes.\nRefracting telescopes first appeared in the Netherlands in 1608, apparently the product of spectacle makers experimenting with lenses. The inventor is unknown, but Hans Lipperhey applied for the first patent, followed by Jacob Metius of Alkmaar. Galileo was one of the first scientists to use this tool for his astronomical observations in 1609. The reflecting telescope was described by James Gregory in his book \"Optica Promota\" (1663). He argued that a mirror shaped like the part of a conic section, would correct the spherical aberration that flawed the accuracy of refracting telescopes. His design, the \"Gregorian telescope\", however, remained un-built.\nIn 1666, Newton argued that the faults of the refracting telescope were fundamental because the lens refracted light of different colors differently. He concluded that light could not be refracted through a lens without causing chromatic aberrations. From these experiments Newton concluded that no improvement could be made in the refracting telescope. However, he was able to demonstrate that the angle of reflection remained the same for all colors, so he decided to build a reflecting telescope. It was completed in 1668 and is the earliest known functional reflecting telescope. 50 years later, Hadley developed ways to make precision aspheric and parabolic objective mirrors for reflecting telescopes, building the first parabolic Newtonian telescope and a Gregorian telescope with accurately shaped mirrors. These were successfully demonstrated to the Royal Society.\nOther devices.\nThe invention of the vacuum pump paved the way for the experiments of Robert Boyle and Robert Hooke into the nature of vacuum and atmospheric pressure. The first such device was made by Otto von Guericke in 1654. It consisted of a piston and an air gun cylinder with flaps that could suck the air from any vessel that it was connected to. In 1657, he pumped the air out of two conjoined hemispheres and demonstrated that a team of sixteen horses were incapable of pulling it apart. The air pump construction was greatly improved by Hooke in 1658.\nEvangelista Torricelli invented the mercury barometer in 1643. The motivation for the invention was to improve on the suction pumps that were used to raise water out of the mines. Torricelli constructed a sealed tube filled with mercury, set vertically into a basin of the same substance. The column of mercury fell downwards, leaving a Torricellian vacuum above.\nMaterials, construction, and aesthetics.\nSurviving instruments from this period tend to be made of durable metals such as brass, gold, or steel, although examples such as telescopes made of wood, pasteboard, or with leather components exist. Those instruments that exist in collections today tend to be robust examples, made by skilled craftspeople for and at the expense of wealthy patrons. These may have been commissioned as displays of wealth. In addition, the instruments preserved in collections may not have received heavy use in scientific work; instruments that had visibly received heavy use were typically destroyed, deemed unfit for display, or excluded from collections altogether. It is also postulated that the scientific instruments preserved in many collections were chosen because they were more appealing to collectors, by virtue of being more ornate, more portable, or made with higher-grade materials.\nIntact air pumps are particularly rare. The pump at right included a glass sphere to permit demonstrations inside the vacuum chamber, a common use. The base was wooden, and the cylindrical pump was brass. Other vacuum chambers that survived were made of brass hemispheres.\nInstrument makers of the late 17th and early 18th centuries were commissioned by organizations seeking help with navigation, surveying, warfare, and astronomical observation. The increase in uses for such instruments, and their widespread use in global exploration and conflict, created a need for new methods of manufacture and repair, which would be met by the Industrial Revolution.\nCriticism.\nThe idea that modern science took place as a kind of revolution has been debated among historians. A weakness of the idea of a scientific revolution is the lack of a systematic approach to the question of knowledge in the period comprehended between the 14th and 17th centuries, leading to misunderstandings on the value and role of modern authors. From this standpoint, the continuity thesis is the hypothesis that there was no radical discontinuity between the intellectual development of the Middle Ages and the developments in the Renaissance and early modern period and has been deeply and widely documented by the works of scholars like Pierre Duhem, John Hermann Randall, Alistair Crombie and William A. Wallace, who proved the preexistence of a wide range of ideas used by the followers of the Scientific Revolution thesis to substantiate their claims. Thus, the idea of a scientific revolution following the Renaissance is\u2014according to the continuity thesis\u2014a myth. Some continuity theorists point to earlier intellectual revolutions occurring in the Middle Ages, usually referring to either a European Renaissance of the 12th century or a medieval Muslim scientific revolution, as a sign of continuity.\nAnother contrary view has been recently proposed by Arun Bala in his dialogical history of the birth of modern science. Bala proposes that the changes involved in the Scientific Revolution\u2014the mathematical realist turn, the mechanical philosophy, the atomism, the central role assigned to the Sun in Copernican heliocentrism\u2014have to be seen as rooted in multicultural influences on Europe. He sees specific influences in Alhazen's physical optical theory, Chinese mechanical technologies leading to the perception of the world as a machine, the Hindu\u2013Arabic numeral system, which carried implicitly a new mode of mathematical atomic thinking, and the heliocentrism rooted in ancient Egyptian religious ideas associated with Hermeticism. Bala argues that by ignoring such multicultural impacts we have been led to a Eurocentric conception of the Scientific Revolution. However, he states: \"The makers of the revolution\u2014Copernicus, Kepler, Galileo, Descartes, Newton, and many others\u2014had to selectively appropriate relevant ideas, transform them, and create new auxiliary concepts in order to complete their task... In the ultimate analysis, even if the revolution was rooted upon a multicultural base it is the accomplishment of Europeans in Europe.\" Critics note that lacking documentary evidence of transmission of specific scientific ideas, Bala's model will remain \"a working hypothesis, not a conclusion\".\nA third approach takes the term \"Renaissance\" literally as a \"rebirth\". A closer study of Greek philosophy and Greek mathematics demonstrates that nearly all of the so-called revolutionary results of the so-called Scientific Revolution were in actuality restatements of ideas that were in many cases older than those of Aristotle and in nearly all cases at least as old as Archimedes. Aristotle even explicitly argues against some of the ideas that were espoused during the Scientific Revolution, such as heliocentrism. The basic ideas of the scientific method were well known to Archimedes and his contemporaries, as demonstrated in the discovery of buoyancy. This approach to the Scientific Revolution reduces it to a period of relearning classical ideas that is very much an extension of the Renaissance. This view does not deny that a change occurred but argues that it was a reassertion of previous knowledge (a renaissance) and not the creation of new knowledge. It cites statements from Newton, Copernicus and others in favour of the Pythagorean worldview as evidence.\nIn more recent analysis of the Scientific Revolution during this period, there has been criticism of the dominance of male scientists of the time. Female scholars were not given the opportunities that a male scholar would have had, and the incorporation of women's work in the sciences during this time tends to be obscured. Scholars have tried to look into the participation of women in the 17th century in science, and even with sciences as simple as domestic knowledge women were making advances. With the limited history provided from texts of the period we cannot know the extent of women's roles in developing the scientific ideas and inventions. Another idea to consider is the way this period influenced even the women scientists of the periods following it. Annie Jump Cannon was a 20th century astronomer who benefitted from the laws and theories developed from this period; she made several advances in the century following the Scientific Revolution. It was an important period for the future of science, including the incorporation of women into fields using the developments made.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "29545", "revid": "733014", "url": "https://en.wikipedia.org/wiki?curid=29545", "title": "Salian dynasty", "text": "German dynasty in the High Middle Ages\nThe Salian dynasty or Salic dynasty () was a dynasty in the High Middle Ages. The dynasty provided four kings of Germany (1024\u20131125), all of whom went on to be crowned Holy Roman emperors (1027\u20131125).\nAfter the death of the last Ottonian emperor in 1024, the Kingdom of Germany and later the entire Holy Roman Empire passed to Conrad II, a Salian. He was followed by three more Salian rulers: Henry III, Henry IV, and Henry V. They established their monarchy as a major European power. The Salian dynasty developed a permanent administrative system based on a class of public officials answerable to the crown.\nOrigins and name.\nModern historians suppose that the Salians descended from the Widonids, a prominent noble kindred emerging in the 7th\u00a0century. Their estates were located at the confluence of rivers Moselle and Saar and they supported the Carolingians. The Widonids' eastward expansion towards the river Rhine started after they founded Hornbach Abbey in the Bliesgau around 750. Hornbach remained their proprietary monastery and royal grants to the abbey established their presence in the Wormsgau. As time passed, several branches split off the Widonids. The late 9th-century Holy Roman Emperor Guy (or Wido) of Spoleto descended from one of these branches, the Lambertines. The Salians' forefathers remained in Rhenish Franconia.\nWipo of Burgundy, the biographer of the first Salian monarch, Emperor Conrad\u00a0II, described Conrad's father and uncle as \"distinguished noble lords from Rhenish Franconia\" around 1044, but without calling them Salians. Wipo added that Conrad's mother, Adelaide of Metz, was \"supposedly descended from the ancient royal house of Troy\". The statement made a connection between Conrad and the royal Merovingians who had claimed a Trojan ancestry for themselves.\nHistorian Stefan Weinfurter proposes that the putative relationship between the Salians and the Merovingians gave rise to the family name, because the Salian Franks had been the most renowned Frankish group. Their memory was preserved through a Frankish law code, known as the Salic law. Peter H. Wilson states the Salians received their name due to their origins amongst the Franks living along the Rhine in western Franconia, a region \"distinguished through its use of Salic law\". A less likely etymology links the appellation to the old German word \"sal\" (\"lordship\"), proposing that the name can be traced to the Salian monarchs' well-documented inclination towards hierarchical structures.\nThe term \"reges salici\" (or Salian kings) was most probably coined early in the 12th\u00a0century. A list of monarchs and archbishops from Mainz, which was completed around 1139\u201340, is the first extant document to contain it. Bishop Otto of Freising, a maternal descendant of the Salian monarchs, also used the term in his \"Chronicle or History of the Two Cities\" in the middle of the 12th\u00a0century. In a narrow sense, only the four German monarchs who ruled from 1024 to 1125 could be called Salians, but the same appellation has already been expanded to their ancestors by modern historians. An earlier name of the family, appearing in 982, was the Wormsers, due to their main holdings being in the Diocese of Worms.\nAll male members of the family who were destined to a secular career were named Conrad or Henry. Emperor Conrad\u00a0II's grandfather, Otto of Worms, established this tradition in the late 10th\u00a0century. He named his eldest son, Henry of Worms, after his maternal great-grandfather, King Henry the Fowler; and he gave the name of his father, Conrad the Red, to one of his younger sons, Conrad of Carinthia. Conrad the Red was most probably named for King Conrad I of Germany.\nEarly Salians.\nWerner.\nCount Werner, who held estates in the Nahegau, Speyergau and Wormsgau early in the 10th\u00a0century, is the Salian monarchs' first certainly identified ancestor. His family links to the Widonids cannot be securely established, but his patrimonial lands and his close relationship with the Hornbach Abbey provide indirect evidence of his Widonid ancestry. He married a kinswoman, most probably a sister, of King Conrad\u00a0I of Germany. This marriage alliance with the Conradines introduced Conrad as a leading name in his family.\nConrad the Red.\nWerner's son, Conrad the Red, inherited his father Franconian estates. His family links with the Conradines facilitated his acquisition of large portions of their domains after King Otto\u00a0I of Germany crushed their revolt in 939. The Conradines lost their preeminent position in Franconia and Conrad the Red emerged as Otto\u00a0I's principal supporter in the region. He was awarded with the Duchy of Lotharingia in 944 or 945 and he married the King's daughter, Luidgard, in 947.\nThe marriage forged a link between the royal Ottonian dynasty and the Salians. He lost Lotharingia after he joined a revolt against his father-in-law in 953 or 954. He died fighting against the invading Magyars in the Battle of Lechfeld in 955. The contemporaneous Widukind of Corvey praised him for his bravery. He was buried in the Worms Cathedral, although mainly bishops and kings had so far been buried in cathedrals.\nOtto of Worms.\nConrad the Red's son, Otto of Worms, found favour with his maternal grandfather, King Otto\u00a0I, Holy Roman Emperor from 962. Still a minor, Otto of Worms was mentioned as a count in the Nahegau in 956. He also seized Wormsgau, Speyergau, Niddagau, Elsenzgau, Kraichgau and Pfinzgau, thus uniting almost all lands between the rivers Rhine and Neckar by the time Otto\u00a0I died in 973. The parentage of his wife, Judith, is uncertain: she may have been related either to Arnulf, Duke of Bavaria, to Count Henry of Arlon, or to Burchard, Margrave in the Eastern Marches.\nOtto\u00a0I's son and successor, Emperor Otto\u00a0II, was worried about the concentration of lands in his nephew's hands in Franconia. The Emperor appointed Otto of Worms to administer the faraway Duchy of Carinthia and March of Verona in 978. The Emperor persuaded Otto to cede his right to administer justice in Worms, and also parts of his revenues in the town, to the local bishop. Otto was persuaded to renounce Carinthia and Verona, but he was lavishly compensated with a large forest in Wasgau, the royal palace at Kaiserslautern and the proprietary rights over Weissenburg Abbey.\nHe could also preserve the title of duke, thus becoming the first duke to bear the title without ruling a duchy in Germany. Otto was the cousin of Otto III, Holy Roman Emperor, thus he had a strong claim to the throne after the Emperor's death, but he concluded an agreement with the Ottonian candidate, Henry of Bavaria in 1002. Henry restored Carinthia to Otto in 1002 and he ruled the duchy until his death in 1004.\nDukes and bishops.\nHenry of Worms.\nHenry was Otto of Worms's eldest son. His wife, Adelaide, was born into a prominent Lotharingian family, being the daughter of Richard, Count of Metz. Their son, Conrad, would be the first Salian monarch, but Henry could not transfer his seniority rights to his son, because he predeceased his father most probably in 990 or 991.\nConrad of Carinthia.\nAfter Henry of Worms' premature death, his seniority rights shifted to his younger brother, Conrad, enabling him to inherit the major part of the patrimonial lands from his father. Conrad married Matilda, a daughter of Herman II, Duke of Swabia, most probably in 1002. Two years later, he succeeded his father as Duke of Carinthia\u2014the duchy passed from father to son for the first time on this occasion. His rule in Carinthia is poorly documented and he died in 1011.\nPope Gregory V.\nBruno\u2014the future Pope Gregory\u00a0V\u2014was a younger son of Otto of Worms. His father's cousin, Otto\u00a0III, placed him on the papal throne in 996, ignoring the provisions of his own \"Diploma Ottonianum\" on papal elections. Bruno, who was the first German pope, assumed his papal name in memory of Pope Gregory the Great. He crowned Otto\u00a0III emperor on the Feast of the Ascension in the same year. The Roman aristocrat Crescentius the Younger expelled him from Rome, but the Emperor crushed the revolt and restored the papal throne to Gregory\u00a0V. The Pope died at the age of twenty-six or twenty-seven in 999.\nWilliam of Strasbourg.\nWilliam was Otto of Worms' youngest son. After serving in the royal court as archchaplain to Queen Gisella, William was made bishop of Strasbourg in 1028 or 1029. The see of Strasbourg was one of the wealthiest German bishoprics. His tenure was almost uneventful and he died in 1046 or 1047.\nConrad the Younger.\nConrad, the elder son of Duke Conrad I of Carinthia and Matilda of Swabia, was born between 1002 and 1005. He was underage when his father died in 1011. He inherited his father's patrimonial lands, but Emperor Henry\u00a0II made Adalbero of Eppelstein the new duke of Carinthia. After Emperor Henry\u00a0II died in 1024, both Conrad and his cousin, Conrad the Elder, laid claim to the throne and Conrad the Elder was elected the new monarch.\nImperial Salians.\nConrad II.\nConrad the Elder was the sole son of Henry of Worms. After his father's premature death, he was placed under the guardianship of Bishop Burchard of Worms. He married Gisela of Swabia in 1016. Both her father Herman II, Duke of Swabia and her mother Gerberga of Burgundy descended from Charlemagne. She was twice widowed. Gisela's first husband Brun I, Count of Brunswick had been a candidate to the imperial throne along with her father and the winning Henry\u00a0II. Her second husband Ernest succeeded her childless brother Herman\u00a0III as duke of Swabia. \nConrad the Elder was elected king of Germany against his cousin Conrad the Younger on 4\u00a0September 1024. Four days later, he was crowned in the Mainz Cathedral by Archbishop Aribo. On learning of Henry\u00a0II the citizens of the Italian city Pavia demolished the local royal palace claiming that during the interregnum no king could own the palace. In his response to the rebels, Conrad emphasized that \"Even if the king died, the kingdom remaind, just as the ship whose steersman falls remains\". A group of Lombard aristocrats offered the throne first to Robert II of France or his eldest son, Hugh Magnus, then to William V, Duke of Aquitaine, but the Lombard bishops and most aristocrats supported Conrad's claim to rule. \nAfter crushing a revolt by his stepson Ernest II, Duke of Swabia and Conrad the Younger in Germany, Conrad marched to Italy. He was crowned king of the Lombards in Milan by Archbishop Aribert probably on 25th\u00a0March 1026. Resistance against his rule was quickly crushed. He reached Rome where he was crowned Holy Roman Emperor by Pope John XIX on 26th\u00a0March 1027.\nSalian monarchy.\nAfter the death of the last Saxon Emperor Henry II, the first Salian regent, Conrad II, was elected by the majority of the Prince-electors and was crowned German king in Mainz on 8 September 1024. Early in 1026 Conrad went to Milan, where Ariberto, archbishop of Milan, crowned him king of Italy. When Rudolph III, King of Burgundy died in 1032, Conrad II also claimed this kingship on the basis of an inheritance Henry II had extorted from the former in 1006. Despite some opposition, the Burgundian and Proven\u00e7al nobles paid homage to Conrad in Z\u00fcrich in 1034. This Kingdom of Burgundy would become known as the Kingdom of Arles from the 12th century.\nAlready in 1028 Conrad II had his son Henry III elected and anointed king of Germany. Henry's tenure led to an overstatement of previously unknown sacral kingship. So during this reign Speyer Cathedral was expanded to be the largest church in Western Christendom. Henry's conception of a legitimate power of royal disposition in the duchies was successful against the dukes, and thus secured royal control. However, in Lorraine, this led to years of conflict, from which Henry emerged as the winner. However, in southern Germany a powerful opposition group was formed in the years 1052\u20131055. In 1046 Henry ended the papal schism, freed the Papacy from dependence on the Roman nobility, and laid the basis for its universal applicability. His early death in 1056 was long regarded as a disaster for the Empire.\nThe early Salians owed much of their success to their alliance with the Church, a policy begun by Otto I, which gave them the material support they needed to subdue rebellious dukes. In time, however, the Church came to regret this close relationship. The alliance broke down in 1075 during what came to be known as the Investiture Controversy (or \"Investiture Dispute\"), a struggle in which the reformist Pope, Gregory VII, demanded that Emperor Henry IV renounce his rights over the Church in Germany. The pope also attacked the concept of monarchy by divine right and gained the support of significant elements of the German nobility interested in limiting imperial absolutism. \nMore importantly, the pope forbade ecclesiastical officials under pain of excommunication from supporting Henry as they had so freely done in the past. In the end, Henry IV journeyed to Canossa in northern Italy in 1077 to do penance and to receive absolution from the pope. However, he resumed the practice of lay investiture (appointment of religious officials by civil authorities) and arranged the election of an antipope (Antipope Clement III) in 1080.\nThe monarch's struggle with the papacy resulted in a war that ravaged through the Holy Roman Empire from 1077 until the Concordat of Worms in 1122. The reign of the last ruler of the Salian dynasty Henry V coincided with the final phase of the great Investiture Controversy, which had pitted pope against emperor. By the settlement of the Concordat of Worms, Henry V surrendered to the demands of the second generation of Gregorian reformers. This agreement stipulated that the pope would appoint high church officials but gave the German king the right to veto the papal choices. \nImperial control of Italy was lost for a time, and the imperial crown became dependent on the political support of competing aristocratic factions. Feudalism became more widespread as freemen sought protection by swearing allegiance to a lord. These powerful local rulers, having thereby acquired extensive territories and large military retinues, took over administration within their territories and organized it around an increasing number of castles. The most powerful of these local rulers came to be called princes rather than dukes.\nAccording to the laws of the feudal system of the Holy Roman Empire, the king had no claims on the vassals of other princes, only on those living within his family's territory. Lacking the support of the formerly independent vassals and weakened by the increasing hostility of the Church, the monarchy lost its pre-eminence. Thus the Investiture Contest strengthened local power in the Holy Roman Empire \u2013 in contrast to the trend in France and England, where centralized royal power grew. The Investiture Contest had an additional effect. The long struggle between emperor and pope hurt the Holy Roman Empire's intellectual life, in this period largely confined to monasteries, and the empire no longer led or even kept pace with developments occurring in France and Italy. For instance, no universities were founded in the Holy Roman Empire until the fourteenth century.\nThe first Hohenstaufen king Conrad III was a grandson of the Salian Henry IV, Holy Roman Emperor. (Agnes, Henry IV's daughter and Henry V's sister, was the heiress to the Salian dynasty's lands: her first marriage produced the royal and imperial Hohenstaufen dynasty and her second marriage the ducal Babenberg potentates of the Duchy of Austria, which was elevated much due to these connections via the Privilegium Minus.)\nSalian Kings and Emperors.\nTheir regnal dates as emperor take into account elections and subsequent coronations.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral references.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "29549", "revid": "9755426", "url": "https://en.wikipedia.org/wiki?curid=29549", "title": "Self-replication", "text": "Type of behavior of a dynamical system\nSelf-replication is any behavior of a dynamical system that yields construction of an identical or similar copy of itself. Biological cells, given suitable environments, reproduce by cell division. During cell division, DNA is replicated and can be transmitted to offspring during reproduction. Biological viruses can replicate, but only by commandeering the reproductive machinery of cells through a process of infection. Harmful prion proteins can replicate by converting normal proteins into rogue forms. Computer viruses reproduce using the hardware and software already present on computers. Self-replication in robotics has been an area of research and a subject of interest in science fiction. Any self-replicating mechanism which does not make a perfect copy (mutation) will experience genetic variation and will create variants of itself. These variants will be subject to natural selection, since some will be better at surviving in their current environment than others and will out-breed them.\nOverview.\nTheory.\nEarly research by John von Neumann established that replicators have several parts:\nExceptions to this pattern may be possible, although almost all known examples adhere to it. Scientists have come close to constructing https:// in an \"environment\" that is a solution of RNA monomers and transcriptase, but such systems are more accurately characterized as \"assisted replication\" than \"self-replication\". In 2021 researchers succeeded in constructing a system with sixteen specially designed DNA sequences. Four of these can be linked together (through base pairing) in a certain order following a template of four already-linked sequences, by changing the temperature up and down. The number of template copies is thus increased in each cycle. No external agent such as an enzyme is needed, but the system must be supplied with a reservoir of the sixteen DNA sequences.\nThe simplest possible case is that only a genome exists. Without some specification of the self-reproducing steps, a genome-only system is probably better characterized as something like a crystal.\nOrigin of life.\nSelf-replication is a fundamental feature of life. It was proposed that self-replication emerged in the evolution of life when a molecule similar to a double-stranded polynucleotide (possibly like RNA) dissociated into single-stranded polynucleotides and each of these acted as a template for synthesis of a complementary strand producing two double stranded copies. In a system such as this, individual duplex replicators with different nucleotide sequences could compete with each other for available mononucleotide resources, thus initiating natural selection for the most \"fit\" sequences. Replication of these early forms of life was likely highly inaccurate producing mutations that influenced the folding state of the polynucleotides, thus affecting the propensities for strand association (promoting stability) and disassociation (allowing genome replication). The evolution of order in living systems has been proposed to be an example of a fundamental order generating principle that also applies to physical systems.\nClasses of self-replication.\nRecent research has begun to categorize replicators, often based on the amount of support they require.\nThe design space for machine replicators is very broad. A comprehensive study to date by Robert Freitas and Ralph Merkle has identified 137 design dimensions grouped into a dozen separate categories, including: (1) Replication Control, (2) Replication Information, (3) Replication Substrate, (4) Replicator Structure, (5) Passive Parts, (6) Active Subunits, (7) Replicator Energetics, (8) Replicator Kinematics, (9) Replication Process, (10) Replicator Performance, (11) Product Structure, and (12) Evolvability.\nA self-replicating computer program.\nIn computer science a quine is a self-reproducing computer program that, when executed, outputs its own code. For example, a quine in the Python programming language is:\nA more trivial approach is to write a program that will make a copy of any stream of data that it is directed to, and then direct it at itself. In this case the program is treated as both executable code, and as data to be manipulated. This approach is common in most self-replicating systems, including biological life, and is simpler as it does not require the program to contain a complete description of itself.\nIn many programming languages an empty program is legal, and executes without producing errors or other output. The output is thus the same as the source code, so the program is trivially self-reproducing.\nSelf-replicating tiling.\nIn geometry a self-replicating tiling is a tiling pattern in which several congruent tiles may be joined together to form a larger tile that is similar to the original. This is an aspect of the field of study known as tessellation. The \"sphinx\" hexiamond is the only known self-replicating pentagon. For example, four such concave pentagons can be joined together to make one with twice the dimensions. Solomon W. Golomb coined the term rep-tiles for self-replicating tilings.\nIn 2012, Lee Sallows identified rep-tiles as a special instance of a self-tiling tile set or setiset. A setiset of order \"n\" is a set of \"n\" shapes that can be assembled in \"n\" different ways so as to form larger replicas of themselves. Setisets in which every shape is distinct are called 'perfect'. A rep-\"n\" rep-tile is just a setiset composed of \"n\" identical pieces.\nSelf replicating clay crystals.\nOne form of natural self-replication that is not based on DNA or RNA occurs in clay crystals. Clay consists of a large number of small crystals, and clay is an environment that promotes crystal growth. Crystals consist of a regular lattice of atoms and are able to grow if e.g. placed in a water solution containing the crystal components; automatically arranging atoms at the crystal boundary into the crystalline form. Crystals may have irregularities where the regular atomic structure is broken, and when crystals grow, these irregularities may propagate, creating a form of self-replication of crystal irregularities. Because these irregularities may affect the probability of a crystal breaking apart to form new crystals, crystals with such irregularities could even be considered to undergo evolutionary development.\nApplications.\nIt is a long-term goal of some engineering sciences to achieve a clanking replicator, a material device that can self-replicate. The usual reason is to achieve a low cost per item while retaining the utility of a manufactured good. Many authorities say that in the limit, the cost of self-replicating items should approach the cost-per-weight of wood or other biological substances, because self-replication avoids the costs of labor, capital and distribution in conventional manufactured goods.\nA fully novel artificial replicator is a reasonable near-term goal.\nA NASA study recently placed the complexity of a clanking replicator at approximately that of Intel's Pentium 4 CPU. That is, the technology is achievable with a relatively small engineering group in a reasonable commercial time-scale at a reasonable cost.\nGiven the currently keen interest in biotechnology and the high levels of funding in that field, attempts to exploit the replicative ability of existing cells are timely, and may easily lead to significant insights and advances.\nA variation of self replication is of practical relevance in compiler construction, where a similar bootstrapping problem occurs as in natural self replication. A compiler (phenotype) can be applied on the compiler's own source code (genotype) producing the compiler itself. During compiler development, a modified (mutated) source is used to create the next generation of the compiler. This process differs from natural self-replication in that the process is directed by an engineer, not by the subject itself.\nMechanical self-replication.\nAn activity in the field of robots is the self-replication of machines. Since all robots (at least in modern times) have a fair number of the same features, a self-replicating robot (or possibly a hive of robots) would need to do the following:\nOn a nano scale, assemblers might also be designed to self-replicate under their own power. This, in turn, has given rise to the \"grey goo\" version of Armageddon, as featured in the science fiction novels \"Bloom\" and \"Prey\".\nThe Foresight Institute has published guidelines for researchers in mechanical self-replication. The guidelines recommend that researchers use several specific techniques for preventing mechanical replicators from getting out of control, such as using a broadcast architecture.\n&lt;templatestyles src=\"Crossreference/styles.css\" /&gt;\nFields.\nResearch has occurred in the following areas:\nIn industry.\nSpace exploration and manufacturing.\nThe goal of self-replication in space systems is to exploit large amounts of matter with a low launch mass. For example, an autotrophic self-replicating machine could cover a moon or planet with solar cells, and beam the power to the Earth using microwaves. Once in place, the same machinery that built itself could also produce raw materials or manufactured objects, including transportation systems to ship the products. Another model of self-replicating machine would copy itself through the galaxy and universe, sending information back.\nIn general, since these systems are autotrophic, they are the most difficult and complex known replicators. They are also thought to be the most hazardous, because they do not require any inputs from human beings in order to reproduce.\nA classic theoretical study of replicators in space is the 1980 NASA study of autotrophic clanking replicators, edited by Robert Freitas.\nMuch of the design study was concerned with a simple, flexible chemical system for processing lunar regolith, and the differences between the ratio of elements needed by the replicator, and the ratios available in regolith. The limiting element was Chlorine, an essential element to process regolith for Aluminium. Chlorine is very rare in lunar regolith, and a substantially faster rate of reproduction could be assured by importing modest amounts.\nThe reference design specified small computer-controlled electric carts running on rails. Each cart could have a simple hand or a small bull-dozer shovel, forming a basic robot.\nPower would be provided by a \"canopy\" of solar cells supported on pillars. The other machinery could run under the canopy.\nA \"casting robot\" would use a robotic arm with a few sculpting tools to make plaster molds. Plaster molds are easy to make, and make precise parts with good surface finishes. The robot would then cast most of the parts either from non-conductive molten rock (basalt) or purified metals. An electric oven melted the materials.\nA speculative, more complex \"chip factory\" was specified to produce the computer and electronic systems, but the designers also said that it might prove practical to ship the chips from Earth as if they were \"vitamins\".\nMolecular manufacturing.\nNanotechnologists in particular believe that their work will likely fail to reach a state of maturity until human beings design a self-replicating assembler of nanometer dimensions.https://\nThese systems are substantially simpler than autotrophic systems, because they are provided with purified feedstocks and energy. They do not have to reproduce them. This distinction is at the root of some of the controversy about whether molecular manufacturing is possible or not. Many authorities who find it impossible are clearly citing sources for complex autotrophic self-replicating systems. Many of the authorities who find it possible are clearly citing sources for much simpler self-assembling systems, which have been demonstrated. In the meantime, a Lego-built autonomous robot able to follow a pre-set track and assemble an exact copy of itself, starting from four externally provided components, was demonstrated experimentally in 2003.https://\nMerely exploiting the replicative abilities of existing cells is insufficient, because of limitations in the process of protein biosynthesis &lt;templatestyles src=\"Crossreference/styles.css\" /&gt;.\nWhat is required is the rational design of an entirely novel replicator with a much wider range of synthesis capabilities.\nIn 2011, New York University scientists have developed artificial structures that can self-replicate, a process that has the potential to yield new types of materials. They have demonstrated that it is possible to replicate not just molecules like cellular DNA or RNA, but discrete structures that could in principle assume many different shapes, have many different functional features, and be associated with many different types of chemical species.\n&lt;templatestyles src=\"Crossreference/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "29550", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=29550", "title": "Shmuel Yosef Agnon", "text": "Israeli writer and Nobel laureate\nShmuel Yosef Agnon (; August 8, 1887 \u2013 February 17, 1970) was an Austro-Hungarian-born Israeli novelist, poet, and short-story writer. He was one of the central figures of modern Hebrew literature. In Hebrew, he is known by the pseudonym Shai Agnon (&lt;templatestyles src=\"Script/styles_hebrew.css\" /&gt;\u05e9\"\u05d9 \u05e2\u05d2\u05e0\u05d5\u05df\u200e). In English, his works are published under the name S. Y. Agnon.\nAgnon was born in Eastern Galicia, then part of the Austro-Hungarian Empire, and later immigrated to Mandatory Palestine, and died in Jerusalem.\nHis works deal with the conflict between the traditional Jewish life and language and the modern world. They also attempt to recapture the fading traditions of the European \"shtetl\" (village). In a wider context, he also contributed to broadening the characteristic conception of the narrator's role in literature. Agnon had a distinctive linguistic style, mixing modern and rabbinic Hebrew.\nIn 1966, he shared the Nobel Prize in Literature with the poet Nelly Sachs.\nBiography.\nShmuel Yosef Halevi Czaczkes (later Agnon) was born in Buczacz (\"Butschatsch\" in German), Galicia, then within the Austro-Hungarian Empire and now Buchach, Ukraine. Officially, his date of birth in the Hebrew calendar was 18 Av 5648 (July 26). However, he always said his birthday was on the fast day of Tisha B'Av, the commemoration of many disasters in Jewish history.\nHis father, Shalom Mordechai Halevy, was ordained as a rabbi but worked in the fur trade and had many connections among the Hasidim. His mother's side had ties to the Misnagdim, a parallel religious movement opposed to Hasidic Judaism.\nShmuel did not attend school; he was schooled by his parents. In addition to studying Jewish texts, Agnon studied writings of the Haskalah, and was also tutored in Standard German. At the age of eight, he began to write in Hebrew and Yiddish. At the age of 15, he published his first poem \u2013 a Yiddish poem about the Kabbalist Joseph della Reina. He continued to write poems and stories in Hebrew and Yiddish that were published in Galicia.\nIn 1908, he moved to Jaffa in Ottoman Palestine. The first story he published there was \"Agunot\" (\"Chained Wives\"), which appeared that same year in the journal \"Ha`omer.\" He used the pen name \"Agnon,\" derived from the title of the story, which he adopted as his official surname in 1924. In 1910, \"Forsaken Wives\" was translated into German. In 1912, at the urging of Yosef Haim Brenner, he published a novella, \"Vehaya Ha'akov Lemishor\" (\"The Crooked Shall Be Made Straight\").\nIn 1912, Agnon moved to the German Empire, where he met Esther Marx (1889-1973), the sister of Alexander Marx. They married in 1920 and had two children. In Germany, he lived in Berlin and Bad Homburg vor der H\u00f6he (1921\u201324). Salman Schocken, a businessman and later also publisher, became his literary patron and freed him from financial worries. From 1931 on, his work was published by Schocken Books, and his short stories appeared regularly in the newspaper \"Haaretz\", also owned by the Schocken family. He continued to write short stories in Germany and collaborated with Martin Buber on an anthology of Hasidic stories. Many of his early books appeared in Buber's \"J\u00fcdischer Verlag\" (Berlin). The assimilated, secular German Jews, Buber and Franz Rosenzweig among them, considered Agnon a legitimate relic, religious man familiar with Jewish scripture. Gershom Scholem called him \"the Jews' Jew\".\nIn 1924, a fire broke out in his home, destroying his manuscripts and rare book collection. This traumatic event crops up occasionally in his stories. Later that year, Agnon returned to Palestine and settled with his family in the Jerusalem neighborhood of Talpiot. In 1929, his library was destroyed again during anti-Jewish riots.\nAgnon's place in Hebrew literature was assured when his novel \"Hakhnasat Kalla\" (\"The Bridal Canopy\") appeared in 1931 to critical acclaim. In 1935, he published \"Sippur Pashut\" (\"A Simple Story\"), a novella set in Buchach at the end of the 19th century. Another novel, \"Tmol Shilshom\" (\"Only Yesterday\"), set in early 20th century Palestine, appeared in 1945.\nAgnon was a strict vegetarian in his personal life.\nDuring much of the 20th century, there was debate about whether Agnon or Yitzhak HaLevi Herzog was the actual author of the Prayer for the Welfare of the State of Israel in 1948. Herzog was generally considered the author until a 1983 article in \"Ma'ariv\" by scholar David Tamar raised the possibility of Agnon's authorship. However, findings by scholar Yoel Rappel and corroborated by the National Library of Israel in 2018 confirmed Herzog's authorship but confirmed that Agnon had edited the work.\nLiterary themes and influences.\nAgnon's writing has been the subject of extensive academic research. Many leading scholars of Hebrew literature have published books and papers on his work, among them Baruch Kurzweil, Dov Sadan, Nitza Ben-Dov, Dan Miron, Dan Laor and Alan Mintz. Agnon writes about Jewish life, but with his own unique perspective and special touch. In his Nobel acceptance speech, Agnon claimed \"Some see in my books the influences of authors whose names, in my ignorance, I have not even heard, while others see the influences of poets whose names I have heard but whose writings I have not read.\" He went on to detail that his primary influences were the stories of the Bible. Agnon acknowledged that he was also influenced by German literature and culture, and European literature in general, which he read in German translation. A collection of essays on this subject, edited in part by Hillel Weiss, with contributions from Israeli and German scholars, was published in 2010: https:// The budding Hebrew literature also influenced his works, notably that of his friend, Yosef Haim Brenner. In Germany, Agnon also spent time with the Hebraists Hayim Nahman Bialik and Ahad Ha'am.\nThe communities he passed through in his life are reflected in his works:\nNitza Ben-Dov writes about Agnon's use of allusiveness, free-association and imaginative dream-sequences, and discusses how seemingly inconsequential events and thoughts determine the lives of his characters.\nSome of Agnon's works, such as \"The Bridal Canopy\", \"And the Crooked Shall Be Made Straight\", and \"The Doctor's Divorce\", have been adapted for theatre. A play based on Agnon's letters to his wife, \"Esterlein Yakirati\", was performed at the Khan Theater in Jerusalem.\nLanguage.\nAgnon's writing often used words and phrases that differed from what would become established modern Hebrew. His distinct language is based on traditional Jewish sources, such as the Torah and the Prophets, Midrashic literature, the Mishnah, and other Rabbinic literature. Some examples include:\nBar-Ilan University has made a computerized concordance of his works in order to study his language.\nAwards and critical acclaim.\nAgnon was twice awarded the Bialik Prize for literature (1934 and 1950). He was also twice awarded the Israel Prize, for literature (1954 and 1958).\nIn 1966, he was awarded the Nobel Prize in Literature \"for his profoundly characteristic narrative art with motifs from the life of the Jewish people\". The prize was shared with German Jewish author Nelly Sachs. In his speech at the award ceremony, Agnon introduced himself in Hebrew: \"As a result of the historic catastrophe in which Titus of Rome destroyed Jerusalem and Israel was exiled from its land, I was born in one of the cities of the Exile. But always I regarded myself as one who was born in Jerusalem\". The award ceremony took place on a Saturday during the Jewish festival of Hanukkah. Agnon, who was religiously observant, postponed attendance at the awards ceremony until he had performed two Jewish ceremonies of his own on Saturday night, to end the Sabbath and to light the menorah.\nIn later years, Agnon's fame was such that when he complained to the municipality that traffic noise near his home was disturbing his work, the city closed the street to cars and posted a sign that read: \"No entry to all vehicles, writer at work!\"\nDeath and legacy.\n \nAgnon died in Jerusalem on February 17, 1970. His daughter, Emuna Yaron, continued to publish his work posthumously. Agnon's archive was transferred by the family to the National Library in Jerusalem. His home in Talpiot, built in 1931 in the Bauhaus style, was turned into a museum, \"Beit Agnon.\" The study where he wrote many of his works was preserved intact. Agnon's image, with a list of his works and his Nobel Prize acceptance speech, appeared on the fifty-shekel bill, second series, in circulation from 1985 to 2014.\nThe main street in Jerusalem's Givat Oranim neighborhood is called Sderot Shai Agnon, and a synagogue in Talpiot, a few blocks from his home, is named after him. Agnon is also memorialized in Buchach (now in Ukraine). The Historical Museum in Buchach has an exhibit about him and a bust of the author is mounted on a pedestal in a plaza across the street from the house where he lived. The house itself is preserved and marked as the home where Agnon lived from birth till the age of (approximately) 19; the street that runs in front of the house is named \"Agnon Street\" (in Ukrainian).\nAgnotherapy is a method developed in Israel to help elderly people express their feelings.\nBeit Agnon.\nAfter Agnon's death, the former mayor of Jerusalem Mordechai Ish-Shalom initiated the opening of his home to the public. In the early 1980s, the kitchen and family dining room were turned into a lecture and conference hall, and literary and cultural evenings were held there. In 2005, the Agnon House Association in Jerusalem renovated the building, which reopened in January 2009. The house was designed by the German-Jewish architect Fritz Korenberg, who was also his neighbor.\nPublished works.\nPosthumous publications.\nIn 1977 the Hebrew University published \"Yiddish Works\", a collection of stories and poems that Agnon wrote in Yiddish during 1903\u20131906.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "29551", "revid": "50481892", "url": "https://en.wikipedia.org/wiki?curid=29551", "title": "Steve Ditko", "text": "American comics artist (1927\u20132018)\nStephen John Ditko (; November 2, 1927\u00a0\u2013 c.\u2009June 29, 2018) was an American comic book artist best known for being the co-creator of Marvel superheroes Spider-Man and Doctor Strange. He also made notable contributions to the character of Iron Man, introducing the character's signature red and yellow design.\nDitko studied under Batman artist Jerry Robinson at the Cartoonist and Illustrators School in New York City. He began his professional career in 1953, working in the studio of Joe Simon and Jack Kirby, beginning as an inker and coming under the influence of artist Mort Meskin. During this time, he began his long association with Charlton Comics, where he did work in the genres of science fiction, horror, and mystery. He also co-created the superhero Captain Atom in 1960.\nDuring the 1950s, Ditko also drew for Atlas Comics, a forerunner of Marvel Comics. He went on to contribute much significant work to Marvel. Ditko was the artist for the first 38 issues of \"The Amazing Spider-Man\", co-creating much of the Spider-Man supporting characters and villains with Stan Lee. Beginning with issue #25, Ditko was also credited as the plotter. In 1966, after being the exclusive artist on \"The Amazing Spider-Man\" and the \"Doctor Strange\" feature in \"Strange Tales\", Ditko left Marvel.\nHe continued to work for Charlton and also DC Comics, including a revamp of the long-running character the Blue Beetle and creating or co-creating The Question, The Creeper, Shade, the Changing Man, Nightshade, and Hawk and Dove. Ditko also began contributing to small independent publishers, where he created Mr. A, a hero reflecting the influence of Ayn Rand's philosophy of Objectivism. Ditko largely declined to give interviews, saying he preferred to communicate through his work.\nHe responded to fan mail, sending thousands of handwritten letters during his lifetime.\nDitko was inducted into the comics industry's Jack Kirby Hall of Fame in 1990 and into the Will Eisner Award Hall of Fame in 1994. In 2024, Ditko was named a Disney Legend for his contributions to Publishing.\nEarly life.\nStephen John Ditko was born on November 2, 1927, in Johnstown, Pennsylvania. His parents were second-generation Americans: children of Rusyn Byzantine Catholic immigrants from the former Austro-Hungarian Empire (now Ukraine). His father, Stefan (\"Stephen\"), was an artistically talented master carpenter at a steel mill and his mother, Anna (Balaschak), a homemaker. The second-oldest child in a working-class family, he was preceded by sister Anna Marie, and followed by sister Elizabeth and brother Patrick. Inspired by his father's love of newspaper comic strips, particularly Hal Foster's \"Prince Valiant\", Ditko found his interest in comics accelerated by the introduction of the superhero Batman in 1939, and by Will Eisner's \"The Spirit\", which appeared in a tabloid-sized comic-book insert in Sunday newspapers.\nDitko in junior high school was part of a group of students who crafted wooden models of German airplanes to aid civilian World War II aircraft-spotters. Upon graduating from Greater Johnstown High School in 1945, he enlisted in the U.S. Army on October 26, 1945, and did military service in Allied-occupied Germany, where he drew comics for an Army newspaper.\nCareer.\nFollowing his discharge, Ditko learned that his idol, Batman artist Jerry Robinson, was teaching at the Cartoonists and Illustrators School (later the School of Visual Arts) in New York City. Moving there in 1950, he enrolled in the art school under the G.I. Bill. Robinson found the young student \"a very hard worker who really focused on his drawing\" and someone who \"could work well with other writers as well as write his own stories and create his own characters\", and he helped Ditko acquire a scholarship for the following year. \"He was in my class for two years, four or five days a week, five hours a night. It was very intense.\" Robinson, who invited artists and editors to speak with his class, once brought in Stan Lee, then editor of Marvel Comics' 1950s precursor Atlas Comics and, \"I think that was when Stan first saw Steve's work.\"\nDitko began professionally illustrating comic books in early 1953, drawing writer Bruce Hamilton's science-fiction story \"Stretching Things\" for the Key Publications imprint Stanmor Publications, which sold the story to Ajax/Farrell, where it finally found publication in \"Fantastic Fears\" #5 (cover-dated February 1954). Ditko's first published work was his second professional story, the six-page \"Paper Romance\" in \"Daring Love\" #1 (October 1953), published by the Key imprint Gillmor Magazines.\nShortly afterward, Ditko found work at the studio of writer-artists Joe Simon and Jack Kirby, who had created Captain America and other characters. Beginning as an inker on backgrounds, Ditko was soon working with and learning from Mort Meskin, an artist whose work he had long admired. \"Meskin was fabulous,\" Ditko once recalled. \"I couldn't believe the ease with which he drew: strong compositions, loose pencils, yet complete; detail without clutter. I loved his stuff\". Ditko's known assistant work includes aiding inker Meskin on the Jack Kirby pencil work of Harvey Comics' \"Captain 3-D\" #1 (December 1953). For his own third published story, Ditko penciled and inked the six-page \"A Hole in His Head\" in \"Black Magic\" vol. 4, #3 (December 1953), published by Simon &amp; Kirby's Crestwood Publications imprint Prize Comics.\nDitko then began a long association with the Derby, Connecticut, publisher Charlton Comics, a low-budget division of a company best known for song-lyric magazines. Beginning with the cover of \"The Thing!\" #12 (Feb. 1954) and the eight-page vampire story \"Cinderella\" in that issue, Ditko would continue to work intermittently for Charlton until the company's demise in 1986, producing science fiction, horror and mystery stories, as well as co-creating Captain Atom, with writer Joe Gill, in \"Space Adventures\" #33 (March 1960). Ditko was allowed a great deal of creative freedom at Charlton due to very little editorial interference. However, the Comics Code Authority was imposed on the comics industry in 1954 due to public concern over graphic violence and horror imagery in comic books, and would prevent Ditko from further developing as a horror artist. He first went on hiatus from the company, and comics altogether, in mid-1954, when he contracted tuberculosis and returned to his parents' home in Johnstown to recuperate.\nMarvel Comics.\nAfter he recovered, Ditko had originally intended to return to Charlton, but Charlton's office had been flooded by Hurricane Diane and operations wouldn't resume until months later. Ditko instead moved back to New York City in late 1955 and began drawing for Atlas Comics, the 1950s precursor of Marvel Comics, beginning with the four-page \"There'll Be Some Changes Made\" in \"Journey into Mystery\" #33 (April 1956); this debut tale would be reprinted in Marvel's \"Curse of the Weird\" #4 (March 1994). In 1957, Atlas switched distributors to the American News Company, which shortly afterward lost a Justice Department lawsuit and discontinued its business, leading to Atlas's entire staff being laid off. Ditko returned to Charlton afterward and experimented with various drawing styles and genres in series such as \"Tales of the Mysterious Traveler\" and \"This Magazine Is Haunted\".\nDuring the summer of 1958, writer-editor Stan Lee invited Ditko back to Atlas. Ditko would go on to contribute a large number of stories, many considered classic, to Atlas/Marvel's \"Strange Tales\" and the newly launched \"Amazing Adventures\", \"Strange Worlds\", \"Tales of Suspense\" and \"Tales to Astonish\", issues of which would typically open with a Kirby-drawn monster story, followed by one or two twist-ending thrillers or sci-fi tales drawn by Don Heck, Paul Reinman, or Joe Sinnott, all capped by an often-surreal, sometimes self-reflective short by Ditko and Stan Lee. The first collaboration between Ditko and Lee was \"2-Gun Western\" #4 (May 1956), which was also Ditko's only non-fantasy story.\nThese Lee-Ditko short stories proved so popular that \"Amazing Adventures\" was reformatted to feature such stories exclusively beginning with issue #7 (Dec. 1961), when the comic was rechristened \"Amazing Adult Fantasy\", a name intended to reflect its more \"sophisticated\" nature, as likewise the new tagline \"The magazine that respects your intelligence\". Lee in 2009 described these \"short, five-page filler strips that Steve and I did together\", originally \"placed in any of our comics that had a few extra pages to fill\", as \"odd fantasy tales that I'd dream up with O. Henry-type endings.\" Giving an early example of what would later be known as the \"Marvel Method\" of writer-artist collaboration, Lee said, \"All I had to do was give Steve a one-line description of the plot and he'd be off and running. He'd take those skeleton outlines I had given him and turn them into classic little works of art that ended up being far cooler than I had any right to expect.\"\nCreation of Spider-Man.\nAfter Marvel Comics editor-in-chief Stan Lee obtained permission from publisher Martin Goodman to create a new \"ordinary teen\" superhero named \"Spider-Man\", Lee originally approached his leading artist, Jack Kirby. Kirby told Lee about his own 1950s character conception, variously called the Silver Spider and Spiderman, in which an orphaned boy finds a magic ring that gives him super powers. Comics historian Greg Theakston says Lee and Kirby \"immediately sat down for a story conference\" and Lee afterward directed Kirby to flesh out the character and draw some pages. \"A day or two later\", Kirby showed Lee the first six pages, and, as Lee recalled, \"I hated the way he was doing it. Not that he did it badly\u00a0\u2014 it just wasn't the character I wanted; it was too heroic\".\nLee turned to Ditko, who developed a visual motif Lee found satisfactory, although Lee would later replace Ditko's original cover with one penciled by Kirby. Ditko said, \"The Spider-Man pages Stan showed me were nothing like the (eventually) published character. In fact, the only drawings of Spider-Man were on the splash [i.e., page 1] and at the end [where] Kirby had the guy leaping at you with a web gun... Anyway, the first five pages took place in the home, and the kid finds a ring and turns into Spider-Man.\"\nDitko also recalled that, \"One of the first things I did was to work up a costume. A vital, visual part of the character. I had to know how he looked ... before I did any breakdowns. For example: A clinging power so he wouldn't have hard shoes or boots, a hidden wrist-shooter versus a web gun and holster, etc. ... I wasn't sure Stan would like the idea of covering the character's face but I did it because it hid an obviously boyish face. It would also add mystery to the character...\"\nMuch earlier, in a rare contemporaneous account, Ditko described his and Lee's contributions in a mail interview with Gary Martin published in \"Comic Fan\" #2 (Summer 1965): \"Stan Lee thought the name up. I did costume, web gimmick on wrist &amp; spider signal\". He added he would continue drawing Spider-Man \"[i]f nothing better comes along.\" That same year, he expressed to the fanzine \"Voice of Comicdom\", regarding a poll of \"Best Liked\" fan-created comics, \"It seems a shame, since comics themselves have so little variety of stories and styles that you would deliberately restrict your own creative efforts to professional comics['] shallow range. What is 'Best Liked' by most readers is what they are most familiar in seeing and any policy based on readers likes has to end up with a lot of look-a-like (sic) strips. You have a great opportunity to show everyone a whole new range of ideas, unlimited types of stories and styles\u2014why FLUB it!\"\nFrom 1958 to 1968, Ditko shared a Manhattan studio at 43rd Street and Eighth Avenue with noted fetish artist Eric Stanton, an art-school classmate. When either artist was under deadline pressure, it was not uncommon for them to pitch in and help the other with his assignment. Ditko biographer Blake Bell, without citing sources, said, \"At one time in history, Ditko denied ever touching Stanton's work, even though Stanton himself said they would each dabble in each other's art; mainly spot-inking\", and the introduction to one book of Stanton's work says, \"Eric Stanton drew his pictures in India ink, and they were then hand-coloured by Ditko\". In a 1988 interview with Theakston, Stanton recalled that although his contribution to Spider-Man was \"almost nil\", he and Ditko had \"worked on storyboards together and I added a few ideas. But the whole thing was created by Steve on his own... I think I added the business about the webs coming out of his hands\".\nSpider-Man debuted in \"Amazing Fantasy\" #15 (Aug. 1962), the final issue of that science-fiction/fantasy anthology series. When the issue proved to be a top seller, Spider-Man was given his own series, \"The Amazing Spider-Man\". Lee and Ditko's collaboration on the series saw the creation of many of the character's best known antagonists including Doctor Octopus in issue #3 (July 1963); the Sandman in #4 (Sept. 1963); the Lizard in #6 (Nov. 1963); Electro in #9 (March 1964); and the Green Goblin in #14 (July 1964). Increasingly irritated by his perception that he was not receiving his due or proper compensation, Ditko demanded credit for the plotting he was contributing under the Marvel Method. Lee acquiesced, and starting with #25 (June 1965), Ditko received plot credit for the stories.\nOne of the most celebrated issues of the Lee-Ditko run is #33 (Feb. 1966), the third part of the story arc \"If This Be My Destiny...!\", and featuring the dramatic scene of Spider-Man, through force of will and thoughts of family, escaping from being pinned by heavy machinery. Comics historian Les Daniels noted, \"Steve Ditko squeezes every ounce of anguish out of Spider-Man's predicament, complete with visions of the uncle he failed and the aunt he has sworn to save.\" Peter David observed, \"After his origin, this two-page sequence from \"Amazing Spider-Man\" #33 is perhaps the best-loved sequence from the Stan Lee/Steve Ditko era.\" Steve Saffel stated the \"full page Ditko image from \"The Amazing Spider-Man\" #33 is one of the most powerful ever to appear in the series and influenced writers and artists for many years to come.\" Matthew K. Manning wrote that \"Ditko's illustrations for the first few pages of this Lee story included what would become one of the most iconic scenes in Spider-Man's history.\" The story was chosen as #15 in the 100 Greatest Marvels of All Time poll of Marvel's readers in 2001. Editor Robert Greenberger wrote in his introduction to the story, \"These first five pages are a modern-day equivalent to Shakespeare as Parker's soliloquy sets the stage for his next action. And with dramatic pacing and storytelling, Ditko delivers one of the great sequences in all comics.\"\nIn this series, Ditko also had a lasting effect on Marvel's branding when he inserted a small box on the upper left-hand corner of issue #2 that featured a picture of Spider-Man's face along with the company name and price. Stan Lee approved of this visual motif and soon made it a standard feature on all of Marvel's subsequent comic books that would last for decades.\nTwo of the most sought-after Spider-Man collectibles during Ditko's time on the series were mail-away items ordered through comic book ads. Ditko art was featured on a very popular t-shirt and on a 6' tall poster.\nDoctor Strange and other characters.\nDitko created the supernatural hero Doctor Strange in \"Strange Tales\" #110 (July 1963). Ditko in the 2000s told a visiting fan that Lee gave Dr. Strange the first name \"Stephen\".\nThough often overshadowed by his Spider-Man work, Ditko's Doctor Strange artwork has been equally acclaimed for its surrealistic mystical landscapes and increasingly psychedelic visuals that helped make the feature a favorite of college students. \"People who read 'Doctor Strange' thought people at Marvel must be heads [i.e. drug users],\" recalled then-associate editor and former Doctor Strange writer Roy Thomas in 1971, \"because they had had similar experiences high on mushrooms. But ... I don't use hallucinogens, nor do I think any artists do.\" Ditko, \"always the most straight-laced man in comics\", was deeply offended by the suggestion that he used psychedelic drugs to create the worlds of \"Dr. Strange\".\nEventually Lee &amp; Ditko would take Strange into ever-more-abstract realms. In an epic 17-issue story arc in \"Strange Tales\" #130\u2013146 (March 1965 \u2013 July 1966), Lee and Ditko introduced the cosmic character Eternity, who personified the universe and was depicted as a silhouette whose outlines are filled with the cosmos. As historian Bradford W. Wright describes,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Steve Ditko contributed some of his most surrealistic work to the comic book and gave it a disorienting, hallucinogenic quality. Dr. Strange's adventures take place in bizarre worlds and twisting dimensions that resembled Salvador Dal\u00ed paintings. ... Inspired by the pulp-fiction magicians of Stan Lee's childhood as well as by contemporary Beat culture. Dr. Strange remarkably predicted the youth counterculture's fascination with Eastern mysticism and psychedelia. Never among Marvel's more popular or accessible characters, Dr. Strange still found a niche among an audience seeking a challenging alternative to more conventional superhero fare.\nThe cartoonist and fine artist Seth in 2003 described Ditko's style as: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...oddball for mainstream comics. Whereas Kirby's stuff clearly appealed to a boy's sensibility because there was so much raw power, Ditko's work was really delicate and cartoony. There was a sense of design to it. You can always recognize anything that Ditko designed because it's always flowery. There is a lot of embroidered detail in the art, which is almost psychedelic.\nIn addition to Dr. Strange, Ditko in the 1960s also drew comics starring the Hulk and Iron Man. He penciled and inked the final issue of \"The Incredible Hulk\" (#6, March 1963), then continued to collaborate with writer-editor Lee on a relaunched Hulk feature in the omnibus \"Tales to Astonish\", beginning with issue #60 (Oct. 1964). Ditko, inked by George Roussos, penciled the feature through #67 (May 1965). Ditko designed the Hulk's primary antagonist, the Leader, in #63 (Jan. 1965).\nDitko also penciled the Iron Man feature in \"Tales of Suspense\" #47\u201349 (Nov. 1963 \u2013 Jan. 1964), with various inkers. The first of these debuted the initial version of Iron Man's modern red-and-golden armor.\nWhichever feature he drew, Ditko's idiosyncratic, cleanly detailed, instantly recognizable art style, emphasizing mood and anxiety, found great favor with readers. The character of Spider-Man and his troubled personal life meshed well with Ditko's own interests, which Lee eventually acknowledged by giving the artist plotting credits on the latter part of their 38-issue run. But after four years on the title, Ditko left Marvel; he and Lee had not been on speaking terms for some time, with art and editorial changes handled through intermediaries. The details of the rift remain uncertain, even to Lee, who confessed in 2003, \"I never really knew Steve on a personal level.\" Ditko later claimed it was Lee who broke off contact and disputed the long-held belief that the disagreement was over the true identity of the Green Goblin: \"Stan never knew what he was getting in my Spider-Man stories and covers until after [production manager] Sol Brodsky took the material from me ... so there couldn't have been any disagreement or agreement, no exchanges ... no problems between us concerning the Green Goblin or anything else from before issue #25 to my final issues\". Spider-Man successor artist John Romita, in a 2010 deposition, recalled that Lee and Ditko \"ended up not being able to work together because they disagreed on almost everything, cultural, social, historically, everything, they disagreed on characters. ...\" A friendly farewell was given to Ditko in the \"Bullpen Bulletins\" of comics cover-dated July 1966, including \"Fantastic Four\" #52: \"Steve recently told us he was leaving for personal reasons. After all these years, we're sorry to see him go, and we wish the talented guy success with his future endeavors.\"\nRegardless, said Lee in 2007, \"Quite a few years ago I met him up at the Marvel offices when I was last in New York. And we spoke; he's a hell of a nice guy and it was very pleasant. ... I haven't heard from him since that meeting.\"\nCharlton and DC Comics.\nBack at Charlton\u2014where the page rate was low but creators were allowed greater freedom\u2014Ditko worked on such characters as the Blue Beetle (1967\u20131968), the Question (1967\u20131968), and Captain Atom (1965\u20131967), returning to the character he had co-created in 1960. In addition, in 1966 and 1967, he drew 16 stories, most of them written by Archie Goodwin, for Warren Publishing's horror-comic magazines \"Creepy\" and \"Eerie\", generally using an ink-wash technique.\nIn 1967, Ditko gave his Objectivist ideas ultimate expression in the form of Mr.\u00a0A, published in Wally Wood's independent title \"witzend\" #\u00a03, an underground anthology comic in black and white that avoided the Comics Code Authority by being published in magazine format and only being available by subscription, and whose editorial policy was to allow artistic freedom without any editorial interference. Mr.\u00a0A is a similar character to the Question, but without being restricted by the Comics Code. Ditko's hard line against criminals was controversial and he continued to produce Mr.\u00a0A stories and one-pagers until the end of the 1970s. Ditko returned to Mr.\u00a0A in 2000 and in 2009. \nDitko moved to DC Comics in 1968, where he co-created the Creeper in \"Showcase\" #73 (April 1968) with Don Segall, under editor Murray Boltinoff. DC Comics writer and executive Paul Levitz observed that Ditko's art on the \"Creeper\" stories made \"them look unlike anything else being published by DC at the time.\" Ditko co-created the team Hawk and Dove in \"Showcase\" #75 (June 1968), with writer Steve Skeates. Around this time, he penciled the lead story, written and inked by Wally Wood, in Wood's early mature-audience, independent-comics publication \"Heroes, Inc. Presents Cannon\" (1969).\nDitko's stay at DC was short\u2014he would work on all six issues of the Creeper's own title, \"Beware the Creeper\" (June 1968 \u2013 April 1969), though leaving midway through the final one\u2014and the reasons for his departure uncertain. But while at DC, Ditko recommended Charlton staffer Dick Giordano to the company, who would go on to become a top DC penciller, inker, editor, and ultimately, in 1981, the managing editor.\nFrom this time up through the mid-1970s, Ditko worked exclusively for Charlton and various small press/independent publishers. Frank McLaughlin, Charlton's art director during this period, describes Ditko as living \"in a local hotel in Derby for a while. He was a very happy-go-lucky guy with a great sense of humor at that time, and always supplied the [female] color separators with candy and other little gifts\".\nFor Charlton, in 1974, he did Liberty Belle backup stories in \"E-Man\" and conceived Killjoy. Ditko produced much work for Charlton's science-fiction and horror titles, as well as for former Marvel publisher Martin Goodman's start-up line Atlas/Seaboard Comics, where he co-created the superhero the Destructor with writer Archie Goodwin, and penciled all four issues of the namesake series (Feb.\u2013Aug. 1975), the first two of which were inked by Wally Wood. Ditko worked on the second and third issues of \"Tiger-Man\" and the third issue of \"Morlock 2001\", with Bernie Wrightson inking.\nAfter 1975.\nDitko returned to DC Comics in 1975, creating a short-lived title, \"Shade, the Changing Man\" (1977\u20131978). Shade was later revived, without Ditko's involvement, in DC's mature-audience imprint Vertigo. With writer Paul Levitz, he co-created the four-issue sword and sorcery series \"Stalker\" (1975\u20131976). Ditko and writer Gerry Conway produced the first issue of a two-issue \"Man-Bat\" series. He also revived the Creeper and did such various other jobs as a short Demon backup series in 1979, created The Odd Man and stories in DC's horror and science-fiction anthologies. Editor Jack C. Harris hired Ditko as guest artist on several issues of \"The Legion of Super-Heroes\", a decision which garnered a mixed reaction from the title's readership. Ditko also drew the Prince Gavyn version of Starman in \"Adventure Comics\" #467\u2013478 (1980). He then decamped to do work for a variety of publishers, briefly contributing to DC again in the mid-1980s, with four pinups of his characters for \"Who's Who: The Definitive Directory of the DC Universe\" and a pinup for \"Superman\" #400 (Oct. 1984) and its companion portfolio.\nDitko returned to Marvel in 1979, taking over Jack Kirby's \"Machine Man\", drawing \"The Micronauts\" and Captain Universe, and continuing to freelance for the company into the late 1990s. Starting in 1984, he penciled the last two years of the space-knight series \"Rom\". A Godzilla story by Ditko and Marv Wolfman was changed into a Dragon Lord story published in \"Marvel Spotlight\". Ditko and writer Tom DeFalco introduced the Speedball character in \"The Amazing Spider-Man Annual\" #22 (1988) and Ditko drew a ten-issue series based on the character.\nIn 1982, he also began freelancing for the early independent comics label Pacific Comics, beginning with \"Captain Victory and the Galactic Rangers\" #6 (Sept. 1982), in which he introduced the superhero Missing Man, with Mark Evanier scripting to Ditko's plot and art. Subsequent Missing Man stories appeared in \"Pacific Presents\" #1\u20133 (Oct. 1982 \u2013 March 1984), with Ditko scripting the former and collaborating with longtime friend Robin Snyder on the script for the latter two. Ditko also created The Mocker for Pacific, in \"Silver Star\" #2 (April 1983).\nFor Eclipse Comics, he contributed a story featuring his character Static (no relation to the later Milestone Comics character) in \"Eclipse Monthly\" #1\u20133 (Aug.\u2013Oct. 1983), introducing supervillain the Exploder in #2. With writer Jack C. Harris, Ditko drew the backup feature \"The Faceless Ones\" in First Comics' \"Warp\" #2\u20134 (April\u2013June 1983). Working with that same writer and others, Ditko drew a handful of the Fly, Flygirl and Jaguar stories for \"The Fly\" #2\u20138 (July 1983 \u2013 Aug. 1984), for Archie Comics' short-lived 1980s superhero line; in a rare latter-day instance of Ditko inking another artist, he inked penciler Dick Ayers on the Jaguar story in \"The Fly\" #9 (Oct. 1984). Western Publishing in 1982 announced a series by Ditko and Harris would appear in a new science-fiction comic, \"Astral Frontiers\", but that title never materialized.\nDitko and Harris created \"3-D Substance\", a character with the power to turn invisible in a 3-D comic, in 1990. Substance also had the ability to project his voice away from himself, which Ditko demonstrated through the placement of word balloons. In the early 1990s Ditko worked for Jim Shooter's newly founded company Valiant Comics, drawing, among others, issues of \"Magnus, Robot Fighter\", \"Solar, Man of the Atom\" and \"X-O-Manowar\". In 1992 Ditko worked with writer Will Murray to produce one of his last original characters for Marvel Comics, the superheroine Squirrel Girl, who debuted in \"Marvel Super-Heroes\" vol. 2, #8, a.k.a. \"Marvel Super-Heroes Winter Special\" (Jan. 1992).\nIn 1992 he had a meeting with Stan Lee, who wanted to work with Ditko on a comic project about a \"garbageman superhero from the future\", but he declined because he didn't like the future portrayed in the concept. When Lee then suggested they should do a Spider-Man graphic novel together, he declined that too, claiming he no longer had the same feelings for the character that he once had.\nIn 1993, he did the Dark Horse Comics one-shot \"The Safest Place in the World\". For the Defiant Comics series \"Dark Dominion,\" he drew issue #0, which was released as a set of trading cards. In 1995, he pencilled a four-issue series for Marvel based on the \"Phantom 2040\" animated TV series. This included a poster that was inked by John Romita Sr. \"Steve Ditko's Strange Avenging Tales\" was announced as a quarterly series from Fantagraphics Books, although it only ran one issue (Feb. 1997) due to publicly unspecified disagreements between Ditko and the publisher.\n\"The New York Times\" assessed in 2008 that, \"By the '70s he was regarded as a slightly old-fashioned odd-ball; by the '80s he was a commercial has-been, picking up wretched work-for-hire gigs. ...following the example of [Ayn] Rand's John Galt, Ditko hacked out moneymaking work, saving his care for the crabbed Objectivist screeds he published with tiny presses. And boy, could Ditko hack: seeing samples of his \"Transformers\" coloring book and his Big Boy comic is like hearing Orson Welles sell frozen peas.\"\nDitko retired from mainstream comics in 1998. His later work for Marvel and DC included such established superheroes as the Sub-Mariner (in \"Marvel Comics Presents\") and newer, licensed characters such as the \"Mighty Morphin Power Rangers\". The last mainstream character he created was Marvel's Longarm in \"Shadows &amp; Light\" #1 (Feb. 1998), in a self-inked, 12-page Iron Man story \"A Man's Reach...\", scripted by Len Wein. His final mainstream work was a five-page New Gods story for DC Comics, \"Infinitely Gentle Infinitely Suffering\", inked by Mick Gray and believed to be intended for the 2000\u20132002 \"Orion\" series but not published until the 2008 trade paperback \"Tales of the New Gods\".\nThereafter, Ditko's solo work was published intermittently by Robin Snyder, who was his editor at Charlton, Archie Comics, and Renegade Press in the 1980s. The Snyder publications have included a number of original books as well as reprints such as \"Static\", \"The Missing Man\", \"The Mocker\" and, in 2002, \"Avenging World\", a collection of stories and essays spanning 30\u00a0years.\nIn 2008, Ditko and Snyder released \"The Avenging Mind\", a 32-page essay publication featuring several pages of new artwork; and \"Ditko, Etc...\", a 32-page comic book composed of brief vignettes and editorial cartoons. Releases have continued in that format, with stories introducing such characters as the Hero, Miss Eerie, the Cape, the Madman, the Grey Negotiator, the !? and the Outline. He said in 2012 of his self-published efforts, \"I do those because that's all they'll let me do\".\nIn addition to the new material, Ditko and Snyder reprinted earlier Ditko material. In 2010 they published a new edition of the 1973 \"Mr.\u00a0A\" comic and a selection of Ditko covers in \"The Cover Series\". In 2011 they published a new edition of the 1975 comic \"...Wha...!? Ditko's H. Series\".\nTwo \"lost\" stories drawn by Ditko in 1978 have been published by DC in hardcover collections of the artist's work. A Creeper story scheduled for the never published \"Showcase\" #106 appears in \"The Creeper by Steve Ditko\" (2010) and an unpublished \"Shade, the Changing Man\" story appears in \"The Steve Ditko Omnibus Vol.\u00a01\" (2011). A Hulk and the Human Torch story written by Jack C. Harris and drawn by Ditko in the 1980s was published by Marvel as \"Incredible Hulk and the Human Torch: From the Marvel Vault\" #1 in August 2011.\nPersonal life.\nAs of 2012, Ditko continued to work in Manhattan's Midtown West neighborhood. He mostly declined to give interviews or make public appearances, explaining in 1969 that, \"When I do a job, it's not my personality that I'm offering the readers but my artwork. It's not what I'm like that counts; it's what I did and how well it was done. I produce a product, a comic art story. Steve Ditko is the brand name.\" However, he did contribute numerous essays to Robin Snyder's fanzine \"The Comics\".\nAs far as it is known, Ditko never married and had no surviving children at the time of his death. He had a nephew, also named Steve Ditko, who became an artist. Will Eisner stated that Ditko had a son out of wedlock; this may have been a confused reference to the nephew.\nPolitically, Ditko supported a \"constitutional republic\" and \"inalienable individual and property rights\". He supported neither George W. Bush nor John Kerry in the 2004 presidential election due to believing neither would prioritize those rights.\nDitko said in 2012 that he had made no income on the four \"Spider-Man\" films released to that time. However, a neighbor of Ditko stated that Ditko received royalty checks. Those involved with creating the 2016 film \"Doctor Strange\" purposely declined to contact him during production, believing they would not be welcome.\nDitko described himself as an atheist.\nObjectivism.\nDitko was an ardent supporter of Objectivism. The philosophy of Ayn Rand had \"forever changed [Ditko's] outlook on morality, finances and his mission as a comic-book creator\". After Ditko had received greater control of the plotting, he began revering the role of policemen in his Spider-Man work. Ditko had once told his Charlton co-worker Pete Morisi, a policeman who moonlighted as a comic book artist, that he envied Morisi for being able to arrest criminals. Randian philosophy had influenced Ditko to demand being credited and compensated as both the plotter and artist for Spider-Man beginning in issue #25, which Stan Lee (now credited as \"scripter\") allowed, though their working relationship would begin deteriorating. Other ways Ditko incorporated Randian views into Spider-Man were by having Peter Parker become more aggressive, demand better pay for his Spider-Man photos, and show contempt for student protestors. Marvel publisher Martin Goodman had been worried that Parker's hard right-wing politics would distance the character from most left-leaning, countercultural university students, and disputes with Goodman over royalties had led to Ditko leaving Marvel. Ditko later expressed his Objectivist views even further with the Question, who criticized the apathy of the public toward right and wrong, and Mr.\u00a0A, who refused to save villains from death.\nHe also described himself as an Aristotelian which his Objectivist views would align with.\nDeath.\nDitko was found unresponsive in his apartment in New York City on June 29, 2018. Police said he had died within the previous two days. He was pronounced dead at the age of 90, with the cause of death initially deemed as a result of a heart attack, brought on by arteriosclerotic and hypertensive cardiovascular disease.\nThe final words of Ditko's last essay, published posthumously in \"Down Memory Lane\" in February 2019, quoted an \"old toast\": \"Here's to those who wish me well, and those that don't can go to hell.\"\nIn June 2021, Ditko's nephew Mark Ditko was interviewed and discussed his history with his uncle and his legacy, dispelling myths about him while also discussing his work with the Bottleworks Exhibition which houses a Steve Ditko Exhibition. He also shared rare photos among many other facts.\nLegacy.\nIn 2021, Steve Ditko's younger brother Patrick, executor of his estate, in cooperation with the estates of artistic colleagues Don Heck, Gene Colan and Don Rico filed a lawsuit to terminate and reclaim the copyrights for their characters from Marvel Comics under the justification of the Copyright Act of 1976. Marvel countersued the litigants citing the same law since the creations were made under work for hire contracts, the company had full ownership. While the other participants settled in June 2023, the Ditko estate persisted until December 8, 2023. Although the settlements are confidential, Marvel's full ownership of the copyrights was secured for undisclosed sums to the creators.\nIn June 2022, a mural was completed in Ditko's hometown. Approved by Marvel Comics, and featuring his two most well-known characters (Spider-Man and Dr. Strange), the outline of the artwork was printed upon large white sheets of durable material. Community members painted upon the sheets during the winter and spring months, and then they were attached to a 28-foot tall wall.\nDitko was honored as a Disney Legend for his contributions to Marvel, and by extension the Walt Disney Company, at the 2024 D23 Expo.\nArtistic style.\nDitko preferred to introduce characters before giving them a proper origin story (which he called \"legends\"), believing that a character should first be proven worthy of having their origins told. For example, Doctor Strange first appeared abruptly in \"Strange Tales\" #110 before his origin was revealed in issue #115, which Stan Lee attributed to the pair forgetting to tell but was in fact intentional.\nBBC documentary.\nIn September 2007, presenter Jonathan Ross hosted a one-hour documentary for BBC Four titled \"In Search of Steve Ditko\". The program covers Ditko's work at Marvel, DC, and Charlton Comics and at Wally Wood's \"witzend\", as well as his following of Objectivism. It includes testimonials by writers and artists Alan Moore, Mark Millar, Jerry Robinson and Stan Lee, among others. Ross, accompanied by writer Neil Gaiman, met Ditko briefly at his New York office, but he declined to be filmed, interviewed or photographed. He did, however, give the two a selection of some comic books. At the end of the show, Ross said he had since spoken to Ditko on the telephone and, as a joke, that he was now on first name terms with him.\nBibliography.\nAs penciler (generally but not exclusively self-inked), unless otherwise noted\nFarrell Publications\nHarvey Comics\nKey Publications\nPrize Comics\nCharlton Comics\nMarvel Comics\n\"Amazing Adult Fantasy\" #7\u201314 (1961\u20131962); becomes\n\"Amazing Fantasy\" #15 (debut Spider-Man) (1962)\nSt. John Publications\nDC Comics\nACG\nDell Publishing\nWarren Publishing\nTower Comics\nIndependent\nAtlas/Seaboard\nCPL Gang\nStar*Reach Productions\nM W Communications\nPacific Comics\nNew Media Publishing\nFirst Comics\nEclipse Comics\nEpic Comics\nArchie Comics\nDeluxe Comics\nRenegade Press\nGlobe Communications\nAce Comics\n3-D- Zone\nValiant Comics\nMarvel UK\nDark Horse Comics\nDefiant Comics\nTopps Comics\nYoe! Studio\nFantagraphics Books\nAC Comics\nRobin Snyder\n\"Steve Ditko's 160-Page Package\" (1999)\n\"Steve Ditko's 80-Page Package: The Missing Man\" (1999)\n\"Steve Ditko's 160-Page Package: From Charlton Press\" (1999)\n\"Steve Ditko's 176-Page Package: Heroes\" (2000)\n\"Steve Ditko's 32-Page Package: Tsk! Tsk!\" (2000)\n\"The Avenging Mind\" (2008)\n\"Ditko, etc...\" (2008)\n\"Ditko Continued...\" (2008)\n\"Oh, No! Not Again, Ditko\" (2009)\n\"Ditko Once More\" (2009)\n\"Ditko Presents\" (2009)\n\"A Ditko Act Two\" (2010)\n\"A Ditko Act 3\" (2010)\n\"Act 4\" (2010)\n\"Act 5\" (2010)\n\"Act 6\" (2011)\n\"Act 7, Seven, Making 12\" (2011)\n\"Act 8, Making Lucky 13\" (2011)\n\"A Ditko #14\" (2011)\n\"A Ditko #15\" (2011)\n\"#16: Sixteen\" (2012)\n\"#17: Seventeen\" (2012)\n\"Ate Tea N: 18\" (2013)\n\"#9 Teen\" (2014)\n\"#20\" (2014)\n\"#2oww1\" (2014)\n\"#22\" (2015)\n\"#23\" (2015)\n\"#24\" (2016)\n\"#25\" (2016)\n\"#26\" (2018)\n\"Down Memory Lane\" (2019)\n\"Vol. I: Overture\" (2019) collecting 5 issues: \"Avenging Mind\" through \"Ditko Once More\"\n\"Vol. II: Opening Acts\" (2019) collecting 5 issues: \"Ditko Presents\" through \"Act 5\"\n\"Vol. III: Character Twists\" (2019) collecting 5 issues: \"Act 6\" through \"A Ditko #15\"\n\"Vol. IV: Postshadowing\" (2019) collecting 6 issues: \"#16: Sixteen\" through \"#2oww1\"\n\"Vol. V: Curtain\" (2019) collecting 6 issues: \"#22\" through \"Down Memory Lane\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29552", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=29552", "title": "Sardinia/Nugoro", "text": ""}
{"id": "29553", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=29553", "title": "Sardinia/Fonni", "text": ""}
{"id": "29554", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=29554", "title": "Sardinia/Gavoi", "text": ""}
{"id": "29555", "revid": "11521989", "url": "https://en.wikipedia.org/wiki?curid=29555", "title": "List of tourist attractions in Sardinia", "text": "This is a list of the most famous tourist destinations of Sardinia. Minor islands are included from Olbia, clockwise \u2014 industrial sites are not included."}
{"id": "29556", "revid": "51009592", "url": "https://en.wikipedia.org/wiki?curid=29556", "title": "List of people from Sardinia", "text": "Sardinia is the second-largest island in the Mediterranean Sea, with a population of about 1.6 million people. The list includes notable natives of Sardinia, as well as those who were born elsewhere but spent a large part of their active life in Sardinia. People of Sardinian heritage and descent are in a separate section of this article.\nPolice officers.\nEmanuela Loi\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29558", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=29558", "title": "Gavinus", "text": "Martyr and saint\nGavinus () is a Christian saint who is greatly celebrated in Sardinia, Italy, as one of the Martyrs of Torres (), along with his companions Protus, a bishop, and Januarius, a deacon.\nNarrative.\nHe was a Roman soldier martyred for the Christian faith during the persecution of Diocletian in 304 in the city of Porto Torres (), according to the legend, on the orders of the governor (\"preside\") of Sardinia and Corsica, a certain Barbarus.\nThe earliest \"passio\" dates to the 12th century:\nBarbaro, who had been sent to Corsica and Sardinia, reached Turres and published the imperial edicts against the Christians, was denounced by Proto, Gavino and Gianuario. They were summoned to the tribunal and being steadfast in refusing to sacrifice to the gods, were summarily beheaded.\nA second, longer, \"passio\", from the middle of the thirteenth century, follows standard medieval hagiographical conventions. In this, Protus and Januarius are arrested and subjected to torture. Gavinus is a soldier conveying them to prison. Impressed with their courage, he releases them and asks for their prayers. The next day Gavinus was arrested for failing to produce his prisoners, and when he declared himself a Christian, was beheaded on the shore. Hearing that Gavinus had preceded them in martyrdom, Protus and Januarius returned to the city, were arrested, and likewise beheaded. The story of the martyrdom was distributed in nine readings for use in the recitation of Matins.\nLegacy.\nThe well-known Romanesque church of San Gavino in Gavoi is dedicated to him, as is the town of San Gavino Monreale, and a number of communes in Corsica.\nThe 11th-century Basilica of San Gavino in Porto Torres, is also dedicated to this saint. It was built by Comita or Gomida, Judge of Torres, and contains the relics, not only of Gavinus, but also of his companions, Protus and Januarius. According to legend, Gavinus appeared to Comita and requested he build the church. The relics of the saints were discovered in the crypt 1614.\nPatronage.\nGavinus is one of the patron saints of Sassari.\nGavinus is the patron saint of Porto Torres, Sardinia, and of Camposano, Campania. \nHis feast day is given in the Roman Martyrology as 30 May.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29559", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=29559", "title": "Sienna", "text": "Earth pigment\nSienna (from it\u00a0'earth of Siena') is an earth pigment containing iron oxide and manganese oxide. In its natural state, it is yellowish brown, and it is called raw sienna. When heated, it becomes a reddish brown, and it is called burnt sienna. It takes its name from the city-state of Siena, where it was produced during the Renaissance. Along with ochre and umber, it was one of the first pigments to be used by humans, and is found in many cave paintings. Since the Renaissance, it has been one of the brown pigments most widely used by artists.\nThe first recorded use of \"sienna\" as a color name in English was in 1760.\nThe for sienna are identical to kobe, first recorded as a color name in English in 1924.\nEarth colors.\nLike the other earth colors, such as yellow ochre and umber, sienna is a clay which is partially composed of iron oxides. In the case of sienna, the most prevalent iron oxides are limonite (which in its natural state has a yellowish color), and goethite. In addition to iron oxides, natural or raw sienna is also composed of manganese oxide, which makes it darker than ochre. Aluminum oxides have also been found in the soil at very low levels. When heated, the limonite and goethite is dehydrated and turns partially to hematite, which gives it a reddish-brown color.\nSienna is lighter in shade than raw umber, which is also clay with iron oxide, but which has a significantly higher content of manganese (5 to 20 percent) making it greenish brown or dark brown in color. When heated, raw umber becomes burnt umber, a very dark brown.\nHistory.\nThe pigment sienna was known and used in its natural form by the ancient Romans. It was mined near Arcidosso (formerly under Sienese control, now in the province of Grosseto) on Monte Amiata in southern Tuscany. It was called \"terra rossa\" (red earth), \"terra gialla\" (yellow earth), or terra di Siena\".\"\nIn the Middle Ages the sienna pigments were used by artists such as Duccio di Buoninsegna and other painters who lived and worked in and around the Republic of Siena. Duccio was painting with earth pigments in the late 13th century until his death in the early 14th century.\nDuring the Renaissance, Giorgio Vasari made note of the pigment under the name terra rossa. Along with umber and yellow ochre, sienna became one of the standard browns used by artists from the 16th to 19th centuries, including Caravaggio (1571\u20131610) and Rembrandt (1606\u20131669), who used all three earth colors in his palette. Cross sections of Rembrandt's works, analyzed by X-Ray and infrared lenses, reveal that he used variations of sienna to prime his paintings. This was especially true for some of his later works.\nAlthough these artists are known to have used sienna and its variations in their works, scholars have pointed out that the pigment was not commonly referenced by name in European sources until the mid-eighteenth century.52\nBy the 1940s, the traditional Italian sources of the pigment were nearly exhausted. Much of today's sienna production is carried out in the Italian islands of Sardinia and Sicily, while other major deposits are found in the Appalachian Mountains, where it is often found alongside the region's iron deposits. It is also still produced in the French Ardennes in the small town of Bonne Fontaine near Ecordal. It is important to note that the chemical composition of the umbers produced in France are distinctly different from the original siennas.\nIn the 20th century, pigments began to be produced using synthetic iron oxide rather than natural deposits. The labels on paint tubes indicate whether they contain natural or synthetic ingredients. PY-43 indicates natural raw sienna, while PR-102 indicates natural burnt sienna.\nHistorical preparation.\nHistorically, the pigment was prepared by taking lumps of earth and placing them into a fire either using a crucible or shovel, in order to induce the necessary chemical reaction. In some seventeenth-century accounts, the lumps of earth are supposed to be pulverized, or at least broken down into smaller pieces, first. However, the instructions from the time period are inconsistent. Furthermore, the amount of time that the pigment needs to be heated is based on what the artist preparing the pigment desires. Generally, a longer exposure to heat leads to a deeper red hue.\nShades and variations.\nSienna varies slightly in shade and hue based on the chemical composition of the soil and the temperature and length of time in which it is prepared. A higher composition of iron oxide in the soil leads to a deeper red pigment.\nThere is no single agreed standard for the color of sienna, and the name is used today for a wide variety of hues and shades. They vary by country and color list, and there are many proprietary variations offered by paint companies. The color box at the top of the article shows one variation from the ISCC-NBS color list.\nRaw sienna.\nRaw sienna is a yellowish-brown natural earth pigment, composed primarily of iron oxide hydroxide. The box shows the color of the pigment in its natural, or raw state. It contains a large quantity of iron oxide and a small quantity (about five percent) of manganese oxide.\nThis kind of pigment is known as yellow ochre, yellow earth, limonite, or terra gialla. The pigment name for natural raw sienna from the Color Index International, shown on the labels of oil paints, is PY-43.\nThis box at right shows a variation of raw sienna from the Italian Ferrario 1919 color list.\nBurnt sienna.\nBurnt sienna contains a large proportion of anhydrous iron oxide. It is made by heating raw sienna, which dehydrates the iron oxide, changing it partially to hematite, giving it rich reddish-brown color.\nThe pigment is also known as red earth, red ochre, and terra rossa. On the Color Index International, the pigment is known as PR-102.\nThis version is from the Italian Ferrario 1919 color list.\nThe first recorded use of \"burnt sienna\" as a color name in English was in 1853.\nBurnt sienna pigment (Maerz and Paul).\nThis variation of burnt sienna is from the Maerz and Paul \"A Dictionary of Color\" from 1930. It is considerably lighter than most other versions of burnt sienna. It was a mix of burnt orange and raw sienna.\nDark sienna (ISCC-NBS).\nThis infobox shows the color dark sienna from the ISCC-NBS color list.\nSienna (X11 color).\nThe web color sienna is defined by the list of X11 colors used in web browsers and web design.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29564", "revid": "6204540", "url": "https://en.wikipedia.org/wiki?curid=29564", "title": "Super Bowl XXXVI", "text": "2002 National Football League championship game\nSuper Bowl XXXVI was an American football game between the National Football Conference (NFC) champion St. Louis Rams and the American Football Conference (AFC) champion New England Patriots to decide the National Football League (NFL) champion for the 2001 season. The underdog Patriots defeated the heavily favored Rams by the score of 20\u201317. It was the Patriots' first Super Bowl championship, and the franchise's first league championship of any kind. The game was also notable for snapping the AFC East's long streak of not being able to win a Super Bowl championship, as the division's teams had lost 8 Super Bowls between the Miami Dolphins' victory in 1974 and the Patriots' 2002 win. This was the last Super Bowl to feature the St. Louis Rams; after relocating to Los Angeles in 2016, the Rams returned to the NFL's championship game in Super Bowl LIII, in which they were again defeated by the Patriots. The Rams would not win another Super Bowl until Super Bowl LVI, as the Los Angeles Rams, defeating the Cincinnati Bengals.\nThe game was played at the Louisiana Superdome in New Orleans, Louisiana, on February 3, 2002. Following the terrorist attacks on September 11, 2001 earlier in the season, the NFL postponed a week of regular-season games and moved the league's playoff schedule back. As a result, Super Bowl XXXVI was rescheduled from the original date of January 27 to February 3, becoming the first Super Bowl played in February. The pregame ceremonies and the halftime show headlined by the Irish rock band U2 honored the victims of 9/11. Due to heightened security measures following the attacks, this was the first Super Bowl designated as a National Special Security Event (NSSE) by the Office of Homeland Security (OHS). The Department of Homeland Security (DHS), which replaced the OHS in 2003, later established the practice of naming each subsequent Super Bowl an NSSE. Additionally, it was the last Super Bowl to be played in New Orleans before Hurricane Katrina ravaged the city on August 29, 2005; the first since then was Super Bowl XLVII in 2013.\nThis game marked the Rams' third Super Bowl appearance in franchise history and the second in three seasons. The Rams posted an NFL-best 14\u20132 regular season record, led by quarterback Kurt Warner and \"The Greatest Show on Turf\" offense. The Patriots clinched their third Super Bowl berth after posting an 11\u20135 regular season record, led by second-year quarterback and first-year starter Tom Brady and a defense that ended the regular season ranked sixth in scoring.\nAlthough the Rams out-gained the Patriots 427\u2013267 in total yards, the Patriots built a 17\u20133 third-quarter lead off three Rams turnovers. After a holding penalty in the fourth quarter negated a Patriots fumble return for a touchdown, Warner scored a 2-yard touchdown run and threw a 26-yard touchdown pass to tie the game, 17\u201317, with 1:30 remaining. Without any timeouts, Brady led the Patriots down the field to set up kicker Adam Vinatieri's game-winning 48-yard field goal as time expired. Brady, who completed 16 of 27 passes for 145 yards and a touchdown, was named Super Bowl MVP. With the Rams being 14-point favorites, it was the biggest upset in a Super Bowl since Super Bowl III and, as of the 2024 season, the biggest upset since the AFL\u2013NFL merger. Many media outlets regard this Super Bowl as one of the best Super Bowls of all time, and one of the most historically significant Super Bowls due to its finale that launched the New England Patriots dynasty. During the NFL's 100th anniversary, this game was ranked as No. 20 of the NFL's Greatest Games of all time.\nBackground.\nTeams.\nSt. Louis Rams.\nAfter the Rams\u2019 1999 season that had culminated in a gripping victory over the Tennessee Titans in Super Bowl XXXIV, their offense again dominated the league in 2000, leading the NFL in passing, scoring, and total yards. However, the Rams had one of the worst defenses in the league, ranking last in points allowed (471). This, along with injury problems and a coaching change from championship-winning head coach Dick Vermeil \u2013 who resigned just 48 hours after the game \u2013 to his offensive coordinator Mike Martz, caused the Rams to slip to a 10\u20136 record in 2000. The season ended with a disappointing loss to the New Orleans Saints in the wild card round of the playoffs.\nAfter signing several new defensive players in the off-season, and hiring new defensive coordinator Lovie Smith, the Rams finished the 2001 season with the NFL's best regular season record at 14\u20132. They led the league in both total offensive yards (6,930) and scoring (503). This was the Rams' third consecutive season with over 500 points, an NFL record. On defense, they only allowed 271 points, improving their 31st ranking in 2000 to 7th in 2001.\nThe Rams' 1999\u20132001 offense, nicknamed \"The Greatest Show on Turf\", is widely considered one of the best in NFL history. The team possessed an incredible amount of offensive talent at nearly every position. In 2001, quarterback Kurt Warner had the best season of his career and was awarded his second and final NFL Most Valuable Player Award after throwing for 4,830 yards and 36 touchdowns, but he also threw 22 interceptions, and earned a league high 101.4 passer rating. Wide receivers Torry Holt and Isaac Bruce each amassed over 1,100 receiving yards, combining for 142 receptions, 2,469 yards, and 13 touchdowns. Wide receiver Ricky Proehl caught 40 passes for 563 yards and 5 touchdowns. Tight end Ernie Conwell caught 38 passes for 431 yards and 4 touchdowns. Wide receiver Az-Zahir Hakim caught 39 passes for 374 yards, and added another 333 yards returning punts.\nHalfback Marshall Faulk won NFL Offensive Player of the Year Award for the third year in a row in 2001. He rushed for 1,382 yards, caught 83 passes for 765 yards, scored 21 touchdowns, and became the first NFL player ever to gain more than 2,000 combined rushing and receiving yards for 4 consecutive seasons. Running back Trung Canidate was also a major contributor, rushing for 441 yards, catching 17 passes for 154 yards, returning kickoffs for 748 yards, and scoring 6 touchdowns. The Rams offensive line was led by guard Adam Timmerman and offensive tackle Orlando Pace, who was selected to the Pro Bowl for the third consecutive year.\nThe Rams' defense ranked third in the league in fewest yards allowed (4,733). The line was anchored by Pro Bowl defensive end Leonard Little, who led the team with 14.5 sacks and recovered a fumble, and defensive end Grant Wistrom, who recorded 9 sacks, 2 interceptions, and 1 fumble recovery. The Rams linebackers unit was led by London Fletcher, who had 4.5 sacks, 2 interceptions, and 4 forced fumbles. St. Louis also had an outstanding secondary, led by Dr\u00e9 Bly (6 interceptions, 150 return yards, and 2 touchdowns), Pro Bowl selection Aeneas Williams (4 interceptions, 69 return yards, 2 touchdowns), and Dexter McCleon (4 interceptions, 66 yards).\nThe Rams also bested the Patriots in a nationally televised ESPN Sunday night game on November 18 at Foxboro Stadium. Although the Patriots jumped out to an early lead, a critical turnover before the end of the first half that led to a Rams score proved costly. In the second half, the Rams wore the Patriots down and won 24\u201317. The Rams lost four of their defensive players with injuries. The Patriots' physical play led Rams head coach Mike Martz to say after the game that the Patriots were \"a Super Bowl\u2013caliber team.\"\nNew England Patriots.\nThe Patriots' chances for a Super Bowl appearance seemed bleak shortly after the season had begun. Before the season started, quarterbacks coach Dick Rehbein died of a heart attack at age 45. The Patriots, coached by Bill Belichick, lost their first two games, and in their second loss at home to the New York Jets, starting quarterback Drew Bledsoe suffered a sheared blood vessel on a hit by Jets linebacker Mo Lewis that caused him to miss several weeks. His replacement was second-year quarterback Tom Brady, a sixth-round draft pick who had thrown only three passes in 2000. Also, midway through the season, wide receiver Terry Glenn, the team's leading receiver in 2000, was benched due to off-the-field problems. He had been suspended the first four games for failing a drug test and played in just four more before injuries and disputes with the coaching staff caused Belichick to deactivate him for good.\nUpon assuming the role of starting quarterback, Brady enjoyed immediate success in the regular season, leading the Patriots to a 44\u201313 win over the Indianapolis Colts in his first start and eventually to an 11\u20135 record. He completed 63.9 percent of his passes for 2,843 yards and 18 touchdowns with 12 interceptions and was selected to the Pro Bowl. Veteran Pro Bowl wide receiver Troy Brown was the main receiving threat, recording 101 receptions for 1,199 yards and 5 touchdowns, while also adding another 413 yards and 2 touchdowns returning punts. His 14.2 yards per punt return average led the NFL. Wide receiver David Patten also was productive, catching 51 passes for 749 yards and 4 touchdowns. Running back Antowain Smith provided the team with a stable running game, rushing for 1,157 yards, catching 19 passes for 192 yards, and scoring 13 touchdowns.\nThe Patriots were outstanding on defense as well. Up front, linemen Bobby Hamilton (7 sacks, 1 fumble recovery) and rookie Richard Seymour excelled at pressuring quarterbacks and stuffing the run. Behind them, the Patriots had three outstanding linebackers: Mike Vrabel (2 interceptions, 3 sacks), Willie McGinest (5 sacks), and Tedy Bruschi (2 interceptions). The secondary also featured outstanding talent such as defensive back Otis Smith, who led the team with five interceptions for 181 yards and two touchdowns. Cornerback Ty Law intercepted three passes, returning them for 91 yards and two touchdowns. Safety Lawyer Milloy had two interceptions during the season, and was selected along with Law to represent the Patriots' defense in the Pro Bowl. The defense ended the season ranked sixth in scoring, but 24th in total yards allowed. Following their loss to the Rams at home, the Patriots dropped to 5\u20135, but did not lose again the rest of the season to clinch a first-round bye in the AFC playoffs.\nCoincidentally, this was the third straight time that the Patriots' Super Bowl appearance would be at the Louisiana Superdome, joining the Dallas Cowboys as the only teams to play three different Super Bowls in one stadium; the Cowboys had played three at the old Miami Orange Bowl in the 1970s. In their maiden Super Bowl appearance in Super Bowl XX (1986), the Patriots lost 46\u201310 \u2013 the biggest margin of victory in a Super Bowl to that point \u2013 to a Chicago Bears team coached by Mike Ditka and including Mike Singletary and Walter Payton. The Patriots returned to the Superdome 11 years later for Super Bowl XXXI but lost 35\u201321 to a Green Bay Packers team including Brett Favre, Reggie White and Desmond Howard and coached by Mike Holmgren. Milloy, Law, Vinatieri, Bledsoe, McGinest, Bruschi, and Otis Smith were among the players who had played in that game while Belichick had been assistant head coach to Bill Parcells. The Patriots did not appear in a Super Bowl hosted by another city until the team played in Super Bowl XXXVIII two years later in Houston, Texas.\nPlayoffs.\nThe Rams began their postseason run with a 45\u201317 win over the Green Bay Packers in the NFC divisional round. Expected to be a close shootout between Warner and Packers quarterback Brett Favre, the Rams defense dominated the Packers by intercepting a playoff record 6 passes from Favre and returning 3 of them for touchdowns. The Rams offense also racked up 24 points on 2 touchdown passes by Warner, a touchdown run by Faulk, and a field goal by Jeff Wilkins, helping the Rams put the game away by the end of the third quarter.\nOne week later, the Rams advanced to the Super Bowl with a 29\u201324 win over the Philadelphia Eagles in the NFC Championship Game. The Eagles managed to build a 17\u201313 halftime lead, but the Rams scored 16 consecutive second half points (2 touchdown runs by Faulk and a Wilkins field goal) to earn the win, limiting the Eagles to only one touchdown pass in the second half. Warner finished the game with 22 of 33 pass completions for 212 yards and a touchdown, with no interceptions, while Faulk rushed for 159 yards and 2 touchdowns.\nIn the AFC Divisional Round, the Patriots defeated the Oakland Raiders 16\u201313 during a raging New England snowstorm in the last game ever played at Foxboro Stadium. The signature moment of the game was a controversial ruling by referee Walt Coleman in the fourth quarter that caused this game to be commonly known as the \"Tuck Rule Game.\" While the Patriots possessed the ball, trailing the Raiders 13\u201310 with under two minutes left in regulation and no time outs, Brady was sacked by defensive back Charles Woodson, and appeared to fumble the ball. The fumble was recovered by Raiders linebacker Greg Biekert, presumably ending the game with a Raiders victory. After reviewing the play using instant replay, Coleman reversed the call on the field pursuant to the \"tuck rule\", where a loose ball is ruled an incomplete pass if lost while \"tucking\" the ball. Most of the controversy centered on whether Brady was still trying to tuck the ball away when he lost control. Brady then led his team to the Raiders' 27-yard line, where kicker Adam Vinatieri made a 45-yard field goal which barely cleared the crossbar to send the game into overtime. The Patriots won the toss in overtime and won on another Vinatieri field goal from 23 yards; per the overtime rules in place at that time. The Raiders' offense never regained possession.\nIn the AFC Championship Game, the Patriots traveled to Heinz Field to face the Pittsburgh Steelers, who were coming off a 27\u201310 win over the previous season's Super Bowl champion Baltimore Ravens. The Patriots scored first with a 55-yard punt return touchdown by Brown, but in the second quarter, Brady was knocked out of the game with a sprained ankle. He was replaced by Bledsoe in Bledsoe's first game action since being injured in September. Upon entering the game, Bledsoe quickly moved the Patriots down the field and threw an 11-yard touchdown pass to Patten to give the Patriots a 14\u20133 halftime lead. Early in the second half, the Steelers moved from their own 32 to the Patriots' 16-yard line, where they lined up for a field goal by Kris Brown. However, Brandon Mitchell blocked the kick, Brown picked up the ball at the 40 and ran 11 yards before lateraling to Antwan Harris, who took it 49 yards for a touchdown that made the score 21\u20133. But the Steelers scored two third-quarter touchdowns to make the score 21\u201317. The Patriots ended the comeback attempt by scoring a field goal in the fourth quarter and intercepting two passes from Steelers quarterback Kordell Stewart in the final 3 minutes of the game.\nHost selection process.\nNFL owners voted to award Super Bowl XXXVI to New Orleans during their October 28, 1998 meeting in Kansas City, Missouri. Two cities made presentations, the other being San Diego (Qualcomm Stadium). San Francisco (Candlestick Park) had planned to pursue XXXVI, but due to logistical complications, withdrew themselves from consideration, and switched their proposal to XXXVII. With only two choices, the league set up a two-round voting system. A city would win if they received &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3\u20444 of the vote during the first round. If neither city won during the first round, the second round would revert to a simple majority. New Orleans won on the second ballot over San Diego in what was described as a \"close vote\". This was the ninth time that New Orleans hosted the game, and fifth time it would be played in the Superdome.\nImmediately after the vote, NFL commissioner Paul Tagliabue made an unexpected and largely unprecedented announcement that San Diego was the favorite to host the next available Super Bowl. With San Francisco tentatively scheduled to host XXXVII in 2003, San Diego was thought likely to host XXXVIII in 2004. However, the league took XXXVII away from San Francisco after plans for a new stadium fell through, and the 2003 game ultimately went to San Diego.\nEffect of the September 11, 2001, attacks.\nThe September 11, 2001, terrorist attacks led the league to postpone its September 16 games and play them a week after the scheduled conclusion of the regular season. This caused the playoffs and Super Bowl to be delayed by one week. Rescheduling Super Bowl XXXVI from January 27 to February 3 proved extraordinarily difficult. In addition to rescheduling the game itself, all related events and activities had to be accommodated. This marked the first time in NFL history that the Super Bowl was played in February; all subsequent Super Bowls (excluding XXXVII in 2003) have been played in February. In turn, this and the games from XXXVIII (2004) to LV (2021) were to now be played on the first Sunday in February. The NFL expanded its season from 16 to 17 regular season games, and LVI (2022) became the first to be played on the second Sunday of the month.\nHistorically, the NFL made allowance for an open weekend between the Conference Championship games and the Super Bowl. However, there was not one scheduled for 2001, due to the NFL's decision beginning in the 1999 season to move the opening week of games to the weekend after Labor Day. Because the date of the Super Bowl had been set through 2003, the bye week prior to the Super Bowl did not return until 2004.\nThe NFL and New Orleans officials worked diligently to put together a deal to reschedule the game. The league considered a number of options, including shortening the regular season, shortening the playoffs, condensing the three playoff rounds in two weeks, and moving the game to the Rose Bowl in Pasadena, California. It was eventually decided to make every effort to maintain a full regular season and playoff, and push the Super Bowl back to February 3. Additionally, due to the Super Bowl being moved back a week, the first weekend of New Orleans Mardi Gras parades rolled one week earlier than normal.\nOne of the most significant logistical challenges was accommodating the National Automobile Dealers Association (NADA) Convention, which was originally slated to occupy the Superdome on February 3. On October 3, 2001, the NFL announced its intentions to hold the game on February 3, even though no agreement had been reached with NADA. Several weeks later, the three parties came to an accord in which the NADA agreed to move its convention date to the original Super Bowl week in exchange for financial and other considerations, including promotional spots shown during selected regular season NFL games. This agreement permitted the NFL to move the game back to February 3, and allowed for a full standard playoff tournament.\nThe original logo for Super Bowl XXXVI had a style that reflected the host city, and was distributed on some memorabilia items during 2001. However, after the 9/11 attacks, a new logo reflecting American patriotism was designed, featuring the shape of the 48 contiguous states and the American flag colors of red, white, and blue. Rob Tornoe of \"The Philadelphia Inquirer\" noted that it had \"become one of the most iconic logos in Super Bowl history\".\nJanet Jackson was originally scheduled to perform during the Halftime Show, but allowed U2 to perform to tribute the events of September 11 (Jackson would perform at the halftime show two years later).\nVenue.\nThis was the final Super Bowl played on the first-generation AstroTurf surface. From 2000 to 2005, NFL stadiums phased out the short-pile AstroTurf in favor of natural grass or other, newer artificial surfaces which closely simulate grass, like FieldTurf.\nPrior to Super Bowl XXXVI, Superdome officials considered installing natural grass for the game. The proposed installation method was comparable to what had been used at the Silverdome during the 1994 FIFA World Cup, and at Giants Stadium from 2000 to 2002. The plan called for large trays of grass to be grown and cultivated outdoors, then brought inside the dome and placed on the field for the game. In the end, cost and quality concerns prompted stadium and league officials to abandon the project.\nPregame notes.\nThe Rams entered as 14-point favorites. This was partly because Rams quarterback Kurt Warner statistically had his best year of his career, with a quarterback rating of 101.4, a 68.7 percent completion rate, and threw for 4,830 yards. Many had believed that the Patriots' Cinderella story was simply a fluke, especially after beating the veteran Oakland Raiders in a controversial playoff game in which a recovered fumble by the Raiders was reversed by the tuck rule.\nThere had been speculation on whether longtime starter Drew Bledsoe might start the game. As stated above, Bledsoe replaced an injured Brady against the Steelers in the AFC Championship game. Eventually, though, Brady was named starter.\nThis Super Bowl also meant that Boston and St. Louis would play each other in the championship game or series of all four major North American sports leagues at least once, becoming the first time that that had happened between teams from two specific cities or regions. This was the eighth meeting between teams from Boston and St. Louis for a major professional sports championship overall. Previously, \nThe Patriots, as the designated home team, wore their home nautical blue jerseys and silver pants, while the Rams donned their road white jerseys and New Century Gold pants.\nBroadcasting.\nThe game was broadcast in the United States by Fox. The telecast was presented in a 480p enhanced-definition format marketed as \"Fox Widescreen\". While promoted as having higher quality than standard-definition, and being the first widescreen sports telecast on U.S. television to use a singular telecast for all viewers (rather than using a separate production exclusive to the widescreen feed), it was not true high definition, but still matched the aspect ratio of HDTV sets.\nThe game was called by play-by-play announcer Pat Summerall and color commentator John Madden. Pam Oliver and Ron Pitts served as sideline reporters. This was Summerall's 26th and final Super Bowl broadcast on television or radio (and his 11th doing play by play). It was also the eighth and final Super Bowl telecast, and final NFL telecast of any kind, for the Summerall and Madden announcing team. The two had become the NFL's most famous broadcast duo since they were paired together in 1981 on CBS. After this game, Summerall retired from broadcasting and Madden moved to ABC's \"Monday Night Football\". As a result, Madden was the first person to announce Super Bowls on different networks in consecutive years when he called Super Bowl XXXVII on ABC with Al Michaels.\nJames Brown hosted all the events with help from his fellow \"Fox NFL Sunday\" cast members Terry Bradshaw, Howie Long, and Cris Collinsworth. Jillian Barberie served as the weather and entertainment reporter during the pre-game show.\nAdvertising.\nMemorable television commercials that aired during the game included Columbia Pictures' trailer for \"Spider-Man\", Budweiser's \"Picking a Card\", and Super Bowl Ad Meter commercial of the year winners Bud Light \"Satin Sheets.\" The best commercial of the year from Adbowl M&amp;M's \"Chocolate on our Pillow or Hotel Check In\" and EA Sports' \"Madden NFL 2002\", which aired during the game three days after \"Madden NFL 2002\" started selling in Japan by Electronic Arts Square.\nEntertainment.\nPregame.\nBefore the game, an ensemble of singers featured Barry Manilow, Yolanda Adams, James Ingram, Wynonna Judd, and Patti LaBelle performing Manilow's song \"Let Freedom Ring.\"\nIn a video segment, past and present NFL players read excerpts from the Declaration of Independence, which has become a part of all subsequent Super Bowls carried by Fox Sports. Super Bowls XXXIX, XLII, and XLV used different active and former players (and a player's widow) reading the Declaration for each version. Former U.S. presidents Gerald Ford, Jimmy Carter, George H. W. Bush, and Bill Clinton appeared in another videotaped segment and recited some of the speeches by Abraham Lincoln. Because Ronald Reagan had Alzheimer's disease, his wife Nancy appeared on the segment in place of him accompanied by Aaron Copland's \"Lincoln Portrait\" performed by the Boston Pops Orchestra under the direction of maestro Keith Lockhart.\nSingers Mary J. Blige and Marc Anthony, along with the Boston Pops, performed \"America the Beautiful\". Paul McCartney then sang his post-9/11 song \"Freedom\". Afterwards, singer Mariah Carey, accompanied by the Boston Pops, performed the national anthem.\nGeorge H. W. Bush became the first president, past or present, to participate in a Super Bowl coin toss in person (Ronald Reagan participated in the Super Bowl XIX coin toss via satellite from the White House in 1985). Bush was joined by former Dallas Cowboys Hall of Fame quarterback Roger Staubach. Staubach played at the United States Naval Academy and was the Most Valuable Player of Super Bowl VI, which was played 30 years prior at New Orleans' Tulane Stadium.\nPatriots entrance into the Superdome.\nAs was customary at the time, the Rams' individual offensive starters were introduced first, as the Rams were considered the visitors. However, when it came time to introduce the Patriots' starters, Pat Summerall, making the public address announcement, revealed that the Patriots chose \"to be introduced as a team.\" According to David Halberstam's book, \"The Education of a Coach\", Belichick was given a choice by the NFL to introduce either the offense or defense. Belichick chose neither, asking that the team be introduced all at once in the spirit of unity. Although this was initially rejected by the NFL, Belichick held his ground and the NFL honored his request. The full team introduction demonstrated solidarity, and struck a chord with the audience in the wake of the 9/11 attacks. Since the next Super Bowl game, both Super Bowl participants have been introduced collectively as a team, a precedent which has continued.\nHalftime.\nThe halftime show featured a three-song set from Irish rock band U2, who had just completed their successful Elevation Tour. After a rendition of \"Beautiful Day\", the band played \"MLK\" and \"Where the Streets Have No Name\" as the names of the victims from the September 11 attacks were projected onto a sheet behind the stage. While singing \"Where the Streets Have No Name\", the group's lead singer Bono replaced the lyrics \"take shelter from the poison rain\" with \"dance in the Louisiana rain\", \"high on a desert plain\" with \"where there's no sorrow or pain\", and the final line \"it's all I can do\" with \"it's all we can do\". At the conclusion of the song, Bono opened his jacket to reveal an American flag printed into the lining. U2's halftime show captivated the audience as a poignant tribute to those who had been lost in the attacks. In 2013, SI.com ranked it as the best halftime show in Super Bowl history, while it was rated the second-greatest by \"Askmen.com\".\nJanet Jackson was originally selected to perform during the Halftime Show, but due to traveling concerns following the September 11 tragedies, the NFL opted for other acts. The NFL thought U2 would \"set the right tone\" in respect to the tragedy, after executives attended the band's Elevation Tour in New York City. She performed for the Super Bowl halftime two years later, when her highly controversial Super Bowl Halftime Show performance incident occurred.\nGame summary.\nFirst quarter.\nAfter the teams exchanged punts to start the game, the Rams scored first, with quarterback Kurt Warner completing six of seven passes for 43 yards on a 48-yard, 10-play drive to set up a 50-yard field goal by kicker Jeff Wilkins, giving the Rams a 3\u20130 lead. At the time, the field goal was the third longest in Super Bowl history. While the rest of the quarter was scoreless, the Patriots were stifling the typically high-powered Rams offense by playing physical man coverage with the Rams; receivers, forcing them into long drives that would end in punts or field goal attempts.\nSecond quarter.\nEarly in the second quarter, the Rams drove to the Patriots' 34-yard line, aided by Warner's 29-yard completion to wide receiver Az-Zahir Hakim on 3rd-and-15, but Wilkins' 52-yard field goal attempt sailed wide left.\nOn the Rams' next possession, with 8:49 left in the half, a blitz by linebacker Mike Vrabel led Warner to be intercepted by cornerback Ty Law on a pass intended for wide receiver Isaac Bruce. Law then returned the interception 47 yards for a touchdown to give the Patriots a 7\u20133 lead. After another exchange of punts, with less than two minutes left in the first half, Warner completed a 15-yard pass to wide receiver Ricky Proehl at the Rams' 40-yard line, but safety Antwan Harris forced a fumble on Proehl, and cornerback Terrell Buckley recovered the ball for the Patriots. Quarterback Tom Brady started off the Patriots' drive with a 16-yard completion to wide receiver Troy Brown and finished it with an 8-yard touchdown pass to wide receiver David Patten with 31 seconds left in the half. By halftime, the Patriots owned a surprising 14\u20133 lead. It was the first time in the entire 2001 season that the Rams fell behind by more than eight points in a game.\nThird quarter.\nThe Patriots received the opening kickoff of the second half, but could only reach the Rams' 43-yard line before being forced to punt. Aided by a 20-yard reception by Hakim, a 22-yard reception by Bruce, and a pass interference penalty on cornerback Otis Smith, the Rams advanced to the Patriots' 41-yard line. However, on the next play, Vrabel and defensive tackle Richard Seymour sacked Warner for a 9-yard loss. Warner then threw two consecutive incompletions, which resulted in the Rams punting.\nOn the Rams' next possession, they reached the New England 45-yard line on three runs for 30 yards by running back Marshall Faulk, but Smith intercepted a pass intended for Rams wide receiver Torry Holt, who slipped while coming off the line of scrimmage, as Smith returned the ball 30 yards to the Rams' 33-yard line. The Patriots were only able to advance the ball 14 yards after the turnover, so kicker Adam Vinatieri made a 37-yard field goal to increase their lead to 17\u20133.\nFourth quarter.\nThe Rams responded by driving to the Patriots' 3-yard line on their ensuing drive, which was highlighted by Warner's 15-yard pass to Bruce, two receptions by Faulk for 29 yards, and a 14-yard reception by Hakim. After Warner threw back-to-back incompletions, he went back to pass on fourth down, but scrambled to his right after seeing no one open and attempted to score himself. Warner fumbled the ball while being tackled by linebacker Roman Phifer, and safety Tebucky Jones returned the fumble 97 yards for a touchdown, but the play was nullified by a holding penalty on linebacker Willie McGinest, who illegally hugged Faulk, giving the Rams a new set of downs on the 1-yard line. Two plays later, Warner scored on a 2-yard touchdown run to cut the Patriots' lead to 17\u201310.\nAfter Warner's touchdown, the Rams' defense forced the Patriots to a three-and-out. The Rams then drove from their own 7-yard line to the Patriots' 36-yard line, aided by a 30-yard reception by Proehl. However, McGinest sacked Warner for a 16-yard loss on second down, pushing the Rams back to their own 46-yard line. The Rams punted after Warner's third down pass was incomplete.\nFinal two minutes.\nWith the Rams trailing 17\u201310 in the final two minutes, they forced the Patriots to another three-and-out, and got the ball back on their own 45-yard line with 1:51 left in the game and no timeouts. Warner threw three consecutive completions to three different receivers \u2014 an 18-yard pass to Hakim, an 11-yard pass to wide receiver Yo Murphy, and finally a 26-yard touchdown completion to Proehl that tied the game, 17\u201317, with 1:30 left in regulation.\nThe Patriots also had no timeouts left for their ensuing drive, which led Fox color commentator John Madden to initially suggest that the Patriots should run out the clock and attempt to win in overtime. Instead, the Patriots attempted to get the winning score in regulation on the final drive. Bill Belichick conferred with offensive coordinator Charlie Weis and they agreed to go for it. Belichick later stated, \"With a quarterback like Brady, going for the win is not that dangerous, because he's not going to make a mistake.\" Brady opened the drive with three dump-off completions to running back J. R. Redmond for 24 yards, who got out of bounds on the last one and moved the ball to their own 41-yard line with 33 seconds left. At this point, Madden admitted on the air that he now liked what the Patriots were doing. After an incomplete pass, Brady completed a 23-yard pass underneath the Rams' zone defense to wide receiver Troy Brown (Brady's longest pass completion of the game), who also got out of bounds, and followed it up with a 6-yard completion to tight end Jermaine Wiggins to advance to the Rams' 30-yard line. Brady then spiked the ball with seven seconds left, which set up Vinatieri's 48-yard field goal attempt. Vinatieri, who had never missed a field goal indoors, made the kick as time expired, giving the Patriots their first-ever Super Bowl title. It marked the first time in Super Bowl history that the game was won by a score on the final play and only the second game where a field goal was decisive, with the first being in Super Bowl V when the Baltimore Colts' Jim O'Brien kicked a 32-yard field goal with nine seconds left to defeat the Dallas Cowboys. With the victory, Brady became at the time the youngest quarterback to win a Super Bowl surpassing Joe Namath. (Namath was 25 years, 7 months and 12 days old when he won Super Bowl III while Brady was 24 years and 6 months old.)\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nHere comes one of greater importance if he makes it. And it's right down the pike. Adam Vinatieri...no time on the clock and the Patriots have won Super Bowl XXXVI. Unbelievable.\nPat Summerall's call of Vinatieri's game-winning field goal on Fox\nBox score.\nSuper Bowl XXXVI: New England Patriots 20, St. Louis Rams 17\n\"at Louisiana Superdome, New Orleans, Louisiana\nStatistical overview.\nWarner finished the game with 28 completions out of 44 passes for 365 yards, 1 touchdown, and 2 interceptions, and rushed 3 times for 6 yards and a touchdown. Warner's 365 passing yards were the second highest total in Super Bowl history behind his own record of 414 yards set in Super Bowl XXXIV. Hakim was the top receiver of the game with 5 catches for 90 yards, and also rushed once for 5 yards. Faulk led the team with 76 rushing yards, and also caught 4 passes for 54 yards.\nPatriots running back Antowain Smith was the top rusher of the game with 92 yards, and caught a pass for 4 yards. Troy Brown was the Patriots' leading receiver with 6 catches for 89 yards. Brown also had a 15-yard kickoff return, and a 4-yard punt return, which gave him 108 total yards. Although the Rams outgained the Patriots 427\u2013267 in total yards, the Patriots forced three turnovers that were converted into 17 points. The Patriots, on the other hand, committed no turnovers.\nFinal statistics.\nSources: http://, https://, https://\nIndividual statistics.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n1Completions/attempts\n2Carries\n3Long gain\n4Receptions\n5Times targeted\nRecords set.\nThe following records were set in Super Bowl XXXVI, according to the official NFL.com boxscore, the 2022 NFL Record &amp; Fact Book and the Pro-Football-Reference.com game summary.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\nStarting lineups.\nSource:\n&lt;mark style=\"color:black;background:#FFCC00\"&gt;Hall of Fame \u2021&lt;/mark&gt;\nAftermath.\nPatriots.\nFour hours after the game ended, Tom Brady visited Bill Belichick's hotel room where, as per team rules, he had to get Belichick's permission to miss the team flight and instead travel to Walt Disney World in Orlando. Belichick gave him a perplexed look, and after a few seconds of dead silence, responded, \"Of course you can go. How many times do you win the Super Bowl?\"\nThe game heralded the Patriots dynasty, being the first of nine Super Bowl appearances under the duo of head coach Belichick and quarterback Brady. The Patriots finished the 2002 NFL season 9\u20137, missing the playoffs. They went on to win Super Bowl XXXVIII, then Super Bowl XXXIX, thus winning three Super Bowls in four years. Then, they won their fourth, fifth, and sixth Super Bowls (Super Bowl XLIX, Super Bowl LI, and Super Bowl LIII) a decade after their third. Brady won four more Super Bowl MVP awards \u2013 three with the Patriots in Super Bowl XXXVIII, Super Bowl XLIX, and Super Bowl LI and one more with the Tampa Bay Buccaneers in Super Bowl LV \u2013 making him the only player to be named Super Bowl MVP five times.\nSuper Bowl XXXVI later became part of the wider 2007 New England Patriots videotaping controversy, also known as \"Spygate\". In addition to other videotaping allegations, the \"Boston Herald\" reported, citing an unnamed source, that the Patriots had also taped the Rams' walkthrough practice prior to the game. After further investigations, the league determined that no tape of the Rams' Super Bowl walkthrough was made, and the \"Herald\" later issued an apology in 2008 for their article about the alleged walkthrough tape. Nevertheless, the Patriots finished the 2007 regular season with a perfect 16\u20130 record, but failed to record an undefeated 19\u20130 championship season after losing Super Bowl XLII to the New York Giants. And at the conclusion of the 2015 NFL season, the Patriots held the NFL's best record since Spygate, compiling a 96\u201332 record from 2008 to 2015.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThe fans of New England have been waiting 42 years for this day. Spirituality, faith and democracy are the cornerstones of our country. We are all Patriots, and tonight, the Patriots are world champions.\nPatriots owner Robert Kraft accepting the Vince Lombardi Trophy\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nSitting behind me, an older Patriots fan had turned bright red -- I couldn't tell whether he was laughing, crying or both -- and he was screaming, \"Fifty years! I've been waiting for this for fifty years!\" and \"They gave us no respect! None!\" And he just kept screaming those things again and again. And again. And again. Meanwhile, the other Patriots fans in our section were hugging one another and carrying on -- none of us knew what to do. We were collectively incredulous. Total disbelief. Nobody could ever make jokes about the Patriots again. We had arrived.\nBill Simmons, who watched the game live at the Superdome, in his postgame column for ESPN Page 2\nThe Patriots' win in this Super Bowl, beyond just serving as a springboard to a dynasty that lasted nearly two decades and resulted in five more championships, also became the starting point for a decade of success in Boston sports, with the city's teams in the four major North American sports leagues (the Red Sox, Celtics and Bruins in addition to the Patriots) winning seven championships including at least one each. Following the Bruins winning the 2011 Stanley Cup Finals, \"Boston Globe\" columnist Dan Shaughnessy ranked all seven championships from the past decade and ranked the Patriots winning Super Bowl XXXVI as the second-greatest Boston sports championship of the decade behind only the Red Sox winning the 2004 World Series and breaking the \"Curse of the Bambino\".\nBrady, Milloy and Vinatieri also provided the team's commentary in the 2001 Patriots' episode of \"\", narrated by actor Martin Sheen.\nThe Patriots winning their first championship in franchise history started a run of a team in American sports from NCAA Football and Basketball and the four major sports (MLB baseball, NFL football, NBA basketball, and NHL hockey) winning either their first franchise championship or their next franchise championship after waiting at least 17 years since their last title. This streak is still continuing in 2025 after the Florida Gators won their first NCAA Basketball national championship in 18 years and the Oklahoma City Thunder won their first NBA championship since 1979 when they were known as the Seattle SuperSonics and their first in 17 years since moving to Oklahoma City.\nRams.\nBeginning with the Rams' appearance in Super Bowl XXXVI, 10 different NFC teams appeared in the Super Bowl over the next 10 years. This trend was broken when the New York Giants earned a trip to Super Bowl XLVI after participating in Super Bowl XLII four years earlier (the Giants defeated the Patriots in both games).\nThis game was regarded as a \"Super Bowl hangover\" for the Rams because they lost a Super Bowl where they were heavy favorites, with a win potentially ushering in a Rams dynasty, but instead the loss signaled the beginning of the end of The Greatest Show on Turf era. Due to injuries to Kurt Warner and Marshall Faulk, the Rams finished with a 7\u20139 record the following year and missed the postseason. They qualified for the playoffs only two more times (2003 and 2004), and only won one more playoff game (the 2004\u201305 wild card game) during the remainder of their tenure in St. Louis. Head coach Mike Martz was fired after missing most of the 2005 season due to illness. Warner suffered a concussion on opening day in 2003, and was later demoted to backup quarterback for the rest of that season. He then signed with the New York Giants in 2004 as a caretaker quarterback, eventually losing the starting job to rookie quarterback Eli Manning. Warner later joined the Arizona Cardinals in 2005 and eventually gained the starting job where he led that team to their first Super Bowl appearance, XLIII, following the 2008 season.\nSuper Bowl XXXVI ended up being the last Super Bowl that the Rams participated while based in St. Louis; they relocated back to Los Angeles in 2016. The Rams would once again reach the Super Bowl in the 2018 season and 2021 season, winning the latter.\nSuper Bowl LIII rematch.\nThe Patriots and the now Los Angeles Rams rematched exactly 17 years later in Super Bowl LIII (2019); again featuring the head coach-quarterback tandem of Bill Belichick and Tom Brady, both of whom were the only active personnel left from Super Bowl XXXVI, on February 3, 2019. Coincidentally like XXXVI, LIII also featured one of the league's top offenses (Rams) against one of the top defenses (Patriots). The Patriots won their record-tying sixth Super Bowl by defeating the Rams again 13\u20133, with Brady remarking that LIII had a \"throwback feel\" to XXXVI. Meanwhile, the Rams would defeat the Cincinnati Bengals three years later.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29565", "revid": "14567206", "url": "https://en.wikipedia.org/wiki?curid=29565", "title": "Supply class support ship", "text": ""}
{"id": "29566", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=29566", "title": "Sacramento class support ship", "text": ""}
{"id": "29570", "revid": "13272187", "url": "https://en.wikipedia.org/wiki?curid=29570", "title": "Scansano", "text": "Scansano is a town and comune, of medieval origin, in the province of Grosseto, Tuscany, central Italy. The area which Scansano lies within is called Maremma.\nScansano area is home to the production of Morellino di Scansano, a type of wine.\n\"Frazioni\".\nThe municipality is formed by the municipal seat of Scansano and the villages (\"frazioni\") of Baccinello, Montorgiali, Murci, Pancole, Poggioferro, Polveraia, Pomonte and Preselle.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "29571", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=29571", "title": "SetTopBox", "text": ""}
{"id": "29572", "revid": "48984234", "url": "https://en.wikipedia.org/wiki?curid=29572", "title": "Southern hemisphere", "text": ""}
{"id": "29574", "revid": "33839581", "url": "https://en.wikipedia.org/wiki?curid=29574", "title": "List of maritime explorers", "text": "This is a list of maritime explorers. The list includes explorers who have substantially contributed to human knowledge of the planet's geography, weather, biodiversity, and human cultures, or who have significantly contributed to the expansion of trade and communication between populations.\nReferences and notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29577", "revid": "1318545053", "url": "https://en.wikipedia.org/wiki?curid=29577", "title": "Wednesday Morning, 3 A.M.", "text": "1964 studio album by Simon &amp; Garfunkel\nWednesday Morning, 3 A.M. is the debut studio album by the American folk rock duo Simon &amp; Garfunkel. Following their early incarnation as rock 'n' roll duo Tom and Jerry, Columbia Records signed the pair in late 1963. The album was produced by Tom Wilson and engineered by Roy Halee. The cover and the label include the subtitle \"exciting new sounds in the folk tradition\". Recorded in March 1964, the album was released on October 19.\nThe album was initially unsuccessful, so Paul Simon moved to London, England and released his first solo album \"The Paul Simon Songbook\". Art Garfunkel continued his studies at Columbia University in his native New York City, before reuniting with Simon in late 1965. \"Wednesday Morning, 3 A.M.\" was re-released in January 1966 (to capitalize on their newly found radio success because of the overdubbing of the song \"The Sound of Silence\" in June 1965, adding electric guitars, bass guitar and a drum kit, which was done under the direction of producer Tom Wilson without the duo's knowledge), and reached No.\u00a030 on the Billboard 200. It was belatedly released in the UK two years later (in 1968) in both mono and stereo formats.\nThe song \"He Was My Brother\" was dedicated to Andrew Goodman, who was their friend and a classmate of Simon at Queens College. Andrew Goodman volunteered in Freedom Summer during 1964 and was abducted and killed in the murders of Chaney, Goodman, and Schwerner.\nThe album is included in its entirety as part of the Simon &amp; Garfunkel box sets \"Collected Works\" and \"The Columbia Studio Recordings (1964\u20131970)\".\nProduction.\nThe album was produced by Tom Wilson and engineered by Roy Halee between March 10\u201331, 1964.\n\u201cBenedictus\" was arranged and adapted from Orlando di Lasso's \"Missa Octavi toni\", a Renaissance setting of the ordinary of the mass. The text, in Latin, is \"benedictus qui venit in nomine Domini\" (KJV: \"Blessed be he that cometh in the name of the Lord\"\u2009). The song is arranged for two voices with cello and sparse guitar accompaniment.\nArtwork.\nThe album's cover photo was shot at the Fifth Avenue / 53rd Street subway station in New York City. In several concerts, Art Garfunkel related that during the photo session, several hundred pictures were taken that were unusable due to the \"old familiar suggestion\" on the wall in the background (a euphemism for the words \"Fuck You\"), which inspired Paul Simon to write the song \"A Poem on the Underground Wall\" for the duo's later \"Parsley, Sage, Rosemary and Thyme\" album.\nReception.\nThe album was initially unsuccessful, having been released in the shadow of the British Invasion. This resulted in Paul Simon moving to England and Art Garfunkel continuing his studies at Columbia University in New York City. It ultimately reached No.\u00a024 on the UK Album Charts, albeit in 1968, long after the duo had re-formed and gone on to greater success. Following the success of \"The Sound of Silence,\" the album peaked at No.\u00a030 on the \"Billboard\" album chart in 1966.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29578", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=29578", "title": "Sheldon Rampton", "text": "American editor and author (born 1957)\nSheldon Rampton is an American editor and author. He was editor of \"PR Watch\", and is the author of several books that criticize the public relations industry.\nCareer.\nIn 1995, Rampton teamed with John Stauber as co-editors of PR Watch, a publication of the Center for Media and Democracy (CMD). They were described as liberal, and their writings are regarded by some members of the public relations industry as one-sided and hostile, but their work drew wide attention. ActivistCash, a website hosted by Washington lobbyist Richard Berman, has castigated them as \"self-anointed watchdogs,\" \"scare-mongers,\" \"reckless\" and \"left-leaning.\" Rampton and Stauber have in turn argued that the ActivistCash critique contains a number of \"demonstrably false\" claims. According to a review in \"The Denver Post\", their 1995 book, \"Toxic Sludge Is Good for You,\" offered \"a sardonic, wide-ranging look at the public relations industry.\"\nAfter leaving the Center for Media and Democracy in 2009, Rampton became a website developer, joining an open government initiative led by New York State Senate chief information officer Andrew Hoppin. In 2010, Hoppin and Rampton co-founded NuCivic, an open source software company, which they sold in December 2014 to GovDelivery, a software services company now known as Granicus. Rampton currently works as a software engineer at Granicus. He also serves on the board of directors of Global Energy Monitor (GEM), a non-governmental organization that catalogs fossil fuel and renewable energy projects worldwide in support of clean energy.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29579", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=29579", "title": "Miller test", "text": "Obscenity test in U.S. law\nThe Miller test, also called the three-prong obscenity test, is the United States Supreme Court's test for determining whether speech or expression can be labeled obscene, in which case it is not protected by the First Amendment to the United States Constitution and can be prohibited.\nHistory and details.\nThe \"Miller\" test was developed in the 1973 case \"Miller v. California\". It has three parts:\nThe work is considered obscene only if \"all three\" conditions are satisfied.\nThe first two prongs of the \"Miller\" test are held to the standards of the community, and the third prong is based on \"whether a reasonable person would find such value in the material, taken as a whole\".\nFor legal scholars, several issues are important. One is that the test allows for community standards rather than a national standard. What offends the average person in one community may differ from what offends the average person in another community. \nAnother important issue is that the \"Miller\" test asks for an interpretation of what the \"average\" person finds offensive, rather than what the more sensitive persons in the community are offended by, as obscenity was defined by the previous test, the Hicklin test, stemming from the English precedent.\nIn practice, pornography showing genitalia and sexual acts is not \"ipso facto\" obscene according to the \"Miller\" test. For instance, in 2000, a jury in Provo, Utah, took only a few minutes to clear Larry Peterman, owner of a Movie Buffs video store, in Utah County, Utah. He had been charged with distributing obscene material for renting pornographic videos that were displayed in a screened-off area of the store clearly marked as adults-only. The Utah County region had often boasted of being one of the most socially conservative areas in the United States. However, researchers had shown that guests at the local Marriott Hotel were disproportionately large consumers of pay-per-view pornographic material, accessing far more material than the store was distributing.\nCriticism.\n\"Miller\" test may lead to greater censorship.\nBecause it allows for community standards and demands \"serious\" value, Justice Douglas worried in his dissent that this test would make it easier to suppress speech and expression. \"Miller\" replaced a previous test asking whether the speech or expression was \"utterly without redeeming social value\". As used, however, the test generally makes it difficult to outlaw any form of expression. Many works decried as pornographic have been successfully argued to have some artistic or literary value, most publicly in the context of the National Endowment for the Arts in the 1990s.\nThe first two prongs of the \"Miller\" test \u2013 that material appeal to the prurient interest and be patently offensive \u2013 have been said to require the impossible: \"They require the audience to be turned on and grossed out at the same time\".\nProblem of jurisdiction in the Internet age.\nThe advent of the Internet has made the \"community standards\" part of the test even more difficult to judge; as material published on a web server in one place can be read by a person residing anywhere else, there is a question as to which jurisdiction should apply. In \"United States v. Extreme Associates\", a pornography distributor from North Hollywood, California, was judged to be held accountable to the community standards applying in western Pennsylvania, where the Third Circuit made its ruling, because the materials were available via Internet in that area. The United States Court of Appeals for the Ninth Circuit has ruled in \"United States v. Kilbride\" that a \"national community standard\" should be used for the Internet, but this has yet to be upheld at the national level.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29580", "revid": "892079", "url": "https://en.wikipedia.org/wiki?curid=29580", "title": "Set-top box", "text": "Device to create output for a television\nA set-top box (STB), also known as a cable box, receiver, or simply box, and historically television decoder or a converter, is an information appliance device that generally contains a TV tuner input and displays output to a television set, turning the source signal into content in a form that can then be displayed on the television screen or other display device. It is designed to be placed alongside or \"on top\" (hence the name) of a television set.\nSet-top boxes are used in cable television, satellite television, terrestrial television and Internet Protocol television systems, as well as other uses such as digital media players (\"streaming boxes\"). Alternatives to set-top boxes are the smaller dongles, and television sets with built-in TV tuners.\nTV signal sources.\nThe signal source might be an Ethernet cable, a satellite dish, a coaxial cable (see cable television), a telephone line (including DSL connections), broadband over power lines (BPL), or even an ordinary VHF or UHF antenna. Content, in this context, could mean any or all of video, audio, Internet web pages, interactive video games, or other possibilities. Satellite and microwave-based services also require specific external receiver hardware, so the use of set-top boxes of various formats has never completely disappeared. Set-top boxes can also enhance source signal quality.\nUHF converter.\nBefore the All-Channel Receiver Act of 1962 required US television receivers to be able to tune the entire VHF and UHF range (which in North America was NTSC-M channels 2 through 83 on 54 to 890MHz), a set-top box known as a UHF converter would be installed at the receiver to shift a portion of the UHF-TV spectrum onto low-VHF channels for viewing. As some 1960s-era 12-channel TV sets remained in use for many years, and Canada and Mexico were slower than the US to require UHF tuners to be factory-installed in new TVs, a market for these converters continued to exist for much of the 1970s.\nCable converter.\nCable television represented a possible alternative to deployment of UHF converters as broadcasts could be frequency-shifted to VHF channels at the cable head-end instead of the final viewing location. However, most cable systems could not accommodate the full 54-to-890\u00a0MHz VHF/UHF frequency range and the twelve channels of VHF space were quickly exhausted on most systems. Adding any additional channels therefore needed to be done by inserting the extra signals into cable systems on nonstandard frequencies, typically either below VHF channel 7 (midband) or directly above VHF channel 13 (superband).\nThese frequencies corresponded to non-television services (such as two-way radio) over the air and were therefore not on standard TV receivers. Before cable-ready TV sets became common in the late 1980s, an electronic tuning device called a cable converter box was needed to receive the additional analogue cable TV channels and transpose or convert the selected channel to analogue radio frequency (RF) for viewing on a regular TV set on a single channel, usually VHF channel 3 or 4. The box allowed an analogue non\u2013cable-ready television set to receive analogue encrypted cable channels and was a prototype topology for later date digital encryption devices. Newer televisions were then converted to be analogue cypher cable-ready, with the standard converter built-in for selling premium television (aka pay-per-view). Several years later and slowly marketed, the advent of digital cable continued and increased the need for various forms of these devices. Block conversion of the entire affected frequency band onto UHF, while less common, was used by some models to provide full VCR compatibility and the ability to drive multiple TV sets, albeit with a somewhat nonstandard channel numbering scheme.\nNewer television receivers greatly reduced the need for external set-top boxes, although cable converter boxes continue to be used to descramble premium cable channels according to carrier-controlled access restrictions, and to receive digital cable channels, along with using interactive services like video on demand, pay per view, and home shopping through television.\nClosed captioning box.\nSet-top boxes were also made to enable closed captioning on older sets in North America, before this became a mandated inclusion in new television sets. Some have also been produced to mute the audio (or replace it with noise) when profanity is detected in the captioning, where the offensive word is also blocked. Some also include a V-chip that allows only programs of some television content rating systems. A function that limits children's time watching TV or playing video games may also be built in, though some work on main electricity rather than the video signal.\nDigital television adapter.\nThe transition to digital terrestrial television after the turn of the millennium left many existing television receivers unable to tune and display the new signal directly. In the United States, where the analogue shutdown was completed in 2009 for full-service broadcasters, a federal subsidy was offered for coupon-eligible converter boxes with deliberately limited capability which would restore signals lost to digital transition.\nProfessional set-top box.\nProfessional set-top boxes are referred to as IRDs or integrated receiver/decoders in the professional broadcast audio/video industry. They are designed for more robust field handling and rack mounting environments. IRDs are capable of outputting uncompressed serial digital interface signals, unlike consumer STBs which usually do not, mostly because of copyright reasons.\nHybrid box.\nHybrid set-top boxes, such as those used for Smart TV programming, enable viewers to access multiple TV delivery methods (including terrestrial, cable, internet, and satellite); like IPTV boxes, they include video on demand, time-shifting TV, Internet applications, videotelephony, surveillance, gaming, shopping, TV-centric electronic program guides, and e-government. By integrating varying delivery streams, hybrids (sometimes known as \"TV-centric\") enable pay-TV operators more flexible application deployment, which decreases the cost of launching new services, increases speed to market, and limits disruption for consumers.\nAs examples, Hybrid Broadcast Broadband TV (HbbTV) set-top boxes allow traditional TV broadcasts, whether from terrestrial (DTT), satellite, or cable providers, to be brought together with video delivered over the Internet and personal multimedia content. Advanced Digital Broadcast (ADB) launched its first hybrid DTT/IPTV set-top box in 2005, which provided Telef\u00f3nica with the digital TV platform for its Movistar TV service by the end of that year. In 2009, ADB provided Europe's first three-way hybrid digital TV platform to Polish digital satellite operator n, which enables subscribers to view integrated content whether delivered via satellite, terrestrial, or internet.\nUK-based Inview Technology has over 8million STBs deployed in the UK for teletext and an original push VOD service for Top Up TV.\nIPTV receiver.\nIn IPTV networks, the set-top box is a small computer providing two-way communications on an IP network and decoding the video streaming media. IP set-top boxes have a built-in home network interface that can be Ethernet, Wireless (802.11g,n,ac), or one of the existing wire home networking technologies such as HomePNA or the ITU-T G.hn standard, which provides a way to create a high-speed (up to 1\u00a0Gbit/s) local area network using existing home wiring (power lines, phone lines, and coaxial cables).\nIn the US and Europe, telephone companies use IPTV (often on ADSL or optical fibre networks) as a means to compete with traditional local cable television monopolies.\nThis type of service is distinct from streaming television, which involves third-party content over the public Internet not controlled by the local system operator.\nFeatures.\nProgramming features.\nElectronic program guide.\nElectronic program guides and interactive program guides provide users of television, radio, and other media applications with continuously updated menus displaying broadcast programming or scheduling information for current and upcoming programming. Some guides, such as ITV, also feature backward scrolling to promote their catch-up content.\nFavorites.\nThis feature allows the user to choose preferred channels, making them easier and quicker to access; this is handy with the wide range of digital channels on offer. The concept of favourite channels is superficially similar to that of the \"bookmark\" function offered in many web browsers.\nTimer.\nThe timer allows the user to program and enable the box to switch between channels at certain times: this is handy to record from more than one channel while the user is out. The user still needs to program the VCR or DVD recorder.\nConvenience features.\nControls on the box.\nSome models have controls on the box, as well as on the remote control. This is useful should the user lose the remote or if the batteries age.\nRemote controls that work with other TVs.\nSome remote controls can also control some basic functions of various brands of TVs. This allows the user to use just one remote to turn the TV on and off, adjust volume, or switch between digital and analogue TV channels or between terrestrial and internet channels.\nParental locks.\nThe parental lock or content filters allow users over 18 years old to block access to channels that are not appropriate for children, using a personal identification number. Some boxes simply block all channels, while others allow the user to restrict access to chosen channels not suitable for children below certain ages.\nSoftware alternatives.\nAs complexity and potential programming faults of the set-top box increase, software such as MythTV, Select-TV and Microsoft's Media Center have developed features comparable to those of set-top boxes, ranging from basic DVR-like functionality to DVD copying, home automation, and housewide music or video playback.\nFirmware update features.\nAlmost all modern set-top boxes feature automatic firmware update processes. The firmware update is typically provided by the service provider.\nAmbiguities in the definition.\nWith the advent of flat-panel televisions, set-top boxes are now deeper in profile than the tops of most modern TV sets. Because of this, set-top boxes are often placed beneath televisions, and the term set-top box has become something of a misnomer, possibly helping the adoption of the term \"digibox\". Additionally, newer set-top boxes that sit at the edge of IP-based distribution networks are often called net-top boxes or NTBs, to differentiate between IP and RF inputs. The Roku LT is around the size of a pack of cards and delivers Smart TV to conventional sets.\nThe distinction between external tuner or demodulator boxes (traditionally considered to be \"set-top boxes\") and storage devices (such as VCR, DVD, or disc-based PVR units) is also blurred by the increasing deployment of satellite and cable tuner boxes with a hard disk, network or USB interfaces built-in.\nDevices with the capabilities of computer terminals, such as the WebTV thin client, also fall into the grey area that could invite the term \"NTB\".\nEurope.\nIn Europe, a set-top box does not necessarily contain a tuner of its own. A box connected to a television (or VCR) SCART connector is fed with the baseband television signal from the set's tuner, and can have the television display the returned processed signal instead.\nThis SCART feature had been used for connection to analogue decoding equipment by pay-TV operators in Europe, and in the past, it was used for connection to teletext equipment before the decoders became built-in. The outgoing signal could be of the same nature as the incoming signal, or RGB component video, or even an \"insert\" over the original signal, due to the \"fast switching\" feature of SCART.\nIn case of analogue pay-TV, this approach avoided the need for a second remote control. The use of digital television signals in more modern pay-TV schemes requires that decoding take place before the digital-to-analogue conversion step, rendering the video outputs of an analogue SCART connector no longer suitable for interconnection to decryption hardware. Standards such as DVB's Common Interface and ATSC's CableCARD therefore use a PCMCIA-like card inserted as part of the digital signal path as their alternative to a tuner-equipped set-top box.\nCosts.\nAccording to the \"Los Angeles Times\", the cost to a cable provider in the United States for a set-top box is between $150 for a basic box to $250 for a more sophisticated box. In 2016, the average pay-TV subscriber paid $231 per year to lease their set-top box from a cable service provider.\nEnergy use.\nIn June 2011, a report from the American National Resources Defense Council brought attention to the energy efficiency of set-top boxes, and the United States Department of Energy announced plans to consider the adoption of energy efficiency standards for set-top boxes. In November 2011, the National Cable &amp; Telecommunications Association announced a new energy efficiency initiative that commits the largest American cable operators to the purchase of set-top boxes that meet Energy Star standards and the development of sleep modes that will use less energy when the set-top box is not being used to watch or record video.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29582", "revid": "1257597357", "url": "https://en.wikipedia.org/wiki?curid=29582", "title": "Scatology", "text": "Study of faeces\nIn medicine and biology, scatology or coprology is the study of faeces.\nScatological studies allow one to determine a wide range of biological information about a creature, including its diet (and thus where it has been), health and diseases such as tapeworms.\nA comprehensive study of scatology was documented by John Gregory Bourke under the title \"Scatalogic Rites of All Nations\" (1891), with a 1913 German translation including a foreword by Sigmund Freud. An abbreviated version of the work was published as \"The Portable Scatalog\" in 1994.\nEtymology.\nThe word derives from the Greek (GEN ) meaning \"dung, feces\"; \"coprology\" derives from the Greek of similar meaning.\nPsychology.\nIn psychology, a scatology is an obsession with excretion or excrement, or the study of such obsessions.\nIn sexual fetishism, scatology or scatophilia (usually abbreviated \"scat\") refers to coprophilia, when someone is sexually aroused by fecal matter, whether in the use of feces in various sexual acts, watching someone defecating, or simply seeing the feces. Entire subcultures in sexuality are devoted to this fetish.\nLiterature.\nIn literature, \"scatological\" is a term to denote the literary trope of the grotesque body. It is used to describe works that make particular reference to excretion or excrement, as well as to toilet humor. Well known for his scatological tropes is the late medieval fictional character of Till Eulenspiegel. Another common example is John Dryden's \"Mac Flecknoe\", a poem that employs extensive scatological imagery to ridicule Dryden's contemporary Thomas Shadwell. German literature is particularly rich in scatological texts and references, including such books as Collofino's \"Non Olet\". A case which has provoked an unusual amount of comment in the academic literature is Mozart's scatological humour. Smith, in his review of English literature's representations of scatology from the Middle Ages to the 18th century, notes two attitudes towards scatology. One of these emphasises the merry and the carnivalesque. This is found in Chaucer and Shakespeare. The other attitude is one of self-disgust and misanthropy. This is found in the works of the Earl of Rochester and Jonathan Swift.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29585", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=29585", "title": "Semiconductors", "text": ""}
{"id": "29586", "revid": "1318653293", "url": "https://en.wikipedia.org/wiki?curid=29586", "title": "\u03a3-algebra", "text": "Algebraic structure of set algebra\nIn mathematical analysis and in probability theory, a \u03c3-algebra (\"sigma algebra\") is part of the formalism for defining sets that can be measured. In calculus and analysis, for example, \u03c3-algebras are used to define the concept of sets with area or volume. In probability theory, they are used to define events with a well-defined probability. In this way, \u03c3-algebras help to formalize the notion of \"size\".\nIn formal terms, a \u03c3-algebra (also \u03c3-field, where the \u03c3 comes from the German \"Summe\", meaning \"sum\") on a set formula_1 is a nonempty collection formula_2 of subsets of \"formula_1\" closed under complement, countable unions, and countable intersections. The ordered pair formula_4 is called a measurable space. \nThe set formula_1 is understood to be an ambient space (such as the 2D plane or the set of outcomes when rolling a six-sided die {1,2,3,4,5,6}), and the collection formula_2 is a choice of subsets declared to have a well-defined size. The closure requirements for \u03c3-algebras are designed to capture our intuitive ideas about how sizes combine: if there is a well-defined probability that an event occurs, there should be a well-defined probability that it does not occur (closure under complements); if several sets have a well-defined size, so should their combination (countable unions); if several events have a well-defined probability of occurring, so should the event where they all occur simultaneously (countable intersections).\nThe definition of \u03c3-algebra resembles other mathematical structures such as a topology (which is required to be closed under all unions but only finite intersections, and which doesn't necessarily contain all complements of its sets) or a set algebra (which is closed only under \"finite\" unions and intersections).\nExamples of \u03c3-algebras.\nIf formula_7 one possible \u03c3-algebra on formula_1 is formula_9 where formula_10 is the empty set. In general, a finite algebra is always a \u03c3-algebra.\nIf formula_11 is a countable partition of formula_1 then the collection of all unions of sets in the partition (including the empty set) is a \u03c3-algebra.\nA more useful example is the set of subsets of the real line formed by starting with all open intervals and adding in all countable unions, countable intersections, and relative complements and continuing this process (by transfinite iteration through all countable ordinals) until the relevant closure properties are achieved (a construction known as the Borel hierarchy).\nMotivation.\nThere are at least three key motivators for \u03c3-algebras: defining measures, manipulating limits of sets, and managing partial information characterized by sets.\nMeasure.\nA measure on formula_1 is a function that assigns a non-negative real number to subsets of formula_14 this can be thought of as making precise a notion of \"size\" or \"volume\" for sets. We want the size of the union of disjoint sets to be the sum of their individual sizes, even for an infinite sequence of disjoint sets.\nOne would like to assign a size to every subset of formula_15 but in many natural settings, this is not possible. For example, the axiom of choice implies that when the size under consideration is the ordinary notion of length for subsets of the real line, then there exist sets for which no size exists, for example, the Vitali sets. For this reason, one considers instead a smaller collection of privileged subsets of formula_16 These subsets will be called the measurable sets. They are closed under operations that one would expect for measurable sets, that is, the complement of a measurable set is a measurable set and the countable union of measurable sets is a measurable set. Non-empty collections of sets with these properties are called \u03c3-algebras.\nLimits of sets.\nMany uses of measure, such as the probability concept of almost sure convergence, involve limits of sequences of sets. For this, closure under countable unions and intersections is paramount. Set limits are defined as follows on \u03c3-algebras.\nThe inner limit is always a subset of the outer limit: formula_34 \nIf these two sets are equal then their limit formula_35 exists and is equal to this common set: \nformula_36\nSub \u03c3-algebras.\nIn much of probability, especially when conditional expectation is involved, one is concerned with sets that represent only part of all the possible information that can be observed. This partial information can be characterized with a smaller \u03c3-algebra which is a subset of the principal \u03c3-algebra; it consists of the collection of subsets relevant only to and determined only by the partial information. Formally, if formula_37 are \u03c3-algebras on formula_1, then formula_39 is a sub \u03c3-algebra of formula_2 if formula_41. \nThe Bernoulli process provides a simple example. This consists of a sequence of random coin flips, coming up Heads (formula_42) or Tails (formula_43), of unbounded length. The sample space \u03a9 consists of all possible infinite sequences of formula_42 or formula_45\nformula_46\nThe full sigma algebra can be generated from an ascending sequence of subalgebras, by considering the information that might be obtained after observing some or all of the first formula_47 coin flips. This sequence of subalgebras is given by\nformula_48\nEach of these is finer than the last, and so can be ordered as a filtration\nformula_49\nThe first subalgebra formula_50 is the trivial algebra: it has only two elements in it, the empty set and the total space. The second subalgebra formula_51 has four elements: the two in formula_52 plus two more: sequences that start with formula_42 and sequences that start with formula_43. Each subalgebra is finer than the last. The formula_47'th subalgebra contains formula_56 elements: it divides the total space formula_57 into all of the possible sequences that might have been observed after formula_47 flips, including the possible non-observation of some of the flips.\nThe limiting algebra formula_59 is the smallest \u03c3-algebra containing all the others. It is the algebra generated by the product topology or weak topology on the product space formula_60\nDefinition and properties.\nDefinition.\nLet formula_1 be some set, and let formula_62 represent its power set, the set of all subsets of formula_1. Then a subset formula_64 is called a \u03c3-algebra if it satisfies the following three properties:\nFrom these properties, it follows that the \u03c3-algebra is also closed under countable intersections (by applying De Morgan's laws).\nIt also follows that the empty set formula_10 is in formula_69 since by (1) formula_1 is in formula_66 and (2) asserts that its complement, the empty set, is also in formula_79 Moreover, since formula_80 satisfies all 3 conditions, it follows that formula_80 is the smallest possible \u03c3-algebra on formula_16 The largest possible \u03c3-algebra on formula_1 is formula_84\nElements of the \u03c3-algebra are called measurable sets. An ordered pair formula_85 where formula_1 is a set and formula_66 is a \u03c3-algebra over formula_15 is called a measurable space. A function between two measurable spaces is called a measurable function if the preimage of every measurable set is measurable. The collection of measurable spaces forms a category, with the measurable functions as morphisms. Measures are defined as certain types of functions from a \u03c3-algebra to formula_89\nA \u03c3-algebra is both a \u03c0-system and a Dynkin system (\u03bb-system). The converse is true as well, by Dynkin's theorem (see below).\nDynkin's \u03c0-\u03bb theorem.\nThis theorem (or the related monotone class theorem) is an essential tool for proving many results about properties of specific \u03c3-algebras. It capitalizes on the nature of two simpler classes of sets, namely the following.\nDynkin's \u03c0-\u03bb theorem says, if formula_90 is a \u03c0-system and formula_92 is a Dynkin system that contains formula_97 then the \u03c3-algebra formula_98 generated by formula_90 is contained in formula_100 Since certain \u03c0-systems are relatively simple classes, it may not be hard to verify that all sets in formula_90 enjoy the property under consideration while, on the other hand, showing that the collection formula_92 of all subsets with the property is a Dynkin system can also be straightforward. Dynkin's \u03c0-\u03bb Theorem then implies that all sets in formula_98 enjoy the property, avoiding the task of checking it for an arbitrary set in formula_104\nOne of the most fundamental uses of the \u03c0-\u03bb theorem is to show equivalence of separately defined measures or integrals. For example, it is used to equate a probability for a random variable formula_1 with the Lebesgue-Stieltjes integral typically associated with computing the probability:\nformula_106 for all formula_68 in the Borel \u03c3-algebra on formula_108\nwhere formula_109 is the cumulative distribution function for formula_15 defined on formula_108 while formula_112 is a probability measure, defined on a \u03c3-algebra formula_66 of subsets of some sample space formula_114\nCombining \u03c3-algebras.\nSuppose formula_115 is a collection of \u03c3-algebras on a space formula_16\nMeet\nThe intersection of a collection of \u03c3-algebras is a \u03c3-algebra. To emphasize its character as a \u03c3-algebra, it often is denoted by: \nformula_117\nSketch of Proof: Let formula_118 denote the intersection. Since formula_1 is in every formula_120 is not empty. Closure under complement and countable unions for every formula_121 implies the same must be true for formula_122 Therefore, formula_118 is a \u03c3-algebra.\nJoin\nThe union of a collection of \u03c3-algebras is not generally a \u03c3-algebra, or even an algebra, but it generates a \u03c3-algebra known as the join which typically is denoted \nformula_124\nA \u03c0-system that generates the join is \nformula_125\nSketch of Proof: By the case formula_126 it is seen that each formula_127 so\nformula_128\nThis implies\nformula_129\nby the definition of a \u03c3-algebra generated by a collection of subsets. On the other hand,\nformula_130\nwhich, by Dynkin's \u03c0-\u03bb theorem, implies\nformula_131\n\u03c3-algebras for subspaces.\nSuppose formula_132 is a subset of formula_1 and let formula_4 be a measurable space.\nRelation to \u03c3-ring.\nA \"\u03c3\"-algebra formula_66 is just a \"\u03c3\"-ring that contains the universal set formula_16 A \"\u03c3\"-ring need not be a \"\u03c3\"-algebra, as for example measurable subsets of zero Lebesgue measure in the real line are a \"\u03c3\"-ring, but not a \"\u03c3\"-algebra since the real line has infinite measure and thus cannot be obtained by their countable union. If, instead of zero measure, one takes measurable subsets of finite Lebesgue measure, those are a ring but not a \"\u03c3\"-ring, since the real line can be obtained by their countable union yet its measure is not finite.\nTypographic note.\n\"\u03c3\"-algebras are sometimes denoted using calligraphic capital letters, or the Fraktur typeface. Thus formula_4 may be denoted as formula_143 or formula_144\nParticular cases and examples.\nSeparable \u03c3-algebras.\nA separable formula_145-algebra (or separable formula_145-field) is a formula_145-algebra formula_148 that is a separable space when considered as a metric space with metric formula_149 for formula_150 and a given finite measure formula_151 (and with formula_152 being the symmetric difference operator). Any formula_145-algebra generated by a countable collection of sets is separable, but the converse need not hold. For example, the Lebesgue formula_145-algebra is separable (since every Lebesgue measurable set is equivalent to some Borel set) but not countably generated (since its cardinality is higher than continuum).\nA separable measure space has a natural pseudometric that renders it separable as a pseudometric space. The distance between two sets is defined as the measure of the symmetric difference of the two sets. The symmetric difference of two distinct sets can have measure zero; hence the pseudometric as defined above need not be a true metric. However, if sets whose symmetric difference has measure zero are identified into a single equivalence class, the resulting quotient set can be properly metrized by the induced metric. If the measure space is separable, it can be shown that the corresponding metric space is, too.\nSimple set-based examples.\nLet formula_1 be any set.\nStopping time sigma-algebras.\nA stopping time formula_166 can define a formula_145-algebra formula_168 the\nso-called , which in a filtered probability space describes the information up to the random time formula_166 in the sense that, if the filtered probability space is interpreted as a random experiment, the maximum information that can be found out about the experiment from arbitrarily often repeating it until the time formula_166 is formula_171\n\u03c3-algebras generated by families of sets.\n\u03c3-algebra generated by an arbitrary family.\nLet formula_172 be an arbitrary family of subsets of formula_16 Then there exists a unique smallest \u03c3-algebra which contains every set in formula_172 (even though formula_172 may or may not itself be a \u03c3-algebra). It is, in fact, the intersection of all \u03c3-algebras containing formula_176 (See intersections of \u03c3-algebras above.) This \u03c3-algebra is denoted formula_177 and is called the \u03c3-algebra generated by formula_176\nIf formula_172 is empty, then formula_180 Otherwise formula_177 consists of all the subsets of formula_1 that can be made from elements of formula_172 by a countable number of complement, union and intersection operations.\nFor a simple example, consider the set formula_184 Then the \u03c3-algebra generated by the single subset formula_185 is \nformula_186 \nBy an abuse of notation, when a collection of subsets contains only one element, formula_187 formula_188 may be written instead of formula_189 in the prior example formula_190 instead of formula_191 Indeed, using formula_192 to mean formula_193 is also quite common.\nThere are many families of subsets that generate useful \u03c3-algebras. Some of these are presented here.\n\u03c3-algebra generated by a function.\nIf formula_194 is a function from a set formula_1 to a set formula_132 and formula_197 is a formula_145-algebra of subsets of formula_199 then the formula_145-algebra generated by the function formula_201 denoted by formula_202 is the collection of all inverse images formula_203 of the sets formula_204 in formula_205 That is,\nformula_206\nA function formula_194 from a set formula_1 to a set formula_132 is measurable with respect to a \u03c3-algebra formula_66 of subsets of formula_1 if and only if formula_212 is a subset of formula_213\nOne common situation, and understood by default if formula_197 is not specified explicitly, is when formula_132 is a metric or topological space and formula_197 is the collection of Borel sets on formula_136\nIf formula_194 is a function from formula_1 to formula_220 then formula_212 is generated by the family of subsets which are inverse images of intervals/rectangles in formula_222\nformula_223\nA useful property is the following. Assume formula_194 is a measurable map from formula_225 to formula_226 and formula_227 is a measurable map from formula_225 to formula_229 If there exists a measurable map formula_230 from formula_231 to formula_226 such that formula_233 for all formula_234 then formula_235 If formula_204 is finite or countably infinite or, more generally, formula_226 is a standard Borel space (for example, a separable complete metric space with its associated Borel sets), then the converse is also true. Examples of standard Borel spaces include formula_220 with its Borel sets and formula_239 with the cylinder \u03c3-algebra described below.\nBorel and Lebesgue \u03c3-algebras.\nAn important example is the Borel algebra over any topological space: the \u03c3-algebra generated by the open sets (or, equivalently, by the closed sets). This \u03c3-algebra is not, in general, the whole power set. For a non-trivial example that is not a Borel set, see the Vitali set or Non-Borel sets.\nOn the Euclidean space formula_240 another \u03c3-algebra is of importance: that of all Lebesgue measurable sets. This \u03c3-algebra contains more sets than the Borel \u03c3-algebra on formula_220 and is preferred in integration theory, as it gives a complete measure space.\nProduct \u03c3-algebra.\nLet formula_242 and formula_243 be two measurable spaces. The \u03c3-algebra for the corresponding product space formula_244 is called the product \u03c3-algebra and is defined by\nformula_245\nObserve that formula_246 is a \u03c0-system.\nThe Borel \u03c3-algebra for formula_220 is generated by half-infinite rectangles and by finite rectangles. For example,\nformula_248\nFor each of these two examples, the generating family is a \u03c0-system.\n\u03c3-algebra generated by cylinder sets.\nSuppose\nformula_249\nis a set of real-valued functions. Let formula_250 denote the Borel subsets of formula_251 A cylinder subset of formula_1 is a finitely restricted set defined as\nformula_253\nEach\nformula_254\nis a \u03c0-system that generates a \u03c3-algebra formula_255 Then the family of subsets\nformula_256\nis an algebra that generates the cylinder \u03c3-algebra for formula_16 This \u03c3-algebra is a subalgebra of the Borel \u03c3-algebra determined by the product topology of formula_258 restricted to formula_16\nAn important special case is when formula_260 is the set of natural numbers and formula_1 is a set of real-valued sequences. In this case, it suffices to consider the cylinder sets\nformula_262\nfor which\nformula_263\nis a non-decreasing sequence of \u03c3-algebras.\nBall \u03c3-algebra.\nThe ball \u03c3-algebra is the smallest \u03c3-algebra containing all the open (and/or closed) balls. This is never larger than the Borel \u03c3-algebra. Note that the two \u03c3-algebra are equal for separable spaces. For some nonseparable spaces, some maps are ball measurable even though they are not Borel measurable, making use of the ball \u03c3-algebra useful in the analysis of such maps.\n\u03c3-algebra generated by random variable or vector.\nSuppose formula_264 is a probability space. If formula_265 is measurable with respect to the Borel \u03c3-algebra on formula_220 then formula_132 is called a random variable (formula_268) or random vector (formula_269). The \u03c3-algebra generated by formula_132 is\nformula_271\n\u03c3-algebra generated by a stochastic process.\nSuppose formula_272 is a probability space and formula_273 is the set of real-valued functions on formula_274 If formula_275 is measurable with respect to the cylinder \u03c3-algebra formula_276 (see above) for formula_1 then formula_132 is called a stochastic process or random process. The \u03c3-algebra generated by formula_132 is\nformula_280\nthe \u03c3-algebra generated by the inverse images of cylinder sets.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29587", "revid": "925588", "url": "https://en.wikipedia.org/wiki?curid=29587", "title": "Second Battle of El Alamein", "text": "Battle in the Western Desert Campaign of the Second World War\nThe Second Battle of El Alamein (23 October \u2013 11 November 1942) was a battle of the Second World War that took place near the Egyptian railway halt of El Alamein. The First Battle of El Alamein and the Battle of Alam el Halfa had prevented the Axis from advancing further into Egypt.\nIn October 1942 Lieutenant-General Bernard Montgomery, commander of Eighth Army, opened his offensive against the Axis forces. In a 13-day battle the Axis \"Panzerarmee Afrika\" was crushed and forced to retreat from Egypt and Libya to the borders of Tunisia. The Allied victory at El Alamein was the beginning of the end of the Western Desert Campaign.\nThe battle ended the Axis threat to the Middle East and Iran and revived the morale of the western Allies, being their first big success against the Axis since Operation Crusader in late 1941. The end of the battle coincided with the Allied invasion of French North Africa in Operation Torch on 8 November, which opened a second front in North Africa.\nBackground.\nPanzer Army Africa (/ \"Generalfeldmarschall\" Erwin Rommel) composed of German and Italian tank and infantry units, subordinated to the new Italian command structure \"Delease\" (North African Command Delegation, Lieutenant-General Curio Barbasetti) had advanced into Egypt after its success at the Battle of Gazala (26 May \u2013 21 June 1942). The Axis advance threatened British control of the Suez Canal, the Middle East and its oil resources. General Claude Auchinleck, Commander-in-Chief of Middle East Command and in tactical command of Eighth Army, withdrew the Eighth Army to within of Alexandria where the Qattara Depression was south of El Alamein on the coast. The depression was impassable and meant that any attack had to be frontal; Axis attacks in the First Battle of El Alamein (1\u201327 July) had been defeated.\nEighth Army counter-attacks in July also failed, as the Axis forces dug in and regrouped. Auchinleck called off the attacks at the end of July to rebuild the army. In early August, Winston Churchill and General Sir Alan Brooke, the Chief of the Imperial General Staff (CIGS), visited Cairo and replaced Auchinleck as Commander-in-chief Middle East Command, with General Harold Alexander. Lieutenant-General William Gott was made commander of the Eighth Army but was killed when his transport aircraft was shot down by \"Luftwaffe\" fighters; Lieutenant-General Bernard Montgomery was flown from Britain to replace him.\nLacking reinforcements and depending on small, underdeveloped ports for supplies and aware of a huge Allied reinforcement operation for the Eighth Army, Rommel decided to attack first. The two armoured divisions of the \"Afrika Korps\" and the reconnaissance units of led the attack but were repulsed at the Alam el Halfa ridge and Point 102 on 30 August 1942, during the Battle of Alam el Halfa; the Axis forces retired to their start lines. The short front line and secure flanks favoured the defensive and Rommel had time to develop the Axis fortifications, sowing minefields with c.\u2009500,000 mines and miles of barbed wire. Alexander and Montgomery intended to establish a superiority of force sufficient to achieve a breakthrough and exploit it to destroy . Earlier in the Western Desert Campaign, neither side had been able to exploit a local victory sufficiently to defeat its opponent before it had withdrawn and transferred the problem of over-extended supply lines to the victor.\nUntil June 1942 Rommel had been receiving detailed information about the strength and movement of British forces from reports sent to Washington by Colonel Bonner Fellers, the U.S. military attach\u00e9 in Cairo. The American code had been stolen following a covert operation by Italian military intelligence at the American Embassy in Rome the previous year. Despite British concerns, the Americans continued to use the code until the end of June. Suspicion that the code was compromised was confirmed when the 9th Australian Division captured the German 621st Signal Battalion in July 1942.\nThe British gained the intelligence advantage because Ultra and local sources exposed the Axis order of battle, its supply position and intentions. A reorganisation of military intelligence in Africa in July had also improved the integration of information received from all sources and the speed of its dissemination. With rare exceptions, intelligence identified the supply ships destined for North Africa, their location or routing and in most cases their cargoes, allowing them to be attacked. By 25 October, was down to three days' supply of fuel, only two days' of which were east of Tobruk. Harry Hinsley, the official historian of British intelligence, wrote in 1981 that \"The Panzer Army...\u00a0did not possess the operational freedom of movement that was absolutely essential in consideration of the fact that the British offensive can be expected to start any day\". Submarine and air transport somewhat eased the shortage of ammunition and by late October, there was sixteen days' supply at the front. After six more weeks, the Eighth Army was ready; 195,000 men and 1,029 tanks began the offensive against the 116,000 men and 547 tanks of the .\nPrelude.\nBritish plan.\nOperation Lightfoot.\nMontgomery's plan was for a main attack to the north of the line and a secondary attack to the south, involving XXX Corps (Lieutenant-General Oliver Leese) and XIII Corps (Lieutenant-General Brian Horrocks), while X Corps (Lieutenant-General Herbert Lumsden) was to exploit the success. With Operation Lightfoot, Montgomery intended to cut two corridors through the Axis minefields in the north. One corridor was to run south-west through the 2nd New Zealand Division sector towards the centre of Miteirya Ridge, while the second was to run west, passing north of the west end of the Miteirya Ridge across the 9th Australian and 51st (Highland) Division sectors. Tanks would then pass through and defeat the German armour. Diversions at Ruweisat Ridge in the centre and also the south of the line would keep the rest of the Axis forces from moving northwards. Montgomery expected a 12-day battle in three stages: the break-in, the dogfight and the final breaking of the enemy.\nFor the first night of the offensive, Montgomery planned for four infantry divisions of XXX Corps to advance on a front to the Oxalic Line, over-running the forward Axis defences. Engineers would clear and mark the two lanes through the minefields, through which the armoured divisions from X Corps would pass to gain the Pierson Line. They would rally and consolidate their position just west of the infantry positions, blocking an Axis tank counter-attack. The British tanks would then advance to \"Skinflint\", astride the north\u2013south Rahman Track deep in the Axis defensive system, to challenge the Axis armour. The infantry battle would continue as the Eighth Army infantry \"crumbled\" the deep Axis defensive fortifications (three successive lines of fortification had been constructed) and destroy any tanks that attacked them.\nOperation Bertram.\nBefore the battle the Commonwealth forces practised deceptions, in Operation Bertram, to confuse the Axis command as to where and when the battle was to occur. In September, they dumped waste materials (discarded packing cases, etc.) under camouflage nets in the northern sector, making them appear to be ammunition or ration dumps. The Axis naturally noticed these but as no offensive action immediately followed and the \"dumps\" did not change in appearance, they were subsequently ignored. This allowed the Eighth Army to build up supplies in the forward area unnoticed by the Axis, by replacing the rubbish with ammunition, petrol and rations at night. A dummy pipeline was built, hopefully leading the Axis to believe the attack would occur much later than it did and much further south. Dummy tanks consisting of plywood frames placed over jeeps were built and deployed in the south. In a reverse feint, the tanks destined for battle in the north were disguised as supply trucks by placing removable plywood superstructures over them.\nOperation Braganza.\nAs a preliminary, the 131st (Queen's) Infantry Brigade of the 44th (Home Counties) Infantry Division, supported by tanks from the 4th Armoured Brigade, launched Operation Braganza attacking the paratroopers of the 185th Infantry Division \"Folgore\" on the night of 29/30 September in an attempt to capture the Deir el Munassib area. The Italian paratroopers repelled the attack, killing or capturing over 300 of the attackers. It was wrongly assumed that \"Fallschirmj\u00e4ger\" (German paratroopers) had manned the defences and been responsible for the British reverse. The \"Afrika Korps\" war diary notes that the Italian paratrooper unit \"bore the brunt of the attack. It fought well and inflicted heavy losses on the enemy.\"\nAxis plan.\nWith the failure of their offensive at the Battle of Alam el Halfa, the Axis forces went onto the defensive but losses had not been excessive. The Axis supply line from Tripoli was extremely long and captured British supplies and equipment had been exhausted, but Rommel decided to advance into Egypt.\nThe Eighth Army was being supplied with men and materials from the United Kingdom, India, Australia and New Zealand, as well as with trucks and the new Sherman tanks from the United States. Rommel continued to request equipment, supplies and fuel but the priority of the German war effort was the Eastern Front and very limited supplies reached North Africa. Rommel was ill and in early September, arrangements were made for him to return to Germany on sick leave and for \"General der Panzertruppe\" Georg Stumme to transfer from the Russian front to take his place. Before he left for Germany on 23 September, Rommel organised the defence and wrote a long appreciation of the situation to \"Oberkommando der Wehrmacht\" (OKW armed forces high command), once again setting out the essential needs of the Panzer Army.\nRommel knew that the British and Commonwealth forces would soon be strong enough to attack. His only hope now relied on the German forces fighting in the Battle of Stalingrad quickly to defeat the Red Army, then move south through the Trans-Caucasus and threaten Iran (Persia) and the Middle East. If successful, large numbers of British and Commonwealth forces would have to be sent from the Egyptian front to reinforce the Ninth Army in Iran, leading to the postponement of any offensive against his army. Rommel hoped to convince OKW to reinforce his forces for the eventual link-up between and the German armies fighting in southern Russia, enabling them finally to defeat the British and Commonwealth armies in North Africa and the Middle East.\nIn the meantime, the dug in and waited for the attack by the Eighth Army or the defeat of the Red Army at Stalingrad. Rommel added depth to his defences by creating at least two belts of mines about apart, connected at intervals to create boxes (Devil's gardens) which would restrict Allied penetration and deprive British armour of room for manoeuvre. The front face of each box was lightly held by battle outposts and the rest of the box was unoccupied but sowed with mines and explosive traps and covered by enfilading fire. The main defensive positions were built to a depth of at least behind the second mine belt. The Axis laid around half a million mines, mostly Teller anti-tank mines with some smaller anti-personnel types such as the S-mine. (Many were British mines captured at Tobruk). To lure Allied vehicles into the minefields, the Italians dragged an axle and tyres through the fields using a long rope to create what appeared to be well-used tracks.\nRommel did not want the British armour to break out into the open because he had neither the strength of numbers nor fuel to match them in a battle of manoeuvre. The battle had to be fought in the fortified zones; a breakthrough had to be defeated quickly. Rommel stiffened his forward lines by alternating German and Italian infantry formations. Because the British deception confused the Axis as to the point of attack, Rommel departed from his usual practice of holding his armoured strength in a concentrated reserve and split it into a northern group (15th Panzer Division and 133rd Armoured Division \"Littorio\") and a southern group (21st Panzer Division and 132nd Armoured Division \"Ariete\"), each organised into battle groups to be able to make a quick armoured intervention wherever the blow fell and prevent narrow breakthroughs from being enlarged. A significant proportion of his armoured reserve was dispersed and held unusually far forward. The 15th Panzer Division had 125 operational tanks (16 Pz.IIs, 43 Pz.III Ausf H, 43 Pz.III Ausf J, 6 Pz.IV Ausf D, 15 Pz.IV Ausf F) while the 21st Panzer Division had 121 operational tanks (12 Pz.IIs, 38 Pz.III Ausf H, 43 Pz.III Ausf J, 2 Pz.IV Ausf D, 15 Pz.IV Ausf F).\nRommel held the 90th Light Division further back and kept the 101st Motorised Division \"Trieste\" in reserve close to the coast. Rommel hoped to move his troops quicker than the Allies, to concentrate his defences at the most important point () but lack of fuel meant that once the had concentrated, it would not be able to move again. The British were well aware that Rommel would be unable to mount a defence based on his usual manoeuvre tactics but no clear picture emerged of how he would fight the battle. British plans seriously underestimated the Axis defences and the fighting power of the .\nBattle.\nPhase one: the break-in.\nPrior to the main barrage, there was a diversion by the 24th Australian Brigade, which involved the 15th Panzer Division being subjected to heavy fire for a few minutes. Then at 21:40 (Egyptian Summer Time) on 23 October on a calm, clear evening under the bright sky of a full moon, Operation Lightfoot began with a 1,000-gun barrage. The fire plan had been arranged so that the first rounds from the 882 guns from the field and medium batteries would land along the front at the same time. After twenty minutes of general bombardment, the guns switched to precision targets in support of the advancing infantry. The shelling plan continued for five and a half hours, by the end of which each gun had fired about 600 rounds, about 529,000 shells.\nOperation Lightfoot alluded to the infantry attacking first. Anti-tank mines would not be tripped by soldiers stepping on them since they were too light. As the infantry advanced, engineers had to clear a path for the tanks coming behind. Each gap was to be wide, which was just enough to get tanks through in single file. The engineers had to clear a route through the Devil's Gardens. It was a difficult task that was not achieved because of the depth of the Axis minefields.\nAt 22:00, the four infantry divisions of XXX Corps began to move. The objective was to establish a bridgehead before dawn at the imaginary line in the desert where the strongest enemy defences were situated, on the far side of the second mine belt. Once the infantry reached the first minefields, the mine sweepers, including Reconnaissance Corps troops and sappers, moved in to create a passage for the armoured divisions of X Corps. Progress was slower than planned but at 02:00, the first of the 500 tanks crawled forward. By 04:00, the lead tanks were in the minefields, where they stirred up so much dust that there was no visibility at all, traffic jams developed and tanks bogged down. Only about half of the infantry attained their objectives and none of the tanks broke through.\nThe 1st South African Division, on the left flank of XXX Corps, attacked on a two-brigade front to secure the southern end of Miteirya Ridge, with the 2nd South African Infantry Brigade on the right and the 3rd South African Infantry Brigade on the left. The 1st South African Infantry Brigade was deployed further south to create an anti-tank screen for the protection of the left flank of the attack. By 08:00 on 24 October, Miteirya Ridge was secured after a night of heavy fighting and a high number of casualties.\nThe 7th Armoured Division (with a Free French Brigade under command) from XIII Corps (Lieutenant-General Brian Horrocks) made a secondary attack to the south. The main attack aimed to achieve a breakthrough, engage and pin down the 21st Panzer Division and the \"Ariete\" Division around Jebel Kalakh, while the Free French on the far left were to secure Qaret el Himeimat and the el Taqa plateau. The right flank of the attack was to be protected by 44th Infantry Division with the 131st Infantry Brigade. The attack met determined resistance, mainly from the 185th Infantry Division \"Folgore\", part of the Ramcke Parachute Brigade and .\nThe minefields were deeper than anticipated and clearing paths through them was impeded by Axis defensive fire. By dawn on 24 October, paths still had not been cleared through the second minefield to release the 22nd and 4th Light Armoured Brigades into the open to make their planned turn north into the rear of enemy positions west of Deir el Munassib. Further north along the XIII Corps front, the 50th (Northumbrian) Infantry Division achieved a limited and costly success against determined resistance from the 17th Infantry Division \"Pavia\", 27th Infantry Division \"Brescia\" and elements of the 185th Infantry Division \"Folgore\". The 4th Indian Infantry Division, on the far left of the XXX Corps front at Ruweisat Ridge, made a mock attack and two small raids to deflect attention to the centre of the front.\nPhase two: the crumbling.\nDawn aerial reconnaissance showed little change in Axis dispositions and Montgomery ordered that the clearance of the northern corridor should be completed and the New Zealand Division supported by the 10th Armoured Division should push south from Miteirya Ridge. The 9th Australian Division, in the north, should plan a crumbling operation for that night, while in the southern sector, the 7th Armoured Division should continue to try to break through the minefields with support, if necessary, from the 44th Division. \"Panzer\" units counter-attacked the 51st Highland Division just after sunrise but were defeated.\nThe morning of Saturday 24 October brought disaster for the German headquarters. The Axis forces were stunned by British attack and their messages became confused and hysterical, with one Italian unit communicating to Germans that it had been wiped out by \"drunken negroes with tanks\". The reports that Stumme had received that morning showed the attacks had been on a broad front but that such penetration as had occurred should be containable by local units. He went forward to see for himself, suffered a heart attack and died. Temporary command was given to Major-General Wilhelm Ritter von Thoma. Hitler had already decided that Rommel should leave his sanatorium and return to North Africa.\nPending complete clearance of paths through the minefields, the Allied armour was held at the Oxalic Line. In the 51st (Highland) Division sector, the Seaforth Highlanders, supported by tanks of the 2nd Armoured Brigade, attacked and captured the \"Stirling\" position. Artillery and the Desert Air Force, making over 1,000 sorties, bombarded Axis positions all day to aid the 'crumbling' of the Axis forces. By 16:00 there was little progress beyond the Oxalic Line.\nAt dusk, with the sun at their backs, Axis tanks from the 15th Panzer Division and the \"Littorio\" Division advanced from the Kidney feature (also known to the Germans and Italians as Hill 28), often wrongly called a ridge as it was actually a depression, to engage the 1st Armoured Division and the first big tank engagement of El Alamein began. Over 100 tanks were involved and half were destroyed by dark; neither position was altered.\nLumsden wanted to call off the attack planned for the night of 24/25 September but Montgomery overruled him. The thrust that night by the 10th Armoured Division from Miteirya Ridge failed. The lifting of mines on the Miteirya Ridge and beyond took far longer than planned and the leading unit, the 8th Armoured Brigade, was caught on their start line at 22:00\u2014zero hour\u2014by an air attack and were scattered. Axis bombers destroyed a convoy of 25 British vehicles carrying petrol and ammunition, setting off a night-long blaze. By the time the 8th Armoured Brigade had reorganised they were well behind schedule and out of touch with the creeping artillery barrage. By daylight the brigade was caught in the open, suffering considerable fire from well sited tanks and anti-tank guns. The 24th Armoured Brigade had pushed forward and reported at dawn they were on the Pierson Line, although it turned out that, in the dust and confusion, they had mistaken their position and were well short.\nThe attack in the XIII Corps sector to the south fared no better. The 131st Infantry Brigade cleared a path through the mines but when the 22nd Armoured Brigade passed through, they came under fire and were repulsed, with 31 tanks disabled. British air activity that night focused on Rommel's northern armoured group, where of bombs were dropped. To prevent a recurrence of the 8th Armoured Brigade's experience from the air, attacks on Axis landing fields were also stepped up.\nD + 2: 25 October.\nThe first attack had ended by Sunday. The British had advanced through the minefields in the west to make a wide and deep inroad. They were on top of Miteirya Ridge in the south-east. Axis forces were firmly entrenched in most of their original battle positions and the attack had been contained. Montgomery decided that the planned advance southward from Miteirya Ridge by the New Zealanders would be too costly and instead decided that XXX Corps\u2014while keeping firm hold of Miteirya\u2014should strike northwards toward the coast with the 9th Australian Division. The 1st Armoured Division\u2014on the Australian left\u2014should continue to attack west and north-west; activity to the south on both corps fronts would be confined to patrolling. The battle would be concentrated at the Kidney feature and Tel el Eisa until a breakthrough occurred.\nRommel flew to Rome early on 25 October to press for more fuel and ammunition, then on to North Africa later in the day. Meanwhile, in the afternoon the Axis forces launched attacks using the 15th Panzer and \"Littorio\" divisions. The Panzer Army probed for a weakness but without success. The British and Commonwealth infantry attacked at dusk. Around midnight, the 51st (Highland) Division launched three attacks. These were hindered by navigational difficulties as no one knew quite where they were, and heavy casualties were suffered amidst the confusion. Nevertheless, most of the Oxalic Line was eventually secured excepting the Aberdeen position on the Kidney feature. While the 51st Highland Division was operating around the Kidney feature, the Australians were attacking Point 29 (sometimes shown on Axis maps as \"28\") a high Axis artillery observation post south-west of Tel el Eisa, to surround the Axis coastal salient containing the German 164th Light Division and large numbers of Italian infantry.\nThis was the new northern thrust Montgomery had devised earlier in the day. The 26th Australian Brigade attacked at midnight, supported by artillery and 30 tanks of the 40th Royal Tank Regiment. The Australians took the position and 240 prisoners. Fighting continued in this area for the next week, as the Axis tried to recover the small hill that was so important to their defence. Night bombers dropped of bombs on targets in the battlefield and on the \"Stuka\" base at Sidi Haneish, while night fighters flew patrols over the battle area and the Axis forward landing grounds. In the south, the 4th Armoured Brigade and the 69th Infantry Brigade attacked the 187th Infantry Regiment \"Folgore\" at Deir Munassib, but lost about 20 tanks gaining only the forward positions. Rommel arrived at El Alamein on the evening of the 25th to resume command of the Panzer Army Africa, which was renamed the German-Italian Panzer Army () that day. Rommel's arrival boosted German morale, though there was little he could do to change the course of the battle.\nOn arrival at his headquarters, Rommel assessed the battle. Casualties, particularly in the north, as a result of incessant artillery and air attack, had been severe. The Italian 102nd Motorised Division \"Trento\" had lost 50 per cent of its infantry and most of its artillery and the 164th Light Division had lost two battalions. The 15th Panzer and \"Littorio\" divisions had prevented the British tanks from breaking through but this had been a costly defensive success, the 15th Panzer Division being reduced to 31 tanks. Most other units were also under strength, on half rations and many men were ill; had only enough fuel for three days.\nPhase three: the counter.\nD + 3: 26 October.\nRommel was convinced by this time that the main assault would come in the north and determined to retake Point 29. He ordered a counter-attack against it by the 15th Panzer Division and the 164th Light Division, with part of the Italian XX Corps to begin at 15:00 but under constant artillery and air attack this came to nothing. According to Rommel this attack did meet some success, with the Italians recapturing part of \"Hill 28\",\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Attacks were now launched on Hill 28 by elements of the 15th Panzer Division, the Littorio and a Bersaglieri Battalion, supported by the concentrated fire of all the local artillery and AA. In the evening part of the Bersaglieri Battalion succeeded in occupying the eastern and western edges of the hill.\nThe bulk of the 2/17th Australian Battalion, which defended the position, was forced to give some ground. Rommel reversed his policy of distributing his armour across the front, ordering the 90th Light Division forward from Ed Daba and 21st Panzer Division north along with one third of the \"Ariete\" Division and half the artillery from the southern sector to join the 15th Panzer Division and the \"Littorio\" Division. The move could not be reversed because of the fuel shortage. The \"Trieste\" Division was ordered from Fuka to replace the 90th Light Division at Ed Daba but the 21st Panzer Division and the \"Ariete\" Division made slow progress during the night under constant attack from DAF bombers.\nAt the Kidney feature, the British were unable to take advantage of the absent tanks; each time they tried to move forward they were stopped by anti-tank guns. Churchill railed, \"Is it really impossible to find a general who can win a battle?\" Bristol Beaufort torpedo bombers of 42 Squadron, attached to 47 Squadron, sank the tanker \"Proserpina\" at Tobruk; three Vickers Wellington torpedo bombers of 38 Squadron destroyed the oil tanker \"Tergestea\" at Tobruk during the night, removing the last hope for refuelling the .\nBy 26 October, XXX Corps had completed the capture of the bridgehead west of the second mine belt. The British Forces had sustained 2000 casualties, the Australians 1000, the New Zealanders 1000 and the South Africans 600. The tanks of X Corps, established just beyond the infantry, had failed to break through the Axis anti-tank defences. Montgomery decided that over the next two days, while continuing the process of attrition, he would thin out his front line to create a reserve for another attack. The reserve was to include the 2nd New Zealand Division (with the 9th Armoured Brigade under command), the 10th Armoured Division and the 7th Armoured Division.\nThe attacks in the south, which lasted three days and caused considerable losses without achieving a breakthrough, were suspended.\nD + 4: 27 October.\nThe main battle was concentrated around Tel el Aqqaqir and the Kidney feature at the end of the 1st Armoured Division's path through the minefield. A mile north-west of the feature was Outpost Woodcock and roughly the same distance south-west lay Outpost Snipe. An attack was planned on these areas using two battalions from 7th Motor Brigade. At 23:00 on 26 October 2 Battalion, The Rifle Brigade would attack Snipe and 2nd Battalion King's Royal Rifle Corps (KRRC) would attack Woodcock. The plan was for 2nd Armoured Brigade to pass round the north of Woodcock the following dawn and 24th Armoured Brigade round the south of Snipe. The attack was to be supported by all the artillery of X and XXX Corps.\nBoth battalions had difficulty finding their way in the dark and dust. At dawn, the KRRC had not reached its objective and had to find cover and dig in some distance from Woodcock. The 2nd Rifle Brigade had been more fortunate and after following the shell bursts of the supporting artillery, dug in when they concluded they had reached their objective having encountered little opposition.\nAt 06:00, the 2nd Armoured Brigade commenced its advance and ran into such stiff opposition that, by noon, it had still not linked with the KRRC. The 24th Armoured Brigade started a little later and was soon in contact with the Rifle Brigade (having shelled them in error for a while). Some hours of confused fighting ensued involving tanks from the \"Littorio\" and troops and anti-tank guns from 15th Panzer which managed to keep the British armour at bay in spite of the support of the anti-tank guns of the Rifle Brigade battle group. Rommel had decided to make two counter-attacks using his fresh troops. 90th Light Division was to make a fresh attempt to capture Point 29 and 21st Panzer were targeted at Snipe (the \"Ariete\" detachment had returned south).\nAt Snipe, mortar and shellfire was constant all day. Lucas-Phillips, in his \"Alamein\" wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The desert was quivering with heat. The gun detachments and the platoons squatted in their pits and trenches, the sweat running in rivers down their dust-caked faces. There was a terrible stench. The flies swarmed in black clouds upon the dead bodies and excreta and tormented the wounded. The place was strewn with burning tanks and carriers, wrecked guns and vehicles, and over all drifted the smoke and the dust from bursting high explosives and from the blasts of guns.\u2014\u200a\nAt 16:00, Rommel launched his major attack. German and Italian tanks moved forward against the Rifle Brigade which had thirteen 6-pounder anti-tank guns along with six more from the 239th Anti-Tank Battery, RA. Although on the point of being overrun more than once they held their ground, destroying 22 German and 10 Italian tanks. The Germans gave up but in error the British battle group was withdrawn without being replaced that evening. Only one anti-tank gun\u2014from 239 Battery\u2014could be brought back. The action at Snipe was an episode of the Battle of El Alamein described by the regimental historian of the Rifle Brigade as the most famous day of the regiment's war. Its CO, Lieutenant-Colonel Victor Buller Turner, was awarded the Victoria Cross.\nWhen it was discovered that neither Woodcock nor Snipe was in Eighth Army hands, the 133rd Lorried Infantry Brigade was sent to capture them. By 01:30 on 28 October, the 4th battalion Royal Sussex Regiment judged they were on Woodcock and dug in. At dawn, the 2nd Armoured Brigade moved up in support but before contact could be made the 4th Royal Sussex were counter-attacked and overrun with many losses. The 133rd Lorried Brigade's two other battalions had moved on Snipe and dug in, only to find out the next day that they were in fact well short of their objective.\nFurther north, the attack by the 90th Light Division attack on Point 29 during the afternoon of 27 October failed under heavy artillery and bombing which broke up the attack before it had closed with the Australians.\nD + 5\u20136: 28\u201329 October.\nOn 28 October, the 15th Panzer Division and 21st Panzer Division made a determined attack on the X Corps front but were halted by artillery, tank and anti-tank gun fire. In the afternoon, they paused to regroup to attack again but they were bombed for two and a half hours and were prevented from forming up. This proved to be Rommel's last attempt to take the initiative and his defeat represented a turning point in the battle. Montgomery ordered X Corps units in the area of Woodcock and Snipe to go over to the defensive while he concentrated the attack further to the north. Late on 27 October, the 133rd Lorried Infantry Brigade was sent forward to recover lost positions.\nOn 28 October much of the force was overrun by German and Italian tanks from the \"Littorio\" Division and supporting 12th Bersaglieri Regiment; several hundred British soldiers were captured. On the night of 28/29 October, the 9th Australian Division was ordered to make a second set-piece attack. The 20th Australian Infantry Brigade with the 40th R.T.R. in support would push north-west from Point 29 to form a base for the 26th Australian Infantry Brigade with the 46th R.T.R., to attack north-east to Thompson's Post south of the railway. Once the post was captured, the Australians were to cross the railway to the coast road and advance south-east, to close on the rear of the Axis troops in the coastal salient. An attack by the third brigade would then be launched on the salient from the south-east.\nThe 20th Australian Infantry Brigade took its objectives with little trouble but the 26th Australian Infantry Brigade had difficulty. Because of the distances involved, the troops were riding on the Valentine tanks of the 46th R.T.R. and carriers, which mines and anti-tank guns soon brought to grief, forcing the infantry to dismount. The infantry and tanks lost touch, fighting with the 125th \"Panzergrenadier\" Regiment and a battalion of the 7th Bersaglieri Regiment sent to reinforce the sector; the advance came to a halt. The Australians suffered 200 casualties in that attack and suffered 27 killed and 290 wounded. The German and Italian forces that had participated in the counter-attack formed an outpost and held on until the arrival of German reinforcements on 1 November.\nIt was too close to dawn to reform and continue the attack and the operation was called off. By the end of these engagements in late October, the British still had 800 serviceable tanks and the \"Panzerarmee\" day report for 28 October (intercepted and read by Eighth Army the following evening) recorded 81 serviceable German tanks and 197 Italian. With the help of signals intelligence information the \"Proserpina\" (carrying of fuel) and \"Tergestea\" (carrying of fuel and of ammunition) had been destroyed on 26 October and the tanker \"Luisiano\" (carrying of fuel) had been sunk off the west coast of Greece by a torpedo from a Wellington bomber on 28 October. Rommel told his commanders, \"It will be quite impossible for us to disengage from the enemy. There is no gasoline for such a manoeuvre. We have only one choice and that is to fight to the end at Alamein\".\nThe Australian and British attacks had alerted Montgomery that Rommel had committed his reserve, the 90th Light Division, to the front and that its presence in the coastal sector suggested that Rommel was expecting the next big offensive there. Montgomery decided to attack further south on a front, south of Point 29. The attack was to take place on the night of 31 October/1 November, as soon as he had completed the reorganisation of his front line to create reserves for the offensive (although in the event it was postponed by 24 hours). To keep Rommel's attention on the coastal sector, Montgomery ordered the renewal of the 9th Australian Division operation on the night of 30/31 October.\nD + 7\u20139: 30 October \u2013 1 November.\nThe night of 30 October saw the third Australian attempt to reach the paved road and by the end of the night they were astride the road and the railway, making the position of the Axis troops in the salient precarious. A battlegroup from the 21st Panzer Division launched four attacks against Thompson's Post on 31 October, all being repulsed. Sergeant William Kibby (2/48th Australian Infantry Battalion), for his actions from 23 October until his death on 31 October, including a lone attack on a machine-gun position at his own initiative, was awarded the Victoria Cross (posthumous). On 1 November, contact with 125 in the nose of the salient was restored; the supporting X Bersaglieri Battalion of the 7th Bersaglieri Regiment resisted several Australian attacks.\nOn 1 November, the tankers \"Tripolino\" and \"Ostia\" were torpedoed and sunk by aircraft, north-west of Tobruk. The shortage forced Rommel to rely increasingly on fuel flown in from Crete on the orders of Albert Kesselring, (OB , Supreme Commander South), despite the restrictions imposed by the bombing of the airfields in Crete and Desert Air Force interceptions of the transport aircraft. Rommel began to plan a retirement to Fuka, some to the west, as he had only 90 tanks remaining, against 800 British tanks. Large amounts of fuel arrived at Benghazi after the German forces had started to retreat but little of it reached the front, a fact Kesselring tried to change by delivering it more closely to the fighting forces. Barbasetti insisted to Rommel that the \"Deutsche-Italienlische Panzerarmee\" must hold at El Alamein as supplies would arrive for them.\nPhase four: Operation Supercharge.\nD + 10: 2 November.\nThis phase of the battle began at 01:00 on 2 November, with the objective of destroying enemy armour, forcing the enemy to fight in the open, reducing the Axis stock of petrol, attacking and occupying enemy supply routes, and causing the disintegration of the enemy army. The intensity and the destruction in Supercharge were greater than anything witnessed so far during this battle. The objective of this operation was Tel el Aqqaqir, the base of the Axis defence roughly north-west of the Kidney feature and situated on the Rahman lateral track.\nThe initial thrust of Supercharge was to be carried out by the 2nd New Zealand Division. Lieutenant-General Bernard Freyberg had tried to free them of this task, as they had lost 1,405 men in just three days, at El Ruweisat Ridge in July. Along with the 5th New Zealand Infantry Brigade and 28th (Maori) Infantry Battalion, the division was to have had placed under its command the 151st (Durham) Brigade from the 50th (Northumbrian) Infantry Division, the 152nd (Seaforth and Camerons) Brigade from the 51st (Highland) Division and the 133rd Royal Sussex Lorried Infantry Brigade and the 9th Armoured Brigade under command.\nAs in Operation Lightfoot, it was planned that two infantry brigades (the 151st on the right and 152nd on the left) each this time supported by a regiment of tanks\u2014the 8th and 50th Royal Tank Regiments\u2014would advance and clear a path through the mines. Once they reached their objectives, distant, 9th Armoured Brigade would pass through supported by a heavy artillery barrage and break open a gap in the Axis defences on and around the Rahman track, some further forward, which the 1st Armoured Division, following behind, would pass through into the open to take on Rommel's armoured reserves. Rommel had ordered 21st Panzer Division from the front line on 31 October to form a mobile counterattacking force. The division had left behind a \"panzergrenadier\" regiment which would bolster the \"Trieste\" Division which had been ordered forward to replace it. Rommel had also interspersed formations from the \"Trieste\" and 15th Panzer Divisions to \"corset\" his weaker forces in the front line. On 1 November the two German armoured divisions had 102 effective tanks to face Supercharge and the \"Littorio\" and \"Trieste\" Divisions had 65 tanks between them.\nSupercharge started with a seven-hour aerial bombardment focused on Tel el Aqqaqir and Sidi Abd el Rahman, followed by a four and a half-hour barrage of 360 guns firing 15,000 shells. The two assault brigades started their attack at 01:05 on 2 November and gained most of their objectives to schedule and with moderate losses. One battalion from the 90th Light Division along with another battalion from the 15th Panzer Division were soon overrun and at 04:45 it was reported that only one Bersaglieri infantry battalion was still manning the defensive line. On the right of the main attack the 28th (Maori) Battalion captured positions to protect the right flank of the new salient and the 133rd Lorried Infantry Brigade did the same on the left. New Zealand engineers cleared five lines through the mines allowing the Royal Dragoons armoured car regiment to slip out into the open and spend the day raiding the Axis communications.\nAt 20:00 on 1 November, the 9th Armoured Brigade had started its approach march from El Alamein railway station with forty Grants, 39 Shermans, 24 Crussader Mk III and 29 Crusader Mk II (132 tanks) and arrived at its start line with only 94 runners (operational tanks). The brigade was to have started its attack towards Tel el Aqqaqir at 05:45 behind a barrage but the attack was postponed for 30 minutes while the brigade regrouped. At 06:15, 30 minutes before dawn, the three regiments of the brigade advanced towards the gun line behind a creeping barrage.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We all realise that for armour to attack a wall of guns sounds like another Balaclava, it is properly an infantry job. But there are no more infantry available. So our armour must do it.\u2014\u200a\nCurrie had stated that the brigade would be attacking on too wide a front with no reserves and that they would suffer 50 per cent losses. The reply came from Freyberg that Montgomery,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...\u00a0was aware of the risk and has accepted the possibility of losing 100% casualties in the 9th Armoured Brigade to make the break, but in view of the promise of immediate following through of the 1st Armoured Division, the risk was not considered as great as all that.\u2014\u200a\nThe German and Italian anti-tank guns (mostly Pak38 and Italian 47 mm guns, along with 24 of the formidable 88 mm flak guns) opened fire on the advancing tanks silhouetted by the rising sun. German tanks, which had penetrated between the Warwickshire Yeomanry and Royal Wiltshire Yeomanry, also caused many casualties. British tanks attacking the \"Folgore\" sector were fought off with petrol bombs and mortar fire as well as with the obsolete Italian 47\u00a0mm guns. The Axis gun screen was unable to stop the tanks and in 30 minutes, around 35 guns were destroyed and several hundred prisoners taken. The 94 tanks that started the attack was reduced to 24 runners and of the 400 men involved in the attack, 230 had been killed, wounded or captured.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If the British armour owed any debt to the infantry of the Eighth Army, the debt was paid on November 2 by 9th Armoured in heroism and blood.\u2014\u200a\nAfter the Brigade's action, Brigadier Gentry of the 6th New Zealand Brigade went ahead to survey the scene. On seeing Currie asleep on a stretcher, he approached him saying, \"Sorry to wake you John, but I'd like to know where your tanks are?\" Currie waved his hand at a group of tanks around him and replied \"There they are\". Gentry said \"I don't mean your headquarters tanks, I mean your armoured regiments. Where are they?\" Currie waved his arm and again replied, \"There are my armoured regiments, Bill\".\nThe brigade had sacrificed itself upon the gun line and caused great damage but had failed to create the gap for the 1st Armoured Division to pass through. Soon after dawn the 1st Armoured Division started to deploy and the remains of the 9th Armoured Brigade came under its command. The 2nd Armoured Brigade came up behind the 9th and by mid-morning the 8th Armoured Brigade had come up on its left, ordered to advance to the south-west. In determined fighting during the day the British armour made little further progress. At 11:00 on 2 November, the remains of the 15th Panzer Division, 21st Panzer Division and the \"Littorio\" Division counter-attacked the 1st Armoured Division and the remnants of the 9th Armoured Brigade, which by that time had dug in with a screen of anti-tank guns and artillery together with intensive air support. The counter-attack failed under a blanket of shells and bombs at a cost of about 100 tanks.\nAlthough X Corps had failed in its attempt to break out, it had succeeded in its objective of finding and destroying Axis tanks. Although tank losses were approximately equal, this represented only a portion of the total British armour but most of Rommel's tanks; the \"Afrika Korps\" strength of tanks fit for battle fell by 70 while in addition to the losses of the 9th Armoured Brigade, the 2nd and 8th Armoured Brigades lost 14 tanks in the fighting, with another 40 damaged or broken down. The fighting was later termed the \"Hammering of the Panzers\". In the late afternoon and early evening, the 133rd Lorried Infantry Brigade and 151st Infantry Brigade, under command of the 51st (Highland) Infantry Division, attacked respectively the Snipe and Skinflint (about a mile west of Snipe) positions to form a base for future operations. The heavy artillery concentration which accompanied their advance suppressed the opposition from the \"Trieste\" Division and the operation succeeded with few casualties.\nOn the night of 2/3 November, Montgomery once again reshuffled his infantry in order to bring four brigades (5th Indian, 151st, 5th New Zealand and 154th) into reserve under XXX Corps, to prepare for the next thrust. He also reinforced X Corps by moving the 7th Armoured Division from army reserve and sending the 4th Light Armoured Brigade from XIII Corps in the south. General von Thoma's report to Rommel that night said he would have at most 35 tanks available to fight the next day and his artillery and anti-tank weapons had been reduced to \u2153 of their strength at the start of the battle. Rommel concluded that to forestall a breakthrough and the destruction of his army, he must start withdrawing to the position at Fuka. He called up \"Ariete\" from the south to join the mobile Italian XX Corps around Tel el Aqqaqir. His mobile forces (XX Corps, \"Afrika Korps\", 90th Light Division and 19th \"Flak\" Division) were ordered to make a fighting withdrawal while his other formations were to withdraw as best they could with the transport available.\nD + 11: 3 November.\nAt 20:30 on 2 November, Lumsden decided that one more effort by X Corps would see the gun screen on the Rahman track defeated and ordered the 7th Motor Brigade to seize the track along a front north of Tel el Aqqaqir. The 2nd and 8th Armoured Brigades would then pass through the infantry to a distance of about . On the morning of 3 November the 7th Armoured Division would pass through and swing north heading for the railway at Ghazal station. 7th Motor Brigade set off at 01:15 on 3 November, but having received its orders late, had not had the chance to reconnoitre the battle area in daylight. This combined with stiff resistance led to the failure of their attack. As a consequence, the orders for the armour were changed and 2nd Armoured Brigade was tasked to support the forward battalion of the 133rd Lorried Brigade (2nd King's Royal Rifle Corps) and the 8th Armoured Brigade was to push south-west. Fighting continued throughout 3 November, but the 2nd Armoured Brigade was held off by elements of the \"Afrika Korps\" and tanks of the \"Littorio\" Division. Further south, the 8th Armoured Brigade was held off by anti-tank units helped later by tanks of the arriving \"Ariete\" Division.\nPhase five: the break-out.\nOn 2 November, Rommel signalled to Hitler that\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The army's strength was so exhausted after its ten days of battle that it was not now capable of offering any effective opposition to the enemy's next break-through attempt\u00a0... With our great shortage of vehicles an orderly withdrawal of the non-motorised forces appeared impossible\u00a0... In these circumstances we had to reckon, at the least, with the gradual destruction of the army.\nand at 13.30 on 3 November Rommel received a reply,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;To Field Marshal Rommel. It is with trusting confidence in your leadership and the courage of the German-Italian troops under your command that the German people and I are following the heroic struggle in Egypt. In the situation which you find yourself there can be no other thought but to stand fast, yield not a yard of ground and throw every gun and every man into the battle. Considerable air force reinforcements are being sent to C.-in-C South. The \"Duce\" and the \"Comando Supremo\" are also making the utmost efforts to send you the means to continue the fight. Your enemy, despite his superiority, must also be at the end of his strength. It would not be the first time in history that a strong will has triumphed over the bigger battalions. As to your troops, you can show them no other road than that to victory or death. Adolf Hitler.\nRommel thought the order (similar to one that had been given at the same time by Benito Mussolini through ),\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;demanded the impossible.\u00a0... We were completely stunned, and for the first time in the African campaign I did not know what to do. A kind of apathy took hold of us as we issued orders for all existing positions to be held on instructions from the highest authority.\nRommel ordered the Italian X and XXI Corps and the 90th Light Division to hold while the withdrew approximately west during the night of 3 November. The Italian XX Corps and the \"Ariete\" Division conformed to their position and Rommel replied to Hitler confirming his determination to hold the battlefield. The Desert Air Force continued its bombing and in its biggest day of the battle it flew 1,208 sorties and dropped of bombs.\nOn the night of 3/4 November, Montgomery ordered three of the infantry brigades in reserve to advance on the Rahman track as a prelude to an armoured break-out. At 17:45, the 152nd Infantry Brigade with the 8th RTR in support, attacked about south of Tel el Aqqaqir. The 5th Indian Infantry Brigade was to attack the track further south during the early hours of 4 November; at 06:15, the 154th Infantry Brigade was to attack Tel el Aqqaqir. The 152nd Infantry Brigade was mistakenly told the Axis had withdrawn from their objectives and unexpectedly met determined resistance. Communications failed and the forward infantry elements ended up digging in well short of their objective. By the time the 5th Indian Brigade set off, the defenders had begun to withdraw and their objective was taken virtually unopposed. By the time the 154th Brigade moved into some artillery-fire, the Axis had left.\nD + 12, 4 November.\nOn 4 November, the Eighth Army plan for pursuit began at dawn; no fresh units were available and the 1st and 7th Armoured divisions were to turn northwards to roll up the Axis units still in the forward lines. The 2nd New Zealand Division with two lorried infantry brigades and the 9th Armoured and 4th Light Armoured brigades under command, was to head west along desert tracks to the escarpment above Fuka, about away. The New Zealanders got off to a slow start because its units were dispersed after the recent fighting and took time to concentrate. Paths through the minefields were congested and had deteriorated, which caused more delays. By dark, the division was only west of the Rahman track, the 9th Armoured Brigade was still at the track and the 6th New Zealand Brigade even further back.\nThe plan to trap the 90th Light Division with the 1st and 7th Armoured divisions misfired. The 1st Armoured Division came into contact with the remnants of 21st Panzer Division and had to spend most of the day pushing them back . The 7th Armoured Division was held up by the \"Ariete\" Armoured Division, which was destroyed conducting a determined resistance. In his diary, Rommel wrote\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Enormous dust-clouds could be seen south and south-east of headquarters [of the DAK], where the desperate struggle of the small and inefficient Italian tanks of XX Corps was being played out against the hundred or so British heavy tanks which had come round their open right flank. I was later told by Major von Luck, whose battalion I had sent to close the gap between the Italians and the Afrika Korps, that the Italians, who at that time represented our strongest motorised force, fought with exemplary courage. Tank after tank split asunder or burned out, while all the time a tremendous British barrage lay over the Italian infantry and artillery positions. The last signal came from the \"Ariete\" at about 15.30 hours \"Enemy tanks penetrated south of Ariete. Ariete now encircled. Location 5\u00a0km north-west Bir el Abd. Ariete tanks still in action\". [...] In the \"Ariete\" we lost our oldest Italian comrades, from whom we had probably always demanded more than they, with their poor armament, had been capable of performing.\nThe 133rd Armoured Division \"Littorio\" and the 101st Motorised Division \"Trieste\" were also destroyed. Berlin radio claimed that in this sector the \"British were made to pay for their penetration with enormous losses in men and material. The Italians fought to the last man.\" The British took many prisoners, since the remnants of Italian infantry divisions were not motorised and could not escape from encirclement. Private Sid Martindale, 1st Battalion Argyll &amp; Sutherland Highlanders, wrote\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The more we advanced the more we realised that the Italians did not have much fight in them after putting up a strong resistance to our overwhelming advance and they started surrendering to our lead troops in droves. There was not much action to see but we came across lots of burnt out Italian tanks that had been destroyed by our tanks. I had never seen a battlefield before and the site [\"sic\"] of so many dead was sickening.\nThe \"Bologna\" Division and the remnants of the \"Trento\" Division tried to fight their way out and marched into the desert without water, food or transport before surrendering, exhausted and dying from dehydration. It was reported that Colonel Arrigo Dall'Olio, commanding the 40th Infantry Regiment of the \"Bologna\" Division, surrendered saying, \"We have ceased firing not because we haven't the desire but because we have spent every round\".\nBy late morning on 4 November, Rommel realised his situation was desperate,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The picture in the early afternoon of the 4th was as follows: powerful enemy armoured forces\u00a0... had burst a 19-kilometre hole in our front, through which strong bodies of tanks were moving to the west. As a result of this, our forces in the north were threatened with encirclement by enemy formations 20 times their number in tanks\u00a0... There were no reserves, as every available man and gun had been put into the line. So now it had come, the thing we had done everything in our power to avoid \u2013 our front broken and the fully motorised enemy streaming into our rear. Superior orders could no longer count. We had to save what there was to be saved.\nRommel telegraphed Hitler for permission to fall back on Fuka. As further British blows fell, Thoma was captured and reports came in from the \"Ariete\" and \"Trento\" divisions that they were encircled. At 17:30, unable to wait any longer for a reply from Hitler, Rommel gave orders to retreat.\nDue to lack of transport, most of the Italian infantry formations were abandoned. Any chance of getting them away with an earlier move had been spoiled by Hitler's insistence that Rommel hold his ground, obliging him to keep the non-motorised Italian units well forward until it was too late. To deepen the armoured thrusts, the 1st Armoured Division was directed at El Daba, down the coast and the 7th Armoured Division towards Galal, a further west along the railway. The New Zealand Division group had hoped to reach their objective by mid-morning on 5 November but was held up by artillery-fire when picking their way through what turned out to be a dummy minefield and the 15th Panzer Division got there first.\nD + 13, 5 November.\nThe 7th Armoured Division was ordered cross-country to cut the coast road at Sidi Haneish, west of the Rahman track, while the 1st Armoured Division, west of El Dada, was ordered to take a wide detour through the desert to Bir Khalda, west of the Rahman track, preparatory to turning north to cut the road at Mersa Matruh. Both moves failed, the 7th Armoured Division finished the day short of its objective. The 1st Armoured Division tried to make up time with a night march but in the darkness the armour became separated from their support vehicles and ran out of fuel at dawn on 6 November, short of Bir Khalda. The DAF continued to fly in support but because of the dispersion of X Corps, it was difficult to establish bomb lines, beyond which, aircraft were free to attack.\nD + 14, 6 November.\nBy 11:00 on 6 November, the \"B\" Echelon support vehicles began to reach the 1st Armoured Division but with only enough fuel to replenish two of the armoured regiments, which set off again hoping to be in time to cut off the Axis. The regiments ran out of fuel again, south-west of Mersa Matruh. A fuel convoy had set out from Alamein on the evening of 5 November but progress was slow as the tracks had become very cut up. By midday on 6 November, it began to rain and the convoy bogged from the rendezvous with the 1st Armoured Division \"B\". The 2nd New Zealand Division advanced toward Sidi Haneish while the 8th Armoured Brigade, 10th Armoured Division, had moved west from Galal to occupy the landing fields at Fuka and the escarpment. Roughly south-west of Sidi Haneish, the 7th Armoured Division encountered the 21st Panzer Division and the \"Voss\" Reconnaissance Group that morning. In a running fight, the 21st Panzer Division lost 16 tanks and numerous guns, narrowly escaping encirclement and reached Mersa Matruh that evening. It was again difficult to define bomb lines but US heavy bombers attacked Tobruk, sinking [] and later attacked Benghazi, sinking and setting the tanker (6,572 GRT), alight.\nD + 15 onward, 7 to 11 November.\nOn 7 November, waterlogged ground and lack of fuel stranded the 1st and 7th Armoured divisions. The 10th Armoured Division, on the coast road and with ample fuel, advanced to Mersa Matruh while its infantry mopped up on the road west of Galal. Rommel intended to fight a delaying action at Sidi Barrani, west of Matruh, to gain time for Axis troops to get through the bottlenecks at Halfaya and Sollum. The last rearguards left Matruh on the night of 7/8 November but were only able to hold Sidi Barrani until the evening of 9 November. By the evening of 10 November, the 2nd New Zealand Division, heading for Sollum, had the 4th Light Armoured Brigade at the foot of the Halfaya Pass while 7th Armoured Division was conducting another detour to the south, to take Fort Capuzzo and Sidi Azeiz. On the morning of 11 November, the 5th New Zealand Infantry Brigade captured the pass, taking 600 Italian prisoners. By nightfall on 11 November, the Egyptian wall was clear but Montgomery was forced to order that the pursuit should temporarily be continued only by armoured cars and artillery, because of the difficulty in supplying larger formations west of Bardia.\nAftermath.\nAnalysis.\nDespite his defeat at El Alamein, Rommel did not lose hope until the end of the Tunisia Campaign. Alexander contacted Churchill and suggested he \"Ring out the bells\". Churchill was due to address the Lord Mayor's Banquet at the Mansion House on 10 November 1942. He spoke at length about the victory and made his famous claim that\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nLooking back in 1950, Churchill wrote in his memoirs that \"It may almost be said, 'Before Alamein we never had a victory. After Alamein we never had a defeat'\".\nThe Allies frequently had numerical superiority in the Western Desert but never had it been so complete in quantity and quality. With the arrival of Sherman tanks, 6-pounder anti-tank guns and Spitfires in the Western Desert, the Allies gained a comprehensive superiority. Montgomery envisioned the battle as an attrition operation, similar to those fought in the First World War and accurately predicted the length of the battle and the number of British and Commonwealth casualties. British artillery was superbly handled and British air support was excellent, in contrast to the \"Luftwaffe\" and \"Regia Aeronautica\", which offered little or no support to ground forces, preferring to engage in air-to-air combat. Air supremacy had a huge effect on the battle. Montgomery wrote,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The moral effect of air action [on the enemy] is very great and out of all proportion to the material damage inflicted. In the reverse direction, the sight and sound of our own air forces operating against the enemy have an equally satisfactory effect on our own troops. A combination of the two has a profound influence on the most important single factor in war\u2014morale.\nHistorians debate the reasons why Rommel decided to advance into Egypt. In 1997, Martin van Creveld wrote that Rommel had been advised by the German and Italian staffs that his army could not properly be supplied so far from the ports of Tripoli and Benghazi. Rommel pressed ahead with his advance to Alamein and as predicted, supply difficulties limited the attacking potential of the Axis forces. According to Maurice Remy (2002), Hitler and Mussolini put pressure on Rommel to advance, the importance to them being the need to capture the Suez Canal and seize the Middle East and Persian oil fields. Rommel had been very pessimistic, especially after the First Battle of El Alamein and knew that as US supplies were en route to Africa and Axis ships were being sunk in the Mediterranean, the Axis was losing a race against time. On 27 August, Kesselring promised Rommel that supplies would arrive in time but Siegfried Westphal pointed out that such an expectation would be unrealistic and the offensive should not begin until they had arrived. After a conversation with Kesselring on 30 August, Rommel decided to attack, \"the hardest [decision] in my life\".\nCasualties.\nIn 2005, Niall Barr wrote that the 36,939 casualties, was an estimate because of the chaos of the Axis retreat. British figures, based on Ultra intercepts, gave German casualties as 1,149 killed, 3,886 wounded and 8,050 men captured. Italian losses were 971 dead, 933 wounded and 15,552 men captured. By 11 November, the number of Axis prisoners had risen to 30,000 men. In a note to \"The Rommel Papers\", Fritz Bayerlein (quoting figures obtained from ) instead estimated German losses in the battle as 1,100 killed, 3,900 wounded and 7,900 prisoners and Italian losses as 1,200 killed, 1,600 wounded and 20,000 prisoners.\nAccording to the Italian official history, Axis losses during the battle were 4,000 to 5,000 killed or missing, 7,000 to 8,000 wounded and 17,000 prisoners; during the retreat the losses rose to 9,000 killed or missing, 15,000 wounded and 35,000 prisoners. According to General Giuseppe Rizzo, total Axis casualties included 25,000 men killed or wounded (including 5,920 Italians killed) and 30,000 prisoners (20,000 Italians and 10,724 Germans), 510 tanks and 2,000 field guns, anti-tank guns, anti-aircraft guns. Axis tank losses were c.\u2009500; on 4 November, only 36 German tanks were left out of the 249 at the beginning of the battle. About half of the 278 Italian tanks had been lost and most of the remainder were knocked out on the next day by the 7th Armoured Division. About 254 Axis guns were lost, along with 64 German and 20 Italian aircraft.\nThe Eighth Army had 13,560 casualties, of whom 2,350 men had been killed, 8,950 wounded and 2,260 were missing; 58 per cent of the casualties were British, 22 per cent Australian, 10 per cent New Zealanders, 6 per cent South African, 1 per cent Indian and 3 per cent other nationalities. The Eighth Army lost from 332 to 500 tanks, although by the end of the battle, 300 had been repaired. The artillery lost 111 guns and the DAF lost 77 British and 20 American aircraft.\nSubsequent operations.\nThe Eighth Army was surprised by the Axis withdrawal and confusion caused by redeployments between the three corps meant they were slow in pursuit, failing to cut off Rommel at Fuka and Mersa Matruh. The Desert Air Force failed to make a maximum effort to bomb a disorganised and retreating opponent, which on 5 November was within range and confined to the coast road. Supply shortages and a belief that the \"Luftwaffe\" were about to get strong reinforcements, led the DAF to be cautious, reduce the number of offensive sorties on 5 November and protect the Eighth Army.\nBattle of El Agheila.\nThe Axis made a fighting withdrawal to El Agheila but the Axis troops were exhausted and had received few replacements, while Montgomery had planned to transport material over great distances, to provide the Eighth Army with of supplies per day. Huge quantities of engineer stores had been collected to repair the coast road; the railway line from El Alamein to Fort Capuzzo, despite having been blown up in over 200 places, was quickly repaired. In the month after the Eighth Army reached Capuzzo, the railway carried of supplies. Benghazi handled a day by the end of December, rather than the expected .\nMontgomery paused for three weeks to concentrate his forces and prepare an assault on El Agheila to deny the Axis the possibility of a counter-attack. On 11 December, the 51st (Highland) Division attacked along the line of the coast road with the 7th Armoured Division on the inland flank. On 12 December the 2nd New Zealand Division started a deeper flanking manoeuvre to cut the Axis line of retreat on the coast road in the rear of the Mersa Brega position. The Highland Division made a slow and costly advance and 7th Armoured Division met stiff resistance from the Combat Group \"Ariete\" (the remains of the 132nd Armoured Division \"Ariete\"). The had lost roughly 75,000 men, 1,000 guns and 500 tanks since the Second Battle of Alamein and withdrew. By 15 December, the New Zealanders had reached the coast road but the firm terrain allowed Rommel to break his forces into smaller units and withdraw cross-country through the gaps between the New Zealand positions.\nRommel conducted a text-book retreat, destroying all equipment and infrastructure left behind and peppering the land behind him with mines and booby traps. The Eighth Army reached Sirte on 25 December but west of the port, were forced to pause to consolidate their strung out formations and to prepare an attack at Wadi Zemzem, near Buerat east of Tripoli. Rommel had, with the agreement of Field Marshal Bastico, sent a request to the Italian \"Comando Supremo\" in Rome to withdraw to Tunisia where the terrain would better suit a defensive action and where he could link with the Axis army forming there after the Operation Torch landings. Mussolini replied on 19 December that the must resist to the last man at Buerat.\nTripoli.\nOn 15 January 1943, the 51st (Highland) Division made a frontal attack while the 2nd New Zealand Division and the 7th Armoured Division drove around the inland flank of the Axis line. Weakened by the withdrawal of 21st Panzer Division to Tunisia to strengthen the 5th Panzer Army (Hans-J\u00fcrgen von Arnim), Rommel conducted a fighting retreat. The port of Tripoli, further west, was taken on 23 January as Rommel continued to withdraw to the Mareth Line, the French southern defensive position in Tunisia.\nTunisia.\nRommel was by this time in contact with the Fifth Panzer Army, which had been fighting against the multi-national First Army in northern Tunisia, since shortly after Operation Torch. Hitler was determined to retain Tunisia and Rommel finally started to receive replacement men and materials. The Axis faced a war on two fronts, with the Eighth Army approaching from the east and the British, French and Americans from the west. The German-Italian Panzer Army was renamed the Italian First Army (General Giovanni Messe) and Rommel assumed command of the new Army Group Africa, responsible for both fronts. The two British armies were commanded by the 18th Army Group (General Harold Alexander). The failure of the Run for Tunis by the First Army in December 1942, led the North African campaign to last longer, ending when the Italian-German forces in North Africa capitulated in May 1943.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "29588", "revid": "48886350", "url": "https://en.wikipedia.org/wiki?curid=29588", "title": "Sextant", "text": "Tool for angle measurement\nA sextant is a doubly reflecting navigation instrument that measures the angular distance between two visible objects. The primary use of a sextant is to measure the angle between an astronomical object and the horizon for the purposes of celestial navigation.\nThe estimation of this angle, the altitude, is known as \"sighting\" or \"shooting\" the object, or \"taking a sight\". The angle, and the time when it was measured, can be used to calculate a position line on a nautical or aeronautical chart\u2014for example, sighting the Sun at noon or Polaris at night (in the Northern Hemisphere) to estimate latitude (with sight reduction). Sighting the height of a landmark can give a measure of \"distance off\" and, held horizontally, a sextant can measure angles between objects for a position on a chart. A sextant can also be used to measure the lunar distance between the moon and another celestial object (such as a star or planet) in order to determine Greenwich Mean Time and hence longitude.\nThe principle of the instrument was first implemented around 1731 by John Hadley (1682\u20131744) and Thomas Godfrey (1704\u20131749), but it was also found later in the unpublished writings of Isaac Newton (1643\u20131727).\nIn 1922, it was modified for aeronautical navigation by Portuguese navigator and naval officer .\nNavigational sextants.\nLike the Davis quadrant, the sextant allows celestial objects to be measured relative to the horizon, rather than relative to the instrument. This allows excellent precision. Also, unlike the backstaff, the sextant allows direct observations of stars. This permits the use of the sextant at night when a backstaff is difficult to use. For solar observations, filters allow direct observation of the Sun.\nSince the measurement is relative to the horizon, the measuring pointer is a beam of light that reaches to the horizon. The measurement is thus limited by the angular accuracy of the instrument and not the sine error of the length of an alidade, as it is in a mariner's astrolabe or similar older instrument.\nA sextant does not require a completely steady aim, because it measures a relative angle. For example, when a sextant is used on a moving ship, the image of both horizon and celestial object will move around in the field of view. However, the relative position of the two images will remain steady, and as long as the user can determine when the celestial object touches the horizon, the accuracy of the measurement will remain high compared to the magnitude of the movement.\nThe sextant is not dependent upon electricity (unlike many forms of modern navigation) or any human-controlled signals (such as GPS). For these reasons it is considered to be an eminently practical back-up navigation tool for ships.\nDesign.\nThe frame of a sextant is in the shape of a sector which is approximately &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20446 of a circle (60\u00b0), hence its name (\"sext\u0101ns, sextantis\" is the Latin word for \"one sixth\"). Both smaller and larger instruments are (or were) in use: the octant, quintant (or pentant) and the (doubly reflecting) quadrant span sectors of approximately &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20448 of a circle (45\u00b0), &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20445 of a circle (72\u00b0) and &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444 of a circle (90\u00b0), respectively. All of these instruments may be termed \"sextants\".\nAttached to the frame are the \"horizon mirror\", an \"index arm\" which moves the \"index mirror\", a sighting telescope, Sun shades, a graduated scale and a micrometer drum gauge for accurate measurements. The scale must be graduated so that the marked degree divisions register twice the angle through which the index arm turns. The scales of the octant, sextant, quintant and quadrant are graduated from below zero to 90\u00b0, 120\u00b0, 140\u00b0 and 180\u00b0 respectively. For example, the sextant illustrated has a scale graduated from \u221210\u00b0 to 142\u00b0, which is basically a quintant: the frame is a sector of a circle subtending an angle of 76\u00b0 at the pivot of the index arm.\nThe necessity for the doubled scale reading follows from consideration of the relations of the fixed ray (between the mirrors), the object ray (from the sighted object) and the direction of the normal perpendicular to the index mirror. When the index arm moves by an angle, say 20\u00b0, the angle between the fixed ray and the normal also increases by 20\u00b0. But the angle of incidence equals the angle of reflection so the angle between the object ray and the normal must also increase by 20\u00b0. The angle between the fixed ray and the object ray must therefore increase by 40\u00b0. This is the case shown in the graphic.\nThere are two types of horizon mirrors on the market today. Both types give good results.\nTraditional sextants have a half-horizon mirror, which divides the field of view in two. On one side, there is a view of the horizon; on the other side, a view of the celestial object. The advantage of this type is that both the horizon and celestial object are bright and as clear as possible. This is superior at night and in haze, when the horizon and/or a star being sighted can be difficult to see. However, one has to sweep the celestial object to ensure that the lowest limb of the celestial object touches the horizon.\nWhole-horizon sextants use a half-silvered horizon mirror to provide a full view of the horizon. This makes it easy to see when the bottom limb of a celestial object touches the horizon. Since most sights are of the Sun or Moon, and haze is rare without overcast, the low-light advantages of the half-horizon mirror are rarely important in practice.\nIn both types, larger mirrors give a larger field of view, and thus make it easier to find a celestial object. Modern sextants often have 5\u00a0cm or larger mirrors, while 19th-century sextants rarely had a mirror larger than 2.5\u00a0cm (one inch). In large part, this is because precision flat mirrors have grown less expensive to manufacture and to silver.\nAn artificial horizon is useful when the horizon is invisible, as occurs in fog, on moonless nights, in a calm, when sighting through a window or on land surrounded by trees or buildings. There are two common designs of artificial horizon. An artificial horizon can consist simply of a pool of water shielded from the wind, allowing the user to measure the distance between the body and its reflection, and divide by two. Another design allows the mounting of a fluid-filled tube with bubble directly to the sextant.\nMost sextants also have filters for use when viewing the Sun and reducing the effects of haze. The filters usually consist of a series of progressively darker glasses that can be used singly or in combination to reduce haze and the Sun's brightness. However, sextants with adjustable polarizing filters have also been manufactured, where the degree of darkness is adjusted by twisting the frame of the filter.\nMost sextants mount a 1 or 3-power monocular for viewing. Many users prefer a simple sighting tube, which has a wider, brighter field of view and is easier to use at night. Some navigators mount a light-amplifying monocular to help see the horizon on moonless nights. Others prefer to use a lit artificial horizon.\nProfessional sextants use a click-stop degree measure and a worm adjustment that reads to a minute, 1/60 of a degree. Most sextants also include a vernier on the worm dial that reads to 0.1 minute. Since 1 minute of error is about a nautical mile, the best possible accuracy of celestial navigation is about . At sea, results within several nautical miles, well within visual range, are acceptable. A highly skilled and experienced navigator can determine position to an accuracy of about .\nA change in temperature can warp the arc, creating inaccuracies. Many navigators purchase weatherproof cases so that their sextant can be placed outside the cabin to come to equilibrium with outside temperatures. The standard frame designs (see illustration) are supposed to equalise differential angular error from temperature changes. The handle is separated from the arc and frame so that body heat does not warp the frame. Sextants for tropical use are often painted white to reflect sunlight and remain relatively cool. High-precision sextants have an invar (a special low-expansion steel) frame and arc. Some scientific sextants have been constructed of quartz or ceramics with even lower expansions. Many commercial sextants use low-expansion brass or aluminium. Brass is lower-expansion than aluminium, but aluminium sextants are lighter and less tiring to use. Some say they are more accurate because one's hand trembles less. Solid brass frame sextants are less susceptible to wobbling in high winds or when the vessel is working in heavy seas, but as noted are substantially heavier. Sextants with aluminum frames and brass arcs have also been manufactured. Essentially, a sextant is intensely personal to each navigator, and they will choose whichever model has the features which suit them best.\nAircraft sextants are now out of production, but had special features. Most had artificial horizons to permit taking a sight through a flush overhead window. Some also had mechanical averagers to make hundreds of measurements per sight for compensation of random accelerations in the artificial horizon's fluid. Older aircraft sextants had two visual paths, one standard and the other designed for use in open-cockpit aircraft that let one view from directly over the sextant in one's lap. More modern aircraft sextants were periscopic with only a small projection above the fuselage. With these, the navigator pre-computed their sight and then noted the difference in observed versus predicted height of the body to determine their position.\nTaking a sight.\nA \"sight\" (or \"measure\") of the angle between the Sun, a star, or a planet, and the horizon is done with the 'star telescope' fitted to the sextant using a visible horizon. On a vessel at sea even on misty days a sight may be done from a low height above the water to give a more definite, better horizon. Navigators hold the sextant by its handle in the right hand, avoiding touching the arc with the fingers.\nFor a Sun sight, a filter is used to overcome the glare such as \"shades\" covering both index mirror and the horizon mirror designed to prevent eye damage. Initially, with the index bar set to zero and the shades covering both mirrors, the sextant is aimed at the sun until it can be viewed on both mirrors through the telescope, then lowered vertically until the portion of the horizon directly below it is viewed on both mirrors. It is necessary to flip back the horizon mirror shade to be able to see the horizon more clearly on it. Releasing the index bar (either by releasing a clamping screw, or on modern instruments, using the quick-release button), and moving it towards higher values of the scale, eventually the image of the Sun will reappear on the index mirror and can be aligned to about the level of the horizon on the horizon mirror. Then the fine adjustment screw on the end of the index bar is turned until the bottom curve (the \"lower limb\") of the Sun just touches the horizon. \"Swinging\" the sextant about the axis of the telescope ensures that the reading is being taken with the instrument held vertically. The angle of the sight is then read from the scale on the arc, making use of the micrometer or vernier scale provided. The exact time of the sight must also be noted simultaneously, and the height of the eye above sea-level recorded.\nAn alternative method is to estimate the current altitude (angle) of the Sun from navigation tables, then set the index bar to that angle on the arc, apply suitable shades only to the index mirror, and point the instrument directly at the horizon, sweeping it from side to side until a flash of the Sun's rays are seen in the telescope. Fine adjustments are then made as above. This method is less likely to be successful for sighting stars and planets.\nStar and planet sights are normally taken during nautical twilight at dawn or dusk, while both the heavenly bodies and the sea horizon are visible. There is no need to use shades or to distinguish the lower limb as the body appears as a mere point in the telescope. The Moon can be sighted, but it appears to move very fast, appears to have different sizes at different times, and sometimes only the lower or upper limb can be distinguished due to its phase.\nAfter a sight is taken, it is reduced to a position by looking at several mathematical procedures. The simplest sight reduction is to draw the equal-altitude circle of the sighted celestial object on a globe. The intersection of that circle with a dead-reckoning track, or another sighting, gives a more precise location.\nSextants can be used very accurately to measure other visible angles, for example between one heavenly body and another and between landmarks ashore. Used horizontally, a sextant can measure the apparent angle between two landmarks such as a lighthouse and a church spire, which can then be used to find the distance \"off\" or out to sea (provided the distance between the two landmarks is known). Used vertically, a measurement of the angle between the lantern of a lighthouse of known height and the sea level at its base can also be used for distance off.\nAdjustment.\nDue to the sensitivity of the instrument it is easy to knock the mirrors out of adjustment. For this reason a sextant should be checked frequently for errors and adjusted accordingly.\nThere are four errors that can be adjusted by the navigator, and they should be removed in the following order.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "29589", "revid": "44884187", "url": "https://en.wikipedia.org/wiki?curid=29589", "title": "Single transferable vote", "text": "Multi-winner electoral system\nThe single transferable vote (STV) or proportional-ranked choice voting (P-RCV), also known as PR-STV and \"proportional representation by means of the single transferable vote\", is a multi-winner electoral system in which each voter casts a single vote in the form of a ranked ballot. Voters have the option to rank candidates, and their vote may be transferred according to alternative preferences if their preferred candidate is eliminated or elected with surplus votes, so that their vote is used to elect someone they prefer over others in the running. STV aims to approach proportional representation based on votes cast in the district where it is used, so that each vote is worth about the same as another.\nSTV is a family of multi-winner proportional representation electoral systems. The proportionality of its results and the proportion of votes actually used to elect someone are equivalent to those produced by proportional representation election systems based on lists. STV systems can be thought of as a variation on the largest remainders method that uses candidate-based solid coalitions, rather than party lists. Surplus votes belonging to winning candidates (those in excess of an electoral quota) may be thought of as remainder votes. Surplus votes may be transferred from a successful candidate to another candidate and then possibly used to elect that candidate. \nUnder STV, votes are transferred to a voter's subsequent preferences if necessary, and depending on how the voter marked their preferences, a vote may be transferred across party lines, to a candidate on a different party slate, if that is how the voter marked their preferences. This allows voters of parties with too few votes to win a seat for their own candidates to have an effect on which candidates of parties with more support are elected. Additionally, this means most voters' preferences contribute to the election of a candidate they supported rather than being wasted on candidates who were not elected or on candidates who received more votes than needed to achieve election.\nUnder STV, no one party or voting bloc can take all the seats in a district unless the number of seats in the district is very small or almost all the votes cast are cast for one party's candidates (which is seldom the case). This makes it different from other commonly used candidate-based systems. In winner-take-all or plurality systems\u00a0\u2013 such as first-past-the-post (FPTP), instant-runoff voting (IRV), and block voting\u00a0\u2013 one party or voting bloc can take all seats in a district.\nThe key to STV's approximation of proportionality is that each voter effectively only casts a single vote in a district contest electing multiple winners, while the ranked ballots (and sufficiently large districts) allow the results to achieve a high degree of proportionality with respect to partisan affiliation within the district, as well as representation by gender and other descriptive characteristics. The use of a quota means that, for the most part, each successful candidate is elected with the same number of votes. This equality produces fairness in the particular sense that a party taking twice as many votes as another party will generally take twice the number of seats compared to that other party.\nUnder STV, winners are elected in a multi-member constituency (district) or at-large, also in a multiple-winner contest. Every substantial group within the district wins at least one seat: the more seats the district has, the smaller the size of the group needed to elect a member. In this way, STV provides approximately proportional representation overall, ensuring that substantial minority factions have some representation.\nThere are several STV variants. Two common distinguishing characteristics are whether or not ticket voting is allowed and the manner in which surplus votes are transferred. In Australia, lower house elections do not allow ticket voting (where voters can simply mark the party of choice); some but not all state upper house systems do allow ticket voting. In Ireland and Malta, surplus votes are transferred as whole votes (there may be some randomness) and neither allows ticket voting. In Hare\u2013Clark, used in Tasmania and the Australian Capital Territory, there is no ticket voting and surplus votes are fractionally transferred based on the last parcel of votes received by winners in accordance with the Gregory method. Systems that use the Gregory method for surplus vote transfers are strictly non-random. Other distinguishing features include district magnitude (number of members in the district, with all districts having the same DM or varying DM), how to fill casual vacancies (by-elections or other), and the number of preferences that the voter must mark (optional-preferential voting or other).\nUnlike party-list proportional representation, under STV voters vote for candidates rather than for parties. STV is also different from the single non-transferable vote election system, a semi-proportional system where candidates are not ranked and votes are not transferred.\nProcess.\nIn a single transferable vote (STV) system, the voter ranks candidates in order of preference on their ballot. A vote is initially allocated to the voter's first preference.\nA quota (the minimum number of votes that guarantees election) is calculated by a specified method (STV generally uses the Hare or Droop quota), and candidates who accumulate that many votes are declared elected. In many STV systems, the quota is also used to determine surplus votes, the number of votes received by successful candidates over and above the quota. Surplus votes are transferred to candidates ranked lower in the voters' preferences, if possible, so they are not wasted by remaining with a candidate who does not need them.\nIf seats remain open after the first count, any surplus votes are transferred. This may generate the necessary winners. As well, least popular candidates may be eliminated as a way to generate winners. \nThe specific method of transferring votes varies in different systems (see ). Transfer of any existing surplus votes is done before eliminations of candidates. This prevents a party from losing a candidate in the early stage who might be elected later through transfers. When surplus votes are transferred under some systems, some or all of the votes held by the winner are apportioned fractionally to the next marked preference on the ballot. In others, the transfers to the next available marked preference is done using whole votes.\nWhen seats still remain to be filled and there are no surplus votes to transfer (none of the remaining candidates have surplus votes needing to be transferred), the least popular candidate is eliminated. The eliminated candidate's votes are transferred to the next-preferred candidate rather than being discarded; if the next-preferred choice has already been eliminated or elected, the procedure is iterated to lower-ranked candidates.\nCounting, eliminations, and vote transfers continue until enough candidates are declared elected (all seats are filled by candidates reaching the quota) or until there are only as many remaining candidates as there are unfilled seats, at which point the remaining candidates are declared elected.\nExample for a non-partisan election.\nSuppose an election is conducted to determine what three foods to serve at a party. There are seven choices: Oranges, Pears, Strawberries, Cake (of the strawberry/chocolate variety), Chocolate, Hamburgers and Chicken. Only three of these may be served to the 23 guests. STV is chosen to make the decision, with the whole-vote method used to transfer surplus votes. The hope is that each guest will be served at least one food that they are happy with.\nTo select the three foods, each guest is given one vote\u00a0\u2013 they each mark their first preference and are also allowed to cast two back-up preferences to be used only if their first-preference food cannot be selected or to direct a transfer of their vote if the first-preference food is chosen with a surplus of votes. The 23 guests at the party mark their ballots: some mark first, second and third preferences; some mark only two preferences.\nWhen the ballots are counted, it is found that the ballots are marked in seven distinct combinations, as shown in the table below:\nThe election step-by-step:\nThe winners are Pears, Cake, and Hamburgers.\nOrange ends up being neither elected nor eliminated.\nSTV in this case produced a large number of effective votes: 19 votes were used to elect the successful candidates. (Only the votes for Oranges at the end were not used to select a food. The Orange voters have satisfaction of seeing their second choice \u2013 Pears \u2013 selected, even if their votes were not used to select any food.)\nAlso, there was general satisfaction with the choices selected. Nineteen voters saw either their first or second choice elected, although four of them did not actually have their vote used to achieve the result. Four saw their third choice elected. Fifteen voters saw their first preference chosen; eight of these 15 saw their first and third choices selected. Four others saw their second preference chosen, with one of them having their second and third choice selected.\nNote that if Hamburger had received only one vote when Chicken was eliminated, it still would have won because the only other remaining candidate, Oranges, had fewer votes, so would have been declared defeated in the next round. This would have left Hamburger as the last remaining candidate to fill the last open seat, even if it did not have quota.\nAs in many STV elections, most of the candidates in winning position in the first round went on to be elected in the end. The leading front runners were Pears and Hamburgers, both of whom were elected. There was a three-way tie for third between Cake, Chicken and Oranges, Cake coming out on top in the end. Transfers seldom affect the election of more than one or two of the initial front runners and sometimes none at all.\nCompared to other systems.\nThis result differs from the one that would have occurred if the voting system used had been non-PR, such as single non-transferable vote (SNTV), first-past-the-post (FPTP) in three districts, first-past-the-post at-large group ticket voting as used to elect members of the US electoral college, or a single-winner winner-take-all system in three districts.\nSingle non-transferable vote would have seen a three-way tie for third place with Oranges, Cake and Chicken tied. The tie would have been resolved by the flip of a coin or the choice of an election official. Possibly Oranges or Chicken would have been determined to be the winner among the three, even though Cake was seen in the vote count process to have more general support. Under SNTV, 15 voters would have seen their first preference win\u00a0\u2013 Oranges (or Chicken or Cake), Pears and Hamburgers. Eight voters would have not seen their first-preference food served. The pro-Oranges voter, if Oranges was not chosen, may have been consoled by their second choice, Pears, being served, but the others would not be served any of the foods they like, except maybe the voter who likes Strawberry and the one who likes Chocolate whose third choice, Hamburgers, was a winner. At least three voters would not be served any of their favorites.\nUnder first-past-the-post, the guests would have been split into three groups with one food chosen by each group based on just the most popular food in each group. The result in this case would have been dependent on how the groups are formed (gerrymandering of the groups to bias the election toward a particular result could occur). It might have been Strawberry cake, Pears and Hamburgers, but also the foods chosen might have been Pears in two groups (districts) and Hamburgers in the other. Or even just Pears alone might have won in each of the three \"districts\", in which case only 8 guests out of 23 would have seen their first choice served, a very unrepresentative outcome, given that three different foods could have been served.\nUsing FPTP, it could happen that under any three-district single-winner system, none of the groups elect Pears, if the 7 votes for it are split and in each \"district\" there is another food that beats it (e.g. Oranges, Hamburgers and Chicken).\nSimilar problems arise to a lesser degree if all districts use a majority system instead of plurality (for instance, two-round or instant-runoff voting) as at least in all districts the majority would have been quite happy, but that still leaves the minority unrepresented.\nIf the voters had been able to choose only one food to serve such as in the ticket voting system used in the US electoral college (first-past-the-post but without \"districts\"), it is likely that Pears, the choice of little more than a third of the 23 party-goers, would have won, meaning Pears would be the only food served at the party. \nEven if they held two rounds of voting (as in the two-round system), the bare majority that prefers some other kind of fruit (Oranges, Pears, Strawberries) would have dominated all other choices.\nGiving electors a single transferable vote is very different from simply having more seats to fill and giving each voter more votes to cast. Plurality block voting is such a system. Under it, each voter is given as many votes as there can be winners. This system can produce very unrepresentative results. In the example above, if every voter voted for three options, the small majority of voters who chose a fruit could easily force all three outcomes to be fruit of some kind: an outcome that is unlikely to be more representative than simply choosing only one winner. In an extreme example, where no faction can command an absolute majority, the largest of the minority groups can force a one-outcome result by running clone candidates. For example, the seven supporters of Pears could arrange in advance to have three types of Pears included on the ballot, then vote for all three, and if no other option reaches more than 7 votes, all three foods served would be a type of Pear. The only way this could be avoided would be for those who do not want Pears to vote tactically, by not voting for their preferred option but instead voting for whatever they consider to be the least bad outcome that is still likely to gain the required number of votes.\nExample for an election with parties.\nElections with parties are conducted in very similar manner to the non-partisan STV election presented above. Parties actually play no role in STV elections \u2013 each voter marks preferences for individual candidates and the voter's secondary preferences may be of a different party.\nThis example shows election of five members in a district. Party A runs five candidates, Party B runs three, and there is one independent in the race. The election is conducted under STV with the Hare quota, which for five seats is 20% (100% divided by five).\nFirst round.\nIn the first round, the vote tally of the most popular candidate of Party A, Candidate A3, is more than quota, so they win a seat.\nSecond, third and fourth rounds.\nSurplus votes are distributed; the voters of Candidate A3 have marked their second preference for another politician of the same party, Candidate A4, so A4 now receives Candidate A3's surplus votes. This transfer of 5 percent of the votes leaves A3 with the quota (20 percent) and A4 with 13 percent.\nIn the third and fourth rounds, the least popular candidates are eliminated (Candidates A1 and A5) and their votes transferred to their next preferences. Voters of Candidate A5 are not very partisan, preferring the independent candidate over the other candidates of Party A.\nFifth and sixth rounds.\nIn the fifth round, Candidate A2 is eliminated with all their votes going to the candidate A4, the last remaining candidate from Party A, who is elected. The surplus votes of Candidate A4 are transferred. All the voters who helped elect Candidate A4 prefer the independent candidate to the candidates of the other party so their 3% surplus votes will go to Candidate I in the sixth round.\nThere are now only four candidates remaining and three seats remaining open. The least popular candidate (Candidate B1) is declared defeated. The remaining three are declared elected regardless of whether they reached the quota.\nIf there is no reason to establish relative popularity of the elected members, the count ends there when the last seats are declared filled. Candidates A3, A4, I, B2 and B3 were elected.\nIf the ranking of the successful candidates is important, the vote count process continues into a seventh round.\nSeventh round.\nIf the ranking of the candidates is important, the votes belonging to the eliminated Candidate B1 are transferred as per below, assuming voters' alternate preferences are marked that way.\nUnder STV, candidates A3, A4, I, B2 and B3 were elected.\nThis vote count varies from the reality of many STV systems because there were no \"exhausted\" non-transferable votes. In most real-life STV elections, some votes that are set to be transferred cannot be and fewer votes are still in play at the end compared to the first round. As well, the Droop quota is usually used in real-life STV elections. With the Droop quota in effect and five seats to be filled, it would have taken 17 percent to be elected with quota, not 20 percent as under the Hare quota. However, if B2's surplus votes under the Droop quota are transferred to any non\u2013Party A candidate, the same five candidates are elected whether Hare or Droop quotas are used, albeit in a slightly different order.\nIn the first round, 74 percent of votes were cast for candidates who were successful in the end. In this case, as in all STV elections, about 80 percent or more of votes cast were used to actually elect someone. Only the 11 percent of votes cast in the end for B1 were not used to elect someone. The members elected in the district represent the sentiments of a large majority of the voters. Due to the diversity of members elected, each voter has someone elected who shares the party label that they voted for in the first place, even if not the individual candidate they preferred, or has seen the election of the independent candidate that they prefer.\nCompared to other systems.\nThis result differs from the one that would have occurred if the voting system used had been non-PR, such as single non-transferable vote (SNTV), first-past-the-post (FPTP) in five districts, first-past-the-post at-large general ticket voting (as used to elect members of the US electoral college), or a single-winner winner-take-all system in five districts\nThis result is different from if all voters could only vote for their first preference but still all seats were filled in a single contest, which is called the single non-transferable vote. Under SNTV, the five candidates most popular when only first preferences are considered were candidates A2, A3, B1, B2 and B3. This means even though Party B's candidates had less support together, they would have received 60% of seats, and Party A only 40%. In this case, Party A overextended themselves by fielding too many candidates, but even if they had strategically nominated only three, they would not necessarily have been successful in gaining three seats instead of two seats, because one or two of their candidates might have taken the lion share of their party votes, leaving not enough votes for the other(s) to be elected. This could be addressed under SNTV if the party voters used coordinated tactical or strategic voting.\nIf voters could vote for five candidates (but not cast ranked votes)\u00a0\u2013 ) as under the plurality block voting system, a type of multiple non-transferable vote\u00a0\u2013 , Party A could have won all seats, leaving Party B and voters of the independent candidate without representation. This is because if all those who voted for A3 marked their votes for all five of the Party A candidates, every Party A candidate would be among the five candidates with the most votes and would be declared elected. That would mean that a voting block of only 48 percent of the electorate would have all the representation.\nUnder majority block voting, if voters voted along party lines, every Party A candidate would receive a vote from 48 percent of the voters, and some even up to 55% if voters of Candidate I also vote for some Party A candidates with their 4 other votes. At the same time, Party B's candidates could only get up to 52% of the votes with the same tactics. If the voters are partisan enough, the likely outcome is that party A would take all the seats although Party A took less than half the votes (minority representation) and all other votes are wasted.\nIn single-winner first-past-the-post, the outcome is uncertain. It likely would be that Party A, with 48 percent of the votes, would achieve a clean sweep of all five seats or that Party A might easily take four of the five seats, with Party B taking just one. (The first case would be achieved by Party B votes being cracked by the district boundaries; the second case would be achieved by Party B voters being mostly packed into just one district, leaving Party A with easy victories in the other four districts.) On the other hand, if districts were drawn in a different fashion, Party A and Party B might divide the seats in a three-to-two ratio. Even under certain circumstances, the independent candidate might take a seat if their supporters are sufficiently concentrated in one district.\nSTV election results are roughly proportional (as much as the number of seats allows) and take into account more than the first preferences of voters. However, it could happen that the independent candidate is eliminated in an early round and so is unable to receive transfers from party voters. If that happens, the supporters of the independent candidate might aid one or another of the main parties. The five seats would be divided among the two main parties, in a more or less fair fashion.\nHowever, under STV (as seen in the example above), the final result may be modulated by cross-party transfers, say from a party A or B candidate to a candidate of the other party or to the independent candidate. When secondary preferences are applied, some voters who gave their first preference to a candidate from a certain party, if that person cannot be elected, might prefer an independent (or even a rival party candidate) before other candidates of their first choice's party. This means that even if it seems that the outcome over-represents or under-represents some faction (based on first preferences), the outcome actually closely adheres to a combination of the first preferences of many voters and secondary preferences of most of the other voters. Under STV, about 80 percent of voters see their vote used to elect someone they prefer (and even more than that portion see someone they prefer elected, even if their vote itself was not used to elect anyone), while under FPTP, often less than half of the votes are used to elect anyone and only the largest group in each district is represented.\nSTV using the Droop quota produces the same results as STV using Hare in this case, assuming the independent candidate has good luck. But with Droop being smaller than Hare, Party A is even more likely to take three seats and Party B to take two, leaving none to the independent. In the scenario shown here, A3 and A4 receive quota on first round or soon after. B2, B3 and the independent are elected at the end due to thinning of the field of candidates to one more than the number of remaining open seats, assuming same rules of transfer as above.\nRelated voting systems.\nInstant-runoff voting (IRV) is the single-winner analogue of STV. It is also called \"single-winner ranked-choice voting\" and \"preferential voting\". Its goal is representation of a majority of the voters in a district by a single official, as opposed to STV's goals of not only the representation of a majority of voters through the election of multiple officials but also of proportional representation of all the substantial voting blocks in the district.\nSingle non-transferable vote (SNTV) produces much the same representation as STV, without the work and complication of preferential ballots and vote transfers. Single voting in a multiple-member district produces mixed roughly proportional representation, which STV's vote transfers sometimes does not alter. (An example was the election of Edmonton, Alberta, MLAs through STV in 1930. The winners were the same under STV as would have been elected under SNTV.)\nThe spare vote is a version of single transferable voting applied to the ranking of parties, first proposed for elections in Germany in 2013. The spare vote system includes the step of transferring the votes of eliminated choices to the next-indicated choice, but it does not transfer surplus votes.\nThe mixed ballot transferable vote (MBTV) is a mixed version of STV, where voters may rank both candidates and parties, even both interchangeably, depending on the ballot type, but must choose at least a local (district) candidate (first preference) and a national list (second preference). The list preferences are used if the vote is unused in the district election, which may use FPTP, IRV or STV rules; in the STV case, the vote is transferred to another tier in favour of the chosen party list. (This is in contrast to the mixed single vote, which is currently used in Hungary, where voters may not define a separate party-list preference and do not cast preferential votes.)\nIndirect single transferable voting is a non-ranked-vote version of STV. Single voting in a multi-seat district is retained. Voters do not mark their ballots with rankings, but votes are transferred, as needed, based on the eliminated or elected candidate's pre-set instructions. This is a useful system to achieve many of the benefits of STV in districts where it is difficult to collect all the ballots in one central place to conduct STV transfers or where X voting is preferred over ranked voting due to voters' inability or disinterest in ranking candidates. Once known as the Gove system, or the schedule system of PR, it was invented by Massachusetts legislator William H. Gove of Salem and Archibald E. Dobbs of Ireland, author of \"Representative Reform for Ireland\" (1879). In 1884, Charles L. Dodgson (Lewis Carroll) argued for a proportional representation system based on multi-member districts similar to indirect STV, with each voter casting only a single vote, quotas as minimum requirements to take seats, and votes transferable by candidates through what is now called liquid democracy. The difference from \"indirect STV\" is that under liquid democracy, candidates, elected members and sometimes voters may transfer votes after the votes are cast to build coalitions; candidates do not have to publish their list beforehand.\nThe modified d'Hondt electoral system is a variant of STV, where an electoral threshold for parties is applied.\nTwo-vote MMP and additional member system systems may also be interpreted as a related, effectively preferential mixed system. Votes are not transferred, but a voter may vote differently for the local election and the overall party vote, with one, both or neither of those votes electing someone.\nThere are also several proportional multiwinner approval voting rules behaving similarly to STV, for instance the method of equal shares, which also sequentially selects candidates and reweights the voters approving these selected candidates.\nBalloting.\nIn STV, each voter casts just one vote although multiple seats are to be filled in the district. Voters mark first preference and can provide alternate preferences, to be used if needed.\nAlternate (secondary) preferences may be required or strictly optional depending on the system used. Some systems declare a ballot spoiled if it is not marked with at least a set number or minimum number of preferences. Rules vary. Sometimes a voter is allowed to mark just their first preference (plump) and not mark any more. In Australian Capital Territory elections, voters are told they must mark at least five preferences if the ballot is to be counted. Even where second and subsequent preferences are marked, in some cases they may not be consulted at all, such as if the first preference candidate is elected at the end of the count to fill the last seat.\nUnder full-preferential voting, a voter must rank all candidates. Under optional preferential voting, a voter can mark as many preferences as they desire. Under semi-optional preferential voting, the voter is required to rank some number of candidates greater than one but less than the total number of candidates in the running. A vote not fully marked as per requirement under full-preferential voting or semi-optional preferential voting may be declared rejected altogether or declared rejected when, in the course of the vote count process, the vote's insufficiency has an effect on the count. Under some full-preferential voting systems, it is impossible to have many votes declared exhausted and thus, in systems that use the Droop quota and sometimes under systems that use the Hare, all, or almost all, winners will receive quota. But at the same time, where most voters must rank all the candidates, some candidates may be neither elected nor eliminated, and their votes may be given no chance to be transferred to where they can contribute to the election. \nBut where there are many exhausted votes, as happens often under optional or semi-optional preferential voting systems, it is possible to have three winners in a district elected with partial quota, even if the Droop quota is used. But in any election, where one or more candidates are elected with partial quota, all the candidates, except for one, are either elected or eliminated, with only one unsuccessful candidate still in the running at the end.\nIn practice, the candidates' names are usually organized in columns so that voters are informed of the candidates' party affiliations or whether they are standing as independents. Voters indicate their preferences by ranking the candidates in order of preference. They usually use numbers (1, 2, 3 etc.) to show this, with 1 representing the voter's first preference.\nAn alternative way to mark preferences for candidates is to use columns for the voters' preference with the name of each candidate appearing in each column. A marking in the first column indicates the most preferred candidate. A marking in the second column indicates the second-preference candidate, etc.\nSome balloting systems allow ticket voting, where a voter simply indicates preference for a party slate, sometimes even ranking party slates, instead of marking preferences for individual candidates.\nSeat filling by quota.\nIn most STV elections, a quota is established to ensure that all elected candidates are elected with approximately equal numbers of votes. In some STV varieties, votes are totalled, and a quota (the minimum number of votes that guarantees election) is derived. Those who are elected are the most popular, and attainment of quota is the benchmark of that popularity. Some say that the importance of quota is to set the number of votes that are surplus; that is, the number that should be transferred away from successful candidates.\nA common formula sets quota as a fraction of the votes cast. A four-seat district using the Hare quota sets quota as one-fourth of the valid votes; a four-seat district using the Droop quota sets the quota as one more than one-fifth of the valid votes.\nIn some implementations, a \"uniform quota\" is simply set by law\u00a0\u2013 any candidate receiving that set number of votes is declared elected, with surplus transferred away. Something like this system was used in New York City from 1937 to 1947, where seats were allocated to each borough based on voter turnout. Under such a system, the number of representatives elected varied from election to election depending on voter turnout. In the 1937 New York City Council election, 26 councillors were elected; in the 1939 New York City Council election, newspapers reported that it was expected that the number of councillors would drop to 17 due to lower voter turnout. Under NYC's STV, total seats on council varied: 1937 New York City Council election 26 seats, 1939 New York City Council election 21 seats, 1941 26 seats, 1943 17 seats, and 1945 23 seats.\nOnce a quota is determined, candidates' vote tallies are consulted. If at any time a candidate achieves the quota, they are declared elected. Then if there are still unfilled seats, in some STV systems, any surplus votes (those over and above the quota) are transferred to other candidates in proportion to the next-highest preference marked on all or some of the ballots that had been received by that candidate, if any.\nUsually one or more candidates achieve quota in the first count. If there are still unfilled seats after the surplus is transferred, the count would proceed with the candidate with the fewest votes being eliminated. Their votes would be transferred to other candidates as determined by those voters' next preference, if any. Elections and eliminations, and vote transfers where applicable, continue until enough candidates are declared elected to fill the open seats or until there are only as many remaining candidates as there are unfilled seats, at which point the remaining candidates are declared elected. These last candidates may be elected without surpassing quota, but their survival until the end is taken as proof of their general acceptability by the voters.\nElection.\nAn STV election count starts with a count of each voter's first choice, recording how many for each candidate, calculation of the total number of votes and the quota and then taking the following steps:\nThere are variations in conducting transfers (see ).\nWhen the number of votes transferred from the losing candidate with the fewest votes is too small to change the ordering of remaining candidates, no transfer is made or more than one candidate is eliminated simultaneously. In most systems, once a candidate has been eliminated or elected, they do not receive any more votes.\nVote transfers and quota.\nSTV systems primarily differ in how they transfer surplus votes and in the size of the quota. For this reason, it has been suggested that STV can be considered a family of voting systems rather than a single system.\nIf fair results are to be produced and the number of candidates is fixed, a quota must be set such that any candidate who receives that many votes is elected. The quota, if used, must be set at a level where no more candidates can reach quota than there are seats to be filled. It cannot be so small that more candidates can be elected than the number of open seats, but the smaller it is, the fairer the result. There are several ways to specify quotas.\nThe Droop quota is the one most commonly used. It is generally considered to be the absolute lowest number that elects the correct number of candidates to fill the available seats, at least based on the original number of votes cast.\nThe Droop quota is given by the floor function formula:\nformula_1\nwhere formula_2 produces the integer less than or equal to its argument. The Droop quota is an extension of the majoritarian principle of a successful candidate having to get at least 50% + 1 in single-winner elections. No one else can get as much. In a three-seat contest, 25% plus 1 is the Droop quota because no more than three people can each have 25% of the vote + 1; using Droop means 10% of the vote + 1 is the quota in a nine-seat district because no more than nine people can each have 10% of the vote + 1, and so on.\nDroop being relatively low means that the largest party, if it has the majority of votes, is likely to take the majority of the seats in a district. Additionally, a small party may have a chance to take a seat.\nThe Hare quota was used in the original proposals by Thomas Hare. It is larger than the Droop and sometimes ensures greater representation to less-popular parties within a district. But also, being larger than Droop, Hare presents more of an obstacle to small parties that hope to take just one seat. Being smaller than Hare, the Droop quota may give a seat to a small party that does not have the votes to take a seat under Hare.\nSurplus votes cast for a winning candidate are sometimes transferred to the voter's next choice candidate, who is also preferred by the voter. (Any vote is only used once but may be allocated to different candidates along the way until it finds its final place.) Most first-count votes cast for a candidate who wins in the end are never transferred \u2013 just the surplus votes are transferred (unless all seats are already filled). Alternate preferences are only consulted if the candidate is unpopular or elected, and not always then. Votes lie where they are when the last seats are filled, so even under STV not all votes are used to elect someone.\nThere are variations in the conduct of transfers in different variations of STV, such as how to transfer surplus votes from winning candidates and whether to transfer votes to already-elected candidates.\nIt can happen that a vote is eligible to be transferred but cannot be because it bears no subsequent preference for any remaining candidate. In the case of transfers of surplus votes, an \"exhausted\" vote remains with the victorious candidates and only transferable votes (votes bearing a usable alternate preference) are used to determine the transfer of the surplus. If the number of transferable votes is less than the number of the surplus, no calculations are needed to make the transfer. Transfer of the transferable votes is done simply by reference to subsequent preference on the votes. Not all the surplus will be transferred if there are not enough transferable votes.\nThe STV systems in use in government elections today (such as in Malta and Ireland) do not allow votes to be transferred to candidates already elected. If the variation of STV used allows transfers to candidates already elected, when a candidate is eliminated and the next preference on the ballot shows preference for a candidate already elected, votes are transferred to the already victorious candidate, forming a new surplus. The new surplus votes for the victorious candidate (transferred from the eliminated candidate) are then transferred to the next preference of the victorious candidate, as happened with their initial surplus, but just using the recently transferred votes as guide. Vote transfers from the victorious candidate to a candidate who has been eliminated are impossible, and reference must be made to the next marked preference, if any. See for details.\nA different quota, one set lower than Droop, is sometimes workable. If fractional votes are used in an STV method, a quota smaller than the Droop quota may be used, where less than a whole number is added to formula_3.\nThe use of an even smaller quota is sometimes defended, although under such a quota, it is theoretically possible to have more candidates receive quota than the number of empty seats. Frank Britton, of the Election Ballot Services at the Electoral Reform Society, stated that the final \"plus one\" of the Droop quota is not needed; the quota he proposed was simply formula_4. The equivalent integer quota may be written:\nformula_5\nSo, the quota for one seat is 50 of 100 votes, not 51.\nEven a low quota, such as the Imperiali quota, is sometimes used. In any case, in most STV elections the appearance of non-transferable votes means that the quota could be lowered significantly below Droop during the counting of the vote with no danger of having too many achieve quota.\nIn STV, vote transfers are of two types\u00a0\u2013 transfers of votes of eliminated candidates and transfers of surplus votes of elected candidates. The first type happens more often than the second type. Surplus votes are transferred only after a candidate is elected and then only if there are still open seats to be filled and if the transfers may affect the ranking of the remaining candidates, although rules vary from STV system to STV system.\nTransfers of votes of eliminated candidates.\nTransfers of votes of eliminated candidates is done simply, without the use of complex math. The next usable preference on the vote gives the destination for the transfer of the vote. If there is no usable preference on the ballot, the vote goes to the \"exhausted\" or non-transferable pile.\nTransfers of surplus votes.\nVarious methods are used in STV systems to transfer surplus votes held by elected candidates. The transfer of surplus votes of an elected candidate may be very simply done or may be done more intricately, depending on the circumstances and the choice of the government or election officials.\nIt can happen that a vote is set to be transferred but cannot be because it bears no subsequent preference for any remaining candidate. In transfers of surplus votes, any non-transferable votes are left with the elected candidate.\nIf the number of transferable votes is less than the surplus, the transfer of surplus votes can be performed just as it is done in the case of transfer of votes of eliminated candidates, the only difference being that non-transferable votes remain with the elected candidate. They do not go to the exhausted pile. Transfer of the transferable votes is done in these cases simply by reference to the next usable preference on the vote.\nIn cases where the number of transferable votes is more than the surplus, a more-involved method may be used to make the transfer proportional and to ensure that the quota left with the successful candidate is proportional as well. But election officials here have a choice of using simpler methods or more involved methods.\nVotes to the number of the surplus can be drawn at random from the candidate's votes. Choosing the votes at random from the pile means that each transfer should be mixed and will likely closely resemble the composition of the entire pile. (This is the system used in Cambridge, Massachusetts, city elections.) \nIn the STV systems used in the Republic of Ireland (except Senate elections) and Malta, the next preference is examined and then surplus votes are transferred as whole votes in proportion to the proportions of votes marked for each of the other candidates. This is called the \"exact method\". Randomness may arise from the later preferences, if any, if they have to be used later. But if they do have to be used later, choosing the votes at random to compose each transfer means that the votes that make up each transfer should carry back-up preferences in approximately true proportion to the whole.\nThe basic formula for how to transfer surplus votes when there are more transferable votes than the surplus to be transferred is:\nformula_6\nSTV variants may transfer whole votes or fractional votes.\nTransferring votes without considering later preferences may influence later transfers and such systems are sometimes thought of as being random. To address this at the cost of introducing complication, in some STV systems the elected candidate's votes are sorted out into many separate piles, separating the various combinations of marked preferences on the ballots and then a requisite number is transferred from each pile, or the same effect is achieved by transferring part of each vote at a transfer value rate. Either way, the vote is transferred in the form of the ballot paper, carrying its own back-up preferences with it for possible later use. This is the Gregory method.\nThe Gregory method (also known as Newland\u2013Britain or Senatorial rules) eliminates randomness by examining all the preferences marked on the last parcel of ballots received by the elected candidate. The later preferences dictate how later transfers, if any, will go. Votes are transferred as fractions of votes. Gregory is in use in Northern Ireland, the Republic of Ireland (Senate elections) and in some electoral systems used in Australia.\nVariants exist under the names inclusive Gregory method (IGM) and the weighted inclusive Gregory method (WIGM). WIGM is used in the Scottish local government elections. Unlike the ordinary Gregory method, these systems look at secondary preferences on all the votes held by the elected candidate, not just the votes that make up the last parcel of votes received.\nBoth Gregory and earlier methods have the problem that, in some circumstances, they do not treat all votes equally. For this reason, Meek's method, Warren's method and the Wright system were invented.\nMeek, in 1969, was the first to realize that computers make it possible to count votes in a way that is conceptually simpler and closer to the original concept of STV. One advantage of Meek's method is that the quota is adjusted at each stage of counting when the number of votes decreases because some become non-transferable. Meek also considered a variant of his system which allows for equal preferences to be expressed. This has subsequently (since 1998) been used by the John Muir Trust for electing its trustees.\nDistrict magnitudes and proportionality.\nFormally, STV satisfies a fairness criterion known as proportionality for solid coalitions.\nHistorically, the district magnitude under STV elections has ranged from two (the absolute minimum) to 21 (currently being used in New South Wales, Australia) and 37 (currently being used in Western Australia). In higher-level government elections district magnitude is usually in the 3 to 5 or 7 range, with New South Wales and West Australia being obvious exceptions. In local government elections such as city councils, STV elections are often held citywide with district magnitudes in the 6 to 13 range, or wards may be used, usually electing 2 to 5 members in each ward.\nIf the Droop quota is used, for example, in a nine-seat district, the quota is 10% (plus one vote); in a three-seat district, it is 25% (plus one vote). The quota acts in some ways as an electoral threshold and the Droop quota in a district is a significantly higher proportion of district votes than the usual electoral threshold in use for most party-list PR systems, but the Droop quota in a district covering just part of a jurisdiction may be set at as few votes as a smaller proportion of the votes cast across a whole jurisdiction. As well, in single transferable voting, it is possible to achieve electoral threshold by receiving first-choice votes alone or by a combination of first-choice votes and votes transferred from other candidates based on lower preferences. It is a common occurrence to see someone elected with less than the quota in STV.\nDistrict elections grow more proportionally representative in direct relation to the increase in the number of seats to be elected in a constituency\u00a0\u2013 the more seats, the more the distribution of the seats in a district will be proportional. For example, in a three-seat STV election using the Hare quota of formula_7, a candidate or party with at least one-third of the votes is guaranteed to win a seat. In a seven-seat STV contest using the Hare quota, any candidate with one-seventh of the vote (either first preferences alone, or a combination of first preferences and lower-ranked preferences transferred from other candidates) will win a seat. Many systems use the Droop quota, which is even smaller than the Hare for the same number of seats, as it produces more proportional results.\nBecause of this quota-based fairness, under STV it is extremely rare for a party to take a majority of the seats in a district without the support of a majority of the district's voters. Additionally, a large majority of voters (generally around 80 percent or more) see their vote used to elect someone. Thus under STV, the members who make up a majority of a district's elected members are supported directly by a majority of the voters in the district.\nHistory.\nOrigin.\nThe concept of transferable voting was first proposed by Thomas Wright Hill in 1819. The system remained unused in public elections until 1855, when Carl Andr\u00e6 proposed a single transferable vote system for elections in Denmark, and his system was used in 1856 to elect the Rigsraad and from 1866 it was also adapted for indirect elections to the second chamber, the Landsting, until 1915.\nAlthough he was not the first to propose transferable votes, the British barrister Thomas Hare is generally credited with the conception of STV, and he developed the idea in 1857 independently of Andrae. Hare's view was that STV should be a means of \"making the exercise of the suffrage a step in the elevation of the individual character, whether it be found in the majority or the minority.\" In Hare's original system, he further proposed that electors should have the opportunity of discovering which candidate their vote had ultimately counted for, to improve their personal connection with voting. At the time of Hare's original proposal, the UK did not use the secret ballot, so not only could the voter determine the ultimate role of their vote in the election, the MPs would have known who had voted for them. As Hare envisaged that the whole House of Commons be elected \"at large\", his proposal would have totally replaced geographical constituencies and local representation with what Hare called \"constituencies of interest\" or \"unanimous constituencies\" \u2013 those people who group themselves into a single voting block that actually votes for an MP. \nAlthough national election systems seldom use at-large districting, in many proportional representation systems the production of unanimous constituencies backing an elected member is achieved by the use of single voting in multi-member districts instead of plurality contests in single-member districts. By the late 1800s, Catherine Helen Spence in Australia and several others had amended Hare's proposal by adding multi-member districts instead of at-large voting (across the whole United Kingdom).\nInstead of a single member being said to represent a whole district of varied sentiment, as under first-past-the-post, under STV multiple members represent the range of sentiments present in a district, each one representing a \"constituency of interest\" made up of only those who voted for the specific elected member of their choice. In 1893, Spence described STV thusly: \"the districts having been made large enough to return eight or ten members, the voter is allowed to vote for as many men as he would like to see in Parliament, but the vote only counts for one, and that is the first candidate on the list who needs his vote and can use it.\" \nThe political essayist John Stuart Mill was a friend of Hare's and an early proponent of STV, praising it at length in his essay \"Considerations on Representative Government\", in which he writes: \"Of all modes in which a national representation can possibly be constituted, this one affords the best security for the intellectual qualifications desirable in the representatives. At present... the only persons who can get elected are those who possess local influence, or make their way by lavish expenditure...\" His contemporary, Walter Bagehot, also praised the Hare system for allowing everyone to elect an MP, even ideological minorities, but also argued that the Hare system would create more problems than it solved: \"[the Hare system] is inconsistent with the extrinsic independence as well as the inherent moderation of a Parliament \u2013 two of the conditions we have seen, are essential to the bare possibility of parliamentary government.\"\nThrough the efforts of Catherine Helen Spence, John S. Mill and others, advocacy of STV spread throughout the British Empire, leading it to be sometimes known as \"British Proportional Representation\". In 1896, Andrew Inglis Clark was successful in persuading the Tasmanian House of Assembly to be the first parliament in the world to be at least partially elected by a form of STV, specifically the \"Hare-Clark electoral system\", named after himself and Thomas Hare. H. G. Wells was a strong advocate, calling it \"proportional representation\". The HG Wells formula for scientific voting, repeated, over many years, in his PR writings, to avoid misunderstanding, is proportional representation by the single transferable vote in large constituencies.\nSTV in large constituencies and multiple-member districts permits an approach to the Hare-Mill-Wells ideal of mirror representation. The UK National Health Service previously used the first-past-the-post system in local or regional elections, and only white male general practitioners were elected to the General Medical Council. In 1979, the UK National Health Service used STV to proportionally elect women and immigrant GPs, and specialists, to the General Medical Council.\nAustralia.\nTasmania first used STV for election of members of the Tasmanian House of Assembly from 1896 to 1902. In 1909, it began to be used on a permanent basis for House of Assembly elections and to elect all House of Assembly members. (Instant-runoff voting was used for elections to the Tasmania Legislative Council (its upper house), with some of the members elected through STV prior to 1946.)\nIn 1948, single transferable vote proportional representation on a state-by-state basis became the method for electing Senators to the Australian Senate. This change has led to the rise of a number of minor parties such as the Democratic Labor Party, Australian Democrats and Australian Greens who have taken advantage of this system to achieve parliamentary representation and the balance of power. From the 1984 election, group ticket voting was introduced to reduce a high rate of informal voting but in 2016, group tickets were abolished to avoid undue influence of preference deals amongst parties that were seen as distorting election results and a form of optional preferential voting was introduced.\nBeginning in the 1970s, Australian states began to reform their upper houses to introduce proportional representation in line with the Federal Senate. The first was the South Australian Legislative Council in 1973, which initially used a party list system (replaced with STV in 1982), followed by the single transferable vote being introduced for the New South Wales Legislative Council in 1978, the Western Australian Legislative Council in 1987 and the Victorian Legislative Council in 2003. The single transferable vote was also introduced for the elections to the Australian Capital Territory Legislative Assembly after a 1992 referendum.\nThe term \"STV\" in Australia refers to the Senate electoral system, a variant of \"Hare-Clark\" characterized by the \"above the line\" group voting ticket, a party list option. It is used in the Australian upper house, the Senate, most state upper houses, the Tasmanian lower house and the Capital Territory assembly. There is a compulsory number of preferences for a vote for candidates (below-the-line) to be valid: for the Senate a minimum of 90% of candidates must be scored, in 2013 in New South Wales that meant writing 99 preferences on the ballot. Therefore, 95% and more of voters use the above-the-line option, making the system, in all but name, a party list system. Parties determine the order in which candidates are elected and also control transfers to other lists and this has led to anomalies: preference deals between parties, and \"micro parties\" which rely entirely on these deals. Additionally, independent candidates are unelectable unless they form, or join, a group above-the-line. Concerning the development of STV in Australia researchers have observed: \"... we see real evidence of the extent to which Australian politicians, particularly at national levels, are prone to fiddle with the electoral system\".\nAs a result of a parliamentary commission investigating the 2013 election, from 2016 the system has been considerably reformed, with group voting tickets (GVTs) abolished and voters no longer required to fill all boxes.\nIn 2023, the single transferable vote was also chosen as the electoral method in South Australia for the state's First Nation's Voice to Parliament as part of Schedule 1 of the Act.\nCanada.\nSTV was used to elect legislators in two Canadian provinces between 1920 and 1955. The cities of Edmonton and Calgary elected their MLAs through STV from 1924 to 1956, when the Alberta provincial government changed those elections to use the first-past-the-post system. The city of Winnipeg elected its MLAs through STV from 1920 to 1955, when the Manitoba provincial government changed those elections to use first-past-the-post.\nLess well known is STV use at the municipal level in western Canada. Calgary and Winnipeg used STV for more than 50 years before city elections were changed to use the first-past-the-post system. Nineteen other municipalities, including the capital cities of the other three western provinces, also used STV For elections in about 100 elections during the 1918 to 1931 period.\nIn British Columbia, Canada, a type of STV called BC-STV was recommended for provincial elections by the British Columbia Citizens' Assembly on Electoral Reform in 2004. In a 2005 provincial referendum, it received 58 percent support and achieved a simple majority in 77 of 79 electoral districts. It was rejected for falling short of the 60 percent threshold that had been set by the BC Liberal provincial government. In a second referendum, on 12 May 2009, BC-STV was defeated 61 percent to 39 percent.\nUnited States.\nIn the United States, the Proportional Representation League was founded in 1893 to promote STV, and their efforts resulted in its adoption by many city councils in the first half of the 20th century. More than twenty cities have used STV, including Cleveland, Cincinnati and New York City. As of January 2010, it is used to elect the city council and school committee in Cambridge, Massachusetts, the park board and board of Estimate and Taxation in Minneapolis, Minnesota, and the board of assessors in Arden, Delaware. STV has also been adopted for student government elections at several American universities, including Carnegie Mellon, MIT, Oberlin, Reed, UC Berkeley, UC Davis, Vassar, UCLA, Whitman, and UT Austin. The Fair Representation Act, introduced in the US Congress in June 2017, would have established STV for US House elections starting in 2022.\nUse.\nSTV has seen its widest adoption in the English-speaking world. In the Commonwealth, two countries\u00a0\u2013 Malta and Australia\u00a0\u2013 use STV at the federal level. Australia also uses it at the state level, and some Australian cities use it as well. Ireland uses STV at local and national levels. Estonia and Denmark used a form of STV previously for national elections. Nepal uses STV to elect some of each state's electoral college, which in turn is used to elect members of the National Assembly.\nNational legislatures.\nThe table below lists countries that use STV to fill a nationally elected legislative body by direct elections.\nOther bodies.\nIndirect.\nIndirect use of STV, where not citizens, but bodies elected by citizens elect another body. Not to be confused with indirect single transferable voting.\nBenefits.\nBenefits of STV may be grouped in two general themes. One emphasizes that in each district where STV is used (with rare exceptions), mixed, balanced representation is produced in which members of varied viewpoints are present. This prevents the landslide victories when voters did not actually vote that way. It also means that in each district, most voters have a member who shares their opinion. The other theme is that most votes are used to elect someone. This aids the production of proportional representation and fairness, as each member is elected by the same, or almost the same, number of votes, both within the district and from district to district. As well, STV gives a group of voters the liberty to support a group of candidates holding particular views within a larger party without those holding those views having to compose a separate party ticket as they would have to do under list PR to ensure getting seats. Voters may also mark their preference according to gender lines, age groupings, race or religion more easily than organizing a slate of candidates that they can sign on to. According to Enid Lakeman and James Lambert, this liberty means that the pressure to form a break-away party is not as strong as under other electoral systems.\nAdvocates for STV, such as the Electoral Reform Society (UK), argue that STV is an improvement over winner-take-all non-proportional voting systems such as first-past-the-post, where vote splits commonly result in a majority of voters electing no one and the successful candidate having support from just a minority of the district voters. STV prevents in most cases one party taking all the seats in a city or general area and its elimination of the least popular candidates during the vote count prevents the election of an extreme candidate or party if it does not have enough overall general appeal.\nSTV is the system of choice of the Proportional Representation Society of Australia (which calls it quota-preferential proportional representation), the Electoral Reform Society in the United Kingdom and FairVote in the United States (which refers to STV as \"proportional ranked choice voting\".) (The FairVote group refers to instant-runoff voting as \"ranked choice voting\", although there are other election systems that use ranked-choice ballots.)\nIn the 2020 Irish election where members of D\u00e1il \u00c9ireann, known as TDs (D\u00e1il deputies), were elected by single transferable vote from 39 constituencies, each with between three and five seats, each member was elected with about the same number of votes and a large proportion of votes cast in each district were used to actually elect someone. Most elected members were elected by achieving the quota. Thus in each district, most elected members were elected by receiving exactly the same number of votes. Quota did vary from district to district but in some cases this was due to unforeseeable variance in voter turnout. In Dublin Bay South, the quota was 7919, while in Wexford it was 12,513. Voter turnout in the first was only 52 percent, while in the latter, 67 percent of eligible voters voted. The number of eligible voters per district seat was similar in each district (19,250 in Dublin Bay South, 22,600 in Wexford). \nIn the 2020 Irish election the few elected with less than full quota received a number of votes close to quota as well. In Dublin Bay South, two were elected with less than quota but the final vote tally of the least popular of these was only about 10 percent less than quota.\nA large proportion of the votes cast in the 2020 Irish election were used to elect someone, with relatively few being wasted. Perhaps one full quota or less is not used to elect anyone in each district. In Dublin Bay South, 78 percent of votes cast were used to elect the winners. As well, in Dublin Bay South, 80 percent of the first preferences were placed on candidates of the four parties that elected a member. So party-wise a large proportion of voters saw someone elected that shared their sentiments.\nIn Cambridge, Massachusetts, under STV in 2021, 90 percent of voters saw their vote help to elect a candidate, more than 65 percent of voters saw their first choice candidate elected, and more than 95 percent of voters saw at least one of their top three choices elected.\nIssues.\nDegree of proportionality.\nThe degree of proportionality of STV election results depends directly on the district magnitude (i.e. the number of seats in each district). While Ireland originally had a median district magnitude of five (ranging from three to nine) in 1923, successive governments lowered this. Systematically lowering the number of representatives from a given district directly benefits larger parties at the expense of smaller ones.\nSupposing that the Droop quota is used: in a nine-seat district, the Droop quota is 10% of district votes (plus one vote); in a three-seat district, it would be 25% of district votes (plus one vote). This electoral threshold seems significantly higher than for most party-list PR systems, based on percentage points. However, the Droop quota in a district covering just part of a jurisdiction may be set at as few votes as an list PR system's electoral threshold set at a lower percentage but based on the votes cast across a whole jurisdiction. For instance, in the 2022 Danish election, the main electoral threshold of 2 percent in use meant 71,000 of the 3.5million votes cast overall were required to be eligible for leveling seats, while in the 10-seat North Zealand Folketing constituency, the Droop quota (set at 9 percent) would have been 26,500 (1/11th of 292,000 valid votes). In the North Zealand constituency in the 2022 election, held using list PR (where the theoretical threshold is ten percent of district votes), the Conservative People's party\u00a0\u2013 with just 22,000 votes\u00a0\u2013 won one out of ten seats in the district. When levelling seats were allocated, the Independent Greens\u00a0\u2013 with almost 32,000 votes overall\u00a0\u2013 were not allocated any seats.\nAn Irish parliamentary committee in 2010 discussed the \"increasing trend towards the creation of three-seat constituencies in Ireland\" and recommended not less than four-seat constituencies, except where the geographic size of such a constituency would be disproportionately large. Establishing an acceptable geographical district size is subjective; for example, the entire country of Ireland is smaller in size than each of the 18 largest single-member ridings used in Canadian elections and only a bit more than three times the size of the Scottish Highlands, which elects just one MP.\nDifficulty of implementation.\nA frequent concern about STV is its complexity compared with single-mark voting methods, such as plurality voting or party-list proportional representation. Before the advent of computers, this complexity made ballot-counting more difficult than in other methods, though Winnipeg successfully used STV to elect ten MLAs in seven elections (1920\u20131945) without the use of computers.\nThe algorithm used in the vote count is more complicated than the one used in first-past-the-post, particularly if Gregory or another fractional-vote method is used. In large elections with many candidates, if Gregory is used, computers may be required. This is because after several rounds of counting, there may be many different categories of previously transferred votes, each with a different permutation of early and later preferences and with different carried-forward weights or values, which have to be tracked. \nHowever, the use of the whole-vote method to conduct transfers of surplus votes was done successfully in the age before computers, when 19 seats were filled in a 76-candidate contest.\nRole of political parties.\nSTV differs from other proportional representation systems in that candidates of one party can be elected on transfers from voters for other parties, a phenomenon sometimes referred to as vote \"leakage\". Hence, STV may reduce the role of political parties in the electoral process and corresponding partisanship and polarization in the resulting government.\nBy-elections.\nAs STV is a multi-member system and uses multi-member districts, filling a vacancy between elections can be problematic, and a variety of methods have been devised:\nTactics.\nIf there are not enough candidates to represent one of the priorities the electorate vote for (such as a party), all of them may be elected in the early stages, with surplus votes being transferred to candidates with other views. On the other hand, putting up too many candidates might result in first-preference votes being spread too thinly among them, and consequently several potential winners with broad second-preference appeal may be eliminated before others are elected and their second-preference votes distributed. In practice, the majority of voters express preference for candidates from the same party in order, which minimizes the impact of this potential effect of STV.\nThe outcome of voting under STV is proportional within a single district to the varied opinions of voters, assuming voters have ranked their real preferences (marking their preferences to truly reflect their views). Due to the district voting mechanisms usually used in conjunction with STV, an election by STV does not guarantee proportionality across all districts. If proportionality is measured by looking at first-preference votes, the final result may appear disproportional. This is natural due to some votes being transferred from one party to another during the vote count procedure before all the seats are allocated.\nIn many elections, each party has their vote spread over the party's slate (if the party runs multiple candidates) so that the large parties' votes may be spread somewhat equally, and candidates of popular parties are mostly all more popular than candidates of less-popular parties. This happened in Cavan-Monaghan in the 2020 Irish general election, where Labour, PBP, Green and Aontu parties were the least popular. Their candidates were four of the five least popular candidates in the first count and were eliminated quickly. SF, FG and FF parties were more popular\u00a0\u2013 their candidates took the five seats\u00a0\u2013 and candidates of those parties were already leading in the first count.\nSeveral methods of tactical or strategic voting can be used in STV elections but much less so than with first-past-the-post elections. In STV elections, most constituencies will be marginal, at least with regard to the allocation of a final seat. Manipulating STV requires knowledge of the contents of all the ballots, effectively only being possible after the ballots are counted; and discovering the correct votes to cast to manipulate the outcome strategically is NP-complete.\nThe difficulty of manipulating results under STV is credited with why it is chosen for use in part of the process of allocating the Academy Awards. As part of the process of selecting winners for the Academy Awards, STV is used to choose nominees within each category. The Academy of Motion Picture Arts and Sciences claims that STV is preferred because \"[a]lthough there are always instances in which an election procedure can be manipulated, an advantage of STV procedures is that the computations are too complex to be manipulated by a voter attempting to rank competitors of its most preferred candidate at the bottom of its preference list.\"\nSTV satisfies the majority-rule principle in that the winners taken together are supported by a majority of the valid votes cast in the district. Variants like Schulze STV and CPO-STV also do.\nElector confusion.\nCritics contend that some voters find the mechanisms behind STV difficult to understand, but this does not make it more difficult for voters to rank the list of candidates in order of preference on an STV ballot paper (see ).\nSTV systems vary, both in ballot design and in whether or not voters are obliged to provide a full list of preferences.\nIn jurisdictions such as Malta, Republic of Ireland and Northern Ireland, voters may rank as many or as few candidates as they wish. Consequently, voters sometimes, for example, rank only the candidates of a single party, or of their most preferred parties. Voters who do not fully understand the system may only vote for as many candidates as the instruction on the ballot gives before \"and so on\", and may even \"bullet vote\", only expressing a first preference, or indicate a first preference for multiple candidates, especially when both STV and plurality are being used in concurrent elections.\nAllowing voters to rank only as many candidates as they wish grants them greater freedom, but can also lead to some voters ranking so few candidates that their vote eventually becomes exhausted \u2013 that is, at a certain point during the count, it can no longer be transferred and influence the result. Some are non-transferable because the choices marked have already been elected, so the voter may be pleased with the overall election result even though their first preference was not elected and their vote itself was not used to elect anyone. Even if a voter marks many preferences, the vote may still be found to be non-transferable, if at any point the vote needs to be transferred and all the preferences ranked lower have already been eliminated or elected. But the number of non-transferable votes is fewer than the number of ignored votes under first-past-the-post and the number of effective votes, votes actually used to elect someone, is higher than under all but the most landslide first-past-the-post election contests.\nThe STV method may be confusing to some and may cause some people to vote incorrectly with respect to their actual preferences.\nSTV ballots can also be long; having multiple pages increases the chances of people not marking multiple preferences and thus missing later opportunities to have their vote transferred. After a vote is transferred twice, is at the end of the count and three candidates remain in the running for the last seat, the voter may have little interest in the choice. None of them were the voter's first choice, nor their second or third preference. And perhaps the voter has already seen one or two of their earlier choices already elected. Many votes up for transfer are found to be non-transferable in the last vote transfers. One to three members at the end are often elected with partial quotas, due to the number of exhausted votes. In STV elections, a majority of votes are used to elect the members who are elected.\nOther.\nSome opponents argue that larger, multi-seat districts would require more campaign funds to reach the voters. Proponents argue that STV can lower campaign costs because like-minded candidates can share some expenses. Proponents reason that negative advertising is disincentivized in such a system, as its effect is diluted among a larger pool of candidates.\nIn addition, candidates do not have to secure the support of the largest voting block to be elected, as they do under FPTP. STV ensures that each substantial group gets at least one seat, allowing candidates to focus campaign spending primarily on supportive voters. Under STV, it is not necessary to be the most popular candidate in the district to be elected; it is only necessary to reach the quota (or survive to the end when the remaining candidates are declared elected). To achieve the quota, it may not be necessary to gain support from across the whole district. If a geographical area of the district has a quota worth of votes and all the voters there support a particular candidate, that candidate will be elected. So, at least theoretically, one would not need to campaign across the whole district.\nFurthermore, STV requires multi-member districts (MMDs). It is thus impossible to use MMDs in a sparsely popluated area, for example in the Scottish Highlands, to elect members of the UK Parliament if that area's electorate is only enough for one member. To create an MMD in a sparsely-settled area, an electoral district would have to cover a large area just to capture the required population to be represented by multiple members. There can be a greater disconnect between the voter, or community, and their representatives. If areas with low population density were using multi-member districts to elect the relatively few high-level members of Parliament in Scotland or of the UK Parliament, constituencies could become so large as to seem to be impractical. However, Scotland successfully uses multiple-member districts in all regions of the country, including the Highlands, in its Scottish Parliament elections (where the additional-member system is used) and STV in its Local Authority elections. The large number of Local Authority or Scottish Parliament members allows the creation of MMDs without having each district cover too large an area. Meanwhile, MMDs even of immense size can be used successfully. In New South Wales, Australia, the whole state elects 21 members of the upper house in one single STV contest and has done so since 1991.\nAnalysis of results.\nMigration of preferences.\nThe relative performance of political parties in STV systems is sometimes analysed in a different fashion from that used in other electoral schemes. For example, seeing which candidates are declared elected on first-preference votes alone in the 2012 Scottish local elections, where 1223 members were elected, can be shown as follows:\nParty popularity can be determined by assessing the number of voters who express only a single preference (plumbed), as can the number of those who express a minimum number of preferences, all for candidates of one party. Where parties nominate multiple candidates in an electoral district, their relative popularity can be seen by their vote tallies. However, transfers as performed are based on the next usable preference marked on the ballot, not necessarily the next marked preference, the difference being some next-marked-preference candidates may have already been eliminated or elected, so the voter's marked preferences are not always seen in the final tallies. \nOther useful information can be found by analysing terminal transfers\u2014i.e., when the votes of a candidate are transferred and no other candidate from that party remains in the contest\u2014especially with respect to the first instance in which that occurs:\nThe transfers of votes under STV mean that candidates who did well on first-preference votes in the first count (but not well enough to be immediately declared elected) may not be elected in the end, and those who did poorly on the first count may be elected in the end. This is due to transfers made according to second and later preferences, but often only a relatively small number lose their place or attain their election due to transfers. Of the 1223 members elected in the Scottish local elections in 2012, only 6 percent of the leading candidates in the first count were not elected. The successful candidates were mostly set in the first count (through the simple mechanics of single voting in multi-member districts), before any vote transfers were done. Only about ten percent or less of the front runners in the first count were not elected in the end.\nThus, of 1223 seats filled in 2012, only 68 were filled by candidates who were not in the top three or four spots in the first count, meaning that most candidates who were the most popular in the first count were not overtaken by candidates who were not in the top three or four in the first count.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
