{"id": "23048", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=23048", "title": "Prion", "text": "Pathogenic type of misfolded protein\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nA prion () is a misfolded protein that induces misfolding in normal variants of the same protein, leading to cellular death. Prions are responsible for prion diseases, known as transmissible spongiform encephalopathy (TSEs), which are fatal and transmissible neurodegenerative diseases affecting both humans and animals. These proteins can misfold sporadically, due to genetic mutations, or by exposure to an already misfolded protein, leading to an abnormal three-dimensional structure that can propagate misfolding in other proteins.\nThe term \"prion\" comes from \"proteinaceous infectious particle\". Unlike other infectious agents such as viruses, bacteria, and fungi, prions do not contain nucleic acids (DNA or RNA). Prions are mainly twisted isoforms of the major prion protein (PrP), a naturally occurring protein with an uncertain function. They are the hypothesized cause of various TSEs, including scrapie in sheep, chronic wasting disease (CWD) in deer, bovine spongiform encephalopathy (BSE) in cattle (mad cow disease), and Creutzfeldt\u2013Jakob disease (CJD) in humans.\nAll known prion diseases in mammals affect the structure of the brain or other neural tissues. These diseases are progressive, have no known effective treatment, and are invariably fatal. Most prion diseases were thought to be caused by PrP until 2015 when a prion form of alpha-synuclein was linked to multiple system atrophy (MSA). Misfolded proteins are also linked to other neurodegenerative diseases like Alzheimer's disease, Parkinson's disease, and amyotrophic lateral sclerosis (ALS), which have been shown to originate and progress by a prion-like mechanism.\nPrions are a type of intrinsically disordered protein that continuously changes conformation unless bound to a specific partner, such as another protein. Once a prion binds to another in the same conformation, it stabilizes and can form a fibril, leading to abnormal protein aggregates called amyloids. These amyloids accumulate in infected tissue, causing damage and cell death. The structural stability of prions makes them resistant to denaturation by chemical or physical agents, complicating disposal and containment, and raising concerns about iatrogenic spread through medical instruments.\nEtymology and pronunciation.\nThe word \"prion\", coined in 1982 by Stanley B. Prusiner, is derived from protein and infection, hence prion. It is short for \"proteinaceous infectious particle\", in reference to its ability to self-propagate and transmit its conformation to other proteins. Its main pronunciation is , although , as the homographic name of the bird (prions or whalebirds) is pronounced, is also heard. In his 1982 paper introducing the term, Prusiner specified that it is \"pronounced \"pree-on\"\".\nPrion protein.\nStructure.\nPrions consist of a misfolded form of major prion protein (PrP), a protein that is a natural part of the bodies of humans and other animals. The PrP found in infectious prions has a different structure and is resistant to proteases, the enzymes in the body that can normally break down proteins. The normal form of the protein is called PrPC, while the infectious form is called PrPSc\u00a0\u2013 the \"C\" refers to 'cellular' PrP, while the \"Sc\" refers to 'scrapie', the prototypic prion disease, occurring in sheep. PrP can also be induced to fold into other more-or-less well-defined isoforms in vitro; although their relationships to the form(s) that are pathogenic in vivo is often unclear, high-resolution structural analyses have begun to reveal structural features that correlate with prion infectivity.\nPrPC.\nPrPC is a normal protein found on the membranes of cells, \"including several blood components of which platelets constitute the largest reservoir in humans\". It has 209 amino acids (in humans), one disulfide bond, a molecular mass of and a mainly alpha-helical structure. Several topological forms exist; one cell surface form that is anchored via glycolipid, and two transmembrane forms. The normal protein is not sedimentable; meaning that it cannot be separated by centrifuging techniques. It has a complex function, which continues to be investigated. PrPC binds copper(II) ions (those in a +2 oxidation state) with high affinity. This property is supposed to play a role in PrPC's anti-oxidative properties via reversible oxidation of the N-terminal's methionine residues into sulfoxide. Moreover, studies have suggested that, in vivo, due to PrPC's low selectivity to metallic substrates, the protein's anti oxidative function is impaired when in contact with metals other than copper. PrPC is readily digested by proteinase K and can be liberated from the cell surface by the enzyme phosphoinositide phospholipase C (PI-PLC), which cleaves the glycophosphatidylinositol (GPI) glycolipid anchor. PrP plays an important role in cell-cell adhesion and intracellular signaling \"in vivo\", and may therefore be involved in cell-cell communication in the brain.\nPrPSc.\nThe infectious isoform of PrP, known as PrPSc, or simply the prion, is able to convert normal PrPC proteins into the infectious isoform by changing their conformation, or shape; this, in turn, alters the way the proteins interact. PrPSc always causes prion disease. PrPSc has a higher proportion of \u03b2-sheet structure in place of the normal \u03b1-helix structure. Several highly infectious, brain-derived PrPSc structures have been discovered by cryo-electron microscopy. Another brain-derived fibril structure isolated from humans with Gerstmann-Straussler-Schienker syndrome has also been determined. All of the structures described in high resolution so far are amyloid fibers in which individual PrP molecules are stacked via intermolecular beta sheets. However, 2-D crystalline arrays have also been reported at lower resolution in \"ex vivo\" preparations of prions. In the prion amyloids, the glycolipid anchors and asparagine-linked glycans, when present, project outward from the lateral surfaces of the fiber cores. Often PrPSc is bound to cellular membranes, presumably via its array of glycolipid anchors, however, sometimes the fibers are dissociated from membranes and accumulate outside of cells in the form of plaques. The end of each fiber acts as a template onto which free protein molecules may attach, allowing the fiber to grow. This growth process requires complete refolding of PrPC. Different prion strains have distinct templates, or conformations, even when composed of PrP molecules of the same amino acid sequence, as occurs in a particular host genotype. Under most circumstances, only PrP molecules with an identical amino acid sequence to the infectious PrPSc are incorporated into the growing fiber. However, cross-species transmission also happens rarely.\nPrPres.\nProtease-resistant PrPSc-like protein (PrPres) is the name given to any isoform of PrPc that is structurally altered and converted into a misfolded proteinase K-resistant form. To model conversion of PrPC to PrPSc \"in vitro\", Kocisko \"et al\". showed that PrPSc could cause PrPC to convert to PrPres under cell-free conditions, and Soto \"et al\". demonstrated sustained amplification of PrPres and prion infectivity by a procedure involving cyclic amplification of protein misfolding. The term \"PrPres\" may refer either to protease-resistant forms of PrPSc, which is isolated from infectious tissue and associated with the transmissible spongiform encephalopathy agent, or to other protease-resistant forms of PrP that, for example, might be generated \"in vitro\". Accordingly, unlike PrPSc, PrPres may not necessarily be infectious.\nNormal function of PrP.\nThe physiological function of the prion protein remains poorly understood. While data from in vitro experiments suggest many dissimilar roles, studies on PrP knockout mice have provided only limited information because these animals exhibit only minor abnormalities. Research in mice has found that the cleavage of PrP in peripheral nerves causes the activation of myelin repair in Schwann cells, and that the lack of PrP proteins causes demyelination in those cells.\nPrP and regulated cell death.\nMAVS, RIP1, and RIP3 are prion-like proteins found in other parts of the body. They also polymerise into filamentous amyloid fibers that initiate regulated cell death in the case of a viral infection to prevent the spread of virions to other, surrounding cells. There is evidence that PrP and pathogenic PrPSc contribute to ferroptosis sensitivity, a condition that is enhanced by RAC3 expression.\nPrP and long-term memory.\nA review of evidence in 2005 suggested that PrP may have a normal function in the maintenance of long-term memory. As well, a 2004 study found that mice lacking genes for normal cellular PrP protein show altered hippocampal long-term potentiation. A recent study that also suggests why this might be the case, found that neuronal protein CPEB has a similar genetic sequence to yeast prion proteins. The prion-like formation of CPEB is essential for maintaining long-term synaptic changes associated with long-term memory formation.\nPrP and stem cell renewal.\nA 2006 article from the Whitehead Institute for Biomedical Research indicates that PrP expression on stem cells is necessary for an organism's self-renewal of bone marrow. The study showed that all long-term hematopoietic stem cells express PrP on their cell membrane and that hematopoietic tissues with PrP-null stem cells exhibit increased sensitivity to cell depletion.\nPrP and innate immunity.\nThere is some evidence that PrP may play a role in innate immunity, as the expression of PRNP, the PrP gene, is upregulated in many viral infections and PrP has antiviral properties against many viruses, including HIV.\nReplication.\nThe first hypothesis that tried to explain how prions replicate in a protein-only manner was the heterodimer model. This model assumed that a single PrPSc molecule binds to a single PrPC molecule and catalyzes its conversion into PrPSc. The two PrPSc molecules then come apart and can go on to convert more PrPC. However, a model of prion replication must explain both how prions propagate, and why their spontaneous appearance is so rare. Manfred Eigen showed that the heterodimer model requires PrPSc to be an extraordinarily effective catalyst, increasing the rate of the conversion reaction by a factor of around 1015. This problem does not arise if PrPSc exists only in aggregated forms such as amyloid, where cooperativity may act as a barrier to spontaneous conversion. What is more, despite considerable effort, infectious monomeric PrPSc has never been isolated.\nAn alternative model assumes that PrPSc exists only as fibrils, and that fibril ends bind PrPC and convert it into PrPSc. If this were all, then the quantity of prions would increase linearly, forming ever longer fibrils. But exponential growth of both PrPSc and the quantity of infectious particles is observed during prion disease. This can be explained by taking into account fibril breakage. A mathematical solution for the exponential growth rate resulting from the combination of fibril growth and fibril breakage has been found. The exponential growth rate depends largely on the square root of the PrPC concentration. The incubation period is determined by the exponential growth rate, and in vivo data on prion diseases in transgenic mice match this prediction. The same square root dependence is also seen in vitro in experiments with a variety of different amyloid proteins.\nThe mechanism of prion replication has implications for designing drugs. Since the incubation period of prion diseases is so long, an effective drug does not need to eliminate all prions, but simply needs to slow down the rate of exponential growth. Models predict that the most effective way to achieve this, using a drug with the lowest possible dose, is to find a drug that binds to fibril ends and blocks them from growing any further.\nResearchers at Dartmouth College discovered that endogenous host cofactor molecules such as the phospholipid molecule (e.g. phosphatidylethanolamine) and polyanions (e.g. single stranded RNA molecules) are necessary to form PrPSc molecules with high levels of specific infectivity \"in vitro\", whereas protein-only PrPSc molecules appear to lack significant levels of biological infectivity.\nTransmissible spongiform encephalopathies.\nPrions cause neurodegenerative disease by aggregating extracellularly within the central nervous system to form plaques known as amyloids, which disrupt the normal tissue structure. This disruption is characterized by \"holes\" in the tissue with resultant spongy architecture due to the vacuole formation in the neurons. Other histological changes include astrogliosis and the absence of an inflammatory reaction. While the incubation period for human prion diseases is relatively long (5 to 20 years or more), once symptoms appear the disease progresses rapidly, leading to brain damage and death. Neurodegenerative symptoms can include convulsions, dementia, ataxia (balance and coordination dysfunction), and behavioural or personality changes.\nMany different mammalian species can be affected by prion diseases, as the prion protein (PrP) is very similar in all mammals. Due to small differences in PrP between different species it is unusual for a prion disease to transmit from one species to another. The human prion disease variant Creutzfeldt\u2013Jakob disease, however, is thought to be caused by a prion that typically infects cattle (causing bovine spongiform encephalopathy) and that is transmitted through infected meat.\nAll known prion diseases are untreatable and fatal.\nUntil 2015 all known mammalian prion diseases were considered to be caused by the prion protein, PrP. After 2015 this remains true for diseases in the category of \"transmissible spongiform encephalopathy\" (TSE), which is transmissible and causes a specific sponge-like appearance of infected brain tissue. The endogenous, properly folded form of the prion protein is denoted PrPC (for Common\" or Cellular\"), whereas the disease-linked, misfolded form is denoted PrPSc (for \"Scrapie\"), after one of the diseases first linked to prions and neurodegeneration. The precise structure of the prion is not known, though they can be formed spontaneously by combining PrPC, homopolymeric polyadenylic acid, and lipids in a protein misfolding cyclic amplification (PMCA) reaction even in the absence of pre-existing infectious prions. This result is further evidence that prion replication does not require genetic information.\nTransmission.\nPrion diseases can arise in three different ways: acquired, familial, or sporadic. It is often assumed that the disease-related form (PrPSc) directly interacts with the normal form (PrPC) to make it rearrange its structure. One idea, the \"Protein X\" hypothesis, is that an as-yet unidentified cellular protein (Protein X) enables the conversion of PrPC to PrPSc by bringing a molecule of each of the two together into a complex.\nThe primary method of prion infection in animals is through ingestion of PrPSc. It is thought that prions may be deposited in the environment through the remains of dead animals and via urine, saliva, and other body fluids. They may then linger in the soil by binding to clay and other minerals.\nA University of California research team has provided evidence that infection can occur from prions in feces. Since animal excrement is present in many areas surrounding water reservoirs, and manure is used to fertilize many crop fields, this raises the possibility of widespread transmission. Preliminary evidence suggesting that prions might be transmitted through the use of urine-derived human menopausal gonadotropin, administered for the treatment of infertility, was published in 2011.\nGenetic susceptibility.\nThe majority of human prion diseases are classified as sporadic (idiopathic) Creutzfeldt\u2013Jakob disease (sCJD). Genetic research has identified an association between susceptibility to sCJD and a polymorphism at codon 129 in the PRNP gene, which encodes the prion protein (PrP). A homozygous methionine/methionine (MM) genotype at this position has been shown to significantly increase the risk of developing sCJD when compared to a heterozygous methionine/valine (MV) genotype. Analysis of multiple studies has shown that individuals with the MM genotype are approximately five times more likely to develop sCJD than those with the MV genotype.\nPrions in plants.\nIn 2015, researchers at The University of Texas Health Science Center at Houston found that plants can be a vector for prions. When researchers fed hamsters grass that grew on ground where a deer that died with chronic wasting disease (CWD) was buried, the hamsters became ill with CWD. The findings suggest that prions can be taken up by plants that are eaten by herbivores, thus completing the cycle. It is thus possible that there is a progressively accumulating number of prions in the environment.\nSterilization.\nInfectious agents possessing nucleic acids are dependent upon DNA or RNA to direct their continued replication. Prions, however, derive their infectivity from their ability to transform normal PrP to PrPSc, the misshapen, disease causing conformation. Inactivating prions via sterilization, therefore, requires the denaturation of the protein to a state in which the molecule is no longer able to induce the abnormal folding of normal PrP. In general, prions are resistant to proteases, heat, ionizing radiation, and formaldehyde treatments, although their infectivity can be reduced by such treatments. Effective prion decontamination relies upon protein hydrolysis or reduction or destruction of protein tertiary structure. Examples of such sterilization agents include sodium hypochlorite, sodium hydroxide, and strongly acidic detergents such as LpH.\nThe World Health Organization recommends any of the following three procedures for the sterilization of all heat-resistant surgical instruments to ensure that they are not contaminated with prions:\nHeating at for 18 minutes in a pressurized steam autoclave has been found to be somewhat effective in deactivating prions. Ozone sterilization has been studied as a potential method for prion denaturation and deactivation. Other approaches being developed include thiourea-urea treatment, guanidinium chloride treatment, and special heat-resistant subtilisin combined with heat and detergent. A number of decontamination reagents have been commercially manufactured with significant differences in efficacy among methods. A method sufficient for sterilizing prions on one material may fail on another.\nRenaturation of a completely denatured prion to infectious status has not yet been achieved; however, partially denatured prions can be renatured to an infective status under certain artificial conditions.\nDegradation resistance in nature.\nOverwhelming evidence shows that prions resist degradation and persist in the environment for years, and that proteases do not degrade them. Experimental evidence shows that \"unbound\" prions degrade over time, while soil-bound prions remain at stable or increasing levels, suggesting that prions likely accumulate in the environment. One 2015 study by US scientists found that repeated drying and wetting may render soil bound prions less infectious, although this was dependent on the soil type they were bound to.\nDegradation by living beings.\nRecent studies suggest that scrapie prions can be degraded by diverse cellular mechanisms in the affected animal cell. In an infected cell, extracellular lysosomal PrPSc does not tend to accumulate and is rapidly cleared by the lysosome via the endosome. The intracellular portion is harder to clear and tends to build up. The ubiquitin proteasome system appears to be able to degrade aggregates if they are small enough. Autophagy plays a bigger role by accepting PrPSc from the ER lumen and degrading it. Altogether these mechanisms allow the cell to delay its death from being overwhelmed by misfolded proteins. Inhibition of autophagy accelerates prion accumulation whereas encouragement of autophagy promotes prion clearance. Some autophagy-promoting compounds have shown promise in animal models by delaying disease onset and death.\nIn addition, keratinase from \"B. licheniformis\", alkaline serine protease from \"Streptomyces sp\", subtilisin-like pernisine from \"Aeropyrum pernix\", alkaline protease from \"Nocardiopsis sp\", nattokinase from \"B. subtilis\", engineered subtilisins from \"B. lentus\" and serine protease from three lichen species have been found to degrade PrPSc.\nFungi.\nProteins showing prion-type behavior are also found in some fungi, which has been useful in helping to understand mammalian prions. Fungal prions do not always cause disease in their hosts. In yeast, protein refolding to the prion configuration is assisted by chaperone proteins such as Hsp104. All known prions induce the formation of an amyloid fold, in which the protein polymerises into an aggregate consisting of tightly packed beta sheets. Amyloid aggregates are fibrils, growing at their ends, and they replicate when breakage causes two growing ends to become four growing ends. The incubation period of prion diseases is determined by the exponential growth rate associated with prion replication, which is a balance between the linear growth and the breakage of aggregates.\nFungal proteins that exhibit templated structural change were discovered in the yeast \"Saccharomyces cerevisiae\" by Reed Wickner in the early 1990s. For their mechanistic similarity to mammalian prions, they were termed yeast prions. Subsequent to this, a prion has also been found in the fungus \"Podospora anserina\". These prions behave similarly to PrP, but, in general, are nontoxic to their hosts. Susan Lindquist's group at the Whitehead Institute has argued that some fungal prions are not associated with any disease state, but they may have a useful role; however, researchers at the NIH have also provided arguments suggesting that fungal prions could be considered a diseased state. There is evidence that fungal prions have evolved specific functions that are beneficial to the microorganism that enhance their ability to adapt to their diverse environments. Further, within yeasts, prions can act as vectors of epigenetic inheritance, transferring traits to offspring without any genomic change.\nResearch into fungal prions has given strong support to the protein-only concept, since purified protein extracted from cells with a prion state has been demonstrated to convert the normal form of the protein into a misfolded form \"in vitro\", and in the process, preserve the information corresponding to different strains of the prion state. It has also shed some light on prion domains, which are regions in a protein that promote the conversion into a prion. Fungal prions have helped to suggest mechanisms of conversion that may apply to all prions, though fungal prions appear to be distinct from infectious mammalian prions in that they lack a cofactor required for propagation. The characteristic prion domains may vary among species\u00a0\u2013 e.g., characteristic fungal prion domains are not found in mammalian prions.\nTreatments.\nThere are no effective treatments for prion diseases as of 2025. Clinical trials in humans have not met with success and have been hampered by the rarity of prion diseases.\nMany possible treatments work in the test-tube but not in lab animals. One treatment that prolongs the incubation period in lab mice has failed in human patients diagnosed with definite or probable vCJD. Another treatment that works in mice was tried in 6 human patients, all of whom died, before it went out of stock. There was no significant increase in lifespan, but autopsy suggests that the drug was safe and reached \"encouraging\" concentrations in the brain and cerebrospinal fluid.\nWhile there is no known way to extend the life of a patient with prion disease, some drugs can be prescribed to control specific symptoms of the disease and accommodations can be given to improve quality of life.\nIn other diseases.\nPrion-like domains have been found in a variety of other mammalian proteins. Some of these proteins have been implicated in the ontogeny of age-related neurodegenerative disorders such as amyotrophic lateral sclerosis (ALS), frontotemporal lobar degeneration with ubiquitin-positive inclusions (FTLD-U), Alzheimer's disease, Parkinson's disease, and Huntington's disease. They are also implicated in some forms of systemic amyloidosis including AA amyloidosis that develops in humans and animals with inflammatory and infectious diseases such as tuberculosis, Crohn's disease, rheumatoid arthritis, and HIV/AIDS. AA amyloidosis, like prion disease, may be transmissible. The involvement of abnormal proteins in all of these diseases has given rise to the 'prion paradigm', where otherwise harmless proteins can be converted to a pathogenic form by a small number of misfolded, nucleating proteins.\nThe definition of a prion-like domain arises from the study of fungal prions. In yeast, prionogenic proteins have a portable prion domain that is both necessary and sufficient for self-templating and protein aggregation. This has been shown by attaching the prion domain to a reporter protein, which then aggregates like a known prion. Similarly, removing the prion domain from a fungal prion protein inhibits prionogenesis. This modular view of prion behaviour has led to the hypothesis that similar prion domains are present in animal proteins, in addition to PrP. These fungal prion domains have several characteristic sequence features. They are typically enriched in asparagine, glutamine, tyrosine and glycine residues, with an asparagine bias being particularly conducive to the aggregative property of prions. Historically, prionogenesis has been seen as independent of sequence and only dependent on relative residue content. However, this has been shown to be false, with the spacing of prolines and charged residues having been shown to be critical in amyloid formation.\nBioinformatic screens have predicted that over 250 human proteins contain prion-like domains (PrLD). These domains are hypothesized to have the same transmissible, amyloidogenic properties of PrP and known fungal proteins. As in yeast, proteins involved in gene expression and RNA binding seem to be particularly enriched in PrLD's, compared to other classes of protein. In particular, 29 of the known 210 proteins with an RNA recognition motif also have a putative prion domain. Meanwhile, several of these RNA-binding proteins have been independently identified as pathogenic in cases of ALS, FTLD-U, Alzheimer's disease, and Huntington's disease.\nRole in neurodegenerative disease.\nThe pathogenicity of prions and proteins with prion-like domains is hypothesized to arise from their self-templating ability and the resulting exponential growth of amyloid fibrils. The presence of amyloid fibrils in patients with degenerative diseases has been well documented. These amyloid fibrils are seen as the result of pathogenic proteins that self-propagate and form highly stable, non-functional aggregates. While this does not necessarily imply a causal relationship between amyloid and degenerative diseases, the toxicity of certain amyloid forms and the overproduction of amyloid in familial cases of degenerative disorders supports the idea that amyloid formation is generally toxic.\nTDP-43.\nSpecifically, aggregation of TDP-43, an RNA-binding protein, has been found in ALS/MND patients, and mutations in the genes coding for these proteins have been identified in familial cases of ALS/MND. These mutations promote the misfolding of the proteins into a prion-like conformation. The misfolded form of TDP-43 forms cytoplasmic inclusions in affected neurons, and is found depleted in the nucleus. In addition to ALS/MND and FTLD-U, TDP-43 pathology is a feature of many cases of Alzheimer's disease, Parkinson's disease and Huntington's disease. The misfolding of TDP-43 is largely directed by its prion-like domain. This domain is inherently prone to misfolding, while pathological mutations in TDP-43 have been found to increase this propensity to misfold, explaining the presence of these mutations in familial cases of ALS/MND. As in yeast, the prion-like domain of TDP-43 has been shown to be both necessary and sufficient for protein misfolding and aggregation.\nRNPA2B1, RNPA1.\nSimilarly, pathogenic mutations have been identified in the prion-like domains of heterogeneous nuclear riboproteins hnRNPA2B1 and hnRNPA1 in familial cases of muscle, brain, bone and motor neuron degeneration. The wild-type form of all of these proteins show a tendency to self-assemble into amyloid fibrils, while the pathogenic mutations exacerbate this behaviour and lead to excess accumulation.\nA\u03b2.\nAlzheimer's disease is a form of dementia that is characterized by the buildup of two abnormal proteins in the brain: A\u03b2 protein in A\u03b2 plaques and tau protein in neurofibrillary tangles. Cumulative evidence indicates that abnormalities of Abeta are the earliest pathologic sign of Alzheimer's. In experimental animals, scientists found that A\u03b2 can be induced to aggregate to form A\u03b2 plaques and cerebral amyloid angiopathy by a mechanism that is similar to that underlying prion diseases. Under highly unusual circumstances, A\u03b2 deposition also can be stimulated in humans by the iatrogenic introduction of abeta 'seeds' (sometimes referred to as 'A\u03b2 prions') into the body. Specifically, researchers analyzed people who had been treated with biological materials (such as growth hormone or dura mater patches) that had been collected from deceased human donors; they found that some of the recipients developed prion disease, but also that some of them had A\u03b2 plaques and cerebral amyloid angiopathy in the brain. This finding suggests that some batches of the biologic agents were contaminated with A\u03b2 seeds, probably because some of the donors had Alzheimer's disease at the time of death. When a very long time had passed following exposure to the contaminated biologic material (30 years or more), some of the affected individuals showed other signs of Alzheimer's disease, including tauopathy. Researchers emphasize that Alzheimer's is not a contagious disease; rather, the findings in humans support the theory that abnormal A\u03b2 initiates Alzheimer's disease by a 'prion-like' mechanism that originates within the body.\nAlpha-synuclein.\nBoth multiple system atrophy (MSA) and Parkinson's disease (PD) are associated with misfolded alpha-synuclein. In 2015, it was found that mice engineered to have a susceptible human version of alpha-synuclein become sick with MSA when injected in the brain with the brain homogenate of human MSA patients, but they do not get PD when injected with the brain homogenate of human PD patients. This suggests that the two diseases are different, with MSA being more transmissible. Misfolded alpha-synuclein from either Parkinson's disease or MSA can be detected by protein misfolding cyclic amplification (PMCA). The two forms, after PMCA, show different levels of fluorescence when bound to thioflavin T. This allows for distinguishing between the two diseases.\nWeaponization.\nPrions could theoretically be employed as a weaponized agent with potential fatality rates of 100%.\nHistory.\nIn the 18th and 19th centuries, exportation of sheep from Spain was observed to coincide with a disease called scrapie. This disease caused the affected animals to \"lie down, bite at their feet and legs, rub their backs against posts, fail to thrive, stop feeding and finally become lame\". The disease was also observed to have the long incubation period that is a key characteristic of transmissible spongiform encephalopathies (TSEs). Although the cause of scrapie was not known back then, it is probably the first transmissible spongiform encephalopathy to be recorded.\nIn the 1950s, Carleton Gajdusek began research which eventually showed that kuru could be transmitted to chimpanzees by what was possibly a new infectious agent, work for which he eventually won the 1976 Nobel Prize. During the 1960s, two London-based researchers, radiation biologist Tikvah Alper and biophysicist John Stanley Griffith, developed the hypothesis that the transmissible spongiform encephalopathies are caused by an infectious agent consisting solely of proteins. Earlier investigations by E.J. Field into scrapie and kuru had found evidence for the transfer of pathologically inert polysaccharides that only become infectious post-transfer, in the new host. Alper and Griffith wanted to account for the discovery that the mysterious infectious agent causing the diseases scrapie and Creutzfeldt\u2013Jakob disease resisted ionizing radiation. Griffith proposed three ways in which a protein could be a pathogen:\nIn the first hypothesis, he suggested that if the protein is the product of a normally suppressed gene, and introducing the protein could induce the gene's expression, that is, wake the dormant gene up, then the result would be a process indistinguishable from replication, as the gene's expression would produce the protein, which would then wake the gene in other cells.\nHis second hypothesis forms the basis of the modern prion theory, and proposed that an abnormal form of a cellular protein can convert normal proteins of the same type into its abnormal form, thus leading to replication.\nHis third hypothesis proposed that the agent could be an antibody if the antibody was its own target antigen, as such an antibody would result in more and more antibody being produced against itself. However, Griffith acknowledged that this third hypothesis was unlikely to be true due to the lack of a detectable immune response.\nFrancis Crick recognized the potential significance of the Griffith protein-only hypothesis for scrapie propagation in the second edition of his \"Central dogma of molecular biology\" (1970): While asserting that the flow of sequence information from protein to protein, or from protein to RNA and DNA was \"precluded\", he noted that Griffith's hypothesis was a potential contradiction (although it was not so promoted by Griffith). The central dogma was later revised, in part, to accommodate reverse transcription (which both Howard Temin and David Baltimore discovered in 1970).\nIn 1982, Stanley B. Prusiner of the University of California, San Francisco, announced that his team had purified the hypothetical infectious protein, which did not appear to be present in healthy hosts, though they did not manage to isolate the protein until two years after Prusiner's announcement. The protein was named a prion, for \"proteinacious infectious particle\", derived from the words protein and infection. When the prion was discovered, Griffith's first hypothesis, that the protein was the product of a normally silent gene, was favored by many. It was subsequently discovered, however, that the same protein exists in normal hosts but in different form.\nFollowing the discovery of the same protein in different form in uninfected individuals, the specific protein that the prion was composed of was named the prion protein (PrP), and Griffith's second hypothesis, that an abnormal form of a host protein can convert other proteins of the same type into its abnormal form, became the dominant theory. Prusiner was awarded the Nobel Prize in Physiology or Medicine in 1997 for his research into prions.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23051", "revid": "21502819", "url": "https://en.wikipedia.org/wiki?curid=23051", "title": "Pascal", "text": "Pascal, Pascal's or PASCAL may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "23052", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=23052", "title": "Primata", "text": ""}
{"id": "23053", "revid": "14650386", "url": "https://en.wikipedia.org/wiki?curid=23053", "title": "Periodic table", "text": "Tabular arrangement of the chemical elements\nThe periodic table, also known as the periodic table of the elements, is an ordered arrangement of the chemical elements into rows (\"periods\") and columns (\"groups\"). An icon of chemistry, the periodic table is widely used in physics and other sciences. It is a depiction of the periodic law, which states that when the elements are arranged in order of their atomic numbers an approximate recurrence of their properties is evident. The table is divided into four roughly rectangular areas called blocks. Elements in the same group tend to show similar chemical characteristics.\nVertical, horizontal and diagonal trends characterize the periodic table. Metallic character increases going down a group and from right to left across a period. Nonmetallic character increases going from the bottom left of the periodic table to the top right.\nThe first periodic table to become generally accepted was that of the Russian chemist Dmitri Mendeleev in 1869; he formulated the periodic law as a dependence of chemical properties on atomic mass. As not all elements were then known, there were gaps in his periodic table, and Mendeleev successfully used the periodic law to predict some properties of some of the missing elements. The periodic law was recognized as a fundamental discovery in the late 19th century. It was explained early in the 20th century, with the discovery of atomic numbers and associated pioneering work in quantum mechanics, both ideas serving to illuminate the internal structure of the atom. A recognisably modern form of the table was reached in 1945 with Glenn T. Seaborg's discovery that the actinides were in fact f-block rather than d-block elements. The periodic table and law have become a central and indispensable part of modern chemistry.\nThe periodic table continues to evolve with the progress of science. In nature, only elements up to atomic number 94 exist; to go further, it was necessary to synthesize new elements in the laboratory. By 2010, the first 118 elements were known, thereby completing the first seven rows of the table; however, chemical characterization is still needed for the heaviest elements to confirm that their properties match their positions. New discoveries will extend the table beyond these seven rows, though it is not yet known how many more elements are possible; moreover, theoretical calculations suggest that this unknown region will not follow the patterns of the known part of the table. Some scientific discussion also continues regarding whether some elements are correctly positioned in the table. Many alternative representations of the periodic law exist, and there is some discussion as to whether there is an optimal form of the periodic table.\nStructure.\nPrimordial\u2003 From decay\u2003 Synthetic\u2003Border shows natural occurrence of the element\nStandard atomic weight \"A\"r, std(E)&lt;templatestyles src=\"Plainlist/styles.css\"/&gt; \nEach chemical element has a unique atomic number (\"Z\"\u2014 for \"Zahl\", German for \"number\") representing the number of protons in its nucleus. Each distinct atomic number therefore corresponds to a class of atom: these classes are called the chemical elements. The chemical elements are what the periodic table classifies and organizes. Hydrogen is the element with atomic number 1; helium, atomic number 2; lithium, atomic number 3; and so on. Each of these names can be further abbreviated by a one- or two-letter chemical symbol; those for hydrogen, helium, and lithium are respectively H, He, and Li. Neutrons do not affect the atom's chemical identity, but do affect its weight. Atoms with the same number of protons but different numbers of neutrons are called isotopes of the same chemical element. Naturally occurring elements usually occur as mixes of different isotopes; since each isotope usually occurs with a characteristic abundance, naturally occurring elements have well-defined atomic weights, defined as the average mass of a naturally occurring atom of that element.\nAll elements have multiple isotopes, variants with the same number of protons but different numbers of neutrons. For example, carbon has three naturally occurring isotopes: all of its atoms have six protons and most have six neutrons as well, but about one per cent have seven neutrons, and a very small fraction have eight neutrons. Isotopes are never separated in the periodic table; they are always grouped together under a single element. When atomic mass is shown, it is usually the weighted average of naturally occurring isotopes; but if no isotopes occur naturally in significant quantities, the mass of the most stable isotope usually appears, often in parentheses.\nIn the standard periodic table, the elements are listed in order of increasing atomic number. A new row (\"period\") is started when a new electron shell has its first electron. Columns (\"groups\") are determined by the electron configuration of the atom; elements with the same number of electrons in a particular subshell fall into the same columns (e.g. oxygen, sulfur, and selenium are in the same column because they all have four electrons in the outermost p-subshell). Elements with similar chemical properties generally fall into the same group in the periodic table, although in the f-block, and to some respect in the d-block, the elements in the same period tend to have similar properties, as well. Thus, it is relatively easy to predict the chemical properties of an element if one knows the properties of the elements around it.\nToday, 118 elements are known, the first 94 of which are known to occur naturally on Earth. The remaining 24, americium to oganesson (95\u2013118), occur only when synthesized in laboratories. Of the 94 naturally occurring elements, 83 are primordial and 11 occur only in decay chains of primordial elements. A few of the latter are so rare that they were not discovered in nature, but were synthesized in the laboratory before it was determined that they exist in nature: technetium (element 43), promethium (element 61), astatine (element 85), neptunium (element 93), and plutonium (element 94). No element heavier than einsteinium (element 99) has ever been observed in macroscopic quantities in its pure form, nor has astatine; francium (element 87) has been only photographed in the form of light emitted from microscopic quantities. Of the 94 natural elements, eighty have a stable isotope and one more (bismuth) has an almost-stable isotope (with a half-life of 2.01\u00d71019\u00a0years, over a billion times the age of the universe). Two more, thorium and uranium, have isotopes undergoing radioactive decay with a half-life comparable to the age of the Earth. The stable elements plus bismuth, thorium, and uranium make up the 83 primordial elements that survived from the Earth's formation. The remaining eleven natural elements decay quickly enough that their continued trace occurrence rests primarily on being constantly regenerated as intermediate products of the decay of thorium and uranium. All 24 known artificial elements are radioactive.\nGroup names and numbers.\nUnder an international naming convention, the groups are numbered numerically from 1 to 18 from the leftmost column (the alkali metals) to the rightmost column (the noble gases). The f-block groups are ignored in this numbering. Groups can also be named by their first element, e.g. the \"scandium group\" for group 3. Previously, groups were known by Roman numerals. In the United States, the Roman numerals were followed by either an \"A\" if the group was in the s- or p-block, or a \"B\" if the group was in the d-block. The Roman numerals used correspond to the last digit of today's naming convention (e.g. the group 4 elements were group IVB, and the group 14 elements were group IVA). In Europe, \"A\" was used for groups 1 through 7, and \"B\" was used for groups 11 through 17. In addition, groups 8, 9 and 10 used to be treated as one triple-sized group, known collectively in both notations as group VIII. In 1988, the new IUPAC (International Union of Pure and Applied Chemistry) naming system (1\u201318) was put into use, and the old group names (I\u2013VIII) were deprecated.\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;a Group 1 is composed of hydrogen (H) and the alkali metals. Elements of the group have one s-electron in the outer electron shell. Hydrogen is not considered to be an alkali metal as it is not a metal, though it is more analogous to them than any other group. This makes the group somewhat exceptional.&lt;templatestyles src=\"Citation/styles.css\"/&gt;b The 14 f-block groups (columns) do not have a group number.&lt;templatestyles src=\"Citation/styles.css\"/&gt;c The correct composition of group 3 is scandium (Sc), yttrium (Y), lutetium (Lu), and lawrencium (Lr), as shown here: this is endorsed by 1988 and 2021 IUPAC reports on the question. General inorganic chemistry texts often put scandium (Sc), yttrium (Y), lanthanum (La), and actinium (Ac) in group 3, so that Ce\u2013Lu and Th\u2013Lr become the f-block between groups 3 and 4; this was based on incorrectly measured electron configurations from history, and Lev Landau and Evgeny Lifshitz already considered it incorrect in 1948. Arguments can still occasionally be encountered in the contemporary literature purporting to defend it, but most authors consider them logically inconsistent. Some sources follow a compromise that puts La\u2013Lu and Ac\u2013Lr as the f-block rows (despite that giving 15 f-block elements in each row, which contradicts quantum mechanics), leaving the heavier members of group 3 ambiguous. See also Group 3 element#Composition.&lt;templatestyles src=\"Citation/styles.css\"/&gt;d Group 18, the noble gases, had not been discovered at the time of Mendeleev's original table. Later (1902), Mendeleev accepted the evidence for their existence, and they could be placed in a new \"group 0\", consistently and without breaking the periodic table principle.&lt;templatestyles src=\"Citation/styles.css\"/&gt;r Group name as recommended by IUPAC.\nPresentation forms.\n&lt;templatestyles src=\"Periodic table (32 columns, micro)/styles.css\"/&gt;\n32 columns\n18 columns\nFor reasons of space, the periodic table is commonly presented with the f-block elements cut out and positioned as a distinct part below the main body. This reduces the number of element columns from 32 to 18.\nBoth forms represent the same periodic table. The form with the f-block included in the main body is sometimes called the 32-column or long form; the form with the f-block cut out the 18-column or medium-long form. The 32-column form has the advantage of showing all elements in their correct sequence, but it has the disadvantage of requiring more space. The form chosen is an editorial choice, and does not imply any change of scientific claim or statement. For example, when discussing the composition of group 3, the options can be shown equally (unprejudiced) in both forms.\nPeriodic tables usually at least show the elements' symbols; many also provide supplementary information about the elements, either via colour-coding or as data in the cells. Tables may include extra information such as the names and atomic numbers of the elements, their blocks, natural occurrences, standard atomic weight, states of matter, melting and boiling points, densities, as well as provide different classifications of the elements.\nElectron configurations.\nThe periodic table is a graphic description of the periodic law, which states that the properties and atomic structures of the chemical elements are a periodic function of their atomic number. Elements are placed in the periodic table according to their electron configurations, the periodic recurrences of which explain the trends in properties across the periodic table.\nAn electron can be thought of as inhabiting an atomic orbital, which characterizes the probability it can be found in any particular region around the atom. Their energies are quantised, which is to say that they can only take discrete values. Furthermore, electrons obey the Pauli exclusion principle: different electrons must always be in different states. This allows classification of the possible states an electron can take in various energy levels known as shells, divided into individual subshells, which each contain one or more orbitals. Each orbital can contain up to two electrons: they are distinguished by a quantity known as spin, conventionally labelled \"up\" or \"down\". In a cold atom (one in its ground state), electrons arrange themselves in such a way that the total energy they have is minimized by occupying the lowest-energy orbitals available. Only the outermost electrons (valence electrons) have enough energy to break free of the nucleus and participate in chemical reactions with other atoms. The others are called core electrons.\nElements are known with up to the first seven shells occupied. The first shell contains only one orbital, a spherical s orbital. As it is in the first shell, this is called the 1s orbital. This can hold up to two electrons. The second shell similarly contains a 2s orbital, and it also contains three dumbbell-shaped 2p orbitals, and can thus fill up to eight electrons (2\u00d71 + 2\u00d73 = 8). The third shell contains one 3s orbital, three 3p orbitals, and five 3d orbitals, and thus has a capacity of 2\u00d71 + 2\u00d73 + 2\u00d75 = 18. The fourth shell contains one 4s orbital, three 4p orbitals, five 4d orbitals, and seven 4f orbitals, thus leading to a capacity of 2\u00d71 + 2\u00d73 + 2\u00d75 + 2\u00d77 = 32. Higher shells contain more types of orbitals that continue the pattern, but such types of orbitals are not filled in the ground states of known elements. The subshell types are characterized by the quantum numbers. Four numbers describe an orbital in an atom completely: the principal quantum number \"n\", the azimuthal quantum number \u2113 (the orbital type), the orbital magnetic quantum number \"m\"\u2113, and the spin magnetic quantum number \"ms\".\nOrder of subshell filling.\nThe sequence in which the subshells are filled is given in most cases by the Aufbau principle, also known as the Madelung or Klechkovsky rule (after Erwin Madelung and Vsevolod Klechkovsky respectively). This rule was first observed empirically by Madelung, and Klechkovsky and later authors gave it theoretical justification. The shells overlap in energies, and the Madelung rule specifies the sequence of filling according to:\n1s \u226a 2s &lt; 2p \u226a 3s &lt; 3p \u226a 4s &lt; 3d &lt; 4p \u226a 5s &lt; 4d &lt; 5p \u226a 6s &lt; 4f &lt; 5d &lt; 6p \u226a 7s &lt; 5f &lt; 6d &lt; 7p \u226a ... \nHere the sign \u226a means \"much less than\" as opposed to &lt; meaning just \"less than\". Phrased differently, electrons enter orbitals in order of increasing \"n\" + \u2113, and if two orbitals are available with the same value of \"n\" + \u2113, the one with lower \"n\" is occupied first. In general, orbitals with the same value of \"n\" + \u2113 are similar in energy, but in the case of the s\u00a0orbitals (with \u2113 = 0), quantum effects raise their energy to approach that of the next \"n\" + \u2113 group. Hence the periodic table is usually drawn to begin each row (often called a period) with the filling of a new s\u00a0orbital, which corresponds to the beginning of a new shell. Thus, with the exception of the first row, each period length appears twice:\n2, 8, 8, 18, 18, 32, 32, ...\nThe overlaps get quite close at the point where the d\u00a0orbitals enter the picture, and the order can shift slightly with atomic number and atomic charge.\nStarting from the simplest atom, this lets us build up the periodic table one at a time in order of atomic number, by considering the cases of single atoms. In hydrogen, there is only one electron, which must go in the lowest-energy orbital 1s. This electron configuration is written 1s1, where the superscript indicates the number of electrons in the subshell. Helium adds a second electron, which also goes into 1s, completely filling the first shell and giving the configuration 1s2.\nStarting from the third element, lithium, the first shell is full, so its third electron occupies a 2s orbital, giving a 1s2 2s1 configuration. The 2s electron is lithium's only valence electron, as the 1s subshell is now too tightly bound to the nucleus to participate in chemical bonding to other atoms: such a shell is called a \"core shell\". The 1s subshell is a core shell for all elements from lithium onward. The 2s subshell is completed by the next element beryllium (1s2 2s2). The following elements then proceed to fill the 2p subshell. Boron (1s2 2s2 2p1) puts its new electron in a 2p orbital; carbon (1s2 2s2 2p2) fills a second 2p orbital; and with nitrogen (1s2 2s2 2p3) all three 2p orbitals become singly occupied. This is consistent with Hund's rule, which states that atoms usually prefer to singly occupy each orbital of the same type before filling them with the second electron. Oxygen (1s2 2s2 2p4), fluorine (1s2 2s2 2p5), and neon (1s2 2s2 2p6) then complete the already singly filled 2p orbitals; the last of these fills the second shell completely.\nStarting from element 11, sodium, the second shell is full, making the second shell a core shell for this and all heavier elements. The eleventh electron begins the filling of the third shell by occupying a 3s orbital, giving a configuration of 1s2 2s2 2p6 3s1 for sodium. This configuration is abbreviated [Ne] 3s1, where [Ne] represents neon's configuration. Magnesium ([Ne] 3s2) finishes this 3s orbital, and the following six elements aluminium, silicon, phosphorus, sulfur, chlorine, and argon fill the three 3p orbitals ([Ne] 3s2 3p1 through [Ne] 3s2 3p6). This creates an analogous series in which the outer shell structures of sodium through argon are analogous to those of lithium through neon, and is the basis for the periodicity of chemical properties that the periodic table illustrates: at regular but changing intervals of atomic numbers, the properties of the chemical elements approximately repeat.\nThe first 18 elements can thus be arranged as the start of a periodic table. Elements in the same column have the same number of valence electrons and have analogous valence electron configurations: these columns are called groups. The single exception is helium, which has two valence electrons like beryllium and magnesium, but is typically placed in the column of neon and argon to emphasise that its outer shell is full. (Some contemporary authors question even this single exception, preferring to consistently follow the valence configurations and place helium over beryllium.) There are eight columns in this periodic table fragment, corresponding to at most eight outer-shell electrons. A period begins when a new shell starts filling. Finally, the colouring illustrates the blocks: the elements in the s-block (coloured red) are filling s\u00a0orbitals, while those in the p-block (coloured yellow) are filling p\u00a0orbitals.\nStarting the next row, for potassium and calcium the 4s subshell is the lowest in energy, and therefore they fill it. Potassium adds one electron to the 4s shell ([Ar] 4s1), and calcium then completes it ([Ar] 4s2). However, starting from scandium ([Ar] 3d1 4s2) the 3d subshell becomes the next highest in energy. The 4s and 3d subshells have approximately the same energy and they compete for filling the electrons, and so the occupation is not quite consistently filling the 3d orbitals one at a time. The precise energy ordering of 3d and 4s changes along the row, and also changes depending on how many electrons are removed from the atom. For example, due to the repulsion between the 3d electrons and the 4s ones, at chromium the 4s energy level becomes slightly higher than 3d, and so it becomes more profitable for a chromium atom to have a [Ar] 3d5 4s1 configuration than an [Ar] 3d4 4s2 one. A similar anomaly occurs at copper, whose atom has a [Ar] 3d10 4s1 configuration rather than the expected [Ar] 3d9 4s2. These are violations of the Madelung rule. Such anomalies, however, do not have any chemical significance: most chemistry is not about isolated gaseous atoms, and the various configurations are so close in energy to each other that the presence of a nearby atom can shift the balance. Therefore, the periodic table ignores them and considers only idealized configurations.\nAt zinc ([Ar] 3d10 4s2), the 3d orbitals are completely filled with a total of ten electrons. Next come the 4p orbitals, completing the row, which are filled progressively by gallium ([Ar] 3d10 4s2 4p1) through krypton ([Ar] 3d10 4s2 4p6), in a manner analogous to the previous p-block elements. From gallium onwards, the 3d orbitals form part of the electronic core, and no longer participate in chemistry. The s- and p-block elements, which fill their outer shells, are called main-group elements; the d-block elements (coloured blue below), which fill an inner shell, are called transition elements (or transition metals, since they are all metals).\nThe next 18 elements fill the 5s orbitals (rubidium and strontium), then 4d (yttrium through cadmium, again with a few anomalies along the way), and then 5p (indium through xenon). Again, from indium onward the 4d orbitals are in the core. Hence the fifth row has the same structure as the fourth.\nThe sixth row of the table likewise starts with two s-block elements: caesium and barium. After this, the first f-block elements (coloured green below) begin to appear, starting with lanthanum. These are sometimes termed inner transition elements. As there are now not only 4f but also 5d and 6s subshells at similar energies, competition occurs once again with many irregular configurations; this resulted in some dispute about where exactly the f-block is supposed to begin, but most who study the matter agree that it starts at lanthanum in accordance with the Aufbau principle. Even though lanthanum does not itself fill the 4f subshell as a single atom, because of repulsion between electrons, its 4f orbitals are low enough in energy to participate in chemistry. At ytterbium, the seven 4f orbitals are completely filled with fourteen electrons; thereafter, a series of ten transition elements (lutetium through mercury) follows, and finally six main-group elements (thallium through radon) complete the period. From lutetium onwards the 4f orbitals are in the core, and from thallium onwards so are the 5d orbitals.\nThe seventh row is analogous to the sixth row: 7s fills (francium and radium), then 5f (actinium to nobelium), then 6d (lawrencium to copernicium), and finally 7p (nihonium to oganesson). Starting from lawrencium the 5f orbitals are in the core, and probably the 6d orbitals join the core starting from nihonium. Again there are a few anomalies along the way: for example, as single atoms neither actinium nor thorium actually fills the 5f subshell, and lawrencium does not fill the 6d shell, but all these subshells can still become filled in chemical environments. For a very long time, the seventh row was incomplete as most of its elements do not occur in nature. The missing elements beyond uranium started to be synthesized in the laboratory in 1940, when neptunium was made. (However, the first element to be discovered by synthesis rather than in nature was technetium in 1937.) The row was completed with the synthesis of tennessine in 2010 (the last element oganesson had already been made in 2002), and the last elements in this seventh row were given names in 2016.\nThis completes the modern periodic table, with all seven rows completely filled to capacity.\nElectron configuration table.\nThe following table shows the electron configuration of a neutral gas-phase atom of each element. Different configurations can be favoured in different chemical environments. The main-group elements have entirely regular electron configurations; the transition and inner transition elements show twenty irregularities due to the aforementioned competition between subshells close in energy level. For the last ten elements (109\u2013118), experimental data is lacking and therefore calculated configurations have been shown instead. Completely filled subshells have been greyed out.\nVariations.\nPeriod 1.\nAlthough the modern periodic table is standard today, the placement of the period 1 elements hydrogen and helium remains an open issue under discussion, and some variation can be found. Following their respective s1 and s2 electron configurations, hydrogen would be placed in group 1, and helium would be placed in group 2. The group 1 placement of hydrogen is common, but helium is almost always placed in group 18 with the other noble gases. The debate has to do with conflicting understandings of the extent to which chemical or electronic properties should decide periodic table placement.\nLike the group 1 metals, hydrogen has one electron in its outermost shell and typically loses its only electron in chemical reactions. Hydrogen has some metal-like chemical properties, being able to displace some metals from their salts. But it forms a diatomic nonmetallic gas at standard conditions, unlike the alkali metals which are reactive solid metals. This and hydrogen's formation of hydrides, in which it gains an electron, brings it close to the properties of the halogens which do the same (though it is rarer for hydrogen to form H\u2212 than H+). Moreover, the lightest two halogens (fluorine and chlorine) are gaseous like hydrogen at standard conditions. Some properties of hydrogen are not a good fit for either group: hydrogen is neither highly oxidizing nor highly reducing and is not reactive with water. Hydrogen thus has properties corresponding to both those of the alkali metals and the halogens, but matches neither group perfectly, and is thus difficult to place by its chemistry. Therefore, while the electronic placement of hydrogen in group 1 predominates, some rarer arrangements show either hydrogen in group 17, duplicate hydrogen in both groups 1 and 17, or float it separately from all groups. This last option has nonetheless been criticized by the chemist and philosopher of science Eric Scerri on the grounds that it appears to imply that hydrogen is above the periodic law altogether, unlike all the other elements. \nHelium is the only element that routinely occupies a position in the periodic table that is not consistent with its electronic structure. It has two electrons in its outermost shell, whereas the other noble gases have eight; and it is an s-block element, whereas all other noble gases are p-block elements. However it is unreactive at standard conditions, and has a full outer shell: these properties are like the noble gases in group 18, but not at all like the reactive alkaline earth metals of group 2. For these reasons helium is nearly universally placed in group 18 which its properties best match; a proposal to move helium to group 2 was rejected by IUPAC in 1988 for these reasons. Nonetheless, helium is still occasionally placed in group 2 today, and some of its physical and chemical properties are closer to the group 2 elements and support the electronic placement. Solid helium crystallises in a hexagonal close-packed structure, which matches beryllium and magnesium in group 2, but not the other noble gases in group 18. Recent theoretical developments in noble gas chemistry, in which helium is expected to show slightly less inertness than neon and to form (HeO)(LiF)2 with a structure similar to the analogous beryllium compound (but with no expected neon analogue), have resulted in more chemists advocating a placement of helium in group 2. This relates to the electronic argument, as the reason for neon's greater inertness is repulsion from its filled p-shell that helium lacks, though realistically it is unlikely that helium-containing molecules will be stable outside extreme low-temperature conditions (around 10\u00a0K).\nThe first-row anomaly in the periodic table has additionally been cited to support moving helium to group 2. It arises because the first orbital of any type is unusually small, since unlike its higher analogues, it does not experience interelectronic repulsion from a smaller orbital of the same type. This makes the first row of elements in each block have unusually small atoms, and such elements tend to exhibit characteristic kinds of anomalies for their group. Some chemists arguing for the repositioning of helium have pointed out that helium exhibits these anomalies if it is placed in group 2, but not if it is placed in group 18: on the other hand, neon, which would be the first group 18 element if helium was removed from that spot, does exhibit those anomalies. The relationship between helium and beryllium is then argued to resemble that between hydrogen and lithium, a placement which is much more commonly accepted. For example, because of this trend in the sizes of orbitals, a large difference in atomic radii between the first and second members of each main group is seen in groups 1 and 13\u201317: it exists between neon and argon, and between helium and beryllium, but not between helium and neon. This similarly affects the noble gases' boiling points and solubilities in water, where helium is too close to neon, and the large difference characteristic between the first two elements of a group appears only between neon and argon. Moving helium to group 2 makes this trend consistent in groups 2 and 18 as well, by making helium the first group 2 element and neon the first group 18 element: both exhibit the characteristic properties of a kainosymmetric first element of a group. The group 18 placement of helium nonetheless remains near-universal due to its extreme inertness. Additionally, tables that float both hydrogen and helium outside all groups may rarely be encountered.\nGroup 3.\nGroup\u00a03: Sc, Y, Lu, Lr \n&lt;templatestyles src=\"Periodic table (32 columns, micro)/styles.css\"/&gt;\nCorrect depiction of Group 3\nGroup\u00a03: Sc, Y, La, Ac \n&lt;templatestyles src=\"Periodic table (32 columns, micro)/styles.css\"/&gt;\nIncorrect depiction of Group 3\nIn many periodic tables, the f-block is shifted one element to the right, so that lanthanum and actinium become d-block elements in group 3, and Ce\u2013Lu and Th\u2013Lr form the f-block. Thus the d-block is split into two very uneven portions. This is a holdover from early mistaken measurements of electron configurations; modern measurements are more consistent with the form with lutetium and lawrencium in group 3, and with La\u2013Yb and Ac\u2013No as the f-block.\nThe 4f shell is completely filled at ytterbium, and for that reason Lev Landau and Evgeny Lifshitz in 1948 considered it incorrect to group lutetium as an f-block element. They did not yet take the step of removing lanthanum from the d-block as well, but Jun Kond\u014d realized in 1963 that lanthanum's low-temperature superconductivity implied the activity of its 4f shell. In 1965, David C. Hamilton linked this observation to its position in the periodic table, and argued that the f-block should be composed of the elements La\u2013Yb and Ac\u2013No. Since then, physical, chemical, and electronic evidence has supported this assignment. The issue was brought to wide attention by William B. Jensen in 1982, and the reassignment of lutetium and lawrencium to group 3 was supported by IUPAC reports dating from 1988 (when the 1\u201318 group numbers were recommended) and 2021. The variation nonetheless still exists because most textbook writers are not aware of the issue.\nA third form can sometimes be encountered in which the spaces below yttrium in group 3 are left empty, such as the table appearing on the IUPAC web site, but this creates an inconsistency with quantum mechanics by making the f-block 15 elements wide (La\u2013Lu and Ac\u2013Lr) even though only 14 electrons can fit in an f-subshell. There is moreover some confusion in the literature on which elements are then implied to be in group 3. While the 2021 IUPAC report noted that 15-element-wide f-blocks are supported by some practitioners of a specialized branch of relativistic quantum mechanics focusing on the properties of superheavy elements, the project's opinion was that such interest-dependent concerns should not have any bearing on how the periodic table is presented to \"the general chemical and scientific community\". Other authors focusing on superheavy elements since clarified that the \"15th entry of the f-block represents the first slot of the d-block which is left vacant to indicate the place of the f-block inserts\", which would imply that this form still has lutetium and lawrencium (the 15th entries in question) as d-block elements in group 3. Indeed, when IUPAC publications expand the table to 32 columns, they make this clear and place lutetium and lawrencium under yttrium in group 3.\nSeveral arguments in favour of Sc-Y-La-Ac can be encountered in the literature, but they have been challenged as being logically inconsistent. For example, it has been argued that lanthanum and actinium cannot be f-block elements because as individual gas-phase atoms, they have not begun to fill the f-subshells. But the same is true of thorium which is never disputed as an f-block element, and this argument overlooks the problem on the other end: that the f-shells complete filling at ytterbium and nobelium, matching the Sc-Y-Lu-Lr form, and not at lutetium and lawrencium as the Sc-Y-La-Ac form would have it. Not only are such exceptional configurations in the minority, but they have also in any case never been considered as relevant for positioning any other elements on the periodic table: in gaseous atoms, the d-shells complete their filling at copper, palladium, and gold, but it is universally accepted by chemists that these configurations are exceptional and that the d-block really ends in accordance with the Madelung rule at zinc, cadmium, and mercury. The relevant fact for placement is that lanthanum and actinium (like thorium) have valence f\u00a0orbitals that can become occupied in chemical environments, whereas lutetium and lawrencium do not: their f-shells are in the core, and cannot be used for chemical reactions. Thus the relationship between yttrium and lanthanum is only a secondary relationship between elements with the same number of valence electrons but different kinds of valence orbitals, such as that between chromium and uranium; whereas the relationship between yttrium and lutetium is primary, sharing both valence electron count and valence orbital type.\nPeriodic trends.\nAs chemical reactions involve the valence electrons, elements with similar outer electron configurations may be expected to react similarly and form compounds with similar proportions of elements in them. Such elements are placed in the same group, and thus there tend to be clear similarities and trends in chemical behaviour as one proceeds down a group. As analogous configurations occur at regular intervals, the properties of the elements thus exhibit periodic recurrences, hence the name of the periodic table and the periodic law. These periodic recurrences were noticed well before the underlying theory that explains them was developed.\nAtomic radius.\nHistorically, the physical size of atoms was unknown until the early 20th century. The first calculated estimate of the atomic radius of hydrogen was published by physicist Arthur Haas in 1910 to within an order of magnitude (a factor of 10) of the accepted value, the Bohr radius (~0.529 \u00c5). In his model, Haas used a single-electron configuration based on the classical atomic model proposed by J. J. Thomson in 1904, often called the plum-pudding model.\nAtomic radii (the size of atoms) are dependent on the sizes of their outermost orbitals. They generally decrease going left to right along the main-group elements, because the nuclear charge increases but the outer electrons are still in the same shell. However, going down a column, the radii generally increase, because the outermost electrons are in higher shells that are thus further away from the nucleus. The first row of each block is abnormally small, due to an effect called kainosymmetry or primogenic repulsion: the 1s, 2p, 3d, and 4f subshells have no inner analogues. For example, the 2p orbitals do not experience strong repulsion from the 1s and 2s orbitals, which have quite different angular charge distributions, and hence are not very large; but the 3p orbitals experience strong repulsion from the 2p orbitals, which have similar angular charge distributions. Thus higher s-, p-, d-, and f-subshells experience strong repulsion from their inner analogues, which have approximately the same angular distribution of charge, and must expand to avoid this. This makes significant differences arise between the small 2p elements, which prefer multiple bonding, and the larger 3p and higher p-elements, which do not. Similar anomalies arise for the 1s, 2p, 3d, 4f, and the hypothetical 5g elements: the degree of this first-row anomaly is highest for the s-block, is moderate for the p-block, and is less pronounced for the d- and f-blocks.\nIn the transition elements, an inner shell is filling, but the size of the atom is still determined by the outer electrons. The increasing nuclear charge across the series and the increased number of inner electrons for shielding somewhat compensate each other, so the decrease in radius is smaller. The 4p and 5d atoms, coming immediately after new types of transition series are first introduced, are smaller than would have been expected, because the added core 3d and 4f subshells provide only incomplete shielding of the nuclear charge for the outer electrons. Hence for example gallium atoms are slightly smaller than aluminium atoms. Together with kainosymmetry, this results in an even-odd difference between the periods (except in the s-block) that is sometimes known as secondary periodicity: elements in even periods have smaller atomic radii and prefer to lose fewer electrons, while elements in odd periods (except the first) differ in the opposite direction. Thus for example many properties in the p-block show a zigzag rather than a smooth trend along the group. For example, phosphorus and antimony in odd periods of group 15 readily reach the +5 oxidation state, whereas nitrogen, arsenic, and bismuth in even periods prefer to stay at +3. A similar situation holds for the d-block, with lutetium through tungsten atoms being slightly smaller than yttrium through molybdenum atoms respectively.\nThallium and lead atoms are about the same size as indium and tin atoms respectively, but from bismuth to radon the 6p atoms are larger than the analogous 5p atoms. This happens because when atomic nuclei become highly charged, special relativity becomes needed to gauge the effect of the nucleus on the electron cloud. These relativistic effects result in heavy elements increasingly having differing properties compared to their lighter homologues in the periodic table. Spin\u2013orbit interaction splits the p\u00a0subshell: one p\u00a0orbital is relativistically stabilized and shrunken (it fills in thallium and lead), but the other two (filling in bismuth through radon) are relativistically destabilized and expanded. Relativistic effects also explain why gold is golden and mercury is a liquid at room temperature. They are expected to become very strong in the late seventh period, potentially leading to a collapse of periodicity. Electron configurations are only clearly known until element 108 (hassium), and experimental chemistry beyond 108 has only been done for elements 112 (copernicium) through 115 (moscovium), so the chemical characterization of the heaviest elements remains a topic of current research.\nThe trend that atomic radii decrease from left to right is also present in ionic radii, though it is more difficult to examine because the most common ions of consecutive elements normally differ in charge. Ions with the same electron configuration decrease in size as their atomic number rises, due to increased attraction from the more positively charged nucleus: thus for example ionic radii decrease in the series Se2\u2212, Br\u2212, Rb+, Sr2+, Y3+, Zr4+, Nb5+, Mo6+, Tc7+. Ions of the same element get smaller as more electrons are removed, because the attraction from the nucleus begins to outweigh the repulsion between electrons that causes electron clouds to expand: thus for example ionic radii decrease in the series V2+, V3+, V4+, V5+.\nIonisation energy.\nThe first ionisation energy of an atom is the energy required to remove an electron from it. This varies with the atomic radius: ionisation energy increases left to right and down to up, because electrons that are closer to the nucleus are held more tightly and are more difficult to remove. Ionisation energy thus is minimized at the first element of each period \u2013 hydrogen and the alkali metals \u2013 and then generally rises until it reaches the noble gas at the right edge of the period. There are some exceptions to this trend, such as oxygen, where the electron being removed is paired and thus interelectronic repulsion makes it easier to remove than expected.\nIn the transition series, the outer electrons are preferentially lost even though the inner orbitals are filling. For example, in the 3d series, the 4s electrons are lost first even though the 3d orbitals are being filled. The shielding effect of adding an extra 3d electron approximately compensates the rise in nuclear charge, and therefore the ionisation energies stay mostly constant, though there is a small increase especially at the end of each transition series.\nAs metal atoms tend to lose electrons in chemical reactions, ionisation energy is generally correlated with chemical reactivity, although there are other factors involved as well.\nElectron affinity.\nThe opposite property to ionisation energy is the electron affinity, which is the energy released when adding an electron to the atom. A passing electron will be more readily attracted to an atom if it feels the pull of the nucleus more strongly, and especially if there is an available partially filled outer orbital that can accommodate it. Therefore, electron affinity tends to increase down to up and left to right. The exception is the last column, the noble gases, which have a full shell and have no room for another electron. This gives the halogens in the next-to-last column the highest electron affinities.\nSome atoms, like the noble gases, have no electron affinity: they cannot form stable gas-phase anions. (They can form metastable resonances if the incoming electron arrives with enough kinetic energy, but these inevitably and rapidly autodetach: for example, the lifetime of the most long-lived He\u2212 level is about 359\u00a0microseconds.) The noble gases, having high ionisation energies and no electron affinity, have little inclination towards gaining or losing electrons and are generally unreactive.\nSome exceptions to the trends occur: oxygen and fluorine have lower electron affinities than their heavier homologues sulfur and chlorine, because they are small atoms and hence the newly added electron would experience significant repulsion from the already present ones. For the nonmetallic elements, electron affinity likewise somewhat correlates with reactivity, but not perfectly since other factors are involved. For example, fluorine has a lower electron affinity than chlorine (because of extreme interelectronic repulsion for the very small fluorine atom), but is more reactive.\nValence and oxidation states.\nThe valence of an element can be defined either as the number of hydrogen atoms that can combine with it to form a simple binary hydride, or as twice the number of oxygen atoms that can combine with it to form a simple binary oxide (that is, not a peroxide or a superoxide). The valences of the main-group elements are directly related to the group number: the hydrides in the main groups 1\u20132 and 13\u201317 follow the formulae MH, MH2, MH3, MH4, MH3, MH2, and finally MH. The highest oxides instead increase in valence, following the formulae M2O, MO, M2O3, MO2, M2O5, MO3, M2O7. Today the notion of valence has been extended by that of the oxidation state, which is the formal charge left on an element when all other elements in a compound have been removed as their ions.\nThe electron configuration suggests a ready explanation from the number of electrons available for bonding; indeed, the number of valence electrons starts at 1 in group 1, and then increases towards the right side of the periodic table, only resetting at 3 whenever each new block starts. Thus in period 6, Cs\u2013Ba have 1\u20132 valence electrons; La\u2013Yb have 3\u201316; Lu\u2013Hg have 3\u201312; and Tl\u2013Rn have 3\u20138. However, towards the right side of the d- and f-blocks, the theoretical maximum corresponding to using all valence electrons is not achievable at all; the same situation affects oxygen, fluorine, and the light noble gases up to krypton.\nA full explanation requires considering the energy that would be released in forming compounds with different valences rather than simply considering electron configurations alone. For example, magnesium forms Mg2+ rather than Mg+ cations when dissolved in water, because the latter would spontaneously disproportionate into Mg0 and Mg2+ cations. This is because the enthalpy of hydration (surrounding the cation with water molecules) increases in magnitude with the charge and radius of the ion. In Mg+, the outermost orbital (which determines ionic radius) is still 3s, so the hydration enthalpy is small and insufficient to compensate the energy required to remove the electron; but ionizing again to Mg2+ uncovers the core 2p subshell, making the hydration enthalpy large enough to allow magnesium(II) compounds to form. For similar reasons, the common oxidation states of the heavier p-block elements (where the ns electrons become lower in energy than the np) tend to vary by steps of 2, because that is necessary to uncover an inner subshell and decrease the ionic radius (e.g. Tl+ uncovers 6s, and Tl3+ uncovers 5d, so once thallium loses two electrons it tends to lose the third one as well). Analogous arguments based on orbital hybridization can be used for the less electronegative p-block elements.\nFor transition metals, common oxidation states are nearly always at least +2 for similar reasons (uncovering the next subshell); this holds even for the metals with anomalous dx+1s1 or dx+2s0 configurations (except for silver), because repulsion between d-electrons means that the movement of the second electron from the s- to the d-subshell does not appreciably change its ionisation energy. Because ionizing the transition metals further does not uncover any new inner subshells, their oxidation states tend to vary by steps of 1 instead. The lanthanides and late actinides generally show a stable +3 oxidation state, removing the outer s-electrons and then (usually) one electron from the (n\u22122)f\u00a0orbitals, that are similar in energy to ns. The common and maximum oxidation states of the d- and f-block elements tend to depend on the ionisation energies. As the energy difference between the (n\u22121)d and ns orbitals rises along each transition series, it becomes less energetically favourable to ionize further electrons. Thus, the early transition metal groups tend to prefer higher oxidation states, but the +2 oxidation state becomes more stable for the late transition metal groups. The highest formal oxidation state thus increases from +3 at the beginning of each d-block row, to +7 or +8 in the middle (e.g. OsO4), and then decrease to +2 at the end. The lanthanides and late actinides usually have high fourth ionisation energies and hence rarely surpass the +3 oxidation state, whereas early actinides have low fourth ionisation energies and so for example neptunium and plutonium can reach +7. The very last actinides go further than the lanthanides towards low oxidation states: mendelevium is more easily reduced to the +2 state than thulium or even europium (the lanthanide with the most stable +2 state, on account of its half-filled f-shell), and nobelium outright favours +2 over +3, in contrast to ytterbium.\nAs elements in the same group share the same valence configurations, they usually exhibit similar chemical behaviour. For example, the alkali metals in the first group all have one valence electron, and form a very homogeneous class of elements: they are all soft and reactive metals. However, there are many factors involved, and groups can often be rather heterogeneous. For instance, hydrogen also has one valence electron and is in the same group as the alkali metals, but its chemical behaviour is quite different. The stable elements of group 14 comprise a nonmetal (carbon), two semiconductors (silicon and germanium), and two metals (tin and lead); they are nonetheless united by having four valence electrons. This often leads to similarities in maximum and minimum oxidation states (e.g. sulfur and selenium in group 16 both have maximum oxidation state +6, as in SO3 and SeO3, and minimum oxidation state \u22122, as in sulfides and selenides); but not always (e.g. oxygen is not known to form oxidation state +6, despite being in the same group as sulfur and selenium).\nElectronegativity.\nAnother important property of elements is their electronegativity. Atoms can form covalent bonds to each other by sharing electrons in pairs, creating an overlap of valence orbitals. The degree to which each atom attracts the shared electron pair depends on the atom's electronegativity \u2013 the tendency of an atom towards gaining or losing electrons. The more electronegative atom will tend to attract the electron pair more, and the less electronegative (or more electropositive) one will attract it less. In extreme cases, the electron can be thought of as having been passed completely from the more electropositive atom to the more electronegative one, though this is a simplification. The bond then binds two ions, one positive (having given up the electron) and one negative (having accepted it), and is termed an ionic bond.\nElectronegativity depends on how strongly the nucleus can attract an electron pair, and so it exhibits a similar variation to the other properties already discussed: electronegativity tends to fall going up to down, and rise going left to right. The alkali and alkaline earth metals are among the most electropositive elements, while the chalcogens, halogens, and noble gases are among the most electronegative ones.\nElectronegativity is generally measured on the Pauling scale, on which the most electronegative reactive atom (fluorine) is given electronegativity 4.0, and the least electronegative atom (caesium) is given electronegativity 0.79. In fact neon is the most electronegative element, but the Pauling scale cannot measure its electronegativity because it does not form covalent bonds with most elements.\nAn element's electronegativity varies with the identity and number of the atoms it is bonded to, as well as how many electrons it has already lost: an atom becomes more electronegative when it has lost more electrons. This sometimes makes a large difference: lead in the +2 oxidation state has electronegativity 1.87 on the Pauling scale, while lead in the +4 oxidation state has electronegativity 2.33.\nMetallicity.\nA simple substance is a substance formed from atoms of one chemical element. The simple substances of the more electronegative atoms tend to share electrons (form covalent bonds) with each other. They form either small molecules (like hydrogen or oxygen) or giant structures stretching indefinitely (like carbon or silicon). The noble gases simply stay as single atoms, as they already have a full shell. Substances composed of discrete molecules or single atoms are held together by weaker attractive forces between the molecules, such as the London dispersion force: as electrons move within the molecules, they create momentary imbalances of electrical charge, which induce similar imbalances on nearby molecules and create synchronized movements of electrons across many neighbouring molecules.\nThe more electropositive atoms tend to instead lose electrons, creating a \"sea\" of electrons engulfing cations. The outer orbitals of one atom overlap to share electrons with all its neighbours, creating a giant structure of molecular orbitals extending over all the atoms. This negatively charged \"sea\" pulls on all the ions and keeps them together in a metallic bond. Elements forming such bonds are often called metals; those which do not are often called nonmetals. Some elements can form multiple simple substances with different structures: these are called allotropes. For example, diamond and graphite are two allotropes of carbon.\nThe metallicity of an element can be predicted from electronic properties. When atomic orbitals overlap during metallic or covalent bonding, they create both bonding and antibonding molecular orbitals of equal capacity, with the antibonding orbitals of higher energy. Net bonding character occurs when there are more electrons in the bonding orbitals than there are in the antibonding orbitals. Metallic bonding is thus possible when the number of electrons delocalized by each atom is less than twice the number of orbitals contributing to the overlap. This is the situation for elements in groups 1 through 13; they also have too few valence electrons to form giant covalent structures where all atoms take equivalent positions, and so almost all of them metallise. The exceptions are hydrogen and boron, which have too high an ionisation energy. Hydrogen thus forms a covalent H2 molecule, and boron forms a giant covalent structure based on icosahedral B12 clusters. In a metal, the bonding and antibonding orbitals have overlapping energies, creating a single band that electrons can freely flow through, allowing for electrical conduction.\nIn group 14, both metallic and covalent bonding become possible. In a diamond crystal, covalent bonds between carbon atoms are strong, because they have a small atomic radius and thus the nucleus has more of a hold on the electrons. Therefore, the bonding orbitals that result are much lower in energy than the antibonding orbitals, and there is no overlap, so electrical conduction becomes impossible: carbon is a nonmetal. However, covalent bonding becomes weaker for larger atoms and the energy gap between the bonding and antibonding orbitals decreases. Therefore, silicon and germanium have smaller band gaps and are semiconductors at ambient conditions: electrons can cross the gap when thermally excited. (Boron is also a semiconductor at ambient conditions.) The band gap disappears in tin, so that tin and lead become metals. As the temperature rises, all nonmetals develop some semiconducting properties, to a greater or lesser extent depending on the size of the band gap. Thus metals and nonmetals may be distinguished by the temperature dependence of their electrical conductivity: a metal's conductivity lowers as temperature rises (because thermal motion makes it more difficult for the electrons to flow freely), whereas a nonmetal's conductivity rises (as more electrons may be excited to cross the gap).\nElements in groups 15 through 17 have too many electrons to form giant covalent molecules that stretch in all three dimensions. For the lighter elements, the bonds in small diatomic molecules are so strong that a condensed phase is disfavoured: thus nitrogen (N2), oxygen (O2), white phosphorus and yellow arsenic (P4 and As4), sulfur and red selenium (S8 and Se8), and the stable halogens (F2, Cl2, Br2, and I2) readily form covalent molecules with few atoms. The heavier ones tend to form long chains (e.g. red phosphorus, grey selenium, tellurium) or layered structures (e.g. carbon as graphite, black phosphorus, grey arsenic, antimony, bismuth) that only extend in one or two rather than three dimensions. Both kinds of structures can be found as allotropes of phosphorus, arsenic, and selenium, although the long-chained allotropes are more stable in all three. As these structures do not use all their orbitals for bonding, they end up with bonding, nonbonding, and antibonding bands in order of increasing energy. Similarly to group 14, the band gaps shrink for the heavier elements and free movement of electrons between the chains or layers becomes possible. Thus for example black phosphorus, black arsenic, grey selenium, tellurium, and iodine are semiconductors; grey arsenic, antimony, and bismuth are semimetals (exhibiting quasi-metallic conduction, with a very small band overlap); and polonium and probably astatine are true metals. Finally, the natural group 18 elements all stay as individual atoms.\nThe dividing line between metals and nonmetals is roughly diagonal from top left to bottom right, with the transition series appearing to the left of this diagonal (as they have many available orbitals for overlap). This is expected, as metallicity tends to be correlated with electropositivity and the willingness to lose electrons, which increases right to left and up to down. Thus the metals greatly outnumber the nonmetals. Elements near the borderline are difficult to classify: they tend to have properties that are intermediate between those of metals and nonmetals, and may have some properties characteristic of both. They are often termed semimetals or metalloids. The term \"semimetal\" used in this sense should not be confused with its strict physical sense having to do with band structure: bismuth is physically a semimetal, but is generally considered a metal by chemists.\nThe following table considers the most stable allotropes at standard conditions. The elements coloured yellow form simple substances that are well-characterised by metallic bonding. Elements coloured light blue form giant network covalent structures, whereas those coloured dark blue form small covalently bonded molecules that are held together by weaker van der Waals forces. The noble gases are coloured in violet: their molecules are single atoms and no covalent bonding occurs. Greyed-out cells are for elements which have not been prepared in sufficient quantities for their most stable allotropes to have been characterized in this way. Theoretical considerations and current experimental evidence suggest that all of those elements would metallise if they could form condensed phases, except perhaps for oganesson.\nMetallic\nNetwork covalent\nMolecular covalent\nSingle atoms\nUnknown\nBackground color shows bonding of simple substances in the periodic table. If there are several, the most stable allotrope is considered.\nGenerally, metals are shiny and dense. They usually have high melting and boiling points due to the strength of the metallic bond, and are often malleable and ductile (easily stretched and shaped) because the atoms can move relative to each other without breaking the metallic bond. They conduct electricity because their electrons are free to move in all three dimensions. Similarly, they conduct heat, which is transferred by the electrons as extra kinetic energy: they move faster. These properties persist in the liquid state, as although the crystal structure is destroyed on melting, the atoms still touch and the metallic bond persists, though it is weakened. Metals tend to be reactive towards nonmetals. Some exceptions can be found to these generalizations: for example, beryllium, chromium, manganese, antimony, bismuth, and uranium are brittle (not an exhaustive list); chromium is extremely hard; gallium, rubidium, caesium, and mercury are liquid at or close to room temperature; and noble metals such as gold are chemically very inert.\nNonmetals exhibit different properties. Those forming giant covalent crystals exhibit high melting and boiling points, as it takes considerable energy to overcome the strong covalent bonds. Those forming discrete molecules are held together mostly by dispersion forces, which are more easily overcome; thus they tend to have lower melting and boiling points, and many are liquids or gases at room temperature. Nonmetals are often dull-looking. They tend to be reactive towards metals, except for the noble gases, which are inert towards most substances. They are brittle when solid as their atoms are held tightly in place. They are less dense and conduct electricity poorly, because there are no mobile electrons. Near the borderline, band gaps are small and thus many elements in that region are semiconductors, such as silicon, germanium, and tellurium. Selenium has both a semiconducting grey allotrope and an insulating red allotrope; arsenic has a metallic grey allotrope, a semiconducting black allotrope, and an insulating yellow allotrope (though the last is unstable at ambient conditions). Again there are exceptions; for example, diamond has the highest thermal conductivity of all known materials, greater than any metal.\nIt is common to designate a class of metalloids straddling the boundary between metals and nonmetals, as elements in that region are intermediate in both physical and chemical properties. However, no consensus exists in the literature for precisely which elements should be so designated. When such a category is used, silicon, germanium, arsenic, and tellurium are almost always included, and boron and antimony usually are; but most sources include other elements as well, without agreement on which extra elements should be added, and some others subtract from this list instead. For example, unlike all the other elements generally considered metalloids or nonmetals, antimony's only stable form has metallic conductivity. Moreover, the element resembles bismuth and, more generally, the other p-block metals in its physical and chemical behaviour. On this basis some authors have argued that it is better classified as a metal than as a metalloid. On the other hand, selenium has some semiconducting properties in its most stable form (though it also has insulating allotropes) and it has been argued that it should be considered a metalloid \u2013 though this situation also holds for phosphorus, which is a much rarer inclusion among the metalloids.\nFurther manifestations of periodicity.\nThere are some other relationships throughout the periodic table between elements that are not in the same group, such as the diagonal relationships between elements that are diagonally adjacent (e.g. lithium and magnesium). Some similarities can also be found between the main groups and the transition metal groups, or between the early actinides and early transition metals, when the elements have the same number of valence electrons. Thus uranium somewhat resembles chromium and tungsten in group 6, as all three have six valence electrons. Relationships between elements with the same number of valence electrons but different types of valence orbital have been called secondary or isodonor relationships: they usually have the same maximum oxidation states, but not the same minimum oxidation states. For example, chlorine and manganese both have +7 as their maximum oxidation state (e.g. Cl2O7 and Mn2O7), but their respective minimum oxidation states are \u22121 (e.g. HCl) and \u22123 (K3[Mn(CO)4]). Elements with the same number of valence vacancies but different numbers of valence electrons are related by a tertiary or isoacceptor relationship: they usually have similar minimum but not maximum oxidation states. For example, hydrogen and chlorine both have \u22121 as their minimum oxidation state (in hydrides and chlorides), but hydrogen's maximum oxidation state is +1 (e.g. H2O) while chlorine's is +7.\nMany other physical properties of the elements exhibit periodic variation in accordance with the periodic law, such as melting points, boiling points, heats of fusion, heats of vaporization, atomisation energy, and so on. Similar periodic variations appear for the compounds of the elements, which can be observed by comparing hydrides, oxides, sulfides, halides, and so on. Chemical properties are more difficult to describe quantitatively, but likewise exhibit their own periodicities. Examples include the variation in the acidic and basic properties of the elements and their compounds, the stabilities of compounds, and methods of isolating the elements. Periodicity is and has been used very widely to predict the properties of unknown new elements and new compounds, and is central to modern chemistry.\nClassification of elements.\nMany terms have been used in the literature to describe sets of elements that behave similarly. The group names \"alkali metal\", \"alkaline earth metal\", \"triel\", \"tetrel\", \"pnictogen\", \"chalcogen\", \"halogen\", and \"noble gas\" are acknowledged by IUPAC; the other groups can be referred to by their number, or by their first element (e.g., group 6 is the chromium group). Some divide the p-block elements from groups 13 to 16 by metallicity, although there is neither an IUPAC definition nor a precise consensus on exactly which elements should be considered metals, nonmetals, or semi-metals (sometimes called metalloids). Neither is there a consensus on what the metals succeeding the transition metals ought to be called, with \"post-transition metal\" and \"poor metal\" being among the possibilities having been used. Some advanced monographs exclude the elements of group 12 from the transition metals on the grounds of their sometimes quite different chemical properties, but this is not a universal practice and IUPAC does not presently mention it as allowable in its \"Principles of Chemical Nomenclature\".\nThe \"lanthanides\" are considered to be the elements La\u2013Lu, which are all very similar to each other: historically they included only Ce\u2013Lu, but lanthanum became included by common usage. The \"rare earth elements\" (or rare earth metals) add scandium and yttrium to the lanthanides. The \"actinides\" are considered to be the elements Ac\u2013Lr (historically Th\u2013Lr), although variation of properties in this set is much greater than within the lanthanides. IUPAC recommends the names \"lanthanoids\" and \"actinoids\" to avoid ambiguity, as the -ide suffix typically denotes a negative ion; however \"lanthanides\" and \"actinides\" remain common. With the increasing recognition of lutetium and lawrencium as d-block elements, some authors began to define the lanthanides as La\u2013Yb and the actinides as Ac\u2013No, matching the f-block. The \"transactinides\" or \"superheavy elements\" are the short-lived elements beyond the actinides, starting at lawrencium or rutherfordium (depending on where the actinides are taken to end).\nMany more categorizations exist and are used according to certain disciplines. In astrophysics, a metal is defined as any element with atomic number greater than 2, i.e. anything except hydrogen and helium. The term \"semimetal\" has a different definition in physics than it does in chemistry: bismuth is a semimetal by physical definitions, but chemists generally consider it a metal. A few terms are widely used, but without any very formal definition, such as \"heavy metal\", which has been given such a wide range of definitions that it has been criticized as \"effectively meaningless\".\nThe scope of terms varies significantly between authors. For example, according to IUPAC, the noble gases extend to include the whole group, including the very radioactive superheavy element oganesson. However, among those who specialize in the superheavy elements, this is not often done: in this case \"noble gas\" is typically taken to imply the unreactive behaviour of the lighter elements of the group. Since calculations generally predict that oganesson should not be particularly inert due to relativistic effects, and may not even be a gas at room temperature if it could be produced in bulk, its status as a noble gas is often questioned in this context. Furthermore, national variations are sometimes encountered: in Japan, alkaline earth metals often do not include beryllium and magnesium as their behaviour is different from the heavier group 2 metals.\nHistory.\nEarly history.\nIn 1817, German physicist Johann Wolfgang D\u00f6bereiner began one of the earliest attempts to classify the elements. In 1829, he found that he could form some of the elements into groups of three, with the members of each group having related properties. He termed these groups triads. Chlorine, bromine, and iodine formed a triad; as did calcium, strontium, and barium; lithium, sodium, and potassium; and sulfur, selenium, and tellurium. Various chemists continued his work and were able to identify more and more relationships between small groups of elements. However, they could not build one scheme that encompassed them all.\nJohn Newlands published a letter in the \"Chemical News\" in February 1863 on the periodicity among the chemical elements. In 1864 Newlands published an article in the \"Chemical News\" showing that if the elements are arranged in the order of their atomic weights, those having consecutive numbers frequently either belong to the same group or occupy similar positions in different groups, and he pointed out that each eighth element starting from a given one is in this arrangement a kind of repetition of the first, like the eighth note of an octave in music (The Law of Octaves). However, Newlands's formulation only worked well for the main-group elements, and encountered serious problems with the others.\nGerman chemist Lothar Meyer noted the sequences of similar chemical and physical properties repeated at periodic intervals. According to him, if the atomic weights were plotted as ordinates (i.e. vertically) and the atomic volumes as abscissas (i.e. horizontally)\u2014the curve obtained a series of maximums and minimums\u2014the most electropositive elements would appear at the peaks of the curve in the order of their atomic weights. In 1864, a book of his was published; it contained an early version of the periodic table containing 28 elements, and classified elements into six families by their valence\u2014for the first time, elements had been grouped according to their valence. Works on organizing the elements by atomic weight had until then been stymied by inaccurate measurements of the atomic weights. In 1868, he revised his table, but this revision was published as a draft only after his death.\nMendeleev.\nThe definitive breakthrough came from the Russian chemist Dmitri Mendeleev. Although other chemists (including Meyer) had found some other versions of the periodic system at about the same time, Mendeleev was the most dedicated to developing and defending his system, and it was his system that most affected the scientific community. On 17 February 1869 (1 March 1869 in the Gregorian calendar), Mendeleev began arranging the elements and comparing them by their atomic weights. He began with a few elements, and over the course of the day his system grew until it encompassed most of the known elements. After he found a consistent arrangement, his printed table appeared in May 1869 in the journal of the Russian Chemical Society. When elements did not appear to fit in the system, he boldly predicted that either valencies or atomic weights had been measured incorrectly, or that there was a missing element yet to be discovered. In 1871, Mendeleev published a long article, including an updated form of his table, that made his predictions for unknown elements explicit. Mendeleev predicted the properties of three of these unknown elements in detail: as they would be missing heavier homologues of boron, aluminium, and silicon, he named them eka-boron, eka-aluminium, and eka-silicon (\"eka\" being Sanskrit for \"one\").\nIn 1875, the French chemist Paul-\u00c9mile Lecoq de Boisbaudran, working without knowledge of Mendeleev's prediction, discovered a new element in a sample of the mineral sphalerite, and named it gallium. He isolated the element and began determining its properties. Mendeleev, reading de Boisbaudran's publication, sent a letter claiming that gallium was his predicted eka-aluminium. Although Lecoq de Boisbaudran was initially sceptical, and suspected that Mendeleev was trying to take credit for his discovery, he later admitted that Mendeleev was correct. In 1879, the Swedish chemist Lars Fredrik Nilson discovered a new element, which he named scandium: it turned out to be eka-boron. Eka-silicon was found in 1886 by German chemist Clemens Winkler, who named it germanium. The properties of gallium, scandium, and germanium matched what Mendeleev had predicted. In 1889, Mendeleev noted at the Faraday Lecture to the Royal Institution in London that he had not expected to live long enough \"to mention their discovery to the Chemical Society of Great Britain as a confirmation of the exactitude and generality of the periodic law\". Even the discovery of the noble gases at the close of the 19th century, which Mendeleev had not predicted, fitted neatly into his scheme as an eighth main group.\nMendeleev nevertheless had some trouble fitting the known lanthanides into his scheme, as they did not exhibit the periodic change in valencies that the other elements did. After much investigation, the Czech chemist Bohuslav Brauner suggested in 1902 that the lanthanides could all be placed together in one group on the periodic table. He named this the \"asteroid hypothesis\" as an astronomical analogy: just as there is an asteroid belt instead of a single planet between Mars and Jupiter, so the place below yttrium was thought to be occupied by all the lanthanides instead of just one element.\nAtomic number.\nAfter the internal structure of the atom was probed, amateur Dutch physicist Antonius van den Broek proposed in 1913 that the nuclear charge determined the placement of elements in the periodic table. The New Zealand physicist Ernest Rutherford coined the word \"atomic number\" for this nuclear charge. In van den Broek's published article he illustrated the first electronic periodic table showing the elements arranged according to the number of their electrons. Rutherford confirmed in his 1914 paper that Bohr had accepted the view of van den Broek.\nThe same year, English physicist Henry Moseley using X-ray spectroscopy confirmed van den Broek's proposal experimentally. Moseley determined the value of the nuclear charge of each element from aluminium to gold and showed that Mendeleev's ordering actually places the elements in sequential order by nuclear charge. Nuclear charge is identical to proton count and determines the value of the atomic number (\"Z\") of each element. Using atomic number gives a definitive, integer-based sequence for the elements. Moseley's research immediately resolved discrepancies between atomic weight and chemical properties; these were cases such as tellurium and iodine, where atomic number increases but atomic weight decreases. Although Moseley was soon killed in World War I, the Swedish physicist Manne Siegbahn continued his work up to uranium, and established that it was the element with the highest atomic number then known (92). Based on Moseley and Siegbahn's research, it was also known which atomic numbers corresponded to missing elements yet to be found: 43, 61, 72, 75, 85, and 87. (Element 75 had in fact already been found by Japanese chemist Masataka Ogawa in 1908 and named \"nipponium\", but he mistakenly assigned it as element 43 instead of 75 and so his discovery was not generally recognized until later. The contemporarily accepted discovery of element 75 came in 1925, when Walter Noddack, Ida Tacke, and Otto Berg independently rediscovered it and gave it its present name, rhenium.)\nThe dawn of atomic physics also clarified the situation of isotopes. In the decay chains of the primordial radioactive elements thorium and uranium, it soon became evident that there were many apparent new elements that had different atomic weights but exactly the same chemical properties. In 1913, Frederick Soddy coined the term \"isotope\" to describe this situation, and considered isotopes to merely be different forms of the same chemical element. This furthermore clarified discrepancies such as tellurium and iodine: tellurium's natural isotopic composition is weighted towards heavier isotopes than iodine's, but tellurium has a lower atomic number.\nElectron shells.\nThe Danish physicist Niels Bohr applied Max Planck's idea of quantization to the atom. He concluded that the energy levels of electrons were quantised: only a discrete set of stable energy states were allowed. Bohr then attempted to understand periodicity through electron configurations, surmising in 1913 that the inner electrons should be responsible for the chemical properties of the element. In 1913, he produced the first electronic periodic table based on a quantum atom.\nBohr called his electron shells \"rings\" in 1913: atomic orbitals within shells did not exist at the time of his planetary model. Bohr explains in Part 3 of his famous 1913 paper that the maximum electrons in a shell is eight, writing, \"We see, further, that a ring of n electrons cannot rotate in a single ring round a nucleus of charge ne unless n &lt; 8.\" For smaller atoms, the electron shells would be filled as follows: \"rings of electrons will only join if they contain equal numbers of electrons; and that accordingly the numbers of electrons on inner rings will only be 2, 4, 8.\" However, in larger atoms the innermost shell would contain eight electrons: \"on the other hand, the periodic system of the elements strongly suggests that already in neon N = 10 an inner ring of eight electrons will occur.\" His proposed electron configurations for the atoms (shown to the right) mostly do not accord with those now known. They were improved further after the work of Arnold Sommerfeld and Edmund Stoner discovered more quantum numbers.\nThe first one to systematically expand and correct the chemical potentials of Bohr's atomic theory was Walther Kossel in 1914 and in 1916. Kossel explained that in the periodic table new elements would be created as electrons were added to the outer shell. In Kossel's paper, he writes: This leads to the conclusion that the electrons, which are added further, should be put into concentric rings or shells, on each of which ... only a certain number of electrons\u2014namely, eight in our case\u2014should be arranged. As soon as one ring or shell is completed, a new one has to be started for the next element; the number of electrons, which are most easily accessible, and lie at the outermost periphery, increases again from element to element and, therefore, in the formation of each new shell the chemical periodicity is repeated.\nIn a 1919 paper, Irving Langmuir postulated the existence of \"cells\" which we now call orbitals, which could each only contain eight electrons each, and these were arranged in \"equidistant layers\" which we now call shells. He made an exception for the first shell to only contain two electrons. The chemist Charles Rugeley Bury suggested in 1921 that eight and eighteen electrons in a shell form stable configurations. Bury proposed that the electron configurations in transitional elements depended upon the valence electrons in their outer shell. He introduced the word \"transition\" to describe the elements now known as transition metals or transition elements. Bohr's theory was vindicated by the discovery of element 72: Georges Urbain claimed to have discovered it as the rare earth element \"celtium\", but Bury and Bohr had predicted that element 72 could not be a rare earth element and had to be a homologue of zirconium. Dirk Coster and Georg von Hevesy searched for the element in zirconium ores and found element 72, which they named hafnium after Bohr's hometown of Copenhagen (\"Hafnia\" in Latin). Urbain's celtium proved to be simply purified lutetium (element 71). Hafnium and rhenium thus became the last stable elements to be discovered.\nPrompted by Bohr, Wolfgang Pauli took up the problem of electron configurations in 1923. Pauli extended Bohr's scheme to use four quantum numbers, and formulated his exclusion principle which stated that no two electrons could have the same four quantum numbers. This explained the lengths of the periods in the periodic table (2, 8, 18, and 32), which corresponded to the number of electrons that each shell could occupy. In 1925, Friedrich Hund arrived at configurations close to the modern ones. As a result of these advances, periodicity became based on the number of chemically active or valence electrons rather than by the valences of the elements. The Aufbau principle that describes the electron configurations of the elements was first empirically observed by Erwin Madelung in 1926, though the first to publish it was Vladimir Karapetoff in 1930. In 1961, Vsevolod Klechkovsky derived the first part of the Madelung rule (that orbitals fill in order of increasing \"n\" + \u2113) from the Thomas\u2013Fermi model; the complete rule was derived from a similar potential in 1971 by Yury N. Demkov and Valentin N. Ostrovsky.\nThe quantum theory clarified the transition metals and lanthanides as forming their own separate groups, transitional between the main groups, although some chemists had already proposed tables showing them this way before then: the English chemist Henry Bassett did so in 1892, the Danish chemist Julius Thomsen in 1895, and the Swiss chemist Alfred Werner in 1905. Bohr used Thomsen's form in his 1922 Nobel Lecture; Werner's form is very similar to the modern 32-column form. In particular, this supplanted Brauner's asteroidal hypothesis.\nThe exact position of the lanthanides, and thus the composition of group 3, remained under dispute for decades longer because their electron configurations were initially measured incorrectly. On chemical grounds Bassett, Werner, and Bury grouped scandium and yttrium with lutetium rather than lanthanum (the former two left an empty space below yttrium as lutetium had not yet been discovered). Hund assumed in 1927 that all the lanthanide atoms had configuration [Xe]4f0\u2212145d16s2, on account of their prevailing trivalency. It is now known that the relationship between chemistry and electron configuration is more complicated than that. Early spectroscopic evidence seemed to confirm these configurations, and thus the periodic table was structured to have group 3 as scandium, yttrium, lanthanum, and actinium, with fourteen f-elements breaking up the d-block between lanthanum and hafnium. But it was later discovered that this is only true for four of the fifteen lanthanides (lanthanum, cerium, gadolinium, and lutetium), and that the other lanthanide atoms do not have a d-electron. In particular, ytterbium completes the 4f shell and thus Soviet physicists Lev Landau and Evgeny Lifshitz noted in 1948 that lutetium is correctly regarded as a d-block rather than an f-block element; that bulk lanthanum is an f-metal was first suggested by Jun Kond\u014d in 1963, on the grounds of its low-temperature superconductivity. This clarified the importance of looking at low-lying excited states of atoms that can play a role in chemical environments when classifying elements by block and positioning them on the table. Many authors subsequently rediscovered this correction based on physical, chemical, and electronic concerns and applied it to all the relevant elements, thus making group 3 contain scandium, yttrium, lutetium, and lawrencium and having lanthanum through ytterbium and actinium through nobelium as the f-block rows: this corrected version achieves consistency with the Madelung rule and vindicates Bassett, Werner, and Bury's initial chemical placement.\nIn 1988, IUPAC released a report supporting this composition of group 3, a decision that was reaffirmed in 2021. Variation can still be found in textbooks on the composition of group 3, and some argumentation against this format is still published today, but chemists and physicists who have considered the matter largely agree on group 3 containing scandium, yttrium, lutetium, and lawrencium and challenge the counterarguments as being inconsistent.\nSynthetic elements.\nBy 1936, the pool of missing elements from hydrogen to uranium had shrunk to four: elements 43, 61, 85, and 87 remained missing. Element 43 eventually became the first element to be synthesized artificially via nuclear reactions rather than discovered in nature. It was discovered in 1937 by Italian chemists Emilio Segr\u00e8 and Carlo Perrier, who named their discovery technetium, after the Greek word for \"artificial\". Elements 61 (promethium) and 85 (astatine) were likewise produced artificially in 1945 and 1940 respectively; element 87 (francium) became the last element to be discovered in nature, by French chemist Marguerite Perey in 1939. The elements beyond uranium were likewise discovered artificially, starting with Edwin McMillan and Philip Abelson's 1940 discovery of neptunium (via bombardment of uranium with neutrons). Glenn T. Seaborg and his team at the Lawrence Berkeley National Laboratory (LBNL) continued discovering transuranium elements, starting with plutonium in 1941, and discovered that contrary to previous thinking, the elements from actinium onwards were congeners of the lanthanides rather than transition metals. Bassett (1892), Werner (1905), and the French engineer Charles Janet (1928) had previously suggested this, but their ideas did not then receive general acceptance. Seaborg thus called them the actinides. Elements up to 101 (named mendelevium in honour of Mendeleev) were synthesized up to 1955, either through neutron or alpha-particle irradiation, or in nuclear explosions in the cases of 99 (einsteinium) and 100 (fermium).\nA significant controversy arose with elements 102 through 106 in the 1960s and 1970s, as competition arose between the LBNL team (now led by Albert Ghiorso) and a team of Soviet scientists at the Joint Institute for Nuclear Research (JINR) led by Georgy Flyorov. Each team claimed discovery, and in some cases each proposed their own name for the element, creating an element naming controversy that lasted decades. These elements were made by bombardment of actinides with light ions. IUPAC at first adopted a hands-off approach, preferring to wait and see if a consensus would be forthcoming. But as it was also the height of the Cold War, it became clear that this would not happen. As such, IUPAC and the International Union of Pure and Applied Physics (IUPAP) created a Transfermium Working Group (TWG, fermium being element 100) in 1985 to set out criteria for discovery, which were published in 1991. After some further controversy, these elements received their final names in 1997, including seaborgium (106) in honour of Seaborg.\nThe TWG's criteria were used to arbitrate later element discovery claims from LBNL and JINR, as well as from research institutes in Germany (GSI) and Japan (Riken). Currently, consideration of discovery claims is performed by a IUPAC/IUPAP Joint Working Party. After priority was assigned, the elements were officially added to the periodic table, and the discoverers were invited to propose their names. By 2016, this had occurred for all elements up to 118, therefore completing the periodic table's first seven rows. The discoveries of elements beyond 106 were made possible by techniques devised by Yuri Oganessian at the JINR: cold fusion (bombardment of lead and bismuth by heavy ions) made possible the 1981\u20132004 discoveries of elements 107 through 112 at GSI and 113 at Riken, and he led the JINR team (in collaboration with American scientists) to discover elements 114 through 118 using hot fusion (bombardment of actinides by calcium ions) in 1998\u20132010. The heaviest known element, oganesson (118), is named in Oganessian's honour. Element 114 is named flerovium in honour of his predecessor and mentor Flyorov.\nIn celebration of the periodic table's 150th anniversary, the United Nations declared the year 2019 as the International Year of the Periodic Table, celebrating \"one of the most significant achievements in science\". The discovery criteria set down by the TWG were updated in 2020 in response to experimental and theoretical progress that had not been foreseen in 1991. Today, the periodic table is among the most recognisable icons of chemistry. IUPAC is involved today with many processes relating to the periodic table: the recognition and naming of new elements, recommending group numbers and collective names, and the updating of atomic weights.\nFuture extension beyond the seventh period.\nThe most recently named elements \u2013 nihonium (113), moscovium (115), tennessine (117), and oganesson (118) \u2013 completed the seventh row of the periodic table. Future elements would have to begin an eighth row. These elements may be referred to either by their atomic numbers (e.g. \"element 164\"), or by the IUPAC systematic element names adopted in 1978, which directly relate to the atomic numbers (e.g. \"unhexquadium\" for element 164, derived from Latin \"unus\" \"one\", Greek \"hexa \" \"six\", Latin \"quadra\" \"four\", and the traditional \"-ium\" suffix for metallic elements). All attempts to synthesize such elements have failed so far. An attempt to make element 119 has been ongoing since 2018 at the Riken research institute in Japan, and an attempt to make element 120 has been ongoing since 2025 at the LBNL in the United States. The JINR in Russia and the Heavy Ion Research Facility in Lanzhou (HIRFL) in China also plan to make their own attempts at synthesizing the first few period 8 elements.\nIf the eighth period followed the pattern set by the earlier periods, then it would contain fifty elements, filling the 8s, 5g, 6f, 7d, and finally 8p subshells in that order. But by this point, relativistic effects should result in significant deviations from the Madelung rule. Various different models have been suggested for the configurations of eighth-period elements, as well as how to show the results in a periodic table. All agree that the eighth period should begin like the previous ones with two 8s elements, 119 and 120. However, after that the massive energetic overlaps between the 5g, 6f, 7d, and 8p subshells means that they all begin to fill together, and it is not clear how to separate out specific 5g and 6f series. Elements 121 through 156 thus do not fit well as chemical analogues of any previous group in the earlier parts of the table, although they have sometimes been placed as 5g, 6f, and other series to formally reflect their electron configurations. Eric Scerri has raised the question of whether an extended periodic table should take into account the failure of the Madelung rule in this region, or if such exceptions should be ignored. The shell structure may also be fairly formal at this point: already the electron distribution in an oganesson atom is expected to be rather uniform, with no discernible shell structure.\nThe situation from elements 157 to 172 should return to normalcy and be more reminiscent of the earlier rows. The heavy p-shells are split by the spin\u2013orbit interaction: one p\u00a0orbital (p1/2) is more stabilized, and the other two (p3/2) are destabilized. (Such shifts in the quantum numbers happen for all types of shells, but it makes the biggest difference to the order for the p-shells.) It is likely that by element 157, the filled 8s and 8p1/2 shells with four electrons in total have sunk into the core. Beyond the core, the next orbitals are 7d and 9s at similar energies, followed by 9p1/2 and 8p3/2 at similar energies, and then a large gap. Thus, the 9s and 9p1/2 orbitals in essence replace the 8s and 8p1/2 ones, making elements 157\u2013172 probably chemically analogous to groups 3\u201318: for example, element 164 would appear two places below lead in group 14 under the usual pattern, but is calculated to be very analogous to palladium in group 10 instead. Thus, it takes fifty-four elements rather than fifty to reach the next noble element after 118. However, while these conclusions about elements 157 through 172's chemistry are generally agreed by models, there is disagreement on whether the periodic table should be drawn to reflect chemical analogies, or if it should reflect likely formal electron configurations, which should be quite different from earlier periods and are not agreed between sources. Discussion about the format of the eighth row thus continues.\nBeyond element 172, calculation is complicated by the 1s electron energy level becoming imaginary. Such a situation does have a physical interpretation and does not in itself pose an electronic limit to the periodic table, but the correct way to incorporate such states into multi-electron calculations is still an open question, which would need to be answered to calculate the periodic table's structure beyond this point.\nNuclear stability will likely prove a decisive factor constraining the number of possible elements. It depends on the balance between the electric repulsion between protons and the strong force binding protons and neutrons together. Protons and neutrons are arranged in shells, just like electrons, and so a closed shell can significantly increase stability: the known superheavy nuclei exist because of such a shell closure, probably at around 114\u2013126 protons and 184 neutrons. They are probably close to a predicted island of stability, where superheavy nuclides should be more long-lived than otherwise expected: predictions for the longest-lived nuclides on the island range from microseconds to millions of years. It should nonetheless be noted that these are essentially extrapolations into an unknown part of the chart of nuclides, and systematic model uncertainties need to be taken into account.\nAs the closed shells are passed, the stabilizing effect should vanish. Thus, superheavy nuclides with more than 184 neutrons are expected to have much shorter lifetimes, spontaneously fissioning within 10\u221215\u00a0seconds. If this is so, then it would not make sense to consider them chemical elements: IUPAC/IUPAP theorizes and recommends an element to exist only if the nucleus lives longer than 10\u221214\u00a0seconds, the time needed for it to gather an electron cloud. Nonetheless, theoretical estimates of half-lives are very model-dependent, ranging over many orders of magnitude. The extreme repulsion between protons is predicted to result in exotic nuclear topologies, with bubbles, rings, and tori expected: this further complicates extrapolation. It is not clear if any further-out shell closures exist, due to an expected smearing out of distinct nuclear shells (as is already expected for the electron shells at oganesson). Furthermore, even if later shell closures exist, it is not clear if they would allow such heavy elements to exist. As such, it may be that the periodic table practically ends around element 120, as elements become too short-lived to observe, and then too short-lived to have chemistry; the era of discovering new elements would thus be close to its end. If another proton shell closure beyond 126 does exist, then it probably occurs around 164; thus the region where periodicity fails more or less matches the region of instability between the shell closures.\nAlternatively, quark matter may become stable at high mass numbers, in which the nucleus is composed of freely flowing up and down quarks instead of binding them into protons and neutrons; this would create a continent of stability instead of an island. Other effects may come into play: for example, in very heavy elements the 1s electrons are likely to spend a significant amount of time so close to the nucleus that they are actually inside it, which would make them vulnerable to electron capture.\nEven if eighth-row elements can exist, producing them is likely to be difficult, and it should become even more difficult as atomic number rises. Although the 8s elements 119 and 120 are expected to be reachable with present means, the elements beyond that are expected to require new technology, if they can be produced at all.\nAlternative periodic tables.\nThe periodic law may be represented in multiple ways, of which the standard periodic table is only one. Within 100 years of the appearance of Mendeleev's table in 1869, Edward G. Mazurs had collected an estimated 700 different published versions of the periodic table. Many forms retain the rectangular structure, including Charles Janet's left-step periodic table (pictured below), and the modernised form of Mendeleev's original 8-column layout that is still common in Russia. Other periodic table formats have been shaped much more exotically, such as spirals (Otto Theodor Benfey's pictured to the right), circles and triangles.\nAlternative periodic tables are often developed to highlight or emphasize chemical or physical properties of the elements that are not as apparent in traditional periodic tables, with different ones skewed more towards emphasizing chemistry or physics at either end. The standard form, which remains by far the most common, is somewhere in the middle.\nThe many different forms of the periodic table have prompted the questions of whether there is an optimal or definitive form of the periodic table, and if so, what it might be. There are no current consensus answers to either question. Janet's left-step table is being increasingly discussed as a candidate for being the optimal or most fundamental form; Scerri has written in support of it, as it clarifies helium's nature as an s-block element, increases regularity by having all period lengths repeated, faithfully follows Madelung's rule by making each period correspond to one value of n + \u2113, and regularises atomic number triads and the first-row anomaly trend. While he notes that its placement of helium atop the alkaline earth metals can be seen a disadvantage from a chemical perspective, he counters this by appealing to the first-row anomaly, pointing out that the periodic table \"fundamentally reduces to quantum mechanics\", and that it is concerned with \"abstract elements\" and hence atomic properties rather than macroscopic properties.\nThis form of periodic table is congruent with the order in which electron shells are ideally filled according to the Madelung rule, as shown in the accompanying sequence in the left margin (read from top to bottom, left to right). The experimentally determined ground-state electron configurations of the elements differ from the configurations predicted by the Madelung rule in twenty instances, but the Madelung-predicted configurations are always at least close to the ground state. The last two elements shown, elements 119 and 120, have not yet been synthesized.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "23055", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=23055", "title": "Potassium", "text": "element with atomic number 19 (K)\nPotassium is a chemical element; it has symbol K (from Neo-Latin ) and atomic number19. It is a silvery white metal that is soft enough to easily cut with a knife. Potassium metal reacts rapidly with atmospheric oxygen to form flaky white potassium peroxide in only seconds of exposure. It was first isolated from potash, the ashes of plants, from which its name derives. In the periodic table, potassium is one of the alkali metals, all of which have a single valence electron in the outer electron shell, which is easily removed to create an\u00a0ion with a positive charge (which combines with anions to form salts). In nature, potassium occurs only in ionic salts. Elemental potassium reacts vigorously with water, generating sufficient heat to ignite hydrogen emitted in the reaction, and burning with a lilac-colored flame. It is found dissolved in seawater (which is 0.04% potassium by weight), and occurs in many minerals such as orthoclase, a common constituent of granites and other igneous rocks.\nPotassium is chemically very similar to sodium, the previous element in group 1 of the periodic table. They have a similar first ionization energy, which allows for each atom to give up its sole outer electron. It was first suggested in 1702 that they were distinct elements that combine with the same anions to make similar salts, which was demonstrated in 1807 when elemental potassium was first isolated via electrolysis. Naturally occurring potassium is composed of three isotopes, of which 40K is radioactive. Traces of 40K are found in all potassium, and it is the most common radioisotope in the human body.\nPotassium ions are vital for the functioning of all living cells. The transfer of potassium ions across nerve cell membranes is necessary for normal nerve transmission; potassium deficiency and excess can each result in numerous signs and symptoms, including an abnormal heart rhythm and various electrocardiographic abnormalities. Fresh fruits and vegetables are good dietary sources of potassium. The body responds to the influx of dietary potassium, which raises serum potassium levels, by shifting potassium from outside to inside cells and increasing potassium excretion by the kidneys.\nMost industrial applications of potassium exploit the high solubility of its compounds in water, such as saltwater soap. Heavy crop production rapidly depletes the soil of potassium, and this can be remedied with agricultural fertilizers containing potassium, accounting for 95% of global potassium chemical production.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nEtymology.\nThe English name for the element \"potassium\" comes from the word \"potash\", which refers to an early method of extracting various potassium salts: placing in a \"pot\" the \"ash\" of burnt wood or tree leaves, adding water, heating, and evaporating the solution. When Humphry Davy first isolated the pure element using electrolysis in 1807, he named it \"potassium\", which he derived from the word \"potash\".\nThe symbol \"K\" stems from \"kali\", itself from the root word \"alkali\", which in turn comes from \"al-qalyah\" 'plant ashes'. In 1797, the German chemist Martin Klaproth discovered \"potash\" in the minerals leucite and lepidolite, and realized that \"potash\" was not a product of plant growth but actually contained a new element, which he proposed calling \"kali\". In 1807, Humphry Davy produced the element via electrolysis: in 1809, Ludwig Wilhelm Gilbert proposed the name \"Kalium\" for Davy's \"potassium\". In 1814, the Swedish chemist Berzelius advocated the name \"kalium\" for potassium, with the chemical symbol \"K\".\nThe English and French-speaking countries adopted the name \"Potassium\", which was favored by Davy and French chemists Joseph Louis Gay-Lussac and Louis Jacques Th\u00e9nard, whereas the other Germanic countries adopted Gilbert and Klaproth's name \"Kalium\". The \"Gold Book\" of the International Union of Pure and Applied Chemistry has designated the official chemical symbol as K.\nProperties.\nPhysical.\nPotassium is the second least dense metal after lithium. It is a soft solid with a low melting point, and can be easily cut with a knife. Potassium is silvery in appearance, but it begins to tarnish toward gray immediately on exposure to air. In a flame test, potassium and its compounds emit a lilac color with a peak emission wavelength of 766.5 nanometers.\nNeutral potassium atoms have 19 electrons, one more than the configuration of the noble gas argon. Because of its low first ionization energy of 418.8kJ/mol, the potassium atom is much more likely to lose the last electron and acquire a positive charge, although negatively charged alkalide ions are not impossible. In contrast, the second ionization energy is very high (3052kJ/mol).\nChemical.\nPotassium reacts with oxygen, water, and carbon dioxide components in air. With oxygen it forms potassium peroxide. With water potassium forms potassium hydroxide (KOH). The reaction of potassium with water can be violently exothermic, especially since the coproduced hydrogen gas can ignite. Because of this, potassium and the liquid sodium\u2013potassium (NaK) alloy are potent desiccants, although they are no longer used as such.\nCompounds.\nFour oxides of potassium are well studied: potassium oxide (), potassium peroxide (), potassium superoxide () and potassium ozonide (). The binary potassium-oxygen compounds react with water forming KOH.\nKOH is a strong base. Illustrating its hydrophilic character, as much as 1.21 kg of KOH can dissolve in a single liter of water. Anhydrous KOH is rarely encountered. KOH reacts readily with carbon dioxide () to produce potassium carbonate (), and in principle could be used to remove traces of the gas from air. Like the closely related sodium hydroxide, KOH reacts with fats to produce soaps.\nIn general, potassium compounds are ionic and, owing to the high hydration energy of the ion, have excellent water solubility. The main species in water solution are the aquo complexes where \"n\" = 6 and 7.\nPotassium heptafluorotantalate () is an intermediate in the purification of tantalum from the otherwise persistent contaminant of niobium.\nOrganopotassium compounds illustrate nonionic compounds of potassium. They feature highly polar covalent K\u2013C bonds. Examples include benzyl potassium . Potassium intercalates into graphite to give a variety of graphite intercalation compounds, including .\nIsotopes.\nThere are 25 known isotopes of potassium, three of which occur naturally: 39K (93.3%), 40K (0.0117%), and 41K (6.7%) (by mole fraction). Naturally occurring 40K has a half-life of years. It decays to stable 40Ar by electron capture or positron emission (11.2%) or to stable 40Ca by beta decay (88.8%). The decay of 40K to 40Ar is the basis of a common method for dating rocks. The conventional K-Ar dating method depends on the assumption that the rocks contained no argon at the time of formation and that all the subsequent radiogenic argon (40Ar) was quantitatively retained. Minerals are dated by measurement of the concentration of potassium and the amount of radiogenic 40Ar that has accumulated. The minerals best suited for dating include biotite, muscovite, metamorphic hornblende, and volcanic feldspar; whole rock samples from volcanic flows and shallow instrusives can also be dated if they are unaltered. Apart from dating, potassium isotopes have been used as tracers in studies of weathering and for nutrient cycling studies because potassium is a macronutrient required for life on Earth.\n40K occurs in natural potassium (and thus in some commercial salt substitutes) in sufficient quantity that large bags of those substitutes can be used as a radioactive source for classroom demonstrations. 40K is the radioisotope with the largest abundance in the human body. In healthy animals and people, 40K represents the largest source of radioactivity, greater even than 14C. In a human body of 70 kg, about 4,400 nuclei of 40K decay per second. The activity of natural potassium is 31 Bq/g.\nHistory.\nPotash.\nPotash is primarily a mixture of potassium salts because plants have little or no sodium content, and the rest of a plant's major mineral content consists of calcium salts of relatively low solubility in water. While potash has been used since ancient times, its composition was not understood. Georg Ernst Stahl obtained experimental evidence that led him to suggest the fundamental difference of sodium and potassium salts in 1702, and Henri Louis Duhamel du Monceau was able to prove this difference in 1736. The exact chemical composition of potassium and sodium compounds, and the status as chemical element of potassium and sodium, was not known then, and thus Antoine Lavoisier did not include the alkali in his list of chemical elements in 1789. For a long time the only significant applications for potash were the production of glass, bleach, soap and gunpowder as potassium nitrate. Potassium soaps from animal fats and vegetable oils were especially prized because they tend to be more water-soluble and of softer texture, and are therefore known as soft soaps. The discovery by Justus Liebig in 1840 that potassium is a necessary element for plants and that most types of soil lack potassium caused a steep rise in demand for potassium salts. Wood-ash from fir trees was initially used as a potassium salt source for fertilizer, but, with the discovery in 1868 of mineral deposits containing potassium chloride near Sta\u00dffurt, Germany, the production of potassium-containing fertilizers began at an industrial scale. Other potash deposits were discovered, and by the 1960s Canada became the dominant producer.\nMetal.\nPotassium \"metal\" was first isolated in 1807 by Humphry Davy, who derived it by electrolysis of molten caustic potash (KOH) with the newly discovered voltaic pile. Potassium was the first metal that was isolated by electrolysis. Later in the same year, Davy reported extraction of the metal sodium from a mineral derivative (caustic soda, NaOH, or lye) rather than a plant salt, by a similar technique, demonstrating that the elements, and thus the salts, are different. Although the production of potassium and sodium metal should have shown that both are elements, it took some time before this view was universally accepted.\nBecause of the sensitivity of potassium to water and air, air-free techniques are normally employed for handling the element. It is unreactive toward nitrogen and saturated hydrocarbons such as mineral oil or kerosene. It readily dissolves in liquid ammonia, up to 480 g per 1000 g of ammonia at 0\u00b0C. Depending on the concentration, the ammonia solutions are blue to yellow, and their electrical conductivity is similar to that of liquid metals. Potassium slowly reacts with ammonia to form KNH2, but this reaction is accelerated by minute amounts of transition metal salts. Because it can reduce the salts to the metal, potassium is often used as the reductant in the preparation of finely divided metals from their salts by the Rieke method. Illustrative is the preparation of magnesium:\nOccurrence.\nPotassium is formed in supernovae by nucleosynthesis from lighter atoms. Potassium is principally created in Type II supernovae via an explosive oxygen-burning process. These are nuclear fusion reactions, not to be confused with chemical burning of potassium in oxygen. 40K is also formed in s-process nucleosynthesis and the neon burning process.\nPotassium is the 20th most abundant element in the Solar System and the 17th most abundant element by weight in the Earth. It makes up about 2.6% of the weight of the Earth's crust and is the seventh most abundant element in the crust. The potassium concentration in seawater is 0.39g/L (0.039 wt/v%), about one twenty-seventh the concentration of sodium.\nGeology.\nElemental potassium does not occur in nature because of its high reactivity. It reacts violently with water and also reacts with oxygen. Orthoclase (potassium feldspar) is a common rock-forming mineral. Granite for example contains 5% potassium, which is well above the average in the Earth's crust. Sylvite (KCl), carnallite (), kainite () and langbeinite () are the minerals found in large evaporite deposits worldwide. The deposits often show layers starting with the least soluble at the bottom and the most soluble on top. Deposits of niter (potassium nitrate) are formed by decomposition of organic material in contact with atmosphere, mostly in caves; because of the good water solubility of niter the formation of larger deposits requires special environmental conditions.\nCommercial production.\nMining.\nPotassium salts such as carnallite, langbeinite, polyhalite, and sylvite form extensive evaporite deposits in ancient lake bottoms and seabeds, making extraction of potassium salts in these environments commercially viable. The principal source of potassium \u2013 potash \u2013 is mined in Canada, Russia, Belarus, Kazakhstan, Germany, Israel, the U.S., Jordan, and other places around the world. The first mined deposits were located near Sta\u00dffurt, Germany, but the deposits span from Great Britain over Germany into Poland. They are located in the Zechstein and were deposited in the Middle to Late Permian. The largest deposits ever found lie below the surface of the Canadian province of Saskatchewan. The deposits are located in the Elk Point Group produced in the Middle Devonian. Saskatchewan, where several large mines have operated since the 1960s, pioneered the technique of freezing of wet sands (the Blairmore formation) to drive mine shafts through them. The main potash mining company in Saskatchewan until its merge was the Potash Corporation of Saskatchewan, now Nutrien. The water of the Dead Sea is used by Israel and Jordan as a source of potash, while the concentration in normal oceans is too low for commercial production at current prices.\nChemical extraction.\nSeveral methods are used to separate potassium salts from sodium and magnesium compounds. The most-used method is fractional precipitation using the solubility differences of the salts. Electrostatic separation of the ground salt mixture is also used in some mines. The resulting sodium and magnesium waste is either stored underground or piled up in slag heaps. Most of the mined potassium mineral ends up as potassium chloride after processing. The mineral industry refers to potassium chloride either as potash, muriate of potash, or simply MOP.\nPure potassium metal can be isolated by electrolysis of its hydroxide in a process that has changed little since it was first used by Humphry Davy in 1807. Although the electrolysis process was developed and used in industrial scale in the 1920s, the thermal method by reacting sodium with potassium chloride in a chemical equilibrium reaction became the dominant method in the 1950s.\nNa + KCl \u2192 NaCl + K\nThe production of sodium\u2013potassium alloys is accomplished by changing the reaction time and the amount of sodium used in the reaction. The Griesheimer process employing the reaction of potassium fluoride with calcium carbide was also used to produce potassium.\nReagent-grade potassium metal costs about $10.00/pound ($22/kg) in 2010 when purchased by the tonne. Lower purity metal is considerably cheaper. The market is volatile because long-term storage of the metal is difficult. It must be stored in a dry inert gas atmosphere or anhydrous mineral oil to prevent the formation of a surface layer of potassium superoxide, a pressure-sensitive explosive that detonates when scratched. The resulting explosion often starts a fire difficult to extinguish.\nCation identification.\nPotassium is now quantified by ionization techniques, but at one time it was quantitated by gravimetric analysis.\nReagents used to precipitate potassium salts include sodium tetraphenylborate, hexachloroplatinic acid, and sodium cobaltinitrite into respectively potassium tetraphenylborate, potassium hexachloroplatinate, and potassium cobaltinitrite.\nThe reaction with sodium cobaltinitrite is illustrative:\nThe potassium cobaltinitrite is obtained as a yellow solid.\nCommercial uses.\nFertilizer.\nPotassium ions are an essential component of plant nutrition and are found in most soil types. They are used as a fertilizer in agriculture, horticulture, and hydroponic culture in the form of chloride (KCl), sulfate (), or nitrate (), representing the 'K' in 'NPK'. Agricultural fertilizers consume 95% of global potassium chemical production, and about 90% of this potassium is supplied as KCl. The potassium content of most plants ranges from 0.5% to 2% of the harvested weight of crops, conventionally expressed as amount of . Modern high-yield agriculture depends upon fertilizers to replace the potassium lost at harvest. Most agricultural fertilizers contain potassium chloride, while potassium sulfate is used for chloride-sensitive crops or crops needing higher sulfur content. The sulfate is produced mostly by decomposition of the complex minerals kainite () and langbeinite (). Only a very few fertilizers contain potassium nitrate. In 2005, about 93% of world potassium production was consumed by the fertilizer industry. Furthermore, potassium can play a key role in nutrient cycling by controlling litter composition.\nMedical use.\nPotassium citrate.\nPotassium citrate is used to treat a kidney stone condition called renal tubular acidosis.\nPotassium chloride.\nPotassium, in the form of potassium chloride is used as a medication to treat and prevent low blood potassium. Low blood potassium may occur due to vomiting, diarrhea, or certain medications. It is given by slow injection into a vein or by mouth.\nFood additives.\nPotassium sodium tartrate (, Rochelle salt) is a main constituent of some varieties of baking powder; it is also used in the silvering of mirrors. Potassium bromate () is a strong oxidizer (E924), used to improve dough strength and rise height. Potassium bisulfite () is used as a food preservative, for example in wine and beer-making (but not in meats). It is also used to bleach textiles and straw, and in the tanning of leathers.\nIndustrial.\nMajor potassium chemicals are potassium hydroxide, potassium carbonate, potassium sulfate, and potassium chloride. Megatons of these compounds are produced annually.\nKOH is a strong base, which is used in industry to neutralize strong and weak acids, to control pH and to manufacture potassium salts. It is also used to saponify fats and oils, in industrial cleaners, and in hydrolysis reactions, for example of esters.\nPotassium nitrate () or saltpeter is obtained from natural sources such as guano and evaporites or manufactured via the Haber process; it is the oxidant in gunpowder (black powder) and an important agricultural fertilizer. Potassium cyanide (KCN) is used industrially to dissolve copper and precious metals, in particular silver and gold, by forming complexes. Its applications include gold mining, electroplating, and electroforming of these metals; it is also used in organic synthesis to make nitriles. Potassium carbonate ( or potash) is used in the manufacture of glass, soap, color TV tubes, fluorescent lamps, textile dyes and pigments. Potassium permanganate () is an oxidizing, bleaching and purification substance and is used for production of saccharin. Potassium chlorate () is added to matches and explosives. Potassium bromide (KBr) was formerly used as a sedative and in photography.\nWhile potassium chromate () is used in the manufacture of a host of different commercial products such as inks, dyes, wood stains (by reacting with the tannic acid in wood), explosives, fireworks, fly paper, and safety matches, as well as in the tanning of leather, all of these uses are due to the chemistry of the chromate ion rather than to that of the potassium ion.\nNiche uses.\nThere are thousands of uses of various potassium compounds. One example is potassium superoxide, , an orange solid that acts as a portable source of oxygen and a carbon dioxide absorber. It is widely used in respiration systems in mines, submarines and spacecraft as it takes less volume than the gaseous oxygen.\nAnother example is potassium cobaltinitrite, , which is used as artist's pigment under the name of Aureolin or Cobalt Yellow.\nThe stable isotopes of potassium can be laser cooled and used to probe fundamental and technological problems in quantum physics. The two bosonic isotopes possess convenient Feshbach resonances to enable studies requiring tunable interactions, while 40K is one of only two stable fermions amongst the alkali metals.\nLaboratory uses.\nAn alloy of sodium and potassium, NaK is a liquid used as a heat-transfer medium and a desiccant for producing dry and air-free solvents. It can also be used in reactive distillation. The ternary alloy of 12% Na, 47% K and 41% Cs has the lowest melting point of \u221278\u00b0C of any metallic compound.\nMetallic potassium is used in several types of magnetometers.\nBiological role.\nPotassium is the eighth or ninth most common element by mass (0.2%) in the human body, so that a 60kg adult contains a total of about 120g of potassium. The body has about as much potassium as sulfur and chlorine, and only calcium and phosphorus are more abundant (with the exception of the ubiquitous CHON elements). Potassium ions are present in a wide variety of proteins and enzymes. Potassium is largely intracellular.\nBiochemical function.\nPotassium levels influence multiple physiological processes, including\nHomeostasis.\nPotassium homeostasis denotes the maintenance of the total body potassium content, plasma potassium level, and the ratio of the intracellular to extracellular potassium concentrations within narrow limits, in the face of pulsatile intake (meals), obligatory renal excretion, and shifts between intracellular and extracellular compartments.\nPlasma levels.\nPlasma potassium is normally kept at 3.5 to 5.5 millimoles (mmol) [or milliequivalents (mEq)] per liter by multiple mechanisms. Levels outside this range are associated with an increasing rate of death from multiple causes. Some cardiac, kidney, and lung diseases progress more rapidly if serum potassium levels are not maintained within the normal range.\nAn average meal of 40\u201350mmol presents the body with more potassium than is present in all plasma (20\u201325mmol). This surge causes the plasma potassium to rise up to 10% before clearance by renal and extrarenal mechanisms.\nHypokalemia, a deficiency of potassium in the plasma, can be fatal if severe. Common causes are increased gastrointestinal loss (vomiting, diarrhea), and increased renal loss (diuresis). Deficiency symptoms include muscle weakness, paralytic ileus, ECG abnormalities, decreased reflex response; and in severe cases, respiratory paralysis, alkalosis, and cardiac arrhythmia.\nControl mechanisms.\nPotassium content in the plasma is tightly controlled by four basic mechanisms, which have various names and classifications. These are:\nCollectively, the first three are sometimes termed the \"external potassium homeostasis system\"; and the first two, the \"reactive potassium homeostasis system\".\nRenal filtration, reabsorption, and excretion.\nRenal handling of potassium is closely connected to sodium handling. Potassium is the major cation (positive ion) inside animal cells (150mmol/L, 4.8g/L), while sodium is the major cation of extracellular fluid (150mmol/L, 3.345g/L). In the kidneys, about 180liters of plasma is filtered through the glomeruli and into the renal tubules per day. This filtering involves about 600mg of sodium and 33mg of potassium. Since only 1\u201310mg of sodium and 1\u20134mg of potassium are likely to be replaced by diet, renal filtering must efficiently reabsorb the remainder from the plasma.\nSodium is reabsorbed to maintain extracellular volume, osmotic pressure, and serum sodium concentration within narrow limits. Potassium is reabsorbed to maintain serum potassium concentration within narrow limits. Sodium pumps in the renal tubules operate to reabsorb sodium. Potassium must be conserved, but because the amount of potassium in the blood plasma is very small and the pool of potassium in the cells is about 30 times as large, the situation is not so critical for potassium. Since potassium is moved passively in counter flow to sodium in response to an apparent (but not actual) Donnan equilibrium, the urine can never sink below the concentration of potassium in serum except sometimes by actively excreting water at the end of the processing. Potassium is excreted twice and reabsorbed three times before the urine reaches the collecting tubules. At that point, urine usually has about the same potassium concentration as plasma. At the end of the processing, potassium is secreted one more time if the serum levels are too high.\nWith no potassium intake, it is excreted at about 200mg per day until, in about a week, potassium in the serum declines to a mildly deficient level of 3.0\u20133.5mmol/L. If potassium is still withheld, the concentration continues to fall until a severe deficiency causes eventual death.\nThe potassium moves passively through pores in the cell membrane. When ions move through ion transporters (pumps) there is a gate in the pumps on both sides of the cell membrane and only one gate can be open at once. As a result, approximately 100 ions are forced through per second. Ion channels have only one gate, and there only one kind of ion can stream through, at 10 million to 100 million ions per second. Calcium is required to open the pores, although calcium may work in reverse by blocking at least one of the pores. Carbonyl groups inside the pore on the amino acids mimic the water hydration that takes place in water solution by the nature of the electrostatic charges on four carbonyl groups inside the pore.\nNutrition.\nDietary recommendations.\nNorth America.\nThe U.S. National Academy of Medicine (NAM), on behalf of both the U.S. and Canada, sets Dietary Reference Intakes, including Estimated Average Requirements (EARs) and Recommended Dietary Allowances (RDAs), or Adequate Intakes (AIs) for when there is not sufficient information to set EARs and RDAs.\nFor both males and females under 9 years of age, the AIs for potassium are: 400mg of potassium for 0 to 6-month-old infants, 860mg of potassium for 7 to 12-month-old infants, 2,000mg of potassium for 1 to 3-year-old children, and 2,300mg of potassium for 4 to 8-year-old children.\nFor males 9 years of age and older, the AIs for potassium are: 2,500mg of potassium for 9 to 13-year-old males, 3,000mg of potassium for 14 to 18-year-old males, and 3,400mg for males that are 19 years of age and older.\nFor females 9 years of age and older, the AIs for potassium are: 2,300mg of potassium for 9 to 18-year-old females, and 2,600mg of potassium for females that are 19 years of age and older.\nFor pregnant and lactating females, the AIs for potassium are: 2,600mg of potassium for 14 to 18-year-old pregnant females, 2,900mg for pregnant females that are 19 years of age and older; furthermore, 2,500mg of potassium for 14 to 18-year-old lactating females, and 2,800mg for lactating females that are 19 years of age and older. As for safety, the NAM also sets tolerable upper intake levels (ULs) for vitamins and minerals, but for potassium the evidence was insufficient, so no UL was established.\nAs of 2004, most Americans adults consume less than 3,000mg.\nEurope.\nLikewise, in the European Union, in particular in Germany, and Italy, insufficient potassium intake is somewhat common. \nThe National Health Service in the United Kingdom recommends a similar intake, saying that \"adults (19 to 64 years) need per day\" and that excess amounts may cause health problems such as stomach pain and diarrhea.\nFood sources.\nPotassium is present in all fruits, vegetables, meat and fish. Foods with high potassium concentrations include yam, parsley, dried apricots, milk, chocolate, all nuts (especially almonds and pistachios), potatoes, bamboo shoots, bananas, avocados, coconut water, soybeans, and bran.\nThe United States Department of Agriculture also lists tomato paste, orange juice, beet greens, white beans, plantains, and many other dietary sources of potassium, ranked in descending order according to potassium content. A day's worth of potassium is in 5 plantains or 11 bananas.\nDeficient intake.\nAlthough mild hypokalemia does not cause distinct symptoms, it is a risk factor for hypertension and cardiac arrhythmia.\nSevere hypokalemia usually presents with hypertension, arrhythmia, muscle cramps, fatigue, weakness and constipation.\nCauses of hypokalemia include vomiting, diarrhea, medications like furosemide and steroids, kidney dialysis, diabetes insipidus, hyperaldosteronism, and hypomagnesemia.\nSupplementation.\nSupplements of potassium are most widely used in conjunction with diuretics that block reabsorption of sodium and water upstream from the distal tubule (thiazides and loop diuretics), because this promotes increased distal tubular potassium secretion, with resultant increased potassium excretion. A variety of prescription and over-the counter supplements are available. Potassium chloride may be dissolved in water, but the salty/bitter taste makes liquid supplements unpalatable. Potassium is also available in tablets or capsules, which are formulated to allow potassium to leach slowly out of a matrix, since very high concentrations of potassium ion that occur adjacent to a solid tablet can injure the gastric or intestinal mucosa. For this reason, non-prescription potassium pills are limited by law in the US to a maximum of 99mg of potassium.\nPotassium supplementation can also be combined with other metabolites, such as citrate or chloride, to achieve specific clinical effects.\nPotassium supplements may be employed to mitigate the impact of hypertension, thereby reducing cardiovascular risk. Potassium chloride and potassium bicarbonate may be useful to control mild hypertension. In 2020, potassium was the 33rd most commonly prescribed medication in the U.S., with more than 17million prescriptions. Potassium supplementation has been shown to reduce both systolic and diastolic blood pressure in individuals with essential hypertension.\nAdditionally, potassium supplements may be employed with the aim of preventing the formation of kidney stones, a condition that can lead to renal complications if left untreated. Low potassium levels can lead to decreased calcium reabsorption in the kidneys, increasing the risk of elevated urine calcium and the formation of kidney stones. By maintaining adequate potassium levels, this risk can be reduced. \nThe mechanism of action of potassium involves various types of transporters and channels that facilitate its movement across cell membranes. This process can lead to an increase in the pumping of hydrogen ions. This, in turn, can escalate the production of gastric acid, potentially contributing to the development of gastric ulcers. \nPotassium has a role in bone health. It contributes to the acid-base equilibrium in the body and helps protect bone tissue. Potassium salts produce an alkaline component that can aid in maintaining bone health.\nFor individuals with diabetes, potassium supplementation may be necessary, particularly for those with type 2 diabetes. Potassium is essential for the secretion of insulin by pancreatic beta cells, which helps regulate glucose levels. Without sufficient potassium, insulin secretion is compromised, leading to hyperglycemia and worsening diabetes.\nExcessive potassium intake can have adverse effects, such as gastrointestinal discomfort and disturbances in heart rhythm.\nPotassium supplementation can have side effects on ulceration, particularly in relation to peptic ulcer disease. Potassium channels have the potential to increase gastric acid secretion, which can lead to an increased risk of ulcerations. Medications used for peptic ulcer disease, known as \"proton pump inhibitors\", work by inhibiting potassium pumps that activate the H/K ATPase. This inhibition helps to reduce the secretion of hydrochloric acid into the parietal cell, thereby decreasing acidic synthesis and lowering the risk of ulcers. Nicorandil, a drug used for the treatment of ischemic heart disease, can stimulate nitrate and potassium ATP channels, and as a result, it has been associated with side effects such as GI, oral, and anal ulcers. Potassium chloride tablets are specifically associated with pill esophagitis. Prolonged and chronic use of potassium supplements has been linked to more severe side effects, including ulcers outside of the gastrointestinal (GI) tract. Close monitoring is necessary for patients who are also taking angiotensinogen-converting enzyme inhibitors, angiotensin receptor blockers, or potassium-sparing diuretics.\nDetection by taste buds.\nPotassium can be detected by taste because it triggers three of the five types of taste sensations, according to concentration. Dilute solutions of potassium ions taste sweet, allowing moderate concentrations in milk and juices, while higher concentrations become increasingly bitter/alkaline, and finally also salty to the taste. The combined bitterness and saltiness of high-potassium solutions makes high-dose potassium supplementation by liquid drinks a palatability challenge. As a food additive, potassium chloride has a salty taste. People wishing to increase their potassium intake or to decrease their sodium intake, after checking with a health professional that it is safe to do so, can substitute potassium chloride for some or all of the sodium chloride (table salt) used in cooking and at the table.\nPrecautions.\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nPotassium metal can react violently with water producing KOH and hydrogen gas.\nThis reaction is exothermic and releases sufficient heat to ignite the resulting hydrogen in the presence of oxygen. Finely powdered potassium ignites in air at room temperature. The bulk metal ignites in air if heated. Because its density is 0.89g/cm3, burning potassium floats in water that exposes it to atmospheric oxygen. Many common fire extinguishing agents, including water, either are ineffective or make a potassium fire worse. Nitrogen, argon, sodium chloride (table salt), sodium carbonate (soda ash), and silicon dioxide (sand) are effective if they are dry. Some Class D dry powder extinguishers designed for metal fires are also effective. These agents deprive the fire of oxygen and cool the potassium metal.\nDuring storage, potassium forms peroxides and superoxides. These peroxides may react violently with organic compounds such as oils. Both peroxides and superoxides may react explosively with metallic potassium.\nBecause potassium reacts with water vapor in the air, it is usually stored under anhydrous mineral oil or kerosene. Unlike lithium and sodium, potassium should not be stored under oil for longer than six months, unless in an inert (oxygen-free) atmosphere, or under vacuum. After prolonged storage in air dangerous shock-sensitive peroxides can form on the metal and under the lid of the container, and can detonate upon opening.\nIngestion of large amounts of potassium compounds, certain drugs, and homeostatic failure, can lead to hyperkalemia, leading to a variety of brady- and tachy-arrhythmias that can be fatal. Potassium chloride is used in the U.S. for lethal injection executions.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23056", "revid": "44458350", "url": "https://en.wikipedia.org/wiki?curid=23056", "title": "Pope", "text": "Head of the Catholic Church\nThe pope is the bishop of Rome and the head of the worldwide Catholic Church. He is also known as the supreme pontiff, Roman pontiff, or sovereign pontiff. From the 8th century until 1870, the pope was the sovereign or head of state of the Papal States, and since 1929 of the much smaller Vatican City State. From a Catholic viewpoint, the primacy of the bishop of Rome is largely derived from his role as the apostolic successor to Saint Peter, to whom primacy was conferred by Jesus, who gave Peter the Keys of Heaven and the powers of \"binding and loosing\", naming him as the \"rock\" upon which the Church would be built. The current pope is Leo XIV, who was elected on 8 May 2025 on the second day of the 2025 papal conclave.\nWhile his office is called the papacy, the jurisdiction of the episcopal see is called the Holy See. The word \"see\" comes from the Latin for 'seat' or 'chair' (, referring in particular to the one on which the newly elected pope sits during the enthronement ceremony). The Holy See is a sovereign entity under international law; it is headquartered in the distinctively independent Vatican City, a city-state which forms a geographical enclave within the conurbation of Rome. It was established by the Lateran Treaty in 1929 between Fascist Italy and the Holy See to ensure its political and spiritual independence. The Holy See is recognized by its adherence at various levels to international organizations and by means of its diplomatic relations and political accords with many independent states.\nAccording to Catholic tradition, the apostolic see of Rome was founded by Saint Peter and Saint Paul in the first century. The papacy is one of the most enduring institutions in the world and has had a prominent part in human history. In ancient times, the popes helped spread Christianity and intervened to find resolutions in various doctrinal disputes. In the Middle Ages, they played a role of secular importance in Western Europe, often acting as arbitrators between Christian monarchs. In addition to the expansion of Christian faith and doctrine, modern popes are involved in ecumenism and interfaith dialogue, charitable work, and the defence of human rights.\nOver time, the papacy accrued broad secular and political influence, eventually rivalling those of territorial rulers. In recent centuries, the temporal authority of the papacy has declined and the office is now largely focused on religious matters. By contrast, papal claims of spiritual authority have been increasingly firmly expressed over time, culminating in 1870 with the proclamation of the dogma of papal infallibility for rare occasions when the pope speaks \u2014literally 'from the chair (of Saint Peter)'\u2014to issue a formal definition of faith or morals. The pope is considered one of the world's most powerful people due to the extensive diplomatic, cultural, and spiritual influence of his position on both 1.3billion Catholics and those outside the Catholic faith, and because he heads the world's largest non-government provider of education and health care, with a vast network of charities.\nHistory.\nTitle and etymology.\nThe word \"pope\" derives from grc \" \"\" (p\u00e1ppas)\"\u00a0'father'. In the early centuries of Christianity, this title was applied, especially in the East, to all bishops and other senior clergy, and later became reserved in the West to the bishop of Rome during the reign of Pope Leo I (440\u2013461), a reservation made official only in the 11th century. The earliest record of the use of the title of 'pope' was in regard to the by-then-deceased patriarch of Alexandria, Heraclas (232\u2013248). The earliest recorded use of the title \"pope\" in English dates to the mid-10th century, when it was used in reference to the 7th century Roman Pope Vitalian in an Old English translation of Bede's .\nPosition within the Church.\nThe Catholic Church teaches that the pastoral office, the office of shepherding the Church, that was held by the apostles, as a group or \"college\" with Saint Peter as their head, is now held by their successors, the bishops, with the bishop of Rome (the pope) as their head. This gives rise to another title by which the pope is known: \"supreme pontiff\". The Catholic Church teaches that Jesus personally appointed Peter as the visible head of the Church, and the Catholic Church's dogmatic constitution makes a clear distinction between apostles and bishops, presenting the latter as the successors of the former, with the pope as successor of Peter, in that he is head of the bishops as Peter was head of the apostles. Some historians argue against the notion that Peter was the first bishop of Rome, noting that the episcopal see in Rome can be traced back no earlier than the 3rd century.\nThe writings of Irenaeus, a Church Father who wrote around 180 AD, reflect a belief that Peter \"founded and organized\" the Church at Rome. Moreover, Irenaeus was not the first to write of Peter's presence in the early Roman Church. The Church of Rome wrote in a letter to the Corinthians (which is traditionally attributed to Clement of Rome c.\u200996) about the persecution of Christians in Rome as the \"struggles in our time\" and presented to the Corinthians its heroes, \"first, the greatest and most just columns\", the \"good apostles\" Peter and Paul. Ignatius of Antioch wrote shortly after Clement; in his letter from the city of Smyrna to the Romans, he said he would not command them as Peter and Paul did. Given this and other evidence, such as Emperor Constantine's erection of the \"Old St. Peter's Basilica\" on the location of Saint Peter's tomb, as held and given to him by Rome's Christian community, many scholars agree that Peter was martyred in Rome under Nero, although some scholars argue that he may have been martyred in Palestine.\nAlthough open to historical debate, first-century Christian communities may have had a group of presbyter-bishops functioning as guides of their local churches. Gradually, episcopal sees were established in metropolitan areas. Antioch may have developed such a structure before Rome. In Rome, there were over time at various junctures rival claimants to be the rightful bishop, though again Irenaeus stressed the validity of one line of bishops from the time of St. Peter up to his contemporary Pope Victor I and listed them. Some writers claim that the emergence of a single bishop in Rome probably did not occur until the middle of the 2nd century. In their view, Linus, Cletus and Clement were possibly prominent presbyter-bishops, but not necessarily monarchical bishops. Documents of the 1st century and early second century indicate that the bishop of Rome had some kind of pre-eminence and prominence in the Church as a whole, as even a letter from the bishop, or patriarch, of Antioch acknowledged the bishop of Rome as \"a first among equals\", though the detail of what this meant is unclear.\nEarly Christianity (c. 30\u2013325).\nSources suggest that at first, the terms and \"presbyter\" were used interchangeably, with the consensus among scholars being that by the turn of the 1st and 2nd centuries, local congregations were led by bishops and presbyters, whose duties of office overlapped or were indistinguishable from one another. Some say that there was probably \"no single 'monarchical' bishop in Rome before the middle of the 2nd century\u00a0... and likely later.\"\nIn the early Christian era, Rome and a few other cities had claims on the leadership of worldwide Church. James the Just, known as \"the brother of the Lord\", served as head of the Jerusalem church, which is still honoured as the \"Mother Church\" in Orthodox tradition. Alexandria had been a center of Jewish learning and became a center of Christian learning. Rome had a large congregation early in the apostolic period whom Paul the Apostle addressed in his Epistle to the Romans, and according to tradition Paul was martyred there.\nDuring the 1st century of the Church (c.\u200930\u2013130), the Roman capital became recognized as a Christian center of exceptional importance. The church there, at the end of the century, wrote an epistle to the Church in Corinth intervening in a major dispute, and apologizing for not having taken action earlier. There are a few other references of that time to recognition of the authoritative primacy of the Roman See outside of Rome. In the Ravenna Document of 13 October 2007, theologians chosen by the Catholic and the Eastern Orthodox Churches stated:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Both sides agree that this canonical taxis was recognised by all in the era of the undivided Church. Further, they agree that Rome, as the Church that \"presides in love\" according to the phrase of St. Ignatius of Antioch (To the Romans, Prologue), occupied the first place in the taxis, and that the bishop of Rome was therefore the protos among the patriarchs. They disagree, however, on the interpretation of the historical evidence from this era regarding the prerogatives of the bishop of Rome as protos, a matter that was already understood in different ways in the first millennium.\u2014\u200a\nIn AD 195, Pope Victor I, in what is seen as an exercise of Roman authority over other churches, excommunicated the Quartodecimans for observing Easter on the 14th of Nisan, the date of the Jewish Passover, a tradition handed down by John the Evangelist (see Easter controversy). Celebration of Easter on a Sunday, as insisted on by the pope, is the system that has prevailed (see computus).\nNicaea to East\u2013West Schism (325\u20131054).\nThe Edict of Milan in 313 granted freedom to all religions in the Roman Empire, beginning the Peace of the Church. In 325, the First Council of Nicaea condemned Arianism, declaring trinitarianism dogmatic, and in its sixth canon recognized the special role of the Sees of Rome, Alexandria, and Antioch. Great defenders of Trinitarian faith included the popes, especially Liberius, who was exiled to Berea by Constantius II for his Trinitarian faith, Damasus I, and several other bishops.\nIn 380, the Edict of Thessalonica declared Nicene Christianity to be the state religion of the empire, with the name \"Catholic Christians\" reserved for those who accepted that faith. While the civil power in the Eastern Roman Empire controlled the church, and the patriarch of Constantinople, the capital, wielded much power, in the Western Roman Empire, the bishops of Rome were able to consolidate the influence and power they already possessed. After the fall of the Western Roman Empire, barbarian tribes were converted to Arian Christianity or Nicene Christianity; Clovis I, king of the Franks, was the first important barbarian ruler to convert to the mainstream church rather than Arianism, allying himself with the papacy. Other tribes, such as the Visigoths, later abandoned Arianism in favour of the established church.\nMiddle Ages.\nAfter the fall of the Western Roman Empire, the pope served as a source of authority and continuity. Pope Gregory I (c.\u2009540\u2013604) administered the church with strict reform. From an ancient senatorial family, Gregory worked with the stern judgement and discipline typical of ancient Roman rule. Theologically, he represents the shift from the classical to the medieval outlook; his popular writings are full of dramatic miracles, potent relics, demons, angels, ghosts, and the approaching end of the world.\nGregory's successors were largely dominated by the exarch of Ravenna, the Byzantine emperor's representative in the Italian Peninsula. These humiliations, the weakening of the Byzantine Empire in the face of the Muslim conquests, and the inability of the emperor to protect the papal estates against the Lombards, made Pope Stephen II turn from Emperor Constantine V. He appealed to the Franks to protect his lands. Pepin the Short subdued the Lombards and donated Italian land to the papacy. When Pope Leo III crowned Charlemagne (800) as emperor, he established the precedent that, in Western Europe, no man would be emperor without being crowned by a pope.\nThe low point of the papacy was 867\u20131049. This period includes the , the Crescentii era, and the Tusculan Papacy. The papacy came under the control of vying political factions. Popes were variously imprisoned, starved, killed, and deposed by force. The Counts of Tusculum made and unmade popes for fifty years. Pope John XII, the great-grandson of one such count, held orgies of debauchery in the Lateran Palace. Emperor Otto I had John accused in an ecclesiastical court, which deposed him and elected a layman as Pope Leo VIII. John mutilated the Imperial representatives in Rome and had himself reinstated as pope. Conflict between the Emperor and the papacy continued, and eventually dukes in league with the emperor were buying bishops and popes almost openly.\nIn 1049, Leo IX travelled to the major cities of Europe to deal with the church's moral problems firsthand, notably simony and clerical marriage and concubinage. With his long journey, he restored the prestige of the papacy in Northern Europe. From the 7th century, it became common for European monarchies and nobility to found churches and perform investiture or deposition of clergy in their states and fiefdoms, their personal interests causing corruption among the clergy. This practice had become common in part because the prelates and secular rulers were also often participants in public life.\nTo combat this, and other practices that had been seen as corrupting, between the years 900 and 1050, centres emerged promoting ecclesiastical reform, the most important being the Abbey of Cluny, which spread its ideals throughout Europe. This reform movement gained strength with the election of Pope Gregory VII in 1073, who adopted a series of measures in the movement known as the Gregorian Reform, in order to fight strongly against simony and the abuse of civil power and try to restore ecclesiastical discipline, including clerical celibacy.\nIn 1122, this conflict between popes and secular autocratic rulers such as the Holy Roman Emperor Henry IV and King Henry I of England, known as the Investiture controversy, was resolved by the Concordat of Worms, in which Pope Callixtus II decreed that clerics were to be invested by clerical leaders, and temporal rulers by lay investiture. Soon after, Pope Alexander III began reforms that would lead to the establishment of canon law.\nStarting at the beginning of the 7th century, Islamic conquests had succeeded in controlling much of the southern Mediterranean. This was perceived as a threat to Christianity. In 1095, the Byzantine emperor, Alexios I Komnenos, asked for military aid from Pope Urban II in the ongoing Byzantine\u2013Seljuq wars. Urban, at the council of Clermont, called the First Crusade to assist the Byzantine Empire to regain the old Christian territories, especially Jerusalem.\nEast\u2013West Schism to Reformation (1054\u20131517).\nWith the East\u2013West Schism, the Eastern Orthodox Church and the Catholic Church split definitively in 1054. This fracture was caused more by political events than by slight divergences of creed. Popes had galled the Byzantine emperors by siding with the king of the Franks, crowning a rival Roman emperor, appropriating the Exarchate of Ravenna, and driving into Greek Italy.\nIn the Middle Ages, popes struggled with monarchs over power. From 1309 to 1377, the pope resided not in Rome but in Avignon. The Avignon Papacy was notorious for greed and corruption. During this period, the pope was effectively an ally of the Kingdom of France, alienating France's enemies, such as the Kingdom of England.\nThe pope was understood to have the power to draw on the Treasury of Merit built up by the saints and by Christ, so that he could grant indulgences, reducing one's time in purgatory. The concept that a monetary fine or donation accompanied contrition, confession, and prayer eventually gave way to the common assumption that indulgences depended on a simple monetary contribution. The popes condemned misunderstandings and abuses, but were too pressed for income to exercise effective control over indulgences.\nPopes also contended with the cardinals, who sometimes attempted to assert the authority of Catholic Ecumenical Councils over the pope's. Conciliarism holds that the supreme authority of the church lies with a General Council, not with the pope. Its foundations were laid early in the 13th century, and it culminated in the 15th century with Jean Gerson as its leading spokesman. The failure of Conciliarism to gain broad acceptance after the 15th century is taken as a factor in the Protestant Reformation.\nVarious Antipopes challenged papal authority, especially during the Western Schism (1378\u20131417). It came to a close when the Council of Constance, at the high point of Concilliarism, decided among the papal claimants. The Eastern Church continued to decline with the Eastern Roman (Byzantine) Empire, undercutting Constantinople's claim to equality with Rome. Twice an Eastern emperor tried to force the Eastern Church to reunify with the West. First in the Second Council of Lyon (1272\u20131274) and secondly in the Council of Florence (1431\u20131449). Papal claims of superiority were a sticking point in reunification, which failed in any event. In the 15th century, the Ottoman Empire captured Constantinople and ended the Byzantine Empire.\nReformation to present (1517 to today).\nProtestant Reformers criticized the papacy as corrupt and characterized the pope as the antichrist. Popes instituted a Catholic Reformation (1560\u20131648), which addressed the challenges of the Protestant Reformation and instituted internal reforms. Pope Paul III initiated the Council of Trent (1545\u20131563), whose definitions of doctrine and whose reforms sealed the triumph of the papacy over elements in the church that sought conciliation with Protestants and opposed papal claims.\nGradually forced to give up secular power to the increasingly assertive European nation states, the popes focused on spiritual issues. In 1870, the First Vatican Council proclaimed the dogma of papal infallibility for the most solemn occasions when the pope speaks when issuing a definition of faith or morals. Later the same year, Victor Emmanuel II of Italy seized Rome from the pope's control and substantially completed the unification of Italy.\nIn 1929, the Lateran Treaty between the Kingdom of Italy and the Holy See established Vatican City as an independent city-state, guaranteeing papal independence from secular rule. In 1950, Pope Pius XII defined the Assumption of Mary as dogma, the only time a pope has spoken since papal infallibility was explicitly declared. The Primacy of St. Peter, the controversial doctrinal basis of the pope's authority, continues to divide the eastern and western churches and to separate Protestants from Rome.\nEarly Christian mentions.\nChurch Fathers.\nThe writings of several Early Church fathers contain references to the authority and unique position held by the bishops of Rome, providing valuable insight into the recognition and significance of the papacy during the early Christian era. These sources attest to the acknowledgement of the bishop of Rome as an influential figure within the Church, with some emphasizing the importance of adherence to Rome's teachings and decisions. Such references served to establish the concept of papal primacy and have continued to inform Catholic theology and practice.\nIn his letters, Cyprian of Carthage (c.\u00a0210\u00a0\u2013 258\u00a0AD) recognized the bishop of Rome as the successor of St. Peter in his \"Letter 55\" (c.\u00a0251\u00a0AD), which is addressed to Pope Cornelius, and affirmed his unique authority in the early Christian Church.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; Cornelius [the Bishop of Rome] was made bishop by the choice of God and of His Christ, by the favorable witness of almost all the clergy, by the votes of the people who were present, and by the assembly of ancient priests and good men. And he was made bishop when no one else had been made bishop before him when the position of Fabian, that is to say, the position of Peter and the office of the bishop's chair, was vacant. But the position once has been filled by the will of God and that appointment has been ratified by the consent of us all, if anyone wants to be made bishop after that, it has to be done outside the church; if a man does not uphold the unity of the Church's unity, it is not possible for him to have the Church's ordination.\nIrenaeus of Lyons (c.\u00a0130\u00a0\u2013 c.\u00a0202\u00a0AD), a prominent Christian theologian of the second century, provided a list of early popes in his work \"Against Heresies III\". The list covers the period from Saint Peter to Pope Eleutherius who served from 174 to 189 AD.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; The blessed apostles [Peter and Paul], then, having founded and built up the Church [in Rome], committed into the hands of Linus the office of the episcopate. Of this Linus, Paul makes mention in the Epistles to Timothy. To him succeeded Anacletus; and after him, in the third place from the apostles, Clement was allotted the bishopric... To this Clement there succeeded Eviristus. Alexander followed Evaristus; then, sixth from the apostles, Sixtus was appointed; after him, Telephorus, who was gloriously martyred; then Hyginus; after him, Pius; then after him, Anicetus. Soter having succeeded Anicetus, Eleutherius does now, in the twelfth place from the apostles, hold the inheritance of the episcopate.\nIgnatius of Antioch (died c. 108/140 AD) wrote in his \"Epistle to the Romans\" that the church in Rome is \"the church that presides over love\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...the Church which is beloved and enlightened by the will of Him that wills all things which are according to the love of Jesus Christ our God, which also presides in the place of the region of the Romans, worthy of God, worthy of honour, worthy of the highest happiness, worthy of praise, worthy of obtaining her every desire, worthy of being deemed holy, and which presides over love, is named from Christ, and from the Father, which I also salute in the name of Jesus Christ, the Son of the Father: to those who are united, both according to the flesh and spirit, to every one of His commandments;\u2014\u200a\nAugustine of Hippo (354\u2013430), in his Letter 53, wrote a list of 38 popes from Saint Peter to Siricius. The order of this list differs from the lists of Irenaeus and the Annuario Pontificio. Augustine's list claims that Linus was succeeded by Clement and Clement was succeeded by Anacletus as in the list of Eusebius, while the other two lists switch the positions of Clement and Anacletus.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For if the lineal succession of bishops is to be taken into account, with how much more certainty and benefit to the Church do we reckon back till we reach Peter himself, to whom, as bearing in a figure the whole Church, the Lord said: Upon this rock will I build my Church, and the gates of hell shall not prevail against it! Matthew 16:18. The successor of Peter was Linus, and his successors in unbroken continuity were these:\u2014 Clement, Anacletus, Evaristus...\u2014\u200a\nOther early Christian mentions.\nEusebius (c. 260/265 \u2013 339) mentions Linus as Saint Peter's successor and Clement as the third bishop of Rome in his book \"Church History.\" As recorded by Eusebius, Clement worked with Saint Paul as his \"co-laborer\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; As to the rest of his followers, Paul testifies that Crescens was sent to Gaul; but Linus, whom he mentions in the Second Epistle to Timothy as his companion at Rome, was Peter's successor in the episcopate of the church there, as has already been shown.\nClement also, who was appointed third bishop of the church at Rome, was, as Paul testifies, his co-laborer and fellow-soldier.\n\u2014\u200aTertullian (c. 155 \u2013 c. 220 AD) wrote in his work \"The Prescription Against Heretics\" about the authority of the church in Rome. In this work, Tertullian said that the Church in Rome has the authority of the Apostles because of its apostolic foundation.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Since, moreover, you are close upon Italy, you have Rome, from which there comes even into our own hands the very authority (of apostles themselves). How happy is its church, on which apostles poured forth all their doctrine along with their blood! Where Peter endures a passion like his Lord's! Where Paul wins his crown in a death like John's where the Apostle John was first plunged, unhurt, into boiling oil, and thence remitted to his island-exile!\u2014\u200a\nAccording to the same book, Clement of Rome was ordained by Saint Peter as the bishop of Rome.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For this is the manner in which the apostolic churches transmit their registers: as the church of Smyrna, which records that Polycarp was placed therein by John; as also the church of Rome, which makes Clement to have been ordained in like manner by Peter.\u2014\u200a\nOptatus the bishop of Milevis in Numidia (today's Algeria) and a contemporary of the Donatist schism, presents a detailed analysis of the origins, beliefs, and practices of the Donatists, as well as the events and debates surrounding the schism, in his book \"The Schism of the Donatists\" (367 A.D)\".\" In the book, Optatus wrote about the position of the bishop of Rome in maintaining the unity of the Church.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;You cannot deny that you are aware that in the city of Rome the episcopal chair was given first to Peter; the chair in which Peter sat, the same who was head\u2014that is why he is also called Cephas ['Rock']\u2014of all the apostles; the one chair in which unity is maintained by all.\u2014\u200a\nSaint Peter and the origin of the papal office.\nThe Catholic Church teaches that, within the Christian community, the bishops as a body has succeeded the apostles as a body (\"apostolic succession\") and the bishop of Rome has succeeded Saint Peter. Scriptural texts proposed in support of Peter's special position in relation to the church include:\nThe symbolic keys in the Papal coats of arms are a reference to the phrase \"the keys of the kingdom of heaven\" in the first of these texts. Some Protestant writers have maintained that the \"rock\" that Jesus speaks of in this text is Jesus himself or the faith expressed by Peter. This idea is undermined by the Biblical usage of \"Cephas\", which is the masculine form of \"rock\" in Aramaic, to describe Peter. The \"Encyclop\u00e6dia Britannica\" comments that \"the consensus of the great majority of scholars today is that the most obvious and traditional understanding should be construed, namely, that rock refers to the person of Peter\".\nNew Eliakim.\nAccording to the Catholic Church, the pope is also the new Eliakim, a figure in the Old Testament of the Bible who directed the affairs of the royal court, managed the palace staff, and handled state affairs. Isaiah also describes him as having the key to the house of David, which symbolizes his authority and power.\nBoth Matthew 16:18\u201319 and Isaiah 22:22 show similarities between Eliakim and Peter getting keys which symbolize power. Eliakim gets the power to close and open, while Peter gets the power to bind and loose. According to the Book of Isaiah, Eliakim receives the keys and power to close and open.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I will place the key of the House of David on his shoulder; what he opens, no one will shut, what he shuts, no one will open.\u2014\u200a\nAccording to the book of Matthew, Peter also gets keys and power to bind and loose.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I will give you the keys of the kingdom of heaven, and whatever you bind on earth shall be bound in heaven, and whatever you loose on earth shall be loosed in heaven.\u2014\u200a\nIn the Books of Isaiah 22:3 and Matthew 16:18, both Eliakim and Peter are compared to an object. Eliakim to a peg (a structure that is driven into a wall or other structure to provide support and stability) while Peter to a rock.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;And I will fasten him like a peg in a secure place, and he will become a throne of honor to his father's house.\u2014\u200a\nIn Matthew 16:18 Peter was compared to a rock.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;And I tell you, you are Peter, and on this rock I will build my church, and the gates of hell shall not prevail against it\u2014\u200a\nElection, death, and resignation.\nElection.\nThe pope was originally chosen by those senior clergymen resident in and near Rome. In 1059, the electorate was restricted to the cardinals of the Holy Roman Church, and the individual votes of all cardinal electors were made equal in 1179. The electors are now limited to those cardinals who have not reached the age of 80 on the day before the death or resignation of a pope. The pope does not need to be a cardinal elector nor indeed even a cardinal; since the pope is the bishop of Rome, only one who can be ordained a bishop can be elected, which means that any male baptized Catholic is eligible. The last to be elected when not yet a bishop was Gregory XVI in 1831, the last to be elected when not even a priest was Leo X in 1513, and the last to be elected when not a cardinal was Urban VI in 1378. If someone who is not a bishop is elected, he must be given episcopal ordination before the election is announced to the people.\nThe Second Council of Lyon was convened on 7 May 1274, to regulate the election of the pope. It was decreed at this council that the cardinal electors must meet within ten days of the pope's death, and that they must remain in seclusion until a pope has been elected; this was prompted by the three-year \"sede vacante\" following the death of Clement IV in 1268. By the mid-16th century, the electoral process had evolved into its present form, allowing for variation in the time between the death of the pope and the meeting of the cardinal electors. Traditionally, the vote was conducted by acclamation, by selection (by committee), or by plenary vote. Acclamation was the simplest procedure, consisting entirely of a voice vote.\nSince 1878, the election of the pope has taken place in the Sistine Chapel, in a sequestered meeting called a \"conclave\" (so called because the cardinal electors are theoretically locked in, \"cum clave\", i.e., with key, until they elect a new pope). Three cardinals are chosen by lot to collect the votes of absent cardinal electors (by reason of illness), three are chosen by lot to count the votes, and three are chosen by lot to review the count of the votes. The ballots are distributed and each cardinal elector writes the name of his choice on it and pledges aloud that he is voting for \"one whom under God I think ought to be elected\" before folding and depositing his vote on a plate atop a large chalice placed on the altar.\nFor the 2005 papal conclave, a special urn was used for this purpose instead of a chalice and plate. The plate is then used to drop the ballot into the chalice, making it difficult for electors to insert multiple ballots. Before being read, the ballots are counted while still folded; if the number of ballots does not match the number of electors, the ballots are burned unopened and a new vote is held. Otherwise, each ballot is read aloud by the presiding cardinal, who pierces the ballot with a needle and thread, stringing all the ballots together and tying the ends of the thread to ensure accuracy and honesty. Balloting continues until someone is elected by a two-thirds majority. With the promulgation of \"\" in 1996, a simple majority after a deadlock of twelve days was allowed, but this was revoked by Pope Benedict XVI by in 2007.\nThe dean of the College of Cardinals then asks two solemn questions of the man who has been elected. First he asks, \"Do you freely accept your election as supreme pontiff?\" If the pope-elect replies with the word \"Accepto\", his reign begins at that instant. In practice, any cardinal who intends not to accept will explicitly state this \"before\" he receives a sufficient number of votes to become pope. The dean asks next, \"By what name shall you be called?\" The new pope announces the regnal name he has chosen. If the dean of the college himself is elected pope, as was the case in the 2005 conclave with the election of Pope Benedict XVI, the vice dean performs this task.\nThe new pope is led to the Room of Tears, a dressing room where three sets of white papal vestments (\"immantatio\") await in three sizes. Donning the appropriate vestments and reemerging into the Sistine Chapel, the new pope is given the \"Fisherman's Ring\" by the camerlengo of the Holy Roman Church. The pope assumes a place of honour as the rest of the cardinals wait in turn to offer their first \"obedience\" (\"adoratio\") and to receive his blessing.\nOne of the most prominent aspects of the papal election process is the means by which the results of each round of voting are announced to the world. Once the ballot papers are counted and bound together, they are burned in a special stove erected in the Sistine Chapel, with the smoke escaping through a small chimney visible from Saint Peter's Square. The ballots from an unsuccessful vote are burned along with a chemical compound to create black smoke, or . Traditionally, wet straw was used to produce the black smoke, but this was not completely reliable; the chemical compound is more reliable than the straw. When a vote is successful, the ballots are burned alone, sending white smoke () through the chimney and announcing to the world the election of a new pope. Starting with the papal conclave of 2005, church bells are also rung as a signal that a new pope has been chosen.\nA short time later, the cardinal protodeacon announces from a balcony over St. Peter's Square the following proclamation: \"Annuntio vobis gaudium magnum! Habemus Papam!\" (\"I announce to you a great joy! We have a pope!\"). He announces the new pope's Christian name along with his newly-chosen regnal or papal name.\nUntil 1978, the pope's election was followed in a few days by the papal coronation, which started with a procession with great pomp and circumstance from the Sistine Chapel to St. Peter's Basilica, with the newly elected pope borne in the \"sedia gestatoria\" (a carried papal throne). After a solemn Papal Mass, the new pope was crowned with the \"triregnum\" (papal tiara) and he gave for the first time as pope the famous blessing \"Urbi et Orbi\" (\"to the City [Rome] and to the World\"). Another renowned part of the coronation was the lighting of a bundle of flax at the top of a gilded pole, which would flare brightly for a moment and then promptly extinguish, as he said, \"Sic transit gloria mundi\" (\"Thus passes worldly glory\"). A similar warning against papal hubris made on this occasion was the traditional exclamation, \"Annos Petri non-videbis\", reminding the newly crowned pope that he would not live to see his rule lasting as long as that of St. Peter. According to tradition, Peter headed the church for 35 years, and has thus far been the longest-reigning pope in the history of the Catholic Church. Nowadays, the newly elected pope celebrates a special mass to inaugurate his papacy, with many tens of thousands of catholic laity, church clerics and religious, and delegations from many nations and other churches across the world, in St Peter's Square.\nFor centuries, starting from 1378 onwards, those elected to the papacy were predominantly Italians. Prior to the election of the Polish-born John Paul II in 1978, the last non-Italian was Adrian VI of the Netherlands, elected in 1522. John Paul II was followed by election of the German-born Benedict XVI, who was in turn followed by Argentine-born Francis, the first non-European after 1272 years and the first Latin American (albeit of Italian ancestry). The most recent election, of Pope Leo XIV (formerly Robert Francis Cardinal Prevost), continues this new tradition of papal selection from a global pool: the current pope was born and lived until his mid-20s in the United States, is a citizen by naturalization of Peru (where he served as an Augustinian priest and bishop for approximately 20 years), and had by the time of his election spent almost 20 years in Italy and the Vatican studying and in various Church leadership roles.\nDeath.\nThe current regulations regarding a papal interregnum\u2014that is, a (\"vacant seat\", literally 'while the see is vacant')\u2014were promulgated by Pope John Paul II in his 1996 document \"\". is a papal interregnum, the period between the death or resignation of a pope and the election of his successor. From this term is derived the term sedevacantism, which designates a category of dissident Catholics who maintain that there is no canonically and legitimately elected pope, and that there is therefore a \"sede vacante\".\nDuring the \"sede vacante\" period, the College of Cardinals is collectively responsible for the government of the Church and of the Vatican itself, under the direction of the Camerlengo of the Holy Roman Church. Canon law specifically forbids the cardinals from introducing any innovation in the government of the Church during the vacancy of the Holy See. Any decision that requires the assent of the pope has to wait until the new pope has been elected and accepts office.\nIn recent centuries, when a pope was judged to have died, it was reportedly traditional for the cardinal camerlengo to confirm the death ceremonially by gently tapping the pope's head thrice with a silver hammer, calling his birth name each time. This was not done on the deaths of popes John Paul I and John Paul II. The cardinal camerlengo retrieves the Ring of the Fisherman and cuts it in two in the presence of the cardinals. The pope's seals are defaced, to keep them from ever being used again, and his personal apartment is sealed.\nThe body lies in state for several days before being interred in the crypt of a leading church or cathedral; all popes who have died in the 20th and 21st centuries have been interred in St. Peter's Basilica, with the exception of Pope Francis as he requested to be interred in the Basilica of St. Mary Major. A nine-day period of mourning (\"novendialis\") follows the interment.\nResignation.\nIt is highly unusual for a pope to resign. The 1983 Code of Canon Law states, \"If it happens that the Roman Pontiff resigns his office, it is required for validity that the resignation is made freely and properly manifested but not that it is accepted by anyone.\" Benedict XVI, who vacated the Holy See on 28 February 2013, was the most recent to do so, and the first since Gregory XII's resignation in 1415.\nTitles.\nRegnal name.\nPopes adopt a new name on their accession, known as papal name, in Italian and Latin. Currently, after a new pope is elected and accepts the election, he is asked, \"By what name shall you be called?\" The new pope chooses the name by which he will be known from that point on. The senior cardinal deacon, or cardinal protodeacon, then appears on the balcony of Saint Peter's to proclaim the new pope by his birth name, and announce his papal name in Latin. It is customary when referring to popes to translate the regnal name into all local languages. For example, the current pope bears the papal name \"Papa Leo XIV\" in Latin, \"Papa Leone XIV\" in Italian, \"Papa Le\u00f3n XIV\" in Spanish, \"Pope Leo XIV\" in English, etc.\nThe pope's regnal name is not his real or legal name, which remains unchanged in legal and governmental documents; neither is it connected in any way to his real name. The current pope was born with the name Robert Francis Prevost.\nOfficial list of titles.\nThe official list of titles of the pope, in the order in which they are given in the \"Annuario Pontificio\", is:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; Bishop of Rome, Vicar of Jesus Christ, Successor of the Prince of the Apostles, Supreme Pontiff of the Universal Church, Patriarch of the West, Primate of Italy, Archbishop and Metropolitan of the Roman Province, Sovereign of the Vatican City State, Servant of the servants of God.\nThe best-known title, that of \"pope\", does not appear in the official list, but is commonly used in the titles of documents, and appears, in abbreviated form, in their signatures. Thus Paul VI signed as \"Paulus PP. VI.\" Sources are divided on the meaning of \"PP.,\" with some asserting that it is merely a reference to \"papa\" (\"pope\"), others \"papa pontifex\" (\"pope and pontiff\"), and others \"pastor pastorum\" (\"shepherd of shepherds\").\nThe title \"pope\" was from the early 3rd century an honorific designation used for \"any\" bishop in the West. In the East, it was used only for the bishop of Alexandria. Marcellinus (d. 304) is the first bishop of Rome shown in sources to have had the title \"pope\" used of him. From the 6th century, the imperial chancery of Constantinople normally reserved this designation for the bishop of Rome. From the early 6th century, it began to be confined in the West to the bishop of Rome, a practice that was firmly in place by the 11th century.\nIn Eastern Christianity, where the title \"pope\" is used also of the bishop of Alexandria, the bishop of Rome is often referred to as the \"pope of Rome\", regardless of whether the speaker or writer is in communion with Rome or not.\nVicar of Jesus Christ.\n\"Vicar of Jesus Christ\" (\"Vicarius Iesu Christi\") is one of the official titles of the pope given in the \"Annuario Pontificio\". It is commonly used in the slightly abbreviated form \"vicar of Christ\" (\"vicarius Christi\"). While it is only one of the terms with which the pope is referred to as \"vicar\", it is \"more expressive of his supreme headship of the Church on Earth, which he bears in virtue of the commission of Christ and with vicarial power derived from him\", a vicarial power believed to have been conferred on Saint Peter when Christ said to him: \"Feed my lambs...Feed my sheep\".\nThe first record of the application of this title to a bishop of Rome appears in a synod of 495 with reference to Gelasius I. But at that time, and down to the 9th century, other bishops too referred to themselves as vicars of Christ, and for another four centuries this description was sometimes used of kings and even judges, as it had been used in the 5th and 6th centuries to refer to the Byzantine emperor. Earlier still, in the 3rd century, Tertullian used \"vicar of Christ\" to refer to the Holy Spirit sent by Jesus. Its use specifically for the pope appears in the 13th century in connection with the reforms of Pope Innocent III, as can be observed already in his 1199 letter to Leo I, King of Armenia. Other historians suggest that this title was already used in this way in association with the pontificate of Eugene III (1145\u20131153).\nThis title \"vicar of Christ\" is thus not used of the pope alone and has been used of all bishops since the early centuries. The Second Vatican Council referred to all bishops as \"vicars and ambassadors of Christ\", and this description of the bishops was repeated by John Paul II in his encyclical \"Ut unum sint,\" 95. The difference is that the other bishops are vicars of Christ for their own local churches, the pope is vicar of Christ for the whole Church.\nOn at least one occasion the title \"vicar of God\" (a reference to Christ as God) was used of the pope. The title \"vicar of Peter\" (\"vicarius Petri\") is used only of the pope, not of other bishops. Variations of it include: \"Vicar of the Prince of the Apostles\" (\"Vicarius Principis Apostolorum\") and \"Vicar of the Apostolic See\" (\"Vicarius Sedis Apostolicae\"). Saint Boniface described Pope Gregory II as vicar of Peter in the oath of fealty that he took in 722. In today's Roman Missal, the description \"vicar of Peter\" is found also in the collect of the Mass for a saint who was a pope.\nSupreme pontiff.\nThe term \"pontiff\" is derived from the , which literally means \"bridge builder\" (\"pons\" + \"facere\") and which designated a member of the principal college of priests in pagan Rome. The Latin word was translated into ancient Greek variously: as , , , (hierophant), or (archiereus, high priest) The head of the college was known as the (the greatest pontiff).\nIn Christian use, \"pontifex\" appears in the Vulgate translation of the New Testament to indicate the High Priest of Israel (in the original Koine Greek, ). The term came to be applied to any Christian bishop, but since the 11th century commonly refers specifically to the bishop of Rome, who is more strictly called the \"Roman Pontiff\". The use of the term to refer to bishops in general is reflected in the terms \"Roman Pontifical\" (a book containing rites reserved for bishops, such as confirmation and ordination), and \"pontificals\" (the insignia of bishops).\nThe \"Annuario Pontificio\" lists as one of the official titles of the pope that of \"Supreme Pontiff of the Universal Church\" (). He is also commonly called the supreme pontiff or the sovereign pontiff (). \"Pontifex Maximus\", similar in meaning to \"Summus Pontifex\", is a title commonly found in inscriptions on papal buildings, paintings, statues and coins, usually abbreviated as \"Pont. Max\" or \"P.M.\" The office of Pontifex Maximus, or head of the College of Pontiffs, was held by Julius Caesar and thereafter, by the Roman emperors, until Gratian (375\u2013383) relinquished it. Tertullian, when he had become a Montanist, used the title derisively of either the pope or the bishop of Carthage. The popes began to use this title regularly only in the 15th century.\nServant of the servants of God.\nAlthough the description \"servant of the servants of God\" () was also used by other Church leaders, including Augustine of Hippo and Benedict of Nursia, it was first used extensively as a papal title by Gregory the Great, reportedly as a lesson in humility for the patriarch of Constantinople, John the Faster, who had assumed the title \"ecumenical patriarch\". It became reserved for the pope in the 12th century and is used in papal bulls and similar important papal documents.\nPatriarch of the West.\nFrom 1863 to 2005, and again in 2024, the \"Annuario Pontificio\" also included the title \"patriarch of the West\". This title was first used by Pope Theodore I in 642, and was only used occasionally. Indeed, it did not begin to appear in the pontifical yearbook until 1863. On 22 March 2006, the Vatican released a statement explaining this omission on the grounds of expressing a \"historical and theological reality\" and of \"being useful to ecumenical dialogue\". The title patriarch of the West symbolized the pope's special relationship with, and jurisdiction over, the Latin Church\u2014and the omission of the title neither symbolizes in any way a change in this relationship, nor distorts the relationship between the Holy See and the Eastern Churches, as solemnly proclaimed by the Second Vatican Council. \"Patriarch of the West\" was reintroduced to the pope's list of titles in the 2024 edition of the Annuario Pontifico. The Vatican has not made any statements explaining why the title has been brought back into use.\nOther titles.\nOther titles commonly used are \"His Holiness\" (either used alone or as an honorific prefix as in \"His Holiness Pope Leo\"; and as \"Your Holiness\" as a form of address) and \"Holy Father\". In Spanish and Italian, \"\"Beat\u00edsimo/Beatissimo Padre\" (Most Blessed Father) is often used in preference to \"Sant\u00edsimo/Santissimo Padre\" (Most Holy Father). In the medieval period, \"Dominus Apostolicus\"\" (\"the Apostolic Lord\") was also used.\nSignature.\nPope Francis signed some documents with his name alone, either in Latin (\"Franciscus\", as in an encyclical dated 29 June 2013) or in another language. Other documents he signed in accordance with the tradition of using Latin only and including the abbreviated form \"PP.\", for the Latin \"Papa\" (\"Pope\"). Popes who have an ordinal numeral in their name traditionally place the abbreviation \"PP.\" before the ordinal numeral, as in \"Leo PP. XIV\" (Pope Leo\u00a0XIV), except in papal bulls of canonization and decrees of ecumenical councils, which a pope signs with the formula, \"Ego N. Episcopus Ecclesiae catholicae\", without the numeral, as in \"Ego Leo Episcopus Ecclesiae catholicae\" (I, Leo, Bishop of the Catholic Church).\nRegalia and insignia.\nIn heraldry, each pope has his own personal coat of arms. Though unique for each pope, the arms have for several centuries been traditionally accompanied by two keys in saltire (i.e., crossed over one another so as to form an \"X\") behind the escutcheon (shield) (one silver key and one gold key, tied with a red cord), and above them a silver \"triregnum\" with three gold crowns and red \"infulae\" (lappets\u2014two strips of fabric hanging from the back of the triregnum which fall over the neck and shoulders when worn). This is blazoned: \"two keys in saltire or and argent, interlacing in the rings or, beneath a tiara argent, crowned or\".\nThe 21st century has seen departures from this tradition. In 2005, Pope Benedict XVI, while maintaining the crossed keys behind the shield, omitted the papal tiara from his personal coat of arms, replacing it with a mitre with three horizontal lines. Beneath the shield he added the pallium, a papal symbol of authority more ancient than the tiara, the use of which is also granted to metropolitan archbishops as a sign of communion with the See of Rome. Although the tiara was omitted in the pope's personal coat of arms, the coat of arms of the Holy See, which includes the tiara, remained unaltered. In 2013, Pope Francis maintained the mitre that replaced the tiara, but omitted the pallium.\nThe flag most frequently associated with the pope is the yellow and white flag of Vatican City, with the arms of the Holy See (blazoned: \"Gules, two keys in saltire or and argent, interlacing in the rings or, beneath a tiara argent, crowned or\") on the right-hand side (the \"fly\") in the white half of the flag (the left-hand side\u2014the \"hoist\"\u2014is yellow). The pope's escucheon does not appear on the flag. This flag was first adopted in 1808, whereas the previous flag had been red and gold. Although Pope Benedict XVI replaced the triregnum with a mitre on his personal coat of arms, it has been retained on the flag.\nPapal garments.\nPope Pius V (reigned 1566\u20131572), is often credited with having originated the custom whereby the pope wears white, by continuing after his election to wear the white habit of the Dominican order. In reality, the basic papal attire was white long before. The earliest document that describes it as such is the \"Ordo XIII\", a book of ceremonies compiled in about 1274. Later books of ceremonies describe the pope as wearing a red mantle, mozzetta, camauro and shoes, and a white cassock and stockings. Many contemporary portraits of 15th and 16th-century predecessors of Pius V show them wearing a white cassock similar to his.\nStatus and authority.\nFirst Vatican Council.\nThe status and authority of the pope in the Catholic Church was dogmatically defined by the First Vatican Council on 18 July 1870. In its Dogmatic Constitution of the Church of Christ, the council established the following canons:\nIf anyone says that the blessed Apostle Peter was not established by the Lord Christ as the chief of all the apostles, and the visible head of the whole militant Church, or, that the same received great honour but did not receive from the same our Lord Jesus Christ directly and immediately the primacy in true and proper jurisdiction: let him be anathema.\nIf anyone says that it is not from the institution of Christ the Lord Himself, or by divine right that the blessed Peter has perpetual successors in the primacy over the universal Church, or that the Roman Pontiff is not the successor of blessed Peter in the same primacy, let him be anathema.\nIf anyone thus speaks, that the Roman pontiff has only the office of inspection or direction, but not the full and supreme power of jurisdiction over the universal Church, not only in things which pertain to faith and morals, but also in those which pertain to the discipline and government of the Church spread over the whole world; or, that he possesses only the more important parts, but not the whole plenitude of this supreme power; or that this power of his is not ordinary and immediate, or over the churches altogether and individually, and over the pastors and the faithful altogether and individually: let him be anathema.\nWe, adhering faithfully to the tradition received from the beginning of the Christian faith, to the glory of God, our Saviour, the elevation of the Catholic religion and the salvation of Christian peoples, with the approbation of the sacred Council, teach and explain that the dogma has been divinely revealed: that the Roman Pontiff, when he speaks ex cathedra, that is, when carrying out the duty of the pastor and teacher of all Christians by his supreme apostolic authority he defines a doctrine of faith or morals to be held by the universal Church, through the divine assistance promised him in blessed Peter, operates with that infallibility with which the divine Redeemer wished that His church be instructed in defining doctrine on faith and morals; and so such definitions of the Roman Pontiff from himself, but not from the consensus of the Church, are unalterable. But if anyone presumes to contradict this definition of Ours, which may God forbid: let him be anathema.\nSecond Vatican Council.\nIn its Dogmatic Constitution on the Church (1964), the Second Vatican Council declared:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; Among the principal duties of bishops the preaching of the Gospel occupies an eminent place. For bishops are preachers of the faith, who lead new disciples to Christ, and they are authentic teachers, that is, teachers endowed with the authority of Christ, who preach to the people committed to them the faith they must believe and put into practice, and by the light of the Holy Spirit illustrate that faith. They bring forth from the treasury of Revelation new things and old, making it bear fruit and vigilantly warding off any errors that threaten their flock. Bishops, teaching in communion with the Roman Pontiff, are to be respected by all as witnesses to divine and Catholic truth. In matters of faith and morals, the bishops speak in the name of Christ and the faithful are to accept their teaching and adhere to it with a religious assent. This religious submission of mind and will must be shown in a special way to the authentic magisterium of the Roman Pontiff, even when he is not speaking ex cathedra; that is, it must be shown so that his supreme magisterium is acknowledged with reverence, the judgments made by him are sincerely adhered to, according to his manifest mind and will. His mind and will in the matter may be known either from the character of the documents, from his frequent repetition of the same doctrine, or from his manner of speaking.\n... this infallibility with which the Divine Redeemer willed His Church to be endowed in defining doctrine of faith and morals, extends as far as the deposit of Revelation extends, which must be religiously guarded and faithfully expounded. And this is the infallibility which the Roman Pontiff, the head of the College of Bishops, enjoys in virtue of his office, when, as the supreme shepherd and teacher of all the faithful, who confirms his brethren in their faith, by a definitive act he proclaims a doctrine of faith or morals. And therefore his definitions, of themselves, and not from the consent of the Church, are justly styled irreformable, since they are pronounced with the assistance of the Holy Spirit, promised to him in blessed Peter, and therefore they need no approval of others, nor do they allow an appeal to any other judgment. For then the Roman Pontiff is not pronouncing judgment as a private person, but as the supreme teacher of the universal Church, in whom the charism of infallibility of the Church itself is individually present, he is expounding or defending a doctrine of Catholic faith. The infallibility promised to the Church resides also in the body of Bishops, when that body exercises the supreme magisterium with the successor of Peter. To these definitions the assent of the Church can never be wanting, on account of the activity of that same Holy Spirit, by which the whole flock of Christ is preserved and progresses in unity of faith.\nOn 11 October 2012, on the occasion of the 50th anniversary of the opening of the Second Vatican Council 60 prominent theologians, (including Hans K\u00fcng), put out a Declaration, stating that the intention of Vatican II to balance authority in the Church has not been realized. \"Many of the key insights of Vatican II have not at all, or only partially, been implemented... A principal source of present-day stagnation lies in misunderstanding and abuse affecting the exercise of authority in our Church.\"\nPolitics and functions of the Holy See.\nResidence and jurisdiction.\nThe pope's official seat is in the Archbasilica of Saint John Lateran, considered the cathedral of the Diocese of Rome. \nThe pope's official residence is the Apostolic Palace. He also possesses a summer residence at Castel Gandolfo, situated on the site of the ancient city of Alba Longa.\nThe names \"Holy See\" and \"Apostolic See\" are ecclesiastical terminology for the ordinary jurisdiction of the bishop of Rome, including the Roman Curia. The pope's honours, powers, and privileges within the Catholic Church and the international community derive from his Episcopate of Rome in lineal succession from the Saint Peter, one of the twelve apostles.\nConsequently, Rome has traditionally occupied a central position in the Catholic Church, although this is not necessarily so. The pope derives his pontificate from being the bishop of Rome but is not required to live there. According to the Latin formula \"ubi Papa, ibi Curia\", wherever the pope resides is the central government of the Church. Between 1309 and 1378, the popes lived in Avignon, France, a period often called the \"Babylonian captivity\" in allusion to the Biblical narrative of Jews of the ancient Kingdom of Judah living as captives in Babylonia.\nSalary and benefits.\nAs of 2024, the pope's salary was \u20ac30,000 per month. Francis, a Jesuit, refused to collect a salary and donated the money to the poor. \nThe Catholic Church traditionally covers the costs of all the pope's meals, housing, apparel, transport (e.g., the Popemobile), security, housekeeping, and healthcare. The pope has free access to Vatican medical services and a private pharmacy. \nIf a pope retires, the monthly pension as of 2024 was \u20ac2,500 per month.\nPastoral care of the Diocese of Rome.\nAlthough the pope is the diocesan bishop of Rome, he delegates most of the day-to-day work of leading the diocese to the cardinal vicar, who assures direct episcopal oversight of the diocese's pastoral needs, not in his own name but in that of the pope. The most recent cardinal vicar was Angelo De Donatis, who served from 2017 until 2024. The current cardinal vicar is Baldassare Reina.\nThis does not mean that popes ignore their diocesan responsibilities. For example, when Pope John XXIII announced his intention to establish the Second Vatican Council in 1959, his reflections dealt first with the state of the Catholic Church within Rome before \"broadening his gaze to the entire world\".\nPolitical role.\nThough the progressive Christianization of the Roman Empire in the 4th century did not confer upon bishops civil authority within the state, the gradual withdrawal of imperial authority during the 5th century left the pope the senior imperial civilian official in Rome, as bishops were increasingly directing civil affairs in other cities of the Western Empire. This status as a secular and civil ruler was vividly displayed by Pope Leo I's confrontation with Attila in 452.\nThe first expansion of papal rule outside of Rome came in 728 with the Donation of Sutri. In 754, the Frankish ruler Pippin the Younger gave the pope the land from his conquest of the Lombards. The pope may have utilized the forged Donation of Constantine to gain this land, which formed the core of the Papal States. This document, accepted as genuine until the 15th century, states that Constantine the Great placed the entire Western Empire of Rome under papal rule.\nIn 800, Pope Leo III crowned the Frankish ruler Charlemagne as Roman emperor, a major step toward establishing what later became known as the Holy Roman Empire. From that date onward the popes claimed the prerogative to crown the emperor. The right fell into disuse after the coronation of Charles V in 1530. In 1804, Pius VII was present at the coronation of Napoleon I but did not actually perform the crowning. As mentioned above, the pope's sovereignty over the Papal States ended in 1870 with their annexation by Italy.\nPopes like Alexander VI, an ambitious if spectacularly corrupt politician, and Julius II, a formidable general and statesman, were not afraid to use power to achieve their own ends, which included increasing the power of the papacy. This political and temporal authority was demonstrated through the papal role in the Holy Roman Empire, especially prominent during periods of contention with the emperors, such as during the pontificates of Pope Gregory VII and Pope Alexander III.\nPapal bulls, interdict, and excommunication, or the threat thereof, have been used many times to exercise papal power. The bull \"Laudabiliter\" in 1155 authorized King Henry II of England to invade Ireland. In 1207, Innocent III placed England under interdict until King John made his kingdom a fiefdom to the pope, complete with yearly tribute, saying, \"we offer and freely yield...to our lord Pope Innocent III and his catholic successors, the whole kingdom of England and the whole kingdom of Ireland with all their rights and appurtenences for the remission of our sins\".\nThe Bull \"Inter caetera\" in 1493 led to the Treaty of Tordesillas in 1494, which divided the world into areas of Spanish and Portuguese rule. The bull \"Regnans in Excelsis\" in 1570 excommunicated Queen Elizabeth I of England and declared that all her subjects were released from allegiance to her. The bull \"Inter gravissimas\" in 1582 established the Gregorian calendar.\nIn recent decades, although the papacy has become less directly involved in politics, popes have nevertheless retained significant political influence. They have also served as mediators, with the support of the Catholic establishment. John Paul II, a native of Poland, was regarded as influential in the fall of Communism in Eastern Europe. He also mediated the Beagle conflict between Argentina and Chile, two predominantly Catholic countries. In the 21st century, Francis played a role in brokering the 2015 improvement in relations between the United States and Cuba.\nInternational position.\nUnder international law, a serving head of state has sovereign immunity from the jurisdiction of the courts of other countries, though not from that of international tribunals. This immunity is sometimes loosely referred to as \"diplomatic immunity\", which is, strictly speaking, the immunity enjoyed by the \"diplomatic representatives\" of a head of state. International law treats the Holy See, essentially the central government of the Catholic Church, as the juridical equal of a state. It is distinct from the state of Vatican City, existing for many centuries before the foundation of the latter.\nIt is common for publications and news media to use \"the Vatican\", \"Vatican City\", and even \"Rome\" as metonyms for the Holy See. Most countries of the world maintain the same form of diplomatic relations with the Holy See that they entertain with other states. Even countries without those diplomatic relations participate in international organizations of which the Holy See is a full member.\nIt is as head of the state-equivalent worldwide religious jurisdiction of the Holy See (not of the territory of Vatican City) that the U.S. Justice Department ruled that the pope enjoys head-of-state immunity. This head-of-state immunity, recognized by the United States, must be distinguished from that envisaged under the United States' Foreign Sovereign Immunities Act of 1976, which, while recognizing the basic immunity of foreign governments from being sued in American courts, lays down nine exceptions, including commercial activity and actions in the United States by agents or employees of the foreign governments. It was in relation to the latter that, in November 2008, the United States Court of Appeals in Cincinnati decided that a case over sexual abuse by Catholic priests could proceed, provided the plaintiffs could prove that the bishops accused of negligent supervision were acting as employees or agents of the Holy See and were following official Holy See policy.\nIn April 2010, there was press coverage in Britain concerning a proposed plan by atheist campaigners and a prominent barrister, Geoffrey Robertson, to have Pope Benedict XVI arrested and prosecuted in the UK for alleged offences, dating from several decades before, in failing to take appropriate action regarding Catholic sex abuse cases and concerning their disputing his immunity from prosecution in that country. This was generally dismissed as \"unrealistic and spurious\". Another barrister said that it was a \"matter of embarrassment that a senior British lawyer would want to allow himself to be associated with such a silly idea\". Sovereign immunity does not apply to disputes relating to commercial transactions, and governmental units of the Holy See can face trial in foreign commercial courts. The first such trial to take place in the English courts happened in 2024\nObjections to the papacy.\nThe pope's claim to authority is either disputed or rejected outright by other churches, for various reasons.\nOrthodox, Anglican and Old Catholic churches.\nOther traditional Christian churches (Assyrian Church of the East, the Oriental Orthodox Church, the Eastern Orthodox Church, the Old Catholic Church, the Anglican Communion, the Independent Catholic churches, etc.) accept the doctrine of Apostolic succession and, to varying extents, papal claims to a primacy of honour, while generally rejecting the pope as the successor to Peter in any other sense than that of other bishops. Primacy is regarded as a consequence of the pope's position as bishop of the original capital city of the Roman Empire, a definition spelled out in the 28th canon of the Council of Chalcedon. These churches see no foundation to papal claims of \"universal immediate jurisdiction\", or to claims of papal infallibility. Several of these churches refer to such claims as \"ultramontanism\".\nProtestant denominations.\nIn 1973, the United States Conference of Catholic Bishops' Committee on Ecumenical and Interreligious Affairs and the USA National Committee of the Lutheran World Federation in the official Catholic\u2013Lutheran dialogue included this passage in a larger statement on papal primacy:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; In calling the pope the \"Antichrist\", the early Lutherans stood in a tradition that reached back into the eleventh century. Not only dissidents and heretics but even saints had called the bishop of Rome the \"Antichrist\" when they wished to castigate his abuse of power. What Lutherans understood as a papal claim to unlimited authority over everything and everyone reminded them of the apocalyptic imagery of Daniel 11, a passage that even prior to the Reformation had been applied to the pope as the Antichrist of the last days.\nProtestant denominations of Christianity reject the claims of Petrine primacy of honour, Petrine primacy of jurisdiction, and papal infallibility. These denominations vary from rejecting the legitimacy of the pope's claim to authority, to believing that the pope is the Antichrist from 1 John 2:18, the Man of Sin from 2 Thessalonians 2:3\u201312, and the Beast out of the Earth from Revelation 13:11\u201318.\nThis sweeping rejection is held by, among others, some denominations of Lutherans: Confessional Lutherans hold that the pope is the Antichrist, stating that this article of faith is part of a \"quia\" (\"because\") rather than \"quatenus\" (\"insofar as\") subscription to the Book of Concord. In 1932, one of these Confessional churches, the Lutheran Church\u2013Missouri Synod (LCMS), adopted \"A Brief Statement of the Doctrinal Position of the Missouri Synod\", which a small number of Lutheran church bodies now hold. The Lutheran Churches of the Reformation, the Concordia Lutheran Conference, the Church of the Lutheran Confession, and the Illinois Lutheran Conference all hold to the \"Brief Statement\", which the LCMS places on its website. The Wisconsin Evangelical Lutheran Synod (WELS), another Confessional Lutheran church that declares the Papacy to be the Antichrist, released its own statement, the \"Statement on the Antichrist\", in 1959. The WELS still holds to this statement.\nHistorically, Protestants objected to the papacy's claim of temporal power over all secular governments, including territorial claims in Italy, the papacy's complex relationship with secular states such as the Roman and Byzantine empires, and the autocratic character of the papal office. In Western Christianity these objections both contributed to and are products of the Protestant Reformation.\nAntipopes.\nGroups sometimes form around antipopes, who claim the Pontificate without being canonically and properly elected to it. Traditionally, this term was reserved for claimants with a significant following of cardinals or other clergy. The existence of an antipope is usually due either to doctrinal controversy within the Church (heresy) or to confusion as to who is the legitimate pope at the time (schism). Briefly in the 15th century, three separate lines of popes claimed authenticity.\nOther uses of the title \"Pope\".\nIn the earlier centuries of Christianity, the title \"Pope\", meaning \"father\", had been used by all bishops. Some popes used the term and others did not. Eventually, the title became associated especially with the bishop of Rome. In a few cases, the term is used for other Christian clerical authorities. In English, Catholic priests are still addressed as \"father\", but the term \"pope\" is reserved for the head of the church hierarchy.\nIn the Catholic Church.\n\"Black Pope\" is a name that was popularly, but unofficially, given to the superior general of the Society of Jesus due to the Jesuits' importance within the Church. This name, based on the black colour of his cassock, was used to suggest a parallel between him and the \"White Pope\" (since in the time of Pius V the pope dressed in white) and the cardinal prefect of the Congregation for the Evangelization of Peoples (formerly called the Sacred Congregation for the Propagation of the Faith), whose red cardinal's cassock gave him the name of the \"Red Pope\" in view of the authority over all territories that were not considered in some way Catholic. In the present time this cardinal has power over mission territories for Catholicism, essentially the Churches of Africa and Asia, but in the past his competence extended also to all lands where Protestants or Eastern Christianity was dominant. Some remnants of this situation remain, with the result that, for instance, New Zealand is still in the care of this Congregation.\nIn the Eastern Churches.\nSince the papacy of Heraclas in the 3rd century, the bishop of Alexandria in both the Coptic Orthodox Church and the Greek Orthodox Church of Alexandria continues to be called \"pope\", the former being called \"Coptic pope\" or, more properly, \"Pope and Patriarch of All Africa on the Holy Orthodox and Apostolic Throne of Saint Mark the Evangelist and Holy Apostle\" and the latter called \"Pope and Patriarch of Alexandria and All Africa\".\nIn the Bulgarian Orthodox Church, Russian Orthodox Church, Serbian Orthodox Church and Macedonian Orthodox Church, it is not unusual for a village priest to be called a \"pope\" (\"\u043f\u043e\u043f\" \"pop\"). This is different from the words used for the head of the Catholic Church (Bulgarian \"\u043f\u0430\u043f\u0430\" \"papa\", Russian \"\u043f\u0430\u043f\u0430 \u0440\u0438\u043c\u0441\u043a\u0438\u0439\" \"papa rimskiy\").\nIn new religious movements and other Christian-related new religious movements.\nSome new religious movements within Christianity, especially those that have disassociated themselves from the Catholic Church yet retain a Catholic hierarchical framework, have used the designation \"pope\" for a founder or current leader. Examples include the African Legio Maria Church and the European Palmarian Catholic Church in Spain. The Cao Dai, a Vietnamese faith that duplicates the Catholic hierarchy, is similarly headed by a pope.\nLengths of papal reign.\nLongest-reigning popes.\nThe longest papal reigns of those whose reign lengths can be determined from contemporary historical data are the following:\nDuring the Western Schism, Avignon Pope Benedict XIII (1394\u20131423) ruled for 28 years, 7 months and 12 days, which would place him third in the above list. Since he is regarded as an anti-pope, he is not included there.\nShortest-reigning popes.\nThere have been a number of popes whose reign lasted about a month or less. In the following list the number of calendar days includes partial days. Thus, for example, if a pope's reign commenced on 1 August and he died on 2 August, this counts as reigning for two calendar days.\nStephen (23\u201326 March 752) died of a stroke three days after his election, and before his consecration as a bishop. He is not recognized as a valid pope, but was added to the lists of popes in the 16th century as \"Stephen II\", causing difficulties in enumerating later popes named Stephen. The Holy See's \"Annuario Pontificio\", in its list of popes and antipopes, attaches a footnote to its mention of Pope Stephen II:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; On the death of Zachary the Roman priest Stephen was elected; but, since four days later he died, before his \"consecratio\", which according to the canon law of the time was the true commencement of his pontificate, his name is not registered in the \"Liber Pontificalis\" nor in other lists of the popes.\nPublished every year by the Roman Curia, the \"Annuario Pontificio\" attaches no consecutive numbers to the popes, stating that it is impossible to decide which side represented at various times the legitimate succession, in particular regarding Pope Leo VIII, Pope Benedict V and some mid-11th-century popes.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "23059", "revid": "45397322", "url": "https://en.wikipedia.org/wiki?curid=23059", "title": "Passover", "text": "Jewish holiday\nPassover, also called Pasch () or Pesach (; ), is a major Jewish holiday and one of the Three Pilgrimage Festivals. It celebrates the Exodus of the Israelites from slavery in Egypt.\nAccording to the Book of Exodus, God commanded Moses to tell the Israelites to slaughter a lamb and mark their doorframes with its blood, in addition to instructions for consuming the lamb that night. For that night, God would send the Angel of Death to bring about the tenth plague, in which he would smite all the firstborn in Egypt. But when the angel saw the blood on the Israelites' doorframes, he would \"pass over\" their homes so that the plague should not enter (hence the name). The story is part of the broader Exodus narrative, in which the Israelites, while living in Egypt, are enslaved en masse by the Pharaoh to suppress them; when Pharaoh refuses God's demand to let them go, God sends ten plagues upon Egypt. After the tenth plague, Pharaoh permits the Israelites to leave. Scholars widely believe that the origins of Passover predate the biblical Exodus, with theories suggesting it evolved from earlier semi-nomadic or pre-Israelite rituals and was later transformed through religious and cultic traditions.\nThis story is recounted at the Passover Seder by reading the Haggadah. The Haggadah is a standardized ritual account of the Exodus story, in fulfillment of the command \"And thou shalt tell [Higgadata] thy son in that day, saying: It is because of that which the LORD did for me when I came forth out of Egypt.\" Jews are forbidden from possessing or eating leavened foods (\"chametz\") during the holiday.\nPesach starts on the 15th day of the Hebrew month of Nisan, which is considered the first month of the Hebrew year. The Rabbinical Jewish calendar is adjusted to align with the solar calendar in such a way that 15 Nisan always coincides with Sunday, Tuesday, Thursday, or Saturday. The Hebrew day starts and ends at sunset, so the holiday starts at sunset the day before. For example, in 2025, 15 Nisan coincides with Sunday, April 13. Therefore, Pesach started at sundown on Saturday, April 12, 2025.\nEtymology.\n is rendered as Tiberian , and Modern Hebrew: . The verb () is first mentioned in the Torah's account of the Exodus, and there is some debate about its exact meaning. The commonly held assumption that it means \"He passed over\" (), in reference to God \"passing over\" (or \"skipping\") the houses of the Hebrews during the final of the Ten Plagues of Egypt, stems from the translation provided in the Septuagint ( in Exodus 12:23, and in Exodus 12:27.) The Targum Onkelos, written in Jewish Babylonian Aramaic, translates as , coming from the Hebrew root , meaning \"to have pity\". Cognate languages yield similar terms with distinct meanings, such as \"make soft, soothe, placate\" (Akkadian ), \"harvest, commemoration, blow\" (Egyptian), or \"separate\" (Arabic ).\nPesach may also refer to the lamb or goat which was designated as the Passover sacrifice. Four days before the Exodus, the Hebrews were commanded to set aside a lamb, and inspect it daily for blemishes. During the day on 14th Nisan, they were to slaughter the animal and use its blood to mark their lintels and door posts. Before midnight on 15th Nisan, they were to consume the lamb.\nThe English term \"Passover\" is first known to be recorded in the English language in William Tyndale's translation of the Bible, later appearing in the King James Version as well. It is a literal translation of the Hebrew term. In the King James Version, Exodus 12:23 reads:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nOrigins and theories.\nThe Passover ritual is \"a mitzvah commanded by Torah (rather than of rabbinic origin).\"\nApotropaic ritual.\nThe Passover ritual is thought by modern scholars to have its origins in an apotropaic rite unrelated to the Exodus to ensure the protection of a family home, a rite conducted wholly within a clan. Ezov was employed to daub the blood of a slaughtered sheep on the lintels and door posts to ensure that demonic forces could not enter the home.\nBarley harvest plus Exodus narrative.\nA further hypothesis maintains that once the Priestly Code was promulgated, the Exodus narrative took on a central function, as the apotropaic rite was, arguably, amalgamated with the Canaanite agricultural festival of spring which was a ceremony of unleavened bread, connected with the barley harvest. As the Exodus motif grew, the original function and symbolism of these double origins was lost. Several motifs replicate the features associated with the Akitu spring festival of ancient Mesopotamian religion, which celebrates the sowing of\u00a0barley. Scholars John Van Seters, Judah Segal, and Tamara Pro\u0161i\u0107 disagree with the merged two-festivals hypothesis.\nBiblical narrative.\nIn the Book of Exodus.\nIn the Book of Exodus, the Israelites are enslaved in ancient Egypt. Yahweh, the god of the Israelites, appears to Moses in a burning bush and commands Moses to confront the Pharaoh. To show his power, Yahweh inflicts a series of ten plagues on the Egyptians, culminating in the plague of the death of the firstborn.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Moses said, \u201cThus says : Toward midnight I will go forth among the Egyptians, and every [male] first-born in the land of Egypt shall die, from the first-born of Pharaoh who sits on his throne to the first-born of the slave girl who is behind the millstones; and all the first-born of the cattle. And there shall be a loud cry in all the land of Egypt, such as has never been or will ever be again;\u2014\u200a\nBefore this final plague, Yahweh commands Moses to tell the Israelites to mark a lamb's blood above their doors so God will pass over them and the plague of the death of the firstborn will not afflict them.\nThe biblical regulations for the observance of the festival require that all leavening be disposed of before the beginning of the 15th of Nisan according to Exodus 13:7 An unblemished lamb or goat, known as the Passover sacrifice or \"Paschal Lamb\", is to be set apart on 10th Nisan, and slaughtered at dusk as 14th Nisan ends in preparation for the 15th of Nisan when it will be eaten after being roasted. The literal meaning of the Hebrew is \"between the two evenings\". It is then to be eaten \"that night\", 15th Nisan, roasted, without the removal of its internal organs with unleavened bread, known as matzah, and bitter herbs known as . Nothing of the sacrifice on which the sun rises by the morning of the 15th of Nisan may be eaten, but must be burned.\nThe biblical regulations of the original Passover at the time of the Exodus only also include how the meal was to be eaten: \"your loins girded, your sandals on your feet, and your staff in your hand; and you shall eat it hurriedly: it is a passover offering to .\"\nThe biblical requirements of slaying the Paschal lamb in the individual homes of the Hebrews and smearing the blood of the lamb on their doorways were celebrated in Egypt. However, once Israel was in the wilderness and the Tabernacle was in operation, a change was made in those two original requirements. Passover lambs were to be sacrificed at the door of the Tabernacle and no longer in the homes of the Jews. No longer, therefore, could blood be smeared on doorways.\nThe Passover in other biblical passages.\nCalled the \"festival [of] the unleavened bread\" () in the Hebrew Bible, the commandment to keep Passover is recorded in the Book of Leviticus:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In the first month, on the fourteenth day of the month at dusk is the LORD's Passover. And on the fifteenth day of the same month is the feast of unleavened bread unto the LORD; seven days ye shall eat unleavened bread. In the first day ye shall have a holy convocation; ye shall do no manner of servile work. And ye shall bring an offering made by fire unto the LORD seven days; in the seventh day is a holy convocation; ye shall do no manner of servile work.\u2014\u200a\nThe sacrifices may be performed only in a specific place prescribed by God. For Judaism, this is Jerusalem.\nThe biblical commandments concerning the Passover (and the Feast of Unleavened Bread) stress the importance of remembering:\nIn 2 Kings 23:21\u201323 and 2 Chronicles 35:1\u201319, King Josiah of Judah restores the celebration of the Passover, to a standard not seen since the days of the judges or the days of the prophet Samuel.\nEzra 6:19\u201321 records the celebration of the passover by the Jews who had returned from exile in Babylon, after the temple had been rebuilt.\nIn extra-biblical sources.\nSome of these details can be corroborated, and to some extent amplified, in extrabiblical sources. The removal (or \"sealing up\") of the leaven is referred to in the Elephantine papyri and ostraca in an Imperial Aramaic papyrus letter from the 5th century BCE from Elephantine, Egypt. The slaughter of the lambs on the 14th is mentioned in Jubilees, a Jewish work of the Ptolemaic period, and by the Herodian-era writers Josephus and Philo. These sources also indicate that \"between the two evenings\" was taken to mean the afternoon. Jubilees states the sacrifice was eaten that night, and together with Josephus states that nothing of the sacrifice was allowed to remain until morning. Philo states that the banquet included hymns and prayers.\nDate and duration.\nThe Passover begins on the 15th day of the month of Nisan, which at present falls between March 26 and April 25 of the Gregorian calendar. The 15th day begins in the evening, after the 14th day, and the seder meal is eaten that evening. Passover is a spring festival, so the 15th day of Nisan typically begins on the night of a full moon after the northern vernal equinox. However, due to leap months falling after the vernal equinox, Passover sometimes starts on the second full moon after vernal equinox, as in 2016.\nTo ensure that Passover did not start before spring, the tradition in ancient Israel held that the lunar new year, the first day of Nisan, would not start until the barley was ripe, being the test for the onset of spring. If the barley was not ripe, or various other phenomena indicated that spring was not yet imminent, an intercalary month (Adar II) would be added. However, since at least the 4th century, the intercalation has been fixed mathematically according to the Metonic cycle.\nIn Israel, Passover is the seven-day holiday of the Feast of Unleavened Bread, with the first and last days celebrated as legal holidays and as holy days involving holiday meals, special prayer services, and abstention from work; the intervening days are known as Chol HaMoed (\"Weekdays [of] the Festival\"). Jews outside of Israel celebrate the festival for eight days. Reform and Reconstructionist Jews usually celebrate the holiday over seven days.\nKaraites use a different calendar; they rely on visual identification of ripe barley and the date of Passover cannot be determined before this. Some modern Karaites follow the Rabbinical calendar in modern Israel because of social pressure.\nThe Samaritans use a calendrical system that uses a different method from that current in Rabbinic practice; it sometimes is the same date on the solar calendar, sometimes two days later, and sometimes an entire month later. In 2024, Rabbinical Passover begins at sunset on 22 April. On the calendar used by the Samaritans, 22 April 2024 is also the day of the Passover sacrifice. Karaite and Samaritan Passovers are each one day long followed by the six-day Festival of Unleavened Bread, for a total of seven days.\nProhibition of Chametz.\nRemoving all leaven (\"chametz\").\nLeaven, in Hebrew \"chametz\" (Hebrew: \"\u1e25amets\", \"leavening\") is made from one of five types of grains combined with water and left to stand for more than eighteen minutes. The consumption, keeping, and owning of \"chametz\" is forbidden during Passover. Yeast and fermentation are not themselves forbidden as seen for example by wine, which is required, rather than merely permitted. According to Halakha, the ownership of such \"chametz\" is also proscribed.\n\"Chametz\" does not include baking soda, baking powder or like products. Although these are defined in English as leavening agents, they leaven by chemical reaction, not by biological fermentation. Thus, bagels, waffles and pancakes made with baking soda and matzah meal are considered permissible, while bagels made with sourdough and pancakes and waffles made with yeast are prohibited.\nThe Torah commandments regarding \"chametz\" are:\nObservant Jews spend the weeks before Passover in the process of thorough housecleaning, to remove all \"chametz\" from every part of the home. Jewish law requires the elimination of olive-sized or larger quantities of leavening from one's possession, but most housekeeping goes beyond this. Even the seams of kitchen counters are thoroughly cleaned to remove traces of flour and yeast, however small. Any containers or implements that have touched \"chametz\" are stored and not used during Passover.\nSome hotels, resorts, and even cruise ships across America, Europe, and Israel also undergo a thorough housecleaning to make their premises \"kosher for Pesach\" to cater to observant Jews.\nInterpretations for abstinence from leaven or yeast.\nSome scholars suggest that the command to abstain from leavened food or yeast suggests that sacrifices offered to God involve the offering of objects in \"their least altered state\", that would be nearest to the way in which they were initially made by God. According to other scholars the absence of leaven or yeast means that leaven or yeast symbolizes corruption and spoiling.\nThere are also variations with restrictions on eating matzah before Passover so that there will be an increased appetite for it during Passover itself. Primarily among Chabad Chassidim, there is a custom of not eating matzah (flat unleavened bread) in the 30 days before Passover begins. Others have a custom to refrain from eating matzah from Rosh Chodesh Nissan, while the halacha merely restricts one from eating matzah on the day before Passover.\nKitniyot.\nKitniyot (Hebrew: \u05e7\u05b4\u05d8\u05b0\u05e0\u05b4\u05d9\u05bc\u05d5\u05b9\u05ea, \"qitniyyot\"; literally \"small things\") refers to legumes, rice, maize, and other foods that are similar to grains. Ashkenazi Jews historically refrain from eating kitniyot on Passover, despite there not being a clear commandment to include them in the category of chametz. Since the 19th century, the Reform movement has permitted eating kitniyot, and in 2015 the Conservative movement followed suit. Sephardi Jews have always permitted eating kitniyot on Passover.\nGebrochts.\nGebrochts (Yiddish: \u05d2\u05e2\u05d1\u05e8\u05d0\u05e7\u05d8\u05e1, 'broken', also known as Hebrew: \u05de\u05e6\u05d4 \u05e9\u05e8\u05d5\u05d9\u05d4, \"matzah shruya\", 'soaked matzah') refers to matzah that has absorbed liquid. Some Hasidic Jews avoid gebrochts as well, to avoid the possibility that a clump of flour that was never properly mixed with water (and thus is still susceptible to leavening) may come into contact with the liquid.\nSale of leaven.\nLeaven or \"chametz\" may be sold rather than discarded, especially in the case of relatively valuable forms such as liquor distilled from wheat, with the products being repurchased afterward. In some cases, they may never leave the house, instead being formally sold while remaining in the original owner's possession in a locked cabinet until they can be repurchased after the holiday. Modern observance may also include sealing cabinets and drawers which contain \"Chametz\" shut by using adhesive tape, which serves a similar purpose to a lock but also shows evidence of tampering. Although the practice of selling \"Chametz\" dates back many years, some Reform rabbinical authorities have come to regard it with disdain \u2013 since the supposed \"new owner\" never takes actual possession of the goods.\nThe sale of \"chametz\" may also be conducted communally via a rabbi, who becomes the \"agent\" for all the community's Jews through a halakhic procedure called a \"kinyan\" (acquisition). Each householder must put aside all the \"chametz\" he is selling into a box or cupboard, and the rabbi enters into a contract to sell all the \"chametz\" to a non-Jew (who is not obligated to celebrate the commandments) in exchange for a small down payment (\"e.g.\" $1.00), with the remainder due after Passover. This sale is considered completely binding according to Halakha, and at any time during the holiday, the buyer may come to take or partake of his property. The rabbi then re-purchases the goods for less than they were sold at the end of the holiday.\nSeparate kosher for Passover utensils and dishes.\nDue to the Torah injunction not to eat \"chametz\" (leaven) during Passover, observant families typically own complete sets of serving dishes, glassware and silverware (and in some cases, even separate dishwashers and sinks) which have never come into contact with \"chametz\", for use only during Passover. Under certain circumstances, some \"chametz\" utensils can be immersed in boiling water (\"hagalat keilim\") to purge them of any traces of \"chametz\" that may have accumulated during the year. Many Sephardic families thoroughly wash their year-round glassware and then use it for Passover, as the Sephardic position is that glass does not absorb enough traces of food to present a problem. Similarly, ovens may be used for Passover either by setting the self-cleaning function to the highest degree for a certain period, or by applying a blow torch to the interior until the oven glows red hot (a process called \"libun gamur\").\nSearch for leaven.\nOn the night of the fourteenth of Nisan, the night before the Passover Seder (after nightfall on the evening before Passover eve), Jews do a formal search in their homes known as \"bedikat chametz\" for any possible remaining leaven (\"chametz\"). The Talmudic sages instructed that a search for \"chametz\" be made in every home, place of work, or any place where \"chametz\" may have been brought during the year. When the first Seder is on a Saturday night, the search is conducted on the preceding Thursday night (thirteenth of Nisan) as \"chametz\" cannot be burned during Shabbat.\nThe Talmud in Pesahim (p.\u00a02a) derives from the Torah that the search for \"chametz\" be conducted by the light of a candle and therefore is done at night, and although the final destruction of the \"chametz\" (usually by burning it in a small bonfire) is done on the next morning, the blessing is made at night because the search is both in preparation for and part of the commandments to remove and destroy all \"chametz\" from one's possession.\nBlessing for search and nullification of hametz.\nBefore the search is begun there is a special blessing. If several people or family members assist in the search then only one person, usually the head of that family recites the blessing having in mind to include everyone present:\nBlessed are You, Hashem our God, King of the universe, Who has sanctified us with his commandments and has commanded us concerning the removal of chametz.\nThe search is then usually conducted by the head of the household joined by his family including children under the supervision of their parents.\nIt is customary to turn off the lights and conduct the search by candlelight, using a feather and a wooden spoon: candlelight effectively illuminates corners without casting shadows; the feather can dust crumbs out of their hiding places; and the wooden spoon which collects the crumbs can be burned the next day with the hametz. However, most contemporary Orthodox authorities permit using a flashlight, while some strongly encourage it due to the danger coupled with using a candle.\nBecause the house is assumed to have been thoroughly cleaned by the night before Passover, there is some concern that making a blessing over the search for hametz will be in vain (\"bracha l'vatala\") if nothing is found. Thus, 10 morsels of bread or cereal smaller than the size of an olive are traditionally hidden throughout the house to ensure that some 'hametz will be found.\nUpon conclusion of the search, with all the small pieces safely wrapped up and put in one bag or place, to be burned the next morning, the following is said:\nAny chametz or leaven that is in my possession which I have not seen and have not removed and do not know about should be annulled and become ownerless like the dust of the earth.\nMorning of 14th of Nisan.\nNote that if the 14th of Nisan is Shabbat, many of the below will be celebrated on the 13th instead due to restrictions in place during Shabbat.\nFast of the Firstborn.\nOn the day preceding the first Passover seder (or on Thursday morning preceding the seder, when the first seder falls on Motza'ei Shabbat), firstborn sons are commanded to celebrate the Fast of the Firstborn which commemorates the salvation of the Hebrew firstborns. According to Exodus 12:29, God struck down all Egyptian firstborns while the Israelites were not affected. However, it is customary for synagogues to conduct a \"siyum\" (ceremony marking the completion of a section of Torah learning) right after morning prayers, and the celebratory meal that follows cancels the firstborn's obligation to fast.\nBurning and nullification of leaven.\nOn the morning of the 14th of Nisan, any leavened products that remain in the householder's possession, along with the 10 morsels of bread from the previous night's search, are burned (\"s'rayfat chametz\"). The head of the household repeats the declaration of \"biyur chametz\", declaring any \"chametz\" that may not have been found to be null and void \"as the dust of the earth\":\nAny chametz or leaven that is in my possession which I have not seen and have not removed and do not know about should be annulled and become ownerless like the dust of the earth.\nThe original declaration, as recited in Aramaic, is:\n\u05db\u05dc \u05d7\u05de\u05d9\u05e8\u05d0 \u05d5\u05d7\u05de\u05d9\u05e2\u05d0 \u05d3\u05d0\u05db\u05d0 \u05d1\u05e8\u05e9\u05d5\u05ea\u05d9 \u05d3\u05dc\u05d0 \u05d7\u05de\u05ea\u05d4 \u05d5\u05d3\u05dc\u05d0 \u05d1\u05e2\u05e8\u05ea\u05d4 \u05d5\u05d3\u05dc\u05d0 \u05d9\u05d3\u05e2\u05e0\u05d0 \u05dc\u05d4 \u05dc\u05d1\u05d8\u05dc \u05d5\u05dc\u05d4\u05d5\u05d9 \u05d4\u05e4\u05e7\u05e8 \u05db\u05e2\u05e4\u05e8\u05d0 \u05d3\u05d0\u05e8\u05e2\u05d0\nShould more \"chametz\" actually be found in the house during the Passover holiday, it must be burnt as soon as possible.\nUnlike \"chametz\", which can be eaten any day of the year except during Passover, kosher for Passover foods can be eaten year-round. They need not be burnt or otherwise discarded after the holiday ends.\nThe historic Passover sacrifice has not been brought following the Romans' destruction of the Second Temple approximately two thousand years ago, and it is therefore still not part of the modern Jewish holiday.\nIn the times when the Jewish Temples stood, the lamb was slaughtered and cooked on the evening of Passover and was completely consumed before the morning as described in Exodus 12:3\u201311.\nNot eating matzah from sunrise until sunset (day before Passover).\nEven matzot that are kosher for Passover cannot be eaten all day on during the daylight hours before Passover eve. Some even practice this up to 30 days before.\nPassover sacrifice.\nThe main entity in Passover according to Judaism is the sacrificial lamb. During the existence of the Tabernacle and later the Temple in Jerusalem, the focus of the Passover festival was the Passover sacrifice, also known as the Paschal lamb, eaten during the Passover Seder on the 15th of Nisan. Every family large enough to completely consume a young lamb or wild goat was required to offer one for sacrifice at the Jewish Temple on the afternoon of the 14th day of Nisan, and eat it that night, which was the 15th of Nisan. If the family was too small to finish eating the entire offering in one sitting, an offering was made for a group of families. The sacrifice could not be offered with anything leavened, and had to be roasted, without its head, feet, or inner organs being removed and eaten together with unleavened bread and bitter herbs (\"maror\"). One had to be careful not to break any bones from the offering, and none of the meat could be left over by morning.\nBecause of the Passover sacrifice's status as a sacred offering, the only people allowed to eat it were those who had the obligation to bring the offering. Among those who could not offer or eat the Passover lamb were an apostate, a servant, an uncircumcised man, a person in a state of ritual impurity except when a majority of Jews are in such a state, and a Gentile. The offering had to be made before a quorum of 30. In the Temple, the Levites sang Hallel while the priests performed the sacrificial service. Men and women were equally obligated regarding the offering (\"Pesahim\" 91b).\nToday, in the absence of the Temple, when no sacrifices are offered or eaten, the mitzvah of the sacrifice is memorialized in the \"Seder Korban Pesach\", a set of scriptural and Rabbinic passages dealing with the Passover sacrifice, customarily recited after the \"Mincha\" (afternoon prayer) service on the 14th of Nisan, and in the form of the \"zeroa\", a symbolic food placed on the Passover Seder Plate (but not eaten), which is usually a roasted shankbone (or a chicken wing or neck). The eating of the afikoman substitutes for the eating of the sacrifice at the end of the Seder meal (Mishnah Pesachim 119a). Many Sephardic Jews have the custom of eating lamb or goat meat during the Seder in memory of the sacrifice.\nMatzah.\nA symbol of the Passover holiday is matzah, an unleavened flatbread made solely from flour and water which is continually worked from mixing through baking, so that it is not allowed to rise. Matzo may be made by machine or by hand. The Torah contains an instruction to eat matzah, specifically, on the first night of Passover and to eat only unleavened bread (in practice, matzah) during the entire week of Passover. Consequently, the eating of matzah figures prominently in the Passover Seder. There are several explanations for this.\nThe Torah says that it is because the Hebrews left Egypt with such haste that there was no time to allow baked bread to rise; thus flat, unleavened bread, matzah, is a reminder of the rapid departure of the Exodus. Other scholars teach that in the time of the Exodus, matzah was commonly baked to travel because it preserved well and was light to carry (making it similar to hardtack), suggesting that matzah was baked intentionally for the long journey ahead.\nMatzo has also been called \"Lechem Oni\" (Hebrew: \"bread of poverty\"). There is an attendant explanation that matzah serves as a symbol to remind Jews what it is like to be a poor slave and to promote humility, appreciate freedom, and avoid the inflated ego symbolized by more luxurious leavened bread.\n\"Shmura matzah\" (\"watched\" or \"guarded\" matzah), is the bread of preference for the Passover Seder in Orthodox Jewish communities. Shmura matzah is made from wheat that is guarded from contamination by leaven from the time of summer harvest to its baking into matzot five to ten months later.\nIn the weeks before Passover, matzot are prepared for holiday consumption. In many Orthodox Jewish communities, men traditionally gather in groups to bake handmade matzah for use at the Seder, the dough being rolled by hand, resulting in a large and round matzah. Groups also work together in machine-made matzah factories, which produce the typically square-shaped matzah sold in stores.\nThe baking of matzah is labour-intensive, as less than 18 minutes is permitted between the mixing of flour and water to the conclusion of baking and removal from the oven. Consequently, only a small number of matzot can be baked at one time, and the group members are enjoined to work the dough constantly so that it is not allowed to ferment and rise. A special cutting tool is run over the dough just before baking to prick any bubbles which might make the matza puff up; this creates the familiar dotted holes in the matzah.\nAfter the matzot come out of the oven, the entire work area is scrubbed down and swept to make sure that no pieces of old, potentially leavened dough remain, as any stray pieces are now hametz and can contaminate the next batch of matzah.\nSome machine-made matzot are completed within five minutes of being kneaded.\nPassover seder.\nIt is traditional for Jewish families to gather on the first night of Passover (first two nights in Orthodox and Conservative communities outside Israel) for a special dinner called a seder (Hebrew: \"seder\" \u2013 derived from the Hebrew word for \"order\" or \"arrangement\", referring to the very specific order of the ritual). The table is set with the finest china and silverware to reflect the importance of the meal. During this meal, the story of the Exodus from Egypt is retold using a special text called the Haggadah. A total of four cups of wine are consumed during the recitation of the Haggadah. The seder is divided by the haggadah into the following 15 parts:\nThese 15 parts parallel the 15 steps in the Temple in Jerusalem on which the Levites stood during Temple services, and which were memorialized in the 15 Psalms (#120\u2013134) known as \"Shir HaMa'a lot\" (Hebrew: \"shiyr ha-ma'al\u00f4th\", \"Songs of Ascent\").\nThe seder is replete with questions, answers, and unusual practices (e.g. the recital of Kiddush which is not immediately followed by the blessing over bread, which is the traditional procedure for all other holiday meals) to arouse the interest and curiosity of the children at the table. The children are also rewarded with nuts and candies when they ask questions and participate in the discussion of the Exodus and its aftermath. Likewise, they are encouraged to search for the \"afikoman\", the piece of matzah which is the last thing eaten at the seder. Audience participation and interaction is the rule, and many families' seders last long into the night with animated discussions and singing. The seder concludes with additional songs of praise and faith printed in the Haggadah, including \"Chad Gadya\" (\"One Little Kid\" or \"One Little Goat\").\nMaror.\nMaror (bitter herbs) symbolizes the bitterness of slavery in Egypt. The following verse from the Torah underscores that symbolism: \"And they embittered (Hebrew: \u05d5\u05d9\u05de\u05e8\u05e8\u05d5 \"ve-yimareru\") their lives with hard labor, with mortar and with bricks and with all manner of labor in the field; any labor that they made them do was with hard labor\" (Exodus 1:14).\nFour cups of wine.\nThere is a Rabbinic requirement that four cups of wine are to be drunk during the seder meal. This applies to both men and women. The Mishnah says (Pes. 10:1) that even the poorest man in Israel must drink. Each cup is connected to a different part of the seder: the first cup is for Kiddush, the second cup is connected with the recounting of the Exodus, the drinking of the third cup concludes Birkat Hamazon and the fourth cup is associated with Hallel. A fifth cup of wine is poured near the end of the seder for the prophet Elijah, a symbol of the future redemption, which is left un-touched.\nThe four questions and participation of children.\nChildren have a very important role in the Passover seder. Traditionally the youngest child is prompted to ask questions about the Passover seder, beginning with the words, \"Mah Nishtana HaLeila HaZeh\" (Why is this night different from all other nights?). The questions encourage the gathering to discuss the significance of the symbols in the meal. The questions asked by the child are:\nWhy is this night different from all other nights?\nOn all other nights, we eat either unleavened or leavened bread, but tonight we eat only unleavened bread?\nOn all other nights, we eat all kinds of vegetables, but tonight, we eat only bitter herbs?\nOn all other nights, we do not dip [our food] even once, but tonight we dip twice?\nOn all other nights, we eat either sitting or reclining, but tonight we only recline?\nOften the leader of the seder and the other adults at the meal will use prompted responses from the Haggadah, which states, \"The more one talks about the Exodus from Egypt, the more praiseworthy he is.\" Many readings, prayers, and stories are used to recount the story of the Exodus. Many households add their own commentary and interpretation and often the story of the Jews is related to the theme of liberation and its implications worldwide.\nAfikoman.\nThe \"afikoman\" \u2013 an integral part of the Seder itself \u2013 is used to engage the interest and excitement of the children at the table. During the fourth part of the Seder, called \"Yachatz\", the leader breaks the middle piece of matzah into two. He sets aside the larger portion as the \"afikoman\". Many families use the \"afikoman\" as a device for keeping the children awake and alert throughout the Seder proceedings by hiding the \"afikoman\" and offering a prize for its return. Alternatively, the children are allowed to \"steal\" the \"afikoman\" and demand a reward for its return. In either case, the \"afikoman\" must be consumed during the twelfth part of the Seder, \"Tzafun\".\nConcluding songs.\nAfter the Hallel, the fourth glass of wine is drunk, and participants recite a prayer that ends in \"Next year in Jerusalem!\". This is followed by several lyric prayers that expound upon God's mercy and kindness, and give thanks for the survival of the Jewish people through a history of exile and hardship. \"Echad Mi Yodea\" (\"Who Knows One?\") is a playful song, testing the general knowledge of the children (and the adults). Some of these songs, such as \"Chad Gadya\" are allegorical.\nHallel.\nDuring Passover, the recitation of \"Hallel\" a collection of Psalms praising and thanking God, is an integral part of the daily prayer service. On the initial day(s) of Passover, it is recited in its entirety, similar to the practice observed on Shavuot and throughout Succot. However, for the subsequent days of the Passover holiday, only half of the Hallel is recited. This traditional practice is widely observed by adherents of the Jewish faith as a way of expressing gratitude and celebrating the significance of Passover, while maintaining variations in the recitation of Hallel based on specific days within the festival.\nCounting of the Omer.\nBeginning on the second night of Passover, the 16th day of Nisan, Jews begin the practice of the Counting of the Omer, a nightly reminder of the approach of the holiday of Shavuot 50 days hence. Each night after the evening prayer service, men and women recite a special blessing and then enumerate the day of the Omer. On the first night, for example, they say, \"Today is the first day in (or, to) the Omer\"; on the second night, \"Today is the second day in the Omer.\" The counting also involves weeks; thus, the seventh day is commemorated, \"Today is the seventh day, which is one week in the Omer.\" The eighth day is marked, \"Today is the eighth day, which is one week and one day in the Omer,\" etc.\nWhen the Temple stood in Jerusalem, a sheaf of new-cut barley was presented before the altar on the second day of Unleavened Bread (Passover). Josephus writes:\nOn the second day of unleavened bread, that is to say the sixteenth, our people partake of the crops which they have reaped and which have not been touched till then, and esteeming it right first to do homage to God, to whom they owe the abundance of these gifts, they offer to him the first-fruits of the barley in the following way. After parching and crushing the little sheaf of ears and purifying the barley for grinding, they bring to the altar an https:// for God, and, having flung a handful thereof on the altar, they leave the rest for the use of the priests. Thereafter all are permitted, publicly or individually, to begin harvest. Since the destruction of the Temple, this offering is brought in word rather than deed.\nOne explanation for the Counting of the Omer is that it shows the connection between Passover and Shavuot. The physical freedom that the Hebrews achieved at the Exodus from Egypt was only the beginning of a process that climaxed with the spiritual freedom they gained at the giving of the Torah at Mount Sinai. Another explanation is that the newborn nation which emerged after the Exodus needed time to learn their new responsibilities vis-a-vis Torah and mitzvot before accepting God's law. The distinction between the Omer offering \u2013 a measure of barley, typically animal fodder \u2013 and the Shavuot offering \u2013 two loaves of wheat bread, human food \u2013 symbolizes the transition process.\nChol HaMoed: The intermediate days of Passover.\nIn Israel, Passover lasts for seven days with the first and last days being major Jewish holidays. In Orthodox and Conservative communities, no work is performed on those days, with most of the rules relating to the observances of Shabbat being applied.\nOutside Israel, in Orthodox and Conservative communities, the holiday lasts for eight days with the first two days and last two days being major holidays. In the intermediate days necessary work can be performed. Reform Judaism observes Passover over seven days, with the first and last days being major holidays.\nLike the holiday of Sukkot, the intermediary days of Passover are known as Chol HaMoed (festival weekdays) and are imbued with a semi-festive status. It is a time for family outings and picnic lunches of matzah, hardboiled eggs, fruits and vegetables, and Passover treats such as macaroons and homemade candies.\nPassover cake recipes call for potato starch or Passover cake flour made from finely granulated matzah instead of regular flour, and a large amount of eggs to achieve fluffiness. Cookie recipes use matzah farfel (broken bits of matzah) or ground nuts as the base. For families with Eastern European backgrounds, borsht, a soup made with beets, is a Passover tradition.\nWhile kosher for Passover packaged goods are available in stores, some families opt to cook everything from scratch during Passover week. In Israel, families that do not kasher their ovens can bake cakes, casseroles, and even meat on the stovetop in a Wonder Pot, an Israeli invention consisting of three parts: an aluminium pot shaped like a Bundt pan, a hooded cover perforated with venting holes, and a thick, round, metal disc with a center hole which is placed between the Wonder Pot and the flame to disperse heat.\nSeventh day of Passover.\n (, 'seventh [day] of Passover') is another full Jewish holiday, with special prayer services and festive meals. Outside the Israel, in the Jewish diaspora, is celebrated on both the seventh and eighth days of Passover. This holiday commemorates the day the Children of Israel reached the Red Sea and witnessed both the miraculous \"Splitting of the Sea\" (Passage of the Red Sea), the drowning of all the Egyptian chariots, horses and soldiers that pursued them. According to the Midrash, only the Pharaoh was spared to give testimony to the miracle that occurred.\nHasidic Rebbes traditionally hold a \"tish\" on the night of and place a cup or bowl of water on the table before them. They use this opportunity to speak about the Splitting of the Sea to their disciples, and sing songs of praise to God.\nSecond Passover.\nThe \"Second Passover\" (Pesach Sheni) on the 14th of Iyar in the Hebrew calendar is mentioned in the Hebrew Bible's Book of Numbers as a make-up day for people who were unable to offer the pesach sacrifice at the appropriate time due to ritual impurity or distance from Jerusalem. Just as on the first Pesach night, breaking bones from the second Paschal offering or leaving meat over until morning is prohibited.\nToday, Pesach Sheni on the 14th of Iyar has the status of a very minor holiday (so much so that many of the Jewish people have never even heard of it, and it essentially does not exist outside of Orthodox and traditional Conservative Judaism). There are not really any special prayers or observances that are considered Jewish law. The only change in the liturgy is that in some communities \"Tachanun\", a penitential prayer omitted on holidays, is not said. There is a custom, though not Jewish law, to eat just one piece of matzah on that night.\nNotable events on Passover.\nBiblical\nModern Day\nTraditional foods.\nBecause the house is free of leaven (\"chametz\") for eight days, the Jewish household typically eats different foods during the week of Passover. Some include:\nAshkenazi foods\nSephardi foods\nEnvironmental links.\nSome see in Passover an important ecological lesson important to the contemporary situation with different ecological threats like climate change. For example, Rabbi Yonatan Neril, founder and executive director of the Interfaith Center for Sustainable Development, compares the impact of climate change to the Plagues of Egypt and the refusal of modern society to change its way of thinking to the refusal of the Pharaoh to free the Jewish slaves. Scientists discovered evidence for climatic change at the end of the rule of Ramesses II, which could potentially impact the flow of the Nile, leading to red algae bloom. This could explain what is described as the ten plagues. According to Neril: \"The Egyptians were very happy to have a free source of labor in the form of Israelite slaves. When God said this needs to stop, they were reluctant to change\u2026Fossil fuels, in the past 150 years, have replaced slave labor as the key driver of human society. There's a Pharaoh within us that wants to continue to do something that's not right.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23061", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=23061", "title": "Philosophical argument", "text": ""}
{"id": "23062", "revid": "40438136", "url": "https://en.wikipedia.org/wiki?curid=23062", "title": "Post Office Protocol", "text": "Family of Internet mail protocols\nIn computing, the Post Office Protocol (POP) is an application-layer Internet standard protocol used by e-mail clients to retrieve e-mail from a mail server. Today, POP version 3 (POP3) is the most commonly used version. Together with IMAP, it is one of the most common protocols for email retrieval.\nPurpose.\nThe Post Office Protocol provides access via an Internet Protocol (IP) network for a user client application to a mailbox (\"maildrop\") maintained on a mail server. The protocol supports list, retrieve and delete operations for messages. POP3 clients connect, retrieve all messages, store them on the client computer, and finally delete them from the server. This design of POP and its procedures was driven by the need of users having only temporary Internet connections, such as dial-up access, allowing these users to retrieve e-mail when connected, and subsequently to view and manipulate the retrieved messages when offline.\nPOP3 clients also have an option to leave mail on the server after retrieval, and in this mode of operation, clients will only download new messages which are identified by using the UIDL command (unique-id list). By contrast, the Internet Message Access Protocol (IMAP) was designed to normally leave all messages on the server to permit management with multiple client applications, and to support both connected (\"online\") and disconnected (\"offline\") modes of operation.\nA POP3 server listens on TCP well-known port number 110 for service requests. Encrypted communication for POP3 is either requested after protocol initiation, using the STLS command, if supported, or by POP3S, which connects to the server using Transport Layer Security (TLS) or Secure Sockets Layer (SSL) on well-known TCP port number 995.\nMessages available to the client are determined when a POP3 session opens the maildrop, and are identified by message-number local to that session or, optionally, by a unique identifier assigned to the message by the POP server. This unique identifier is permanent and unique to the maildrop and allows a client to access the same message in different POP sessions. Mail is retrieved and marked for deletion by the message-number. When the client exits the session, mail marked for deletion is removed from the maildrop.\nHistory.\nThe first version of the Post Office Protocol, POP1, was specified in RFC 918 (1984) by Joyce K. Reynolds. POP2 was specified in RFC 937 (1985).\nPOP3 is the version in most common use. It originated with RFC 1081 (1988) but the most recent specification is RFC 1939, updated with an extension mechanism (RFC 2449) and an authentication mechanism in RFC 1734. This led to a number of POP implementations such as Pine, POPmail, and other early mail clients. \nWhile the original POP3 specification supported only an unencrypted USER/PASS login mechanism or Berkeley .rhosts access control, today POP3 supports several authentication methods to provide varying levels of protection against illegitimate access to a user's e-mail. Most are provided by the POP3 extension mechanisms. POP3 clients support SASL authentication methods via the AUTH extension. MIT Project Athena also produced a Kerberized version. RFC 1460 introduced APOP into the core protocol. APOP is a challenge\u2013response protocol which uses the MD5 hash function in an attempt to avoid replay attacks and disclosure of the shared secret. Clients implementing APOP include Mozilla Thunderbird, Opera Mail, Eudora, KMail, Novell Evolution, RimArts' Becky!, Windows Live Mail, PowerMail, Apple Mail, and Mutt. RFC 1460 was obsoleted by RFC 1725, which was in turn obsoleted by RFC 1939.\nPOP4.\nPOP4 exists only as an informal proposal adding basic folder management, multipart message support, as well as message flag management to compete with IMAP; however, its development has not progressed since 2003. There are now two known POP4 server implementations. As of October 2013, the POP4.org domain and website are now hosted by simbey.com, which also runs the other POP4 http://\nExtensions and specifications.\nAn extension mechanism was proposed in RFC 2449 to accommodate general extensions as well as announce in an organized manner support for optional commands, such as TOP and UIDL. The RFC did not intend to encourage extensions, and reaffirmed that the role of POP3 is to provide simple support for mainly download-and-delete requirements of mailbox handling.\nThe extensions are termed capabilities and are listed by the CAPA command. With the exception of APOP, the optional commands were included in the initial set of capabilities. Following the lead of ESMTP (RFC 5321), capabilities beginning with an X signify local capabilities.\nSTARTTLS.\nThe STARTTLS extension allows the use of Transport Layer Security (TLS) or Secure Sockets Layer (SSL) to be negotiated using the \"STLS\" command, on the standard POP3 port, rather than an alternate. Some clients and servers instead use the alternate-port method, which uses TCP port 995 (POP3S).\nSDPS.\nDemon Internet introduced extensions to POP3 that allow multiple accounts per domain, and has become known as \"Standard Dial-up POP3 Service\" (SDPS). To access each account, the username includes the hostname, as \"john@hostname\" or \"john+hostname\".\nGoogle Apps uses the same method.\nKerberized Post Office Protocol.\nIn computing, local e-mail clients can use the Kerberized Post Office Protocol (KPOP), an application-layer Internet standard protocol, to retrieve e-mail from a remote server over a TCP/IP connection. The KPOP protocol is based on the POP3 protocol \u2013 differing in that it adds Kerberos security and that it runs by default over TCP port number 1109 instead of 110. One mail server software implementation is found in the Cyrus IMAP server.\nSession example.\nThe following POP3 session dialog is an example in RFC 1939:\n S: &lt;wait for connection on TCP port 110&gt;\n C: &lt;open connection&gt;\n S: +OK POP3 server ready &lt;1896.697170952@dbc.mtview.ca.us&gt;\n C: APOP mrose c4c9334bac560ecc979e58001b3e22fb\n S: +OK mrose's maildrop has 2 messages (320 octets)\n C: STAT\n S: +OK 2 320\n C: LIST\n S: +OK 2 messages (320 octets)\n S: 1 120\n S: 2 200\n S: .\n C: RETR 1\n S: +OK 120 octets\n S: &lt;the POP3 server sends message 1&gt;\n S: .\n C: DELE 1\n S: +OK message 1 deleted\n C: RETR 2\n S: +OK 200 octets\n S: &lt;the POP3 server sends message 2&gt;\n S: .\n C: DELE 2\n S: +OK message 2 deleted\n C: QUIT\n S: +OK dewey POP3 server signing off (maildrop empty)\n C: &lt;close connection&gt;\n S: &lt;wait for next connection&gt;\nPOP3 servers without the optional APOP command expect the client to log in with the USER and PASS commands:\n C: USER mrose\n S: +OK User accepted\n C: PASS tanstaaf\n S: +OK Pass accepted\nComparison with IMAP.\nThe Internet Message Access Protocol (IMAP) is an alternative and more recent mailbox access protocol. The highlights of differences are:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "23063", "revid": "1893265", "url": "https://en.wikipedia.org/wiki?curid=23063", "title": "Preface of Origin", "text": ""}
{"id": "23065", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=23065", "title": "Populism and nationalism", "text": ""}
{"id": "23068", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=23068", "title": "Portland Oregon", "text": ""}
{"id": "23069", "revid": "35498457", "url": "https://en.wikipedia.org/wiki?curid=23069", "title": "Punch (magazine)", "text": "British weekly satirical magazine, 1841\u20132002\nPunch, or The London Charivari was a British weekly magazine of humour and satire established in 1841 by Henry Mayhew and wood-engraver Ebenezer Landells. Historically, it was most influential in the 1840s and 1850s, when it helped to coin the term \"cartoon\" in its modern sense as a humorous illustration. Artists at \"Punch\" included John Tenniel who, from 1850, was the chief cartoon artist at the magazine for over 50 years. The editors took the anarchic puppet Mr Punch, of Punch and Judy, as their mascot\u2014the character appears in many magazine covers\u2014with the character also an inspiration for the magazine's name.\nWith its satire of the contemporary, social, and political scene, \"Punch\" became a household name in Victorian Britain. Sales of 40,000 copies a week by 1850 rose above 100,000 by 1910. After the 1940s, when its circulation peaked, it went into a long decline, closing in 1992. It was revived in 1996, but closed again in 2002.\nHistory.\n\"Punch\" was founded on 17 July 1841 by Henry Mayhew and wood-engraver Ebenezer Landells, on an initial investment of \u00a325 (). It was jointly edited by Mayhew and Mark Lemon. It was subtitled \"The London Charivari\" in homage to Charles Philipon's French satirical humour magazine \"Le Charivari\". Reflecting their satiric and humorous intent, the two editors took for their name and masthead the anarchic glove puppet Mr. Punch, of Punch and Judy; the name also referred to a joke made early on about one of the magazine's first editors, Lemon, that \"punch is nothing without lemon\".\nMayhew ceased to be joint editor in 1842 and became \"suggestor in chief\" until he severed his connection in 1845. The magazine initially struggled for readers, except for an 1842 \"Almanack\" issue which shocked its creators by selling 90,000 copies. In December 1842, due to financial difficulties, the magazine was sold to Bradbury and Evans, both printers and publishers. Bradbury and Evans capitalised on newly evolving mass printing technologies and also were the publishers for Charles Dickens and William Makepeace Thackeray.\nCartoon terminology.\nThe term \"cartoon\" to refer to comic drawings was first used in \"Punch\" in 1843, when the Houses of Parliament were to be decorated with murals, and \"cartoons\" for the mural were displayed for the public; the term \"cartoon\" then meant a finished preliminary sketch on a large piece of cardboard, or in Italian. \"Punch\" humorously appropriated the term to refer to its political cartoons, and the popularity of the \"Punch\" cartoons led to the term's widespread use.\nArtistry.\nIllustrator Archibald Henning designed the cover of the magazine's first issues. The cover design varied in the early years, though Richard Doyle designed what became the magazine's masthead in 1849. Artists who published in \"Punch\" during the 1840s and 1850s included John Leech, Doyle, John Tenniel, and Charles Keene. This group became known as \"The \"Punch\" Brotherhood\", which also included Charles Dickens, who joined Bradbury and Evans after leaving Chapman and Hall in 1843. \"Punch\"'s authors and artists also contributed to another Bradbury and Evans literary magazine called \"Once A Week\" (est. 1859), created in response to Dickens' departure from \"Household Words\".\nHelen Hoppner Coode contributed nineteen drawings to \"Punch\" and is recognised as its first woman contributor.\nLiberal competition.\nIn the 1860s and '70s, conservative \"Punch\" faced competition from upstart liberal journal \"Fun\", but after about 1874, \"Fun\"'s fortunes faded. At Evans's caf\u00e9 in London, the two journals had \"round tables\" in competition with each other.\nGaining a market and relations with other papers.\nAfter months of financial difficulty and lack of market success, \"Punch\" became a staple for British drawing rooms because of its sophisticated humour and absence of offensive material, especially when viewed against the satirical press of the time. \"The Times\" and the Sunday paper \"News of the World\" used small pieces from \"Punch\" as column fillers, giving the magazine free publicity and indirectly granting a degree of respectability, a privilege not enjoyed by any other comic publication. \"Punch\" shared a friendly relationship with not only \"The Times\", but also journals aimed at intellectual audiences such as the \"Westminster Review\", which published a 53-page illustrated article on \"Punch\"'s first two volumes. Historian Richard Altick writes that \"To judge from the number of references to it in the private letters and memoirs of the 1840s...\"Punch\" had become a household word within a year or two of its founding, beginning in the middle class and soon reaching the pinnacle of society, royalty itself\".\nIncreasing in readership and popularity throughout the remainder of the 1840s and '50s, \"Punch\" was the success story of a threepenny weekly paper that had become one of the most talked-about and enjoyed periodicals. \"Punch\" enjoyed an audience including Elizabeth Barrett, Robert Browning, Thomas Carlyle, Edward FitzGerald, Charlotte Bront\u00eb, Queen Victoria, Prince Albert, Ralph Waldo Emerson, Emily Dickinson, Herman Melville, Henry Wadsworth Longfellow, and James Russell Lowell. \"Punch\" gave several phrases to the English language, including The Crystal Palace, and the \"Curate's egg\" (first seen in an 1895 cartoon by George du Maurier). Several British humour classics were first serialised in \"Punch\", such as the \"Diary of a Nobody\" and \"1066 and All That\". Towards the end of the 19th century, the artistic roster included Harry Furniss, Linley Sambourne, Francis Carruthers Gould, and Phil May. Among the outstanding cartoonists of the following century were Bernard Partridge, H. M. Bateman, Bernard Hollowood (who also edited the magazine from 1957 to 1968), Kenneth Mahood, and Norman Thelwell.\nCirculation broke the 100,000 mark around 1910, and peaked in 1947\u20131948 at 175,000 to 184,000. Sales declined steadily thereafter; ultimately, the magazine was forced to close in 2002 after 161 years of publication.\n\"Punch\" was widely emulated worldwide and was popular throughout the British Empire. The experience of Britons in British colonies, especially in India, influenced \"Punch\" and its iconography. Tenniel's \"Punch\" cartoons of the 1857 Sepoy Mutiny led to a surge in the magazine's popularity. India was frequently caricatured in \"Punch\" and was an important source of knowledge on the subcontinent for British readers.\nLater years.\n\"Punch\" material was collected in book formats from the late 19th century, which included \"Pick of the Punch\" annuals with cartoons and text features, \"Punch and the War\" (a 1941 collection of WWII-related cartoons), and \"A Big Bowl of Punch\" \u2013 which was republished a number of times. Many \"Punch\" cartoonists of the late 20th century published collections of their own, partly based on \"Punch\" contributions.\nIn early 1996, businessman Mohamed Al-Fayed bought the rights to the name, and \"Punch\" was relaunched later that year. The new version of the magazine was intended to be a spoiler aimed at \"Private Eye\", which had published many items critical of Fayed. \"Punch\" never became profitable in its new incarnation, and at the end of May 2002, it was announced as once more ceasing publication. Press reports quoted a loss of \u00a316 million over the six years of publication, with only 6,000 subscribers at the end.\nWhereas the earlier version of \"Punch\" prominently featured the clownish character Punchinello (Punch of Punch and Judy) performing antics on front covers, the resurrected \"Punch\" did not use the character, but featured on its weekly covers a photograph of a boxing glove, thus informing its readers that the new magazine intended its name to mean \"punch\" in the sense of a boxing blow.\n\"Punch\" table.\nIn 2004, much of the archives was acquired by the British Library, including the \"Punch\" table. The long, oval, Victorian table was brought into the offices some time around 1855, and was used for staff meetings and on other occasions. The wooden surface is scarred with the carved initials of the magazine's long-term writers, artists, and editors, as well as six invited \"strangers\", including James Thurber and Charles III (then Prince of Wales). Mark Twain declined the invitation, saying that the already-carved initials of William Makepeace Thackeray included his own.\nContributors.\nEditors.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nInfluence.\n\"Punch\" was influential throughout the British Empire, and in countries including Turkey, India, Japan, and China, with \"Punch\" imitators appearing in Cairo, Yokohama, Tokyo, Hong Kong, and Shanghai. \nA Canadian version, \"Punch in Canada\", was launched on 1 January 1849. The magazine was published by Thomas Blades de Walden, a dilapidated member of one of the great aristocratic families of England, and an associated of the officers of the garrison stationed in Toronto. According to John Henry Walker, a wood engraver working for \"Punch\", the magazine was doing well. However, the production ceased abruptly in 1850 when De Walden and Charles Dawson Shanly fled to New York.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "23070", "revid": "10370269", "url": "https://en.wikipedia.org/wiki?curid=23070", "title": "Pacific Ocean", "text": "Oceanic division\nThe Pacific Ocean is the largest and deepest of Earth's five oceanic divisions. It extends from the Arctic Ocean in the north to the Southern Ocean, or, depending on the definition, to Antarctica in the south, and is bounded by the continents of Asia and Australia in the west and the Americas in the east.\nAt in area (as defined with a southern Antarctic border), the Pacific Ocean is the largest division of the World Ocean and the hydrosphere and covers approximately 46% of Earth's water surface and about 32% of the planet's total surface area, larger than its entire land area (). The centers of both the water hemisphere and the Western Hemisphere, as well as the oceanic pole of inaccessibility, are in the Pacific Ocean. Ocean circulation (caused by the Coriolis effect) subdivides it into two largely independent volumes of water that meet at the equator, the North Pacific Ocean and the South Pacific Ocean (or more loosely the South Seas). The Pacific Ocean can also be informally divided by the International Date Line into the East Pacific and the West Pacific, which allows it to be further divided into four quadrants, namely the Northeast Pacific off the coasts of North America, the Southeast Pacific off South America, the Northwest Pacific off Far Eastern/Pacific Asia, and the Southwest Pacific around Oceania.\nThe Pacific Ocean's mean depth is . The Challenger Deep in the Mariana Trench, located in the northwestern Pacific, is the deepest known point in the world, reaching a depth of . The Pacific also contains the deepest point in the Southern Hemisphere, the Horizon Deep in the Tonga Trench, at . The third deepest point on Earth, the Sirena Deep, was also located in the Mariana Trench. It is the warmest ocean, as its temperatures can reach as high as 31\u00b0C (88\u00b0F) due to it surrounding major and minor Pacific islands, which have a tropical, hot climate.\nThe Pacific has many major marginal seas, including (listed clockwise from the west) the Philippine Sea, South China Sea, East China Sea, Sea of Japan, Sea of Okhotsk, Bering Sea, Gulf of Alaska, Gulf of California, Tasman Sea, and the Coral Sea.\nEtymology.\nIn the early 16th century, Spanish explorer Vasco N\u00fa\u00f1ez de Balboa crossed the Isthmus of Panama in 1513 and sighted the great \"Southern Sea\", which he named (in Spanish). Afterwards, the ocean's current name was coined by Portuguese explorer Ferdinand Magellan during the Spanish circumnavigation of the world in 1520, as he encountered favorable winds upon reaching the ocean. He called it , which in Portuguese and Spanish means 'peaceful sea'.\nHistory.\nPrehistory.\nAcross the continents of Asia, Australia and the Americas, more than 25,000 islands, large and small, rise above the surface of the Pacific Ocean. Multiple islands were the shells of former active volcanoes that have lain dormant for thousands of years. Close to the equator, without vast areas of blue ocean, are a dot of atolls that have over intervals of time been formed by seamounts as a result of tiny coral islands strung in a ring within surroundings of a central lagoon.\nEarly migrations.\nImportant human migrations occurred in the Pacific in prehistoric times. Modern humans first reached the western Pacific in the Paleolithic, at around 60,000 to 70,000 years ago. Originating from a southern coastal human migration out of Africa, they reached East Asia, Mainland Southeast Asia, the Philippines, New Guinea, and then Australia by making the sea crossing of at least between Sundaland and Sahul. It is not known with any certainty what level of maritime technology was used by these groups\u00a0\u2013 the presumption is that they used large bamboo rafts which may have been equipped with some sort of sail. The reduction in favourable winds for a crossing to Sahul after 80,000 B.P. fits with the dating of the settlement of Australia, with no later migrations in the prehistoric period. The seafaring abilities of pre-Austronesian residents of Island South-east Asia are confirmed by the settlement of Buka by 32,000 B.P. and Manus by 25,000 B.P. Journeys of and are involved, respectively.\nThe descendants of these migrations today are the Negritos, Melanesians, and Indigenous Australians. Their populations in maritime Southeast Asia, coastal New Guinea, and Island Melanesia later intermarried with the incoming Austronesian settlers from Taiwan and the northern Philippines, but also earlier groups associated with Austroasiatic-speakers, resulting in the modern peoples of Island Southeast Asia and Oceania.\nA later seaborne migration is the Neolithic Austronesian expansion of the Austronesian peoples. Austronesians originated from the island of Taiwan c.\u20093000\u20131500 BCE. They are associated with distinctive maritime sailing technologies (notably outrigger boats, catamarans, lashed-lug boats, and the crab claw sail)\u00a0\u2013 it is likely that the progressive development of these technologies were related to the later steps of settlement into Near and Remote Oceania. Starting at around 2200 BCE, Austronesians sailed southwards to settle the Philippines. From, probably, the Bismarck Archipelago they crossed the western Pacific to reach the Marianas Islands by 1500 BCE, as well as Palau and Yap by 1000 BCE. They were the first humans to reach Remote Oceania, and the first to cross vast distances of open water. They also continued spreading southwards and settling the rest of Maritime Southeast Asia, reaching Indonesia and Malaysia by 1500 BCE, and further west to Madagascar and the Comoros in the Indian Ocean by around 500 CE. More recently, it is suggested that Austronesians expanded already earlier, arriving in the Philippines already in 7000 BCE. Additional earlier migrations into Insular Southeast Asia, associated with Austroasiatic-speakers from Mainland Southeast Asia, are estimated to have taken place already in 15000 BCE.\nAt around 1300 to 1200 BCE, a branch of the Austronesian migrations known as the Lapita culture reached the Bismarck Archipelago, the Solomon Islands, Vanuatu, Fiji, and New Caledonia. From there, they settled Tonga and Samoa by 900 to 800 BCE. Some also back-migrated northwards in 200 BCE to settle the islands of eastern Micronesia (including the Carolines, the Marshall Islands, and Kiribati), mixing with earlier Austronesian migrations in the region. This remained the furthest extent of the Austronesian expansion into Polynesia until around 700 CE when there was another surge of island exploration. They reached the Cook Islands, Tahiti, and the Marquesas by 700 CE; Hawai\u02bbi by 900 CE; Rapa Nui by 1000 CE; and finally New Zealand by 1200 CE. Austronesians may have also reached as far as the Americas, although evidence for this remains inconclusive.\nEuropean exploration.\nThe first contact of European navigators with the western edge of the Pacific Ocean was made by the Portuguese expeditions of Ant\u00f3nio de Abreu and Francisco Serr\u00e3o, via the Lesser Sunda Islands, to the Maluku Islands, in 1512, and with Jorge \u00c1lvares's expedition to southern China in 1513, both ordered by Afonso de Albuquerque from Malacca.\nThe eastern side of the ocean was encountered by Spanish explorer Vasco N\u00fa\u00f1ez de Balboa in 1513 after his expedition crossed the Isthmus of Panama and reached a new ocean. He named it \"Mar del Sur\" (\"Sea of the South\" or \"South Sea\") because the ocean was to the south of the coast of the isthmus where he first observed the Pacific.\nIn 1520, navigator Ferdinand Magellan and his crew were the first to cross the Pacific in recorded history. They were part of a Spanish expedition to the Spice Islands that would eventually result in the first world circumnavigation. Magellan called the ocean \"Pac\u00edfico\" (or \"Pacific\" meaning, \"peaceful\") because, after sailing through the stormy seas off Cape Horn, the expedition found calm waters. The ocean was often called the Sea of Magellan in his honor until the eighteenth century. Magellan stopped at one uninhabited Pacific island before stopping at Guam in March 1521. Although Magellan himself died in the Philippines in 1521, Spanish navigator Juan Sebasti\u00e1n Elcano led the remains of the expedition back to Spain across the Indian Ocean and round the Cape of Good Hope, completing the first world circumnavigation in 1522. Sailing around and east of the Moluccas, between 1525 and 1527, Portuguese expeditions encountered the Caroline Islands, the Aru Islands, and Papua New Guinea. In 1542\u201343 the Portuguese also reached Japan.\nIn 1564, five Spanish ships carrying 379 soldiers crossed the ocean from Mexico led by Miguel L\u00f3pez de Legazpi, and colonized the Philippines and Mariana Islands. For the remainder of the 16th century, Spain maintained military and mercantile control, with ships sailing from Mexico and Peru across the Pacific Ocean to the Philippines via Guam, and establishing the Spanish East Indies. The Manila galleons operated for two and a half centuries, linking Manila and Acapulco, in one of the longest trade routes in history. Spanish expeditions also arrived at Tuvalu, the Marquesas, the Cook Islands, the Solomon Islands, Vanuatu, the Marshalls and the Admiralty Islands in the South Pacific.\nLater, in the quest for Terra Australis (\"the [great] Southern Land\"), Spanish explorations in the 17th century, such as the expedition led by the Portuguese navigator Pedro Fernandes de Queir\u00f3s, arrived at the Pitcairn and Vanuatu archipelagos, and sailed the Torres Strait between Australia and New Guinea, named after navigator Lu\u00eds Vaz de Torres. Dutch explorers, sailing around southern Africa, also engaged in exploration and trade; Willem Janszoon, made the first completely documented European landing in Australia (1606), in Cape York Peninsula, and Abel Janszoon Tasman circumnavigated and landed on parts of the Australian continental coast and arrived at Tasmania and New Zealand in 1642.\nIn the 16th and 17th centuries, Spain considered the Pacific Ocean a \"mare clausum\"\u00a0\u2013 a sea closed to other naval powers. As the only known entrance from the Atlantic, the Strait of Magellan was at times patrolled by fleets sent to prevent the entrance of non-Spanish ships. On the western side of the Pacific Ocean the Dutch threatened the Spanish Philippines.\nThe 18th century marked the beginning of major exploration by the Russians in Alaska and the Aleutian Islands, such as the First Kamchatka expedition and the Great Northern Expedition, led by the Danish-born Russian navy officer Vitus Bering. Spain also sent expeditions to the Pacific Northwest, reaching Vancouver Island in southern Canada, and Alaska. The French explored and colonized Polynesia, and the British made three voyages with James Cook to the South Pacific and Australia, Hawaii, and the North American Pacific Northwest. In 1768, Pierre-Antoine V\u00e9ron, a young astronomer accompanying Louis Antoine de Bougainville on his voyage of exploration, established the width of the Pacific with precision for the first time in history. One of the earliest voyages of scientific exploration was organized by Spain in the Malaspina Expedition of 1789\u20131794. It sailed vast areas of the Pacific, from Cape Horn to Alaska, Guam and the Philippines, New Zealand, Australia, and the South Pacific.\nNew Imperialism.\nGrowing imperialism during the 19th century resulted in the occupation of much of Oceania by European powers, and later Japan and the United States. Significant contributions to oceanographic knowledge were made by the voyages of HMS \"Beagle\" in the 1830s, with Charles Darwin aboard; HMS \"Challenger\" during the 1870s; the USS \"Tuscarora\" (1873\u201376); and the German \"Gazelle\" (1874\u201376).\nIn Oceania, France obtained a leading position as imperial power after making Tahiti and New Caledonia protectorates in 1842 and 1853, respectively. After navy visits to Easter Island in 1875 and 1887, Chilean navy officer Policarpo Toro negotiated the incorporation of the island into Chile with native Rapanui in 1888. By occupying Easter Island, Chile joined the imperial nations.53 By 1900 nearly all Pacific islands were in control of Britain, France, United States, Germany, Japan, and Chile.\nAlthough the United States gained control of Guam and the Philippines from Spain in 1898, Japan controlled most of the western Pacific by 1914 and occupied many other islands during the Pacific War; however, by the end of that war, Japan was defeated and the U.S. Pacific Fleet was the virtual master of the ocean. The Japanese-ruled Northern Mariana Islands came under the control of the United States. Since the end of World War II, many former colonies in the Pacific have become independent states.\nGeography.\nThe Pacific separates Asia and Australia from the Americas. It may be further subdivided by the equator into northern (North Pacific) and southern (South Pacific) portions. It extends from the Antarctic region in the South to the Arctic in the north. The Pacific Ocean encompasses approximately one-third of the Earth's surface, having an area of \u00a0\u2013 larger than Earth's entire landmass combined, .\nExtending approximately from the Bering Sea in the Arctic to the northern extent of the circumpolar Southern Ocean at 60\u00b0S (older definitions extend it to Antarctica's Ross Sea), the Pacific reaches its greatest east\u2013west width at about 5\u00b0N latitude, where it stretches approximately from Indonesia to the coast of Colombia\u00a0\u2013 halfway around the world, and more than five times the diameter of the Moon. Its geographic center is in eastern Kiribati south of Kiritimati, just west from Starbuck Island at . The lowest known point on Earth\u00a0\u2013 the Mariana Trench\u00a0\u2013 lies below sea level. Its average depth is , putting the total water volume at roughly .\nDue to the effects of plate tectonics, the Pacific Ocean is currently shrinking by roughly per year on three sides, roughly averaging a year. By contrast, the Atlantic Ocean is increasing in size.\nAlong the Pacific Ocean's irregular western margins lie many seas, the largest of which are the Celebes Sea, Coral Sea, East China Sea (East Sea), Philippine Sea, Sea of Japan, South China Sea (South Sea), Sulu Sea, Tasman Sea, and Yellow Sea (West Sea of Korea). The Indonesian Seaway (including the Strait of Malacca and Torres Strait) joins the Pacific and the Indian Ocean to the west, and Drake Passage and the Strait of Magellan link the Pacific with the Atlantic Ocean on the east. To the north, the Bering Strait connects the Pacific with the Arctic Ocean.\nAs the Pacific straddles the 180th meridian, the \"West Pacific\" (or \"western Pacific\", near Asia) is in the Eastern Hemisphere, while the \"East Pacific\" (or \"eastern Pacific\", near the Americas) is in the Western Hemisphere.\nThe Southern Pacific Ocean harbors the Southeast Indian Ridge crossing from south of Australia turning into the Pacific-Antarctic Ridge (north of the South Pole) and merges with another ridge (south of South America) to form the East Pacific Rise which also connects with another ridge (south of North America) which overlooks the Juan de Fuca Ridge.\nFor most of Magellan's voyage from the Strait of Magellan to the Philippines, the explorer indeed found the ocean peaceful; however, the Pacific is not always peaceful. Many tropical storms batter the islands of the Pacific. The lands around the Pacific Rim are full of volcanoes and often affected by earthquakes. Tsunamis, caused by underwater earthquakes, have devastated many islands and in some cases destroyed entire towns.\nThe Martin Waldseem\u00fcller map of 1507 was the first to show the Americas separating two distinct oceans. Later, the Diogo Ribeiro map of 1529 was the first to show the Pacific at about its proper size.\nAsia-Pacific.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nAmericas.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nUninhabited territories.\nTerritories with no permanent civilian population.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nLandmasses and islands.\nThe Pacific Ocean has most of the islands in the world. There are about 25,000 islands in the Pacific Ocean. The islands entirely within the Pacific Ocean can be divided into three main groups known as Micronesia, Melanesia and Polynesia. Micronesia, which lies north of the equator and west of the International Date Line, includes the Mariana Islands in the northwest, the Caroline Islands in the center, the Marshall Islands to the east and the islands of Kiribati in the southeast.\nMelanesia, to the southwest, includes New Guinea, the world's second largest island after Greenland and by far the largest of the Pacific islands. The other main Melanesian groups from north to south are the Bismarck Archipelago, the Solomon Islands, Santa Cruz, Vanuatu, Fiji and New Caledonia.\nThe largest area, Polynesia, stretching from Hawaii in the north to New Zealand in the south, also encompasses Tuvalu, Tokelau, Samoa, Tonga and the Kermadec Islands to the west, the Cook Islands, Society Islands and Austral Islands in the center, and the Marquesas Islands, Tuamotu, Mangareva Islands, and Easter Island to the east.\nIslands in the Pacific Ocean are of four basic types: continental islands, high islands, coral reefs and uplifted coral platforms. Continental islands lie outside the andesite line and include New Guinea, the islands of New Zealand, and the Philippines. Some of these islands are structurally associated with nearby continents. High islands are of volcanic origin, and many contain active volcanoes. Among these are Bougainville, Hawaii, and the Solomon Islands.\nThe coral reefs of the South Pacific are low-lying structures that have built up on basaltic lava flows under the ocean's surface. One of the most dramatic is the Great Barrier Reef off northeastern Australia with chains of reef patches. A second island type formed of coral is the uplifted coral platform, which is usually slightly larger than the low coral islands. Examples include Banaba (formerly Ocean Island) and Makatea in the Tuamotu group of French Polynesia.\nWater characteristics.\nThe volume of the Pacific Ocean, representing about 50.1 percent of the world's oceanic water, has been estimated at some . Surface water temperatures in the Pacific can vary from , the freezing point of seawater, in the poleward areas to about near the equator. Salinity also varies latitudinally, reaching a maximum of 37 parts per thousand in the southeastern area. The water near the equator, which can have a salinity as low as 34 parts per thousand, is less salty than that found in the mid-latitudes because of abundant equatorial precipitation throughout the year. The lowest counts of less than 32 parts per thousand are found in the far north as less evaporation of seawater takes place in these frigid areas. The motion of Pacific waters is generally clockwise in the Northern Hemisphere (the North Pacific gyre) and counter-clockwise in the Southern Hemisphere. The North Equatorial Current, driven westward along latitude 15\u00b0N by the trade winds, turns north near the Philippines to become the warm Japan or Kuroshio Current.\nTurning eastward at about 45\u00b0N, the Kuroshio forks and some water moves northward as the Aleutian Current, while the rest turns southward to rejoin the North Equatorial Current. The Aleutian Current branches as it approaches North America and forms the base of a counter-clockwise circulation in the Bering Sea. Its southern arm becomes the chilled slow, south-flowing California Current. The South Equatorial Current, flowing west along the equator, swings southward east of New Guinea, turns east at about 50\u00b0S, and joins the main westerly circulation of the South Pacific, which includes the Earth-circling Antarctic Circumpolar Current. As it approaches the Chilean coast, the South Equatorial Current divides; one branch flows around Cape Horn and the other turns north to form the Peru or Humboldt Current.\nClimate.\nThe climate patterns of the Northern and Southern Hemispheres generally mirror each other. The trade winds in the southern and eastern Pacific are remarkably steady while conditions in the North Pacific are far more varied with, for example, cold winter temperatures on the east coast of Russia contrasting with the milder weather off British Columbia during the winter months due to the preferred flow of ocean currents.\nIn the tropical and subtropical Pacific, the El Ni\u00f1o Southern Oscillation (ENSO) affects weather conditions. To determine the phase of ENSO, the most recent three-month sea surface temperature average for the area approximately to the southeast of Hawaii is computed, and if the region is more than above or below normal for that period, then an El Ni\u00f1o or La Ni\u00f1a is considered in progress.\nIn September 2025, NOAA reported that global ocean surface temperatures remained at near-record levels, with June\u2013August 2025 ranking as the third warmest in their 176-year record.\nIn the tropical western Pacific, the monsoon and the related wet season during the summer months contrast with dry winds in the winter which blow over the ocean from the Asian landmass. Worldwide, tropical cyclone activity peaks in late summer, when the difference between temperatures aloft and sea surface temperatures is the greatest; however, each particular basin has its own seasonal patterns. On a worldwide scale, May is the least active month, while September is the most active month. November is the only month in which all the tropical cyclone basins are active. The Pacific hosts the two most active tropical cyclone basins, which are the northwestern Pacific and the eastern Pacific. Pacific hurricanes form south of Mexico, sometimes striking the western Mexican coast and occasionally the Southwestern United States between June and October, while typhoons forming in the northwestern Pacific moving into southeast and east Asia from May to December. Tropical cyclones also form in the South Pacific basin, where they occasionally impact island nations.\nIn the arctic, icing from October to May can present a hazard for shipping while persistent fog occurs from June to December. A climatological low in the Gulf of Alaska keeps the southern coast wet and mild during the winter months. The Westerlies and associated jet stream within the Mid-Latitudes can be particularly strong, especially in the Southern Hemisphere, due to the temperature difference between the tropics and Antarctica, which records the coldest temperature readings on the planet. In the Southern hemisphere, because of the stormy and cloudy conditions associated with extratropical cyclones riding the jet stream, it is usual to refer to the Westerlies as the Roaring Forties, Furious Fifties and Shrieking Sixties according to the varying degrees of latitude.\nGeology.\nThe ocean was first mapped by Abraham Ortelius; he called it Maris Pacifici following Ferdinand Magellan's description of it as \"a pacific sea\" during his circumnavigation from 1519 to 1522. To Magellan, it seemed much more calm (pacific) than the Atlantic.\nThe andesite line is the most significant regional distinction in the Pacific. A petrologic boundary, it separates the deeper, mafic igneous rock of the Central Pacific Basin from the partially submerged continental areas of felsic igneous rock on its margins. The andesite line follows the western edge of the islands off California and passes south of the Aleutian arc, along the eastern edge of the Kamchatka Peninsula, the Kuril Islands, Japan, the Mariana Islands, the Solomon Islands, and New Zealand's North Island.\nThe dissimilarity continues northeastward along the western edge of the Andes Cordillera along South America to Mexico, returning then to the islands off California. Indonesia, the Philippines, Japan, New Guinea, and New Zealand lie outside the andesite line.\nWithin the closed loop of the andesite line are most of the deep troughs, submerged volcanic mountains, and oceanic volcanic islands that characterize the Pacific basin. Here basaltic lavas gently flow out of rifts to build huge dome-shaped volcanic mountains whose eroded summits form island arcs, chains, and clusters. Outside the andesite line, volcanism is of the explosive type, and the Pacific Ring of Fire is the world's foremost belt of explosive volcanism. The Ring of Fire is named after the several hundred active volcanoes that sit above the various subduction zones.\nThe Pacific Ocean is the only ocean which is mostly bounded by subduction zones. Only the central part of the North American coast and the Antarctic and Australian coasts have no nearby subduction zones.\nGeological history.\nThe Pacific Ocean was born 750million years ago at the breakup of Rodinia, although it is generally called the Panthalassa until the breakup of Pangea, about 200million years ago. The oldest Pacific Ocean floor is only around 180 Ma old, with older crust subducted by now.\nSeamount chains.\nThe Pacific Ocean contains several long seamount chains, formed by hotspot volcanism. These include the Hawaiian\u2013Emperor seamount chain and the Louisville Ridge.\nEconomy.\nThe exploitation of the Pacific's mineral wealth is hampered by the ocean's great depths. In shallow waters of the continental shelves off the coasts of Australia and New Zealand, petroleum and natural gas are extracted, and pearls are harvested along the coasts of Australia, Japan, Papua New Guinea, Nicaragua, Panama, and the Philippines, although in sharply declining volume in some cases.\nFishing.\nFish are an important economic asset in the Pacific. The shallower shoreline waters of the continents and the more temperate islands yield herring, salmon, sardines, snapper, swordfish, and tuna, as well as shellfish. Overfishing has become a serious problem in some areas. Overfishing leads to depleted fish populations and closed fisheries, causing both economic and ecologic consequences. For example, catches in the rich fishing grounds of the Okhotsk Sea off the Russian coast have been reduced by at least half since the 1990s as a result of overfishing.\nEnvironment.\nThe Northwestern Pacific Ocean is most susceptible to micro plastic pollution due to its proximity to highly populated countries like Japan and China. The quantity of small plastic fragments floating in the north-east Pacific Ocean increased a hundredfold between 1972 and 2012. The ever-growing Great Pacific Garbage Patch between California and Japan is three times the size of France. An estimated 80,000 metric tons of plastic inhabit the patch, totaling 1.8trillion pieces.\nMarine pollution is a generic term for the harmful entry into the ocean of chemicals or particles. The main culprits are those using the rivers for disposing of their waste. The rivers then empty into the ocean, often also bringing chemicals used as fertilizers in agriculture. The excess of oxygen-depleting chemicals in the water leads to hypoxia and the creation of a dead zone.\nMarine debris, also known as marine litter, is human-created waste that has ended up floating in a lake, sea, ocean, or waterway. Oceanic debris tends to accumulate at the center of gyres and coastlines, frequently washing aground where it is known as beach litter.\nIn addition, the Pacific Ocean has served as the crash site of satellites, including Mars 96, Fobos-Grunt, and Upper Atmosphere Research Satellite.\nNuclear waste.\nFrom 1946 to 1958, Marshall Islands served as the Pacific Proving Grounds, designated by the United States, and played host to a total of 67 nuclear tests conducted across various atolls. Several nuclear weapons were lost in the Pacific Ocean, including one-megaton bomb that was lost during the 1965 Philippine Sea A-4 incident.\nIn 2021, the discharge of radioactive water from the Fukushima nuclear plant into the Pacific Ocean over a course of 30 years was approved by the Japanese Cabinet. The Cabinet concluded the radioactive water would have been diluted to drinkable standard. Apart from dumping, leakage of tritium into the Pacific was estimated to be between 20 and 40 trillion Bqs from 2011 to 2013, according to the Fukushima plant.\nDeep sea mining.\nAn emerging threat for the Pacific Ocean is the development of deep-sea mining.\nDeep-sea mining is aimed at extracting manganese nodules that contain minerals such as magnesium, nickel, copper, zinc and cobalt. The largest deposits of these are found in the Pacific Ocean between Mexico and Hawaii in the Clarion Clipperton fracture zone.\nDeep-sea mining for manganese nodules appears to have drastic consequences for the ocean. It disrupts deep-sea ecosystems and may cause irreversible damage to fragile marine habitats. Sediment stirring and chemical pollution threaten various marine animals. In addition, the mining process can lead to greenhouse gas emissions and promote further climate change. Preventing deep-sea mining is therefore important to ensure the long-term health of the ocean.\nList of major ports.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "23071", "revid": "40727880", "url": "https://en.wikipedia.org/wiki?curid=23071", "title": "Prince Edward Island", "text": "Province of Canada\nPrince Edward Island is an island province of Canada. It is the smallest province by both land area and population, and has the highest population density in Canada. The island has several nicknames: \"Garden of the Gulf\", \"Birthplace of Confederation\" and \"Cradle of Confederation\". Its capital and largest city is Charlottetown. It is one of the three Maritime provinces and one of the four Atlantic provinces.\nHistorically, the island has formed an integral part of the Mi'kmaw homeland, Mi'kma'ki, comprising one part of the district (also spelled , lit.\u2009'PEI and Pictou'). Come 1604, Epekwitk would be colonized by the French as part of the colony of Acadia, where it became known as Isle St-Jean (St. John's Island). It was later ceded to the British at the conclusion of the Seven Years' War in 1763 and became part of the colony of Nova Scotia. In 1769, St. John's Island became its own British colony and its name was changed to Prince Edward Island (PEI) in 1798. PEI hosted the Charlottetown Conference in 1864 to discuss a union of the Maritime provinces; however, the conference became the first in a series of meetings which led to Canadian Confederation on July 1, 1867. Prince Edward Island initially balked at Confederation but, facing bankruptcy from the Land Question and construction of a railroad, joined as Canada's seventh province on July 1, 1873.\nAccording to Statistics Canada, the province of Prince Edward Island had 180,029 residents in 2025. The backbone of the island economy is farming; it produces 25% of Canada's potatoes. Other important industries include fisheries, tourism, aerospace, biotechnology, information technology and renewable energy. As Prince Edward Island is one of Canada's older settled areas, its population still reflects the origins of its earliest settlers, with Acadian, Scottish, Irish, and English surnames being dominant.\nPrince Edward Island is located in the Gulf of St. Lawrence, about 10\u00a0km (6 miles) across the Northumberland Strait from both Nova Scotia and New Brunswick. It is about north of Halifax and east of Quebec City. It has a land area of , is the 104th-largest island in the world and Canada's 23rd-largest island. It is the only Canadian province consisting entirely of islands.\nEtymology.\nThe island is known in Mi'kmawi'simk, the indigenous Mi'kmaw language, as or , roughly translated as \"land cradled on the waves\".\nWhen the island was part of Acadia, originally settled by French colonists, its French name was ('St. John's Island'). In French, the island is today called .\nThe island was split from the British colony of Nova Scotia in 1769, and renamed in 1798 after Prince Edward, Duke of Kent and Strathearn (1767\u20131820), the fourth son of King George III and, in 1819, father of the future Queen Victoria. Thus, Prince Edward has been called \"Father of the Canadian Crown\".\nIn Scottish Gaelic, the island's name is (lit.\u2009'the Island of the Prince', the local form of the longer ) or (literally, 'John's Island' in reference to the island's former French name) for some Gaelic speakers in Nova Scotia, though not on PEI.\nGeography.\nPrince Edward Island is located in the Gulf of St. Lawrence, west of Cape Breton Island, north of the Nova Scotia peninsula, and northeast of New Brunswick. Its southern shore bounds the Northumberland Strait. The island has two urban areas, and in total, is the most densely populated province in Canada.\nClimate.\nThe island has a maritime climate, moderate and strongly influenced by the surrounding Gulf of St. Lawrence. As such, it is generally milder than many areas of New Brunswick and Nova Scotia due to the warmer waters of the Gulf of St. Lawrence. The climate is characterized by changeable weather throughout the year; in which specific weather conditions seldom last for long.\nDuring July and August, the average daytime high in PEI is ; however, the temperature can sometimes exceed during these months. In the winter months of January and February, the average daytime high is . The Island receives an average yearly rainfall of and an average yearly snowfall of .\nWinters are moderately cold and long but are milder than inland locations, with clashes of cold Arctic air and milder Atlantic air causing frequent temperature swings. The climate is considered to be more humid continental climate than oceanic since the Gulf of St. Lawrence freezes over, thus eliminating any moderation. The mean temperature is in January. During the winter months, the island usually has many storms (which may produce rain as well as snow) and blizzards since during this time, storms originating from the North Atlantic or the Gulf of Mexico frequently pass through. Springtime temperatures typically remain cool until the sea ice has melted, usually in late April or early May.\nThe following climate chart depicts the average conditions of Charlottetown, as an example of the province's climate.\nGeology.\nBetween 250 and 300 million years ago, freshwater streams flowing from ancient mountains brought silt, sand and gravel into what is now the Gulf of St. Lawrence. These sediments accumulated to form a sedimentary basin, and make up the island's bedrock. When the Pleistocene glaciers receded about 15,000 years ago, glacial debris such as till were left behind to cover most of the area that would become the island. This area was connected to the mainland by a strip of land, but when ocean levels rose as the glaciers melted, this land strip was flooded, forming the island. As the land rebounded from the weight of the ice, the island rose up to elevate it farther from the surrounding water.\nMost of the bedrock in Prince Edward Island is composed of red sandstone, part of the Permian age Pictou Group.\nAlthough commercial deposits of minerals have not been found, exploration in the 1940s for natural gas beneath the northeastern end of the province resulted in the discovery of an undisclosed quantity of gas. The Island was reported by government to have only 0.08\u00a0tcf of \"technically recoverable\" natural gas. Twenty exploration wells for hydrocarbon resources have been drilled on Prince Edward Island and offshore. The first reported well was Hillsborough No.#1, drilled in Charlottetown Harbour in 1944 (the world's first offshore well), and the most recent was New Harmony No.#1 in 2007. Since the resurgence of exploration in the mid-1990s, all wells that have shown promising gas deposits have been stimulated through hydraulic fracture or \"fracking\". All oil and natural gas exploration and exploitation activities on the Island are governed by the \"Oil and Natural Gas Act\" R.S.P.E.I. 1988, Cap. 0-5 and its associated regulations and orders.\nWater supply.\nThe Province of Prince Edward Island is completely dependent on groundwater for its source of drinking water, with approximately 305 high capacity wells in use as of December 2018. As groundwater flows through an aquifer, it is naturally filtered. The water for the city of Charlottetown is extracted from thirteen wells in three wellfields and distributed to customers. The water removed is replenished by precipitation.\nInfrastructure in Charlottetown that was installed in 1888 is still in existence. With the age of the system in the older part of Charlottetown, concern has been raised regarding lead pipes. The Utility has been working with its residents on a lead-replacement program. A plebiscite in 1967 was held in Charlottetown over fluoridation, and residents voted in favour. Under provincial legislation, the Utility is required to report to its residents on an annual basis. It is also required to do regular sampling of the water and an overview is included in each annual report. The Winter River watershed provides about 92 per cent of the daily water supply for the city of Charlottetown, which had difficulty in each of 2011, 2012 and 2013 with its supply, until water meters were installed.\nGovernment tabled a discussion paper on the proposed \"Water Act\" for the province on July 8, 2015. The use of groundwater came under scrutiny as the potato industry, which accounts for $1 billion every year and 50% of farm receipts, has pressed the government to lift a moratorium on high-capacity water wells for irrigation. The release of the discussion paper was to set off a consultation process in the autumn of 2015.\nDetailed information about the quality of drinking water in PEI communities and watersheds can be found on the provincial government's official website. It provides a summary of the ongoing testing of drinking water done by the Prince Edward Island Analytical Laboratories. Average drinking-water quality results are available, and information on the following parameters are provided: alkalinity; cadmium; calcium; chloride; chromium; iron; magnesium; manganese; nickel; nitrate; pH; phosphorus; potassium; sodium; and sulfate, as well as the presence of pesticides. Water-testing services are provided for a variety of clients through the PEI Analytical Laboratories which assesses according to the recommendations of the Guidelines for Canadian Drinking Water Quality published by Health Canada.\nFlora and fauna.\nPrince Edward Island used to have native moose, bear, caribou, wolf, and other larger species. Due to hunting and habitat disruption these species are no longer found on the island. Some species common to P.E.I. are red foxes, coyote, blue jays, and robins. Skunks and raccoons are common non-native species. Species at risk in P.E.I. include piping plovers, American eel, bobolinks, little brown bat, and beach pinweed.\nSome species are unique to the province. In 2008, a new ascomycete species, \"Jahnula apiospora\" (Jahnulales, Dothideomycetes), was collected from submerged wood in a freshwater creek on Prince Edward Island.\nNorth Atlantic right whales, one of the rarest whale species, once thought to be rare visitors into St. Lawrence regions until 1994, have been showing dramatic increases (annual concentrations were discovered off Perc\u00e9 in 1995 and gradual increases across the regions since 1998), and since 2014, notable numbers of whales have been recorded around Cape Breton to Prince Edward Island as 35 to 40 whales were seen in these areas in 2015.\nHistory.\nMi'kmaw district.\nThe Mi'kmaq are the Indigenous inhabitants of what is now Prince Edward Island, calling their country Mi'kma'ki. The island's land based formed one part of the district \"Epekwitk aq Piktuk\" (also spelled \"Epegwitg aq Pigtug\"). Named \"Epekwitk\" (and rendered as \"Abegweit\" in English)\u2014meaning \"cradled on the waves\"\u2014the island was governed by \"Saqamaq\", or community chiefs, a women's council (\"Saqama'sgw\"), and wampum keepers (\"Putu's\"), eventually falling under the jurisdiction of the \"Sante' (or Mi'kmawey) Mawio'mi\" and the Grand Chief, or \"Kji Sagamaw\". Today, Epekwitk (aq Piktuk), along with the other seven districts of Mi'kma'ki, are protected by the Peace and Friendship Treaties that the Mi'kmaq have with the Crown; however, rather than district-level governance, administration is currently overseen by band governments. On Epekwitk, the two communities are the Abegweit and Lennox Island First Nations.\nStretching back into deep history, the earliest stories of the Mi'kmaq go back to the time of Glooscap, a cultural hero and first human in Wabanaki mythology. Big in size and power, Mi'kmaw legend says that when Glooscap finished painting the splendour of the world, he dipped his brush into a blend of all the colours and created Epekwitk\u2014his favourite island. When Glooscap slept, \"Enmigtaqamu'g\" (or mainland Nova Scotia) was his bed and Epekwitk his pillow. Another legend tells us that \"Minegoo\"\u2014another name for the island, meaning, simply, \"island\" in Mi'kmawi'simk\u2014was formed by the Great Spirit placing on the Blue Waters some dark red crescent-shaped clay.\nMi'kmaw oral history recalls a time when the world was covered in water. It was then that the being Sebanees, arriving in \"kjiktu\u2019lnu \"(\"our great boat\"), landed on the shores of Epekwitk. The boat, made of ice, carried all the animals and fish his family would need for survival, and it is said that Epekwitk's unique land formation was a result of the melting of the ice boat. Archaeological evidence, such as shell middens and campsite remains, corroborate Mi'kmaw stories which indicate an ancient presence in Epekwitk. Prior to European colonization of the Americas, Mi'kmaq engaged in varied relations with neighbouring nations, such as the Wolastoqiyik (Maliseet), Passamaquoddy, and Abenaki, with whom they formed the Wabanaki Confederacy in Dawnland.\nFrench colony.\nIn 1534, Jacques Cartier was the first European to see the island. In 1604, the Kingdom of France laid claim to the lands of the Maritimes under the discovery doctrine, including Prince Edward Island, establishing the French colony of Acadia in Mi'kma'ki. The island was named \"\u00cele Saint-Jean\" (St. John's Island) by the French. The Mi'kmaq never recognized the claim but welcomed the French as trading partners and allies.\nDuring the 18th century, the French were engaged in a series of conflicts with the Kingdom of Great Britain and its colonies. Several battles between the two belligerents occurred on Prince Edward Island during this period. Following the British capture of Louisbourg during the War of the Austrian Succession, New Englanders launched an attack on \u00cele Saint-Jean (now Prince Edward Island); with a British detachment landed at Port-la-Joye. The island's capital had a garrison of 20 French soldiers under the command of Joseph du Pont Duvivier. The troops fled the settlement, and the New Englanders burned the settlement to the ground. Duvivier and the twenty men retreated up the Northeast River (Hillsborough River), pursued by the New Englanders until the French troops were reinforced with the arrival of the Acadian militia and the Mi'kmaq. The French troops and their allies were able to drive the New Englanders to their boats. Nine New Englanders were killed, wounded or made prisoner. The New Englanders took six Acadian hostages, who would be executed if the Acadians or Mi'kmaq rebelled against New England control. The New England troops left for Louisbourg. Duvivier and his 20 troops left for Quebec. After the fall of Louisbourg, the resident French population of \u00cele Royale (now Cape Breton Island) were deported to France, with the remaining Acadians of \u00cele Saint-Jean living under the threat of deportation for the remainder of the war.\nNew Englanders had a force of 200 soldiers stationed at Port-La-Joye, as well as two warships boarding supplies for its journey of Louisbourg. To regain Acadia, Ramezay was sent from Quebec to the region to join forces with the Duc d'Anville expedition. Upon arriving at Chignecto, he sent Boishebert to \u00cele Saint-Jean to ascertain the size of the New England force. After Boishebert returned, Ramezay sent Joseph-Michel Legardeur de Croisille et de Montesson along with over 500 men, 200 of whom were Mi'kmaq, to Port-La-Joye. In July 1746, the battle happened near York River. Montesson and his troops killed forty New Englanders and captured the rest. Montesson was commended for having distinguished himself in his first independent command. Hostilities between the British and French were ended in 1748 with the Treaty of Aix-la-Chapelle in 1748.\nRoughly one thousand Acadians lived on the island prior to the Acadian Exodus from Nova Scotia. The population grew to nearly 5,000 the late 1740s and early 1750s, as Acadians from Nova Scotia fled to the island during the Acadian Exodus, and the subsequent British-ordered expulsions beginning in 1755.\nHostilities between British and French colonial forces resumed in 1754, although formal declarations of war were not issued until 1756. After French forces were defeated at the siege of Louisbourg, the British performed a military campaign on Ile Saint-Jean (now Prince Edward Island) to secure the island. The campaign was led by Colonel Andrew Rollo under orders from General Jeffery Amherst. The following campaigns saw the deportation of most Acadians from the island. Many Acadians died in the expulsion en route to France; on December 13, 1758, the transport ship \"Duke William\" sank and 364 died. A day earlier the \"Violet\" sank and 280 died; several days later sank with 213 on board. The French formally ceded the island, and most of New France to the British in the Treaty of Paris of 1763.\nBritish colony.\nInitially named St. John's Island by the British, the island was administered as part of the colony of Nova Scotia, until it was split into a separate colony in 1769. In the mid-1760s, a survey team led by Samuel Holland divided the Island into 67 lots. On July 1, 1767, these properties were allocated to supporters of King George III by means of a lottery. Ownership of the land remained in the hands of landlords in England, angering Island settlers who were unable to gain title to land on which they worked and lived. Significant rent charges (to absentee landlords) created further anger. The land had been given to the absentee landlords with a number of conditions attached regarding upkeep and settlement terms, many of which were not satisfied. Islanders spent decades trying to convince the Crown to confiscate the lots; however, the descendants of the original owners were generally well connected to the British government and refused to give up the land.\nAfter the island was detached from Nova Scotia to become a separate colony, Walter Patterson was appointed the first British governor of St. John's Island in 1769. Assuming the office in 1770, he had a controversial career during which land title disputes and factional conflict slowed the initial attempts to populate and develop the island under a feudal system. In an attempt to attract settlers from Ireland, in one of his first acts (1770) Patterson led the island's colonial assembly to rename the island \"New Ireland\", but the British Government promptly vetoed this as it exceeded the authority vested in the colonial government; only the Privy Council in London could change the name of a colony.\nDuring the American Revolutionary War Charlottetown was raided in 1775 by a pair of American-employed privateers. Two armed schooners, \"Franklin\" and \"Hancock\", from Beverly, Massachusetts, made prisoner of the attorney-general at Charlottetown, on advice given them by some Pictou residents after they had taken eight fishing vessels in the Gut of Canso.\nDuring and after the American Revolutionary War, from 1776 to 1783, the colony's efforts to attract exiled Loyalist refugees from the rebellious North American colonies met with some success. Walter Patterson's brother, John Patterson, one of the original grantees of land on the island, was a temporarily exiled Loyalist and led efforts to persuade others to come. Governor Patterson's dismissal in 1787, and his recall to London in 1789, dampened his brother's efforts, leading John to focus on his interests in the United States. Edmund Fanning, also a Loyalist exiled by the Revolution, took over as the second governor, serving until 1804. His tenure was more successful than Patterson's. A large influx of Scottish Highlanders in the late 1700s also resulted in St. John's Island having the highest proportion of Scottish immigrants in Canada. This led to a higher proportion of Scottish Gaelic speakers and thriving culture surviving on the island than in Scotland itself, as the settlers could more easily avoid English influence overseas.\nOn November 29, 1798, during Fanning's administration, the British government granted approval to change the colony's name from St. John's Island to Prince Edward Island to distinguish it from areas with similar names in what is now Atlantic Canada, such as the cities of Saint John in New Brunswick and St. John's in Newfoundland. The colony's new name honoured the fourth son of King George III, Prince Edward Augustus, the Duke of Kent (1767\u20131820), who subsequently led the British military forces on the continent as Commander-in-Chief, North America (1799\u20131800), with his headquarters in Halifax.\nIn 1853, the Island government passed the Land Purchase Act which empowered them to purchase lands from those owners who were willing to sell, and then resell the land to settlers for low prices. This scheme collapsed when the Island ran short of money to continue with the purchases. Many of these lands also were fertile, and were some of the key factors to sustaining Prince Edward Island's economy.\nConfederation.\nFrom September 1 to 7, 1864, Prince Edward Island hosted the Charlottetown Conference, which was the first meeting in the process leading to the Quebec Resolutions and the creation of Canada in 1867. Prince Edward Island found the terms of union unfavourable and balked at joining in 1867, choosing to remain a colony of the United Kingdom. In the late 1860s, the colony examined various options, including the possibility of becoming a discrete dominion unto itself, as well as entertaining delegations from the United States, who were interested in Prince Edward Island joining the United States.\nIn 1871, the colony began construction of the Prince Edward Island Railway (PEIR) and, frustrated by Great Britain's Colonial Office, began negotiations with the United States. In 1873, Canadian Prime Minister John A. Macdonald, anxious to thwart American expansionism and facing the distraction of the Pacific Scandal, negotiated for Prince Edward Island to join Canada. The Dominion Government of Canada assumed the colony's extensive railway debts and agreed to finance a buy-out of the last of the colony's absentee landlords to free the island of leasehold tenure and from any new immigrants entering the island (accomplished through the passage of the \"Land Purchase Act, 1875\"). Prince Edward Island entered Confederation on July 1, 1873.\nAs a result of having hosted the inaugural meeting of Confederation, the Charlottetown Conference, Prince Edward Island presents itself as the \"Birthplace of Confederation\" and this is commemorated through several buildings, a ferry vessel, and the Confederation Bridge (constructed 1993 to 1997). The most prominent building in the province honouring this event is the Confederation Centre of the Arts, presented as a gift to Prince Edward Islanders by the 10 provincial governments and the Federal Government upon the centenary of the Charlottetown Conference, where it stands in Charlottetown as a national monument to the \"Fathers of Confederation\". The centre is one of the 22 National Historic Sites of Canada located in Prince Edward Island.\nDemographics.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nEthnicity.\nAccording to the 2016 Canadian Census of the 139,690 people who self-identified with an ethnic origin, 98,615 were of European origins and 85,145 chose British Isles Origins. The largest ethnic group consists of people of Scottish descent (36%), followed by English (29%), Irish (28%), French (21%), German (5%), and Dutch (3%) descent.\nPrince Edward Island's population is largely white; there are few visible minorities. Chinese Canadians are the largest visible minority group of Prince Edward Island, comprising 1.3% of the province's population. Almost half of respondents identified their ethnicity as \"Canadian\".\n\"Source: Statistics Canada\"\nLanguage.\nAs of the 2021 Canadian Census, the ten most spoken languages in the province included English (149,525 or 99.36%), French (19,445 or 12.92%), Mandarin (2,940 or 1.95%), Hindi (1,660 or 1.1%), Tagalog (1,630 or 1.08%), Punjabi (1,550 or 1.03%), Spanish (1,425 or 0.95%), Arabic (1,165 or 0.77%), German (1,040 or 0.69%), and Vietnamese (785 or 0.52%). The question on knowledge of languages allows for multiple responses.\nThe Canada 2016 Census showed a population of 142,910. Of the 140,020 singular responses to the census question concerning mother tongue, the most commonly reported languages were as follows:\nIn addition, there were 460 responses of both English and a \"non-official language\"; 30 of both French and a \"non-official language\"; 485 of both English and French; and 20 of English, French, and a \"non-official language\". (Figures shown are for the number of single language responses and the percentage of total single-language responses.)\nReligion.\nAccording to the 2021 census, religious groups in Prince Edward Island included:\nTraditionally, the population has been evenly divided between Catholic and Protestant affiliations. The 2001 census indicated number of adherents for the Roman Catholic Church with 63,240 (47%) and various Protestant churches with 57,805 (43%). This included the United Church of Canada with 26,570 (20%); the Presbyterian Church with 7,885 (6%) and the Anglican Church of Canada with 6,525 (5%); those with no religion were among the lowest of the provinces with 8,705 (6.5%). If one considers that the founders of the United Church of Canada were largely Presbyterians in Prince Edward Island, the Island has one of the highest percentages of Presbyterians in the country. Since 2016 there are two Amish settlements on Prince Edward Island.\nEconomy.\nAgriculture remains the dominant industry in the provincial economy, as it has since colonial times. In 2015, agriculture and agri-food manufacturing was responsible for 7.6% of the province's GDP. The Island has a total land area of with approximately cleared for agricultural use. In 2016, the Census of Agriculture counted 1,353 farms on the Island, which is a 9.5% decrease from the previous census (2011). During the 20th century, potatoes were grown as a cash crop across more than a million acres of farmland. Traditionally, crops were grown on a rotational basis: common examples would be either potatoes, hay, clover, or oats being grown on a piece of land at any given time. More recently, the total amount of farms used for potatoes has decreased, but the province is still Canada's largest supplier of the crop. The number of acres under potato production in 2010 was 88,000, while soy accounted for 55,000. There are approximately 330 potato growers on PEI, with the grand majority of these being family farms, often with multiple generations working together. The province currently accounts for a quarter of Canada's total potato production, producing approximately annually. Comparatively, the state of Idaho produces approximately annually, with a population approximately 9.5 times greater. The province is a major producer of seed potatoes, exporting to more than twenty countries around the world. An estimated total of 70% of the land is cultivated and 25% of all potatoes grown in Canada originate from P.E.I. The processing of frozen fried potatoes, green vegetables, and berries is a leading business activity.\nAs a legacy of the island's colonial history, the provincial government enforces strict rules for non-resident land ownership, especially since the PEI \"Lands Protection Act\" of 1982. Residents and corporations are limited to maximum holdings of 400 and 1,200 hectares respectively. There are also restrictions on non-resident ownership of shorelines. Some groups, however, such as the Buddhist organization Bliss and Wisdom, have been accused of exploiting loopholes in the lands protection legislation to purchase vast quantities of land.\nMany of the province's coastal communities rely upon shellfish harvesting, particularly lobster fishing as well as oyster fishing and mussel farming.\nThe island's economy has grown significantly over the last decade in key areas of innovation. Aerospace, bioscience, information and communications technology, and renewable energy have been a focus for growth and diversification. Aerospace alone now accounts for over 25% of the province's international exports and is the island's fourth largest industry at $355 million in annual sales. The bioscience industry employs over 1,300 people and generates over $150 million in sales.\nThe sale of carbonated beverages such as beer and soft drinks in non-refillable containers, such as aluminum cans or plastic bottles, was banned in 1976 as an environmental measure in response to public concerns over litter. Beer and soft drink companies opted to use refillable glass bottles for their products which were redeemable at stores and bottle depots.\nThough often environmental and economic agendas may be at odds, the \u2018ban the can\u2019 legislation, along with being environmentally driven, was also economically motivated as it protected jobs. Seaman's Beverages, a bottling company and carbonated beverage manufacturer, was established in 1939 and a major employer in Charlottetown, Prince Edward Island. Making it illegal to retail cans led to a bigger share of the carbonated beverage market for Seamans. Seamans Beverages was eventually acquired by Pepsi Bottling Group Inc in 2002 prior to the lifting of the legislation.\nThe introduction of recycling programs for cans and plastic bottles in neighbouring provinces in recent years (also using a redemption system) has seen the provincial government introduce legislation to reverse this ban with the restriction lifted on May 3, 2008.\nPrior to harmonization in 2013, Prince Edward Island had one of Canada's highest provincial retail sales tax rates at 10%. On April 1, 2013, the provincial tax was harmonized with the federal Goods and Services Tax, and became known as the \"harmonized sales tax\". The 15% tax is applied to almost all goods and services except some clothing, food and home heating fuel. This rate is the same as the neighbouring Atlantic provinces, with the exception of Nova Scotia.\nThe provincial government provides consumer protection in the form of regulation for certain items, ranging from apartment rent increases to petroleum products including gas, diesel, propane and heating oil. These are regulated through the Prince Edward Island Regulatory and Appeals Commission (IRAC). IRAC is authorized to limit the number of companies who are permitted to sell petroleum products.\nAs of 2015[ [update]], the median family income on Prince Edward Island is $76,607/year. The minimum wage is $16.00/hour as of \u00a01, 2024[ [update]].\nEnergy.\nSince 1918, Maritime Electric has delivered electricity to customers on the Island. The utility is currently owned and operated by Fortis Inc. Approximately twenty-five percent of electricity consumed on the island is generated from renewable energy (largely wind turbines); the provincial government had set a renewable energy target for 30\u201350% for electricity consumed by 2015, though this goal has not been met. The total capacity of wind power on the island is 204 MW from 89 turbines. There are eight wind farms on the island, the largest being West Cape Wind Park with a capacity of 99 MW from 55 turbines. All of the turbines have been manufactured by Vestas: the Vestas V-80, Vestas V90, and Vestas V-47. A thermal oil-fired generating station, the Charlottetown Thermal Generating Station, is used sometimes for emergencies. It is being decommissioned. A second thermal generation station exists in Borden, the Borden Generating Station. The majority of electricity consumed on Prince Edward Island comes from New Brunswick through undersea cables. A recent $140M upgrade brought the capacity of the cable system from 200 MW to 560 MW.\nThe Point Lepreau nuclear plant in New Brunswick was closed for refurbishments from 2008 to 2012, resulting in a steep price hike of about 25 per cent, but the province later subsidized rates. Residents were to pay 11.2 per cent more for electricity when the harmonized sales tax was adopted in April 2013, according to the P.E.I. Energy Accord that was tabled in the legislature on December 7, 2012. and passed as the \"Electric Power (Energy Accord Continuation) Amendment Act\", which establishes electric pricing from April 1, 2013, to March 1, 2016. Regulatory powers are derived for IRAC from the \"Electric Power Act\".\nEducation.\nPrince Edward Island's public school system has an English school district named the Public Schools Branch (previously the English Language School Board), as well as a Francophone district, the Commission scolaire de langue fran\u00e7aise. The English language district has a total of 10 secondary schools and 54 intermediate and elementary schools while the Francophone district has 6 schools covering all grades. 22 per cent of the student population is enrolled in French immersion. This is one of the highest levels in the country.\nThree public post-secondary institutions operate in the province, including one university, and two colleges. The University of Prince Edward Island is the province's only public university, and is located in the city of Charlottetown. The university was created by the Island legislature to replace Prince of Wales College and St. Dunstan's University. UPEI is also home to the Atlantic Veterinary College, which offers the region's only veterinary medicine program.\nGovernment and politics.\nThe provincial government is responsible for such areas as health and social services, education, economic development, labour legislation and civil law. These matters of government are overseen in the provincial capital, Charlottetown.\nPrince Edward Island is governed by a parliamentary government within the construct of constitutional monarchy; the monarchy in Prince Edward Island is the foundation of the executive, legislative, and judicial branches. The sovereign is King Charles III, who also serves as head of state of 14 other Commonwealth countries, each of Canada's nine other provinces, and the Canadian federal realm, and resides in the United Kingdom. As such, the King's representative, the Lieutenant Governor of Prince Edward Island (presently Wassim Salamoun), carries out most of the royal duties in Prince Edward Island.\nThe direct participation of the royal and viceroyal figures in any of these areas of governance is limited; in practice, their use of the executive powers is directed by the Executive Council, a committee of ministers of the Crown responsible to the unicameral, elected Legislative Assembly and chosen and headed by the Premier of Prince Edward Island (presently Rob Lantz), the head of government. To ensure the stability of government, the lieutenant governor will usually appoint as premier the person who is the current leader of the political party that can obtain the confidence of a plurality in the Legislative Assembly. The leader of the party with the second-most seats usually becomes the Leader of His Majesty's Loyal Opposition (presently Hal Perry) and is part of an adversarial parliamentary system intended to keep the government in check.\nEach of the 27 Members of the Legislative Assembly (MLA) is elected by simple plurality in an electoral district. General elections are called by the lieutenant governor for the first Monday in October four years after the previous election, or may be called earlier on the advice of the premier. Historically, politics in the province have been dominated by the Liberal and the Progressive Conservative Parties since the province joined Confederation. From the 2015 election, the Green Party of Prince Edward Island gained a small representation in the Legislative Assembly, and in the 2019 election gained an additional six seats to form the Official Opposition.\nThe Mi'kmaq Confederacy of PEI is the tribal council and provincial-territorial organization in the province that represents both the Lennox Island and Abegweit First Nations.\nAdministrative divisions.\nPrince Edward Island is divided into three counties that have historically been used as administrative divisions for the provincial government, and prior to Confederation (in 1873), the colonial government.\nToday, the counties are no longer used as administrative boundaries for the provincial government, though they continue to be used as census divisions by Statistics Canada for statistical purposes in administering the Canadian census.\nHealth care and sanitation.\nThe province has a single health administrative region (or district health authority) called Health PEI. Health PEI receives funding for its operations and is regulated by the Department of Health and Wellness.\nMany PEI homes and businesses are served by central sewage collection and treatment systems. These are operated either by a municipality or a private utility. Many industrial operations have their own wastewater treatment facilities. Staff members with the Department of Environment, Water and Climate Change provide advice to operators, as needed, on proper system maintenance. The IRAC regulates municipal water and sewer in the province, now under the \"Environmental Protection Act\". Since around 1900, the residents of the City of Charlottetown have benefited from a central sanitary sewer service. Early disposal practices, while advanced for their time, eventually were found to compromise the ecological integrity of the nearby Hillsborough River and the Charlottetown Harbour. By 1974, the commission had spearheaded the development of a primary wastewater treatment plant, known as the Charlottetown Pollution Control Plant, together with the construction of several pumping stations along the city's waterfront, and outfall piping deep into the Hillsborough River.\nUntil 2016, Prince Edward Island was the only province in Canada that did not provide abortion services through its hospitals. Until that time, the last abortion that had been performed in the province was in 1982 prior to the opening of the Queen Elizabeth Hospital which saw the closure of the Roman Catholic-affiliated Charlottetown Hospital and the non-denominational Prince Edward Island Hospital; a condition of the \"merger\" being that abortions not be performed in the province. In 1988, following the court decision \"R. v. Morgentaler\", the then-opposition Progressive Conservative Party of Prince Edward Island tabled a motion demanding that the ban on abortions be upheld at the province's hospitals; the then-governing Prince Edward Island Liberal Party under Premier Joe Ghiz acquiesced and the ban was upheld. Until more local access was guaranteed, the Government of Prince Edward Island funded abortions for women who travelled to another province. Women from Prince Edward Island also travelled to the nearest private user-pay clinic, where they were required pay for the procedure using their own funds. Formerly this was the Morgentaler Clinic in Fredericton, New Brunswick until this clinic closed due to lack of funds in July 2014. The clinic was reopened under new ownership in 2016 as Clinic 554 with expanded services. During that gap, women had to travel to Halifax or further. In 2016, the Liberal government led by Premier Wade MacLauchlan announced they would open a women's reproductive health clinic to provide abortions within the province. Abortions are now provided in Prince Edward Island.\nTransportation.\nPrince Edward Island's transportation network has traditionally revolved around its seaports of Charlottetown, Summerside, Borden, Georgetown, and Souris\u00a0\u2014linked to its railway system, and the two main airports in Charlottetown and Summerside, for communication with mainland North America. The Prince Edward Island Railway system was abandoned by CN in 1989 in favour of an agreement with the federal government to improve major highways.\nUntil May 1997, the province was linked by two passenger-vehicle ferry services to the mainland: one, provided by Marine Atlantic, operated year-round between Borden and Cape Tormentine, New Brunswick; the other, provided by Northumberland Ferries Limited, operates seasonally between Wood Islands and Caribou, Nova Scotia. A third ferry service provided by CTMA operates all year round with seasonal times between Souris and Cap-aux-Meules, Quebec, in the Magdalen Islands. In May 1997, the Confederation Bridge opened, connecting Borden-Carleton to Cape Jourimain, New Brunswick. The world's longest bridge over ice-covered waters, it replaced the Marine Atlantic ferry service. Since then, the Confederation Bridge's assured transportation link to the mainland has altered the province's tourism and agricultural and fisheries export economies.\nThe Island has the highest concentration of roadways in Canada. The provincially managed portion of the network consists of of paved roadways and of non-paved or clay roads. The province has very strict laws regarding use of roadside signs. Billboards and the use of portable signs are banned. There are standard direction information signs on roads in the province for various businesses and attractions in the immediate area. The by-laws of some municipalities also restrict the types of permanent signs that may be installed on private property.\nSeveral airlines service the Charlottetown Airport (CYYG); the Summerside Airport (CYSU) is an additional option for general aviation.\nThere is an extensive bicycling and hiking trail that spans the island. The Confederation Trail is a recreational trail system. The land was once owned and used by Canadian National Railway (CN) as a rail line on the island.\nCulture.\nArts.\nThe island's cultural traditions of art, music and creative writing are supported through the public education system. There is an annual arts festival, the Charlottetown Festival, hosted at the Confederation Centre of the Arts.\nLucy Maud Montgomery, who was born in Clifton (now New London) in 1874, drew inspiration from the land during the late Victorian Era for the setting of her classic novel \"Anne of Green Gables\" (1908). The musical play \"Anne of Green Gables\" has run every year at the Charlottetown festival for more than four decades. The sequel, \"Anne &amp; Gilbert\", premiered in the Playhouse in Victoria in 2005. The actual location of Green Gables, the house featured in Montgomery's \"Anne\" books, is in Cavendish, on the north shore of PEI.\nPrince Edward Island's documented music history begins in the 19th century with religious music, some written by the local pump and block maker and organ-importer Watson Duchemin. Several big bands including the Sons of Temperance Band and the Charlottetown Brass Band were active. Today, Acadian, Celtic, folk, and rock music prevail, with exponents including Gene MacLellan, his daughter Catherine MacLellan, Al Tuck, Lennie Gallant, Two Hours Traffic and Paper Lions. The celebrated singer-songwriter Stompin' Tom Connors spent his formative years in Skinners Pond. Celtic music is certainly the most common traditional music on the island, with fiddling and step dancing being very common. This tradition, largely Scottish, Irish and Acadian in origin is very similar to the music of Cape Breton and to a lesser extent, Newfoundland and is unique to the region. Due to the Islands influence as a former Highlander Clans Scottish colony, a March 4/4 for bagpipes was composed in honour of Prince Edward Island.\nFestivals.\nThere is an annual arts festival, the Charlottetown Festival, hosted at the Confederation Centre of the Arts as well as the Island Fringe Festival that takes place around Charlottetown. An annual jazz festival, the P.E.I. Jazz and Blues Festival. is a week-long series of concerts taking place at several venues including Murphy's Community Centre, outdoor stages, and churches in Charlottetown. The moving of its date to mid-August caused in 2011 a serious loss in funding from Ottawa's regional development agency ACOA. The musician's line up in 2011 included Oliver Jones, Sophie Milman, Matt Dusk, Jack de Keyzer, Jack Semple, Meaghan Smith and Jimmy Bowskill. There is also Canada Rocks, and the Cavendish Beach Music Festival. With agriculture and fishery playing a large role in the economy, P.E.I. has been marketed as a food tourism destination.\nSports.\nThe province is home to a major junior ice hockey team, the Charlottetown Islanders of the Quebec Maritimes Junior Hockey League, and a Junior A ice hockey team, the Summerside Western Capitals, which play in the Maritime Junior A Hockey League. The Prince Edward Island Senators played in the American Hockey League from 1993 to 1996. Relocated from New Haven, Connecticut, the team was affiliated with the Ottawa Senators. The team eventually ended up in Binghamton, New York and became the Binghamton Senators in 2002.\nThe Island Storm were a professional basketball team that played in the National Basketball League of Canada. The team was founded in 2011 as the Summerside Storm for the league's inaugural season and became the Island Storm in 2013. The team was granted a one-year leave of absence in 2021 but have not returned since.\nPrince Edward Island has hosted three Canada Games: two winter editions in 1991 and 2023; and a summer edition in 2009.\nThe UPEI Panthers represent the University of Prince Edward Island in the Atlantic University Sport conference of U Sports. The Holland Hurricanes represent Holland College in the Atlantic Collegiate Athletic Association conference of the Canadian Collegiate Athletic Association.\nThe island was a part of the IIGA, the association that organises the biannual Island Games. During their time participating in the multi sport competition, they won 6 gold medals, 6 silver medals and 9 bronze medals, totalling to 21 medals awarded during the 9 times they competed. The island resigned from the IIGA in 2011.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "23072", "revid": "4", "url": "https://en.wikipedia.org/wiki?curid=23072", "title": "Portland Oregon/Lore", "text": ""}
{"id": "23073", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=23073", "title": "Present King of France", "text": ""}
{"id": "23077", "revid": "42636", "url": "https://en.wikipedia.org/wiki?curid=23077", "title": "Political liberal", "text": ""}
{"id": "23079", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=23079", "title": "Philip Zimmermann", "text": ""}
{"id": "23080", "revid": "612538", "url": "https://en.wikipedia.org/wiki?curid=23080", "title": "Pretty Good Privacy", "text": "Data encryption and authentication program\nPretty Good Privacy (PGP) is an encryption program that provides cryptographic privacy and authentication for data communication. PGP is used for signing, encrypting, and decrypting texts, e-mails, files, directories, and whole disk partitions and to increase the security of e-mail communications. Phil Zimmermann developed PGP in 1991.\nPGP and similar software follow the OpenPGP standard (RFC 4880), an open standard for encrypting and decrypting data. Modern versions of PGP are interoperable with GnuPG and other OpenPGP-compliant systems.\nThe OpenPGP standard has received criticism for its long-lived keys and the difficulty in learning it, as well as the Efail security vulnerability that previously arose when select e-mail programs used OpenPGP with S/MIME. The new OpenPGP standard (RFC 9580) has also been criticised by the maintainer of GnuPG Werner Koch, who in response created his own specification LibrePGP. This response was dividing, with some embracing his alternative specification, and others considering it to be insecure.\nDesign.\nPGP\u00a0encryption uses a serial combination of hashing, data compression, symmetric-key cryptography, and finally public-key cryptography; each step uses one of several supported algorithms. Each public key is bound to a username or an e-mail address. The first version of this system was generally known as a web of trust to contrast with the X.509 system, which uses a hierarchical approach based on certificate authority and which was added to PGP implementations later. Current versions of PGP encryption include options through an automated key management server.\nPGP fingerprint.\nA public key fingerprint is a shorter version of a public key. From a fingerprint, someone can validate the correct corresponding public key. A fingerprint such as C3A6 5E46 7B54 77DF 3C4C 9790 4D22 B3CA 5B32 FF66 can be printed on a business card.\nCompatibility.\nAs PGP evolves, versions that support newer features and algorithms can create encrypted messages that older PGP systems cannot decrypt, even with a valid private key. Therefore, it is essential that partners in PGP communication understand each other's capabilities or at least agree on PGP settings.\nConfidentiality.\nPGP can be used to send messages confidentially. For this, PGP uses a hybrid cryptosystem by combining symmetric-key encryption and public-key encryption. The message is encrypted using a symmetric encryption algorithm, which requires a symmetric key generated by the sender. The symmetric key is used only once and is also called a session key. The message and its session key are sent to the receiver. The session key must be sent to the receiver so they know how to decrypt the message, but to protect it during transmission it is encrypted with the receiver's public key. Only the private key belonging to the receiver can decrypt the session key, and use it to symmetrically decrypt the message.\nDigital signatures.\nPGP supports message authentication through digital signatures to verify whether a message was actually sent by the person or entity claimed to be the sender. The sender uses PGP to create a digital signature for the message with one of several supported public-key algorithms. To do so, PGP computes a hash, or digest, from the plaintext and then creates the digital signature from that hash using the sender's private key.\nWeb of trust.\nBoth when encrypting messages and when verifying signatures, it is critical that the public key used to send messages to someone or some entity actually does 'belong' to the intended recipient. Simply downloading a public key from somewhere is not a reliable assurance of that association; deliberate (or accidental) impersonation is possible. From its first version, PGP has always included provisions for distributing user's public keys in an 'identity certification', which is also constructed cryptographically so that any tampering (or accidental garble) is readily detectable. However, merely making a certificate that is impossible to modify without being detected is insufficient; this can prevent corruption only after the certificate has been created, not before. Users must also ensure by some means that the public key in a certificate actually does belong to the person or entity claiming it. A given public key (or more specifically, information binding a user name to a key) may be digitally signed by a third-party user to attest to the association between someone (actually a user name) and the key. There are several levels of confidence that can be included in such signatures. Although many programs read and write this information, few (if any) include this level of certification when calculating whether to trust a key.\nThe web of trust protocol was first described by Phil Zimmermann in 1992, in the manual for PGP version 2.0:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;As time goes on, you will accumulate keys from other people that you may want to designate as trusted introducers. Everyone else will each choose their own trusted introducers. And everyone will gradually accumulate and distribute with their key a collection of certifying signatures from other people, with the expectation that anyone receiving it will trust at least one or two of the signatures. This will cause the emergence of a decentralized fault-tolerant web of confidence for all public keys.\nThe web of trust mechanism has advantages over a centrally managed public key infrastructure scheme such as that used by S/MIME but has not been universally used. Users have to be willing to accept certificates and check their validity manually or have to simply accept them. No satisfactory solution has been found for the underlying problem.\nCertificates.\nIn the (more recent) OpenPGP specification, \"trust signatures\" can be used to support creation of certificate authorities. A trust signature indicates both that the key belongs to its claimed owner and that the owner of the key is trustworthy to sign other keys at one level below their own. A level 0 signature is comparable to a web of trust signature since only the validity of the key is certified. A level 1 signature is similar to the trust one has in a certificate authority because a key signed to level 1 is able to issue an unlimited number of level 0 signatures. A level 2 signature is highly analogous to the trust assumption users must rely on whenever they use the default certificate authority list (like those included in web browsers); it allows the owner of the key to make other keys certificate authorities.\nPGP versions have always included a way to cancel ('revoke') public key certificates. A lost or compromised private key will require this if communication security is to be retained by that user. This is, more or less, equivalent to the certificate revocation lists of centralised PKI schemes. Recent PGP versions have also supported certificate expiration dates.\nThe problem of correctly identifying a public key as belonging to a particular user is not unique to PGP. All public key/private key cryptosystems have the same problem, even if in slightly different guises, and no fully satisfactory solution is known. PGP's original scheme at least leaves the decision as to whether or not to use its endorsement/vetting system to the user, while most other PKI schemes do not, requiring instead that every certificate attested to by a central certificate authority be accepted as correct.\nSecurity quality.\nTo the best of publicly available information, there is no known method which will allow a person or group to break PGP encryption by cryptographic or computational means. Indeed, in 1995, cryptographer Bruce Schneier characterized an early version as being \"the closest you're likely to get to military-grade encryption.\" Early versions of PGP have been found to have theoretical vulnerabilities and so current versions are recommended. In addition to protecting data in transit over a network, PGP encryption can also be used to protect data in long-term data storage such as disk files. These long-term storage options are also known as data at rest, i.e. data stored, not in transit.\nThe cryptographic security of PGP encryption depends on the assumption that the algorithms used are unbreakable by direct cryptanalysis with current equipment and techniques.\nIn the original version, the RSA algorithm was used to encrypt session keys. RSA's security depends upon the one-way function nature of mathematical integer factoring. Similarly, the symmetric key algorithm used in PGP version 2 was IDEA, which might at some point in the future be found to have previously undetected cryptanalytic flaws. Specific instances of current PGP or IDEA insecurities (if they exist) are not publicly known. As current versions of PGP have added additional encryption algorithms, their cryptographic vulnerability varies with the algorithm used. However, none of the algorithms in current use are publicly known to have cryptanalytic weaknesses.\nNew versions of PGP are released periodically and vulnerabilities fixed by developers as they come to light. Any agency wanting to read PGP messages would probably use easier means than standard cryptanalysis, e.g. rubber-hose cryptanalysis or black-bag cryptanalysis (e.g. installing some form of trojan horse or keystroke logging software/hardware on the target computer to capture encrypted keyrings and their passwords). The FBI has already used this attack against PGP in its investigations. However, any such vulnerabilities apply not just to PGP but to any conventional encryption software.\nIn 2003, an incident involving seized Psion PDAs belonging to members of the Red Brigade indicated that neither the Italian police nor the FBI were able to decrypt PGP-encrypted files stored on them.\nA second incident in December 2006, (see \"In re Boucher\"), involving US customs agents who seized a laptop PC that allegedly contained child pornography, indicates that US government agencies find it \"nearly impossible\" to access PGP-encrypted files. Additionally, a magistrate judge ruling on the case in November 2007 has stated that forcing the suspect to reveal his PGP passphrase would violate his Fifth Amendment rights i.e. a suspect's constitutional right not to incriminate himself. The Fifth Amendment issue was opened again as the government appealed the case, after which a federal district judge ordered the defendant to provide the key.\nEvidence suggests that , British police investigators are unable to break PGP, so instead have resorted to using RIPA legislation to demand the passwords/keys. In November 2009 a British citizen was convicted under RIPA legislation and jailed for nine months for refusing to provide police investigators with encryption keys to PGP-encrypted files.\nPGP as a cryptosystem has been criticized for complexity of the standard, implementation and very low usability of the user interface including by recognized figures in cryptography research. It uses an ineffective serialization format for storage of both keys and encrypted data, which resulted in signature-spamming attacks on public keys of prominent developers of GNU Privacy Guard. Backwards compatibility of the OpenPGP standard results in usage of relatively weak default choices of cryptographic primitives (CAST5 cipher, CFB mode, S2K password hashing). The standard has been also criticized for leaking metadata, usage of long-term keys and lack of forward secrecy. Popular end-user implementations have suffered from various signature-striping, cipher downgrade and metadata leakage vulnerabilities which have been attributed to the complexity of the standard.\nHistory.\nEarly history.\nPhil Zimmermann created the first version of PGP encryption in 1991. The name, \"Pretty Good Privacy\" was inspired by the name of a grocery store, \"Ralph's Pretty Good Grocery\", featured in radio host Garrison Keillor's fictional town, Lake Wobegon. This first version included a symmetric-key algorithm that Zimmermann had designed himself, named BassOmatic after a \"Saturday Night Live\" sketch. Zimmermann had been a long-time anti-nuclear activist, and created PGP encryption so that similarly inclined people might securely use BBSs and securely store messages and files. No license fee was required for its non-commercial use, and the complete source code was included with all copies.\nIn a posting of June 5, 2001, entitled \"PGP Marks 10th Anniversary\", Zimmermann describes the circumstances surrounding his release of PGP:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It was on this day in 1991 that I sent the first release of PGP to a couple of my friends for uploading to the Internet. First, I sent it to Allan Hoeltje, who posted it to Peacenet, an ISP that specialized in grassroots political organizations, mainly in the peace movement. Peacenet was accessible to political activists all over the world. Then, I uploaded it to Kelly Goen, who proceeded to upload it to a Usenet newsgroup that specialized in distributing source code. At my request, he marked the Usenet posting as \"US only\". Kelly also uploaded it to many BBS systems around the country. I don't recall if the postings to the Internet began on June 5th or 6th.\nIt may be surprising to some that back in 1991, I did not yet know enough about Usenet newsgroups to realize that a \"US only\" tag was merely an advisory tag that had little real effect on how Usenet propagated newsgroup postings. I thought it actually controlled how Usenet routed the posting. But back then, I had no clue how to post anything on a newsgroup, and didn't even have a clear idea what a newsgroup was.\nPGP found its way onto the Internet and rapidly acquired a considerable following around the world. Users and supporters included dissidents in totalitarian countries (some affecting letters to Zimmermann have been published, some of which have been included in testimony before the US Congress), civil libertarians in other parts of the world (see Zimmermann's published testimony in various hearings), and the 'free communications' activists who called themselves cypherpunks (who provided both publicity and distribution); decades later, CryptoParty activists did much the same via Twitter.\nCriminal investigation.\nShortly after its release, PGP encryption found its way outside the United States, and in February 1993 Zimmermann became the formal target of a criminal investigation by the US Government for \"munitions export without a license\". At the time, cryptosystems using keys larger than 40 bits were considered munitions within the definition of the US export regulations; PGP has never used keys smaller than 128 bits, so it qualified at that time. Penalties for violation, if found guilty, were substantial. After several years, the investigation of Zimmermann was closed without filing criminal charges against him or anyone else.\nZimmermann challenged these regulations in an imaginative way. In 1995, he published the entire source code of PGP in a hardback book, via MIT Press, which was distributed and sold widely. Anybody wishing to build their own copy of PGP could cut off the covers, separate the pages, and scan them using an OCR program (or conceivably enter it as a type-in program if OCR software was not available), creating a set of source code text files. One could then build the application using the freely available GNU Compiler Collection. PGP would thus be available anywhere in the world. The claimed principle was simple: export of \"munitions\"\u2014guns, bombs, planes, and software\u2014was (and remains) restricted; but the export of \"books\" is protected by the First Amendment. The question was never tested in court with respect to PGP. In cases addressing other encryption software, however, two federal appeals courts have established the rule that cryptographic software source code is speech protected by the First Amendment (the Ninth Circuit Court of Appeals in the Bernstein case and the Sixth Circuit Court of Appeals in the Junger case).\nUS export regulations regarding cryptography remain in force, but were liberalized substantially throughout the late 1990s. Since 2000, compliance with the regulations is also much easier. PGP encryption no longer meets the definition of a non-exportable weapon, and can be exported internationally except to seven specific countries and a list of named groups and individuals (with whom substantially all US trade is prohibited under various US export controls).\nThe criminal investigation was dropped in 1996.\nPGP 3 and founding of PGP Inc..\nDuring this turmoil, Zimmermann's team worked on a new version of PGP encryption called PGP 3. This new version was to have considerable security improvements, including a new certificate structure that fixed small security flaws in the PGP 2.x certificates as well as permitting a certificate to include separate keys for signing and encryption. Furthermore, the experience with patent and export problems led them to eschew patents entirely. PGP 3 introduced the use of the CAST-128 (a.k.a. CAST5) symmetric key algorithm, and the DSA and ElGamal asymmetric key algorithms, all of which were unencumbered by patents.\nAfter the Federal criminal investigation ended in 1996, Zimmermann and his team started a company to produce new versions of PGP encryption. They merged with Viacrypt (to whom Zimmermann had sold commercial rights and who had licensed RSA directly from RSADSI), which then changed its name to PGP Incorporated. The newly combined Viacrypt/PGP team started work on new versions of PGP encryption based on the PGP 3 system. Unlike PGP 2, which was an exclusively command line program, PGP 3 was designed from the start as a software library allowing users to work from a command line or inside a GUI environment. The original agreement between Viacrypt and the Zimmermann team had been that Viacrypt would have even-numbered versions and Zimmermann odd-numbered versions. Viacrypt, thus, created a new version (based on PGP 2) that they called PGP 4. To remove confusion about how it could be that PGP 3 was the successor to PGP 4, PGP 3 was renamed and released as PGP 5 in May 1997.\nNetwork Associates acquisition.\nIn December 1997, PGP Inc. was acquired by Network Associates, Inc. (\"NAI\"). Zimmermann and the PGP team became NAI employees. NAI was the first company to have a legal export strategy by publishing source code. Under NAI, the PGP team added disk encryption, desktop firewalls, intrusion detection, and IPsec VPNs to the PGP family. After the export regulation liberalizations of 2000 which no longer required publishing of source, NAI stopped releasing source code.\nAsset split.\nIn early 2001, Zimmermann left NAI. He served as Chief Cryptographer for Hush Communications, who provide an OpenPGP-based e-mail service, Hushmail. He has also worked with Veridis and other companies. In October 2001, NAI announced that its PGP assets were for sale and that it was suspending further development of PGP encryption. The only remaining asset kept was the PGP E-Business Server (the original PGP Commandline version). In February 2002, NAI canceled all support for PGP products, with the exception of the renamed commandline product.\nMcAfee.\nNAI, now known as McAfee, continued to sell and support the commandline product under the name McAfee E-Business Server until 2013. In 2010, Intel Corporation acquired McAfee. In 2013, the McAfee E-Business Server was transferred to Software Diversified Services (SDS), which now sells, supports, and develops it under the name SDS E-Business Server.\nFor the enterprise, Townsend Security currently offers a commercial version of PGP for the IBM i and IBM z mainframe platforms. Townsend Security partnered with Network Associates in 2000 to create a compatible version of PGP for the IBM i platform. Townsend Security again ported PGP in 2008, this time to the IBM z mainframe. This version of PGP relies on a free z/OS encryption facility, which utilizes hardware acceleration. SDS also offers a commercial version of PGP (SDS E-Business Server) for the IBM z mainframe.\nPGP Corporation.\nIn August 2002, several ex-PGP team members formed a new company, PGP Corporation, and bought the PGP assets (except for the command line version) from NAI. The new company was funded by Rob Theis of Doll Capital Management (DCM) and Terry Garnett of Venrock Associates. PGP Corporation supported existing PGP users and honored NAI's support contracts. Zimmermann served as a special advisor and consultant to PGP Corporation while continuing to run his own consulting company. In 2003, PGP Corporation created a new server-based product called PGP Universal. In mid-2004, PGP Corporation shipped its own command line version called PGP Command Line, which integrated with the other PGP Encryption Platform applications. In 2005, PGP Corporation made its first acquisition: the German software company Gl\u00fcck &amp; Kanja Technology AG, which became PGP Deutschland AG. In 2010, PGP Corporation acquired Hamburg-based certificate authority TC TrustCenter and its parent company, ChosenSecurity, to form its PGP TrustCenter division.\nAfter the 2002 purchase of NAI's PGP assets, PGP Corporation offered worldwide PGP technical support from its offices in Draper, Utah; Offenbach, Germany; and Tokyo, Japan.\nSymantec.\nOn April 29, 2010, Symantec Corp. announced that it would acquire PGP Corporation for $300 million with the intent of integrating it into its Enterprise Security Group. This acquisition was finalized and announced to the public on June 7, 2010. The source code of PGP Desktop 10 is available for peer review.\nIn May 2018, a bug named EFAIL was discovered in certain implementations of PGP which from 2003 could reveal the plaintext contents of emails encrypted with it. The chosen mitigation for this vulnerability in PGP Desktop is to mandate the use SEIP protected packets in the ciphertext, which can lead to old emails or other encrypted objects to be no longer decryptable after upgrading to the software version that has the mitigation.\nBroadcom.\nOn August 9, 2019, Broadcom Inc. announced they would be acquiring the Enterprise Security software division of Symantec, which includes PGP Corporation.\n\"This section describes commercial programs available from PGP Corporation. For information on other programs compatible with the OpenPGP specification, see External links below.\"\nPGP Corporation encryption applications.\nWhile originally used primarily for encrypting the contents of e-mail messages and attachments from a desktop client, PGP products have been diversified since 2002 into a set of encryption applications that can be managed by an optional central policy server. PGP encryption applications include e-mails and attachments, digital signatures, full disk encryption, file and folder security, protection for IM sessions, batch file transfer encryption, and protection for files and folders stored on network servers and, more recently, encrypted or signed HTTP request/responses by means of a client-side (Enigform) and a server-side (mod openpgp) module. There is also a WordPress plugin available, called wp-enigform-authentication, that takes advantage of the session management features of Enigform with mod_openpgp.\nThe PGP Desktop 9.x family includes PGP Desktop Email, PGP Whole Disk Encryption, and PGP NetShare. Additionally, a number of Desktop bundles are also available. Depending on the application, the products feature desktop e-mail, digital signatures, IM security, whole disk encryption, file, and folder security, encrypted self-extracting archives, and secure shredding of deleted files. Capabilities are licensed in different ways depending on the features required.\nThe PGP Universal Server 2.x management console handles centralized deployment, security policy, policy enforcement, key management, and reporting. It is used for automated e-mail encryption in the gateway and manages PGP Desktop 9.x clients. In addition to its local keyserver, PGP Universal Server works with the PGP public keyserver\u2014called the PGP Global Directory\u2014to find recipient keys. It has the capability of delivering e-mail securely when no recipient key is found via a secure HTTPS browser session.\nWith PGP Desktop 9.x managed by PGP Universal Server 2.x, first released in 2005, all PGP encryption applications are based on a new proxy-based architecture. These newer versions of PGP software eliminate the use of e-mail plug-ins and insulate the user from changes to other desktop applications. All desktop and server operations are now based on security policies and operate in an automated fashion. The PGP Universal server automates the creation, management, and expiration of keys, sharing these keys among all PGP encryption applications.\nThe Symantec PGP platform has now undergone a rename. PGP Desktop is now known as Symantec Encryption Desktop (SED), and the PGP Universal Server is now known as Symantec Encryption Management Server (SEMS). The current shipping versions are Symantec Encryption Desktop 10.3.0 (Windows and macOS platforms) and Symantec Encryption Server 3.3.2.\nAlso available are PGP Command-Line, which enables command line-based encryption and signing of information for storage, transfer, and backup, as well as the PGP Support Package for BlackBerry which enables RIM BlackBerry devices to enjoy sender-to-recipient messaging encryption.\nNew versions of PGP applications use both OpenPGP and the S/MIME, allowing communications with any user of a NIST specified standard.\nOpenPGP.\nWithin PGP Inc., there was still concern surrounding patent issues. RSADSI was challenging the continuation of the Viacrypt RSA license to the newly merged firm. The company adopted an informal internal standard that they called \"Unencumbered PGP\" which would \"use no algorithm with licensing difficulties\". Because of PGP encryption's importance worldwide, many wanted to write their own software that would interoperate with PGP 5. Zimmermann became convinced that an open standard for PGP encryption was critical for them and for the cryptographic community as a whole. In July 1997, PGP Inc. proposed to the IETF that there be a standard called OpenPGP. They gave the IETF permission to use the name OpenPGP to describe this new standard as well as any program that supported the standard. The IETF accepted the proposal and started the OpenPGP Working Group.\nOpenPGP is on the Internet Standards Track and is under active development. Many e-mail clients provide OpenPGP-compliant email security as described in RFC 3156. The current specification is RFC 9580 (July 2024), the successor to RFC 4880. RFC 9580 specifies a suite of required algorithms consisting of X25519, Ed25519, SHA2-256 and AES-128. In addition to these algorithms, the standard recommends X448, Ed448, SHA2-384, SHA2-512 and AES-256. Beyond these, many other algorithms are supported.\nOpenPGP's encryption can ensure the secure delivery of files and messages, as well as provide verification of who created or sent the message using a process called digital signing. The open source office suite LibreOffice implemented document signing with OpenPGP as of version 5.4.0 on Linux. Using OpenPGP for communication requires participation by both the sender and recipient. OpenPGP can also be used to secure sensitive files when they are stored in vulnerable places like mobile devices or in the cloud.\nIn late 2023, a schism occurred in the OpenPGP world: IETF's OpenPGP working group decided to choose a \"crypto-refresh\" update strategy for the RFC 4880 specification, rather than a more gradual \"4880bis\" path preferred by Werner Koch, author of GnuPG. As a result, Koch took his draft, now abandoned by the workgroup, and forked it into a \"LibrePGP\" specification.\nImplementations.\nThe Free Software Foundation has developed its own OpenPGP-compliant software suite called GNU Privacy Guard, freely available together with all source code under the GNU General Public License and is maintained separately from several graphical user interfaces that interact with the GnuPG library for encryption, decryption, and signing functions (see KGPG, Seahorse, MacGPG). Several other vendors have also developed OpenPGP-compliant software.\nThe development of an open source OpenPGP-compliant library, OpenPGP.js, written in JavaScript and supported by the Horizon 2020 Framework Programme of the European Union, has allowed web-based applications to use PGP encryption in the web browser.\nPGP keys are supported in Mozilla Thunderbird (Built-in in version 78 onwards on PC, and with the OpenKeychain app as of version 9 on Android), GitHub, and GitLab.\nLimitations.\nWith the advancement of cryptography, parts of PGP and OpenPGP have been criticized for being dated:\nIn October 2017, the ROCA vulnerability was announced, which affects RSA keys generated by buggy Infineon firmware used on Yubikey 4 tokens, often used with OpenPGP. Many published PGP keys were found to be susceptible. Yubico offers free replacement of affected tokens.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23083", "revid": "45366078", "url": "https://en.wikipedia.org/wiki?curid=23083", "title": "Playing card", "text": "Card used for playing various card games\nA playing card is a piece of specially prepared card stock, heavy paper, thin cardboard, plastic-coated paper, cotton-paper blend, or thin plastic that is marked with distinguishing motifs. Often the front (face) and back of each card has a finish to make handling easier. They are most commonly used for playing card games, and are also used in magic tricks, cardistry, card throwing, and card houses; cards may also be collected. Playing cards are typically palm-sized for convenient handling, and usually are sold together in a set as a deck of cards or pack of cards.\nThe most common type of playing card in the West is the French-suited, standard 52-card pack, of which the most widespread design is the English pattern, followed by the Belgian-Genoese pattern. However, many countries use other, traditional types of playing card, including those that are German, Italian, Spanish and Swiss-suited. Tarot cards (also known locally as \"Tarocks\" or \"tarocchi\") are an old genre of playing card that is still very popular in France, central and Eastern Europe and Italy. Customised Tarot card decks are also used for divination; including tarot card reading and cartomancy. Asia, too, has regional cards such as the Japanese hanafuda, Chinese money-suited cards, or Indian ganjifa. The reverse side of the card is often covered with a pattern that will make it difficult for players to look through the translucent material to read other people's cards or to identify cards by minor scratches or marks on their backs.\nPlaying cards are available in a wide variety of styles, as decks may be custom-produced for competitions, casinos and magicians (sometimes in the form of trick decks), made as promotional items, or intended as souvenirs, artistic works, educational tools, or branded accessories. Decks of cards or even single cards are also collected as a hobby or for monetary value.\nHistory.\nChina.\nPlaying cards were most likely invented during the Tang dynasty around the 9th century, as a result of the usage of woodblock printing technology. The reference to a leaf game in a 9th-century text known as the \"Collection of Miscellanea at Duyang\" (), written by Tang dynasty writer Su E, is often cited in connection to the existence of playing cards. However the connection between playing cards and the leaf game is disputed. The reference describes Princess Tongchang, daughter of Emperor Yizong of Tang, playing the \"leaf game\" in 868 with members of the Wei clan, the family of the princess's husband. The first known book on the \"leaf\" game was called the \"Yezi Gexi\" and allegedly written by a Tang woman. It received commentary by writers of subsequent dynasties. The Song dynasty (960\u20131279) scholar Ouyang Xiu (1007\u20131072) asserts that the \"leaf\" game existed at least since the mid-Tang dynasty and associated its invention with the development of printed sheets as a writing medium. However, Ouyang also claims that the \"leaves\" were pages of a book used in a board game played with dice, and that the rules of the game were lost by 1067.\nOther games revolving around alcoholic drinking involved using playing cards of a sort from the Tang dynasty onward. However, these cards did not contain suits or numbers. Instead, they were printed with instructions or forfeits for whoever drew them.\nThe earliest dated instance of a game involving cards occurred on 17 July 1294 when the Ming Department of Punishments caught two gamblers, Yan Sengzhu and Zheng Zhugou, playing with paper cards. Wood blocks for printing the cards were impounded, together with nine of the actual cards.\nWilliam Henry Wilkinson suggests that the first cards may have been actual paper currency which doubled as both the tools of gaming and the stakes being played for, similar to trading card games. Using paper money was inconvenient and risky so they were substituted by play money known as \"money cards\". One of the earliest games in which we know the rules is \"madiao\", a trick-taking game, which dates to the Ming Dynasty (1368\u20131644). Fifteenth-century scholar Lu Rong described it as being played with 38 \"money cards\" divided into four suits: 9 in coins, 9 in strings of coins (which may have been misinterpreted as sticks from crude drawings), 9 in myriads (of coins or of strings), and 11 in tens of myriads (a myriad is 10,000). The two latter suits had \"Water Margin\" characters instead of pips on them with Chinese to mark their rank and suit. The suit of coins is in reverse order with 9 of coins being the lowest going up to 1 of coins as the high card.\nPersia.\nDespite the wide variety of different patterns, the suits show a uniformity of structure. Every suit contains twelve cards with the top two usually being the court cards of king and vizier and the bottom ten being pip cards. Some decks can contain 8 suits to make a 96-card deck, like the deck for Ganjifa. Half the suits use reverse ranking for their pip cards. There are many motifs for the suit pips but some include coins, clubs, jugs, and swords which resemble later Mamluk and Latin suits. Michael Dummett speculated that Mamluk cards may have descended from an earlier deck which consisted of 48 cards divided into four suits each with ten pip cards and two court cards.\nEgypt.\nBy the 11th century, playing cards were spreading throughout the Asian continent and later came into Egypt. The oldest surviving cards in the world are four fragments found in the Keir Collection and one in the Benaki Museum. They are dated to the 12th and 13th centuries (late Fatimid, Ayyubid, and early Mamluk periods).\nA near complete pack of Mamluk playing cards dating to the 15th century, and of similar appearance to the fragments above, was discovered by Leo Aryeh Mayer in the Topkap\u0131 Palace, Istanbul, in 1939. It is not a complete set and is actually composed of three different packs, probably to replace missing cards. The Topkap\u0131 pack originally contained 52 cards comprising four suits: polo-sticks, coins, swords, and cups. Each suit contained ten pip cards and three court cards, called \"malik\" (king), \"n\u0101'ib malik\" (viceroy or deputy king), and \"th\u0101n\u012b n\u0101'ib\" (second or under-deputy). The \"th\u0101n\u012b n\u0101'ib\" is a non-existent title so it may not have been in the earliest versions; without this rank, the Mamluk suits would structurally be the same as a Ganjifa suit. In fact, the word \"Kanjifah\" appears in Arabic on the king of swords and is still used in parts of the Middle East to describe modern playing cards. Influence from further east can explain why the Mamluks, most of whom were Central Asian Turkic Kipchaks, called their cups \"tuman\", which means \"myriad\" (10,000) in the Turkic, Mongolian, and Jurchen languages. Wilkinson postulated that the cups may have been derived from inverting the Chinese and Jurchen ideogram for \"myriad\", , which was pronounced as something like \"man\" in Middle Chinese.\nThe Mamluk court cards showed abstract designs or calligraphy not depicting persons possibly due to religious proscription in Sunni Islam, though they did bear the ranks on the cards. \"N\u0101'ib\" would be borrowed into French (\"nahipi\"), Italian (\"naibi\"), and Spanish (\"naipes\"), the latter word still in common usage. Panels on the pip cards in two suits show they had a reverse ranking, a feature found in madiao, ganjifa, and old European card games like ombre, tarot, and maw. A fragment of two uncut sheets of Moorish-styled cards of a similar was found in Spain and dated to the early 15th century.\nExport of these cards (from Cairo, Alexandria, and Damascus), ceased after the fall of the Mamluks in the 16th century. The rules to play these games are lost but they are believed to be plain trick games without trumps.\nSpread across Europe and early design changes.\n \nPlaying cards probably came to Europe from the East, specifically those used by the Mamluks in Egypt, and probably arrived first in Spain since the earliest European mention of playing cards appears in 1371 in a Catalan language rhyme dictionary which lists \"naip\" among words ending in \"-ip\". According to Trevor Denning, the only attested meaning of this Catalan word is \"playing card\". This suggests that cards may have been \"reasonably well known\" in Catalonia (now part of Spain) at that time, perhaps introduced as a result of maritime trade with the Mamluk rulers of Egypt.\nThe earliest record of playing cards in central Europe is believed by some researchers to be a ban on card games in the city of Bern in 1367, but this source is disputed as the earliest copy available dates to 1398 and may have been amended. Generally accepted as the first Italian reference is a Florentine ban dating to 1377. Also appearing in 1377 was the treatise by John of Rheinfelden, in which he describes playing cards and their moral meaning. From this year onwards more and more records (usually bans) of playing cards occur, first appearing in England as early as 1413.\nAmong the early patterns of playing card were those derived from the Mamluk suits of cups, coins, swords, and polo sticks, which are still used in traditional Latin decks. As polo was an obscure sport to Europeans then, the polo-sticks became batons or cudgels. In addition to Catalonia in 1371, the presence of playing cards is attested in 1377 in Switzerland, and 1380 in many locations including Florence and Paris. Wide use of playing cards in Europe can, with some certainty, be traced from 1377 onward.\nIn the account books of Johanna, Duchess of Brabant and Wenceslaus I, Duke of Luxembourg, an entry dated May 14, 1379, by receiver general of Brabant Renier Hollander reads: \"Given to Monsieur and Madame four peters and two florins, worth eight and a half sheep, for the purchase of packs of cards\". In his book of accounts for 1392 or 1393, Charles or Charbot Poupart, treasurer of the household of Charles VI of France, records payment for the painting of three sets of cards.\nFrom about 1418 to 1450 professional card makers in Ulm, Nuremberg, and Augsburg created printed decks. Playing cards even competed with devotional images as the most common uses for woodcuts in this period. Most early woodcuts of all types were coloured after printing, either by hand or, from about 1450 onwards, stencils. These 15th-century playing cards were probably painted. The Flemish Hunting Deck, held by the Metropolitan Museum of Art, is the oldest complete set of ordinary playing cards made in Europe from the 15th century.\nAs cards spread from Italy to Germanic countries, the Latin suits were replaced with the suits of leaves (or shields), hearts (or roses), bells, and acorns. France initially used Latin-suited cards and the Aluette pack used today in western France may be a relic of that time, but around 1480, French card manufacturers, perhaps in order to facilitate mass production, went over to very much simplified versions of the German suit symbols. A combination of Latin and Germanic suit pictures and names resulted in the French suits of (clovers), (tiles), (hearts), and (pikes) around 1480. The \"tr\u00e8fle\" (clover) was probably derived from the acorn and the (pike) from the leaf of the German suits. The names and \"spade\", however, may have derived from the sword () of the Italian suits. In England, the French suits were eventually used, although the earliest packs circulating may have had Latin suits. This may account for why the English called the clovers \"clubs\" and the pikes \"spades\".\nIn the late 14th century, Europeans changed the Mamluk court cards to represent European royalty and attendants. In a description from 1377, the earliest courts were originally a seated \"king\", an upper marshal that held his suit symbol up, and a lower marshal that held it down. The latter two correspond with the \"Ober\" and \"Unter\" cards still found today in German and Swiss playing cards. The Italians and Iberians replaced the / system with the \"Knight\" and \" or \" before 1390, perhaps to make the cards more visually distinguishable.\nIn England, the lowest court card was called the \"knave\" which originally meant \"male child\" (compare German ), so in this context the character could represent the \"prince\", son to the king and queen; the meaning \"servant\" developed later. Queens appeared sporadically in packs as early as 1377, especially in Germany. Although the Germans abandoned the queen before the 1500s, the French permanently picked it up and placed it under the king.\nIn 1628, the Mystery of Makers of Playing Cards of the City of London (now the Worshipful Company of Makers of Playing Cards) was incorporated under a royal charter by Charles I; the Company received livery status from the Court of Aldermen of the City of London in 1792. The Company still exists today, having expanded its member ranks to include \"card makers... card collectors, dealers, bridge players, [and] magicians\".\nDuring the mid 16th century, Portuguese traders introduced playing cards to Japan. The first indigenous Japanese deck was the named after the period.\nLater design changes.\nPacks with corner and edge indices (i.e. the value of the card printed at the corner(s) or edges of the card) enabled players to hold their cards close together in a fan with one hand (instead of the two hands previously used). An early example of a pack with edge indices and Latin suits was printed by Infirerra and dated 1693. However, this feature was commonly used only from the end of the 18th century. The first American-manufactured (French) deck with this innovation was the Saladee's Patent, printed by Samuel Hart in 1864. In 1870, he and his cousins at Lawrence &amp; Cohen followed up with the Squeezers, the first cards with indices that had a large diffusion.\nThis was followed by the innovation of reversible court cards. This invention is attributed to a French card maker of Agen in 1745. But the French government, which controlled the design of playing cards, prohibited the printing of cards with this innovation. In central Europe (Trappola cards) and Italy (Tarocco Bolognese) the innovation was adopted during the second half of the 18th century. In Great Britain, the pack with reversible court cards was patented in 1799 by Edward Ludlow and Ann Wilcox. Not being registered card-makers, they worked with printer Thomas Wheeler to produce a French-suited pack using this patent, which was first sold in 1801.\nSharp corners wear out more quickly, and could possibly reveal the card's value, so they were replaced with rounded corners. Before the mid-19th century, British, American, and French players preferred blank backs. The need to hide wear and tear and to discourage writing on the back led cards to have designs, pictures, photos, or advertising on the reverse.\nThe United States introduced the joker into the deck. It was devised for the game of euchre, which spread from Europe to America beginning shortly after the American Revolutionary War. In euchre, the highest trump card is the Jack of the trump suit, called the \"right bower\" (from the German \"\"); the second-highest trump, the \"left bower\", is the jack of the suit of the same color as trumps. The joker was invented c. 1860 as a third trump, the \"imperial\" or \"best bower\", which ranked higher than the other two \"bowers\". The name of the card is believed to derive from \"juker\", a variant name for euchre. The earliest reference to a joker functioning as a wild card dates to 1875 with a variation of poker.\nPlaying cards were also some of the earliest products to be sold in packaging. Early card packs were sold in paper sleeves held closed with a string. The 19th century saw the apparition of progressively more complex cardboard packaging, with tuck-flap boxes becoming common by the end of the century. Cellophane wrappers were common by 1937.\nModern-era manufacturers and artists.\nThe Japanese video game company Nintendo was founded in 1889 to produce and distribute , most notably . \"Hanafuda\" cards had become popular after Japan banned most forms of gambling in 1882 but largely left \"hanafuda\" untouched. Sales of \"hanafuda\" cards were popular with the yakuza-run gaming parlors in Kyoto. Other card manufacturers had opted to leave the market not wanting to be associated with criminal ties, but Nintendo founder Fusajiro Yamauchi continued, becoming the largest producer of \"hanafuda\" within a few years. With the increase of the cards' popularity, Yamauchi hired assistants to mass-produce to satisfy the demand. Even with a favorable start, the business faced financial struggle due to operating in a niche market, the slow and expensive manufacturing process, high product price, alongside long durability of the cards, which impacted sales due to the low replacement rate. As a solution, Nintendo produced a cheaper and lower-quality line of playing cards, , while also conducting product offerings in other cities such as Osaka, where card game profits were high. In addition, local merchants were interested in the prospect of a continuous renewal of decks, thus avoiding the suspicions that reusing cards would generate.\nResearch.\nColumbia University's Rare Book and Manuscript Library holds the Albert Field Collection of Playing Cards, an archive of over 6,000 individual decks from over 50 countries and dating back to the 1550s. In 2018 the university digitized over 100 of its decks.\nSince 2017, Vanderbilt University has been home to the 1,000-volume George Clulow and United States Playing Card Co. Gaming Collection, which has been called one of the \"most complete and scholarly collections [of books on cards and gaming] that has ever been gathered together\".\nJournals.\nJournals and magazines dedicated to the subject of playing cards include:\nModern formats.\nContemporary playing cards are grouped into three broad categories based on the suits they use: French, Latin, and Germanic. Latin suits are used in the closely related Spanish and Italian formats. The Swiss-German suits are distinct enough to merit their subcategory. Excluding jokers and tarot trumps, the French 52-card deck preserves the number of cards in the original Mamluk deck, while Latin and Germanic decks average fewer. Latin decks usually drop the higher-valued pip cards, while Germanic decks drop the lower-valued ones.\nWithin suits, there are regional or national variations called \"standard patterns.\" Pattern differences are most easily found in the face cards but the number of cards per deck, the use of numeric indices, or even minor shape and arrangement differences of the pips can be used to distinguish them. Some patterns have been around for hundreds of years. Jokers are not part of any pattern as they are a relatively recent invention and lack any standardized appearance so each publisher usually puts its own trademarked illustration into their decks. The wide variation of jokers has turned them into collectible items. Any card that bore the stamp duty like the ace of spades in England, the ace of clubs in France or the ace of coins in Italy are also collectible as that is where the manufacturer's logo is usually placed.\nTypically, playing cards have indices printed in the upper-left and lower-right corners. While this design does not restrict which hand players hold their cards, some left-handed players may prefer to fan their cards in the opposite direction. Some designs exist with indices in all four corners.\nFrench-suited decks.\nFrench decks come in a variety of patterns and deck sizes. The 52-card deck is the most popular deck and includes 13 ranks of each suit with reversible \"court\" or face cards. Each suit includes an ace, depicting a single symbol of its suit, a king, queen, and jack, each depicted with a symbol of their suit; and ranks two through ten, with each card depicting that number of pips of its suit. As well as these 52 cards, commercial packs often include between one and six jokers, most often two.\nDecks with fewer than 52 cards are known as stripped decks. The piquet pack has all values from 2 through 6 in each suit removed for a total of 32 cards. It is popular in France, the Low Countries, Central Europe and is used to play piquet, belote, bezique and skat. Values in Russian 36-card stripped deck (used to play durak and many other traditional games) range from 6 to 10. It is also used in the Sri Lankan, whist-based game known as \"omi\". Forty-card French suited packs are common in northwest Italy; these remove the 8s through 10s like Latin-suited decks. 24-card decks, removing 2s through 8s are also sold in Austria and Bavaria to play Schnapsen.\nA pinochle deck consists of two copies of a 24-card schnapsen deck, thus 48 cards.\nThe 78-card Tarot Nouveau adds the knight card between queens and jacks along with 21 numbered trumps and the unnumbered Fool.\nManufacturing.\nToday the process of making playing cards is highly automated. Large sheets of paper are glued together to create a sheet of pasteboard; the glue may be black or dyed another dark color to increase the card stock's opacity. In the industry, this black compound is sometimes known as \"gick\". Some card manufacturers may purchase pasteboard from various suppliers; large companies such as USPCC create their own proprietary pasteboard. After the desired imagery is etched into printing plates, the art is printed onto each side of the pasteboard sheet, which is coated with a textured or smooth finish, sometimes called a varnish or paint coating. These coatings can be water- or solvent-based, and different textures and visual effects can be achieved by adding certain dyes or foils, or using multiple varnish processes.\nThe pasteboard is then split into individual uncut sheets, which are cut into single cards and sorted into decks. The corners are then rounded, after which the decks are packaged, commonly in tuck boxes wrapped in cellophane. The tuck box may have a seal applied.\nCard manufacturers must pay special attention to the registration of the cards, as non-symmetrical cards can be used to cheat.\nNon-standard design and use.\nAirlines.\nAirlines have produced playing cards to give to passengers since the 1920s, with the practice reaching a zenith in the 1960s and 1970s. However, the practice has become less common in recent decades.\nDelta Air Lines has created several series of decks, with several featuring art by Daniel C. Sweeney, John Hardy, and Jack Laycox.\nCasinos.\nGambling corporations commonly have playing cards made specifically for their casinos. As casinos consume many decks daily, they sometimes resell used cards that were \"on the [casino] floor\". The cards sold to the public are altered, either by cutting the deck's corners or by punching a hole in the deck, to prevent them from being used for cheating in the casino.\nCasinos may also sell decks separately as a souvenir item \u2014 one notable example is Jerry's Nugget playing cards, released in 1970.\nCold case cards.\nPolice departments, local governments, state prison systems, and even private organizations across the United States and other countries have created decks of cards that feature photos, names, and details of cold case victims or missing persons on each card. These decks are sold in prison commissaries, or even to the public, in the hopes that an inmate (or anyone else) might provide a new lead. Cold case card programs have been introduced in over a dozen states, including by Oklahoma's State Bureau of Investigation, Connecticut's Division of Criminal Justice (five editions), the Minnesota Bureau of Criminal Apprehension (in 2008), Delaware's Department of Correction, the Florida Department of Law Enforcement, and Rhode Island's Department of Corrections, among others. The Indiana Department of Correction sells cold case cards in prisons, and in 2024, Mississippi Coast Crime Stoppers created cold case playing cards, distributing 2,500 decks.\nAmong inmates, they may be called \"snitch cards\". Prisoners with information may be motivated to come forward in order to receive a lightened sentence.\nCollecting.\nBecause of the long history and wide variety in designs, playing cards are also collector's items. In 1911, the \"New York Times\" described May King Van Rensselaer's playing card collection of over 900 decks as the largest in the world. According to \"Guinness World Records\", the largest playing card collection comprises 11,087 decks and is owned by Liu Fuchang of China. Individual playing cards are also collected, such as the world record collection of 8,520 different jokers belonging to Tony de Santis of Italy.\nCustom designs and artwork.\nCustom decks may be produced for myriad purposes. Across the world, both individuals and large companies such as United States Playing Card Company (USPCC) design and release many different styles of decks, including commemorative decks, cards created for fundraising, and souvenir decks. Bold and colorful designs tend to be used for cardistry decks, while more generally, playing cards (as well as tarot cards) may focus on artistic value. Custom deck production is commonly funded on platforms such as Kickstarter, with companies offering card printing services to the public.\nIn 1976, the JPL Gallery in London commissioned a card deck from a variety of contemporary British artists including Maggie Hambling, Patrick Heron, David Hockney, Howard Hodgkin, John Hoyland, and Allen Jones called \"The Deck of Cards\". Forty years later in 2016, the British Council commissioned a similar deck called \"Taash ke Patte\" featuring Indian artists such as Bhuri Bai, Shilpa Gupta, Krishen Khanna, Ram Rahman, Gulam Mohammed Sheikh, Arpita Singh, and Thukral &amp; Tagra. American artist Tom Sachs has printed several custom decks featuring photos of his artwork.\nPlaying cards themselves may also be used to make art, such as being used as a canvas for an artist trading card.\nMilitary identification.\nPlaying cards are a useful tool to pass information to troops during downtime. In World War II, the United States Playing Card Company produced a deck of cards featuring silhouettes of American, British, German, Italian, and Japanese aircraft. The Allies also produced maps concealed in playing cards. During the 2003 invasion of Iraq, the US military produced Most-wanted Iraqi playing cards to help soldiers identify enemy leaders. According to a Defense Intelligence Agency spokesperson, the practice actually dates back to the American Civil War. A design depicting Igor Girkin and presumably other Russian leaders appeared during the 2022 Russian invasion of Ukraine, and a similar deck of cards depicting Hamas was produced after the October 7, 2023 Hamas attacks on Israel.\nCard decks have also been used as an educational tool to help military personnel and civilians identify unexploded ordnance.\nSymbols in Unicode.\nThe Unicode standard for character encoding defines 8 characters (symbols) for card suits in the Miscellaneous Symbols block, at U+2660\u20132667. The Unicode names for each group of four glyphs are 'black' and 'white' but might have been more accurately described as 'solid' and 'outline' since the colour actually used at display or printing time is an application choice.\nLater, Unicode 7.0 added the 52 cards of the modern French pack, plus 4 knights, and a character for \"Playing Card Back\" and black, red and white jokers, in the Playing Cards block (U+1F0A0\u20131F0FF).\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nStandard 52-card deck\nStripped deck\nTarot\nTransformation playing card\nTrick deck\nCard game\nCartomancy\nCard manipulation\nCard money\nCard throwing\nHouse of cards\nSleight of hand\nChinese playing cards\nFrench playing cards\nGanjifa\nGerman playing cards\nHanafuda\nItalian playing cards\nKaruta\nSpanish playing cards\nSwiss playing cards\nTujeon\nGlossary of card game terms\nList of playing card nicknames\nArchaeology awareness playing cards\nMost-wanted Iraqi playing cards\nPoliticards\nTrading card\nZener cards (parapsychology)\nCary Collection of Playing Cards\nInternational Playing-Card Society\nMus\u00e9e Fran\u00e7ais de la Carte \u00e0 Jouer\nMuseum of Fournier de Naipes\n\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCited sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "23084", "revid": "50890361", "url": "https://en.wikipedia.org/wiki?curid=23084", "title": "Paleontology", "text": "Study of past life through fossils\nPaleontology or palaeontology is the scientific study of the past, mainly but not exclusively through the study of fossils. Paleontologists use fossils as a means to classify organisms, measure geologic time, and assess the interactions between prehistoric organisms and their natural environment. While paleontological observations are known from at least the 6th century BC, the foundation of paleontology as a science dates back to the work of Georges Cuvier in 1796. Cuvier demonstrated evidence for the concept of extinction and how the life of the past was not necessarily the same as that of the present. The field developed rapidly over the course of the following decades, and the French word \"pal\u00e9ontologie\" was introduced for the study in 1822, which was derived from the Ancient Greek word for 'ancient' and words describing relatedness and a field of study. Further advances in the field accompanied the work of Charles Darwin who popularized the concept of evolution. Together, evolution and extinction can be understood as complementary processes that shaped the history of life.\nPaleontology overlaps the most with the fields of geology and biology. It draws on technology and analysis of a wide range of sciences to apply them to the study of life and environments of the past, particularly for the subdisciplines of paleobiology and paleoecology that are analogous to biology and ecology. Paleontology also contributes to other sciences, being utilized for biostratigraphy to reconstruct the geologic time scale of Earth, or in studies on extinction to establish both external and internal factors that can lead to the disappearance of a species. Much of the history of life is now better understood because of advances in paleontology and the increase in interdisciplinary studies. Several improvements in understanding have occurred from the introduction of theoretical analysis to paleontology in the 1950s and 1960s which led to the rise of more focused fields of paleontology that assess the changing geography and climate of Earth, the phylogenetic relationships between different species, and the analysis of how fossilization occurs and what biases can impact the quality of the fossil record.\nPaleontology is also one of the most high profile of the sciences, comparable to astrophysics and global health in the amount of attention in mass media. Public attention to paleontology can be traced back to the mythologies of indigenous peoples of many continents and the interpretation of discovered fossils as the bones of dragons or giants. Prehistoric life is used as the inspiration for toys, television and film, computer games, and tourism, with the budgets for these public projects often exceeding the funding within the field of paleontology itself. This has led to exploitation and imperialism of fossils collected for institutions in Europe and North America, and also appeals to the public for sponsorships to the benefit of some areas of paleontology at the detriment of others.\nConcept.\nPaleontology (also spelled palaeontology) is the study of life of the past, characterized but not defined by the study and interpretation of fossils. It overlaps with the fields of geology and biology especially, but also with ecology, chemistry, physics and mathematics. Paleontology consists of both conceptual theorizing and focused scientific study. Traditionally, the sub-field of invertebrate paleontology has been closely tied to the study of geology, biostratigraphy, and historical geology, which have both commercial and academic drivers, whereas vertebrate paleontology has been more closely tied to biology with limited commercial applications. Both areas of study have broadened over time as a result of developing technology, but the \"classical\" requirements of fieldwork, laboratory preparation, and study of comparative anatomy remain core components of most sub-fields of paleontology. Paleontological study provides a direct source of information on the anatomy, physiology, ecology, and chronology of life on Earth, and the fossil record can be used to test hypotheses relevant to a range of scientific disciplines including other earth sciences and life sciences.\nThe word paleontology or palaeontology is a compound word formed from the roots \"paleo-\", \"onto-\" and \"-logy\", equivalent to the French word pal\u00e9ontologie or the German word Pal\u00e4ontologie. The spelling paleontology is primarily used in North America, while the spelling palaeontology is preferred in the United Kingdom and was historic spelled as pal\u00e6ontology. Multiple different pronunciations can be found, including (), (), and (). The root word \"paleo-\" is from the classical Latin or scientific Latin \"palaeo-\" and its predecessor Ancient Greek \u03c0\u03b1\u03bb\u03b1\u03b9\u03bf- meaning \"ancient\" or \"old\", the root noun \"onto-\" is from the Ancient Greek \u1f40\u03bd\u03c4- meaning a sense of relatedness, and the root word \"-logy\" is from the French \"\u2011logie\" which derives from the classical Latin \"\u2011logia\" and the Ancient Greek \"\u2011\u03bb\u03bf\u03b3\u03af\u03b1\" and in context means a field of study.\nFoundation.\nPaleontology includes the study of extinct animals and plants, including both direct observations about their remains and inferences about their behavior and how they interacted with their environment. From the recognition that fossils represented the remains of extinct organisms, paleontology became the zoology, botany, and biology of extinct organisms and therefore an important source for comparative anatomy. It was not always understood that paleontology is an evolutionary science, but over time, instances of evolution were recognized in the fossil record, and the two concepts have been closely linked ever since. The long span of geological time preserved in the fossil record allows very slow evolutionary changes to be observed, and the discovery of extinct organisms has allowed scientists to fill in gaps in the tree of life that cannot be understood through the study of extant organisms. The incorporation of a wider range of life sciences has allowed sub-disciplines like paleobiology and others to emerge.\nFossils.\nPrior to the 19th century, the word \"fossil\" was used as a descriptive noun to characterize anything that had been dug out of the ground, including bones, stones, and gems. Early descriptions of what we now understand to be fossils described their appearances alongside and in the context of other minerals, crystals, and rocks. These early publications varied in contents of \"fossils\" across a wide spectrum of inorganic to organic appearances, including true fossils of differing preservation qualities, inorganic concretions, and structures with a resemblance to organisms. Over time the criteria for separating organic fossils from potentially organic or clearly inorganic materials brought about a change in the etymology of the word \"fossil\" itself, so accounts before the 19th century may not reflect the same use of the word fossil as modern paleontology. Both inorganic and organic fossils were illustrated in numerous books on the topic throughout the 16th century, with some attributing them to the work of God and other suggesting applications in construction or medicine. Fossils were not believed to have been organic, but instead to have exhibited the same kind of \"growth\" as crystals. Support for a possibly organic nature of fossils began in the 17th century, though it remained contentious as different quarries or strata yielded different fossils, which the scientists of the time did not have the context to explain. The fact that most fossils came from organisms that had never been observed alive anywhere in the world seemed to imply that these organisms were extinct, which was contrary to the belief of a perfect divine creation. Another compounding factor was that fossils of apparently marine animals were found in parts of the world that were well above sea-level. Some suggested that these fossils had accumulated in horizontal layers under the sea and that subsequent tectonic activity had displaced them from their original positions. As these observations were made over time, it was eventually understood that fossils could be used to make inferences about the history of life from their presence or absence in particular areas over time.\nThe fossil record is the main tool used by scientists to study the history of life and assess the diversification of life over time. Very little is known about the origins of life and the oldest life forms, and this is likely a result of the poor quality of fossil preservation in older rocks. Older rocks preserve less information on average than those deposited closer to the present, and this effect is compounded across the billions of years that life is believed to have existed. Most fossils are made up of the hard parts of an organism that have been recrystallized by minerals, preserving bone, wood, or shells in a material than can be harder or denser than in life. While the hard parts are the most likely to fossilize, soft tissues can also leave impressions on sediment before they fully decompose, allowing non-mineralized parts of an organisms anatomy to be preserved. Even more rarely, a complete organism can be encased in sediment before decomposition, preserving it completely. While most fossils are body fossils (made of the actual body parts of a dead organism), some fossils can also consist of traces of the behaviour or life of organisms. This can include preserved burrows, footprints or coprolites, which are grouped together and called trace fossils. However, only a small minority of all dead organisms will ever become fossils. Some things can destroy organisms before or even after fossilization, including scavengers, decomposers, or natural disasters, and fossils can even be destroyed after they are formed by taphonomic processes. Even if a fossil survives burial, it can still be destroyed by weathering if it is exposed and not collected. The habitat of an organism can also impact its chances of fossilization. Seafloors are more likely to fossilize than land, and rivers or lakes are more likely to fossilize than mountains or deserts. Fossilized teeth are very common, but are not always collected when they are found, and more complete fossils may be more likely to be collected, but they are generally rarer in absolute terms. Even after collection, fossils may not be studied for a long time. They may remain in museum storage in crates, be on display, or be otherwise unaccessible to scientists.\nGeologic time.\nThe earliest discussions in the field of geology centered around the possible origins of geological features and what implications these had on Christianity. The concept of a history of Earth had existed for a long time, and those who studies rocks of fossils had come to the idea of changes over time. However, in the beginning of the field of geology in the early 19th century, the most common explanation for causes of geological change were that they were the result of sedimentation during the Biblical Flood, rather than slow processes drawn out over millions of years. French naturalist Georges Cuvier and his contemporaries believed that the Earth was not recently created (as in Young Earth Creationism), nor had it been around forever. They instead believed that there was a vast \"prehuman\" or antediluvian history. Cuvier was not the first to believe in a lengthy but finite age of the Earth, but he was the first to combine this idea with his study of fossils to suggest prehistoric events could be understood through the study of geology and the fossil record. Studies on rocks and their stratigraphy continued, including the development of geological maps highlighting the relative ages of regional geologic formations, and it was still believed that the Biblical Flood was a primary explanation for the formation of these features. \nEnglish geologist Charles Lyell was among the first to propose that a great flood had not occurred, and this was supported by the existence of overlapping terrestrial and marine sediment layers. He observed that the twisting, uplifting and carving of geological features supported the idea that the crust was moving continuously, and the sea level was also adjusting over time. This interpretation was not only supported by the differing levels of marine strata, but also by the shared commonality of fossils he found within them, even across large distances and at different levels above the sea. Combining these facts with his own previous work led Lyell to suggest some core principles of the history of the Earth. He suggested that here were progressive trends in the history of life, that geological history was continuously changing with periods of calm and chaos, and that the causes of these geological events were as much around in present day as in the deep past.\nFollowing the ongoing study of geology, geologic formations, and the establishment of geochronology, the geologic time scale was created to separate and categorize the vast history of Earth into a scale of named geochronologic units, defined and standardized by the International Commission on Stratigraphy. The age and duration of different units has changed over time following further restudy including absolute and relative dating of different sediments, with the current standard recognizing four eons, ten eras, 22 periods, 37 epochs and 96 ages. Present day is recognized as the Meghalayan age, of the Holocene epoch, of the Quaternary period, of the Cenozoic era, of the Phanerozoic eon. These geological time units are correlated globally through combinations of assigned times, index fossils, paleomagnetism, and other methods, with the correlation of taxa with time being termed biochronology. Through biochronology, paleontological events such as the evolution, extinction, or speciation of a taxon can be established at a point in time, and features such as mass extinctions can be identified.\nExtinction.\nFossils have been documented from at least as far back as Ancient Greece. However, the belief of philosophers including Plato and Aristotle was that anything that existed had existed forever and would exist forever, or was along a continuum of perfection without any gaps. As a result of this fundamental belief, evidence of extinction was ignored or explained away by naturalists for most of recorded history. It was not until the work of Cuvier with the publication of his \"Recherches sur les ossemens fossiles\" (or \"Investigations on fossil bones\"), that extinction was understood and considered the principal basis for paleontology as a science. By the early-mid 19th century, it was no longer controversial that fossil animals existed in a sequential order and as a result that fauna and flora were changing over time. Cuvier himself denied that there was any direct continuity from any of these fossils to organisms alive in the present day, and thus that all were extinct. However, he also did not believe the idea that any presently extant organisms had been alive in the past. Instead he believed that over time great \"revolutions\" occurred in which all living organisms went extinct, and new ones arose, which was consistent with belief in the Biblical Flood. It was not until English naturalist Charles Darwin suggested that extinction and evolution both occurred together, that a full explanation could be given for changes of life over time. The fossil record showed that there was not a predetermined length of time for which a particular organism (or group of organisms) existed, and it also gave evidence for periods where a large percentage of organisms went extinct at once, which could be the result of mass extinction events.\nExtinction can be seen as the final step of evolutionary change for any species. While modern biologists assess rates of extinction can be through the presence or absence of species in nature, paleontologists are limited in their understanding of this by the inherent rarity of fossils and the incompleteness of the fossil record. These difficulties make it more challenging to infer what extinction rates were in the past, and can make it difficult to differentiate between a true extinction and a \"pseudoextinction\", where one species evolves directly into another. Extinction of a species can occur from a variety of causes, and the intensity of extinction rates vary significantly over time. At least five mass extinction events are recognized to have occurred during the history of Earth, and it is also possible that the Earth is currently undergoing a sixth extinction as a result of human activity. However, mass extinction events only account for a small percentage of total species extinctions. Most extinctions occur as a result of other causes at differing times throughout Earth's history, which is sometimes called the background extinction rate. For most organisms in the fossil record, it is impossible to determine the cause of extinction in particular or even general cases.\nEvolution.\nFor most of human history, philosophers, theologians, and other intellectuals believed that the world was perfectly ordered by divine forces and could not have come about from natural processes. There are exceptions such as the Greek philosopher \u0415mp\u0435do\u0441l\u0435s who thought that fossils may have come from organic life that had undergone change, but this was the exception. Most religious doctrines, including Christianity and Judaism, taught that the world was created by God as it currently exists, so life could not have progressed and the natural world was instead the product of intelligent design. The evolutionary significance of the fossil record was not initially recognized because individual fossils only show snapshots of evolutionary history. However, recognition of the ability for traits to be passed to later generations was used by French naturalist Jean-Baptiste Lamarck in the 19th century to argue for evolution. Early proponents of evolution initially believed that God had set the world in motion but let it progress naturally, while critics such as Cuvier thought that intermediate forms required would have been unable to survive and so rejected the possibility of evolution outright. Influenced by the writings of Lyell, Charles Darwin studied similarities in organisms during his time aboard the \"HMS Beagle\" which would eventually became the book \"On the Origin of Species\". In it, Darwin proposed the concept of natural selection which would become fundamental to the later theory of evolution. Darwin also suggested that gaps in the fossil record were the result of incomplete fossilization and that transitional fossils would eventually be found that would corroborate the theory of evolution.\nPaleontologists cannot use the species concepts of modern biology due to limitations of working on fossils rather than living organisms. However, differences in the morphology of organisms based on their fossil remains can be used to separate phenotypes. Once phenotypic differences in a population of organisms accumulate, they should become genetically isolated and thus separate species. Therefore, the phenotypes observed in fossils can be used as a proxy to infer differences between species throughout deep time. It is possible that these evolutionary and morphological changes occurred slowly and gradually as is hypothesized by phyletic gradualism, or that short bursts of rapid evolution occurred in punctuated equilibrium. Evidence for both methods of macroevolution are present in the fossil record, and the discovery of new fossils continuously helps to fill gaps in our understanding of the evolutionary history of life.\nHistory.\nCuvier is generally regarded as the first paleontologist, and the origins of paleontology as a science trace their origins directly to his demonstrations that fossils in stone were traces of organisms that were once alive but had gone extinct. Despite this, he was far from the first to write about fossils or make observations about things found in rock. Isolated comments from writers about fossils can be found going back to classical antiquity. The philosopher Xenophanes (6th century BCE) believed fossil shells represented life from the past, whereas Aristotle instead explained fossils as \"vaporous exhalations\". Aristotle's belief was later refined into the theory of a petrifying liquid by Arabic philosopher Avicenna and German philosopher Albert of Saxony in the middle ages. Chinese naturalist Shen Kuo also proposed a theory of climate change around this time based on the presence of petrified bamboo in regions that in his time were too dry for bamboo. In unpublished notebooks, the Italian polymath Leonardo da Vinci justified an organic origin for the fossil shells available to him. His notes show observations of living mollusks and their ecology, the processes of sedimentation, and the recognition that the fossil shells had similar features, showed similar growth stages, and had similar pathologies to living mollusks. Da Vinci's study of sedimentation meant he understood why fossils were usually embedded in rocks, and his notes demonstrate a very modern interpretation of the origin of fossils. He rejected the Aristotelian theory of vapors and also did not believe that the Biblical Flood was the primary cause of fossil formation. Da Vinci's notebooks may have inspired others of the time to accept a biologic origin of fossils, but this belief was not accepted by everyone. In addition to his study of body fossils, da Vinci is also credited as the founder of the field of ichnology, which is primarily concerned with trace fossils and how they can provide insights into the behavior of extinct organisms.\nIn the 17th century, naturalists like the Danish scientist Nicolas Steno and the English polymath Robert Hooke provided further discussions on the origins of fossils. The general belief was that fossils were of organic origin, but that they had been fossilized by petrifying liquids and moved into elevation by the Biblical Flood or some other means. Conversely, the English physician Martin Lister completely rejected the possibility of organic fossil origins. The fossils available to Steno, da Vinci, and others mentioned above were primarily the easily-identifiable shells of marine animals, and their organic origin was a relatively straightforward inference. The fossils in England were from rocks dating to the Jurassic or Carboniferous and came from a variety of different organisms that bore no clear resemblance to modern organisms. Many explanations were suggested for the posible inorganic or organic origins of fossils, how they came to be lithified, and how they ended up far above the sea, but the ideas of extinction and deep time had not yet been developed, so an explanation eluded naturalists of the time.\nA significant moment in the history of paleontology was the publication of the 1796 paper \"On the species of living and fossil elephants\" by Georges Cuvier, which contained detailed evidence for extinction. Cuvier named the fossil taxon \"Megatherium\", based on bones found in Paraguay. The large size of these bones made it unlikely that they were from an extant, but undiscovered, animal. Cuvier reached a similar conclusion regarding the fossils named the mastodon, with the uniqueness of these animals demonstrating that they belonged to species that were no longer alive and thus extinct. To further justify this conclusion, Cuvier extensively studied the fossils of elephants and proved the distinction of mammoths from Siberia and Europe from their living relatives. Presenting this work on the extinction of the megafauna, Cuvier termed the events that led to their disappearance \"revolutions\", contrasting with the idea of gradual change in the environment and the fauna within it. Of the three possibilities leading to the disappearance, Cuvier supported extinction over migration as well as over evolution as suggested by Lamarck, with his view that extinction and evolution were conflicting explanations. Cuvier also studied the comparative anatomy of both living and fossil organisms and developed a way to assess their morphological characters, which opened the door for developing an understanding of the animals of the past.\nDevelopments in the fields of stratigraphy and paleontology following the work of Cuvier became widespread throughout Europe, and the classification of extinct organisms into different groups that included their living relatives also proliferated. While most of Cuvier's early studies had been on mammals, there were some fossils with no close living analogues such as the bird-like fossil reptile he called the \"Ptero-dactyle\" or the fish-like marine reptiles that were eventually named ichthyosaurs. It was in 1822 that Henri Marie Ducrotay de Blainville, a former student of Cuvier, introduced the name \"pal\u00e9ontologie\" for the study of these ancient beings. He had earlier introduced the names \"pal\u00e9ozoologie\" and \"pal\u00e9osomiologie\" for the studies of fossil animals and fossils in general, respectively, but the latter did not see widespread use and paleontology was the name generally adopted for the field by naturalists of the time. Some of the most significant discoveries of this early time in paleontology were made by Mary Anning and her family, who uncovered skeletons from a variety of marine reptiles and other animals in the Lyme Regis region including \"Ichthyosaurus\" and \"Plesiosaurus\". These animals were geologically older than the mammals of Cuvier's earlier work, and this relative age became the study of stratigraphy which enabled scientists to date and order animals relative to one another in geologic time. The works of Cuvier and Lamarck on extinction and the history of life, and the works of Lyell and English geologist Adam Sedgwick on geology, were all synthesized by Charles Darwin in his seminal works on the theory of evolution. He suggested that the history of life was full of gradual changes, with the constant presence of extinction acting as the driver evolution through natural selection. This was validated by multiple discoveries soon after Darwin began publishing. The discovery of the theropods \"Compsognathus\" and \"Archaeopteryx\" demonstrated evidence for the progressive evolution of birds from other reptiles, which shifted paleontological study in the direction of studying the evolution of life.\nFor a time paleontology was considered a sub-discipline of geology with relatively little study given to the biological aspects of the field, and paleontology was generally not treated as an important field of study of either science. Over the subsequent decades, geology and biology advanced to theory-based analysis while paleontology lagged behind as a field focused primarily on stratigraphy. This changed with the development of paleobiology in the second half of the 20th century. This shift was driven by conceptual changes in the study of evolution and phylogenetics and the emergence of new ways to study geology through biostratigraphy, paleobiogeography, taphonomy and paleoclimatology. Phylogenetics were developed as a way to quantitatively analyze and interpret the evolution and relationships of organisms, providing context and predictability for evolutionary processes and the impacts of mass extinctions and their recoveries. Paleoecology itself has seen the emergence of subdisciplines including the field of taphonomy to study the nature of the fossil record. Emphasis was also given to the analysis of diversity and the distribution of taxa, the study of trace fossils, the understanding of paleoenvironments, and conservation paleobiology. Advancements in technology and the analytical tools of other sciences have also been integrated into paleontology including geochemical analysis, molecular biology, and other computer-aided visualization or analysis techniques.\nThe heyday of paleontology was arguably in the Victorian era, with little substantial change since beyond the notable discoveries of new taxa. These on their own have done little to change our overall understanding of the history of life. However, the history of life is not just the story of evolutionary changes, and paleontology has increasingly broadened to include a wider variety of scientific questions. The sizes of the largest dinosaurs, pterosaurs, or arthropods pose interesting questions to study in the fields of biomechanics, ontogeny, and physiology. Diversification and mass extinction can be predicted and better understood from the studies of phylogenetics, and as technologies and precision improve, the depth to which we understand life of the past will increase.\nApplications.\nPaleontology both draws from and contributes to the fields of geology and biology, despite historically being dismissed as an undemanding science. Analysis and description of fossils allows the researchers to illustrate biological, geological, ecological and tectonic changes and phenomena which have implications for our understanding of science in the present. Many disciplines and areas of study interact with paleontology and overlap in some areas with the field. Through this overlap, paleontology has the ability to better our understanding of the origin, diversity and evolution of life, and can be used by other fields to investigate patterns in the fossil record. In the modern day, paleontology is viewed as important by researchers. Its study enables scientists to understand the history of life. It can explain different worlds of the past and the impact of a changing climate and biodiversity, and paleontology helps expand our understanding of both evolution and extinction. Subfields of paleontology also enable geologists to robustly establish the ages of various rock formations.\nHistory of life.\nPaleontological discoveries have discussed the origins and history of life for centuries, with very little knowledge of life before the Cambrian for a significant amount of time. Fossils from prior to the Cambrian were limited to 2.1 billion year old fossilized algae and possibly \"plants\" until the discoveries of fauna in the Bitter Springs Group and Apex chert of Australia, the Mistaken Point Formation of Canada, and the Doushantuo Formation of China, all of which have significantly expanded knowledge of the Ediacaran biota that includes a range of life from microscopic single-celled organisms to macroscopic multicellular life. Fossil discoveries have also improved knowledge about the Cambrian explosion with the discoveries of multiple new lagerst\u00e4tte deposits. The Burgess Shale was one of the first such deposits and has been further explored, and around 40 other Burgess-type localities are now known globally. These localities are filled with soft-bodied taxa that show the decline of the Ediacaran biota and the emergence of other kinds of metazoan life. The refinement of Cambrian stratigraphy will also improve the understanding of these early faunas and how they changed over time.\nThrough advances in paleontology many other evolutionary paths have become better understood even in more recent life. The evolution of birds is now understood to have occurred from gradual evolutionary changes in saurischian dinosaurs up to the point where it is difficult to draw a line between what dinosaurs are or are not birds. The origins of dinosaurs themselves are better understood from the discoveries of multiple near-dinosaur taxa. Discoveries within the Eocene of fossil mammals have allowed for the evolution of whales to be nearly completely understood, with the fully terrestrial mesonychids becoming gradually amphibious before becoming aquatic swimmers. Relatives of modern whales such as \"Basilosaurus\" were obligate swimmers, but even then had not developed the bauplan of modern cetaceans that occurred over further gradual evolution. The evolution of reptile groups such as ichthyosaurs and turtles, while still controversial, is much better understood with finds such as the early incompletely-shelled turtle \"Proganochelys\".\nHuman evolution is also much better understood from progress in paleontology, including both the evolution of hominids from basal primates as well as the speciation and origins of humans within the hominids. Fossils of \"Australopithecus\" and \"Ardipithecus\" show that humans never transitioned through an ape-like stage, instead being bipedal with adaptations for arboreal locomotion. \"Adripithecus\" is known from lowland forest environments, and not grasslands, suggesting the origins of humanity within a variable and unpredictable habitat. The evolution of humans within the genus \"Homo\" is similarly complex and does not follow a clean linear path as sometimes described. Some species of \"Homo\" may have overlapped in time and place with others, but all show that then evolution of the genus was likely in Africa. Advancements and new discoveries have also shown that the neanderthals were a complex society with the use of tools, clothes, and having their own mythology. DNA from neanderthals and humans show substantial differences, but also that there was interbreeding between populations.\nExtinction events.\nThe idea of a mass extinction has been around since the beginning of paleontology and is generally accepted as true events that drive the evolution of life. However, the question of what makes an extinction event a \"mass extinction\" is still uncertain. On the scale of geologic time, mass extinction events happen rapidly, and such rapid events can be caused by both gradual environmental processes and large-scale catastrophes. A notable exception to this rule is the Cretaceous-Paleogene extinction event, which is believed to have been caused by an asteroid impact which caused global wildfires and a disruption of the nutrient cycle in the ocean. If this is the case, it would be an unprecedentedly rapid extinction event, occurring over the course of one or a few years. However, even this extinction's cause is debated. Some have suggested that it was caused by marine regression or volcanism that occurred near or at the same time as an impact. No other extinction events can be linked clearly with an extra-terrestrial cause. Glaciation and subsequent global warming has been suggested as a cause for the Late Ordovician mass extinction, and the volcanic activity of the Siberian Traps large igneous province has been suggested as the primary cause for the Permian-Triassic mass extinction. The causes of the Late Devonian mass extinction and the Triassic-Jurassic mass extinction remain mostly uncertain to this day.\nThe period of ecological recovery following a mass extinction is also a significant time for biodiversity and adaptive radiation. The term \"disaster species\" has been applied to the organisms that follow an ecological disruption, and there are many known from the fossil record. Following the Cretaceous-Paleogene extinction, there is a large spike in the abundance of fossil ferns that is interpreted as an early post-extinction flora that would later be overtaken by different floral communities. There is a similarly rapid diversification of small, generalist mammals for the first 3 million years before more diverse faunal communities evolved. However, not all mass extinctions have similarly rapid diversification events. The recovery period following the Permian-Triassic extinction took up to 10 million years. The recovery of ecosystems from mass extinctions involves the evolution of novel ecological relationships between groups of animals that would not have been possible in the pre-extinction ecosystem.\nBiostratigraphy.\nFossils have been used for stratigraphic correlation since at least the 18th century. Observed changes in the fossils found through geologic time led to the principle of ecological succession, however this study was not elaborated on until the 1960s. The first and last appearance of a taxon in the fossil record can be used to compare the relative ages of different lithographic sections of sediment. This principle allows for relative ages of different sediments to be determined more precisely. These \"index fossils\" are combined with measurements of volcanic ash, paleomagnetic reversals, or pre-dated sediments to make precise measurements of geologic time. For example, the Jurassic Period was named and defined based on ten main subdivisions identified through the English and French assemblages of ammonites, some of which are still in use today. Biostratigraphy is also applied to the analysis of stratotype sections and boundaries of geologic time units. It can also use the first or last appearance date of a taxon to establish time periods that are independent of their constituent strata.\nThe geologic time scale is based primarily on the biostratigraphy (correlating strata) and equivalent biochronology (correlating times) of the appearance and disappearance of various fossil taxa. Some factors can introduce uncertainty into this process including the quality or quantity of sampled fossils. Different graphical and numerical methods are used in the construction of the geologic time scale. Even the Ediacaran, which is poorly represented through fossils, can be assessed using biostratigraphy in combination with chemostratigraphy and absolute dating. The biostratigraphy of the Ordovician and Silurian is based primarily on fossils of graptolites and conodonts. Other common groups used in zonation include ammonites, foraminifera, and plant pollen, where it is preserved.\nClassification.\nThe foundation of modern taxonomy is the scheme of hierarchy adopted by Carl Linnaeus where taxa were grouped in taxonomic categories. While Linnaean hierarchy was not the first system, it formed the basis for subsequent systems, with seven principle categories arising to classify life: Kingdom, Phylum, Class, Order, Family, Genus, and Species (Division instead of Phylum for botany). Intermediate categories were also developed, though they were not considered mandatory to specify. Following \"On the Origin of Species\" in 1859, the concept of taxonomic hierarchy shifted to describe common descent through evolution rather than similarity, rendering some previously-accepted groups non-monophyletic as they excluded descendants. The continued trend of emphasizing evolutionary descent has led to a reduced significance of Linnaean taxonomy because of these inconsistencies.\nAn important development classification in modern paleontology was the adoption of phylogenetic systematics as a tool to study the evolutionary tree of life. The use of phylogenetics allows scientists to quantitatively describe the relatedness of organisms through reconstructions of evolutionary trees. Phylogenetic analysis was first applied to the fields of entomology and ichthyology, after extensive debates within those fields before being adopted by evolutionary biologists more broadly. By using systematics, scientists can test and retest hypotheses about evolutionary relationships, and the results are typically displayed as a cladogram. The widespread use of systematics coincided with the advent of molecular biology, which has allowed scientists to use genetic data in addition to morphological data to study evolutionary relationships. Classification systems in general have also shifted in favor of phylogenetics. The Linnean classification scheme with its well-defined taxonomic ranks has gradually fallen out of use, because it does not generally perform well as a reflection of true evolutionary relationships.\nFurther applications of classification to paleontology include more focused issues such as delineating the distinction between microevolution and macroevolution. Microevolutionary paleontology is the study of how evolutionary pressure impacts the ability of single individuals to survive over others, while macroevolutionary paleontology focuses on the ability of whole species to survive over others. Some scientists have suggested that microevolution and macroevolution are separate processes, with morphological changes originating from speciation rather than gradual anagenesis of a population. Others have argued that both individuals and populations are affected by natural selection.\nSubdisciplines.\nPaleontology overlaps and integrates with many other disciplines of science into fields that focus on more specific topics. The overlap of paleontology with biology, paleobiology, includes studies on macroevolution, extinction, speciation, diversification, morphology, biogeography, phylogeny, paleoecology, molecular paleontology, taphonomy, and evolutionary developmental biology. Many subdisciplines of paleontology are focused on specific groups of organisms: invertebrate paleontology is the study of fossil invertebrates; vertebrate paleontology is the study of fossil vertebrates; paleoalgology is the study of fossil algae; paleobotany is the study of fossil plants; paleoentomology is the study of fossil insects; paleoherpetology is the study of fossil reptiles and amphibians; paleoichthyology is the study of fossil fish; paleomalacology is the study of fossil mollusks; paleomammalogy is the study of fossil mammals; paleomycology is the study of fossil fungi; paleomyrmecology is the study of fossil ants; paleornithology is the study of fossil birds; paleoprimatology is the study of fossil primates; and paleozoology is the study of fossil animals. Paleontology in general also overlaps with studies on growth, paleoanthropology, many fields that focus on the Earths climatic and geographic past, histology, ichnology, pathology and forensics, and taphonomy, forming the subdisciplines described below.\nPaleoanthropology.\nPaleoanthropology is a field of study that focuses on the evolutions of humans. The field can trace its origins to the works of German naturalist Johann Blumenbach in the late 18th century and then the discovery of a neanderthal in the mid 19th century though it only took its modern form as the study of human evolution following World War II with the acceptance of evolutionary biology. Paleoanthropology utilizes information on humans drawn from both fossils and archaeology to interpret the rise and spread of humans. Beliefs were that only a single species of hominid was present at any one time, forming a natural progression to modern humans, considering the diverse groups of species proposed as synonyms. Discoveries showed that this belief was not correct, with human evolution displaying a complex and uncertain arrangement of individuals, populations, and species with the advent of phylogenetic analyses. \"Ardipithecus\" is one of the oldest known of the human branch of hominids, having lived 4.4 million years ago and only found in 1994. Species of the genus \"Australopithecus\" from across Africa have been named since the 1970s are slightly younger, but already show the bipedal stance of modern humans. From \"Australopithecus\" likely evolved both \"Homo\" and the more robust hominid \"Paranthropus\", which is unlike modern humans in build but lived alongside early humans for some time.\nIt is known that early humans were capable of making and using tools from the discoveries of fossils of \"Homo habilis\" in places where stone tools had previously been found. The earliest known stone tools are from around 3.3 million years ago, and while they are often associated with \"Homo\" it is also possible that the coexisting species \"Australopithecus garhi\" was a toolmaker. There is reluctance to believe that a australopith was capable of making and using tools, but the origins of \"Homo\" are unclear and there is little that can be used to distinguish tool-making from non-tool-making hominids when fossils and tools are not found together. The first humans to show a more slender modern bauplan are those of \"Homo ergaster\", which is sometimes considered part of African \"Homo erectus\", from around 1.6 million years ago. Once the modern body form evolved, humans spread far beyond Africa, spreading across Eurasia from which evolved \"Homo heidelbergensis\" and \"Homo neanderthalensis\". Though the diversity of neanderthals is uncertain, sites have been found that show they had a burial culture and a rich technological record. The similarities between \"Homo sapiens\" and these older or coexisting species makes it difficult to determine what made modern humans unique.\nPaleobiogeography.\nPaleobiogeography is a very similar field to biogeography but focuses instead on fossils rather than modern organisms. Both fields work to explain the differences in flora and fauna between different locations, rather than the expectation that regions of similar climate and habitat would house the same organisms. Biogeography relies on exploration, both as an exploratory tool to understand the world, but also the physical act of travelling to different places to observe differences. Paleobiogeography is named with the prefix \"paleo\" to differentiate in its use of the fossil record to study biogeography, which means that paleobiogeography suffers from the same issues as other paleontological fields regarding the limitations of the fossil record. It was established as a geoscience from the recognition and acceptance of the theory of continental drift that was hinted at by the discoveries of similar fossils on now-distance continents during the 19th century. Paleobiogeography involves studying the history of life, but is relevant for the study of evolutionary, geological, and ecological changes as external factors such as biogeography are one of the two drivers of evolution. Ecological processes can be studied that cause speciation or regulate diversity, and these differences across location can be tied to geological processes like plate tectonics and climate change. Modern biogeography has the advantage of being able to study molecular markers and more thoroughly study small spatial and temporal regions creating a better picture of a specific environment. Paleobiogeography on the other hand is capable of studying very long timescales, able to track history beyond just the modern era. Flora and fauna may be affected by small-scale cycles as well as broader effects that cannot be seen on a limited timescale, so paleobiogeography can provide a more complete picture of patterns and processes. Through the fossil record, paleobiogeography can monitor the evolution and coevolution of life on Earth, associating patterns with geological events and over long timescales, working with the field of biogeography to understand biogeographical processes.\nPaleobiology.\nPaleobiology is the study of the biology of extinct organisms. As a topic it has been around since the beginning of paleontology itself, as fossils are the remains of extinct organisms, but the areas of research covered by paleobiology have changed to capture much more theoretical thinking, studying the biological aspects of paleontology rather than geological topics like stratigraphy. This means there is a particular focus on evolution, adaptation, ecology, function, and behavior in paleobiology, especially of invertebrates which are far more common in the fossil record. Darwin's work on evolution was largely paleobiological in nature, drawing from paleontology, geology and biology, but also pushed paleontology into the background as the incompleteness of the fossil record became a hindrance to advancements in evolution. The first use of \"paleobiology\" as a word came in 1893, but it was the work of Othenio Abel in the 1910s that established \"p\u00e4leobiologie\" as the study of biologically informed paleontology. Franz Nopcsa is also understood to have been a pioneer of paleobiology, and one of the first paleontologists to use histology and the interpret the paleophysiology of extinct animals. Biological questions did not change the field of paleontology greatly until the general transformation of the field in the 1950s and 1960s with new approaches to the fossil record and a differing view on the place of paleontology as a discipline. Paleontology was no longer seen as a subdivision of geology but instead as a field of biology or a field of its own, able to be grounded in theoretical thinking and assessed numerically. Paleontology was suggested to be educated as two separate areas: stratigraphy and paleobiology, with significant overlap and incerconnection. Throughout following decades paleobiology would expand to encompass many theoretical fields related to evolution or extinction, and become a feature of museums and universities supporting the connection between paleontology and biology.\nMany of the fields of paleontology can be seen as part of the study of paleobiology, and paleontologists themselves may be better referred to as paleobiologists. Evolution and paleoecology are large parts of the change towards paleobiology and major areas of study and advancements of the field. Theoretical thinking and analysis of evolution has advanced and improved applications of the fossil record. Studies of taphonomy, evolutionary paleoecology, diversity, behavior, trace fossils, and the paleoenvironment all fall under the breadth of paleoecology. Paleobiology is able to inform on questions about the life appearances of organisms, their ways of communicating or reproducing, their growth, and how they survived and died out. Effective paleobiology requires knowledge of biological fields (evolution, genetics, systematics, evolutionary developmental biology, biogeography, ecology, biochemistry), geological fields (sedimentology, stratigraphy, Earth history, isotopes, geochemistry, taphonomy), statistics and applied math, and often even computer science. Findings and studies in biology are relevant and applicable to paleontology, and as a result the findings of paleontology become relevant to biology. The available information to study between the two fields is different, forcing paleontological studies to be more integrated while biological studies are more focused, but this is an opportunity for collaborative work.\nPaleoclimatology.\nPaleoclimatology is the study of the ancient climates, and is a \"paleo-science\" alongside paleoecology and paleoceanography. Studies on the climate before and during the Quaternary, where direct measurements become available, are beginning to converge in scope, but the term \"paleoclimatology\" remains often restricted to the former. Before the identification and acceptance of plate tectonics, paleoclimatology had been applied from the observation that fossils were sometimes found where the climate was currently not suitable to that organism. Little discussion was had about the changing of the climate beyond the Last Glacial Maximum, so paleoclimatology was restricted to the climate of the Quaternary. Inconsistencies between climate-significant rocks and current geography were not able to be reconciled until plate tectonics demonstrates that climate zones were constant but the landmasses beneath them would change. Indicators of the paleoclimate could be found in certain types of rocks, which coupled with reconstructions of the paleogeography showed that climate zones in the past were roughly the same as today, with exceptions. During the time of the supercontinent Pangaea, arid regions were believed to be generally lower in latitude that at other times in the past, which would be explained by the monsoonal nature of the continent in the 1970s and the understanding that atmospheric circulation of monsoons also affected the regionality of climates. Ocean drilling of core samples from the seabed were then used to identify isotopes that could examine the proportions of oxygen and carbon dioxide over time to illustrate the warmth and coldness of ocean waters. In some sense, global paleoclimatology would not be possible without these ocean drilling programs. Numerical modelling of the paleoclimate was employed to further the field, though it struggles with the polar regions and the climate of continental interiors. Further development of paleoclimatology will likely focus on the impact to humans of the alterations to the climate that are occurring, and use information from the past to make predictions about the future.\nPaleoecology.\nPaleoecology is a diverse field of paleontology that relates to the reconstruction of lifestyles and ecosystems of ancient life. While we know much about the evolution of life, less is understood about the interactions and behavior of organisms. The large amount of speculation involved in paleoecological interpretations means it may be disregarded at times, but a developing use of numerical and statistical techniques allows for quantitative assessments of paleoecological hypotheses. Paleoecology also investigates the long-term changing of ecologies and the balancing of chemical, biological, and physical changes of the world. Fossil animals and plant do not normally preserve in completion or in their undisturbed habitats, with scavenging, erosion, or transportation complicating their interpretation. The study of these complications from fossilization is taphonomy, which is its own significant and developing field of paleontology. The combination of reconstructions of ancient environments with the evolution of these environments over time is termed evolutionary paleoecology. Global patterns of diversity can be investigated through paleoecology, suggesting large bursts of diversification and the temporal separation of major faunas forms. However, these interpretations of changing diversity may be due to biases towards the preservation and discovery of more recent environments over older ones, where the field of taphonomy can become significant.\nPaleoecology has been able to identify several large-scale patterns in evolution and different faunas. It has been interpreted that communities living nearshore exhibit earlier diversification before spreading to offshore environments, or that tropical latitudes exhibit greater diversification. A largely detritus-feeding Cambrian fauna appears to be replaced by a suspension-feeding Paleozoic fauna, before itself being replaced by a modern fauna of marine invertebrates, though these faunas and their distinctiveness have also been questioned. Some communities show very little modification over time in a form of statis with stable composition, which changes during brief periods of turnover before stabilizing again. Competition and coevolution driving evolution may be studied through the fossil record, as well as predation and other forms of species interactions. The study of trace fossils, ichnology, also related to paleoecology as the study of fossils arising from behavioral patterns in organisms. Paleobiogeography, paleoclimatology and conservation paleobiology are also related fields of paleoecology, with the latter in particular being relevant to policies that attempt to preserve biodiversity.\nPaleohistology.\nPaleohistology is the study of the hard tissues of fossils, analogous to the field of histology that studies biological tissues. The field is comparatively restricted as fossils preserve only superficial tissue structure and not molecules that can be found in modern histology, but it still has a long history following the use of microscopes to study both living and extinct organisms. Fossilization changes the composition of bones and to a lesser extent teeth, though their histology can still be examined through thin sections. The first use of thin sections in studying tissues in fossils was that of Richard Owen in a set of volumes in the 1840s that included dinosaurs and pterosaurs, which was simultaneously the first large comparative study of hard tissue histology. The microscopic structure of the bones, dermal armor, and teeth of early vertebrates and fossil fish was studies soon after, though polished bone surfaces were used rather than thin sections. The hard tissue structure of these early vertebrates has been used to classify them and separate jawless vertebrates (ostracoderms) from those with jaws such as placoderms and acanthodians. Similarly, the paleohistology of tetrapods has been used as evidence of both their classifications and their function. The internal structure of bones of many tetrapods can be used to identify their age quantitatively through the count of growth arrest lines. Paleohistology combines structural knowledge with functional interpretations and evolutionary processes to help understand evolution.\nPaleopathology.\nPaleopathology is the study of ancient disease, with the clarification that \"disease\" is not limited to pathogens but also any other impairments that can impact health. Though paleopathology is most often discussed in the context of archaeology and human history, it has also included the study of pathologies in any fossil organism since the word was first introduced by Robert Schufeldt in 1892. It is important to separate pathological conditions from alterations that have arisen due to taphonomy, and from that distinction modern diagnostic techniques can be used to interpret the causes and impacts of pathologies in fossil organisms. Biomolecular studies have been able to isolate genetic material in fossil animals and humans to identify specific pathogens, and questioning the strength of these identifications has led to re-evaluations of the history of disease in humans and a more nuanced approach towards the study of disease in humans. Multiple factors can cause skeletal lesions that preserve well in fossils and it can be difficult to distinguish these causes due to not being able to confidently identify causes of mortality and predispositions for vulnerability. Most of the focus of paleopathology remains on human disease, though the field of animal paleopathology emerged in 1999 and expanded to cover much of the same scope of studies as human paleopathology. Specific studies into the stress fractures in the bones of dinosaurs have used their presence and distribution to identify the activity levels of the impacted animals such as running, migrating, or restraining prey.\nPaleophysiology.\nPaleophysiology is the study of how ancient life coped with its chemical and physical surroundings. Much is known about physiological changes on a short time scale, but less so about long-term responses including genetic modification. Paleophysiological analysis can investigate how species evolved or went extinct from gradual or rapid environmental change and apply that to modern scenarios to predict responses in the future. Past geological records can be found that resemble those predicted for the future. Extinctions of ancient organisms tend to be selective to certain traits like metabolic rate, temperature tolerance, photosynthesis and homeostasis, but much is not yet understood about the physiology of ancient organisms. The most useful tool for assessing paleophysiology is through the studies of \"living fossils\" that has presumably changed very little physiologically over long periods of time and therefor can be used to indicate paleophysiological conditions. It remains largely unknown how calcifying organisms built robust skeletons at times when atmospheric carbon dioxide levels were high, but the understanding of this process can be applicable to current rising carbon dioxide levels. Similar work may explain how photosynthetic corals and reefs can exist in times of higher acidity and temperatures as in the past. Plants respond to changes in temperature, precipitation, soil quality, and atmospheric gas composition, which can be seen in their fossils. Fossils offer a large array of phenotypes and physiologies that are rare or absent in modern biotas making it possible to assess adaptations that are not found in living species.\nPaleoichnology.\nPaleoichnology is the study of trace fossils, which can display interactions between organisms or other aspects of behavior. Common trace fossils are the burrows of bivalves or worms in shallow water, feeding traces on the deep ocean floor, and the footprints of dinosaurs and other animals in mud and sand beside bodies of water. The description of dinosaur tracks goes back to the early 19th century, but larger discussions about paleoichnology and its uses came with the reidentification of supposed plant fossils as invertebrate trackways in the 1880s to 1920s, where modern analogues were introduced to interpret these trace fossils. Advancements by Adolf Seilacher in the 1960s identified the shortcomings of ichnology: trace fossils were limited in their ability to establish the paleoenvironment, and as they lacked a consistent naming scheme it was difficult to classify and compare trace fossils. Seilacher expanded upon ichnotaxonomy as a way to classify trace fossils according to the behavior that caused them allowing the identification of sedimentary or environmental contexts. From this, ichnotaxonomy differentiates between trace fossils created by tracks, burrows or borings, excrement, and other types of behaviours, rather than describing the organism that created them. One animal can make many different kinds of traces, and one trace can be made my many different kinds of animals.\nFootprints made by vertebrates can often be compared more with the organism that could have created them, but this identification is not definitive and can be reinterpreted over time. Different kinds of trace fossils can also be dependent on the type of sediment the organisms were interacting with, with feeding traces on the ocean floor fossilizing differently over different substrates, and trackways of vertebrates being able to be followed across distances. The understanding that trace fossils directly correlate to sediments means that they can be used as indicators of environment types, termed ichnofacies and paleosols. In rare cases trace fossils can also be preserved alongside body fossils, such as the dinosaur \"Oryctodromeus\" that is the first to show definitive evidence of burrowing behavior as its body fossils were found buried within a fossilized burrow. Trace fossils are able to be used as markers of biochronology and biogeography for correlation, and some such as coprolites can be used to understand the diets, diseases, parasites, or climates of the organisms that created them. Some trace fossils show evidence of gregariousness in animals travelling together in the same direction or congregating at a site, while others can show pathologies in the form of uneven gaits or pathologic foot impressions. Trackways of footprints can even be used to estimate the size and speed of their creators and their courtship and nesting behaviors.\nTaphonomy.\nTaphonomy is the field of study of the process of fossilization and the processes that occur between burial and discovery. The term taphonomy was introduced in 1940 by Ivan Yefremov as a new branch of paleontology, though the consideration of how an organism becomes a fossil predates his work. Taphonomy did not gain prominence as a field until the 1960s when it became important to consider how fossilized deposits relate to their original ecosystems, and the incompleteness of the fossil record became important for evolutionary theories such as punctuated equilibrium. Taphonomic studies of this time involved experimentations to see how the properties of water can transport, sort, or bury bones. It is unlikely that an organism will become a fossil after death, as many factors can damage or destroy both soft and hard tissues before they are buried. The hardest parts of an organism, such as shells or skeletons, are the most likely to survive to be buried and fossilized, though in rare cases soft tissues can be preserved as well. If a dead organism is buried immediately, and particularly in an anaerobic environment where decay is slowed or stopped, a complete body fossil including both soft and hard tissues may be formed, but even then different chemical or geological processes can alter the fossil, through the mineralization of organic material, or the forming of concretions around them.\nWhen not buried immediately, many different taphonomic processes can be involved in the completeness and type of preservation. The transport of organisms from their original position can result in disarticulation or the incompleteness of material, and exposure to scavengers or the surrounding environment can result in decay, fragmentation, or abrasion. After burial the rock containing fossils may be flattened geologically or deformed by the distortion of metamorphic activity. Plants can commonly be fossilized as layers of carbon where all soluble elements of the plant have been removed, and large accumulations of these carbonaceous materials may be transformed into coal seams. Many filters influence the preservation and recovery of fossils, all of which impact the completeness of the fossil record. Common organisms in an environment, that lived around shallow bodies of water with little natural erosion is more likely to be preserved, and after preservation is more likely to be discovered if the rock does not undergo severe metamorphosis, is moved to the surface geologically, and is in a location where it can be exposed to humans. Nearly every paleobiological study incorporates a taphonomic assessment and recognizes biases in the fossil record that can impact their reconstructions.\nCultural significance.\nPaleontology is one of the most high profile of the sciences. Discoveries, especially concerning dinosaurs or human evolution, are commonly reported in the mass media, with only astrophysics and global health comparable in the level of press attention. Prehistoric life is inspiration for toys, television and films, computer games, and attractions in tourism. Environments and organisms from the deep past are some of the most familiar concepts drawn from modern science, such as the dinosaurs \"Tyrannosaurus\", \"Triceratops\" and \"Brontosaurus\", early humans like the Neanderthal and \"Homo floresiensis\", extinct megafauna like mammoths and sabre-toothed cats, and invertebrates like trilobites and ammonites. Paleontology academically is not a particularly well-financed field of science; the operational budget of the American Museum of Natural History in 2021 was $178 million while the budget of the 2018 film \"Jurassic World II\" was $516.1 million. The influence of paleontology in public consciousness may be due to a number of causes such as the mystery, the immense scale of time, the size of some organisms, or the similarities between myths of dragons and giants and their representation in extinct faunas. Paleontologists draw from public funding and use appeals to gain sponsorships, but the public aspect also overshadows some portions of the field to the benefit of others. There is an overwhelming focus in paleontology on the study of dinosaurs or specific geographical regions, with the most iconic taxa almost exclusively coming from the late 19th and early 20th century excavations in North America. The marketing to children of paleontological items can make the field be regarded as \"childish\" and undermine the utility of the science in popular consciousness.\nPublic perception of paleontology goes back to mythological interpretations of fossils' discovery by numerous indigenous peoples of many continents. Traditional Chinese medicine made use of Pleistocene mammal fossils as \"dragon bones\" or \"dragon teeth\"; indigenous peoples of Australia and North America made reference to landforms and fossils; and fossils have been interpreted as Nephilim, mentioned in the Book of Genesis, by European and North American Christianity. Early reconstructions of deep time following the foundation of paleontology saw paleoartistic reconstructions of past ecosystems, including the creation of the Crystal Palace Dinosaurs sculptures and landscaping in the 1850s under the direction of Benjamin Waterhouse Hawkins. Hawkins would also create the first free-standing skeletal mount of a dinosaur in the 1860s: \"Hadrosaurus\" at the Academy of Natural Sciences in Philadelphia. The Bone Wars between American paleontologists Othniel Charles Marsh and Edward Drinker Cope in the late 19th century engaged with the media at the time, and has since been used as a common popular narrative of paleontology through novels, comics, popular books, and even a musical. Following Marsh and Cope, a second American dinosaur rush occurred at the start of the 20th century when new museums and institutions aimed to excavate and display the highest-quality dinosaur fossils, accompanied by paleoart, news media, and exchanges with overseas institutions. This exploitation for popular appeal also intertwined paleontology of the time with imperialism, as fossils from Africa, Asia, and South America were excavated and taken by North American and European institutions.\nFurther public engagement of paleontology has taken the form of fictional novels and films focused on paleontology and dinosaurs, beginning with stone-age Europeans in stories of the 1890s, but notably with the publication of \"The Lost World\" by Arthur Conan Doyle in 1912. Paleontology would be characterized by many tropes in the 1920s to 1940s, including film adaptation of the book as well as \"King Kong\" and \"Fantasia\". Popular representations of paleontology declined coinciding with the Cold War, but resurged in the 1970s with numerous popular works such as \"The Dinosaur Heresies\" by paleontologist Robert Bakker and papers by John Ostrom that reframed dinosaurs as active animals in a time termed the \"dinosaur renaissance\". The most significant establishment of paleontology in public was in the 1990s with the publications of the \"Jurassic Park\" novel by Michael Crichton and the subsequent Steven Spielberg film, where the story frames warmings about scientific development and genetic technology. The expansion of interest in paleontology has been met with the creation of new institutions globally to study and preserve fossils, but the focus since the \"Jurassic Park\" works has been on dinosaurs. New media have risen to paleontological blogging and podcasts and a greater online presence of those in the field. Conjectural forms of paleoart have arisen that engage with new science, and the boundaries between an artist, hobbyist, and professional have blurred. Paleontology has significant amounts of public outreach to drive its engagement and maintain its presence in the public sphere, and this public significance has in turn led to additional resources, recognition, and funding for the science."}
{"id": "23085", "revid": "49798966", "url": "https://en.wikipedia.org/wiki?curid=23085", "title": "Plotter", "text": "Computer output device that draws lines on paper by moving a pen\nA plotter is a machine that produces vector graphics drawings. Plotters draw lines on paper using a pen, or in some applications, use a knife to cut a material like vinyl or leather. In the latter case, they are sometimes known as a cutting plotter.\nIn the past, plotters were used in applications such as computer-aided design, as they were able to produce line drawings much faster and of a higher quality than contemporary conventional printers. Smaller desktop plotters were often used for business graphics. Printers with graphics capabilities took away some of the market by the early 1980s, and the introduction of laser printers in the mid-1980s largely eliminated the use of plotters from most roles.\nPlotters retained a niche for producing very large drawings for many years, but have now largely been replaced by wide-format conventional printers. Cutting plotters remain in use in a number of industries.\nOverview.\nDigitally controlled plotters evolved from earlier fully analog XY-writers used as output devices for measurement instruments and analog computers.\nPen plotters print by moving a pen or other instrument across the surface of a piece of paper. This means that plotters are vector graphics devices, rather than raster graphics as with other printers. Pen plotters can draw complex line art, including text, but do so slowly because of the mechanical movement of the pens. They are often incapable of efficiently creating a solid region of color, but can hatch an area by drawing a number of close, regular lines.\nPlotters offered the fastest way to efficiently produce very large drawings or color high-resolution vector-based artwork when computer memory was very expensive and processor power was very limited, and other types of printers had limited graphic output capabilities.\nPen plotters have essentially become obsolete, and have been replaced by large-format inkjet printers and LED toner-based printers. Such devices may still understand vector languages originally designed for plotter use, because in many uses, they offer a more efficient alternative to raster data.\nTypes.\nX\u2013Y plotter.\nAn X\u2013Y plotter is a plotter that operates in two axes of motion (\"X\" and \"Y\") in order to draw continuous vector graphics. The term was used to differentiate it from standard plotters which had control only of the \"y\" axis, the \"x\" axis being continuously fed to provide a plot of some variable with time. Plotters differ from inkjet and laser printers in that a plotter draws a continuous line, much like a pen on paper, while inkjet and laser printers use a very fine matrix of dots to form images, such that while a line may appear continuous to the naked eye, it in fact is a discrete set of points.\nX-Y plotters were categorized by two features: the format they could handle (from A4 up to A0, the largest papersheet available), and their architecture. The main architecture was flatbed plotters or table plotters. In this configuration the paper lays on a table and a carriage holds the pens. The whole carriage is moving on the X axis on the rail. This rail is moving on the Y axis along the structure of the table. The carriage was equipped of several type of pens depending on the manufacturers. Typically Rotring pens or Pentel pens were mostly used. Usually each carriage held several pens covering the various color needs; typically black, blue, red and green. The other system was roller plotters where the paper moved on the X axis on a large roller and the Y axis was covered by a carriage holding the pens; this carriage moved on a rail creating the Y axis. The main manufacturers of large-format (A0) plotters were Calcomp, a California-based company; and Benson, a French company especially present in Europe and the USSR. For the smaller formats Hewlett-Packard and Tectonics were the main suppliers.\nElectrostatic plotters.\nElectrostatic plotters used a dry toner transfer process similar to that in many photocopiers. They were faster than pen plotters and were available in large formats, suitable for reproducing engineering drawings. The quality of image was often not as good as contemporary pen plotters. Electrostatic plotters were made in both flat-bed and drum types. The electrostatic plotter uses the pixel as a drawing means, like a raster graphics display device. The plotter head consists of a large number of tiny styluses (as many as 21760) embedded in it. This head traverses over the width of the paper as it rolls past the head to make a drawing. The resolutions available may be 100 to 508 dots per inch. Electrostatic plotters are very fast with plotting speed of 6 to 32\u00a0mm/s, depending on the plotter resolution.\nCutting plotters.\nCutting plotters use knives to cut into a piece of material (such as paper, mylar film, or vinyl film) that is lying on the flat surface area of the plotter. The cutting plotter is connected to a computer, which is equipped with cutting design or drawing computer software programs. Those computer software programs are responsible for sending the necessary cutting dimensions or designs in order to command the cutting knife to produce the correct project cutting needs.\nIn recent years the use of cutting plotters (generally called die-cut machines) has become popular with home enthusiasts of paper crafts such as cardmaking and scrapbooking. Such tools allow desired card and decal shapes to be cut out very precisely, and repeatably.\nVinyl cutter.\nA vinyl cutter (sometimes known as a cutting plotter) is used to create posters, billboards, signs, T-shirt logos, and other weather-resistant graphical designs. The vinyl can also be applied to car bodies and windows for large, bright company advertising and to sailboat transoms. A similar process is used to cut tinted vinyl for automotive windows.\nColors are limited by the collection of vinyl on hand. To prevent creasing of the material, it is stored in rolls. Typical vinyl roll sizes are 15-inch, 24-inch, 36-inch and 48-inch widths, and have a backing material for maintaining the relative placement of all design elements.\nVinyl cutter hardware is similar to a traditional plotter except that the ink pen is replaced by a very sharp knife to outline each shape, and may have a pressure control to adjust how hard the knife presses down into the vinyl film, preventing the cuts from also penetrating the backing material. Besides losing relative placement of separate design elements, loose pieces cut out of the backing material may fall out and jam the plotter roll feed or the cutter head. After cutting, the vinyl material outside of the design is peeled away, leaving the design on the backing material which can be applied using self-adhesion, glue, lamination, or a heat press.\nThe vinyl knife is usually shaped like a plotter pen and is also mounted on a swivel head so that the knife edge self-rotates to face the correct direction as the plotter head moves.\nVinyl cutters are primarily used to produce single-color line art and lettering. Multiple color designs require cutting separate sheets of vinyl, then overlaying them during application; but this process quickly becomes cumbersome for more than a couple of hues.\nSign cutting plotters are in decline in applications such as general billboard design, where wide-format inkjet printers that use solvent-based inks are employed to print directly onto a variety of materials. Cutting plotters are still relied upon for precision contour-cutting of graphics produced by wide-format inkjet printers \u2013 for example to produce window or car graphics, or shaped stickers.\nLarge-format inkjet printers are increasingly used to print onto heat-shrink plastic sheeting, which is then applied to cover a vehicle surface and shrunk to fit using a heat gun, known as a vehicle wrap.\nStatic cutting table.\nA static cutting table is a type of cutting plotter used a large flat vacuum table. It is used for cutting non-rigid and porous material such as textiles, foam, or leather, that may be too difficult or impossible to cut with roll-fed plotters. Static cutters can also cut much thicker and heavier materials than a typical roll-fed or sheet-fed plotter is capable of handling.\nThe surface of the table has a series of small pinholes drilled in it. Material is placed on the table, and a coversheet of plastic or paper is overlaid onto the material to be cut. A vacuum pump is turned on, and air pressure pushes down on the coversheet to hold the material in place. The table then operates like a normal vector plotter, using various cutting tools to cut holes or slits into the fabric. The coversheet is also cut, which may lead to a slight loss of vacuum around the edges of the coversheet, but this loss is not significant.\nModern flatbed cutting table systems have evolved to integrate seamlessly with large-format digital printing workflows, incorporating vision systems, standardized cut file profiles, and sophisticated blade pressure control for both kiss cutting (slicing through top layers while preserving backing material) and through cutting with sub-millimeter precision.\nLanguages.\nA number of printer control languages were created to operate pen plotters, and transmit commands like \"lift pen from paper\", \"place pen on paper\", or \"draw a line from here to here\". Three common ASCII-based plotter control languages are Hewlett-Packard's HP-GL, its successor HP-GL/2, and Houston Instruments DMPL. Here is a simple HP-GL script drawing a line:\nThis program instructs the plotter, in order, to take the first pen (SP1 = Select Pen 1), to go to coordinates X=500, Y=500 on the paper sheet (PA = Plot Absolute), to lower the pen against the paper (PD = Pen Down), to move 1000 units in the Y direction (thus drawing a vertical line - PR = Plot Relative), to lift the pen (PU = Pen Up) and finally to put it back in its stall.\nProgrammers using FORTRAN or BASIC generally did not program these directly, but used software packages, such as the Calcomp library, or device independent graphics packages, such as Hewlett-Packard's AGL libraries or BASIC extensions or high end packages such as DISSPLA. These would establish scaling factors from world coordinates to device coordinates, and translate to the low level device commands. For example, to plot X*X in HP 9830 BASIC, the program would be\n10 SCALE -1,1,1,1\n20 FOR X = -1 to 1 STEP 0.1\n30 PLOT X, X*X\n40 NEXT X\n50 PEN\n60 END\nHistory.\nOne of the earliest plotter was Konrad Zuse's computer-controlled and transistorized Graphomat Z64 in 1958, also shown at the Hannover Messe in 1961.\nEarly pen plotters, e.g., the Calcomp 565 of 1959, worked by placing the paper over a roller that moved the paper back and forth for X motion, while the pen moved back and forth on a track for Y motion. The paper was supplied in roll form and had perforations along both edges that were engaged by sprockets on the rollers.\nAnother approach, e.g. Computervision's Interact I, involved attaching ball-point pens to drafting pantographs and driving the machines with stepper motors controlled by the computer. This had the disadvantage of being somewhat slow to move, as well as requiring floor space equal to the size of the paper, but could double as a digitizer. A later change was the addition of an electrically controlled clamp to hold the pens, which allowed them to be changed, and thus create multi-colored output.\nHewlett Packard and Tektronix produced small, desktop-sized flatbed plotters in the late 1960s and 1970s. The pens were mounted on a traveling bar, whereby the y-axis was represented by motion up and down the length of the bar and the x-axis was represented by motion of the bar back and forth across the plotting table. Due to the mass of the bar, these plotters operated relatively slowly.\nIn the 1980s, the small and lightweight HP 7470 introduced the \"grit wheel\" mechanism, eliminating the need for perforations along the edges, unlike the Calcomp plotters two decades earlier. The grit wheels at opposite edges of the sheet press against resilient polyurethane-coated rollers and form tiny indentations in the sheet. As the sheet is moved back and forth, the grit wheels keep the sheet in proper registration due to the grit particles falling into the earlier indentations, much like the teeth of two gears meshing. The pen is mounted on a carriage that moves back and forth in a line between the grit wheels, representing the orthogonal axis. These smaller \"home-use\" plotters became popular for desktop business graphics and in engineering laboratories, but their low speed meant they were not useful for general printing purposes, and different conventional printer would be required for those jobs. One category, introduced by Hewlett Packard's MultiPlot for the HP 2647, was the \"word chart\", which used the plotter to draw large letters on a transparency. This was the forerunner of the modern Powerpoint chart. With the widespread availability of high-resolution inkjet and laser printers, inexpensive memory and computers fast enough to rasterize color images, pen plotters have all but disappeared. However, the grit wheel mechanism is still found in inkjet-based, large format engineering plotters.\nPlotters were also used in the Create-A-Card kiosks that were available for a while in the greeting card area of supermarkets that used the HP 7475 six-pen plotter.\nPlotters are used primarily in technical drawing and CAD applications, where they have the advantage of working on very large paper sizes while maintaining high resolution. Another use has been found by replacing the pen with a cutter, and in this form plotters can be found in many garment and sign shops.\nChanging the color or width of a line required the plotter to change pens. This was either done manually on small plotters, but more typically the plotter would have a magazine of four or more pens which could be automatically mounted.\nA niche application of plotters is in creating tactile images for people with visual impairment on special thermal cell paper.\nUnlike other printer types, pen plotter speed is measured by pen speed and acceleration rate, instead of by page printing speed. A pen plotter's speed is primarily limited by the type of pen used, so the choice of pen is a key factor in pen plotter output speed. Indeed, most modern pen plotters have commands to control slewing speed, depending on the type of pen currently in use.\nThere are many types of plotter pen, some of which are no longer mass-produced. Technical pen tips are often used, many of which can be renewed using parts and supplies for manual drafting pens. Early HP flatbed and grit wheel plotters used small, proprietary fiber-tipped or plastic nib disposable pens.\nOne type of plotter pen uses a cellulose fiber rod inserted through a circular foam tube saturated with ink, with the end of the rod sharpened into a conical tip. As the pen moves across the paper surface, capillary wicking draws the ink from the foam, down the rod, and onto the paper. As the ink supply in the foam is depleted, the migration of ink to the tip begins to slow down, resulting in faint lines. Slowing the plotting speed will allow the lines drawn by a worn-out pen to remain dark, but the fading will continue until the foam is completely depleted. Also, as the fiber tip pen is used, the tip slowly wears away on the plotting medium, producing a progressively wider, smudged line.\nBall-point plotter pens with refillable clear plastic ink reservoirs are available. They do not have the fading or wear effects of fiber pens, but are generally more expensive and uncommon. Also, conventional ball-point pens can be modified to work in most pen plotters.\nContemporary uses of pen plotters.\nIn the mid-to-late 2000s artists and hackers began to rediscover pen plotters as quirky, customizable output devices. The quality of the lines produced by pens on paper is quite different from other digital output techniques. Even 30-year-old pen plotters typically still function reliably, and many were available for less than $100 on auction and resale websites. While support for driving pen plotters directly or saving files as HP-GL has disappeared from most commercial graphics applications, several contemporary software packages make working with HP-GL on modern operating systems possible.\nAs use of pen plotters has waned, the large-format printers that have largely replaced them have sometimes come to be called \"plotters\" as well.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23086", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=23086", "title": "Poker equipment", "text": ""}
{"id": "23090", "revid": "1047063212", "url": "https://en.wikipedia.org/wiki?curid=23090", "title": "Ante", "text": "Ante or Antes may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "23093", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=23093", "title": "Bug (poker)", "text": "Type of wild card in poker\nA bug in poker is a limited form of wild card. One or both jokers are often added to the deck and played as bugs.\nIn draw poker played for high and pai gow poker, the bug is considered to be an ace, unless it can be used as a missing card to complete a straight or a flush, in which case it becomes the highest card which can complete the hand.\nIn California lowball, the bug is the lowest unpaired card in a hand. For example, in 8-6-4-3 plus the bug, the bug becomes an ace; in A-2-3-5 plus the bug, the bug becomes a four.\nHolding the bug greatly increases the power of certain drawing hands. For example, playing for high, a natural four-straight such as Q-J-10-9 drawing one has nine outs to complete the hand, any king or eight or the bug. By contrast, a four-straight including the bug can have as many as sixteen outs to complete the straight - Q-J-10-Joker can catch any ace, king, nine, or eight.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23094", "revid": "1311098477", "url": "https://en.wikipedia.org/wiki?curid=23094", "title": "Wild card (cards)", "text": "Card which may stand in for a card of another value\nA wild card in card games is one that may be used to represent any other playing card, sometimes with certain restrictions. Jokers are often used as wild cards, but other cards may be designated as wild by the rules or by agreement. In addition to their use in card games played with a standard pack, wild cards may also exist in dedicated deck card games, such as the 'Master' card in Lexicon.\nUse.\nA wild card is one that may be used to represent any natural card, its holder usually designating its rank and suit. Jokers are frequently used as wild cards, for example in games of the Rummy family. Jokers, however, may also have other uses, such as being a permanent top trump in games like Euchre or 500, the odd one out in Old Maid, or high-value matching cards in Zwicker. \nIn many games, ordinary cards may be designated as wild, for example, the &lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;J\u2663 and &lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;9\u2666 in Classic Brag or the \"deuces wild\" in Poker. A card that is not wild may be referred to as a natural card. \nIn some cases, the wild card or cards must be agreed upon by players before the cards are dealt and play commences. However, in many games, such as Canasta, Perlaggen or Yellow Dwarf, the wild card or cards are a standard feature of the rules.\nIn some Austrian and South Tyrolean card games, one or more other cards may be used as wild cards, including the \"Weli\", a special 6 of Bells, the 7 of Bells and 7 of Acorns. In the game of Perlaggen there are six or seven wild cards: four permanent \"Perlaggs\" - K or \"Maxl\", 6 or \"Weli\", 7 or \"Little Weli\", the 7 of Bells or \"Bell-Spitz\" and 7 or \"Eichelspitz\" - as well as 3 \"Trump \"Perlaggs\"\" - the 7, Unter and Ober of Trumps.\nCasino practice.\nSometimes a distinction is made between being fully or partially wild. A card that is fully wild can be designated by its holder as any card they choose with no restrictions. Under this rule, for example, a hand with any natural pair and a wild card becomes three of a kind.\nA 'limited wild' card may be called a 'bug'. The common rule in casinos is that a wild card plays as a bug, which is given the rank of ace unless designating it as a different card would complete a straight, flush, or straight flush. Under this rule, a hand such as &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Ks\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Kh\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Jkr\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;5c\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;2h is just a pair of kings (with an ace kicker), but any four same-suit cards with a bug make a flush, and a hand such as &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;7h\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Jkr\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;5c\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;4h\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;3s makes a straight.\nThere is also a variation of the \"fully wild\" rule in which the wild card (in this instance they are usually jokers as there are traditionally only two and there is only one black and one red) can be any card of the suits matching the cards colour or current suit. For example, in a jokers wild game with these rules, the red joker could be used as any card of hearts or diamonds. Inversely, the black joker would be any card of clubs or spades.\nTwo exceptions to standard poker practice sometimes seen in home games are the double-ace flush rule, and the natural wins rule. The latter rule states that between hands that would otherwise tie, the hand with fewer wild cards wins. This is not common in casinos and should be treated as an exception to standard practice (as is the double-ace flush).\nExamples.\nThe following is a selection of cards and the games in which they are wild, based on Parlett:"}
{"id": "23095", "revid": "274716", "url": "https://en.wikipedia.org/wiki?curid=23095", "title": "Double-ace flush", "text": ""}
{"id": "23096", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=23096", "title": "Ace-to-six low", "text": ""}
{"id": "23097", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=23097", "title": "Deuce-to-seven low", "text": ""}
{"id": "23098", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=23098", "title": "Ace-to-five low", "text": ""}
{"id": "23101", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=23101", "title": "High-low split", "text": "In traditional poker games, the player with the best traditional hand wins the whole pot. Lowball variations award the pot to the lowest hand, by any of several methods (see Low hand (poker)). High-low split games are those in which the pot is divided between the player with the best traditional hand (called the high hand) and the player with the low hand.\nThere are two common methods for playing high-low split games, called declaration and cards speak. In a declaration game, each player declares (either verbally or using markers such as chips) whether he wishes to contest for the high hand or the low hand. The lowest hand among those who declared low wins that half of the pot, and the highest hand among those who declared high wins that half (for further details, see declaration). In a cards speak game, all players simply reveal their cards at showdown and the hands are evaluated by all players; high hand wins half of the pot and low hand wins the other half.\nEspecially when using the ace-to-five low method, it is possible for one player to have both the low hand and the high hand, and therefore win all of the pot (called \"scooping,\" \"hogging\" the pot, or \"going pig\"). In the event more than one player ties for either high or low, the pot can be further split into quarters or smaller fractions. For example, if one player has the high hand on showdown, and two other players tie for the best low hand, the high hand wins half of the pot and each low hand wins only a quarter of the pot.\nIt is common, especially in cards speak games, to require a certain hand value or better to win the low half of the pot, called a \"qualifier\". For example, in an \"eight or better to qualify low\" game, a player with a hand of eight-high or lower is entitled to win the low half of the pot (assuming his hand defeats all other low hands), but a player with a 10-high or 9-high hand cannot win, even if his hand is the lowest. In this case, the high hand wins the entire pot. There is generally no qualifier to win high, although one common variant is \"any pair/no pair\", where a hand of at least a pair is required to win high and any hand with no pair is required to win low.\nIn high-low split games where each player is dealt more than five cards, each player chooses five of his cards to play as his high hand, and/or five of his cards to play as his low hand. The sets may overlap: for example, in seven-card stud played high-low split, a player dealt 7-7-6-4-4-3-2 can play a high hand of 7-7-4-4-6 (two pair, sevens and fours) and a low hand of 7-6-4-3-2 (seven-high).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23102", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=23102", "title": "No pair", "text": ""}
{"id": "23104", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=23104", "title": "One pair", "text": ""}
{"id": "23106", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=23106", "title": "Kicker (poker)", "text": "Tie breaking card in poker\nA kicker, also called a side card, is a card in a poker hand that does not itself take part in determining the rank of the hand, but that may be used to break ties between hands of the same rank. For example, the hand Q-Q-10-5-2 is ranked as a pair of queens. The 10, 5, and 2 are kickers. This hand would defeat any hand with no pair, or with a lower-ranking pair, and lose to any higher-ranking hand. But the kickers can be used to break ties between other hands that also have a pair of queens. For example, Q-Q-K-3-2 would win (because its K kicker outranks the 10), but Q-Q-10-4-3 would lose (because its 4 is outranked by the 5).\nKickers in draw poker.\nThe term is also used in draw poker to denote an unmatched card (often an ace) retained by a player during the draw in the hope that either it will be paired on the draw, or else play as a kicker (in the first sense) on the showdown. A kicker may also be retained in order to deceive an opponent, for example, to represent a three-of-a-kind when the player has only a pair.\nKickers in Texas hold 'em.\nKickers take on special importance in Texas hold 'em, because a common winning hand is one card in a player's hand matched with a card on the board, while the player's second card acts as a kicker. For example, if one player holds A-8, a second player holds A-7, and the board is\nA-K-6-5-4, the player with the A-8 will outkick the player with the A-7, since A-8's best hand is A-A-K-8-6, while the A-7's hand is A-A-K-7-6.\nHowever, if the board held A-K-Q-J-3, the players would tie, because both would play the hand A-A-K-Q-J; in this case it is said that the players' kickers \"don't play\", or that the \"kicker on the board plays\". In this case, there would be a split pot."}
{"id": "23107", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=23107", "title": "Two pair", "text": ""}
{"id": "23111", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=23111", "title": "Straight (poker)", "text": ""}
{"id": "23113", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=23113", "title": "Wheel (poker)", "text": ""}
{"id": "23114", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=23114", "title": "Flush (poker)", "text": ""}
{"id": "23116", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=23116", "title": "Full house (poker)", "text": ""}
{"id": "23118", "revid": "20284245", "url": "https://en.wikipedia.org/wiki?curid=23118", "title": "Four of a kind", "text": "Four of a kind may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "23120", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=23120", "title": "Straight flush", "text": ""}
{"id": "23124", "revid": "38415975", "url": "https://en.wikipedia.org/wiki?curid=23124", "title": "Blind (poker)", "text": "Type of bet in poker\nBlinds are forced bets posted by players to the left of the dealer button in flop-style poker games. The number of blinds is usually two, but it can range from none to three. When there are two blinds they are called the small blind and the big blind.\nOverview.\nThe small blind is placed by the player to the left of the dealer button and the big blind is then posted by the next player to the left. The one exception is when there are only two players (a \"heads-up\" game), when the player on the button (the dealer) is the small blind, and the other player is the big blind. (Both the player and the bet may be referred to as big or small blind.)\nAfter the cards are dealt, the player to the left of the big blind is the first to act during the first betting round. If any players call the big blind, the big blind is then given an extra opportunity to raise. This is known as a \"live blind\". If the live blind checks, the betting round then ends. After the flop, turn and river, the first person to act is the player seated to the left of the dealer position. \nGenerally, the big blind is equal to the minimum bet. The small blind is normally half the big blind. In cases where posting exactly half the big blind is impractical due to the big blind being some odd-valued denomination, the small blind is rounded (usually down) to the nearest practical value. For example, if the big blind in a live table game is $3, then the small blind will usually be $1 or $2 since most casinos do not distribute large quantities of $0.50 poker chips.\nThe blinds exist because Omaha and Texas hold 'em are frequently played without antes, allowing a player to fold their hand without placing a bet. The blind bets introduce a regular cost to take part in the game, thus inducing a player to enter pots in an attempt to compensate for that expense. The blinds are bets that start the betting process, and differ from antes in that regard. \nIt is possible to play without blinds. The minimum bet is then the lowest denomination chip in play, and tossing only one chip is considered as a call. Anything higher than that is considered a raise. Poker without blinds is usually played with everyone posting an ante to receive cards.\nBlinds in cash games.\nIn cash games, otherwise known as ring games, blinds primarily serve to ensure all players are subject to some minimum, ongoing cost for participating in the game. This encourages players to play hands they otherwise might not, thereby increasing the average size of the pots and, by extension, increasing the amount of rake earned by the cardroom hosting the game.\nIn cash games, the amount of the blinds are normally fixed for each particular table and will not change for the duration of the game. However, many cardrooms will allow blind levels to change in cases where all players unanimously agree to a change. Larger cardrooms will often include tables with different blind levels to give players the option of playing at whatever stakes they are most comfortable with. In online poker, blinds range from as little as one U.S. cent to USD1,000 or more.\nThe minimum and maximum buy-in at a table is usually set in relation to the big blind. At live games, the minimum buy-in is usually between 50 and 80 big blinds, while the maximum buy-in is usually between 100 and 250 big blinds. Some online cardrooms offer \"short stack\" tables where the maximum buy-in is 50 big blinds or less and/or \"deep stack\" tables where the minimum buy-in is 100 big blinds or more.\nMissed blinds.\nIn cash games that do not deal cards to players who are absent from the table at the start of the hand (or, in online games, are designated as \"sitting out\"), special rules are necessary to deal with players who miss their blinds.\nPlayers who miss their big blind will not be dealt in again until the button has passed them. At that point, the player must \"super-post\" (post both the big and small blinds) in order to rejoin the game and be dealt cards. Of these, only the big blind is considered \"live\" while the small blind is \"dead\"\u2014it is placed in the center of the pot apart from the big blind and will not count towards calling any additional bets or raises by other players. If the player has only missed the small blind, then the same procedure applies except that the player only has to post the \"dead\" small blind to rejoin the game. Most cardrooms allow players to relieve themselves of these obligations if they wait until they are again due to post the big blind before rejoining the game.\nSome cardrooms hosting live cash games do not allow players to miss their blinds in this manner. Rather, all players with chips on the table are dealt in whether or not they are present at the table. Any blinds due will be posted from the player's stack - depending on the cardroom's rules, this will be done either by the dealer, another cardroom employee or a nearby player under staff supervision. Players who do not return to the table by the time it is their turn to act are automatically folded.\nBlinds in tournament play.\nIn poker tournament play, blinds serve a dual purpose. In addition to the purpose explained above, blinds are also used to control how long the tournament will last. Before the tournament begins, the players will agree to a blinds structure, usually set by the tournament organizer. This structure defines how long each round is and how much the blinds increase per round. Typically, they are increased at a smooth rate of between 25% and 50% per round over the previous round. As the blinds increase, players need to increase their chip counts (or \"stacks\") to stay in the game. The blinds will eventually consume all of a player's stack if they do not play to win more.\nUnlike many cash games, it is not possible for a player to \"miss\" blinds in a tournament. If a player is absent from the table, they will continue to have their cards dealt and mucked and will have blinds and, if applicable, antes taken from his stack as they are due, either until they return or until their stack is completely consumed by blinds and antes. A player who loses their chips in this manner is said to have been \"blinded off.\"\nGoals.\nThere are two main goals for the blinds structure:\nIf desired, antes can be added to further increase the pressure to win more chips.\nExample.\nIf each player in a tournament starts with 5,000 in chips and after four hours, the big blind is 10,000 (with a small blind of 5,000), a player with only 15,000 in chips would be able to stay in the game for at most one more rotation of the dealer button if they do not win any additional chips.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23125", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=23125", "title": "Bring-in (poker)", "text": ""}
{"id": "23126", "revid": "107782", "url": "https://en.wikipedia.org/wiki?curid=23126", "title": "Community card", "text": ""}
{"id": "23128", "revid": "47684007", "url": "https://en.wikipedia.org/wiki?curid=23128", "title": "Showdown (poker)", "text": "Situation near the end of a poker round\nIn poker, the showdown is the situation when, if more than one player remains after the final betting round, the remaining players expose and compare their hands to determine the winner or winners.\nTo win any part of a pot at showdown, a player must show all of their cards faceup on the table, whether those cards were used in the final hand played or not. Cards speak for themselves: the actual value of a player's hand prevails in the event a player mis-states the value of their hand. Because exposing a losing hand gives information to an opponent, players may be reluctant to expose their hands until after their opponents have done so and will muck their losing hands without exposing them. \"Robert's Rules of Poker\" state that the last player to take aggressive action by a bet or raise is the first to show the hand\u2014unless everyone checks (or is all-in) on the last round of betting, then the first player to the left of the dealer button is the first to show the hand.\nIf there is a side pot, players involved in the side pot should show their hands before anyone who is all-in for only the main pot. To speed up the game, a player holding a probable winner is encouraged to show the hand without delay. Any player who has been dealt in may request to see any hand that is eligible to participate in the showdown, even if the hand has been mucked. This option is generally only used when a player suspects collusion or some other sort of cheating by other players. When the privilege is abused by a player (i.e. the player does not suspect cheating, but asks to see the cards just to get insight on another player's style or betting patterns), they may be warned by the dealer, or even removed from the table.\nThere has been a recent trend in public cardroom rules to limit the ability of players to request to see mucked losing hands at the showdown. Specifically, some cardrooms only grant the right to view a mucked losing hand if the requesting player articulates a concern about possible collusion. Under such rules, players do not have an inherent right to view mucked hands.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23129", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=23129", "title": "Fold (poker)", "text": ""}
{"id": "23130", "revid": "5519934", "url": "https://en.wikipedia.org/wiki?curid=23130", "title": "Call (poker)", "text": ""}
{"id": "23131", "revid": "16752040", "url": "https://en.wikipedia.org/wiki?curid=23131", "title": "Raise (poker)", "text": ""}
{"id": "23133", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=23133", "title": "Poker/Bluff", "text": ""}
{"id": "23134", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=23134", "title": "Check-raise", "text": "Deceptive play in poker\nA check-raise in poker is a common deceptive play in which a player checks early in a betting round, hoping someone else will open. The player who checked then raises in the same round.\nThis might be done, for example, when the first player believes that an opponent has an inferior hand and will not call a direct bet, but that they may attempt to bluff, allowing the first player to win more money than they would by betting straightforwardly. The key point is that if no one else is keen to bet, then the most a player can raise by (in a limit game) is one single bet. If someone else bets first, they can raise, thus increasing the value of the pot by two bets. In a no-limit game, there is no restriction on the size of one's bet, and a raise is likely to be much larger than the second player's bet. Of course, if no other player chooses to open, the betting will be \"checked around\" and the play will have failed to elicit additional money for the pot. Like a simple check, a failed check-raise provides other players an opportunity to view the next card or cards dealt without requiring the other players to commit more money to the pot. A check-raise thus contains an element of risk because the check-raising player's advantage may deteriorate when new cards are revealed.\nWhile it can be an important part of one's poker strategy, this play is not allowed by a house rule in some home games and certain small-stakes casino games. It is also frequently not allowed in the game of California lowball. In older poker material and among stud and draw poker players, it is sometimes referred to as \"sandbagging\".\nCheck-raises can also be used as an intimidation technique over the course of a game; a player who has frequently been check-raised may be less likely to attempt to steal the pot.\nIn online poker games special tracking software can be used to determine the exact percentage of times a player check-raised when they had the opportunity. This information helps to determine if a player who check-raised has a monster hand or is bluffing as part of their routine poker play.\nNot all players agree that a check-raise is an especially effective play, however. In \"Super/System\", Doyle Brunson claims to check-raise very rarely in no-limit hold 'em; he contends that it is more profitable to simply bet a quality hand, regardless of whether his opponent will try to bluff. His reasoning for this is twofold: First, a failed check-raise gives other players the chance to see free cards that may improve their hand; second, it makes it obvious to other players that you potentially have a very strong hand. The latter, however, may be used as a strong bluff technique, although the opponent could put in a re-raise to scare off a bluff.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23135", "revid": "214427", "url": "https://en.wikipedia.org/wiki?curid=23135", "title": "Poker table stakes rules", "text": ""}
{"id": "23136", "revid": "214427", "url": "https://en.wikipedia.org/wiki?curid=23136", "title": "No limit (poker)", "text": ""}
{"id": "23137", "revid": "214427", "url": "https://en.wikipedia.org/wiki?curid=23137", "title": "Pot limit", "text": ""}
{"id": "23138", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=23138", "title": "Fixed limit (poker)", "text": ""}
{"id": "23139", "revid": "214427", "url": "https://en.wikipedia.org/wiki?curid=23139", "title": "Spread limit", "text": ""}
{"id": "23144", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=23144", "title": "Twist (poker)", "text": "Twist is poker jargon for a round with specific rules which is sometimes used in the poker variant stud poker.\nOne can replace any round of (or add a round to) a stud poker game with a twist round, in which each player is offered the option to replace exactly one card in his hand with a new one from the remaining deck stub.\nThis is similar to the draw phase of draw poker, differing in the following way: if the player chooses to replace a downcard, he discards it and is dealt a replacement card also face down; if he wishes to replace an upcard, he discards it and receives the replacement face up.\nOn a twist round, players make the decision of which card to replace in turn starting with the player who bet first on the preceding round (usually the player whose upcards make the best hand), discarding the card they choose to replace, if any.\nAfter everyone has made their decision, the replacement cards are dealt starting at the dealer's left as usual. If the game includes a \"low\" win, either alone or as split with \"high,\" this draw sequence clearly favors the dealer, because the dealer can wait to see whether his/her current hand beats showing hands as is or needs a replacement card. A variant to avoid this bias is to start the replacement round at the player showing the lowest hand.\nSometimes replacement cards are \"bought\" by requiring a player to add a fixed amount to the pot to be able to get a replacement.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23145", "revid": "1316030499", "url": "https://en.wikipedia.org/wiki?curid=23145", "title": "Stripped deck", "text": "Playing cards\nA stripped deck or short deck (US), short pack or shortened pack (UK), is a set of playing cards reduced in size from a full pack or deck by the removal of a certain card or cards. The removed cards are usually pip cards, but can also be court cards or Tarot cards. Many card games use stripped decks, and stripped decks for popular games are commercially available.\nHistory.\nWhen playing cards first arrived in Europe during the 1370s, they had the same format as the modern standard 52-card deck, consisting of four suits each with ten pip cards and three face cards. During the late 14th and 15th centuries, the Spanish and Portuguese decks dropped the 10s while the German and Swiss packs removed the Aces to create 48-card decks. It is far easier to print 48 cards using two woodblocks than 52 cards. While the removal of the above cards was motivated by manufacturing considerations, later expulsions are the result of trying to speed up card games to make them more exciting. Trappola is the first known card game to be played with a deck that was stripped for game play. It removed all the cards from 3 to 6, inclusive, to create a 36-card deck.\nThe most popular card game in 16th-century Europe was Piquet, played with a 36-card deck that dropped ranks from 5 to 2. Around 1700, it dropped the 6s as well to create the 32-card deck, which is now the most popular format in France. 32 and 36-card decks are the most widespread in countries that were once part of the Holy Roman (the Low Countries, Germany, and Switzerland), Austro-Hungarian, and Russian empires. 24 card decks to play Schnapsen are widely available in central Europe, although it may be shortened to 20 in the future, as that is how the modern variant is now commonly played.\nThe Spanish, Portuguese, Italians, and Latin Americans use mostly 40-card decks. Unlike the countries above, they drop the higher-ranking numerals so that the 7 is located immediately under the face cards. This was due to the popularity of Ombre, the game that introduced the concept of bidding.\nThe British and the Scandinavians are the most resistant to shortened packs, having maintained the 52-card format since receiving them in the 15th century. The British have also propagated that pack size through whist, the most popular card game of the 19th century. In the 20th century, this has been followed by contract bridge, gin rummy, canasta, and poker which all require that deck size. The British prefer games involving four players as opposed to the continental three-player games which use smaller packs.\nAsian countries also created stripped decks using their traditional playing cards. In contrast to the Western practice of removing \"ranks\", Asians remove \"suits\". During the Qing dynasty, the Chinese money-suited cards dropped one suit as rummy-type games became more popular. In India, the gambling game of Naqsha overtook the Ganjifa trick-taking game and many decks were made with only half of the traditional suits.\nThe opposite of a stripped deck is an expanded deck. Many commercial attempts have tried and failed to increase the standard deck above 52 cards. The most successful addition to the standard deck is the Joker which first appeared during the American Civil War as a Euchre trump card. The Joker has since been adopted as a wild card in a few other standard playing card games with different values and quantities depending on which game is being played. 500 is a Euchre offshoot invented by the United States Playing Card Company (USPCC) during the early 20th century. To play the six-handed version, USPCC created a deck with ranks 11, 12, and 13. 500 decks are now produced by other manufacturers and are sold primarily in English-speaking countries where the game is played. A much older expanded deck is tarot, invented in 15th-century Italy, with an extra suit of trumps and an extra rank. Tarot card games were the most popular card games of the 18th century but have since declined. They are still played in various continental European countries with France having the largest community. Tarot decks are not immune to stripping either. The Tarocco Bolognese, Tarocco Siciliano, Industrie und Gl\u00fcck, and Cego decks have excised some pip cards.\nPiquet deck.\nA French-suited deck of 32 cards, consisting of 7, 8, 9, 10, Jack, Queen, King and Ace in four suits each, is used in the two-player game Piquet, which dates back to the 16th century. \nGames played with a piquet deck (or the equivalent German- or Swiss-suited decks) are still among the most popular in some parts of Europe. This includes belote and klaverjas (the national games of France and the Netherlands, respectively) and skat (the German national game, which is also played with the equivalent German-suited decks in some regions). Bezique is played with two piquet decks.\nIn poker variants.\nStripped decks are used in certain poker variants. The earliest form of poker was played with only 20 cards. The Australian game of Manila uses a piquet deck, and Mexican stud is played with the 8s, 9s, and 10s removed from the deck (and a joker added). This may require adjusting hand values: in both of these games, a flush ranks above a full house, because having fewer cards of each suit available makes flushes rarer.\nA hand such as 6-7-J-Q-K plays as a straight in Mexican stud, skipping over the removed ranks. Some places may allow a hand such as 10-9-8-7-A to play as a straight (by analogy to a wheel) in the 32-card game, the A playing low and skipping over the removed ranks (although this is not the case in Manila). Finally, the relative frequency of straights versus three of a kind is also sensitive to the deck composition (and to the number of cards dealt), so some places may consider three of a kind to be superior to a straight, but the difference is small enough that this complication is not necessary for most games. Similarly, a full house tends to occur more often than a flush in a piquet deck, due to the increased frequency of each playing card rank, creating a change in poker combination ranking.\nFive-card stud is also often played with a piquet deck. In lively home games it might work better to only strip three ranks (2s through 4s) with seven or eight players; with only two or three players 7s and 8s could be stripped as well, leaving the same 24-card deck used in euchre. In any of these cases, a flush should rank above a full house (in a 24-card deck it is actually rarer than four of a kind, but is rarely played that flushes are superior to four of a kind). Stripped deck five-card stud is a game particularly susceptible to cheating by collusion, because it is easy for partners to signal a single hole card and the relative value of knowing the location of a single card is higher than with a full deck.\nOther games.\nThe game of euchre is also played with a 24-card stripped deck, consisting of only 9-10-J-Q-K-A of each suit, the 2-8 being stripped from the deck. The game of pinochle is played with 48 cards, consisting of a doubled euchre deck (that is, two copies of 9-A of each suit).\nIn some games, a small number of cards are stripped from the deck to make the deal exact. For example, it is customary to remove the &lt;templatestyles src=\"Template:Cards/styles.css\" /&gt;2\u2663 when three people play Hearts.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23146", "revid": "17862675", "url": "https://en.wikipedia.org/wiki?curid=23146", "title": "Roll-your-own cigarette", "text": "Cigarette assembled by the user as opposed to a manufacturer\nA roll-your-own (RYO) cigarette, also called a handrolled cigarette, roll-up or rollie, is a cigarette made from loose tobacco (usually a \"shag\" cut) and rolling paper. Factory-made cigarettes are called industrial or tailor-made cigarettes.\nRolling tobacco.\nRolling tobacco, or cigarette tobacco, is the primary tobacco used for RYO cigarettes. It is generally packaged in pouches. \nAfter 2009, the United States federal tax rate on RYO tobacco was raised from $1.0969 per pound to $24.78 per pound. This increase has caused many people to switch to using pipe tobacco to make cigarettes, since the pipe tobacco tax rate was also increased, but only to $2.83 per pound.\nIn Australia, loose tobacco was taxed less than manufactured cigarettes until September 2016.\nCigarette rolling.\nCigarette rolling may be done either by hand of with a cigarette roller. It should not be confused with cigarette stuffer.\nIn Russia a special kind of self-rolled cigarette was in use, called \"goat's leg\" (). A paper (commonly a newspaper paper) was rolled in a cone, which was bent in half in the middle and the wider part was filled with tobacco. In a way, it resembled a tobacco pipe.\nPrevalence.\nRelatively few smokers in the US, only 6.7%, actually roll their own cigarettes. In contrast, this rate was 17.1% in Canada, 24.2% in Australia, and 28.4% in the UK. Reasons for this difference include the generally lower price of traditional cigarettes in most states in the US compared to Canada and Europe.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23147", "revid": "1951353", "url": "https://en.wikipedia.org/wiki?curid=23147", "title": "Rollout (poker)", "text": "Game phase in certain poker variants\nRollout or roll 'em out is poker jargon used for a game phase in certain poker variants. It is often incorrectly called \"roll your own\", to which it has similarities but from which it is fundamentally different.\nPoker games with a rollout phase resemble stud poker but have significantly different strategies, because players generally receive all of their cards up front (sometimes with a draw phase), and know the final value of their hand in early betting rounds. They resemble stud poker only in that cards are revealed to other players one at a time for each betting round.\nThere are the same three variations on the idea as with roll your own, depending on when players are allowed to choose which card to reveal. They can either be forced to arrange the order of their cards before any betting begins (\"choose before\"), or they can also be allowed to choose cards in later rounds based on information found in earlier rounds (\"choose after\"). In the latter case, the revealing can be made simultaneously or in turn.\nIn the game of show five, for example, each player is dealt seven cards before any betting begins, and each of the game's five betting rounds begins with the players simultaneously revealing one of their cards (\"simultaneous choose-after rollout\"). Rollout games are frequently played high-low split, and players choose which cards to reveal in order to delay as long as possible revealing which half of the pot they intend to win."}
{"id": "23148", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=23148", "title": "Blind stud", "text": ""}
{"id": "23149", "revid": "49398645", "url": "https://en.wikipedia.org/wiki?curid=23149", "title": "One player to a hand", "text": "One player to a hand is an important poker rule, designed to promote fair play that is universally applied in casino play. It states that all game decisions about the play of each hand must be made by one player without any assistance. This means, for example, that a player may not ask for advice from any other players or observers during the play of the hand, nor should anyone offer such an advice. The phrase is often used as a warning to players making what might be perceived as minor violations, such as commenting upon other players' possible hands.\nNote that any player correcting an error on a declared holding once the hands are exposed, is not a violation of this rule since no further decisions can be made. Some rulebooks declare it an ethical obligation of a player to point out any error in the awarding of a pot or the reading of hands shown down.\nPurpose and scope.\nThe rule serves three main objectives:\nOnline poker.\nIn Internet rooms the rule is built into software (no visible hole cards) but still applies to voice chat and screen\u2011sharing. Operators treat proven violations as collusion and may confiscate funds or suspend accounts."}
{"id": "23150", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=23150", "title": "Cards speak", "text": "Cards speak (\"for themselves\"), also known as \"cards read\" is used in two poker contexts:\nFirst, it is used to describe a high-low split game without a declaration. That is, in a cards speak game, players all reveal their hands at the showdown, and whoever has the highest hand wins the high half of the pot and whoever has the lowest hand wins the low half.\nThe second is as a house rule in casino cardrooms. \"Cards speak\" means that any verbal declaration as to the content of a player\u2019s hand is not binding. If Mary says she has no pair, but in fact she has a flush, her cards speak and her hand is viewed for its genuine value, that of a flush. Likewise if John says he has a flush, but in fact he does not, his hand is judged on its actual merits, not his verbal declaration. At the discretion of management, a player deemed to be deliberately miscalling his hand may incur a penalty.\nThe \"cards speak\" rule does not address the awarding of a pot, player responsibilities, or the similar one player to a hand rule. It merely means that verbal statements do not make a hand value, but the cards do."}
{"id": "23151", "revid": "91689", "url": "https://en.wikipedia.org/wiki?curid=23151", "title": "Declaration (poker)", "text": "There are several actions in poker called declaration, in which a player formally expresses his intent to take some action (which he may perform at a later point). For example, one may verbally declare an action such as fold, call, raise (bet) while in turn, which obligates the player to complete that action.\nOne may declare a number of cards to draw in a draw poker game (which is typically not binding), or one may declare some other choice specific to the variant being played.\nBut most commonly, the term refers to the declaration in the final phase of a high-low split game, in which players indicate whether their hands are to be evaluated as high hands, low hands, or both at showdown. This is only one option for high-low split games; the other is known as \"cards speak\", in which players simply reveal their hands at showdown and award the pot to the highest and lowest hands shown (possibly subject to qualifications). Cards speak is used commonly in casinos because it is the much simpler method. High-low with declaration is common in home games.\nMethods of declaration.\nFirst, declarations can be made either in turn or simultaneously.\nGames with verbal in-turn declarations (called \"last raise declares\") are uncommon, because the positional value of declaring last is so great. Some think that makes the game unfair. Others see it merely as strategy, making the game more interesting, because players may alter their betting in the last rounds to get the position of declaring last or after a certain player. Also, if all the other remaining players declare one way, the last player to declare can then call the other way and take half the pot regardless of the actual rank of his hand.\nSimultaneous declarations are commonly done by the \"chips in hand\" method. Each player remaining in the game takes two chips or coins below the table, then brings up a closed hand containing zero, one, or two of the chips.\nAfter all players have brought their closed hands above the table, they all then open their hands to reveal their choices: for example, no chips in the hand means the player is declaring \"low\", one chip \"high\", and two chips \"swing\" (both ways).\nSome games then have another round of betting after the declaration, called \"bet/declare/bet\", which clearly gives an advantage if there is just one person going a certain way.\nAwarding the pot.\nAfter declaration and showdown, half of the pot is awarded to the highest hand among those players who declared high, and half to the lowest hand among those who declared low. If no one declared in one direction, the whole pot is awarded to the other (for example, if all players declared low, the lowest hand is awarded the whole pot).\nIf any player declared \"swing\", then that player must have both the high and low hands to take any part of the pot, though there are several rule variations covering the specifics. First, if the rules specify that ties are acceptable, then a player declaring swing must win or tie both directions to win anything, but if he does, he is entitled to his appropriate share. For example, if the swing player has the clearly highest hand but shares the lowest hand with another player, he wins three-fourths of the pot and the other low hand wins one-fourth. If the rules specify that ties are not acceptable, then a swing player must clearly win both directions: even a tie in one direction means he wins nothing.\nIf a swing player fails for half the pot, the half that he would have otherwise won can be awarded either to the second-best hand in that direction, or to the player who defeated him in the other. The latter rule affords more strategic possibilities in declaration. For example, if a player declaring swing has the best high hand but loses for low (or ties for low with a no-ties rule), the whole pot is awarded to the low hand that defeated him.\nA rule must be adopted for the case where no player is eligible to win the pot (for example, if all players declare swing, and no player winds both ways). Some possible rules include playing the hand as a no-declare hand, or having the pot ride over to the next hand.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23157", "revid": "23939382", "url": "https://en.wikipedia.org/wiki?curid=23157", "title": "Value (poker)", "text": "Poker terminology\nIn poker, the strength of a hand (how likely it is to be the best according to the rules of the game being played) is often called its value; however, in the context of poker strategy the term is more often used to describe a betting tactic, a value bet. This bet (or raise) is intended to increase the size of the pot, by inducing opponents to call. A value bet is in contrast to a \"bluff\" or a \"protection bet\" (though some bets may have a combination of these motives).\nFor a value bet to be correct, a player must have a positive expectation, that is, they will win more than one bet for every bet they put in the pot. Pot odds do not matter in this situation, because the factor here is whether it is more profitable to \"raise\" or \"call\", rather than to \"call\" or \"fold\". Betting for value can apply to both made hand and drawing hand situations, although in the latter situation it is less often correct, as the drawing hand's chances of winning are generally lower. Many made hands will win the pot more than 50% of the time, therefore a value bet is usually correct, even heads up.\nFor example, in a game of Texas hold 'em, a player with &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;8c\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;6s and a flop of &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;9h\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;7d\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;2c has an open-ended straight draw and so has eight outs (four 10s and four 5s). With 47 unknown cards, the player will make the straight approximately one time for every five times they don't, so betting is profitable if six or more of their opponents will call the bet (they will win once (+6 bets) and lose five times (-5 bets) out of every six hands like this, resulting in an expectation of +1 bet). If they think that fewer than six opponents will call the bet, they would be losing money by betting and should simply check instead."}
{"id": "23158", "revid": "1728614", "url": "https://en.wikipedia.org/wiki?curid=23158", "title": "Nut hand", "text": "Poker hand\nIn poker, the nut hand (or the nuts) is the strongest possible hand in a given situation. The second-nut hand or third-nut hand (and so on) may refer to the second and third best possible hands. The term applies mostly to community card poker games where the individual holding the strongest possible hand, with the given board of community cards, is capable of knowing that they have the nut hand.\nUsage in context.\nIn Texas hold 'em, if the board is 5\u2660 6\u2660 A\u2663 9\u2660 5\u2665, a player holding 7\u2660 8\u2660 has the nut hand because those hole cards complete a 9-high straight flush of spades, which cannot be beaten by any other possible combination of hole cards and community cards. On the same board, the hand 5\u2663 5\u2666 would be the second-nut hand, four of a kind fives; the third-nut hand would be any pair of the remaining three aces, making a full house, aces full of fives.\nIt is important to note that the \"actual\" nut hand may not be the same as the \"absolute\" nut hand; for example, if the board is 7\u2665 2\u2663 K\u2660 K\u2665 3\u2666 a player with K\u2663 K\u2666 has the absolute nut hand. However, any player with K-7 knows that he has the nut hand as it is impossible for another player to have two kings. The phrase may also refer to a hand in progress with cards yet to be dealt, as the player can be said to have the nuts at that time. For example, if a player holds 7\u2660 8\u2660 on a board of 5\u2663 6\u2660 9\u2665 he can be said to have the nuts, however if the next card comes 7\u2665 then 8-10 becomes the nuts. This makes some nut hands very vulnerable in nine-card games, such as Omaha hold 'em.\nIn high-low split games one often speaks of \"nut-low\" and \"nut-high\" hands separately. In Omaha hold 'em, if the board is 5\u2660 6\u2660 A\u2663 9\u2660 5\u2665, any player with 2-3 makes the nut-low hand, 6-5-3-2-A, while a player with 2-4 makes the second-nut-low hand, 6-5-4-2-A (the nut-high hands remain the same as in Texas hold 'em, in this case 7\u2660 8\u2660 to make a straight flush, although one can go as low as aces full by introducing quads and straight flush blockers). Similarly, one can sometimes hear the term \"nut-nut\", which refers to a hand that makes both the best possible high and low. In Omaha, with the same board as above, a player holding 7\u2660 8\u2660 plus 2-3 of any suit has the nut-nut and is guaranteed no worse than a split of the low pot plus a win of the high pot.\nOrigins.\nA common and certainly apocryphal folk etymology is that the term originated from the historical poker games in the colonial west of America, where if a player bet everything he possessed, he would place the nuts of his wagon wheels on the table to ensure that, should he lose, he would be unable to flee and would have to make good on the bet. Since it would be expected that a player would only make such a bet when he had the best possible hand, the folk lore says that this is how the best possible hand came to be known as the nuts. It is also rumored that these historical games were played only in the winter, and therefore, the nuts that were placed on the table were \"stone cold\", hence coining the term \"stone-cold-nuts\".\nAnother explanation is that \"the nuts\" originated from the old English usage of \"nuts\", meaning \"any source of pleasure\".\nAnother seemingly fitting explanation is that the term was derived from the UK English slang \"the dog's bollocks\" or \"the mutt's nuts\", meaning \"the absolute best\". However, this phrase originated around 1949, and the term \"the nuts\" pre-dates it."}
{"id": "23159", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=23159", "title": "Protection (poker)", "text": "Type of poker bet\n \nProtection in poker is a bet made with a strong but vulnerable hand, such as top pair when straight or flush draws are possible. The bet forces opponents with draws to either call with insufficient pot odds, or to fold, both of which are profitable for the betting player. By contrast, if he failed to protect his hand, another player could draw out on him at no cost, meaning he gets no value from his made hand.\nA protection play differs from a bluff in that the bluff can win \"only\" when the opponent folds, while protection bet is made with a hand that is likely to win a showdown, but isn't strong enough for slow playing.\nThe importance of protection increases when there are multiple opponents. For example, if a hand is currently the best, but each of four opponents has a 1-in-6 chance of drawing an out, the four opponents \"combined\" become the favorite to win, even though each one is individually an underdog. With a protection bet, some or all of them may fold, leaving fewer opponents and a better chance of winning.\nThe term \"protection\" is also often heard in the context of an \"all-in\" player (see poker table stakes rules). A bet by an opponent serves to protect the all-in player by reducing the number of opponents the all-in player must beat. To deliberately make such a bet solely to protect another player's hand constitutes collusion.\nA player may also be said to \"protect\" his or her cards by placing an object like a specialty chip or miniature figure upon them. This prevents the player from having his cards accidentally collected by the dealer or being fouled by other players' discards.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23160", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=23160", "title": "Draw (poker)", "text": "Poker hand\nA poker player is drawing if they have a hand that is incomplete and needs further cards to become valuable. The hand itself is called a draw or drawing hand. For example, in seven-card stud, if four of a player's first five cards are all spades, but the hand is otherwise weak, they are \"drawing to\" a flush. In contrast, a made hand already has value and does not necessarily need to draw to win. A made starting hand with no help can lose to an inferior starting hand with a favorable draw. If an opponent has a made hand that will beat the player's draw, then the player is \"drawing dead\"; even if they make their desired hand, they will lose. Not only draws benefit from additional cards; many made hands can be improved by catching an out \u2013 and may have to in order to win.\nOuts.\nAn unseen card that would improve a drawing hand to a likely winner is an out. Playing a drawing hand has a positive expectation if the probability of catching an out is greater than the pot odds offered by the pot.\nThe probability formula_1 of catching an out with one card to come is:\nformula_2\nThe probability formula_3 of catching at least one out with two cards to come is:\nformula_4\nformula_5\nA dead out is a card that would normally be considered an out for a particular drawing hand, but should be excluded when calculating the probability of catching an out. Outs can be dead for two reasons:\nTypes of draws.\nFlush draw.\nA flush draw, or four flush, is a hand with four cards of the same suit that may improve to a flush. For example, K\u2663 9\u2663 8\u2663 5\u2663 x. A flush draw has nine outs (thirteen cards of the suit less the four already in the hand). If a player has a flush draw in Hold'em, the probability to flush the hand in the end is 34.97 percent if there are two more cards to come, and 19.56 percent (9 live cards divided by 46 unseen cards) if there is only one more card to come.\nOutside straight draw.\nAn outside straight draw, also called up and down, double-ended straight draw or open-ended straight draw, is a hand with four of the five needed cards in sequence (and could be completed on either end) that may improve to a straight. For example, x-9-8-7-6-x. An outside straight draw has eight outs (four cards to complete the top of the straight and four cards to complete the bottom of the straight). Straight draws including an ace are not outside straight draws, because the straight can only be completed on one end (has four outs).\nInside straight draw.\nAn inside straight draw, or gutshot draw or belly buster draw, is a hand with four of the five cards needed for a straight, but missing one in the middle. For example, 9-x-7-6-5. An inside straight draw has four outs (four cards to fill the missing internal rank). Because straight draws including an ace only have four outs, they are also considered inside straight draws. For example, A-K-Q-J-x or A-2-3-4-x. The probability of catching an out for an inside straight draw is half that of catching an out for an outside straight draw.\nDouble inside straight draw.\nA double inside straight draw, or double gutshot draw or double belly buster draw can occur when either of two ranks will make a straight, but both are \"inside\" draws. For example, in 11-card games, 9-x-7-6-5-x-3, or 9-8-x-6-5-x-3-2, or in Texas Hold'em when holding 9-J hole cards on a 7-10-K flop. The probability of catching an out for a double inside straight draw is the same as for an outside straight draw.\nOther draws.\nSometimes a made hand needs to draw to a better hand. For example, if a player has two pair or three of a kind, but an opponent has a straight or flush, to win the player must draw an out to improve to a full house (or four of a kind). There are a multitude of potential situations where one hand needs to improve to beat another, but the expected value of most drawing plays can be calculated by counting outs, computing the probability of winning, and comparing the probability of winning to the pot odds.\nBackdoor draw.\nA backdoor draw, or runner-runner draw, is a drawing hand that needs to catch two outs to win. For example, a hand with three cards of the same suit has a \"backdoor flush draw\" because it needs two more cards of the suit. The probability formula_6 of catching two outs with two cards to come is:\nformula_7\nFor example, if after the flop in Texas hold 'em, a player has a backdoor flush draw (e.g., three spades), the probability of catching two outs on the turn and river is (10 \u00f7 47) \u00d7 (9 \u00f7 46) = 4.16 percent. Completing backdoor draws is generally unlikely; the probability of seeing two out of seven outs on the turn and river is roughly the same as completing a draw with only out on either the turn or the river (1/47 + 1/46 = 4.3%). A backdoor outside straight draw (such as J-10-9) is equally likely as a backdoor flush, but any other 3-card straight draw (such as J-8-7) is less likely than getting a specific card after the flop, calculated above.\nDrawing dead.\nA player is said to be \"drawing dead\" when the hand he hopes to complete will nonetheless lose to a player who already has a better one. For example, drawing to a straight or flush when the opponent already has a full house. In games with community cards, the term can also refer to a situation where no possible additional community card draws results in a win for a player. (This may be because another player has folded the cards that would complete his hand, his opponent's hand is already stronger than any hand he can possibly draw to or that the card that completes his hand also augments his opponent's.)\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23161", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=23161", "title": "Made hand", "text": ""}
{"id": "23162", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=23162", "title": "Out (poker)", "text": "Poker card\nIn a poker game with more than one betting round, an out is any unseen card that, if drawn, will improve a player's hand to one that is likely to win. Knowing the number of outs a player has is an important part of poker strategy. For example, in draw poker, a hand with four diamonds has nine outs to make a flush: there are 13 diamonds in the deck, and four of them have been seen. If a player has two small pairs, and he believes that it will be necessary for him to make a full house to win, then he has four outs: the two remaining cards of each rank that he holds.\nOne's number of outs is often used to describe a drawing hand: \"I had a two-outer\" meaning you had a hand that only two cards in the deck could improve to a winner, for example. In draw poker, one also hears the terms \"12-way\" or \"16-way\" straight draw for hands such as 6\u2665 7\u2665 8\u2660 (Joker), in which any of sixteen cards (4 fours, 4 fives, 4 nines, 4 tens) can fill a straight.\nThe number of outs can be converted to the probability of making the hand on the next card by dividing the number of outs by the number of unseen cards. For example, say a Texas Holdem player holds two spades, and two more appear in the flop. He has seen five cards (regardless of the number of players, as there are no upcards in Holdem except the board), of which four are spades. He thus has 9 outs for a flush out of 47 cards yet to be drawn, giving him a 9/47 chance to fill his flush on the turn. If he fails on the turn, he then has a 9/46 chance to fill on the river. Calculating the combined odds of filling on \"either\" the turn or river is more complicated: it is (1 - ((38/47) * (37/46))), or about 35%. A common approximation used is to double the number of outs and add one for the percentage to hit on the next card, or to multiply outs by four for the either-of-two case. This approximation works out to within a 1% error margin for up to 14 outs.\nNote that the hidden cards of a player's opponents may affect the calculation of outs. For example, assume that a Texas hold 'em board looks like this after the third round: 5\u2660 K\u2666 7\u2666 J\u2660, and that a player is holding A\u2666 10\u2666. The player's current hand is just a high ace, which is not likely to win unimproved, so the player has a drawing hand. He has a minimum of nine outs for certain, called \"nut outs\", because they will make his hand the best possible: those are the 2\u2666, 3\u2666, 4\u2666, 6\u2666, 8\u2666, 9\u2666, and Q\u2666 (which will give him an ace-high flush with no possible better hand on the board) and the Q\u2663 and Q\u2665, which will give him an ace-high straight with no higher hand possible. The 5\u2666 and J\u2666 will also make him an ace-high flush, so those are \"possible outs\" since they give him a hand that is likely to win, but they also make it possible for an opponent to have a full house (if the opponent has something like K\u2660 K\u2663, for example). Likewise, the Q\u2660 will fill his ace-high straight, but will also make it possible for an opponent to have a spade flush. It is possible that an opponent could have as little as something like 7\u2663 9\u2663 (making a pair of sevens); in this case even catching any of the three remaining aces or tens will give the player a pair to beat the opponent's, so those are even more \"potential outs\". In sum, the player has 9 guaranteed outs, and possibly as many as 18, depending on what cards he expects his opponents to have.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23163", "revid": "1300552528", "url": "https://en.wikipedia.org/wiki?curid=23163", "title": "Pot odds", "text": "Poker term\nIn poker, pot odds are the ratio of the current size of the pot to the cost of a contemplated call. Pot odds are compared to the odds of winning a hand with a future card in order to estimate the call's expected value. The purpose of this is to statistically guide a player's decision between the options of call or fold. Raising is an alternative to place this decision on the opponent.\nCalculating equity.\nPot odds are only useful if a player has enough equity. Equity is the chance a player has to win the hand at showdown. It is calculated as the fraction of remaining cards in the deck for each remaining street (sequential card being dealt, e.g. turn, river) that can give a player the winning hand. For example, in Texas hold'em, if a player has an inside straight draw on the flop, there are four remaining cards in the deck, or outs, that can give them a straight on the turn or the river. The addition law of probability combines the chances of making the straight on the turn (4/47 = 8.5%) and on the river (4/46 = 8.7%) to give the player an equity of 17.2%, assuming no other cards will give them a winning hand. Calculating equity makes an assumption of the opponents hand. If the opponent holds blockers (outs that the player needs to make their hand), then the player's equity is lower than what is calculated from assuming all outs remain in the deck. While this may be a lot for a player to consider in the moment, calculating equity can be simplified with the rule of two and four.\nRule of two and four.\nWhen playing against a clock, calculating odds and percentages under pressure can be challenging. To facilitate this, the rule of two and four can be used. It is an estimate of equity. The player's number of outs are multiplied with double the amount of remaining streets. Using the example from before, the player had 4 outs with two streets to come. 4 outs multiplied by 4 (double the amount of remaining streets) gives an estimated equity of 16%. Compared to the actual equity of 17.2%, this estimation is close enough for games such as Texas hold'em where bet sizes are usually kept to less than or equal to 100% of the pot, where the relative pot odds have a large enough margin of error for the player to meet with their calculated equity.\nConverting odds ratios to and from percentages.\nOdds are most commonly expressed as ratios, but they are not useful when comparing to equity percentages for poker. The ratio has two numbers: the size of the pot and the cost of the call. To convert this ratio to the equivalent percentage, the cost of the call is divided by the sum of these two numbers. For example, the pot is $30, and the cost of the call is $10. The pot odds in this situation are 30:10, or 3:1 when simplified. To get the percentage, 1 is divided by the sum of 3 and 1, giving 0.25, or 25% or 1/(3+1).\nTo convert any percentage or fraction to the equivalent odds, the numerator is subtracted from the denominator. The difference is compared to the numerator as a ratio. For example, to convert 25%, or 1/4, 1 is subtracted from 4 to get 3. The resulting ratio is 3:1.\nUsing pot odds to determine expected value.\nWhen a player holds a drawing hand (a hand that is behind now but is likely to win if a certain card is drawn) pot odds are used to determine the expected value of that hand when the player is faced with a bet.\nThe expected value of a call is determined by comparing the pot odds to the odds of drawing a hand that wins at showdown. If the odds of drawing a desired hand are better than the pot odds (e.g. 3:1 drawing odds against 4:1 pot odds), the call has a positive expected value. The law of large numbers predicts the player will profit in the long run if they continue to call with advantageous pot odds. The opposite is true if the player continues to call with disadvantageous pot odds. \nExample (Texas hold'em).\nAlice holds 5-4 of clubs. The board on the turn is Queen of clubs, Jack of clubs, 9 of diamonds, and 7 of hearts. Her hand will almost certainly not win at showdown unless one of the 9 remaining clubs comes on the river to give her a flush. Excluding her two hole cards and the four community cards, there are 46 remaining cards to draw from. This gives a probability of 9/46 (19.6%). The rule of 2 and 4 estimates Alice's equity at 18%. The approximate equivalent odds of hitting her flush are 4:1. Her opponent bets $10, so that the total pot now becomes, say, $50. This gives Alice pot odds of 5:1. The odds of her hitting her flush are better than her pot odds, so she should call.\nValidity of strategy.\nIt is important to note that using pot odds makes assumptions of your opponent's hand. When calculating the odds of Alice drawing her flush, it was assumed that her opponent did not hold any of the remaining clubs. It was also assumed that her opponent did not have two-pair or a set. In these cases, her opponent could have been drawing on a higher flush, a full house, or four of a kind, all of which would win even if Alice made her flush. This is where considering the range of an opponent's hands becomes important. If, for example, Alice's opponent raised multiple times preflop, it would be more likely that they have a stronger drawing hand, such as Ace-King of clubs, by the time the turn came. \nPot odds are just one aspect of a sound strategy for poker based on game theory. The purpose of using game theory in poker is to make a player indifferent to how their opponent plays. It should not matter if the opponent is passive or aggressive, tight or loose. Pot odds can help the player make more mathematically based decisions, as opposed to playing exploitatively where the player guesses their opponent's decisions based on certain behaviors.\nImplied pot odds.\nImplied pot odds, or simply implied odds, are calculated the same way as pot odds, but take into consideration estimated future betting. Implied odds are calculated in situations where the player expects to fold in the following round if the draw is missed, thereby losing no additional bets, but expects to gain additional bets when the draw is made. Since the player expects to always gain additional bets in later rounds when the draw is made, and never lose any additional bets when the draw is missed, the extra bets that the player expects to gain, excluding their own, can fairly be added to the current size of the pot. This adjusted pot value is known as the implied pot.\nExample (Texas hold'em).\nOn the turn, Alice's hand is certainly behind, and she faces a $1 call to win a $10 pot against a single opponent. There are four cards remaining in the deck that make her hand a certain winner. Her probability of drawing one of those cards is therefore 4/47 (8.5%), which when converted to odds is 10.75:1. Since the pot lays 10:1 (9.1%), Alice will on average lose money by calling if there is no future betting. However, Alice expects her opponent to call her additional $1 bet on the final betting round if she makes her draw. Alice will fold if she misses her draw and thus lose no additional bets. Alice's implied pot is therefore $11 ($10 plus the expected $1 call to her additional $1 bet), so her implied pot odds are 11:1 (8.3%). Her call now has a positive expectation.\nReverse implied pot odds.\nReverse implied pot odds, or simply reverse implied odds, apply to situations where a player will win the minimum if holding the best hand but lose the maximum if not having the best hand. Aggressive actions (bets and raises) are subject to reverse implied odds, because they win the minimum if they win immediately (the current pot), but may lose the maximum if called (the current pot plus the called bet or raise). These situations may also occur when a player has a made hand with little chance of improving what is believed to be currently the best hand, but an opponent continues to bet. An opponent with a weak hand will be likely to give up after the player calls and not call any bets the player makes. An opponent with a superior hand, will, on the other hand, continue, (extracting additional bets or calls from the player).\nLimit Texas hold'em example.\nWith one card to come, Alice holds a made hand with little chance of improving and faces a $10 call to win a $30 pot. If her opponent has a weak hand or is bluffing, Alice expects no further bets or calls from her opponent. If her opponent has a superior hand, Alice expects the opponent to bet another $10 on the end. Therefore, if Alice wins, she only expects to win the $30 currently in the pot, but if she loses, she expects to lose $20 ($10 call on the turn plus $10 call on the river). Because she is risking $20 to win $30, Alice's reverse implied pot odds are 1.5-to-1 ($30/$20) or 40 percent (1/(1.5+1)). For calling to have a positive expectation, Alice must believe the probability of her opponent having a weak hand is over 40 percent.\nManipulating pot odds.\nOften a player will bet to manipulate the pot odds offered to other players. A common example of manipulating pot odds is to make a bet to protect a made hand that discourages opponents from chasing a drawing hand.\nNo-limit Texas hold 'em example.\nWith one card to come, Bob has a made hand, but the board shows a potential flush draw. According to the Fundamental theorem of poker, \nBob wants to bet enough for an opponent with a flush draw to incorrectly call, but Bob does not want to bet more than he has to in the event the opponent already has him beat. \nAssuming a $20 pot and one opponent, if Bob bets $10 (half the pot), when his opponent acts, the pot will be $30 and it will cost $10 to call. The opponent's pot odds will be 3-to-1, or 25 percent. If the opponent is on a flush draw (9/46, approximately 19.565 percent or 4.11-to-1 odds against with one card to come), the pot is not offering adequate pot odds for the opponent to call unless the opponent thinks they can induce additional final round betting from Bob if the opponent completes their flush draw (see implied pot odds).\nA bet of $6.43, resulting in pot odds of 4.11-to-1, would make his opponent mathematically indifferent to calling if implied odds are disregarded.\nBluffing frequency.\nAccording to David Sklansky, game theory shows that a player should bluff a percentage of the time equal to his opponent's pot odds to call the bluff. For example, in the final betting round, if the pot is $30 and a player is contemplating a $30 bet (which will give his opponent 2-to-1 pot odds for the call), the player should bluff half as often as he would bet for value (one out of three times). \nSlanksy notes that this conclusion does not take into account some of the context of specific situations. A player's bluffing frequency often accounts for many different factors, particularly the tightness or looseness of their opponents. Bluffing against a tight player is more likely to induce a fold than bluffing against a loose player, who is more likely to call the bluff. His strategy is an equilibrium strategy in the sense that it is optimal against someone playing an optimal strategy against it, though no lesser strategy can beat it (another strategy may beat the lesser strategy by more).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23165", "revid": "48924397", "url": "https://en.wikipedia.org/wiki?curid=23165", "title": "Position (poker)", "text": "Order in which poker players are seated\nPosition in poker is the order in which players are seated around the table and the related poker strategy implications. Players who act first are in \"early position\"; players who act later are in \"late position\"; players who act in between are in \"middle position\". A player \"has position\" on opponents acting before them and is \"out of position\" to opponents acting after them. Because players act in clockwise order, a player \"has position\" on opponents seated to his right, except when the opponent has the button and certain cases in the first betting round of games with blinds.\nPosition in Texas hold 'em.\nThe primary advantage held by a player in late position is that they will have more information with which to make better decisions than players in early position, who will have to act first, without the benefit of this extra information. This advantage has led to many players in heads-up play raising on the button with an extremely wide range of hands because of this positional advantage. Also, as earlier opponents fold, the probability of a hand being the best goes up as the number of opponents goes down. \nThe blinds are the least desirable position because a player is forced to contribute to the pot and they must act first on all betting rounds after the flop. Although the big blind has a big advantage on the first round of betting, it is on average the biggest money long term losing position.\nTexas hold 'em example.\nThere are 10 players playing $4/$8 fixed limit. Alice pays the $2 small blind. Bob pays the $4 big blind. Carol is under the gun (first to act). If Carol has a hand like K\u2665 J\u2660, she may choose to fold. With nine opponents remaining to act, there is approximately a 40% chance that at least one of them will have a better hand than Carol's like A-A, K-K, Q-Q, J-J, A-K, A-Q, A-J or K-Q. Even if no one does, seven of them (all but the two players in the blind) will have position on Carol in the next three betting rounds.\nNow instead, suppose David in the cut-off position (to the right of the button) has the same K\u2665 J\u2660 and all players fold to him. In this situation, there are only three opponents left to act, so the odds that one of them has a better hand are considerably less (only around 16%). Secondly, two of those three (Alice and Bob) will be out of position to David on later betting rounds. A common play would be for David to raise and hope that the button (the only player who has position on David) folds. David's raise might simply steal the blinds if they do not have playable hands, but if they do play, David will be in good shape to take advantage of his position in later betting rounds."}
{"id": "23166", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=23166", "title": "Steal (poker)", "text": "In poker, a steal is a type of a bluff, a raise during the first betting round made with an inferior hand and meant to make other players fold superior hands because of shown strength. A steal is normally either an \"ante steal\" or \"blind steal\" (depending on whether the game being played uses antes or blinds).\nSteals are done with hands less valuable than what might normally be considered a raising hand, normally a below average one, with the hope that the few players remaining will not have a hand worth calling the raise, thereby winning the antes or blinds without further action. This play is used either in late position after several people have folded, or when the game is short-handed. Steals happen more often in tournament situations due to the escalating ante/blind structure making the starting pot quite valuable.\nWhile steals don't win much money per hand, they can accumulate to considerable profit if the players to the left of the stealer are tight enough not to contest enough steals. Of course, skilled players will recognize repeated steal plays and frequently reraise for defense.\nSteals being made in late position when everyone folds to the stealer, or when the game is short-handed, are the most common steals, but a raise under other conditions can also act as a steal. An aggressive player, especially one with a large stack of chips, might reraise, also known as re-steal, someone he knows might be trying to steal. The objective here is twofold: the re-raiser hopes to pick up both the blinds and antes and the original raiser's chips when the raiser folds, and he also hopes to keep that player from constantly raising before she or he can act because that cuts down on the reraiser's own stealing opportunities.\nIf one or more players have called a raise pre-flop, a player can re-raise as a bluff in what is called a squeeze play. The original raiser will often only continue with a truly premium holding as several other players have shown signs of strength, and he may well be playing out of position. The players that have just called the original raise are unlikely to have very strong hands as they have not re-raised. "}
{"id": "23169", "revid": "1233313", "url": "https://en.wikipedia.org/wiki?curid=23169", "title": "Dead money (poker)", "text": ""}
{"id": "23170", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=23170", "title": "Isolation (poker)", "text": "In poker, an isolation play is usually a raise designed to encourage one or more players to fold, specifically for the purpose of making the hand a one-on-one contest with a specific opponent. For example, if an opponent raises and a player suspects they are holding a weak, but playable hand, they may reraise to pressure other opponents to fold, with the aim of getting heads up with the opening raiser.\nIsolation plays are most common against overly-aggressive players (\"maniacs\") who frequently play inferior hands, or with players who may have a drawing hand. Isolation plays are also common in tournaments to isolate a player who is \"short stacked\", that is, one who is in imminent danger of elimination, and so is likely to be playing aggressively out of desperation. However, when a player is extremely short stacked compared to the rest of the field in a tournament, making him bust will sometimes be more profitable than winning his chips, so inducing overcalls from other players trumps isolation play.\nIsolating is encouraged when holding a hand that fares better heads up than in a multi-way pot. For instance, when a player has a small pocket pair they may raise a large amount simply to knock out other players because typically a small pocket pair is about 50\u201360% likely to win an all-in pot in a heads up situation, but less likely when facing multiple opponents.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23171", "revid": "96240", "url": "https://en.wikipedia.org/wiki?curid=23171", "title": "Dominating hand", "text": ""}
{"id": "23172", "revid": "47103691", "url": "https://en.wikipedia.org/wiki?curid=23172", "title": "Freeroll", "text": "Type of poker tournament\n \nIn poker, a freeroll tournament is a tournament with no entry fee, and a freeroll hand is where a player is guaranteed to at least split the pot with their opponent, with a chance they can win the whole pot if certain final cards are dealt.\nFreeroll hand.\nIn playing a particular hand of poker, a freeroll is a situation that arises (usually when only two players remain) before the last card has been dealt, in which one player is guaranteed to at least split the pot with his opponent no matter what the final cards are, but where there is some chance he can win the whole pot if certain final cards are dealt. This most commonly occurs in a high-low split game where one player knows that he has a guaranteed low hand made, his opponent cannot make a better low no matter what the last card is, but the player who is low might possibly catch a lucky card that gives him a straight or flush, winning high as well.\nHere's an example from Texas hold'em: Angie holds &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Kc\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;10c, and Burt holds &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Kh\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;10h. After the fourth card is dealt, the board is &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Ac\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Qd\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Jh\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;4c. Both players have an ace-high straight, the current nut hand, and so they will most likely split the pot. But if the final card happens to be a club, Burt's straight will lose to Angie's flush. There is no other possible final card that will give Burt more than a straight; only Angie can improve, so she is \"freerolling\" Burt.\nIf a player knows they have a freeroll, they can raise the pot with impunity, and often a less-skilled opponent with a good hand who does not realize that they are on the wrong end of the freeroll will continue to put in raises with no possible hope of gain.\nFreeroll tournament.\nA freeroll tournament is a tournament with no entry fee, although some freerolls require a payment at some point to gain entry to the tournament.\nIn a typical pay-to-play tournament, the prize pool consists of an accumulation of the entry fees minus a \"fee\" which is retained by the house. In a freeroll (at least from the players' perspective) the prize pool is essentially a \"donation\" provided by the house. Of course, in most freerolls the house is able defray a significant portion of the prize pool (or even turn a profit) by charging for food and beverages, sponsorship fees, admission to spectators, broadcast rights fees, or any combination of these. Sometimes a particular cardroom or casino (either traditional or online) will offer a freeroll tournament to frequent players. Invitation-only tournaments are frequently freerolls.\nFreerolls at Internet poker sites should not be confused with their close counterpart -- play money tournaments. Freerolls are different from play-money tournaments in two respects. Play money tournaments usually require the 'payment' of play money and the tournament winnings are play money. Freeroll tournaments can be genuinely free, may require a payment of points (from a point system developed by the site), or on some occasions require a deposit of funds into the player's account. The winnings are either real money, points, merchandise or entry tickets (invitations) to other tournaments.\nMost if not all Internet poker sites have freeroll tournaments although in many cases require a payment of points to play. These points typically can only be earned by paying and playing real money hands which in essence is a payment required to play their 'freerolls' and therefore a loose use of the term 'freeroll'. There are Internet sites that allow playing in freerolls without payment of any kind and with the chance to win real money.\nIt is not unusual to pay to play in a feeder tournament that gives the winner(s) a free entry to another tournament but it is debatable whether these second level tournaments can be called 'freerolls', since they require a buy-in, albeit smaller than the major tournament one. More often, such tournaments are called 'satellites'. This format is typical of freeroll tournaments both on the Internet and in the 'brick and mortar' sites. \nThe Professional Poker Tour is one such 'freeroll', with entrants being required to qualify through their results in previous tournaments. Sponsorship and broadcast-rights fees fund the prize pools.\nFreeroll tournaments are not exclusive to poker. Casinos frequently offer them to frequent and/or high-value players in games such as craps, blackjack, video poker and slot machines.\nOrigin of the term.\nMany believe the term comes from early 1950s Las Vegas, when guests would often be given a \"free roll\" of nickels to play at the slot machines upon check-in. Guests would often ask for their \"free rolls\" and the words became fused together and expanded to mean any complimentary gaming bonus.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23173", "revid": "35897031", "url": "https://en.wikipedia.org/wiki?curid=23173", "title": "Starting hand", "text": ""}
{"id": "23174", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=23174", "title": "Omaha hold 'em", "text": "Community card poker game\nOmaha hold 'em (also known as Omaha holdem or simply Omaha) is a community card poker game similar to Texas hold 'em, where each player is dealt four cards and must make their best hand using exactly two of them, plus exactly three of the five community cards. The exact origin of the game is unknown, but casino executive Robert Turner first brought Omaha into a casino setting when he introduced the game to Bill Boyd, who offered it as a game at the Las Vegas Golden Nugget Casino (calling it \"Nugget Hold'em\"). Omaha uses a 52-card French deck. Omaha hold 'em 8-or-better is the \"O\" game featured in H.O.R.S.E.\nHistory.\nOmaha hold 'em derives its name from two types of games.\n\"Hold'em\" refers to a game using community cards that are shared by all players. This is opposed to draw games, where each player's hand is composed only of concealed cards, and stud games, where each player's unique hand contains a mix of cards visible to the other players and concealed hole cards.\nIn the original Omaha poker game, players were only dealt two hole cards and had to use both to make a hand combined with community cards. This version of Omaha is defined in the glossary of \"Super/System\" (under Omaha) as being interchangeable with \"Tight hold 'em\". Across all the variations of the game, the requirement of using exactly two hole cards is the only consistent rule. The \"Omaha\" part of the name represents this aspect of the game.\nExplanation.\nIn North American casinos, the term \"Omaha\" can refer to several poker games. The original game is also commonly known as \"Omaha high\". A high-low split version called \"Omaha Hi-Lo\", or sometimes \"Omaha eight-or-better\" or \"Omaha/8\", is also played. In Europe, \"Omaha\" still typically refers to the high version of the game, usually played pot-limit. Pot-limit Omaha is often abbreviated as \"PLO.\" Pot-limit and no-limit Omaha eight-or-better can be found in some casinos and online, though no-limit is rarer.\nIt is often said that Omaha is a game of \"the nuts\", i.e. the best possible high or low hand, because it frequently takes \"the nuts\" to win a showdown. It is also a game where between the cards in their hand and the community cards a player may have drawing possibilities to multiple different types of holdings. For example, a player may have both a draw to a flush and a full house using different combinations of cards. At times, even seasoned players may need additional time to figure what draws are possible for their hand.\nThe basic differences between Omaha and Texas hold 'em are these: first, each player is dealt four hole cards instead of two. The betting rounds and layout of community cards are identical. At showdown, each player's hand is the best five-card hand made from \"exactly three\" of the five cards on the board, plus \"exactly two\" of the player's own cards. Unlike Texas hold 'em, a player cannot play four or five of the cards on the board with fewer than two of their own (nor can a player play three or four of their hole cards).\nA maximum of eleven players can be dealt a hand in Omaha, regardless of whether or not burn cards are used, however Omaha is most commonly played six handed or nine handed.\nSome specific things to notice about Omaha hands are:\nOmaha hi-low split-8 or better.\nIn Omaha hi-low split-8 or better (often called Omaha/8), each player makes a separate five-card high hand and five-card ace-to-five low hand (eight-high or lower to qualify), and the pot is split between the high and low (which may be the same player). A few casinos play with a 9-low qualifier instead, but this is rare.\nThe high hand is played as normal by creating the best hand possible according to Omaha's rules.\nThe low hand is created by creating the worst hand possible according to the rules with cards 8-7-6-5-4-3-2-A (e.g. \"eight or better\"). Any combination of cards identified as a \"hand\" - even a lowly pair of twos - is viewed negatively in the low portion. \nThe player can use different cards for the high and low hands. Each player can play any two of their four hole cards to make their high hand, and any two of their four hole cards to make their low hand. If there is no qualifying low hand, the high hand wins (\"scoops\") the whole pot.\nThe game is usually played in the fixed limit version, although pot limit Omaha/8 is becoming more popular. A few low-stakes online tournaments feature no limit Omaha/8.\nThe game is complex so a number of examples will be useful to clarify play. The table below shows a five-card board of community cards at the end of play and shows each player's initial private four hole cards in the leftmost column. The middle and right columns show the best five-card high and low hands each player can play on showdown.\nChris wins the high-hand half of the pot with a J-high straight. \nBryan and Eve split the low hand pot with 7-5-3-2-A, a junk hand. Both Alan (pair of twos) and Derek (pair of sevens) lose as their hands are low in value but are more valuable than Bryan and Eve's junk hands. Had Bryan and Eve had hands (a pair of threes, for example) then Alan would have won with the least valuable hand, a lowly pair of deuces.\nSome specific things to notice about Omaha/8 hands are:\nPot-limit Omaha.\nPot-limit Omaha (frequently shortened to PLO) is popular in Europe, online, and in high-stakes \"mixed games\" played in some American casinos. This variant is more often played high only, but can also be played high-low. To a still greater degree than in Limit Omaha Hi-Lo, PLO is a game of drawing, when drawing, to the nut hand. Second best flushes and straights can be, and frequently become, losing hands, especially when a player is willing to commit their entire stack to the pot. Furthermore, because of the exponential growth of the pot size in pot-limit play, seeing one of these hands to the end can be very expensive and carry immense reverse implied odds.\nWraps.\nIn poker, an out is any unseen card in the deck that will give a player the best hand. A wrap is a straight draw with nine or more outs. This is called a wrap because the player\u2019s hole cards are said to wrap-around the board cards. In Texas hold 'em, where players have two hole cards, the greatest number of straight outs possible is eight; however, in Omaha, there are four hole cards, which can result in straight draws which can have up to 20 outs. An example of a twenty-out wrap is &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Jh\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Ts\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;7d\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;6c on a flop of &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;9h\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;8s\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;2d. To hit a straight, any of the following cards is needed: &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;5h\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;5s\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;5d\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;5c\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;6h\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;6s\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;6d\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;7h\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;7s\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;7c\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Th\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Td\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Tc &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Js\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Jd\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Jc\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Qh\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Qs\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Qd\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Qc.\nRedraws.\nA desirable hand to have in PLO is the current best hand with a redraw to the nuts. For example, if the board is &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Qs\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Js\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Th, and the player has &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;As\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Kc\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Qc\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Qh, then not only do they have the current best hand possible (their ace-king makes the ace-high straight), but they also have a redraw with the two queens in their hand because if the board pairs, they will make a full house, or four queens. &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;As\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Ks\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Qc\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Qh would be an even better hand because it has flush and royal flush redraws as well. In fact, with the &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Qs\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Js\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Th board, &lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;As\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Ks\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Qc\u00a0&lt;templatestyles src=\"Template:Cards/styles.css\"/&gt;Qh is approximately an 80-20 money favorite over a random hand containing ace-king (see freerolling). Even a pair of queens with any two spades is better than 55-45 against a random ace-king hand.\nOmaha variations.\nThe most common variations of Pot Limit Omaha high are Five-card Omaha, commonly referred as \"Big O\" very popular in Southeastern United States as a home game and Six-card Omaha or 6-O which can be found in many casinos across the UK. Some online poker rooms support Five-card Omaha, Six-card Omaha and Courchevel.\n\"Big O\" (occasionally called Five-card Omaha or 5-O) began appearing in Southern California in 2008 and had spread to most of the card rooms in the area by the end of the year.\nSometimes the high-low split game is played with a 9 or a 7-high qualifier instead of 8-high. It can also be played with five cards dealt to each player instead of four. In that case, the same rules for making a hand apply: exactly two from the player's hand, and exactly three from the board.\nCourchevel.\nCourchevel is named after the high-end ski resort in the French Alps. According to the urban legend, bored tourists wanted to play a version of poker no-one has ever played before, so they came up with this game. The place where Courchevel was most commonly played was the Aviation Club de France in Paris. That casino is now closed.\nIn the game of Courchevel, players are dealt five hole cards rather than four. Simultaneously, the first community card is dealt. Following an opening round of betting, two additional community cards are dealt, creating a 3-card flop, where the structure of the game is then identical to standard Omaha. Still, exactly two of the five hole cards must be used. Courchevel is popular in France but its popularity has expanded in other parts of Europe, particularly the United Kingdom. Courchevel is also available in a hi-low 8 or better variety, and while Courchevel is rarely offered on any of the major online poker sites, as of 2019, hi-low sit-and-go games at the micro stakes level can be found taking place several times a day on Pokerstars, which had the game since 2013.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23178", "revid": "668752", "url": "https://en.wikipedia.org/wiki?curid=23178", "title": "Rule variations (poker)", "text": ""}
{"id": "23184", "revid": "49686338", "url": "https://en.wikipedia.org/wiki?curid=23184", "title": "Aggression (poker)", "text": "Class of poker play\nIn the game of poker, opens and raises are considered aggressive plays, while calls and checks are considered passive (though a check-raise would be considered a very aggressive play). It is said that \"aggression has its own value\", meaning that often aggressive plays can make money with weak hands because of bluff value. In general, opponents must respond to aggressive play by playing more loosely, which offers more opportunities to make mistakes.\nWhile it is true that aggressive play is generally superior to passive play, using any play exclusively can lead to predictability. A player who is constantly aggressive and plays many inferior hands is called a \"maniac\", and skilled players will take advantage of him by calling him more often, using isolation plays, and by other means.\nIf a player is not aggressive with his weaker hands, the opponents can safely fold whenever the player does bet or raise. The appropriate amount of aggression can be computed using game theory, and depends on the game being played and the tendencies of the opponents.\nMost theorists, like David Sklansky and Doyle Brunson, suggest aggression as an important tool. Aggressive play should not be confused with loose play. Loose players may play passively, resulting in a calling station, while tight players may play aggressively, referred to as a TAG. Aggression is called for in particular circumstances. Very strong starting hands should be played very aggressively most of the time. A very strong propositional hand \u2013 one that is more likely to win with a straight or a flush \u2013 is one of the hands that can be played for effect with an aggressive style. Such aggression is deceptive, as the low and unpaired ranks of the starting hand require much improvement to win. This is beneficial for two reasons:\nThe second reasoning is what is known as \"advertising\" in poker. It can be very profitable for a player to convince the other players at the table that he is willing to gamble with less than premium cards. The result is larger pots when the aggressive player has tremendously strong hands.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23187", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=23187", "title": "Playing card/Anglo-American", "text": ""}
{"id": "23189", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=23189", "title": "Shuffling", "text": "Procedure used to randomize a deck of playing cards\nShuffling is a technique used to randomize a deck of playing cards, introducing an element of chance into card games. Various shuffling methods exist, each with its own characteristics and potential for manipulation.\nOne of the simplest shuffling techniques is the overhand shuffle, where small packets of cards are transferred from one hand to the other. This method is easy to perform but can be manipulated to control the order of cards. Another common technique is the riffle shuffle, where the deck is split into two halves and interleaved. This method is more complex but minimizes the risk of exposing cards. The Gilbert\u2013Shannon\u2013Reeds model suggests that seven riffle shuffles are sufficient to thoroughly randomize a deck, although some studies indicate that six shuffles may be enough.\nOther shuffling methods include the Hindu shuffle, commonly used in Asia, and the pile shuffle, where cards are dealt into piles and then stacked. The Mongean shuffle involves a specific sequence of transferring cards between hands, resulting in a predictable order. The faro shuffle, a controlled shuffle used by magicians, involves interweaving two halves of the deck and can restore the original order after several shuffles.\nShuffling can be simulated using algorithms like the Fisher\u2013Yates shuffle, which generates a random permutation of cards. In online gambling, the randomness of shuffling is crucial, and many sites provide descriptions of their shuffling algorithms. Shuffling machines are also used in casinos to increase complexity and prevent predictions. Despite these advances, the mathematics of shuffling continue to be a subject of research, with ongoing debates about the number of shuffles required for true randomization.\nTechniques.\nOverhand.\nOne of the easiest shuffles to accomplish after a little practice is the overhand shuffle. Johan Jonasson wrote, \"The overhand shuffle... is the shuffling technique where you gradually transfer the deck from, say, your right hand to your left hand by sliding off small packets from the top of the deck with your thumb.\" In detail as normally performed, with the pack initially held in the left hand (say), most of the cards are grasped as a group from the bottom of the pack between the thumb and fingers of the right hand and lifted clear of the small group that remains in the left hand. Small packets are then released from the right hand a packet at a time so that they drop on the top of the pack accumulating in the left hand. The process is repeated several times. The randomness of the whole shuffle is increased by the number of small packets in each shuffle and the number of repeat shuffles performed.\nThe overhand shuffle offers sufficient opportunity for sleight of hand techniques to be used to affect the ordering of cards, creating a stacked deck. The most common way that players cheat with the overhand shuffle is by having a card at the top or bottom of the pack that they require, and then slipping it to the bottom at the start of a shuffle (if it was on top to start), or leaving it as the last card in a shuffle and just dropping it on top (if it was originally on the bottom of the deck).\nRiffle.\nA common shuffling technique is called the \"riffle,\" or \"dovetail\" shuffle or \"leafing the cards\", in which half of the deck is held in each hand with the thumbs inward, then cards are released by the thumbs so that they fall to the table interleaved. Many also lift the cards up after a riffle, forming what is called a bridge which puts the cards back into place; it can also be done by placing the halves flat on the table with their rear corners touching, then lifting the back edges with the thumbs while pushing the halves together. While this method is more difficult, it is often used in casinos because it minimizes the risk of exposing cards during the shuffle. There are two types of perfect riffle shuffles: if the top card moves to be second from the top then it is an in shuffle, otherwise it is known as an out shuffle (which preserves both the top and bottom cards).\nThe Gilbert\u2013Shannon\u2013Reeds model provides a mathematical model of the random outcomes of riffling that has been shown experimentally to be a good fit to human shuffling and that forms the basis for a recommendation that card decks be riffled seven times in order to randomize them thoroughly. Later, mathematicians Lloyd M. Trefethen and Lloyd N. Trefethen authored a paper using a tweaked version of the Gilbert\u2013Shannon\u2013Reeds model showing that the minimum number of riffles for total randomization could also be six, if the method of defining randomness is changed.\nBox.\nAlso known as \"strip.\" The deck is held from the top by one hand close to the top of the table, and a pile is stripped off the top of the deck with the other hand and placed on the table. Additional piles are stripped off and placed on top of the previous pile until all cards have been placed onto the new pile. Boxing the cards is functionally the same as an overhand shuffle, however, by keeping the cards close to the table, it is less likely that cards will be accidentally exposed.\nHindu.\nAlso known as the \"Indian\", \"Kattar\", \"Kenchi\" (Hindi for scissor) or \"Kutti Shuffle\". The deck is held face down, with the middle finger on one long edge and the thumb on the other on the bottom half of the deck. The other hand draws off a packet from the top of the deck. This packet is allowed to drop into the palm. The maneuver is repeated over and over, with newly drawn packets dropping onto previous ones, until the deck is all in the second hand. Indian shuffle differs from stripping in that all the action is in the hand \"taking\" the cards, whereas in stripping, the action is performed by the hand with the original deck, \"giving\" the cards to the resulting pile. This is the most common shuffling technique in Asia and other parts of the world, while the overhand shuffle is primarily used in Western countries.\nPile.\nCards are simply dealt out into a number of piles, then the piles are stacked on top of each other. Though this is deterministic and does not randomize the cards at all, it ensures that cards that were next to each other are now separated. Some variations on the pile shuffle attempt to make it slightly random by dealing to the piles in a random order each circuit.\n52 pickup.\nA person may throw a deck of cards into the air or across a surface, and then pick up the cards in random order, assembled with the cards facing the same direction. If specific cards are observed too closely as they are picked up, an additional 52 pickup or an additional shuffling method may be needed for sufficient randomization. This method is useful for beginners, but the shuffle requires a large clean surface for spreading out the cards, and it may take more time than is desired. \n'A game of 52 pickup' is also the name of a child's prank, where one child asks a 'friend' if they want to play 52 pickup. They then throw the cards into the air, and demand the other child 'pick them up'.\nCorgi.\nThis method is similar to 52 pickup and also useful for beginners. Also known as the Chemmy, Irish, wash, scramble, hard shuffle, smooshing, schwirsheling, or washing the cards, this involves simply spreading the cards out face down, and sliding them around and over each other with one's hands. Then the cards are moved into one pile so that they begin to intertwine and are then arranged back into a stack. Statistically random shuffling is achieved after approximately one minute of smooshing. Smooshing has been largely popularized by Simon Hofman.\nMongean.\nThe Mongean shuffle, or Monge's shuffle, is performed as follows (by a right-handed person): Start with the unshuffled deck in the left hand and transfer the top card to the right. Then repeatedly take the top card from the left hand and transfer it to the right, putting the second card at the top of the new deck, the third at the bottom, the fourth at the top, the fifth at the bottom, etc. The result, if one started with cards numbered consecutively formula_1, would be a deck with the cards in the following order: formula_2.\nFaro.\nWeaving is the procedure of pushing the ends of two halves of a deck against each other in such a way that they naturally intertwine. Sometimes the deck is split into equal halves of 26 cards which are then pushed together in a certain way so as to make them perfectly interweave. This is known as a \"Faro Shuffle\".\nThe faro shuffle is performed by cutting the deck into two, preferably equal, packs in both hands as follows (right-handed):\nThe cards are held from above in the right and from below in the left hand. Separation of the deck is done simply lifting up half the cards with the right hand thumb slightly and pushing the left hand's packet forward away from the right hand. The two packets are often crossed and tapped against each other to align them. They are then pushed together by the short sides and bent (either up or down). The cards then alternately fall into each other, much like a zipper. A flourish can be added by springing the packets together by applying pressure and bending them from above, as called the bridge finish. The faro is a controlled shuffle which does not randomize a deck when performed properly.\nA perfect faro shuffle, where the cards are perfectly alternated, is considered one of the most difficult sleights by card magicians, simply because it requires the shuffler to be able to cut the deck into two equal packets and apply just the right amount of pressure when pushing the cards into each other. Performing eight perfect faro shuffles in a row restores the order of the deck to the original order only if there are 52 cards in the deck and if the original top and bottom cards remain in their positions (1st and 52nd) during the eight shuffles. If the top and bottom cards are weaved in during each shuffle, it takes 52 shuffles to return the deck back into original order (or 26 shuffles to reverse the order).\nMexican spiral.\nThe Mexican spiral shuffle is performed by cyclic actions of moving the top card onto the table, then the new top card under the deck, the next onto the table, next under the deck, and so on until the last card is dealt onto the table. It takes quite a long time, compared with riffle or overhand shuffles, but allows other players to fully control cards which are on the table. The Mexican spiral shuffle was popular at the end of the 19th century in some areas of Mexico as a protection from gamblers and con men arriving from the United States.\nTeam shuffle.\nEspecially useful for large decks, a shuffler may divide a deck into two or more smaller decks, and give the other portion(s) to (an)other shuffler(s), each to choose their own shuffling method(s). Smaller decks or portions of smaller decks may be traded around as shuffling continues, then the smaller decks are combined (and briefly shuffled) into the original large deck. This also prevents one shuffler having unfair control of the randomization.\nCut.\nTypically performed after a previous shuffling method, the cut is of simply taking a deck, dividing it into two portions of random size, and putting the previously lower portion on top of the previously higher portion. This is occasionally performed by a second shuffler, for additional assurance of randomization, and to prevent either the shuffler or an observer from knowing the top or bottom card.\nFaking.\nMagicians, sleight-of-hand artists, and card cheats employ various methods of shuffling whereby the deck appears to have been shuffled fairly, when in reality one or more cards (up to and including the entire deck) stays in the same position. It is also possible, though generally considered very difficult, to \"stack the deck\" (place cards into a desirable order) by means of one or more riffle shuffles; this is called \"riffle stacking\".\nBoth performance magicians and card sharps regard the Zarrow shuffle and the Push-Through-False-Shuffle as particularly effective examples of the false shuffle. In these shuffles, the entire deck remains in its original order, although spectators think they see an honest riffle shuffle.\nMachines.\nCasinos often equip their tables with shuffling machines instead of having croupiers shuffle the cards, as it gives the casino a few advantages, including an increased complexity to the shuffle and therefore an increased difficulty for players to make predictions, even if they are collaborating with croupiers. The shuffling machines are carefully designed to avoid biasing the shuffle and are typically computer-controlled. Shuffling machines also save time that would otherwise be wasted on manual shuffling, thereby increasing the profitability of the table. These machines are also used to lessen repetitive-motion-stress injuries to a dealer.\nPlayers with superstitions often regard with suspicion any electronic equipment, so casinos sometimes still have the croupiers perform the shuffling at tables that typically attract those crowds (e.g., baccarat tables). Additionally, casinos replace their decks at regular intervals; even if a shuffling machine is being used, the croupier usually manually shuffles the replacement decks before placing them into the machine.\nRandomization.\nThere are 52 factorial (expressed in shorthand as 52!) possible orderings of the cards in a 52-card deck. In other words, there are 52 \u00d7 51 \u00d7 50 \u00d7 49 \u00d7 \u00b7\u00b7\u00b7 \u00d7 4 \u00d7 3 \u00d7 2 \u00d7 1 possible combinations of card sequence. This is approximately (80,658vigintillion) possible orderings, or specifically 80,658,175,170,943,878,571,660,636,856,403,766,975,289,505,440,883,277,824,000,000,000,000. The magnitude of this number means that it is exceedingly improbable that two randomly selected, truly randomized decks will be the same. However, while the exact sequence of all cards in a randomized deck is unpredictable, it may be possible to make some probabilistic predictions about a deck that is not sufficiently randomized.\nSufficiency.\nThe number of shuffles that are sufficient for a \"good\" level of randomness depends on the type of shuffle and the measure of \"good enough randomness\", which in turn depends on the game in question. For most games, four to seven riffle shuffles are sufficient: for unsuited games such as blackjack, four riffle shuffles are sufficient, while for suited games, seven riffle shuffles are necessary. There are some games, however, for which even seven riffle shuffles are insufficient.\nIn practice the number of shuffles required depends both on the quality of the shuffle and how significant non-randomness is, particularly how good the people playing are at noticing and using non-randomness. Two to four shuffles is good enough for casual play. But in club play, good bridge players take advantage of non-randomness after four shuffles, and top blackjack players supposedly track aces through the deck; this is known as \"ace tracking\", or more generally, as \"shuffle tracking\".\nResearch.\nFollowing early research at Bell Labs, which was abandoned in 1955, the question of how many shuffles was required remained open until 1990, when it was convincingly solved as \"seven shuffles,\" as elaborated below. Some results preceded this, and refinements have continued since.\nA leading figure in the mathematics of shuffling is mathematician and magician Persi Diaconis, who began studying the question around 1970, and has authored many papers in the 1980s, 1990s, and 2000s on the subject with numerous co-authors. Most famous is , co-authored with mathematician Dave Bayer, which analyzed the Gilbert\u2013Shannon\u2013Reeds model of random riffle shuffling and concluded that the deck did not start to become random until five good riffle shuffles, and was truly random after seven, in the precise sense of variation distance described in Markov chain mixing time; of course, you would need more shuffles if your shuffling technique is poor. Recently, the work of Trefethen et al. has questioned some of Diaconis' results, concluding that six shuffles are enough. The difference hinges on how each measured the randomness of the deck. Diaconis used a very sensitive test of randomness, and therefore needed to shuffle more. Even more sensitive measures exist, and the question of what measure is best for specific card games is still open. Diaconis released a response indicating that you only need four shuffles for un-suited games such as blackjack.\nOn the other hand, variation distance may be too forgiving a measure and seven riffle shuffles may be many too few. For example, seven shuffles of a new deck leaves an 81% probability of winning New Age Solitaire where the probability is 50% with a uniform random deck. One sensitive test for randomness uses a standard deck without the jokers divided into suits with two suits in ascending order from ace to king, and the other two suits in reverse. (Many decks already come ordered this way when new.) After shuffling, the measure of randomness is the number of rising sequences that are left in each suit.\nAlgorithms.\nIf a computer has access to purely random numbers, it is capable of generating a \"perfect shuffle\", a random permutation of the cards; beware that this terminology (an algorithm that perfectly randomizes the deck) differs from \"a perfectly executed single shuffle\", notably a perfectly interleaving faro shuffle. The Fisher\u2013Yates shuffle, popularized by Donald Knuth, is simple (a few lines of code) and efficient (O(\"n\") on an \"n\"-card deck, assuming constant time for fundamental steps) algorithm for doing this. Shuffling can be seen as the opposite of sorting.\nA new alternative to Fisher-Yates, which does not use any array memory operations, is the use a Pseudo Random Index Generator (PRIG) function algorithm.\nThere are other, less-desirable algorithms in common use. For example, one can assign a random number to each card, and then sort the cards in order of their random numbers. This will generate a random permutation, unless any of the random numbers generated are the same as any others (i.e. pairs, triplets etc.). This can be eliminated either by adjusting one of the pair's values randomly up or down by a small amount, or reduced to an arbitrarily low probability by choosing a sufficiently wide range of random number choices. If using efficient sorting such as mergesort or heapsort this is an O(\"n\" log \"n\") average and worst-case algorithm.\nOnline gambling.\nThese issues are of considerable commercial importance in online gambling, where the randomness of the shuffling of packs of simulated cards for online card games is crucial. For this reason, many online gambling sites provide descriptions of their shuffling algorithms and the sources of randomness used to drive these algorithms, with some gambling sites also providing auditors' reports of the performance of their systems.\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nPhysical card shuffling:\nMathematics of shuffling:\nReal world (historical) application:"}
{"id": "23190", "revid": "50129357", "url": "https://en.wikipedia.org/wiki?curid=23190", "title": "Cut (cards)", "text": "Spliting a deck of cards by someone other than the dealer\nIn card games, to cut the cards (also \"cut the deck\" or \"cut the pack\") is to split the deck into two packets by lifting one packet from the top and placing it face down next to the remaining cards beneath it. The lower packet is then placed on top of it. This is typically done after the cards have already been shuffled, and the procedure is used just prior to the cards being dealt to the players. The aim of this is to reduce the possibility of cheating, for example, by knowing the top or bottom card. Cutting the cards is also a common way of determining the seating order at a card table, the partnerships or the first dealer.\nPurpose.\nThe practice of cutting is primarily a method of reducing the likelihood of someone cheating by manipulating the order of cards to gain an advantage. Even if the dealer (or the shuffler, if they are not the dealer) does not plan on cheating, cutting will prevent suspicions, thus many rules require it. Some players also consider the cut to be lucky. David Parlett says the purpose of cutting is to prevent the bottom card from being known.\nA secondary purpose is as a form of drawing lots whereby all the players cut the pack before the game starts and reveal the card at the bottom of the lifted packet to determine initial conditions of the game such as seating, partnerships, and the first dealer. The card rankings applied for this purpose may differ from that used for the rules of the game, e.g. with Aces low, as follows: Joker\u2013A\u20132\u20133\u20134\u20135\u20136\u20137\u20138\u20139\u201310\u2013J\u2013Q\u2013K. Alternatively the shuffled pack is often fanned, face down, on the table, with players drawing and revealing one card at random.\nProcedure.\nA common cutting procedure is that after the cards have been shuffled, the dealer sets the cards face down on the table near the player designated to make the cut. This is usually the player who would be dealt to last, i.e. the dealer's right in clockwise-dealt games, or the player to dealer's left when dealt counter-clockwise.\nThe cutter lifts a contiguous group of cards off the top of the deck and places it face down on the table, off of the deck. The dealer then completes the cut by placing the original bottom portion of the deck on top of this lifted group of cards. Once the cut is complete, the dealer picks up the deck, straightens or \"squares\" it, and deals the cards.\nRules of this procedure may vary concerning who makes the cut, the minimum or maximum number of cards which may be lifted off the top of the deck, whether the dealer or the cutter restacks the cards, whether a cut card is employed, whether a cut is mandatory or the cutter may opt not to cut (typically by tapping the top of the pack or the table) and more.\nEtiquette.\nDuring informal card games, the dealer is typically not required to offer the cut, and even if offered, the designated player can decline the request. A player may request to cut the cards before they are dealt, and if a cut is requested, it should be granted by the dealer.\nIn formal settings, an offer by the dealer to cut the deck is mandatory and the designated player must perform the cut, generally by inserting a cut card into the deck, after which the dealer completes the cut, leaving the cut card covering the bottom of the deck. When the dealer is not a player (i.e. a casino employee), the cut is mandatory and usually performed by the dealer.\nRules may specify that at least three cards be taken or left in making a cut. Multiple cuts may also be allowed. According to Parlett, a sensible minimum cut size is about one-fifth of the deck.\nA cut should be completed with one hand to limit possibility of a false cut.\nTypes of cut.\nScarne's cut.\nWhen the contiguous section is taken from the middle of the deck this is called \"Scarne's cut,\" named after the American magician John Scarne who developed it during World War II to help protect servicemen against cheating by unscrupulous dealers. This style of cut is against the rules or considered poor etiquette in some settings.\nMultiple cuts.\nMultiple consecutive standard cuts are equivalent to a single cut the size of the sum of the cut sizes modulo the size of the deck.\nFor example, in a 10 card deck, if a 7 card cut is made, followed by a 4 card cut, these two consecutive cuts are equivalent to a single cut the size of ((7 + 4) mod 10) = 1.\nFalse cut.\nA false cut is a sleight of hand used in magic or for cheating at card games. It appears to be a real cut, but leaves the deck in the same order as when it began, or another order known to the cutter.\nJoke.\nThe command to \"cut the cards\", followed by someone literally chopping the deck in half with an axe, is a gag that has been used many times in popular media, going back to at least the vaudeville days. Examples include Harpo Marx in \"Horse Feathers\", Curly Howard in \"Ants in the Pantry\", and Bugs Bunny in \"Bugs Bunny Rides Again\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23193", "revid": "48736052", "url": "https://en.wikipedia.org/wiki?curid=23193", "title": "Philology", "text": "Study of language in historical sources\nPhilology (from grc \" ' ()\"\u00a0'love of word') is the study of language in oral and written historical sources. It is the intersection of textual criticism, literary criticism, history, and linguistics with strong ties to etymology. Philology is also defined as the study of literary texts and oral and written records, the establishment of their authenticity and their original form, and the determination of their meaning. A person who pursues this kind of study is known as a philologist. In older usage, especially British, philology is more general, covering comparative and historical linguistics.\nClassical philology studies classical languages. Classical philology principally originated from the Library of Pergamum and the Library of Alexandria around the fourth century BC, and was continued by the Ancient Greeks and then the Romans throughout the Roman and Byzantine Empire. It was eventually resumed by European scholars of the Renaissance, where it was soon joined by philologies of other European (Romance, Germanic, Celtic, Slavic, etc.), Asian (Arabic, Persian, Sanskrit, Chinese, etc.), and African (Egyptian, etc.) languages. Indo-European studies involve the comparative philology of all Indo-European languages.\nPhilology, with its focus on historical development (diachronic analysis), is contrasted with linguistics due to Ferdinand de Saussure's insistence on the importance of synchronic analysis. While the contrast continued with the emergence of structuralism and the emphasis of Noam Chomsky on syntax, research in historical linguistics often relies on philological materials and findings.\nEtymology.\nThe term \"philology\" is derived from the Greek (\"philolog\u00eda\"), from the terms (\"ph\u00edlos\") 'love, affection, loved, beloved, dear, friend' and (\"l\u00f3gos\") 'word, articulation, reason', describing a love of learning, of literature, as well as of argument and reasoning, reflecting the range of activities included under the notion of . The term changed little with the Latin \"philologia\", and later entered the English language in the 16th century, from the Middle French \"philologie\", in the sense of 'love of literature'.\nThe adjective (\"phil\u00f3logos\") meant 'fond of discussion or argument, talkative', in Hellenistic Greek, also implying an excessive (\"sophistic\") preference of argument over the love of true wisdom, (\"phil\u00f3sophos\").\nAs an allegory of literary erudition, \"philologia\" appears in fifth-century postclassical literature (Martianus Capella, \"De nuptiis Philologiae et Mercurii\"), an idea revived in Late Medieval literature (Chaucer, Lydgate).\nThe meaning of \"love of learning and literature\" was narrowed to \"the study of the historical development of languages\" (historical linguistics) in 19th-century usage of the term. Due to the rapid progress made in understanding sound laws and language change, the \"golden age of philology\" lasted throughout the 19th century, or \"from Giacomo Leopardi and Friedrich Schlegel to Nietzsche\".\nBranches.\nComparative.\nThe comparative linguistics branch of philology studies the relationship between languages. Similarities between Sanskrit and European languages were first noted in the early 16th century and led to speculation of a common ancestor language from which all these descended. It is now named Proto-Indo-European. Philology's interest in ancient languages led to the study of what was, in the 18th century, \"exotic\" languages, for the light they could cast on problems in understanding and deciphering the origins of older texts.\nTextual.\nPhilology also includes the study of texts and their history. It includes elements of textual criticism, trying to reconstruct an author's original text based on variant copies of manuscripts. This branch of research arose among ancient scholars in the Greek-speaking world of the 4th century BC, who desired to establish a standard text of popular authors for both sound interpretation and secure transmission. Since that time, the original principles of textual criticism have been improved and applied to other widely distributed texts such as the Bible. Scholars have tried to reconstruct the original readings of the Bible from the manuscript variants. This method was applied to classical studies and medieval texts as a way to reconstruct the author's original work. The method produced so-called \"critical editions\", which provided a reconstructed text accompanied by a \"critical apparatus\", i.e., footnotes that listed the various manuscript variants available, enabling scholars to gain insight into the entire manuscript tradition and argue about the variants.\nA related study method known as higher criticism studies the authorship, date, and provenance of text to place such text in a historical context. As these philological issues are often inseparable from issues of interpretation, there is no clear-cut boundary between philology and hermeneutics. When text has a significant political or religious influence (such as the reconstruction of Biblical texts), scholars have difficulty reaching objective conclusions.\nSome scholars avoid all critical methods of textual philology, especially in historical linguistics, where it is important to study the actual recorded materials. The movement known as \"new philology\" has rejected textual criticism because it injects editorial interpretations into the text and destroys the integrity of the individual manuscript, hence damaging the reliability of the data. Supporters of new philology insist on a strict \"diplomatic\" approach: a faithful rendering of the text exactly as found in the manuscript, without emendations.\nCognitive.\nAnother branch of philology, cognitive philology, studies written and oral texts. Cognitive philology considers these oral texts as the results of human mental processes. This science compares the results of textual science with the results of experimental research of both psychology and artificial intelligence production systems.\nDecipherment.\nIn the case of Bronze Age literature, philology includes the prior decipherment of the language under study. This has notably been the case with the Egyptian, Sumerian, Assyrian, Hittite, Ugaritic, and Luwian languages. Beginning with the famous decipherment and translation of the Rosetta Stone by Jean-Fran\u00e7ois Champollion in 1822, some individuals attempted to decipher the writing systems of the Ancient Near East and Aegean. In the case of Old Persian and Mycenaean Greek, decipherment yielded older records of languages already known from slightly more recent traditions (Middle Persian and Alphabetic Greek).\nWork on the ancient languages of the Near East progressed rapidly. In the mid-19th century, Henry Rawlinson and others deciphered the Behistun Inscription, which records the same text in Old Persian, Elamite, and Akkadian, using a variation of cuneiform for each language. The elucidation of cuneiform led to the decipherment of Sumerian. Hittite was deciphered in 1915 by Bed\u0159ich Hrozn\u00fd.\nLinear B, a script used in the ancient Aegean, was deciphered in 1952 by Michael Ventris and John Chadwick, who demonstrated that it recorded an early form of Greek, now known as Mycenaean Greek. Linear A, the writing system that records the still-unknown language of the Minoans, resists deciphering, despite many attempts.\nWork continues on scripts such as the Maya, with great progress since the initial breakthroughs of the phonetic approach championed by Yuri Knorozov and others in the 1950s. Since the late 20th century, the Maya code has been almost completely deciphered, and the Mayan languages are among the most documented and studied in Mesoamerica. The code is described as a logosyllabic style of writing.\nContention.\nIn English-speaking countries, use of the term \"philology\" to describe work on languages and works of literature, which had become synonymous with the practices of German scholars, was abandoned as a consequence of anti-German feelings following World War I. Most continental European countries still maintain the term to designate departments, colleges, position titles, and journals. J. R. R. Tolkien opposed the nationalist reaction against philological practices, claiming that \"the philological instinct\" was \"universal as is the use of language\". In British English usage, and British academia, \"philology\" remains largely synonymous with \"historical linguistics\", while in US English, and US academia, the wider meaning of \"study of a language's grammar, history and literary tradition\" remains more widespread. Based on the harsh critique of Friedrich Nietzsche, some US scholars since the 1980s have viewed philology as responsible for a narrowly scientistic study of language and literature.\nDisagreements in the modern day of this branch of study are followed with the likes of how the method is treated among other scholars, as noted by both the philologists R.D Fulk and Leonard Neidorf who have been quoted saying \"This field \"philology's commitment to falsification renders it \"at odds with what many literary scholars believe because the purpose of philology is to narrow the range of possible interpretations rather than to treat all reasonable ones as equal\". This use of falsification can be seen in the debate surrounding the etymology of the Old English character Unferth from the heroic epic poem Beowulf.\nJames Turner further disagrees with how the use of the term is dismissed in the academic world, stating that due to its branding as a \"simpleminded approach to their subject\" the term has become unknown to college-educated students, furthering the stereotypes of \"scrutiny of ancient Greek or Roman texts of a nit-picking classicist\" and only the \"technical research into languages and families\".\nIn popular culture.\nIn \"The Space Trilogy\" by C. S. Lewis, the main character, Elwin Ransom, is a philologist \u2013 as was Lewis' close friend J. R. R. Tolkien.\nDr. Edward Morbius, one of the main characters in the science fiction film \"Forbidden Planet\", is a philologist.\nPhilip, the main character of Christopher Hampton's 'bourgeois comedy' \"The Philanthropist\", is a professor of philology in an English university town.\nMoritz-Maria von Igelfeld, the main character in Alexander McCall Smith's 1997 comic novel \"Portuguese Irregular Verbs\" is a philologist, educated at Cambridge.\nThe main character in the Academy Award Nominee for Best Foreign Language Film in 2012, \"Footnote\", is a Hebrew philologist, and a significant part of the film deals with his work.\nThe main character of the science fiction TV show \"Stargate SG-1\", Dr. Daniel Jackson, is mentioned as having a PhD in philology."}
{"id": "23194", "revid": "28979433", "url": "https://en.wikipedia.org/wiki?curid=23194", "title": "Phonetics", "text": "Study of how humans produce and perceive sounds\nPhonetics is a branch of linguistics that studies how humans produce and perceive sounds or, in the case of sign languages, the equivalent aspects of sign. Linguists who specialize in studying the physical properties of speech are phoneticians. The field of phonetics is traditionally divided into three sub-disciplines: articulatory phonetics, acoustic phonetics, and auditory phonetics. Traditionally, the minimal linguistic unit of phonetics is the phone\u2014a speech sound in a language which differs from the phonological unit of phoneme; the phoneme is an abstract categorization of phones and it is also defined as the smallest unit that discerns meaning between sounds in any given language.\nPhonetics deals with two aspects of human speech: production (the ways humans make sounds) and perception (the way speech is understood). The communicative modality of a language describes the method by which a language produces and perceives languages. Languages with oral-aural modalities such as English produce speech orally and perceive speech aurally (using the ears). Sign languages, such as Australian Sign Language (Auslan) and American Sign Language (ASL), have a manual-visual modality, producing speech manually (using the hands) and perceiving speech visually. ASL and some other sign languages have in addition a manual-manual dialect for use in tactile signing by deafblind speakers where signs are produced with the hands and perceived with the hands as well.\nHistory.\nAntiquity.\nThe first known study of phonetics was undertaken by Sanskrit grammarians as early as the 6th century\u00a0BCE. The Hindu scholar P\u0101\u1e47ini is among the most well known of these early investigators. His four-part grammar, written c.\u2009350\u00a0BCE, is influential in modern linguistics and still represents \"the most complete generative grammar of any language yet written\". His grammar formed the basis of modern linguistics and described several important phonetic principles, including voicing. This early account described resonance as being produced either by tone, when vocal folds are closed, or noise, when vocal folds are open. The phonetic principles in the grammar are considered \"primitives\" in that they are the basis for his theoretical analysis rather than the objects of theoretical analysis themselves, and the principles can be inferred from his system of phonology.\nThe Sanskrit study of phonetics is called \"Shiksha\", which the 1st-millennium BCE Taittiriya Upanishad defines as follows:\n\"Om! We will explain the Shiksha.\"&lt;br&gt;\n\"Sounds and accentuation, Quantity (of vowels) and the expression (of consonants),\"&lt;br&gt;\n\"Balancing (Saman) and connection (of sounds), So much about the study of Shiksha.\" || 1 |\nTaittiriya Upanishad 1.2, Shikshavalli, translated by Paul Deussen\"\".\nModern.\nAdvancements in phonetics after P\u0101\u1e47ini and his contemporaries were limited until the modern era, save some limited investigations by Greek and Roman grammarians. In the millennia between Indic grammarians and modern phonetics, the focus shifted from the difference between spoken and written language, which was the driving force behind P\u0101\u1e47ini's account, and began to focus on the physical properties of speech alone. Sustained interest in phonetics began again around 1800 CE with the term \"phonetics\" being first used in the present sense in 1841. With new developments in medicine and the development of audio and visual recording devices, phonetic insights were able to use and review new and more detailed data. This early period of modern phonetics included the development of an influential phonetic alphabet based on articulatory positions by Alexander Melville Bell. Known as visible speech, it gained prominence as a tool in the oral education of deaf children.\nBefore the widespread availability of audio recording equipment, phoneticians relied heavily on a tradition of practical phonetics to ensure that transcriptions and findings were able to be consistent across phoneticians. This training involved both ear training\u2014the recognition of speech sounds\u2014as well as production training\u2014the ability to produce sounds. Phoneticians were expected to learn to recognize by ear the various sounds on the International Phonetic Alphabet and the IPA still tests and certifies speakers on their ability to accurately produce the phonetic patterns of English (though they have discontinued this practice for other languages). As a revision of his visible speech method, Melville Bell developed a description of vowels by height and backness resulting in 9 cardinal vowels. As part of their training in practical phonetics, phoneticians were expected to learn to produce these cardinal vowels to anchor their perception and transcription of these phones during fieldwork. This approach was critiqued by Peter Ladefoged in the 1960s based on experimental evidence where he found that cardinal vowels were auditory rather than articulatory targets, challenging the claim that they represented articulatory anchors by which phoneticians could judge other articulations.\nProduction.\nLanguage production consists of several interdependent processes which transform a nonlinguistic message into a spoken or signed linguistic signal. Linguists debate whether the process of language production occurs in a series of stages (serial processing) or whether production processes occur in parallel. After identifying a message to be linguistically encoded, a speaker must select the individual words\u2014known as lexical items\u2014to represent that message in a process called lexical selection. The words are selected based on their meaning, which in linguistics is called semantic information. Lexical selection activates the word's lemma, which contains both semantic and grammatical information about the word.\nAfter an utterance has been planned, it then goes through phonological encoding. In this stage of language production, the mental representation of the words are assigned their phonological content as a sequence of phonemes to be produced. The phonemes are specified for articulatory features which denote particular goals such as closed lips or the tongue in a particular location. These phonemes are then coordinated into a sequence of muscle commands that can be sent to the muscles, and when these commands are executed properly the intended sounds are produced. Thus the process of production from message to sound can be summarized as the following sequence:\nPlace of articulation.\nSounds which are made by a full or partial constriction of the vocal tract are called consonants. Consonants are pronounced in the vocal tract, usually in the mouth, and the location of this constriction affects the resulting sound. Because of the close connection between the position of the tongue and the resulting sound, the place of articulation is an important concept in many subdisciplines of phonetics.\nSounds are partly categorized by the location of a constriction as well as the part of the body doing the constricting. For example, in English the words \"fought\" and \"thought\" are a minimal pair differing only in the organ making the construction rather than the location of the construction. The \"f\" in \"fought\" is a labiodental articulation made with the bottom lip against the teeth. The \"th\" in \"thought\" is a linguodental articulation made with the tongue against the teeth. Constrictions made by the lips are called labials while those made with the tongue are called lingual.\nConstrictions made with the tongue can be made in several parts of the vocal tract, broadly classified into coronal, dorsal and radical places of articulation. Coronal articulations are made with the front of the tongue, dorsal articulations are made with the back of the tongue, and radical articulations are made in the pharynx. These divisions are not sufficient for distinguishing and describing all speech sounds. For example, in English the sounds and are both coronal, but they are produced in different places of the mouth. To account for this, more detailed places of articulation are needed based upon the area of the mouth in which the constriction occurs.\nLabial.\nArticulations involving the lips can be made in three different ways: with both lips (bilabial), with one lip and the teeth, so they have the lower lip as the active articulator and the upper teeth as the passive articulator (labiodental), and with the tongue and the upper lip (linguolabial). Depending on the definition used, some or all of these kinds of articulations may be categorized into the class of labial articulations. Bilabial consonants are made with both lips. In producing these sounds the lower lip moves farthest to meet the upper lip, which also moves down slightly, though in some cases the force from air moving through the aperture (opening between the lips) may cause the lips to separate faster than they can come together. Unlike most other articulations, both articulators are made from soft tissue, and so bilabial stops are more likely to be produced with incomplete closures than articulations involving hard surfaces like the teeth or palate. Bilabial stops are also unusual in that an articulator in the upper section of the vocal tract actively moves downward, as the upper lip shows some active downward movement. Linguolabial consonants are made with the blade of the tongue approaching or contacting the upper lip. Like in bilabial articulations, the upper lip moves slightly towards the more active articulator. Articulations in this group do not have their own symbols in the International Phonetic Alphabet, rather, they are formed by combining an apical symbol with a diacritic implicitly placing them in the coronal category. They exist in a number of languages indigenous to Vanuatu such as Tangoa.\nLabiodental consonants are made by the lower lip rising to the upper teeth. Labiodental consonants are most often fricatives while labiodental nasals are also typologically common. There is debate as to whether true labiodental plosives occur in any natural language, though a number of languages are reported to have labiodental plosives including Zulu, Tonga, and Shubi.\nCoronal.\nCoronal consonants are made with the tip or blade of the tongue and, because of the agility of the front of the tongue, represent a variety not only in place but in the posture of the tongue. The coronal places of articulation represent the areas of the mouth where the tongue contacts or makes a constriction, and include dental, alveolar, and post-alveolar locations. Tongue postures using the tip of the tongue can be apical if using the top of the tongue tip, laminal if made with the blade of the tongue, or sub-apical if the tongue tip is curled back and the bottom of the tongue is used. Coronals are unique as a group in that every manner of articulation is attested. Australian languages are well known for the large number of coronal contrasts exhibited within and across languages in the region. Dental consonants are made with the tip or blade of the tongue and the upper teeth. They are divided into two groups based upon the part of the tongue used to produce them: apical dental consonants are produced with the tongue tip touching the teeth; interdental consonants are produced with the blade of the tongue as the tip of the tongue sticks out in front of the teeth. No language is known to use both contrastively though they may exist allophonically. Alveolar consonants are made with the tip or blade of the tongue at the alveolar ridge just behind the teeth and can similarly be apical or laminal.\nCrosslinguistically, dental consonants and alveolar consonants are frequently contrasted leading to a number of generalizations of crosslinguistic patterns. The different places of articulation tend to also be contrasted in the part of the tongue used to produce them: most languages with dental stops have laminal dentals, while languages with apical stops usually have apical stops. Languages rarely have two consonants in the same place with a contrast in laminality, though Taa (\u01c3X\u00f3\u00f5) is a counterexample to this pattern. If a language has only one of a dental stop or an alveolar stop, it will usually be laminal if it is a dental stop, and the stop will usually be apical if it is an alveolar stop, though for example Temne and Bulgarian do not follow this pattern. If a language has both an apical and laminal stop, then the laminal stop is more likely to be affricated like in Isoko, though Dahalo show the opposite pattern with alveolar stops being more affricated.\nRetroflex consonants have several different definitions depending on whether the position of the tongue or the position on the roof of the mouth is given prominence. In general, they represent a group of articulations in which the tip of the tongue is curled upwards to some degree. In this way, retroflex articulations can occur in several different locations on the roof of the mouth including alveolar, post-alveolar, and palatal regions. If the underside of the tongue tip makes contact with the roof of the mouth, it is sub-apical though apical post-alveolar sounds are also described as retroflex. Typical examples of sub-apical retroflex stops are commonly found in Dravidian languages, and in some languages indigenous to the southwest United States the contrastive difference between dental and alveolar stops is a slight retroflexion of the alveolar stop. Acoustically, retroflexion tends to affect the higher formants.\nArticulations taking place just behind the alveolar ridge, known as post-alveolar consonants, have been referred to using a number of different terms. Apical post-alveolar consonants are often called retroflex, while laminal articulations are sometimes called palato-alveolar; in the Australianist literature, these laminal stops are often described as 'palatal' though they are produced further forward than the palate region typically described as palatal. Because of individual anatomical variation, the precise articulation of palato-alveolar stops (and coronals in general) can vary widely within a speech community.\nDorsal.\nDorsal consonants are those consonants made using the tongue body rather than the tip or blade and are typically produced at the palate, velum or uvula. Palatal consonants are made using the tongue body against the hard palate on the roof of the mouth. They are frequently contrasted with velar or uvular consonants, though it is rare for a language to contrast all three simultaneously, with Jaqaru as a possible example of a three-way contrast. Velar consonants are made using the tongue body against the velum. They are incredibly common cross-linguistically; almost all languages have a velar stop. Because both velars and vowels are made using the tongue body, they are highly affected by coarticulation with vowels and can be produced as far forward as the hard palate or as far back as the uvula. These variations are typically divided into front, central, and back velars in parallel with the vowel space. They can be hard to distinguish phonetically from palatal consonants, though are produced slightly behind the area of prototypical palatal consonants. Uvular consonants are made by the tongue body contacting or approaching the uvula. They are rare, occurring in an estimated 19 percent of languages, and large regions of the Americas and Africa have no languages with uvular consonants. In languages with uvular consonants, stops are most frequent followed by continuants (including nasals).\nPharyngeal and laryngeal.\nConsonants made by constrictions of the throat are pharyngeals, and those made by a constriction in the larynx are laryngeal. Laryngeals are made using the vocal folds as the larynx is too far down the throat to reach with the tongue. Pharyngeals however are close enough to the mouth that parts of the tongue can reach them.\nRadical consonants either use the root of the tongue or the epiglottis during production and are produced very far back in the vocal tract. Pharyngeal consonants are made by retracting the root of the tongue far enough to almost touch the wall of the pharynx. Due to production difficulties, only fricatives and approximants can be produced this way. Epiglottal consonants are made with the epiglottis and the back wall of the pharynx. Epiglottal stops have been recorded in Dahalo. Voiced epiglottal consonants are not deemed possible due to the cavity between the glottis and epiglottis being too small to permit voicing.\nGlottal consonants are those produced using the vocal folds in the larynx. Because the vocal folds are the source of phonation and below the oro-nasal vocal tract, a number of glottal consonants are impossible such as a voiced glottal stop. Three glottal consonants are possible, a voiceless glottal stop and two glottal fricatives, and all are attested in natural languages. Glottal stops, produced by closing the vocal folds, are notably common in the world's languages. While many languages use them to demarcate phrase boundaries, some languages like Arabic and Huatla Mazatec have them as contrastive phonemes. Additionally, glottal stops can be realized as laryngealization of the following vowel in this language. Glottal stops, especially between vowels, do usually not form a complete closure. True glottal stops normally occur only when they are geminated.\nThe larynx.\nThe larynx, commonly known as the \"voice box\", is a cartilaginous structure in the trachea responsible for phonation. The vocal folds (chords) are held together so that they vibrate, or held apart so that they do not. The positions of the vocal folds are achieved by movement of the arytenoid cartilages. The intrinsic laryngeal muscles are responsible for moving the arytenoid cartilages as well as modulating the tension of the vocal folds. If the vocal folds are not close or tense enough, they will either vibrate sporadically or not at all. If they vibrate sporadically it will result in either creaky or breathy voice, depending on the degree; if do not vibrate at all, the result will be voicelessness.\nIn addition to correctly positioning the vocal folds, there must also be air flowing across them or they will not vibrate. The difference in pressure across the glottis required for voicing is estimated at 1 \u2013 2 cm H2O (98.0665 \u2013 196.133 pascals). The pressure differential can fall below levels required for phonation either because of an increase in pressure above the glottis (superglottal pressure) or a decrease in pressure below the glottis (subglottal pressure). The subglottal pressure is maintained by the respiratory muscles. Supraglottal pressure, with no constrictions or articulations, is equal to about atmospheric pressure. However, because articulations\u2014especially consonants\u2014represent constrictions of the airflow, the pressure in the cavity behind those constrictions can increase resulting in a higher supraglottal pressure.\nLexical access.\nAccording to the lexical access model two different stages of cognition are employed; thus, this concept is known as the two-stage theory of lexical access. The first stage, lexical selection, provides information about lexical items required to construct the functional-level representation. These items are retrieved according to their specific semantic and syntactic properties, but phonological forms are not yet made available at this stage. The second stage, retrieval of wordforms, provides information required for building the positional level representation.\nArticulatory models.\nWhen producing speech, the articulators move through and contact particular locations in space resulting in changes to the acoustic signal. Some models of speech production take this as the basis for modeling articulation in a coordinate system that may be internal to the body (intrinsic) or external (extrinsic). Intrinsic coordinate systems model the movement of articulators as positions and angles of joints in the body. Intrinsic coordinate models of the jaw often use two to three degrees of freedom representing translation and rotation. These face issues with modeling the tongue which, unlike joints of the jaw and arms, is a muscular hydrostat\u2014like an elephant trunk\u2014which lacks joints. Because of the different physiological structures, movement paths of the jaw are relatively straight lines during speech and mastication, while movements of the tongue follow curves.\nStraight-line movements have been used to argue articulations as planned in extrinsic rather than intrinsic space, though extrinsic coordinate systems also include acoustic coordinate spaces, not just physical coordinate spaces. Models that assume movements are planned in extrinsic space run into an inverse problem of explaining the muscle and joint locations which produce the observed path or acoustic signal. The arm, for example, has seven degrees of freedom and 22 muscles, so multiple different joint and muscle configurations can lead to the same final position. For models of planning in extrinsic acoustic space, the same one-to-many mapping problem applies as well, with no unique mapping from physical or acoustic targets to the muscle movements required to achieve them. Concerns about the inverse problem may be exaggerated, however, as speech is a highly learned skill using neurological structures which evolved for the purpose.\nThe equilibrium-point model proposes a resolution to the inverse problem by arguing that movement targets be represented as the position of the muscle pairs acting on a joint. Importantly, muscles are modeled as springs, and the target is the equilibrium point for the modeled spring-mass system. By using springs, the equilibrium point model can easily account for compensation and response when movements are disrupted. They are considered a coordinate model because they assume that these muscle positions are represented as points in space, equilibrium points, where the spring-like action of the muscles converges.\nGestural approaches to speech production propose that articulations are represented as movement patterns rather than particular coordinates to hit. The minimal unit is a gesture that represents a group of \"functionally equivalent articulatory movement patterns that are actively controlled with reference to a given speech-relevant goal (e.g., a bilabial closure).\" These groups represent coordinative structures or \"synergies\" which view movements not as individual muscle movements but as task-dependent groupings of muscles which work together as a single unit. This reduces the degrees of freedom in articulation planning, a problem especially in intrinsic coordinate models, which allows for any movement that achieves the speech goal, rather than encoding the particular movements in the abstract representation. Coarticulation is well described by gestural models as the articulations at faster speech rates can be explained as composites of the independent gestures at slower speech rates.\nAcoustics.\nSpeech sounds are created by the modification of an airstream which results in a sound wave. The modification is done by the articulators, with different places and manners of articulation producing different acoustic results. Because the posture of the vocal tract, not just the position of the tongue can affect the resulting sound, the manner of articulation is important for describing the speech sound. The words \"tack\" and \"sack\" both begin with alveolar sounds in English, but differ in how far the tongue is from the alveolar ridge. This difference has large effects on the air stream and thus the sound that is produced. Similarly, the direction and source of the airstream can affect the sound. The most common airstream mechanism is pulmonic\u2014using the lungs\u2014but the glottis and tongue can also be used to produce airstreams.\nVoicing and phonation types.\nA major distinction between speech sounds is whether they are voiced. Sounds are voiced when the vocal folds begin to vibrate in the process of phonation. Many sounds can be produced with or without phonation, though physical constraints may make phonation difficult or impossible for some articulations. When articulations are voiced, the main source of noise is the periodic vibration of the vocal folds. Articulations like voiceless plosives have no acoustic source and are noticeable by their silence, but other voiceless sounds like fricatives create their own acoustic source regardless of phonation.\nPhonation is controlled by the muscles of the larynx, and languages make use of more acoustic detail than binary voicing. During phonation, the vocal folds vibrate at a certain rate. This vibration results in a periodic acoustic waveform comprising a fundamental frequency and its harmonics. The fundamental frequency of the acoustic wave can be controlled by adjusting the muscles of the larynx, and listeners perceive this fundamental frequency as pitch. Languages use pitch manipulation to convey lexical information in tonal languages, and many languages use pitch to mark prosodic or pragmatic information.\nFor the vocal folds to vibrate, they must be in the proper position and there must be air flowing through the glottis. Phonation types are modeled on a continuum of glottal states from completely open (voiceless) to completely closed (glottal stop). The optimal position for vibration, and the phonation type most used in speech, modal voice, exists in the middle of these two extremes. If the glottis is slightly wider, breathy voice occurs, while bringing the vocal folds closer together results in creaky voice.\nThe normal phonation pattern used in typical speech is modal voice, where the vocal folds are held close together with moderate tension. The vocal folds vibrate as a single unit periodically and efficiently with a full glottal closure and no aspiration. If they are pulled farther apart, they do not vibrate and so produce voiceless phones. If they are held firmly together they produce a glottal stop.\nIf the vocal folds are held slightly further apart than in modal voicing, they produce phonation types like breathy voice (or murmur) and whispery voice. The tension across the vocal ligaments (vocal cords) is less than in modal voicing allowing for air to flow more freely. Both breathy voice and whispery voice exist on a continuum loosely characterized as going from the more periodic waveform of breathy voice to the more noisy waveform of whispery voice. Acoustically, both tend to dampen the first formant with whispery voice showing more extreme deviations.\nHolding the vocal folds more tightly together results in a creaky voice. The tension across the vocal folds is less than in modal voice, but they are held tightly together resulting in only the ligaments of the vocal folds vibrating. The pulses are highly irregular, with low pitch and frequency amplitude.\nSome languages do not maintain a voicing distinction for some consonants, but all languages use voicing to some degree. For example, no language is known to have a phonemic voicing contrast for vowels with all known vowels canonically voiced. Other positions of the glottis, such as breathy and creaky voice, are used in a number of languages, like Jalapa Mazatec, to contrast phonemes while in other languages, like English, they exist allophonically.\nThere are several ways to determine if a segment is voiced or not, the simplest being to feel the larynx during speech and note when vibrations are felt. More precise measurements can be obtained through acoustic analysis of a spectrogram or spectral slice. In a spectrographic analysis, voiced segments show a voicing bar, a region of high acoustic energy, in the low frequencies of voiced segments. In examining a spectral splice, the acoustic spectrum at a given point in time a model of the vowel pronounced reverses the filtering of the mouth producing the spectrum of the glottis. A computational model of the unfiltered glottal signal is then fitted to the inverse filtered acoustic signal to determine the characteristics of the glottis. Visual analysis is also available using specialized medical equipment such as ultrasound and endoscopy.\nVowels.\n&lt;templatestyles src=\"IPA common/styles.css\" /&gt;\nVowels are broadly categorized by the area of the mouth in which they are produced, but because they are produced without a constriction in the vocal tract their precise description relies on measuring acoustic correlates of tongue position. The location of the tongue during vowel production changes the frequencies at which the cavity resonates, and it is these resonances\u2014known as formants\u2014which are measured and used to characterize vowels.\nVowel height traditionally refers to the highest point of the tongue during articulation. The height parameter is divided into four primary levels: high (close), close-mid, open-mid, and low (open). Vowels whose height are in the middle are referred to as mid. Slightly opened close vowels and slightly closed open vowels are referred to as near-close and near-open respectively. The lowest vowels are not just articulated with a lowered tongue, but also by lowering the jaw.\nWhile the IPA implies that there are seven levels of vowel height, it is unlikely that a given language can minimally contrast all seven levels. Chomsky and Halle suggest that there are only three levels, although four levels of vowel height seem to be needed to describe Danish and it is possible that some languages might even need five.\nVowel backness is dividing into three levels: front, central and back. Languages usually do not minimally contrast more than two levels of vowel backness. Some languages claimed to have a three-way backness distinction include Nimboran and Norwegian.\nIn most languages, the lips during vowel production can be classified as either rounded or unrounded (spread), although other types of lip positions, such as compression and protrusion, have been described. Lip position is correlated with height and backness: front and low vowels tend to be unrounded whereas back and high vowels are usually rounded. Paired vowels on the IPA chart have the spread vowel on the left and the rounded vowel on the right.\nTogether with the universal vowel features described above, some languages have additional features such as nasality, length and different types of phonation such as voiceless or creaky. Sometimes more specialized tongue gestures such as rhoticity, advanced tongue root, pharyngealization, stridency and frication are required to describe a certain vowel.\nManner of articulation.\nKnowing the place of articulation is not enough to fully describe a consonant, the way in which the stricture happens is equally important. Manners of articulation describe how exactly the active articulator modifies, narrows or closes off the vocal tract.\nStops (also referred to as plosives) are consonants where the airstream is completely obstructed. Pressure builds up in the mouth during the stricture, which is then released as a small burst of sound when the articulators move apart. The velum is raised so that air cannot flow through the nasal cavity. If the velum is lowered and allows for air to flow through the nose, the result in a nasal stop. However, phoneticians almost always refer to nasal stops as just \"nasals\". Affricates are a sequence of stops followed by a fricative in the same place.\nFricatives are consonants where the airstream is made turbulent by partially, but not completely, obstructing part of the vocal tract. Sibilants are a special type of fricative where the turbulent airstream is directed towards the teeth, creating a high-pitched hissing sound.\nNasals (sometimes referred to as nasal stops) are consonants in which there's a closure in the oral cavity and the velum is lowered, allowing air to flow through the nose.\nIn an approximant, the articulators come close together, but not to such an extent that allows a turbulent airstream.\nLaterals are consonants in which the airstream is obstructed along the center of the vocal tract, allowing the airstream to flow freely on one or both sides. Laterals have also been defined as consonants in which the tongue is contracted in such a way that the airstream is greater around the sides than over the center of the tongue. The first definition does not allow for air to flow over the tongue.\nTrills are consonants in which the tongue or lips are set in motion by the airstream. The stricture is formed in such a way that the airstream causes a repeating pattern of opening and closing of the soft articulator(s). Apical trills typically consist of two or three periods of vibration.\nTaps and flaps are single, rapid, usually apical gestures where the tongue is thrown against the roof of the mouth, comparable to a very rapid stop. These terms are sometimes used interchangeably, but some phoneticians make a distinction. In a tap, the tongue contacts the roof in a single motion whereas in a flap the tongue moves tangentially to the roof of the mouth, striking it in passing.\nDuring a glottalic airstream mechanism, the glottis is closed, trapping a body of air. This allows for the remaining air in the vocal tract to be moved separately. An upward movement of the closed glottis will move this air out, resulting in it an ejective consonant. Alternatively, the glottis can lower, sucking more air into the mouth, which results in an implosive consonant.\nClicks are stops in which tongue movement causes air to be sucked in the mouth, this is referred to as a velaric airstream. During the click, the air becomes rarefied between two articulatory closures, producing a loud 'click' sound when the anterior closure is released. The release of the anterior closure is referred to as the click influx. The release of the posterior closure, which can be velar or uvular, is the click efflux. Clicks are used in several African language families, such as the Khoisan and Bantu languages.\nPulmonary and subglottal system.\nThe lungs drive nearly all speech production, and their importance in phonetics is due to their creation of pressure for pulmonic sounds. The most common kinds of sound across languages are pulmonic egress, where air is exhaled from the lungs. The opposite is possible, though no language is known to have pulmonic ingressive sounds as phonemes. Many languages such as Swedish use them for paralinguistic articulations such as affirmations in a number of genetically and geographically diverse languages. Both egressive and ingressive sounds rely on holding the vocal folds in a particular posture and using the lungs to draw air across the vocal folds so that they either vibrate (voiced) or do not vibrate (voiceless). Pulmonic articulations are restricted by the volume of air able to be exhaled in a given respiratory cycle, known as the vital capacity.\nThe lungs are used to maintain two kinds of pressure simultaneously to produce and modify phonation. To produce phonation at all, the lungs must maintain a pressure of 3\u20135\u00a0cm H2O higher than the pressure above the glottis. However small and fast adjustments are made to the subglottal pressure to modify speech for suprasegmental features like stress. A number of thoracic muscles are used to make these adjustments. Because the lungs and thorax stretch during inhalation, the elastic forces of the lungs alone can produce pressure differentials sufficient for phonation at lung volumes above 50 percent of vital capacity. Above 50 percent of vital capacity, the respiratory muscles are used to \"check\" the elastic forces of the thorax to maintain a stable pressure differential. Below that volume, they are used to increase the subglottal pressure by actively exhaling air.\nDuring speech, the respiratory cycle is modified to accommodate both linguistic and biological needs. Exhalation, usually about 60 percent of the respiratory cycle at rest, is increased to about 90 percent of the respiratory cycle. Because metabolic needs are relatively stable, the total volume of air moved in most cases of speech remains about the same as quiet tidal breathing. Increases in speech intensity of 18\u00a0dB (a loud conversation) has relatively little impact on the volume of air moved. Because their respiratory systems are not as developed as adults, children tend to use a larger proportion of their vital capacity compared to adults, with more deep inhales.\nSource\u2013filter theory.\nThe source\u2013filter model of speech is a theory of speech production which explains the link between vocal tract posture and the acoustic consequences. Under this model, the vocal tract can be modeled as a noise source coupled onto an acoustic filter. The noise source in many cases is the larynx during the process of voicing, though other noise sources can be modeled in the same way. The shape of the supraglottal vocal tract acts as the filter, and different configurations of the articulators result in different acoustic patterns. These changes are predictable. The vocal tract can be modeled as a sequence of tubes, closed at one end, with varying diameters, and by using equations for acoustic resonance the acoustic effect of an articulatory posture can be derived. The process of inverse filtering uses this principle to analyze the source spectrum produced by the vocal folds during voicing. By taking the inverse of a predicted filter, the acoustic effect of the supraglottal vocal tract can be undone giving the acoustic spectrum produced by the vocal folds. This allows quantitative study of the various phonation types.\nPerception.\nLanguage perception is the process by which a linguistic signal is decoded and understood by a listener. To perceive speech, the continuous acoustic signal must be converted into discrete linguistic units such as phonemes, morphemes, and words. To correctly identify and categorize sounds, listeners prioritize certain aspects of the signal that can reliably distinguish between linguistic categories. While certain cues are prioritized over others, many aspects of the signal can contribute to perception. For example, though oral languages prioritize acoustic information, the McGurk effect shows that visual information is used to distinguish ambiguous information when the acoustic cues are unreliable.\nWhile listeners can use a variety of information to segment the speech signal, the relationship between acoustic signal and category perception is not a perfect mapping. Because of coarticulation, noisy environments, and individual differences, there is a high degree of acoustic variability within categories. Known as the problem of perceptual invariance, listeners are able to reliably perceive categories despite the variability in acoustic instantiation. To do this, listeners rapidly accommodate to new speakers and will shift their boundaries between categories to match the acoustic distinctions their conversational partner is making.\nAudition.\nAudition, the process of hearing sounds, is the first stage of perceiving speech. Articulators cause systematic changes in air pressure which travel as sound waves to the listener's ear. The sound waves then hit the listener's ear drum causing it to vibrate. The vibration of the ear drum is transmitted by the ossicles\u2014three small bones of the middle ear\u2014to the cochlea. The cochlea is a spiral-shaped, fluid-filled tube divided lengthwise by the organ of Corti which contains the basilar membrane. The basilar membrane increases in thickness as it travels through the cochlea causing different frequencies to resonate at different locations. This tonotopic design allows for the ear to analyze sound in a manner similar to a Fourier transform.\nThe differential vibration of the basilar causes the hair cells within the organ of Corti to move. This causes depolarization of the hair cells and ultimately a conversion of the acoustic signal into a neuronal signal. While the hair cells do not produce action potentials themselves, they release neurotransmitter at synapses with the fibers of the auditory nerve, which does produce action potentials. In this way, the patterns of oscillations on the basilar membrane are converted to spatiotemporal patterns of firings which transmit information about the sound to the brainstem.\nProsody.\nBesides consonants and vowels, phonetics also describes the properties of speech that are not localized to segments but greater units of speech, such as syllables and phrases. Prosody includes auditory characteristics such as pitch, speech rate, duration, and loudness. Languages use these properties to different degrees to implement stress, pitch accents, and intonation \u2014 for example, stress in English and Spanish is correlated with changes in pitch and duration, whereas stress in Welsh is more consistently correlated with pitch than duration and stress in Thai is only correlated with duration.\nTheories of speech perception.\nEarly theories of speech perception such as motor theory attempted to solve the problem of perceptual invariance by arguing that speech perception and production were closely linked. In its strongest form, motor theory argues that speech perception \"requires\" the listener to access the articulatory representation of sounds; to properly categorize a sound, a listener reverse engineers the articulation which would produce that sound and by identifying these gestures is able to retrieve the intended linguistic category. While findings such as the McGurk effect and case studies from patients with neurological injuries have provided support for motor theory, further experiments have not supported the strong form of motor theory, though there is some support for weaker forms of motor theory which claim a non-deterministic relationship between production and perception.\nSuccessor theories of speech perception place the focus on acoustic cues to sound categories and can be grouped into two broad categories: abstractionist theories and episodic theories. In abstractionist theories, speech perception involves the identification of an idealized lexical object based on a signal reduced to its necessary components and normalizing the signal to counteract speaker variability. Episodic theories such as the exemplar model argue that speech perception involves accessing detailed memories (i.e., episodic memories) of previously heard tokens. The problem of perceptual invariance is explained by episodic theories as an issue of familiarity: normalization is a byproduct of exposure to more variable distributions rather than a discrete process as abstractionist theories claim.\nSubdisciplines.\nAcoustic phonetics.\nAcoustic phonetics deals with the acoustic properties of speech sounds. The sensation of sound is caused by pressure fluctuations which cause the eardrum to move. The ear transforms this movement into neural signals that the brain registers as sound. Acoustic waveforms are records that measure these pressure fluctuations.\nArticulatory phonetics.\nArticulatory phonetics deals with the ways in which speech sounds are made.\nAuditory phonetics.\nAuditory phonetics studies how humans perceive speech sounds. Due to the anatomical features of the auditory system distorting the speech signal, humans do not experience speech sounds as perfect acoustic records. For example, the auditory impressions of volume, measured in decibels (dB), does not linearly match the difference in sound pressure.\nThe mismatch between acoustic analyses and what the listener hears is especially noticeable in speech sounds that have a lot of high-frequency energy, such as certain fricatives. To reconcile this mismatch, functional models of the auditory system have been developed.\nDescribing sounds.\nHuman languages use many different sounds and to compare them linguists must be able to describe sounds in a way that is language independent. Speech sounds can be described in a number of ways. Most commonly speech sounds are referred to by the mouth movements needed to produce them. Consonants and vowels are two gross categories that phoneticians define by the movements in a speech sound. More fine-grained descriptors are parameters such as place of articulation. Place of articulation, manner of articulation, and voicing are used to describe consonants and are the main divisions of the International Phonetic Alphabet consonant chart. Vowels are described by their height, backness, and rounding. Sign language are described using a similar but distinct set of parameters to describe signs: location, movement, hand shape, palm orientation, and non-manual features. In addition to articulatory descriptions, sounds used in oral languages can be described using their acoustics. Because the acoustics are a consequence of the articulation, both methods of description are sufficient to distinguish sounds with the choice between systems dependent on the phonetic feature being investigated.\nConsonants are speech sounds that are articulated with a complete or partial closure of the vocal tract. They are generally produced by the modification of an airstream exhaled from the lungs. The respiratory organs used to create and modify airflow are divided into three regions: the vocal tract (supralaryngeal), the larynx, and the subglottal system. The airstream can be either egressive (out of the vocal tract) or ingressive (into the vocal tract). In pulmonic sounds, the airstream is produced by the lungs in the subglottal system and passes through the larynx and vocal tract. Glottalic sounds use an airstream created by movements of the larynx without airflow from the lungs. Click consonants are articulated through the rarefaction of air using the tongue, followed by releasing the forward closure of the tongue.\nVowels are syllabic speech sounds that are pronounced without any obstruction in the vocal tract. Unlike consonants, which usually have definite places of articulation, vowels are defined in relation to a set of reference vowels called cardinal vowels. Three properties are needed to define vowels: tongue height, tongue backness, and lip roundedness. Vowels that are articulated with a stable quality are called monophthongs; a combination of two separate vowels in the same syllable is a diphthong. In the IPA, the vowels are represented on a trapezoid shape representing the human mouth: the vertical axis representing the mouth from floor to roof and the horizontal axis represents the front-back dimension.\nTranscription.\nPhonetic transcription is a system for transcribing phones that occur in a language, whether oral or sign. The most widely known system of phonetic transcription, the International Phonetic Alphabet (IPA), provides a standardized set of symbols for oral phones. The standardized nature of the IPA enables its users to transcribe accurately and consistently the phones of different languages, dialects, and idiolects. The IPA is a useful tool not only for the study of phonetics but also for language teaching, professional acting, and speech pathology.\nWhile no sign language has a standardized writing system, linguists have developed their own notation systems that describe the handshape, location and movement. The Hamburg Notation System (HamNoSys) is similar to the IPA in that it allows for varying levels of detail. Some notation systems such as KOMVA and the Stokoe system were designed for use in dictionaries; they also make use of alphabetic letters in the local language for handshapes whereas HamNoSys represents the handshape directly. SignWriting aims to be an easy-to-learn writing system for sign languages, although it has not been officially adopted by any deaf community yet.\nSign languages.\nUnlike spoken languages, words in sign languages are perceived with the eyes instead of the ears. Signs are articulated with the hands, upper body and head. The main articulators are the hands and arms. Relative parts of the arm are described with the terms proximal and distal. Proximal refers to a part closer to the torso whereas a distal part is further away from it. For example, a wrist movement is distal compared to an elbow movement. Due to requiring less energy, distal movements are generally easier to produce. Various factors \u2013 such as muscle flexibility and being considered taboo \u2013 restrict what can be considered a sign. Native signers do not look at their conversation partner's hands. Instead, their gaze is fixated on the face. Because peripheral vision is not as focused as the center of the visual field, signs articulated near the face allow for more subtle differences in finger movement and location to be perceived.\nUnlike spoken languages, sign languages have two identical articulators: the hands. Signers may use whichever hand they prefer with no disruption in communication. Due to universal neurological limitations, two-handed signs generally have the same kind of articulation in both hands; this is referred to as the Symmetry Condition. The second universal constraint is the Dominance Condition, which holds that when two handshapes are involved, one hand will remain stationary and have a more limited set of handshapes compared to the dominant, moving hand. Additionally, it is common for one hand in a two-handed sign to be dropped during informal conversations, a process referred to as weak drop. Just like words in spoken languages, coarticulation may cause signs to influence each other's form. Examples include the handshapes of neighboring signs becoming more similar to each other (assimilation) or weak drop (an instance of deletion).\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "23195", "revid": "37664675", "url": "https://en.wikipedia.org/wiki?curid=23195", "title": "Petroleum", "text": "Naturally occurring combustible liquid\nPetroleum, also known as crude oil or simply oil, is a naturally occurring, yellowish-black liquid chemical mixture found in geological formations, consisting mainly of hydrocarbons. The term \"petroleum\" refers both to naturally occurring unprocessed crude oil, as well as to petroleum products that consist of refined crude oil.\nPetroleum is a fossil fuel formed over millions of years from anaerobic decay of organic materials from buried prehistoric organisms, particularly planktons and algae. It is estimated that 70% of the world's oil deposits were formed during the Mesozoic, 20% were formed in the Cenozoic, and only 10% were formed in the Paleozoic. Conventional reserves of petroleum are primarily recovered by drilling, which is done after a study of the relevant structural geology, analysis of the sedimentary basin, and characterization of the petroleum reservoir. There are also unconventional reserves such as oil sands and oil shale which are recovered by other means such as fracking.\nOnce extracted, oil is refined and separated, most easily by distillation, into innumerable products for direct use or use in manufacturing. Petroleum products include fuels such as gasoline (petrol), diesel, kerosene and jet fuel; bitumen, paraffin wax and lubricants; reagents used to make plastics; solvents, textiles, refrigerants, paint, synthetic rubber, fertilizers, pesticides, pharmaceuticals, and thousands of other petrochemicals. Petroleum is used in manufacturing a vast variety of materials essential for modern life, and it is estimated that the world consumes about each day. Petroleum production played a key role in industrialization and economic development, especially after the Second Industrial Revolution. Some petroleum-rich countries, known as petrostates, gained significant economic and international influence during the latter half of the 20th century due to their control of oil production and trade.\nPetroleum is a non-renewable resource, and exploitation is damaging to both the natural environment, climate system and human health (see Health and environmental impact of the petroleum industry). Extraction, refining and burning of petroleum fuels reverse the carbon sink and release large quantities of greenhouse gases back into the Earth's atmosphere, so petroleum is one of the major contributors to anthropogenic climate change. Other negative environmental effects include direct releases, such as oil spills, as well as air and water pollution at almost all stages of use. Oil access and pricing have also been a source of domestic and geopolitical conflicts, leading to state-sanctioned oil wars, diplomatic and trade frictions, energy policy disputes and other resource conflicts. Production of petroleum is estimated to reach peak oil before 2035 as global economies lower dependencies on petroleum as part of climate change mitigation and a transition toward more renewable energy and electrification.\nEtymology.\nThe word \"petroleum\" comes from Medieval Latin (literally 'rock oil'), which comes from Latin petra 'rock' (from Greek ) and oleum 'oil' (from Greek ).\nThe origin of the term stems from monasteries in southern Italy where it was in use by the end of the first millennium as an alternative for the older term \"naphtha\". After that, the term was used in numerous manuscripts and books, such as in the treatise \"De Natura Fossilium\", published in 1546 by the German mineralogist Georg Bauer, also known as Georgius Agricola. After the advent of the oil industry, during the second half of the 19th century, the term became commonly known for the liquid form of hydrocarbons.\nHistory.\nEarly.\nPetroleum, in one form or another, has been used since ancient times. More than 4300 years ago, bitumen was mentioned when the Sumerians used it to make boats. A tablet of the legend of the birth of Sargon of Akkad mentions a basket which was closed by straw and bitumen. More than 4000 years ago, according to Herodotus and Diodorus Siculus, asphalt was used in the construction of the walls and towers of Babylon; there were oil pits near Ardericca and Babylon, and a pitch spring on Zakynthos. Great quantities of it were found on the banks of the river Issus, one of the tributaries of the Euphrates. Ancient Persian tablets indicate the medicinal and lighting uses of petroleum in the upper levels of their society.\nThe use of petroleum in ancient China dates back to more than 2000 years ago. The \"I Ching\", one of the earliest Chinese writings, cites that oil in its raw state, without refining, was first discovered, extracted, and used in China in the first century BCE. In addition, the Chinese were the first to record the use of petroleum as fuel as early as the fourth century BCE. By 347 CE, oil was produced from bamboo-drilled wells in China.\nIn the 7th century, petroleum was among the essential ingredients for Greek fire, an incendiary projectile weapon that was used by Byzantine Greeks against Arab ships, which were then attacking Constantinople. Crude oil was also distilled by Persian chemists, with clear descriptions given in Arabic handbooks such as those of Abu Bakr al-Razi (Rhazes). The streets of Baghdad were paved with tar, derived from petroleum that became accessible from natural fields in the region.\nIn the 9th century, oil fields were exploited in the area around modern Baku, Azerbaijan. These fields were described by the Persian geographer Abu Bakr al-Razi in the 10th century, and by Marco Polo in the 13th century, who described the output of those wells as hundreds of shiploads. Arab and Persian chemists also distilled crude oil to produce flammable products for military purposes. Through Islamic Spain, distillation became available in Western Europe by the 12th century. It has also been present in Romania since the 13th century, being recorded as p\u0103cur\u0103.\nSophisticated oil pits, deep, were dug by the Seneca people and other Iroquois in Western Pennsylvania as early as 1415\u20131450. The French General Louis-Joseph de Montcalm encountered Seneca using petroleum for ceremonial fires and as a healing lotion during a visit to Fort Duquesne in 1750.\nEarly British explorers to Myanmar documented a flourishing oil extraction industry based in Yenangyaung that, in 1795, had hundreds of hand-dug wells under production.\nMerkwiller-Pechelbronn is said to be the first European site where petroleum has been explored and used. The still active Erdpechquelle, a spring where petroleum appears mixed with water has been used since 1498, notably for medical purposes.\n19th century.\nIn the mid-19th century, various parts of the world saw oil well developments, though the title of the \"first oil well\" depends on the criteria. In 1846, a group of Russian Imperial engineers directed by Major Alexeyev of the Bakinskii Corps of Mining Engineers accidentally struck oil while hand-drilling with a primitive percussion rig in Bibi-Heybat, near Baku (now Azerbaijan), though they were not specifically searching for oil.\nIn 1853, Ignacy \u0141ukasiewicz, who discovered how to distill kerosene from seep crude oil and invented the modern kerosene lamp, hand-dug the first intentional well for commercial oil extraction in B\u00f3brka, Poland to supply fuel for lighting (still operational as of 2025[ [update]]). In 1856 in Ulaszowice, near Jas\u0142o, he opened the world's first industrial oil refinery.\nA hand-dug well and another refinery followed in 1857 near Ploie\u0219ti, Romania. Romania (then a vassal of the Ottoman Empire) was the first country in the world to have its annual crude oil output officially recorded in international statistics \u2013 275 tonnes for 1857.\nIn 1859, Edwin Drake drilled the first steam-powered well in Titusville, Pennsylvania in the US, attracting investment and \"kick-starting\" the mass production and rapid expansion of the global petroleum industry. The same year, engine-drilled wells appeared also in West Virginia.\nIn 1858, Georg Christian Konrad Hun\u00e4us found a significant amount of petroleum while drilling for lignite in Wietze, Germany. Wietze later provided about 80% of German consumption in the Wilhelmine Era. The production stopped in 1963, but Wietze has hosted a Petroleum Museum since 1970.\nOil sands have been mined since the 18th century. In Wietze in lower Saxony, natural asphalt/bitumen has been explored since the 18th century. Both in Pechelbronn as in Wietze, the coal industry dominated the petroleum technologies.\nChemist James Young in 1847 noticed a natural petroleum seepage in the coal mine at riddings Alfreton, Derbyshire from which he distilled a light thin oil suitable for use as lamp oil, at the same time obtaining a more viscous oil suitable for lubricating machinery. In 1848, Young set up a small business refining crude oil.\nYoung eventually succeeded, by distilling cannel coal at low heat, in creating a fluid resembling petroleum, which when treated in the same way as the seep oil gave similar products. Young found that by slow distillation he could obtain several useful liquids from it, one of which he named \"paraffine oil\" because at low temperatures it congealed into a substance resembling paraffin wax.The production of these oils and solid paraffin wax from coal formed the subject of his patent dated October 17, 1850. In 1850, Young &amp; Meldrum and Edward William Binney entered into partnership under the title of E.W. Binney &amp; Co. at Bathgate in West Lothian and E. Meldrum &amp; Co. at Glasgow; their works at Bathgate were completed in 1851 and became the first truly commercial oil-works in the world with the first modern oil refinery.\nThe world's first oil refinery was built in 1856 by Ignacy \u0141ukasiewicz in Austria. His achievements also included the discovery of how to distill kerosene from seep oil, the invention of the modern kerosene lamp (1853), the introduction of the first modern street lamp in Europe (1853), and the construction of the world's first modern oil \"mine\" (1854). at B\u00f3brka, near Krosno (still operational as of 2025).\nThe demand for petroleum as a fuel for lighting in North America and around the world quickly grew.\nThe first oil well in the Americas was drilled in 1859 by Edwin Drake at what is now called the Drake Well in Cherrytree Township, Pennsylvania. There also was a company associated with it, and it sparked a major oil drilling boom.\nThe first commercial oil well in Canada became operational in 1858 at Oil Springs, Ontario (then Canada West). Businessman James Miller Williams dug several wells between 1855 and 1858 before discovering a rich reserve of oil four metres below ground. Williams extracted 1.5\u00a0million litres of crude oil by 1860, refining much of it into kerosene lamp oil. Williams's well became commercially viable a year before Drake's Pennsylvania operation and could be argued to be the first commercial oil well in North America. The discovery at Oil Springs touched off an oil boom which brought hundreds of speculators and workers to the area. Advances in drilling continued into 1862 when local driller Shaw reached a depth of 62 metres using the spring-pole drilling method. On January 16, 1862, after an explosion of natural gas, Canada's first oil gusher came into production, shooting into the air at a recorded rate of per day. By the end of the 19th century the Russian Empire, particularly the Branobel company in Azerbaijan, had taken the lead in production.\n20th century.\nAccess to oil was and still is a major factor in several military conflicts of the 20th century, including World War II, during which oil facilities were a major strategic asset and were extensively bombed. The German invasion of the Soviet Union included the goal to capture the Baku oilfields, as it would provide much-needed oil supplies for the German military which was suffering from blockades.\nOil exploration in North America during the early 20th century later led to the U.S. becoming the leading producer by mid-century. As petroleum production in the U.S. peaked during the 1960s, the United States was surpassed by Saudi Arabia and the Soviet Union in total output.\nIn the 1973 oil crisis, Saudi Arabia and other Arab nations imposed an oil embargo against the United States, United Kingdom, Japan and other Western nations which supported Israel in the Yom Kippur War of October 1973. The embargo caused an oil crisis. This was followed by the 1979 oil crisis, which was caused by a drop in oil production in the wake of the Iranian Revolution and caused oil prices to more than double.\n21st century.\nThe two oil price shocks had many short- and long-term effects on global politics and the global economy. They led to sustained reductions in demand as a result of substitution to other fuels, especially coal and nuclear, and improvements in energy efficiency, facilitated by government policies. High oil prices also induced investment in oil production by non-OPEC countries, including Prudhoe Bay in Alaska, the North Sea offshore fields of the United Kingdom and Norway, the Cantarell offshore field of Mexico, and oil sands in Canada.\nAbout 90 percent of vehicular fuel needs are met by oil. Petroleum also makes up 40 percent of total energy consumption in the United States, but is responsible for only one percent of electricity generation. Petroleum's worth as a portable, dense energy source powering the vast majority of vehicles and as the base of many industrial chemicals makes it one of the world's most important commodities.\nThe top three oil-producing countries as of 2018 are the United States, Russia, and Saudi Arabia. In 2018, due in part to developments in hydraulic fracturing and horizontal drilling, the United States became the world's largest producer.\nAbout 80 percent of the world's readily accessible reserves are located in the Middle East, with 62.5 percent coming from the Arab five: Saudi Arabia, United Arab Emirates, Iraq, Qatar, and Kuwait. A large portion of the world's total oil exists as unconventional sources, such as bitumen in Athabasca oil sands and extra heavy oil in the Orinoco Belt. While significant volumes of oil are extracted from oil sands, particularly in Canada, logistical and technical hurdles remain, as oil extraction requires large amounts of heat and water, making its net energy content quite low relative to conventional crude oil. Thus, Canada's oil sands are not expected to provide more than a few million barrels per day in the foreseeable future.\nComposition.\nPetroleum consists of a variety of liquid, gaseous, and solid components. Lighter hydrocarbons are the gases methane, ethane, propane and butane. Otherwise the bulk of the liquid and solids are largely heavier organic compounds, often hydrocarbons (C and H only). The proportion of light hydrocarbons in the petroleum mixture varies among oil fields.\nAn oil well produces predominantly crude oil. Because the pressure is lower at the surface than underground, some of the gas will come out of solution and be recovered (or burned) as \"associated gas\" or \"solution gas\". A gas well produces predominantly natural gas. However, because the underground temperature is higher than at the surface, the gas may contain heavier hydrocarbons such as pentane, hexane, and heptane (\"natural-gas condensate\", often shortened to \"condensate.\") Condensate resembles gasoline in appearance and is similar in composition to some volatile light crude oils.\nThe hydrocarbons in crude oil are mostly alkanes, cycloalkanes and various aromatic hydrocarbons, while the other organic compounds contain nitrogen, oxygen, and sulfur, and traces of metals such as iron, nickel, copper and vanadium. Many oil reservoirs contain live bacteria. The exact molecular composition of crude oil varies widely from formation to formation but the proportion of chemical elements varies over fairly narrow limits as follows:\nFour different types of hydrocarbon appear in crude oil. The relative percentage of each varies from oil to oil, determining the properties of each oil.\nThe alkanes from pentane (C5H12) to octane (C8H18) are refined into gasoline, the ones from nonane (C9H20) to hexadecane (C16H34) into diesel fuel, kerosene and jet fuel. Alkanes with more than 16 carbon atoms can be refined into fuel oil and lubricating oil. At the heavier end of the range, paraffin wax is an alkane with approximately 25 carbon atoms, while asphalt has 35 and up, although these are usually cracked in modern refineries into more valuable products. The lightest fraction, the so-called petroleum gases are subjected to diverse processing depending on cost. These gases are either flared off, sold as liquefied petroleum gas, or used to power the refinery's own burners. During the winter, butane (C4H10), is blended into the gasoline pool at high rates, because its high vapour pressure assists with cold starts.\nThe \"aromatic hydrocarbons\" are unsaturated hydrocarbons that have one or more benzene rings. They tend to burn with a sooty flame, and many have a sweet aroma. Some are carcinogenic.\nThese different components are separated by fractional distillation at an oil refinery to produce gasoline, jet fuel, kerosene, and other hydrocarbon fractions.\nThe components in an oil sample can be determined by gas chromatography and mass spectrometry. Due to the large number of co-eluted hydrocarbons within oil, many cannot be resolved by traditional gas chromatography. This unresolved complex mixture (UCM) of hydrocarbons is particularly apparent when analysing weathered oils and extracts from tissues of organisms exposed to oil.\nCrude oil varies greatly in appearance depending on its composition. It is usually black or dark brown (although it may be yellowish, reddish, or even greenish). In the reservoir it is usually found in association with natural gas, which being lighter forms a \"gas cap\" over the petroleum, and saline water which, being heavier than most forms of crude oil, generally sinks beneath it. Crude oil may also be found in a semi-solid form mixed with sand and water, as in the Athabasca oil sands in Canada, where it is usually referred to as crude bitumen. In Canada, bitumen is considered a sticky, black, tar-like form of crude oil which is so thick and heavy that it must be heated or diluted before it will flow. Venezuela also has large amounts of oil in the Orinoco oil sands, although the hydrocarbons trapped in them are more fluid than in Canada and are usually called extra heavy oil. These oil sands resources are called unconventional oil to distinguish them from oil which can be extracted using traditional oil well methods. Between them, Canada and Venezuela contain an estimated of bitumen and extra-heavy oil, about twice the volume of the world's reserves of conventional oil.\nFormation.\nFossil petroleum.\nPetroleum is a fossil fuel derived from fossilized organic materials, such as zooplankton and algae. Vast amounts of these remains settled to sea or lake bottoms where they were covered in stagnant water (water with no dissolved oxygen) or sediments such as mud and silt faster than they could decompose aerobically. Approximately 1 m below this sediment, water oxygen concentration was low, below 0.1\u00a0mg/L, and anoxic conditions existed. Temperatures also remained constant.\nAs further layers settled into the sea or lake bed, intense heat and pressure built up in the lower regions. This process caused the organic matter to change, first into a waxy material known as kerogen, found in various oil shales around the world, and then with more heat into liquid and gaseous hydrocarbons via a process known as catagenesis. Formation of petroleum occurs from hydrocarbon pyrolysis in a variety of mainly endothermic reactions at high temperatures or pressures, or both. These phases are described in detail below.\nAnaerobic decay.\nIn the absence of plentiful oxygen, \"aerobic\" bacteria were prevented from decaying the organic matter after it was buried under a layer of sediment or water. However, \"anaerobic\" bacteria were able to reduce sulfates and nitrates among the matter to H2S and N2 respectively by using the matter as a source for other reactants. Due to such anaerobic bacteria, at first, this matter began to break apart mostly via hydrolysis: polysaccharides and proteins were hydrolyzed to simple sugars and amino acids respectively. These were further anaerobically oxidized at an accelerated rate by the enzymes of the bacteria: e.g., proteins went through oxidative deamination to amino acids, which in turn reacted further to ammonia and \u03b1-keto acids. Monosaccharides in turn ultimately decayed to CO2 and methane. The anaerobic decay products of amino acids, monosaccharides, phenols and aldehydes combined into fulvic acids. Fats and waxes were not extensively hydrolyzed under these mild conditions.\nKerogen formation.\nSome phenolic compounds produced from previous reactions worked as bactericides and the Actinomycetales order of bacteria also produced antibiotic compounds (e.g., streptomycin). Thus the action of anaerobic bacteria ceased at about 10\u00a0m below the water or sediment. The mixture at this depth contained fulvic acids, unreacted and partially reacted fats and waxes, slightly modified lignin, resins and other hydrocarbons. As more layers of organic matter settled into the sea or lake bed, intense heat and pressure built up in the lower regions. As a consequence, compounds of this mixture began to combine in poorly understood ways to kerogen. Combination happened in a similar fashion as phenol and formaldehyde molecules react to urea-formaldehyde resins, but kerogen formation occurred in a more complex manner due to a bigger variety of reactants. The total process of kerogen formation from the beginning of anaerobic decay is called diagenesis, a word that means a transformation of materials by dissolution and recombination of their constituents.\nTransformation of kerogen into fossil fuels.\nKerogen formation continued to a depth of about 1 km from the Earth's surface where temperatures may reach around 50 \u00b0C. Kerogen formation represents a halfway point between organic matter and fossil fuels: kerogen can be exposed to oxygen, oxidize and thus be lost, or it could be buried deeper inside the Earth's crust and be subjected to conditions which allow it to slowly transform into fossil fuels like petroleum. The latter happened through catagenesis in which the reactions were mostly radical rearrangements of kerogen. These reactions took thousands to millions of years and no external reactants were involved. Due to the radical nature of these reactions, kerogen reacted towards two classes of products: those with low H/C ratio (anthracene or products similar to it) and those with high H/C ratio (methane or products similar to it); i.e., carbon-rich or hydrogen-rich products. Because catagenesis was closed off from external reactants, the resulting composition of the fuel mixture was dependent on the composition of the kerogen via reaction stoichiometry. Three types of kerogen exist: type I (algal), II (liptinic) and III (humic), which were formed mainly from algae, plankton and woody plants (this term includes trees, shrubs and lianas) respectively.\nCatagenesis was pyrolytic despite the fact that it happened at relatively low temperatures (when compared to commercial pyrolysis plants) of 60 to several hundred \u00b0C. Pyrolysis was possible because of the long reaction times involved. Heat for catagenesis came from the decomposition of radioactive materials of the crust, especially 40K, 232Th, 235U and 238U. The heat varied with geothermal gradient and was typically 10\u201330\u00a0\u00b0C per km of depth from the Earth's surface. Unusual magma intrusions, however, could have created greater localized heating.\nOil window (temperature range).\nGeologists often refer to the temperature range in which oil forms as an \"oil window\". Below the minimum temperature oil remains trapped in the form of kerogen. Above the maximum temperature the oil is converted to natural gas through the process of thermal cracking. Sometimes, oil formed at extreme depths may migrate and become trapped at a much shallower level. The Athabasca oil sands are one example of this.\nAbiogenic petroleum.\nAn alternative mechanism to the one described above was proposed by Russian scientists in the mid-1850s, the hypothesis of abiogenic petroleum origin (petroleum formed by inorganic means), but this is contradicted by geological and geochemical evidence. Abiogenic sources of oil have been found, but never in commercially profitable amounts. \"The controversy isn't over whether abiogenic oil reserves exist,\" said Larry Nation of the American Association of Petroleum Geologists. \"The controversy is over how much they contribute to Earth's overall reserves and how much time and effort geologists should devote to seeking them out.\"\nReservoirs.\nThree conditions must be present for oil reservoirs to form:\nWithin these reservoirs, fluids will typically organize themselves like a three-layer cake with a layer of water below the oil layer and a layer of gas above it, although the different layers vary in size between reservoirs. Because most hydrocarbons are less dense than rock or water, they often migrate upward through adjacent rock layers until either reaching the surface or becoming trapped within porous rocks (known as reservoirs) by impermeable rocks above. However, the process is influenced by underground water flows, causing oil to migrate hundreds of kilometres horizontally or even short distances downward before becoming trapped in a reservoir. When hydrocarbons are concentrated in a trap, an oil field forms, from which the liquid can be extracted by drilling and pumping.\nThe reactions that produce oil and natural gas are often modeled as first order breakdown reactions, where hydrocarbons are broken down to oil and natural gas by a set of parallel reactions, and oil eventually breaks down to natural gas by another set of reactions. The latter set is regularly used in petrochemical plants and oil refineries.\nPetroleum has mostly been recovered by oil drilling (natural petroleum springs are rare). Drilling is carried out after studies of structural geology (at the reservoir scale), sedimentary basin analysis, and reservoir characterisation (mainly in terms of the porosity and permeability of geologic reservoir structures). Wells are drilled into oil reservoirs to extract the crude oil. \"Natural lift\" production methods that rely on the natural reservoir pressure to force the oil to the surface are usually sufficient for a while after reservoirs are first tapped. In some reservoirs, such as in the Middle East, the natural pressure is sufficient over a long time. The natural pressure in most reservoirs, however, eventually dissipates. Then the oil must be extracted using \"artificial lift\" means. Over time, these \"primary\" methods become less effective and \"secondary\" production methods may be used. A common secondary method is \"waterflood\" or injection of water into the reservoir to increase pressure and force the oil to the drilled shaft or \"wellbore.\" Eventually \"tertiary\" or \"enhanced\" oil recovery methods may be used to increase the oil's flow characteristics by injecting steam, carbon dioxide and other gases or chemicals into the reservoir. In the United States, primary production methods account for less than 40 percent of the oil produced on a daily basis, secondary methods account for about half, and tertiary recovery the remaining 10 percent. Extracting oil (or \"bitumen\") from oil/tar sand and oil shale deposits requires mining the sand or shale and heating it in a vessel or retort, or using \"in-situ\" methods of injecting heated liquids into the deposit and then pumping the liquid back out saturated with oil.\nUnconventional oil reservoirs.\nOil-eating bacteria biodegrade oil that has escaped to the surface. Oil sands are reservoirs of partially biodegraded oil still in the process of escaping and being biodegraded, but they contain so much migrating oil that, although most of it has escaped, vast amounts are still present\u2014more than can be found in conventional oil reservoirs. The lighter fractions of the crude oil are destroyed first, resulting in reservoirs containing an extremely heavy form of crude oil, called crude bitumen in Canada, or extra-heavy crude oil in Venezuela. These two countries have the world's largest deposits of oil sands.\nOn the other hand, oil shales are source rocks that have not been exposed to heat or pressure long enough to convert their trapped hydrocarbons into crude oil. Technically speaking, oil shales are not always shales and do not contain oil, but are fined-grain sedimentary rocks containing an insoluble organic solid called kerogen. The kerogen in the rock can be converted into crude oil using heat and pressure to simulate natural processes. The method has been known for centuries and was patented in 1694 under British Crown Patent No. 330 covering, \"A way to extract and make great quantities of pitch, tar, and oil out of a sort of stone.\" Although oil shales are found in many countries, the United States has the world's largest deposits.\nClassification.\nThe petroleum industry generally classifies crude oil by the geographic location it is produced in (e.g., West Texas Intermediate, Brent, or Oman), its API gravity (an oil industry measure of density), and its sulfur content. Crude oil may be considered \"light\" if it has low density, \"heavy\" if it has high density, or \"medium\" if it has a density between that of \"light\" and \"heavy\". Additionally, it may be referred to as \"sweet\" if it contains relatively little sulfur or \"sour\" if it contains substantial amounts of sulfur.\nThe geographic location is important because it affects transportation costs to the refinery. \"Light\" crude oil is more desirable than \"heavy\" oil since it produces a higher yield of gasoline, while \"sweet\" oil commands a higher price than \"sour\" oil because it has fewer environmental problems and requires less refining to meet sulfur standards imposed on fuels in consuming countries. Each crude oil has unique molecular characteristics which are revealed by the use of crude oil assay analysis in petroleum laboratories.\nBarrels from an area in which the crude oil's molecular characteristics have been determined and the oil has been classified are used as pricing references throughout the world. Some of the common reference crudes are:\nThere are declining amounts of these benchmark oils being produced each year, so other oils are more commonly what is actually delivered. While the reference price may be for West Texas Intermediate delivered at Cushing, the actual oil being traded may be a discounted Canadian heavy oil \u2013 Western Canadian Select \u2013 delivered at Hardisty, Alberta, and for a Brent Blend delivered at Shetland, it may be a discounted Russian Export Blend delivered at the port of Primorsk.\nOnce extracted, oil is refined and separated, most easily by distillation, into numerous products for direct use or use in manufacturing, such as gasoline (petrol), diesel and kerosene to asphalt and chemical reagents (ethylene, propylene, butene, acrylic acid, para-xylene) used to make plastics, pesticides and pharmaceuticals.\nUse.\nIn terms of volume, most petroleum is converted into fuels for combustion engines. In terms of value, petroleum underpins the petrochemical industry, which includes many high value products such as pharmaceuticals and plastics.\nFuels and lubricants.\nPetroleum is used mostly, by volume, for refining into fuel oil and gasoline, both important \"primary energy\" sources. 84% by volume of the hydrocarbons present in petroleum is converted into fuels, including gasoline, diesel, jet, heating, and other fuel oils, and liquefied petroleum gas.\nDue to its high energy density, easy transportability and relative abundance, oil has become the world's most important source of energy since the mid-1950s. Petroleum is also the raw material for many chemical products, including pharmaceuticals, solvents, fertilizers, pesticides, and plastics; the 16 percent not used for energy production is converted into these other materials. Petroleum is found in porous rock formations in the upper strata of some areas of the Earth's crust. There is also petroleum in oil sands (tar sands). Known oil reserves are typically estimated at 190\u00a0km3 (1.2 trillion (short scale) barrels) without oil sands, or 595\u00a0km3 (3.74\u00a0trillion barrels) with oil sands. Consumption is currently around per day, or 4.9\u00a0km3 per year, yielding a remaining oil supply of only about 120 years, if current demand remains static. More recent studies, however, put the number at around 50 years.\nClosely related to fuels for combustion engines are Lubricants, greases, and viscosity stabilizers. All are derived from petroleum.\nChemicals.\nMany pharmaceuticals are derived from petroleum, albeit via multistep processes. Modern medicine depends on petroleum as a source of building blocks, reagents, and solvents. Similarly, virtually all pesticides - insecticides, herbicides, etc. - are derived from petroleum. Pesticides have profoundly affected life expectancies by controlling disease vectors and by increasing yields of crops. Like pharmaceuticals, pesticides are in essence petrochemicals. Almost all plastics and synthetic polymers are derived from petroleum, which is the source of monomers. Alkenes (olefins) are one important class of these precursor molecules.\nIndustry.\nTransport.\nIn the 1950s, shipping costs made up 33 percent of the price of oil transported from the Persian Gulf to the United States, but due to the development of supertankers in the 1970s, the cost of shipping dropped to only 5 percent of the price of Persian oil in the US. Due to the increase in the value of crude oil during the last 30 years, the share of the shipping cost on the final cost of the delivered commodity was less than 3% in 2010.\nTrade.\nCrude oil is traded as a future on both the NYMEX and ICE exchanges. Futures contracts are agreements in which buyers and sellers agree to purchase and deliver specific amounts of physical crude oil on a given date in the future. A contract covers any multiple of 1000 barrels and can be purchased up to nine years into the future.\nUse by country.\nConsumption.\nAccording to the US Energy Information Administration (EIA) estimate for 2021, the world consumes 97.26\u00a0million barrels of oil each day.\nThis table orders the amount of petroleum consumed in 2011 in thousand barrels (1,000 bbl) per day and in thousand cubic metres (1,000\u00a0m3) per day:\nSource: US Energy Information Administration\nPopulation Data:\nProduction.\n&lt;includeonly&gt;&lt;templatestyles src=\"Chart/styles.css\"/&gt;Top oil-producing countries View .&lt;/includeonly&gt;\nIn petroleum industry parlance, \"production\" refers to the quantity of crude extracted from reserves, not the literal creation of the product.\nExportation.\nIn order of net exports in 2011, 2009 and 2006 in thousand bbl/d and thousand m3/d:\nSource: US Energy Information Administration\nTotal world production/consumption (as of 2005) is approximately .\nImportation.\nIn order of net imports in 2011, 2009 and 2006 in thousand bbl/d and thousand m3/d:\nSource: US Energy Information Administration\n1 peak production of oil expected in 2020\nNon-producing consumers.\nCountries whose oil production is 10% or less of their consumption.\nSource: CIA World Factbook\nEnvironmental effects.\nClimate.\nAs of 2018[ [update]], about a quarter of annual global greenhouse gas emissions is the carbon dioxide from burning petroleum (plus methane leaks from the industry). Along with the burning of coal, petroleum combustion is the largest contributor to the increase in atmospheric CO2. Atmospheric CO2 has risen over the last 150 years to current levels of over 415\u00a0ppmv, from the 180\u2013300\u00a0ppmv of the prior 800 thousand years. The rise in Arctic temperature has reduced the minimum Arctic ice pack to , a loss of almost half since satellite measurements started in 1979.\nOcean acidification is the increase in the acidity of the Earth's oceans caused by the uptake of carbon dioxide (CO2) from the atmosphere.The saturation state of calcium carbonate decreases with the uptake of carbon dioxide in the ocean. This increase in acidity inhibits all marine life\u2014having a greater effect on smaller organisms as well as shelled organisms (see scallops).\nExtraction.\nOil extraction is simply the removal of oil from the reservoir (oil pool). There are many methods on extracting the oil from the reservoirs for example; mechanical shaking, water-in-oil emulsion, and specialty chemicals called demulsifiers that separate the oil from water. Oil extraction is costly and often environmentally damaging. Offshore exploration and extraction of oil disturb the surrounding marine environment.\nOil spills.\nCrude oil and refined fuel spills from tanker ship accidents have damaged natural ecosystems and human livelihoods in Alaska, the Gulf of Mexico, the Gal\u00e1pagos Islands, France and many other places.\nThe quantity of oil spilled during accidents has ranged from a few hundred tons to several hundred thousand tons (e.g., Deepwater Horizon oil spill, SS Atlantic Empress, Amoco Cadiz). Smaller spills have already proven to have a great impact on ecosystems, such as the \"Exxon Valdez\" oil spill.\nOil spills at sea are generally much more damaging than those on land, since they can spread for hundreds of nautical miles in a thin oil slick which can cover beaches with a thin coating of oil. This can kill sea birds, mammals, shellfish, and other organisms it coats. Oil spills on land are more readily containable if a makeshift earth dam can be rapidly bulldozed around the spill site before most of the oil escapes, and land animals can avoid the oil more easily.\nControl of oil spills is difficult, requires ad hoc methods, and often a large amount of manpower. The dropping of bombs and incendiary devices from aircraft on the wreck produced poor results; modern techniques would include pumping the oil from the wreck, like in the \"Prestige\" oil spill or the \"Erika\" oil spill.\nThough crude oil is predominantly composed of various hydrocarbons, certain nitrogen heterocyclic compounds, such as pyridine, picoline, and quinoline are reported as contaminants associated with crude oil, as well as facilities processing oil shale or coal, and have also been found at legacy wood treatment sites. These compounds have a very high water solubility, and thus tend to dissolve and move with water. Certain naturally occurring bacteria, such as \"Micrococcus\", \"Arthrobacter\", and \"Rhodococcus\" have been shown to degrade these contaminants.\nBecause petroleum is a naturally occurring substance, its presence in the environment does not need to be the result of human causes such as accidents and routine activities (seismic exploration, drilling, extraction, refining and combustion). Phenomena such as seeps and tar pits are examples of areas that petroleum affects without human involvement.\nTarballs.\nA tarball is a blob of crude oil (not to be confused with tar, which is a human-made product derived from pine trees or refined from petroleum) which has been weathered after floating in the ocean. Tarballs are an aquatic pollutant in most environments, although they can occur naturally, for example in the Santa Barbara Channel of California or in the Gulf of Mexico off Texas. Their concentration and features have been used to assess the extent of oil spills. Their composition can be used to identify their sources of origin, and tarballs themselves may be dispersed over long distances by deep sea currents. They are slowly decomposed by bacteria, including \"Chromobacterium violaceum\", \"Cladosporium resinae\", \"Bacillus submarinus\", \"Micrococcus varians\", \"Pseudomonas aeruginosa\", \"Candida marina\" and \"Saccharomyces estuari\".\nWhales.\nJames S. Robbins has argued that the advent of petroleum-refined kerosene saved some species of great whales from extinction by providing an inexpensive substitute for whale oil, thus eliminating the economic imperative for open-boat whaling, but others say that fossil fuels increased whaling with most whales being killed in the 20th century.\nAlternatives.\nIn 2018 road transport used 49% of petroleum, aviation 8%, and uses other than energy 17%. Electric vehicles are the main alternative for road transport and biojet for aviation. Single-use plastics have a high carbon footprint and may pollute the sea, but as of 2022 the best alternatives are unclear.\nInternational relations.\nControl of petroleum production has been a significant driver of international relations during much of the 20th and 21st centuries. Organizations like OPEC have played an outsized role in international politics. Some historians and commentators have called this the \"Age of Oil\" With the rise of renewable energy and addressing climate change some commentators expect a realignment of international power away from petrostates.\nCorruption.\n\"Oil rents\" have been described as connected with corruption in political literature. A 2011 study suggested that increases in oil rents increased corruption in countries with heavy government involvement in the production of oil. The study found that increases in oil rents \"significantly deteriorates political rights\". The investigators say that oil exploitation gave politicians \"an incentive to extend civil liberties but reduce political rights in the presence of oil windfalls to evade redistribution and conflict\".\nConflict.\nPetroleum production has been linked with conflict for many years, leading to thousands of deaths. Petroleum deposits are in hardly any countries around the world; mainly in Russia and some parts of the middle east. Conflicts may start when countries refuse to cut oil production in which other countries respond to such actions by increasing their production causing a trade war as experienced during the 2020 Russia\u2013Saudi Arabia oil price war. Other conflicts start due to countries wanting petroleum resources or other reasons on oil resource territory experienced in the Iran\u2013Iraq War.\nFuture production.\nConsumption in the twentieth and twenty-first centuries has been abundantly pushed by automobile sector growth. The 1985\u20132003 oil glut even fueled the sales of low fuel economy vehicles in OECD countries. The 2008 economic crisis seems to have had some impact on the sales of such vehicles; still, in 2008 oil consumption showed a small increase.\nIn 2016 Goldman Sachs predicted lower demand for oil due to emerging economies concerns, especially China. The BRICS (Brasil, Russia, India, China, South Africa) countries might also kick in, as China briefly had the largest automobile market in December 2009. In the long term, uncertainties linger; the OPEC believes that the OECD countries will push low consumption policies at some point in the future; when that happens, it will definitely curb oil sales, and both OPEC and the Energy Information Administration (EIA) kept lowering their 2020 consumption estimates during the past five years. A detailed review of International Energy Agency oil projections have revealed that revisions of world oil production, price and investments have been motivated by a combination of demand and supply factors. All together, Non-OPEC conventional projections have been fairly stable the last 15 years, while downward revisions were mainly allocated to OPEC. Upward revisions are primarily a result of US tight oil.\nProduction will also face an increasingly complex situation; while OPEC countries still have large reserves at low production prices, newly found reservoirs often lead to higher prices; offshore giants such as Tupi, Guara and Tiber demand high investments and ever-increasing technological abilities. Subsalt reservoirs such as Tupi were unknown in the twentieth century, mainly because the industry was unable to probe them. Enhanced Oil Recovery (EOR) techniques (example: DaQing, China) will continue to play a major role in increasing the world's recoverable oil.\nThe expected availability of petroleum resources has always been around 35 years or even less since the start of the modern exploration. The oil constant, an insider pun in the German industry, refers to that effect.\nA growing number of divestment campaigns from major funds pushed by newer generations who question the sustainability of petroleum may hinder the financing of future oil prospection and production.\nPeak oil.\nPeak oil is a term applied to the projection that future petroleum production, whether for individual oil wells, entire oil fields, whole countries, or worldwide production, will eventually peak and then decline at a similar rate to the rate of increase before the peak as these reserves are exhausted. The peak of oil discoveries was in 1965, and oil production per year has surpassed oil discoveries every year since 1980.\nIt is difficult to predict the oil peak in any given region, due to the lack of knowledge and/or transparency in the accounting of global oil reserves. Based on available production data, proponents have previously predicted the peak for the world to be in the years 1989, 1995, or 1995\u20132000. Some of these predictions date from before the recession of the early 1980s, and the consequent lowering in global consumption, the effect of which was to delay the date of any peak by several years. Just as the 1971 U.S. peak in oil production was only clearly recognized after the fact, a peak in world production will be difficult to discern until production clearly drops off.\nIn 2020, according to BP's Energy Outlook 2020, peak oil had been reached, due to the changing energy landscape coupled with the economic toll of the COVID-19 pandemic.\nWhile there has been much focus historically on peak oil supply, the focus is increasingly shifting to peak demand as more countries seek to transition to renewable energy. The GeGaLo index of geopolitical gains and losses assesses how the geopolitical position of 156 countries may change if the world fully transitions to renewable energy resources. Former oil exporters are expected to lose power, while the positions of former oil importers and countries rich in renewable energy resources is expected to strengthen.\nUnconventional oil.\nUnconventional oil is petroleum produced or extracted using techniques other than the conventional methods. The calculus for peak oil has changed with the introduction of unconventional production methods. In particular, the combination of horizontal drilling and hydraulic fracturing has resulted in a significant increase in production from previously uneconomic plays. Certain rock strata contain hydrocarbons but have low permeability and are not thick from a vertical perspective. Conventional vertical wells would be unable to economically retrieve these hydrocarbons. Horizontal drilling, extending horizontally through the strata, permits the well to access a much greater volume of the strata. Hydraulic fracturing creates greater permeability and increases hydrocarbon flow to the wellbore.\nHydrocarbons on other worlds.\nOn Saturn's largest moon, Titan, lakes of liquid hydrocarbons comprising methane, ethane, propane and other constituents, occur naturally. Data collected by the space probe \"Cassini\u2013Huygens\" yield an estimate that the visible lakes and seas of Titan contain about 300 times the volume of Earth's proven oil reserves. Drilled samples from the surface of Mars taken in 2015 by the \"Curiosity\" rover's Mars Science Laboratory have found organic molecules of benzene and propane in 3-billion-year-old rock samples in Gale Crater.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nExplanatory footnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23196", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=23196", "title": "Particular", "text": "Concept in metaphysics\nIn metaphysics, particulars or individuals are usually contrasted with \"universals\". Universals concern features that can be exemplified by various different particulars. Particulars are often seen as concrete, spatiotemporal entities as opposed to abstract entities, such as properties or numbers. There are, however, theories of \"abstract particulars\" or \"tropes\". For example, Socrates is a particular (there's only one Socrates-the-teacher-of-Plato and one cannot make copies of him, e.g., by cloning him, without introducing new, distinct particulars). Redness, by contrast, is not a particular, because it is abstract and multiply instantiated (for example a bicycle, an apple, and a particular woman's hair can all be red).\nIn the nominalist view, everything is particular. A universal at each moment in time, from the point of view of an observer, is a set of particulars.\nOverview.\nSybil Wolfram writes: \nParticulars include only individuals of a certain kind: as a first approximation individuals with a definite place in space and time, such as persons and material objects or events, or which must be identified through such individuals, like smiles or thoughts.\nSome terms are used by philosophers with a rough-and-ready idea of their meaning. This can occur if there is lack of agreement about the best definition of the term. In formulating a solution to the problem of universals, the term 'particular' can be used to describe the \"particular\" instance of redness of a certain apple as opposed to the 'universal' 'redness' (being abstract).\nThe term particular is also used as a modern equivalent of the Aristotelian notion of individual substance. Used in this sense, particular can mean any concrete (individual) entity, irrespective of whether it is spatial and temporal or not.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23197", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=23197", "title": "Poultry", "text": "Domesticated birds kept by humans for their eggs, meat, or feathers\nPoultry () are domesticated birds kept by humans for the purpose of harvesting animal products such as meat, eggs or feathers. The practice of raising poultry is known as poultry farming. These birds are most typically members of the superorder Galloanserae (fowl), especially the order Galliformes (which includes chickens, quails, and turkeys). The term also includes waterfowls of the family Anatidae (ducks and geese) but does not include wild birds hunted for food known as game or quarry.\nRecent genomic studies involving the four extant junglefowl species reveals that the domestication of chicken, the most populous poultry species, occurred around 8,000 years ago in Southeast Asia. This was previously believed to have occurred around 5,400 years ago, also in Southeast Asia. The process may have originally occurred as a result of people hatching and rearing young birds from eggs collected from the wild, but later involved keeping the birds permanently in captivity. Domesticated chickens may have been used for cockfighting at first and quail kept for their songs, but people soon realised the advantages of having a captive-bred source of food. Selective breeding for fast growth, egg-laying ability, conformation, plumage and docility took place over the centuries, and modern breeds often look very different from their wild ancestors. Although some birds are still kept in small flocks in extensive systems, most birds available in the market today are reared in intensive commercial enterprises.\nTogether with pork, poultry is one of the two most widely-eaten types of meat globally, with over 70% of the meat supply in 2012 between them; poultry provides nutritionally beneficial food containing high-quality protein accompanied by a low proportion of fat. All poultry meat should be properly handled and sufficiently cooked in order to reduce the risk of food poisoning. Semi-vegetarians who consume poultry as the only source of meat are said to adhere to pollotarianism.\nEtymology.\nThe word \"poultry\" comes from Middle English \"pultry\" or \"pultrie\", itself derived from Old French/Norman word . The term for an immature poultry, pullet, like its doublet \"poult\", comes from Middle English \"pulet\" and Old French \"polet\", both from the Latin word \"pullus\", meaning a young fowl or young animal. The word \"fowl\" is of Germanic origin (cf. Old English \"Fugol\", German \"Vogel\", Danish \"Fugl\").\nDefinition.\n\"Poultry\" is a term used for any kind of domesticated bird, captive-raised for its utility, and traditionally the word has been used to refer to wildfowl (Galliformes) and waterfowl (Anseriformes) but not to cagebirds such as songbirds and parrots. \"Poultry\" can be defined as domestic fowls, including chickens, turkeys, geese and ducks, raised for the production of meat or eggs and the word is also used for the flesh of these birds used as food.\nThe Encyclop\u00e6dia Britannica lists the same bird groups but also includes guinea fowl and squabs (young pigeons). In R. D. Crawford's \"Poultry breeding and genetics\", squabs are omitted but Japanese quail and common pheasant are added to the list, the latter frequently being bred in captivity and released into the wild. In his 1848 classic book on poultry, \"Ornamental and Domestic Poultry: Their History, and Management\", Edmund Dixon included chapters on the peafowl, guinea fowl, mute swan, turkey, various types of geese, the muscovy duck, other ducks and all types of chickens including bantams.\nIn colloquial speech, the term \"fowl\" is often used near-synonymously with \"domesticated chicken\" (\"Gallus gallus\"), or with \"poultry\" or even just \"bird\", and many languages do not distinguish between \"poultry\" and \"fowl\". Both words are also used for the flesh of these birds. Poultry can be distinguished from \"game\", defined as wild birds or mammals hunted for food or sport, a word also used to describe the meat of these when eaten.\nChickens.\nChickens are medium-sized, chunky birds with an upright stance and characterised by fleshy red combs and wattles on their heads. Males, known as cocks, are usually larger, more boldly coloured, and have more exaggerated plumage than females (hens). Chickens are gregarious, omnivorous, ground-dwelling birds that in their natural surroundings search among the leaf litter for seeds, invertebrates, and other small animals. They seldom fly except as a result of perceived danger, preferring to run into the undergrowth if approached. Today's domestic chicken (\"Gallus gallus domesticus\") is mainly descended from the wild red junglefowl of Asia, with some additional input from grey junglefowl, Sri Lankan junglefowl, and green junglefowl.\nGenomic studies estimate that the chicken was domesticated 8,000 years ago in Southeast Asia and spread to China and India 2000\u20133000 years later. Archaeological evidence supports domestic chickens in Southeast Asia well before 6000\u00a0BC, China by 6000\u00a0BC and India by 2000\u00a0BC. A landmark 2020 Nature study that fully sequenced 863 chickens across the world suggests that all domestic chickens originate from a single domestication event of red junglefowl whose present-day distribution is predominantly in southwestern China, northern Thailand and Myanmar. These domesticated chickens spread across Southeast and South Asia where they interbred with local wild species of junglefowl, forming genetically and geographically distinct groups. Analysis of the most popular commercial breed shows that the White Leghorn breed possesses a mosaic of divergent ancestries inherited from subspecies of red junglefowl.\nChickens were one of the domesticated animals carried with the sea-borne Austronesian migrations into Taiwan, Island Southeast Asia, Island Melanesia, Madagascar, and the Pacific Islands; starting from around 3500 to 2500\u00a0BC.\nBy 2000\u00a0BC, chickens seem to have reached the Indus Valley and 250 years later, they arrived in Egypt. They were still used for fighting and were regarded as symbols of fertility. The Romans used them in divination, and the Egyptians made a breakthrough when they learned the difficult technique of artificial incubation. Since then, the keeping of chickens has spread around the world for the production of food with the domestic fowl being a valuable source of both eggs and meat.\nSince their domestication, a large number of breeds of chickens have been established, but with the exception of the white Leghorn, most commercial birds are of hybrid origin. In about 1800, chickens began to be kept on a larger scale, and modern high-output poultry farms were present in the United Kingdom from around 1920 and became established in the United States soon after the Second World War. By the mid-20th century, the poultry meat-producing industry was of greater importance than the egg-laying industry. Poultry breeding has produced breeds and strains to fulfil different needs; light-framed, egg-laying birds that can produce 300 eggs a year; fast-growing, fleshy birds destined for consumption at a young age, and utility birds which produce both an acceptable number of eggs and a well-fleshed carcase. Male birds are unwanted in the egg-laying industry and can often be identified as soon as they are hatch for subsequent culling. In meat breeds, these birds are sometimes castrated (often chemically) to prevent aggression. The resulting bird, called a capon, has more tender and flavorful meat, as well.\nA bantam is a small variety of domestic chicken, either a miniature version of a member of a standard breed, or a \"true bantam\" with no larger counterpart. The name derives from the town of Bantam in Java where European sailors bought the local small chickens for their shipboard supplies. Bantams may be a quarter to a third of the size of standard birds and lay similarly small eggs. They are kept by small-holders and hobbyists for egg production, use as broody hens, ornamental purposes, and showing.\nCockfighting.\nCockfighting is said to be the world's oldest spectator sport. Two mature males (cocks or roosters) are set to fight each other, and will do so with great vigour until one is critically injured or killed. Cockfighting is extremely widespread in Island Southeast Asia, and often had ritual significance in addition to being a gambling sport. They also formed part of the cultures of ancient India, China, Persia, Greece, Rome, and large sums were won or lost depending on the outcome of an encounter. Breeds such as the Aseel were developed in the Indian subcontinent for their aggressive behaviour. Cockfighting has been banned in many countries during the last century on the grounds of cruelty to animals.\nDucks.\nDucks are medium-sized aquatic birds with broad bills, eyes on the side of the head, fairly long necks, short legs set far back on the body, and webbed feet. Males, known as drakes, are often larger than females (known as hens) and are differently coloured in some breeds. Domestic ducks are omnivores, eating a variety of animal and plant materials such as aquatic insects, molluscs, worms, small amphibians, waterweeds, and grasses. They feed in shallow water by dabbling, with their heads underwater and their tails upended. Most domestic ducks are too heavy to fly, and they are social birds, preferring to live and move around together in groups. They keep their plumage waterproof by preening, a process that spreads the secretions of the preen gland over their feathers.\nClay models of ducks found in China dating back to 4000\u00a0BC may indicate the domestication of ducks took place there during the Yangshao culture. Even if this is not the case, domestication of the duck took place in the Far East at least 1500 years earlier than in the West. Lucius Columella, writing in the first century BC, advised those who sought to rear ducks to collect wildfowl eggs and put them under a broody hen, because when raised in this way, the ducks \"lay aside their wild nature and without hesitation breed when shut up in the bird pen\". Despite this, ducks did not appear in agricultural texts in Western Europe until about 810, when they began to be mentioned alongside geese, chickens, and peafowl as being used for rental payments made by tenants to landowners.\nIt is widely agreed that the mallard (\"Anas platyrhynchos\") is the ancestor of all breeds of domestic duck (with the exception of the Muscovy duck (\"Cairina moschata\"), which is not closely related to other ducks). Ducks are farmed mainly for their meat, eggs, and down. As is the case with chickens, various breeds have been developed, selected for egg-laying ability, fast growth, and a well-covered carcase. The most common commercial breed in the United Kingdom and the United States is the Pekin duck, which can lay 200 eggs a year and can reach a weight of in 44 days. In the Western world, ducks are not as popular as chickens, because the latter produce larger quantities of white, lean meat and are easier to keep intensively, making the price of chicken meat lower than that of duck meat. While popular in \"haute cuisine\", duck appears less frequently in the mass-market food industry. However, things are different in the East. Ducks are more popular there than chickens and are mostly still herded in the traditional way and selected for their ability to find sufficient food in harvested rice fields and other wet environments.\nGoose.\nThe greylag goose (\"Anser anser\") was domesticated by the Egyptians at least 3000 years ago, and a different wild species, the swan goose (\"Anser cygnoides\"), domesticated in Siberia about a thousand years later, is known as a Chinese goose. The two hybridise with each other and the large knob at the base of the beak, a noticeable feature of the Chinese goose, is present to a varying extent in these hybrids. The hybrids are fertile and have resulted in several of the modern breeds. Despite their early domestication, geese have never gained the commercial importance of chickens and ducks.\nDomestic geese are much larger than their wild counterparts and tend to have thick necks, an upright posture, and large bodies with broad rear ends. The greylag-derived birds are large and fleshy and used for meat, while the Chinese geese have smaller frames and are mainly used for egg production. The fine down of both is valued for use in pillows and padded garments. They forage on grass and weeds, supplementing this with small invertebrates, and one of the attractions of rearing geese is their ability to grow and thrive on a grass-based system. They are very gregarious and have good memories and can be allowed to roam widely in the knowledge that they will return home by dusk. The Chinese goose is more aggressive and noisy than other geese and can be used as a guard animal to warn of intruders. The flesh of meat geese is dark-coloured and high in protein, but they deposit fat subcutaneously, although this fat contains mostly monounsaturated fatty acids. The birds are killed either around 10 or about 24 weeks. Between these ages, problems with dressing the carcase occur because of the presence of developing pin feathers.\nIn some countries, geese and ducks are force-fed to produce livers with an exceptionally high fat content for the production of \"foie gras\". Over 75% of world production of this product occurs in France, with lesser industries in Hungary and Bulgaria and a growing production in China. \"Foie gras\" is considered a luxury in many parts of the world, but the process of feeding the birds in this way is banned in many countries on animal welfare grounds.\nTurkeys.\nTurkeys are large birds, their nearest relatives being the pheasant and the guineafowl. Males are larger than females and have spreading, fan-shaped tails and distinctive, fleshy wattles, called a snood, that hang from the top of the beak and are used in courtship display. Wild turkeys can fly, but seldom do so, preferring to run with a long, straddling gait. They roost in trees and forage on the ground, feeding on seeds, nuts, berries, grass, foliage, invertebrates, lizards, and small snakes.\nThe modern domesticated turkey is descended from one of six subspecies of wild turkey (\"Meleagris gallopavo\") found in the present Mexican states of Jalisco, Guerrero and Veracruz. Pre-Aztec tribes in south-central Mexico first domesticated the bird around 800\u00a0BC, and Pueblo Indians inhabiting the Colorado Plateau in the United States did likewise around 200\u00a0BC. They used the feathers for robes, blankets, and ceremonial purposes. More than 1,000 years later, they became an important food source. The first Europeans to encounter the bird misidentified it as a guineafowl, a bird known as a \"turkey fowl\" at that time because it had been introduced into Europe via Turkey.\nCommercial turkeys are usually reared indoors under controlled conditions. These are often large buildings, purpose-built to provide ventilation and low light intensities (this reduces the birds' activity and thereby increases the rate of weight gain). The lights can be switched on for 24\u00a0h/day, or a range of step-wise light regimens to encourage the birds to feed often and therefore grow rapidly. Females achieve slaughter weight at about 15 weeks of age and males at about 19. Mature commercial birds may be twice as heavy as their wild counterparts. Many different breeds have been developed, but the majority of commercial birds are white, as this improves the appearance of the dressed carcass, the pin feathers being less visible. Turkeys were at one time mainly consumed on special occasions such as Christmas (10 million birds in the United Kingdom) or Thanksgiving (60 million birds in the United States). However, they are increasingly becoming part of the everyday diet in many parts of the world.\nOther poultry.\nGuineafowl originated in southern Africa, and the species most often kept as poultry is the helmeted guineafowl (\"Numida meleagris\"). It is a medium-sized grey or speckled bird with a small naked head with colorful wattles and a knob on top, and was domesticated by the time of the ancient Greeks and Romans. Guineafowl are hardy, sociable birds that subsist mainly on insects, but also consume grasses and seeds. They will keep a vegetable garden clear of pests and will eat the ticks that carry Lyme disease. They happily roost in trees and give a loud vocal warning of the approach of predators. Their flesh and eggs can be eaten in the same way as chickens, young birds being ready for the table at the age of about four months.\nA squab is the name given to the young of domestic pigeons that are destined for the table. Like other domesticated pigeons, birds used for this purpose are descended from the rock dove (\"Columba livia\"). Special utility breeds with desirable characteristics are used. Two eggs are laid and incubated for about 17 days. When they hatch, the squabs are fed by both parents on \"pigeon's milk\", a thick secretion high in protein produced by the crop. Squabs grow rapidly, but are slow to fledge and are ready to leave the nest at 26 to 30 days weighing about . By this time, the adult pigeons will have laid and be incubating another pair of eggs and a prolific pair should produce two squabs every four weeks during a breeding season lasting several months.\nPoultry farming.\nWorldwide, more chickens are kept than any other type of poultry, with over 50 billion birds being raised each year as a source of meat and eggs. Traditionally, such birds would have been kept extensively in small flocks, foraging during the day and housed at night. This is still the case in developing countries, where the women often make important contributions to family livelihoods through keeping poultry. However, rising world populations and urbanization have led to the bulk of production being in larger, more intensive specialist units. These are often situated close to where the feed is grown or near to where the meat is needed, and result in cheap, safe food being made available for urban communities. Profitability of production depends very much on the price of feed, which has been rising. High feed costs could limit further development of poultry production.\nIn free-range husbandry, the birds can roam freely outdoors for at least part of the day. Often, this is in large enclosures, but the birds have access to natural conditions and can exhibit their normal behaviours. A more intensive system is yarding, in which the birds have access to a fenced yard and poultry house at a higher stocking rate. Poultry can also be kept in a barn system, with no access to the open air, but with the ability to move around freely inside the building. The most intensive system for egg-laying chickens is battery cages, often set in multiple tiers. In these, several birds share a small cage which restricts their ability to move around and behave in a normal manner. The eggs are laid on the floor of the cage and roll into troughs outside for ease of collection. Battery cages for hens have been illegal in the EU since January 1, 2012.\nChickens raised intensively for their meat are known as \"broilers\". Breeds have been developed that can grow to an acceptable carcass size () in six weeks or less. Broilers grow so fast, their legs cannot always support their weight and their hearts and respiratory systems may not be able to supply enough oxygen to their developing muscles. Mortality rates at 1% are much higher than for less-intensively reared laying birds which take 18 weeks to reach similar weights. Processing the birds is done automatically with conveyor-belt efficiency. They are hung by their feet, stunned, killed, bled, scalded, plucked, have their heads and feet removed, eviscerated, washed, chilled, drained, weighed, and packed, all within the course of little over two hours.\nBoth intensive and free-range farming have animal welfare concerns. In intensive systems, cannibalism, feather pecking and vent pecking can be common, with some farmers using beak trimming as a preventative measure. Diseases can also be common and spread rapidly through the flock. In extensive systems, the birds are exposed to adverse weather conditions and are vulnerable to predators and disease-carrying wild birds. Barn systems have been found to have the worst bird welfare. In Southeast Asia, a lack of disease control in free-range farming has been associated with outbreaks of avian influenza.\nPoultry shows.\nIn many countries, national and regional poultry shows are held where enthusiasts exhibit their birds which are judged on certain phenotypical breed traits as specified by their respective breed standards. The idea of poultry exhibition may have originated after cockfighting was made illegal, as a way of maintaining a competitive element in poultry husbandry. Breed standards were drawn up for egg-laying, meat-type, and purely ornamental birds, aiming for uniformity. Sometimes, poultry shows are part of general livestock shows, and sometimes they are separate events such as the annual \"National Championship Show\" in the United Kingdom organised by the Poultry Club of Great Britain. \nPoultry as food.\nTrade.\nPoultry is the second most widely eaten type of meat in the world, accounting for about 30% of total meat production worldwide compared to pork at 38%. Sixteen billion birds are raised annually for consumption, more than half of these in industrialised, factory-like production units. Global broiler meat production rose to 84.6 million tonnes in 2013. The largest producers were the United States (20%), China (16.6%), Brazil (15.1%) and the European Union (11.3%). There are two distinct models of production; the European Union supply chain model seeks to supply products which can be traced back to the farm of origin. This model faces the increasing costs of implementing additional food safety requirements, welfare issues and environmental regulations. In contrast, the United States model turns the product into a commodity.\nWorld production of duck meat was about 4.2 million tonnes in 2011 with China producing two thirds of the total, some 1.7 billion birds. Other notable duck-producing countries in the Far East include Vietnam, Thailand, Malaysia, Myanmar, Indonesia and South Korea (12% in total). France (3.5%) is the largest producer in the West, followed by other EU nations (3%) and North America (1.7%). China was also by far the largest producer of goose and guinea fowl meat, with a 94% share of the 2.6 million tonne global market.\nGlobal egg production was expected to reach 65.5 million tonnes in 2013, surpassing all previous years. Between 2000 and 2010, egg production was growing globally at around 2% per year, but since then growth has slowed down to nearer 1%. In 2018, egg production reached 76.7 million tonnes, a huge 24% growth since 2008.\nCuts of poultry.\nPoultry is available fresh or frozen, as whole birds or as joints (cuts), bone-in or deboned, seasoned in various ways, raw or ready cooked. The meatiest parts of a bird are the flight muscles on its chest, called \"breast\" meat, and the walking muscles on the legs, called the \"thigh\" and \"drumstick\". The wings are also eaten (Buffalo wings are a popular example in the United States) and may be split into three segments, the meatier \"drumette\", the \"wingette\" (also called the \"flat\"), and the wing tip (also called the \"flapper\"). In Japan, the wing is frequently separated, and these parts are referred to as \u624b\u7fbd\u5143 (\"teba-moto\" \"wing base\") and \u624b\u7fbd\u5148 (\"teba-saki\" \"wing tip\").\nDark meat, which avian myologists refer to as \"red muscle\", is used for sustained activity\u2014chiefly walking, in the case of a chicken. The dark color comes from the protein myoglobin, which plays a key role in oxygen uptake and storage within cells. White muscle, in contrast, is suitable only for short bursts of activity such as, for chickens, flying. Thus, the chicken's leg and thigh meat are dark, while its breast meat (which makes up the primary flight muscles) is white. Other birds with breast muscle more suitable for sustained flight, such as ducks and geese, have red muscle (and therefore dark meat) throughout. Some cuts of meat including poultry expose the microscopic regular structure of intracellular muscle fibrils which can diffract light and produce iridescent colors, an optical phenomenon sometimes called structural coloration.\nHealth and disease (humans).\n no clinical trials have assessed poultry intake on human health. Poultry meat and eggs provide nutritionally beneficial food containing protein of high quality. This is accompanied by low levels of fat which have a favourable mix of fatty acids. Chicken meat contains about two to three times as much polyunsaturated fat as most types of red meat when measured by weight. However, for boneless, skinless chicken breast, the amount is much lower. of raw chicken breast contains of fat and of protein, compared to of fat and of protein for the same portion of raw beef flank steak.\nA 2011 study by the Translational Genomics Research Institute showed that 47% of the meat and poultry sold in United States grocery stores was contaminated with \"Staphylococcus aureus\", and 52% of the bacteria concerned showed resistance to at least three groups of antibiotics. Thorough cooking of the product would kill these bacteria, but a risk of cross-contamination from improper handling of the raw product is still present. Also, some risk is present for consumers of poultry meat and eggs to bacterial infections such as \"Salmonella\" and \"Campylobacter\". Poultry products may become contaminated by these bacteria during handling, processing, marketing, or storage, resulting in food-borne illness if the product is improperly cooked or handled.\nIn general, avian influenza is a disease of birds caused by bird-specific influenza A virus that is not normally transferred to people; however, people in contact with live poultry are at the greatest risk of becoming infected with the virus and this is of particular concern in areas such as Southeast Asia, where the disease is endemic in the wild bird population and domestic poultry can become infected. The virus possibly could mutate to become highly virulent and infectious in humans and cause an influenza pandemic.\nBacteria can be grown in the laboratory on nutrient culture media, but viruses need living cells in which to replicate. Many vaccines to infectious diseases can be grown in fertilised chicken eggs. Millions of eggs are used each year to generate the annual flu vaccine requirements, a complex process that takes about six months after the decision is made as to what strains of virus to include in the new vaccine. A problem with using eggs for this purpose is that people with egg allergies are unable to be immunised, but this disadvantage may be overcome as new techniques for cell-based rather than egg-based culture become available. Cell-based culture will also be useful in a pandemic when it may be difficult to acquire a sufficiently large quantity of suitable sterile, fertile eggs.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23198", "revid": "5016021", "url": "https://en.wikipedia.org/wiki?curid=23198", "title": "Poker variant", "text": ""}
{"id": "23200", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=23200", "title": "PythagoreanTheorem", "text": ""}
{"id": "23203", "revid": "770058", "url": "https://en.wikipedia.org/wiki?curid=23203", "title": "Propaganda", "text": "Communication used to influence opinion\nPropaganda is communication that is primarily used to influence or persuade an audience to further an agenda, which may not be objective and may be selectively presenting facts to encourage a particular synthesis or perception, or using loaded language to produce an emotional rather than a rational response to the information that is being presented. Propaganda can be found in a wide variety of different contexts.\nBeginning in the twentieth century, the English term \"propaganda\" became associated with a manipulative approach, but historically, propaganda had been a neutral descriptive term of any material that promotes certain opinions or ideologies.\nA wide range of materials and media are used for conveying propaganda messages, which changed as new technologies were invented, including paintings, cartoons, posters, pamphlets, films, radio shows, TV shows, and websites. More recently, the digital age has given rise to new ways of disseminating propaganda, for example, in computational propaganda, bots and algorithms are used to manipulate public opinion, e.g., by creating fake or biased news to spread it on social media or using chatbots to mimic real people in discussions in social networks.\nEtymology.\n\"Propaganda\" is a modern Latin word, the neuter plural gerundive form of , meaning 'to spread' or 'to propagate', thus \"propaganda\" means \"the things which are to be propagated\". Originally this word derived from a new administrative body (congregation) of the Catholic Church created in 1622 as part of the Counter-Reformation, called the \"Congregatio de Propaganda Fide\" (\"Congregation for Propagating the Faith\"), or informally simply \"Propaganda\". Its activity was aimed at \"propagating\" the Catholic faith in non-Catholic countries.\nFrom the 1790s, the term began being used also to refer to \"propaganda\" in secular activities. In English, the cognate began taking a pejorative or negative connotation in the mid-19th century, when it was used in the political sphere.\nNon-English cognates of \"propaganda\" as well as some similar non-English terms retain neutral or positive connotations. For example, in official party discourse, \"xuanchuan\" is treated as a more neutral or positive term, though it can be used pejoratively through protest or other informal settings within China.\nDefinitions.\nHistorian Arthur Aspinall observed that newspapers were not expected to be independent organs of information when they began to play an important part in political life in the late 1700s, but were assumed to promote the views of their owners or government sponsors. In the 20th century, the term propaganda emerged along with the rise of mass media, including newspapers and radio. As researchers began studying the effects of media, they used suggestion theory to explain how people could be influenced by emotionally-resonant persuasive messages. Harold Lasswell provided a broad definition of the term propaganda, writing it as: \"the expression of opinions or actions carried out deliberately by individuals or groups with a view to influencing the opinions or actions of other individuals or groups for predetermined ends and through psychological manipulations.\" Garth Jowett and Victoria O'Donnell theorize that propaganda\nand persuasion are linked as humans use communication as a form of soft power through the development and cultivation of propaganda materials.\nIn a 1929 literary debate with Edward Bernays, Everett Dean Martin argues that, \"Propaganda is making puppets of us. We are moved by hidden strings which the propagandist manipulates.\" In the 1920s and 1930s, propaganda was sometimes described as all-powerful. For example, Bernays acknowledged in his book \"Propaganda\" that \"The conscious and intelligent manipulation of the organized habits and opinions of the masses is an important element in democratic society. Those who manipulate this unseen mechanism of society constitute an invisible government which is the true ruling power of our country. We are governed, our minds are molded, our tastes formed, our ideas suggested, largely by men we have never heard of.\"\nNATO's 2011 guidance for military public affairs defines propaganda as \"information, ideas, doctrines, or special appeals disseminated to influence the opinion, emotions, attitudes, or behaviour of any specified group in order to benefit the sponsor, either directly or indirectly\". More recently the RAND Corporation coined the term Firehose of Falsehood to describe how modern communication capabilities enable a large number of messages to be broadcast rapidly, repetitively, and continuously over multiple channels (like news and social media) without regard for truth or consistency. \nHistory.\nPrimitive forms of propaganda have been a human activity as far back as reliable recorded evidence exists. The Behistun Inscription (c.\u2009515 BCE) detailing the rise of Darius I to the Persian throne is viewed by most historians as an early example of propaganda. Another striking example of propaganda during ancient history is the last Roman civil wars (44\u201330 BCE) during which Octavian and Mark Antony blamed each other for obscure and degrading origins, cruelty, cowardice, oratorical and literary incompetence, debaucheries, luxury, drunkenness and other slanders. This defamation took the form of \"uituperatio\" (Roman rhetorical genre of the invective) which was decisive for shaping the Roman public opinion at this time. Another early example of propaganda was from Genghis Khan. The emperor would send some of his men ahead of his army to spread rumors to the enemy. In many cases, his army was actually smaller than his opponents'.\nHoly Roman Emperor Maximilian I was the first ruler to utilize the power of the printing press for propaganda \u2013 in order to build his image, stir up patriotic feelings in the population of his empire (he was the first ruler who utilized one-sided battle reports \u2013 the early predecessors of modern newspapers or \"neue zeitungen\" \u2013 targeting the mass.) and influence the population of his enemies. Propaganda during the Reformation, helped by the spread of the printing press throughout Europe, and in particular within Germany, caused new ideas, thoughts, and doctrine to be made available to the public in ways that had never been seen before the 16th century. During the era of the American Revolution, the American colonies had a flourishing network of newspapers and printers who specialized in the topic on behalf of the Patriots (and to a lesser extent on behalf of the Loyalists). Academic Barbara Diggs-Brown conceives that the negative connotations of the term \"propaganda\" are associated with the earlier social and political transformations that occurred during the French Revolutionary period movement of 1789 to 1799 between the start and the middle portion of the 19th century, in a time when the word started to be used in a nonclerical and political context.\nThe first large-scale and organised propagation of government propaganda was occasioned by the outbreak of the First World War in 1914. After the defeat of Germany, military officials such as General Erich Ludendorff suggested that British propaganda had been instrumental in their defeat. Adolf Hitler came to echo this view, believing that it had been a primary cause of the collapse of morale and revolts in the German home front and Navy in 1918 (see also: Dolchsto\u00dflegende). In \"Mein Kampf\" (1925) Hitler expounded his theory of propaganda, which provided a powerful base for his rise to power in 1933. Historian Robert Ensor explains that \"Hitler...puts no limit on what can be done by propaganda; people will believe anything, provided they are told it often enough and emphatically enough, and that contradicters are either silenced or smothered in calumny.\" This was to be true in Germany and backed up with their army making it difficult to allow other propaganda to flow in. Most propaganda in Nazi Germany was produced by the Ministry of Public Enlightenment and Propaganda under Joseph Goebbels. Goebbels mentions propaganda as a way to see through the masses. Symbols are used towards propaganda such as justice, liberty and one's devotion to one's country. World War II saw continued use of propaganda as a weapon of war, building on the experience of WWI, by Goebbels and the British Political Warfare Executive, as well as the United States Office of War Information.\nIn the early 20th century, the invention of motion pictures (as in movies, diafilms) gave propaganda-creators a powerful tool for advancing political and military interests when it came to reaching a broad segment of the population and creating consent or encouraging rejection of the real or imagined enemy. In the years following the October Revolution of 1917, the Soviet government sponsored the Russian film industry with the purpose of making propaganda films (e.g., the 1925 film \"The Battleship Potemkin\" glorifies Communist ideals). In WWII, Nazi filmmakers produced highly emotional films to create popular support for occupying the Sudetenland and attacking Poland. The 1930s and 1940s, which saw the rise of totalitarian states and the Second World War, are arguably the \"Golden Age of Propaganda\". Leni Riefenstahl, a filmmaker working in Nazi Germany, created one of the best-known propaganda movies, \"Triumph of the Will\". In 1942, the propaganda song \"Niet Molotoff\" was made in Finland during the Continuation War, making fun of the Red Army's failure in the Winter War, referring the song's name to the Soviet's Minister of Foreign Affairs, Vyacheslav Molotov. In the US, animation became popular, especially for winning over youthful audiences and aiding the U.S. war effort, e.g., \"Der Fuehrer's Face\" (1942), which ridicules Hitler and advocates the value of freedom. Some American war films in the early 1940s were designed to create a patriotic mindset and convince viewers that sacrifices needed to be made to defeat the Axis powers. Others were intended to help Americans understand their Allies in general, as in films like \"Know Your Ally: Britain\" and \"Our Greek Allies\". Apart from its war films, Hollywood did its part to boost American morale in a film intended to show how stars of stage and screen who remained on the home front were doing their part not just in their labors, but also in their understanding that a variety of peoples worked together against the Axis menace: \"Stage Door Canteen\" (1943) features one segment meant to dispel Americans' mistrust of the Soviets, and another to dispel their bigotry against the Chinese. Polish filmmakers in Great Britain created the anti-Nazi color film \"Calling Mr. Smith\" (1943) about Nazi crimes in German-occupied Europe and about lies of Nazi propaganda.\nThe John Steinbeck novel \"The Moon Is Down\" (1942), about the Socrates-inspired spirit of resistance in an occupied village in Northern Europe, was presumed to be about Norway's response to the German occupiers. In 1945, Steinbeck received the King Haakon VII Freedom Cross for his literary contributions to the Norwegian resistance movement.\nThe West and the Soviet Union both used propaganda extensively during the Cold War. Both sides used film, television, and radio programming to influence their own citizens, each other, and Third World nations. Through a front organization called the Bedford Publishing Company, the CIA through a covert department called the Office of Policy Coordination disseminated over one million books to Soviet readers over the span of 15 years, including novels by George Orwell, Albert Camus, Vladimir Nabokov, James Joyce, and Pasternak in an attempt to promote anti-communist sentiment and sympathy of Western values. George Orwell's contemporaneous novels \"Animal Farm\" and \"Nineteen Eighty-Four\" portray the use of propaganda in fictional dystopian societies. During the Cuban Revolution, Fidel Castro stressed the importance of propaganda. Propaganda was used extensively by Communist forces in the Vietnam War as means of controlling people's opinions.\nDuring the Yugoslav wars, propaganda was used as a military strategy by governments of Federal Republic of Yugoslavia and Croatia. Propaganda was used to create fear and hatred, and particularly to incite the Serb population against the other ethnicities (Bosniaks, Croats, Albanians and other non-Serbs). Serb media made a great effort in justifying, revising or denying mass war crimes committed by Serb forces during these wars.\nPublic perceptions.\nIn the early 20th century the term propaganda was used by the founders of the nascent public relations industry to refer to their people. Literally translated from the Latin gerundive as \"things that must be disseminated\", in some cultures the term is neutral or even positive, while in others the term has acquired a strong negative connotation. The connotations of the term \"propaganda\" can also vary over time. For example, in Portuguese and some Spanish language speaking countries, particularly in the Southern Cone, the word \"propaganda\" usually refers to the most common manipulative media in business terms\u00a0\u2013 \"advertising\".\nIn English, \"propaganda\" was originally a neutral term for the dissemination of information in favor of any given cause. During the 20th century, however, the term acquired a thoroughly negative meaning in western countries, representing the intentional dissemination of often false, but certainly \"compelling\" claims to support or justify political actions or ideologies. According to Harold Lasswell, the term began to fall out of favor due to growing public suspicion of propaganda in the wake of its use during World War I by the Creel Committee in the United States and the Ministry of Information in Britain: Writing in 1928, Lasswell observed, \"In democratic countries the official propaganda bureau was looked upon with genuine alarm, for fear that it might be suborned to party and personal ends. The outcry in the United States against Mr. Creel's famous Bureau of Public Information (or 'Inflammation') helped to din into the public mind the fact that propaganda existed. ... The public's discovery of propaganda has led to a great of lamentation over it. Propaganda has become an epithet of contempt and hate, and the propagandists have sought protective coloration in such names as 'public relations council,' 'specialist in public education,' 'public relations adviser.' \" In 1949, political science professor Dayton David McKean wrote, \"After World War I the word came to be applied to 'what you don't like of the other fellow's publicity,' as Edward L. Bernays said...\"\nContestation.\nThe term is essentially contested and some have argued for a neutral definition,9 arguing that ethics depend on intent and context, while others define it as necessarily unethical and negative. Emma Briant defines it as \"the deliberate manipulation of representations (including text, pictures, video, speech etc.) with the intention of producing any effect in the audience (e.g. action or inaction; reinforcement or transformation of feelings, ideas, attitudes or behaviours) that is desired by the propagandist.\"9 The same author explains the importance of consistent terminology across history, particularly as contemporary euphemistic synonyms are used in governments' continual efforts to rebrand their operations such as 'information support' and strategic communication.9 Other scholars also see benefits to acknowledging that propaganda can be interpreted as beneficial or harmful, depending on the message sender, target audience, message, and context.\nDavid Goodman argues that the 1936 League of Nations \"Convention on the Use of Broadcasting in the Cause of Peace\" tried to create the standards for a liberal international public sphere. The Convention encouraged empathetic and neighborly radio broadcasts to other nations. It called for League prohibitions on international broadcast containing hostile speech and false claims. It tried to define the line between liberal and illiberal policies in communications, and emphasized the dangers of nationalist chauvinism. With Nazi Germany and Soviet Russia active on the radio, its liberal goals were ignored, while free speech advocates warned that the code represented restraints on free speech.\nTypes.\nIdentifying propaganda has always been a problem. The main difficulties have involved differentiating propaganda from other types of persuasion, and avoiding a biased approach. Richard Alan Nelson provides a definition of the term: \"Propaganda is neutrally defined as a systematic form of purposeful persuasion that attempts to influence the emotions, attitudes, opinions, and actions of specified target audiences for ideological, political or commercial purposes through the controlled transmission of one-sided messages (which may or may not be factual) via mass and direct media channels.\" The definition focuses on the communicative process involved \u2013 or more precisely, on the purpose of the process, and allow \"propaganda\" to be interpreted as positive or negative behavior depending on the perspective of the viewer or listener.\nPropaganda can often be recognized by the rhetorical strategies used in its design. In the 1930s, the Institute for Propaganda Analysis identified a variety of propaganda techniques that were commonly used in newspapers and on the radio, which were the mass media of the time period. Propaganda techniques include \"name calling\" (using derogatory labels), \"bandwagon\" (expressing the social appeal of a message), or \"glittering generalities\" (using positive but imprecise language). With the rise of the internet and social media, Renee Hobbs identified four characteristic design features of many forms of contemporary propaganda: (1) it activates strong emotions; (2) it simplifies information; (3) it appeals to the hopes, fears, and dreams of a targeted audience; and (4) it attacks opponents.\nPropaganda is sometimes evaluated based on the intention and goals of the individual or institution who created it. According to historian Zbyn\u011bk Zeman, propaganda is defined as either white, grey or black. White propaganda openly discloses its source and intent. Grey propaganda has an ambiguous or non-disclosed source or intent. Black propaganda purports to be published by the enemy or some organization besides its actual origins (compare with black operation, a type of clandestine operation in which the identity of the sponsoring government is hidden). In scale, these different types of propaganda can also be defined by the potential of true and correct information to compete with the propaganda. For example, opposition to white propaganda is often readily found and may slightly discredit the propaganda source. Opposition to grey propaganda, when revealed (often by an inside source), may create some level of public outcry. Opposition to black propaganda is often unavailable and may be dangerous to reveal, because public cognizance of black propaganda tactics and sources would undermine or backfire the very campaign the black propagandist supported.\nThe propagandist seeks to change the way people understand an issue or situation for the purpose of changing their actions and expectations in ways that are desirable to the interest group. Propaganda, in this sense, serves as a corollary to censorship in which the same purpose is achieved, not by filling people's minds with approved information, but by preventing people from being confronted with opposing points of view. What sets propaganda apart from other forms of advocacy is the willingness of the propagandist to change people's understanding through deception and confusion rather than persuasion and understanding. The leaders of an organization know the information to be one sided or untrue, but this may not be true for the rank and file members who help to disseminate the propaganda.\nReligious.\nPropaganda was often used to influence opinions and beliefs on religious issues, particularly during the split between the Roman Catholic Church and the Protestant churches or during the Crusades.\nThe sociologist Jeffrey K. Hadden has argued that members of the anti-cult movement and Christian counter-cult movement accuse the leaders of what they consider cults of using propaganda extensively to recruit followers and keep them. Hadden argued that ex-members of cults and the anti-cult movement are committed to making these movements look bad.\nPropaganda against other religions in the same community or propaganda intended to keep political power in the hands of a religious elite can incite religious hate on a global or national scale. It could make use of many propaganda mediums. War, terrorism, riots, and other violent acts can result from it. It can also conceal injustices, inequities, exploitation, and atrocities, leading to ignorance-based indifference and alienation.\nWartime.\nIn the Peloponnesian War, the Athenians exploited the figures from stories about Troy as well as other mythical images to incite feelings against Sparta. For example, Helen of Troy was even portrayed as an Athenian, whose mother Nemesis would avenge Troy. During the Punic Wars, extensive campaigns of propaganda were carried out by both sides. To dissolve the Roman system of socii and the Greek poleis, Hannibal released without conditions Latin prisoners that he had treated generously to their native cities, where they helped to disseminate his propaganda. The Romans on the other hand tried to portray Hannibal as a person devoid of humanity and would soon lose the favour of gods. At the same time, led by Q.Fabius Maximus, they organized elaborate religious rituals to protect Roman morale.\nIn the early sixteenth century, Maximilian I invented one kind of psychological warfare targeting the enemies. During his war against Venice, he attached pamphlets to balloons that his archers would shoot down. The content spoke of freedom and equality and provoked the populace to rebel against the tyrants (their Signoria).\nPropaganda is a powerful weapon in war; in certain cases, it is used to dehumanize and create hatred toward a supposed enemy, either internal or external, by creating a false image in the mind of soldiers and citizens. This can be done by using derogatory or racist terms (e.g., the racist terms \"Jap\" and \"gook\" used during World War II and the Vietnam War, respectively), avoiding some words or language or by making allegations of enemy atrocities. The goal of this was to demoralize the opponent into thinking what was being projected was actually true. Most propaganda efforts in wartime require the home population to feel the enemy has inflicted an injustice, which may be fictitious or may be based on facts (e.g., the sinking of the passenger ship by the German Navy in World War I). The home population must also believe that the cause of their nation in the war is just. In these efforts it was difficult to determine the accuracy of how propaganda truly impacted the war. In NATO doctrine, propaganda is defined as \"Information, especially of a biased or misleading nature, used to promote a political cause or point of view.\" Within this perspective, the information provided does not need to be necessarily false but must be instead relevant to specific goals of the \"actor\" or \"system\" that performs it.\nPropaganda is also one of the methods used in psychological warfare, which may also involve false flag operations in which the identity of the operatives is depicted as those of an enemy nation (e.g., The Bay of Pigs Invasion used CIA planes painted in Cuban Air Force markings). The term propaganda may also refer to false information meant to reinforce the mindsets of people who already believe as the propagandist wishes (e.g., During the First World War, the main purpose of British propaganda was to encourage men to join the army, and women to work in the country's industry. Propaganda posters were used because regular general radio broadcasting was yet to commence and TV technology was still under development). The assumption is that, if people believe something false, they will constantly be assailed by doubts. Since these doubts are unpleasant (see cognitive dissonance), people will be eager to have them extinguished, and are therefore receptive to the reassurances of those in power. For this reason, propaganda is often addressed to people who are already sympathetic to the agenda or views being presented. This process of reinforcement uses an individual's predisposition to self-select \"agreeable\" information sources as a mechanism for maintaining control over populations.\nPropaganda may be administered in insidious ways. For instance, disparaging disinformation about the history of certain groups or foreign countries may be encouraged or tolerated in the educational system. Since few people actually double-check what they learn at school, such disinformation will be repeated by journalists as well as parents, thus reinforcing the idea that the disinformation item is really a \"well-known fact\", even though no one repeating the myth is able to point to an authoritative source. The disinformation is then recycled in the media and in the educational system, without the need for direct governmental intervention on the media. Such permeating propaganda may be used for political goals: by giving citizens a false impression of the quality or policies of their country, they may be incited to reject certain proposals or certain remarks or ignore the experience of others.\nIn the Soviet Union during the Second World War, the propaganda designed to encourage civilians was controlled by Stalin, who insisted on a heavy-handed style that educated audiences easily saw was inauthentic. On the other hand, the unofficial rumors about German atrocities were well founded and convincing. Stalin was a Georgian who spoke Russian with a heavy accent. That would not do for a national hero so starting in the 1930s all new visual portraits of Stalin were retouched to erase his and make him a more generalized Soviet hero. Only his eyes and famous moustache remained unaltered. Zhores Medvedev and Roy Medvedev say his \"majestic new image was devised appropriately to depict the leader of all times and of all peoples.\"\nArticle 20 of the International Covenant on Civil and Political Rights prohibits any propaganda for war as well as any advocacy of national or religious hatred that constitutes incitement to discrimination, hostility or violence by law.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Naturally, the common people don't want war; neither in Russia nor in England nor in America, nor for that matter in Germany. That is understood. But, after all, it is the leaders of the country who determine the policy and it is always a simple matter to drag the people along, whether it is a democracy or a fascist dictatorship or a Parliament or a Communist dictatorship. The people can always be brought to the bidding of the leaders. That is easy. All you have to do is tell them they are being attacked and denounce the pacifists for lack of patriotism and exposing the country to danger. It works the same way in any country.\u2014\u200aSimply enough the covenant specifically is not defining the content of propaganda. In simplest terms, an act of propaganda if used in a reply to a wartime act is not prohibited.\nAdvertising.\nPropaganda shares techniques with advertising and public relations, each of which can be thought of as propaganda that promotes a commercial product or shapes the perception of an organization, person, or brand. For example, after claiming victory in the 2006 Lebanon War, Hezbollah campaigned for broader popularity among Arabs by organizing mass rallies where Hezbollah leader Hassan Nasrallah combined elements of the local dialect with classical Arabic to reach audiences outside Lebanon. Banners and billboards were commissioned in commemoration of the war, along with various merchandise items with Hezbollah's logo, flag color (yellow), and images of Nasrallah. T-shirts, baseball caps and other war memorabilia were marketed for all ages. The uniformity of messaging helped define Hezbollah's brand.\nIn the journalistic context, advertisements evolved from the traditional commercial advertisements to include also a new type in the form of paid articles or broadcasts disguised as news. These generally present an issue in a very subjective and often misleading light, primarily meant to persuade rather than inform. Normally they use only subtle propaganda techniques and not the more obvious ones used in traditional commercial advertisements. If the reader believes that a paid advertisement is in fact a news item, the message the advertiser is trying to communicate will be more easily \"believed\" or \"internalized\". Such advertisements are considered obvious examples of \"covert\" propaganda because they take on the appearance of objective information rather than the appearance of propaganda, which is misleading. Federal law specifically mandates that any advertisement appearing in the format of a news item must state that the item is in fact a paid advertisement.\nEdmund McGarry illustrates that advertising is more than selling to an audience but a type of propaganda that is trying to persuade the public and not to be balanced in judgement.\nPolitics.\nPropaganda has become more common in political contexts, in particular, to refer to certain efforts sponsored by governments, political groups, but also often covert interests. In the early 20th century, propaganda was exemplified in the form of party slogans. Propaganda also has much in common with public information campaigns by governments, which are intended to encourage or discourage certain forms of behavior (such as wearing seat belts, not smoking, not littering, and so forth). Again, the emphasis is more political in propaganda. Propaganda can take the form of leaflets, posters, TV, and radio broadcasts and can also extend to any other medium. In the case of the United States, there is also an important legal (imposed by law) distinction between advertising (a type of overt propaganda) and what the Government Accountability Office (GAO), an arm of the United States Congress, refers to as \"covert propaganda.\" Propaganda is divided into two in political situations, they are preparation, meaning to create a new frame of mind or view of things, and operational, meaning they instigate actions.\nRoderick Hindery argues that propaganda exists on the political left, and right, and in mainstream centrist parties. Hindery further argues that debates about most social issues can be productively revisited in the context of asking \"what is or is not propaganda?\" Not to be overlooked is the link between propaganda, indoctrination, and terrorism/counterterrorism. He argues that threats to destroy are often as socially disruptive as physical devastation itself.\nSince 9/11 and the appearance of greater media fluidity, propaganda institutions, practices and legal frameworks have been evolving in the US and Britain. Briant shows how this included expansion and integration of the apparatus cross-government and details attempts to coordinate the forms of propaganda for foreign and domestic audiences, with new efforts in strategic communication. These were subject to contestation within the US Government, resisted by Pentagon Public Affairs and critiqued by some scholars. The National Defense Authorization Act for Fiscal Year 2013 (section 1078 (a)) amended the US Information and Educational Exchange Act of 1948 (popularly referred to as the Smith-Mundt Act) and the Foreign Relations Authorization Act of 1987, allowing for materials produced by the State Department and the Broadcasting Board of Governors (BBG) to be released within U.S. borders for the Archivist of the United States. The Smith-Mundt Act, as amended, provided that \"the Secretary and the Broadcasting Board of Governors shall make available to the Archivist of the United States, for domestic distribution, motion pictures, films, videotapes, and other material 12 years after the initial dissemination of the material abroad (...) Nothing in this section shall be construed to prohibit the Department of State or the Broadcasting Board of Governors from engaging in any medium or form of communication, either directly or indirectly, because a United States domestic audience is or may be thereby exposed to program material, or based on a presumption of such exposure.\" Public concerns were raised upon passage due to the relaxation of prohibitions of domestic propaganda in the United States.\nIn the wake of this, the internet has become a prolific method of distributing political propaganda, benefiting from an evolution in coding called bots. Software agents or bots can be used for many things, including populating social media with automated messages and posts with a range of sophistication. During the 2016 U.S. election a cyber-strategy was implemented using bots to direct US voters to Russian political news and information sources, and to spread politically motivated rumors and false news stories. At this point it is considered commonplace contemporary political strategy around the world to implement bots in achieving political goals.\nTechniques.\nCommon media for transmitting propaganda messages include news reports, government reports, historical revision, junk science, books, leaflets, movies, radio, television, posters and social media. Some propaganda campaigns follow a strategic transmission pattern to indoctrinate the target group. This may begin with a simple transmission, such as a leaflet or advertisement dropped from a plane or an advertisement. Generally, these messages will contain directions on how to obtain more information, via a website, hotline, radio program, etc. (as it is seen also for selling purposes among other goals). The strategy intends to initiate the individual from information recipient to information seeker through reinforcement, and then from information seeker to opinion leader through indoctrination.\nA number of techniques based in social psychological research are used to generate propaganda. Many of these same techniques can be found under logical fallacies, since propagandists use arguments that, while sometimes convincing, are not necessarily valid.\nSome time has been spent analyzing the means by which the propaganda messages are transmitted. That work is important but it is clear that information dissemination strategies become propaganda strategies only when coupled with \"propagandistic messages\". Identifying these messages is a necessary prerequisite to study the methods by which those messages are spread.\nTheodor W. Adorno wrote that fascist propaganda encourages identification with an authoritarian personality characterized by traits such as obedience and extreme aggression.17 In \"The Myth of the State,\" Ernst Cassirer wrote that while fascist propaganda mythmaking flagrantly contradicted empirical reality, it provided a simple and direct answer to the anxieties of the secular present.63\nPropaganda can also be turned on its makers. For example, postage stamps have frequently been tools for government advertising, such as North Korea's extensive issues. The presence of Stalin on numerous Soviet stamps is another example. In Nazi Germany, Hitler frequently appeared on postage stamps in Germany and some of the occupied nations. A British program to parody these, and other Nazi-inspired stamps, involved airdropping them into Germany on letters containing anti-Nazi literature.\nIn 2018 a scandal broke in which the journalist Carole Cadwalladr, several whistleblowers and the academic Emma Briant revealed advances in digital propaganda techniques showing that online human intelligence techniques used in psychological warfare had been coupled with psychological profiling using illegally obtained social media data for political campaigns in the United States in 2016 to aid Donald Trump by the firm Cambridge Analytica. The company initially denied breaking laws but later admitted breaking UK law, the scandal provoking a worldwide debate on acceptable use of data for propaganda and influence.\nModels.\nPersuasion in social psychology.\nThe field of social psychology includes the study of persuasion. Social psychologists can be sociologists or psychologists. The field includes many theories and approaches to understanding persuasion. For example, communication theory points out that people can be persuaded by the communicator's credibility, expertise, trustworthiness, and attractiveness. The elaboration likelihood model, as well as heuristic models of persuasion, suggest that a number of factors (e.g., the degree of interest of the recipient of the communication), influence the degree to which people allow superficial factors to persuade them. Nobel Prize\u2013winning psychologist Herbert A. Simon won the Nobel prize for his theory that people are cognitive misers. That is, in a society of mass information, people are forced to make decisions quickly and often superficially, as opposed to logically.\nAccording to William W. Biddle's 1931 article \"A psychological definition of propaganda\", \"[t]he four principles followed in propaganda are: (1) rely on emotions, never argue; (2) cast propaganda into the pattern of \"we\" versus an \"enemy\"; (3) reach groups as well as individuals; (4) hide the propagandist as much as possible.\"\nMore recently, studies from behavioral science have become significant in understanding and planning propaganda campaigns, these include for example nudge theory which was used by the Obama Campaign in 2008 then adopted by the UK Government Behavioural Insights Team. Behavioural methodologies then became subject to great controversy in 2016 after the company Cambridge Analytica was revealed to have applied them with millions of people's breached Facebook data to encourage them to vote for Donald Trump.\nHaifeng Huang argues that propaganda is not always necessarily about convincing a populace of its message (and may actually fail to do this) but instead can also function as a means of intimidating the citizenry and signalling the regime's strength and ability to maintain its control and power over society; by investing significant resources into propaganda, the regime can forewarn its citizens of its strength and deterring them from attempting to challenge it.\nPropaganda theory and education.\nDuring the 1930s, educators in the United States and around the world became concerned about the rise of anti-Semitism and other forms of violent extremism. The Institute for Propaganda Analysis was formed to introduce methods of instruction for high school and college students, helping learners to recognize and desist propaganda by identifying persuasive techniques. This work built upon classical rhetoric and it was informed by suggestion theory and social scientific studies of propaganda and persuasion. In the 1950s, propaganda theory and education examined the rise of American consumer culture, and this work was popularized by Vance Packard in his 1957 book, \"The Hidden Persuaders\". European theologian Jacques Ellul's landmark work, \"\" framed propaganda in relation to larger themes about the relationship between humans and technology. Media messages did not serve to enlighten or inspire, he argued. They merely overwhelm by arousing emotions and oversimplifying ideas, limiting human reasoning and judgement.\nIn the 1980s, academics recognized that news and journalism could function as propaganda when business and government interests were amplified by mass media. The propaganda model is a theory advanced by Edward S. Herman and Noam Chomsky which argues systemic biases exist in mass media that are shaped by structural economic causes. It argues that the way in which commercial media institutions are structured and operate (e.g. through advertising revenue, concentration of media ownership, or access to sources) creates an inherent conflict of interest that make them act as propaganda for powerful political and commercial interests:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The 20th century has been characterized by three developments of great political importance: the growth of democracy, the growth of corporate power, and the growth of corporate propaganda as a means of protecting corporate power against democracy.\nFirst presented in their book \"\" (1988), the propaganda model analyses commercial mass media as businesses that sell a product\u00a0\u2013 access to readers and audiences\u00a0\u2013 to other businesses (advertisers) and that benefit from access to information from government and corporate sources to produce their content. The theory postulates five general classes of \"filters\" that shape the content that is presented in news media: ownership of the medium, reliance on advertising revenue, access to news sources, threat of litigation and commercial backlash (flak), and anti-communism and \"fear ideology\". The first three (ownership, funding, and sourcing) are generally regarded by the authors as being the most important. Although the model was based mainly on the characterization of United States media, Chomsky and Herman believe the theory is equally applicable to any country that shares the basic political economic structure, and the model has subsequently been applied by other scholars to study media bias in other countries.\nBy the 1990s, the topic of propaganda was no longer a part of public education, having been relegated to a specialist subject. Secondary English educators grew fearful of the study of propaganda genres, choosing to focus on argumentation and reasoning instead of the highly emotional forms of propaganda found in advertising and political campaigns. In 2015, the European Commission funded Mind Over Media, a digital learning platform for teaching and learning about contemporary propaganda. The study of contemporary propaganda is growing in secondary education, where it is seen as a part of language arts and social studies education.\nSelf-propaganda.\nSelf-propaganda is a form of propaganda that refers to the act of an individual convincing themself of something, no matter how irrational that idea may be. Self propaganda makes it easier for individuals to justify their own actions as well as the actions of others. Self-propaganda often works to lessen the cognitive dissonance felt by individuals when their personal actions or the actions of their government do not line up with their moral beliefs. Self-propaganda is a type of self deception. Self-propaganda can have a negative impact on those who perpetuate the beliefs created by using self-propaganda.\nChildren.\nOf all the potential targets for propaganda, children are the most vulnerable because they are the least prepared with the critical reasoning and contextual comprehension they need to determine whether message is a propaganda or not. The attention children give their environment during development, due to the process of developing their understanding of the world, causes them to absorb propaganda indiscriminately. Also, children are highly imitative: studies by Albert Bandura, Dorothea Ross and Sheila A. Ross in the 1960s indicated that, to a degree, socialization, formal education and standardized television programming can be seen as using propaganda for the purpose of indoctrination. The use of propaganda in schools was highly prevalent during the 1930s and 1940s in Germany in the form of the Hitler Youth.\nAnti-Semitic propaganda for children.\nIn Nazi Germany, the education system was thoroughly co-opted to indoctrinate the German youth with anti-Semitic ideology. From the 1920s on, the Nazi Party targeted German youth as one of their special audience for its propaganda messages. Schools and texts mirrored what the Nazis aimed of instilling in German youth through the use and promotion of racial theory. Julius Streicher, the editor of \"Der St\u00fcrmer\", headed a publishing house that disseminated anti-Semitic propaganda picture books in schools during the Nazi dictatorship. This was accomplished through the National Socialist Teachers League, of which 97% of all German teachers were members in 1937.\nThe League encouraged the teaching of racial theory. Picture books for children such as \"Trust No Fox on his Green Heath and No Jew on his Oath\", \"Der Giftpilz\" (translated into English as \"The Poisonous Mushroom\") and \"The Poodle-Pug-Dachshund-Pinscher\" were widely circulated (over 100,000 copies of \"Trust No Fox\"...\u00a0were circulated during the late 1930s) and contained depictions of Jews as devils, child molesters and other morally charged figures. Slogans such as \"Judas the Jew betrayed Jesus the German to the Jews\" were recited in class. During the Nuremberg Trial, \"Trust No Fox on his Green Heath and No Jew on his Oath\", and \"Der Giftpilz\" were received as documents in evidence because they document the practices of the Nazis The following is an example of a propagandistic math problem recommended by the National Socialist Essence of Education: \"The Jews are aliens in Germany\u2014in 1933 there were 66,606,000 inhabitants in the German Reich, of whom 499,682 (0.75%) were Jews.\"\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n(See also version of text at website \"www.historyisaweapon.com\": \"Propaganda.\")"}
{"id": "23204", "revid": "6727347", "url": "https://en.wikipedia.org/wiki?curid=23204", "title": "Physical quantity", "text": "Measurable property of a material or system\nA physical quantity (or simply quantity) is a property of a material or system that can be quantified by measurement. A physical quantity can be expressed as a \"value\", which is the algebraic multiplication of a \"numerical value\" and a \"unit of measurement\". For example, the physical quantity mass, symbol \"m\", can be quantified as \"m\"\n\"n\"kg, where \"n\" is the numerical value and kg is the unit symbol (for kilogram). Vector quantities have, besides numerical value and unit, direction or orientation in space.\nPrinciples.\nDimensions.\nThe notion of \"dimension\" of a physical quantity was introduced by Joseph Fourier in 1822. By convention, physical quantities are organized in a dimensional system built upon base quantities, each of which is regarded as having its own dimension.\nThe dimension of a quantity \"Z\" is denoted or dim(\"Z\").\nKind.\nDimensional homogeneity is not necessarily sufficient for quantities to be comparable;\nfor example, both kinematic viscosity and thermal diffusivity have dimension of square length per time (in units of m2/s).\nQuantities of the same kind share extra commonalities beyond their dimension and units allowing their comparison;\nfor example, not all dimensionless quantities are of the same kind (&lt;templatestyles src=\"Crossreference/styles.css\" /&gt;).\nUnit.\nThere is often a choice of unit, though SI units are usually used in scientific contexts due to their ease of use, international familiarity and prescription. For example, a quantity of mass might be represented by the symbol \"m\", and could be expressed in the units kilograms (kg), pounds (lb), or daltons (Da).\nThe unit of a quantity Z is denoted [\"Z\"].\nNumerical value.\nFollowing ISO 80000-1, any value or magnitude of a physical quantity is expressed as a comparison to a unit of that quantity. The \"value\" of a physical quantity \"Z\" is expressed as the product of a \"numerical value\" {\"Z\"} (a pure number) and a unit [\"Z\"]:\nformula_1\nFor example, let formula_2 be \"2 metres\"; then, formula_3 is the numerical value and formula_4 is the unit.\nConversely, the numerical value expressed in an arbitrary unit can be obtained as:\nformula_5\nThe multiplication sign is usually left out, just as it is left out between variables in the scientific notation of formulas. The convention used to express quantities is referred to as \"quantity calculus\". In formulas, the unit [\"Z\"] can be treated as if it were a specific magnitude of a kind of physical dimension: see \"Dimensional analysis\" for more on this treatment.\nTypography.\nInternational recommendations for the use of symbols for quantities are set out in ISO/IEC 80000, the IUPAP red book and the IUPAC green book. For example, the recommended symbol for the physical quantity \"mass\" is \"m\", and the recommended symbol for the quantity \"electric charge\" is \"Q\".\nPhysical quantities are normally typeset in italics.\nPurely numerical quantities, even those denoted by letters, are usually printed in roman (upright) type, though sometimes in italics. Symbols for elementary functions (circular trigonometric, hyperbolic, logarithmic etc.), changes in a quantity like \u0394 in \u0394\"y\" or operators like d in d\"x\", are also recommended to be printed in roman type.\nExamples:\nSupport.\nScalars.\nA \"scalar\" is a physical quantity that has magnitude but no direction. Symbols for physical quantities are usually chosen to be a single letter of the Latin or Greek alphabet, and are printed in italic type.\nVectors.\n\"Vectors\" are physical quantities that possess both magnitude and direction and whose operations obey the axioms of a vector space. Symbols for physical quantities that are vectors are in bold type, underlined or with an arrow above. For example, if \"u\" is the speed of a particle, then the straightforward notations for its velocity are u, u, or formula_6.\nTensors.\nScalar and vector quantities are the simplest tensor quantities, which are tensors that can be used to describe more general physical properties. For example, the Cauchy stress tensor possesses magnitude, direction, and orientation qualities.\nBase and derived quantities.\nBase quantities.\nA system of quantities relates physical quantities, and due to this dependence, a limited number of quantities can serve as a basis in terms of which the dimensions of all the remaining quantities of the system can be defined. A set of mutually independent quantities may be chosen by convention to act as such a set, and are called base quantities. The seven base quantities of the International System of Quantities (ISQ) and their corresponding SI units and dimensions are listed in the following table.136 Other conventions may have a different number of base units (e.g. the CGS and MKS systems of units).\nThe angular quantities, plane angle and solid angle, are defined as derived dimensionless quantities in the SI. For some relations, their units radian and steradian can be written explicitly to emphasize the fact that the quantity involves plane or solid angles.137\nGeneral derived quantities.\nDerived quantities are those whose definitions are based on other physical quantities (base quantities).\nSpace.\nImportant applied base units for space and time are below. Area and volume are thus, of course, derived from the length, but included for completeness as they occur frequently in many derived quantities, in particular densities.\nDensities, flows, gradients, and moments.\nImportant and convenient derived quantities such as densities, fluxes, flows, currents are associated with many quantities. Sometimes different terms such as \"current density\" and \"flux density\", \"rate\", \"frequency\" and \"current\", are used interchangeably in the same context; sometimes they are used uniquely.\nTo clarify these effective template-derived quantities, we use \"q\" to stand for \"any\" quantity within some scope of context (not necessarily base quantities) and present in the table below some of the most commonly used symbols where applicable, their definitions, usage, SI units and SI dimensions \u2013 where [\"q\"] denotes the dimension of \"q\".\nFor time derivatives, specific, molar, and flux densities of quantities, there is no one symbol; nomenclature depends on the subject, though time derivatives can be generally written using overdot notation. For generality we use \"qm\", \"qn\", and F respectively. No symbol is necessarily required for the gradient of a scalar field, since only the nabla/del operator \u2207 or grad needs to be written. For spatial density, current, current density and flux, the notations are common from one context to another, differing only by a change in subscripts.\nFor current density, formula_7 is a unit vector in the direction of flow, i.e. tangent to a flowline. Notice the dot product with the unit normal for a surface, since the amount of current passing through the surface is reduced when the current is not normal to the area. Only the current passing perpendicular to the surface contributes to the current passing \"through\" the surface, no current passes \"in\" the (tangential) plane of the surface.\nThe calculus notations below can be used synonymously.\nIf \"X\" is a \"n\"-variable function formula_8, then\nDifferential The differential \"n\"-space volume element is formula_9,\nIntegral: The \"multiple\" integral of \"X\" over the \"n\"-space volume is formula_10.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23205", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=23205", "title": "Physical constant", "text": "Universal and unchanging physical quantity\nA physical constant, sometimes called a fundamental physical constant or universal constant, is a physical quantity that cannot be explained by a theory and therefore must be measured experimentally. It is distinct from a \"mathematical constant\", which has a fixed numerical value, but does not directly involve any physical measurement.\nThere are many physical constants in science, some of the most widely recognized being the speed of light in vacuum \"c\", the gravitational constant \"G\", the Planck constant \"h\", the electric constant \"\u03b5\"0, and the elementary charge \"e\". Physical constants can take many dimensional forms: the speed of light has dimension of length divided by time (), while the proton-to-electron mass ratio is dimensionless.\nThe term \"fundamental physical constant\" is sometimes used to refer to universal-but-dimensioned physical constants such as those mentioned above. Increasingly, however, physicists reserve the expression for the narrower case of \"dimensionless universal physical constants\", such as the fine-structure constant \"\u03b1\", which characterizes the strength of the electromagnetic interaction.\nPhysical constants, as discussed here, should not be confused with \"empirical constants\", which are coefficients or parameters assumed to be constant in a given context without being fundamental. Examples include the characteristic time, characteristic length, or characteristic number (dimensionless) of a given system, or material constants (e.g., Madelung constant, electrical resistivity, and heat capacity) of a particular material or substance.\nCharacteristics.\nPhysical constants are parameters in a physical theory that cannot be explained by that theory. This may be due to the apparent fundamental nature of the constant or due to limitations in the theory. Consequently, physical constants must be measured experimentally.\nThe set of parameters considered physical constants change as physical models change and how fundamental they appear can change. For example, formula_1, the speed of light, was originally considered a property of light, a specific system. The discovery and verification of Maxwell's equations connected the same quantity with an entire system, electromagnetism. When the theory of special relativity emerged, the quantity came to be understood as the basis of causality. The speed of light is so fundamental it now defines the international unit of length.\nRelationship to units.\nNumerical values.\nWhereas the physical quantity indicated by a physical constant does not depend on the unit system used to express the quantity, the numerical values of dimensional physical constants do depend on choice of unit system. The term \"physical constant\" refers to the physical quantity, and not to the numerical value within any given system of units. For example, the speed of light is defined as having the numerical value of when expressed in the SI unit metres per second, and as having the numerical value of 1 when expressed in the natural units Planck length per Planck time. While its numerical value can be defined at will by the choice of units, the speed of light itself is a single physical constant.\nInternational System of Units.\nSince 2019 revision, all of the units in the International System of Units have been defined in terms of fixed natural phenomena, including three fundamental constants: the speed of light in vacuum, \"c\"; the Planck constant, \"h\"; and the elementary charge, \"e\".\nAs a result of the new definitions, an SI unit like the kilogram can be written in terms of fundamental constants and one experimentally measured constant, \u0394\"\u03bd\"Cs:\n 1\u00a0kg = .\nNatural units.\nIt is possible to combine dimensional universal physical constants to define fixed quantities of any desired dimension, and this property has been used to construct various systems of natural units of measurement. Depending on the choice and arrangement of constants used, the resulting natural units may be convenient to an area of study. For example, Planck units, constructed from \"c\", \"G\", \"\u0127\", and \"k\"B give conveniently sized measurement units for use in studies of quantum gravity, and atomic units, constructed from \"\u0127\", \"m\"e, \"e\" and 4\"\u03c0\"\"\u03b5\"0 give convenient units in atomic physics. The choice of constants used leads to widely varying quantities.\nNumber of fundamental constants.\nThe number of fundamental physical constants depends on the physical theory accepted as \"fundamental\". Currently, this is the theory of general relativity for gravitation and the Standard Model for electromagnetic, weak and strong nuclear interactions and the matter fields. Between them, these theories account for a total of 19 independent fundamental constants. There is, however, no single \"correct\" way of enumerating them, as it is a matter of arbitrary choice which quantities are considered \"fundamental\" and which as \"derived\". Uzan lists 22 \"fundamental constants of our standard model\" as follows: \nThe number of 19 independent fundamental physical constants is subject to change under possible extensions of the Standard Model, notably by the introduction of neutrino mass (equivalent to seven additional constants, i.e. 3 Yukawa couplings and 4 lepton mixing parameters).\nThe discovery of variability in any of these constants would be equivalent to the discovery of \"new physics\".\nThe question as to which constants are \"fundamental\" is neither straightforward nor meaningless, but a question of interpretation of the physical theory regarded as fundamental; as pointed out by , not all physical constants are of the same importance, with some having a deeper role than others. proposed a classification schemes of three types of constants: \nThe same physical constant may move from one category to another as the understanding of its role deepens; this has notably happened to the speed of light, which was a class A constant (characteristic of light) when it was first measured, but became a class B constant (characteristic of electromagnetic phenomena) with the development of classical electromagnetism, and finally a class C constant with the discovery of special relativity.\nTests on time-independence.\nBy definition, fundamental physical constants are subject to measurement, so that their being constant (independent on both the time and position of the performance of the measurement) is necessarily an experimental result and subject to verification.\nPaul Dirac in 1937 speculated that physical constants such as the gravitational constant or the fine-structure constant might be subject to change over time in proportion of the age of the universe. Experiments can in principle only put an upper bound on the relative change per year. For the fine-structure constant, this upper bound is comparatively low, at roughly 10\u221217 per year (as of 2008).\nThe gravitational constant is much more difficult to measure with precision, and conflicting measurements in the 2000s have inspired the controversial suggestions of a periodic variation of its value in a 2015 paper. However, while its value is not known to great precision, the possibility of observing type Ia supernovae which happened in the universe's remote past, paired with the assumption that the physics involved in these events is universal, allows for an upper bound of less than 10\u221210 per year for the gravitational constant over the last nine billion years.\nSimilarly, an upper bound of the change in the proton-to-electron mass ratio has been placed at 10\u22127 over a period of 7 billion years (or 10\u221216 per year) in a 2012 study based on the observation of methanol in a distant galaxy.\nIt is problematic to discuss the proposed rate of change (or lack thereof) of a single \"dimensional\" physical constant in isolation. The reason for this is that the choice of units is arbitrary, making the question of whether a constant is undergoing change an artefact of the choice (and definition) of the units.\nFor example, in SI units, the speed of light was given a defined value in 1983. Thus, it was meaningful to experimentally measure the speed of light in SI units prior to 1983, but it is not so now. Similarly, with effect from May 2019, the Planck constant has a defined value, such that all SI base units are now defined in terms of fundamental physical constants. With this change, the international prototype of the kilogram is being retired as the last physical object used in the definition of any SI unit.\nTests on the immutability of physical constants look at \"dimensionless\" quantities, i.e. ratios between quantities of like dimensions, in order to escape this problem. Changes in physical constants are not meaningful if they result in an \"observationally indistinguishable\" universe. For example, a \"change\" in the speed of light \"c\" would be meaningless if accompanied by a corresponding change in the elementary charge \"e\" so that the expression \"e\"2/(4\u03c0\"\u03b5\"0\"\u0127c\") (the fine-structure constant) remained unchanged.\nDimensionless physical constants.\nAny ratio between physical constants of the same dimensions results in a dimensionless physical constant, for example, the proton-to-electron mass ratio. The fine-structure constant \"\u03b1\", introduced by Arnold Sommerfeld, is the best known dimensionless fundamental physical constant. It is the value of the elementary charge squared expressed in Planck units. This value has become a standard example when discussing the derivability or non-derivability of physical constants.\nFine-tuned universe.\nSome physicists have explored the notion that if the dimensionless physical constants had sufficiently different values, our Universe would be so radically different that intelligent life would probably not have emerged, and that our Universe therefore seems to be fine-tuned for intelligent life. The anthropic principle states a logical truism: the fact of our existence as intelligent beings who can measure physical constants requires those constants to be such that beings like us can exist. There are a variety of interpretations of the constants' values, including that of a divine creator (the apparent fine-tuning is actual and intentional), or that the universe is one universe of many in a multiverse (e.g. the many-worlds interpretation of quantum mechanics), or even that, if information is an innate property of the universe and logically inseparable from consciousness, a universe without the capacity for conscious beings cannot exist.\nTable of physical constants.\nThe table below lists some frequently used constants and their CODATA recommended values. For a more extended list, refer to \"List of physical constants\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23206", "revid": "50817739", "url": "https://en.wikipedia.org/wiki?curid=23206", "title": "Parsley", "text": "Species of flowering plant in the celery family Apiaceae cultivated as an herb\n&lt;templatestyles src=\"Template:Taxobox/core/styles.css\" /&gt;\nParsley, or garden parsley (Petroselinum crispum), is a species of flowering plant in the family Apiaceae that is native to the Balkans. It has been introduced and naturalized in Europe and elsewhere in the world with suitable climates, and is widely cultivated as a herb and a vegetable.\nIt is believed to have been originally grown in Sardinia, and was cultivated in around the 3rd century BC. Linnaeus stated its wild habitat to be Sardinia, whence it was brought to England and apparently first cultivated in Britain in 1548, though literary evidence suggests parsley was used in England in the Middle Ages as early as the Anglo-Saxon period.\nParsley is widely used in European, Middle Eastern, and American cuisine. Curly-leaf parsley is often used as a garnish. In central Europe, eastern Europe, and southern Europe, as well as in western Asia, many dishes are served with fresh green chopped parsley sprinkled on top. Flat-leaf parsley is similar, but is often preferred by chefs because it has a stronger flavor. Root parsley is very common in central, eastern, and southern European cuisines, where it is eaten as a snack, or as a vegetable in many soups, stews, and casseroles.\nEtymology.\nThe word \"parsley\" is a merger of Old English ' (which is identical to the contemporary German word for parsley: ) and the Old French '. Both of these names are derived from Medieval Latin , from Latin , which is the latinization of the Greek , from and . Mycenaean Greek se-ri-no, in Linear B, is the earliest attested form of the word \"selinon\".\nDescription.\nGarden parsley is a bright green, biennial plant in temperate climates, or an annual herb in subtropical and tropical areas.\nWhere it grows as a biennial, in the first year, it forms a rosette of tripinnate leaves 10\u201325\u00a0cm long with numerous 1\u20133\u00a0cm leaflets, and a taproot used as a food store over the winter. In the second year, it grows a flowering stem to tall with sparser leaves and flat-topped 3\u201310\u00a0cm diameter umbels with numerous 2\u00a0mm diameter yellow to yellowish-green flowers.\nThe seeds are ovoid, 2\u20133\u00a0mm long, with prominent style remnants at the apex. One of the compounds of the essential oil is apiole. The plant normally dies after seed maturation.\nUses.\nCulinary.\nParsley is widely used in Middle Eastern, Mediterranean, Brazilian, and American cuisine. Curly leaf parsley is used often as a garnish. Green parsley is used frequently as a garnish on potato dishes (boiled or mashed potatoes), on rice dishes (risotto or pilaf), on fish, fried chicken, lamb, goose, and steaks, as well as in meat or vegetable stews (including shrimp creole, beef bourguignon, goulash, or chicken paprikash).\nParsley seeds are also used in cooking, imparting a stronger parsley flavor than leaves.\nParsley, when consumed, is credited with neutralising odours associated with garlic in cooking.\nIn central Europe, eastern Europe, and southern Europe, as well as in western Asia, many dishes are served with fresh green, chopped parsley sprinkled on top. In southern and central Europe, parsley is part of \"bouquet garni\", a bundle of fresh herbs used as an ingredient in stocks, soups, and sauces. Freshly chopped green parsley is used as a topping for soups such as chicken soup, green salads, or salads such as \"salade Olivier\", and on open sandwiches with cold cuts or \"p\u00e2t\u00e9s\".\n\"Persillade\" is a mixture of chopped garlic and chopped parsley in French cuisine.\nParsley is the main ingredient in Italian salsa verde, which is a mixed condiment of parsley, capers, anchovies, garlic, and sometimes bread, soaked in vinegar. It is an Italian custom to serve it with bollito misto or fish. \"Gremolata\", a mixture of parsley, garlic, and lemon zest, is a traditional accompaniment to the Italian veal stew, \"ossobuco alla milanese\".\nRoot parsley is very common in Central, Eastern, and Southern European cuisines, where it is used as a snack or a vegetable in many soups, stews, and casseroles, and as ingredient for broth.\nFreshly chopped parsley () and freshly chopped scallion () are the main ingredients in the herb seasoning called (literally \"green aroma\"), which is used as key seasoning for major Brazilian dishes, including meat, chicken, fish, rice, beans, stews, soups, vegetables, salads, condiments, sauces, and stocks. is sold in food markets as a bundle of both types of fresh herbs. In some Brazilian regions, chopped parsley may be replaced by chopped coriander (also called cilantro, in Portuguese) in the mixture.\nParsley is a key ingredient in several Middle Eastern salads such as Lebanese \"tabbouleh\"; it is also often mixed in with the chickpeas and/or fava beans while making falafel (that gives the inside of the falafel its green color). It is also a main component of the Iranian stew \"ghormeh sabzi\".\nParsley is a component of a standard Seder plate arrangement, it is eaten to symbolize the flourishing of the Jews after first arriving in Egypt.\nMilitary.\nThe Parsley Massacre in October 1937 claimed the lives of an estimated 14,000 to 40,000 Haitian men, women, and children. Dominican Republic soldiers would hold up a sprig of parsley to someone and ask what it was. How the person pronounced the Spanish word for parsley (perejil) determined their fate. If they could pronounce it the Spanish way the soldiers considered them Dominican and let them live, but if they pronounced it the French or Creole way they considered them Haitian and murdered them. Haitian speakers can have difficulty pronouncing the alveolar tap or the alveolar trill of Spanish. However, most scholars think this story an exaggeration.\nComposition.\nNutritional content.\nParsley is a source of flavonoids and antioxidants, especially luteolin, apigenin, folate, vitamin K, vitamin C, and vitamin A. Half a tablespoon (a gram) of dried parsley contains about 6.0\u00a0\u03bcg of lycopene and 10.7\u00a0\u03bcg of alpha carotene as well as 82.9\u00a0\u03bcg of lutein+zeaxanthin and 80.7\u00a0\u03bcg of beta carotene. Dried parsley can contain about 45\u00a0mg/gram apigenin. The apigenin content of fresh parsley is reportedly 215.5\u00a0mg/100 grams, which is much higher than the next highest food source, green celery hearts providing 19.1\u00a0mg/100 grams. Parsley essential oil is high in myristicin.\nPrecautions.\nExcessive consumption of parsley should be avoided by pregnant women. Normal food quantities are safe for pregnant women, but consuming excessively large amounts may have uterotonic effects.\nCultivation.\nParsley grows best in moist, well-drained soil, with full sun. It grows best between , and usually is grown from seed. Germination is slow, taking four to six weeks, and it often is difficult because of furanocoumarins in its seed coat. Typically, plants grown for the leaf crop are spaced 10\u00a0cm apart, while those grown as a root crop are spaced 20\u00a0cm apart to allow for the root development.\nParsley attracts several species of wildlife. Some swallowtail butterflies use parsley as a host plant for their larvae; their caterpillars are black and green striped with yellow dots, and will feed on parsley for two weeks before turning into butterflies. Bees and other nectar-feeding insects also visit the flowers. \nCultivars.\nParsley is subdivided into several cultivar groups. Often these are treated as botanical varieties, despite being cultivated selections, not of natural botanical origin.\nLeaf parsley.\nThe two main groups of parsley used as herbs are French, or curly leaf (\"P. crispum\" Crispum Group; syn. \"P. crispum\" var. \"crispum\"); and, Italian, or flat leaf (\"P. crispum\" Neapolitanum Group; syn. \"P. crispum\" var. \"neapolitanum\"). Flat-leaved parsley is preferred by some gardeners as it is easier to cultivate, being more tolerant of both rain and sunshine, and is said to have a stronger flavor\u2014although this is disputed\u2014while curly leaf parsley is preferred by others because of its more decorative appearance in garnishing. A third type, sometimes grown in southern Italy, has thick leaf stems resembling celery.\nRoot parsley.\nAnother type of parsley is grown as a root vegetable, the Hamburg root parsley (\"P. crispum\" Radicosum Group, syn. \"P. crispum\" var. \"tuberosum\"). This type of parsley produces much thicker roots than types cultivated for their leaves. Although seldom used in Britain and the United States, root parsley is common in central and eastern European cuisine, where it is used in soups and stews, or simply eaten raw, as a snack (similar to carrots).\nAlthough root parsley looks similar to the parsnip, which is among its closest relatives in the family Apiaceae, its taste is quite different.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23209", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=23209", "title": "Peppermint", "text": "Hybrid flowering plant in the family Lamiaceae\n&lt;templatestyles src=\"Template:Taxobox/core/styles.css\" /&gt;\nPeppermint (Mentha\" \u00d7 \"piperita) is a hybrid species of mint, a cross between watermint and spearmint. Indigenous to Europe and the Middle East, the plant is now widely spread and cultivated in many regions of the world. It is occasionally found in the wild with its parent species.\nAlthough the genus \"Mentha\" comprises more than 25 species, the one in most common use is peppermint. While Western peppermint is derived from \"Mentha \u00d7 piperita\", Chinese peppermint, or \"bohe\", is derived from the fresh leaves of \"M. haplocalyx\". \"M. \u00d7 piperita\" and \"M. haplocalyx\" are both recognised as plant sources of menthol and menthone, and are among the oldest herbs used for both culinary and medicinal products.\nBotany.\nPeppermint was first identified in Hertfordshire, England, by a Dr. Eales, a discovery which John Ray published 1696 in the second edition of his book \"Synopsis Methodica Stirpium Britannicarum\". He initially gave it the name \"Mentha spicis brevioribus et habitioribus, foliis Mentha fusca, sapore fervido piperis\" and later in his 1704 volume \"Historia Plantarum\" he called it \"Mentha palustris\" or Peper\u2013Mint. The plant was then added to the London \"Pharmacopoeia\" under the name \"Mentha piperitis sapore\" in 1721. \nIt was given the name \"Mentha piperita\" in 1753 by Carl Linnaeus in his \"Species Plantarum\" Volume 2. Linnaeus treated peppermint as a species, but it is now agreed to be a hybrid between \"Mentha aquatica\" and \"Mentha spicata\", with \"M. spicata\" itself also being considered by some authors to be a hybrid between \"Mentha longifolia\" and \"Mentha suaveolens\".\nPeppermint is a herbaceous, rhizomatous, perennial plant that grows to be tall, with smooth stems, square in cross section. The rhizomes are wide-spreading and fleshy, and bear fibrous roots. The leaves can be long and broad. They are dark green with reddish veins, with an acute apex and coarsely toothed margins. The leaves and stems are usually slightly fuzzy. The flowers are purple, long, with a four-lobed corolla about diameter; they are produced in whorls (verticillasters) around the stem, forming thick, blunt spikes. Flowering season lasts from mid- to late summer. The chromosome number is variable, with 2n counts of 66, 72, 84, and 120 recorded. Peppermint is a fast-growing plant, spreading quickly once it has sprouted.\nEcology.\nPeppermint typically occurs in moist habitats, including stream sides and drainage ditches. Being a hybrid, it is usually sterile, producing no seeds and reproducing only vegetatively, spreading by its runners.\nOutside of its native range, areas where peppermint was formerly grown for oil often have an abundance of feral plants, and it is considered invasive in Australia, the Gal\u00e1pagos Islands, New Zealand, and the United States in the Great Lakes region, noted since 1843.\nCultivation.\nPeppermint generally grows best in moist, shaded locations, and expands by underground rhizomes. Young shoots are taken from old stocks and dibbled into the ground about 0.5\u00a0m (1.5\u00a0ft) apart. They grow quickly and cover the ground with runners if it is permanently moist. For the home gardener, it is often grown in containers to restrict rapid spreading. It grows best with a good supply of water, without being waterlogged, and planted in areas with partial sun to shade.\nThe leaves and flowering tops are used; they are collected as soon as the flowers begin to open and can be dried. The wild form of the plant is less suitable for this purpose, with cultivated plants having been selected for more and better oil content. They may be allowed to lie and wilt a little before distillation, or they may be taken directly to the still.\nCultivars.\nSeveral cultivars have been selected for garden use:\nCommercial cultivars may include:\nDiseases.\nVerticillium wilt is a major constraint in peppermint cultivation. 'Todd's Mitcham', 'Refined Murray', 'Roberts Mitcham' (see above), and a few other cultivars have some degree of resistance.\nProduction.\nIn 2022, world production of peppermint was 51,081 tonnes, led by Morocco with 84% of the total and Argentina with 14% (table). \nIn the United States, Oregon and Washington produce most of the country's peppermint, the leaves of which are processed for the essential oil to produce flavourings mainly for chewing gum and toothpaste.\nChemical constituents.\nPeppermint has a high menthol content. Dried peppermint typically has 0.3\u20130.4% of volatile oil containing menthol (7\u201348%), menthone (20\u201346%), menthyl acetate (3\u201310%), menthofuran (1\u201317%), and 1,8-cineol (3\u20136%).\nPeppermint contains terpenoids and flavonoids such as eriocitrin, hesperidin, and kaempferol 7-O-rutinoside.\nOil.\nPeppermint oil has a high concentration of natural pesticides, mainly pulegone (found mainly in \"\"M. arvensis\" var. \"piperascens\"\" [= \"Mentha canadensis\"], and to a lesser extent (6,530 ppm) in \"Mentha\" \u00d7 \"piperita\") and menthone. It is known to repel some pest insects, including mosquitos, and has uses in organic gardening. It is also widely used to repel rodents.\nThe chemical composition of the essential oil from \"Mentha\" \u00d7 \"piperita\" was analysed by GC/FID and GC-MS. The main constituents were menthol (40.7%) and menthone (23.4%). Further components are 1,8-cineole (5.3%), (+/-)-Menthyl acetate (4.2%), iso-Menthone (3.7%), Menthofurane (3.7%), neo-Menthol (3.2%), Limonene (2.6%), Pulegone (1.9%), \u03b2-Caryophyllene (1.7%), \u03b2-Pinene (1.1%), Germacrene D (0.9%), \u03b1-Pinene (0.7%), and Piperitone (0.6%). Peppermint oil also contains smaller amounts of many additional compounds \nResearch and health effects.\nPeppermint oil is under preliminary research for its potential as a short-term treatment for irritable bowel syndrome. High oral doses of peppermint oil (500\u00a0mg) can cause mucosal irritation and mimic heartburn.\nPeppermint oil and leaves have a cooling effect when used topically for muscle pain, nerve pain, relief from itching, or as a fragrance.\nPeppermint oil had supposed uses in ancient traditional medicine for minor gastrointestinal diseases.\nCulinary and other uses.\nFresh or dried peppermint leaves are often used alone in peppermint tea or with other herbs in herbal teas (tisanes, infusions). Peppermint is used for flavouring ice cream, candy, fruit preserves, alcoholic beverages, chewing gum, toothpaste, and some shampoos, soaps, and skin care products.\nMenthol activates cold-sensitive TRPM8 receptors in the skin and mucosal tissues, and is the primary source of the cooling sensation that follows the topical application of peppermint oil.\nPeppermint oil is also used in construction and plumbing to test for the tightness of pipes and disclose leaks by its odour.\nSafety.\nMedicinal uses of peppermint have not been approved as effective or safe by the US Food and Drug Administration. With caution that the concentration of the peppermint constituent pulegone should not exceed 1% (140\u00a0mg), peppermint preparations are considered safe by the European Medicines Agency when used in topical formulations for adult subjects. Diluted peppermint essential oil is safe for oral intake when only a few drops are used.\nAlthough peppermint is commonly available as a herbal supplement, no established, consistent manufacturing standards exist for it, and some peppermint products may be contaminated with toxic metals or other substituted compounds. Skin rashes, irritation, or allergic reactions may result from applying peppermint oil to the skin, and its use on the face or chest of young children may cause side effects if the oil menthol is inhaled. A common side effect from oral intake of peppermint oil or capsules is heartburn. Oral use of peppermint products may have adverse effects when used with iron supplements, cyclosporine, medicines for heart conditions or high blood pressure, or medicines to decrease stomach acid.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23210", "revid": "30395827", "url": "https://en.wikipedia.org/wiki?curid=23210", "title": "Pseudorandomness", "text": "Appearing random but actually being generated by a deterministic, causal process\nA pseudorandom sequence of numbers is one that appears to be statistically random, despite having been produced by a completely deterministic and repeatable process. Pseudorandom number generators are often used in computer programming, as traditional sources of randomness available to humans (such as rolling dice) rely on physical processes not readily available to computer programs, although developments in hardware random number generator technology have challenged this.\nBackground.\nThe generation of random numbers has many uses, such as for random sampling, Monte Carlo methods, board games, or gambling. In physics, however, most processes, such as gravitational acceleration, are deterministic, meaning that they always produce the same outcome from the same starting point. Some notable exceptions are radioactive decay and quantum measurement, which are both modeled as being truly random processes in the underlying physics. Since these processes are not practical sources of random numbers, pseudorandom numbers are used, which ideally have the unpredictability of a truly random sequence, despite being generated by a deterministic process.\nIn many applications, the deterministic process is a computer algorithm called a pseudorandom number generator, which must first be provided with a number called a random seed. Since the same seed will yield the same sequence every time, it is important that the seed be well chosen and kept hidden, especially in security applications, where the pattern's unpredictability is a critical feature.\nIn some cases where it is important for the sequence to be demonstrably unpredictable, physical sources of random numbers have been used, such as radioactive decay, atmospheric electromagnetic noise harvested from a radio tuned between stations, or intermixed timings of keystrokes. The time investment needed to obtain these numbers leads to a compromise: using some of these physics readings as a seed for a pseudorandom number generator.\nHistory.\nBefore modern computing, researchers requiring random numbers would either generate them through various means (dice, cards, roulette wheels, etc.) or use existing random number tables.\nThe first attempt to provide researchers with a ready supply of random digits was in 1927, when the Cambridge University Press published a table of 41,600 digits developed by L.H.C. Tippett. In 1947, the RAND Corporation generated numbers by the electronic simulation of a roulette wheel; the results were eventually published in 1955 as \"A Million Random Digits with 100,000 Normal Deviates\".\nIn computational complexity.\nIn theoretical computer science, a distribution is pseudorandom against a class of adversaries if no adversary from the class can distinguish it from the uniform distribution with significant advantage.\nThis notion of pseudorandomness is studied in computational complexity theory and has applications to cryptography.\nFormally, let \"S\" and \"T\" be finite sets and let F = {\"f\": \"S\" \u2192 \"T\"} be a class of functions. A distribution D over \"S\" is \u03b5-pseudorandom against F if for every \"f\" in F, the statistical distance between the distributions formula_1 and formula_2, where formula_3 is sampled from D and formula_4 is sampled from the uniform distribution on \"S\", is at most \u03b5.\nIn typical applications, the class F describes a model of computation with bounded resources and one is interested in designing distributions D with certain properties that are pseudorandom against F. The distribution D is often specified as the output of a pseudorandom generator."}
{"id": "23211", "revid": "22651524", "url": "https://en.wikipedia.org/wiki?curid=23211", "title": "Peoples Republic of China", "text": ""}
{"id": "23212", "revid": "43744280", "url": "https://en.wikipedia.org/wiki?curid=23212", "title": "Poales", "text": "Order of monocotyledonous flowering plants\nThe Poales are a large order of flowering plants in the monocotyledons, and includes families of plants such as the grasses, bromeliads, rushes and sedges. 14 plant families are currently recognized by botanists to be part of Poales.\nDescription.\nThe flowers are typically small, enclosed by bracts, and arranged in inflorescences (except in three species of the genus \"Mayaca\", which possess very reduced, one-flowered inflorescences). The flowers of many species are wind pollinated; the seeds usually contain starch.\nTaxonomy.\nThe APG IV system (2016) accepts the order within a monocot clade called commelinids, with 14 families.\nThe APG III system (2009) recognized Anarthriaceae and Centrolepidaceae as separate families, which APG IV includes in Restionaceae. The first APG system (1998) adopted the same placement of the order, although it used the spelling \"commelinoids\". It did not include the Bromeliaceae and Mayaceae, but had the additional families Prioniaceae (now included in Thurniaceae), Sparganiaceae (now in Typhaceae), and Hydatellaceae (now transferred out of the monocots; recently discovered to be an 'early-diverging' lineage of flowering plants).\nThe morphology-based Cronquist system did not include an order named Poales, assigning these families to the orders Bromeliales, Cyperales, Hydatellales, Juncales, Restionales and Typhales.\nIn early systems, an order including the grass family did not go by the name Poales but by a descriptive botanical name such as Graminales in the Engler system (update of 1964) and in the Hutchinson system (first edition, first volume, 1926), Glumiflorae in the Wettstein system (last revised 1935) or Glumaceae in the Bentham &amp; Hooker system (third volume, 1883).\nEvolution and phylogeny.\nThe earliest fossils attributed to the Poales date to the late Cretaceous period about million years ago, though some studies (e.g., Bremer, 2002) suggest the origin of the group may extend to nearly 115 million years ago, likely in South America. The earliest known fossils include pollen and fruits.\nThe phylogenetic position of Poales within the commelinids was difficult to resolve, but an analysis using complete chloroplast DNA found support for Poales as sister group of Commelinales plus Zingiberales. Major lineages within the Poales have been referred to as bromeliad, cyperid, xyrid, graminid, and restiid clades. A phylogenetic analysis resolved most relationships within the order but found weak support for the monophyly of the cyperid clade. The relationship between Centrolepidaceae and Restoniaceae within the restiid clade remains unclear; the first may actually be embedded in the latter.\nDiversity.\nThe four most species-rich families in the order are:\nHistoric taxonomy.\nCyperales.\nCyperales was a name for an order of flowering plants. As used in the Engler system (update, of 1964) and in the Wettstein system it consisted of only the single family. In the Cronquist system it is used for an order (placed in subclass \"Commelinidae\") and circumscribed as (1981):\nThe APG system now assigns the plants involved to the order \"Poales\".\nEriocaulales.\nEriocaulales is a botanical name for an order of flowering plants. The name was published by Takenoshin Nakai. In the Cronquist system the name was used for an order placed in the subclass \"Commelinidae\". The order consisted of one family only (1981):\nThe APG IV system now assigns these plants to the order \"Poales\".\nUses.\nThe Poales are the most economically important order of monocots and possibly the most important order of plants in general. Within the order, by far the most important family economically is the family of grasses (Poaceae, syn. Gramineae), which includes the starch staples barley, maize, millet, rice, and wheat as well as bamboos (mostly used structurally, like wood, but somewhat as vegetables), and a few \"seasonings\" like sugarcane and lemongrass. Graminoids, especially the grasses, are typically dominant in open (low moisture but not yet arid, or also fire climax) habitats like prairie/steppe and savannah and thus form a large proportion of the forage of grazing livestock. Possibly due to pastoral nostalgia or simply a desire for open areas for play, they dominate most Western yards as lawns, which consume vast sums of money in upkeep (artificial grazing\u2014mowing\u2014for aesthetics and to keep the allergenic flowers suppressed, irrigation, and fertilizer). Many Bromeliaceae are used as ornamental plants (and one, the pineapple, is internationally grown in the tropics for fruit). Many wetland species of sedges, rushes, grasses, and cattails are important habitat plants for waterfowl, are used in weaving chair seats, and (especially cattails) were important pre-agricultural food sources for man. Two sedges, chufa (\"Cyperus esculentus\", also a significant weed) and water chestnut (\"Eleocharis dulcis\") are still at least locally important wetland starchy root crops.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23213", "revid": "26072613", "url": "https://en.wikipedia.org/wiki?curid=23213", "title": "Political correctness", "text": "Measures to avoid offense or disadvantage\nPolitical correctness (adjectivally \"politically correct\"; commonly abbreviated to P.C.) is a term used to describe language, policies, or measures that are intended to avoid perceived offense or disadvantage to members of particular groups in society. Since the late 1980s, the term has been used to describe a preference for inclusive language and avoidance of language or behavior that can be seen as excluding, marginalizing, or insulting to groups of people disadvantaged or discriminated against, particularly groups defined by ethnicity, sex, gender, sexual orientation, or disability. In public discourse and the media, the term\u2019s use is generally pejorative, with an implication that these policies are excessive or unwarranted. It can also be humorous, or ironic in nature. \nThe phrase \"politically correct\" first appeared in the 1930s, when it was used to describe dogmatic adherence to ideology in totalitarian regimes, such as Nazi Germany and Soviet Russia. Early usage of the term \"politically correct\" by leftists in the 1970s and 1980s was as self-critical satire; usage was ironic, rather than a name for a serious political movement. It was considered an in-joke among leftists used to satirise those who were too rigid in their adherence to political orthodoxy. The modern pejorative usage of the term emerged from conservative criticism of the New Left in the late 20th century, with many describing it as a form of censorship.\nCommentators on the political left in the United States contend that conservatives use the concept of political correctness to downplay and divert attention from substantively discriminatory behavior against disadvantaged groups. They also argue that the political right enforces its own forms of political correctness to suppress criticism of its favored constituencies and ideologies. In the United States, the term has played a major role in the culture war between liberals and conservatives.\nConceptual background.\nSeveral researchers describe political correctness not only as a political label but also as a practice of linguistic reform aimed at reducing exclusionary or derogatory expressions in public language, often in line with egalitarian or inclusive norms. Geoffrey Hughes and Norman Fairclough both note that these language reforms are intertwined with broader social efforts to reshape public discourse and social relations.\nHistory.\nEarly-to-mid 20th century.\nIn the early-to-mid 20th century, the phrase \"politically correct\" was used to describe strict adherence to a range of ideological orthodoxies within politics. In 1934, \"The New York Times\" reported that Nazi Germany was granting reporting permits \"only to pure 'Aryans' whose opinions are politically correct\".\nThe term \"political correctness\" first appeared in Marxist\u2013Leninist vocabulary following the Russian Revolution of 1917. At that time, it was used to describe strict adherence to the policies and principles of the Communist Party of the Soviet Union, that is, the party line. Later in the United States, the phrase came to be associated with accusations of dogmatism in debates between communists and socialists. According to American educator Herbert Kohl, writing about debates in New York in the late 1940s and early 1950s.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The term \"politically correct\" was used disparagingly, to refer to someone whose loyalty to the CP line overrode compassion, and led to bad politics. It was used by Socialists against Communists, and was meant to separate out Socialists who believed in egalitarian moral ideas from dogmatic Communists who would advocate and defend party positions regardless of their moral substance.\u2014\u200a\n1970s.\nIn the 1970s, the American New Left began using the term \"politically correct\". In the essay \"The Black Woman: An Anthology\" (1970), Toni Cade Bambara said that \"a man cannot be politically correct and a [male] chauvinist, too\". William Safire records this as the first use in the typical modern sense. The term \"political correctness\" was believed to have been revived by the New Left through familiarity in the West with Mao's Little Red Book, in which Mao stressed holding to the correct party line. The term rapidly began to be used by the New Left in an ironic or self-deprecating sense.\nThereafter, the term was often used as self-critical satire. Debra L. Shultz said that \"throughout the 1970s and 1980s, the New Left, feminists, and progressives... used their term 'politically correct' ironically, as a guard against their own orthodoxy in social change efforts\". \"PC\" is used in the comic book \"Merton of the Movement\", by Bobby London, which was followed by the term \"ideologically sound\", in the comic strips of Bart Dickon. In her essay \"Toward a feminist Revolution\" (1992) Ellen Willis said, \"In the early eighties, when feminists used the term 'political correctness', it was used to refer sarcastically to the anti-pornography movement's efforts to define a 'feminist sexuality'.\"\nStuart Hall suggests one way in which the original use of the term may have developed into the modern one:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;According to one version, political correctness actually began as an in-joke on the left: radical students on American campuses acting out an ironic replay of the Bad Old Days BS (Before the Sixties) when every revolutionary groupuscule had a party line about everything. They would address some glaring examples of sexist or racist behaviour by their fellow students in imitation of the tone of voice of the Red Guards or Cultural Revolution Commissar: \"Not very 'politically correct', Comrade!\"\n1980s and 1990s.\nAllan Bloom's \"The Closing of the American Mind\", a book first published in 1987, heralded a debate about political correctness in American higher education in the 1980s and 1990s. Professor of English literary and cultural studies at CMU Jeffrey J. Williams wrote that the \"assault on ... political correctness that simmered through the Reagan years, gained bestsellerdom with Bloom's \"Closing of the American Mind\"\". According to Z.F. Gamson, Bloom's book \"attacked the faculty for 'political correctness'\". Sociologist Anthony Platt says the \"campaign against 'political correctness'\" was launched by Bloom's book in 1987.\nAn October 1990 \"New York Times\" article by Richard Bernstein is credited with popularizing the term. At this time, the term was mainly being used within academia: \"Across the country the term p.c., as it is commonly abbreviated, is being heard more and more in debates over what should be taught at the universities.\" Nexis citations in \"arcnews/curnews\" reveal only seventy total citations in articles to \"political correctness\" for 1990; but one year later, Nexis records 1,532 citations, with a steady increase to more than 7,000 citations by 1994. In May 1991, \"The New York Times\" had a follow-up article, according to which the term was increasingly being used in a wider public arena:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;What has come to be called \"political correctness\", a term that began to gain currency at the start of the academic year last fall, has spread in recent months and has become the focus of an angry national debate, mainly on campuses, but also in the larger arenas of American life.\nThe previously obscure far-left term became common currency in the lexicon of the conservative social and political challenges against progressive teaching methods and curriculum changes in the secondary schools and universities of the U.S. Policies, behavior, and speech codes that the speaker or the writer regarded as being the imposition of a liberal orthodoxy, were described and criticized as politically correct. In May 1991, at a commencement ceremony for a graduating class of the University of Michigan, then U.S. President George H. W. Bush used the term in his speech: \"The notion of political correctness has ignited controversy across the land. And although the movement arises from the laudable desire to sweep away the debris of racism and sexism and hatred, it replaces old prejudice with new ones. It declares certain topics off-limits, certain expression off-limits, even certain gestures off-limits.\"\nAfter 1991, its use as a pejorative phrase became widespread amongst conservatives in the US. It became a key term encapsulating conservative concerns about the left in cultural and political debates extending beyond academia. Two articles on the topic in late 1990 in \"Forbes\" and \"Newsweek\" both used the term \"thought police\" in their headlines, exemplifying the tone of the new usage, but it was Dinesh D'Souza's \"Illiberal Education: The Politics of Race and Sex on Campus\" (1991) which \"captured the press's imagination\". These trends were at least in part a response to multiculturalism and the rise of identity politics, with movements such as feminism, gay rights movements and ethnic minority movements. That response received funding from conservative foundations and think tanks such as the John M. Olin Foundation, which funded several books such as D'Souza's.\nHerbert Kohl, in 1992, commented that a number of neoconservatives who promoted the use of the term \"politically correct\" in the early 1990s were former Communist Party members, and, as a result, familiar with the Marxist use of the phrase. He argued that in doing so, they intended \"to insinuate that egalitarian democratic ideas are actually authoritarian, orthodox, and Communist-influenced, when they oppose the right of people to be racist, sexist, and homophobic\".\nDuring the 1990s, conservative and right-wing politicians, think tanks, and speakers adopted the phrase as a pejorative descriptor of their ideological enemies, especially in the context of the culture wars about language and the content of public-school curricula. Roger Kimball, in \"Tenured Radicals\", endorsed Frederick Crews's view that PC is best described as \"Left Eclecticism\", a term defined by Kimball as \"any of a wide variety of anti-establishment modes of thought from structuralism and poststructuralism, deconstruction, and Lacanian analyst to feminist, homosexual, black, and other patently political forms of criticism\".\nLiberal commentators have argued that the conservatives and reactionaries who used the term did so in an effort to divert political discussion away from the substantive matters of resolving societal discrimination, such as racial, social class, gender, and legal inequality, against people whom conservatives do not consider part of the social mainstream. Jan Narveson wrote that \"that phrase was born to live between scare-quotes: it suggests that the operative considerations in the area so called are \"merely\" political, steamrolling the genuine reasons of principle for which we ought to be acting...\". Commenting in 2001, one such British journalist, Polly Toynbee, said \"the phrase is an empty, right-wing smear, designed only to elevate its user\", and in 2010 she wrote \"the phrase 'political correctness' was born as a coded cover for all who still want to say \"Paki\", \"spastic\", or \"queer\"\". Another British journalist, Will Hutton, wrote in 2001:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Political correctness is one of the brilliant tools that the American Right developed in the mid\u20131980s, as part of its demolition of American liberalism... What the sharpest thinkers on the American Right saw quickly was that by declaring war on the cultural manifestations of liberalism \u2013 by levelling the charge of \"political correctness\" against its exponents \u2013 they could discredit the whole political project.\u2014\u200a\nGlenn Loury wrote in 1994 that to address the subject of \"political correctness\" when power and authority within the academic community is being contested by parties on either side of that issue, is to invite scrutiny of one's arguments by would-be \"friends\" and \"enemies\". Combatants from the left and the right will try to assess whether a writer is \"for them\" or \"against them\". Geoffrey Hughes suggested that debate over political correctness concerns whether changing language actually solves political and social problems, with critics viewing it less about solving problems than imposing censorship, intellectual intimidation and demonstrating the moral purity of those who practice it. Hughes also argues that political correctness tends to be pushed by a minority rather than an organic form of language change.\nRight-wing political correctness.\n\"Political correctness\" is a label typically used to describe liberal or left-wing terms and actions but rarely used for analogous attempts to mold language and behavior on the right. Alex Nowrasteh of the Cato Institute referred to the right's own version of political correctness as \"patriotic correctness\".\nAs a socio-linguistic phenomenon.\nIn subsequent academic scholarship, some scholars have examined political correctness as a form of linguistic and moral reform rather than as a coherent political ideology. Linguist Geoffrey Hughes described political correctness as \u201cliberal in its aims but often illiberal in its practices,\u201d identifying a tension between its reformist intentions and its perceived coerciveness. Similarly, Norman Fairclough has analyzed political correctness as part of a broader discourse of linguistic and moral reform, in which \u201cchanging language practices is part of changing social relations\u201d and \u201ccritical awareness of language\u201d is linked to the pursuit of \u201cfairness and inclusiveness.\u201d\nUsage.\nThe modern pejorative usage of the term emerged from conservative criticism of the New Left in the late 20th century. This usage was popularized by a number of articles in \"The New York Times\" and other media throughout the 1990s, and was widely used in the debate surrounding Allan Bloom's 1987 book \"The Closing of the American Mind\". The term gained further currency in response to Roger Kimball's \"Tenured Radicals\" (1990), and conservative author Dinesh D'Souza's 1991 book \"Illiberal Education\". Supporters of politically correct language have been pejoratively referred to as the \"language police\".\nEducation.\nModern debate on the term was sparked by conservative critiques of perceived liberal bias in academia and education, and conservatives have since used it as a major line of attack.\nPreliminary research published in 2020 indicated that students at a large U.S. public university generally felt instructors were open-minded and encouraged free expression of diverse viewpoints; nonetheless, most students worried about the consequences of voicing their political opinions, with \"[a]nxieties about expressing political views and self-censorship ... more prevalent among students who identify as conservative\".\nAs a conspiracy theory.\nSome conservative commentators in the West argue that \"political correctness\" and multiculturalism are part of a conspiracy with the ultimate goal of undermining Judeo-Christian values. This theory, which holds that political correctness originates from the critical theory of the Frankfurt School as part of a conspiracy that its proponents call \"Cultural Marxism\". The theory originated with Michael Minnicino's 1992 essay \"New Dark Age: Frankfurt School and 'Political Correctness'\", published in a Lyndon LaRouche movement journal. In 2001, conservative commentator Patrick Buchanan wrote in \"The Death of the West\" that \"political correctness is cultural Marxism\", and that \"its trademark is intolerance\".\nMedia.\nIn the US, the term has been widely used in books and journals, but in Britain the usage has been confined mainly to the popular press. Many such authors and popular-media figures, particularly on the right, have used the term to criticize what they see as bias in the media. William McGowan argues that journalists get stories wrong or ignore stories worthy of coverage, because of what McGowan perceives to be their liberal ideologies and their fear of offending minority groups. Robert Novak, in his essay \"Political Correctness Has No Place in the Newsroom\", used the term to blame newspapers for adopting language use policies that he thinks tend to excessively avoid the appearance of bias. He argued that political correctness in language not only destroys meaning but also demeans the people who are meant to be protected.\nAuthors David Sloan and Emily Hoff claim that in the US, journalists shrug off concerns about political correctness in the newsroom, equating the political correctness criticisms with the old \"liberal media bias\" label. According to author John Wilson, left-wing forces of \"political correctness\" have been blamed for unrelated censorship, with \"Time\" citing campaigns against violence on network television in the US as contributing to a \"mainstream culture [that] has become cautious, sanitized, scared of its own shadow\" because of \"the watchful eye of the p.c. police\", protests and advertiser boycotts targeting TV shows are generally organized by right-wing religious groups campaigning against violence, sex, and depictions of homosexuality on television.\nInclusive language.\nInclusive or Equity Language is a language style that avoids expressions that its proponents perceive as expressing or implying ideas that are sexist, racist, or otherwise biased, prejudiced, or insulting to any particular group of people; and instead uses language intended to avoid offense and fulfill the ideals of egalitarianism. This language style is sometimes referred to as a type of \"political correctness\", either as a neutral description or with negative connotations by its opponents. At least some supporters deny an association between the two (\"Political correctness is focused on not offending whereas inclusive language is focused on honoring people's identities.\").\nSatirical use.\nPolitical correctness is often satirized, for example in \"The PC Manifesto\" (1992) by Saul Jerushalmy and Rens Zbignieuw X, and \"Politically Correct Bedtime Stories\" (1994) by James Finn Garner, which presents fairy tales re-written from an exaggerated politically correct perspective. In 1994, the comedy film \"PCU\" took a look at political correctness on a college campus. Other examples include the television program \"Politically Incorrect\", George Carlin's \"Euphemisms\" routine, and \"The Politically Correct Scrapbook\". The popularity of the \"South Park\" cartoon program led to the creation of the term \"\"South Park\" Republican\" by Andrew Sullivan, and later the book \"South Park Conservatives\" by Brian C. Anderson. In its Season 19 (2015), \"South Park\" introduced the character PC Principal, who embodies the principle, to poke fun at the principle of political correctness.\n\"The Colbert Report\"'s host Stephen Colbert often talked, satirically, about the \"PC Police\".\nScience.\nGroups who oppose certain generally accepted scientific views about evolution, second-hand tobacco smoke, AIDS, climate change, race and other politically contentious scientific matters have used the term \"political correctness\" to describe what they view as unwarranted rejection of their perspective on these issues by a scientific community that they believe has been corrupted by liberal politics.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt; \nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23215", "revid": "49853791", "url": "https://en.wikipedia.org/wiki?curid=23215", "title": "Political conservative", "text": ""}
{"id": "23218", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=23218", "title": "Political conservatism", "text": ""}
{"id": "23219", "revid": "48932058", "url": "https://en.wikipedia.org/wiki?curid=23219", "title": "Ploidy", "text": "Number of sets of chromosomes of a cell \nPloidy () is the number of complete sets of chromosomes in a cell, and hence the number of possible alleles for autosomal and pseudoautosomal genes. Here \"sets of chromosomes\" refers to the number of maternal and paternal chromosome copies, respectively, in each homologous chromosome pair\u2014the form in which chromosomes naturally exist. Somatic cells, tissues, and individual organisms can be described according to the number of sets of chromosomes present (the \"ploidy level\"): monoploid (1 set), diploid (2 sets), triploid (3 sets), tetraploid (4 sets), pentaploid (5 sets), hexaploid (6 sets), heptaploid or septaploid (7 sets), etc. The generic term polyploid is often used to describe cells with three or more sets of chromosomes.\nVirtually all sexually reproducing organisms are made up of somatic cells that are diploid or greater, but ploidy level may vary widely between different organisms, between different tissues within the same organism, and at different stages in an organism's life cycle. Half of all known plant genera contain polyploid species, and about two-thirds of all grasses are polyploid. Many animals are uniformly diploid, though polyploidy is common in invertebrates, reptiles, and amphibians. In some species, ploidy varies between individuals of the same species (as in the social insects), and in others entire tissues and organ systems may be polyploid despite the rest of the body being diploid (as in the mammalian liver). For many organisms, especially plants and fungi, changes in ploidy level between generations are major drivers of speciation. In mammals and birds, ploidy changes are typically fatal. There is, however, evidence of polyploidy in organisms now considered to be diploid, suggesting that polyploidy has contributed to evolutionary diversification in plants and animals through successive rounds of polyploidization and rediploidization.\nHumans are diploid organisms, normally carrying two complete sets of chromosomes in their somatic cells: one copy of paternal and maternal chromosomes, respectively, in each of the 23 homologous pairs of chromosomes that humans normally have. This results in two homologous chromosomes within each of the 23 homologous pairs, providing a full complement of 46 chromosomes. This total number of individual chromosomes (counting all complete sets) is called the chromosome number or chromosome complement. The number of chromosomes found in a single complete set of chromosomes is called the monoploid number (\"x\"). The haploid number (\"n\") refers to the total number of chromosomes found in a gamete (a sperm or egg cell produced by meiosis in preparation for sexual reproduction). Under normal conditions, the haploid number is exactly half the total number of chromosomes present in the organism's somatic cells, with one paternal and maternal copy in each chromosome pair. For diploid organisms, the monoploid number and haploid number are equal; in humans, both are equal to 23. When a human germ cell undergoes meiosis, the diploid 46 chromosome complement is split in half to form haploid gametes. After fusion of a male and a female gamete (each containing 1 set of 23 chromosomes) during fertilization, the resulting zygote again has the full complement of 46 chromosomes: 2 sets of 23 chromosomes. Any organism having a number of chromosomes that is an exact multiple of the number in a typical gamete of is species is called \"euploid\", while if it has any other number it is called \"aneuploid\". For example, a person with Turner syndrome may be missing one sex chromosome (X or Y), resulting in a (45,X) karyotype instead of the usual (46,XX) or (46,XY). This is a type of aneuploidy, and cells from the person may be said to be aneuploid with a (diploid) chromosome complement of 45.\nEtymology.\nThe term \"ploidy\" is a back-formation from \"haploidy\" and \"diploidy\". \"Ploid\" is a combination of Ancient Greek -\u03c0\u03bb\u03cc\u03bf\u03c2 (-pl\u00f3os, \"-fold\") and -\u03b5\u03b9\u03b4\u03ae\u03c2 (-\"eid\u1e17s\"), from \u03b5\u1f36\u03b4\u03bf\u03c2 (\"e\u00eedos\", \"form, likeness\"). The principal meaning of the Greek word \u1fb0\u0314\u03c0\u03bb\u03cc\u03bf\u03c2 (hapl\u00f3os) is \"single\", from \u1f01- (ha-, \"one, same\"). \u03b4\u03b9\u03c0\u03bb\u03cc\u03bf\u03c2 (\"dipl\u00f3os\") means \"duplex\" or \"two-fold\". Diploid therefore means \"duplex-shaped\" (compare \"humanoid\", \"human-shaped\").\nPolish-German botanist Eduard Strasburger coined the terms \"haploid\" and \"diploid\" in 1905. Some authors suggest that Strasburger based the terms on August Weismann's conception of the id (or germ plasm), hence haplo-\"id\" and diplo-\"id\". The two terms were brought into the English language from German through William Henry Lang's 1908 translation of a 1906 textbook by Strasburger and colleagues.\nTypes of ploidy.\nHaploid and monoploid.\nThe term haploid is used with two distinct but related definitions. In the most generic sense, haploid refers to having the number of sets of chromosomes normally found in a gamete. Because two gametes necessarily combine during sexual reproduction to form a single zygote from which somatic cells are generated, healthy gametes always possess exactly half the number of sets of chromosomes found in the somatic cells, and therefore \"haploid\" in this sense refers to having exactly half the number of sets of chromosomes found in a somatic cell. By this definition, an organism whose gametic cells contain a single copy of each chromosome (one set of chromosomes) may be considered haploid while the somatic cells, containing two copies of each chromosome (two sets of chromosomes), are diploid. This scheme of diploid somatic cells and haploid gametes is widely used in the animal kingdom and is the simplest to illustrate in diagrams of genetics concepts. But this definition also allows for haploid gametes with \"more than one\" set of chromosomes. As given above, gametes are by definition haploid, regardless of the actual number of sets of chromosomes they contain. An organism whose somatic cells are tetraploid (four sets of chromosomes), for example, will produce gametes by meiosis that contain two sets of chromosomes. These gametes might still be called haploid even though they are numerically diploid.\nAn alternative usage defines \"haploid\" as having a single copy of each chromosome \u2013 that is, one and only one set of chromosomes. In this case, the nucleus of a eukaryotic cell is said to be haploid only if it has a single set of chromosomes, each one not being part of a pair. By extension a cell may be called haploid if its nucleus has one set of chromosomes, and an organism may be called haploid if its body cells (somatic cells) have one set of chromosomes per cell. By this definition haploid therefore would not be used to refer to the gametes produced by the tetraploid organism in the example above, since these gametes are numerically diploid. The term monoploid is often used as a less ambiguous way to describe a single set of chromosomes; by this second definition, haploid and monoploid are identical and can be used interchangeably.\nGametes (sperm and ova) are haploid cells. The haploid gametes produced by most organisms combine to form a zygote with \"n\" pairs of chromosomes, i.e. 2\"n\" chromosomes in total. The chromosomes in each pair, one of which comes from the sperm and one from the egg, are said to be homologous. Cells and organisms with pairs of homologous chromosomes are called diploid. For example, most animals are diploid and produce haploid gametes. During meiosis, sex cell precursors have their number of chromosomes halved by randomly \"choosing\" one member of each pair of chromosomes, resulting in haploid gametes. Because homologous chromosomes usually differ genetically, gametes usually differ genetically from one another.\nAll plants and many fungi and algae switch between a haploid and a diploid state, with one of the stages emphasized over the other. This is called alternation of generations. Most fungi and algae are haploid during the principal stage of their life cycle, as are some primitive plants like mosses. More recently evolved plants, like the gymnosperms and angiosperms, spend the majority of their life cycle in the diploid stage. Most animals are diploid, but male bees, wasps, and ants are haploid organisms because they develop from unfertilized, haploid eggs, while females (workers and queens) are diploid, making their system haplodiploid.\nIn some cases there is evidence that the \"n\" chromosomes in a haploid set have resulted from duplications of an originally smaller set of chromosomes. This \"base\" number \u2013 the number of apparently originally unique chromosomes in a haploid set \u2013 is called the monoploid number, also known as basic or cardinal number, or fundamental number. As an example, the chromosomes of common wheat are believed to be derived from three different ancestral species, each of which had 7 chromosomes in its haploid gametes. The monoploid number is thus 7 and the haploid number is 3\u00a0\u00d7\u00a07\u00a0= 21. In general \"n\" is a multiple of \"x\". The somatic cells in a wheat plant have six sets of 7 chromosomes: three sets from the egg and three sets from the sperm which fused to form the plant, giving a total of 42 chromosomes. As a formula, for wheat 2\"n\"\u00a0= 6\"x\"\u00a0= 42, so that the haploid number \"n\" is 21 and the monoploid number \"x\" is 7. The gametes of common wheat are considered to be haploid, since they contain half the genetic information of somatic cells, but they are not monoploid, as they still contain three complete sets of chromosomes (\"n\"\u00a0=\u00a03\"x\").\nIn the case of wheat, the origin of its haploid number of 21 chromosomes from three sets of 7 chromosomes can be demonstrated. In many other organisms, although the number of chromosomes may have originated in this way, this is no longer clear, and the monoploid number is regarded as the same as the haploid number. Thus in humans, \"x\"\u00a0=\u00a0\"n\"\u00a0=\u00a023.\nDiploid.\nDiploid describes a cell or nucleus which contains two copies of genetic material, or a complete set of chromosomes, paired with their homologs (chromosome carrying the same information from the other parent).\nDiploid cells have two homologous copies of each chromosome, usually one from the mother and one from the father. All or nearly all mammals are diploid organisms. The suspected tetraploid (possessing four-chromosome sets) plains viscacha rat (\"Tympanoctomys barrerae\") and golden viscacha rat (\"Pipanacoctomys aureus\") have been regarded as the only known exceptions (as of 2004). However, some genetic studies have rejected any polyploidism in mammals as unlikely, and suggest that amplification and dispersion of repetitive sequences best explain the large genome size of these two rodents. All normal diploid individuals have some small fraction of cells that display polyploidy. Human diploid cells have 46 chromosomes (the somatic number, \"2n\") and human haploid gametes (egg and sperm) have 23 chromosomes (\"n\"). Retroviruses that contain two copies of their RNA genome in each viral particle are also said to be diploid. Examples include human foamy virus, human T-lymphotropic virus, and HIV.\nPolyploidy.\nPolyploidy is the state where all cells have multiple sets of chromosomes beyond the basic set, usually 3 or more. Specific terms are triploid (3 sets), tetraploid (4 sets), pentaploid (5 sets), hexaploid (6 sets), heptaploid or septaploid (7 sets), octoploid (8 sets), nonaploid (9 sets), decaploid (10 sets), undecaploid (11 sets), dodecaploid (12 sets), tridecaploid (13 sets), tetradecaploid (14 sets), etc. Some higher ploidies include hexadecaploid (16 sets), dotriacontaploid (32 sets), and tetrahexacontaploid (64 sets), though Greek terminology may be set aside for readability in cases of higher ploidy (such as \"16-ploid\"). Polytene chromosomes of plants and fruit flies can be 1024-ploid. Ploidy of systems such as the salivary gland, elaiosome, endosperm, and trophoblast can exceed this, up to 1048576-ploid in the silk glands of the commercial silkworm \"Bombyx mori\".\nThe chromosome sets may be from the same species or from closely related species. In the latter case, these are known as allopolyploids (or amphidiploids, which are allopolyploids that behave as if they were normal diploids). Allopolyploids are formed from the hybridization of two separate species. In plants, this probably most often occurs from the pairing of meiotically unreduced gametes, and not by diploid\u2013diploid hybridization followed by chromosome doubling. The so-called \"Brassica\" triangle is an example of allopolyploidy, where three different parent species have hybridized in all possible pair combinations to produce three new species.\nPolyploidy occurs commonly in plants, but rarely in animals. Even in diploid organisms, many somatic cells are polyploid due to a process called endoreduplication, where duplication of the genome occurs without mitosis (cell division). The extreme in polyploidy occurs in the fern genus \"Ophioglossum\", the adder's-tongues, in which polyploidy results in chromosome counts in the hundreds, or, in at least one case, well over one thousand.\nIt is possible for polyploid organisms to revert to lower ploidy by haploidisation.\nIn bacteria and archaea.\nPolyploidy is a characteristic of the bacterium \"Deinococcus radiodurans\" and of the archaeon \"Halobacterium salinarum\". These two species are highly resistant to ionizing radiation and desiccation, conditions that induce DNA double-strand breaks. This resistance appears to be due to efficient homologous recombinational repair.\nVariable or indefinite ploidy.\nDepending on growth conditions, prokaryotes such as bacteria may have a chromosome copy number of 1 to 4, and that number is commonly fractional, counting portions of the chromosome partly replicated at a given time. This is because under exponential growth conditions the cells are able to replicate their DNA faster than they can divide.\nIn ciliates, the macronucleus is called ampliploid, because only part of the genome is amplified.\nMixoploidy.\nMixoploidy is the case where two cell lines, one diploid and one polyploid, coexist within the same organism. Though polyploidy in humans is not viable, mixoploidy has been found in live adults and children. There are two types: diploid-triploid mixoploidy, in which some cells have 46 chromosomes and some have 69, and diploid-tetraploid mixoploidy, in which some cells have 46 and some have 92 chromosomes. It is a major topic of cytology.\nDihaploidy and polyhaploidy.\nDihaploid and polyhaploid cells are formed by haploidisation of polyploids, i.e., by halving the chromosome constitution.\nDihaploids (which are diploid) are important for selective breeding of tetraploid crop plants (notably potatoes), because selection is faster with diploids than with tetraploids. Tetraploids can be reconstituted from the diploids, for example by somatic fusion.\nThe term \"dihaploid\" was coined by Bender to combine in one word the number of genome copies (diploid) and their origin (haploid). The term is well established in this original sense, but it has also been used for doubled monoploids or doubled haploids, which are homozygous and used for genetic research.\nEuploidy and aneuploidy.\nEuploidy (Greek \"eu\", \"true\" or \"even\") is the state of a cell or organism having one or more than one set of the same set of chromosomes, possibly excluding the sex-determining chromosomes. For example, most human cells have 2 of each of the 23 homologous monoploid chromosomes, for a total of 46 chromosomes. A human cell with one extra set of the 23 normal chromosomes (functionally triploid) would be considered euploid. Euploid karyotypes would consequentially be a multiple of the haploid number, which in humans is 23.\nAneuploidy is the state where one or more individual chromosomes of a normal set are absent or present in more than their usual number of copies (excluding the absence or presence of complete sets, which is considered euploidy). Unlike euploidy, aneuploid karyotypes will not be a multiple of the haploid number. In humans, examples of aneuploidy include having a single extra chromosome (as in Down syndrome, where affected individuals have three copies of chromosome 21) or missing a chromosome (as in Turner syndrome, where affected individuals have only one sex chromosome). Aneuploid karyotypes are given names with the suffix \"-somy\" (rather than \"-ploidy\", used for euploid karyotypes), such as trisomy and monosomy.\nHomoploid.\nHomoploid means \"at the same ploidy level\", i.e. having the same number of homologous chromosomes. For example, homoploid hybridization is hybridization where the offspring have the same ploidy level as the two parental species. This contrasts with a common situation in plants where chromosome doubling accompanies or occurs soon after hybridization. Similarly, homoploid speciation contrasts with polyploid speciation.\nZygoidy and azygoidy.\nZygoidy is the state in which the chromosomes are paired and can undergo meiosis. The zygoid state of a species may be diploid or polyploid. In the azygoid state the chromosomes are unpaired. It may be the natural state of some asexual species or may occur after meiosis. In diploid organisms the azygoid state is monoploid. (See below for dihaploidy.)\nSpecial cases.\nMore than one nucleus per cell.\nIn the strictest sense, ploidy refers to the number of sets of chromosomes in a single nucleus rather than in the cell as a whole. Because in most situations there is only one nucleus per cell, it is commonplace to speak of the ploidy of a cell, but in cases in which there is more than one nucleus per cell, more specific definitions are required when ploidy is discussed. Authors may at times report the total combined ploidy of all nuclei present within the cell membrane of a syncytium, though usually the ploidy of each nucleus is described individually. For example, a fungal dikaryon with two separate haploid nuclei is distinguished from a diploid cell in which the chromosomes share a nucleus and can be shuffled together.\nAncestral ploidy levels.\nIt is possible on rare occasions for ploidy to increase in the germline, which can result in polyploid offspring and ultimately polyploid species. This is an important evolutionary mechanism in both plants and animals and is known as a primary driver of speciation. As a result, it may become desirable to distinguish between the ploidy of a species or variety as it presently breeds and that of an ancestor. The number of chromosomes in the ancestral (non-homologous) set is called the monoploid number (\"x\"), and is distinct from the haploid number (\"n\") in the organism as it now reproduces.\nCommon wheat (\"Triticum aestivum\") is an organism in which \"x\" and \"n\" differ. Each plant has a total of six sets of chromosomes (with two sets likely having been obtained from each of three different diploid species that are its distant ancestors). The somatic cells are hexaploid, 2\"n\"\u00a0=\u00a06\"x\"\u00a0=\u00a042 (where the monoploid number \"x\"\u00a0=\u00a07 and the haploid number \"n\"\u00a0=\u00a021). The gametes are haploid for their own species, but triploid, with three sets of chromosomes, by comparison to a probable evolutionary ancestor, einkorn wheat.\nTetraploidy (four sets of chromosomes, 2\"n\"\u00a0=\u00a04\"x\") is common in many plant species, and also occurs in amphibians, reptiles, and insects. For example, species of \"Xenopus\" (African toads) form a ploidy series, featuring diploid (\"X. tropicalis\", 2n=20), tetraploid (\"X. laevis\", 4n=36), octaploid (\"X. wittei\", 8n=72), and dodecaploid (\"X. ruwenzoriensis\", 12n=108) species.\nOver evolutionary time scales in which chromosomal polymorphisms accumulate, these changes become less apparent by karyotype \u2013 for example, humans are generally regarded as diploid, but the 2R hypothesis has confirmed two rounds of whole genome duplication in early vertebrate ancestors.\nHaplodiploidy.\nPloidy can also vary between individuals of the same species or at different stages of the life cycle. In some insects it differs by caste. In humans, only the gametes are haploid, but in many of the social insects, including ants, bees, and termites, males develop from unfertilized eggs, making them haploid for their entire lives, even as adults.\nIn the Australian bulldog ant, \"Myrmecia pilosula\", a haplodiploid species, haploid individuals of this species have a single chromosome and diploid individuals have two chromosomes. In \"Entamoeba\", the ploidy level varies from 4\"n\" to 40\"n\" in a single population. Alternation of generations occurs in most plants, with individuals \"alternating\" ploidy level between different stages of their sexual life cycle.\nTissue-specific polyploidy.\nIn large multicellular organisms, variations in ploidy level between different tissues, organs, or cell lineages are common. Because the chromosome number is generally reduced only by the specialized process of meiosis, the somatic cells of the body inherit and maintain the chromosome number of the zygote by mitosis. However, in many situations somatic cells double their copy number by means of endoreduplication as an aspect of cellular differentiation. For example, the hearts of two-year-old human children contain 85% diploid and 15% tetraploid nuclei, but by 12 years of age the proportions become approximately equal, and adults examined contained 27% diploid, 71% tetraploid and 2% octaploid nuclei.\nAdaptive and ecological significance of variation in ploidy.\nThere is continued study and debate regarding the fitness advantages or disadvantages conferred by different ploidy levels. A study comparing the karyotypes of endangered or invasive plants with those of their relatives found that being polyploid as opposed to diploid is associated with a 14% lower risk of being endangered, and a 20% greater chance of being invasive. Polyploidy may be associated with increased vigor and adaptability. Some studies suggest that selection is more likely to favor diploidy in host species and haploidy in parasite species. However, polyploidization is associated with an increase in transposable element content and relaxed purifying selection on recessive deleterious alleles.\nWhen a germ cell with an uneven number of chromosomes undergoes meiosis, the chromosomes cannot be evenly divided between the daughter cells, resulting in aneuploid gametes. Triploid organisms, for instance, are usually sterile. Because of this, triploidy is commonly exploited in agriculture to produce seedless fruit such as bananas and watermelons. If the fertilization of human gametes results in three sets of chromosomes, the condition is called triploid syndrome.\nIn unicellular organisms the ploidy nutrient limitation hypothesis suggests that nutrient limitation should encourage haploidy in preference to higher ploidies. This hypothesis is due to the higher surface-to-volume ratio of haploids, which eases nutrient uptake, thereby increasing the internal nutrient-to-demand ratio. Mable 2001 finds \"Saccharomyces cerevisiae\" to be somewhat inconsistent with this hypothesis however, as haploid growth is faster than diploid under high nutrient conditions. The NLH is also tested in haploid, diploid, and polyploid fungi by Gerstein et al. 2017. This result is also more complex: On the one hand, under phosphorus and other nutrient limitation, lower ploidy is selected as expected. However under normal nutrient levels or under limitation of only nitrogen, higher ploidy was selected. Thus the NLH \u2013 and more generally, the idea that haploidy is selected by harsher conditions \u2013 is cast into doubt by these results.\nOlder WGDs have also been investigated. Only as recently as 2015 was the ancient whole genome duplication in Baker's yeast proven to be allopolyploid, by Marcet-Houben and Gabald\u00f3n 2015. It still remains to be explained why there are not more polyploid events in fungi, and the place of neopolyploidy and mesopolyploidy in fungal history.\nLess efficient natural selection in diploid compared to haploid tissue.\nThe concept that those genes of an organism that are expressed exclusively in the diploid stage are under less efficient natural selection than those genes expressed in the haploid stage is referred to as the \"masking theory\". Evidence in support of this masking theory has been reported in studies of the single-celled yeast \"Saccharomyces cerevisiae\". In further support of the masking theory, evidence of strong purifying selection in haploid tissue-specific genes has been reported for the plant Scots Pine.\nGlossary of ploidy numbers.\nThe common potato (\"Solanum tuberosum\") is an example of a tetraploid organism, carrying four sets of chromosomes. During sexual reproduction, each potato plant inherits two sets of 12 chromosomes from the pollen parent, and two sets of 12 chromosomes from the ovule parent. The four sets combined provide a full complement of 48 chromosomes. The haploid number (half of 48) is 24. The monoploid number equals the total chromosome number divided by the ploidy level of the somatic cells: 48 chromosomes in total divided by a ploidy level of 4 equals a monoploid number of 12. Hence, the monoploid number (12) and haploid number (24) are distinct in this example.\nHowever, commercial potato crops (as well as many other crop plants) are commonly propagated vegetatively (by asexual reproduction through mitosis), in which case new individuals are produced from a single parent, without the involvement of gametes and fertilization, and all the offspring are genetically identical to each other and to the parent, including in chromosome number. The parents of these vegetative clones may still be capable of producing haploid gametes in preparation for sexual reproduction, but these gametes are not used to create the vegetative offspring by this route.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nSome eukaryotic genome-scale or genome size databases and other sources which may list the ploidy levels of many organisms:"}
{"id": "23220", "revid": "69801", "url": "https://en.wikipedia.org/wiki?curid=23220", "title": "Plea of nolo contendere", "text": ""}
{"id": "23221", "revid": "499010", "url": "https://en.wikipedia.org/wiki?curid=23221", "title": "Playboy", "text": "American lifestyle and entertainment magazine\nPlayboy (stylized in all caps) is an American men's lifestyle and entertainment magazine, available both online and in print. It was founded in Chicago in 1953 by Hugh Hefner and his associates, funded in part by a $1,000 loan from Hefner's mother.\nKnown for its centerfolds of nude and semi-nude models (Playmates), \"Playboy\" played an important role in the sexual revolution and remains one of the world's best-known brands, with a presence in nearly every medium. In addition to the flagship magazine in the United States, special nation-specific versions of \"Playboy\" are published worldwide, including those by licensees, such as Dirk Steenekamp's DHS Media Group.\nThe magazine has a long history of publishing short stories by novelists such as Arthur C. Clarke, Ian Fleming, Vladimir Nabokov, Saul Bellow, Chuck Palahniuk, P. G. Wodehouse, Roald Dahl, Haruki Murakami, and Margaret Atwood. With a regular display of full-page color cartoons, it became a showcase for cartoonists such as Jack Cole, Eldon Dedini, Jules Feiffer, Harvey Kurtzman, Shel Silverstein, Doug Sneyd, Erich Sokol, Roy Raymonde, Gahan Wilson, and Rowland B. Wilson. Art Paul designed the bunny logo. Leroy Neiman drew the Femlin characters for Playboy jokes. Patrick Nagel painted the headers for Playboy Forum and other sections.\n\"Playboy\" features monthly interviews of public figures, such as artists, architects, economists, composers, conductors, film directors, journalists, novelists, playwrights, religious figures, politicians, athletes, and race car drivers. The magazine generally reflects a liberal editorial stance, although it often interviews conservative celebrities.\nAfter a year-long removal of most nude photos in \"Playboy\" magazine, the March\u2013April 2017 issue brought back nudity.\nPublication history.\n1950s.\nBy spring 1953, Hugh Hefner\u2014a 1949 University of Illinois psychology graduate who had worked in Chicago for \"Esquire\" magazine writing promotional copy; Publisher's Development Corporation in sales and marketing; and \"Children's Activities\" magazine as circulation promotions manager\u2014had planned out the elements of his magazine, that he would call \"Stag Party\". He formed HMH Publishing Corporation, and recruited his friend Eldon Sellers to find investors. Hefner eventually raised just over $8,000, including from his brother and mother. However, the publisher of an unrelated men's adventure magazine, \"Stag\", contacted Hefner and informed him it would file suit to protect their trademark if he were to launch his magazine with that name. Hefner, his wife Millie, and Sellers met to seek a new name, considering \"Top Hat\", \"Gentleman\", \"Sir'\", \"Satyr\", \"Pan\", and \"Bachelor\" before Sellers suggested \"Playboy\".\nPublished in December 1953, the first issue was undated, as Hefner was unsure there would be a second. He produced it in his Hyde Park kitchen. The first centerfold was Marilyn Monroe, although the picture used initially was taken for a calendar rather than for \"Playboy\". Hefner chose what he deemed the \"sexiest\" image, a previously unused nude study of Monroe stretched with an upraised arm on a red velvet background with closed eyes and mouth open. The heavy promotion centered on Monroe's nudity on the already-famous calendar, together with the teasers in marketing, made the new \"Playboy\" magazine a success.\nThe first issue sold out in weeks. Known circulation was 53,991. The cover price was 50\u00a2. Copies of the first issue in mint to near-mint condition sold for over $5,000 in 2002.\nThe novel \"Fahrenheit 451\", by Ray Bradbury, was published in 1953 and serialized in the March, April and May 1954 issues of \"Playboy\".\nAn urban legend started about Hefner and the Playmate of the Month because of markings on the front covers of the magazine. From 1955 to 1979 (except for a six-month gap in 1976), the \"P\" in \"Playboy\" had stars printed in or around the letter. Urban legend stated that this was either a rating that Hefner gave to the Playmate according to how attractive she was, the number of times that Hefner had slept with her, or how good she was in bed. In truth, stars, between zero and 12, indicated the domestic or international advertising region for that printing.\n1960s\u20131990s.\nIn the 1960s, the magazine added \"The Playboy Philosophy\" column. Early topics included gay rights, women's rights, censorship, and the First Amendment. \"Playboy\" was an early proponent of cannabis reform and provided founding support to the National Organization for the Reform of Marijuana Laws in 1970.\nFrom 1966 to 1976, Robie Macauley was the fiction editor at \"Playboy\". During this period the magazine published fiction by Saul Bellow, Se\u00e1n \u00d3 Faol\u00e1in, John Updike, James Dickey, John Cheever, Doris Lessing, Joyce Carol Oates, Vladimir Nabokov, Michael Crichton, John le Carr\u00e9, Irwin Shaw, Jean Shepherd, Arthur Koestler, Isaac Bashevis Singer, Bernard Malamud, John Irving, Anne Sexton, Nadine Gordimer, Kurt Vonnegut and J. P. Donleavy, as well as poetry by Yevgeny Yevtushenko.\nIn 1968, at the feminist Miss America protest, symbolically feminine products were thrown into a \"Freedom Trash Can\". These included copies of \"Playboy\" and \"Cosmopolitan\" magazines. One of the key pamphlets produced by the protesters was \"No More Miss America!\", by Robin Morgan, which listed ten characteristics of the Miss America pageant that the authors believed degraded women; it compared the pageant to \"Playboy\"'s centerfold as sisters under the skin, describing this as \"The Unbeatable Madonna\u2013Whore Combination\".\nMacauley contributed all of the popular \"Ribald Classics\" series published between January 1978 and March 1984.\nAfter reaching its peak in the 1970s, \"Playboy\" saw a decline in circulation and cultural relevance due to competition in the field it founded\u2014first from \"Penthouse\", then from \"Oui\" (which was published as a spin-off of \"Playboy\") and \"Gallery\" in the 1970s; later from pornographic videos; and more recently from lad mags such as \"Maxim\", \"FHM\", and \"Stuff\". In response, \"Playboy\" attempted to re-assert its hold on the 18\u201335-year-old male demographic through slight changes to the content and focusing on issues and personalities more appropriate to its audience\u2014such as hip-hop artists being featured in the \"\"Playboy\" Interview\". In February 1974, Ratna Assan became the first women of Indonesian descent to be featured, shortly after a positively received role in the film \"Papillon\" (1973).\nChristie Hefner, daughter of founder Hugh Hefner, joined \"Playboy\" in 1975 and became head of the company in 1988. She announced in December 2008 that she would be stepping down from leading the company, effective in January 2009. She said that the election of Barack Obama as the next President had inspired her to give more time to charitable work and that the decision to step down was her own. \"Just as this country is embracing change in the form of new leadership, I have decided that now is the time to make changes in my own life as well\", she said. Hefner was succeeded by company director and media veteran Jerome H. Kern as interim CEO, who was in turn succeeded by publisher Scott Flanders.\n2000\u2013present.\nThe magazine celebrated its 50th anniversary with the January 2004 issue. Celebrations were held at Las Vegas, Los Angeles, New York, and Moscow during the year to commemorate this event. \"Playboy\" also launched limited-edition products designed by fashion houses such as Versace, Vivienne Westwood and Sean John. As a homage to the magazine's 50th anniversary, MAC Cosmetics released two limited-edition products: lipstick and glitter cream.\nThe printed magazine ran several annual features and ratings. One of the most popular was its annual ranking of the top \"party schools\" among all U.S. universities and colleges. In 2009, the magazine used five criteria\u2014bikini, brains, campus, sex, and sports\u2014to develop its list. The top-ranked party school by \"Playboy\" for 2009 was the University of Miami.\nIn June 2009, the magazine reduced its publication schedule to 11 yearly issues, with a combined July/August issue. On August 11, 2009, London's \"Daily Telegraph\" newspaper reported that Hugh Hefner had sold his English manor house (next door to the Playboy Mansion in Los Angeles) for $18\u00a0m ($10\u00a0m less than the reported asking price) to another American, Daren Metropoulos, the President and co-owner of Pabst Blue Ribbon, and that due to significant losses in the company's value (down from $1 billion in 2000 to $84 million in 2009), the Playboy publishing empire was for sale for $300 million. In December 2009, the publication schedule was reduced to 10 issues per year, with a combined January/February issue.\nOn July 12, 2010, Playboy Enterprises Inc. announced Hefner's $5.50 per share offer ($122.5 million based on shares outstanding on April 30 and the closing price on July 9) to buy the portion of the company he did not already own and take the company private with the help of Rizvi Traverse Management LLC. The company derived much of its income from licensing rather than from the magazine. On July 15, \"Penthouse\" owner FriendFinder Networks Inc. offered $210 million (the company is valued at $185 million). However, Hefner, who already owned 70 percent of voting stock, did not want to sell. In January 2011, the publisher of \"Playboy\" magazine agreed to an offer by Hefner to take the company private for $6.15 per share, an 18 percent premium over the price of the last previous day of trading. The buyout was completed in March 2011.\n2016\u20132018 changes and brief ending of full-frontal nudity.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThis is what I always intended \"Playboy\" Magazine to look like.\n \u2014 Hugh Hefner, when asked about ending nudity in \"Playboy\"\nIn October 2015, \"Playboy\" announced the magazine would no longer feature full-frontal nudity beginning with the March 2016 issue. Company CEO Scott Flanders acknowledged the magazine's inability to compete with freely available internet pornography and nudity; according to him, \"You're now one click away from every sex act imaginable for free. And so it's just pass\u00e9 at this juncture\". Hefner agreed with the decision. The redesigned \"Playboy\", however, would still feature a Playmate of the Month and pictures of women. Still, they would be rated as not appropriate for children under 13. The move would not affect PlayboyPlus.com (which features nudity at a paid subscription). Josh Horwitz of \"Quartz\" argued that the motivation for the decision to remove nudity from the magazine was to give Playboy Licensing a less inappropriate image in India and China, where the brand is a popular item on apparel and thus generates significant revenue.\nOther changes to the magazine included ending the popular jokes section and the various cartoons that appeared throughout the magazine. The redesign eliminated the use of jump copy (articles continuing on non-consecutive pages), eliminating most of the space for cartoons. Hefner, himself a former cartoonist, reportedly resisted dropping the cartoons more than the nudity, but ultimately obliged. \"Playboy\"'s plans were to market itself as a competitor to \"Vanity Fair\", as opposed to more traditional competitors \"GQ\" and \"Maxim\".\n\"Playboy\" announced in February 2017, however, that the dropping of nudity had been a mistake. Furthermore, for its March/April issue, it reestablished some of its franchises, including the Playboy Philosophy and Party Jokes, but dropped the subtitle \"Entertainment for Men\", inasmuch as gender roles have evolved. The company's chief creative officer made the announcement on Twitter with the hashtag #NakedIsNormal.\nIn early 2018, and according to Jim Puzzanghera of the \"Los Angeles Times\", \"Playboy\" was reportedly \"considering killing the print magazine\", as the publication \"has lost as much as $7 million annually in recent years\". However, in the July/August 2018 issue a reader asked if the print magazine would discontinue, and \"Playboy\" responded that it was not going anywhere.\nFollowing Hefner's death and his family's financial stake in the company, the magazine changed direction. In 2019, \"Playboy\" was relaunched as a quarterly publication without adverts. Topics covered included an interview with Tarana Burke, a profile of Pete Buttigieg, coverage of BDSM, and a cover photo representing gender and sexual fluidity.\nOnline-only.\nIn March 2020, Ben Kohn, CEO of Playboy Enterprises, announced that the spring 2020 issue would be the last regularly scheduled printed issue and that the magazine would publish its content online. The decision to close the print edition was attributed in part to the COVID-19 pandemic, which interfered with the distribution of the magazine.\nPublicly traded.\nIn autumn 2020, Playboy announced a reverse merger deal with Mountain Crest Acquisition Corp.\u2014a special purpose acquisition company (SPAC). In February 2021, the stock of a combined company, PLBY Group, began trading on the Nasdaq exchange as \"PLBY\".\nIn August 2024 it was announced that the magazine would relaunch in print in February 2025; it will now be published annually. In 2025 it was announced that the Playboy headquarters would move from Los Angeles to Miami Beach by September 2026. Alongside plans to open a new Playboy Club in Miami Beach.\nCirculation history and statistics.\nIn 1971, \"Playboy\" had a circulation rate base of seven million, which was its high point. The best-selling individual issue was the November 1972 edition, which sold 7,161,561 copies. One-quarter of all American college men were buying or subscribing to the magazine every month. On the cover was model Pam Rawlings, photographed by Rowland Scherman. Perhaps coincidentally, a cropped image of the issue's centerfold (which featured Lena S\u00f6derberg) became a \"de facto\" standard image for testing image processing algorithms. It is known simply as the \"Lenna\" (also \"Lena\") image in that field. In 1972, \"Playboy\" was the ninth highest circulation magazine in the United States.\nThe 1975 average circulation was 5.6 million; by 1981, it was 5.2 million and by 1982 down to 4.9 million. Its decline continued in later decades and reached about 800,000 copies per issue in late 2015, and 400,000 copies by December 2017.\nIn 1970, \"Playboy\" became the first gentleman's magazine printed in braille. It is also one of the few magazines whose microfilm format was in color, not black and white.\nFeatures and format.\nRabbit logo.\n\"Playboy\"'s enduring mascot, a stylized silhouette of a rabbit wearing a tuxedo bow tie, was created by \"Playboy\" art director Art Paul for the second issue as an endnote, but was adopted as the official logo and has appeared ever since. A running joke in the magazine involves hiding the logo somewhere in the cover art or photograph. Hefner said he chose the rabbit for its \"humorous sexual connotation\" and because the image was \"frisky and playful\". In an interview, Hefner explained his choice of a rabbit as \"Playboy\"'s logo to the Italian journalist Oriana Fallaci:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; The rabbit, the bunny, in America has a sexual meaning; and I chose it because it's a fresh animal, shy, vivacious, jumping - sexy. First it smells you then it escapes, then it comes back, and you feel like caressing it, playing with it. A girl resembles a bunny. Joyful, joking. Consider the girl we made popular: the Playmate of the Month. She is never sophisticated, a girl you cannot really have. She is a young, healthy, simple girl - the girl next door ... we are not interested in the mysterious, difficult woman, the femme fatale, who wears elegant underwear, with lace, and she is sad, and somehow mentally filthy. The \"Playboy\" girl has no lace, no underwear, she is naked, well washed with soap and water, and she is happy.\nThe jaunty rabbit quickly became a popular symbol of extroverted male culture, becoming a lucrative source of merchandizing revenue for the company. In the 1950s, it was adopted as the military aircraft insignia for the US Navy's Air Test and Evaluation Squadron Four (VX-4).\nThe \"Playboy\" Interview.\nBesides its centerfold, a major part of \"Playboy\" for much of its existence has been the \"Playboy\" Interview, an extensive (usually several-thousand-word) discussion between a publicly known individual and an interviewer. Writer Alex Haley served as a \"Playboy\" interviewer on a few occasions; one of his interviews was with Martin Luther King Jr.; he also interviewed Malcolm X and American Nazi Party founder George Lincoln Rockwell. The magazine interviewed then-presidential candidate Jimmy Carter in the November 1976 issue, in which he stated \"I've committed adultery in my heart many times.\" David Sheff's interview with John Lennon and Yoko Ono appeared in the January 1981 issue, which was on newsstands at the time of Lennon's murder; the interview was later published in book format.\nAnother interview-type section, entitled \"20Q\" (a play on the game of Twenty Questions), was added in October 1978. Cheryl Tiegs was the first interviewee for the section.\nRock the Rabbit.\n\"Rock the Rabbit\" was an annual music news and pictorial feature published in the March edition. The pictorial featured images of rock bands photographed by music photographer Mick Rock. Fashion designers participated in the Rock the Rabbit event by designing T-shirts inspired by \"Playboy\"'s rabbit head logo for each band. The shirts were sold at \"Playboy\"'s retailers and auctioned off to raise money for AIDS research and treatment at LIFEbeat: The Music Industry Fights AIDS. Bands who were featured include: MGMT, Daft Punk, Iggy Pop, Duran Duran, Flaming Lips, Snow Patrol, and The Killers.\nPhotographers.\nThe photographers who have contributed to \"Playboy\" include Mario Casilli, Ana Dias, Richard Fegley, Arny Freytag, Ron Harris, Tom Kelley, Annie Leibovitz, Ken Marcus, David Mecey, Russ Meyer, Helmut Newton, Pompeo Posar, Suze Randall, Herb Ritts, Ellen von Unwerth, Stephen Wayda, Sam Wu, and Bunny Yeager.\nCelebrities.\nMany celebrities (singers, actresses, models, etc.) have posed for \"Playboy\" over the years. This list is only a small portion of those who have posed. Some of them are:\nFilm:\nMusic:\nSports:\nTelevision:\nOther editions.\n\"Playboy Special Edition\"s.\nThe success of \"Playboy\" magazine has led PEI to market other versions of the magazine, the \"Special Edition\"s (formerly called \"Newsstand Special\"s), such as \"Playboy's College Girls\" and \"Playboy's Book of Lingerie\", as well as the \"Playboy\" video collection.\nBraille.\nThe National Library Service for the Blind and Physically Handicapped (NLS) has published a braille edition of \"Playboy\" since 1970. The braille version includes all the written words in the non-braille magazine, but no pictorial representations. Congress cut off funding for the braille magazine translation in 1985, but U.S. District Court Judge Thomas Hogan reversed the decision on First Amendment grounds.\nOnline.\nThe growth of the Internet prompted the magazine to develop an official internet presence called \"Playboy\" Online in the late 1980s. The company launched Playboy.com, the official website for Playboy Enterprises and an online companion to \"Playboy\" magazine, in 1994. As part of the online presence, Playboy developed a pay web site called the \"Playboy Cyber Club\" in 1995 which features online chats, additional pictorials, videos of Playmates and Playboy Cyber Girls that are not featured in the magazine. Archives of past \"Playboy\" articles and interviews are also included. In September 2005, \"Playboy\" began publishing a digital version of the magazine.\nIn 2010, Playboy introduced \"The Smoking Jacket\", a safe-for-work website designed to appeal to young men, while avoiding nude images or key words that would cause the site to be filtered or otherwise prohibited in the workplace.\nIn May 2011, Playboy introduced iplayboy.com, a complete, uncensored version of its near-700-issue archive, targeting the Apple iPad. By launching the archive as a web app, Playboy was able to circumvent both Apple's App Store content restrictions and their 30% subscription fee.\nLitigation and legal issues.\nIn 1966, Jane Fonda filed a $17.5 million lawsuit against \"Playboy\" for publishing nude photos without her consent. As part of her settlement, the February 1971 issue contained a full-page ad in support of the Vietnam Veterans Against the War.\nStacy Arthur, Playboy's Playmate of the Month for January, 1991, filed a $70 million lawsuit against Playboy Enterprises Inc. and others alleging she was raped and sodomized by three Playboy employees on October 6, 1991, at the Playboy mansion in Los Angeles and that inaction by the magazine led to the death of her husband.\nOn January 14, 2004, the Ninth Circuit U.S. Court of Appeals ruled that Playboy Enterprises Inc.'s trademark terms \"Playboy\" and \"Playmate\" should be protected in the situation where a user typing \"Playboy\" or \"Playmate\" in a browser search was instead shown advertisements of companies that competed with PEI. This decision reversed an earlier district court ruling. The suit started on April 15, 1999, when Playboy sued Excite Inc. and Netscape for trademark infringement.\nCensorship.\nMany in the American religious community opposed the publication of \"Playboy\". The Louisiana pastor and author L.\u00a0L.\u00a0Clover wrote in his 1974 treatise, \"Evil Spirits, Intellectualism and Logic\", that \"Playboy\" encouraged young men to view themselves as \"pleasure-seeking individuals for whom sex is fun and women are play things.\"\nIn many parts of Asia, including India, mainland China, Myanmar, Malaysia, Thailand, Singapore, and Brunei, sale and distribution of \"Playboy\" is banned. In addition, sale and distribution is banned in most Muslim countries (except Lebanon and Turkey) including Iran, Saudi Arabia, and Pakistan. Despite the ban on the magazine in these countries, the official \"Playboy\" brand itself can still appear on various merchandise, such as perfume and deodorants.\nWhile banned in mainland China, the magazine is sold in Hong Kong. In Japan, where genitals of models cannot be shown, a separate edition was published under license by Shueisha. An Indonesian edition was launched in April 2006, but controversy started before the first issue hit the stands. Though the publisher said the content of the Indonesian edition will be different from the original edition, the government tried to ban it by using anti-pornography rules. A Muslim organization, the Islamic Defenders Front (IDF), opposed \"Playboy\" on the grounds of pornography. On April 12, about 150 IDF members clashed with police and stoned the editorial offices. Despite this, the edition quickly sold out. On April 6, 2007, the chief judge of the case dismissed the charges because they had been incorrectly filed.\nIn 1986, the American convenience store chain 7-Eleven removed the magazine. The store returned \"Playboy\" to its shelves in late 2003. 7-Eleven had also been selling \"Penthouse\" and other similar magazines before the ban.\nIn 1995, \"Playboy\" was returned to shelves in the Republic of Ireland after a 36-year ban, despite staunch opposition from many women's groups.\n\"Playboy\" was not sold in the state of Queensland, Australia, during 2004 and 2005, but returned as of 2006. Due to declining sales, the last Australia-wide edition of \"Playboy\" was the January 2000 issue.\nIn 2013, \"Playboy\" was cleared by the Pentagon of violating its rule against selling sexually explicit material on military property, but the base exchanges stopped selling it anyway.\nIn March 2018, \"Playboy\" announced that they would be deactivating their Facebook accounts due to the \"sexually repressive\" nature of the social media platform and their mismanagement of user data resulting from the Cambridge Analytica problem.\nFemale perspectives and experiences.\nGloria Steinem.\nGloria Steinem, an American activist and journalist, went undercover as an employee in 1963 at the New York City Playboy club. The same year she wrote an expose article called \"A Bunny's Tale\", discussing the inner-workings of a Playboy Bunny, which was later turned into a TV film. Steinem, going by the cover name of Marie Cathrine Ochs, applied for the job of a Playboy bunny. Her goal was to research and investigate the alleged mistreatment and harassment of women at the Playboy club. Steinem prepared a whole background story, very careful not to be discovered. Steinem arrived at the club in New York City, and filled out an application to be a Playboy Bunny. When applying, she was told that as a 24-year-old, she was considered relatively old to work there. Additionally, Steinem detailed how Playboy didn't want any backstory, but just wanted their employees to be a pretty face for the company. When applying, Steinem was told the expectations of the workers. Bunnies had to maintain a certain level of personal maintenance, such as always having their makeup, nails and hair done without flaws. The Bunnies were instructed to always be perceived as happy and optimistic. They were also expected to weigh a certain amount, and to have a certain bust size, or else they would get fined. There was a club motto that the Bunnies were hired for 1. Beauty 2. Personality 3. Ability, and the order was very important. Steinem was hired on the spot, and told to come back in a few days for training. She was given the \"Bunny Bible\", a rulebook with all the etiquette information. The club had fine lines around prostitution. No Bunny could seem interested or available to customers, however if a top client or a \"key-holder\" expressed interest, they were encouraged and suggested to comply. Additionally, the club would take 50% of tips earned from the first $30 of the night, 25% of tips up to $60 and 5% of tips after that.\nSteinem detailed many forms of harassment she allegedly received during training, including customers touching her costume, putting their arm around her, breathing heavily down her neck, along with multiple instances of being yelled at when refusing to go home with a customer. Steinem claimed to have worked long night shifts in uncomfortable clothing, with no breaks or food. The Bunnies were told they would make around $200 \u2013 300 a week, when in reality they had to share tips and they were underpaid. Steinem also observed and noted in her expose how Bunnies of color were called \"Chocolate Bunnies\" and were given lower ranking jobs in the club.\nJennifer Saginor.\nJennifer Saginor, author of her memoir \"Playground: A Childhood Lost Inside the Playboy Mansion\", experienced the infamous Playboy mansion at the age of six years old for the first time. Her father, Mark Saginor, was Hugh Hefner's physician, otherwise known as \"Dr. Feelgood\". Dr. Saginor was the primary reason that Jennifer was introduced to the mansion at such a young age due to his residency there. While her parents were still together, Jennifer and her sister would spend a good amount of time at the mansion with their father, having a plethora of adult experiences sprung on them at a young age. Her mother fought, trying to prevent her daughters from stepping foot into that mansion. She went as far as getting a divorce with \"Dr. Feelgood\", hoping for full custody, as well as court orders.\nAfter Jennifer's parents' divorce, Dr. Saginor spent significantly more time at the mansion than prior, bringing his children along with him. No matter how often her mother would forbid them from going, Jennifer would lie about her whereabouts to spend time at the \"playhouse\". Jennifer yearned for her father's love and affection, so, she would insist on going to the mansion with him. Unfortunately for Jennifer, this would lead to years of processing her broken childhood, which she is continuing to work on in present times. \nA specific story that Jennifer references in her memoir is, again, at the age of six when she ventures to the mansion for the first time, meeting Hugh Hefner, and is left to her own devices by her father. As she walked through the mansion, surrounded by half-naked strangers, she ran into the butler who showed her to the pool. Once getting to the pool, Jennifer discovered a secret tunnel under the water, leading to an underground Jacuzzi in a separate section of the house. Here, she walked in on John Belushi having sexual intercourse with one of the Playboy Bunnies. She was six years old at the time, but describes her response to this experience as \"I am no longer six. I have grown to full maturity in a matter of seconds.\" Throughout the rest of her book, she discusses several stories involving herself and others, sharing what really went down in the mansion during her time residing there, including the sexual relationship she was involved in with one of Hugh Hefner's girlfriends.\nSondra Theodore.\nSondra Theodore, Hugh Hefner's girlfriend from 1979 to 1981, lived with Hefner in his mansion with her children throughout the duration of her relationship. One of the most famous playboy bunnies, Theodore was featured on the cover of \"Playboy\" in 1977 and had many centerfold photo shoots throughout her time as a Playboy bunny. In the documentary series \"Secrets of Playboy\", she spoke out about her experience and the mistreatment she received during her time in the house. Theodore also spoke about her experience in a joint interview with her daughter for People magazine. In the interview they discuss the vastly different experiences and perspectives they had living in the mansion.\nIn the documentary, Theodore spoke about the pressure she felt to engage in sexual acts, not only with Hefner, but also with other men and women who frequented the house. She also alleged that she was forced to be a \"drug mule\" for Hefner, stating that he forced her to retrieve drugs, including cocaine, for his personal use. Many other former bunnies called out Theodore saying that she was \"chasing fame\" and alleging that her accusations were false due to the fact that she didn't speak out for years. The backlash that Theodore faced was in part due to the fact that after their split she remained on good terms with Hefner. She ended up marrying a close friend of Hefner. She also returned to the mansion many times after her split with Hefner and when she eventually divorced her husband it was Hefner who gave her money for a divorce lawyer. Their close friendship, even after their romantic relationship ended, led many to question the validity of Theodore's story. In the documentary Theodore acknowledges how she waited to speak out due to blocking out traumatic memories and believing that she didn't have a voice. The documentary gave her and other former bunnies a chance to share their experiences. In response to Theodore's allegations and the documentary in general, Playboy released an open letter stating that \"today's Playboy is not Hugh Hefner's Playboy\".\nBooks.\nGeneral compilations\nAnniversary collections\nInterview compilations\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nOfficial\nMetadata"}
{"id": "23222", "revid": "38472774", "url": "https://en.wikipedia.org/wiki?curid=23222", "title": "Pennsylvanian (geology)", "text": "Second subperiod of the Carboniferous\nThe Pennsylvanian ( , also known as Upper Carboniferous or Late Carboniferous) is, on the ICS geologic timescale, the younger of two subperiods of the Carboniferous Period (or the upper of two subsystems of the Carboniferous System). It lasted from roughly {{}}: Error! the period you specified has not been recognised! This could be because you mis-spelt it, or because it is missing from or .. As with most other geochronologic units, the rock beds that define the Pennsylvanian are well identified, but the exact date of the start and end are uncertain by a few hundred thousand years. The Pennsylvanian is named after the U.S. state of Pennsylvania, where the coal beds of this age are widespread.\nThe division between Pennsylvanian and Mississippian comes from North American stratigraphy. In North America, where the early Carboniferous beds are primarily marine limestones, the Pennsylvanian was in the past treated as a full-fledged geologic period between the Mississippian and the Permian. In parts of Europe, the Mississippian and Pennsylvanian are one more-or-less continuous sequence of lowland continental deposits and are grouped together as the Carboniferous Period. The current internationally used geologic timescale of the ICS gives the Mississippian and Pennsylvanian the rank of subperiods, subdivisions of the Carboniferous Period.\nLife.\nFungi.\nAll modern classes of fungi have been found in rocks of Pennsylvanian age.\nInvertebrates.\nThe major forms of life at this time were the arthropods. Arthropods were far larger than modern ones. \"Arthropleura\", a giant millipede, was a common sight and the giant griffinfly \"Meganeura\" \"flew the skies\". It is commonly considered that is because of high oxygen level, however some of those large arthropod records are also known from period with relatively low oxygen, which suggest high oxygen pressure may not have been a primary reason for their gigantism.\nVertebrates.\nAmphibians were diverse and common; some were several meters long as adults. The collapse of the rainforest ecology in the mid-Pennsylvanian (between the Moscovian and the Kasimovian) removed many amphibian species that did not survive as well in the cooler, drier conditions. Amniotes, however, prospered due to specific key adaptations. One of the greatest evolutionary innovations of the Carboniferous was the amniote egg, which allowed for the further exploitation of the land by certain tetrapods. These included the earliest sauropsid reptiles (\"Hylonomus\"), and the earliest known \"pelycosaur\" synapsids (\"Archaeothyris\"). Small lizard-like animals quickly gave rise to many descendants. Amniotes underwent a major evolutionary radiation, in response to the drier climate that followed the rainforest collapse.\nFor some reason, pelycosaurs were able to reach larger sizes before reptiles could, and this trend continued until the end of the Permian, during which their cynodont descendants became smaller and nocturnal, as the reptilian archosaurs took over, although dicynodonts would remain megafaunal until their extinction at the end of the Triassic. Most pre-rainforest collapse tetrapods remained smaller, probably due to the land being primarily occupied by the gigantic millipedes, scorpions, and flying insects. After the rainforest collapse, the giant arthropods disappeared, allowing amniote tetrapods to achieve larger sizes.\nSubdivisions.\nThe Pennsylvanian has been variously subdivided. The international timescale of the ICS follows the Russian subdivision into four stages:\nNorth American subdivision is into five stages, but not precisely the same, with additional (older) Appalachian series names following:\nThe Virgilian or Conemaugh corresponds to the Gzhelian plus the uppermost Kasimovian.\nThe Missourian or Monongahela corresponds to the rest of the Kasimovian.\nThe Desmoinesian or Allegheny corresponds to the upper half of the Moscovian.\nThe Atokan or upper Pottsville corresponds to the lower half of the Moscovian.\nThe Morrowan corresponds to the Bashkirian.\nIn the European subdivision, the Carboniferous is divided into two epochs: Dinantian (early) and Silesian (late). The Silesian starts earlier than the Pennsylvanian and is divided in three ages:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23224", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=23224", "title": "Paul H\u00e9roult", "text": "French scientist\nPaul (Louis-Toussaint) H\u00e9roult (10 April 1863 \u2013 9 May 1914) was a French scientist. He was one of the inventors of the Hall-H\u00e9roult process for smelting aluminium, and developed the first successful commercial electric arc furnace. He lived in Thury-Harcourt, Normandy.\nLife and career.\nPaul H\u00e9roult read Henri Sainte-Claire Deville's treatise on aluminium, when he was 15 years old. At that time, aluminium was as expensive as silver and was used mostly for luxury items and jewellery. H\u00e9roult wanted to make it cheaper.\nHe succeeded in doing so when he discovered the electrolytic aluminium process in 1886.\nThe same year, in the United States, Charles Martin Hall (1863\u20131914) was discovering the same process. Because of this, the process was called the Hall\u2013Heroult process.\nH\u00e9roult's second most important contribution is the first commercially successful electric arc furnace (EAF) for steel in 1900. The H\u00e9roult furnace gradually replaced the giant smelters for the production of a variety of steels. In 1905, Paul H\u00e9roult was invited to the United States as a technical adviser to several companies, and in particular to the United States Steel Corporation and the Halcomb Steel Company. Halcomb installed the first H\u00e9roult furnace in the US.\nThe invention of the electric arc furnace probably began when Humphry Davy discovered the carbon arc in 1800. Then in 1878 Carl Wilhelm Siemens patented, constructed and operated both direct and indirect EAFs. Commercial use still needed to wait for larger supplies of electricity and better carbon electrodes.\nPaul H\u00e9roult is renowned for other major inventions, among them a\nself-supporting conduit still used to bring water down from mountain heights and across rivers to hydraulic power plants, avoiding the need to build expensive bridges.\nChristian Bickert said of him \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Paul H\u00e9roult had none of the attributes of the traditional scholar.\nHe was highstrung, unruly, occasionally hard and insolent; he did not fit the image of wise, disciplined men of science.\nHe loved games, the company of women, travels by land and sea; he was a free spirit in an impetuous body.\nNo comparison with the austere scientist, struggling with stubborn mysteries. \nHis discoveries were not the result of long sleepless nights spent in a laboratory, or of complicated scientific demonstrations. \nH\u00e9roult loved life, and could not have borne such restrictions.\nInstead, his inventions appeared suddenly, out of the blue, a stroke of common sense, or of genius, sometimes during a lively \ngame of billiards, his favorite pastime.\nH\u00e9roult died on 9 May 1914; he was 51 years and 29 days old.\nFootnotes and references.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23226", "revid": "31876559", "url": "https://en.wikipedia.org/wiki?curid=23226", "title": "Permian", "text": "Sixth and last period of the Paleozoic Era\nThe Permian ( ) is a geologic period and stratigraphic system which spans 47 million years, from the end of the Carboniferous Period Ma (million years ago) to the beginning of the Triassic Period 251.902 Ma. It is the sixth and last period of the Paleozoic Era; the following Triassic Period belongs to the Mesozoic Era. The concept of the Permian was introduced in 1841 by geologist Sir Roderick Murchison, who named it after the region of Perm in Russia.\nThe Permian witnessed the diversification of the two groups of amniotes, the synapsids and the sauropsids (reptiles). The world at the time was dominated by the supercontinent Pangaea, which had formed due to the collision of Euramerica and Gondwana during the Carboniferous. Pangaea was surrounded by the superocean Panthalassa. The Carboniferous rainforest collapse left behind vast regions of desert within the continental interior. Amniotes, which could better cope with these drier conditions, rose to dominance in place of their amphibian ancestors.\nVarious authors have proposed at least three, and possibly four major extinction events in the Permian, though the validity of some of these extinctions has been disputed. The end of the Early Permian (Cisuralian) has a gap in the fossil record that may have constituted a major extinction, as most lineages of primitive \"pelycosaur\" synapsids becoming extinct, being replaced by more advanced therapsids. The end of the Capitanian Stage of the Permian was marked by the major Capitanian mass extinction event, associated with the eruption of the Emeishan Traps. The Permian (along with the Paleozoic) ended with the Permian\u2013Triassic extinction event (colloquially known as the Great Dying), the largest mass extinction in Earth's history (which is the last of the three or four crises that occurred in the Permian), in which nearly 81% of marine species and 70% of terrestrial species died out, associated with the eruption of the Siberian Traps. It took well into the Triassic for life to recover from this catastrophe; on land, ecosystems took 30 million years to recover.\nEtymology and history.\nPrior to the introduction of the term \"Permian\", rocks of equivalent age in Germany had been named the Rotliegend and Zechstein, and in Great Britain as the New Red Sandstone.\nThe term \"Permian\" was introduced into geology in 1841 by Sir Roderick Impey Murchison, president of the Geological Society of London, after extensive Russian explorations undertaken with \u00c9douard de Verneuil in the vicinity of the Ural Mountains in the years 1840 and 1841. Murchison identified \"vast series of beds of marl, schist, limestone, sandstone and conglomerate\" that succeeded Carboniferous strata in the region. Murchison, in collaboration with Russian geologists, named the period after the surrounding Russian region of Perm, which takes its name from the medieval kingdom of Permia that occupied the same area hundreds of years prior, and which is now located in the Perm Krai administrative region. Between 1853 and 1867, Jules Marcou recognised Permian strata in a large area of North America from the Mississippi River to the Colorado River and proposed the name \"Dyassic\", from \"Dyas\" and \"Trias\", though Murchison rejected this in 1871. The Permian system was controversial for over a century after its original naming, with the United States Geological Survey until 1941 considering the Permian a subsystem of the Carboniferous equivalent to the Mississippian and Pennsylvanian.\nGeology.\nThe Permian Period is divided into three epochs, from oldest to youngest, the Cisuralian, Guadalupian, and Lopingian. Geologists divide the rocks of the Permian into a stratigraphic set of smaller units called stages, each formed during corresponding time intervals called ages. Stages can be defined globally or regionally. For \"global\" stratigraphic correlation, the International Commission on Stratigraphy (ICS) ratify global stages based on a Global Boundary Stratotype Section and Point (GSSP) from a single formation (a stratotype) identifying the lower boundary of the stage. The ages of the Permian, from youngest to oldest, are:\nFor most of the 20th century, the Permian was divided into the Early and Late Permian, with the Kungurian being the last stage of the Early Permian. Glenister and colleagues in 1992 proposed a tripartite scheme, advocating that the Roadian-Capitanian was distinct from the rest of the Late Permian, and should be regarded as a separate epoch. The tripartite split was adopted after a formal proposal by Glenister et al. (1999).\nHistorically, most marine biostratigraphy of the Permian was based on ammonoids; however, ammonoid localities are rare in Permian stratigraphic sections, and species characterise relatively long periods of time. All GSSPs for the Permian are based around the first appearance datum of specific species of conodont, an enigmatic group of jawless chordates with hard tooth-like oral elements. Conodonts are used as index fossils for most of the Palaeozoic and the Triassic.\nCisuralian.\nThe Cisuralian Series is named after the strata exposed on the western slopes of the Ural Mountains in Russia and Kazakhstan. The name was proposed by J. B. Waterhouse in 1982 to comprise the Asselian, Sakmarian, and Artinskian stages. The Kungurian was later added to conform to the Russian \"Lower Permian\". Albert Auguste Cochon de Lapparent in 1900 had proposed the \"Uralian Series\", but the subsequent inconsistent usage of this term meant that it was later abandoned.\nThe Asselian was named by the Russian stratigrapher V.E. Ruzhenchev in 1954, after the Assel River in the southern Ural Mountains. The GSSP for the base of the Asselian is located in the Aidaralash River valley near Aqt\u00f6be, Kazakhstan, which was ratified in 1996. The beginning of the stage is defined by the first appearance of \"Streptognathodus postfusus.\"\nThe Sakmarian is named in reference to the Sakmara River in the southern Urals, and was coined by Alexander Karpinsky in 1874. The GSSP for the base of the Sakmarian is located at the Usolka section in the southern Urals, which was ratified in 2018. The GSSP is defined by the first appearance of \"Sweetognathus binodosus\".\nThe Artinskian was named after the city of Arti in Sverdlovsk Oblast, Russia. It was named by Karpinsky in 1874. The Artinskian currently lacks a defined GSSP. The proposed definition for the base of the Artinskian is the first appearance of \"Sweetognathus aff. S. whitei.\"\nThe Kungurian takes its name after Kungur, a city in Perm Krai. The stage was introduced by Alexandr Antonovich Stukenberg in 1890. The Kungurian currently lacks a defined GSSP. Recent proposals have suggested the appearance of \"Neostreptognathodus pnevi\" as the lower boundary.\nGuadalupian.\nThe Guadalupian Series is named after the Guadalupe Mountains in Texas and New Mexico, where extensive marine sequences of this age are exposed. It was named by George Herbert Girty in 1902.\nThe Roadian was named in 1968 in reference to the Road Canyon Member of the Word Formation in Texas. The GSSP for the base of the Roadian is located 42.7m above the base of the Cutoff Formation in Stratotype Canyon, Guadalupe Mountains, Texas, and was ratified in 2001. The beginning of the stage is defined by the first appearance of \"Jinogondolella nankingensis\".\nThe Wordian was named in reference to the Word Formation by Johan August Udden in 1916, Glenister and Furnish in 1961 was the first publication to use it as a chronostratigraphic term as a substage of the Guadalupian Stage. The GSSP for the base of the Wordian is located in Guadalupe Pass, Texas, within the sediments of the Getaway Limestone Member of the Cherry Canyon Formation, which was ratified in 2001. The base of the Wordian is defined by the first appearance of the conodont \"Jinogondolella aserrata\".\nThe Capitanian is named after the Capitan Reef in the Guadalupe Mountains of Texas, named by George Burr Richardson in 1904, and first used in a chronostratigraphic sense by Glenister and Furnish in 1961 as a substage of the Guadalupian Stage. The Capitanian was ratified as an international stage by the ICS in 2001. The GSSP for the base of the Capitanian is located at Nipple Hill in the southeast Guadalupe Mountains of Texas, and was ratified in 2001, the beginning of the stage is defined by the first appearance of \"Jinogondolella postserrata\".\nLopingian.\nThe Lopingian was first introduced by Amadeus William Grabau in 1923 as the \"Loping Series\" after Leping, Jiangxi, China. Originally used as a lithostraphic unit, T.K. Huang in 1932 raised the Lopingian to a series, including all Permian deposits in South China that overlie the Maokou Limestone. In 1995, a vote by the Subcommission on Permian Stratigraphy of the ICS adopted the Lopingian as an international standard chronostratigraphic unit.\"\"\nThe Wuchiapinginan and Changhsingian were first introduced in 1962, by J. Z. Sheng as the \"Wuchiaping Formation\" and \"Changhsing Formation\" within the Lopingian series. The GSSP for the base of the Wuchiapingian is located at Penglaitan, Guangxi, China and was ratified in 2004. The boundary is defined by the first appearance of \"Clarkina postbitteri postbitteri\"\"\" The Changhsingian was originally derived from the Changxing Limestone, a geological unit first named by the Grabau in 1923, ultimately deriving from Changxing County, Zhejiang .The GSSP for the base of the Changhsingian is located 88\u00a0cm above the base of the Changxing Limestone in the Meishan D section, Zhejiang, China and was ratified in 2005, the boundary is defined by the first appearance of \"Clarkina wangi\".\nThe GSSP for the base of the Triassic is located at the base of Bed 27c at the Meishan D section, and was ratified in 2001. The GSSP is defined by the first appearance of the conodont \"Hindeodus parvus\".\nRegional stages.\nThe Russian Tatarian Stage includes the Lopingian, Capitanian and part of the Wordian, while the underlying Kazanian includes the rest of the Wordian as well as the Roadian. \nIn North America, the Permian is divided into the Wolfcampian (which includes the Nealian and the Lenoxian stages); the Leonardian (Hessian and Cathedralian stages); the Guadalupian; and the Ochoan, corresponding to the Lopingian.\nThe New Zealand geologic time scale divides the Permian into three epochs, Pre-Telfordian (undivided), D'Urville (divided into the Makarewan, Waiitian, and Puruhauan stages), and Aparima (Flettian, Barrettian, Mangapirian, and Telfordian stages). The Pre-Telfordian epoch corresponds approximately to the Asselian, Sakmarian, and Artinskian stages; the D'Urville epoch is roughly contemporary with the Kungurian stage and Guadalupian epoch; and the Aparima epoch is closely contemporary with the Lopingian epoch.\nPaleogeography.\nDuring the Permian, all the Earth's major landmasses were collected into a single supercontinent known as Pangaea, with the microcontinental terranes of Cathaysia to the east. Pangaea straddled the equator and extended toward the poles, with a corresponding effect on ocean currents in the single great ocean (\"Panthalassa\", the \"universal sea\"), and the Paleo-Tethys Ocean, a large ocean that existed between Asia and Gondwana. The Cimmeria continent rifted away from Gondwana and drifted north to Laurasia, causing the Paleo-Tethys Ocean to shrink. A new ocean was growing on its southern end, the Neotethys Ocean, an ocean that would dominate much of the Mesozoic Era. A magmatic arc, containing Hainan on its southwesternmost end, began to form as Panthalassa subducted under the southeastern South China. The Central Pangean Mountains, which began forming due to the collision of Laurasia and Gondwana during the Carboniferous, reached their maximum height during the early Permian around 295 Ma, comparable to the present Himalayas, but became heavily eroded as the Permian progressed. The Kazakhstania block collided with Baltica during the Cisuralian, while the North China Craton, the South China Block and Indochina fused to each other and Pangea by the end of the Permian. The Zechstein Sea, a hypersaline epicontinental sea, existed in what is now northwestern Europe.\nLarge continental landmass interiors experience climates with extreme variations of heat and cold (\"continental climate\") and monsoon conditions with highly seasonal rainfall patterns. Deserts seem to have been widespread on Pangaea. Such dry conditions favored gymnosperms, plants with seeds enclosed in a protective cover, over plants such as ferns that disperse spores in a wetter environment. The first modern trees (conifers, ginkgos and cycads) appeared in the Permian.\nThree general areas are especially noted for their extensive Permian deposits\u2014the Ural Mountains (where Perm itself is located), China, and the southwest of North America, including the Texas red beds. The Permian Basin in the U.S. states of Texas and New Mexico is so named because it has one of the thickest deposits of Permian rocks in the world.\nPaleoceanography.\nSea levels dropped slightly during the earliest Permian (Asselian). The sea level was stable at several tens of metres above present during the Early Permian, but there was a sharp drop beginning during the Roadian, culminating in the lowest sea level of the entire Palaeozoic at around present sea level during the Wuchiapingian, followed by a slight rise during the Changhsingian.\nClimate.\nThe Permian was cool in comparison to most other geologic time periods, with modest pole to Equator temperature gradients. At the start of the Permian, the Earth was still in the Late Paleozoic icehouse (LPIA), which began in the latest Devonian and spanned the entire Carboniferous period, with its most intense phase occurring during the latter part of the Pennsylvanian epoch. A significant trend of increasing aridification can be observed over the course of the Cisuralian. Early Permian aridification was most notable in Pangaean localities at near-equatorial latitudes. Sea levels also rose notably in the Early Permian as the LPIA slowly waned. At the Carboniferous-Permian boundary, a warming event occurred. In addition to becoming warmer, the climate became notably more arid at the end of the Carboniferous and beginning of the Permian. Nonetheless, temperatures continued to cool during most of the Asselian and Sakmarian, during which the LPIA peaked. By 287 Ma, temperatures warmed and the South Pole ice cap retreated in what was known as the Artinskian Warming Event (AWE), though glaciers remained present in the uplands of eastern Australia, and perhaps also the mountainous regions of far northern Siberia. Southern Africa also retained glaciers during the late Cisuralian in upland environments. The AWE also witnessed aridification of a particularly great magnitude. \nIn the late Kungurian, cooling resumed, resulting in a cool glacial interval that lasted into the early Capitanian, though average temperatures were still much higher than during the beginning of the Cisuralian. Another cool period began around the middle Capitanian. This cool period, lasting for 3\u20134 Myr, was known as the Kamura Event. It was interrupted by the Emeishan Thermal Excursion in the late part of the Capitanian, around 260 million years ago, corresponding to the eruption of the Emeishan Traps. This interval of rapid climate change was responsible for the Capitanian mass extinction event. \nDuring the early Wuchiapingian, following the emplacement of the Emeishan Traps, global temperatures declined as carbon dioxide was weathered out of the atmosphere by the large igneous province's emplaced basalts. The late Wuchiapingian saw the finale of the Late Palaeozoic Ice Age, when the last Australian glaciers melted. The end of the Permian is marked by a temperature excursion, much larger than the Emeishan Thermal Excursion, at the Permian-Triassic boundary, corresponding to the eruption of the Siberian Traps, which released more than 5 teratonnes of CO2, more than doubling the atmospheric carbon dioxide concentration. A -2% \"\u03b4\"18O excursion signifies the extreme magnitude of this climatic shift. This extremely rapid interval of greenhouse gas release caused the Permian-Triassic mass extinction, as well as ushering in an extreme hothouse that persisted for several million years into the next geologic epoch, the Triassic.\nThe Permian climate was also extremely seasonal and characterised by megamonsoons, which produced high aridity and extreme seasonality in Pangaea's interiors. Precipitation along the western margins of the Palaeo-Tethys Ocean was very high. Evidence for the megamonsoon includes the presence of megamonsoonal rainforests in the Qiangtang Basin of Tibet, enormous seasonal variation in sedimentation, bioturbation, and ichnofossil deposition recorded in sedimentary facies in the Sydney Basin, and palaeoclimatic models of the Earth's climate based on the behaviour of modern weather patterns showing that such a megamonsoon would occur given the continental arrangement of the Permian. The aforementioned increasing equatorial aridity was likely driven by the development and intensification of this Pangaean megamonsoon.\nLife.\nMarine biota.\nPermian marine deposits are rich in fossil mollusks, brachiopods, and echinoderms. Brachiopods were highly diverse during the Permian. The extinct order Productida was the predominant group of Permian brachiopods, accounting for up to about half of all Permian brachiopod genera. Brachiopods also served as important ecosystem engineers in Permian reef complexes. Amongst ammonoids, Goniatitida were a major group during the Early-Mid Permian, but declined during the Late Permian. Members of the order Prolecanitida were less diverse. The Ceratitida originated from the family Daraelitidae within Prolecanitida during the mid-Permian, and extensively diversified during the Late Permian. Only three families of trilobite are known from the Permian, Proetidae, Brachymetopidae and Phillipsiidae. Diversity, origination and extinction rates during the Early Permian were low. Trilobites underwent a diversification during the Kungurian-Wordian, the last in their evolutionary history, before declining during the Late Permian. By the Changhsingian, only a handful (4\u20136) genera remained. Corals exhibited a decline in diversity over the course of the Middle and Late Permian.\nTerrestrial biota.\nTerrestrial life in the Permian included diverse plants, fungi, arthropods, and various types of tetrapods. The period saw a massive desert covering the interior of Pangaea. The warm zone spread in the northern hemisphere, where extensive dry desert appeared. The rocks formed at that time were stained red by iron oxides, the result of intense heating by the sun of a surface devoid of vegetation cover. A number of older types of plants and animals died out or became marginal elements.\nThe Permian began with the Carboniferous flora still flourishing. About the middle of the Permian a major transition in vegetation began. The swamp-loving lycopod trees of the Carboniferous, such as \"Lepidodendron\" and \"Sigillaria\", were progressively replaced in the continental interior by the more advanced seed ferns and early conifers as a result of the Carboniferous rainforest collapse. At the close of the Permian, lycopod and equisete swamps reminiscent of Carboniferous flora survived only in Cathaysia, a series of equatorial islands in the Paleo-Tethys Ocean that later would become South China.\nThe Permian saw the radiation of many important conifer groups, including the ancestors of many present-day families. Rich forests were present in many areas, with a diverse mix of plant groups. The southern continent saw extensive seed fern forests of the \"Glossopteris\" flora. Oxygen levels were probably high there. The ginkgos and cycads also appeared during this period.\nInsects.\nInsects, which had first appeared and become abundant during the preceding Carboniferous, experienced a dramatic increase in diversification during the Early Permian. Towards the end of the Permian, there was a substantial drop in both origination and extinction rates. By the start of the Permian, there was already an active coevolutionary arms race between insects and plant reproductive structures, evidenced by both insect-caused damage in plants and defensive structures in plants aimed at minimising predation by insects. The dominant insects during the Permian Period were early representatives of Paleoptera, Polyneoptera, and Paraneoptera. Palaeodictyopteroidea, which had represented the dominant group of insects during the Carboniferous, declined during the Permian. This is likely due to competition by Hemiptera, due to their similar mouthparts and therefore ecology. Primitive relatives of damselflies and dragonflies (Meganisoptera), which include the largest flying insects of all time, also declined during the Permian. Holometabola, the largest group of modern insects, also diversified during this time. \"Grylloblattidans\", an extinct group of winged insects thought to be related to modern ice crawlers, reached their apex of diversity during the Permian, representing up to a third of all insects at some localities. Mecoptera (sometimes known as scorpionflies) first appeared during the Early Permian, going on to become diverse during the Late Permian. Some Permian mecopterans, like Mesopsychidae have long proboscis that suggest they may have pollinated gymnosperms. The earliest known beetles appeared at the beginning of the Permian. Early beetles such as members of Permocupedidae were likely xylophagous, feeding on decaying wood. Several lineages such as Schizophoridae expanded into aquatic habitats by the Late Permian. Members of the modern orders Archostemata and Adephaga are known from the Late Permian. Complex wood boring traces found in the Late Permian of China suggest that members of Polyphaga, the most diverse group of modern beetles, were also present by the Late Permian.\nTetrapods.\nThe terrestrial fossil record of the Permian is patchy and temporally discontinuous. Early Permian records are dominated by equatorial Europe and North America, while those of the Middle and Late Permian are dominated by temperate Karoo Supergroup sediments of South Africa and the Ural region of European Russia. Early Permian terrestrial faunas of North America and Europe were dominated by primitive pelycosaur synapsids including the herbivorous edaphosaurids, and carnivorous sphenacodontids, diadectids and amphibians. Early Permian reptiles, such as acleistorhinids, were mostly small insectivores.\nAmniotes.\nSynapsids (the group that would later include mammals) thrived and diversified greatly during the Cisuralian. Permian synapsids included some large members such as \"Dimetrodon\". The special adaptations of synapsids enabled them to flourish in the drier climate of the Permian and they grew to dominate the vertebrates. A faunal turnover occurred around the transition between the Cisuralian and Guadalupian, with the decline of amphibians and the replacement of pelycosaurs (a paraphyletic group) with more advanced therapsids, although the decline of early synapsid clades was apparently a slow event that lasted about 20 Ma, from the Sakmarian to the end of the Kungurian. Predator-prey interactions among terrestrial synapsids became more dynamic. If terrestrial deposition ended around the end of the Cisuralian in North America and began in Russia during the early Guadalupian, a continuous record of the transition is not preserved. Uncertain dating has led to suggestions that there is a global hiatus in the terrestrial fossil record during the late Kungurian and early Roadian, referred to as \"Olson's Gap\" that obscures the nature of the transition. Other proposals have suggested that the North American and Russian records overlap, with the latest terrestrial North American deposition occurring during the Roadian, suggesting that there was an extinction event, dubbed \"Olson's Extinction\". \nThe Middle Permian faunas of South Africa and Russia are dominated by therapsids, most abundantly by the diverse Dinocephalia. Dinocephalians become extinct at the end of the Middle Permian, during the Capitanian mass extinction event. Late Permian faunas are dominated by advanced therapsids such as the predatory sabertoothed gorgonopsians and herbivorous beaked dicynodonts, alongside large herbivorous pareiasaur parareptiles. The Archosauromorpha, the group of reptiles that would give rise to the pseudosuchians, dinosaurs, and pterosaurs in the following Triassic, first appeared and diversified during the Late Permian, including the first appearance of the Archosauriformes during the latest Permian. Cynodonts, the group of therapsids ancestral to modern mammals, first appeared and gained a worldwide distribution during the Late Permian. Another group of therapsids, the therocephalians (such as \"Lycosuchus\"), arose in the Middle Permian. There were no flying vertebrates, though the extinct lizard-like reptile family Weigeltisauridae from the Late Permian had extendable wings like modern gliding lizards, and are the oldest known gliding vertebrates.\nAmphibians.\nPermian stem-amniotes consisted of lepospondyli and batrachosaurs, according to some phylogenies; according to others, stem-amniotes are represented only by diadectomorphs. \nTemnospondyls reached a peak of diversity in the Cisuralian, with a substantial decline during the Guadalupian-Lopingian following Olson's extinction, with the family diversity dropping below Carboniferous levels.\nEmbolomeres, a group of aquatic crocodile-like limbed vertebrates that are reptilliomorphs under some phylogenies. They previously had their last records in the Cisuralian, are now known to have persisted into the Lopingian in China.\nModern amphibians (lissamphibians) are suggested to have originated during Permian, descending from a lineage of dissorophoid temnospondyls or lepospondyls.\nFish.\nThe diversity of fish during the Permian is relatively low compared to the following Triassic. The dominant group of bony fishes during the Permian were the \"Paleopterygii\" a paraphyletic grouping of Actinopterygii that lie outside of Neopterygii. The earliest unequivocal members of Neopterygii appear during the Early Triassic, but a Permian origin is suspected. The diversity of coelacanths is relatively low throughout the Permian in comparison to other marine fishes, though there is an increase in diversity during the terminal Permian (Changhsingian), corresponding with the highest diversity in their evolutionary history during the Early Triassic. Diversity of freshwater fish faunas was generally low and dominated by lungfish and \"Paleopterygians\". The last common ancestor of all living lungfish is thought to have existed during the Early Permian. Though the fossil record is fragmentary, lungfish appear to have undergone an evolutionary diversification and size increase in freshwater habitats during the Early Permian, but subsequently declined during the middle and late Permian. Conodonts experienced their lowest diversity of their entire evolutionary history during the Permian. Permian chondrichthyan faunas are poorly known. Members of the chondrichthyan clade Holocephali, which contains living chimaeras, reached their apex of diversity during the Carboniferous-Permian, the most famous Permian representative being the \"buzz-saw shark\" \"Helicoprion,\" known for its unusual spiral shaped spiral tooth whorl in the lower jaw. Hybodonts, a group of shark-like chondrichthyans, were widespread and abundant members of marine and freshwater faunas throughout the Permian. Xenacanthiformes, another extinct group of shark-like chondrichthyans, were common in freshwater habitats, and represented the apex predators of freshwater ecosystems.\nFlora.\nFour floristic provinces in the Permian are recognised, the Angaran, Euramerican, Gondwanan, and Cathaysian realms. The Carboniferous Rainforest Collapse would result in the replacement of lycopsid-dominated forests with tree-fern dominated ones during the late Carboniferous in Euramerica, and result in the differentiation of the Cathaysian floras from those of Euramerica. The Gondwanan floristic region was dominated by Glossopteridales, a group of woody gymnosperm plants, for most of the Permian, extending to high southern latitudes. The ecology of the most prominent glossopterid, \"Glossopteris\", has been compared to that of bald cypress, living in mires with waterlogged soils. The tree-like calamites, distant relatives of modern horsetails, lived in coal swamps and grew in bamboo-like vertical thickets. A mostly complete specimen of \"Arthropitys\" from the Early Permian Chemnitz petrified forest of Germany demonstrates that they had complex branching patterns similar to modern angiosperm trees. By the Late Permian, high thin forests had become widespread across the globe, as evidenced by the global distribution of weigeltisaurids.\nThe oldest likely record of Ginkgoales (the group containing \"Ginkgo\" and its close relatives) is \"Trichopitys heteromorpha\" from the earliest Permian of France. The oldest known fossils definitively assignable to modern cycads are known from the Late Permian. In Cathaysia, where a wet tropical frost-free climate prevailed, the Noeggerathiales, an extinct group of tree fern-like progymnosperms were a common component of the flora The earliest Permian (~ 298 million years ago) Cathyasian Wuda Tuff flora, representing a coal swamp community, has an upper canopy consisting of lycopsid tree \"Sigillaria,\" with a lower canopy consisting of Marattialean tree ferns, and Noeggerathiales. Early conifers appeared in the Late Carboniferous, represented by primitive walchian conifers, but were replaced with more derived voltzialeans during the Permian. Permian conifers were very similar morphologically to their modern counterparts, and were adapted to stressed dry or seasonally dry climatic conditions. The increasing aridity, especially at low latitudes, facilitated the spread of conifers and their increasing prevalence throughout terrestrial ecosystems. Bennettitales, which would go on to become in widespread the Mesozoic, first appeared during the Cisuralian in China. Lyginopterids, which had declined in the late Pennsylvanian and subsequently have a patchy fossil record, survived into the Late Permian in Cathaysia and equatorial east Gondwana.\nPermian\u2013Triassic extinction event.\nThe Permian ended with the most extensive extinction event recorded in paleontology: the Permian\u2013Triassic extinction event. 90 to 95% of marine species became extinct, as well as 70% of all land organisms. It is also the only known mass extinction of insects. Recovery from the Permian\u2013Triassic extinction event was protracted; on land, ecosystems took 30 million years to recover. Trilobites, which had thrived since Cambrian times, finally became extinct before the end of the Permian. Nautiloids, a subclass of cephalopods, surprisingly survived this occurrence.\nThere is evidence that magma, in the form of flood basalt, poured onto the Earth's surface in what is now called the Siberian Traps, for thousands of years, contributing to the environmental stress that led to mass extinction. The reduced coastal habitat and highly increased aridity probably also contributed. Based on the amount of lava estimated to have been produced during this period, the worst-case scenario is the release of enough carbon dioxide from the eruptions to raise world temperatures five degrees Celsius.\nAnother hypothesis involves ocean venting of hydrogen sulfide gas. Portions of the deep ocean will periodically lose all of its dissolved oxygen allowing bacteria that live without oxygen to flourish and produce hydrogen sulfide gas. If enough hydrogen sulfide accumulates in an anoxic zone, the gas can rise into the atmosphere. Oxidizing gases in the atmosphere would destroy the toxic gas, but the hydrogen sulfide would soon consume all of the atmospheric gas available. Hydrogen sulfide levels might have increased dramatically over a few hundred years. Models of such an event indicate that the gas would destroy ozone in the upper atmosphere allowing ultraviolet radiation to kill off species that had survived the toxic gas. There are species that can metabolize hydrogen sulfide.\nAnother hypothesis builds on the flood basalt eruption theory. An increase in temperature of five degrees Celsius would not be enough to explain the death of 95% of life. But such warming could slowly raise ocean temperatures until frozen methane reservoirs below the ocean floor near coastlines melted, expelling enough methane (among the most potent greenhouse gases) into the atmosphere to raise world temperatures an additional five degrees Celsius. The frozen methane hypothesis helps explain the increase in carbon-12 levels found midway in the Permian\u2013Triassic boundary layer. It also helps explain why the first phase of the layer's extinctions was land-based, the second was marine-based (and starting right after the increase in C-12 levels), and the third land-based again.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "23227", "revid": "50928646", "url": "https://en.wikipedia.org/wiki?curid=23227", "title": "Pisces (constellation)", "text": "Zodiac constellation straddling the celestial equator\nPisces is a constellation of the zodiac. Its vast bulk \u2014 and main asterism viewed in most European cultures per Greco-Roman antiquity as a distant pair of fishes connected by one cord each that join at an apex \u2014 are in the Northern celestial hemisphere. Its traditional astrological symbol is (\u2653\ufe0e). Its name is Latin for \"fishes\". It is between Aquarius, of similar size, to the southwest and Aries, which is smaller, to the east. The ecliptic and the celestial equator intersect within this constellation and in Virgo. The Sun passes directly overhead of the equator, on average, at approximately this point in the sky, at the March equinox.\nThe right ascension/declination 00 is located within the boundaries of Pisces.\nFeatures.\nThe March equinox is currently situated in Pisces, directly south of \u03c9 Psc, and because of precession, it is gradually drifting westward, just below the western fish and moving toward Aquarius.\nStars.\nAlthough Pisces is a large constellation, there are only two stars brighter than magnitude 4 in Pisces. It is also the second dimmest of the zodiac constellations.\nDue to the dimness of these stars, the constellation is essentially invisible in or near any major city due to light pollution.\nDeep-sky objects.\nM74 is a loosely wound (type Sc) spiral galaxy in Pisces, found at a distance of 30 million light years (redshift 0.0022). It has many clusters of young stars and the associated nebulae, showing extensive regions of star formation. It was discovered by Pierre M\u00e9chain, a French astronomer, in 1780. A type II-P supernova was discovered in the outer regions of M74 by Robert Evans in June 2003; the star that underwent the supernova was later identified as a red supergiant with a mass of 8 solar masses. It is the brightest member of the M74 Group.\nNGC 488 is an isolated face-on prototypical spiral galaxy. Two supernovae have been observed in the galaxy.\nNGC 520 is a pair of colliding galaxies located 105 million light-years away.\nCL0024+17 is a massive galaxy cluster that lenses the galaxy behind it, creating arc-shaped images of the background galaxy. The cluster is primarily made up of yellow elliptical and spiral galaxies, at a distance of 3.6 billion light-years from Earth (redshift 0.4), half as far away as the background galaxy, which is at a distance of 5.7 billion light-years (redshift 1.67).\n3C 31 is an active galaxy and radio source in Pisces 237 million light-years from Earth (redshift 0.0173). Its jets, caused by the supermassive black hole at its center, extend several million light-years in opposing directions, making them some of the largest objects in the universe.\nHistory and mythology.\nPisces originates from some composition of the Babylonian constellations \"\u0160inunutu4\" \"the great swallow\" in current western Pisces, and \"Anunitum\" the \"Lady of the Heaven\", at the place of the northern fish. In the first-millennium BC texts known as the \"Astronomical Diaries\", part of the constellation was also called DU.NU.NU (\"Rikis-nu.mi\", \"the fish cord or ribbon\").\nGreco-Roman period.\nPisces is associated with the Greek legend that Aphrodite and her son Eros either shape-shifted into forms of fishes to escape, or were rescued by two fishes.\nIn the Greek version according to Hyginus, Aphrodite and Eros while visiting Syria fled from the monster Typhon by leaping into the Euphrates River and transforming into fishes (\"Poeticon astronomicon\" 2.30, citing Diognetus Erythraeus). The Roman variant of the story has Venus and Cupid (counterparts for Aphrodite and Eros) carried away from this danger on the backs of two fishes (Ovid \"Fasti\" 2.457ff).\nThere is also a different origin tale that Hyginus preserved in another work. According to this, an egg rolled into the Euphrates, and some fishes nudged this to shore, after which the doves sat on the egg until Aphrodite (thereafter called the Syrian Goddess) hatched out of it. The fishes were then rewarded by being placed in the skies as a constellation (\"Fabulae\" 197). This story is also recorded by the Third Vatican Mythographer.\nModern period.\nIn 1690, the astronomer Johannes Hevelius in his \"Firmamentum Sobiescianum\" regarded the constellation Pisces as being composed of four subdivisions:\n\"Piscis Austrinus\" now refers to a separate constellation in its own right, which Hevelius and Bode called Piscis Notius.\nIn 1754, the botanist and author John Hill proposed to sever a southern zone of Pisces as Testudo (the Turtle). 24 \u2013 27 \u2013 YY(30) \u2013 33 \u2013 29 Psc., It would host a natural but quite faint asterism in which the star 20\u00a0Psc is the head of the turtle. While Admiral Smyth mentioned the proposal, it was largely neglected by other astronomers, and it is now obsolete.\nWestern folklore.\nThe Fishes are in the German lore of Antenteh, who owned just a tub and a crude cabin when he met two magical fish. They offered him a wish, which he refused. However, his wife begged him to return to the fish and ask for a beautifully furnished home. This wish was granted, but her desires were not satisfied. She then asked to be a queen and have a palace, but when she asked to become a goddess, the fish became angry and took the palace and home, leaving the couple with the tub and cabin once again. The tub is sometimes recognized as the Great Square of Pegasus.\nIn non-Western astronomy.\nThe stars of Pisces were incorporated into several constellations in Chinese astronomy. Wai-ping (\"Outer Enclosure\") was a fence that kept a pig farmer from falling into the marshes and kept the pigs where they belonged. It was represented by Alpha, Delta, Epsilon, Zeta, Mu, Nu, and Xi Piscium. The marshes were represented by the four stars designated Phi Ceti. The northern fish of Pisces was a part of the House of the Sandal, Koui-siou.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
