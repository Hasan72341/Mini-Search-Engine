{"id": "22109", "revid": "46010350", "url": "https://en.wikipedia.org/wiki?curid=22109", "title": "Nikolai Bukharin", "text": "Soviet revolutionary and politician (1888\u20131938)\nNikolai Ivanovich Bukharin (; Russian: , ; 9 October\u00a0[O.S. 27 September]\u00a01888 \u2013 15 March 1938) was a Russian revolutionary, Soviet politician, and Marxist theorist. A prominent Bolshevik described by Vladimir Lenin as a \"most valuable and major theorist\" of the Communist Party, Bukharin was active in the Soviet government from 1917 until his purge in 1937.\nBukharin joined the Russian Social Democratic Labour Party in 1906, and studied economics at Moscow Imperial University. In 1910, he was arrested and internally exiled to Onega, but the following year escaped abroad, where he met Lenin and Leon Trotsky and built his reputation with works such as \"Imperialism and World Economy\" (1915). After the February Revolution of 1917, Bukharin returned to Moscow and became a leading figure in the party, and after the October Revolution became editor of its newspaper, \"Pravda\". He led the Left Communist faction in 1918, and during the civil war wrote \"The ABC of Communism\" (1920; with Yevgeni Preobrazhensky) and \"Historical Materialism: A System of Sociology\" (1921), among other works.\nBukharin was initially a proponent of war communism, but in 1921 supported the introduction of the New Economic Policy (NEP) and became its chief theorist and advocate, supporting the party leadership against Trotsky and the Left Opposition. By late 1924, this stance had positioned Bukharin favourably as Joseph Stalin's chief ally, with Bukharin soon elaborating Stalin's theory of \"socialism in one country\". From 1926 to 1929, Bukharin served as General Secretary of the Comintern's executive committee. Following Stalin's decision to proceed with agricultural collectivisation in the Great Break, Bukharin was labelled as the leader of the Right Opposition and was removed from \"Pravda\", the Comintern, and the party leadership in 1929.\nAfter a period in lower positions, in 1934 Bukharin was reelected to the Central Committee and became editor of the newspaper \"Izvestia\". He was a principal architect of the 1936 Soviet Constitution. During the Great Purge, Bukharin was accused of treason in February 1937 and executed after a show trial in 1938.\nBefore 1917.\nNikolai Bukharin was born on 27 September (9 October, new style), 1888, in Moscow. He was the second son of two schoolteachers, Ivan Gavrilovich Bukharin and Liubov Ivanovna Bukharina. According to Nikolai his father did not believe in God and, from the age of four, often asked him to recite poetry for family friends. His childhood is vividly recounted in his mostly autobiographic novel \"How It All Began\".\nBukharin's political life began at the age of sixteen, with his lifelong friend Ilya Ehrenburg, when they participated in student activities at Moscow University related to the Russian Revolution of 1905. He joined the Russian Social Democratic Labour Party in 1906, and became a member of its Bolshevik faction. With Grigori Sokolnikov, Bukharin convened the 1907 national youth conference in Moscow, which was later considered the founding of Komsomol.\nBy age twenty, he was a member of the Moscow Committee of the party. The committee was widely infiltrated by the Tsarist secret police, the Okhrana. As one of its leaders, Bukharin quickly became a person of interest to them. During this time, he became closely associated with Valerian Obolensky and Vladimir Smirnov. He also met his future first wife, Nadezhda Mikhailovna Lukina, his cousin and the sister of Nikolai Lukin, who was also a member of the party. They married in 1911, soon after returning from internal exile.\nIn 1911, after a brief imprisonment, Bukharin was exiled to Onega in Arkhangelsk, but he soon escaped to Hanover. He stayed in Germany for a year before visiting Krak\u00f3w (Poland) in 1912 to meet Vladimir Lenin for the first time. During the exile, he continued his education and wrote several books that established him in his 20s as a major Bolshevik theorist. His work \"\" influenced Lenin, who freely borrowed from it in his larger and better-known work, \"Imperialism, the Highest Stage of Capitalism\". He and Lenin also often had hot disputes on theoretical issues, as well as Bukharin's closeness with the European Left and his anti-statist tendencies. Bukharin developed an interest in the works of Austrian Marxists and heterodox Marxist economic theorists, such as Aleksandr Bogdanov, who did not agree with Lenin. Also, while in Vienna in 1913, he helped the Georgian Bolshevik Joseph Stalin write an article \"Marxism and the National Question\" at Lenin's request.\nIn October 1916, while based in New York City, Bukharin edited the newspaper (\"New World\") with Leon Trotsky and Alexandra Kollontai. When Trotsky arrived in New York in January 1917, Bukharin was the first of the \u00e9migr\u00e9s to greet him. (Trotsky's wife recalled, \"with a bear hug and immediately began to tell them about a public library which stayed open late at night and which he proposed to show us at once\" dragging the tired Trotskys across town \"to admire his great discovery\").\nFrom 1917 to 1923.\nAt the news of the Russian Revolution of February 1917, exiled revolutionaries from around the world began to flock back to the homeland. Trotsky left New York on 27 March 1917, sailing for St. Petersburg. Bukharin left New York in early April and returned to Russia by way of Japan (where he was temporarily detained by local police), arriving in Moscow in early May 1917. Politically, the Bolsheviks in Moscow were a minority in relation to the Mensheviks and the Socialist Revolutionaries. As more people began to be attracted to Lenin's promise to bring peace by withdrawing from the Great War, membership in the Bolshevik faction began to increase dramatically \u2013 from 24,000 members in February 1917 to 200,000 members in October 1917. Upon his return to Moscow, Bukharin resumed his seat on the Moscow City Committee and also became a member of the Moscow Regional Bureau of the party.\nTo complicate matters further, the Bolsheviks themselves were divided into a right wing and a left wing. The right-wing of the Bolsheviks, including Aleksei Rykov and Viktor Nogin, controlled the Moscow Committee, while the younger left-wing Bolsheviks, including Vladimir Smirnov, Valerian Osinsky, Georgii Lomov, Nikolay Yakovlev, Ivan Kizelshtein and Ivan Stukov, were members of the Moscow Regional Bureau. On 10 October 1917, Bukharin was elected to the Central Committee, along with two other Moscow Bolsheviks: Andrei Bubnov and Grigori Sokolnikov. This strong representation on the Central Committee was a direct recognition of the Moscow Bureau's increased importance. Whereas the Bolsheviks had previously been a minority in Moscow behind the Mensheviks and the Socialist Revolutionaries, by September 1917 the Bolsheviks were in the majority in Moscow. Furthermore, the Moscow Regional Bureau was formally responsible for the party organizations in each of the thirteen central provinces around Moscow \u2013 which accounted for 37% of the whole population of Russia and 20% of the Bolshevik membership.\nWhile no one dominated revolutionary politics in Moscow during the October Revolution as Trotsky did in St. Petersburg, Bukharin certainly was the most prominent leader in Moscow. During the October Revolution, Bukharin drafted, introduced, and defended the revolutionary decrees of the Moscow Soviet. Bukharin then represented the Moscow Soviet in their report to the revolutionary government in Petrograd. Following the October Revolution, Bukharin became the editor of the party's newspaper, \"Pravda\".\nBukharin believed passionately in the promise of world revolution. In the Russian turmoil near the end of World War I, when a negotiated peace with the Central Powers was looming, he demanded a continuance of the war, fully expecting to incite all the foreign proletarian classes to arms. Even as he was uncompromising toward Russia's battlefield enemies, he also rejected any fraternization with the capitalist Allied powers: he reportedly wept when he learned of official negotiations for assistance.\nBukharin emerged as the leader of the Left Communists in bitter opposition to Lenin's decision to sign the Treaty of Brest-Litovsk. In this wartime power struggle, Lenin's arrest had been seriously discussed by them and Left Socialist Revolutionaries in 1918. Bukharin revealed this in a Pravda article in 1924 and stated that it had been \"a period when the party stood a hair from a split, and the whole country a hair from ruin\".\nAfter the ratification of the treaty, Bukharin resumed his responsibilities within the party. In March 1919, he became a member of the Comintern's executive committee and a candidate member of the Politburo. During the Civil War period, he published several theoretical economic works, including the popular primer \"The ABC of Communism\" (with Yevgeni Preobrazhensky, 1919), and the more academic \"Economics of the Transitional Period\" (1920) and \"Historical Materialism\" (1921).\nBy 1921, he changed his position and accepted Lenin's emphasis on the survival and strengthening of the Soviet state as the bastion of the future world revolution. He became the foremost supporter of the New Economic Policy (NEP), to which he was to tie his political fortunes. Considered by the Left Communists as a retreat from socialist policies, the NEP reintroduced money and allowed private ownership and capitalistic practices in agriculture, retail trade, and light industry while the state retained control of heavy industry.\nPower struggle.\nAfter Lenin's death in 1924, Bukharin became a full member of the Politburo. In the subsequent power struggle among Leon Trotsky, Grigory Zinoviev, Lev Kamenev and Stalin, Bukharin allied himself with Stalin, who positioned himself as centrist of the Party and supported the NEP against the Left Opposition, which wanted more rapid industrialization, escalation of class struggle against the kulaks (wealthier peasants), and agitation for world revolution. It was Bukharin who formulated the thesis of \"Socialism in One Country\" put forth by Stalin in 1924, which argued that socialism (in Marxist\u2013Leninist theory, the period of transition to communism) could be developed in a single country, even one as underdeveloped as Russia. This new theory stated that socialist gains could be consolidated in a single country, without that country relying on simultaneous successful revolutions across the world. The thesis would become a hallmark of Stalinism.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nHe is an unprincipled intriguer, who subordinates everything to the preservation of his own power. He changes his theory according to whom he needs to get rid of.\nBukharin on Stalin's theoretical position, 1928.\nTrotsky, the prime force behind the Left Opposition, was defeated by a triumvirate formed by Stalin, Zinoviev, and Kamenev, with the support of Bukharin. At the Fourteenth Party Congress in December 1925, Stalin openly attacked Kamenev and Zinoviev, revealing that they had asked for his aid in expelling Trotsky from the Party. By 1926, the Stalin-Bukharin alliance ousted Zinoviev and Kamenev from the Party leadership, and Bukharin enjoyed the highest degree of power during the 1926\u20131928 period. He emerged as the leader of the Party's right wing, which included two other Politburo members (Alexei Rykov, Lenin's successor as Chairman of the Council of People's Commissars and Mikhail Tomsky, head of trade unions) and he became General Secretary of the Comintern's executive committee in 1926. However, prompted by a grain shortage in 1928, Stalin reversed himself and proposed a program of rapid industrialization and forced collectivization because he believed that the NEP was not working fast enough. Stalin felt that in the new situation the policies of his former foes\u2014Trotsky, Zinoviev, and Kamenev\u2014were the right ones.\nBukharin was worried by the prospect of Stalin's plan, which he feared would lead to \"military-feudal exploitation\" of the peasantry. Bukharin did want the Soviet Union to achieve industrialization but he preferred the more moderate approach of offering the peasants the opportunity to become prosperous, which would lead to greater grain production for sale abroad. Bukharin pressed his views throughout 1928 in meetings of the Politburo and at the Communist Party Congress, insisting that enforced grain requisition would be counterproductive, as War Communism had been a decade earlier.\nFall from power.\nBukharin's support for the continuation of the NEP was not popular with higher Party cadres, and his slogan to peasants, \"Enrich yourselves!\" and proposal to achieve socialism \"at snail's pace\" left him vulnerable to attacks first by Zinoviev and later by Stalin. Stalin attacked Bukharin's views, portraying them as capitalist deviations and declaring that the revolution would be at risk without a strong policy that encouraged rapid industrialization.\nHaving helped Stalin achieve unchecked power against the Left Opposition, Bukharin found himself easily outmaneuvered by Stalin. Yet Bukharin played to Stalin's strength by maintaining the appearance of unity within the Party leadership. Meanwhile, Stalin used his control of the Party machine to replace Bukharin's supporters in the Rightist power base in Moscow, trade unions, and the Comintern.\nBukharin attempted to gain support from earlier foes including Kamenev and Zinoviev who had fallen from power and held mid-level positions within the Communist party. The details of his meeting with Kamenev, to whom he confided that Stalin was \"Genghis Khan\" and changed policies to get rid of rivals, were leaked by the Trotskyist press and subjected him to accusations of factionalism. Jules Humbert-Droz, a former ally and friend of Bukharin, wrote that in spring 1929, Bukharin told him that he had made contact with the \u201cZinoviev-Kamenev faction\u201d, and that they were planning to use individual terror (assassination) to get rid of Stalin. Eventually, Bukharin lost his position in the Comintern and the editorship of \"Pravda\" in April 1929, and he was expelled from the Politburo on 17 November of that year.\nBukharin was forced to renounce his views under pressure. He wrote letters to Stalin pleading for forgiveness and rehabilitation, but through wiretaps of Bukharin's private conversations with Stalin's enemies, Stalin knew Bukharin's repentance was insincere.\nInternational supporters of Bukharin, Jay Lovestone of the Communist Party USA among them, were also expelled from the Comintern. They formed an international alliance to promote their views, calling it the \"International Communist Opposition\", though it became better known as the Right Opposition, after a term used by the Trotskyist Left Opposition in the Soviet Union to refer to Bukharin and his supporters there.\nEven after his fall, Bukharin still did some important work for the Party. For example, he helped write the 1936 Soviet constitution, which he believed would guarantee real democratization. There is some evidence that Bukharin was thinking of evolution toward some kind of two-party or at least two-slate elections. Boris Nikolaevsky reported that Bukharin said: \"A second party is necessary. If there is only one electoral list, without opposition, that's equivalent to Nazism.\" Grigory Tokaev, a Soviet defector and admirer of Bukharin, reported that: \"Stalin aimed at one party dictatorship and complete centralisation. Bukharin envisaged several parties and even nationalist parties, and stood for the maximum of decentralisation.\"\nFriendship with Osip Mandelstam and Boris Pasternak.\nIn the brief period of thaw in 1934\u20131936, Bukharin was politically rehabilitated and was made editor of \"Izvestia\" in 1934. There, he consistently highlighted the dangers of fascist regimes in Europe and the need for \"proletarian humanism\". One of his first decisions as editor was to invite Boris Pasternak to contribute to the newspaper and sit in on editorial meetings. Pasternak described Bukharin as \"a wonderful, historically extraordinary man, but fate has not been kind to him\". They first met during the lying-in-state of the Soviet police chief, Vyacheslav Menzhinsky in May 1934, when Pasternak was seeking help for his fellow poet, Osip Mandelstam, who had been arrested \u2013 though at that time neither Pasternak nor Bukharin knew why.\nBukharin had acted as Mandelstam's political protector since 1922. According to Mandelstam's wife, Nadezhda, \"M. owed him all the pleasant things in his life. His 1928 volume of poetry would never have come out without the active intervention of Bukharin. The journey to Armenia, our apartment and ration cards, contracts for future volumes\u00a0\u2013 all this was arranged by Bukharin.\" Bukharin wrote to Stalin, pleading clemency for Mandelstam, and appealed personally to the head of the NKVD, Genrikh Yagoda. It was Yagoda who told him about Mandelstam's Stalin Epigram, after which he refused to have any further contact with Nadezhda Mandelstam, who had lied to him by denying that her husband had written \"anything rash\" \u2013 but continued to befriend Pasternak.\nSoon after Mandelstam's arrest, Bukharin was delegated to prepare the official report on poetry for the First Soviet Writers' Congress, in August 1934. He could not any longer risk mentioning Mandelstam in his speech to the congress, but did devote a large section of his speech to Pasternak, whom he described as \"remote from current affairs\u00a0... a singer of the old intelligensia\u00a0... delicate and subtle\u00a0... a wounded and easily vulnerable soul. He is the embodiment of chaste but self-absorbed laboratory craftsmanship\". His speech was greeted with wild applause, though it greatly offended some of the listeners, such as the communist poet Semyon Kirsanov, who complained: \"according to Bukharin, all the poets who have used their verses to participate in political life are out of date, but the others are not out of date, the so-called pure (and not so pure) lyric poets\".\nWhen Bukharin was arrested two years later, Boris Pasternak displayed extraordinary courage by having a letter delivered to Bukharin's wife saying that he was convinced of his innocence.\nIncreasing tensions with Stalin.\nStalin's collectivization policy proved to be as disastrous as Bukharin predicted, but Stalin had by then achieved unchallenged authority in the party leadership. However, there were signs that moderates among Stalin's supporters sought to end official terror and bring a general change in policy, after mass collectivization was largely completed and the worst was over. Although Bukharin had not challenged Stalin since 1929, his former supporters, including Martemyan Ryutin, drafted and clandestinely circulated an anti-Stalin platform, which called Stalin the \"evil genius of the Russian Revolution\".\nHowever, Sergey Kirov, First Secretary of the Leningrad Regional Committee was assassinated in Leningrad in December 1934, and his death was used by Stalin as a pretext to launch the Great Purge, in which about 700,000 people were to perish as Stalin eliminated all past and potential opposition to his authority. Some historians believe that Kirov's assassination in 1934 was arranged by Stalin himself, despite the lack of evidence to plausibly posit such a conclusion. After Kirov's assassination, the NKVD charged an ever-growing group of former oppositionists with Kirov's murder and other acts of treason, terrorism, sabotage, and espionage.\nGreat Purge.\nIn February 1936, shortly before the purge started in earnest, Bukharin was sent to Paris by Stalin to negotiate the purchase of the Marx and Engels archives, held by the German Social Democratic Party (SPD) before its dissolution by Hitler. He was joined by his young wife Anna Larina, which therefore opened the possibility of exile, but he decided against it, saying that he could not live outside the Soviet Union.\nBukharin, who had been forced to follow the Party line since 1929, confided to his old friends and former opponents his real view of Stalin and his policy. His conversations with Boris Nicolaevsky, a Menshevik leader who held the manuscripts on behalf of the SPD, formed the basis of \"Letter of an Old Bolshevik\", which was very influential in contemporary understanding of the period (especially the Ryutin Affair and the Kirov murder), although there are doubts about its authenticity.\nAccording to Nicolaevsky, Bukharin spoke of \"the mass annihilation of completely defenseless men, with women and children\" under forced collectivization and liquidation of kulaks as a class that dehumanized the Party members with \"the profound psychological change in those communists who took part in the campaign. Instead of going mad, they accepted terror as a normal administrative method and regarded obedience to all orders from above as a supreme virtue.\u00a0... They are no longer human beings. They have truly become the cogs in a terrible machine.\"\nYet to another Menshevik leader, Fyodor Dan, he confided that Stalin became \"the man to whom the Party granted its confidence\" and \"is a sort of a symbol of the Party\" even though he \"is not a man, but a devil\". In Dan's account, Bukharin's acceptance of the Soviet Union's new direction was thus a result of his utter commitment to Party solidarity.\nTo his boyhood friend, Ilya Ehrenburg, he expressed the suspicion that the whole trip was a trap set up by Stalin. Indeed, his contacts with Mensheviks during this trip were to feature prominently in his trial.\nTrial.\nStalin was for a long time undecided on Bukharin and Georgy Pyatakov. After receiving Nikolay Yezhov's written evidence denouncing Bukharin, Stalin declined to sanction his arrest. After the trial and execution of Zinoviev, Kamenev, and other leftist Old Bolsheviks in 1936, Bukharin and Rykov were arrested on 27 February 1937 following a plenum of the Central Committee, and were charged with conspiring to overthrow the Soviet state. Photostatic evidence shows that Stalin's first impulse was to simply exile Bukharin, without sending him to trial. In the end, Bukharin was killed, but according to historian Alec Nove, \"the road to his demise was not a straight one\".\nBukharin was tried in the Trial of the Twenty One on 2\u201313 March 1938 during the Great Purge, along with ex-premier Alexei Rykov, Christian Rakovsky, Nikolai Krestinsky, Genrikh Yagoda, and 16 other defendants alleged to belong to the so-called \"Bloc of Rightists and Trotskyites\". In a trial meant to be the culmination of previous show trials, it was alleged that Bukharin and others sought to assassinate Lenin and Stalin from 1918, murder Maxim Gorky by poison, partition the Soviet Union and hand out her territories to Germany, Japan, and Great Britain.\nEven more than earlier Moscow show trials, Bukharin's trial horrified many previously sympathetic observers as they watched allegations levelled against someone who had been so close to Stalin and Lenin. For some prominent Communists such as Bertram Wolfe, Jay Lovestone, Arthur Koestler, and Heinrich Brandler, the Bukharin trial marked their final break with Communism and even eventually turned the first three into passionate anti-Communists.\nBukharin wrote letters to Stalin while imprisoned, attempting without success to negotiate his innocence in the case of the alleged crimes, his eventual execution, and his hope for release. \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If I'm to receive the death sentence, then I implore you beforehand, I entreat you, by all that you hold dear, not to have me shot. Let me drink poison in my cell instead (let me have morphine so that I can fall asleep and never wake up). For me, this point is extremely important. I don't know what words I should summon up in order to entreat you to grant me this as an act of charity. After all, politically, it won't really matter, and, besides, no one will know a thing about it. But let me spend my last moments as I wish. Have pity on me!\nIn his letter of 10 December 1937, Bukharin suggests becoming Stalin's tool against Trotsky, but there's no evidence Stalin ever seriously considered Bukharin's offer.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If, contrary to expectation, my life is to be spared, I would like to request (though I would first have to discuss it with my wife) the following:\nWhile Anastas Mikoyan and Vyacheslav Molotov later claimed that Bukharin was never tortured and his letters from prison do not give the suggestion that he was tortured, it is also known that his interrogators were given the order: \"beating permitted\". Bukharin held out for three months, but threats to his young wife and infant son, combined with \"methods of physical influence\" wore him down. But when he read his confession amended and corrected personally by Stalin, he withdrew his whole confession. The examination started all over again, with a double team of interrogators.\nBukharin's confession and his motivation became subject of much debate among Western observers, inspiring Koestler's acclaimed novel \"Darkness at Noon\" and a philosophical essay by Maurice Merleau-Ponty in \"Humanism and Terror\". His confessions were somewhat different from others in that while he pleaded guilty to the \"sum total of crimes\", he denied knowledge when it came to specific crimes. Some astute observers noted that he would allow only what was in the written confession and refuse to go any further.\nThere are several interpretations of Bukharin's motivations (besides being coerced) in the trial. Koestler and others viewed it as a true believer's last service to the Party (while preserving the little amount of personal honor left) whereas Bukharin biographer Stephen Cohen and Robert Tucker saw traces of Aesopian language, with which Bukharin sought to turn the tables into an anti-trial of Stalinism (while keeping his part of the bargain to save his family). While his letters to Stalin \u2013 he wrote 34 very emotional and desperate letters tearfully protesting his innocence and professing his loyalty \u2013 suggest a complete capitulation and acceptance of his role in the trial, it contrasts with his actual conduct in the trial. Bukharin himself speaks of his \"peculiar duality of mind\" in his last plea, which led to \"semi-paralysis of the will\" and Hegelian \"unhappy consciousness\", which likely stemmed not only from his knowledge of the ruinous reality of Stalinism (although of course he could not say so in the trial) but also of the impending threat of fascism.\nThe result was a curious mix of fulsome confessions (of being a \"degenerate fascist\" working for the \"restoration of capitalism\") and subtle criticisms of the trial. After disproving several charges against him (one observer noted that he \"proceeded to demolish, or rather showed he could very easily demolish, the whole case\") and saying that \"the confession of the accused is not essential. The confession of the accused is a medieval principle of jurisprudence\" in a trial that was solely based on confessions, he finished his last plea with the words:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...\u00a0the monstrousness of my crime is immeasurable especially in the new stage of struggle of the U.S.S.R. May this trial be the last severe lesson, and may the great might of the U.S.S.R. become clear to all.\nThe state prosecutor, Andrey Vyshinsky, characterized Bukharin as an \"accursed crossbreed of fox and pig\" who supposedly committed a \"whole nightmare of vile crimes\".\nWhile in prison, he wrote at least four book-length manuscripts including a lyrical autobiographical novel, \"How It All Began\", a philosophical treatise, \"Philosophical Arabesques\", a collection of poems, and \"Socialism and Its Culture\" \u2013 all of which were found in Stalin's archive and published in the 1990s.\nExecution.\nAmong other intercessors, the French author and Nobel laureate Romain Rolland wrote to Stalin seeking clemency, arguing that \"an intellect like that of Bukharin is a treasure for his country\". He compared Bukharin's situation to that of the great chemist Antoine Lavoisier who was guillotined during the French Revolution: \"We in France, the most ardent revolutionaries\u00a0... still profoundly grieve and regret what we did.\u00a0... I beg you to show clemency.\" He had earlier written to Stalin in 1937, \"For the sake of Gorky I am asking you for mercy, even if he may be guilty of something\", to which Stalin noted: \"We must not respond.\" Bukharin was executed on 15 March 1938 at the Kommunarka shooting ground, but the announcement of his death was overshadowed by the Nazi Anschluss of Austria.\nAccording to Zhores and Roy Medvedev in \"The Unknown Stalin\" (2006), Bukharin's last message to Stalin stated \"Koba, why do you need me to die?\", which was written in a note to Stalin just before his execution. \"Koba\" was Stalin's \"nom de guerre\", and Bukharin's use of it was a sign of how close the two had once been. The note was allegedly found still in Stalin's desk after his death in 1953.\nDespite the promise to spare his family, Bukharin's wife, Anna Larina, was sent to a labor camp, but she survived to see her husband officially rehabilitated by the Soviet state under Mikhail Gorbachev in 1988. Their son, Yuri Larin (born 1936), was sent to an orphanage in an attempt to keep him safe from the authorities, and also lived to see his rehabilitation. His first wife, Nadezhda, died in a labor camp after being arrested in 1938. His second wife, Esfir' Gurvich, and their daughter Svetlana Gurvich-Bukharina (born 1924), were arrested in 1949, but survived past 1988, though they had lived in fear of the government their whole lives.\nPolitical stature and achievements.\nBukharin was immensely popular within the party throughout the twenties and thirties, even after his fall from power. In his testament, Lenin portrayed him as the Golden Boy of the party, writing:\nSpeaking of the young C.C. members, I wish to say a few words about Bukharin and Pyatakov. They are, in my opinion, the most outstanding figures (among the youngest ones), and the following must be borne in mind about them: Bukharin is not only a most valuable and major theorist of the Party; he is also rightly considered the favourite of the whole Party, but his theoretical views can be classified as fully Marxist only with great reserve, for there is something scholastic about him (he has never made a study of the dialectics, and, I think, never fully understood it)\u00a0... Both of these remarks, of course, are made only for the present, on the assumption that both these outstanding and devoted Party workers fail to find an occasion to enhance their knowledge and amend their one-sidedness.\nBukharin made several notable contributions to Marxist\u2013Leninist thought, most notably \"The Economics of the Transition Period\" (1920) and his prison writings, \"Philosophical Arabesques\", as well as being a founding member of the Soviet Academy of Arts and Sciences, and a keen botanist. His primary contributions to economics were his critique of marginal utility theory, his analysis of imperialism, and his writings on the transition to communism in the Soviet Union.\nBukharin alongside Trotsky have been viewed by some scholars as representing political alternatives to Stalinism. In part, due to their de facto leadership of the Right Opposition and Left Opposition which was at variance with Stalin. These core differences ranged from areas related to economics, foreign policy and cultural matters.\nHis ideas, especially in economics and the question of market socialism, known as Bukharinism, later became highly influential in the Chinese socialist market economy and Deng Xiaoping's economic reforms.\nBritish author Martin Amis argues that Bukharin was perhaps the only major Bolshevik to acknowledge \"moral hesitation\" by questioning, even in passing, the violence and sweeping reforms of the early Soviet Union. Amis writes that Bukharin said \"during the Civil War he had seen 'things that I would not want even my enemies to see'\".\nWorks.\nCartoons.\nBukharin was a cartoonist who left many cartoons of contemporary Soviet politicians. The renowned artist Konstantin Yuon once told him: \"Forget about politics. There is no future in politics for you. Painting is your real calling.\" His cartoons are sometimes used to illustrate the biographies of Soviet officials. Russian historian Yury Zhukov stated that Nikolai Bukharin's portraits of Joseph Stalin were the only ones drawn from the original, not from a photograph.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22110", "revid": "43370107", "url": "https://en.wikipedia.org/wiki?curid=22110", "title": "Nasal consonant", "text": "Consonant pronounced by letting air escape through the nose but not through the mouth\nIn phonetics, a nasal, also called a nasal occlusive or nasal stop in contrast with an oral stop or nasalized consonant, is an occlusive consonant produced with a lowered velum, allowing air to escape freely through the nose. The vast majority of consonants are oral consonants. Examples of nasals in English are , and , in words such as \"nose\", \"bring\" and \"mouth\".\nNasal occlusives are nearly universal in human languages. There are also other kinds of nasal consonants in some languages.\nDefinition.\nNearly all nasal consonants are nasal occlusives, in which air escapes through the nose but not through the mouth, as it is blocked (occluded) by the lips or tongue. The oral cavity still acts as a resonance chamber for the sound. Rarely, non-occlusive consonants may be nasalized.\nMost nasals are voiced, and in fact, the nasal sounds and are among the most common sounds cross-linguistically. Voiceless nasals occur in a few languages such as Burmese, Welsh, Icelandic and Guaran\u00ed. (Compare oral stops, which block off the air completely, and fricatives, which obstruct the air with a narrow channel. Both stops and fricatives are more commonly voiceless than voiced, and are known as obstruents.)\nIn terms of acoustics, nasals are sonorants, which means that they do not significantly restrict the escape of air (as it can freely escape out the nose). However, nasals are also obstruents in their articulation because the flow of air through the mouth is blocked. This duality, a sonorant airflow through the nose along with an obstruction in the mouth, means that nasal occlusives behave both like sonorants and like obstruents. For example, nasals tend to pattern with other sonorants such as and , but in many languages, they may develop from or into stops.\nAcoustically, nasals have bands of energy at around 200 and 2,000\u00a0Hz.\n1. &lt;templatestyles src=\"Citation/styles.css\"/&gt;^ The symbol \u27e8\u27e9 is commonly used to represent the dental nasal as well, rather than \u27e8\u27e9, as it is rarely distinguished from the alveolar nasal.\nExamples of languages containing nasal occlusives:\nThe voiced retroflex nasal is a common sound in Languages of South Asia and Australian Aboriginal languages.\nThe voiced palatal nasal is a common sound in European languages, such as: Spanish \u27e8\u00f1\u27e9, French and Italian \u27e8gn\u27e9, Catalan and Hungarian \u27e8ny\u27e9, Czech and Slovak \u27e8\u0148\u27e9, Polish \u27e8\u0144\u27e9, Occitan and Portuguese \u27e8nh\u27e9, and (before a vowel) Modern Greek \u27e8\u03bd\u03b9\u27e9.\nMany Germanic languages, including German, Dutch, English and Swedish, as well as varieties of Chinese such as Mandarin and Cantonese, have , and . Malayalam has a six-fold distinction between \u27e8\u0d2e, \u0d28, \u0d29, \u0d23, \u0d1e, \u0d19\u27e9; some speakers also have a .\nThe Nuosu language also contrasts six categories of nasals, . They are represented in romanisation by &lt;m, n, hm, hn, ny, ng&gt;. Nuosu also contrasts prenasalised stops and affricates with their voiced, unvoiced, and aspirated versions. \n/\u0271/ is the rarest voiced nasal to be phonemic, as it is mostly an allophone of other nasals before labiodentals. Currently, there is only 1 reported language, Kukuya, which distinguishes and also a set of prenasalized consonants like . Yuanmen used to have it phonemically before merging it with .\nCatalan, Occitan, Spanish, and Italian have as phonemes, and as allophones. It may also be claimed that Catalan has phonemic , at least on the basis of Central Catalan forms such as , although the only minimal pairs involve foreign proper nouns. Also, among many younger speakers of Rioplatense Spanish, the palatal nasal has been lost, replaced by a cluster , as in English \"canyon\".\nIn Brazilian Portuguese and Angolan Portuguese , written \u27e8nh\u27e9, is typically pronounced as , a nasal palatal approximant, a nasal glide (in Polish, this feature is also possible as an allophone). Semivowels in Portuguese often nasalize before and always after nasal vowels, resulting in and . What would be coda nasal occlusives in other West Iberian languages is only slightly pronounced before dental consonants. Outside this environment the nasality is spread over the vowel or become a nasal diphthong (\"mambembe\" , outside the final, only in Brazil, and \"mant\u00e9m\" in all Portuguese dialects).\nThe Japanese syllabary kana , typically romanized as \"n\" and occasionally \"m\", can manifest as one of several different nasal consonants depending on what consonant follows it; this allophone, colloquially written in IPA as , is known as the moraic nasal, per the language's moraic structure.\nWelsh has a set of voiceless nasals, , which occur predominantly as a result of nasal mutation of their voiced counterparts ().\nThe Mapos Buang language of New Guinea has a phonemic uvular nasal, /\u0274/, which contrasts with a velar nasal. It is extremely rare for a language to have /\u0274/ as a phoneme. The distinction also occurs in a few Inuit languages like I\u00f1upiaq. Chamdo languages like Lamo (Kyilwa dialect), Larong sMar (Tangre Chaya dialect), Drag-yab sMar (Razi dialect) have an extreme distinction of , also one of the few languages to have a .\nYanyuwa is highly unusual in that it has a seven-way distinction between (palato-alveolar), (front velar), and (back velar). This may be the only language in existence that contrasts nasals at seven distinct points of articulation.\nY\u00e9l\u00ee Dnye also has an extreme contrast of .\nThe term 'nasal occlusive' (or 'nasal stop') is generally abbreviated to \"nasal\". However, there are also nasalized fricatives, nasalized flaps, nasal glides, and nasal vowels, as in French, Portuguese, and Polish. In the , nasal vowels and nasalized consonants are indicated by placing a tilde (~) over the vowel or consonant in question: French \"sang\" , Portuguese \"bom\" , Polish \"w\u0105\u017c\" .\nVoiceless nasals.\nA few languages have phonemic voiceless nasal occlusives. Among them are Icelandic, Faroese, Burmese, Jalapa Mazatec, Kildin Sami, Welsh, and Central Alaskan Yup'ik. Iaai of New Caledonia has an unusually large number of them, with , along with a number of voiceless approximants.\nOther kinds of nasal consonant.\nLadefoged and Maddieson (1996) distinguish purely nasal consonants, the nasal occlusives such as \"m n ng\" in which the airflow is purely nasal, from partial nasal consonants such as prenasalized consonants and nasal pre-stopped consonants, which are nasal for only part of their duration, as well as from nasalized consonants, which have simultaneous oral and nasal airflow. In some languages, such as Portuguese, a nasal consonant may have occlusive and non-occlusive allophones. In general, therefore, a nasal consonant may be:\nA nasal trill has been described from some dialects of Romanian, and is posited as an intermediate historical step in rhotacism. However, the phonetic variation of the sound is considerable, and it is not clear how frequently it is actually trilled. Some languages contrast like Toro-tegu Dogon (contrasts ) and Inor. A nasal lateral has been reported for some languages, Nzema contrasts , Nemi contrasts . Ganza contrasts .\nLanguages without nasals.\nA few languages, perhaps 2%, contain no phonemically distinctive nasals. This led Ferguson (1963) to assume that all languages have at least one primary nasal occlusive. However, there are exceptions.\nLack of phonemic nasals.\nWhen a language is claimed to lack nasals altogether, as with several Niger\u2013Congo languages or the Pirah\u00e3 language of the Amazon, nasal and non-nasal or prenasalized consonants usually alternate allophonically, and it is a theoretical claim on the part of the individual linguist that the nasal is not the basic form of the consonant. In the case of some Niger\u2013Congo languages, for example, nasals occur before only nasal vowels. Since nasal vowels are phonemic, it simplifies the picture somewhat to assume that nasalization in occlusives is allophonic. There is then a second step in claiming that nasal vowels nasalize oral occlusives, rather than oral vowels denasalizing nasal occlusives, that is, whether are phonemically without full nasals, or without prenasalized stops. Postulating underlying oral or prenasalized stops rather than true nasals helps to explain the apparent instability of nasal correspondences throughout Niger\u2013Congo compared with, for example, Indo-European. Proto-Mande has also been reconstructed with a system in which nasals are allophones of oral stops and approximants.\nThis analysis comes at the expense, in some languages, of postulating either a single nasal consonant that can only be syllabic, or a larger set of nasal vowels than oral vowels, both typologically odd situations. The way such a situation could develop is illustrated by a Jukunoid language, Wukari. Wukari allows oral vowels in syllables like \"ba, mba\" and nasal vowels in \"b\u00e3, m\u00e3\", suggesting that nasals become prenasalized stops before oral vowels. Historically, however, *mb became **mm before nasal vowels, and then reduced to *m, leaving the current asymmetric distribution.\nIn older speakers of the Tlingit language, and are allophones. Tlingit is usually described as having an unusual, perhaps unique lack of despite having five lateral obstruents; the older generation could be argued to have but at the expense of having no nasals.\nLack of phonetic nasals.\nSeveral of languages surrounding Puget Sound, such as Quileute (Chimakuan family), Lushootseed (Salishan family), and Makah (Wakashan family), are truly without any nasalization whatsoever, in consonants or vowels, except in special speech registers such as baby talk or the archaic speech of mythological figures (and perhaps not even that in the case of Quileute). This is an areal feature, only a few hundred years old, where nasals became voiced stops ( became , became , became , became , became , became , became , etc.) after colonial contact. For example, \"Snohomish\" is currently pronounced \"sdohobish\", but was transcribed with nasals in the first English-language records.\nThe only other places in the world where this is known to occur are in Melanesia. In the central dialect of the Rotokas language of Bougainville Island, nasals are only used when imitating foreign accents. (A second dialect has a series of nasals.) The Lakes Plain languages of West Irian are similar.\nThe unconditioned loss of nasals, as in Puget Sound, is unusual. Currently in Korean, and are shifting to and , but only word-initially. This started out in nonstandard dialects and was restricted to the beginning of prosodic units (a common position for fortition), but has expanded to many speakers of the standard language to the beginnings of common words even within prosodic units.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"IPA common/styles.css\" /&gt;&lt;templatestyles src=\"IPA pulmonic consonants/styles.css\" /&gt;&lt;templatestyles src=\"IPA co-articulated consonants/styles.css\" /&gt;&lt;templatestyles src=\"IPA vowels/styles.css\" /&gt;"}
{"id": "22111", "revid": "46866511", "url": "https://en.wikipedia.org/wiki?curid=22111", "title": "Nuvistor", "text": "Late vacuum tube design designed to compete with transistors\nThe nuvistor is a type of vacuum tube announced by RCA in 1959. Nuvistors were made to compete with the then-new bipolar junction transistors, and were much smaller than conventional tubes of the day, almost approaching the compactness of early discrete transistor casings. Due to their small size, there was no space to include a vacuum fitting to evacuate the tube; instead, nuvistors were assembled and processed in a vacuum chamber by simple robotic devices. The tube envelope is made of metal, with a ceramic base. Triodes and a few tetrodes and pentodes were made; nuvistor tetrodes were taller than triodes. \nNuvistors are among the highest-performing small-signal radio-frequency receiving tubes, largely due to low stray capacitance and inductance due to their small size. They have excellent VHF and UHF performance, and low noise figures, and were widely used throughout the 1960s for low-power applications in television sets (beginning with RCA's \"New Vista\" line of color sets in 1961 with the CTC-11 chassis), radio receivers and transmitters, audio equipment, and oscilloscopes. RCA discontinued their use in television tuners in late 1971.\nNuvistor applications included the Ampex MR-70, a studio tape recorder whose entire electronics section was based on nuvistors, and studio-grade microphones from that era, such as the AKG/Norelco C12a, which employed the 7586. It was also later found that, with minor circuit modification, the nuvistor made a sufficient replacement for the obsolete Telefunken VF14M tube, used in the Neumann U47 studio microphone. Tektronix used nuvistors in several of its high end oscilloscopes of the 1960s, before replacing them later with solid-state JFETs. Nuvistors were used in the Ranger space program and Russian-made ones (with soldered pigtail leads, more reliable than sockets) were used in the Soviet MiG-25 fighter jet, presumably to radiation-harden the fighter's electronics; this was discovered following the defection of Viktor Belenko.\nPin layouts.\nNuvistor sockets have a standardized layout based on four imaginary concentric circles with the pins laid out at 60 degree angles from the center point of the base. The metal shell has two fins that extend below the base; the larger of these two fins is the key position. Sockets can accommodate up to 12 pins, but usually only five or six are used.\nPins 1, 2 and 3 are assigned to the outermost circle, with Pin 1 located 60 degrees clockwise of the key fin. Pin 2, which is in line with the small fin, is 120 degrees clockwise of Pin 1. Pin 3 is 120 degrees clockwise of pin 2. For triodes, these pins (usually just Pin 2) are the plate/anode connection. For tetrodes, one of these pins is the screen grid connection and the plate/anode has a top cap connection.\nPins 4, 5 and 6 are assigned to the next circle. Pin 4 is in line with the key fin. Pin 5 is 120 degrees clockwise of Pin 4 and the key fin. Pin 6 is 120 degrees clockwise of Pin 5. The pins in this circle (usually pin 4) connect to the control grid.\nPins 7, 8 and 9 are assigned to the next circle. They are in the same lines as Pins 1, 2 and 3 and also increase in order going clockwise. These pins (usually pin 8) connect to the cathode.\nPins 10, 11 and 12 are assigned to the innermost circle. They are in the same lines as Pins 4, 5 and 6 and also increase in order going clockwise. These pins (usually Pins 10 and 12) connect to the heater.\nBase 12AQ -- which is used by most triodes, including 6CW4 and 6DS4 -- is the most common connection layout. The connections are:\nBase 12AS is the tetrode layout. The connections are:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22113", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=22113", "title": "No Logo", "text": "1999 nonfiction book by Naomi Klein\nNo Logo: Taking Aim at the Brand Bullies is a book by the Canadian author Naomi Klein. First published by Knopf Canada and Picador in December 1999, shortly after the 1999 Seattle WTO protests had generated media attention around such issues, it became one of the most influential books about the alter-globalization movement and an international bestseller.\nFocus.\nThe book focuses on branding and often makes connections with the anti-globalization movement. Throughout the four parts (\"No Space\", \"No Choice\", \"No Jobs\", and \"No Logo\"), Klein writes about issues such as sweatshops in the Americas and Asia, culture jamming, corporate censorship, and Reclaim the Streets. She pays special attention to the deeds and misdeeds of Nike, The Gap, McDonald's, Shell and Microsoft \u2013 and of their lawyers, contractors, and advertising agencies. \nWhile globalization appears frequently as a recurring theme, Klein rarely addresses the topic of globalization itself, and when she does, it is usually indirectly. She goes on to discuss globalization in much greater detail in her book \"Fences and Windows\" (2002).\nSummary.\nThe book comprises four sections. The first three sections deal with the negative effects of brand-oriented corporate activity, while the fourth and final section discusses various movements that arose in opposition to the corporate activities discussed in the rest of the book.\n\"No Space\".\nThe book begins by tracing the history of brands. Klein argues that there has been a shift in the usage of branding and gives examples of this shift to \"anti-brand\" branding. Early examples of brands were often used to put a recognizable face on factory-produced products. These slowly gave way to the idea of selling lifestyles. According to Klein, in response to an economic crash in the late 1980s (due to the Latin American debt crisis, Black Monday (1987), the savings and loan crisis, and the Japanese asset price bubble), corporations began to seriously rethink their approach to marketing and to target the youth demographic, as opposed to the baby boomers, who had previously been considered a much more valuable segment.\nThe book discusses how brand names such as Nike or Pepsi expanded beyond the mere products which bore their names, and how these names and logos began to appear everywhere. As this happened, the brands' obsession with the youth market drove them to further associate themselves with whatever the youth considered \"cool\". Along the way, the brands attempted to associate their names with everything from movie stars and athletes to grassroots social movements.\nKlein argues that large multinational corporations consider the marketing of a brand name to be more important than the actual manufacture of products; this theme recurs in the book, and Klein suggests that it helps explain the shift to production in Third World countries in such industries as clothing, footwear, and computer hardware.\nThis section also looks at ways in which brands have \"muscled\" their presence into the school system, and how in doing so, they have pipelined advertisements into the schools and used their position to gather information about the students. Klein argues that this is part of a trend toward targeting younger and younger consumers.\n\"No Choice\".\nIn the second section, Klein discusses how brands use their size and clout to limit the number of choices available to the public \u2013 whether through market dominance (e.g., Wal-Mart) or through aggressive invasion of a region (e.g., Starbucks). Klein argues that each company's goal is to become the dominant force in its respective field. Meanwhile, other corporations, such as Sony or Disney, simply open their own chains of stores, preventing the competition from even putting their products on the shelves.\nThis section also discusses the way that corporations merge with one another in order to add to their ubiquity and provide greater control over their image. ABC News, for instance, is allegedly under pressure not to air any stories that are overly critical of Disney, its parent company. Other chains, such as Wal-Mart, often threaten to pull various products off their shelves, forcing manufacturers and publishers to comply with their demands. This might mean driving down manufacturing costs or changing the artwork or content of products like magazines or albums so they better fit with Wal-Mart's image of family friendliness.\nAlso discussed is the way that corporations abuse copyright laws in order to silence anyone who might attempt to criticize their brand.\n\"No Jobs\".\nIn this section, the book takes a darker tone and looks at the way in which manufacturing jobs move from local factories to foreign countries, and particularly to places known as export processing zones. Such zones often have no labor laws, leading to dire working conditions.\nThe book then shifts back to North America, where the lack of manufacturing jobs has led to an influx of work in the service sector, where most of the jobs are for minimum wage and offer no benefits. The term \"McJob\" is introduced, defined as a job with poor compensation that does not keep pace with inflation, inflexible or undesirable hours, little chance of advancement, and high levels of stress. Meanwhile, the public is being sold the perception that these jobs are temporary employment for students and recent graduates, and therefore need not offer living wages or benefits.\nAll of this is set against a backdrop of massive profits and wealth being produced within the corporate sector. The result is a new generation of employees who have come to resent the success of the companies they work for. This resentment, along with rising unemployment, labour abuses abroad, disregard for the environment, and the ever-increasing presence of advertising breeds a new disdain for corporations.\n\"No Logo\".\nThe final section of the book discusses various movements that have sprung up during the 1990s. These include \"Adbusters\" magazine and the culture-jamming movement, as well as Reclaim the Streets and the McLibel trial. Less radical protests are also discussed, such as the various movements aimed at putting an end to sweatshop labour.\nKlein concludes by contrasting consumerism and citizenship, opting for the latter. \"When I started this book,\" she writes, \"I honestly didn't know whether I was covering marginal atomized scenes of resistance or the birth of a potentially broad-based movement. But as time went on, what I clearly saw was a movement forming before my eyes.\"\nResponses.\nAfter the book's release, Klein was heavily criticized by the newspaper \"The Economist\", leading to a broadcast debate with Klein and the magazine's writers, dubbed \"No Logo vs. Pro Logo\".\nThe 2004 book \"The Rebel Sell\" (published as \"Nation of Rebels\" in the United States) specifically criticized \"No Logo\", stating that turning the improving quality of life in the working class into a fundamentally anti-market ideology is shallow.\nNike published a point-by-point response to the book, refuting each of the statements Klein had made about the company's labor practices.\nAwards.\nIn 2000, \"No Logo\" was short-listed for the \"Guardian\" First Book Award in 2000.\nIn 2001, the book won the following awards:\nEditions.\nSeveral imprints of \"No Logo\" exist, including a hardcover first edition, a subsequent hardcover edition, and a paperback. A 10th anniversary edition was published by Fourth Estate that includes a new introduction by the author. Translations from the original English into several other languages have also been published. The subtitle, \"Taking Aim at the Brand Bullies\", was dropped in some later editions.\nVideo.\nNaomi Klein explains her ideas in the 40-minute video \"No Logo \u2013 Brands, Globalization &amp; Resistance\" (2003), directed by Sut Jhally.\nLegacy.\nMembers of the English rock group Radiohead recommended the book to fans on their website and was rumored to have considered calling the album \"Kid A\" \"No Logo\" for a time. Argentine artist Indio Solari wrote a song for his first solo album named \"Nike es la cultura\" (\"Nike is the culture\"), in which he says, \"You shout No Logo! Or you don't shout No Logo! Or you shout No Logo No!\" in reference to this book.\nArgentine-American rock singer Kevin Johansen wrote a song, \"Logo\", inspired by Klein's book. A copy of \"No Logo\" is even used in the official video for the song.\nDave Longstreth of american indie-pop band Dirty Projectors names the book and its author in their 2016 song \"Keep Your Name\" \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22115", "revid": "1869658", "url": "https://en.wikipedia.org/wiki?curid=22115", "title": "National War College", "text": "School in the National Defense University\nIn the United States, the National War College (NWC) is a school within the National Defense University. It is housed in Roosevelt Hall on Fort Lesley J. McNair, Washington, D.C., the third-oldest Army post still active.\nHistory.\nThe National War College (NWC) was officially established on July 1, 1946, as an upgraded replacement for the Army-Navy Staff College, which operated from June 1943 to July 1946. The college was one of James Forrestal's favorite causes.\nAccording to Lt. Gen. Leonard T. Gerow, President of the Board that recommended its formation:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The College is concerned with grand strategy and the utilization of the national resources necessary to implement that strategy. ... Its graduates will exercise a great influence on the formulation of national and foreign policy in both peace and war. ...\nMid-level and senior military officers who are likely to be promoted to the senior ranks are selected to study at the War College to prepare for higher staff and command positions. About 75 percent of the student body is composed of equal representation from the land, air, and sea (including Marine and Coast Guard) services. The remaining 25 percent are drawn from the Department of State and other federal departments and agencies. In addition, international fellows from several countries join the student body. The curriculum is based upon critical analysis of strategic problem solving with an emphasis on strategic leadership. As of the 2014\u20132015 academic year, the curriculum was based upon a core standard throughout National Defense University.\nBecause of the NWC's privileged location close to the White House, the Supreme Court, and Capitol Hill, it has been able throughout its history to call upon an extraordinarily well-connected array of speakers to animate its discussions. All lectures at the National War College are conducted under a strict \"no quotation nor attribution\" policy, which has facilitated discussion on some of the most challenging issues of the day.\nCommandants.\nSource for commandants up to 2010.\nAlumni and influence.\nAmerican graduates of the National War College include a secretary of state and a secretary of defense, national security advisors, a senator and congressman, and a White House chief of staff, in addition to chairmen of the joint chiefs of staff and numerous other current and former flag officers, general officers, and U.S. ambassadors. No other graduate institution of national security policy in the world has had more impact in the development of the United States senior cadre of national security leaders. Graduates from other countries include prime ministers from nations as diverse as Iran and Bulgaria, as well as many national military leaders from every continent on earth except Antarctica. Notable graduates include:\n--A--\n--B--\n--C--\n--D--\n--F--\n--G--\n--H--\n--J--\n--K--\n--L--\n--M--\n--N--\n--O--\n--P--\n--R--\n--S--\n--W--\n--Y--\n--Z--\nRoosevelt Hall.\nRoosevelt Hall (built 1903\u20131907) is a Beaux Arts\u2013style building housing the NWC since its inception in 1946. Designed by the New York architectural firm McKim, Mead &amp; White, it is now designated a National Historic Landmark. It is listed on the National Register of Historic Places.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22117", "revid": "34259990", "url": "https://en.wikipedia.org/wiki?curid=22117", "title": "Neelin", "text": "Rural Community\nNeelin is a small community in the Canadian province of Manitoba. It is located on Manitoba Provincial Highway 5 in the Rural Municipality of Argyle, about 29\u00a0km east of Killarney, or about 200\u00a0km southwest of Winnipeg.\nThe Roseberry school district was established in 1885, leading to the construction of a one-room schoolhouse in 1904. The school served as a K\u201312 school until 1960, when high school students began to bus to either Baldur, Killarney or Cartwright. Roseberry, now known as Neelin school, continued until 1968, when it was closed. The building has since been demolished.\nNeelin was also home to a Manitoba Pool elevator. The elevator stood on the CPR railroad tracks until its closure in 1978.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22118", "revid": "48948231", "url": "https://en.wikipedia.org/wiki?curid=22118", "title": "Norn language", "text": "Extinct Germanic language spoken in the Northern Isles of Scotland\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nNorn is an extinct North Germanic language that was spoken in the Northern Isles (Orkney and Shetland) off the north coast of mainland Scotland and in Caithness in the far north of the Scottish mainland. After Orkney and Shetland were pledged to Scotland by Norway in 1468\u201369, it was gradually replaced by Scots. Norn is thought to have become extinct around 1850, after the death of Walter Sutherland, the language's last known speaker, though there are claims the language persisted as late as 1932.\nHistory.\nNorse settlement in the islands probably began in the early 9th century. These settlers are believed to have arrived in very substantial numbers, and like those who migrated to Iceland and the Faroe Islands, it is probable that most came from the west coast of Norway. Shetland toponymy bears some resemblance to that of northwest Norway, while Norn vocabulary implies links with more southerly Norwegian regions.\nOrkney and Shetland were pledged to James III in 1468 and 1469 respectively, and it is with these pledges that the replacement of Norn with Scots is most associated. However, the decline of Norse speech in Orkney probably began in 1379 when the Earldom of Orkney, covering all of the Northern Isles, passed into the hands of Henry Sinclair, of Clan Sinclair. Scots had superseded Norse as the language of prestige on Orkney by the early 15th century.\nIn Shetland, the transition began later, but by the end of the 15th century both island groups were bilingual. Despite this, the process by which Scots overtook Norn as the primary spoken language on the islands was not a swift one, and most natives of Orkney and Shetland probably spoke Norn as a first language until the late 16th and early-to-mid 17th centuries respectively. One of the last documents written in Norn was for a 1597 mortgage issued over a property belonging to Else, sister of Anna Throndsen, who had married a Shetland man Andrew Mowat of Heogoland in Eshaness.\nExtinction.\nIt is not known exactly when Norn became extinct. Sources from the 17th and 18th centuries speak of Norn (sometimes identified as \"Norse\", \"Norwegian\" or \"Danish\") as being in a state of decline and generally indicate that the language remained stronger in Shetland than in Orkney. A source from 1670 states that there are \"only three or four parishes\" in Orkney where people speak \"Noords or rude Danish\" and that they do so \"chiefly when they are at their own houses\". Another from 1701 indicates that there were still a few monoglot \"Norse\" speakers who were capable of speaking \"no other thing\", and notes that there were more speakers of the language in Shetland than in Orkney. It was said in 1703 that the people of Shetland generally spoke a Lowland Scots dialect brought to Shetland from the end of the fifteenth century by settlers from Fife and Lothian, but that \"many among them retain the ancient Danish Language\"; while in 1750 Orkney-born James Mackenzie wrote that Norn was not yet entirely extinct, being \"retained by old people\", who still spoke it among each other.\nThe last reports of Norn speakers are claimed to be from the 19th century, with some claims of a very limited use up until the early 20th century, but it is more likely that the language was dying out in the late 18th century. The isolated islands of Foula and Unst are variously claimed as the last refuges of the language in Shetland, where there were people \"who could repeat sentences in Norn\", probably passages from folk songs or poems, as late as 1894. Walter Sutherland from Skaw in Unst, who died about 1850, has been cited as the last native speaker of the Norn language.\nHowever, fragments of vocabulary survived the death of the main language and remain to this day, mainly in place-names and terms referring to nature, mood, and fishing. For example, 'vae'/'voe' (an inlet or small bay) are found in some English dictionaries and are legal words in Scrabble.\nNorn had also been a spoken language in Caithness but had probably become extinct there by the 15th century, replaced by Scots. Hence, some scholars also speak about \"Caithness Norn\", but others avoid this. Even less is known about \"Caithness Norn\" than about Orkney and Shetland Norn. Almost no written Norn has survived, but what little remains includes a version of the Lord's Prayer and a ballad, \"Hildina\". Michael P Barnes, professor of Scandinavian Studies at University College London, has published a study, \"The Norn Language of Orkney and Shetland\".\nSongs in Norn survived in the oral tradition long enough to be recorded. In the 1940s and 1950s, John Stickle of Unst and Kitty Anderson of Lerwick were recorded singing versions of the 'Unst Boat Song' in Norn and the ballad of Orfeo with a Norn refrain.\nModern use.\nMost of the use of Norn/Norse in modern-day Shetland and Orkney is purely ceremonial, and mostly in Old Norse, for example the Shetland motto, \"\" 'with law shall land be built', which is the same motto used by the Icelandic police force and inspired by the medieval Norwegian Frostathing Law.\nAnother example of the use of Norse/Norn in the Northern Isles can be found in the names of ferries:\nNorn words are still used to describe many of the colour and pattern variations in the native sheep of Shetland and Orkney, which survive as the Shetland and North Ronaldsay breeds. Icelandic uses similar words for many of the same colour variations in Icelandic sheep.\nThere are some enthusiasts who are engaged in developing and disseminating a modern form called Nynorn (\"New Norn\"), based upon linguistic analysis of the known records and Norse linguistics in general.\nIn 2022 at the Glasgow Royal Concert Hall, as part of the Shetland 550 concert celebrating the 550th anniversary of Shetland becoming Scottish, singer Inge Thompson sang a rendition of a song in Norn.\nIn 2023 the singer Siobhan Wilson released a song featuring the Norn language.\nClassification.\nNorn is an Indo-European language belonging to the North Germanic branch of the Germanic languages. Together with Faroese, Icelandic and Norwegian, it belongs to the West Scandinavian group, separating it from the East Scandinavian and Gutnish groups consisting of Swedish, Danish and Gutnish.\nWhile this classification is based on the differences between the North Germanic languages at the time they split, their present-day characteristics justify another classification, dividing them into Insular Scandinavian and Mainland Scandinavian language groups based on mutual intelligibility. Under this system, Norwegian is grouped together with Danish and Swedish because the last millennium has seen all three undergo important changes, especially in grammar and lexis, which have set them apart from Faroese and Icelandic.\nNorn is generally considered to have been fairly similar to Faroese, sharing many phonological and grammatical traits, and might even have been mutually intelligible with it. Thus, it can be considered an Insular Scandinavian language.\nFew written texts remain. It is distinct from the present-day Shetland dialect, which evolved from Middle English.\nPhonology.\nThe phonology of Norn can never be determined with much precision because of the lack of source material, but the general aspects can be extrapolated from the few written sources that exist. Norn shared many traits with the dialects of southwest Norway. That includes a voicing of to after vowels and (in the Shetland dialect but only partially in the Orkney dialect) a conversion of and (\"thing\" and \"that\" respectively) to and respectively.\nMorphology.\nNorn grammar had features very similar to the other Scandinavian languages. There were two numbers, three genders and four cases (nominative, accusative, genitive and dative). The two main conjugations of verbs in present and past tense were also present. Like all other North Germanic languages (except West and South Jutlandic), it used a suffix instead of a prepositioned article to indicate definiteness as in modern Scandinavian: ' (\"man\"); ' (\"the man\"). Though it is difficult to be certain of many of the aspects of Norn grammar, documents indicate that it may have featured subjectless clauses, which were common in the West Scandinavian languages.\nSample text.\nThe following are Norn, Old Norse and contemporary Scandinavian versions of the Lord's Prayer:\n\"\n\"\n\"\n\"\n\"\n\"\n\"\n\"\n\"\n\"\n\"\n\"\n\"\n\"\n\"\n\"\n\"\n\"\n\"\n\" \n\"\n\"\n\"\" \nA Shetland \"guddick\" (riddle) in Norn, which Jakob Jakobsen heard told on Unst, the northernmost island in Shetland, in the 1890s. The same riddle is also known from the Faroe Islands, Norway, and Iceland, and a variation also occurs in England.\nThe answer is a cow: four teats hang, four legs walk, two horns and two ears stand skyward, two eyes show the way to the field and one tail comes shaking (dangling) behind.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22120", "revid": "42383571", "url": "https://en.wikipedia.org/wiki?curid=22120", "title": "Nuoro", "text": "Nuoro ( ; ) is a city and municipality in central-eastern Sardinia in Italy, situated on the slopes of Mount Ortobene. It is the capital and largest city of the province of Nuoro. As of 2025, with a population of 33,106, it is the sixth-largest city in Sardinia. Its (borough) of Lollove is one of (\"The most beautiful villages of Italy\").\nBirthplace of several renowned artists, including writers, poets, painters, sculptors, Nuoro hosts some of the most important museums in Sardinia. It is considered an important cultural center of the region and it has been referred to as the \"Sardinian Athens\". Nuoro is the hometown of Grazia Deledda, the only Italian woman to win (1926) the Nobel Prize in Literature.\nHistory.\nThe earliest traces of human settlement in the Nuoro area (called \" the Nuorese\") are the so-called Domus de janas, rock-cut tombs dated at the third millennium BC. However, fragments of ceramics of the Ozieri culture have also been discovered and dated at c. 3500 BC.\nThe Nuorese was a centre of the Nuragic civilization (which developed in Sardinia from c. 1500 BC to c. 250 BC), as attested by more than 30 Nuragic sites, such has the village discovered in the countryside of Tanca Manna, just outside Nuoro, which was made of about 800 huts.\nThe Nuorese was crossed by a Roman road which connected Karalis (Cagliari) to Ulbia (Olbia). The legacy of the Roman colonization can especially be found in the variety of the Sardinian language which is still spoken today in Nuoro: Nuorese Sardinian is considered the most conservative dialect of Sardinian, which is in turn the most conservative Romance language.\nAfter the fall of the Western Roman Empire, Sardinia was held first by the Vandals and then by the Byzantines. According to the letters of Pope Gregory I, a Romanized and Christianized culture (that of the \"provinciales\") co-existed with several Pagan cultures (those of the \"Gens Barbaricina\", i.e. \"Barbarian People\") mainly located in the island's interior. As the Byzantine control waned, the Judicates appeared. A small village known as Nugor appears on a medieval map from 1147. In the two following centuries it grew to more than 1000 inhabitants. Nuoro remained a town of average importance under the Aragonese and Spanish domination of Sardinia, until famine and plague struck it in the late 17th century.\nAfter the annexation to the Kingdom of Sardinia, the town became the administrative center of the area, obtaining the title of city in 1836.\nDemographics.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nAs of 2025, Nuoro has a population of 33,106, of whom 48.1% are male and 51.9% are female. Minors make up 11.9% of the population, and seniors make up 28.5%, compared to the Italian average of 14.9% and 24.7% respectively.\nAs of 2024, the foreign-born population is 1,111, equal to 3.3% of the population. The 5 largest foreign nationalities are Romanians (310), Senegalese (233), Chinese (102), Pakistanis (80) and Moroccans (72).\nCulture.\nISRE.\nSince 1972 in Nuoro is active the Istituto superiore regionale etnografico (ISRE), which is an institution that promotes the \"study and documentation of the social and cultural life of Sardinia in its traditional manifestations and its transformations\". In fact, in addition to managing museums and libraries, it organizes national and international events, including:\nthe Sardinia International Ethnographic Film Festival (SIEFF) and the Festival Biennale Italiano dell\u2019Etnografia (ETNU) (Italian Biennial Festival of Ethnography).\nLanguage.\nAlong with Italian, the traditional language spoken in Nuoro is Sardinian, in its Logudorese-Nuorese variety.\nFood.\nNuoro is home to the world's rarest pasta, \"su filindeu\". The name in Sardinian language means \"the threads (or wool) of God\" and is made exclusively by the women of a single family in the town, with the recipe being passed down through generations.\nTransport.\nRoad.\nNuoro is served by the SS 131 DCN (Olbia-Abbasanta), the SS 129 (Orosei-Macomer), and the SS 389 (Monti-Lanusei).\nBus.\nARST, Azienda Regionale Sarda Trasporti provide regular connections to Cagliari, Sassari, Olbia, and to several minor centres in the province and the region.\nOther private operators (including Deplano Autolinee, Turmotravel, Redentours) connects Nuoro to various cities and airports in the island.\nRail.\nNuoro is connected by train to Macomer via Ferrovie della Sardegna.\nLocal transportation.\nATP Nuoro's bus system provides service within the city.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22121", "revid": "23527582", "url": "https://en.wikipedia.org/wiki?curid=22121", "title": "Nugoro", "text": ""}
{"id": "22122", "revid": "41295437", "url": "https://en.wikipedia.org/wiki?curid=22122", "title": "N\u00fcrburgring", "text": "Race track in N\u00fcrburg, Rhineland-Palatinate, Germany\nThe () is a 150,000-person capacity motorsports complex located in the town of N\u00fcrburg, Rhineland-Palatinate, Germany. It features a Grand Prix race track built in 1984, and a long configuration, built in the 1920s, around the village and medieval castle of N\u00fcrburg in the Eifel mountains. The north loop is long and contains more than of elevation change from its lowest to highest points. Scottish racing driver Jackie Stewart nicknamed the track \"the Green Hell\".\nOriginally, the track featured four configurations, namely the , which in turn consisted of the then- , and the . There was also a warm-up loop called , or , around the pit area. Between 1982 and 1983, the start\u2013finish area was demolished to create a new , which is now used for all major and international racing events. However, the shortened is still in use for racing, testing and public access.\nPrior to World War II, the N\u00fcrburgring hosted 13 editions of the German Grand Prix from 1927 to 1939. In Formula One (F1), it has hosted 42 Grands Prix, including the German, European, Luxembourg, and\u00a0\u2013 most recently\u00a0\u2013 2020 Eifel Grand Prix; Michael Schumacher achieved the most victories at the N\u00fcrburgring, winning on five occasions between 1995 and 2006. The 1976 German Grand Prix, held on the , was the last F1 race ever contested on a circuit of . As of 2025[ [update]], the venue hosts several national GT events, including the Deutsche Tourenwagen Masters.\nHistory.\n1925\u20131939: The beginning of the \"N\u00fcrburg-Ring\".\nIn 1904, the Gordon Bennett Trophy was held on the twice-run Taunus circuit, a circuit made up of public roads starting between the towns of Wehrheim, Limburg and Saalburg, just north of Frankfurt that was long. In 1907, the Taunus circuit was re-routed and shortened to , and it was used one more time for the first Eifelrennen race, which was won by Italian racer Felice Nazzaro. In the early 1920s, ADAC Eifelrennen races were held on the twisty Nideggen public road circuit near Cologne and Bonn. Around 1925, the construction of a dedicated race track was proposed just south of the Nideggen circuit around the ancient castle of the town of N\u00fcrburg, following the examples of Italy's Monza and Targa Florio courses, and Berlin's AVUS, yet with a different character. The layout of the circuit in the mountains was similar to the Targa Florio event, one of the most important motor races at that time. The original N\u00fcrburgring was to be a showcase for German automotive engineering and racing talent. Construction of the track, designed by the \"Eichler Architekturb\u00fcro\" from Ravensburg (led by architect Gustav Eichler), began in September 1925.\nThe track was completed in the spring of 1927, and the ADAC Eifelrennen races were continued there. The first races to take place on 18 June 1927 showed motorcycles and sidecars, and were won by Toni Ulmen on an English 350cc Velocette. The cars followed a day later, and Rudolf Caracciola was the winner of the over\u20135000cc class in a supercharged Mercedes-Benz \"K\". In addition, the track was opened to the public in the evenings and on weekends, as a one-way toll road. The entire track consisted of 174 bends (prior to 1971 changes), and averaged in width. The fastest time ever around the full \"Gesamtstrecke\" was by Louis Chiron, at an average speed of in his Bugatti.\nIn 1929 the full N\u00fcrburgring was used for the last time in major racing events, as future Grands Prix would be held only on the \"Nordschleife\". Motorcycles and minor races primarily used the shorter and safer \"S\u00fcdschleife\". Memorable pre-war races at the circuit featured the talents of early \"Ringmeister\" (Ringmasters) such as Rudolf Caracciola, Tazio Nuvolari, and Bernd Rosemeyer.\n1947\u20131970: \"The Green Hell\".\nAfter World War II, racing resumed in 1947, and in 1951, the \"Nordschleife\" of the N\u00fcrburgring again became the main venue for the German Grand Prix as part of the Formula One World Championship (with the exception of 1959, when it was held on the AVUS in Berlin). A new group of \"Ringmeister\" arose to dominate the race \u2013 Alberto Ascari, Juan Manuel Fangio, Stirling Moss, Jim Clark, John Surtees, Jackie Stewart and Jacky Ickx.\nOn 5 August 1961, during practice for the 1961 German Grand Prix, Phil Hill became the first person to complete a lap of the \"Nordschleife\" in under 9 minutes, with a lap of 8 minutes 55.2 seconds (153.4 km/h or 95.3 mph) in the Ferrari 156 \"Sharknose\" Formula One car. Over half a century later, even the highest performing road cars still have difficulty breaking 8 minutes without a professional race driver or one very familiar with the track. Also, several rounds of the German motorcycle Grand Prix were held, mostly on the \"S\u00fcdschleife\", but the Hockenheimring and the Solitudering were the main sites for Grand Prix motorcycle racing.\nIn 1953, the ADAC 1000 km N\u00fcrburgring race was introduced, an Endurance race and Sports car racing event that counted towards the World Sportscar Championship for decades. The 24 Hours N\u00fcrburgring for touring car racing was added in 1970.\nBy the late 1960s, the \"Nordschleife\" and many other tracks were becoming increasingly dangerous for the latest generation of F1 cars. In 1967, a chicane was added before the start/finish straight, called \"Hohenrain\", in order to reduce speeds at the pit lane entry. This made the track longer. Even this change, however, was not enough to keep Stewart from nicknaming it \"The Green Hell\" () following his victory in the 1968 German Grand Prix amid a driving rainstorm and thick fog. In 1970, after the fatal crash of Piers Courage at Zandvoort, the F1 drivers decided at the French Grand Prix to boycott the N\u00fcrburgring unless major changes were made, as they had done at Spa the year before. The changes were not possible on short notice, and the German GP was moved to the Hockenheimring, which had already been modified.\n1971\u20131983: Changes.\nIn accordance with the demands of the F1 drivers, the \"Nordschleife\" was reconstructed by taking out some bumps, smoothing out some sudden jumps (particularly at Br\u00fcnnchen), and installing Armco safety barriers. The track was made straighter, following the race line, which reduced the number of corners. The German GP could be hosted at the N\u00fcrburgring again, and was for another six years from 1971 to 1976.\nIn 1973 the entrance into the dangerous and bumpy Kallenhard corner was made slower by adding another left-hand corner after the fast Metzgesfeld sweeping corner. Safety was improved again later on by removing the jumps on the long main straight and widening it. They also took away the bushes right next to the track at the main straight, which had made that section of the N\u00fcrburgring dangerously narrow. A second series of three more F1 races was held until 1976. However, primarily due to its length of over , and the lack of space due to its situation on the sides of the mountains, increasing demands by the F1 drivers and the FIA's CSI commission were too expensive or impossible to meet. For instance, by the 1970s the German Grand Prix required five times the marshals and medical staff as a typical F1 race, something the German organizers were unwilling to provide. Additionally, even with the 1971 modifications it was still possible for cars to become airborne off the track. The N\u00fcrburgring was also unsuitable for the burgeoning television market; its vast expanse made it almost impossible to effectively cover a race there. As a result, early in the season it was decided that the 1976 race would be the last to be held on the old circuit.\nNiki Lauda, the reigning world champion and only person ever to lap the full \"Nordschleife\" in under seven minutes (6:58.6, 1975), proposed to the other drivers that they boycott the circuit in 1976. Lauda was not only concerned about the safety arrangements and the lack of marshals around the circuit, he also did not like the prospect of running the race in another rainstorm. Usually when that happened, some parts of the circuit were wet and other parts were dry, which is what the conditions of the circuit were for that race. The other drivers voted against the idea and the race went ahead. Lauda crashed in his Ferrari coming out of the left-hand kink before Bergwerk after a new magnesium component (lighter but more fragile than aluminum used until then) on his Ferrari's rear suspension failed. He was badly burned as his car was still loaded with fuel in lap 2. Lauda was saved by the combined actions of fellow drivers Arturo Merzario, Guy Edwards, Brett Lunger, Emerson Fittipaldi and Harald Ertl.\nThe crash also showed that the track's distances were too long for regular fire engines and ambulances, even though the \"ONS-Staffel\" was equipped with a Porsche 911 rescue car, marked (R). The old N\u00fcrburgring never hosted another F1 race again, as the German Grand Prix was moved to the Hockenheimring for 1977. The German motorcycle Grand Prix was held for the last time on the old N\u00fcrburgring in 1980, also permanently moving to Hockenheim.\nBy its very nature, the \"Nordschleife\" was impossible to make safe in its old configuration. It soon became apparent that it would have to be completely overhauled if there was any prospect of Formula One returning there - the N\u00fcrburgring's administration and race organizers were not willing to provide the enormous expense of providing the number of marshals needed for a Grand Prix - up to six times the amount that most other circuits needed. With this in mind, in 1981 work began on a new circuit, which was built on and around the old pit area.\nAt the same time, a bypass shortened the \"Nordschleife\" to , and with an additional small pit lane, this version was used for races in 1983, e.g. the 1000km N\u00fcrburgring endurance race, while construction work was going on nearby. During qualifying for that race, Stefan Bellof set a lap of 6:11.13 for the \"Nordschleife\" in his Porsche 956, or on average. This lap held the all-time record for 35 years (partially because no major racing has taken place there since 1984) until it was surpassed by Timo Bernhard in the Porsche 919 Hybrid Evo, which ran the slightly longer version of the circuit in 5:19.546- averaging on 29 June 2018.\nMeanwhile, more run-off areas were added at corners like Aremberg and Br\u00fcnnchen, where originally there were just embankments protected by Armco barriers. The track surface was made safer in some spots where there had been bumps and jumps. Racing line markers were added to the corners all around the track as well. Also, bushes and hedges at the edges of corners were replaced with Armco and grass.\nThe former \"S\u00fcdschleife\" had not been modified in 1970\u20131971 and was abandoned a few years later in favour of the improved \"Nordschleife\". It is now mostly gone (in part due to the construction of the new circuit) or converted to a normal public road, but since 2005 a vintage car event has been hosted on the old track layout, including part of the parking area.\n1984: New Grand Prix track.\nThe new track was completed in 1984 and named \"GP-Strecke\" (: literally, \"Grand Prix Course\"). It was built to meet the highest safety standards. However, it was considered in character a mere shadow of its older sibling. Some fans, who had to sit much farther away from the track, called it \"Eifelring\", \"Ersatzring\", \"Gr\u00fcnering\" or similar nicknames, believing it did not deserve to be called N\u00fcrburgring. Like many circuits of the time, it offered few overtaking opportunities.\nPrior to the 2013 German Grand Prix both Mark Webber and Lewis Hamilton said they liked the track. Webber described the layout as \"an old school track\" before adding, \"It's a beautiful little circuit for us to still drive on so I think all the guys enjoy driving here.\" While Hamilton said \"It's a fantastic circuit, one of the classics and it hasn't lost that feel of an old classic circuit.\"\nTo celebrate its opening, an exhibition race was held on 12 May. The 1984 N\u00fcrburgring Race of Champions featured an array of notable drivers driving identical Mercedes 190E 2.3\u201316's: the line-up was Elio de Angelis, Jack Brabham (Formula 1 World Champion 1959, 1960, 1966), Phil Hill (1961), Denis Hulme (1967), James Hunt (1976), Alan Jones (1980), Jacques Laffite, Niki Lauda (1975, 1977)*, Stirling Moss, Alain Prost*, Carlos Reutemann, Keke Rosberg (1982), Jody Scheckter (1979), Ayrton Senna*, John Surtees (1964) and John Watson. [Drivers marked with * won the Formula 1 World Championship subsequent to the race]. Senna won ahead of Lauda, Reutemann, Rosberg, Watson, Hulme and Jody Scheckter, being the only one to resist Lauda's performance who \u2013 having missed the qualifying \u2013 had to start from the last row and overtook all the others except Senna. There were nine former and two future Formula 1 World Champions competing, in a field of 20 cars with 17 Formula 1 drivers including then 56 year old Hans Herrmann plus three drivers known for racing Porsche: Klaus Ludwig, Manfred Schurti and Udo Sch\u00fctz.\nBesides other major international events, the N\u00fcrburgring has seen the brief return of Formula One racing, as the 1984 European Grand Prix was held at the track, followed by the 1985 German Grand Prix. As F1 did not stay, other events are now the highlights at the new N\u00fcrburgring, including the 1000km N\u00fcrburgring, DTM, motorcycles, and newer types of events, like truck racing, vintage car racing at the AvD \"Oldtimer Grand Prix\", and even the \"Rock am Ring\" concerts.\nFollowing the success and first world championship of Michael Schumacher, a second German F1 race was held at the N\u00fcrburgring between 1995 and 2006, called the European Grand Prix, or in 1997 and 1998, the Luxembourg Grand Prix.\nFor 2002, the track was changed, by replacing the former \"Castrol-chicane\" at the end of the start/finish straight with a sharp right-hander (nicknamed \"Haug-Hook\"), in order to create an overtaking opportunity. Also, a slow Omega-shaped section was inserted, on the site of the former kart track. This extended the GP track from , while at the same time, the Hockenheimring was shortened from .\nBoth the N\u00fcrburgring and the Hockenheimring events lost money due to high and rising Formula One licence fees charged by Bernie Ecclestone and low attendance due to high ticket prices; starting with the 2007 Formula One season, Hockenheim and N\u00fcrburgring alternated in hosting the German GP.\nIn Formula One, Ralf Schumacher collided with his teammate Giancarlo Fisichella and his brother at the start of the 1997 race which was won by Jacques Villeneuve. In 1999, in changing conditions, Johnny Herbert managed to score the only win for the team of former \"Ringmeister\" Jackie Stewart. One of the highlights of the 2005 season was Kimi R\u00e4ikk\u00f6nen's spectacular exit while in the last lap of the race, when his suspension gave way after being rattled lap after lap by a flat-spotted tyre that was not changed due to the short-lived 'one set of tyres' rule.\nPrior to the 2007 European Grand Prix, the \"Audi S\" (turns 8 and 9) was renamed \"Michael Schumacher S\" after Michael Schumacher. Schumacher had retired from Formula One the year before, but returned in 2010, and in 2011 became the second Formula One driver to drive through a turn named after them (after Ayrton Senna driving his \"S for Senna\" at Aut\u00f3dromo Jos\u00e9 Carlos Pace).\nAlternation with Hockenheim.\nIn 2007, the FIA announced that Hockenheimring and N\u00fcrburgring would alternate with the German Grand Prix with N\u00fcrburgring hosting in 2007. Due to name-licensing problems, it was held as the European Grand Prix that year. In 2014, the new owners of the N\u00fcrburgring were unable to secure a deal to continue hosting the German Grand Prix in the odd-numbered years, so the 2015 and 2017 German Grands Prix were cancelled.\nReturn of Formula One.\nIn July 2020, it was announced that after seven years, the race track would be an official Formula One Grand Prix with the event taking place from 9 to 11 October 2020. This race was called the Eifel Grand Prix in honour of the nearby mountain range, meaning the venue held a Grand Prix under a fourth different name having hosted races under the German, European and Luxembourg Grands Prix titles previously. That race was won by Lewis Hamilton, who equalled Michael Schumacher's record of wins.\nFatal accidents.\nWhile it is unusual for deaths to occur during sanctioned races, there are many accidents and several deaths each year during public sessions. It is common for the track to be closed several times a day for cleanup, repair, and medical intervention. While track management does not publish any official figures, several regular visitors to the track have used police reports to estimate the number of fatalities as between 3 and 12 in a full year. Jeremy Clarkson noted in \"Top Gear\" in 2004 that \"over the years this track has claimed over 200 lives\".\nRacing.\n\"Nordschleife\" racing today.\nSeveral touring car series still compete on the \"Nordschleife\", using either only the simple version with its separate small pit lane, or a combined track that uses a part of the original modern F1 track (without the Mercedes Arena section, which is often used for support pits) plus its huge pit facilities. Entry-level competition requires a regularity test (GLP) for street-legal cars. Two racing series (RCN/CHC and VLN) compete on 15 Saturdays each year, for several hours.\nThe annual highlight is the 24 Hours N\u00fcrburgring weekend, held usually in mid-May, featuring 220 cars \u2013 from small cars to Turbo Porsche cars or factory race cars built by BMW, Opel, Audi, and Mercedes-Benz, over 700 drivers (amateurs and professionals), and up to 290,000 spectators.\nAs of 2015 the World Touring Car Championship holds the FIA WTCC Race of Germany at the Nordschleife as a support category to the 24 Hours.\nBMW Sauber's Nick Heidfeld made history on 28 April 2007 as the first driver in over thirty years to tackle the N\u00fcrburgring \"Nordschleife\" track in a contemporary Formula One car. Heidfeld's three laps in an F1.06 were part of festivities celebrating BMW's contribution to motorsport. About 45,000 spectators showed up for the main event, the third four-hour VLN race of the season. Conceived largely as a photo opportunity, the lap times were not as fast as the car was capable of, BMW instead needing to run the chassis at a particularly high ride height to allow for the \"Nordschleife\"'s abrupt gradient changes and to limit maximum speeds accordingly. Former F1 driver Hans-Joachim Stuck was injured during the race when he crashed his BMW Z4.\nAs part of the festivities before the 2013 24 Hours N\u00fcrburgring race, Michael Schumacher and other Mercedes-Benz drivers took part in a promotional event which saw Schumacher complete a demonstration lap of the Nordschleife at the wheel of a 2011 Mercedes W02. As with Heidfeld's lap, and also partly due to Formula One's strict in-season testing bans, the lap left many motorsport fans underwhelmed.\nPublic access.\n\"Nordschleife\".\nSince its opening in 1927, the track has been used by the public for the so-called \"Touristenfahrten\": anyone with a road-legal car or motorcycle, as well as tour buses, motor homes, or cars with trailers, are able to access the Nordschleife. It is open every day from mid-March through mid-November, except when racing takes place. The track is not open to the public during the winter, when construction work is ongoing or in the event of bad weather. Passing on the right is prohibited, and some sections have speed limits; the normal traffic rules (StVO in German) apply also here.\nThe N\u00fcrburgring is a popular attraction for many driving enthusiasts and riders from all over the world, partly because of its history and the challenge it provides. The lack of oncoming traffic and intersections sets it apart from regular roads, and the absence of a blanket speed limit is a further attraction.\nNormal ticket buyers on tourist days cannot quite complete a full lap of the \"Nordschleife\", which bypasses the modern \"GP-Strecke\", as they are required to slow down and pass through a \"pit lane\" section where toll gates are installed. On busier days, a mobile ticket barrier is installed on the main straight in order to reduce the length of queues at the fixed barriers. This is open to all ticket holders. On rare occasions, it is possible to drive both the \"Nordschleife\" and the Grand Prix circuit combined.\nDrivers interested in lap times often time themselves from the first bridge after the barriers to the last gantry (aka Bridge-to-Gantry or BTG time) before the exit. However, the track's general conditions state that any form of racing, including speed record attempts, is forbidden. The driver's insurance coverage may consequently be voided, leaving the driver fully liable for damage. Normal, non-racing, non-timed driving accidents might be covered by driver's insurance, but it is increasingly common for insurers to insert exclusion clauses that mean drivers and riders on the N\u00fcrburgring only have third-party coverage or are not covered at all.\nDrivers who have crashed into the barriers, suffered mechanical failure or been otherwise required to be towed off track during \"Touristenfahrten\" sessions are referred to as having joined the \"Bongard Club\". This nickname is derived from the name of the company which operates the large yellow recovery flatbed trucks which ferry those unfortunate drivers and their vehicles to the nearest exit. Due to the high volume of traffic, there is an emphasis on quickly clearing and repairing any compromised safety measures so the track can be immediately re-opened for use.\nAdditionally, those found responsible for damage to the track or safety barriers are required to pay for repairs, along with the time and cost associated with personnel, equipment and track closure to address those damages, making any accident or breakdown a potentially expensive incident. Because it is technically operated as a public toll road, failing to report an accident or instance where track surfaces are affected is considered to be an instance of unlawfully leaving the scene of an accident. This is all part of the rules and regulations which aim to ensure a safe experience for all visitors to the track.\nOn 20 February 2025, the administration of the circuit decided to forbid motorcycles during public Touristenfahrten tourist laps starting from the opening of the 2025 season.\nThe entire N\u00fcrburgring was open to the public from its initial opening. At several points around the circuit there were access roads and toll points from which drivers and riders could begin or end a drive. The had one of these at the bottom of the uphill stretch near .\nCommercial aspects.\nProduction car testing.\nFor decades, automotive media outlets and manufacturers have used lap times on the Nordschleife as a standard to measure the performance of production vehicles. A car's time on the circuit is commonly used as a benchmark for its overall performance, and cars from disparate marques or time periods may be directly compared via their lap times. Since 2019, two times have been recorded: one for the whole length of the track, and another for a traditional, slightly truncated layout. Nordschleife test cars are piloted by experienced test drivers with intricate knowledge of the circuit, and are often variants specially prepared for circuit racing, as is the case with the Lexus LFA's \"N\u00fcrburgring package\".\nFor sixteen weeks per year, the \"industry pool\" () rents exclusive daytime use of the track for automotive development and endurance testing. As of 2017[ [update]] the industry pool consisted of approximately 30 car manufacturers, associations, and component suppliers. By 2019, the track was being rented by the industry pool for 18 weeks per year.\nSome journalists have opined that Nordschleife testing is deleterious to a car's normal driving experience, producing cars that have sacrificed comfort and driveability in favor of better lap times. Former \"Top Gear\" host James May, who is known for his open dislike of testing run on the track, has claimed that the N\u00fcrburgring prompts designers to focus on a car's grip at the expense of pleasant-feeling handling, and creates cars that are ill-suited for real-world driving conditions. Others have expressed concern over the relevance of these test laps, which lack independent verification and may be conducted using cars significantly different from stock. Porsche is reported as having tried\u2014and failed\u2014to replicate the Nissan GT-R Nismo's record-breaking lap, preparing its own GT-R test car for the task, and the Lamborghini Hurac\u00e1n Performante's time was met with incredulity even after Lamborghini provided video documentation.\nTelevision and games.\nThe TV series \"Top Gear\" sometimes used the \"Nordschleife\" for its challenges, often involving Sabine Schmitz. The first corner of the \"Nordschleife\" loop was renamed as the \"Sabine-Schmitz-Kurve\" in Schmitz's honor after she died of cancer in 2021. In addition, during series 17 (summer 2011) of \"Top Gear\", James May was very critical of the ride quality of cars whose development processes included testing on the \"Nordschleife\", saying that cars which were tested at Nordschleife got ruined.\nMultiple layouts of the N\u00fcrburgring have been featured in video games, such as the \"Gran Turismo\" series, the \"Forza Motorsport\" series, the , \"Project CARS 2\", \"iRacing\" and \"Assetto Corsa\". \"Grand Prix Legends\", a historic racing simulator also included the N\u00fcrburgring on its roster of default Grand Prix tracks.\nLeisure development.\nOther pastimes are hosted at the N\u00fcrburgring, such as the Rock am Ring, Germany's biggest rock music festival, attracting close to 100,000 rock fans each year since 1985. Since 1978, the \"Nordschleife\" is also the venue of a major running event (\"N\u00fcrburgring-Lauf/Run am Ring\"). In 2003, a major bicycling event (\"Rad am Ring\") was added and it became the multi-sports event \"Rad &amp; Run am Ring\".\nIn 2009, new commercial areas opened, including a hotel and shopping mall. In the summer of 2009, ETF Ride Systems opened a new interactive dark ride application called \"Motor Mania\" at the racetrack, in collaboration with Lagotronics B.V. The roller coaster \"ring\u00b0racer\" was scheduled to open in 2011, but was delayed significantly due to technical issues. It eventually opened on 31 October 2013 and was closed after just four days of operation on 3 November 2013.\nOwnership.\nIn 2012, the track was preparing to file for bankruptcy as a result of nearly $500 million in debts and the inability to secure financing. On 1 August 2012, the government of Rheinland-Pfalz guaranteed $312 million to allow the track to meet its debt obligations.\nIn 2013, the N\u00fcrburgring was for sale for US$165 million (\u20ac127.3 million). The sale process was by sealed-bid auction with an expected completion date of \"Late Summer\". This meant there was to be a new owner in 2013, unencumbered by the debts of the previous operation, with the circuit expected to return to profitability.\nOn 11 March 2014, it was reported that the N\u00fcrburgring was sold for 77 million euros ($106.8 million). D\u00fcsseldorf-based Capricorn Development was the buyer. The company was to take full ownership of the N\u00fcrburgring on 1 January 2015. But in October 2014, Russian billionaire, the chairman of Moscow-based Pharmstandard, Viktor Kharitonin, bought a majority stake in the N\u00fcrburgring.\nIn May 2015, the N\u00fcrburgring was set to hold the first Gr\u00fcne H\u00f6lle Rock festival as a replacement for the Rock am Ring festival, but the project did not take place. Gr\u00fcne H\u00f6lle Rock changed their name to Rock im Revier and the event was held in the Schalke area.\nLayout.\n\"Nordschleife\" layout.\nThe \"Nordschleife\" operates in a clockwise direction, and was formerly known for its abundance of sharp crests, causing fast-moving, firmly-sprung racing cars to jump clear off the track surface at many locations.\n\"Flugplatz\" (\"air field\", a small airport).\nAlthough by no means the most fearsome, \"Flugplatz\" is perhaps the most aptly (although coincidentally) named and widely remembered section. The name of this part of the track comes from a small airfield, which in the early years was located close to the track in this area. The track features a very short straight that climbs sharply uphill for a short time, then suddenly drops slightly downhill, and this is immediately followed by two very fast right-hand kinks. Chris Irwin's career was ended following a massive accident at \"Flugplatz\", in a Ford 3L GT sports car in 1968. Manfred Winkelhock flipped his March Formula Two car at the same corner in 1980. This section of the track was renovated in 2016 after an accident in which Jann Mardenborough's Nissan GT-R flew over the fence and killed a spectator. The \"Flugplatz\" is one of the most important parts of the N\u00fcrburgring because after the two very fast right-handers comes what is possibly the fastest part of the track: a downhill straight called \"Kottenborn\", into a very fast curve called \"Schwedenkreuz\" (Swedish Cross). Drivers are flat out (full-speed) for some time here.\nRight before \"Flugplatz\" is \"Quiddelbacher-H\u00f6he\" (peak, as in \"mountain summit\"), where the track crosses a bridge over the Bundesstra\u00dfe 257.\n\"Fuchsr\u00f6hre\" (\"Fox Hole\").\nThe \"Fuchsr\u00f6hre\" is soon after the very fast downhill section succeeding the \"Flugplatz\". After negotiating a long right-hand corner called \"Aremberg\" (which is after \"Schwedenkreuz\") the road goes under a bridge \"Postbrucke\" as it plunges downhill, and the road switches back left and right and finding a point of reference for the racing line is difficult. This whole sequence is flat out and then, the road climbs sharply uphill. The road then turns left and levels out at the same time; this is one of the many jumps of the N\u00fcrburgring where the car goes airborne. This leads to the \"Adenauer Forst\" (forest) turns. The \"Fuchsr\u00f6hre\" is one of the fastest and most dangerous parts of the N\u00fcrburgring because of the extremely high speeds in such a tight and confined place; this part of the N\u00fcrburgring goes right through a forest and there is only about of grass separating the track from Armco barrier, and beyond the barriers is a wall of trees.\n\"Bergwerk\" (\"Mine\").\nPerhaps the most notorious corner on the long circuit, \"Bergwerk\" has been responsible for some serious and sometimes fatal accidents. A tight right-hand corner, coming just after a long, fast section and a left-hand kink on a small crest, was where Carel Godin de Beaufort fatally crashed. The fast kink was also the scene of Niki Lauda's infamous fiery accident during the 1976 German Grand Prix. This left kink is often referred to as the \"Lauda-Links\" (Lauda left). The \"Bergwerk\", along with the \"Breidscheid\"/\"Adenauer\" Bridge corners before it, are one of the series of corners that make or break one's lap time around the N\u00fcrburgring because of the fast, lengthy uphill section called \"Kesselchen\" (Little Valley) that comes after the \"Bergwerk\".\nCaracciola \"Karussell\" (\"Carousel\").\nAlthough being one of the slower corners on the \"Nordschleife\", the \"Karussell\" is perhaps its most famous and one of its most iconic- it is one of two berm-style, banked corners on the track. Soon after the driver has negotiated the long uphill section after \"Bergwerk\" and gone through a section called \"Klostertal\" (Monastery Valley), the driver turns right through a long hairpin, past an abandoned section called \"Steilstrecke\" (Steep Route) and then goes up another hill towards the \"Karrusell\". The entrance to the corner is blind, although Juan Manuel Fangio is reputed to have advised a young driver to \"aim for the tallest tree,\" a feature that was also built into the rendering of the circuit in the \"Gran Turismo 4\" and \"Grand Prix Legends\" video games. Once the driver has reached the top of the hill, the road then becomes sharply banked on one side and level on the other- this banking drops off, rather than climbing up like most bankings on circuits. The sharply banked side has a concrete surface, and there is a foot-wide tarmac surface on the bottom of the banking for cars to get extra grip through the very rough concrete banking. Cars drop into the concrete banking, and keep the car in the corner (which is 210 degrees, much like a hairpin bend) until the road levels out and the concrete surface becomes tarmac again. This corner is very hard on the driver's wrists and hands because of the prolonged bumpy cornering the driver must do while in the \"Karrusell\". Usually, cars come out of the top of the end of the banking to hit the apex that comes right after the end of the \"Karrusell\".\nThe combination of a recognisable corner, slow-moving cars, and the variation in viewing angle as cars rotate around the banking, means that this is one of the circuit's most popular locations for photographers. It is named after German pre-WWII racing driver Rudolf Caracciola, who reportedly made the corner his own by hooking the inside tires into a drainage ditch to help his car \"hug\" the curve. As more concrete was uncovered and more competitors copied him, the trend took hold. At a later reconstruction, the corner was remade with real concrete banking, as it remains to this day.\nShortly after the \"Karussell\" is a steep section, with gradients in excess of 16%, leading to a right-hander called \"Hohe Acht\", which is some higher in altitude than \"Breidscheid\".\n\"Br\u00fcnnchen\" (\"Small Well\").\nA favourite spectator vantage point, the \"Br\u00fcnnchen\" section is composed of two right-hand corners and a very short straight. The first corner goes sharply downhill and the next, after the very short downhill straight, goes uphill slightly. This is a section of the track where on public days, accidents happen particularly at the blind uphill right-hand corner. Like almost every corner at the N\u00fcrburgring, both right-handers are blind. The short straight used to have a steep and sudden drop-off that caused cars to take off and a bridge that went over a pathway; these were taken out and smoothed over when the circuit was rebuilt in 1970 and 1971. The uphill right-hand corner is often referred to as \"Youtube corner\", because of the large number of videos featuring a perspective of that corner.\n\"Pflanzgarten\" (\"Planting Garden\") and \"Stefan Bellof S\" (\"Stefan Bellof Esses\").\nThe \"Pflanzgarten\", which is soon after the \"Br\u00fcnnchen\", is one of the fastest, trickiest and most difficult sections of the N\u00fcrburgring. It is full of jumps, including two huge ones, one of which is called \"Sprungh\u00fcgel\" (Jump Hill). This very complex section is unique in that it is made up of two different sections; getting the entire \"Pflanzgarten\" right is crucial to a good lap time around the N\u00fcrburgring. This section was the scene of Briton Peter Collins's fatal accident during the 1958 German Grand Prix, and the scene of a number of career-ending accidents in Formula One in the 1970s\u00a0\u2014Britons Mike Hailwood and Ian Ashley were two victims of the Pflanzgarten.\n\"Pflanzgarten 1\" is made up of a slightly banked, downhill left-hander which then suddenly switches back left, then right. Then immediately, giving the driver nearly no time to react (knowledge of this section is key) the road drops away twice: the first jump is only slight, then right after (somewhat like a staircase) the road drops away very sharply which usually causes almost all cars to go airborne at this jump; the drop is so sudden. Then, immediately after the road levels out very shortly after the jump and the car touches the ground again, the road immediately and suddenly goes right very quickly and then right again; this is what makes up the end of the first \"Pflanzgarten\"- a very fast multiple apex sequence of right-hand corners.\nThe road then goes slightly uphill and then through another jump; the road suddenly drops away and levels out and at the same time, the road turns through a flat-out left-hander. Then, the road drops away again very suddenly, which is the second huge jump of the \"Pflanzgarten\" known as the \"Sprungh\u00fcgel\". The road then goes downhill then quickly levels out, then it goes through a flat-out right-hander and this starts the \"Stefan Bellof S\" (named as such because Bellof crashed a Porsche 956 there during the 1983 Nurburgring 1000\u00a0km), which was known as \"Pflanzgarten 2\" prior to 2013. The \"Stefan Bellof S\" is very tricky because the road quickly switches back left and right\u2014a car is going so fast through here that it is like walking on a tightrope. It is very difficult to find the racing line here because the curves come up so quickly, so it is hard to find any point of reference. Then, after a jump at the end of the switchback section, it goes through a flat-out, top gear right-hander and into a short straight that leads into two very fast curves called the \"Schwalbenschwanz\" (Swallow's Tail).\nThe room for error on every part of the consistently high-speed \"Pflanzgarten\" and the \"Stefan Bellof S\" is virtually non-existent (much like the entire track itself). The road and the surface of the \"Pflanzgarten\" and the \"Stefan Bellof S\" moves around unpredictably; knowledge of this section is key to getting through cleanly.\n\"Schwalbenschwanz/Kleines Karussell\" (\"Swallow's Tail\"/\"Little Carousel\").\nThe \"Schwalbenschwanz\" is a sequence of very fast sweepers located after the \"Stefan Bellof S\". After a short straight, there is a very fast right-hand sweeper that progressively goes uphill, and this leads into a blind left-hander that is a bit slower. The apex is completely blind, and the corner then changes gradient a bit; it goes up then down, which leads into a short straight that ends at the \"Kleines Karussell\". Originally, this part had a bridge that went over a stream and was very bumpy; this bridge was taken out and replaced with a culvert (large industrial pipe) so that the road could be smoothed over.\nThe \"Kleines Karussell\" is similar to its bigger brother, except that it is a 90-degree corner instead of 210 degrees, and is faster and slightly less banked. Once this part of the track is dealt with, the drivers are near the end of the lap; with two more corners \"Galgenkopf\" to negotiate before the long \"D\u00f6ttinger H\u00f6he\" straight.\n\"S\u00fcdschleife\" layout.\nThe N\u00fcrburgring \"S\u00fcdschleife\" (south loop) was a motor racing circuit which was built in 1927 at the same time as the \"Nordschleife\".\nThe \"S\u00fcdschleife\" and \"Nordschleife\" layouts were joined together by the \"Start und Ziel\" (start/finish) area, and could therefore be driven as one track that was over long. Races were held at the combined layout only until 1931. The \"S\u00fcdschleife\" was used for the ADAC Eifelrennen from 1928 until 1931 and from 1958 until 1968, as well as for the Eifelpokal and other minor races.\nThe \"S\u00fcdschleife\" was rarely used after the \"Nordschleife\" was rebuilt and updated in 1970 and 1971, and was finally destroyed by the building of the current N\u00fcrburgring Grand Prix circuit in the early 1980s. Today only small sections of the original track remain.\nTrack description.\nThe shared start/finish area of the N\u00fcrburgring complex consisted of two back-to-back straights joined together at the southern end by a tight loop. The entrance to the \"S\u00fcdschleife\" lay on the outside edge of this hairpin and was signposted as the road to Bonn. It immediately dropped sharply downhill and under a public road before winding through a heavily-wooded section.\nTight corners soon gave way to fast downhill sections with flowing bends until, at the outskirts of the nearby town of M\u00fcllenbach, the track turned sharply right northwards and began a long climb up the hill.\nAt the end of this run came a right hairpin turn which led to a long left curve around the bottom of a hill. This led onto the back straight of the start/finish area. At this point it was possible to continue onto the \"Nordschleife\" or take two sharp right-hand turns in order to enter the starting straight once again.\nPhotographs of the track in use show that trees and hedges were not cut back in many areas, being allowed to grow right up to the trackside. Although the \"Nordschleife\" had very little in the way of run-off areas, the \"S\u00fcdschleife\" seems to have had none at all, which was likely to have been a factor in the choice of circuit for major events.\nSections of routes.\nThe route sections bore the following names, among others \"Br\u00e4nkekopf\", \"Aschenschlag\", \"Seifgen\", \"Bocksberg\", \"M\u00fcllenbach\" und \"Scharfer Kopf\".\nStichstra\u00dfe shortcut.\nIn 1938 a small section of new track (the \"Stichstra\u00dfe\") was laid which allowed drivers nearing the end of the \"S\u00fcdschleife\" to bypass the start/finish straights and take a right turn which led back to the start of the downhill twists. This shortened a lap to around . This layout was used for tourist rides and for testing.\nRemaining sections.\nThe current Grand Prix circuit required the complete destruction of the start/finish area but at a point around into the \"S\u00fcdschleife\", a modern public road now follows the route, although the bends have been eased and the vegetation does not come as close to the road as it did when the track was open.\nThis public road continues into the town of M\u00fcllenbach but leaves the route of the old track on the outskirts. Nothing remains of the famous corners there.\nThe road up the hill still exists and is sometimes used to allow access to parking areas for the Grand Prix track. The lower sections are no longer maintained.\nSurviving sections, and the parking lots, are still used in competition. The Cologne-Ahrweiler Rally often uses the S\u00fcdschleife in competition.\nLap records.\nN\u00fcrburgring Nordschleife.\nAs of May 2023, the fastest official race lap records at the N\u00fcrburgring Nordschleife are listed as:\nN\u00fcrburgring S\u00fcdschleife.\nThe fastest official race lap records on the S\u00fcdschleife are listed as:\nModern N\u00fcrburgring.\nAs of September 2025, the fastest official lap records at the modern N\u00fcrburgring circuit layouts are listed as:\nLap times recorded on the N\u00fcrburgring \"Nordschleife\" are published by several manufacturers. They are published and discussed in print media, and online.\nThe lap record on the S\u00fcdschleife is held by Helmut Kelleners with 2:38.6 minutes = , driven with a March 707 in the CanAm run of the 3rd International AvD SCM circuit race on 18 October 1970. Previous record holder was Brian Redman, who achieved 2:47.0 minutes = in the Formula 2 race on 21 April 1968 with a Ferrari.\nClimate.\nThe N\u00fcrburgring is known for its frequently changing weather. The near-fatal accident of Niki Lauda in 1976 was accompanied by poor weather conditions and also the 2007 Grand Prix race saw an early deluge take several cars out through aquaplaning, with Vitantonio Liuzzi making a lucky escape, hitting a retrieving truck with the rear wing first, rather than the fatal accident that befell Jules Bianchi seven years later at Suzuka. In spite of this reputation, the N\u00fcrburg weather station only recorded an average of between 1981 and 2010. Contrasting this, the relatively nearby Ardennes racetrack of Spa-Francorchamps in Wallonia, Belgium has a much rainier climate, as can be implied by data from the village hosting the track called Stavelot and the village of Malmedy, through which the circuit passes.\nN\u00fcrburg has a semi-continental climate with both oceanic and continental tendencies. It does however land in the former category (K\u00f6ppen \"Cfb\"). Due to the Nordschleife's varied terrain and elevation, weather may be completely different on either end of the track. The elevation shift also makes thermal differences a strong possibility. The modern Grand Prix circuit also has sizeable elevation changes between the start-finish straight and the lowest point on the opposite end of the track, but the geographical distance and actual elevation gain between the two are lower. Annual sunshine is in the 1500s, which is low by European standards, but only slightly gloomier than the nearest large city of Cologne located on a plain. Contrasting that, N\u00fcrburg has cooler weather year-round due to the higher elevation of the Eifel Mountains than the Rhine Valley.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "22123", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=22123", "title": "Nuclear weapons", "text": ""}
{"id": "22124", "revid": "11952314", "url": "https://en.wikipedia.org/wiki?curid=22124", "title": "Nuclear Proliferation Treaty", "text": ""}
{"id": "22126", "revid": "50584560", "url": "https://en.wikipedia.org/wiki?curid=22126", "title": "Northern Hemisphere", "text": "Half of Earth that is north of the Equator\nThe Northern Hemisphere is the half of Earth that is north of the equator. For other planets in the Solar System, north is defined as being in the same celestial hemisphere relative to the invariable plane of the Solar System as Earth's North Pole.\nDue to Earth's axial tilt of 23.439281\u00b0, there is a seasonal variation in the lengths of the day and night. There is also a seasonal variation in temperatures, which lags the variation in day and night. Conventionally, winter in the Northern Hemisphere is taken as the period from the December solstice (typically December 21 UTC) to the March equinox (typically March 20 UTC), while summer is taken as the period from the June solstice through to the September equinox (typically on 23 September UTC). The dates vary each year due to the difference between the calendar year and the astronomical year. Within the Northern Hemisphere, oceanic currents can change the weather patterns that affect many factors within the north coast. Such events include El Ni\u00f1o\u2013Southern Oscillation.\nTrade winds blow from east to west just above the equator. The winds pull surface water with them, creating currents, which flow westward due to the Coriolis effect. The currents then bend to the right, heading north. At about 30 degrees north latitude, a different set of winds, the westerlies, push the currents back to the east, producing a closed clockwise loop.\nIts surface is 60.7% water, compared with 80.9% water in the case of the Southern Hemisphere, and it contains 67.3% of Earth's land. The continents of North America and mainland Eurasia are located entirely in the Northern Hemisphere, together with about two-thirds of Africa and a small part of South America.\nGeography and climate.\nDuring the 2.5 million years of the Pleistocene, numerous cold phases called glacials (Quaternary ice age), or significant advances of continental ice sheets, in Europe and North America, occurred at intervals of approximately 40,000 to 100,000 years. The long glacial periods were separated by more temperate and shorter interglacials which lasted about 10,000\u201315,000 years. The last cold episode of the last glacial period ended about 10,000 years ago. Earth is currently in an interglacial period of the Quaternary, called the Holocene. The glaciations that occurred during the glacial period covered many areas of the Northern Hemisphere.\nThe Arctic is a region around the North Pole (90\u00b0 latitude). Its climate is characterized by cold winters and cool summers. Precipitation mostly comes in the form of snow. Areas inside the Arctic Circle (66\u00b034\u2032 latitude) experience some days in summer when the Sun never sets, and some days during the winter when it never rises. The duration of these phases varies from one day for locations right on the Arctic Circle to several months near the Pole, which is the middle of the Northern Hemisphere. Between the Arctic Circle and the Tropic of Cancer (23\u00b026\u2032 latitude) lies the Northern temperate zone. The changes in these regions between summer and winter are generally mild, rather than extreme hot or cold. However, a temperate climate can have very unpredictable weather.\nTropical regions (between the Tropic of Cancer and the Equator, 0\u00b0 latitude) are generally hot all year round and tend to experience a rainy season during the summer months, and a dry season during the winter months.\nIn the Northern Hemisphere, objects moving across or above the surface of the Earth tend to turn to the right because of the Coriolis effect. As a result, large-scale horizontal flows of air or water tend to form clockwise-turning gyres. These are best seen in ocean circulation patterns in the North Atlantic and North Pacific oceans. Within the Northern Hemisphere, oceanic currents can change the weather patterns that affect many factors within the north coast. For the same reason, flows of air down toward the northern surface of the Earth tend to spread across the surface in a clockwise pattern. Thus, clockwise air circulation is characteristic of high pressure weather cells in the Northern Hemisphere. Conversely, air rising from the northern surface of the Earth (creating a region of low pressure) tends to draw air toward it in a counterclockwise pattern. Hurricanes and tropical storms (massive low-pressure systems) spin counterclockwise in the Northern Hemisphere.\nThe shadow of a sundial moves clockwise on latitudes north of the subsolar point and anticlockwise to the south. During the day at these latitudes, the Sun tends to rise to its maximum at a southerly position. Between the Tropic of Cancer and the Equator, the Sun can be seen to the north, directly overhead, or to the south at noon, depending on the time of year. In the Southern Hemisphere, the midday Sun is predominantly in the north.\nWhen viewed from the Northern Hemisphere, the Moon appears inverted compared to a view from the Southern Hemisphere. The North Pole faces away from the Galactic Center of the Milky Way. This results in the Milky Way being sparser and dimmer in the Northern Hemisphere compared to the Southern Hemisphere, making the Northern Hemisphere more suitable for deep-space observation, as it is not \"blinded\" by the Milky Way.\nDemographics.\nAs of 2015, the Northern Hemisphere is home to approximately 6.4 billion people, which is around 87.0% of the Earth's total human population of 7.3 billion people.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22127", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=22127", "title": "Nuclear Non-Proliferation Treaty/Treaty text", "text": ""}
{"id": "22130", "revid": "50710569", "url": "https://en.wikipedia.org/wiki?curid=22130", "title": "Noun class", "text": "Linguistic category of nouns\nIn linguistics, a noun class is a particular category of nouns. A noun may belong to a given class because of the characteristic features of its referent, such as gender, animacy, shape, but such designations are often clearly conventional. Some authors use the term \"grammatical gender\" as a synonym of \"noun class\", but others consider these different concepts. Noun classes should not be confused with noun classifiers.\nNotion.\nThere are three main ways by which natural languages categorize nouns into noun classes:\nUsually, a combination of the three types of criteria is used, though one is more prevalent.\nNoun classes form a system of grammatical agreement. A noun in a given class may require:\nModern English expresses noun classes through the third person singular personal pronouns \"he\" (male person), \"she\" (female person), and \"it\" (object, abstraction, or animal), and their other inflected forms. Countable and uncountable nouns are distinguished by the choice of \"many\"/\"much\". The choice between the relative pronoun \"who\" (persons) and \"which\" (non-persons) may also be considered a form of agreement with a semantic noun class. A few nouns also exhibit vestigial noun classes, such as \"stewardess\", where the suffix \"-ess\" added to \"steward\" denotes a female person. This type of noun affixation is not very frequent in English, but quite common in languages which have the true grammatical gender, including most of the Indo-European family, to which English belongs.\nIn languages without inflectional noun classes, nouns may still be extensively categorized by independent particles called noun classifiers.\nCommon criteria for noun classes.\nCommon criteria that define noun classes include:\nLanguage families.\nAlgonquian languages.\nThe Ojibwe language and other members of the Algonquian languages distinguish between animate and inanimate classes. Some sources argue that the distinction is between things which are powerful and things which are not. Living things, as well as sacred things and things connected to the Earth, are considered powerful and belong to the animate class. Still, the assignment is somewhat arbitrary, as \"raspberry\" is animate, but \"strawberry\" is inanimate.\nAthabaskan languages.\nIn Navajo (Southern Athabaskan) nouns are classified according to their animacy, shape, and consistency. Morphologically, however, the distinctions are not expressed on the nouns themselves, but on the verbs of which the nouns are the subject or direct object. For example, in the sentence \"\" \"My shirt is lying on the bed\", the verb \"lies\" is used because the subject \"\" \"my shirt\" is a flat, flexible object. In the sentence \"My belt is lying on the bed\", the verb \"\" \"lies\" is used because the subject \"\" \"my belt\" is a slender, flexible object.\nKoyukon (Northern Athabaskan) has a more intricate system of classification. Like Navajo, it has classificatory verb stems that classify nouns according to animacy, shape, and consistency. However, in addition to these verb stems, Koyukon verbs have what are called \"gender prefixes\" that further classify nouns. That is, Koyukon has two different systems that classify nouns: (a) a classificatory verb system and (b) a gender system. To illustrate, the verb stem \"-tonh\" is used for enclosed objects. When \"-tonh\" is combined with different gender prefixes, it can result in \"daaltonh\" which refers to objects enclosed in boxes or \"etltonh\" which refers to objects enclosed in bags.\nAustralian Aboriginal languages.\nThe Dyirbal language is well known for its system of four noun classes, which tend to be divided along the following semantic lines:\nThe class usually labeled \"feminine\", for instance, includes the word for fire and nouns relating to fire, as well as all dangerous creatures and phenomena. (This inspired the title of the George Lakoff book \"Women, Fire, and Dangerous Things\".)\nThe Ngangikurrunggurr language has noun classes reserved for canines and hunting weapons. The Anindilyakwa language has a noun class for things that reflect light. The Diyari language distinguishes only between female and other objects. Perhaps the most noun classes in any Australian language are found in Yanyuwa, which has 16 noun classes, including nouns associated with food, trees and abstractions, in addition to separate classes for men and masculine things, women and feminine things. In the men's dialect, the classes for men and for masculine things have simplified to a single class, marked the same way as the women's dialect marker reserved exclusively for men.\nBasque.\nBasque has two classes, animate and inanimate; however, the only difference is in the declension of locative cases (inessive, ablative, allative, terminal allative, and directional allative). For inanimate nouns, the locative case endings are attached directly if the noun is singular, and plural and indefinite number are marked by the suffixes \"-eta-\" and \"-(e)ta-\", respectively, before the case ending (this is in contrast to the non-locative cases, which follow a different system of number marking where the indefinite form of the ending is the most basic). For example, the noun \"etxe\" \"house\" has the singular ablative form \"etxetik\" \"from the house\", the plural ablative form \"etxeetatik\" \"from the houses\", and the indefinite ablative form \"etxetatik\" (the indefinite form is mainly used with determiners that precede the noun: \"zenbat etxetatik\" \"from how many houses\"). For animate nouns, on the other hand, the locative case endings are attached (with some phonetic adjustments) to the suffix \"-gan-\", which is itself attached to the singular, plural, or indefinite genitive case ending. Alternatively, \"-gan-\" may attach to the absolutive case form of the word if it ends in a vowel. For example, the noun \"ume\" \"child\" has the singular ablative form \"umearengandik\" or \"umeagandik\" \"from the child\", the plural ablative form \"umeengandik\" \"from the children\", and the indefinite ablative form \"umerengandik\" or \"umegandik\" (cf. the genitive forms \"umearen\", \"umeen\", and \"umeren\" and the absolutive forms \"umea\", \"umeak\", and \"ume\"). In the inessive case, the case suffix is replaced entirely by \"-gan\" for animate nouns (compare \"etxean\" \"in/at the house\" and \"umearengan\"/\"umeagan\" \"in/at the child\").\nCaucasian languages.\nSome members of the Northwest Caucasian family, and almost all of the Northeast Caucasian languages, manifest noun class. In the Northeast Caucasian family, only Lezgian, Udi, and Aghul do not have noun classes. Some languages have only two classes, whereas Bats has eight. The most widespread system, however, has four classes: male, female, animate beings and certain objects, and finally a class for the remaining nouns. The Andi language has a noun class reserved for insects.\nAmong Northwest Caucasian languages, only Abkhaz and Abaza have noun class, making use of a human male/human female/non-human distinction.\nIn all Caucasian languages that manifest class, it is not marked on the noun itself but on the dependent verbs, adjectives, pronouns and postpositions or prepositions.\nAtlantic\u2013Congo languages.\nAtlantic\u2013Congo languages can have ten or more noun classes, defined according to non-sexual criteria. Certain nominal classes are reserved for humans. The Fula language has about 26 noun classes (the exact number varies slightly by dialect).\nBantu languages.\nAccording to Carl Meinhof, the Bantu languages have a total of 22 noun classes called nominal classes (this notion was introduced by W.\u00a0H.\u00a0I. Bleek). While no single language is known to express all of them, most of them have at least 10 noun classes. For example, by Meinhof's numbering, Shona has 21 classes, Swahili has 15, Sotho has 18 and Ganda has 17.\nAdditionally, there are polyplural noun classes. A polyplural noun class is a plural class for more than one singular class. For example, Proto-Bantu class 10 contains plurals of class 9 nouns and class 11 nouns, while class 6 contains plurals of class 5 nouns and class 15 nouns. Classes 6 and 10 are inherited as polyplural classes by most surviving Bantu languages, but many languages have developed new polyplural classes that are not widely shared by other languages.\nSpecialists in Bantu emphasize that there is a clear difference between genders (such as known from Afro-Asiatic and Indo-European) and nominal classes (such as known from Niger\u2013Congo). Languages with nominal classes divide nouns formally on the base of hyperonymic meanings. The category of nominal class replaces not only the category of gender, but also the categories of number and case.\nCritics of Meinhof's approach notice that his numbering system of nominal classes counts singular and plural numbers of the same noun as belonging to separate classes. This seems to them to be inconsistent with the way other languages are traditionally considered, where number is orthogonal to gender (according to the critics, a Meinhof-style analysis would give Ancient Greek 9 genders). If one follows broader linguistic tradition and counts singular and plural as belonging to the same class, then Swahili has 8 or 9 noun classes, Sotho has 11 and Ganda has 10.\nThe Meinhof numbering tends to be used in scientific works dealing with comparisons of different Bantu languages. For instance, in Swahili the word 'friend' belongs to the class 9 and its \"plural form\" is of the class 6, even if most nouns of the 9 class have the plural of the class 10. For this reason, noun classes are often referred to by combining their singular and plural forms, e.g., would be classified as \"9/6\", indicating that it takes class 9 in the singular, and class 6 in the plural.\nHowever not all Bantu languages have these exceptions. In Ganda each singular class has a corresponding plural class (apart from one class which has no singular\u2013plural distinction; also some plural classes correspond to more than one singular class) and there are no exceptions as there are in Swahili. For this reason Ganda linguists use the orthogonal numbering system when discussing Ganda grammar (other than in the context of Bantu comparative linguistics), giving the 10 traditional noun classes of that language.\nThe distinction between genders and nominal classes is blurred still further by Indo-European languages that have nouns that behave like Swahili's . Italian, for example, has a group of nouns deriving from Latin neuter nouns that acts as masculine in the singular but feminine in the plural: /; /. (These nouns are still placed in a neuter gender of their own by some grammarians.)\nNominal classes in Swahili.\n\"\u00d8-\" means no prefix. Some classes are homonymous (esp. 9 and 10). The Proto-Bantu class 12 disappeared in Swahili, class 13 merged with 7, and 14 with 11.\nClass prefixes appear also on adjectives and verbs, e.g.:\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\nThe class markers which appear on the adjectives and verbs may differ from the noun prefixes: \n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\nIn this example, the verbal prefix ' and the pronominal prefix ' are in concordance with the noun prefix : they all express class 1 despite their different forms.\nZande.\nThe Zande language distinguishes four noun classes:\nThere are about 80 inanimate nouns which are in the animate class, including nouns denoting heavenly objects (moon, rainbow), metal objects (hammer, ring), edible plants (sweet potato, pea), and non-metallic objects (whistle, ball). Many of the exceptions have a round shape, and some can be explained by the role they play in Zande mythology.\nNoun classes versus grammatical gender.\nThe term \"gender\", as used by some linguists, refers to a noun-class system composed with two, three, or four classes, particularly if the classification is semantically based on a distinction between masculine and feminine. Genders are then considered a sub-class of noun classes. Not all linguists recognize a distinction between noun-classes and genders, however, and instead use either the term \"gender\" or \"noun class\" for both.\nSometimes the distinction can drift over time. For instance, in Danish, the main dialects merged the three original genders down to a total of two genders. Some other dialects merged all three genders down to almost a one gender similar to English, but kept the neuter adjective form for uncountable nouns (which are all neuter in Danish). This effectively created a noun class system of countable and uncountable nouns reflected in adjectives. \nNoun classes versus noun classifiers.\nSome languages, such as Japanese, Chinese and the Tai languages, have elaborate systems of particles that go with nouns based on shape and function, but are free morphemes rather than affixes. Because the classes defined by these classifying words are not generally distinguished in other contexts, there are many linguists who take the view that they do not create noun classes.\nReferences.\nInline.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n*Global map and discussion of languages by type of noun class at http://\n* Contini-Morava, Ellen. \"http:// \". 1994.\n*https://"}
{"id": "22131", "revid": "47039979", "url": "https://en.wikipedia.org/wiki?curid=22131", "title": "Natural gas", "text": "Gaseous fossil fuel\nNatural gas (also methane gas, and gas) is a naturally occurring compound of gaseous hydrocarbons, primarily methane (95%), small amounts of higher alkanes, and traces of carbon dioxide and nitrogen, hydrogen sulfide and helium. Methane is a colorless and odorless gas, and, after carbon dioxide, is the second-greatest greenhouse gas that contributes to global climate change. Because natural gas is odorless, a commercial odorizer, such as methanethiol, that smells of hydrogen sulfide (rotten eggs) is added to the gas for the ready detection of gas leaks.\nNatural gas is a fossil fuel that is formed when layers of organic matter (primarily marine microorganisms) are thermally decomposed under oxygen-free conditions, subjected to intense heat and pressure underground over millions of years. The energy that the decayed organisms originally obtained from the sun via photosynthesis is stored as chemical energy within the molecules of methane and other hydrocarbons.\nNatural gas can be burned for heating, cooking, and electricity generation. Consisting mainly of methane, natural gas is rarely used as a chemical feedstock.\nThe extraction and consumption of natural gas is a major industry. When burned for heat or electricity, natural gas emits fewer toxic air pollutants, less carbon dioxide, and almost no particulate matter compared to other fossil fuels. However, gas venting and unintended fugitive emissions throughout the supply chain can result in natural gas having a similar carbon footprint to other fossil fuels overall.\nNatural gas can be found in underground geological formations, often alongside other fossil fuels like coal and oil (petroleum). Most natural gas has been created through either biogenic or thermogenic processes. Thermogenic gas takes a much longer period of time to form and is created when organic matter is heated and compressed deep underground. Methanogenic organisms produce methane from a variety of sources, principally carbon dioxide.\nDuring petroleum production, natural gas is sometimes flared rather than being collected and used. Before natural gas can be burned as a fuel or used in manufacturing processes, it almost always has to be processed to remove impurities such as water. The byproducts of this processing include ethane, propane, butanes, pentanes, and higher molecular weight hydrocarbons. Hydrogen sulfide (which may be converted into pure sulfur), carbon dioxide, water vapor, and sometimes helium and nitrogen must also be removed.\nNatural gas is sometimes informally referred to simply as \"gas\", especially when it is being compared to other energy sources, such as oil, coal or renewables. However, it is not to be confused with gasoline, which is also shortened in colloquial usage to \"gas\", especially in North America.\nNatural gas is measured in standard cubic meters or standard cubic feet. The density compared to air ranges from 0.58 (16.8\u00a0g/mole, 0.71\u00a0kg per standard cubic meter) to as high as 0.79 (22.9\u00a0g/mole, 0.97\u00a0kg per scm), but generally less than 0.64 (18.5\u00a0g/mole, 0.78\u00a0kg per scm). For comparison, pure methane (16.0425\u00a0g/mole) has a density 0.5539 times that of air (0.678\u00a0kg per standard cubic meter).\nName.\nIn the early 1800s, natural gas became known as \"natural\" to distinguish it from the dominant gas fuel at the time, coal gas. Unlike coal gas, which is manufactured by heating coal, natural gas can be extracted from the ground in its native gaseous form. When the use of natural gas overtook the use of coal gas in English speaking countries in the 20th century, it was increasingly referred to as simply \"gas.\" In order to highlight its role in exacerbating the climate crisis, however, many organizations have criticized the continued use of the word \"natural\" in referring to the gas. These advocates prefer the term \"fossil gas\" or \"methane gas\" as better conveying to the public its climate threat. A 2020 study of Americans' perceptions of the fuel found that, across political identifications, the term \"methane gas\" led to better estimates of its harms and risks.\nHistory.\nNatural gas can come out of the ground and cause a long-burning fire. In ancient Greece, the gas flames at Mount Chimaera contributed to the legend of the fire-breathing creature Chimera. In ancient China, gas resulting from the drilling for brines was first used by about 400 BC. The Chinese transported gas seeping from the ground in crude pipelines of bamboo to where it was used to boil salt water to extract the salt in the Ziliujing District of Sichuan.\nNatural gas was not widely used before the development of long distance pipelines in the early 20th century. Before that, most use was near to the source of the well, and the predominant gas for fuel and lighting during the industrial revolution was manufactured coal gas.\nThe history of natural gas in the United States begins with localized use. In the seventeenth century, French missionaries witnessed the American Indians setting fire to natural gas seeps around Lake Erie, and scattered observations of these seeps were made by European-descended settlers throughout the eastern seaboard through the 1700s. In 1821, William Hart dug the first commercial natural gas well in the United States at Fredonia, New York, United States, which led in 1858 to the formation of the Fredonia Gas Light Company. Further such ventures followed near wells in other states, until technological innovations allowed the growth of major long distance pipelines from the 1920s onwards.\nBy 2009, (or 8%) had been used out of the total of estimated remaining recoverable reserves of natural gas.\nSources.\nNatural gas.\nIn the 19th century, natural gas was primarily obtained as a by-product of producing oil. The small, light gas carbon chains came out of solution as the extracted fluids underwent pressure reduction from the reservoir to the surface, similar to uncapping a soft drink bottle where the carbon dioxide effervesces. The gas was often viewed as a by-product, a hazard, and a disposal problem in active oil fields. The large volumes produced could not be used until relatively expensive pipeline and storage facilities were constructed to deliver the gas to consumer markets.\nUntil the early part of the 20th century, most natural gas associated with oil was either simply released or burned off at oil fields. Gas venting and production flaring are still practiced in modern times, but efforts are ongoing around the world to retire them, and to replace them with other commercially viable and useful alternatives.\nIn addition to transporting gas via pipelines for use in power generation, other end uses for natural gas include export as liquefied natural gas (LNG) or conversion of natural gas into other liquid products via gas to liquids (GTL) technologies. GTL technologies can convert natural gas into liquids products such as gasoline, diesel or jet fuel. A variety of GTL technologies have been developed, including Fischer\u2013Tropsch (F\u2013T), methanol to gasoline (MTG) and syngas to gasoline plus (STG+). F\u2013T produces a synthetic crude that can be further refined into finished products, while MTG can produce synthetic gasoline from natural gas. STG+ can produce drop-in gasoline, diesel, jet fuel and aromatic chemicals directly from natural gas via a single-loop process. In 2011, Royal Dutch Shell's per day F\u2013T plant went into operation in Qatar.\nNatural gas can be \"associated\" (found in oil fields), or \"non-associated\" (isolated in natural gas fields), and is also found in coal beds (as coalbed methane). It sometimes contains a significant amount of ethane, propane, butane, and pentane\u2014heavier hydrocarbons removed for commercial use prior to the methane being sold as a consumer fuel or chemical plant feedstock. Non-hydrocarbons such as carbon dioxide, nitrogen, helium (rarely), and hydrogen sulfide must also be removed before the natural gas can be transported.\nNatural gas extracted from oil wells is called casinghead gas (whether or not truly produced up the annulus and through a casinghead outlet) or associated gas. The natural gas industry is extracting an increasing quantity of gas from challenging, unconventional resource types: sour gas, tight gas, shale gas, and coalbed methane.\nThere is some disagreement on which country has the largest proven gas reserves. Sources that consider that Russia has by far the largest proven reserves include the US Central Intelligence Agency (47,600\u00a0km3) and Energy Information Administration (47,800\u00a0km3), as well as the Organization of Petroleum Exporting Countries (48,700\u00a0km3). Contrarily, BP credits Russia with only 32,900\u00a0km3, which would place it in second, slightly behind Iran (33,100 to 33,800\u00a0km3, depending on the source).\nIt is estimated that there are about 900,000\u00a0km3 of \"unconventional\" gas such as shale gas, of which 180,000\u00a0km3 may be recoverable. In turn, many studies from MIT, Black &amp; Veatch and the US Department of Energy predict that natural gas will account for a larger portion of electricity generation and heat in the future.\nThe world's largest gas field is the offshore South Pars/North Dome Gas-Condensate field, shared between Iran and Qatar. It is estimated to have of natural gas and of natural gas condensates.\nBecause natural gas is not a pure product, as the reservoir pressure drops when non-associated gas is extracted from a field under supercritical (pressure/temperature) conditions, the higher molecular weight components may partially condense upon isothermic depressurizing\u2014an effect called retrograde condensation. The liquid thus formed may get trapped as the pores of the gas reservoir get depleted. One method to deal with this problem is to re-inject dried gas free of condensate to maintain the underground pressure and to allow re-evaporation and extraction of condensates. More frequently, the liquid condenses at the surface, and one of the tasks of the gas plant is to collect this condensate. The resulting liquid is called natural gas liquid (NGL) and has commercial value.\nShale gas.\nShale gas is natural gas produced from shale. Because shale's matrix permeability is too low to allow gas to flow in economical quantities, shale gas wells depend on fractures to allow the gas to flow. Early shale gas wells depended on natural fractures through which gas flowed; almost all shale gas wells today require fractures artificially created by hydraulic fracturing. Since 2000, shale gas has become a major source of natural gas in the United States and Canada. Because of increased shale gas production the United States was in 2014 the number one natural gas producer in the world. The production of shale gas in the United States has been described as a \"shale gas revolution\" and as \"one of the landmark events in the 21st century.\"\nFollowing the increased production in the United States, shale gas exploration is beginning in countries such as Poland, China, and South Africa. Chinese geologists have identified the Sichuan Basin as a promising target for shale gas drilling, because of the similarity of shales to those that have proven productive in the United States. Production from the Wei-201 well is between 10,000 and 20,000 m3 per day. In late 2020, China National Petroleum Corporation claimed daily production of 20 million cubic meters of gas from its Changning-Weiyuan demonstration zone.\nTown gas.\nTown gas is a flammable gaseous fuel made by the destructive distillation of coal. It contains a variety of calorific gases including hydrogen, carbon monoxide, methane, and other volatile hydrocarbons, together with small quantities of non-calorific gases such as carbon dioxide and nitrogen, and was used in a similar way to natural gas. This is a historical technology and is not usually economically competitive with other sources of fuel gas today.\nMost town \"gashouses\" located in the eastern US in the late 19th and early 20th centuries were simple by-product coke ovens that heated bituminous coal in air-tight chambers. The gas driven off from the coal was collected and distributed through networks of pipes to residences and other buildings where it was used for cooking and lighting. (Gas heating did not come into widespread use until the last half of the 20th century.) The coal tar (or asphalt) that collected in the bottoms of the gashouse ovens was often used for roofing and other waterproofing purposes, and when mixed with sand and gravel was used for paving streets.\nSynthetic natural gas.\nSynthetic natural gas (SNG), is a fuel gas (predominantly methane, CH4) that can be produced from fossil fuels such as lignite coal, oil shale, or from biofuels or using electricity with power-to-gas system. Gasification process is used to generate SNG. When the gasification is conducted with hydrogen in place of oxygen/air, it is called hydrogasification.\nRenewable natural gas.\nRenewable natural gas (RNG), also known as biomethane, is a renewable fuel made from biogas that has been upgraded to a quality similar to fossil natural gas and has a methane concentration of 90% or greater.\nCrystallized natural gas \u2013 clathrates.\nHuge quantities of natural gas (primarily methane) exist in the form of clathrates under sediment on offshore continental shelves and on land in arctic regions that experience permafrost, such as those in Siberia. Hydrates require a combination of high pressure and low temperature to form.\nIn 2013, Japan Oil, Gas and Metals National Corporation (JOGMEC) announced that they had recovered commercially relevant quantities of natural gas from methane hydrate.\nProcessing.\nThe image below is a schematic block flow diagram of a typical natural gas processing plant. It shows the various unit processes used to convert raw natural gas into sales gas pipelined to the end user markets.\nThe block flow diagram also shows how processing of the raw natural gas yields byproduct sulfur, byproduct ethane, and natural gas liquids (NGL) propane, butanes and natural gasoline (denoted as pentanes +).\nDemand.\nAs of mid-2020, natural gas production in the US had peaked three times, with current levels exceeding both previous peaks. It reached 24.1\u00a0trillion cubic feet per year in 1973, followed by a decline, and reached 24.5\u00a0trillion cubic feet in 2001. After a brief drop, withdrawals increased nearly every year since 2006 (owing to the shale gas boom), with 2017 production at 33.4\u00a0trillion cubic feet and 2019 production at 40.7\u00a0trillion cubic feet. After the third peak in December 2019, extraction continued to fall from March onward due to decreased demand caused by the COVID-19 pandemic in the US.\nThe 2021 global energy crisis was driven by a global surge in demand as the world quit the economic recession caused by COVID-19, particularly due to strong energy demand in Asia.\nStorage and transport.\nBecause of its low density, it is not easy to store natural gas or to transport it by vehicle. Natural gas pipelines are impractical across oceans, since the gas needs to be cooled down and compressed, as the friction in the pipeline causes the gas to heat up. Many existing pipelines in the US are close to reaching their capacity, prompting some politicians representing northern states to speak of potential shortages. The large trade cost implies that natural gas markets are globally much less integrated, causing significant price differences across countries. In Western Europe, the gas pipeline network is already dense. New pipelines are planned or under construction between Western Europe and the Near East or Northern Africa.\nWhenever gas is bought or sold at custody transfer points, rules and agreements are made regarding the gas quality. These may include the maximum allowable concentration of CO2, H2S and H2O. Usually sales quality gas that has been treated to remove contamination is traded on a \"dry gas\" basis and is required to be commercially free from objectionable odours, materials, and dust or other solid or liquid matter, waxes, gums and gum forming constituents, which might damage or adversely affect operation of equipment downstream of the custody transfer point.\nBased on their geographic origin, H-gas (high-calorific gas) and L-gas (low-calorific gas) are to be distinguished. Both types require separate transport, leading to two separate pipeline networks, e.g. in parts of Germany (with a strengthened focus and transition towards H-gas, as the L-gas reservoirs in Germany and the Netherlands are declining).\nLNG carrier ships transport liquefied natural gas (LNG) across oceans, while tank trucks can carry LNG or compressed natural gas (CNG) over shorter distances. Sea transport using CNG carrier ships that are now under development may be competitive with LNG transport in specific conditions.\nGas is turned into liquid at a liquefaction plant, and is returned to gas form at regasification plant at the terminal. Shipborne regasification equipment is also used. LNG is the preferred form for long distance, high volume transportation of natural gas, whereas pipeline is preferred for transport for distances up to over land and approximately half that distance offshore.\nCNG is transported at high pressure, typically above . Compressors and decompression equipment are less capital intensive and may be economical in smaller unit sizes than liquefaction/regasification plants. Natural gas trucks and carriers may transport natural gas directly to end-users, or to distribution points such as pipelines.\nIn the past, the natural gas which was recovered in the course of recovering petroleum could not be profitably sold, and was simply burned at the oil field in a process known as flaring. Flaring is now illegal in many countries. Additionally, higher demand in the last 20\u201330 years has made production of gas associated with oil economically viable. As a further option, the gas is now sometimes re-injected into the formation for enhanced oil recovery by pressure maintenance as well as miscible or immiscible flooding. Conservation, re-injection, or flaring of natural gas associated with oil is primarily dependent on proximity to markets (pipelines), and regulatory restrictions.\nNatural gas can be indirectly exported through the absorption in other physical output. The expansion of shale gas production in the US has caused prices to drop relative to other countries. This has caused a boom in energy intensive manufacturing sector exports, whereby the average dollar unit of US manufacturing exports has almost tripled its energy content between 1996 and 2012.\nA \"master gas system\" was invented in Saudi Arabia in the late 1970s, ending any necessity for flaring. Satellite and nearby infra-red camera observations, however, shows that flaring and venting are still happening in some countries.\nNatural gas is used to generate electricity and heat for desalination. Similarly, some landfills that also discharge methane gases have been set up to capture the methane and generate electricity.\nNatural gas is often stored underground [references about geological storage needed]inside depleted gas reservoirs from previous gas wells, salt domes, or in tanks as liquefied natural gas. The gas is injected in a time of low demand and extracted when demand picks up. Storage nearby end users helps to meet volatile demands, but such storage may not always be practicable.\nWith 15 countries accounting for 84% of the worldwide extraction, access to natural gas has become an important issue in international politics, and countries vie for control of pipelines. In the first decade of the 21st century, Gazprom, the state-owned energy company in Russia, engaged in disputes with Ukraine and Belarus over the price of natural gas, which have created concerns that gas deliveries to parts of Europe could be cut off for political reasons. The United States is preparing to export natural gas.\nFloating liquefied natural gas.\nFloating liquefied natural gas (FLNG) is an innovative technology designed to enable the development of offshore gas resources that would otherwise remain untapped due to environmental or economic factors which currently make them impractical to develop via a land-based LNG operation. FLNG technology also provides a number of environmental and economic advantages:\nMany gas and oil companies are considering the economic and environmental benefits of floating liquefied natural gas (FLNG). There are currently projects underway to construct five FLNG facilities. Petronas is close to completion on their FLNG-1 at Daewoo Shipbuilding and Marine Engineering and are underway on their FLNG-2 project at Samsung Heavy Industries. Shell Prelude is due to start production 2017. The Browse LNG project will commence FEED in 2019.\nUses.\nNatural gas is primarily used in the northern hemisphere. North America and Europe are major consumers.\nOften well head gases require removal of various hydrocarbon molecules contained within the gas. Some of these gases include heptane, pentane, propane and other hydrocarbons with molecular weights above methane (CH4). The natural gas transmission lines extend to the natural gas processing plant or unit which removes the higher-molecular weight hydrocarbons to produce natural gas with energy content between . The processed natural gas may then be used for residential, commercial and industrial uses.\nMid-stream natural gas.\nNatural gas flowing in the distribution lines is called mid-stream natural gas and is often used to power engines which rotate compressors. These compressors are required in the transmission line to pressurize and repressurize the mid-stream natural gas as the gas travels. Typically, natural gas powered engines require natural gas to operate at the rotational name plate specifications. Several methods are used to remove these higher molecular weighted gases for use by the natural gas engine. A few technologies are as follows:\nDomestic use.\nIn the US, over one-third of households (&gt;40 million homes) cook with gas. Natural gas dispensed in a residential setting can generate temperatures in excess of making it a powerful domestic cooking and heating fuel. Stanford scientists estimated that gas stoves emit 0.8\u20131.3% of the gas they use as unburned methane and that total U.S. stove emissions are 28.1 gigagrams of methane. In much of the developed world it is supplied through pipes to homes, where it is used for many purposes including ranges and ovens, heating/cooling, outdoor and portable grills, and central heating. Heaters in homes and other buildings may include boilers, furnaces, and water heaters. Both North America and Europe are major consumers of natural gas.\nDomestic appliances, furnaces, and boilers use low pressure, usually with a standard pressure around over atmospheric pressure. The pressures in the supply lines vary, either the standard utilization pressure (UP) mentioned above or elevated pressure (EP), which may be anywhere from over atmospheric pressure. Systems using EP have a regulator at the service entrance to step down to UP.\nNatural gas piping systems inside buildings are often designed with pressures of , and have downstream pressure regulators to reduce pressure as needed. In the United States the maximum allowable operating pressure for natural gas piping systems within a building is based on NFPA 54: National Fuel Gas Code, except when approved by the Public Safety Authority or when insurance companies have more stringent requirements.\nGenerally, natural gas system pressures are not allowed to exceed unless all of the following conditions are met:\nGenerally, a maximum liquefied petroleum gas pressure of is allowed, provided the building is constructed in accordance with NFPA 58: Liquefied Petroleum Gas Code, Chapter 7.\nA seismic earthquake valve operating at a pressure of 55 psig (3.7 bar) can stop the flow of natural gas into the site wide natural gas distribution piping network (that runs (outdoors underground, above building roofs, and or within the upper supports of a canopy roof). Seismic earthquake valves are designed for use at a maximum of 60 psig.\nIn Australia, natural gas is transported from gas processing facilities to regulator stations via transmission pipelines. Gas is then regulated down to distributed pressures and the gas is distributed around a gas network via gas mains. Small branches from the network, called services, connect individual domestic dwellings, or multi-dwelling buildings to the network. The networks typically range in pressures from 7 kPa (low pressure) to 515 kPa (high pressure). Gas is then regulated down to 1.1 kPa or 2.75 kPa, before being metered and passed to the consumer for domestic use. Natural gas mains are made from a variety of materials: historically cast iron, though more modern mains are made from steel or polyethylene.\nIn some states in the USA, natural gas can be supplied by independent natural gas wholesalers/suppliers using existing pipeline owners' infrastructure through Natural Gas Choice programs.\nLPG (liquefied petroleum gas) typically fuels outdoor and portable grills. Although, compressed natural gas (CNG) is sparsely available for similar applications in the US in rural areas underserved by the existing pipeline system and distribution network of the less expensive and more abundant LPG (liquefied petroleum gas).\nTransportation.\nCNG is a cleaner and also cheaper alternative to other automobile fuels such as gasoline (petrol). By the end of 2014, there were over 20\u00a0million natural gas vehicles worldwide, led by Iran (3.5\u00a0million), China (3.3\u00a0million), Pakistan (2.8\u00a0million), Argentina (2.5\u00a0million), India (1.8\u00a0million), and Brazil (1.8\u00a0million). The energy efficiency is generally equal to that of gasoline engines, but lower compared with modern diesel engines. Gasoline/petrol vehicles converted to run on natural gas suffer because of the low compression ratio of their engines, resulting in a cropping of delivered power while running on natural gas (10\u201315%). CNG-specific engines, however, use a higher compression ratio due to this fuel's higher octane number of 120\u2013130.\nBesides use in road vehicles, CNG can also be used in aircraft. Compressed natural gas has been used in some aircraft like the Aviat Aircraft Husky 200 CNG and the Chromarat VX-1 KittyHawk\nLNG is also being used in aircraft. Russian aircraft manufacturer Tupolev for instance is running a development program to produce LNG- and hydrogen-powered aircraft. The program has been running since the mid-1970s, and seeks to develop LNG and hydrogen variants of the Tu-204 and Tu-334 passenger aircraft, and also the Tu-330 cargo aircraft. Depending on the current market price for jet fuel and LNG, the consumption cost advantage for LNG-powered aircraft is approximately 18.96%, along with a 53.72% reduction to carbon monoxide, hydrocarbon and nitrogen oxide emissions.\nThe advantages of liquid methane as a jet engine fuel are that it has more specific energy than the standard kerosene mixes do and that its low temperature can help cool the air which the engine compresses for greater volumetric efficiency, in effect replacing an intercooler. Alternatively, it can be used to lower the temperature of the exhaust.\nFertilizers.\nNatural gas is a major feedstock for the production of ammonia, via the Haber process, for use in fertilizer production. The development of synthetic nitrogen fertilizer has significantly supported global population growth\u00a0\u2014 it has been estimated that almost half the people on the Earth are currently fed as a result of synthetic nitrogen fertilizer use.\nHydrogen.\nNatural gas can be used to produce hydrogen, with one common method being the hydrogen reformer. Hydrogen has many applications: it is a primary feedstock for the chemical industry, a hydrogenating agent, an important commodity for oil refineries, and the fuel source in hydrogen vehicles.\nAnimal and fish feed.\nProtein rich animal and fish feed is produced by feeding natural gas to Methylococcus capsulatus bacteria on commercial scale.\nOlefins(alkenes).\nNatural gas components(alkanes) can be converted into olefins(alkenes) or other chemical synthesis. Ethane by oxidative dehydrogenation converts to ethylene, which can be further converted to ethylene oxide, ethylene glycol, acetaldehyde or other olefins. Propane by oxidative hydrogenation converts to propylene or can be oxidized to acrylic acid and acrylonitrile.\nOther.\nNatural gas is also used in the manufacture of fabrics, glass, steel, plastics, paint, synthetic oil, and other products.\nFuel for industrial heating and desiccation processes.\nRaw material for large-scale fuel production using gas-to-liquid (GTL) process (e.g. to produce sulphur-and aromatic-free diesel with low-emission combustion).\nHealth effects.\nCooking with natural gas contributes to poor indoor air quality and can lead to severe respiratory diseases such as asthma.\nEnvironmental effects.\nGreenhouse effect and natural gas release.\nNatural gas is a growing contributor to climate change. Both the NG itself (specifically methane) and carbon dioxide, which is released when natural gas is burned, are greenhouse gases.\nHuman activity is responsible for about 60% of all methane emissions and for most of the resulting increase in atmospheric methane. Natural gas is intentionally released or is otherwise known to leak during the extraction, storage, transportation, and distribution of fossil fuels. Globally, methane accounts for an estimated 33% of anthropogenic greenhouse gas warming. The decomposition of municipal solid waste (a source of landfill gas) and wastewater account for an additional 18% of such emissions. These estimates include substantial uncertainties which should be reduced in the near future with improved satellite measurements, such as those planned for MethaneSAT.\nAfter release to the atmosphere, methane is removed by gradual oxidation to carbon dioxide and water by hydroxyl radicals (OH-) formed in the troposphere or stratosphere, giving the overall chemical reaction CH4 + 2O2 \u2192 CO2 + 2H2O. While the lifetime of atmospheric methane is relatively short when compared to carbon dioxide, with a half-life of about 7 years, it is more efficient at trapping heat in the atmosphere, so that a given quantity of methane has 84 times the global-warming potential of carbon dioxide over a 20-year period and 28 times over a 100-year period. Natural gas is thus a potent greenhouse gas due to the strong radiative forcing of methane in the short term, and the continuing effects of carbon dioxide in the longer term.\nTargeted efforts to reduce warming quickly by reducing anthropogenic methane emissions is a climate change mitigation strategy supported by the Global Methane Initiative.\nGreenhouse gas emissions.\nWhen refined and burned, natural gas can produce 25\u201330% less carbon dioxide per joule delivered than oil, and 40\u201345% less than coal. It can also produce potentially fewer toxic pollutants than other hydrocarbon fuels. However, compared to other major fossil fuels, natural gas causes more emissions in relative terms during the production and transportation of the fuel, meaning that the life cycle greenhouse gas emissions are about 50% higher than the direct emissions from the site of consumption.\nIn terms of the warming effect over 100 years, natural gas production and use comprises about one fifth of human greenhouse gas emissions, and this contribution is growing rapidly. Globally, natural gas use emitted about 7.8\u00a0billion tons of CO2 in 2020 (including flaring), while coal and oil use emitted 14.4 and 12\u00a0billion tons, respectively. The IEA estimates the energy sector (oil, natural gas, coal and bioenergy) to be responsible for about 40% of human methane emissions. According to the IPCC Sixth Assessment Report, natural gas consumption grew by 15% between 2015 and 2019, compared to a 5% increase in oil and oil product consumption.\nThe continued financing and construction of new gas pipelines indicates that huge emissions of fossil greenhouse gases could be locked-in for 40 to 50 years into the future. In the U.S. state of Texas alone, five new long-distance gas pipelines have been under construction, with the first entering service in 2019, and the others scheduled to come online during 2020\u20132022.\nInstallation bans.\nTo reduce its greenhouse emissions, the Netherlands is subsidizing a transition away from natural gas for all homes in the country by 2050. In Amsterdam, no new residential gas accounts have been allowed since 2018, and all homes in the city are expected to be converted by 2040 to use the excess heat from adjacent industrial buildings and operations.\nSome cities in the United States have started prohibiting gas hookups for new houses, with state laws passed and under consideration to either require electrification or prohibit local requirements. New gas appliance hookups are banned in New York State and the Australian Capital Territory. Additionally, the state of Victoria in Australia has implemented a ban on new natural gas hookups starting from January 1, 2024, as part of its gas substitution roadmap. This followed campaigning which resulted in a prohibition on onshore gas exploration and production in Victoria in 2014. This was partially lifted in 2021 but a constitutional ban remains on fracking.\nThe UK government is also experimenting with alternative home heating technologies to meet its climate goals. To preserve their businesses, natural gas utilities in the United States have been lobbying for laws preventing local electrification ordinances, and are promoting renewable natural gas and hydrogen fuel.\nOther pollutants.\nAlthough natural gas produces far lower amounts of sulfur dioxide and nitrogen oxides (NOx) than other fossil fuels, from burning natural gas in homes can be a health hazard.\nRadionuclides.\nNatural gas extraction also produces radioactive isotopes of polonium (Po-210), lead (Pb-210) and radon (Rn-220). Radon is a gas with initial activity from 5 to 200,000 becquerels per cubic meter of gas. It decays rapidly to Pb-210 which can build up as a thin film in gas extraction equipment.\nSafety concerns.\nThe natural gas extraction workforce face unique health and safety challenges.\nProduction.\nSome gas fields yield sour gas containing hydrogen sulfide (H2S), a toxic compound when inhaled. Amine gas treating, an industrial scale process which removes acidic gaseous components, is often used to remove hydrogen sulfide from natural gas.\nExtraction of natural gas (or oil) leads to decrease in pressure in the reservoir. Such decrease in pressure in turn may result in subsidence \u2014 sinking of the ground above. Subsidence may affect ecosystems, waterways, sewer and water supply systems, foundations, and so on.\nFracking.\nReleasing natural gas from subsurface porous rock formations may be accomplished by a process called hydraulic fracturing or \"fracking\". Since the first commercial hydraulic fracturing operation in 1949, approximately one million wells have been hydraulically fractured in the United States. The production of natural gas from hydraulically fractured wells has used the technological developments of directional and horizontal drilling, which improved access to natural gas in tight rock formations. Strong growth in the production of unconventional gas from hydraulically fractured wells occurred between 2000 and 2012.\nIn hydraulic fracturing, well operators force water mixed with a variety of chemicals through the wellbore casing into the rock. The high pressure water breaks up or \"fracks\" the rock, which releases gas from the rock formation. Sand and other particles are added to the water as a proppant to keep the fractures in the rock open, thus enabling the gas to flow into the casing and then to the surface. Chemicals are added to the fluid to perform such functions as reducing friction and inhibiting corrosion. After the \"frack\", oil or gas is extracted and 30\u201370% of the frack fluid, i.e. the mixture of water, chemicals, sand, etc., flows back to the surface. Many gas-bearing formations also contain water, which will flow up the wellbore to the surface along with the gas, in both hydraulically fractured and non-hydraulically fractured wells. This produced water often has a high content of salt and other dissolved minerals that occur in the formation.\nThe volume of water used to hydraulically fracture wells varies according to the hydraulic fracturing technique. In the United States, the average volume of water used per hydraulic fracture has been reported as nearly 7,375 gallons for vertical oil and gas wells prior to 1953, nearly 197,000 gallons for vertical oil and gas wells between 2000 and 2010, and nearly 3\u00a0million gallons for horizontal gas wells between 2000 and 2010.\nDetermining which fracking technique is appropriate for well productivity depends largely on the properties of the reservoir rock from which to extract oil or gas. If the rock is characterized by low-permeability \u2013 which refers to its ability to let substances, i.e. gas, pass through it, then the rock may be considered a source of tight gas. Fracking for shale gas, which is currently also known as a source of unconventional gas, involves drilling a borehole vertically until it reaches a lateral shale rock formation, at which point the drill turns to follow the rock for hundreds or thousands of feet horizontally. In contrast, conventional oil and gas sources are characterized by higher rock permeability, which naturally enables the flow of oil or gas into the wellbore with less intensive hydraulic fracturing techniques than the production of tight gas has required. The decades in development of drilling technology for conventional and unconventional oil and gas production have not only improved access to natural gas in low-permeability reservoir rocks, but also posed significant adverse impacts on environmental and public health.\nThe US EPA has acknowledged that toxic, carcinogenic chemicals, i.e. benzene and ethylbenzene, have been used as gelling agents in water and chemical mixtures for high volume horizontal fracturing (HVHF). Following the hydraulic fracture in HVHF, the water, chemicals, and frack fluid that return to the well's surface, called flowback or produced water, may contain radioactive materials, heavy metals, natural salts, and hydrocarbons which exist naturally in shale rock formations. Fracking chemicals, radioactive materials, heavy metals, and salts that are removed from the HVHF well by well operators are so difficult to remove from the water they are mixed with, and would so heavily pollute the water cycle, that most of the flowback is either recycled into other fracking operations or injected into deep underground wells, eliminating the water that HVHF required from the hydrologic cycle.\nHistorically low gas prices have delayed the nuclear renaissance, as well as the development of solar thermal energy.\nAdded odor.\nIn its native state, natural gas is colorless and almost odorless. In the US, the New London School explosion that occurred in 1937 in Texas caused a push for legislation requiring the addition of an odorant to assist consumers in detecting leaks. An odorizer with an unpleasant smell, such as thiophane or tert-butylthiol (t-butyl mercaptan) may be added. Situations have occurred in which an odorant cannot be properly detected by an observer with a normal sense of smell despite being detectable by analytical instruments. This is caused by odor masking, when one odor overpowers the sensation of another. As of 2011, the industry is conducting research on the causes of odor masking.\nRisk of explosion.\nExplosions caused by natural gas leaks occur a few times each year. Individual homes, small businesses and other structures are most frequently affected when an internal leak builds up gas inside the structure. Leaks often result from excavation work, such as when contractors dig and strike pipelines, sometimes without knowing any damage resulted. Frequently, the blast is powerful enough to significantly damage a building but leave it standing. In these cases, the people inside tend to have minor to moderate injuries. Occasionally, the gas can collect in high enough quantities to cause a deadly explosion, destroying one or more buildings in the process. Many building codes now forbid the installation of gas pipes inside cavity walls or below floor boards to mitigate against this risk. Gas usually dissipates readily outdoors, but can sometimes collect in dangerous quantities if flow rates are high enough. However, considering the tens of millions of structures that use the fuel, the individual risk from using natural gas is low.\nRisk of carbon monoxide inhalation.\nNatural gas heating systems may cause carbon monoxide poisoning if unvented or poorly vented. Improvements in natural gas furnace designs have greatly reduced CO poisoning concerns. Detectors are also available that warn of carbon monoxide or explosive gases such as methane and propane.\nEnergy content, statistics, and pricing.\nQuantities of natural gas are measured in standard cubic meters (cubic meter of gas at temperature and pressure ) or standard cubic feet (cubic foot of gas at temperature 60.0\u00a0\u00b0F and pressure ), 1 standard cubic meter\u00a0=\u00a035.301\u00a0standard cubic feet. The gross heat of combustion of commercial quality natural gas is around , but this can vary by several percent. This is about 50 to 54\u00a0MJ/kg depending on the density. For comparison, the heat of combustion of pure methane is 37.7\u00a0MJ per standard cubic metre, or 55.5\u00a0MJ/kg.\nExcept in the European Union, the U.S., and Canada, natural gas is sold in gigajoule retail units. LNG (liquefied natural gas) and LPG (liquefied petroleum gas) are traded in metric tonnes (1,000\u00a0kg) or million BTU as spot deliveries. Long term natural gas distribution contracts are signed in cubic meters, and LNG contracts are in metric tonnes. The LNG and LPG is transported by specialized transport ships, as the gas is liquified at cryogenic temperatures. The specification of each LNG/LPG cargo will usually contain the energy content, but this information is in general not available to the public. The European Union aimed to cut its gas dependency on Russia by two-thirds in 2022.\nIn August 2015, possibly the largest natural gas discovery in history was made and notified by an Italian gas company ENI. The energy company indicated that it has unearthed a \"supergiant\" gas field in the Mediterranean Sea covering about . This was named the Zohr gas field and could hold a potential of natural gas. ENI said that the energy is about . The Zohr field was found in the deep waters off the northern coast of Egypt and ENI claims that it will be the largest ever in the Mediterranean and even the world.\nEuropean Union.\nGas prices for end users vary greatly across the EU. A single European energy market, one of the key objectives of the EU, should level the prices of gas in all EU member states. Moreover, it would help to resolve supply and global warming issues, as well as strengthen relations with other Mediterranean countries and foster investments in the region. During the prelude to the 2022 Russian invasion of Ukraine, Qatar was asked by the US to supply emergency gas to the EU in case of supply disruptions.\nUnited States.\nIn US units, of natural gas produces around . The actual heating value when the water formed does not condense is the net heat of combustion and can be as much as 10% less.\nIn the United States, retail sales are often in units of therms (th); 1 therm = 100,000\u00a0BTU. Gas sales to domestic consumers are often in units of 100 standard cubic feet (scf). Gas meters measure the volume of gas used, and this is converted to therms by multiplying the volume by the energy content of the gas used during that period, which varies slightly over time. The typical annual consumption of a single family residence is 1,000 therms or one Residential Customer Equivalent (RCE). Wholesale transactions are generally done in decatherms (Dth), thousand decatherms (MDth), or million decatherms (MMDth). A million decatherms is a trillion BTU, roughly a billion cubic feet of natural gas.\nThe price of natural gas varies greatly depending on location and type of consumer. The typical caloric value of natural gas is roughly 1,000\u00a0BTU per cubic foot, depending on gas composition. Natural gas in the United States is traded as a futures contract on the New York Mercantile Exchange. Each contract is for 10,000\u00a0million BTU or . Thus, if the price of gas is $10/million BTU on the NYMEX, the contract is worth $100,000.\nCanada.\nCanada uses metric measure for internal trade of petrochemical products. Consequently, natural gas is sold by the gigajoule (GJ), cubic meter (m3) or thousand cubic meters (E3m3). Distribution infrastructure and meters almost always meter volume (cubic foot or cubic meter). Some jurisdictions, such as Saskatchewan, sell gas by volume only. Other jurisdictions, such as Alberta, sell gas by energy content (GJ). In these areas, almost all meters for residential and small commercial customers measure volume (m3 or ft3), and billing statements include a multiplier to convert the volume to the energy content of the local gas supply.\nA gigajoule (GJ) is a measure approximately equal to of oil, or or 1\u00a0million BTUs of gas. The energy content of gas supply in Canada can vary from depending on gas supply and processing between the wellhead and the customer.\nAdsorbed natural gas (ANG).\nNatural gas may be stored by adsorbing it to the porous solids called sorbents. The optimal condition for methane storage is at room temperature and atmospheric pressure. Pressures up to 4 MPa (about 40 times atmospheric pressure) will yield greater storage capacity. The most common sorbent used for ANG is activated carbon (AC), primarily in three forms: Activated Carbon Fiber (ACF), Powdered Activated Carbon (PAC), and activated carbon monolith.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22132", "revid": "41195652", "url": "https://en.wikipedia.org/wiki?curid=22132", "title": "Nymphomania", "text": ""}
{"id": "22133", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=22133", "title": "Nuclear chain reaction", "text": "When one nuclear reaction causes more\nIn nuclear physics, a nuclear chain reaction occurs when one single nuclear reaction causes an average of one or more subsequent nuclear reactions, thus leading to the possibility of a self-propagating series or \"positive feedback loop\" of these reactions. The specific nuclear reaction may be the fission of heavy isotopes (e.g., uranium-235, 235U). A nuclear chain reaction releases several million times more energy per reaction than any chemical reaction.\nHistory.\nChemical chain reactions were first proposed by German chemist Max Bodenstein in 1913, and were reasonably well understood before nuclear chain reactions were proposed. It was understood that chemical chain reactions were responsible for exponentially increasing rates in reactions, such as produced in chemical explosions.\nThe concept of a nuclear chain reaction was reportedly first hypothesized by Hungarian scientist Le\u00f3 Szil\u00e1rd on September 12, 1933. Szil\u00e1rd that morning had been reading in a London paper of an experiment in which protons from an accelerator had been used to split lithium-7 into alpha particles, and the fact that much greater amounts of energy were produced by the reaction than the proton supplied. Ernest Rutherford commented in the article that inefficiencies in the process precluded use of it for power generation. However, the neutron had been discovered by James Chadwick in 1932, shortly before, as the product of a nuclear reaction. Szil\u00e1rd, who had been trained as an engineer and physicist, put the two nuclear experimental results together in his mind and realized that if a nuclear reaction produced neutrons, which then caused further similar nuclear reactions, the process might be a self-perpetuating nuclear chain reaction, spontaneously producing new isotopes and power without the need for protons or an accelerator. Szil\u00e1rd, however, did not propose fission as the mechanism for his chain reaction since the fission reaction was not yet discovered, or even suspected. Instead, Szil\u00e1rd proposed using mixtures of lighter known isotopes which produced neutrons in copious amounts. He filed a patent for his idea of a simple nuclear reactor the following year.\nIn 1936, Szil\u00e1rd attempted to create a chain reaction using beryllium and indium but was unsuccessful. Nuclear fission was discovered by Otto Hahn and Fritz Strassmann in December 1938 and explained theoretically in January 1939 by Lise Meitner and her nephew Otto Robert Frisch. In their second publication on nuclear fission in February 1939, Hahn and Strassmann used the term \"uranspaltung\" (uranium fission) for the first time and predicted the existence and liberation of additional neutrons during the fission process, opening up the possibility of a nuclear chain reaction.\nA few months later, Fr\u00e9d\u00e9ric Joliot-Curie, H. Von Halban and L. Kowarski in Paris searched for, and discovered, neutron multiplication in uranium, proving that a nuclear chain reaction by this mechanism was indeed possible. On May 4, 1939, Joliot-Curie, Halban, and Kowarski filed three patents. The first two described power production from a nuclear chain reaction, the last one called \"Perfectionnement aux charges explosives\" was the first patent for the atomic bomb and is filed as patent No. 445686 by the Caisse nationale de Recherche Scientifique. In parallel, Szil\u00e1rd and Enrico Fermi in New York made the same analysis. This discovery prompted the letter from Szil\u00e1rd and signed by Albert Einstein to President Franklin D. Roosevelt, warning of the possibility that Nazi Germany might be attempting to build an atomic bomb.\nOn December 2, 1942, a team led by Fermi (and including Szil\u00e1rd) produced the first artificial self-sustaining nuclear chain reaction with the Chicago Pile-1 experimental reactor in a racquets court below the bleachers of Stagg Field at the University of Chicago. Fermi's experiments at the University of Chicago were part of Arthur H. Compton's Metallurgical Laboratory of the Manhattan Project; the lab was renamed Argonne National Laboratory and tasked with conducting research in harnessing fission for nuclear energy.\nIn 1956, Paul Kuroda of the University of Arkansas postulated that a natural fission reactor may have once existed. Since nuclear chain reactions may only require natural materials (such as water and uranium, if the uranium has sufficient amounts of 235U), it was possible to have these chain reactions occur in the distant past when uranium-235 concentrations were higher than today, and where there was the right combination of materials within the Earth's crust. Uranium-235 made up a larger share of uranium on Earth in the geological past because of the different half-lives of the isotopes 235U and 238U, the former decaying almost an order of magnitude faster than the latter. Kuroda's prediction was verified with the discovery of evidence of natural self-sustaining nuclear chain reactions in the past at Oklo in Gabon in September 1972. To sustain a nuclear fission chain reaction at present isotope ratios in natural uranium on Earth would require the presence of a neutron moderator like heavy water or high purity carbon (e.g. graphite) in the absence of neutron poisons, which is even more unlikely to arise by natural geological processes than the conditions at Oklo some two billion years ago.\nProcess.\nFission chain reactions occur because of interactions between neutrons and fissile isotopes (such as 235U). The chain reaction requires both the release of neutrons from fissile isotopes undergoing nuclear fission and the subsequent absorption of some of these neutrons in fissile isotopes. When an atom undergoes nuclear fission, a few neutrons (the exact number depends on uncontrollable and unmeasurable factors; the expected number depends on several factors, usually between 2.5 and 3.0) are ejected from the reaction. These free neutrons will then interact with the surrounding medium, and if more fissile fuel is present, some may be absorbed and cause more fissions. Thus, the cycle repeats to produce a reaction that is self-sustaining.\nNuclear power plants operate by precisely controlling the rate at which nuclear reactions occur. Nuclear weapons, on the other hand, are specifically engineered to produce a reaction that is so fast and intense it cannot be controlled after it has started. When properly designed, this uncontrolled reaction will lead to an explosive energy release.\nFuel.\nNuclear weapons employ high quality, highly enriched fuel exceeding the critical size and geometry (critical mass) necessary in order to obtain an explosive chain reaction. The fuel for energy purposes, such as in a nuclear fission reactor, is very different, usually consisting of a low-enriched oxide material (e.g. uranium dioxide, UO2). There are two primary isotopes used for fission reactions inside of nuclear reactors. \nThe first and most common is uranium-235. This is the fissile isotope of uranium and it makes up approximately 0.7% of all naturally occurring uranium. Because of the small amount of 235U that exists, it is considered a non-renewable energy source despite being found in rock formations around the world. Uranium-235 cannot be used as fuel in its base form for energy production; it must undergo a process known as refinement to produce the compound UO2. The UO2 is then pressed and formed into ceramic pellets, which can subsequently be placed into fuel rods. This is when UO2 can be used for nuclear power production. \nThe second most common isotope used in nuclear fission is plutonium-239, because it is able to become fissile with slow neutron interaction. This isotope is formed inside nuclear reactors by exposing 238U to the neutrons released during fission. As a result of neutron capture, uranium-239 is produced, which undergoes two beta decays to become plutonium-239. Plutonium once occurred as a primordial element in Earth's crust, but only trace amounts remain so it is predominantly synthetic. \nAnother proposed fuel for nuclear reactors, which however plays no commercial role as of 2021, is uranium-233, which is \"bred\" by neutron capture and subsequent beta decays from natural thorium, which is almost 100% composed of the isotope thorium-232. This is called the thorium fuel cycle.\nEnrichment process.\nThe fissile isotope uranium-235 in its natural concentration is unfit for the vast majority of nuclear reactors. In order to be prepared for use as fuel in energy production, it must be enriched. The enrichment process does not apply to plutonium. Reactor-grade plutonium is created as a byproduct of neutron interaction between two different isotopes of uranium. \nThe first step to enriching uranium begins by converting uranium oxide (created through the uranium milling process) into a gaseous form. This gas is known as uranium hexafluoride, which is created by combining hydrogen fluoride, fluorine, and uranium oxide. Uranium dioxide is also present in this process and is sent off to be used in reactors not requiring enriched fuel. The remaining uranium hexafluoride compound is drained into metal cylinders where it solidifies. The next step is separating the uranium hexafluoride from the depleted U-235 left over. This is typically done with centrifuges that spin fast enough to allow for the 1% mass difference in uranium isotopes to separate themselves. A laser is then used to enrich the hexafluoride compound. The final step involves reconverting the enriched compound back into uranium oxide, leaving the final product: enriched uranium oxide. This form of UO2 can now be used in fission reactors inside power plants to produce energy.\nReaction products.\nWhen a fissile atom undergoes nuclear fission, it breaks into two or more fission fragments. Also, several free neutrons, gamma rays, and neutrinos are emitted, and a large amount of energy is released. The sum of the rest masses of the fission fragments and ejected neutrons is less than the sum of the rest masses of the original atom and incident neutron (of course the fission fragments are not at rest). The mass difference is accounted for in the release of energy according to the equation \"E=\u0394mc2\":\nmass of released energy = formula_1\nDue to the extremely large value of the speed of light, \"c\", a small decrease in mass is associated with a tremendous release of active energy (for example, the kinetic energy of the fission fragments). This energy (in the form of radiation and heat) carries the missing mass when it leaves the reaction system (total mass, like total energy, is always conserved). While typical chemical reactions release energies on the order of a few eVs (e.g. the binding energy of the electron to hydrogen is 13.6\u00a0eV), nuclear fission reactions typically release energies on the order of hundreds of millions of eVs.\nTwo typical fission reactions are shown below with average values of energy released and number of neutrons ejected:\nformula_2\nNote that these equations are for fissions caused by slow-moving (thermal) neutrons. The average energy released and number of neutrons ejected is a function of the incident neutron speed. Also, note that these equations exclude energy from neutrinos since these subatomic particles are extremely non-reactive and therefore rarely deposit their energy in the system.\nReactor physics.\nPrompt neutron lifetime.\nThe prompt neutron lifetime, formula_3, is the average time between the emission of a neutron and either its absorption or escape from the system. The neutrons that occur directly from fission are called \"prompt\" neutrons, and the ones that are a result of radioactive decay of fission fragments are called \"delayed\" neutrons. The term \"lifetime\" is used because the emission of a neutron is often considered its \"birth\", and its subsequent absorption or escape from the core is considered its \"death\".\nFor \"thermal\" (slow-neutron) fission reactors, the typical prompt neutron lifetime is on the order of 10\u22124 seconds, and for fast fission reactors, the prompt neutron lifetime is on the order of 10\u22127 seconds. These extremely short lifetimes mean that in 1 second, 10,000 to 10,000,000 neutron lifetimes can pass. The \"average\" (also referred to as the \"adjoint unweighted\") prompt neutron lifetime takes into account all prompt neutrons regardless of their importance in the reactor core; the \"effective\" prompt neutron lifetime (referred to as the \"adjoint weighted\" over space, energy, and angle) refers to a neutron with average importance.\nMean generation time.\nThe mean generation time, \"formula_4\", is the average time from a neutron emission to a capture that results in fission. The mean generation time is different from the prompt neutron lifetime because the mean generation time only includes neutron absorptions that lead to fission reactions (not other absorption reactions). The two times are related by the following formula:\nformula_5\nIn this formula \"formula_6\" is the effective neutron multiplication factor, described below.\nEffective neutron multiplication factor.\nThe effective neutron multiplication factor formula_6 is most often quantified as the ratio of the rate of neutron production to the rate of neutron loss in a nuclear system, and it is often described using the six-factor formula. \nformula_8\nUsing formula_6 and the prompt neutron lifetime, formula_3, the following differential equation can be used to describe the time rate of change of the neutron population:\nformula_11\nWhen solved for formula_12, this equation represents the neutron population formula_13 at any given time formula_14 given an initial neutron population formula_15 at formula_16:\nformula_17\nWhen describing a nuclear reactor, where neutron population is directly proportional to thermal power, the following equation is used:\nformula_18\nwhere formula_19 is the reactor power at time formula_14, given an initial power formula_21, and formula_22, the reactor period. The value of formula_22 can be calculated as\nformula_24\nSix-factor formula.\nThe effective neutron multiplication factor formula_6 can be described using the product of six probability factors that describe a nuclear system. These factors, traditionally arranged chronologically with regards to the life of a neutron in a thermal reactor, include the probability of fast non-leakage formula_26, the fast fission factor formula_27, the resonance escape probability formula_28, the probability of thermal non-leakage formula_29, the thermal utilization factor formula_30, and the neutron reproduction factor formula_31 (also called the neutron efficiency factor). The six-factor formula is traditionally written as follows:\nformula_32\nWhere:\nThe multiplication factor is sometimes calculated with a simplified four-factor formula, which is the same as described above with formula_26 and formula_29 both equal to 1, and is used when an assumption is made that the reactor is \"infinite\" in that neutrons are very unlikely to leak out of the system. This value formula_43 is often used in safety evaluations of reactor designs.\nCriticality.\nBecause the value of formula_6 is directly related to the time rate of change of the neutron population in a system, it is convenient to classify the state of the nuclear system with regards to the critical value of the neutron population equation. The point at which the behavior of a nuclear system shifts is when formula_6 is exactly equal to 1. This point is called \"criticality,\" and describes a system in which the production rate and loss rate of neutrons is exactly equal.\nWhen formula_6 is less than or greater than one, the terms subcriticality and supercriticality are used respectively to describe the system:\nIn a practical nuclear system, like a fission reactor, if criticality is intended it is likely that formula_6 will actually oscillate from slightly less than 1 to slightly more than 1, primarily due to thermal feedback effects. The neutron population, when averaged over time, appears constant, leaving the average value of formula_6 at around 1 during a constant power run. Both delayed neutrons and the transient fission product \"burnable poisons\" play an important role in the timing of these oscillations.\nReactivity.\nThe value of formula_6 is generally not easy to calculate or use practically. Instead, a system's reactivity is quantified instead. The reactivity of a nuclear system is qualitatively described as the departure from criticality. The equation below describes the pure reactivity formula_53 as a function of the neutron multiplication factor formula_6:\nformula_55\nor when comparing the reactivity differences between two nuclear systems with multiplication factors formula_56 and formula_57,\nformula_58\nFor most systems, the reactivity formula_53 has a very small range, making any value difficult to qualitatively describe or interpret, like formula_6. Often, it is expressed in units of formula_61, per cent mille, or (almost solely in the United States) with the derived units of dollars and cents. Note that formula_53 is often also expressed as formula_63\nformula_64\nformula_65\nformula_66\nThe value formula_67 is known as the effective delayed neutron fraction, and it describes the fractional contribution of delayed neutrons to the fission rate of the system and is quantified as the ratio of the total number of fissions caused by delayed neutrons to the total number of fissions in a system. This number is slightly different than the delayed neutron fraction formula_68, which is the fraction of neutrons in the system that are delayed, because delayed neutrons are generally born at lower energies, and thus are easier to thermalize, meaning they are more likely to cause a fission than a prompt neutron. This weighting effect is given in the derivation of formula_67.\nSubcritical multiplication.\nWhen a nuclear system is subcritical, an introduction of neutrons to the system will result in that population decaying away; however, if neutrons are introduced at a constant rate (i.e. from a neutron source), a nuclear system can appear critical while not actually maintaining true criticality. This is called source criticality and due to a phenomenon called subcritical multiplication.\nThe neutron population equation can be modified to be written as follows:\nformula_70\nWe take the above equation and define a new factor formula_71, called the subcritical multiplication factor:\nformula_72\nMultiplying this factor by the source strength (in neutrons/sec) will give the stable neutron population, as long as formula_6 is known:\nformula_74\nMuch more commonly, this equation is used to estimate formula_6, as the stable neutron population is easy to measure, but it is difficult to know the strength of a neutron source. To get around this, as a system approaches criticality, formula_71 approaches infinity; therefore, it is much more practical to measure formula_77, which approaches zero as a system approaches criticality. formula_77 can be approximated by the ratio of count rates before and after a reactivity addition. \nformula_79\nMost neutron sources are a combination of an alpha particle emitter and beryllium. Beryllium-9, the only naturally occurring stable isotope of beryllium, is capable of emitting a neutron when an alpha particle is absorbed. This (formula_80) binary reaction is what generates neutrons. The most common of these are americium-beryllium (AmBe), plutonium-beryllium (PuBe), and polonium-beryllium (PoBe) sources.\n&lt;chem&gt;{^9_4 Be} + {^4_2 \\alpha} \\Rightarrow {^1_0 n} + {^{12}_{6} C}&lt;/chem&gt;\nAntimony-124 is also used in conjunction with beryllium to generate neutrons, as the gamma ray emitted by antimony-124 is at a unique energy that can be absorbed by beryllium and cause it to emit a neutron. This is called a (formula_81) reaction. Antimony-124 sources are commonly used to locate beryllium ore by mining companies. \n&lt;chem&gt;{^9_4 Be} + {\\gamma} \\Rightarrow {^1_0 n} + {^{8}_{4} Be}&lt;/chem&gt;\nOther sources of neutrons are from accelerators that use fusion to generate neutrons using deuterium and tritium fusion via this reaction\n&lt;chem&gt;{^2_1 D} + {^2_1 D} \\Rightarrow {^1_0 n} + {^3_2 He}&lt;/chem&gt;\n&lt;chem&gt;{^2_1 D} + {^3_1 T} \\Rightarrow {^1_0 n} + {^4_2 He}&lt;/chem&gt;\nSpecial reactivity cases.\nNot all neutrons are emitted as a direct product of fission; some are instead due to the radioactive decay of some of the fission fragments. The neutrons that occur directly from fission are called \"prompt neutrons\", and the ones that are a result of radioactive decay of fission fragments are called \"delayed neutrons\". The fraction of neutrons that are delayed is called formula_68, as discussed before, and this fraction is typically less than 1% of all the neutrons in the chain reaction.\nAs the delayed neutron precursors (the radionuclides that decay via neutron emission) have decay constants on the order of seconds and milliseconds, the delayed neutrons born from them allow the neutron population in a system to respond to small reactivity changes several orders of magnitude more slowly than just prompt neutrons would alone, as these delayed neutrons effectively increase the mean neutron lifetime formula_3. Without delayed neutrons, changes in reaction rates in nuclear systems would occur at speeds that are too fast for humans to control.\nWhen formula_84 and formula_85, a nuclear system is called delayed critical. The region of supercriticality where formula_86 is known as delayed supercriticality. It is in this region that all nuclear power reactors operate. When formula_87, the system is described as prompt critical. The region of supercriticality for formula_88 is known as prompt supercriticality. This is the region in which nuclear weapons operate, alongside some pulsing nuclear research reactors, like the TRIGA reactor.\nNuclear weapons.\nNuclear fission weapons require a mass of fissile fuel that is prompt supercritical. For a given mass of fissile material the value of \"k\" can be increased by increasing the density. Since the probability per distance travelled for a neutron to collide with a nucleus is proportional to the material density, increasing the density of a fissile material can increase \"k\". This concept is utilized in the implosion method for nuclear weapons. In these devices, the nuclear chain reaction begins after increasing the density of the fissile material with a conventional explosive.\nIn a gun-type fission weapon, two subcritical masses of fuel are rapidly brought together. The value of \"k\" for a combination of two masses is always greater than that of its components. The magnitude of the difference depends on distance, as well as the physical orientation. The value of \"k\" can also be increased by using a neutron reflector surrounding the fissile material.\nOnce the mass of fuel is prompt supercritical, the power increases exponentially. However, the exponential power increase cannot continue for long since \"k\" decreases when the amount of fission material that is left decreases (i.e. it is consumed by fissions). Also, the geometry and density are expected to change during detonation since the remaining fission material is torn apart from the explosion.\nPredetonation.\nDetonation of a nuclear weapon involves bringing fissile material into its optimal supercritical state very rapidly (about one microsecond, or one-millionth of a second). During part of this process, the assembly is supercritical, but not yet in an optimal state for a chain reaction. Free neutrons, in particular from spontaneous fissions, can cause the device to undergo a preliminary chain reaction that destroys the fissile material before it is ready to produce a large explosion, which is known as predetonation.\nTo keep the probability of predetonation low, the duration of the non-optimal assembly period is minimized, and fissile and other materials are used that have low spontaneous fission rates. In fact, the combination of materials has to be such that it is unlikely that there is even a single spontaneous fission during the period of supercritical assembly. In particular, the gun method cannot be used with plutonium.\nNuclear power plants and control of chain reactions.\nChain reactions naturally give rise to reaction rates that grow (or shrink) exponentially, whereas a nuclear power reactor needs to be able to hold the reaction rate reasonably constant. To maintain this control, the chain reaction criticality must have a slow enough time scale to permit intervention by additional effects (e.g., mechanical control rods or thermal expansion). Consequently, all nuclear power reactors (even fast-neutron reactors) rely on delayed neutrons for their criticality. An operating nuclear power reactor fluctuates between being slightly subcritical and slightly delayed-supercritical, but must always remain below prompt-critical.\nIt is impossible for a nuclear power plant to undergo a nuclear chain reaction that results in an explosion of power comparable with a nuclear weapon, but even low-powered explosions from uncontrolled chain reactions (that would be considered \"fizzles\" in a bomb) may still cause considerable damage and meltdown in a reactor. For example, the Chernobyl disaster involved a runaway chain reaction, but the result was a low-powered steam explosion from the relatively small release of heat, as compared with a bomb. However, the reactor complex was destroyed by the heat, as well as by ordinary burning of the graphite exposed to air. Such steam explosions would be typical of the very diffuse assembly of materials in a nuclear reactor, even under the worst conditions.\nIn addition, other steps can be taken for safety. For example, power plants licensed in the United States require a negative void coefficient of reactivity (this means that if coolant is removed from the reactor core, the nuclear reaction will tend to shut down, not increase). This eliminates the possibility of the type of accident that occurred at Chernobyl (which was caused by a positive void coefficient). However, nuclear reactors are still capable of causing smaller chemical explosions even after complete shutdown, such as was the case of the Fukushima Daiichi nuclear disaster. In such cases, residual decay heat from the core may cause high temperatures if there is loss of coolant flow, even a day after the chain reaction has been shut down (see SCRAM). This may cause a chemical reaction between water and fuel that produces hydrogen gas, which can explode after mixing with air, with severe contamination consequences, since fuel rod material may still be exposed to the atmosphere from this process. However, such explosions do not happen during a chain reaction, but rather as a result of energy from radioactive beta decay, after the fission chain reaction has been stopped.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22135", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=22135", "title": "Nichiren", "text": "Japanese Buddhist monk and philosopher (1222\u20131282)\n was a Japanese Buddhist monk and philosopher of the Kamakura period. His teachings form the basis of Nichiren Buddhism, a unique branch of Japanese Mahayana Buddhism based on the \"Lotus Sutra\".\nNichiren declared that the \"Lotus Sutra\" alone contains the highest truth of Buddhism and that it is the only sutra suited for the Age of Dharma Decline. He insisted that the sovereign of Japan and its people should support only this form of Buddhism and eradicate all others, or they would face social collapse and environmental disasters. Nichiren advocated the faithful recitation of the title of the \"Lotus Sutra\", \"Namu My\u014dh\u014d Renge Ky\u014d\", as the only effective path to Buddhahood in this very life, a path which he saw as accessible to all people regardless of class, education or ability. Nichiren held that Shakyamuni and all other Buddhist deities were manifestations of the Original Eternal Buddha (\u672c\u4ecf \"Honbutsu\") of the \"Lotus Sutra\", which he equated with the \"Lotus Sutra\" itself and its title. He also declared that believers of the \"Lotus Sutra\" must propagate it even though this would lead to many difficulties and even persecution, which Nichiren understood as a way of \"reading\" the \"Lotus Sutra\" with one's very body. Nichiren believed that the spread of the \"Lotus Sutra\" teachings would lead to the creation of a Pure Land on earth.\nNichiren was a prolific writer and his biography, temperament, and the evolution of his beliefs has been gleaned primarily from his writings. He claimed to be the reincarnation of bodhisattva Vi\u015bi\u1e63\u1e6dac\u0101ritra (\"J\u014dgy\u014d\"), and designated six senior disciples, which later led to much disagreement after his death. Nichiren's harsh critiques of the Buddhist establishment led to many persecutions against him and his followers. He was exiled twice and some of his followers were imprisoned or killed. After his death, Nichiren\u2019s followers continued to grow, making it one of Japan's largest Buddhist traditions. He was posthumously bestowed the title by the Emperor Go-K\u014dgon in 1358. The title was also later conferred by the Emperor Taish\u014d in 1922.\nNichiren Buddhism today includes more than forty different officially registered organizations, some of which have significant international presence. These include traditional temple schools such as Nichiren-sh\u016b sects and Nichiren Sh\u014dsh\u016b, as well as modern lay movements such as Soka Gakkai, Rissh\u014d K\u014dsei Kai, Reiy\u016bkai, Kensh\u014dkai, Honmon Butsury\u016b-sh\u016b, Kempon Hokke, and Sh\u014dshinkai among many others. Each group has varying views of Nichiren's teachings, some being more exclusivist than the others. Some see Nichiren as being the Bodhisattva Vi\u015bi\u1e63\u1e6dac\u0101ritra, while other sects claim that Nichiren was actually the .\nLife.\nThe main narrative of Nichiren's life has been constructed from extant letters and treatises he wrote, counted in one collection as 523 complete writings and 248 fragments. Aside from historical documents stored in the repositories of various Nichiren sects, the first extensive non-religious biographical account of Nichiren did not appear until more than 200 years after his death. Several hagiographies about Nichiren and are reflected in various pieces of artwork about incidents in his life.\nNichiren is most well known for his promotion of \"Lotus Sutra\" devotion over and above all other Buddhist scriptures and teachings. He held that reciting the title of the \"Lotus Sutra\" (with the formula \"Nam(u)-myoho-renge-kyo\") encompassed all Buddhist teachings, and thus it could lead to enlightenment in this life. As a result of his adamant stance, he experienced severe persecution imposed by the Kamakura Shogunate, which Nichiren saw as proof of the righteousness of his cause to spread the \"Lotus Sutra\".\nNichiren remains a controversial figure among scholars who cast him as either a fervent nationalist or a social reformer with a transnational religious vision. Critical scholars have used words such as intolerant, nationalistic, militaristic, and self-righteous to portray him. On the other hand, Nichiren has been presented as a revolutionary, a classic reformer, and as a prophet. Nichiren is often compared to other religious figures who shared similar rebellious and revolutionary drives to reform degeneration in their respective societies or schools.\nBirth.\nAccording to the lunar Chinese calendar, Nichiren was born on 16th of the second month in 1222, which is 6 April in the Gregorian calendar.\nNichiren was born in the village of Kominato (today part of the city of Kamogawa), Nagase District, Awa Province (within present-day Chiba Prefecture). Accounts of his lineage vary. Nichiren described himself as \"the son of a \"Sendara\" (\"Skt: chandala\", despised outcast), \"a son born of the lowly people living on a rocky strand of the out-of-the-way sea,\" and \"the son of a sea-diver.\" In contrast, H\u014dnen, Shinran, D\u014dgen, and Eisai, the other founders of religious schools who predated Nichiren, were all born in the Kyoto region and came from noble or samurai backgrounds. Although his writings reflect a fierce pride of his lowly birth, followers after his death began to ascribe to him a more noble lineage, perhaps to attract more adherents. Some have claimed his father was a r\u014dnin, a manorial functionary (\"shokan\"), or a political refugee.\nNichiren's father was Mikuni-no-Tayu Shigetada, also known as Nukina Shigetada Jiro (died 1258); and his mother was Umegiku-nyo (died 1267). On his birth, his parents named him which has variously been translated into English as \"Splendid Sun\" and \"Virtuous Sun Boy\" among others. The exact site of Nichiren's birth is believed to be currently submerged off the shore from present-day near a temple in Kominato that commemorates his birth.\nBuddhist education.\nAt the age of 12 he began his Buddhist study at a temple of the Tendai school, . He was formally ordained as a novice at sixteen years old to became a monk at twenty years old and took the Buddhist name , \"Rench\u014d\" meaning \"Lotus Growth\".\nBetween the years 1233 and 1253 Nichiren studied the major Buddhist traditions in Japan at that time, including Tendai, Pure Land Buddhism and Shingon. During these years, he became convinced of the preeminence of the \"Lotus Sutra\" and in 1253 returned to the temple where he first studied to present his findings.\nIn a 1271 letter Nichiren writes of this time of his life:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nHe later left Seich\u014d-ji for Kamakura where he studied Pure Land Buddhism, a school that stressed salvation through the invocation of the name Amit\u0101bha (Japanese \"Amida\"), a practiced called nembutsu. He also studied Zen which had been growing in popularity in both Kamakura and Kyoto. He next traveled to Mount Hiei, the center of Japanese Tendai Buddhism, where he scrutinized the school's original doctrines, including Pure Land and Tendai Esoteric Buddhism. In the final stage of this twenty-year period he traveled to Mount K\u014dya, the center of Shingon esoteric Buddhism, and to Nara where he studied its six established schools, especially the Ritsu sect which emphasized strict monastic discipline.\nDeclaration of the \"Lotus Sutra\".\nAccording to one of his letters, Nichiren returned to Seicho-ji Temple on 28 April 1253 to lecture on the supremacy of the \"Lotus Sutra.\" What followed was his first public declaration of \"Nam(u) Myoho Renge Kyo\" atop Mount Kiyosumi that same day. This marked the start of his campaign to convince the Tendai tradition to shift its focus back to the \"Lotus Sutra\" and his efforts to convert the entire Japanese nation to this belief. This declaration also marks the start of his efforts to make profound Buddhist theory practical and actionable so an ordinary person could manifest Buddhahood within his or her own lifetime in the midst of day-to-day realities.\nAt the same event, according to his own account and subsequent hagiography, he changed his name to \"Nichiren\", an abbreviation of and . \"Nichi\" represents both the light of truth and the sun goddess Amaterasu, symbolizing Japan itself. \"Ren\" signifies the \"Lotus Sutra\". Nichiren envisioned Japan as the country where the true teaching of Buddhism would be revived and the starting point for its worldwide spread.\nAt his lecture, it is construed, Nichiren vehemently attacked Honen, the founder of Pure Land Buddhism, and its practice of chanting the Nembutsu. It is likely he also denounced the nembutsu teachings found at Seicho-ji. In so doing he earned the animosity of the local steward, Tojo Kagenobu, and eventually Nichiren was forced to leave the temple. Modern scholarship suggests that events unfolded not in a single day but over a longer period of time and had social, and political dimensions.\nNichiren then moved to a hermitage in the hills around Kamakura. From there he converted several Tendai priests, directly ordained others, and attracted lay disciples who were drawn mainly from the strata of the lower and middle samurai class. Their households provided Nichiren with economic support and became the core Nichiren communities in several locations in the Kanto region of Japan.\nFirst remonstration to the Kamakura government.\nNichiren arrived in Kamakura in 1254. Between 1254 and 1260 half of the population had perished due to a tragic succession of calamities that included drought, earthquakes, epidemics, famine, fires, and storms. Nichiren sought scriptural references to explain the unfolding of natural disasters and then wrote a series of works which, based on the Buddhist theory of the non-duality of the human mind and the environment, attributed the sufferings to the weakened spiritual condition of people, thereby causing the \"Kami\" (protective forces or traces of the Buddha) to abandon the nation. The root cause of this, he argued, was the widespread decline of the Dharma due to the mass adoption of the exclusive nembutsu teachings of H\u014dnen.\nThe most renowned of these works, considered his first major treatise, was the , \"On Securing the Peace of the Land through the Propagation of True Buddhism.\" Nichiren submitted it to H\u014dj\u014d Tokiyori, the \"de facto\" leader of the Kamakura shogunate, as a political move to effectuate radical reform. In it he argued the necessity for \"the Sovereign to recognize and accept the singly true and correct form of Buddhism (i.e., ) as the only way to achieve peace and prosperity for the land and its people and end their suffering (i.e., ).\"\nUsing a dialectic form well-established in China and Japan, the treatise is a 10-segment fictional dialogue between a Buddhist wise man, presumably Nichiren, and a visitor who together lament the tragedies that have beleaguered the nation. The wise man answers the guest's questions and, after a heated exchange, gradually leads him to enthusiastically embrace the vision of a country grounded firmly on the ideals of the \"Lotus Sutra\". In this writing Nichiren displays a skill in using analogy, anecdote, and detail to persuasively appeal to an individual's unique psychology, experiences, and level of understanding.\nThe teacher builds his argument by quoting extensively from a set of Buddhist sutras and commentaries. In his future writings Nichiren continued to draw from the same sutras and commentaries which he deemed supportive of the \"Lotus Sutra\", including the \"Konkomyo, Daijuku, Ninno, Yakushi,\" and \"Nirvana\" sutras. They share in common themes like prophecies of Dharma decline and nation-protecting teachings. The \"Rissh\u014d Ankoku Ron\" concludes with an urgent appeal to the ruler to cease all financial support for Buddhist schools promoting inferior teachings. Otherwise, Nichiren warns, as predicted by the sutras, the continued influence of inferior teachings would invite even more natural disasters as well as the outbreak of civil strife and foreign invasion.\nNichiren submitted his treatise on 16 July 1260 but it drew no official response. It did, however, prompt a severe backlash from the Buddhist priests of other schools. Nichiren was challenged to a religious debate with leading Kamakura prelates in which, by his account, they were swiftly dispatched. Their lay followers then formed a mob and attacked Nichiren at his dwelling, forcing him to flee Kamakura. His critics had influence with key governmental figures and spread slanderous rumors about him. One year after he submitted the \"Rissho Ankoku Ron\" the authorities had him arrested and exiled to the Izu peninsula.\nNichiren's Izu exile lasted two years. In his extant writings from this time period, Nichiren began to strongly draw from chapters 10\u201322 of the \"Lotus Sutra\", what Tanabe calls its \"third realm\" \"(daisan h\u014dmon)\". Nichiren began to emphasize the purpose of human existence as being the practice of the bodhisattva ideal in the real world which entails undertaking struggle and manifesting endurance. He suggested that he is a model of this behavior, a \"votary\" (\"gy\u014dja\") of the Lotus Sutra.\nUpon being pardoned in 1263 Nichiren returned to Kamakura. In November 1264 he was ambushed and nearly killed at Komatsubara in Awa Province by a force led by Lord T\u014dj\u014d Kagenobu. He suffered a broken arm and a sword cut across his forehead, and one of his followers was killed. For the next few years he preached in provinces outside of Kamakura but returned in 1268. At this point the Mongols sent envoys to Japan demanding tribute and threatening invasion. Nichiren sent 11 letters to influential leaders reminding them about his predictions in the \"Rissho Ankoku Ron\".\nAttempt at execution.\nThe threat of Mongol invasion was the worst crisis in pre-modern Japanese history. In 1269 Mongol envoys again arrived to demand Japanese submission to their hegemony and the \"bakufu\" responded by mobilizing military defenses. The role of Buddhism in \"nation-protection\" (\"chingo kokka\") was long established in Japan at this time and the government galvanized prayers from Buddhist schools for this purpose. Nichiren and his followers, however, felt emboldened that the predictions he had made in 1260 of foreign invasion seemingly were being fulfilled. Nichiren redoubled his efforts and continued to give regular lectures as more people joined the movement. Daring a rash response from the \"bakufu\", Nichiren vowed in letters to his followers that he was giving his life to actualize the \"Lotus Sutra\". He accelerated his polemics against the non-Lotus teachings the government had been patronizing at the very time it was attempting to solidify national unity and resolve. In a series of letters to prominent leaders he directly provoked the major prelates of Kamakura temples that the Hojo family patronized, criticized the principles of Zen which was popular among the samurai class, critiqued the esoteric practices of Shingon just as the government was invoking them, and condemned the ideas underlying Rissh\u016b as it was enjoying a revival.His actions at that time have been described by modern scholars either as a high form of altruism, or the ravings of a fanatic.\nHis claims drew the ire of the influential religious figures of the time and their followers, especially the Shingon priest . In September 1271, after a fiery exchange of letters between the two, Nichiren was arrested by a band of soldiers and tried by , the deputy chief of the Hojo clan's Board of Retainers. Nichiren considered this as his second remonstration to the government.\nAccording to Nichiren's own account, he was sentenced to exile but was brought to Tatsunukuchi beach in Shichirigahama for execution. According to some traditional accounts, the execution was stopped at the final moment as \"a brilliant orb as bright as the moon\" arced over the execution grounds, terrifying Nichiren's executioners. Modern scholars have proposed alternative narratives for this story and question its historicity. Whatever the case, Nichiren himself believed he had undergone a transformative experience. After this event, Nichiren was exiled to Sado Island. This incident has become known as the \"Tatsunokuchi Persecution\" and was regarded by Nichiren as a death-and-resurrection turning point. In the Nichiren tradition this is called his moment of , translated as \"casting off the transient and revealing the true\" or \"outgrowing the provisional and revealing the essential.\"\nSecond banishment and exile.\nNichiren was then exiled to a second location, on Sado Island in the Sea of Japan. Upon arriving, he was dispatched to a small dilapidated temple located in a graveyard. Nichiren was accompanied by a few disciples and in the first winter they endured terrible cold, food deprivation, and threats from local inhabitants. Nichiren scholars describe a clear shift in both tone and message in letters written before his Sado exile and those written during and after. Initially, Nichiren's urgent concern was to rally his followers in Kamakura. The tactics of the \"bakufu\" suppression of the Nichiren community included exile, imprisonment, land confiscation, or ousting from clan membership. Apparently a majority of his disciples abandoned their faith and others questioned why they and Nichiren were facing such adversity in light of the \"Lotus Sutra\"'s promise of \"peace and security in the present life.\"\nIn some of his writings during a second exile (1271\u20131274), Nichiren began to identify himself with two major \"Lotus Sutra\" bodhisattvas: Sad\u0101paribh\u016bta and Vi\u015bi\u1e63\u1e6dac\u0101ritra. Sad\u0101paribh\u016bta (\"Never Despising\") is a key figure in the \"Lotus Sutra\", who in the 20th chapter invited repeated persecution in his efforts to propagate the sutra by paying homage to everyone he meets and telling them they will be a Buddha. His hardship, Nichiren argued, fulfilled and validated the \"Lotus Sutra\". He thus began to see himself as \"bodily reading the Lotus Sutra (\"Jpn. Hokke shikidoku\"), which meant that due to his attempts to teach the \"Lotus Sutra\" and the hardships he faced, he was re-enacting the practices of Sad\u0101paribh\u016bta bodhisattva. Nichiren also identified himself with the bodhisattva Vi\u015bi\u1e63\u1e6dac\u0101ritra (\"Superior Practice\") to whom Shakyamuni entrusted the future propagation of the \"Lotus Sutra,\" seeing himself in the role of leading a vast outpouring of Bodhisattvas of the Earth who pledged to liberate the oppressed. \nThe numerous letters and minor treatises he wrote in Sado include what is considered his two most significant works, the and the . The former text discusses the practice of daimoku as a form of \"mind contemplation\" (kanjin \u89b3\u5fc3), which is the appropriate practice for the Age of Dharma Decline. In the latter text he stated that facing adversity should be regarded as a matter of course and that the resolve to carry on with the mission to propagate the sutra was for him more important than guarantees of protection: \"Let Heaven forsake me. Let ordeals confront me. I will not begrudge bodily life... . No matter what trials we may encounter, so long as we do not have a mind of doubt, I and my disciples will naturally achieve the Buddha realm.\" He concluded this work with the vow to be the \"pillar of Japan, the eyes of Japan, the great ship of Japan.\"\nThe Mandala Gohonzon.\nAt the end of the 1271\u20131272 winter Nichiren's conditions had improved. He had attracted a small band of followers in Sado who provided him with support and disciples from the mainland began visiting him and providing supplies. In 1272 there was an attempted coup in Kamakura and Kyoto, seemingly fulfilling the prediction he had made in the \"Rissho Ankoku Ron\" of rebellion in the country. At this point Nichiren was transferred to much better accommodations.\nWhile on Sado island, Nichiren inscribed the first Mandala . Although there is evidence of a Gohonzon in embryonic form as far back as the days right before his exile, the first in full form is dated to 8 July 1273 and includes the inscription of \"Nichiren inscribes this for the first time.\" His writings on Sado provide his rationale for a calligraphic mandala depicting the assembly at Vulture Peak (\"G\u1e5bdhrak\u016b\u1e6da\") which was to be used as an object of devotion or worship. Nichiren found doctrinal rational for this in the 16th (\"Life span\") chapter of the \"Lotus Sutra\". It is at this time that he developed the concept of a three-fold \"secret Dharma\" of the \"daimoku\", the object of worship (\"honzon\"), and the ordination platform (\"kaidan\").\nAt the bottom of each mandala he wrote: \"This is the great mandala never before revealed in Jambudvipa during the more than 2,200 years since the Buddha's nirvana.\" He inscribed many Mandala Gohonzon during the rest of his life. More than a hundred Mandala Gohonzon preserved today are attributed to Nichiren's own hand.\nReturn to Kamakura.\nIn 1274, after his two predictions of foreign invasion and political strife were seemingly actualized by the first attempted Mongol invasion of Japan along with an unsuccessful coup within the H\u014dj\u014d clan, Nichiren was pardoned by the Shogunate authorities.The pardon came in effect on 14 February 1274 and Nichiren returned to Kamakura one month later on March 26. Nichiren wrote that his innocence and the accuracy of his predictions caused the regent H\u014dj\u014d Tokimune to intercede on his behalf. Scholars have suggested that some of his well-connected followers might have had influence on the government's decision to release him.\nOn 8 April he was summoned by Hei no Saemon, who inquired about the timing of the next Mongol invasion. Nichiren predicted that it would occur within the year. He used the audience as yet another opportunity to remonstrate with the government. Claiming that reliance on prayers based on esoteric rituals would invite further calamity, he urged the \"bakufu\" to ground itself exclusively on the Lotus Sutra.\nDeeply disappointed by the government's refusal to heed his advice, Nichiren left Kamakura one month later, on 12 May, determined to become a solitary wayfarer. Five days later, however, on a visit to the residence of Lord Hakii Sanenaga of Mt. Minobu, he learned that followers in nearby regions had held steadfast during his exile. Despite severe weather and deprivation, Nichiren remained in Minobu for the rest of his career.\nRetirement to Mount Minobu.\nDuring his self-imposed exile at Mount Minobu, a location in Kai province, 100 miles west of Kamakura. Nichiren led a widespread movement of followers in Kanto and Sado mainly through his prolific letter-writing. During the so-called \"Atsuhara affair\" of 1279 when governmental attacks were aimed at Nichiren's followers rather than himself, Nichiren's letters reveal an assertive and well-informed leader who provided detailed instructions through a sophisticated network of disciples serving as liaisons between Minobu and other affected areas in Japan. He also showed the ability to provide a compelling narrative of events that gave his followers a broad perspective of what was unfolding.\nMore than half of the extant letters of Nichiren were written during his years at Minobu. Some consisted of moving letters to followers expressing appreciation for their assistance, counseling on personal matters, and explaining his teachings in more understandable terms. Two of his works from this period, the and the constitute, along with his \"Rissh\u014d Ankoku Ron\" (\"On Establishing the Correct Teaching for the Peace of the Land\"), \"Kaimoku Sh\u014d\" (\"The Opening of the Eyes\"), and \"Kanjin no Honzon Sh\u014d\" (\"The Object of Devotion for Observing the Mind\"), what is commonly regarded as his five major writings.\nDuring his years at Minobu Nichiren intensified his attacks on that had been incorporated into the Japanese Tendai school. It becomes clear at this point that he understood that he was creating his own form of Lotus Buddhism. Nichiren and his disciples completed the in 1281. In the 19th century this structure burned down to be replaced by a new structure completed in the second half of the Meiji era.\nWhile at Minobu Nichiren also inscribed numerous Mandala Gohonzon for bestowal upon specific disciples and lay believers. Nichiren Shoshu believers claim that after the execution of the three Atsuhara farmers he inscribed the \"Dai Gohonzon\" on 12 October 1279, a Gohonzon specifically addressed to all humanity. This assertion has been disputed by other schools as historically and textually incorrect. It is apparent that Nichiren took great care in deciding which of his disciples were eligible to receive a Gohonzon inscribed by him. In the case of a letter written to Lady Niiama he took great care to explain why he would not inscribe a Gohonzon despite a deep personal bond. Among the Gohonzon he inscribed were several that were quite large and perhaps intended for congregational use in chapels maintained by some lay followers.\nDeath.\nIn 1282, after years of seclusion, Nichiren fell ill. His followers encouraged him to travel to the hot springs in Hitachi for their medicinal benefits. He was also encouraged by his disciples to travel there for the warmer weather, and to use the land offered by Hagiri Sanenaga for recuperation. En route, unable to travel further, he stopped at the home of a disciple in Ikegami, outside of present-day Tokyo, and died on 13 October 1282. According to legend, he died in the presence of fellow disciples after having spent several days lecturing from his sickbed on the Lotus Sutra, writing a final letter, and leaving instructions for the future of his movement after his death, namely the designation of the six senior disciples. His funeral and cremation took place the following day.\nHis disciples left Ikegami with Nichiren's ashes on 21 October, reaching back to Minobu on 25 October.\nTeachings.\nNichiren's teachings developed over the course of his career and their evolution can be seen through the study of his writings as well as in the annotations he made in his personal copy of the \"Lotus Sutra\", the so-called \"Ch\u016b-hokeky\u014d\". Some scholars set a clear demarcation in his teachings divided by his arrival on Sado Island, whereas others see a threefold division of thought: (1) up to and through the Izu exile, (2) from his return to Kamakura through the Sado Island exile, and (3) during his years at Minobu. According to Anesaki, Nichiren, upon his arrival at Minobu, quickly turned his attention to consolidating his teachings toward their perpetuation. The scope of his thinking was outlined in an essay , considered by Nikk\u014d Sh\u014dnin as one of Nichiren's ten major writings.\nNichiren's main ideas include an affirmation of the supremacy of the \"Lotus Sutra\" and the eternal Buddha of the \"Lotus Sutra\", the fact that all beings could achieve Buddhahood in this life, the centrality of the daimoku as the best practice for mapp\u014d, and the importance of spreading the teachings of the \"Lotus Sutra\". Nichiren's vision of widely and extensively spreading the \"Lotus Sutra\" (Kosen-rufu) looks towards a time when the teachings would be widely spread throughout the world. Nichiren also set a precedent for Buddhist activism centuries before its emergence in other Buddhist schools. He held adamantly that his teachings would permit a nation to right itself and ultimately lead to world peace.\nSome of his religious thinking was derived from the Tendai tradition and the works of Chinese Tiantai masters Zhiyi and Zhanran, as well as from new perspectives that were products of Kamakura Buddhism. Other ideas were completely original and unique to Nichiren.\nThe Final Age and the state of Japan.\nThe Kamakura period (1185-1333) was characterized by a sense of decline and foreboding. Nichiren, as well as the others of this time, believed that they had entered the Age of Dharma Decline or the \"Final Dharma Age\" (Mapp\u014d). The Kamakura period, a time of natural disasters, internal strife, wars, and political conflict, gave many Japanese the impression that the era of decline had begun. According to various Mahayana sutras, during the age of decline, most of the Buddha's teachings would be lost or lose their efficacy. Nichiren held that since Japan had entered Mapp\u014d, teachings like nembutsu, Zen and esoteric practices were no longer effective \u2013 only \"Lotus Sutra\" practices were effective.\nNichiren also believed that the world had entered the final age of degeneration. Like many Buddhists of his time, he held that this was a reflection of the degenerate state of the minds of the people. This is based on the classic Mahayana theory that says that the world is a reflection of the collective karmic traces of the minds of all beings living in the world. For Nichiren, the activities of the Japanese elite had caused the current state of chaos. Furthermore, Nichiren held that due to their lack of virtue, Japan was being abandoned by the gods, leading to the natural disasters which were occurring and to the threat of Mongol invasion. Japan had a long-established system of folk beliefs (now called Shinto) based on local Kami (indigenous deities). These had been adopted by Buddhist traditions, who often argued that \"kami\" were 'traces' of the Buddha. Buddhists institutions often engaged in rites calling on Kami as well as on Buddhist deities, to protect the nation (\"chingo kokka\"). Nichiren argued that the various protective deities had abandoned Japan because the court and the people had turned away from the true Dharma of the \"Lotus Sutra\" to false teachings. Thus, if the government and the people turned to the true Dharma, society would transform into an ideal world in which peace and wisdom prevail and \"the wind will not thrash the branches nor the rain fall hard enough to break clods.\"\nAlthough Nichiren attributed the turmoils and disasters in society to the widespread practice of what he deemed inferior Buddhist teachings sponsored by the government, he was also enthusiastically upbeat about the portent of the age. He asserted, in contrast to other schools, Mapp\u014d was the best possible time to be alive, since now the Bodhisattvas of the Earth would appear teach and spread the \"Lotus Sutra.\"\nFive Principles.\nNichiren also taught Five Principles (\"gogi\") or five criteria for evaluating Buddhist teachings and establishing the supremacy of the \"Lotus Sutra\" as the highest and best teaching for Japan at his time. The five are:\nBuddhahood and the mutual inclusion of all realms.\nNichiren stressed the idea that the Buddha's Pure Land is immanent in this present world (\"shaba soku jakk\u014ddo\") and that all beings have the innate potential to attain Buddhahood in this very body (\"sokushin j\u014dbutsu\"), though this can only be achieved by relying on the \"Lotus Sutra\". Nichiren was influenced by earlier ideas taught by K\u016bkai and Saich\u014d, who had taught the possibility of becoming a Buddha in this life and the belief all beings are \"originally enlightened\" (\"hongaku\").\nIn the Tendai school, these theories were also closely related to Zhiyi's theory of the \"mutual inclusion of the ten Dharma-realms\" (\"jikkai gogu\" \u5341\u754c\u4e92\u5177), also called Three Thousand Realms in a Single Thought (\"ichinen sanzen\" \u4e00\u5ff5\u4e09\u5343), as well as on Zhanran's view of the all-pervasive character of Buddha-nature. As Jacqueline Stone writes \"\"ichinen sanzen\" means that the smallest phenomenon (a single thought-moment) and the entire cosmos (three thousand realms) are mutually encompassing: the one and the many; good and evil; delusion and awakening; subject and object; self and other; and all sentient beings from hell dwellers, hungry ghosts, and animals up through bodhisattvas and buddhas, as well as their respective environments, simultaneously interpenetrate and encompass one another without losing their individual identity.\" This realization is itself the wisdom of the Buddha, and the \"Wonderful Dharma\" (my\u014dh\u014d \u5999\u6cd5) taught by the \"Lotus Sutra\".\nNichiren saw \"ichinen sanzen\" as pointing to the potential for Buddhahood in all beings (ri no ichinen sanzen \u7406\u306e\u4e00\u5ff5\u4e09\u5343) and to the actualization of Buddhahood itself (ji no ichinen sanzen \u4e8b\u306e\u4e00\u5ff5\u4e09\u5343), which encompasses and illuminates all other realms. He associated these with the \"trace\" teaching of the first half of the \"Lotus Sutra\" and with the \"origin\" teaching of the latter half of the sutra respectively. He also saw ichinen sanzen as the ultimate truth and the heart of the \"Lotus Sutra\", writing that \"only the Tiantai ichinen sanzen is the path of attaining Buddhahood.\" However, he also saw his own teaching of ichinen sanzen as different and as going beyond that which was taught by Zhiyi. This is because Nichiren held that his teaching of the \"true ichinen sanzen\" was based on the latter half of the \"Lotus Sutra\" (the origin teaching), instead of on second chapter. For Nichiren this is \"the doctrine of original cause (hon\u2019in) and original effect (honga). The nine realms are inherent in the beginningless Buddha realm; the Buddha realm inheres in the beginningless nine realms.\" This teaching \"demolishes\" all views of gradual training.\nSingle-minded devotion to the \"Lotus Sutra\".\nNichiren held that this teaching of the interfusion of all reality, the ultimate meaning of the \"Lotus Sutra,\" could now be realized solely through devotion to the sutra, especially by the practice of faithfully chanting the title of the sutra (daimoku). This allowed one to contemplate one's mind (kanjin) and to attain the fruit of Buddhahood in this life. This was possible because the \"Lotus Sutra\" and the daimoku contains the entirety of the Buddha's teachings within it, as well as all of Shakyamuni Buddha's power and merits. This is Nichiren's teaching of ichinen sanzen as \"actuality\" (ji), meaning a practice that relies on an actual form (jis\u014d), which he contrasted with the teaching of Zhiyi's \"Mohe Zhiguan\" which taught ichinen sanzen of \"principle\" (ri).\nAccording to Nichiren, Buddhahood would manifest when a person faithfully chants the sutra's title and shares it with others, at whatever the cost. Indeed, for Nichiren, \"Lotus Sutra\" focused practice was the only efficacious practice in the Final Dharma Age. This is because Nichiren held that the \"Lotus Sutra\" contains the true intent of the Buddha:The \"Lotus Sutra\" is the written expression of \u015a\u0101kyamuni Tath\u0101gata\u2019s intent; it is his pure voice transformed into written words. Thus its written words are endowed with the Buddha\u2019s mind. It is like the case of seeds, sprouts, shoots, and grain; though they differ in form, their essence is the same. \u015a\u0101kyamuni Buddha and the words of the \"Lotus Sutra\" are different, but their spirit is one. Thus when you look upon the words of the Lotus Sutra, you should think that you are encountering the living \u015a\u0101kyamuni Tath\u0101gata.Nichiren emphasized the importance of faith, practice, and study. Faith meant embracing the \"Lotus Sutra,\" something that needed to be continually deepened. \"To accept (\"ju\") [faith in the sutra] is easy,\" he explained to a follower, \"to uphold it (\"ji\") is difficult. But the realization of Buddhahood lies in upholding [faith].\" This could only be manifested by the practice of chanting the \"daimoku\" as well as teaching others to do the same, and study.\nConsequently, Nichiren consistently and vehemently objected to the perspective of the Pure Land School that stressed an other-worldly aspiration to some Pure Land outside of this world. Behind his assertion is the concept of the nonduality of the subjective realm (the individual) and the objective realm (the land that the individual inhabits) which indicates that when the individual taps into Buddhahood, his or her present world becomes peaceful and harmonious. For Nichiren the widespread propagation of the \"Lotus Sutra\" and consequent world peace (\"kosen-rufu\") was achievable and inevitable. He thus tasked his future followers with a mandate to accomplish it.\nWhile Nichiren critiqued H\u014dnen's Pure Land tradition for sidelining the \"Lotus Sutra\", he was also influenced by it. H\u014dnen had introduced the concept of focusing on a single practice over all others (which was to be nembutsu). This practice was revolutionary because it was simple and accessible to all. It also minimalized the elitist and monopolistic role of the Buddhist establishment. Nichiren appropriated the structure of a universally accessible single practice but substituted the nembutsu with the recitation of the daimoku (\"Namu My\u014dh\u014d Renge Ky\u014d\"), while also affirming that this practice could lead to Buddhahood in this life, instead of just leading to birth in a Pure Land.\nThe Three Great Secret Dharmas.\nSince Nichiren deemed the world to be in a degenerate age where most teachings were ineffective, he held that people required a simple and effective method to attain Buddhahood. According to Nichiren, the way to Buddhahood was through the Three Great Secret Dharmas (sandai hih\u014d \u4e09\u5927\u79d8\u6cd5): the invocation of the \"Lotus Sutra\"'s title (\"daimoku\"), the object of worship (\"honzon\"), and the ordination platform or place of worship (\"kaidan\"). Nichiren held that these three Dharmas are the concrete manifestations of \"the actualization of ichinen sanzen\" (ji no ichinen sanzen) specific to the Age of Dharma Decline.\nA work attributed to Nichiren named the \"Sandai hi h\u014d honj\u014dji\" (\u4e09\u5927\u79d8\u6cd5\u7a1f\u627f\u4e8b, \"Transmission of the Three Great Secret Dharmas\") states that Nichiren discovered the three Dharmas in the 16th chapter of the \"Lotus Sutra,\" and that as the leader of the Bodhisattvas of the Earth, he secretly received them from the original Buddha (honbutsu) who resides in the originally existing Land of Tranquil Light. Several modern scholars have questioned the authenticity of this text however.\nAccording to Nichiren, practicing the Three Secret Dharmas results in the \"Three Proofs\" which verify their validity. The first proof is \"documentary,\" whether the religion's fundamental texts, here the writings of Nichiren, make a lucid case for the eminence of the religion. \"Theoretical proof\" is an intellectual standard of whether a religion's teachings reasonably clarify the mysteries of life and death. \"Actual proof,\" deemed the most important by Nichiren, demonstrates the validity of the teaching through the actual improvements and experiences which manifest in the daily life of practitioners.\nDaimoku.\n\"Namu My\u014dh\u014d Renge Ky\u014d\", the \"daimoku\" (\"the title\" of the \"Lotus Sutra\" preceded by \"Namu\", meaning \"homage to\"), is both the essence of the \"Lotus Sutra\"'s Dharma and the means to discover that truth, i.e. the interconnected unity of self, others and environment with Buddhahood itself. Nichiren sees this as the only truly effective practice, the superior Buddhist practice for this time. Thus, according to Nichiren, \"it is better to be a leper who chants Nam(u) My\u014dh\u014d Renge Ky\u014d than be a chief abbot of the Tendai school.\" For Nichiren, the daimoku is \"the heart of the eighty thousand sacred teachings and the eye of all buddhas,\" and contains the entire Buddhadharma.\nNichiren was influenced by Zhiyi, who argued in his \"Profound Meaning of the Lotus S\u016btra\" (Fahua xuanyi \u6cd5\u83ef\u7384\u7fa9) that the title of the sutra contains the meaning of the entire sutra (which itself contains the whole of Buddhism). Stone writes, \"for Nichiren, the daimoku, as the embodiment of ichinen sanzen, encompasses all phenomena, including all beings and their environments in the ten realms of existence.\" This non-dual reality is contained in the term \"My\u014dh\u014d\" (Miao in Chinese).\nFurthermore, the daimoku is also said to contain the Buddha's enlightenment and all his spiritual powers. As he writes in the \"Kanjin honzon sh\u014d\": \"\u015a\u0101kyamuni\u2019s causal practices and their resulting virtues are all contained within the five characters My\u014dh\u014d Renge Ky\u014d. When we embrace these five characters, he will naturally transfer to us the merit of his causes and effects.\" He also writes:For those who are incapable of understanding the truth of ichinen sanzen, Lord \u015a\u0101kyamuni Buddha, with His great compassion, wraps this jewel in the five characters of my\u014d, h\u014d, ren, ge, and ky\u014d and hangs it around the neck of the ignorant in the Latter Age of Degeneration.Like other Tendai figures of his time, Nichiren held that the \"Lotus Sutra\" taught the unity of the cause (skillful means) and the effect (Buddhahood). Nichiren held that the term \"Renge\" (Dharma Flower) represents how the cause and the effect (practice and Buddhahood) are one. This is symbolized by the lotus flower because its blossoms and seed pods grow at the same time.\nThus, the chanting of the daimoku allowed one to access all the merit of the Buddha's practices. It links a practitioner to the Buddha's wisdom which sees all of reality as a single whole and thus allows one to attain the \"realization of buddhahood with this very body.\"\nFurthermore, Nichiren saw this practice as going beyong the self-power versus other-power dichotomy used by Pure Land Buddhism:The Lotus Sutra establishes self-power but is not self-power. Since the \"self\" encompasses all beings of the ten realms, one\u2019s own person from the outset contains the Buddha realm of both oneself and of all be- ings. Thus one does not now become a Buddha for the first time. [The sutra] also establishes other-power but is not other-power. Since the Buddha who is \"other\" is contained within us ordinary worldlings, this Buddha naturally manifests himself as identical to ourselves.For Nichiren, Buddhahood is immanently accessible through the daimoku. Nichiren also saw the daimoku as granting worldly benefits, such as healing and protection from harm. He taught that by relying on the daimoku, one would achieve a state of inner fredom, writing: \"Recognize suffering as suffering, enjoy pleasures for what they are, and whether in suffering or joy, keep chanting Namu My\u014dh\u014d Renge Ky\u014d... Then you will know the joy of the Dharma for yourself.\"\nGohonzon.\nThe chanting of the daimoku is to be done while contemplating the daimandara \u5927\u66fc\u837c\u7f85 (\"great mandala\") or gohonzon \u5fa1\u672c\u5c0a (\"revered object of worship\"). Japanese Buddhists often had a personal shrine with an object of worship (honzon), which could be a painting, mandala or statue. These objects were often held to embody the powers of the Buddhas. Nichiren created a unique honzon style in the form of a calligraphic mandala (in Chinese characters and two Siddham glyphs) representing the entire cosmos, specifically centered around the \"Lotus Sutra\"'s ceremony in the air above Vulture Peak.\nNichiren inscribed many of these mandalas as personal honzons for his followers. More than 120 of them survive in Nichiren's own hand with his signature. Nichiren drew on earlier visual representations of the \"Lotus Sutra\" and was also influenced by contemporary figures like My\u014de and Shinran who also created calligraphic honzon for their disciples. Since these did not require expert painters or expensive materials to make, they could be made in larger numbers for wide dissemination.\nNichiren's gohonzons contain the daimoku written vertically in the center. It is flanked by the names of \u015a\u0101kyamuni and Prabh\u016btaratna Buddha, as well as the names of various bodhisattvas (especially prominent being the Four Bodhisattvas of the Earth), deities, and other beings. These figures also represent \"ichinen sanzen\", the mutual inclusion of the ten realms. Thus, the great mandala embodies the entire cosmos and its interfusion with Buddhahood. In other words, the gohonzon symbolizes the non-duality between our world and the sacred realm of the original Buddha of the \"Lotus Sutra\", where the sutra is being taught eternally.\nAccording to Stone, the logic of this mandala is influenced by Esoteric Buddhist yogas, in which the yogi visualizes their unity with the Buddha realm. However, for Nichiren, the unity of oneself and the Buddha is not achieved through yogic means, but mainly through faith. As Stone explains, \"by chanting the daimoku, the devotee \"enters\" the mandala, the realm of the original Buddha\u2019s awakening, and participates in the enlightened reality that it depicts.\"\nKaidan.\nNichiren discusses the ordination platform (kaidan \u6212\u58c7) or place of worship\",\" less frequently than the other great secret Dharmas for the mapp\u014d era. Teachings on it can be found in the \"Sandai hi h\u014d honj\u014dji\", a work of questionable authenticity. Traditionally, a kaidan is a place where the Buddhist precepts are transmitted to novices. However, Nichiren held that the merit of the precepts was already contained within the daimoku, and that embracing the \"Lotus Sutra\" was the only true precept in the Final Dharma Age. Nichiren's intentions for the establishment of an \"ordination platform of the origin teaching\" (honmon no kaidan \u672c\u9580\u306e\u6212\u58c7) is thus far from clear, though he seems to have held that it would supersede the Tendai ordination platform on Mount Hiei. The \"Sandai hi h\u014d honj\u014dji\" teaches that it will be built as great Dharma center for all the people of the world once the Emperor and his government all embraced the \"Lotus Sutra\".\nNichiren left the fulfillment of the \"kaidan\" to his successors and its interpretation has been a matter of heated debate. Some state that it refers to the construction of a physical ordination platform sanctioned by the Emperor; others contend that the ordination platform is the community of believers (\"sangha\") or, simply, the place where practitioners of the \"Lotus Sutra\" live and make collective efforts to realize the ideal of establishing the true Dharma in order to establish peace to the land (\"rissh\u014d ankoku\"). The latter metaphorical interpretation is based on the \"Lotus S\u016btra\" itself which states that \"the place of enlightenment\" is any place where one upholds the sutra. The latter conception reflects Nichiren's understanding that Buddhist practice must be grounded in a concrete place and must be engaged with the real world outside of temples and hermitages. It has also been interpreted as promoting engagement with the secular world as well as working to improve society.\nPropagating the \"Lotus Sutra\" far and wide.\nNichiren's teachings are replete with practical aspirations for self-transformation. He urged his followers to \"quickly reform the tenets you hold in your heart\" (\"Rissh\u014d Ankoku Ron\"), and to reflect on their behavior as human beings. Nichiren also made a \"great vow\" that he and all his followers would create the conditions for a peaceful Dharmic nation. This is described in the \"Lotus Sutra\" as \"kosen-rufu\" (lit. \"to extensively declare and spread [the \"Lotus Sutra\"] far and wide\"). In earlier Japanese Buddhism the concept of \"nation\" was equated with Imperial rule and peace with political stability. Nichiren's teachings embraced a new view which held that \"nation\" referred to the land and the people. Nichiren was unique among his contemporaries in charging the actual government in power (the \"bakufu\"), as responsible for peace and for the thriving of Dharma. For Nichiren, all human beings were equal in the eyes of the Buddha and all were responsible for the state of their nation. Furthermore, enlightenment is not restricted to one's inner life, but is actualized by making efforts toward the transformation of nation and society.\nBecause of this, Nichiren saw himself as responsible for saving the Japanese nation, which he believed could only be accomplished by spreading the teaching of the \"Lotus Sutra.\" Nichiren saw his struggles to spread the \"Lotus\" as reflecting and re-enacting the efforts of the bodhisattvas which appear in the \"Lotus Sutra\", mainly Sad\u0101paribh\u016bta and Vi\u015bi\u1e63\u1e6dac\u0101ritra. He constantly enjoined his followers to continue to spread the teaching of the \"Lotus\" and to keep working to create a Pure Land in this world in the future.\nPolemics and shakubuku.\nThe tradition of Buddhist debate has deep-seated roots in the Buddhist tradition, going all the way back to Indian works on debate and Siddhanta texts. In addition to formalized religious debates, the Kamakura period was marked by flourishing and competitive oral religious discourse. Temples competed for the patronage of elites through oratorical sermonizing and temple lecturers (\"k\u014dshi\") faced pressure to attract crowds. Sermonizing spread from within the confines of temples to homes and the streets as wandering mendicants (\"shid\u014dso\", \"hijiri\", or \"inja\") preached to both the educated and illiterate in exchange for alms. In order to teach principles of faith preachers incorporated colorful storytelling, music, vaudeville, and drama\u2014which later evolved into Noh.\nA predominant topic of debate in Kamakura Buddhism was the concept of rebuking \"slander of the Dharma\", a topic found in the \"Lotus Sutra\". Polemical critiques of other sects could be found in the works of numerous Kamakura period authors. H\u014dnen had taught people to , , , and all non-Pure Land teachings and his followers often took this to radical extremes. His ideas were vociferously attacked by many authors including My\u014de and J\u014dkei. Thus, Nichiren's critiques of other sects must be understood in the context of a time in which religious polemics were common. Nichiren himself saw countering slander of the Dharma as a key pillar of Buddhist practice.\nAt age 32, Nichiren began a career of denouncing several Mahayana schools of his time and declaring what he asserted was the correct teaching. The first target of his polemics was H\u014dnen's Pure Land teaching which had by now become very popular. Nichiren's detailed rationale is most famously articulated in his first major work, the . While Nichiren's polemics were often harsh, he always chose personal or written debate and did not resort to religious violence. Nichiren remained non-violent even while experiencing persecution and living in a world in which established sects like the Tendai school wielded armies of warrior monks (S\u014dhei) to attack their critics. Nichiren is said to have stated: \"Whatever obstacles I may encounter, as long as men [persons] of wisdom do not prove my teachings to be false, I will never yield.\"\nFor Nichiren, Buddhist texts discuss to main approaches to spreading the Buddhadharma: the gradual method of sh\u014dju (\u6442 \u53d7) in which one leads others without confronting or challenging them, and shakubuku (\u6298\u4f0f), an assertive method of critiquing others' views. Nichiren held that depending on the time and place, one could use either of these. Nichiren believed that since Japan was a Buddhist country that had entered the Final Dharma Age in which people were discarding the \"Lotus Sutra\", it was necessary to make use of confrontational shakubuku when encountering certain people. Nichiren saw his critiques as a compassionate act, since he was convinced only the \"Lotus\" could lead to liberation in this age. Even if people rejected his teachings, Nichiren held that hearing about the \"Lotus Sutra\" would plant a seed in their minds which would sprout in the future. However, he also acknowledged that in some cases, one should also rely on sh\u014dju, even during this time. One example was when teaching in a non-buddhist country. This flexibility opened the way for later controversy in the Nichiren tradition, which has often been divided over which approach to employ.\nThe Four Denunciations.\nThroughout his career Nichiren harshly denounced various Buddhist traditions, as well as the existing social and political system that supported them. Modern detractors criticize his exclusivist perspective as intolerant. Apologists argue his arguments should be understood in the context of his times and not through a modern lens that rejects religious confrontation.\nNichiren's polemics included sharp criticisms of the Pure Land, Shingon (meaning Esoteric Buddhism in general), Zen, and Ritsu schools. The core of Nichiren's critique was that these schools had turned people away from the \"Lotus Sutra,\" making them focus on other thing like a postmortem destination (Pure Land), secret and elitist master disciple transmissions (Zen, and Esotericism) and monastic rules (Ritsu). His criticisms have become known as the \"Four Denunciations\". He also critiqued the Japanese Tendai school for its appropriation of esoteric elements (Taimitsu). Reliance on esoteric rituals, he claimed, was useless magic and would lead to national decay. He held that Zen was devilish in its belief that attaining enlightenment was possible through a \"secret transmission outside the scriptures\", and that Ritsu was thievery because it hid behind token deeds such as public works. In modern parlance, the Four Denunciations rebuked demoralized and disengaged people by discouraging occultism, clericalism, legalism, and escapism.\nIn spite of his critiques, Nichiren did not reject all other Buddhist traditions or practices in full. His focus remained on those whom he saw as \"slandering the Dharma\", i.e. those who turned people away from the \"Lotus Sutra\" or argued that it was a sutra of a lower class. Thus, he writes in \"The\" \"Opening of the Eyes\": I believe that the devotees and followers of the \"Flower Garland\", \"Meditation\", \"Mah\u0101vairochana\", and other sutras will undoubtedly be protected by the Buddhas, bodhisattvas, and heavenly beings of the respective sutras that they uphold. But if the votaries of the \"Mah\u0101vairochana, Meditation\", and other sutras should set themselves up as the enemies of the votary of the \"Lotus Sutra\", then the Buddhas, bodhisattvas, and heavenly beings will abandon them and will protect the votary of the \"Lotus Sutra\". It is like the case of a filial son whose father opposes the ruler of the kingdom. The son will abandon his father and support the ruler, for to do so is the height of filial piety.\nBodily reading the \"Lotus Sutra\".\nNichiren's combative preaching led to many attacks and persecutions against him and his followers. Nichiren saw these attacks as signifying his role as a , one who bears witness to the truth of the sutra through their own life and is thus assured of enlightenment. The \"Lotus Sutra\" states that those who base themselves on its teachings and attempt to spread it will experience many trials and personal attacks. By persevering in this, they will eventually reach Buddhahood. Nichiren claimed to be \"reading [the \"Lotus Sutra\"] with his body\" (shikidoku \u8272\u8aad), that is directly and physically experiencing the words of the sutra instead of just reciting or thinking about it. Stone writes that this process entails a circular hermeneutic in which \"the s\u016btra\u2019s predictions that its devotees will encounter hardships legitimated Nichiren\u2019s actions, and Nichiren\u2019s experience of persecution, in fulfilling scriptural prophecy, legitimated the \"Lotus S\u016btra.\"\"\nNichiren saw it as his personal mission to actively face these trials, and claimed he found great meaning and joy in them. He even expressed appreciation to his tormentors for giving him the opportunity to serve as an envoy of the Buddha. Furthermore, for Nichiren, experiencing trials and even death in service to the \"Lotus Sutra\" was also a way to attain Buddhahood. This practice of \"bodily reading\" the sutra and \"not begrudging bodily life\" is one of the most central elements of Nichiren's soteriology. Nichiren found this teaching in the \"Lotus Sutra\"'s statement \"we do not value bodily life, but cherish only the unexcelled way.\"\nNichiren also saw his sufferings as redemptive opportunities to quickly transform his karma and repay his debts to the triple gem, to one's parents, nation, and to all of beings. He further held that encountering great trials for the sake of the \"Lotus\" guaranteed one's future Buddhahood, and he compared this to the radical acts of self-sacrifice found in the Mahayana sutras. His personal example has provided enduring encouragement to Nichiren Buddhists as well as to other individuals who have risked their lives to uphold their convictions.\nNichiren was well aware of the struggles his followers faced in their lives. He taught them that facing these challenges would lead to a sense of inner freedom, peace of mind, and to an understanding of the Dharma. Nichiren accepted the classic Buddhist views on karma which taught that a person's current conditions were the cumulative effect of past thoughts, words, and actions. However, he preferred to focus on how all people, even the ignorant, poor and evil, could become Buddhas through devotion to the \"Lotus Sutra\". Nichiren thus taught that when confronting difficult karmic situations, chanting of the daimoku would open the wisdom of the Buddha and transform one's karma, awakening a universal concern for one's society. In some of his letters, Nichiren extended his theory of facing persecution for the \"Lotus Sutra\" to personal problems like familial discord or illness. He encouraged his followers to take ownership of negative life events, and to view them as opportunities to repay karmic debts and to practice Dharma, which help could shorten the length of these events.\nFor Nichiren, finding joy in experiencing the \"Lotus Sutra\" through one's personal life experience was of paramount in importance. Nichiren held that peace of mind in the face of life's challenges is precisely what the Lotus Sutra meant by its statement that those to uphold the sutra will have peace and security. According to Stone, Nichiren \"demonstrated an attitude that wastes little energy in railing against it but unflinchingly embraces it, interpreting it in whatever way appears meaningful at the moment so as to use that suffering for one's own development and to offer it on behalf of others.\"\nThe non-dual Lotus Land.\nNichiren defends a profound nonduality between subjective existence and the surrounding world, the non-separation of subjective experience and environmental karmic effects (\"esh\u014d funi\", \u4f9d\u6b63\u4e0d\u4e8c). According to this doctrine, the environment reflects the inner life-condition of the sentient beings who inhabit it. Thus, the same world appears differently to individuals based on their state of mind: a person in a state of hellish suffering experiences a hell-like world, while an awakened being experiences a Pure Land. This teaching was not limited to internal realization; it implied that sincere Buddhist practice would directly affect the external world. Because each of the Ten Realms interpenetrates and includes both sentient beings and their environments, the act of actualizing Buddhahood within oneself simultaneously actualizes Buddhahood in one\u2019s surroundings. As more individuals engage in the chanting practice, the transformation would extend outward, gradually turning this world into an ideal Buddha-field.\nNichiren envisioned this transformed world as a tangible outcome of faith and practice, though he rarely detailed its specific characteristics. However, in one writing, he claims that if everyone chanted in unison, natural disasters would cease, social harmony would prevail, and people would gain long lives. This suggests that through faith in the \"Lotus Sutra\", a society in alignment with nature and moral governance could be established. This vision imbues Nichiren\u2019s doctrine with a clear social dimension: the realization of the Pure Land is not solely an individual spiritual goal but a communal one. His followers across history have pursued this aim in various forms, inspired by the belief that practice can reform society. Nichiren's this-worldly orientation stands in contrast to the Pure Land Buddhism ideal prevalent in his time, which encouraged rejection of this impure world in favor of rebirth in a transcendent land after death.\nIn his later years, Nichiren did address the question of the devotee\u2019s destiny after death. He taught that anyone who embraced the \"Lotus Sutra\" and had faith in it would enter the \"Pure Land of Vulture Peak\" (\"Ry\u014dzen j\u014dd\u014d\", \u970a\u5c71\u6d44\u571f), associated with the \"Lotus Sutra's\" assembly in the air. This provided a peaceful postmortem destination for Nichiren's followers, analogous to the pure land of Sukhavati. However, Nichiren did not regard this Pure Land as realm separate from this world. Even though it encompasses the faithful deceased, this land is ultimately the sacred space of enlightenment accessible here and now through devotion to the \"Lotus S\u016btra\". It is thus the \"land of tranquil light\" (\"j\u014d jakk\u014ddo\"), the highest Pure Land in the Tendai system. For Nichiren, the boundary between the mundane and the sacred collapses in the moment of embracing the \"Lotus\". By chanting \"Namu My\u014dh\u014d Renge Ky\u014d\", \"gains entrance by faith\" into the Buddha's presence, participating in the \"eternal assembly in open space\" (\"kok\u016be no gishiki\") of the \"Lotus Sutra,\" where Shakyamuni and Many Jewels Buddha teach from the Jeweled Stupa.\nThus, Nichiren says in his \"Kanjin no Honzon-sh\u014d\":The \"sah\u0101\" world of the present moment (\"ima\"), which is the original time (\"honji\") [of the Buddha\u2019s enlightenment], is the constantly abiding pure land, liberated from the three disasters and beyond [the cycle of] the four kalpas [formation, stability, decline and extinction]. Its Buddha has not already entered nirv\u0101\u1e47a in the past, nor is he yet to be born in the future. And his disciples are of the same essence. This [world] is [implicit in] the three realms, which are inherent in the three thousand realms of one\u2019s mind. Thus, through faith and the daimoku, one can enter the Pure Land in this life, which is equivalent to \"attaining buddhahood in this body\" (\"sokushin j\u014dbutsu\"). Therefore, unlike with the Pure Land teaching of Sukhavati, Nichiren's idea of the Pure Land is not a world outside of Sa\u1e43s\u0101ra and does not require one to loathe this defiled world and seek to escape it. Nichiren writes:The originally enlightened Buddha of the perfect teaching abides in this world. If one abandons this land, toward what other land should one aspire? . . . The practitioner who believes in the \"Lotus\" and \"Nirvana\" sutras should not seek another place, for wherever one has faith in this sutra is precisely the pure land. . . . . For people of our day, who have not yet formed a bond with the \"Lotus Sutra\", to aspire to the Western Pure Land is to aspire to a land of rubble.\nEquality.\nNichiren taught that all beings had the same capacity to attain Buddhahood. He held that the \"Lotus Sutra\" teaches the equality of all beings. He also taught that neither social class nor gender were barriers to one's Buddhahood. This view was rare in Japan, which was a society dominated by elite men. Women were not even allowed on Mount Hiei for example, and were traditionally considered to be impure during menstruation. Nichiren emphasized that women are equal in their spiritual capacity: Many women in their prime became nuns during Shakyamuni's time and practiced the way of the Buddha, but they were never despised because of their menstrual periods. Menstruation is not a pollution that comes from without. It is simply a feminine characteristic... \nNichiren and his followers.\nNichiren was a charismatic leader who attracted many followers during both his missionary trips and his exiles. They included samurai, feudal lords, commoners and merchants, men and women. He taught his followers that women were equally able to attain enlightenment. He wrote to them often, sharing his rationale and strategies with them, openly urging them to share his conviction and struggles.\nNichiren's many extant letters demonstrate the scope and breadth of his relationship with them and his expectations for them. They recognized and trusted his charismatic leadership and his understanding of Buddhism. Many sought his guidance to overcome personal problems. Many were actively involved with supporting him financially and protecting his community of followers. Several of disciples were praised by him for sharing in his privations and a few lost their lives in these situations. The relationship between Nichiren and his disciples has been called \"shitei funi\", the oneness of mentor and disciple. Although the functions of the mentor and disciple may vary, they share the same goals and the same responsibility. Nichiren claimed the precedent for \"shitei funi\" is a core theme of the \"Lotus Sutra\", especially in chapters 21 and 22 where the Buddha entrusts the future propagation of the sutra to the gathered bodhisattvas.\nPosthumous influence.\nIn the centuries after his death, the Nichiren movement experienced many internal divisions and further persecutions. Nevertheless, Nichiren's Lotus (\"Hokke\") tradition grew steadily and maintained Nichiren's teachings. In the years after his death, Nichiren's teachings were interpreted in different ways by his followers. As a result, Nichiren Buddhism encompasses several major branches and schools, each with its own doctrine and set of interpretations of Nichiren's teachings. Today his followers are found in influential lay movements as well as traditional Nichiren schools like Nichiren-sh\u016b and Nichiren Sh\u014dsh\u016b. With an estimated 10 millions followers, modern Nichiren Buddhism is the second largest tradition of Japanese Buddhism (second only to Pure Land Buddhism with 22 million followers).\nA massive body of scholarship on Nichiren has been written in Japanese. This includes sectarian and academic works. The Institute of Nichiren Buddhist Studies at Rissh\u014d University (Rissh\u014d Daigaku Nichiren Ky\u014dgaku Kenky\u016bjo \u7acb\u6b63\u5927 \u5b66\u65e5\u84ee\u6559\u5b66\u784f\u7a76\u6240) is a major Japanese institution which focuses on Nichiren studies. It is affiliated with Nichiren-sh\u016b. Nichiren has drawn less attention from Western scholars than other Japanese Buddhist figures, and he was initially stereotyped as intolerant or militant. Nevertheless, scholars like Gaston Renondeau, Alicia Matsunaga, Daigan Matsunaga, Bruno Petzold, Lucia Dolce and Jacqueline Stone have written in English on Nichiren.\nWritings.\nNichiren was a prolific writer. His collected works in four volumes contains up to five hundred writings. Nichiren also kept a copy of the \"Lotus S\u016btra\" which he annotated profusely and has also been published. Many writings still exist in his original handwriting, some as complete works and some as fragments. Other documents survive as copies made by his immediate disciples. Nichiren's existing works number over 700 manuscripts in total, including transcriptions of orally delivered lectures, letters of remonstration and illustrations. According to Fumihiko Sueki: \"the most rigorously edited and reliable collection of Nichiren\u2019s writings is the \"Sh\u014dwa teihon Nichiren Sh\u014dnin ibun\" \u662d\u548c\u5b9a\u672c\u65e5\u84ee\u8056\u4eba\u907a\u6587 (STN), edited and published after World War II by Rissh\u014d Daigaku Nichiren Ky\u014dgaku Kenky\u016bjo (1988).\"\nScholars have divided the writings attributed to Nichiren into three categories: those whose authenticity are universally accepted, those generally designated as written by someone else after his death, and a third category in which the veracity of works is still being debated.\nIn addition to treatises written in formal , Nichiren also wrote expositories and letters to followers in mixed kanji-kana vernacular as well as letters in simplified kana for believers such as children who could not read the more formal styles. Some of Nichiren's \"kanbun\" works, especially the \"Rissh\u014d Ankoku Ron\", are considered exemplary of the \"kanbun\" style, while many of his letters focus on more empathic exhortations to commoners and laypeople.\nSelected important writings.\nAmong his main Classical Chinese treatises, five are generally accepted by all Nichiren schools as his major works:\nNikk\u014d Sh\u014dnin added an additional five writings to comprise a set of ten major writings (this specific list is only central in Nichiren Sh\u014dsh\u016b).\nPersonal letters.\nAmong the collection of his extant writings are numerous letters to his follows in the form of thank you notes, messages of condolence, responses to questions, and spiritual counseling for trying moments in his followers' lives. Collectively these letters demonstrate that Nichiren was a master of providing both comfort and challenge befitting the unique personalities and situations of each individual.\nMany of these letters use tales drawn from Indian, Chinese, and Japanese traditions as well as historical anecdotes and stories from the Buddhist canon. Nichiren incorporated several hundred of these anecdotes and took liberty to freely embellish some of them; a few of the stories he provided do not appear in other collections and could be original.\nAnother category of his letters follow the genres of Japanese \"zuihitsu\", lyrical and loosely organized essays that combine personal reflection and poetic language, or personal diaries (\"nikki bungaku).\" Nichiren was a master of this genre and these colloquial works reveal his highly personal and charismatic method of proselytization as well as his deep caring for his followers.\nNichiren used his letters as a means to inspire key supporters. About one hundred followers are identified as recipients and several received between 5 and 20 of them. The recipients tended to be of the warrior class and only scattered references appear about his lower status followers, many of whom were illiterate. The series of letters he wrote his followers during the \"Atsuhara Affair\" of 1279 provide a case study of how he used personal written communications to direct a response to the government's actions and to keep his followers steadfast during the ordeal.\nWritings to women.\nAgainst a backdrop of earlier Buddhist teachings that deny the possibility of enlightenment to women or reserve that possibility for life after death, Nichiren is highly sympathetic to women. Based on various passages from the \"Lotus Sutra\", Nichiren asserts that \"Other sutras are written for men only. This sutra is for everyone.\"\nNinety of his extant letters, nearly a fifth of the total, were addressed to female correspondents. Nichiren Shu has published separate volumes with those writings. In these letters Nichiren plays particular attention to the instantaneous attainment of enlightenment of the Dragon King's daughter in the \"Devadatta\" (Twelfth) chapter of the \"Lotus Sutra\" and displays deep concern for the fears and worries of his female disciples.\nDisputed writings.\nThere is a lively scholarly debate as to the authenticity of many writings attributed to Nichiren. Such disputed works include the \"Sandai hih\u014d honj\u014dji\" and the \"Ongi kuden\". Some Japanese scholars initially questioned whether any work which contained hongaku thought could be Nichiren's. These include important writings sent to the Tendai monk Sairen-bo which also show some stylistic differences to other writings by Nichiren. More recent scholarship by authors like Jacqueline Stone have argued that this single criterion is not enough for rejecting a work's authenticity. Thus, according to Sueki, the authenticity of the \"Rissh\u014dkan j\u014d\" (Treatise on right contemplation) is highly probable. In 1997, Ito Zuiei used computer analysis to study the \"Sandai hih\u014d honj\u014dji\" and argued that it is possibly authentic. Thus, the scholarship on Nichiren's \"problematic\" works is still up for debate and continues to change.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nEnglish translations of Nichiren's writings.\nOne recent translation collection of Nichiren's work appears is the work of Nichirensh\u016b Overseas Propagation Promotion Association (NOPPA) and is published by Nichiren Buddhist International Center. Now in its second edition, it was published in 2021 and contains seven volumes:\nOther translations of Nichiren's work into English include:"}
{"id": "22136", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=22136", "title": "Namu Myoho Renge Kyo", "text": ""}
{"id": "22137", "revid": "39191556", "url": "https://en.wikipedia.org/wiki?curid=22137", "title": "Nichiren Buddhism", "text": "Japanese branch of Buddhism\nNichiren Buddhism (), also known as Hokkesh\u016b (, meaning \"Lotus Sect\"), is a branch of Mahayana Buddhism based on the teachings of the 13th-century Japanese Buddhist priest Nichiren (1222\u20131282) and is one of the Kamakura period schools. Its teachings derive from some 300\u2013400 extant letters and treatises either authored by or attributed to Nichiren.\nNichiren Buddhism generally sources its basic doctrine from the Lotus Sutra claiming that all sentient beings possess an internal Buddha-nature capable of attaining Buddhahood in the current life. There are three essential aspects to Nichiren Buddhism:\nAfter his death, Nichiren left to both his senior disciples and lay followers the mandate to widely propagate the \"Gohonzon\" and chanting the \"Daimoku\" in order to secure the peace and prosperity of society.\nTraditionalist Nichiren Buddhist temple groups are commonly associated with Nichiren Sh\u014dsh\u016b and various Nichiren-sh\u016b schools. In addition, modern lay organizations not affiliated with temples such as Soka Gakkai, Kenshokai, Shoshinkai, Rissh\u014d K\u014dsei Kai, and Honmon Butsury\u016b-sh\u016b also exist while some Japanese new religions are Nichiren-inspired lay groups.\nThe Soka Gakkai International is often called \"the most prominent Japanese 'export' religion to draw significant numbers of non-Japanese converts\", by which Nichiren Buddhism has spread throughout the world.\nNichiren upheld the belief that the Lotus Sutra alone contains the highest degree of Buddhist teachings and proposed a classification system that ranks the quality of religions and various Nichiren schools can be either accommodating or vigorously opposed to any other forms of Buddhism or religious beliefs. Various followers debate Nichiren status, as a Bodhisattva, a mortal saint, or an \"Original Buddha\" of the third age of Buddhism. Nichiren Buddhism is practiced in many countries. The largest groups are Soka Gakkai International, Nichiren Shu, and Nichiren Sh\u014dsh\u016b.\nBasic teachings.\nThe basic practice of Nichiren Buddhism is chanting the invocation \"Namu My\u014dh\u014d Renge Ky\u014d\" to an object called the \"Gohonzon\". Embracing \"Namu My\u014dh\u014d Renge Ky\u014d\" entails both chanting and having the mind of faith (\"Shinjin\"). It has three pillars namely: faith, practice and study. Both the invocation and the Gohonzon, as taught by Nichiren, embody the title and essence of the Lotus Sutra, which he taught as the only valid scripture for the Latter Day of the Law, as well as the life state of Buddhahood inherent in all life.\nNichiren considered that in the Latter Day of the Law \u2013 a time of human strife and confusion, when Buddhism would be in decline \u2013 Buddhism had to be more than the theoretical or meditative practice it had become, but was meant to be practiced \"with the body\", that is, in one's actions and the consequent results that are manifested. More important than the formality of ritual, he claimed, was the substance of the practitioner's life in which the spiritual and material aspects are interrelated. He considered conditions in the world to be a reflection of the conditions of the inner lives of people; the premise of his first major remonstrance, Rissho Ankoku Ron (Establishing The Correct Teaching for the Peace of The Land), is that if a nation abandons heretical forms of Buddhism and adopts faith in the Lotus Sutra, the nation will know peace and security. He considered his disciples the \"Bodhisattvas of the Earth\" who appeared in the Lotus Sutra with the vow to spread the correct teaching and thereby establish a peaceful and just society. For Nichiren, enlightenment is not limited to one's inner life, but is \"something that called for actualization in endeavors toward the transformation of the land, toward the realization of an ideal society.\"\nThe specific task to be pursued by Nichiren's disciples was the widespread propagation of his teachings (the invocation and the \"Gohonzon\") in a way that would effect actual change in the world's societies so that the sanctuary, or seat, of Buddhism could be built. Nichiren saw this sanctuary as a specific seat of his Buddhism, but there is thought that he also meant it in a more general sense, that is, wherever his Buddhism would be practiced. This sanctuary, along with the invocation and \"Gohonzon\", comprise \"the three great secret laws (or dharmas)\" found in the Lotus Sutra.\nNichiren.\nNichiren and his time.\nNichiren Buddhism originated in 13th-century feudal Japan. It is one of six new forms of \"Shin Bukkyo\" (English: \"New Buddhism\") of \"Kamakura Buddhism.\" The arrival of these new schools was a response to the social and political upheaval in Japan during this time as power passed from the nobility to a shogunate military dictatorship led by the Minamoto clan and later to the H\u014dj\u014d clan. A prevailing pessimism existed associated with the perceived arrival of the Age of the Latter Day of the Law. The era was marked by an intertwining relationship between Buddhist schools and the state which included clerical corruption.\nBy Nichiren's time the Lotus S\u016btra was firmly established in Japan. From the ninth century, Japanese rulers decreed that the Lotus S\u016btra be recited in temples for its \"nation-saving\" qualities. It was the most frequently read and recited sutra by the literate lay class and its message was disseminated widely through art, folk tales, music, and theater. It was commonly held that it had powers to bestow spiritual and worldly benefits to individuals. However, even Mount Hiei, the seat of Tiantai Lotus Sutra devotion, had come to adopt an eclectic assortment of esoteric rituals and Pure Land practices as \"expedient means\" to understand the sutra itself.\nDevelopment during Nichiren's life.\nNichiren developed his thinking in this midst of confusing Lotus Sutra practices and a competing array of other \"Old Buddhism\" and \"New Buddhism\" schools. The biographical development of his thinking is sourced almost entirely from his extant writings as there is no documentation about him in the public records of his times. Modern scholarship on Nichiren's life tries to provide sophisticated textual and sociohistorical analyses to cull longstanding myths about Nichiren that accrued over time from what is actually concretized.\nIt is clear that from an early point in his studies Nichiren came to focus on the Lotus Sutra as the culmination and central message of Shakyamuni. As his life unfolded he engaged in a \"circular hermeneutic\" in which the interplay of the Lotus Sutra text and his personal experiences verified and enriched each other in his mind. As a result, there are significant turning points as his teachings reach full maturity. Scholar Yoshir\u014d Tamura categorizes the development of Nichiren's thinking into three periods:\nEarly stage: From initial studies to 1260.\nFor more than 20 years Nichiren examined Buddhist texts and commentaries at Mount Hiei's Enryaku-ji temple and other major centers of Buddhist study in Japan. In later writings he claimed he was motivated by four primary questions: (1) What were the essentials of the competing Buddhist sects so they could be ranked according to their merits and flaws? (2) Which of the many Buddhist scriptures that had reached Japan represented the essence of Shakyamuni's teaching? (3) How could he be assured of the certainty of his own enlightenment? (4) Why was the Imperial House defeated by the Kamakura regime in 1221 despite the prayers and rituals of Tendai and Shingon priests? He eventually concluded that the highest teachings of Shakyamuni Buddha (c.\u2009563\u00a0\u2013 c.\u2009483 BC) were to be found in the Lotus Sutra. Throughout his career Nichiren carried his personal copy of the Lotus Sutra which he continually annotated. The mantra he expounded on 28 April 1253, known as the \"Daimoku\" or \"Odaimoku\", Namu My\u014dh\u014d Renge Ky\u014d, expresses his devotion to the Lotus Sutra.\nFrom this early stage of his career, Nichiren started to engage in fierce polemics criticizing the teachings of Buddhism taught by the other sects of his day, a practice that continued and expanded throughout his life. Although Nichiren accepted the Tendai theoretical constructs of \"original enlightenment\" (\"hongaku shis\u014d\") and \"attaining Buddhahood in one's present form\" (\"sokushin jobutsu\") he drew a distinction, insisting both concepts should be seen as practical and realizable amidst the concrete realities of daily life. He took issue with other Buddhist schools of his time that stressed transcendence over immanence. Nichiren's emphasis on \"self-power\" (Jpn. \"ji-riki\") led him to harshly criticize H\u014dnen and his Pure Land Buddhism school because of its exclusive reliance on Amida Buddha \"other-power\" (Jpn. \"ta-riki\") for salvation. In addition to his critique of Pure Land Buddhism, he later expanded his polemics to criticisms of the Zen, Shingon, and Ritsu sects. These four critiques were later collectively referred to as his \"four dictums.\" Later in his writings, Nichiren referred to his early exegeses of the Pure Land teachings as just the starting point for his polemics against the esoteric teachings, which he had deemed as a far more significant matter of concern. Adding to his criticisms of esoteric Shingon, Nichiren wrote detailed condemnations about the Tendai school which had abandoned its Lotus Sutra-exclusiveness and incorporated esoteric doctrines and rituals as well as faith in the soteriological power of Amida Buddha.\nThe target of his tactics expanded during the early part of his career. Between 1253 and 1259 he proselytized and converted individuals, mainly attracting mid- to lower-ranking samurai and local landholders and debated resident priests in Pure Land temples. In 1260, however, he attempted to directly reform society as a whole by submitting a treatise entitled \"\"Rissh\u014d Ankoku Ron\" (\"Establishment of the Legitimate Teaching for the Protection of the Country\"\") to H\u014dj\u014d Tokiyori, the \"de facto\" leader of the nation.\nIn it he cites passages from the Ninn\u014d, Yakushi, Daijuku, and Konk\u014dmy\u014d sutras. Drawing on Tendai thinking about the non-duality of person and land, Nichiren argued that the truth and efficacy of the people's religious practice will be expressed in the outer conditions of their land and society. He thereby associated the natural disasters of his age with the nation's attachment to inferior teachings, predicted foreign invasion and internal rebellion, and called for the return to legitimate dharma to protect the country. Although the role of Buddhism in \"nation-protection\" (\"chingo kokka\") was well-established in Japan at this time, in this thesis Nichiren explicitly held the leadership of the country directly responsible for the safety of the land.\nMiddle stage: 1261\u20131273.\nDuring the middle stage of his career, in refuting other religious schools publicly and vociferously, Nichiren provoked the ire of the country's rulers and of the priests of the sects he criticized. As a result, he was subjected to persecution which included two assassination attempts, an attempted beheading and two exiles. His first exile, to Izu Peninsula (1261\u20131263), convinced Nichiren that he was \"bodily reading the Lotus Sutra (\"Jpn. Hokke shikidoku\")\", fulfilling the predictions on the 13th chapter (\"Fortitude\") that votaries would be persecuted by ignorant lay people, influential priests, and their friends in high places.\nNichiren began to argue that through \"bodily reading the Lotus Sutra,\" rather than just studying its text for literal meaning, a country and its people could be protected. According to Habito, Nichiren argued that bodily reading the Lotus Sutra entails four aspects:\n\n\nHis three-year exile to Sado Island proved to be another key turning point in Nichiren's life. Here he began inscribing the \"Gohonzon\" and wrote several major theses in which he claimed that he was Bodhisattva Superior Practices, the leader of the Bodhisattvas of the Earth.\nHe concludes his work \"The Opening of the Eyes\" with the declaration \"I will be the pillar of Japan; I will be the eyes of Japan; I will be the vessel of Japan. Inviolable shall remain these vows!\" His thinking now went beyond theories of karmic retribution or guarantees of the Lotus Sutra as a protective force. Rather, he expressed a resolve to fulfill his mission despite the consequences. All of his disciples, he asserted, should emulate his spirit and work just like him in helping all people open their innate Buddha lives even though this means entails encountering enormous challenges.\nFinal stage: 1274\u20131282.\nNichiren's teachings reached their full maturity between the years 1274 and 1282 while he resided in primitive settings at Mount Minobu located in today's Yamanashi Prefecture. During this time he devoted himself to training disciples, produced most of the \"Gohonzon\" which he sent to followers, and authored works constituting half of his extant writings including six treatises that were categorized by his follower Nikk\u014d as among his ten most important.\nIn 1278 the \"Atsuhara Affair\" (\"Atsuhara Persecution\") occurred, culminating three years later. In the prior stage of his career, between 1261 and 1273, Nichiren endured and overcame numerous trials that were directed at him personally including assassination attempts, an attempted execution, and two exiles, thereby \"bodily reading the Lotus Sutra\" (\"shikidoku\" \u8272\u8aad). In so doing, according to him, he validated the 13th (\"Fortitude\") chapter of the Lotus Sutra in which a host of bodhisattvas promise to face numerous trials that follow in the wake of upholding and spreading the sutra in the evil age following the death of the Buddha: slander and abuse; attack by swords and staves; enmity from kings, ministers, and respected monks; and repeated banishment.\nOn two occasions, however, the persecution was aimed at his followers. First, in 1271, in conjunction with the arrest and attempted execution of Nichiren and his subsequent exile to Sado, many of his disciples were arrested, banished, or had lands confiscated by the government. At that time, Nichiren stated, most recanted their faith in order to escape the government's actions. In contrast, during the Atsuhara episode twenty lay peasant-farmer followers were arrested on questionable charges and tortured; three were ultimately executed. This time none recanted their faith. Some of his prominent followers in other parts of the country were also being persecuted but maintained their faith as well.\nAlthough Nichiren was situated in Minobu, far from the scene of the persecution, the Fuji district of present-day Shizuoka Prefecture, Nichiren held his community together in the face of significant oppression through a sophisticated display of legal and rhetorical responses. He also drew on a wide array of support from the network of leading monks and lay disciples he had raised, some of whom were also experiencing persecution at the hands of the government.\nThroughout the events he wrote many letters to his disciples in which he gave context to the unfolding events by asserting that severe trials have deep significance. According to Stone, \"By standing firm under interrogation, the Atsuhara peasants had proved their faith in Nichiren's eyes, graduating in his estimation from 'ignorant people' to devotees meriting equally with himself the name of 'practitioners of the Lotus Sutra.'\" During this time Nichiren inscribed 114 mandalas that are extant today, 49 of which have been identified as being inscribed for individual lay followers and which may have served to deepen the bond between teacher and disciple. In addition, a few very large mandalas were inscribed, apparently intended for use at gathering places, suggesting the existence of some type of conventicle structure.\nThe Atsuhara Affair also gave Nichiren the opportunity to better define what was to become Nichiren Buddhism. He stressed that meeting great trials was a part of the practice of the Lotus Sutra; the great persecutions of Atsuhara were not results of karmic retribution but were the historical unfolding of the Buddhist Dharma. The vague \"single good of the true vehicle\" which he advocated in the \"Rissh\u014d ankoku ron\" now took final form as chanting the Lotus Sutra's \"daimoku\" or title which he described as the heart of the \"origin teaching\" (\"honmon\" \u672c\u9580) of the Lotus Sutra. This, he now claimed, lay hidden in the depths of the 16th (\"The Life Span of the Tath\u0101gata\") chapter, never before being revealed, but intended by the Buddha solely for the beginning of the Final Dharma Age.\nNichiren's writings.\nA prolific writer, Nichiren's personal communiques among his followers as well as numerous treatises detail his view of the correct form of practice for the \"Latter Day of the Law\" (\"mapp\u014d\"); lay out his views on other Buddhist schools, particularly those of influence during his lifetime; and elucidate his interpretations of Buddhist teachings that preceded his. These writings are collectively known as or .\nOut of 162 historically identified followers of Nichiren, 47 were women. Many of his writings were to women followers in which he displays strong empathy for their struggles, and continually stressed the Lotus Sutra's teaching that all people, men and women equally, can become enlightened just as they are. His voice is sensitive and kind which differs from the strident picture painted about him by critics.\nWhich of these writings, including the \"Ongi Kuden\" (orally transmitted teachings), are deemed authentic or apocryphal is a matter of debate within the various schools of today's Nichiren Buddhism. His \"Rissho Ankoku Ron\", preserved at Shochuzan Hokekyo-ji, is one of the National Treasures of Japan.\nPost-Nichiren development in Japan.\nDevelopment in Medieval Japan.\nAfter Nichiren's death in 1282 the Kamakura shogunate weakened largely due to financial and political stresses resulting from defending the country from the Mongols. It was replaced by the Ashikaga shogunate (1336\u20131573), which in turn was succeeded by the Azuchi\u2013Momoyama period (1573\u20131600), and then the Tokugawa shogunate (1600\u20131868). During these time periods, collectively comprising Japan's medieval history, Nichiren Buddhism experienced considerable fracturing, growth, turbulence and decline. A prevailing characteristic of the movement in medieval Japan was its lack of understanding of Nichiren's own spiritual realization. Serious commentaries about Nichiren's theology did not appear for almost two hundred years. This contributed to divisive doctrinal confrontations that were often superficial and dogmatic.\nThis long history of foundings, divisions, and mergers have led to today's 37 legally incorporated Nichiren Buddhist groups. In the modern period, Nichiren Buddhism experienced a revival, largely initiated by lay people and lay movements.\nDevelopment of the major lineages.\nSeveral denominations comprise the umbrella term \"Nichiren Buddhism\" which was known at the time as the \"Hokkesh\u016b\" (Lotus School) or \"Nichirensh\u016b\" (Nichiren School). The splintering of Nichiren's teachings into different schools began several years after Nichiren's passing. Despite their differences, however, the Nichiren groups shared commonalities: asserting the primacy of the Lotus Sutra, tracing Nichiren as their founder, centering religious practice on chanting \"Namu My\u014dh\u014d Renge Ky\u014d\", using the \"Gohonzon\" in meditative practice, insisting on the need for propagation, and participating in remonstrations with the authorities.\nThe movement was supported financially by local warlords or stewards (\"jit\u00f5\") who often founded tightly organized clan temples (\"ujidera\") that were frequently led by sons who became priests. Most Nichiren schools point to the founding date of their respective head or main temple (for example, Nichiren Sh\u016b the year 1281, Nichiren Sh\u014dsh\u016b the year 1288, and Kempon Hokke the year 1384) although they did not legally incorporate as religious bodies until the late 19th and early 20th century. A last wave of temple mergers took place in the 1950s.\nThe roots of this splintering can be traced to the organization of the Nichiren community during his life. In 1282, one year before his death, Nichiren named \"six senior priests\" () disciple to lead his community: Nikk\u014d Sh\u014dnin (\u65e5\u8208), Nissh\u014d (\u65e5\u662d), Nichir\u014d (\u65e5\u6717), Nik\u014d (\u65e5\u5411), Nitch\u014d (\u65e5\u9802), and Nichiji (\u65e5\u6301). Each had led communities of followers in different parts of the Kanto region of Japan and these groups, after Nichiren's death, ultimately morphed into lineages of schools.\nNikk\u014d Sh\u014dnin, Nichir\u014d, and Nissh\u014d were the core of the Minobu (also known as the Nik\u014d or Kuon-ji) \"monryu\" or school. Nik\u014d became the second chief abbot of Minobu (Nichiren is considered by this school to be the first). Nichir\u014d's direct lineage was called the Nichir\u014d or Hikigayatsu \"monryu\". Nissh\u014d's lineage became the Nissh\u014d or Hama \"monryu\". Nitch\u014d formed the Nakayama lineage but later returned to become a follower of Nikk\u014d. Nichiji, originally another follower of Nikk\u014d, eventually traveled to the Asian continent (c. 1295) on a missionary journey and some scholarship suggests he reached northern China, Manchuria, and possibly Mongolia. Kuon-ji in Mount Minobu eventually became the head temple of today's Nichiren Sh\u016b, the largest branch among traditional schools, encompassing the schools and temples tracing their origins to Nik\u014d, Nichir\u014d, Nissh\u014d, Nitch\u014d, and Nichiji. The lay and/or new religious movements Reiy\u016bkai, Rissh\u014d K\u014dsei Kai, and Nipponzan-My\u014dh\u014dji-Daisanga stem from this lineage.\nNikk\u014d left Kuon-ji in 1289 and became the founder of what was to be called the Nikk\u014d \"monryu\" or lineage. He founded a center at the foot of Mount Fuji which would later be known as the Taiseki-ji temple of Nichiren Sh\u014dsh\u016b. Soka Gakkai is the largest independent lay organization that shares roots with this lineage.\nFault lines between the various Nichiren groups crystallized over several issues:\nLocal gods. A deeply embedded and ritualized part of Japanese village life, Nichiren schools clashed over the practice of honoring local gods (kami) by lay disciples of Nichiren. Some argued that this practice was a necessary accommodation. The group led by the monk Nikk\u014d objected to such syncretism.\nContent of Lotus S\u016btra. Some schools (called \"Itchi\") argued that all chapters of the s\u016btra should be equally valued and others (called \"Sh\u014dretsu\") claimed that the latter half was superior to the former half. (See below for more details.)\nIdentity of Nichiren. Some of his later disciples identified him with Vi\u015bi\u1e63\u1e6dac\u0101ritra, the leader of the Bodhisattvas of the Earth who were entrusted in Chapter Twenty-Two to propagate the Lotus S\u016btra. The Nikk\u014d group identified Nichiren as the original and eternal Buddha.\nIdentification with Tiantai school. The Nissh\u014d group began to identify itself as a Tiantai school, having no objections to its esoteric practices, perhaps as an expedient means to avoid persecution from Tiantai, Pure Land, and Shingon followers. This deepened the rift with Nikk\u014d.\nThe Three Gems. All schools of Buddhism speak of the concept of the Three Gems (the Buddha, the Dharma, and the Sangha) but define it differently. Over the centuries the Nichiren schools have come to understand it differently as well. The Minobu school has come to identify the Buddha as Shakyamuni whereas the Nikk\u014d school identifies it as Nichiren. For Minobu the Dharma is \"Namu My\u014dh\u014d Renge Ky\u014d\", the Nikk\u014d school identifies it as the \"Namu My\u014dh\u014d Renge Ky\u014d\" that is hidden in the 16th \"Lifespan\" Chapter of the Lotus Sutra (the \"Gohonzon\"). Currently, Nichiren Sh\u014dsh\u016b claims this specifically refers to the \"Dai Gohonzon\", whereas Soka Gakkai holds it represents all \"Gohonzon\". The Sangha, sometimes translated as \"the priest\", is also interpreted differently. Minobu defines it as Nichiren; Nichiren Shoshu as Nikk\u014d representing its priesthood; and the Soka Gakkai as Nikk\u014d representing the harmonious community of practitioners.\nThe cleavage between Nichiren groups has also been classified by the so-called \"Itchi\" (meaning unity or harmony) and \"Shoretsu\" (a contraction of two words meaning superior/inferior) lineages.\nOrigin of the Fuji School.\nAlthough there were rivalries and unique interpretations among the early Hokkesh\u0169 lineages, none were as deep and distinct as the divide between the Nikk\u014d or Fuji school and the rest of the tradition. Animosity and discord among the six senior disciples started after the second death anniversary of Nichiren's 100th Day Memorial ceremony (23 January 1283) when the rotation system as agreed upon the \"Shuso Gosenge Kiroku\" (English: Record Document of Founder's Demise) and \"Rimbo Cho\" (English: Rotation Wheel System) to clean and maintain Nichiren's grave. By the third anniversary of Nichiren's passing (13 October 1284), these arrangements seemed to have broken down. Nikk\u014d claimed that the other five senior priests no longer returned to Nichiren's tomb in Mount Minobu, citing signs of neglect at the gravesite. He took up residency and overall responsibility for Kuon-ji temple while Nik\u014d served as its doctrinal instructor. Before long tensions grew between the two concerning the behavior of Hakii Nanbu Rokur\u014d Sanenaga, the steward of the Minobu district and the temple's patron.\nNikk\u014d accused Sanenaga of unorthodox practices deemed to be heretical such as crafting a standing statue of Shakyamuni Buddha as an object of worship, providing funding for the construction of a Pure Land \"stupa\" in Fuji, and visiting and worshiping at the Mishima Taisha Shinto shrine which was an honorary shrine of the H\u014dj\u014d clan shogunate. Nikk\u014d regarded the latter as a violation of Nichiren's \"Rissho Ankoku Ron\".\nIn addition, Nikk\u014d made accusatory charges that after Nichiren's death, other disciples slowly began to gradually deviate from what Nikk\u014d viewed as Nichiren's orthodox teachings. Chief among these complaints was the syncretic practices of some of the disciples to worship images of Shakyamuni Buddha. Nikk\u014d admonished other disciple priests for signing their names \"Tendai Shamon\" (of the Tendai Buddhist school) in documents they sent to the Kamakura government. Furthermore, Nikk\u014d alleged that the other disciples disregarded some of Nichiren's writings written in Katakana rather than in Classical Chinese.\nSanenaga defended his actions, claiming that it was customary for his political family to provide monetary donations and make homage to the Shinto shrine of the Kamakura shogunate. Nik\u014d tolerated Sanenaga's acts, claiming that similar incidents occurred previously with the knowledge of Nichiren. Sanenaga sided with Nik\u014d and Nikk\u014d departed in 1289 from Minobu. He returned to his home in Suruga Province and established two temples: Taiseki-ji in the Fuji district and Honmon-ji in Omosu district. He spent most of his life at the latter, where he trained his followers.\nAccording to Stone, it is not absolutely clear that Nikk\u014d intended to completely break from the other senior disciples and start his own school. However, his followers claimed that he was the only one of the six senior disciples who maintained the purity of Nichiren's legacy. Two documents appeared, first mentioned and discovered by Taiseki-ji High Priest Nikkyo Shonin in 1488, claiming Nichiren transferred his teaching exclusively to Nikk\u014d but their authenticity has been questioned. Taiseki-ji does not dispute that the original documents are missing but holds that certified copies are preserved in their repositories. In contrast, other Nichiren sects vehemently claim them as forgeries since they are not in the original handwriting of Nichiren or Nikk\u014d, holding they were copied down by Nikk\u014d's disciples after his death.\"\nIn addition to using the letters to defend its claim to orthodoxy, the documents may have served to justify Taiseki-ji's claimed superiority over other Nikk\u014d temples, especially Honmon-ji, the site of Nichiren's tomb. Even though there had been efforts by temples of the Nikk\u014d lineage in the late 19th century to unify into one single separate Nichiren school the \"Kommon-ha\", today's Nichiren Sh\u014dsh\u016b comprises only the Taiseki-ji temple and its dependent temples. It is not identical to the historical Nikk\u014d or Fuji lineage. Parts of the \"Kommon-ha\", the \"Honmon-sh\u016b\", eventually became part of Nichiren Sh\u016b in the 1950s. Japanese new religious movements such as the S\u014dka Gakkai, Sh\u014dshinkai, and Kensh\u014dkai trace their origins to the Nichiren Sh\u014dsh\u016b school and they all eventually branched from it.\n15th century through the early 19th century.\nIn the early 14th century Hokkesh\u016b followers spread the teachings westward and established congregations (Jpn. ) into the imperial capital of Kyoto and as far as Bizen and Bitchu. During this time there is documentation of face-to-face public debates between Hokkesh\u016b and Nembutsu adherents. By the end of the century Hokkesh\u016b temples had been founded all over Kyoto, only being outnumbered by Zen temples. The demographic base of support in Kyoto were members of the merchant class (Jpn. ), some of whom had acquired great wealth. Tanabe hypothesizes they were drawn to this faith because of Nichiren's emphasis on the \"third realm\" (Jpn. ) of the Lotus Sutra, staked out in chapters 10\u201322, which emphasize practice in the mundane world.\nIn the 15th century, the political and social order began to collapse and Hokkesh\u016b followers armed themselves. The \"Hokke-ikki\" was an uprising in 1532 of Hokke followers against the followers of the Pure Land school in 1532. Initially successful it became the most powerful religious group in Kyoto but its fortunes were reversed in 1536 when Mt. Hiei armed forces destroyed twenty-one Hokkesh\u016b temples and killed some 58,000 of its followers. In 1542 permission was granted by the government to rebuild the destroyed temples and the Hokke \"machish\u016b\" played a crucial role in rebuilding the commerce, industry, and arts in Kyoto. Their influence in the arts and literature continued through the Momoyama (1568\u20131615) and Edo (1615\u20131868) periods and many of the most famous artists and literati were drawn from their ranks.\nAlthough the various sects of Nichiren Buddhism were administratively independent, there is evidence of cooperation between them. For example, in 1466 the major Hokke temples in Kyoto signed the Kansh\u014d-era accord (Kansh\u014d \"meiyaku\") to protect themselves against threats from Mt. Hiei. Despite strong sectarian differences, there is also evidence of interactions between Hokkesh\u016b and Tendai scholar-monks.\nDuring the Edo period, with the consolidation of power by the Tokugawa shogunate, increased pressure was placed on major Buddhist schools and Nichiren temples to conform to governmental policies. Some Hokkesh\u016b adherents, the followers of the so-called Fuju-fuse lineage, adamantly bucked this policy based on their readings of Nichiren's teachings to neither take (\"fuju\") nor give (\"fuse\") offerings from non-believers. Suppressed, adherents often held their meetings clandestinely which led to the Fuju-fuse persecution and numerous executions of believers in 1668. During this time of persecution, most likely to prevent young priests from adopting a passion for propagation, Nichiren seminaries emphasized Tendai studies with only a few top-ranking students permitted to study some of Nichiren's writings.\nDuring the Edo period the majority of Hokkesh\u016b temples were subsumed into the shogunate's Danka system, an imposed nationwide parish system designed to ensure religious peace and root out Christianity. In this system Buddhist temples, in addition to their ceremonial duties, were forced to carry out state administrative functions. Thereby they became agents of the government and were prohibited to engage in any missionary activities. Hokkesh\u016b temples were now obligated, just like those of other Buddhist schools, to focus on funeral and memorial services (\"S\u014dshiki bukky\u014d\") as their main activity. Stagnation was often the price for the protected status.\n19th century: From Tokugawa to Meiji periods.\nNichiren Buddhism was deeply influenced by the transition from the Tokugawa (1600\u20131868) to Meiji (1868\u20131912) periods in nineteenth-century Japan. The changeover from early modern (\"kinsei\") to modern (\"kindai\") was marked by the transformation of late-feudal institutions into modern ones as well as the political transition from shogunal to imperial rule and the economic shift from national isolation to integration in the world economy. This entailed creating a centralized state, stitching together some 260 feudal domains ruled by hereditary leaders (\"daimy\u014d\"), and moving from a caste social system to a meritocracy based on educational achievement. Although commonly perceived as a singular event called the Meiji Restoration, the transition was full of twists and turns that began in the later Tokugawa years and continued decades after the 1867\u20131868 demise of the shogunate and launch of imperial rule.\nBy this time Japanese Buddhism was often characterized by syncretism in which local nativistic worship was incorporated into Buddhist practice. For example, Tendai, Shingon, Jod\u014d, and Nichiren temples often had chapels within them dedicated to Inari Shinto worship. Within Nichiren Buddhism there was a phenomenon of (Lotus Shinto), closely influenced by Yoshida Shint\u014d.\nAnti-Buddhist sentiment had been building throughout the latter part of the Tokugawa period (1603\u20131868). Scholars such as Tominaga Nakamoto and Hirata Atsutane attacked the theoretical roots of Buddhism. Critics included promoters of Confucianism, nativism, Shinto-inspired Restorationists, and modernizers. Buddhism was critiqued as a needless drain on public resources and also as an insidious foreign influence that had obscured the indigenous Japanese spirit.\nUnder attack by two policies of the day, \"shinbutsu bunri\" (Separation of Shinto Deities and Buddhas) and \"haibutsu kishaku\" (Eradication of Buddhism), Japanese Buddhism during the Tokugawa-to-Meiji transition proved to be a crisis of survival. The new government promoted policies that reduced the material resources available to Buddhist temples and downgraded their role in the religious, political, and social life of the nation.\nThe policies of \"shibutsu bunri\" were implemented at the local level throughout Japan but were particularly intense in three domains that were the most active in the Restoration: Satsuma, Choshii, and Tosa. In Satsuma, for example, by 1872 all of its 1000+ Buddhist temples had been abolished, their monks laicized, and their landholdings confiscated. Throughout the country thousands of Buddhist temples and, at a minimum, tens of thousands of Buddhist sutras, paintings, statues, temple bells and other ritual objects were destroyed, stolen, lost, or sold during the early years of the restoration.\nStarting in the second decade of the restoration, pushback against these policies came from Western powers interested in providing a safe harbor for Christianity and Buddhist leaders who proposed an alliance of Shinto and Buddhism to resist Christianity. As part of this accommodation, Buddhist priests were forced to promote key teachings of Shinto and provide support for national policies.\nNichiren Buddhism, like the other Buddhist schools, struggled between accommodation and confrontation. The Nichiren scholar Udana-in Nichiki (1800\u20131859) argued for a policy of co-existence with other schools of Buddhism, Confucianism, Shinto, and European religions. His disciple Arai Nissatsu (1830\u20131888) forged an alliance of several Nichiren branches and became the first superintendent of the present Nichiren Sh\u016b which was incorporated in 1876. Nissatsu was active in Buddhist intersect cooperation to resist the government's hostile policies, adopted the government's \"Great Teaching\" policy that was Shinto-derived, and promoted intersectarian understanding. In the process, however, he reinterpreted some of Nichiren's important teachings. Among those arguing against accommodation were Nichiren scholar and lay believer Ogawa Taid\u014d (1814\u20131878) and the cleric Honda Nissh\u014d (1867\u20131931) of the Kempon Hokke denomination.\nAfter the above events and centuries of splintering based on dogma and institutional histories, the following major Nichiren temple schools, according to Matsunaga, were officially recognized in the Meiji era:\nMy\u014dmanji-ha became Kempon Hokke based at My\u014dmanji, Kyoto\nHappon-ha became Honmon Hokkesh\u016b based in Honj\u014dji, Niigata\nHonj\u014dji-ha became Hokkesh\u016b based in Honry\u016bji, Kyoto\nHonry\u016bji-ha became Honmy\u014d Hokkesh\u016b, also based in Honry\u016bji, Kyoto\nFuji-ha became Honmonsh\u016b in Monmonji, Shizuoka\nDevelopment in modern Japanese history.\nNichiren Buddhism went through many reforms in the Meiji Period during a time of persecution, , when the government attempted to eradicate mainstream Japanese Buddhism. As a part of the Meiji Restoration, the interdependent Danka system between the state and Buddhist temples was dismantled which left the latter without its funding. Buddhist institutions had to align themselves to the new nationalistic agenda or perish. Many of these reform efforts were led by lay people.\nThe trend toward lay centrality was prominent in Nichiren Buddhism as well, predating the Meiji period. Some Nichiren reformers in the Meiji period attempted to inject a nationalistic interpretation of Nichiren's teachings; others called for globalist perspectives. According to Japanese researcher \"Yoshiro Tamura\", the term \"Nichirenism\" applies broadly to the following three categories:\nAs a form of nationalism.\nBoth Nichiren and his followers have been associated with fervent Japanese nationalism specifically identified as Nichirenism between the Meiji period and the conclusion of World War II. The nationalistic interpretation of Nichiren's teachings were inspired by lay Buddhist movements like Kokuch\u016bkai and resulted in violent historical events such as the May 15 Incident and the League of Blood Incident. Among the key proponents of this interpretation are Chigaku Tanaka who founded the Kokuch\u016bkai (English: Nation's Pillar Society). Tanaka was charismatic and through his writings and lecturers attracted many followers such as Kanji Ishiwara. Nissh\u014d Honda advocated the unification of Japanese Buddhists to support the imperial state. Other nationalist activists who based their ideas on Nichiren were Ikki Kita and Nissh\u014d Inoue.\nAs a form of socialism.\nNichirenism also includes several intellectuals and activists who reacted against the prewar nationalistic interpretations and argued for an egalitarian and socialist vision of society based on Nichiren's teachings and the Lotus Sutra. These figures ran against the growing tide of Japanese militarism and were subjected to political harassment and persecution. A leading figure in this group was Gir\u014d Seno'o who formed the New Buddhist Youth League ().\nOriginally influenced by the ideals of Tanaka and Honda, Giro Seno came to reject nationalism and argued for humanism, socialism, pacifism, and democracy as a new interpretation of Nichiren's beliefs. He was imprisoned for two years under the National Security Act. The same fate was also endured by Tsunesabur\u014d Makiguchi, who refused the religious dictum of Shinto display accepted by Nichiren Sh\u014dsh\u016b for the \"Soka Kyoiku Gakkai\", his lay organization composed of primarily secretaries and teachers until it grew to become Soka Gakkai after World War II.\nWithin new social and religious movements.\nSeveral Nichiren-inspired religious movements arose and appealed primarily to this segment of society with a message of alleviating suffering salvation for many poor urban workers. Honmon Butsury\u016b-sh\u016b, an early example of lay-based religious movements of the modern period inspired by Nichiren, was founded several years before the Meiji Restoration. Reiy\u016bkai, Rissh\u014d K\u014dseikai stemming from Nichiren Sh\u016b while Kensh\u014dkai and Soka Gakkai once affiliated with Nichiren Sh\u014dsh\u016b and the Japanese principle \"Shin\" (\u4fe1 ), \"Gyo\" (\u884c), \"Gaku\" (\u5b66) as \"Faith, Practices, Study\", are more recent examples of lay-inspired movements drawing from Nichiren's teachings and life.\nIn culture and literature.\nNichiren Buddhism has had a major impact on Japan's literary and cultural life. Japanese literary figure Takayama Chogy\u016b and children's author Kenji Miyazawa praised Nichiren's teachings. A prominent researcher, Masaharu Anesaki, was encouraged to study Nichiren which led to the work \"Nichiren: The Buddhist Prophet\" which introduced Nichiren to the West. Non-Buddhist Japanese individuals such as Uchimura Kanz\u014d listed Nichiren as one of five historical figures who best represented Japan, while Tadao Yanaihara described Nichiren as one of the four historical figures he most admired.\nGlobalization.\nWhile various sects and organizations have had a presence in nations outside Japan for over a century, the genuine expansion of Nichiren Buddhism overseas started in 1960 when Soka Gakkai president Daisaku Ikeda initiated his group's worldwide propagation efforts stemming from a few hundred transplanted Japanese to over 3500 families by 1962.\nNichiren Buddhism is now practiced in many countries outside of Japan. In the United States, religious studies scholar Charles S. Prebish coined the typology of \"two Buddhisms\" to delineate the divide between forms of Buddhism that appealed either primarily to people of the Asian diaspora or to Euro-American converts. Nattier, on the other hand, proposes a three-way typology. \"Import\" or \"elite\" Buddhism refers to a class of people who have the time and means to seek Buddhist teachers to appropriate certain Buddhist techniques such as meditation. \"Export\" or \"evangelical\" Buddhism refers to groups that actively proselytize for new members in their local organizations. \"Baggage\" or \"ethnic\" Buddhism refers to diaspora Buddhists, usually of a single ethnic group, who have relocated more for social and economic advancement than for evangelical purposes. Another taxonomy divides Western Buddhist groups into three different categories: evangelical, church-like, and meditational.\nNichiren Sh\u016b has been classified into the church-like category. One of several Japanese Buddhist schools that followed in the wake of Japanese military conquest and colonization, Nichiren Sh\u016b opened a temple in Pusan, Korea in 1881. Its fortunes rose and diminished with the political tides but eventually failed. It also established missions in Sakhalin, Manchuria, and Taiwan. A Nichiren Sh\u016b mission was established in Hawaii in 1900. By 1920 it established temples at Pahala, Honolulu, Wailuku and Maui. In 1955, it officially started a mission in Brazil. In 1991, it established the Nichiren Buddhist International Center in 1991 and in 2002 built a center in Hayward, California, to help overseas missions. However, Nichiren Sh\u016b does not widely propagate in the West.\nSome have characterized the Soka Gakkai as evangelical but others claim that it broke out of the \"Two Buddhisms\" paradigm. It is quite multi-ethnic and it has taken hold among native populations in locations including Korea, Malaysia, Brazil, Europe, parts of Africa, India, and North America. The growth of the Soka Gakkai was sparked by repeated missionary trips beginning in the early 1960s by Daisaku Ikeda, its third president. In 1975 the Soka Gakkai International was launched in Guam. In the United States it has attracted a diverse membership including a significant demographic of African Americans. Since the 1970s, it has created institutions, publications and exhibitions to support its overall theme of \"peace, culture, and education.\" There is academic research on various national organizations affiliated with this movement: the United States, the United Kingdom, Italy, Canada, Brazil, Scotland, Southeast Asia, Germany, and Thailand.\nThe Rissh\u014d K\u014dseikai focuses on using its teachings to promote a culture of religiosity through inter-religious dialogue. In 1967, it launched the \"Faith to All Men Movement\" to awaken a globalized religiosity. It has over 2 million members and 300 Dharma centers in 20 countries throughout the world including Frankfurt and Moorslede. It is active in interfaith organizations, including the International Association for Religious Freedom (IARF) and Religions for Peace (WCRP). It has consultative states with the United Nations and since 1983 issues an annual Peace Prize to individuals or organizations worldwide that work for peace and development and promote interreligious cooperation.\nThe Reiy\u016bkai conducts more typical missionary activities in the West. It has a membership of between five hundred and one thousand members in Europe, concentrated in Italy, Spain, England and France. The approximately 1,500 members of the Nipponzan My\u014dh\u014dji have built peace pagodas, conducted parades beating the drum while chanting the daimoku, and encouraged themselves and others to create world peace.\nNichiren Sh\u014dsh\u016b has six temples in the United States led by Japanese priests and supported by lay Asians and non-Asians. There is one temple in Brazil and the residing priest serves as a \"circuit rider\" to attend to other locations.\nLists of major schools and organizations.\nThe following lists are based on English-language Wikipedia articles and the Japanese Wikipedia article on .\nClerical Nichiren Buddhist schools and their head temples.\nIn alphabetical order (Japanese characters preceded by \"Ja:\" link to articles in the Japanese Wikipedia). \n20th-century movements and lay organizations.\nIn alphabetical order (Japanese characters preceded by \"Ja:\" link to articles in the Japanese Wikipedia):\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22138", "revid": "4842600", "url": "https://en.wikipedia.org/wiki?curid=22138", "title": "NODE", "text": ""}
{"id": "22139", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=22139", "title": "NOAD", "text": ""}
{"id": "22141", "revid": "50169936", "url": "https://en.wikipedia.org/wiki?curid=22141", "title": "Newport News Shipbuilding", "text": "American shipyard\nNewport News Shipbuilding (NNS), a division of Huntington Ingalls Industries, is the sole designer, builder, and refueler of aircraft carriers and one of two providers of submarines for the United States Navy, founded as the Chesapeake Dry Dock and Construction Co. in 1886 and located in the city of Newport News, Virginia. Newport News Shipbuilding has built more than 800 ships, including both naval and commercial ships. Its facilities span more than .\nThe shipyard is a major employer for the lower Virginia Peninsula, portions of Hampton Roads south of the James River and the harbor, portions of the Middle Peninsula region, and even some northeastern counties of North Carolina.\nThe shipyard is building two s: , and .\nIn 2013, Newport News Shipbuilding began the deactivation of the nuclear-powered aircraft carrier , which it also built.\nNewport News Shipbuilding also performs refueling and complex overhaul (RCOH) work on s. This is a four-year vessel renewal program that involves refueling the vessel's nuclear reactors and performing modernization work. The yard has completed RCOH for five \"Nimitz\"-class carriers (, , , and ). As of November 2017, this work was underway for the \"Nimitz\"-class vessel .\nHistory.\nIndustrialist Collis P. Huntington (1821\u20131900) provided crucial funding to complete the Chesapeake and Ohio Railroad (C&amp;O) from Richmond, Virginia, to the Ohio River in the early 1870s. Although originally built for general commerce, this C&amp;O rail link to the midwest was soon also being used to transport bituminous coal from the previously isolated coalfields, adjacent to the New River and the Kanawha River in West Virginia. In 1881, the Peninsula Extension of the C&amp;O was built from Richmond down the Virginia Peninsula to reach a new coal pier on Hampton Roads in Warwick County near the small unincorporated community of Newport News Point. However, building the railroad and coal pier was only the first part of Huntington's dreams for Newport News.\nThe shipyard's early years.\nIn 1886, Huntington built a shipyard to repair ships servicing this transportation hub. In 1891 Newport News Shipbuilding and Drydock Company delivered its first ship, the tugboat \"Dorothy\". By 1897 NNS had built three warships for the US Navy: , and .\nWhen Collis died in 1900, his nephew Henry E. Huntington inherited much of his uncle's fortune. He also married Collis' widow Arabella Huntington, and assumed Collis' leadership role with Newport News Shipbuilding and Drydock Company. Under Henry Huntington's leadership, growth continued.\nIn 1906 the revolutionary launched a great naval race worldwide. Between 1907 and 1923, Newport News built six of the US Navy's total of 22 dreadnoughts \u2013 , , , , and . All but the first were in active service in World War II. In 1907 President Theodore Roosevelt sent the Great White Fleet on its round-the-world voyage. NNS had built seven of its 16 battleships.\nIn 1914 NNS built SS \"Medina\" for the Mallory Steamship Company; as she was until 2009 the world's oldest active ocean-faring passenger ship.\nNewport News and the shipyard.\nIn the early years, leaders of the Newport News community and those of the shipyard were virtually interchangeable. Shipyard president Walter A. Post served from March 9, 1911, to February 12, 1912, when he died. Earlier, he had come to the area as one of the builders of the C&amp;O Railway's terminals, and had served as the first mayor of Newport News after it became an independent city in 1896. It was on March 14, 1914, that Albert Lloyd Hopkins, a young New Yorker trained in engineering, succeeded Post as president of the company. In May 1915 while traveling to England on shipyard business aboard , Hopkins died when that ship was torpedoed and sunk by a German U-boat off Queenstown on the Irish coast. His assistant, Frederic Gauntlett, was also on board, but was able to swim to safety. Homer Lenoir Ferguson was company vice president when Hopkins died, and assumed the presidency the following August. He saw the company through both world wars, became a noted community leader, and was a co-founder of the Mariners' Museum with Archer Huntington. He served until July 31, 1946, after World War II had ended on both the European and Pacific fronts.\nJust northwest of the shipyard, Hilton Village, one of the first planned communities in the country, was built by the federal government to house shipyard workers in 1918. The planners met with the wives of shipyard workers. Based on their input 14 house plans were designed for the projected 500 English-village-style homes. After the war, in 1922, Henry Huntington acquired it from the government, and helped facilitate the sale of the homes to shipyard employees and other local residents. Three streets there were named after Post, Hopkins, and Ferguson.\nNavy orders during and after World War I.\n The \"Lusitania\" incident was among the events that brought the United States into World War I. Between 1918 and 1920 NNS delivered 25 destroyers, and after the war it began building aircraft carriers. was delivered in 1934, and NNS went on to build and .\n In 1917, the year the U.S entered World War I, the Newport News Shipbuilding &amp; Drydock Company was contracted to build several ships for the U.S military. In order to fulfill this contract, the company had to hire thousands of employees from across the country. However, a large problem arose: the city of Newport News did not have the housing to support this large influx of its population. This led to the creation of Hilton Village, a neighborhood still found in Newport News, Virginia, today, that was created to house these workers.\nOcean liners.\nAfter World War I NNS completed a major reconditioning and refurbishment of the ocean liner . Before the war she had been the German liner \"Vaterland\", but the start of hostilities found her laid up in New York Harbor and she had been seized by the US Government in 1917 and converted into a troopship. War duty and age meant that all wiring, plumbing, and interior layouts were stripped and redesigned while her hull was strengthened and her boilers converted from coal to oil while being refurbished. Virtually a new ship emerged from NNS in 1923, and SS \"Leviathan\" became the flagship of United States Lines.\nIn 1927 NNS launched the world's first significant turbo-electric ocean liner: Panama Pacific Line's \u00a0GRT . At the time she was also the largest merchant ship yet built in the United States, although she was a modest size compared with the biggest European liners of her era. NNS launched \"California\"'s sister ships \"Virginia\" in 1928 and \"Pennsylvania\" in 1929. NNS followed them by launching two even larger turbo-electric liners for Dollar Steamship Company: the \u00a0GRT in 1930, followed by her sister in 1931. was launched in 1939 and entered service with United States lines shortly before World War II but soon returned to the shipyard for conversion to a troopship, USS \"West Point\".\nNavy orders before and during World War II.\nBy 1940 the Navy had ordered a battleship, seven more aircraft carriers and four cruisers. During World War II, NNS built ships as part of the U.S. government's Emergency Shipbuilding Program, and swiftly filled requests for \"Liberty ships\" that were needed during the war. It founded the North Carolina Shipbuilding Company, an emergency yard on the banks of the Cape Fear River and launched its first Liberty ship before the end of 1941, building 243 ships in all, including 186 Libertys. For its contributions during the war, the Navy awarded the company its \"E\" pennant for excellence in shipbuilding. NNS ranked 23rd among United States corporations in the value of wartime production contracts.\nPost-war ships.\nIn the post-war years NNS built the passenger liner , which set a transatlantic speed record that still stands today. In 1954 NNS, Westinghouse and the US Navy developed and built a prototype nuclear reactor for a carrier propulsion system. NNS designed in 1960. In 1959 NNS launched its first nuclear-powered submarine, .\nIn the 1970s, NNS launched two of the largest tankers ever built in the western hemisphere and also constructed three liquefied natural gas carriers \u2013 at over 390,000 deadweight tons, the largest ever built in the United States. NNS and Westinghouse Electric Company jointly formed Offshore Power Systems to build floating nuclear power plants for Public Service Electric and Gas Company.\nIn the 1980s, NNS produced a variety of Navy products, including nuclear aircraft carriers and nuclear attack submarines. Since 1999 the shipyard has only produced warships for the Navy.\nSubmarine building problems.\nIn 2007, the US Navy found that workers had used the incorrect metal to fuse together pipes and joints on submarines under construction and this could have eventually led to cracking and leaks. In 2009 it was found that bolts and fasteners in weapons-handling systems on four Navy submarines, , , , and , were installed incorrectly, delaying the launching of the boats while the problems were corrected.\nMergers, realignment, and spin-off.\nIn 1968, Newport News merged with Tenneco Corporation. In 1996, Tenneco initiated a spinoff of Newport News into an independent company (Newport News Shipbuilding). In 2001, General Dynamics made a second bid to purchase the company after a failed bid in 1999. Such a merger would have eliminated competition for the production of \"Virginia\"-class submarines, which have only been made by Newport News and GD subsidiary Electric Boat. Northrop Grumman matched GD with a similar bid, and following a Department of Justice anti-trust lawsuit to block GD's bid, GD called off their bid. Now as the sole bidder, Northrop Grumman purchased the company for $2.6 billion and renamed it \"Northrop Grumman Newport News\". This division was merged with Northrop Grumman Ship Systems in 2008 and given the name \"Northrop Grumman Shipbuilding\". Three years later, the company was spun off as Huntington Ingalls Industries, Inc., which trades under the symbol HII on the New York Stock Exchange.\nShips built.\nOther ships built at the Newport News yard include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22142", "revid": "13051", "url": "https://en.wikipedia.org/wiki?curid=22142", "title": "Nicolas of Myra", "text": ""}
{"id": "22145", "revid": "29330520", "url": "https://en.wikipedia.org/wiki?curid=22145", "title": "Newton's method", "text": "Algorithm for finding zeros of functions\nIn numerical analysis, the Newton\u2013Raphson method, also known simply as Newton's method, named after Isaac Newton and Joseph Raphson, is a root-finding algorithm which produces successively better approximations to the roots (or zeroes) of a real-valued function. The most basic version starts with a real-valued function f, its derivative , and an initial guess for a root of f. If f satisfies certain assumptions and the initial guess is close, then\nformula_1\nis a better approximation of the root than . Geometrically, is the x-intercept of the tangent to the graph of f at : that is, the improved guess, , is the unique root of the linear approximation of f at the initial guess, . The process is repeated as\nformula_2\nuntil a sufficiently precise value is reached. The number of correct digits roughly doubles with each step. This algorithm is first in the class of Householder's methods, and was succeeded by Halley's method. The method can also be extended to complex functions and to systems of equations.\nDescription.\nThe purpose of Newton's method is to find a root of a function. The idea is to start with an initial guess near a root, approximate the function by its tangent line near the guess, and then take the root of the linear approximation as a next guess at the function's root. This will typically be closer to the function's root than the previous guess, and the method can be iterated.\nThe best linear approximation to an arbitrary differentiable function formula_3 near the point formula_4 is the tangent line to the curve, with equation\nformula_5\nThe root of this linear function, the place where it intercepts the &amp;NoBreak;&amp;NoBreak;-axis, can be taken as a closer approximate root &amp;NoBreak;}&amp;NoBreak;:\nformula_6\nThe process can be started with any arbitrary initial guess &amp;NoBreak;&amp;NoBreak;, though it will generally require fewer iterations to converge if the guess is close to one of the function's roots. The method will usually converge if &amp;NoBreak;&amp;NoBreak;. Furthermore, for a root of multiplicity\u00a01, the convergence is at least quadratic (see \"Rate of convergence\") in some sufficiently small neighbourhood of the root: the number of correct digits of the approximation roughly doubles with each additional step. More details can be found in \"\" below.\nHouseholder's methods are similar but have higher order for even faster convergence. However, the extra computations required for each step can slow down the overall performance relative to Newton's method, particularly if &amp;NoBreak;&amp;NoBreak; or its derivatives are computationally expensive to evaluate.\nHistory.\nIn the Old Babylonian period (19th\u201316th century BCE), the side of a square of known area could be effectively approximated, and this is conjectured to have been done using a special case of Newton's method, described algebraically below, by iteratively improving an initial estimate; an equivalent method can be found in Hero of Alexandria's \"Metrica\" (1st\u20132nd century CE), so is often called \"Heron's method\". Jamsh\u012bd al-K\u0101sh\u012b used a method to solve to find roots of \"N\", a method that was algebraically equivalent to Newton's method, and in which a similar method was found in \"Trigonometria Britannica\", published by Henry Briggs in 1633. His method first appeared in his 1427 publication \"Mift\u0101\u1e25 al-\u1e24is\u0101b\" (\"The Key to Arithmetic\"). Al-K\u0101sh\u012b's work was founded on the earlier contributions of the polymath al-B\u012br\u016bn\u012b (973\u20131048) and the mathematician Sharaf al-D\u012bn al-\u1e6c\u016bs\u012b (1135\u20131213). The contributions of al-K\u0101sh\u012b remained largely unknown to the Western scientific community for centuries, until the work of Fran\u00e7ois Vi\u00e8te (1540\u20131603). In 1600, Vi\u00e8te rediscovered a technique similar to al-K\u0101sh\u012b's in the context of solving scalar polynomial equations of degree six.\nThe method that laid the groundwork for what is now the modern Newton's method which would be developed by Joseph Raphson and Thomas Simpson first appeared in Isaac Newton's work in \"De analysi per aequationes numero terminorum infinitas\" (written in 1669, published in 1711 by William Jones) and in \"De metodis fluxionum et serierum infinitarum\" (written in 1671, translated and published as \"Method of Fluxions\" in 1736 by John Colson). However, while Newton gave the basic ideas, his method differs from the modern method given above. He applied the method only to polynomials, starting with an initial root estimate and extracting a sequence of error corrections. He used each correction to rewrite the polynomial in terms of the remaining error, and then solved for a new correction by neglecting higher-degree terms. He did not explicitly connect the method with derivatives or present a general formula. Newton applied this method to both numerical and algebraic problems, producing Taylor series in the latter case. Despite this, in the later second and third editions of Newton's 1687 \"Philosophi\u00e6 Naturalis Principia Mathematica\", he did apply his method in an iterative manner to a nonpolynomial equation, specifically Kepler's equation, which were the first published uses of Newton's method in this form by him.\nNewton may have derived his method from a similar, less precise method by mathematician Vi\u00e8te, however, the two methods are not the same. The essence of Vi\u00e8te's own method can be found in the work of the mathematician Sharaf al-Din al-Tusi.\nThe Japanese mathematician Seki K\u014dwa used a form of Newton's method in the 1680s to solve single-variable equations, though the connection with calculus was missing.\nNewton's method was first published in 1685 in \"A Treatise of Algebra both Historical and Practical\" by John Wallis. In 1690, Raphson published a simplified description in \"Analysis aequationum universalis\". Raphson also applied the method only to polynomials, but he avoided Newton's tedious rewriting process by extracting each successive correction from the original polynomial. This allowed him to derive a reusable iterative expression for each problem. Finally, in 1740, Simpson described Newton's method as an iterative method for solving general nonlinear equations using calculus, essentially giving the description above. In the same publication, Simpson also gives the generalization to systems of two equations and notes that Newton's method can be used for solving optimization problems by setting the gradient to zero.\nArthur Cayley in 1879 in \"The Newton\u2013Fourier imaginary problem\" was the first to notice the difficulties in generalizing Newton's method to complex roots of polynomials with degree greater than 2 and complex initial values. This opened the way to the study of the theory of iterations of rational functions.\nPractical considerations.\nNewton's method is a powerful technique\u2014if the derivative of the function at the root is nonzero, then the convergence is at least quadratic: as the method converges on the root, the difference between the root and the approximation is squared (the number of accurate digits roughly doubles) at each step. However, there are some difficulties with the method.\nDifficulty in calculating the derivative of a function.\nNewton's method requires that the derivative can be calculated directly. An analytical expression for the derivative may not be easily obtainable or could be expensive to evaluate. In these situations, it may be appropriate to approximate the derivative by using the slope of a line through two nearby points on the function. Using this approximation would result in something like the secant method whose convergence is slower than that of Newton's method.\nFailure of the method to converge to the root.\nIt is important to review the proof of quadratic convergence of Newton's method before implementing it. Specifically, one should review the assumptions made in the proof. For situations where the method fails to converge, it is because the assumptions made in this proof are not met.\nFor example, in some cases, if the first derivative is not well behaved in the neighborhood of a particular root, then it is possible that Newton's method will fail to converge no matter where the initialization is set. In some cases, Newton's method can be stabilized by using successive over-relaxation, or the speed of convergence can be increased by using the same method.\nIn a robust implementation of Newton's method, it is common to place limits on the number of iterations, bound the solution to an interval known to contain the root, and combine the method with a more robust root finding method.\nSlow convergence for roots of multiplicity greater than 1.\nIf the root being sought has multiplicity greater than one, the convergence rate is merely linear (errors reduced by a constant factor at each step) unless special steps are taken. When there are two or more roots that are close together then it may take many iterations before the iterates get close enough to one of them for the quadratic convergence to be apparent. However, if the multiplicity m of the root is known, the following modified algorithm preserves the quadratic convergence rate:\nformula_7\nThis is equivalent to using successive over-relaxation. On the other hand, if the multiplicity m of the root is not known, it is possible to estimate m after carrying out one or two iterations, and then use that value to increase the rate of convergence.\nIf the multiplicity m of the root is finite then g(x) = will have a root at the same location with multiplicity 1. Applying Newton's method to find the root of recovers quadratic convergence in many cases although it generally involves the second derivative of . In a particularly simple case, if f(x) = x then g(x) = and Newton's method finds the root in a single iteration with\nformula_8\nSlow convergence.\nThe function \"f\"(\"x\") \n \"x\"2 has a root at 0. Since f is continuously differentiable at its root, the theory guarantees that Newton's method as initialized sufficiently close to the root will converge. However, since the derivative \"f\" \u2032 is zero at the root, quadratic convergence is not ensured by the theory. In this particular example, the Newton iteration is given by\nformula_9\nIt is visible from this that Newton's method could be initialized anywhere and converge to zero, but at only a linear rate. If initialized at 1, dozens of iterations would be required before ten digits of accuracy are achieved.\nThe function \"f\"(\"x\") \n \"x\" + \"x\"4/3 also has a root at 0, where it is continuously differentiable. Although the first derivative \"f\" \u2032 is nonzero at the root, the second derivative \"f\" \u2032\u2032 is nonexistent there, so that quadratic convergence cannot be guaranteed. In fact the Newton iteration is given by\nformula_10\nFrom this, it can be seen that the rate of convergence is superlinear but subquadratic. This can be seen in the following tables, the left of which shows Newton's method applied to the above \"f\"(\"x\") \n \"x\" + \"x\"4/3 and the right of which shows Newton's method applied to \"f\"(\"x\") \n \"x\" + \"x\"2. The quadratic convergence in iteration shown on the right is illustrated by the orders of magnitude in the distance from the iterate to the true root (0,1,2,3,5,10,20,39...) being approximately doubled from row to row. While the convergence on the left is superlinear, the order of magnitude is only multiplied by about 4/3 from row to row (0,1,2,4,5,7,10,13...).\nThe rate of convergence is distinguished from the number of iterations required to reach a given accuracy. For example, the function \"f\"(\"x\") \n \"x\"20 \u2212 1 has a root at 1. Since \"f\" \u2032(1) \u2260 0 and f is smooth, it is known that any Newton iteration convergent to 1 will converge quadratically. However, if initialized at 0.5, the first few iterates of Newton's method are approximately 26214, 24904, 23658, 22476, decreasing slowly, with only the 200th iterate being 1.0371. The following iterates are 1.0103, 1.00093, 1.0000082, and 1.00000000065, illustrating quadratic convergence. This highlights that quadratic convergence of a Newton iteration does not mean that only few iterates are required; this only applies once the sequence of iterates is sufficiently close to the root.\nConvergence dependent on initialization.\nThe function \"f\"(\"x\") \n \"x\"(1 + \"x\"2)\u22121/2 has a root at 0. The Newton iteration is given by\nformula_11\nFrom this, it can be seen that there are three possible phenomena for a Newton iteration. If initialized strictly between \u00b11, the Newton iteration will converge (super-)quadratically to 0; if initialized exactly at 1 or \u22121, the Newton iteration will oscillate endlessly between \u00b11; if initialized anywhere else, the Newton iteration will diverge. This same trichotomy occurs for \"f\"(\"x\") \n arctan \"x\".\nIn cases where the function in question has multiple roots, it can be difficult to control, via choice of initialization, which root (if any) is identified by Newton's method. For example, the function \"f\"(\"x\") \n \"x\"(\"x\"2 \u2212 1)(\"x\" \u2212 3)e\u2212(\"x\" \u2212 1)2/2 has roots at \u22121, 0, 1, and 3. If initialized at \u22121.488, the Newton iteration converges to 0; if initialized at \u22121.487, it diverges to \u221e; if initialized at \u22121.486, it converges to \u22121; if initialized at \u22121.485, it diverges to \u2212\u221e; if initialized at \u22121.4843, it converges to 3; if initialized at \u22121.484, it converges to 1. This kind of subtle dependence on initialization is not uncommon; it is frequently studied in the complex plane in the form of the Newton fractal.\nDivergence even when initialization is close to the root.\nConsider the problem of finding a root of \"f\"(\"x\") \n \"x\"1/3. The Newton iteration is\nformula_12\nUnless Newton's method is initialized at the exact root 0, it is seen that the sequence of iterates will fail to converge. For example, even if initialized at the reasonably accurate guess of 0.001, the first several iterates are \u22120.002, 0.004, \u22120.008, 0.016, reaching 1048.58, \u22122097.15, ... by the 20th iterate. This failure of convergence is not contradicted by the analytic theory, since in this case f is not differentiable at its root.\nIn the above example, failure of convergence is reflected by the failure of \"f\"(\"x\"\"n\") to get closer to zero as n increases, as well as by the fact that successive iterates are growing further and further apart. However, the function \"f\"(\"x\") \n \"x\"1/3e\u2212\"x\"2 also has a root at 0. The Newton iteration is given by\nformula_13\nIn this example, where again f is not differentiable at the root, any Newton iteration not starting exactly at the root will diverge, but with both \"x\"\"n\" + 1 \u2212 \"x\"\"n\" and \"f\"(\"x\"\"n\") converging to zero. This is seen in the following table showing the iterates with initialization 1:\nAlthough the convergence of \"x\"\"n\" + 1 \u2212 \"x\"\"n\" in this case is not very rapid, it can be proved from the iteration formula. This example highlights the possibility that a stopping criterion for Newton's method based only on the smallness of \"x\"\"n\" + 1 \u2212 \"x\"\"n\" and \"f\"(\"x\"\"n\") might falsely identify a root.\nOscillatory behavior.\nIt is easy to find situations for which Newton's method oscillates endlessly between two distinct values. For example, for Newton's method as applied to a function f to oscillate between 0 and 1, it is only necessary that the tangent line to f at 0 intersects the x-axis at 1 and that the tangent line to f at 1 intersects the x-axis at 0. This is the case, for example, if \"f\"(\"x\") \n \"x\"3 \u2212 2\"x\" + 2. For this function, it is even the case that Newton's iteration as initialized sufficiently close to 0 or 1 will \"asymptotically\" oscillate between these values. For example, Newton's method as initialized at 0.99 yields iterates 0.99, \u22120.06317, 1.00628, 0.03651, 1.00196, 0.01162, 1.00020, 0.00120, 1.000002, and so on. This behavior is present despite the presence of a root of f approximately equal to \u22121.76929.\nUndefinedness of Newton's method.\nIn some cases, it is not even possible to perform the Newton iteration. For example, if \"f\"(\"x\") \n \"x\"2 \u2212 1, then the Newton iteration is defined by\nformula_14\nSo Newton's method cannot be initialized at 0, since this would make \"x\"1 undefined. Geometrically, this is because the tangent line to f at 0 is horizontal (i.e. \"f\" \u2032(0) \n 0), never intersecting the \"x\"-axis.\nEven if the initialization is selected so that the Newton iteration can begin, the same phenomenon can block the iteration from being indefinitely continued.\nIf f has an incomplete domain, it is possible for Newton's method to send the iterates outside of the domain, so that it is impossible to continue the iteration. For example, the natural logarithm function \"f\"(\"x\") \n ln \"x\" has a root at 1, and is defined only for positive x. Newton's iteration in this case is given by\nformula_15\nSo if the iteration is initialized at e, the next iterate is 0; if the iteration is initialized at a value larger than e, then the next iterate is negative. In either case, the method cannot be continued.\nAnalysis.\nSuppose that the function f has a zero at \u03b1, i.e., , and f is differentiable in a neighborhood of \u03b1.\nIf f is continuously differentiable and its derivative is nonzero at\u00a0\u03b1, then there exists a neighborhood of \u03b1 such that for all starting values in that neighborhood, the sequence will converge to \u03b1.\nIf f is continuously differentiable, its derivative is nonzero at\u00a0\u03b1, \"and\" it has a second derivative at\u00a0\u03b1, then the convergence is quadratic or faster. If the second derivative is not 0 at \u03b1 then the convergence is merely quadratic. If the third derivative exists and is bounded in a neighborhood of \u03b1, then:\nformula_16\nwhere\nformula_17\nIf the derivative is 0 at \u03b1, then the convergence is usually only linear. Specifically, if f is twice continuously differentiable, and , then there exists a neighborhood of \u03b1 such that, for all starting values in that neighborhood, the sequence of iterates converges linearly, with rate . Alternatively, if and for , x\u00a0in a neighborhood U of \u03b1, \u03b1 being a zero of multiplicity r, and if , then there exists a neighborhood of \u03b1 such that, for all starting values in that neighborhood, the sequence of iterates converges linearly.\nHowever, even linear convergence is not guaranteed in pathological situations.\nIn practice, these results are local, and the neighborhood of convergence is not known in advance. But there are also some results on global convergence: for instance, given a right neighborhood of \u03b1, if f is twice differentiable in and if , in , then, for each in the sequence is monotonically decreasing to \u03b1.\nProof of quadratic convergence for Newton's iterative method.\nAccording to Taylor's theorem, any function which has a continuous second derivative can be represented by an expansion about a point that is close to a root of . Suppose this root is \u03b1. Then the expansion of about is:\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nwhere the Lagrange form of the Taylor series expansion remainder is\nformula_18\nwhere is in between and \u03b1.\nSince \u03b1 is the root, (1) becomes:\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nDividing equation (2) by and rearranging gives\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nRemembering that is defined by\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\none finds that\nformula_19\nThat is,\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nTaking the absolute value of both sides gives\nEquation (6) shows that the order of convergence is at least quadratic if the following conditions are satisfied:\nwhere M is given by\nformula_20\nIf these conditions hold,\nformula_21\nFourier conditions.\nSuppose that \"f\"(\"x\") is a concave function on an interval, which is strictly increasing. If it is negative at the left endpoint and positive at the right endpoint, the intermediate value theorem guarantees that there is a zero \u03b6 of f somewhere in the interval. From geometrical principles, it can be seen that the Newton iteration \"x\"\"i\" starting at the left endpoint is monotonically increasing and convergent, necessarily to \u03b6.\nJoseph Fourier introduced a modification of Newton's method starting at the right endpoint:\nformula_22\nThis sequence is monotonically decreasing and convergent. By passing to the limit in this definition, it can be seen that the limit of \"y\"\"i\" must also be the zero \u03b6.\nSo, in the case of a concave increasing function with a zero, initialization is largely irrelevant. Newton iteration starting anywhere left of the zero will converge, as will Fourier's modified Newton iteration starting anywhere right of the zero. The accuracy at any step of the iteration can be determined directly from the difference between the location of the iteration from the left and the location of the iteration from the right. If f is twice continuously differentiable, it can be proved using Taylor's theorem that\nformula_23\nshowing that this difference in locations converges quadratically to zero.\nAll of the above can be extended to systems of equations in multiple variables, although in that context the relevant concepts of monotonicity and concavity are more subtle to formulate. In the case of single equations in a single variable, the above monotonic convergence of Newton's method can also be generalized to replace concavity by positivity or negativity conditions on an arbitrary higher-order derivative of f. However, in this generalization, Newton's iteration is modified so as to be based on Taylor polynomials rather than the tangent line. In the case of concavity, this modification coincides with the standard Newton method.\nError for n&gt;1 variables.\nIf we seek the root of a single function formula_24\nthen the error formula_25 is a vector such that its components obey formula_26 where formula_27 is a quadratic form:\nformula_28\nevaluated at the root formula_29\n(where formula_30 is the 2nd derivative Hessian matrix).\nExamples.\nUse of Newton's method to compute square roots.\nNewton's method is one of many known methods of computing square roots. Given a positive number a, the problem of finding a number x such that \"x\"2 \n \"a\" is equivalent to finding a root of the function \"f\"(\"x\") \n \"x\"2 \u2212 \"a\". The Newton iteration defined by this function is given by\nformula_31.\nThis happens to coincide with the \"Babylonian\" method of finding square roots, which consists of replacing an approximate root \"x\"\"n\" by the arithmetic mean of and . By performing this iteration, it is possible to evaluate a square root to any desired accuracy by only using the basic arithmetic operations.\nThe following three tables show examples of the result of this computation for finding the square root of 612, with the iteration initialized at the values of 1, 10, and \u221220. Each row in a \"\"x\"\"n\"\" column is obtained by applying the preceding formula to the entry above it, for instance\nformula_32\nThe correct digits are underlined. It is seen that with only a few iterations one can obtain a solution accurate to many decimal places. The first table shows that this is true even if the Newton iteration were initialized by the very inaccurate guess of 1.\nWhen computing any nonzero square root, the first derivative of f must be nonzero at the root, and that f is a smooth function. So, even before any computation, it is known that any convergent Newton iteration has a quadratic rate of convergence. This is reflected in the above tables by the fact that once a Newton iterate gets close to the root, the number of correct digits approximately doubles with each iteration.\nSolution of cos(x) = x3 using Newton's method.\nConsider the problem of finding the positive number x with cos (x) = x3. We can rephrase that as finding the zero of f(x) = cos(x) \u2212 x3. We have (x) = \u2212sin(x) \u2212 3x2. Since for all x and for , we know that our solution lies between 0 and 1.\nA starting value of 0 will lead to an undefined result which illustrates the importance of using a starting point close to the solution. For example, with an initial guess x0 = 0.5, the sequence given by Newton's method is:\nformula_33\nThe correct digits are underlined in the above example. In particular, is correct to 12 decimal places. We see that the number of correct digits after the decimal point increases from 2 (for ) to 5 and 10, illustrating the quadratic convergence.\nMultidimensional formulations.\nSystems of equations.\nk variables, k functions.\nOne may also use Newton's method to solve systems of k equations, which amounts to finding the (simultaneous) zeroes of k continuously differentiable functions formula_34 This is equivalent to finding the zeroes of a single vector-valued function formula_35 In the formulation given above, the scalars xn are replaced by vectors x and instead of dividing the function by its derivative one instead has to left multiply the function by the inverse of its Jacobian matrix . This results in the expression\nformula_36\nor, by solving the system of linear equations\nformula_37\nfor the unknown x \u2212 x.\nk variables, m equations, with.\nThe k-dimensional variant of Newton's method can be used to solve systems of greater than k (nonlinear) equations as well if the algorithm uses the generalized inverse of the non-square Jacobian matrix instead of the inverse of J. If the nonlinear system has no solution, the method attempts to find a solution in the non-linear least squares sense. See Gauss\u2013Newton algorithm for more information.\nExample.\nA milk carton with a capacity of 2 pints is to be constructed from a sheet of waxed carboard with a 5mm overlap. The requirement is that the minimum surface area is used for the carton.\nSuppose the width, breadth and height of the carton are denoted by formula_38, formula_39 and formula_40 respectively, in millimetres. The total surface area, formula_41, is given by\nformula_42\nSince 2 pints is approximately 1.136 litres, and 1 litre is formula_43, it also follows that\nformula_44\nSolving for formula_38 gives\nformula_46\nLetting formula_47 be the vector of two unknowns, formula_39 and formula_40, the surface area can then be expressed as\nformula_50\nMinimization of this function entails equating its partial derivatives to zero, which gives\nformula_51\nand\nformula_52\nTo simplify notation, let\nformula_53\nand\nformula_54\nThe function vector formula_55 is therefore\nformula_56\nand Jacobian matrix formula_57 is\nformula_58\nApplying Newton's method with initial guess formula_59 and with a stopping criterion of formula_60 gives the following iterations:\nTo show that formula_61 minimises formula_62, it suffices to show that its Hessian matrix is positive definite. In this case, the Hessian matrix is simply\nformula_63\nThe characteristic polynomial of this matrix is\nformula_64.\nApplying the quadratic formula gives the two eigenvalues as\nformula_65\nand\nformula_66\nSince all eigenvalues are positive, formula_67 is positive definite, and therefore formula_68 is a minimum.\nComplex functions.\nWhen dealing with complex functions, Newton's method can be directly applied to find their zeroes. Each zero has a basin of attraction in the complex plane, the set of all starting values that cause the method to converge to that particular zero. These sets can be mapped as in the image shown. For many complex functions, the boundaries of the basins of attraction are fractals.\nIn some cases there are regions in the complex plane which are not in any of these basins of attraction, meaning the iterates do not converge. For example, if one uses a real initial condition to seek a root of , all subsequent iterates will be real numbers and so the iterations cannot converge to either root, since both roots are non-real. In this case almost all real initial conditions lead to chaotic behavior, while some initial conditions iterate either to infinity or to repeating cycles of any finite length.\nCurt McMullen has shown that for any possible purely iterative algorithm similar to Newton's method, the algorithm will diverge on some open regions of the complex plane when applied to some polynomial of degree 4 or higher. However, McMullen gave a generally convergent algorithm for polynomials of degree 3. Also, for any polynomial, Hubbard, Schleicher, and Sutherland gave a method for selecting a set of initial points such that Newton's method will certainly converge at one of them at least.\nIn a Banach space.\nAnother generalization is Newton's method to find a root of a functional F defined in a Banach space. In this case the formulation is\nformula_69\nwhere is the Fr\u00e9chet derivative computed at . One needs the Fr\u00e9chet derivative to be boundedly invertible at each in order for the method to be applicable. A condition for existence of and convergence to a root is given by the Newton\u2013Kantorovich theorem.\nNash\u2013Moser iteration.\nIn the 1950s, John Nash developed a version of the Newton's method to apply to the problem of constructing isometric embeddings of general Riemannian manifolds in Euclidean space. The \"loss of derivatives\" problem, present in this context, made the standard Newton iteration inapplicable, since it could not be continued indefinitely (much less converge). Nash's solution involved the introduction of smoothing operators into the iteration. He was able to prove the convergence of his smoothed Newton method, for the purpose of proving an implicit function theorem for isometric embeddings. In the 1960s, J\u00fcrgen Moser showed that Nash's methods were flexible enough to apply to problems beyond isometric embedding, particularly in celestial mechanics. Since then, a number of mathematicians, including Mikhael Gromov and Richard Hamilton, have found generalized abstract versions of the Nash\u2013Moser theory. In Hamilton's formulation, the Nash\u2013Moser theorem forms a generalization of the Banach space Newton method which takes place in certain Fr\u00e9chet spaces.\nModifications.\nQuasi-Newton methods.\nWhen the Jacobian is unavailable or too expensive to compute at every iteration, a quasi-Newton method can be used.\nChebyshev's third-order method.\nSince higher-order Taylor expansions offer more accurate local approximations of a function f, it is reasonable to ask why Newton\u2019s method relies only on a second-order Taylor approximation. In the 19th century, Russian mathematician Pafnuty Chebyshev explored this idea by developing a variant of Newton\u2019s method that used cubic approximations.\nOver p-adic numbers.\nIn p-adic analysis, the standard method to show a polynomial equation in one variable has a p-adic root is Hensel's lemma, which uses the recursion from Newton's method on the p-adic numbers. Because of the more stable behavior of addition and multiplication in the p-adic numbers compared to the real numbers (specifically, the unit ball in the p-adics is a ring), convergence in Hensel's lemma can be guaranteed under much simpler hypotheses than in the classical Newton's method on the real line.\nq-analog.\nNewton's method can be generalized with the q-analog of the usual derivative.\nModified Newton methods.\nMaehly's procedure.\nA nonlinear equation has multiple solutions in general. But if the initial value is not appropriate, Newton's method may not converge to the desired solution or may converge to the same solution found earlier. When we have already found N solutions of formula_70, then the next root can be found by applying Newton's method to the next equation:\nformula_71\nThis method is applied to obtain zeros of the Bessel function of the second kind.\nHirano's modified Newton method.\nHirano's modified Newton method is a modification conserving the convergence of Newton method and avoiding unstableness. It is developed to solve complex polynomials.\nInterval Newton's method.\nCombining Newton's method with interval arithmetic is very useful in some contexts. This provides a stopping criterion that is more reliable than the usual ones (which are a small value of the function or a small variation of the variable between consecutive iterations). Also, this may detect cases where Newton's method converges theoretically but diverges numerically because of an insufficient floating-point precision (this is typically the case for polynomials of large degree, where a very small change of the variable may change dramatically the value of the function; see Wilkinson's polynomial).\nConsider , where X is a real interval, and suppose that we have an interval extension of , meaning that takes as input an interval and outputs an interval such that:\nformula_72\nWe also assume that , so in particular f has at most one root in X.\nWe then define the interval Newton operator by:\nformula_73\nwhere . Note that the hypothesis on implies that is well defined and is an interval (see interval arithmetic for further details on interval operations). This naturally leads to the following sequence:\nformula_74\nThe mean value theorem ensures that if there is a root of f in , then it is also in . Moreover, the hypothesis on F\u2032 ensures that is at most half the size of when m is the midpoint of Y, so this sequence converges towards , where x* is the root of f in X.\nIf strictly contains 0, the use of extended interval division produces a union of two intervals for ; multiple roots are therefore automatically separated and bounded.\nApplications.\nMinimization and maximization problems.\nNewton's method can be used to find a minimum or maximum of a function . The derivative is zero at a minimum or maximum, so local minima and maxima can be found by applying Newton's method to the derivative. The iteration becomes:\nformula_75\nMultiplicative inverses of numbers and power series.\nAn important application is Newton\u2013Raphson division, which can be used to quickly find the reciprocal of a number a, using only multiplication and subtraction, that is to say the number x such that = a. We can rephrase that as finding the zero of f(x) = \u2212 a. We have (x) = \u2212.\nNewton's iteration is\nformula_76\nTherefore, Newton's iteration needs only two multiplications and one subtraction.\nThis method is also very efficient to compute the multiplicative inverse of a power series.\nSolving transcendental equations.\nMany transcendental equations can be solved up to an arbitrary precision by using Newton's method. For example, finding the cumulative probability density function, such as a Normal distribution to fit a known probability generally involves integral functions with no known means to solve in closed form. However, computing the derivatives needed to solve them numerically with Newton's method is generally known, making numerical solutions possible. For an example, see the numerical solution to the inverse Normal cumulative distribution.\nNumerical verification for solutions of nonlinear equations.\nA numerical verification for solutions of nonlinear equations has been established by using Newton's method multiple times and forming a set of solution candidates.\nCode.\nThe following is an example of a possible implementation of Newton's method in the Python (version 3.x) programming language for finding a root of a function codice_1 which has derivative codice_2.\nThe initial guess will be x0 = 1 and the function will be f(x) = x2 \u2212 2 so that (x) = 2x.\nEach new iteration of Newton's method will be denoted by codice_3. We will check during the computation whether the denominator (codice_4) becomes too small (smaller than codice_5), which would be the case if , since otherwise a large amount of error could be introduced.\ndef f(x): \n return x**2 - 2 # f(x) = x^2 - 2\ndef f_prime(x):\n return 2*x # f'(x) = 2x\ndef newtons_method(x0, f, f_prime, tolerance, epsilon, max_iterations):\n \"\"\"Newton's method\n Args:\n x0: The initial guess\n f: The function whose root we are trying to find\n f_prime: The derivative of the function\n tolerance: Stop when iterations change by less than this\n epsilon: Do not divide by a number smaller than this\n max_iterations: The maximum number of iterations to compute\n for _ in range(max_iterations):\n y = f(x0)\n y_prime = f_prime(x0)\n if abs(y_prime) &lt; epsilon: # Give up if the denominator is too small\n break\n x1 = x0 - y / y_prime # Do Newton's computation\n if abs(x1 - x0) &lt;= tolerance: # Stop when the result is within the desired tolerance\n return x1 # x1 is a solution within tolerance and maximum number of iterations\n x0 = x1 # Update x0 to start the process again\n return None # Newton's method did not converge\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22146", "revid": "20685249", "url": "https://en.wikipedia.org/wiki?curid=22146", "title": "New Order (band)", "text": "English rock band\nNew Order are an English rock band formed in Salford in 1980 by vocalist and guitarist Bernard Sumner, bassist Peter Hook, and drummer Stephen Morris, with keyboardist Gillian Gilbert joining the band shortly after. Sumner, Hook and Morris were previously members of Joy Division, which had disbanded earlier in 1980 after the suicide of lead singer Ian Curtis. Their fusion of post-punk and electronic dance music made them one of the most acclaimed and influential bands of the 1980s. They became the flagship band for the Manchester-based independent record label Factory Records and its nightclub, The Ha\u00e7ienda. They worked in a long-term collaboration with graphic designer Peter Saville who worked on their album covers.\nWhile the band's early years were initially overshadowed by Joy Division's post-punk legacy, their experience in the early 1980s New York club scene led them to incorporate dance rhythms and electronic instrumentation into their work. Their 1983 hit \"Blue Monday\" became the best-selling 12-inch single of all time and a popular club track. In the 1980s, they released several successful albums, such as \"Power, Corruption &amp; Lies\" (1983), \"Technique\" (1989), and the singles compilation album \"Substance\" (1987). The band disbanded in 1993 to focus on their individual projects but reunited in 1998. Since then, New Order have gone through various hiatuses and changes in personnel, most notably the departure of Hook in 2007 due to personal disputes with the other members. In 2015, they released their tenth studio album, \"Music Complete.\" In 2023, both Joy Division and New Order were nominated as one act for induction into the Rock and Roll Hall of Fame.\nHistory.\nOrigins and formation: 1977\u20131980.\nBetween 1977 and 1980, Ian Curtis, Peter Hook, Stephen Morris, and Bernard Sumner were members of the post-punk band Joy Division, often featuring heavy production input from producer Martin Hannett. Curtis died by suicide on 18 May 1980, the day before Joy Division were scheduled to depart for their first North American tour, and before the release of the band's second album, \"Closer\".\nBefore Curtis's death, the band had agreed to stop using the name Joy Division if any member died or left. Thus, when the three remaining members decided to continue without him, they chose to perform under a different name. During the summer of 1980, the remaining members recorded their first demos, including a track called \"Haystack\" with vocalist Kevin Hewick, whom Factory's co-founder Tony Wilson had suggested as the band's new frontman. On 29 July 1980, the as-yet unnamed trio debuted live at Manchester's Beach Club. Rob Gretton, the band's manager for over twenty years, is credited with finding the name New Order in an article in \"The Guardian\" titled \"The New Order of Kampuchean Rebels\". They also considered the name The Witch Doctors of Zimbabwe, before finally choosing New Order of Kampuchean Rebels, which was narrowed down to the name New Order despite its previous use for former Stooge Ron Asheton's band The New Order. The group emphasized that the name New Order, like Joy Division, was not intended to reference Nazism or fascism.\nNew Order embarked on a short US tour in early autumn 1980. In these shows, Sumner, Morris and Hook all sang lead vocals on different tracks. Sumner ultimately took the role of frontman even though he struggled to sing while playing guitar. During this tour, the band recorded two tracks written by Joy Division: \"Ceremony\" and \"In a Lonely Place\", which were released as New Order's debut single in January 1981.\nThe band wanted to complete the line-up with someone they knew well and whose musical skills and style were compatible with their own. Gretton suggested Morris's girlfriend Gillian Gilbert, and she was invited to join the band in early October 1980 as keyboardist and guitarist. She made her live debut with the band at the Squat in Manchester on 25 October 1980. As a quartet, New Order subsequently re-recorded \"Ceremony\", which was released as a twelve-inch single in September 1981.\n\"Movement\": 1981\u20131982.\nNew Order's first commercial release was the single \"Ceremony\", backed with \"In a Lonely Place\". These two songs were written in the weeks before Curtis took his own life. With the release of their debut album, \"Movement\", in November 1981, New Order initially started on a similar route as their previous incarnation, performing dark, melodic songs, albeit with an increased use of synthesizers. The band viewed the period as a low point, as they were still reeling from Curtis's death. Hook commented that the only positive thing to come out of the \"Movement\" sessions was that producer Martin Hannett showed the band how to use a mixing board. This allowed the band to produce records by themselves from then on. More recently, Hook indicated a change of heart: \"I think \"Movement\" gets a raw deal in general, really\u2014for me, when you consider the circumstances in which it was written, it is a fantastic record.\"\nNew Order visited New York City again in 1981, where the band were introduced to post-disco, freestyle, and electro. To cheer themselves up, the band started listening to Italian disco while Morris taught himself drum programming. The singles that followed, \"Everything's Gone Green\" and \"Temptation\", saw a change in direction toward dance music and the departure of producer Martin Hannett, who walked off halfway through the mix of \"Everything's Gone Green\", leading the band to produce \"Temptation\" themselves.\nThe Ha\u00e7ienda, Factory Records' own nightclub (largely funded by New Order), opened in May 1982 in Manchester and was even issued a Factory catalogue number: FAC51. The opening of the UK's first-ever superclub was marked by a nearly 23-minute instrumental piece originally entitled \"Prime 5 8 6\", but released 15 years later as \"Video 5 8 6\". Composed primarily by Sumner and Morris, \"Prime 5 8 6\"/\"Video 5 8 6\" was an early version of \"5 8 6\" that contained rhythm elements that would later surface on \"Blue Monday\" and \"Ultraviolence\".\n\"Power, Corruption &amp; Lies\": 1983\u20131984.\nNew Order's second LP, \"Power, Corruption &amp; Lies\", was released in May 1983. This synth-pop album incorporated some of the post-punk style sound from their previous band, Joy Division, and their first album, \"Movement\". The band had been hinting at the increased use of technology during the music-making process for a number of years then, including their work as Joy Division. Starting from what earlier singles had hinted, this was where the band found their footing, mixing early techno music with their earlier guitar-based sound and showing the strong influence of acts like Kraftwerk and Giorgio Moroder. Even further in this direction was the electronically sequenced, four-on-the-floor single \"Blue Monday\". Inspired by Klein + M.B.O.'s \"Dirty Talk\" and Sylvester's disco classic \"You Make Me Feel (Mighty Real)\", \"Blue Monday\" became the best-selling independent 12-inch single of all time in the UK; however, it was not on the track list of \"Power, Corruption &amp; Lies\". The song was included only on the cassette format in some countries, such as Australia and New Zealand, and on the original North American CD release of the album, alongside its B-side, \"The Beach\". \"Blue Monday\" was also included on the 2008 collector's edition of \"Power, Corruption &amp; Lies\".\nThe 1983 single \"Confusion\" firmly established the group as a dance music force, inspiring many musicians in subsequent years. In 1984 they followed the largely synthesized single \"Thieves Like Us\" with the heavy guitar-drum-bass rumble of \"Murder\", a not-too-distant cousin of \"Ecstasy\" from the \"Power, Corruption &amp; Lies\" album.\n\"Low-Life\", \"Brotherhood\", and \"Substance\": 1985\u20131987.\nReleased in 1985, \"Low-Life\" refined and sometimes mixed the two styles, guitar-based and electronic, and included \"The Perfect Kiss\" \u2013 the video for which was filmed by Jonathan Demme \u2013 and \"Sub-culture\". In February 1986, the soundtrack album to \"Pretty in Pink\" featuring \"Shellshock\" was released on A&amp;M Records. An instrumental version of \"Thieves Like Us\" and the instrumental \"Elegia\" appeared in the film but were not on the soundtrack album. Later that summer, New Order headlined a line-up that included the Smiths, the Fall, and A Certain Ratio during the Festival of the Tenth Summer at Manchester's G-Mex.\n\"Brotherhood\" (1986) divided the two approaches onto separate album sides. The album notably featured \"Bizarre Love Triangle\" (a Top 20 hit in Australia and New Zealand) and \"Angel Dust\" (of which a remixed instrumental version is available on the UK \"True Faith\" CD video single, under the title \"Evil Dust\"), a track which marries a synth break beat with \"Low-Life\"-era guitar effects. While New Order toured North America with friends Echo &amp; the Bunnymen, the summer of 1987 saw the release of the compilation \"Substance\", which featured the new single \"True Faith\". \"Substance\" was an important album in collecting the group's 12-inch singles onto CD for the first time and featured new versions of \"Temptation\" and \"Confusion\"\u2014referred to as \"Temptation '87\" and \"Confusion '87\". A second disc featured several of the B-sides from the singles on the first disc, as well as additional A-sides \"Procession\" and \"Murder\". The single, \"True Faith\", with its surreal video, became a hit on MTV and the band's first American top 40 hit. The single's B-side, \"1963\"\u2014originally planned on being the A-side until the group's label convinced them to release \"True Faith\" instead\u2014would later be released as a single in its own right several years later, with two new versions.\nIn December 1987, the band released a further single, \"Touched by the Hand of God\", with a Kathryn Bigelow-directed video parodying glam-metal. The song was one of four new tracks recorded for the American comedy film \"Salvation!\", and reached number 20 on the UK Singles Chart and number 1 in the UK Independent Singles Chart. However, it would not appear on an album until the 1994 compilation \"The Best of New Order\".\n\"Technique\", \"Republic\" and first break-up: 1988\u20131993.\nBy this time, the group was heavily influenced by the Balearic sounds of Ibiza, which were making their way into the Ha\u00e7ienda. Partly recorded at Mediterranean Sound studios on Ibiza, \"Technique\" was released in February 1989. The album entered the charts at number one in the UK and contained a mix of acid house influence (as on the opening track \"Fine Time\") and a more traditional rock sound (as on the single \"Run 2\"). The album is a blend of upbeat, accessible music coupled with blunt, poignant lyrics. During the summer of 1989, New Order supported \"Technique\" by touring with Public Image Ltd, Throwing Muses and the Sugarcubes across the United States and Canada in what the press dubbed the \"Monsters of Alternative Rock\" tour. Around this time, band members also began side projects, including Electronic (Sumner with Johnny Marr) and Revenge (Hook with Davyth Hicks). Morris and Gilbert began to work together on outside TV theme production work. In 1991, the band was sued by the publishing company of American singer John Denver, who claimed that the guitar break in \"Run 2\" was similar to his song \"Leaving on a Jet Plane\". The case was settled out of court, and the song has since been credited to both New Order and John Denver.\nIn 1990, New Order recorded the official song of the England national football team's 1990 World Cup campaign, \"World in Motion\", under the ad hoc band name EnglandNewOrder. The song, co-written by comedian Keith Allen, was the band's sole number one UK hit. The song was originally planned to be titled \"E for England\"; however the Football Association vetoed the title upon realizing that this was a reference to ecstasy, a drug heavily associated with the Hacienda. (Allen claimed that his original draft lyrics included \"E is for England, England starts with E / We'll all be smiling when we're in Italy.\") The song also featured chanting from members of the England team and Allen, and a guest rap from England player John Barnes. It was again produced by Stephen Hague, whom the band chose to produce their next album.\nThe band's next album, \"Republic\", was shadowed by the collapse of their long-time label, Factory Records, in 1992. The label had been ailing due to financial difficulties and was forced to declare bankruptcy. New Order never had a formal contract with Factory Records; although unusual for a major group, this was Factory's standard practice until the mid-1980s. Because of this, the band, rather than Factory Records, legally owned all of their recordings. This has been cited by Wilson himself as the main reason why London Records' 1992 offer to buy the ailing label fell through. Following Factory's collapse, New Order signed with London Records, as did Morris and Gilbert separately for their side project, the Other Two. The Other Two's debut album was originally intended for release on Factory. \"Republic\", released around the world in 1993, spawned the singles \"Regret\"\u2014New Order's highest-charting single in the US\u2014\"Ruined in a Day\", \"World\", and \"Spooky\".\nFollowing the release and promotion of \"Republic\", the band put New Order on hold while focusing on side projects, with the Other Two's debut album released in 1993. In 1994, a second singles collection was released, entitled \"The Best of New Order\". It featured all of the band's singles since \"Substance\" as well as a few extra tracks: \"Vanishing Point\" (from 1989's \"Technique\"), \"The Perfect Kiss\", \"Thieves Like Us\", \"Shellshock\", and remixes of \"True Faith\", \"Bizarre Love Triangle\", \"1963\", and \"Round &amp; Round\". The new versions of \"True Faith\" and \"1963\" (the latter as a more guitar-orientated version produced by Arthur Baker) were released as singles to promote the album. In the US, the track listing was altered to set it apart from \"Substance\" as well as the UK release of \"The Best of New Order,\" which had been available months prior. This collection was followed by a remix album, \"The Rest of New Order\", featuring a selection of existing and newly commissioned mixes of classic New Order tracks. Some versions contained an extra disc or cassette composed entirely of remixes of \"Blue Monday\". \"Blue Monday\" was released as a single for a third time to promote the collection.\nReformation and \"Get Ready\": 1998\u20132003.\nThe group reconvened in 1998 at the suggestion of Rob Gretton, nearly five years since they had last seen each other. Sumner said, \"We decided before we agreed to doing any gig, to have a meeting, and if anyone had any grudges to bear, to iron them out.\" By the second meeting everyone agreed to continue playing, scheduling their reunion gig for the Phoenix Festival that same year. In addition to rarer songs, New Order also decided to begin playing Joy Division songs again. When the Phoenix Festival was cancelled due to low ticket sales, New Order instead played the last night of that year's Reading Festival.\nTheir 2001 album \"Get Ready\" largely departed from their more electronic style and focused on more guitar-orientated music. According to Sumner, \"\"Get Ready\" was guitar-heavy simply because we felt that we'd left that instrument alone for a long time.\" Long-time fan Billy Corgan of the Smashing Pumpkins played guitar and sang backup on the track \"Turn My Way\", and in 2001 toured with the band on dates in the UK, US, and Japan for a short period of time. Phil Cunningham (formerly of Marion) joined the band in a live capacity, deputizing for Gilbert, who declined to tour in favour of caring for her and Morris' children. Primal Scream's Bobby Gillespie provided vocals on the track \"Rock the Shack\". Singles from the album included \"Crystal\", \"60 Miles an Hour\" and \"Someone Like You\".\nIn 2002 New Order released the single \"Here to Stay\", produced by the Chemical Brothers, which also featured on the soundtrack to the Michael Winterbottom film \"24 Hour Party People\". The film depicts the rise and fall of Factory Records and features portrayals of the band. Scenes from the film appear in the single's music video.\nAlso in 2002, \"Q\" featured New Order on their list of the \"50 Bands to See Before You Die\", although this was as part of a sub-list of \"5 Bands That Could Go Either Way\".\n\"Waiting for the Sirens' Call\", \"Singles\" and second break-up: 2004\u20132007.\nThe band released a new album on 27 March 2005, titled \"Waiting for the Sirens' Call\", which was their first with new member Phil Cunningham. Cunningham replaced Gilbert (now married to Morris) so she could look after their children. Singles from this album were \"Krafty\", \"Jetstream\" (which features guest vocals by Ana Matronic from Scissor Sisters), and the title track. At the 2005 \"NME\" Awards, New Order and Joy Division received the award for \"Godlike Geniuses\" (for lifetime achievement). Previous winners include Ozzy Osbourne, the Clash, and Happy Mondays. In 2006 the album track \"Guilt Is a Useless Emotion\" was nominated for a Grammy Award in the category of Best Dance Recording.\nIn the autumn of 2005, the group released another greatest hits compilation, in the form of \"Singles\". The two-disc release was an updated version of the \"Substance\" collection and contained every single released from their 1981 debut all the way through to \"Waiting for the Sirens' Call\". However, unlike \"Substance\", which focused almost exclusively on the 12-inch versions of the group's singles, \"Singles\" collected the 7-inch versions, many of which (like \"Ceremony\", \"Temptation\" and \"Confusion\") had never been released on CD. The album was accompanied by a two-disc DVD set, titled \"Item\", that collected the extended UK version of the documentary \"NewOrderStory\" with a DVD of all New Order music videos as well as two newly commissioned videos for \"Temptation '87\" and \"Ceremony\".\nThe \"New Order: Live in Glasgow\" DVD was recorded at the Glasgow Academy in 2006 and features 18 tracks, including 4 Joy Division songs. Next to that, the release also contains a bonus disc of footage from the band's personal archive, including 1980s footage from Glastonbury (June 1981), Rome, Cork, Rotterdam and Toronto.\nIn 2006, the band played several one-off live dates as well as short tours in the UK, Brazil and Argentina. After their Buenos Aires show in November 2006, Peter Hook suggested that the band should stop touring. In early May 2007, Hook was interviewed by British radio station XFM\u2014originally to talk about his contribution to the debut album of Jane's Addiction singer Perry Farrell's new band, Satellite Party\u2014and stated that \"Me and Bernard aren't working together.\" Further complicating the news, NewOrderOnline, a website with support from New Order management, reported that according to \"a source close to the band\", \"The news about the split is false... New Order still exists despite what [Hook] said ... Peter Hook can leave the band, but this doesn't mean the end of New Order.\" However, Sumner revealed in 2009 that he no longer wished to make music as New Order.\nReunion with new line-up, \"Lost Sirens\" and \"Music Complete\": 2011\u20132016.\nIn September 2011, the band announced that they would perform for the first time since 2006 at the Ancienne Belgique, Brussels, on 17 October and at the Bataclan, Paris, on 18 October. The band's line-up included keyboardist Gillian Gilbert, who returned to the band after a ten-year break, and Bad Lieutenant bassist Tom Chapman in place of Peter Hook. They played subsequent shows in London and South America in December and released \"Live at the London Troxy\", a live album from their performance on 10 December 2011 at The Troxy in London.\nThey continued to tour throughout 2012, including a short tour of New Zealand and Australia in February/March and several festival appearances in 2012. New Order performed at Hyde Park with Blur and the Specials to celebrate the closing of the 2012 Summer Olympics.\n\"Lost Sirens\" was released in the United Kingdom in January 2013. \"Lost Sirens\" is an eight-track album of songs recorded during the sessions for \"Waiting for the Sirens' Call\". The album was discussed by Gillian Gilbert in a Brazilian interview to promote the band's appearance in S\u00e3o Paulo. She acknowledged issues with former member Peter Hook and stated there was \"a lot going on behind the scenes on the copyright\" delaying the release.\nThe band debuted their first new song since the \"Waiting for the Sirens' Call\" sessions, \"Singularity\", during Lollapalooza Chile in March 2014. In July, the group toured North America, where they debuted another song, \"Plastic\". On 2 September the band signed to Mute Records. The New Order back catalogue remains with Warner Music.\nIn September 2015, the band released a new album, \"Music Complete\", their first without Peter Hook. The album was produced mostly by the band themselves, except \"Singularity\" and \"Unlearn This Hatred\", both produced by Tom Rowlands, while \"Superheated\" features additional production by Stuart Price.\nIn May 2016, New Order released a follow-up remix album, \"Complete Music\", which consists of extended and reworked mixes of each track from \"Music Complete\".\nIn November 2015, Peter Hook sued Bernard Sumner, Stephen Morris and Gillian Gilbert. In an objection, it was revealed that Sumner, Morris and Gilbert had set up a new company behind Hook's back, which generated an income of \u00a37.8 million in four years, while Hook received only a fraction of that sum. The three members argued they had treated Hook fairly and that his stake in the band's royalties was reasonable, despite the fact that in four years, Hook had only received \"1.25 per cent of the band's royalties and other income from merchandising and performances\". The judge ruled that there was \"at least a reasonable prospect\" of Hook proving that he was not getting a fair share of royalties and other income and rejected Sumner and Morris's lawyer's argument. The judge was willing to hear the case but urged the parties to come to an agreement rather than suffer legal costs of around \u00a3900,000. On 20 September 2017, the band announced that a full and final settlement had been reached in the dispute.\nTouring and recent work: 2017\u2013present.\nOn 13 July 2017, New Order played a concert at Manchester International Festival with Liam Gillick. In July 2019 the performance was released as a live album titled \"\u03a3(No,12k,Lg,17Mif) New Order + Liam Gillick: So it goes.. (Live at MIF)\". The collaboration between Gillick and New Order was the subject of the documentary feature \"New Order: Decades\", directed by Mike Christie and broadcast in the UK by Sky Arts and Showtime in the US.\nOn August 23, 2018, the band kicked off their North American tour at the Palace Theatre in St. Paul, Minnesota, with stops in Cleveland, Washington, D.C., Toronto, Long Beach, and Hawaii. In November, they also performed in Santiago, Chile.\nIn January 2020, the band played a four-night residency at The Fillmore Miami Beach at the Jackie Gleason Theater in Miami Beach, Florida, and in February 2020, they announced a co-headlining tour in North America with the Pet Shop Boys, and that the only concert in the UK in 2020 would be at The O2 on 10 October. These tour dates were later rescheduled for 2021 due to the COVID-19 pandemic.\nIn September 2020 the band released the single \"Be a Rebel\", 5 years after their previous release. A music video for the single, directed by NYSU, premiered on YouTube in December.\nIn February 2021, the band announced their plans to release a live album and concert film of their 2018 show at London's Alexandra Palace, directed by Mike Christie. Entitled \"Education Entertainment Recreation (Live at Alexandra Palace)\", it was released on 7 May.\nNew Order kicked off their Unity Tour (with the Pet Shop Boys) on 17 September 2022. The tour consisted of 13 dates in the United States and Canada.\nNew Order kicked off their 2023 UK and European tour on 21 September 2023.\nNew Order kicked off their 2025 tour on 25 February 2025. The tour is ongoing and consists of 9 dates in Japan (with Mark Reeder and special guest Denki Groove), Australia (with Juno Mamba and DJ TinTin), and the United States.\nOther projects.\nIn 1988, Bernard Sumner teamed up with former Smiths guitarist Johnny Marr to form the group Electronic; Sumner and Marr also enlisted the help of Neil Tennant and Chris Lowe of the Pet Shop Boys. Electronic regrouped in 1996 for \"Raise the Pressure\", which also featured Karl Bartos (formerly of Kraftwerk). The project's third album, \"Twisted Tenderness\", was released in 1999; after the album's release, the band dissolved.\nIn June 2009, Sumner formed a new band called Bad Lieutenant with Phil Cunningham (guitar) and Jake Evans (guitar and vocals). Their album \"Never Cry Another Tear\" was released on 5 October 2009. In addition to Cunningham and Evans, the album also features appearances by Stephen Morris (drums), Jack Mitchell (drums), Tom Chapman (bass) and Alex James (bass). The live band included Morris on drums and Chapman on bass.\nPeter Hook has been involved with several other projects. In the 1990s, Hook recorded with Killing Joke with a view to joining the band. However, original bassist Martin 'Youth' Glover instead returned to the band. In 1995, he toured with the Durutti Column. He has recorded one album with the band Revenge with Davyth Hicks and Chris Jones and two with Monaco (both as bassist, keyboardist and lead vocalist) with David Potts. Monaco scored a club and alternative radio hit with \"What Do You Want From Me?\" in 1997. Hook also formed a band called Freebass with fellow bass players Mani (the Stone Roses) and Andy Rourke (the Smiths) in addition to vocalist Gary Briggs. \"Freebass\" was active from 2007 to 2010. He also contributed to Perry Farrell's Satellite Party. Hook's current band, Peter Hook and the Light is touring and performing full albums from both Joy Division and New Order.\nIn 1990, Gillian Gilbert and Stephen Morris formed their own band, The Other Two. The Other Two released its first single, \"Tasty Fish\" in 1991 and released two albums, \"The Other Two &amp; You\" in 1993 and \"Super Highways\" in 1999. They have also been involved in scoring television soundtracks, like \"Making Out\". In 2007, Gilbert and Morris remixed two tracks for the Nine Inch Nails remixes album \"Year Zero Remixed\".\nBeMusic.\n\"BeMusic\" was a name the band used for their publishing company (the LP label for \"Movement\" says \"B Music\" in large letters, though using an italic \u00df for the letter B). All four members of the band used the name for production work for other artists' recordings between 1982 and 1985.\nBeMusic was first credited when Peter Hook produced Stockholm Monsters in 1982. Other artists with producer or musician credit for \"BeMusic\" were 52nd Street, Section 25, Marcel King, Quando Quango, Paul Haig, Thick Pigeon, Nyam Nyam, and Life.\nTheir production work as BeMusic was collected on two LTM Recordings compilation CDs, \"Cool As Ice: The BeMusic Productions\" and \"Twice As Nice\" (which also included production work by Donald Johnson of A Certain Ratio and Arthur Baker).\nInfluences and style.\nNew Order is known to incorporate elements of both rock and dance music, as showcased by the songs \"Temptation\" (1982), \"Blue Monday\" (1983), and \"True Faith\" (1987). According to AllMusic, the band is considered \"the first alternative dance\" music group, having \"fused icy, gloomy post-punk with Kraftwerk-style synth-pop\". Critics have also described the band as synth-pop, post-punk, alternative rock, new wave, dance-rock, electronic rock, and electronica.\nEarly influences on New Order included the rock musicians Neil Young, David Bowie, and Iggy Pop. Founding member Hook stated that the band's transition from playing cold, dark post-punk to producing more synthesizer-driven music from 1982, was inspired by the German electronic group Kraftwerk, the Giorgio Moroder/Donna Summer collaboration \"I Feel Love\", and the US rock band Sparks (who had produced disco/electro-rock music with Moroder on their \"No. 1 in Heaven\" album). Frontman Sumner noted that his shift in songwriting style was also influenced by English electronic groups such as Cabaret Voltaire, the Human League, and OMD.\nDrummer Stephen Morris used a combination of acoustic and electronic drums, while all members of the band were observed switching instruments during live performances. This is documented in Jonathan Demme's video for \"The Perfect Kiss\" and the concert videos \"Taras Shevchenko\" (recorded in New York, November 1981) and \"Pumped Full of Drugs\" (Tokyo, May 1985). During live shows, Sumner alternated between guitar, keyboards, melodica, cowbell, and, during performances of \"Confusion\", bass guitar. Gilbert switched between keyboards and guitar, Morris between drums and keyboards, and Hook between bass and electronic drums. In early performances, band members sometimes left the stage before the final song \"Temptation\" had concluded, allowing sequencers and drum machines to complete the track.\nCover artwork.\nAlmost all New Order recordings have distinctive packaging, and Peter Saville was the art director. The group's record sleeves bucked the 1980s trend by rarely showing the band members (with the exception of the \"Low-Life\" album) or even providing basic information such as the band name or title of the release. Song names were often hidden within the shrink-wrapped package, either on the disc itself (such as the \"Blue Monday\" single), on an inconspicuous part of an inner sleeve (\"The Perfect Kiss\" single), or written in a cryptic colour code invented by Saville (\"Power, Corruption &amp; Lies\"). Saville said his intention was to sell the band as a \"mass-produced secret\" of sorts and that the minimalist style was enough to allow fans to identify the band's products without explicit labelling. He frequently sent the artwork straight to the printer, without review by either the band or the label. Their 1983 album, \"Power, Corruption &amp; Lies\", was one of ten classic album covers from British artists commemorated on a UK postage stamp issued by the Royal Mail.\nLegacy.\nThe band have influenced techno, rock, and pop musicians including Moby, the Killers, and the xx. Numerous covers of their songs have been released, notably Orgy's cover of Blue Monday, as well as several tribute albums.\nDramatized versions of New Order appear in two films, \"24 Hour Party People\" (2002) and \"Control\" (2007). \"24 Hour Party People\", directed by Michael Winterbottom, depicts the rise and fall of Factory Records as seen through the eyes of founder Tony Wilson, played by Steve Coogan. The film includes portrayals of manager Rob Gretton and designer Peter Saville. The soundtrack features several New Order tracks, including \"Here to Stay\" and a cover of \"New Dawn Fades\" featuring Moby. \"Control\", directed by Anton Corbijn, traces Ian Curtis' life from the founding of Joy Division until his suicide. While the members of New Order are portrayed in the film, New Order as such is only hinted at in the final scene. In addition to several tracks on the soundtrack, New Order contributed the original incidental music.\nReputation.\nFollowing in the path of Joy Division, New Order were also among the most successful artists on the Factory Records label, which was run by Granada television personality Tony Wilson. New Order partnered with Factory to finance the Manchester club The Ha\u00e7ienda. Speaking in 2009, fellow synth-pop musician Phil Oakey described New Order's slow-burn career as cult musicians as being unusually prolonged and effective: \"If you want to make a lot of money out of pop, be number 3 a lot. Like New Order did.\"\nAwards and nominations.\n! Year !! Awards !! Work !! Category !! Result\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22148", "revid": "14965160", "url": "https://en.wikipedia.org/wiki?curid=22148", "title": "Nicolo Tartaglia", "text": "Italian mathematician (1499\u20131557)\nNicolo, known as Tartaglia (; 1499/1500 \u2013 13 December 1557), was an Italian mathematician, engineer (designing fortifications), a surveyor (of topography, seeking the best means of defense or offense) and a bookkeeper from the then Republic of Venice. He published many books, including the first Italian translations of Archimedes and Euclid, and an acclaimed compilation of mathematics. Tartaglia was the first to apply mathematics to the investigation of the paths of cannonballs, known as ballistics, in his \"Nova Scientia\" (\"A New Science\", 1537); his work was later partially validated and partially superseded by Galileo's studies on falling bodies. He also published a treatise on retrieving sunken ships.\nPersonal life.\nNicolo was born in Brescia, the son of Michele, a dispatch rider who travelled to neighbouring towns to deliver mail. In 1506, Michele was murdered by robbers, and Nicolo, his two siblings, and his mother were left impoverished. Nicolo experienced further tragedy in 1512 when King Louis XII's troops invaded Brescia during the War of the League of Cambrai against Venice. The militia of Brescia defended their city for seven days. When the French finally broke through, they took their revenge by massacring the inhabitants of Brescia. By the end of battle, over 45,000 residents were killed. During the massacre, Nicolo and his family sought sanctuary in the local cathedral. French soldiers entered the cathedral and a soldier sliced Nicolo's jaw and palate with a saber and left him for dead. His mother nursed him back to health but the young boy was left with a speech impediment, prompting the nickname \"Tartaglia\" (\"stammerer\"). After this he would never shave, and grew a beard to camouflage his scars.\nHis surname at birth, if any, is disputed. Some sources have him as \"Niccol\u00f2 Fontana\", but others claim that the only support for this is a will in which he named a brother, Zuampiero Fontana, as heir, and point out that this does not imply he had the same surname. \nTartaglia's biographer Arnoldo Masotti writes that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;At the age of about fourteen, he [Tartaglia] went to a Master Francesco to learn to write the alphabet; but by the time he reached \u201ck,\u201d he was no longer able to pay the teacher. \u201cFrom that day,\u201d he later wrote in a moving autobiographical sketch, \u201cI never returned to a tutor, but continued to labour by myself over the works of dead men, accompanied only by the daughter of poverty that is called industry\u201d (\"Quesiti\", bk. VI, question 8).\nTartaglia moved to Verona around 1517, then to Venice in 1534, a major European commercial hub and one of the great centres of the Italian renaissance at this time. Also relevant is Venice's place at the forefront of European printing culture in the sixteenth century, making early printed texts available even to poor scholars if sufficiently motivated or well-connected \u2014 Tartaglia knew of Archimedes' work on the quadrature of the parabola, for example, from Guarico's Latin edition of 1503, which he had found \"in the hands of a sausage-seller in Verona in 1531\" (\"in mano di un salzizaro in Verona, l'anno 1531\" in his words). Tartaglia's mathematics is also influenced by the works of medieval Islamic scholar Muhammad ibn Musa Al-Khwarizmi from 12th Century Latin translations becoming available in Europe.\nTartaglia eked out a living teaching practical mathematics in abacus schools and earned a penny where he could:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;This remarkable man [Tartaglia] was a self-educated mathematics teacher who sold mathematical advice to gunners and architects, ten pennies one question, and had to litigate with his customers when they gave him a worn-out cloak for his lectures on Euclid instead of the payment agreed on.\nHe died in Venice.\nBallistics.\n\"Nova Scientia\" (1537) was Tartaglia's first published work, described by Matteo Valleriani as:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;... one of the most fundamental works on mechanics of the Renaissance, indeed, the first to transform aspects of practical knowledge accumulated by the early modern artillerists into a theoretical \"and\" mathematical framework.\nThen dominant Aristotelian physics preferred categories like \"heavy\" and \"natural\" and \"violent\" to describe motion, generally eschewing mathematical explanations. Tartaglia brought mathematical models to the fore, \"eviscerat[ing] Aristotelian terms of projectile movement\" in the words of Mary J. Henninger-Voss. One of his findings was that the maximum range of a projectile was achieved by directing the cannon at a 45\u00b0 angle to the horizon.\nTartaglia's model for a cannonball's flight was that it proceeded from the cannon in a straight line, then after a while started to arc towards the earth along a circular path, then finally dropped in another straight line directly towards the earth. At the end of Book 2 of \"Nova Scientia\", Tartaglia proposes to find the length of that initial rectilinear path for a projectile fired at an elevation of 45\u00b0, engaging in a Euclidean-style argument, but one with numbers attached to line segments and areas, and eventually proceeds algebraically to find the desired quantity (\"procederemo per algebra\" in his words).\nMary J. Henninger-Voss notes that \"Tartaglia's work on military science had an enormous circulation throughout Europe\", being a reference for common gunners into the eighteenth century, sometimes through unattributed translations. He influenced Galileo as well, who owned \"richly annotated\" copies of his works on ballistics as he set about solving the projectile problem once and for all.\nTranslations.\nArchimedes' works began to be studied outside the universities in Tartaglia's day as exemplary of the notion that mathematics is the key to understanding physics, Federigo Commandino reflecting this notion when saying in 1558 that \"with respect to geometry no one of sound mind could deny that Archimedes was some god\". Tartaglia published a 71-page Latin edition of Archimedes in 1543, http://, containing Archimedes' works on the parabola, the circle, centres of gravity, and floating bodies. Guarico had published Latin editions of the first two in 1503, but the works on centres of gravity and floating bodies had not been published before. Tartaglia published Italian versions of some Archimedean texts later in life, his executor continuing to publish his translations after his death. Galileo probably learned of Archimedes' work through these widely disseminated editions.\nTartaglia's Italian edition of Euclid in 1543, https://, was especially significant as the first translation of the \"Elements\" into any modern European language. For two centuries Euclid had been taught from two Latin translations taken from an Arabic source; these contained errors in Book V, the Eudoxian theory of proportion, which rendered it unusable. Tartaglia's edition was based on Zamberti's Latin translation of an uncorrupted Greek text, and rendered Book V correctly. He also wrote the first modern and useful commentary on the theory. This work went through many editions in the sixteenth century and helped diffuse knowledge of mathematics to a non-academic but increasingly well-informed literate and numerate public in Italy. The theory became an essential tool for Galileo, as it had been for Archimedes.\n\"General Trattato di Numeri et Misure\".\nTartaglia exemplified and eventually transcended the abaco tradition that had flourished in Italy since the twelfth century, a tradition of concrete commercial mathematics taught at abacus schools maintained by communities of merchants. \"Maestros d'abaco\" like Tartaglia taught not with the abacus but with paper-and-pen, inculcating algorithms of the type found in grade schools today.\nTartaglia's masterpiece was the \"General Trattato di Numeri et Misure\" (\"General Treatise on Number and Measure\"), a 1500-page encyclopedia in six parts written in the Venetian dialect, the first three coming out in 1556 about the time of Tartaglia's death and the last three published posthumously by his literary executor and publisher Curtio Troiano in 1560. David Eugene Smith wrote of the \"General Trattato\" that it was:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;the best treatise on arithmetic that appeared in Italy in his century, containing a very full discussion of the numerical operations and the commercial rules of the Italian arithmeticians. The life of the people, the customs of the merchants, and the efforts at improving arithmetic in the 16th century are all set forth in this remarkable work.\nPart I is 554 pages long and constitutes essentially commercial arithmetic, taking up such topics as basic operations with the complex currencies of the day (ducats, soldi, pizolli, and so on), exchanging currencies, calculating interest, and dividing profits into joint companies. The book is replete with worked examples with much emphasis on methods and rules (that is, algorithms), all ready to use virtually as is.\nPart II takes up more general arithmetic problems, including progressions, powers, binomial expansions, Tartaglia's triangle (also known as \"Pascal's triangle\"), calculations with roots, and proportions / fractions.\nPart IV concerns triangles, regular polygons, the Platonic solids, and Archimedean topics like the quadrature of the circle and circumscribing a cylinder around a sphere.\nTartaglia's triangle.\nTartaglia was proficient with binomial expansions and included many worked examples in Part II of the \"General Trattato\", one a detailed explanation of how to calculate the summands of formula_1, including the appropriate binomial coefficients.\nTartaglia knew of Pascal's triangle one hundred years before Pascal, as shown in this image from the \"General Trattato\". His examples are numeric, but he thinks about it geometrically, the horizontal line formula_2 at the top of the triangle being broken into two segments formula_3 and formula_4, where point formula_5 is the apex of the triangle. Binomial expansions amount to taking formula_6 for exponents formula_7 as you go down the triangle. The symbols along the outside represent powers at this early stage of algebraic notation: formula_8, and so on. He writes explicitly about the additive formation rule, that (for example) the adjacent 15 and 20 in the fifth row add up to 35, which appears beneath them in the sixth row.\nSolution to cubic equations.\nTartaglia is perhaps best known today for his conflicts with Gerolamo Cardano. In 1539, Cardano cajoled Tartaglia into revealing his solution to the cubic equations by promising not to publish them. Tartaglia divulged the secrets of the solutions of three different forms of the cubic equation in verse. Several years later, Cardano happened to see unpublished work by Scipione del Ferro who independently came up with the same solution as Tartaglia. (Tartaglia had previously been challenged by del Ferro's student Fiore, which made Tartaglia aware that a solution existed.)\nAs the unpublished work was dated before Tartaglia's, Cardano decided his promise could be broken and included Tartaglia's solution in his next publication. Even though Cardano credited his discovery, Tartaglia was extremely upset and a famous public challenge match resulted between himself and Cardano's student, Ludovico Ferrari. Widespread stories that Tartaglia devoted the rest of his life to ruining Cardano, however, appear to be completely fabricated. Mathematical historians now credit both Cardano and Tartaglia with the formula to solve cubic equations, referring to it as the \"Cardano\u2013Tartaglia formula\".\nVolume of a tetrahedron.\nTartaglia was a prodigious calculator and master of solid geometry. In Part IV of the \"General Trattato\" he shows by example how to calculate the height of a pyramid on a triangular base, that is, an irregular tetrahedron.\nThe base of the pyramid is a 13-14-15 triangle \"bcd\", and the edges rising to the apex \"a\" from points \"b\", \"c\", and \"d\" have respective lengths 20, 18, and 16. The base triangle \"bcd\" partitions into 5-12-13 and 9-12-15 triangles by dropping the perpendicular from point \"d\" to side \"bc\". He proceeds to erect a triangle in the plane perpendicular to line \"bc\" through the pyramid's apex, point \"a\", calculating all three sides of this triangle and noting that its height is the height of the pyramid. At the last step, he applies what amounts to this formula for the height \"h\" of a triangle in terms of its sides \"p\", \"q\", \"r\" (the height from side \"p\" to its opposite vertex):\nformula_9\na formula deriving from the law of cosines (not that he cites any justification in this section of the \"General Trattato\").\nTartaglia drops a digit early in the calculation, taking as , but his method is sound. The final (correct) answer is:\nformula_10\nThe volume of the pyramid is easily obtained from this, though Tartaglia does not give it:\nformula_11\nSimon Stevin invented decimal fractions later in the sixteenth century, so the approximation would have been foreign to Tartaglia, who always used fractions. His approach is in some ways a modern one, suggesting by example an algorithm for calculating the height of irregular tetrahedra, but (as usual) he gives no explicit general formula.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22149", "revid": "50633408", "url": "https://en.wikipedia.org/wiki?curid=22149", "title": "Nagarjuna", "text": "3rd-century Indian Buddhist philosopher\nN\u0101g\u0101rjuna (, ; c.\u2009150\u00a0\u2013 c.\u2009250 CE) was an Indian philosopher and Mah\u0101y\u0101na Buddhist monk of the Madhyamaka (Centrism, Middle Way) school. N\u0101g\u0101rjuna is widely considered one of the most important Buddhist philosophers. He was the founder of the Madhyamaka school of Buddhist philosophy and a defender of the Mah\u0101y\u0101na movement. His \"M\u016blamadhyamakak\u0101rik\u0101\" (\"Root Verses on Madhyamaka\", MMK) is the most important text on the Madhyamaka philosophy of emptiness. The MMK inspired a large number of commentaries in Sanskrit, Chinese, Tibetan, Korean and Japanese and continues to be studied today.\nHistory.\nBackground.\nIndia in the first and second centuries CE was politically divided into various states, including the Kushan Empire and the Satavahana Kingdom. At this point in Buddhist history, the Buddhist community was already divided into various Buddhist schools and had spread throughout India.\nAt this time, there was already a small and nascent Mah\u0101y\u0101na movement. Mah\u0101y\u0101na ideas were held by a minority of Buddhists in India at the time. As Joseph Walser writes, \"Mah\u0101y\u0101na before the fifth century was largely invisible and probably existed only as a minority and largely unrecognized movement within the fold of nik\u0101ya Buddhism.\" By the second century, early Mah\u0101y\u0101na S\u016btras such as the \"A\u1e63\u1e6das\u0101hasrik\u0101 Praj\u00f1\u0101p\u0101ramit\u0101\" were already circulating among certain Mah\u0101y\u0101na circles.\nLife.\nVery little is reliably known of the life of N\u0101g\u0101rjuna and modern historians do not agree on a specific date (1st to 3rd century CE) or place (multiple places in India suggested) for him. The earliest surviving accounts were written in Chinese and Tibetan centuries after his death and are mostly hagiographical accounts that are historically unverifiable.\nSome scholars such as Joseph Walser argue that N\u0101g\u0101rjuna was an advisor to a king of the S\u0101tav\u0101hana dynasty which ruled the Deccan Plateau in the second century. This is supported by most of the traditional hagiographical sources as well. Archaeological evidence at Amar\u0101vat\u012b indicates that if this is true, the king may have been Yaj\u00f1a \u015ar\u012b \u015a\u0101takar\u1e47i (c. second half of the 2nd century). On the basis of this association, N\u0101g\u0101rjuna is conventionally placed at around 150\u2013250 CE.\nWalser thinks that it is most likely that when N\u0101g\u0101rjuna wrote the \"Ratnavali\", he lived in a mixed monastery (with Mah\u0101y\u0101nists and non-Mah\u0101y\u0101nists) in which Mah\u0101y\u0101nists were the minority. The most likely sectarian affiliation of the monastery according to Walser was Purvasailya, Aparasailya, or Caityaka (which were Mah\u0101s\u0101\u1e43ghika sub-schools).\nHe also argues that \"it is plausible that he wrote the \"Ratnavali\" within a thirty-year period at the end of the second century in the Andhra region around Dhanyakataka (modern-day Amaravati).\"\nTraditional hagiography.\nAccording to Walser, \"the earliest extant legends about N\u0101g\u0101rjuna are compiled into Kum\u0101raj\u012bva\u2019s biography of N\u0101g\u0101rjuna, which he translated into Chinese in about 405\u00a0CE.\" According to this biography, N\u0101g\u0101rjuna was born into a Brahmin family and later became a Buddhist. The traditional religious hagiographies place N\u0101g\u0101rjuna in various regions of India (Kum\u0101raj\u012bva and Candrakirti place him in Vidarbha region of South India, Xuanzang in south Kosala)\nTraditional religious hagiographies credit N\u0101g\u0101rjuna with being associated with the teaching of the Praj\u00f1\u0101p\u0101ramit\u0101 s\u016btras as well as with having revealed these scriptures to the world after they had remained hidden for some time. The sources differ on where this happened and how N\u0101g\u0101rjuna retrieved the sutras. Some sources say he retrieved the sutras from the land of the n\u0101gas. \nN\u0101g\u0101rjuna himself is often depicted in composite form comprising human and n\u0101ga characteristics. N\u0101gas are snake-like supernatural beings of great magical power that feature in Hindu, Buddhist and Jain mythology. N\u0101gas are found throughout Indian religious culture, and typically signify intelligent serpents or dragons that are responsible for rain, lakes, and other bodies of water. In Buddhism, a naga can be a symbol of a realised arhat or wise person.\nTraditional sources also claim that N\u0101g\u0101rjuna practised ayurvedic alchemy (ras\u0101yana). Kum\u0101raj\u012bva's biography for example, has N\u0101g\u0101rjuna making an elixir of invisibility, and Buton Rinchen Drub, Taranatha and Xuanzang all state that he could turn rocks into gold.\nTibetan hagiographies also state that N\u0101g\u0101rjuna studied at N\u0101landa University. However, according to Walser, this university was not a strong monastic center until about 425. Also, as Walser notes, \"Xuanzang and Yijing both spent considerable time at N\u0101landa and studied N\u0101g\u0101rjuna\u2019s texts there. It is strange that they would have spent so much time there and yet chose not to report any local tales of a man whose works played such an important part in the curriculum.\"\nSome sources (Buton Rinchen Drub and the other Tibetan historians) claim that in his later years, N\u0101g\u0101rjuna lived on the mountain of \u015ar\u012bparvata near the city that would later be called N\u0101g\u0101rjunako\u1e47\u1e0da (\"Hill of N\u0101g\u0101rjuna\"). The ruins of N\u0101g\u0101rjunako\u1e47\u1e0da are located in Guntur district, Andhra Pradesh. The Caitika and Bahu\u015brut\u012bya nik\u0101yas are known to have had monasteries in N\u0101g\u0101rjunako\u1e47\u1e0da. The archaeological finds at N\u0101g\u0101rjunako\u1e47\u1e0da have not resulted in any evidence that the site was associated with Nagarjuna. The name \"N\u0101g\u0101rjunako\u1e47\u1e0da\" dates from the medieval period, and the 3rd\u20134th century inscriptions found at the site make it clear that it was known as \"Vijayapuri\" in the ancient period.\nOther N\u0101g\u0101rjunas.\nThere are a multitude of texts attributed to \"N\u0101g\u0101rjuna\", many of these texts date from much later periods. This has caused much confusion for the traditional Buddhist biographers and doxographers. Modern scholars are divided on how to classify these later texts and how many later writers called \"N\u0101g\u0101rjuna\" existed (the name remains popular today in Andhra Pradesh).\nSome scholars have posited that there was a separate Aryuvedic writer called N\u0101g\u0101rjuna who wrote numerous treatises on Rasayana. Also, there is a later Tantric Buddhist author by the same name who may have been a scholar at N\u0101land\u0101 University and wrote on Buddhist tantra. According to Donald S. Lopez Jr., he originally belonged to a Brahmin family from eastern India and later became Buddhist.\nThere is also a Jain figure of the same name who was said to have travelled to the Himalayas. Walser thinks that it is possible that stories related to this figure influenced Buddhist legends as well.\nWorks.\nThere exist a number of influential texts attributed to N\u0101g\u0101rjuna; however, as there are many pseudepigrapha attributed to him, lively controversy exists over which are his authentic works.\n\"M\u016blamadhyamakak\u0101rik\u0101\".\nThe \"M\u016blamadhyamakak\u0101rik\u0101\" is N\u0101g\u0101rjuna's best-known work. It is \"not only a grand commentary on the Buddha's discourse to Kaccayana, the only discourse cited by name, but also a detailed and careful analysis of most of the important discourses included in the Nikayas and the Agamas, especially those of the \"Atthakavagga\" of the \"Sutta-nipata\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Utilizing the Buddha's theory of \"dependent arising\" (\"pratitya-samutpada\"), Nagarjuna demonstrated the futility of [...] metaphysical speculations. His method of dealing with such metaphysics is referred to as \"middle way\" (\"madhyama pratipad\"). It is the middle way that avoided the substantialism of the Sarvastivadins as well as the nominalism of the Sautrantikas.\nIn the \"M\u016blamadhyamakak\u0101rik\u0101\", \"[A]ll experienced phenomena are empty (\"sunya\"). This did not mean that they are not experienced and, therefore, non-existent; only that they are devoid of a permanent and eternal substance (\"svabhava\") because, like a dream, they are mere projections of human consciousness. Since these imaginary fictions are experienced, they are not mere names (\"prajnapti\").\"\nMajor attributed works.\nAccording to David Seyfort Ruegg, the \"Madhyamakasastrastuti\" attributed to Candrakirti (c.\u00a0600 \u2013 c.\u00a0650) refers to eight texts by Nagarjuna:the \"(Madhyamaka)karikas\", the \"Yuktisastika\", the \"Sunyatasaptati\", the \"Vigrahavyavartani\", the \"Vidala\" (i.e. \"Vaidalyasutra/Vaidalyaprakarana\"), the \"Ratnavali\", the \"Sutrasamuccaya\", and \"Samstutis\" (Hymns). This list covers not only much less than the grand total of works ascribed to Nagarjuna in the Chinese and Tibetan collections, but it does not even include all such works that Candrakirti has himself cited in his writings.According to one view, that of Christian Lindtner, the works definitely written by N\u0101g\u0101rjuna are:\nOther scholars have challenged and argued against some of the above works being Nagarjuna's. David F. Burton notes that Christian Lindtner is \"rather liberal\" with his list of works and that other scholars have called some of these into question. He notes how Paul Williams argued convincingly that the must be a later text. In his study, Burton relies on the texts that he considers \"least controversial\": \"M\u016blamadhyamaka-k\u0101rik\u0101, Vigrahavy\u0101vartan\u012b, \u015a\u016bnyat\u0101saptati,\" , , and \"Ratn\u0101val\u012b\". \nSimilarly, Jan Westerhoff notes how there is uncertainty about the attribution of Nagarjuna's works (and about his life in general). He relies on six works: MMK, \"Vigrahavy\u0101vartan\u012b, \u015a\u016bnyat\u0101saptati,\" , and \"Ratn\u0101val\u012b,\" all of which \"expound a single, coherent philosophical system\", and are attributed to Nagarjuna by a variety of Indian and Tibetan sources. \nThe Tibetan historian Buston considers the first six to be the main treatises of N\u0101g\u0101rjuna (this is called the \"yukti corpus\", \"rigs chogs\"), while according to T\u0101ran\u0101tha only the first five are the works of N\u0101g\u0101rjuna. TRV Murti considers \"Ratn\u0101val\u012b\", \"Prat\u012btyasamutp\u0101dah\u1e5ddaya\" and \"S\u016btrasamuccaya\" to be works of N\u0101g\u0101rjuna as the first two are quoted profusely by Chandrakirti and the third by Shantideva.\nOther attributed works.\nIn addition to works mentioned above, numerous other works are attributed to N\u0101g\u0101rjuna, many of which are dubious attributions and later works. There is an ongoing, lively controversy over which of those works are authentic. Christian Lindtner divides the various attributed works as \"1) correctly attributed, 2) wrongly attributed to him, and 3) those which may or may not be genuine.\"\nLindtner further divides the third category of dubious or questionable texts into those which are \"perhaps authentic\" and those who are unlikely to be authentic.\nThose which he sees as \"perhaps\" being authentic include:\nRuegg notes various works of uncertain authorship which have been attributed to Nagarjuna, including the \"Dharmadhatustava\" (Hymn to the Dharmadhatu, which shows later influences), \"Mahayanavimsika, Salistambakarikas,\" the \"Bhavasamkranti,\" and the \"Dasabhumtkavibh\u0101s\u0101.\" Furthermore, Ruegg writes that \"three collections of stanzas on the virtues of intelligence and moral conduct ascribed to Nagarjuna are extant in Tibetan translation\": \"Praj\u00f1asatakaprakarana\", \"Nitisastra-Jantuposanabindu\" and \"Niti-sastra-Praj\u00f1adanda.\"\nAttributions which are likely to be false.\nMeanwhile, those texts that Lindtner considers as questionable and likely inauthentic are: \"Aksarasataka, Akutobhaya (Mulamadhyamakavrtti), Aryabhattaraka-Manjusriparamarthastuti, Kayatrayastotra, Narakoddharastava, Niruttarastava, Vandanastava, Dharmasamgraha, Dharmadhatugarbhavivarana, Ekaslokasastra, Isvarakartrtvanirakrtih (A refutation of God/Isvara), Sattvaradhanastava, Upayahrdaya, Astadasasunyatasastra, Dharmadhatustava, Yogaratnamala.\"Meanwhile, Lindtner's list of outright wrong attributions is: \"Mah\u0101praj\u00f1\u0101p\u0101ramitopade\u015ba (D\u00e0 zh\u00ecd\u00f9 l\u00f9n), Abudhabodhakaprakarana\", \"Guhyasamajatantratika\", \"Dvadasadvaraka\", \"Praj\u00f1aparamitastotra,\" and \"Svabhavatrayapravesasiddhi.\"Notably, the \"D\u00e0 zh\u00ecd\u00f9 l\u00f9n\" (Taisho 1509, \"Commentary on the great praj\u00f1aparamita\") which has been influential in Chinese Buddhism, has been questioned as a genuine work of N\u0101g\u0101rjuna by various scholars including Lamotte. This work is also only attested in a Chinese translation by Kum\u0101raj\u012bva and is unknown in the Tibetan and Indian traditions.\nOther works are extant only in Chinese, one of these is the \"Shih-erh-men-lun\" or 'Twelve-topic treatise' (*\"Dvadasanikaya\" or *\"Dvadasamukha-sastra\"); one of the three basic treatises of the Sanlun school (East Asian Madhyamaka).\nSeveral works considered important in esoteric Buddhism are attributed to N\u0101g\u0101rjuna and his disciples by traditional historians like T\u0101ran\u0101tha from 17th century Tibet. These historians try to account for chronological difficulties with various theories, such as seeing later writings as mystical revelations. For a useful summary of this tradition, see Wedemeyer 2007. Lindtner sees the author of some of these tantric works as being a tantric Nagarjuna who lives much later, sometimes called \"Nagarjuna II\".\nPhilosophy.\nSunyata.\nN\u0101g\u0101rjuna's major thematic focus is the concept of \u015b\u016bnyat\u0101 (translated into English as \"emptiness\") which brings together other key Buddhist doctrines, particularly an\u0101tman \"not-self\" and prat\u012btyasamutp\u0101da \"dependent origination\", to refute the metaphysics of some of his contemporaries. For N\u0101g\u0101rjuna, as for the Buddha in the early texts, it is not merely sentient beings that are \"selfless\" or non-substantial; all phenomena (dhammas) are without any svabh\u0101va, literally \"own-being\", \"self-nature\", or \"inherent existence\" and thus without any underlying essence. They are \"empty\" of being independently existent; thus the heterodox theories of svabh\u0101va circulating at the time were refuted on the basis of the doctrines of early Buddhism. This is so because all things arise always dependently: not by their own power, but by depending on conditions leading to their becoming\u2014coming into existence\u2014as opposed to being.\nN\u0101g\u0101rjuna means by real any entity which has a nature of its own (svabh\u0101va), which is not produced by causes (akrtaka), which is not dependent on anything else (paratra nirapeksha).\nChapter 24 verse 14 of the \"M\u016blamadhyamakak\u0101rik\u0101\" provides one of N\u0101g\u0101rjuna's most famous quotations on emptiness and co-arising:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"sarva\u1e43 ca yujyate tasya \u015b\u016bnyat\u0101 yasya yujyatesarva\u1e43 na yujyate tasya \u015b\u016bnya\u1e43 yasya na yujyate\"\nAll is possible when emptiness is possible.Nothing is possible when emptiness is impossible.\nAs part of his analysis of the emptiness of phenomena in the \"M\u016blamadhyamakak\u0101rik\u0101\", N\u0101g\u0101rjuna critiques svabh\u0101va in several different concepts. He discusses the problems of positing any sort of inherent essence to causation, movement, change and personal identity. N\u0101g\u0101rjuna makes use of the Indian logical tool of the tetralemma to attack any essentialist conceptions. N\u0101g\u0101rjuna's logical analysis is based on four basic propositions:\nAll things (dharma) exist: affirmation of being, negation of non-being\nAll things (dharma) do not exist: affirmation of non-being, negation of being\nAll things (dharma) both exist and do not exist: both affirmation and negation\nAll things (dharma) neither exist nor do not exist: neither affirmation nor negation \nTo say that all things are 'empty' is to deny any kind of ontological foundation; therefore N\u0101g\u0101rjuna's view is often seen as a kind of ontological anti-foundationalism or a metaphysical anti-realism. Understanding the nature of the emptiness of phenomena is simply a means to an end, which is nirvana. Thus N\u0101g\u0101rjuna's philosophical project is ultimately a soteriological one meant to correct our everyday cognitive processes which mistakenly posits svabh\u0101va on the flow of experience.\nSome scholars such as Fyodor Shcherbatskoy and T.R.V. Murti held that N\u0101g\u0101rjuna was the inventor of the Shunyata doctrine; however, more recent work by scholars such as Choong Mun-keat, Yin Shun and Dhammajothi Thero has argued that N\u0101g\u0101rjuna was not an innovator by putting forth this theory, but that, in the words of Shi Huifeng, \"the connection between emptiness and dependent origination is not an innovation or creation of N\u0101g\u0101rjuna\".\nTwo truths.\nN\u0101g\u0101rjuna was also instrumental in the development of the two truths doctrine, which claims that there are two levels of truth in Buddhist teaching, the ultimate truth (\"param\u0101rtha satya\") and the conventional or superficial truth (\"sa\u1e43v\u1e5btisatya\"). The ultimate truth to N\u0101g\u0101rjuna is the truth that everything is empty of essence, this includes emptiness itself ('the emptiness of emptiness'). While some (Murti, 1955) have interpreted this by positing N\u0101g\u0101rjuna as a neo-Kantian and thus making ultimate truth a metaphysical noumenon or an \"ineffable ultimate that transcends the capacities of discursive reason\", others such as Mark Siderits and Jay L. Garfield have argued that N\u0101g\u0101rjuna's view is that \"the ultimate truth is that there is no ultimate truth\" (Siderits) and that N\u0101g\u0101rjuna is a \"semantic anti-dualist\" who posits that there are only conventional truths. Hence according to Garfield:\nSuppose that we take a conventional entity, such as a table. We analyze it to demonstrate its emptiness, finding that there is no table apart from its parts [...]. So we conclude that it is empty. But now let us analyze that emptiness [...]. What do we find? Nothing at all but the table's lack of inherent existence. [...]. To see the table as empty [...] is to see the table as conventional, as dependent.\nIn articulating this notion in the \"M\u016blamadhyamakak\u0101rik\u0101\", N\u0101g\u0101rjuna drew on an early source in the \"Kacc\u0101nagotta Sutta\", which distinguishes definitive meaning (\"n\u012bt\u0101rtha\") from interpretable meaning (\"ney\u0101rtha\"):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;By and large, Kaccayana, this world is supported by a polarity, that of existence and non-existence. But when one reads the origination of the world as it actually is with right discernment, \"non-existence\" with reference to the world does not occur to one. When one reads the cessation of the world as it actually is with right discernment, \"existence\" with reference to the world does not occur to one.\nBy and large, Kaccayana, this world is in bondage to attachments, clingings (sustenances), and biases. But one such as this does not get involved with or cling to these attachments, clingings, fixations of awareness, biases, or obsessions; nor is he resolved on \"my self\". He has no uncertainty or doubt that just stress, when arising, is arising; stress, when passing away, is passing away. In this, his knowledge is independent of others. It's to this extent, Kaccayana, that there is right view.\n\"Everything exists\": That is one extreme. \"Everything doesn't exist\": That is a second extreme. Avoiding these two extremes, the Tathagata teaches the Dhamma via the middle...\nThe version linked to is the one found in the nikayas, and is slightly different from the one found in the \"Samyuktagama\". Both contain the concept of teaching via the middle between the extremes of existence and non-existence. Nagarjuna does not make reference to \"everything\" when he quotes the agamic text in his \"M\u016blamadhyamakak\u0101rik\u0101\".\nCausality.\nJay L. Garfield describes that N\u0101g\u0101rjuna approached causality from the Four Noble Truths and dependent origination. N\u0101g\u0101rjuna distinguished two dependent origination views in a causal process, that which causes effects and that which causes conditions. This is predicated in the two truth doctrine, as conventional truth and ultimate truth held together, in which both are empty in existence. The distinction between effects and conditions is controversial. In N\u0101g\u0101rjuna's approach, cause means an event or state that has power to bring an effect. Conditions, refer to proliferating causes that bring a further event, state or process; without a metaphysical commitment to an occult connection between explaining and explanans. He argues nonexistent causes and various existing conditions. The argument draws from unreal causal power. Things conventional exist and are ultimately nonexistent to rest in the Middle Way in both causal existence and nonexistence as casual emptiness within the M\u016blamadhyamakak\u0101rik\u0101 doctrine. Although seeming strange to Westerners, this is seen as an attack on a reified view of causality.\nRelativity.\nN\u0101g\u0101rjuna also taught the idea of relativity; in the Ratn\u0101val\u012b, he gives the example that shortness exists only in relation to the idea of length. The determination of a thing or object is only possible in relation to other things or objects, especially by way of contrast. He held that the relationship between the ideas of \"short\" and \"long\" is not due to intrinsic nature (svabh\u0101va). This idea is also found in the Pali Nik\u0101yas and Chinese \u0100gamas, in which the idea of relativity is expressed similarly: \"That which is the element of light ... is seen to exist on account of [in relation to] darkness; that which is the element of good is seen to exist on account of bad; that which is the element of space is seen to exist on account of form.\"\nComparative philosophy.\nHinduism.\nN\u0101g\u0101rjuna was fully acquainted with the classical Hindu philosophies of Samkhya and even the Vaiseshika. N\u0101g\u0101rjuna assumes a knowledge of the definitions of the sixteen categories as given in the Nyaya Sutras, the chief text of the Hindu Nyaya school, and wrote a treatise on the pramanas where he reduced the syllogism of five members into one of three. In the Vigrahavyavartani Karika, N\u0101g\u0101rjuna criticises the Nyaya theory of \"pramanas\" (means of knowledge).\nMah\u0101y\u0101na Buddhism.\nN\u0101g\u0101rjuna was conversant with many of the \u015ar\u0101vaka philosophies and with the Mah\u0101y\u0101na tradition; however, determining N\u0101g\u0101rjuna's affiliation with a specific nik\u0101ya is difficult, considering much of this material has been lost. If the most commonly accepted attribution of texts (that of Christian Lindtner) holds, then he was clearly a M\u0101hay\u0101nist, but his philosophy holds assiduously to the \u015ar\u0101vaka \"Tripi\u1e6daka\", and while he does make explicit references to Mah\u0101y\u0101na texts, he is always careful to stay within the parameters set out by the \u015ar\u0101vaka canon.\nN\u0101g\u0101rjuna may have arrived at his positions from a desire to achieve a consistent exegesis of the Buddha's doctrine as recorded in the \u0101gamas. In the eyes of N\u0101g\u0101rjuna, the Buddha was not merely a forerunner, but the very founder of the Madhyamaka system. David Kalupahana sees N\u0101g\u0101rjuna as a successor to Moggaliputta-Tissa in being a champion of the middle-way and a reviver of the original philosophical ideals of the Buddha.\nPyrrhonism and its influence.\nBecause of the high degree of similarity between N\u0101g\u0101rjuna's philosophy and Pyrrhonism, particularly the surviving works of Sextus Empiricus, According to Thomas McEvilley this is because Nagarjuna was likely influenced by Greek Pyrrhonist texts imported into India. Pyrrho of Elis (c.\u00a0360\u00a0\u2013 c.\u00a0270\u00a0BCE), the founder of this school of sceptical philosophy, was himself influenced by Indian philosophy. Pyrrho travelled to India with Alexander the Great's army and studied with the gymnosophists. According to Christopher I. Beckwith, Pyrrho's teachings are based on Buddhism, because the Greek terms \"adiaphora\", \"astathm\u0113ta\" and \"anepikrita\" in the \"Aristocles Passage\" resemble the Buddhist three marks of existence. According to him, the key innovative tenets of Pyrrho's scepticism were only found in Indian philosophy at the time and not in Greece.\nHowever, other scholars, such as Stephen Batchelor and Charles Goodman question Beckwith's conclusions about the degree of Buddhist influence on Pyrrho.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "22150", "revid": "40123752", "url": "https://en.wikipedia.org/wiki?curid=22150", "title": "Nuclear Power", "text": ""}
{"id": "22151", "revid": "3798137", "url": "https://en.wikipedia.org/wiki?curid=22151", "title": "Nuclear reactor", "text": "Device for controlled nuclear reactions\nA nuclear reactor is a device used to sustain a controlled fission nuclear chain reaction. They are used for commercial electricity, marine propulsion, weapons production and research. Fissile nuclei (primarily uranium-235 or plutonium-239) absorb single neutrons and split, releasing energy and multiple neutrons, which can induce further fission. Reactors stabilize this, regulating neutron absorbers and moderators in the core. Fuel efficiency is exceptionally high; low-enriched uranium is 120,000 times more energy-dense than coal. \nHeat from nuclear fission is passed to a working fluid coolant. In commercial reactors, this drives turbines and electrical generator shafts. Some reactors are used for district heating, and isotope production for medical and industrial use.\nAfter the discovery of fission in 1938, many countries launched military nuclear research programs. Early subcritical experiments probed neutronics. In 1942, the first artificial critical nuclear reactor, Chicago Pile-1, was built by the Metallurgical Laboratory. From 1944, for weapons production, the first large-scale reactors were operated at the Hanford Site. The pressurized water reactor design, used in about 70% of commercial reactors, was developed for US Navy submarine propulsion, beginning with S1W in 1953. In 1954, nuclear electricity production began with the Soviet Obninsk plant.\nSpent fuel can be reprocessed, reducing nuclear waste and recovering reactor-usable fuel. This also poses a proliferation risk via production of plutonium and tritium for nuclear weapons. \nReactor accidents have been caused by combinations of design and operator failure. The 1979 Three Mile Island accident, at INES Level 5, and the 1986 Chernobyl disaster and 2011 Fukushima disaster, both at Level 7, all had major effects on the nuclear industry and anti-nuclear movement.\nAs of 2025[ [update]], there are 417 commercial reactors, 226 research reactors, and over 200 marine propulsion reactors in operation globally. Commercial reactors provide 9% of the global electricity supply, compared to 30% from renewables, together comprising low-carbon electricity. Almost 90% of this comes from pressurized and boiling water reactors. Other designs include gas-cooled, fast-spectrum, breeder, heavy-water, molten-salt, and small modular, each of which improves safety, efficiency, cost, fuel type, enrichment, or burnup, and the now-obsolete Light water graphite reactor.\nTerminology.\nDuring early 1940s nuclear research, the phrase \"atomic pile\" was used for any assembly involving uranium and attempts at neutron multiplication, including the majority which were subcritical. After Chicago Pile-1 demonstrated a self-sustaining chain reaction, the \"reactor\" terminology became more common. The phrases \"nuclear pile\" and \"atomic reactor\" were also common. \nCritical mass experiments, while being far simpler, are sometimes referred to as research reactors, such as the Godiva device. \n\"Nuclear reactor\" is predominantly used to refer to the nuclear fission reactor. It can also refer to a nuclear fusion reactor, of which only net negative power systems have been constructed. Radioisotope thermoelectric generators and radioisotope heater units, while deriving power from nuclear decay reactions, are not referred to as nuclear reactors as they do not \"induce\" reactions.\nOperation.\nJust as conventional thermal power stations generate electricity by harnessing the thermal energy released from burning fossil fuels, nuclear reactors convert the energy released by controlled nuclear fission into thermal energy for further conversion to mechanical or electrical forms.\nFission.\nWhen a large fissile atomic nucleus such as uranium-235, uranium-233, or plutonium-239 absorbs a neutron, it may undergo nuclear fission. The heavy nucleus splits into two or more lighter nuclei, (the fission products), releasing kinetic energy, gamma radiation, and free neutrons. A portion of these neutrons may be absorbed by other fissile atoms and trigger further fission events, which release more neutrons, and so on. This is known as a nuclear chain reaction.\nTo control such a nuclear chain reaction, control rods containing neutron poisons and neutron moderators are able to change the portion of neutrons that will go on to cause more fission. Nuclear reactors generally have automatic and manual systems to shut the fission reaction down if monitoring or instrumentation detects unsafe conditions.\nHeat generation.\nThe reactor core generates heat in a number of ways:\nA kilogram of uranium-235 (U-235) converted via nuclear processes releases approximately three million times more energy than a kilogram of coal burned conventionally (7.2\u00a0\u00d7\u00a01013 joules per kilogram of uranium-235 versus 2.4\u00a0\u00d7\u00a0107 joules per kilogram of coal).\nThe fission of one kilogram of uranium-235 releases about 19 billion kilocalories, so the energy released by 1\u00a0kg of uranium-235 corresponds to that released by burning 2.7 million kg of coal.\nCooling.\nA nuclear reactor coolant \u2013 usually water but sometimes a gas or a liquid metal (like liquid sodium or lead) or molten salt \u2013 is circulated past the reactor core to absorb the heat that it generates. The heat is carried away from the reactor and is then used to generate steam. Most reactor systems employ a cooling system that is physically separated from the water that will be boiled to produce pressurized steam for the turbines, like the pressurized water reactor. However, in some reactors the water for the steam turbines is boiled directly by the reactor core; for example the boiling water reactor.\nReactivity control.\nThe rate of fission reactions within a reactor core can be adjusted by controlling the quantity of neutrons that are able to induce further fission events. Nuclear reactors typically employ several methods of neutron control to adjust the reactor's power output. Some of these methods arise naturally from the physics of radioactive decay and are simply accounted for during the reactor's operation, while others are mechanisms engineered into the reactor design for a distinct purpose.\nThe fastest method for adjusting levels of fission-inducing neutrons in a reactor is via movement of the control rods. Control rods are made of so-called neutron poisons and therefore absorb neutrons. When a control rod is inserted deeper into the reactor, it absorbs more neutrons than the material it displaces \u2013 often the moderator. This action results in fewer neutrons available to cause fission and reduces the reactor's power output. Conversely, extracting the control rod will result in an increase in the rate of fission events and an increase in power.\nThe physics of radioactive decay also affects neutron populations in a reactor. One such process is delayed neutron emission by a number of neutron-rich fission isotopes. These delayed neutrons account for about 0.65% of the total neutrons produced in fission, with the remainder (termed \"prompt neutrons\") released immediately upon fission. The fission products which produce delayed neutrons have half-lives for their decay by neutron emission that range from milliseconds to as long as several minutes, and so considerable time is required to determine exactly when a reactor reaches the critical point. Keeping the reactor in the zone of chain reactivity where delayed neutrons are \"necessary\" to achieve a critical mass state allows mechanical devices or human operators to control a chain reaction in \"real time\"; otherwise the time between achievement of criticality and nuclear meltdown as a result of an exponential power surge from the normal nuclear chain reaction, would be too short to allow for intervention. This last stage, where delayed neutrons are no longer required to maintain criticality, is known as the prompt critical point. There is a scale for describing criticality in numerical form, in which bare criticality is known as \"zero dollars\" and the prompt critical point is \"one dollar\", and other points in the process interpolated in cents.\nIn some reactors, the coolant also acts as a neutron moderator. A moderator increases the power of the reactor by causing the fast neutrons that are released from fission to lose energy and become thermal neutrons. Thermal neutrons are more likely than fast neutrons to cause fission. If the coolant is a moderator, then temperature changes can affect the density of the coolant/moderator and therefore change power output. A higher temperature coolant would be less dense, and therefore a less effective moderator.\nIn other reactors, the coolant acts as a poison by absorbing neutrons in the same way that the control rods do. In these reactors, power output can be increased by heating the coolant, which makes it a less dense poison. Nuclear reactors generally have automatic and manual systems to scram the reactor in an emergency shut down. These systems insert large amounts of poison (often boron in the form of boric acid) into the reactor to shut the fission reaction down if unsafe conditions are detected or anticipated.\nMost types of reactors are sensitive to a process variously known as xenon poisoning, or the iodine pit. The common fission product Xenon-135 produced in the fission process acts as a neutron poison that absorbs neutrons and therefore tends to shut the reactor down. Xenon-135 accumulation can be controlled by keeping power levels high enough to destroy it by neutron absorption as fast as it is produced. Fission also produces iodine-135, which in turn decays (with a half-life of 6.57 hours) to new xenon-135. When the reactor is shut down, iodine-135 continues to decay to xenon-135, making restarting the reactor more difficult for a day or two, as the xenon-135 decays into cesium-135, which is not nearly as poisonous as xenon-135, with a half-life of 9.2 hours. This temporary state is the \"iodine pit.\" If the reactor has sufficient extra reactivity capacity, it can be restarted. As the extra xenon-135 is transmuted to xenon-136, which is much less a neutron poison, within a few hours the reactor experiences a \"xenon burnoff (power) transient\". Control rods must be further inserted to replace the neutron absorption of the lost xenon-135. Failure to properly follow such a procedure was a key step in the Chernobyl disaster.\nReactors used in nuclear marine propulsion (especially nuclear submarines) often cannot be run at continuous power around the clock in the same way that land-based power reactors are normally run, and in addition often need to have a very long core life without refueling. For this reason many designs use highly enriched uranium but incorporate burnable neutron poison in the fuel rods. This allows the reactor to be constructed with an excess of fissionable material, which is nevertheless made relatively safe early in the reactor's fuel burn cycle by the presence of the neutron-absorbing material which is later replaced by normally produced long-lived neutron poisons (far longer-lived than xenon-135) which gradually accumulate over the fuel load's operating life.\nElectrical power generation.\nThe energy released in the fission process generates heat, some of which can be converted into usable energy. A common method of harnessing this thermal energy is to use it to boil water to produce pressurized steam which will then drive a steam turbine that turns an alternator and generates electricity.\nLife-times.\nModern nuclear power plants are typically designed for a lifetime of 60 years, while older reactors were built with a planned typical lifetime of 30\u201340 years, though many of those have received renovations and life extensions of 15\u201320 years. Some believe nuclear power plants can operate for as long as 80 years or longer with proper maintenance and management. While most components of a nuclear power plant, such as steam generators, are replaced when they reach the end of their useful lifetime, the overall lifetime of the power plant is limited by the life of components that cannot be replaced when aged by wear and neutron embrittlement, such as the reactor pressure vessel. At the end of their planned life span, plants may get an extension of the operating license for some 20 years and in the US even a \"subsequent license renewal\" (SLR) for an additional 20 years.\nEven when a license is extended, it does not guarantee the reactor will continue to operate, particularly in the face of safety concerns or incident. Many reactors are closed long before their license or design life expired and are decommissioned. The costs for replacements or improvements required for continued safe operation may be so high that they are not cost-effective. Or they may be shut down due to technical failure. Other ones have been shut down because the area was contaminated, like Fukushima, Three Mile Island, Sellafield, and Chernobyl. The British branch of the French concern EDF Energy, for example, extended the operating lives of its Advanced Gas-cooled Reactors (AGR) with only between 3 and 10 years. All seven AGR plants were expected to be shut down in 2022 and in decommissioning by 2028. Hinkley Point B was extended from 40 to 46 years, and closed. The same happened with Hunterston B, also after 46 years.\nAn increasing number of reactors is reaching or crossing their design lifetimes of 30 or 40 years. In 2014, Greenpeace warned that the lifetime extension of ageing nuclear power plants amounts to entering a new era of risk. It estimated the current European nuclear liability coverage in average to be too low by a factor of between 100 and 1,000 to cover the likely costs, while at the same time, the likelihood of a serious accident happening in Europe continues to increase as the reactor fleet grows older.\nHistory.\nThe neutron was discovered in 1932 by British physicist James Chadwick. The concept of a nuclear chain reaction brought about by nuclear reactions mediated by neutrons was first realized shortly thereafter, by Hungarian scientist Le\u00f3 Szil\u00e1rd, in 1933. He filed a patent for his idea of a simple reactor the following year while working at the Admiralty in London, England. However, Szil\u00e1rd's idea did not incorporate the idea of nuclear fission as a neutron source, since that process was not yet discovered. Szil\u00e1rd's ideas for nuclear reactors using neutron-mediated nuclear chain reactions in light elements proved unworkable.\nInspiration for a new type of reactor using uranium came from the discovery by Otto Hahn, Lise Meitner, and Fritz Strassmann in 1938 that bombardment of uranium with neutrons (provided by an alpha-on-beryllium fusion reaction, a \"neutron howitzer\") produced a barium residue, which they reasoned was created by fission of the uranium nuclei. In their second publication on nuclear fission in February 1939, Hahn and Strassmann predicted the existence and liberation of additional neutrons during the fission process, opening the possibility of a nuclear chain reaction. Subsequent studies in early 1939 (one of them by Szil\u00e1rd and Fermi), revealed that several neutrons were indeed released during fission, making available the opportunity for the nuclear chain reaction that Szil\u00e1rd had envisioned six years previously.\nOn 2 August 1939, Albert Einstein signed a letter to President Franklin D. Roosevelt (written by Szil\u00e1rd) suggesting that the discovery of uranium's fission could lead to the development of \"extremely powerful bombs of a new type\", giving impetus to the study of reactors and fission. Szil\u00e1rd and Einstein knew each other well and had worked together years previously, but Einstein had never thought about this possibility for nuclear energy until Szilard reported it to him, at the beginning of his quest to produce the Einstein-Szil\u00e1rd letter to alert the U.S. government.\nShortly after, Nazi Germany invaded Poland in 1939, starting World War II in Europe. The U.S. was not yet officially at war, but in October, when the Einstein-Szil\u00e1rd letter was delivered to him, Roosevelt commented that the purpose of doing the research was to make sure \"the Nazis don't blow us up.\" The U.S. nuclear project followed, although with some delay as there remained skepticism (some of it from Enrico Fermi) and also little action from the small number of officials in the government who were initially charged with moving the project forward.\nThe following year, the U.S. Government received the Frisch\u2013Peierls memorandum from the UK, which stated that the amount of uranium needed for a chain reaction was far lower than had previously been thought. The memorandum was a product of the MAUD Committee, which was working on the UK atomic bomb project, known as Tube Alloys, later to be subsumed within the Manhattan Project.\nEventually, the first artificial nuclear reactor, Chicago Pile-1, was constructed at the University of Chicago, by a team led by Italian physicist Enrico Fermi, in late 1942. By this time, the program had been pressured for a year by U.S. entry into the war. The Chicago Pile achieved criticality on 2 December 1942 at 3:25\u00a0PM. The reactor support structure was made of wood, which supported a pile (hence the name) of graphite blocks, embedded in which was natural uranium oxide 'pseudospheres' or 'briquettes'.\nSoon after the Chicago Pile, the Metallurgical Laboratory developed a number of nuclear reactors for the Manhattan Project starting in 1943. The primary purpose for the largest reactors (located at the Hanford Site in Washington), was the mass production of plutonium for nuclear weapons. Fermi and Szilard applied for a patent on reactors on 19 December 1944. Its issuance was delayed for 10\u00a0years because of wartime secrecy.\n\"World's first nuclear power plant\" is the claim made by signs at the site of the EBR-I, which is now a museum near Arco, Idaho. Originally called \"Chicago Pile-4\", it was carried out under the direction of Walter Zinn for Argonne National Laboratory. This experimental LMFBR operated by the U.S. Atomic Energy Commission produced 0.8\u00a0kW in a test on 20 December 1951 and 100\u00a0kW (electrical) the following day, having a design output of 200\u00a0kW (electrical).\nBesides the military uses of nuclear reactors, there were political reasons to pursue civilian use of atomic energy. U.S. President Dwight Eisenhower made his famous Atoms for Peace speech to the UN General Assembly on 8 December 1953. This diplomacy led to the dissemination of reactor technology to U.S. institutions and worldwide.\nThe first nuclear power plant built for civil purposes was the AM-1 Obninsk Nuclear Power Plant, launched on 27 June 1954 in the Soviet Union. It produced around 5\u00a0MW (electrical). It was built after the F-1 (nuclear reactor) which was the first reactor to go critical in Europe, and was also built by the Soviet Union.\nAfter World War II, the U.S. military sought other uses for nuclear reactor technology. Research by the Army led to the power stations for Camp Century, Greenland and McMurdo Station, Antarctica Army Nuclear Power Program. The Air Force Nuclear Bomber project resulted in the Molten-Salt Reactor Experiment. The U.S. Navy succeeded when they steamed the USS \"Nautilus\" (SSN-571) on nuclear power 17 January 1955.\nThe first commercial nuclear power station, Calder Hall in Sellafield, England was opened in 1956 with an initial capacity of 50 MW (later 200 MW).\nThe first portable nuclear reactor \"Alco PM-2A\" was used to generate electrical power (2 MW) for Camp Century from 1960 to 1963.\nReactor types.\n Number of reactors by type (end 2014)\n Net power capacity (GWe) by type (end 2014)\nClassifications.\nBy type of nuclear reaction.\nAll commercial power reactors are based on nuclear fission. They generally use uranium and its product plutonium as nuclear fuel, though a thorium fuel cycle is also possible. Fission reactors can be divided roughly into two classes, depending on the energy of the neutrons that sustain the fission chain reaction:\nIn principle, fusion power could be produced by nuclear fusion of elements such as the deuterium isotope of hydrogen. While an ongoing rich research topic since at least the 1940s, no self-sustaining fusion reactor for any purpose has ever been built.\nBy moderator material.\nUsed by thermal reactors:\nBy generation.\nIn 2003, the French Commissariat \u00e0 l'\u00c9nergie Atomique (CEA) was the first to refer to \"Gen II\" types in \"Nucleonics Week\".\nThe first mention of \"Gen III\" was in 2000, in conjunction with the launch of the Generation IV International Forum (GIF) plans.\n\"Gen IV\" was named in 2000, by the United States Department of Energy (DOE), for developing new plant types.\n These reactors use a pressure vessel to contain the nuclear fuel, control rods, moderator, and coolant. The hot radioactive water that leaves the pressure vessel is looped through a steam generator, which in turn heats a secondary (nonradioactive) loop of water to steam that can run turbines. They represent the majority (around 80%) of current reactors. This is a thermal neutron reactor design, the newest of which are the Russian VVER-1200, Japanese Advanced Pressurized Water Reactor, American AP1000, Chinese Hualong Pressurized Reactor and the Franco-German European Pressurized Reactor. All the United States Naval reactors are of this type.\n A BWR is like a PWR without the steam generator. The lower pressure of its cooling water allows it to boil inside the pressure vessel, producing the steam that runs the turbines. Unlike a PWR, there is no primary and secondary loop. The thermal efficiency of these reactors can be higher, and they can be simpler, and even potentially more stable and safe. This is a thermal-neutron reactor design, the newest of which are the Advanced Boiling Water Reactor and the Economic Simplified Boiling Water Reactor.\n A Canadian design (known as CANDU), very similar to PWRs but using heavy water. While heavy water is significantly more expensive than ordinary water, it has greater neutron economy (creates a higher number of thermal neutrons), allowing the reactor to operate without fuel enrichment facilities. Instead of using a single large pressure vessel as in a PWR, the fuel is contained in hundreds of pressure tubes. These reactors are fueled with natural uranium and are thermal-neutron reactor designs. PHWRs can be refueled while at full power, (online refueling) which makes them very efficient in their use of uranium (it allows for precise flux control in the core). CANDU PHWRs have been built in Canada, Argentina, China, India, Pakistan, Romania, and South Korea. India also operates a number of PHWRs, often termed 'CANDU derivatives', built after the Government of Canada halted nuclear dealings with India following the 1974 Smiling Buddha nuclear weapon test.\n A Soviet design, RBMKs are in some respects similar to CANDU in that they can be refueled during power operation and employ a pressure tube design instead of a PWR-style pressure vessel. However, unlike CANDU they are unstable and large, making containment buildings for them expensive. A series of critical safety flaws have also been identified with the RBMK design, though some of these were corrected following the Chernobyl disaster. Their main attraction is their use of light water and unenriched uranium. As of 2024, 7 remain open, mostly due to safety improvements and help from international safety agencies such as the U.S. Department of Energy. Despite these safety improvements, RBMK reactors are still considered one of the most dangerous reactor designs in use. RBMK reactors were deployed only in the former Soviet Union.\n These designs have a high thermal efficiency compared with PWRs due to higher operating temperatures. There are a number of operating reactors of this design, mostly in the United Kingdom, where the concept was developed. Older designs (i.e. Magnox stations) are either shut down or will be in the near future. However, the AGRs have an anticipated life of a further 10 to 20\u00a0years. This is a thermal-neutron reactor design. Decommissioning costs can be high due to the large volume of the reactor core.\n This totally unmoderated reactor design produces more fuel than it consumes. They are said to \"breed\" fuel, because they produce fissionable fuel during operation because of neutron capture. These reactors can function much like a PWR in terms of efficiency, and do not require much high-pressure containment, as the liquid metal does not need to be kept at high pressure, even at very high temperatures. These reactors are fast neutron, not thermal neutron designs. These reactors come in two types:\nLead-cooled\n Using lead as the liquid metal provides excellent radiation shielding, and allows for operation at very high temperatures. Also, lead is (mostly) transparent to neutrons, so fewer neutrons are lost in the coolant, and the coolant does not become radioactive. Unlike sodium, lead is mostly inert, so there is less risk of explosion or accident, but such large quantities of lead may be problematic from toxicology and disposal points of view. Often a reactor of this type would use a lead-bismuth eutectic mixture. In this case, the bismuth would present some minor radiation problems, as it is not quite as transparent to neutrons, and can be transmuted to a radioactive isotope more readily than lead. The Russian Alfa class submarine uses a lead-bismuth-cooled fast reactor as its main power plant.\n Sodium-cooled\n Most LMFBRs are of this type. The TOPAZ, BN-350 and BN-600 in USSR; Superph\u00e9nix in France; and Fermi-I in the United States were reactors of this type. The sodium is relatively easy to obtain and work with, and it also manages to actually prevent corrosion on the various reactor parts immersed in it. However, sodium explodes violently when exposed to water, so care must be taken, but such explosions would not be more violent than (for example) a leak of superheated fluid from a pressurized-water reactor. The Monju reactor in Japan suffered a sodium leak in 1995 and could not be restarted until May 2010. The EBR-I, the first reactor to have a core meltdown, in 1955, was also a sodium-cooled reactor. \n These use fuel molded into ceramic balls, and then circulate gas through the balls. The result is an efficient, low-maintenance, very safe reactor with inexpensive, standardized fuel. The prototypes were the AVR and the THTR-300 in Germany, which produced up to 308MW of electricity between 1985 and 1989 until it was shut down after experiencing a series of incidents and technical difficulties. The HTR-10 is operating in China, where the HTR-PM is being developed. The HTR-PM is expected to be the first generation IV reactor to enter operation.\nThese dissolve the fuels in fluoride or chloride salts, or use such salts for coolant. MSRs potentially have many safety features, including the absence of high pressures or highly flammable components in the core. They were initially designed for aircraft propulsion due to their high efficiency and high power density. One prototype, the Molten-Salt Reactor Experiment, was built to confirm the feasibility of the Liquid fluoride thorium reactor, a thermal spectrum reactor which would breed fissile uranium-233 fuel from thorium.\n These reactors use as fuel soluble nuclear salts (usually uranium sulfate or uranium nitrate) dissolved in water and mixed with the coolant and the moderator. As of April 2006, only five AHRs were in operation.\nFuture and developing technologies.\nAdvanced reactors.\nMore than a dozen advanced reactor designs are in various stages of development. Some are evolutionary from the PWR, BWR and PHWR designs above, and some are more radical departures. The former include the advanced boiling water reactor (ABWR), two of which are now operating with others under construction, and the planned passively safe Economic Simplified Boiling Water Reactor (ESBWR) and AP1000 units (see Nuclear Power 2010 Program).\nRolls-Royce aims to sell nuclear reactors for the production of synfuel for aircraft.\nGeneration IV reactors.\nGeneration IV reactors are a set of theoretical nuclear reactor designs. These are generally not expected to be available for commercial use before 2040\u20132050, although the World Nuclear Association suggested that some might enter commercial operation before 2030. Current reactors in operation around the world are generally considered second- or third-generation systems, with the first-generation systems having been retired some time ago. Research into these reactor types was officially started by the Generation\u00a0IV International Forum (GIF) based on eight technology goals. The primary goals being to improve nuclear safety, improve proliferation resistance, minimize waste and natural resource utilization, and to decrease the cost to build and run such plants.\nGeneration V+ reactors.\nGeneration V reactors are designs which are theoretically possible, but which are not being actively considered or researched at present. Though some generation V reactors could potentially be built with current or near term technology, they trigger little interest for reasons of economics, practicality, or safety.\nFusion reactors.\nControlled nuclear fusion could in principle be used in fusion power plants to produce power without the complexities of handling actinides, but significant scientific and technical obstacles remain. Despite research having started in the 1950s, no commercial fusion reactor is expected before 2050. The ITER project is currently leading the effort to harness fusion power.\nNuclear fuel cycle.\nThermal reactors generally depend on refined and enriched uranium. Some nuclear reactors can operate with a mixture of plutonium and uranium (see MOX). The process by which uranium ore is mined, processed, enriched, used, possibly reprocessed and disposed of is known as the nuclear fuel cycle.\nUnder 1% of the uranium found in nature is the easily fissionable U-235 isotope and as a result most reactor designs require enriched fuel.\nEnrichment involves increasing the percentage of U-235 and is usually done by means of gaseous diffusion or gas centrifuge. The enriched result is then converted into uranium dioxide powder, which is pressed and fired into pellet form. These pellets are stacked into tubes which are then sealed and called fuel rods. Many of these fuel rods are used in each nuclear reactor.\nMost BWR and PWR commercial reactors use uranium enriched to about 4% U-235, and some commercial reactors with a high neutron economy do not require the fuel to be enriched at all (that is, they can use natural uranium). According to the International Atomic Energy Agency there are at least 100 research reactors in the world fueled by highly enriched (weapons-grade/90% enrichment) uranium. Theft risk of this fuel (potentially used in the production of a nuclear weapon) has led to campaigns advocating conversion of this type of reactor to low-enrichment uranium (which poses less threat of proliferation).\nFissile U-235 and non-fissile but fissionable and fertile U-238 are both used in the fission process. U-235 is fissionable by thermal (i.e. slow-moving) neutrons. A thermal neutron is one which is moving about the same speed as the atoms around it. Since all atoms vibrate proportionally to their absolute temperature, a thermal neutron has the best opportunity to fission U-235 when it is moving at this same vibrational speed. On the other hand, U-238 is more likely to capture a neutron when the neutron is moving very fast. This U-239 atom will soon decay into plutonium-239, which is another fuel. Pu-239 is a viable fuel and must be accounted for even when a highly enriched uranium fuel is used. Plutonium fissions will dominate the U-235 fissions in some reactors, especially after the initial loading of U-235 is spent. Plutonium is fissionable with both fast and thermal neutrons, which make it ideal for either nuclear reactors or nuclear bombs.\nMost reactor designs in existence are thermal reactors and typically use water as a neutron moderator (moderator means that it slows down the neutron to a thermal speed) and as a coolant. But in a fast breeder reactor, some other kind of coolant is used which will not moderate or slow the neutrons down much. This enables fast neutrons to dominate, which can effectively be used to constantly replenish the fuel supply. By merely placing cheap unenriched uranium into such a core, the non-fissionable U-238 will be turned into Pu-239, \"breeding\" fuel.\nIn a thorium fuel cycle, thorium-232 absorbs a neutron in either a fast or thermal reactor. The thorium-233 beta decays to protactinium-233 and then to uranium-233, which in turn is used as fuel. Hence, like uranium-238, thorium-232 is a fertile material. The thorium fuel cycle is considered to be more resistant to nuclear proliferation than uranium or MOX cycles, but has not been widely adopted.\nFueling of nuclear reactors.\nThe amount of energy in the reservoir of nuclear fuel is frequently expressed in terms of \"full-power days,\" which is the number of 24-hour periods (days) a reactor is scheduled for operation at full power output for the generation of heat energy. The number of full-power days in a reactor's operating cycle (between refueling outage times) is related to the amount of fissile uranium-235 (U-235) contained in the fuel assemblies at the beginning of the cycle. A higher percentage of U-235 in the core at the beginning of a cycle will permit the reactor to be run for a greater number of full-power days.\nAt the end of the operating cycle, the fuel in some of the assemblies is \"spent\", having spent four to six years in the reactor producing power. This spent fuel is discharged and replaced with new (fresh) fuel assemblies. Though considered \"spent,\" these fuel assemblies contain a large quantity of fuel. In practice it is economics that determines the lifetime of nuclear fuel in a reactor. Long before all possible fission has taken place, the reactor is unable to maintain 100%, full output power, and therefore, income for the utility lowers as plant output power lowers. Most nuclear plants operate at a very low profit margin due to operating overhead, mainly regulatory costs, so operating below 100% power is not economically viable for very long. The fraction of the reactor's fuel core replaced during refueling is typically one-third, but depends on how long the plant operates between refueling. Plants typically operate on 18 month refueling cycles, or 24 month refueling cycles. This means that one refueling, replacing only one-third of the fuel, can keep a nuclear reactor at full power for nearly two years. \nThe disposition and storage of this spent fuel is one of the most challenging aspects of the operation of a commercial nuclear power plant. This nuclear waste is highly radioactive and its toxicity presents a danger for thousands of years. After being discharged from the reactor, spent nuclear fuel is transferred to the on-site spent fuel pool. The spent fuel pool is a large pool of water that provides cooling and shielding of the spent nuclear fuel as well as limit radiation exposure to on-site personnel. Once the energy has decayed somewhat (approximately five years), the fuel can be transferred from the fuel pool to dry shielded casks, that can be safely stored for thousands of years. After loading into dry shielded casks, the casks are stored on-site in a specially guarded facility in impervious concrete bunkers. On-site fuel storage facilities are designed to withstand the impact of commercial airliners, with little to no damage to the spent fuel. An average on-site fuel storage facility can hold 30 years of spent fuel in a space smaller than a football field.\nNot all reactors need to be shut down for refueling; for example, pebble bed reactors, RBMK reactors, molten-salt reactors, Magnox, AGR and CANDU reactors allow fuel to be shifted through the reactor while it is running. In a CANDU reactor, this also allows individual fuel elements to be situated within the reactor core that are best suited to the amount of U-235 in the fuel element.\nThe amount of energy extracted from nuclear fuel is called its burnup, which is expressed in terms of the heat energy produced per initial unit of fuel weight. Burnup is commonly expressed as megawatt days thermal per metric ton of initial heavy metal.\nNuclear safety.\nNuclear safety covers the actions taken to prevent nuclear and radiation accidents and incidents or to limit their consequences. The nuclear power industry has improved the safety and performance of reactors, and has proposed new, safer (but generally untested) reactor designs but there is no guarantee that the reactors will be designed, built and operated correctly. Mistakes do occur and the designers of reactors at Fukushima in Japan did not anticipate that a tsunami generated by an earthquake would disable the backup systems that were supposed to stabilize the reactor after the earthquake, despite multiple warnings by the NRG and the Japanese nuclear safety administration. According to UBS AG, the Fukushima I nuclear accidents have cast doubt on whether even an advanced economy like Japan can master nuclear safety. Catastrophic scenarios involving terrorist attacks are also conceivable. An interdisciplinary team from MIT has estimated that given the expected growth of nuclear power from 2005 to 2055, at least four serious nuclear accidents would be expected in that period.\nNuclear accidents.\nSerious, though rare, nuclear and radiation accidents have occurred. These include the Windscale fire (October 1957), the SL-1 accident (1961), the Three Mile Island accident (1979), Chernobyl disaster (April 1986), and the Fukushima Daiichi nuclear disaster (March 2011). Nuclear-powered submarine mishaps include the K-19 reactor accident (1961), the K-27 reactor accident (1968), and the K-431 reactor accident (1985).\nNuclear reactors have been launched into Earth orbit at least 34 times. A number of incidents connected with the unmanned nuclear-reactor-powered Soviet RORSAT especially Kosmos 954 radar satellite which resulted in nuclear fuel reentering the Earth's atmosphere from orbit and being dispersed in northern Canada (January 1978).\nNatural nuclear reactors.\nAlmost two billion years ago a series of self-sustaining nuclear fission \"reactors\" self-assembled in the area now known as Oklo in Gabon, West Africa. The conditions at that place and time allowed a natural nuclear fission to occur with circumstances that are similar to the conditions in a constructed nuclear reactor. Fifteen fossil natural fission reactors have so far been found in three separate ore deposits at the Oklo uranium mine in Gabon. First discovered in 1972 by French physicist Francis Perrin, they are collectively known as the Oklo Fossil Reactors. Self-sustaining nuclear fission reactions took place in these reactors approximately 1.5\u00a0billion years ago, and ran for a few hundred thousand years, averaging 100\u00a0kW of power output during that time. The concept of a natural nuclear reactor was theorized as early as 1956 by Paul Kuroda at the University of Arkansas.\nSuch reactors can no longer form on Earth in its present geologic period. Radioactive decay of formerly more abundant uranium-235 over the time span of hundreds of millions of years has reduced the proportion of this naturally occurring fissile isotope to below the amount required to sustain a chain reaction with only plain water as a moderator.\nThe natural nuclear reactors formed when a uranium-rich mineral deposit became inundated with groundwater that acted as a neutron moderator, and a strong chain reaction took place. The water moderator would boil away as the reaction increased, slowing it back down again and preventing a meltdown. The fission reaction was sustained for hundreds of thousands of years, cycling on the order of hours to a few days.\nThese natural reactors are extensively studied by scientists interested in geologic radioactive waste disposal. They offer a case study of how radioactive isotopes migrate through the Earth's crust. This is a significant area of controversy as opponents of geologic waste disposal fear that isotopes from stored waste could end up in water supplies or be carried into the environment.\nEmissions.\nNuclear reactors produce tritium as part of normal operations, which is eventually released into the environment in trace quantities.\nAs an isotope of hydrogen, tritium (T) frequently binds to oxygen and forms T2O. This molecule is chemically identical to H2O and so is both colorless and odorless, however the additional neutrons in the hydrogen nuclei cause the tritium to undergo beta decay with a half-life of 12.3 years. Despite being measurable, the tritium released by nuclear power plants is minimal. The United States NRC estimates that a person drinking water for one year out of a well contaminated by what they would consider to be a significant tritiated water spill would receive a radiation dose of 0.3 millirem. For comparison, this is an order of magnitude less than the 4 millirem a person receives on a round trip flight from Washington, D.C. to Los Angeles, a consequence of less atmospheric protection against highly energetic cosmic rays at high altitudes.\nThe amounts of strontium-90 released from nuclear power plants under normal operations is so low as to be undetectable above natural background radiation. Detectable strontium-90 in ground water and the general environment can be traced to weapons testing that occurred during the mid-20th century (accounting for 99% of the Strontium-90 in the environment) and the Chernobyl accident (accounting for the remaining 1%).\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22153", "revid": "8500787", "url": "https://en.wikipedia.org/wiki?curid=22153", "title": "Nuclear power", "text": "Power generated from nuclear reactions\nNuclear power is the use of nuclear reactions to produce electricity. Nuclear power can be obtained from nuclear fission, nuclear decay and nuclear fusion reactions. Presently, the vast majority of electricity from nuclear power is produced by nuclear \"fission\" of uranium and plutonium in nuclear power plants. Nuclear \"decay\" processes are used in niche applications such as radioisotope thermoelectric generators in some space probes such as \"Voyager 2\". Reactors producing controlled \"fusion\" power have been operated since 1958 but have yet to generate net power and are not expected to be commercially available in the near future.\nThe first nuclear power plant was built in the 1950s. The global installed nuclear capacity grew to 100GW in the late 1970s, and then expanded during the 1980s, reaching 300GW by 1990. The 1979 Three Mile Island accident in the United States and the 1986 Chernobyl disaster in the Soviet Union resulted in increased regulation and public opposition to nuclear power plants. Nuclear power plants supplied 2,602 terawatt hours (TWh) of electricity in 2023, equivalent to about 9% of global electricity generation, and were the second largest low-carbon power source after hydroelectricity. As of \u00a02025,[ [update]] there are 416 civilian fission reactors in the world, with overall capacity of 376GW, 63 under construction and 87 planned, with a combined capacity of 66GW and 84GW, respectively. The United States has the largest fleet of nuclear reactors, generating almost 800TWh per year with an average capacity factor of 92%. The average global capacity factor is 89%. Most new reactors under construction are generation III reactors in Asia.\nNuclear power is a safe, sustainable energy source that reduces carbon emissions. This is because nuclear power generation causes one of the lowest levels of fatalities per unit of energy generated compared to other energy sources. \"Economists estimate that each nuclear plant built could save more than 800,000 life years.\" Coal, petroleum, natural gas and hydroelectricity have each caused more fatalities per unit of energy due to air pollution and accidents. Nuclear power plants also emit no greenhouse gases and result in less life-cycle carbon emissions than common sources of renewable energy. The radiological hazards associated with nuclear power are the primary motivations of the anti-nuclear movement, which contends that nuclear power poses threats to people and the environment, citing the potential for accidents like the Fukushima nuclear disaster in Japan in 2011, and is too expensive to deploy when compared to alternative sustainable energy sources.&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\nOrigins.\nThe process of nuclear fission was discovered in 1938 after over four decades of work on the science of radioactivity and the elaboration of new nuclear physics that described the components of atoms. Soon after the discovery of the fission process, it was realized that neutrons released by a fissioning nucleus could, under the right conditions, induce fissions in nearby nuclei, thus initiating a self-sustaining chain reaction. Once this was experimentally confirmed in 1939, scientists in many countries petitioned their governments for support for nuclear fission research, just on the cusp of World War II, in order to develop a nuclear weapon.\nIn the United States, these research efforts led to the creation of the first human-made nuclear reactor, the Chicago Pile-1 under the Stagg Field stadium at the University of Chicago, which achieved criticality on December 2, 1942. The reactor's development was part of the Manhattan Project, the Allied effort to create atomic bombs during World War II. It led to the building of larger single-purpose production reactors for the production of weapons-grade plutonium for use in the first nuclear weapons. The United States tested the first nuclear weapon in July 1945, the Trinity test, and the atomic bombings of Hiroshima and Nagasaki happened one month later.\nDespite the military nature of the first nuclear devices, there was strong optimism in the 1940s and 1950s that nuclear power could provide cheap and endless energy. Electricity was generated for the first time by a nuclear reactor on December 20, 1951, at the EBR-I experimental station near Arco, Idaho, which initially produced about 100kW. In 1953, American President Dwight Eisenhower gave his \"Atoms for Peace\" speech at the United Nations, emphasizing the need to develop \"peaceful\" uses of nuclear power quickly. This was followed by the Atomic Energy Act of 1954 which allowed rapid declassification of U.S. reactor technology and encouraged development by the private sector.\nFirst power generation.\nThe first organization to develop practical nuclear power was the U.S. Navy, with the S1W reactor for the purpose of propelling submarines and aircraft carriers. The first nuclear-powered submarine, , was put to sea in January 1954. The S1W reactor was a pressurized water reactor. This design was chosen because it was simpler, more compact, and easier to operate compared to alternative designs, thus more suitable to be used in submarines. This decision would result in the PWR being the reactor of choice also for power generation, thus having a lasting impact on the civilian electricity market in the years to come.\nOn June 27, 1954, the Obninsk Nuclear Power Plant in the USSR became the world's first nuclear power plant to generate electricity for a power grid, producing around 5 megawatts of electric power. The world's first commercial nuclear power station, Calder Hall at Windscale, England was connected to the national power grid on 27 August 1956. In common with a number of other generation I reactors, the plant had the dual purpose of producing electricity and plutonium-239, the latter for the nascent nuclear weapons program in Britain.\nExpansion and first opposition.\nThe total global installed nuclear capacity initially rose relatively quickly, rising from less than 1 gigawatt (GW) in 1960 to 100GW in the late 1970s. During the 1970s and 1980s rising economic costs (related to extended construction times largely due to regulatory changes and pressure-group litigation) and falling fossil fuel prices made nuclear power plants then under construction less attractive. In the 1980s in the U.S. and 1990s in Europe, the flat electric grid growth and electricity liberalization also made the addition of large new baseload energy generators economically unattractive.\nThe 1973 oil crisis had a significant effect on countries, such as France and Japan, which had relied more heavily on oil for electric generation to invest in nuclear power. France would construct 25 nuclear power plants over the next 15 years, and as of 2019, 71% of French electricity was generated by nuclear power, the highest percentage by any nation in the world.\nSome local opposition to nuclear power emerged in the United States in the early 1960s. In the late 1960s, some members of the scientific community began to express pointed concerns. These anti-nuclear concerns related to nuclear accidents, nuclear proliferation, nuclear terrorism and radioactive waste disposal. In the early 1970s, there were large protests about a proposed nuclear power plant in Wyhl, Germany. The project was cancelled in 1975. The anti-nuclear success at Wyhl inspired opposition to nuclear power in other parts of Europe and North America.\nBy the mid-1970s anti-nuclear activism gained a wider appeal and influence, and nuclear power began to become an issue of major public protest. In some countries, the nuclear power conflict \"reached an intensity unprecedented in the history of technology controversies\". The increased public hostility to nuclear power led to a longer license procurement process, more regulations and increased requirements for safety equipment, which made new construction much more expensive. In the United States, over 120 Light Water Reactor proposals were ultimately cancelled and the construction of new reactors ground to a halt. The 1979 accident at Three Mile Island with no fatalities, played a major part in the reduction in the number of new plant constructions in many countries.\nChernobyl and renaissance.\nDuring the 1980s one new nuclear reactor started up every 17\u00a0days on average. By the end of the decade, global installed nuclear capacity reached 300GW. Since the late 1980s, new capacity additions slowed significantly, with the installed nuclear capacity reaching 365GW in 2005.\nThe 1986 Chernobyl disaster in the USSR, involving an RBMK reactor, altered the development of nuclear power and led to a greater focus on meeting international safety and regulatory standards. It is considered the worst nuclear disaster in history both in total casualties, with 56 direct deaths, and financially, with the cleanup and the cost estimated at 18billionRbls (US$68billion in 2019, adjusted for inflation). The international organization to promote safety awareness and the professional development of operators in nuclear facilities, the World Association of Nuclear Operators (WANO), was created as a direct outcome of the 1986 Chernobyl accident. The Chernobyl disaster played a major part in the reduction in the number of new plant constructions in the following years. Influenced by these events, Italy voted against nuclear power in a 1987 referendum, becoming the first major economy to completely phase out nuclear power in 1990.\nIn the early 2000s, nuclear energy was expecting a nuclear renaissance, an increase in the construction of new reactors, due to concerns about carbon dioxide emissions. During this period, newer generation III reactors, such as the EPR began construction.\nFukushima accident.\nProspects of a nuclear renaissance were delayed by another nuclear accident. The 2011 Fukushima Daiichi nuclear accident was caused by the T\u014dhoku earthquake and tsunami, one of the largest earthquakes ever recorded. The Fukushima Daiichi Nuclear Power Plant suffered three core meltdowns due to failure of the emergency cooling system for lack of electricity supply. This resulted in the most serious nuclear accident since the Chernobyl disaster.\nThe accident prompted a re-examination of nuclear safety and nuclear energy policy in many countries. Germany approved plans to close all its reactors by 2022, and many other countries reviewed their nuclear power programs. \nFollowing the disaster, Japan shut down all of its nuclear power reactors, some of them permanently, and in 2015 began a gradual process to restart the remaining 40 reactors, following safety checks and based on revised criteria for operations and public approval.\nIn 2022, the Japanese government, under the leadership of Prime Minister Fumio Kishida, declared that 10 more nuclear power plants were to be reopened since the 2011 disaster. Kishida is also pushing for research and construction of new safer nuclear plants to safeguard Japanese consumers from the fluctuating price of the fossil fuel market and reduce Japan's greenhouse gas emissions. Kishida intends to have Japan become a significant exporter of nuclear energy and technology to developing countries around the world.\nCurrent prospects.\nBy 2015, the IAEA's outlook for nuclear energy had become more promising, recognizing the importance of low-carbon generation for mitigating climate change. As of 2015[ [update]], the global trend was for new nuclear power stations coming online to be balanced by the number of old plants being retired. In 2016, the U.S. Energy Information Administration projected for its \"base case\" that world nuclear power generation would increase from 2,344 terawatt hours (TWh) in 2012 to 4,500TWh in 2040. Most of the predicted increase was expected to be in Asia. As of 2018, there were over 150 nuclear reactors planned including 50 under construction. In January 2019, China had 45 reactors in operation, 13 under construction, and planned to build 43 more, which would make it the world's largest generator of nuclear electricity. As of 2021, 17 reactors were reported to be under construction. Its share of electricity from nuclear power was 5% in 2019. \nIn October 2021, the Japanese cabinet approved the new Plan for Electricity Generation to 2030 prepared by the Agency for Natural Resources and Energy (ANRE) and an advisory committee, following public consultation. The nuclear target for 2030 requires the restart of another ten reactors. Prime Minister Fumio Kishida in July 2022 announced that the country should consider building advanced reactors and extending operating licences beyond 60 years.\nAs of 2022, with world oil and gas prices on the rise, while Germany is restarting its coal plants to deal with loss of Russian gas that it needs to supplement its , many other countries have announced ambitious plans to reinvigorate ageing nuclear generating capacity with new investments. French President Emmanuel Macron announced his intention to build six new reactors in coming decades, placing nuclear at the heart of France's drive for carbon neutrality by 2050. Meanwhile, in the United States, the Department of Energy, in collaboration with commercial entities, TerraPower and X-energy, is planning on building two different advanced nuclear reactors by 2027, with further plans for nuclear implementation in its long term green energy and energy security goals.\nPower plants.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nNuclear power plants are thermal power stations that generate electricity by harnessing the thermal energy released from nuclear fission. A fission nuclear power plant is generally composed of: a nuclear reactor, in which the nuclear reactions generating heat take place; a cooling system, which removes the heat from inside the reactor; a steam turbine, which transforms the heat into mechanical energy; an electric generator, which transforms the mechanical energy into electrical energy.\nWhen a neutron hits the nucleus of a uranium-235 or plutonium atom, it can split the nucleus into two smaller nuclei, which is a nuclear fission reaction. The reaction releases energy and neutrons. The released neutrons can hit other uranium or plutonium nuclei, causing new fission reactions, which release more energy and more neutrons. This is called a chain reaction. In most commercial reactors, the reaction rate is contained by control rods that absorb excess neutrons. The controllability of nuclear reactors depends on the fact that a small fraction of neutrons resulting from fission are delayed. The time delay between the fission and the release of the neutrons slows changes in reaction rates and gives time for moving the control rods to adjust the reaction rate.\nFuel cycle.\nThe life cycle of nuclear fuel starts with uranium mining. The uranium ore is then converted into a compact ore concentrate form, known as yellowcake (U3O8), to facilitate transport. Fission reactors generally need uranium-235, a fissile isotope of uranium. The concentration of uranium-235 in natural uranium is low (about 0.7%). Some reactors can use this natural uranium as fuel, depending on their neutron economy. These reactors generally have graphite or heavy water moderators. For light water reactors, the most common type of reactor, this concentration is too low, and it must be increased by a process called uranium enrichment. In civilian light water reactors, uranium is typically enriched to 3.5\u20135% uranium-235. The uranium is then generally converted into uranium oxide (UO2), a ceramic, that is then compressively sintered into fuel pellets, a stack of which forms fuel rods of the proper composition and geometry for the particular reactor.\nAfter some time in the reactor, the fuel will have reduced fissile material and increased fission products, until its use becomes impractical. At this point, the spent fuel will be moved to a spent fuel pool which provides cooling for the thermal heat and shielding for ionizing radiation. After several months or years, the spent fuel is radioactively and thermally cool enough to be moved to dry storage casks or reprocessed.\nUranium resources.\nUranium is a fairly common element in the Earth's crust: it is approximately as common as tin or germanium, and is about 40 times more common than silver. Uranium is present in trace concentrations in most rocks, dirt, and ocean water, but is generally economically extracted only where it is present in relatively high concentrations. As of 2011 the world's known resources of uranium, economically recoverable at the arbitrary price ceiling of US$130/kg, were enough to last for between 70 and 100 years in current reactors.\nLight water reactors (which account for almost all operational reactors) make relatively inefficient use of nuclear fuel, mostly using only the very rare uranium-235 isotope. \nLimited uranium-235 supply may inhibit substantial expansion with the current nuclear technology. \nNuclear reprocessing can make this waste reusable, and newer reactors also achieve a more efficient use of the available resources than older ones. \nMore advanced nuclear reactor technologies, such as fast reactors, can use much more of the natural uranium, use current nuclear waste as fuel, as well as creating new fuel out of non-fissile material (see breeder reactor). \nWith a pure fast reactor fuel cycle with a burn up of all the uranium and actinides (which presently make up the most hazardous substances in nuclear waste), there is an estimated 160,000 years worth of uranium in total conventional resources and phosphate ore at the price of 60\u2013100 US$/kg. \nThese advanced fuel cycles and nuclear reprocessing are currently not widely used because the price of uranium is very low compared to the cost of nuclear plants, so it's more economically viable to mine new uranium rather than reprocess it. \nNuclear reprocessing also carries higher risk of nuclear proliferation, as it separates material that can be used to manufacture nuclear weapons. \nUnconventional uranium resources also exist. Uranium is naturally present in seawater at a concentration of about 3 micrograms per liter, with 4.4 billion tons of uranium considered present in seawater at any time. In 2014 it was suggested that it would be economically competitive to produce nuclear fuel from seawater if the process was implemented at large scale. Over geological timescales, uranium extracted on an industrial scale from seawater would be replenished by both river erosion of rocks and the natural process of uranium dissolved from the surface area of the ocean floor, both of which maintain the solubility equilibria of seawater concentration at a stable level. Some commentators have argued that this strengthens the case for nuclear power to be considered a renewable energy.\nWaste.\nThe normal operation of nuclear power plants and facilities produce radioactive waste, or nuclear waste. This type of waste is also produced during plant decommissioning. There are two broad categories of nuclear waste: low-level waste and high-level waste. The first has low radioactivity and includes contaminated items such as clothing, which poses limited threat. High-level waste is mainly the spent fuel from nuclear reactors, which is very radioactive and must be cooled and then safely disposed of or reprocessed.\nHigh-level waste.\nThe most important waste stream from nuclear power reactors is spent nuclear fuel, which is considered high-level waste (HLW). For light water reactors (LWRs), spent fuel is typically composed of 95% uranium, 4% fission products, and about 1% transuranic actinides (mostly plutonium, neptunium and americium). The fission products are responsible for the bulk of the short-term radioactivity, whereas the plutonium and other transuranics are responsible for the bulk of the long-term radioactivity.\nHigh-level waste must be stored isolated from the biosphere with sufficient shielding so as to limit radiation exposure. After being removed from the reactors, used fuel bundles are stored for six to ten years in spent fuel pools, which provide cooling and shielding against radiation. After that, the fuel is cool enough that it can be safely transferred to dry cask storage. \nThe radioactivity decreases exponentially with time, such that it will have decreased by 99.5% after 100 years. \nThe more intensely radioactive short-lived fission products (SLFPs) decay into stable elements in approximately 300 years, and after about 100,000 years, the spent fuel becomes less radioactive than natural uranium ore.\nCommonly suggested methods to isolate long-lived fission product (LLFP) waste from the biosphere include separation and transmutation, synroc treatments, or deep geological storage.\nThermal-neutron reactors, which presently constitute the majority of the world fleet, cannot burn up the reactor grade plutonium that is generated during the reactor operation. This limits the life of nuclear fuel to a few years. In some countries, such as the United States, spent fuel is classified in its entirety as a nuclear waste. In other countries, such as France, it is largely reprocessed to produce a partially recycled fuel, known as mixed oxide fuel or MOX. \nFor spent fuel that does not undergo reprocessing, the most concerning isotopes are the medium-lived transuranic elements, which are led by reactor-grade plutonium (with a half-life 24,000 years). \nSome proposed reactor designs, such as the integral fast reactor and molten salt reactors, can use as fuel the plutonium and other actinides in spent fuel from light water reactors, thanks to their fast fission spectrum. This offers a potentially more attractive alternative to deep geological disposal.\nThe thorium fuel cycle results in similar fission products, though creates a much smaller proportion of transuranic elements from neutron capture events within a reactor. Spent thorium fuel, although more difficult to handle than spent uranium fuel, may present somewhat lower proliferation risks.\nLow-level waste.\nThe nuclear industry also produces a large volume of low-level waste, with low radioactivity, in the form of contaminated items like clothing, hand tools, water purifier resins, and (upon decommissioning) the materials of which the reactor itself is built. Low-level waste can be stored on-site until radiation levels are low enough to be disposed of as ordinary waste, or it can be sent to a low-level waste disposal site.\nWaste relative to other types.\nIn countries with nuclear power, radioactive wastes account for less than 1% of total industrial toxic wastes, much of which remains hazardous for long periods. Overall, nuclear power produces far less waste material by volume than fossil-fuel based power plants. Coal-burning plants, in particular, produce large amounts of toxic and mildly radioactive ash resulting from the concentration of naturally occurring radioactive materials in coal. A 2008 report from Oak Ridge National Laboratory concluded that coal power actually results in more radioactivity being released into the environment than nuclear power operation, and that the population effective dose equivalent from radiation from coal plants is 100 times that from the operation of nuclear plants. Although coal ash is much less radioactive than spent nuclear fuel by weight, coal ash is produced in much higher quantities per unit of energy generated. It is also released directly into the environment as fly ash, whereas nuclear plants use shielding to protect the environment from radioactive materials.\nNuclear waste volume is small compared to the energy produced. For example, at Yankee Rowe Nuclear Power Station, which generated 44 billion kilowatt hours of electricity when in service, its complete spent fuel inventory is contained within sixteen casks. It is estimated that to produce a lifetime supply of energy for a person at a western standard of living (approximately 3GWh) would require on the order of the volume of a soda can of low enriched uranium, resulting in a similar volume of spent fuel generated.\nWaste disposal.\nFollowing interim storage in a spent fuel pool, the bundles of used fuel rod assemblies of a typical nuclear power station are often stored on site in dry cask storage vessels.\nDisposal of nuclear waste is often considered the most politically divisive aspect in the lifecycle of a nuclear power facility. The lack of movement of nuclear waste in the 2 billion year old natural nuclear fission reactors in Oklo, Gabon is cited as \"a source of essential information today.\" Experts suggest that centralized underground repositories which are well-managed, guarded, and monitored, would be a vast improvement. There is an \"international consensus on the advisability of storing nuclear waste in deep geological repositories\". With the advent of new technologies, other methods including horizontal drillhole disposal into geologically inactive areas have been proposed.\nThere are no commercial scale purpose built underground high-level waste repositories in operation. However, in Finland the Onkalo spent nuclear fuel repository of the Olkiluoto Nuclear Power Plant was under construction as of 2015.\nReprocessing.\nMost thermal-neutron reactors run on a once-through nuclear fuel cycle, mainly due to the low price of fresh uranium. However, many reactors are also fueled with recycled fissionable materials that remain in spent nuclear fuel. The most common fissionable material that is recycled is the reactor-grade plutonium (RGPu) that is extracted from spent fuel. It is mixed with uranium oxide and fabricated into mixed-oxide or MOX fuel. Because thermal LWRs remain the most common reactor worldwide, this type of recycling is the most common. It is considered to increase the sustainability of the nuclear fuel cycle, reduce the attractiveness of spent fuel to theft, and lower the volume of high level nuclear waste. Spent MOX fuel cannot generally be recycled for use in thermal-neutron reactors. This issue does not affect fast-neutron reactors, which are therefore preferred in order to achieve the full energy potential of the original uranium.\nThe main constituent of spent fuel from LWRs is slightly enriched uranium. This can be recycled into reprocessed uranium (RepU), which can be used in a fast reactor, used directly as fuel in CANDU reactors, or re-enriched for another cycle through an LWR. Re-enriching of reprocessed uranium is common in France and Russia. Reprocessed uranium is also safer in terms of nuclear proliferation potential.\nReprocessing has the potential to recover up to 95% of the uranium and plutonium fuel in spent nuclear fuel, as well as reduce long-term radioactivity within the remaining waste. However, reprocessing has been politically controversial because of the potential for nuclear proliferation and varied perceptions of increasing the vulnerability to nuclear terrorism. Reprocessing also leads to higher fuel cost compared to the once-through fuel cycle. While reprocessing reduces the volume of high-level waste, it does not reduce the fission products that are the primary causes of residual heat generation and radioactivity for the first few centuries outside the reactor. Thus, reprocessed waste still requires an almost identical treatment for the initial first few hundred years.\nReprocessing of civilian fuel from power reactors is currently done in France, the United Kingdom, Russia, Japan, and India. In the United States, spent nuclear fuel is currently not reprocessed. The La Hague reprocessing facility in France has operated commercially since 1976 and is responsible for half the world's reprocessing as of 2010. It produces MOX fuel from spent fuel derived from several countries. More than 32,000 tonnes of spent fuel had been reprocessed as of 2015, with the majority from France, 17% from Germany, and 9% from Japan.\nBreeding.\nBreeding is the process of converting non-fissile material into fissile material that can be used as nuclear fuel. The non-fissile material that can be used for this process is called fertile material, and constitute the vast majority of current nuclear waste. This breeding process occurs naturally in breeder reactors. As opposed to light water thermal-neutron reactors, which use uranium-235 (0.7% of all natural uranium), fast-neutron breeder reactors use uranium-238 (99.3% of all natural uranium) or thorium. A number of fuel cycles and breeder reactor combinations are considered to be sustainable or renewable sources of energy. In 2006 it was estimated that with seawater extraction, there was likely five billion years' worth of uranium resources for use in breeder reactors.\nBreeder technology has been used in several reactors, but as of 2006, the high cost of reprocessing fuel safely requires uranium prices of more than US$200/kg before becoming justified economically. Breeder reactors are however being developed for their potential to burn all of the actinides (the most active and dangerous components) in the present inventory of nuclear waste, while also producing power and creating additional quantities of fuel for more reactors via the breeding process. As of 2017, there are two breeders producing commercial power, BN-600 reactor and the BN-800 reactor, both in Russia. The Ph\u00e9nix breeder reactor in France was powered down in 2009 after 36 years of operation. Both China and India are building breeder reactors. The Indian 500 MWe Prototype Fast Breeder Reactor is in the commissioning phase, with plans to build more.\nAnother alternative to fast-neutron breeders are thermal-neutron breeder reactors that use uranium-233 bred from thorium as fission fuel in the thorium fuel cycle. Thorium is about 3.5 times more common than uranium in the Earth's crust, and has different geographic characteristics. India's three-stage nuclear power programme features the use of a thorium fuel cycle in the third stage, as it has abundant thorium reserves but little uranium.\nDecommissioning.\nNuclear decommissioning is the process of dismantling a nuclear facility to the point that it no longer requires measures for radiation protection, returning the facility and its parts to a safe enough level to be entrusted for other uses. Due to the presence of radioactive materials, nuclear decommissioning presents technical and economic challenges. The costs of decommissioning are generally spread over the lifetime of a facility and saved in a decommissioning fund.\nProduction.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nCivilian nuclear power supplied 2,602 terawatt hours (TWh) of electricity in 2023, equivalent to about 9% of global electricity generation, and was the second largest low-carbon power source after hydroelectricity. Nuclear power's contribution to global energy production was about 4% in 2023. This is a little more than wind power, which provided 3.5% of global energy in 2023. Nuclear power's share of global electricity production has fallen from 16.5% in 1997, in large part because the economics of nuclear power have become more difficult.\nAs of \u00a02024,[ [update]] there are 415 civilian fission reactors in the world, with a combined electrical capacity of 374 gigawatt (GW). There are also 66 nuclear power reactors under construction and 87 reactors planned, with a combined capacity of 72GW and 84GW, respectively. The United States has the largest fleet of nuclear reactors, generating over 800TWh per year with an average capacity factor of 92%. Most reactors under construction are generation III reactors in Asia.\nRegional differences in the use of nuclear power are large. The United States produces the most nuclear energy in the world, with nuclear power providing 19% of the electricity it consumes, while France produces the highest percentage of its electrical energy from nuclear reactors\u201465% in 2023. In the European Union, nuclear power provides 22% of the electricity as of 2022.\nNuclear power is the single largest low-carbon electricity source in the United States, and accounts for about half of the European Union's low-carbon electricity. Nuclear energy policy differs among European Union countries, and some, such as Austria, Estonia, Ireland and Italy, have no active nuclear power stations.\nIn addition, there were approximately 140 naval vessels using nuclear propulsion in operation, powered by about 180 reactors. These include military and some civilian ships, such as nuclear-powered icebreakers.\nInternational research is continuing into additional uses of process heat such as hydrogen production (in support of a hydrogen economy), for desalinating sea water, and for use in district heating systems.\nEconomics.\nThe economics of new nuclear power plants is a controversial subject. Nuclear power plants typically have high capital costs for building the plant. For this reason, comparison with other power generation methods is strongly dependent on assumptions about construction timescales and capital financing for nuclear plants. \nBecause of this strong dependency, the final cost of electricity from nuclear power is strongly dependent on the cost of capital.\nAnalysis of the economics of nuclear power must also take into account who bears the risks of future uncertainties. As of 2010, all operating nuclear power plants have been developed by state-owned or regulated electric utility monopolies. Many countries have since liberalized the electricity market where these risks, and the risk of cheaper competitors emerging before capital costs are recovered, are borne by plant suppliers and operators rather than consumers, which leads to a significantly different evaluation of the economics of new nuclear power plants.\nThe levelized cost of electricity (LCOE) from a new nuclear power plant is estimated to be 69USD/MWh, according to an analysis by the International Energy Agency and the OECD Nuclear Energy Agency. This represents the median cost estimate for an nth-of-a-kind nuclear power plant to be completed in 2025, at a discount rate of 7%. Nuclear power was found to be the least-cost option among dispatchable technologies. Variable renewables can generate cheaper electricity: the median cost of onshore wind power was estimated to be 50USD/MWh, and utility-scale solar power 56USD/MWh. However, these sources are not directly comparable to nuclear power as they are not dispatchable.\nMeasures to mitigate global warming, such as a carbon tax or carbon emissions trading, may favor the economics of nuclear power. \nAt the assumed CO2 emission cost of 30USD/ton, power from coal (88USD/MWh) and gas (71USD/MWh) is more expensive than low-carbon technologies. Electricity from long-term operation of nuclear power plants by lifetime extension was found to be the least-cost option, at 32USD/MWh.\nThe high cost of construction is one of the biggest challenges for nuclear power plants. Nuclear power cost trends show large disparity by nation, design, build rate and the establishment of familiarity in expertise. The only two nations for which data is available that saw cost decreases in the 2000s were India and South Korea.\nNew small modular reactors, such as those developed by NuScale Power, are aimed at reducing the investment costs for new construction by making the reactors smaller and modular, so that they can be built in a factory.\nCertain designs had considerable early positive economics, such as the CANDU, which realized a much higher capacity factor and reliability when compared to generation II light water reactors up to the 1990s.\nDue to the on-line refueling reactor design, PHWRs (of which the CANDU design is a part) continue to hold many world record positions for longest continual electricity generation, often over 800 days. The specific record as of 2019 is held by a PHWR at Kaiga Atomic Power Station, generating electricity continuously for 962 days.\nNuclear power plants, though capable of some grid-load following, are typically run as much as possible to keep the cost of the generated electrical energy as low as possible, supplying mostly base-load electricity. \nIn some cases, Governments were found to force \"consumers to pay upfront for potential cost overruns\" or subsidize uneconomic nuclear energy or be required to do so. Nuclear operators are liable to pay for the waste management in the European Union. In the U.S., the Congress reportedly decided 40 years ago that the nation, and not private companies, would be responsible for storing radioactive waste with taxpayers paying for the costs. The World Nuclear Waste Report 2019 found that \"even in countries in which the polluter-pays-principle is a legal requirement, it is applied incompletely\" and notes the case of the German Asse II deep geological disposal facility, where the retrieval of large amounts of waste has to be paid for by taxpayers. Similarly, other forms of energy, including fossil fuels and renewables, have a portion of their costs covered by governments.\nUse in space.\nThe most common use of nuclear power in space is the use of radioisotope thermoelectric generators, which use radioactive decay to generate power. These power generators are relatively small scale (few kW), and they are mostly used to power space missions and experiments for long periods where solar power is not available in sufficient quantity, such as in the \"Voyager 2\" space probe. A few space vehicles have been launched using nuclear reactors: 34 reactors belong to the Soviet RORSAT series and one was the American SNAP-10A.\nBoth fission and fusion appear promising for space propulsion applications, generating higher mission velocities with less reaction mass.\nSafety.\nNuclear power plants have three unique characteristics that affect their safety, as compared to other power plants. Firstly, intensely radioactive materials are present in a nuclear reactor. Their release to the environment could be hazardous. Secondly, the fission products, which make up most of the intensely radioactive substances in the reactor, continue to generate a significant amount of decay heat even after the fission chain reaction has stopped. If the heat cannot be removed from the reactor, the fuel rods may overheat and release radioactive materials. Thirdly, a criticality accident (a rapid increase of the reactor power) is possible in certain reactor designs if the chain reaction cannot be controlled. These three characteristics have to be taken into account when designing nuclear reactors.\nAll modern reactors are designed so that an uncontrolled increase of the reactor power is prevented by natural feedback mechanisms, a concept known as negative void coefficient of reactivity. If the temperature or the amount of steam in the reactor increases, the fission rate inherently decreases. The chain reaction can also be manually stopped by inserting control rods into the reactor core. Emergency core cooling systems (ECCS) can remove the decay heat from the reactor if normal cooling systems fail. If the ECCS fails, multiple physical barriers limit the release of radioactive materials to the environment even in the case of an accident. The last physical barrier is the large containment building.\nWith a death rate of 0.03 per TWh, nuclear power is the second safest energy source per unit of energy generated, after solar power, in terms of mortality when the historical track-record is considered. Energy produced by coal, petroleum, natural gas and hydropower has caused more deaths per unit of energy generated due to air pollution and energy accidents. This is found when comparing the immediate deaths from other energy sources to both the immediate and the latent, or predicted, indirect cancer deaths from nuclear energy accidents. When the direct and indirect fatalities (including fatalities resulting from the mining and air pollution) from nuclear power and fossil fuels are compared, the use of nuclear power has been calculated to have prevented about 1.84 million deaths from air pollution between 1971 and 2009, by reducing the proportion of energy that would otherwise have been generated by fossil fuels. Following the 2011 Fukushima nuclear disaster, it has been estimated that if Japan had never adopted nuclear power, accidents and pollution from coal or gas plants would have caused more lost years of life.\nSerious impacts of nuclear accidents are often not directly attributable to radiation exposure, but rather social and psychological effects. Evacuation and long-term displacement of affected populations created problems for many people, especially the elderly and hospital patients. Forced evacuation from a nuclear accident may lead to social isolation, anxiety, depression, psychosomatic medical problems, reckless behavior, and suicide. A comprehensive 2005 study on the aftermath of the Chernobyl disaster concluded that the mental health impact is the largest public health problem caused by the accident. Frank N. von Hippel, an American scientist, commented that a disproportionate fear of ionizing radiation (radiophobia) could have long-term psychological effects on the population of contaminated areas following the Fukushima disaster.\nAccidents.\nSome serious nuclear and radiation accidents have occurred. The severity of nuclear accidents is generally classified using the International Nuclear Event Scale (INES) introduced by the International Atomic Energy Agency (IAEA). The scale ranks anomalous events or accidents on a scale from 0 (a deviation from normal operation that poses no safety risk) to 7 (a major accident with widespread effects). There have been three accidents of level 5 or higher in the civilian nuclear power industry, two of which, the Chernobyl accident and the Fukushima accident, are ranked at level 7.\nThe first major nuclear accidents were the Kyshtym disaster in the Soviet Union and the Windscale fire in the United Kingdom, both in 1957. The first major accident at a nuclear reactor in the USA occurred in 1961 at the SL-1, a U.S. Army experimental nuclear power reactor at the Idaho National Laboratory. An uncontrolled chain reaction resulted in a steam explosion which killed the three crew members and caused a meltdown. Another serious accident happened in 1968, when one of the two liquid-metal-cooled reactors on board the underwent a fuel element failure, with the emission of gaseous fission products into the surrounding air, resulting in 9 crew fatalities and 83 injuries.\nThe Fukushima Daiichi nuclear accident was caused by the 2011 Tohoku earthquake and tsunami. The accident has not caused any radiation-related deaths but resulted in radioactive contamination of surrounding areas. The difficult cleanup operation is expected to cost tens of billions of dollars over 40 or more years. The Three Mile Island accident in 1979 was a smaller scale accident, rated at INES level 5. There were no direct or indirect deaths caused by the accident.\nThe impact of nuclear accidents is controversial. According to Benjamin K. Sovacool, fission energy accidents ranked first among energy sources in terms of their total economic cost, accounting for 41% of all property damage attributed to energy accidents. Another analysis found that coal, oil, liquid petroleum gas and hydroelectric accidents (primarily due to the Banqiao Dam disaster) have resulted in greater economic impacts than nuclear power accidents. The study compares latent cancer deaths attributable to nuclear power with immediate deaths from other energy sources per unit of energy generated, and does not include fossil fuel related cancer and other indirect deaths created by the use of fossil fuel consumption in its \"severe accident\" (an accident with more than five fatalities) classification. The Chernobyl accident in 1986 caused approximately 50 deaths from direct and indirect effects, and some temporary serious injuries from acute radiation syndrome. The future predicted mortality from increases in cancer rates is estimated at 4000 in the decades to come. \nNuclear power works under an insurance framework that limits or structures accident liabilities in accordance with national and international conventions. It is often argued that this potential shortfall in liability represents an external cost not included in the cost of nuclear electricity. This cost is small, amounting to about 0.1% of the levelized cost of electricity, according to a study by the Congressional Budget Office in the United States. These beyond-regular insurance costs for worst-case scenarios are not unique to nuclear power. Hydroelectric power plants are similarly not fully insured against a catastrophic event such as dam failures. For example, the failure of the Banqiao Dam caused the death of an estimated 30,000 to 200,000 people, and 11 million people lost their homes. As private insurers base dam insurance premiums on limited scenarios, major disaster insurance in this sector is likewise provided by the state.\nAttacks and sabotage.\nTerrorists could target nuclear power plants in an attempt to release radioactive contamination into the community. The United States 9/11 Commission has said that nuclear power plants were potential targets originally considered for the September 11, 2001 attacks. An attack on a reactor's spent fuel pool could also be serious, as these pools are less protected than the reactor core. The release of radioactivity could lead to thousands of near-term deaths and greater numbers of long-term fatalities.\nIn the United States, the Nuclear Regulatory Commission carries out \"Force on Force\" (FOF) exercises at all nuclear power plant sites at least once every three years. In the United States, plants are surrounded by a double row of tall fences which are electronically monitored. The plant grounds are patrolled by a sizeable force of armed guards.\nInsider sabotage is also a threat because insiders can observe and work around security measures. Successful insider crimes depended on the perpetrators' observation and knowledge of security vulnerabilities. A fire caused 5\u201310 million dollars' worth of damage to New York's Indian Point Energy Center in 1971. The arsonist was a plant maintenance worker.\nProliferation.\nNuclear proliferation is the spread of nuclear weapons, fissionable material, and weapons-related nuclear technology to states that do not already possess nuclear weapons. Many technologies and materials associated with the creation of a nuclear power program have a dual-use capability, in that they can also be used to make nuclear weapons. For this reason, nuclear power presents proliferation risks.\nNuclear power program can become a route leading to a nuclear weapon. An example of this is the concern over Iran's nuclear program. The re-purposing of civilian nuclear industries for military purposes would be a breach of the Non-Proliferation Treaty, to which 190 countries adhere. As of April 2012, there are thirty one countries that have civil nuclear power plants, of which nine have nuclear weapons. The vast majority of these nuclear weapons states have produced weapons before commercial nuclear power stations.\nA fundamental goal for global security is to minimize the nuclear proliferation risks associated with the expansion of nuclear power. The Global Nuclear Energy Partnership was an international effort to create a distribution network in which developing countries in need of energy would receive nuclear fuel at a discounted rate, in exchange for that nation agreeing to forgo their own indigenous development of a uranium enrichment program. The France-based Eurodif/\"European Gaseous Diffusion Uranium Enrichment Consortium\" is a program that successfully implemented this concept, with Spain and other countries without enrichment facilities buying a share of the fuel produced at the French-controlled enrichment facility, but without a transfer of technology. Iran was an early participant from 1974 and remains a shareholder of Eurodif via Sofidif.\nA 2009 United Nations report said that:\nthe revival of interest in nuclear power could result in the worldwide dissemination of uranium enrichment and spent fuel reprocessing technologies, which present obvious risks of proliferation as these technologies can produce fissile materials that are directly usable in nuclear weapons.\nOn the other hand, power reactors can also reduce nuclear weapon arsenals when military-grade nuclear materials are reprocessed to be used as fuel in nuclear power plants. The Megatons to Megawatts Program is considered the single most successful non-proliferation program to date. Up to 2005, the program had processed $8 billion of high enriched, weapons-grade uranium into low enriched uranium suitable as nuclear fuel for commercial fission reactors by diluting it with natural uranium. This corresponds to the elimination of 10,000 nuclear weapons. For approximately two decades, this material generated nearly 10 percent of all the electricity consumed in the United States, or about half of all U.S. nuclear electricity, with a total of around 7,000TWh of electricity produced. In total it is estimated to have cost $17 billion, a \"bargain for US ratepayers\", with Russia profiting $12 billion from the deal. Much needed profit for the Russian nuclear oversight industry, which after the collapse of the Soviet economy, had difficulties paying for the maintenance and security of the Russian Federation's highly enriched uranium and warheads. The Megatons to Megawatts Program was hailed as a major success by anti-nuclear weapon advocates as it has largely been the driving force behind the sharp reduction in the number of nuclear weapons worldwide since the cold war ended. However, without an increase in nuclear reactors and greater demand for fissile fuel, the cost of dismantling and down blending has dissuaded Russia from continuing their disarmament. As of 2013, Russia appears to not be interested in extending the program.\nEnvironmental impact.\nBeing a low-carbon energy source with relatively little land-use requirements, nuclear energy can have a positive environmental impact. It also requires a constant supply of significant amounts of water and affects the environment through mining and milling.&lt;ref name=\"10.3390/ijerph13070700\"&gt;&lt;/ref&gt; Its largest potential negative impacts on the environment may arise from its transgenerational risks for nuclear weapons proliferation that may increase risks of their use in the future, risks for problems associated with the management of the radioactive waste such as groundwater contamination, risks for accidents and for risks for various forms of attacks on waste storage sites or reprocessing- and power-plants. However, these remain mostly only risks as historically there have only been few disasters at nuclear power plants with known relatively substantial environmental impacts.\nCarbon emissions.\nNuclear power is one of the leading low carbon power generation methods of producing electricity, and in terms of total life-cycle greenhouse gas emissions per unit of energy generated, has emission values comparable to or lower than renewable energy. A 2014 analysis of the carbon footprint literature by the Intergovernmental Panel on Climate Change (IPCC) reported that the embodied total life-cycle emission intensity of nuclear power has a median value of 12g CO2eq/kWh, which is the lowest among all commercial baseload energy sources. This is contrasted with coal and natural gas at 820 and 490\u00a0g CO2 eq/kWh. As of 2021, nuclear reactors worldwide have helped avoid the emission of 72 billion tonnes of carbon dioxide since 1970, compared to coal-fired electricity generation, according to a report.\nRadiation.\nThe average dose from natural background radiation is 2.4 millisievert per year (mSv/a) globally. It varies between 1mSv/a and 13mSv/a, depending mostly on the geology of the location. According to the United Nations (UNSCEAR), regular nuclear power plant operations, including the nuclear fuel cycle, increases this amount by 0.0002mSv/a of public exposure as a global average. The average dose from operating nuclear power plants to the local populations around them is less than 0.0001mSv/a. For comparison, the average dose to those living within of a coal power plant is over three times this dose, at 0.0003mSv/a.\nChernobyl resulted in the most affected surrounding populations and male recovery personnel receiving an average initial 50 to 100mSv over a few hours to weeks, while the remaining global legacy of the worst nuclear power plant accident in average exposure is 0.002mSv/a and is continuously dropping at the decaying rate, from the initial high of 0.04mSv per person averaged over the entire populace of the Northern Hemisphere in the year of the accident in 1986.\nDebate.\nThe nuclear power debate concerns the controversy which has surrounded the deployment and use of nuclear fission reactors to generate electricity from nuclear fuel for civilian purposes.\nProponents of nuclear energy regard it as a sustainable energy source that reduces carbon emissions and increases energy security by decreasing dependence on other energy sources that are often dependent on imports. For example, proponents note that annually, nuclear-generated electricity reduces 470 million metric tons of carbon dioxide emissions that would otherwise come from fossil fuels. Additionally, the amount of comparatively low waste that nuclear energy does create is safely disposed of by the large scale nuclear energy production facilities or it is repurposed/recycled for other energy uses. \nProponents also claim that the present quantity of nuclear waste is small and can be reduced through the latest technology of newer reactors and that the operational safety record of fission-electricity in terms of deaths is so far \"unparalleled\". Kharecha and Hansen estimated that \"global nuclear power has prevented an average of 1.84 million air pollution-related deaths and 64 gigatonnes of CO2-equivalent (GtCO2-eq) greenhouse gas (GHG) emissions that would have resulted from fossil fuel burning\" and, if continued, it could prevent up to 7 million deaths and 240GtCO2-eq emissions by 2050.\nProponents also bring to attention the opportunity cost of using other forms of electricity. For example, the United States Environmental Protection Agency estimates that coal kills 30,000 people a year as a result of its environmental impact, while 60 people died in the Chernobyl disaster. \nA real world example of impact provided by proponents is the 650,000 ton increase in carbon emissions in the two months following the closure of the Vermont Yankee nuclear plant.\nOpponents believe that nuclear power poses many threats to people's health and environment such as the risk of nuclear weapons proliferation, long-term safe waste management and terrorism in the future. They also contend that nuclear power plants are complex systems where many things can and have gone wrong. \nCritics find that one of the largest drawbacks to building new nuclear fission power plants are the high costs when compared to alternatives of sustainable energy sources.&lt;ref name=\"10.1016/j.erss.2014.04.015\"&gt;&lt;/ref&gt;&lt;ref name=\"10.1016/j.enpol.2016.03.012\"&gt;&lt;/ref&gt;&lt;ref name=\"10.1177/2399654418777765\"&gt;&lt;/ref&gt; \nProponents note that focusing on the levelized cost of energy (LCOE), however, ignores the value premium associated with 24/7 dispatchable electricity and the cost of storage and backup systems necessary to integrate variable energy sources into a reliable electrical grid. \"Nuclear thus remains the dispatchable low-carbon technology with the lowest expected costs in 2025. Only large hydro reservoirs can provide a similar contribution at comparable costs but remain highly dependent on the natural endowments of individual countries.\"\nOverall, many opponents find that nuclear energy cannot meaningfully contribute to climate change mitigation. In general, they find it to be too dangerous, too expensive, to take too long for deployment, as much as to be an obstacle to achieving a transition towards sustainability and carbon-neutrality.&lt;ref name=\"10.5281/zenodo.5573718\"&gt;&lt;/ref&gt; These opponents find nuclear to be effectively a distraction in the competition for resources (i.e. human, financial, time, infrastructure and expertise) for the deployment and development of alternative, sustainable, energy system technologies\nNevertheless, there is ongoing research and debate over costs of new nuclear, especially in regions where seasonal energy storage is difficult to provide and which aim to phase out fossil fuels in favor of low carbon power faster than the global average. Some find that financial transition costs for a 100% renewables-based European energy system that has completely phased out nuclear energy could be more costly by 2050 based on current technologies (i.e. not considering potential advances in e.g. green hydrogen, transmission and flexibility capacities, ways to reduce energy needs, geothermal energy and fusion energy) when the grid only extends across Europe. Arguments of economics and safety are used by both sides of the debate.\nComparison with renewable energy.\nSlowing global warming requires a transition to a low-carbon economy, mainly by burning far less fossil fuel. This has generated considerable interest and dispute in determining the best path forward to rapidly replace fossil-based fuels in the global energy mix, with intense academic debate. Sometimes the IEA says that countries without nuclear should develop it as well as their renewable power.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nNuclear power is comparable to, and in some cases lower, than many renewable energy sources in terms of lives lost per unit of electricity delivered. \nNuclear reactors produce a much smaller volume of waste compared to renewable energy sources, although nuclear waste is much more toxic, expensive to manage and longer-lived compared to waste from renewable technologies. \nNuclear waste can be dangerous if leaked to the environment, and need to be stored safely for thousands or even hundreds of thousand of years.\nNuclear plants are also far more complex to decommission compared to renewable energy plants. A nuclear plant needs to be disassembled and removed and much of the disassembled nuclear plant needs to be stored as low-level nuclear waste for a few decades. \nNuclear power may also pose the risk of nuclear proliferation. Separated plutonium and enriched uranium could be used for nuclear weapons, which pose a substantial global risk to human civilization and the environment.\nSpeed of transition and investment needed.\nAnalysis in 2015 by professor Barry W. Brook and colleagues found that nuclear energy could displace or remove fossil fuels from the electric grid completely within 10 years. This finding was based on the historically modest and proven rate at which nuclear energy was added in France and Sweden during their building programs in the 1980s. In a similar analysis, Brook had earlier determined that 50% of all global energy, including transportation synthetic fuels etc., could be generated within approximately 30 years if the global nuclear fission build rate was identical to historical proven installation rates calculated in GW per year per unit of global GDP (GW/year/$). This is in contrast to the conceptual studies for 100% renewable energy systems, which would require an order of magnitude more costly global investment per year, which has no historical precedent. These renewable scenarios would also need far greater land devoted to onshore wind and onshore solar projects. Brook notes that the \"principal limitations on nuclear fission are not technical, economic or fuel-related, but are instead linked to complex issues of societal acceptance, fiscal and political inertia, and inadequate critical evaluation of the real-world constraints facing [the other] low-carbon alternatives.\"\nLand use.\nThe median land area used by US nuclear power stations per 1GW installed capacity is . To generate the same amount of electricity annually (taking into account capacity factors) from solar PV would require about , and from a wind farm about . Not included in this, is land required for the associated transmission lines, water supply, rail lines, mining and processing of nuclear fuel, and for waste disposal.\nResearch.\nAdvanced fission reactor designs.\nCurrent fission reactors in operation around the world are second or third generation systems, with most of the first-generation systems having been already retired. Research into advanced generation IV reactor types was officially started by the Generation IV International Forum (GIF) based on eight technology goals, including to improve economics, safety, proliferation resistance, natural resource use and the ability to consume existing nuclear waste in the production of electricity. Most of these reactors differ significantly from current operating light water reactors, and are expected to be available for commercial construction after 2030.\nHybrid fusion-fission.\nHybrid nuclear power is a proposed means of generating power by the use of a combination of nuclear fusion and fission processes. The concept dates to the 1950s and was briefly advocated by Hans Bethe during the 1970s, but largely remained unexplored until a revival of interest in 2009, due to delays in the realization of pure fusion. When a sustained nuclear fusion power plant is built, it has the potential to be capable of extracting all the fission energy that remains in spent fission fuel, reducing the volume of nuclear waste by orders of magnitude, and more importantly, eliminating all actinides present in the spent fuel, substances which cause security concerns.\nFusion.\nNuclear fusion reactions have the potential to be safer and generate less radioactive waste than fission. These reactions appear potentially viable, though technically quite difficult and have yet to be created on a scale that could be used in a functional power plant. Fusion power has been under theoretical and experimental investigation since the 1950s. Nuclear fusion research is underway but fusion energy is not likely to be commercially widespread before 2050.\nSeveral experimental nuclear fusion reactors and facilities exist. The largest and most ambitious international nuclear fusion project currently in progress is ITER, a large tokamak under construction in France. ITER is planned to pave the way for commercial fusion power by demonstrating self-sustained nuclear fusion reactions with positive energy gain. Construction of the ITER facility began in 2007, but the project has run into many delays and budget overruns. The facility is now not expected to begin operations until the year 2034. A follow on commercial nuclear fusion power station, DEMO, has been proposed. There are also suggestions for a power plant based upon a different fusion approach, that of an inertial fusion power plant.\nFusion-powered electricity generation was initially believed to be readily achievable, as fission-electric power had been. However, the extreme requirements for continuous reactions and plasma containment led to projections being extended by several decades. In 2020, more than 80 years after the first attempts, commercialization of fusion power production was thought to be unlikely before 2050.\nTo enhance and accelerate the development of fusion energy, the United States Department of Energy (DOE) granted $46 million to eight firms, including Commonwealth Fusion Systems and Tokamak Energy Inc, in 2023. This ambitious initiative aims to introduce pilot-scale fusion within a decade.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "22155", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=22155", "title": "Noughts and Crosses", "text": ""}
{"id": "22156", "revid": "14176974", "url": "https://en.wikipedia.org/wiki?curid=22156", "title": "BI Norwegian Business School", "text": "Business school in Norway\nBI Norwegian Business School (, BI was originally \"Bedrifts\u00f8konomisk Institutt\") is a Norwegian specialized university that provides education and conducts research primarily in the fields of business and economics, marketing, strategy, management, and administration. BI is organized as a self-owned foundation whose sole purpose is teaching and research. As of 2024, with over 21,000 students, BI is the largest business school and the fourth-largest university in Norway. BI's main campus is located in Nydalen, Oslo, with regional campuses in Bergen, Trondheim, and Stavanger. \u00a0\nFor several years, BI has been ranked as Norway's top business school by the Financial Times European Business School Ranking. BI also participates in several of Financial Times' sub-rankings, including Executive MBA, Executive Education, and Master's in management.\nHistory.\nBI Norwegian Business School was founded by Finn \u00d8ien on 1 June 1943, as a private evening school in \"trade and office subjects\". Together with his partner, Jens Rosef, Finn \u00d8ien was responsible for administration, teaching, and journals, while Rosef was in charge of the accounting and auditing consultancy department. The following year, Nils Skott joined as a third owner, with responsibility for the rationalization department.\n1943 \u2013 1979\nThe first course in business administration at BI was conducted in the evenings and lasted for three months. From 1946, the school established a full-time economics study program that lasted for two years. BI developed as a provider of short, independent courses in accounting, industrial bookkeeping, machine bookkeeping, and corporate statistics. \u00a0\nIn 1968, BI was reorganized from a privately owned corporation to a self-owned foundation. In 1969, the Norwegian Parliament decided to provide state funding to BI. \u00a0\nIn the 1960s and early 1970s, the entire higher education system in Norway was undergoing several changes. There was a significant increase in the number of students, and several regional colleges were established. In the 1960s and 1970s, BI established a regional network of local schools offering studies in business administration.\n1980 \u2013 2000\nIn the 1980s, there was a high demand for economic administrative education in Norway. BI experienced a significant increase in students, and its revenue grew tenfold. In 1986, over 12,000 applied to study business administration at BI. \u00a0\nDuring the 1980s, the management at BI set the goal to develop BI as a specialized university. Academicization and increased efficiency were key aspects, and in 1983, BI hired its first professors. Research activity was also strengthened during this period. \u00a0\nIn 1985, BI decided to establish a national network of local branches. Former partner schools were either being closed down or incorporated into BI's organization. That same year, BI obtained the right to award the title of Master of Science in business (Sivil\u00f8konom), which was crucial for BI's recognition as a business school. \u00a0\nIn the 1990s, the ambition was to make BI a leading business school in Europe. In 1993, BI established its doctoral program in collaboration with the University of Oslo and Copenhagen Business School. Later on, BI also established educational programs in Shanghai, China, and in 2000, it did the same in Lithuania.\n2001 \u2013 now\nIn 2005, BI's campuses in Sandvika, Schous plass, and Ekeberg were consolidated into a new campus in Nydalen, Oslo.\nAt the same time, it was decided to focus BI's studies around business and economics, marketing, strategy, management, and administration. The number of campuses decreased from twelve to three. The number of bachelor's programs was also reduced from 19 to 13, and the number of Master of Science programs from 8 to 5. \u00a0\nIn 2014, BI became the first business school in Norway to achieve the three most prestigious international accreditations, EQUIS, AACSB, and AMBA. With this, BI joined the one percent of business schools worldwide that can be referred to as a \"Triple Crown\" school. \u00a0\nIn 2022, BI appointed Finnish Karen Spens as the new president. With this, she became BI's first female and international rector.\nAccreditations.\nSchools that hold these three accreditations are referred to as \"Triple Crown\" schools.\nStudy programmes.\nBI Norwegian Business School offers education at all levels, including bachelor's degree, master's degree, doctoral degree, and postgraduate education. The education covers areas such as economics, finance, management, marketing, communication, HR, real estate, law, data, and digital business. BI also offers an MBA program in collaboration with Fudan University School of Management, China.\nStudent Association.\nBISO, BI Student Organization, is the student association for all students at BI. BISO develops student politics and works on important student issues. They represent the students in various collaborative forums with BI and organize welfare measures and events such as company presentations, social gatherings, and the Fadderullan (orientation program) at the beginning of the academic year.\nBISO has multiple subject associations, as well as various interest groups. In addition, BISO is a co-owner of StudConsult, a consulting company operated by students affiliated with BI Norwegian Business School.\nDepartments and Research Centers.\nDepartments.\nBI has organized its academic activities into nine departments:\nBI Research Centres.\nBI has established several research centers affiliated with the departments to foster knowledge development within selected sectors and topics:\nHonorary doctorates.\nBI has a tradition of appointing honorary doctorates who have contributed with inspiration, demonstrated clear leadership, and achieved impressive results in their careers. The full list of Honorary Doctorates can be found at BI's website.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n "}
{"id": "22158", "revid": "50236370", "url": "https://en.wikipedia.org/wiki?curid=22158", "title": "Nuclear proliferation", "text": "Spread of nuclear weapons\nNuclear proliferation is the spread of nuclear weapons to additional countries, particularly those not recognized as nuclear-weapon states by the Treaty on the Non-Proliferation of Nuclear Weapons, commonly known as the \"Non-Proliferation Treaty\" or \"NPT\". Nuclear proliferation occurs through the spread of fissile material, and the technology and capabilities needed to produce it and to design and manufacture nuclear weapons. In a modern context, it also includes the spread of nuclear weapons to non-state actors. Proliferation has been opposed by many nations with and without nuclear weapons, as governments fear that more countries with nuclear weapons will increase the possibility of nuclear warfare (including the so-called countervalue targeting of civilians), de-stabilize international relations, or infringe upon the principle of state sovereignty. Conversely, supporters of deterrence theory argue that controlled proliferation decreases conflict rates via nuclear peace.\nNuclear weapons were initially researched during World War II, jointly by the United States, United Kingdom and Canada, and separately by Germany, Japan, the Soviet Union, and France. The United States was the first and is the only country to have used a nuclear weapon in war, when it used two bombs against Japan in August 1945. After surrendering, Germany and Japan ceased to be involved in any nuclear weapon research. A nuclear arms race followed, with further countries developing and testing nuclear weapons. The US primarily competed with the Soviet Union, which carried out their first test in 1949. Seven other countries developed nuclear weapons during the Cold War. The UK and France, both NATO members, developed fission and fusion weapons throughout the 1950s, and 1960s, respectively. China developed both against the backdrop of the Sino-Soviet split.\nFive countries besides the five recognized Nuclear Weapon States have acquired, or are presumed to have acquired, nuclear weapons: Israel, South Africa, India, Pakistan, and North Korea. While South Africa dismantled its program and acceded, the other four states are not members of the NPT. One critique of the NPT is that the treaty is discriminatory in the sense that only those countries that tested nuclear weapons before 1968 are recognized as nuclear weapon states while all other states are treated as non-nuclear-weapon states who can only join the treaty if they forswear nuclear weapons.\nMany other states pursued a nuclear weapons program without attaining weapons. These include Yugoslavia, South Korea, Libya, Brazil, Iraq, Iran, and Syria. Some states, such as modern Iran and Japan, are suggested to maintain nuclear latency, the capacity to rapidly develop nuclear weapons on demand. Proliferation is tied to the development of civilian nuclear power, as fuel reprocessing and uranium enrichment facilities have dual use for producing both civilian and weapons-grade fissile material. It is also tied to the proliferation of nuclear weapons delivery systems, especially ballistic missiles.\nHistory of nuclear non-proliferation efforts.\nEarly efforts to prevent nuclear proliferation involved intense government secrecy, the wartime acquisition of known uranium stores (the Combined Development Trust), and at times even outright sabotage\u2014such as the bombing of a heavy-water facility in Norway thought to be used for a German nuclear program. These efforts began immediately after the discovery of nuclear fission and its military potential. None of these efforts were explicitly public, because the weapon developments themselves were kept secret until the bombing of Hiroshima.\nEarnest international efforts to promote nuclear non-proliferation began soon after World War II, when the Truman Administration proposed the Baruch Plan of 1946, named after Bernard Baruch, America's first representative to the United Nations Atomic Energy Commission (UNAEC). The Baruch Plan, which drew heavily from the Acheson\u2013Lilienthal Report of 1946, proposed the verifiable dismantlement and destruction of the U.S. nuclear arsenal (which, at that time, was the only nuclear arsenal in the world) after all governments had cooperated successfully to accomplish two things: (1) the establishment of an \"international atomic development authority,\" which would actually own and control all military-applicable nuclear materials and activities, and (2) the creation of a system of automatic sanctions, which not even the U.N. Security Council could veto, and which would proportionately punish states attempting to acquire the capability to make nuclear weapons or fissile material.\nBaruch's plea for the destruction of nuclear weapons invoked basic moral and religious intuitions. In one part of his address to the UN, Baruch said, \"Behind the black portent of the new atomic age lies a hope which, seized upon with faith, can work out our salvation. If we fail, then we have damned every man to be the slave of Fear. Let us not deceive ourselves. We must elect World Peace or World Destruction... We must answer the world's longing for peace and security.\" With this remark, Baruch helped launch the field of nuclear ethics, to which many policy experts and scholars have contributed.\nAlthough the Baruch Plan enjoyed wide international support, it failed to emerge from the UNAEC because the Soviet Union planned to veto it in the Security Council. Still, it remained official American policy until 1953, when President Eisenhower made his \"Atoms for Peace\" proposal before the U.N. General Assembly. Eisenhower's proposal led eventually to the creation of the International Atomic Energy Agency (IAEA) in 1957. Under the \"Atoms for Peace\" program thousands of scientists from around the world were educated in nuclear science and then dispatched home, where many later pursued secret weapons programs in their home country.\nEfforts to conclude an international agreement to limit the spread of nuclear weapons did not begin until the early 1960s, after four nations (the United States, the Soviet Union, the United Kingdom and France) had acquired nuclear weapons (see List of states with nuclear weapons for more information). Although these efforts stalled in the early 1960s, they renewed once again in 1964, after China detonated a nuclear weapon. In 1968, governments represented at the Eighteen Nation Disarmament Committee (ENDC) finished negotiations on the text of the NPT. In June 1968, the U.N. General Assembly endorsed the NPT with General Assembly Resolution 2373 (XXII), and in July 1968, the NPT opened for signature in Washington, D.C., London and Moscow. The NPT entered into force in March 1970.\nSince the mid-1970s, the primary focus of non-proliferation efforts has been to maintain, and even increase, international control over the fissile material and specialized technologies necessary to build such devices because these are the most difficult and expensive parts of a nuclear weapons program. The main materials whose generation and distribution are controlled are highly enriched uranium and plutonium. Other than the acquisition of these special materials, the scientific and technical means for weapons construction to develop rudimentary, but working, nuclear explosive devices are considered to be within the reach of industrialized nations.\nSince its founding by the United Nations in 1957, the International Atomic Energy Agency (IAEA) has promoted two, sometimes contradictory, missions: on the one hand, the Agency seeks to promote and spread internationally the use of civilian nuclear energy; on the other hand, it seeks to prevent, or at least detect, the diversion of civilian nuclear energy to nuclear weapons, nuclear explosive devices or purposes unknown. The IAEA now operates a safeguards system as specified under Article III of the Nuclear Non-Proliferation Treaty (NPT) of 1968, which aims to ensure that civil stocks of uranium and plutonium, as well as facilities and technologies associated with these nuclear materials, are used only for peaceful purposes and do not contribute in any way to proliferation or nuclear weapons programs. It is often argued that the proliferation of nuclear weapons to many other states has been prevented by the extension of assurances and mutual defence treaties to these states by nuclear powers, but other factors, such as national prestige, or specific historical experiences, also play a part in hastening or stopping nuclear proliferation.\nDual-use technology.\nDual-use technology refers to the possibility of military use of civilian nuclear power technology. Many technologies and materials associated with the creation of a nuclear power program have a dual-use capability, in that several stages of the nuclear fuel cycle allow diversion of nuclear materials for nuclear weapons. When this happens a nuclear power program can become a route leading to the atomic bomb or a public annex to a secret bomb program. The crisis over Iran's nuclear activities is a case in point.\nMany UN and US agencies warn that building more nuclear reactors unavoidably increases nuclear proliferation risks. A fundamental goal for American and global security is to minimize the proliferation risks associated with the expansion of nuclear power. If this development is \"poorly managed or efforts to contain risks are unsuccessful, the nuclear future will be dangerous\". For nuclear power programs to be developed and managed safely and securely, it is important that countries have domestic \u201cgood governance\u201d characteristics that will encourage proper nuclear operations and management:\nThese characteristics include low degrees of corruption (to avoid officials selling materials and technology for their own personal gain as occurred with the A.Q. Khan smuggling network in Pakistan), high degrees of political stability (defined by the World Bank as \"likelihood that the government will be destabilized or overthrown by unconstitutional or violent means, including politically-motivated violence and terrorism\"), high governmental effectiveness scores (a World Bank aggregate measure of \"the quality of the civil service and the degree of its independence from political pressures [and] the quality of policy formulation and implementation\"), and a strong degree of regulatory competence.\nInternational Cooperation.\nTreaty on the Non-Proliferation of Nuclear Weapons.\nAt present, 189 countries are States Parties to the \"Treaty on the Nonproliferation of Nuclear Weapons\", more commonly known as the Nuclear Non-Proliferation Treaty or NPT. These include the five Nuclear Weapons States (NWS) recognized by the NPT: the People's Republic of China, France, Russian Federation, the UK, and the United States.\nNotable non-signatories to the NPT are Israel, Pakistan, and India (the latter two have since tested nuclear weapons, while Israel is considered by most to be an unacknowledged nuclear weapons state). North Korea was once a signatory but withdrew in January 2003. The legality of North Korea's withdrawal is debatable but on 9 October 2006 North Korea said it tested a nuclear device, for which it was sanctioned by the UN Security Council.\nInternational Atomic Energy Agency.\nThe IAEA was established on 29 July 1957 to help nations develop nuclear energy for peaceful purposes. Allied to this role is the administration of safeguards arrangements to provide assurance to the international community that individual countries are honoring their commitments under the treaty. Though established under its own international treaty, the IAEA reports to both the United Nations General Assembly and the Security Council.\nThe IAEA regularly inspects civil nuclear facilities to verify the accuracy of documentation supplied to it. The agency checks inventories, and samples and analyzes materials. Safeguards are designed to deter a diversion of nuclear material by increasing the risk of early detection. They are complemented by controls on the export of sensitive technology from countries such as the UK and the United States through voluntary bodies such as the Nuclear Suppliers Group. The main concern of the IAEA is that uranium not be enriched beyond what is necessary for commercial civil plants, and that plutonium which is produced by nuclear reactors not be refined into a form that would be suitable for bomb production.\nScope of safeguards.\nTraditional safeguards are arrangements to account for and control the use of nuclear materials. This verification is a key element in the international system which ensures that uranium in particular is used only for peaceful purposes.\nParties to the NPT agree to accept technical safeguard measures applied by the IAEA. These require that operators of nuclear facilities maintain and declare detailed accounting records of all movements and transactions involving nuclear material. Over 550 facilities and several hundred other locations are subject to regular inspection, and their records and the nuclear material being audited. Inspections by the IAEA are complemented by other measures such as surveillance cameras and instrumentation.\nThe inspections act as an alert system providing a warning of the possible diversion of nuclear material from peaceful activities. The system relies on;\nAll NPT non-weapons states must accept these full-scope safeguards. In the five weapons states plus the non-NPT states (India, Pakistan and Israel), facility-specific safeguards apply. IAEA inspectors regularly visit these facilities to verify completeness and accuracy of records.\nThe terms of the NPT cannot be enforced by the IAEA itself, nor can nations be forced to sign the treaty. In reality, as shown in Iraq and North Korea, safeguards can be backed up by diplomatic, political and economic measures.\nWhile traditional safeguards easily verified the correctness of formal declarations by suspect states, in the 1990s attention turned to what might not have been declared. While accepting safeguards at declared facilities, Iraq had set up elaborate equipment elsewhere in an attempt to enrich uranium to weapons-grade. North Korea attempted to use research reactors (not commercial electricity-generating reactors) and a nuclear reprocessing plant to produce some weapons-grade plutonium.\nThe weakness of the NPT regime lay in the fact that no obvious diversion of material was involved. The uranium used as fuel probably came from indigenous sources, and the nuclear facilities were built by the countries themselves without being declared or placed under safeguards. Iraq, as an NPT party, was obliged to declare all facilities but did not do so. Nevertheless, the activities were detected and brought under control using international diplomacy. In Iraq, a military defeat assisted this process.\nIn North Korea, the activities concerned took place before the conclusion of its NPT safeguards agreement. With North Korea, the promised provision of commercial power reactors appeared to resolve the situation for a time, but it later withdrew from the NPT and declared it had nuclear weapons.\nAdditional Protocol.\nIn 1993 a program was initiated to strengthen and extend the classical safeguards system, and a model protocol was agreed by the IAEA Board of Governors 1997. The measures boosted the IAEA's ability to detect undeclared nuclear activities, including those with no connection to the civil fuel cycle.\nInnovations were of two kinds. Some could be implemented on the basis of IAEA's existing legal authority through safeguards agreements and inspections. Others required further legal authority to be conferred through an Additional Protocol. This must be agreed by each non-weapons state with IAEA, as a supplement to any existing comprehensive safeguards agreement. Weapons states have agreed to accept the principles of the model additional protocol.\nKey elements of the model Additional Protocol:\nAs of 3 July 2015, 146 countries have signed the Additional Protocols and 126 have brought them into force. The IAEA is also applying the measures of the Additional Protocol in Taiwan. Under the Joint Comprehensive Plan of Action, Iran has agreed to implement its protocol provisionally. Among the leading countries that have not signed the Additional Protocol are Egypt, which says it will not sign until Israel accepts comprehensive IAEA safeguards, and Brazil, which opposes making the protocol a requirement for international cooperation on enrichment and reprocessing, but has not ruled out signing.\nLimitations of safeguards.\nThe greatest risk from nuclear weapons proliferation comes from countries that have not joined the NPT and which have significant unsafeguarded nuclear activities; India, Pakistan, and Israel fall within this category. While safeguards apply to some of their activities, others remain beyond scrutiny.\nA further concern is that countries may develop various sensitive nuclear fuel cycle facilities and research reactors under full safeguards and then subsequently opt out of the NPT. Bilateral agreements, such as insisted upon by Australia and Canada for sale of uranium, address this by including fallback provisions, but many countries are outside the scope of these agreements. If a nuclear-capable country does leave the NPT, it is likely to be reported by the IAEA to the United Nations Security Council, just as if it were in breach of its safeguards agreement. Trade sanctions would then be likely.\nIAEA safeguards can help ensure that uranium supplied as nuclear fuel and other nuclear supplies do not contribute to nuclear weapons proliferation. In fact, the worldwide application of those safeguards and the substantial world trade in uranium for nuclear electricity make the proliferation of nuclear weapons much less likely.\nThe Additional Protocol, once it is widely in force, will provide credible assurance that there are no undeclared nuclear materials or activities in the states concerned. This will be a major step forward in preventing nuclear proliferation.\nOther developments.\nThe Nuclear Suppliers Group communicated its guidelines, essentially a set of export rules, to the IAEA in 1978. These were to ensure that transfers of nuclear material or equipment would not be diverted to unsafeguarded nuclear fuel cycle or nuclear explosive activities, and formal government assurances to this effect were required from recipients. The Guidelines also recognised the need for physical protection measures in the transfer of sensitive facilities, technology and weapons-usable materials, and strengthened retransfer provisions. The group began with seven members\u2014the United States, the former USSR, the United Kingdom, France, Germany, Canada and Japan\u2014but now includes 46 countries including all five nuclear weapons states.\nThe International Framework for Nuclear Energy Cooperation is an international project involving 25 partner countries, 28 observer and candidate partner countries, and the International Atomic Energy Agency, the Generation IV International Forum, and the European Commission. Its goal is to \"[..] provide competitive, commercially-based services as an alternative to a state\u2019s development of costly, proliferation-sensitive facilities, and address other issues associated with the safe and secure management of used fuel and radioactive waste.\"\nAccording to Kenneth D. Bergeron's \"Tritium on Ice: The Dangerous New Alliance of Nuclear Weapons and Nuclear Power\", tritium is not classified as a \"special nuclear material\" but rather as a by-product. It is seen as an important litmus test on the seriousness of the United States' intention to nuclear disarm. This radioactive, super-heavy, hydrogen isotope is used to boost the efficiency of fissile materials in nuclear weapons. The United States resumed tritium production in 2003 for the first time in 15 years. This could indicate that there is a potential nuclear arms stockpile replacement since the isotope naturally decays.\nIn May 1995, NPT parties reaffirmed their commitment to a Fissile Materials Cut-off Treaty to prohibit the production of any further fissile material for weapons. This aims to complement the Comprehensive Nuclear-Test-Ban Treaty of 1996 (not entered into force as of June 2020) and to codify commitments made by the United States, the UK, France and Russia to cease production of weapons material, as well as putting a similar ban on China. This treaty will also put more pressure on Israel, India and Pakistan to agree to international verification.\nOn 9 August 2005, Ayatollah Ali Khamenei issued a fatwa forbidding the production, stockpiling and use of nuclear weapons. Khamenei's official statement was made at the meeting of the International Atomic Energy Agency (IAEA) in Vienna. As of February 2006 Iran formally announced that uranium enrichment within their borders has continued. Iran claims it is for peaceful purposes but the United Kingdom, France, Germany, and the United States claim the purpose is for nuclear weapon research and construction.\nUnsanctioned Nuclear Activity or U.N.A.\nNPT Non Signatories.\nIndia, Pakistan and Israel have been \"threshold\" countries in terms of the international non-proliferation regime. They possess or are quickly capable of assembling one or more nuclear weapons. They have remained outside the 1970 NPT. They are thus largely excluded from trade in nuclear plants or materials, except for safety-related devices for a few safeguarded facilities.\nIn May 1998 India and Pakistan each exploded several nuclear devices underground. This heightened concerns regarding a nuclear arms race between them, with Pakistan involving the People's Republic of China, an acknowledged nuclear weapons state. Both countries are opposed to the NPT as it stands, and India has consistently attacked the Treaty since its inception in 1970 labeling it as a lopsided treaty in favor of the nuclear powers.\nRelations between the two countries are tense and hostile, and the risks of nuclear conflict between them have long been considered quite high. Kashmir is a prime cause of bilateral tension, its sovereignty being in dispute since 1948. There is a persistent low-level bilateral military conflict due to the alleged backing of insurgency by Pakistan in India, and the infiltration of Pakistani state-backed militants into Indian-administered Jammu and Kashmir, along with the disputed status of Kashmir.\nBoth engaged in a conventional arms race in the 1980s, including sophisticated technology and equipment capable of delivering nuclear weapons. In the 1990s the arms race quickened. In 1994 India reversed a four-year trend of reduced allocations for defence, and despite its much smaller economy, Pakistan was expected to push its own expenditures yet higher. Both have lost their patrons: India, the former USSR, and Pakistan, the United States.\nBut it is the growth and modernization of China's nuclear arsenal and its assistance with Pakistan's nuclear power programme and, reportedly, with missile technology, which exacerbate Indian concerns. In particular, as viewed by Indian strategists, Pakistan is aided by China's People's Liberation Army.\nIndia.\nNuclear power for civil use is well established in India. Its civil nuclear strategy has been directed towards complete independence in the nuclear fuel cycle, necessary because of its outspoken rejection of the NPT. Due to economic and technological isolation of India after the nuclear tests in 1974, India has largely diverted focus on developing and perfecting the fast breeder technology by intensive materials and fuel cycle research at the dedicated center established for research into fast reactor technology, Indira Gandhi Center for Atomic Research (IGCAR) at Kalpakkam, in the southern part of the country. At the moment, India has a small fast breeder reactor and is planning a much larger one (Prototype Fast Breeder Reactor). This self-sufficiency extends from uranium exploration and mining through fuel fabrication, heavy water production, reactor design and construction, to reprocessing and waste management. It is also developing technology to utilise its abundant resources of thorium as a nuclear fuel.\nIndia has 14 small nuclear power reactors in commercial operation, two larger ones under construction, and ten more planned. The 14 operating ones (2548 MWe total) comprise:\nThe two under construction and two of the planned ones are 450 MWe versions of these 200 MWe domestic products. Construction has been seriously delayed by financial and technical problems. In 2001 a final agreement was signed with Russia for the country's first large nuclear power plant, comprising two VVER-1000 reactors, under a Russian-financed US$3 billion contract. The first unit is due to be commissioned in 2007. A further two Russian units are under consideration for the site. Nuclear power supplied 3.1% of India's electricity in 2000.\nIts weapons material appears to come from a Canadian-designed 40 MW \"research\" reactor which started up in 1960, well before the NPT, and a 100 MW indigenous unit in operation since 1985. Both use local uranium, as India does not import any nuclear fuel. It is estimated that India may have built up enough weapons-grade plutonium for a hundred nuclear warheads.\nIt is widely believed that the nuclear programs of India and Pakistan used Canadian CANDU reactors to produce fissionable materials for their weapons; however, this is not accurate. Both Canada (by supplying the 40 MW research reactor) and the United States (by supplying 21 tons of heavy water) supplied India with the technology necessary to create a nuclear weapons program, dubbed CIRUS (Canada-India Reactor, United States). Canada sold India the reactor on the condition that the reactor and any by-products would be http:// . Similarly, the United States sold India heavy water for use in the reactor http:// . India, in violation of these agreements, used the Canadian-supplied reactor and American-supplied heavy water to produce plutonium for their first nuclear explosion, Smiling Buddha. The Indian government controversially justified this, however, by claiming that Smiling Buddha was a \"peaceful nuclear explosion.\"\nThe country has at least three other research reactors including the tiny one which is exploring the use of thorium as a nuclear fuel, by breeding fissile U-233. In addition, an advanced heavy-water thorium cycle is under development.\nIndia exploded a nuclear device in 1974, the so-called Smiling Buddha test, which it has consistently claimed was for peaceful purposes. Others saw it as a response to China's nuclear weapons capability. It was then universally perceived, notwithstanding official denials, to possess, or to be able to quickly assemble, nuclear weapons. In 1999 it deployed its own medium-range missile and has developed an intermediate-range missile capable of reaching targets in China's industrial heartland.\nIn 1995 the United States quietly intervened to head off a proposed nuclear test. However, in 1998 there were five more tests in Operation Shakti. These were unambiguously military, including one claimed to be of a sophisticated thermonuclear device, and their declared purpose was \"to help in the design of nuclear weapons of different yields and different delivery systems\".\nIndian security policies are driven by:\nIt perceives nuclear weapons as a cost-effective political counter to China's nuclear and conventional weaponry, and the effects of its nuclear weapons policy in provoking Pakistan is, by some accounts, considered incidental.\nIndia has had an unhappy relationship with China. After an uneasy ceasefire ended the 1962 war, relations between the two nations were frozen until 1998. Since then a degree of high-level contact has been established and a few elementary confidence-building measures put in place. China still occupies some territory which it captured during the aforementioned war, claimed by India, and India still occupies some territory claimed by China. Its nuclear weapon and missile support for Pakistan is a major bone of contention.\nAmerican President George W. Bush met with India Prime Minister Manmohan Singh to discuss India's involvement with nuclear weapons. The two countries agreed that the United States would give nuclear power assistance to India.\nPakistan.\nOver the years in Pakistan, nuclear power infrastructure has been well established. It is dedicated to the industrial and economic development of the country. Its current nuclear policy is aimed to promote the socio-economic development of its people as a \"foremost priority\"; and to fulfill energy, economic, and industrial needs from nuclear sources. As of 2012[ [update]], there were three operational mega-commercial nuclear power plants while three larger ones were under construction. The nuclear power plants supplied 787\u00a0megawatts (MW) (roughly \u22483.6%) of electricity, and the country has projected production of 8800 MW by 2030. Infrastructure established by the IAEA and the U.S. in the 1950s\u20131960s was based on peaceful research and development and the economic prosperity of the country.\nAlthough the civil-sector nuclear power was established in the 1950s, the country has an active nuclear weapons program which was started in the 1970s. The bomb program has its roots after East Pakistan gained its independence through the Bangladesh Liberation War, as the new nation of Bangladesh, after India's successful intervention led to a decisive victory over Pakistan in 1971. This large-scale but clandestine atomic bomb project was directed towards the indigenous development of reactor and military-grade plutonium. In 1974, when India surprised the world with the successful detonation of its own bomb, codename \"Smiling Buddha\", it became \"imperative for Pakistan\" to pursue weapons research. According to a leading scientist in the program, it became clear that once India detonated their bomb, \"Newton's Third Law\" came into \"operation\", from then on it was a classic case of \"action and reaction\". Earlier efforts were directed towards mastering the plutonium technology from France, but that route was slowed when the plan failed after U.S. intervention to cancel the project. Contrary to popular perception, Pakistan did not forego the \"plutonium\" route and covertly continued its indigenous research under Munir Ahmad Khan and it succeeded with that route in the early 1980s. Reacting to India's first nuclear weapon test, Prime Minister Zulfikar Ali Bhutto and the country's political and military science circles sensed this test as final and dangerous anticipation to Pakistan's \"moral and physical existence.\" With diplomat Aziz Ahmed on his side, Prime Minister Bhutto launched a serious diplomatic offense and aggressively maintained at the session of the United Nations Security Council:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Pakistan was exposed to a kind of \"nuclear threat and blackmail\" unparalleled elsewhere. ... If the world's community failed to provide political insurance to Pakistan and other countries against the nuclear blackmail, these countries would be constraint to launch atomic bomb programs of their own! ... [A]ssurances provided by the United Nations were not \"Enough!\"...\u00a0\u2014\u200a\nAfter 1974, Bhutto's government redoubled its effort, this time equally focused on uranium and plutonium. Pakistan had established science directorates in almost all of her embassies in the important countries of the world, with theoretical physicist S.A. Butt being the director. Abdul Qadeer Khan then established a network through Dubai to smuggle URENCO technology to the Engineering Research Laboratories. Earlier, he worked with the \"Physics Dynamics Research Laboratories\" (FDO), a subsidiary of the Dutch firm VMF-Stork based in Amsterdam. Later after joining, Urenco, he had access through photographs and documents to the technology. Against popular perception, the technology that Khan had brought from Urenco was based on first generation civil reactor technology, filled with many serious technical errors, though it was an authentic and vital link for the country's gas centrifuge project. After the British Government stopped the British subsidiary of the American Emerson Electric Co. from shipping components to Pakistan, he describes his frustration with a supplier from Germany as: \"That man from the German team was unethical. When he did not get the order from us, he wrote a letter to a Labour Party member and questions were asked in [British] Parliament.\" By 1978, his efforts paid off and made him into a national hero.\nIn early 1996 the next Prime Minister of Pakistan Benazir Bhutto made it clear that \"if India conducts a nuclear test, Pakistan could be forced to \"follow suit\". In 1997, her statement was echoed by Prime Minister Nawaz Sharif who maintained that \"since 1972, [P]akistan had progressed significantly, and we have left that stage (developmental) far behind. Pakistan will not be made a \"hostage\" to India by signing the CTBT, before (India).!\" In May 1998, within weeks of India's nuclear tests, Pakistan announced that it had conducted six underground tests in the Chagai Hills, five on 28 May and one on 30 May. Seismic events consistent with these claims were recorded.\nIn 2004, the revelation of Khan's efforts led to the exposure of many defunct European consortiums which had defied export restrictions in the 1970s, and of many defunct Dutch companies that exported thousands of centrifuges to Pakistan as early as 1976. Many centrifuge components were apparently manufactured by the Malaysian Scomi Precision Engineering with the assistance of South Asian and German companies, and used a UAE-based computer company as a false front.\nIt was widely believed to have had direct involvement by the Government of Pakistan. This claim could not be verified due to the refusal of that Government to allow the IAEA to interview the alleged head of the nuclear black market, who happened to be no other than Abdul Qadeer Khan. Confessing his crimes a month later on national television, Khan bailed out the Government by taking full responsibility. Independent investigation conducted by International Institute for Strategic Studies (IISS) confirmed that he had control over the import-export deals, and his acquisition activities were largely unsupervised by Pakistan governmental authorities. All of his activities went undetected for several years. He duly confessed to running the atomic proliferation ring from Pakistan to Iran and North Korea. He was immediately given presidential immunity. The exact nature of involvement at the governmental level is still unclear, but the manner in which the government acted cast doubt on the sincerity of Pakistan. However, the contents of Abdul Qadeer Khan's personal diaries present his perspective on the matters related to his activities concerning nuclear secrets. He claimed that he acted only at the order or \"instigation\" of the Pakistan government. Even when there was no official authorization, Pakistani military knew of Khan's activity according to the contents of the diaries. On one occasion in 1980, a colonel knew of Khan being in touch with Syria's Defense Minister Gen. Mustafa Tlass and Gen. Hikmat Shihabi. Six months later, Khan was warned by Zia Ul Haq to be careful over \"nuclear drawings\".\nIn May 2025, the United States Defense Intelligence Agency's 2025 Worldwide Threat Assessment highlighted Pakistan's nuclear proliferation efforts. It estimated the stockpile at approximately 170 warheads in 2024 and projected a potential increase to 200 by 2025. The report linked this growth to Pakistan's perception of India as an existential threat. It stated that Pakistan intended to counter India's conventional superiority through the development of tactical nuclear weapons. The report also noted that Pakistan had not adopted a \u201cNo First Use\u201d policy.\nNorth Korea.\nThe Democratic People's Republic of Korea (or better known as North Korea), joined the NPT in 1985 and had subsequently signed a safeguards agreement with the IAEA. However, it was believed that North Korea was diverting plutonium extracted from the fuel of its reactor at Yongbyon, for use in nuclear weapons. The subsequent confrontation with IAEA on the issue of inspections and suspected violations, resulted in North Korea threatening to withdraw from the NPT in 1993. This eventually led to negotiations with the United States resulting in the Agreed Framework of 1994, which provided for IAEA safeguards being applied to its reactors and spent fuel rods. These spent fuel rods were sealed in canisters by the United States to prevent North Korea from extracting plutonium from them. North Korea had to therefore freeze its plutonium programme.\nDuring this period, Pakistan-North Korea cooperation in missile technology transfer was being established. A high-level delegation of Pakistan military visited North Korea in August\u2013September 1992, reportedly to discuss the supply of missile technology to Pakistan. In 1993, PM Benazir Bhutto repeatedly traveled to China, and the paid state visit to North Korea. The visits are believed to be related to the subsequent acquisition technology to developed its Ghauri system by Pakistan. During the period 1992\u20131994, A.Q. Khan was reported to have visited North Korea thirteen times. The missile cooperation program with North Korea was under Dr. A. Q. Khan Research Laboratories. At this time China was under U.S. pressure not to supply the M Dongfeng series of missiles to Pakistan. It is believed by experts that possibly with Chinese connivance and facilitation, the latter was forced to approach North Korea for missile transfers. Reports indicate that North Korea was willing to supply missile sub-systems including rocket motors, inertial guidance systems, control and testing equipment for US$50 million.\nIt is not clear what North Korea got in return. Joseph S. Bermudez Jr. in \"Jane's Defence Weekly\" (27 November 2002) reports that Western analysts had begun to question what North Korea received in payment for the missiles; many suspected it was the nuclear technology. The KRL was in charge of both the uranium program and also of the missile program with North Korea. It is therefore likely during this period that cooperation in nuclear technology between Pakistan and North Korea was initiated. Western intelligence agencies began to notice the exchange of personnel, technology and components between KRL and entities of the North Korean 2nd Economic Committee (responsible for weapons production).\nA \"New York Times\" report on 18 October 2002 quoted U.S. intelligence officials having stated that Pakistan was a major supplier of critical equipment to North Korea. The report added that equipment such as gas centrifuges appeared to have been \"part of a barter deal\" in which North Korea supplied Pakistan with missiles. Separate reports indicate (\"The Washington Times\", 22 November 2002) that U.S. intelligence had as early as 1999 picked up signs that North Korea was continuing to develop nuclear arms. Other reports also indicate that North Korea had been working covertly to develop an enrichment capability for nuclear weapons for at least five years and had used technology obtained from Pakistan (\"The Washington Times\", 18 October 2002).\nIsrael.\nIsrael is also thought to possess an arsenal of potentially up to several hundred nuclear warheads based on estimates of the amount of fissile material produced by Israel. This has never been openly confirmed or denied however, due to Israel's policy of deliberate ambiguity.\nAn Israeli nuclear installation is located about ten kilometers to the south of Dimona, the Negev Nuclear Research Center. Its construction commenced in 1958, with French assistance. The official reason given by the Israeli and French governments was to build a nuclear reactor to power a \"desalination plant\", in order to \"green the Negev\". The purpose of the Dimona plant is widely assumed to be the manufacturing of nuclear weapons, and the majority of defense experts have concluded that it does in fact do that. However, the Israeli government refuses to confirm or deny this publicly, a policy it refers to as \"ambiguity\".\nNorway sold 20 tonnes of heavy water needed for the reactor to Israel in 1959 and 1960 in a secret deal. There were no \"safeguards\" required in this deal to prevent the use of heavy water for non-peaceful purposes. The British newspaper \"Daily Express\" accused Israel of working on a bomb in 1960.\nWhen the United States intelligence community discovered the purpose of the Dimona plant in the early 1960s, it demanded that Israel agree to international inspections. Israel agreed, but on a condition that the U.S., rather than IAEA, inspectors were used, and that Israel would receive advanced notice of all inspections.\nSome claim that because Israel knew the schedule of the inspectors' visits, it was able to hide the alleged purpose of the site from the inspectors by installing temporary false walls and other devices before each inspection. The inspectors eventually informed the U.S. government that their inspections were useless due to Israeli restrictions on what areas of the facility they could inspect. In 1969, the United States terminated the inspections.\nIn 1986, Mordechai Vanunu, a former technician at the Dimona plant, revealed to the media some evidence of Israel's nuclear program. Israeli Mossad agents arrested him in Italy, drugged him and transported him to Israel. An Israeli court then tried him in secret on charges of treason and espionage, and sentenced him to eighteen years imprisonment. He was freed on 21 April 2004, but was severely limited by the Israeli government. He was arrested again on 11 November 2004, though formal charges were not immediately filed.\nComments on photographs taken by Vanunu inside the Negev Nuclear Research Center have been made by prominent scientists. British nuclear weapons scientist Frank Barnaby, who questioned Vanunu over several days, estimated Israel had enough plutonium for about 150 weapons.\nAccording to Lieutenant Colonel Warner D. Farr in a report to the USAF Counterproliferation Center, while France was previously a leader in nuclear research \"Israel and France were at a similar level of expertise after WWII, and Israeli scientists could make significant contributions to the French effort.\" In 1986 Francis Perrin, French high-commissioner for atomic energy from 1951 to 1970 stated that in 1949 Israeli scientists were invited to the Saclay nuclear research facility, this cooperation leading to a joint effort including sharing of knowledge between French and Israeli scientists especially those with knowledge from the Manhattan Project.\nNuclear arms control in South Asia.\nThe public stance of India and Pakistan on non-proliferation differs markedly. Pakistan has initiated a series of regional security proposals. It has repeatedly proposed a nuclear-free zone in South Asia, and has proclaimed its willingness to engage in nuclear disarmament and to sign the Non-Proliferation Treaty if India would do so. It has endorsed a United States proposal for a regional five power conference to consider non-proliferation in South Asia.\nIndia has taken the view that solutions to regional security issues should be found at the international rather than the regional level, since its chief concern is with China. It therefore rejects Pakistan's proposals.\nInstead, the 'Gandhi Plan', put forward in 1988, proposed the revision of the Non-Proliferation Treaty, which it regards as inherently discriminatory in favor of the nuclear-weapon States, and a timetable for complete nuclear weapons disarmament. It endorsed early proposals for a Comprehensive Test Ban Treaty and for an international convention to ban the production of highly enriched uranium and plutonium for weapons purposes, known as the 'cut-off' convention.\nThe United States for some years, especially under the Clinton administration, pursued a variety of initiatives to persuade India and Pakistan to abandon their nuclear weapons programs and to accept comprehensive international safeguards on all their nuclear activities. To this end, the Clinton administration proposed a conference of the five nuclear-weapon states, Japan, Germany, India and Pakistan.\nIndia refused this and similar previous proposals, and countered with demands that other potential weapons states, such as Iran and North Korea, should be invited, and that regional limitations would only be acceptable if they were accepted equally by China. The United States would not accept the participation of Iran and North Korea and these initiatives have lapsed.\nAnother, more recent approach, centers on 'capping' the production of fissile material for weapons purposes, which would hopefully be followed by 'roll back'. To this end, India and the United States jointly sponsored a UN General Assembly resolution in 1993 calling for negotiations for a 'cut-off' convention. Should India and Pakistan join such a convention, they would have to agree to halt the production of fissile materials for weapons and to accept international verification on their relevant nuclear facilities (enrichment and reprocessing plants). It appears that India is now prepared to join negotiations regarding such a Cut-off Treaty, under the UN Conference on Disarmament.\nBilateral confidence-building measures between India and Pakistan to reduce the prospects of confrontation have been limited. In 1990 each side ratified a treaty not to attack the other's nuclear installations, and at the end of 1991 they provided one another with a list showing the location of all their nuclear plants, even though the respective lists were regarded as not being wholly accurate. Early in 1994 India proposed a bilateral agreement for a 'no first use' of nuclear weapons and an extension of the 'no attack' treaty to cover civilian and industrial targets as well as nuclear installations.\nHaving promoted the Comprehensive Test Ban Treaty since 1954, India dropped its support in 1995 and in 1996 attempted to block the Treaty. Following the 1998 tests the question has been reopened and both Pakistan and India have indicated their intention to sign the CTBT. Indian ratification may be conditional upon the five weapons states agreeing to specific reductions in nuclear arsenals. The UN Conference on Disarmament has also called upon both countries \"to accede without delay to the Non-Proliferation Treaty\", presumably as non-weapons states.\nNPT signatories.\nEgypt.\nIn 2004 and 2005, Egypt disclosed past undeclared nuclear activities and material to the IAEA. In 2007 and 2008, high-enriched and low-enriched uranium particles were found in environmental samples taken in Egypt. In 2008, the IAEA states Egypt's statements were consistent with its own findings. In May 2009, \"Reuters\" reported that the IAEA was conducting further investigation in Egypt.\nIran.\nIn 2003, the IAEA reported that Iran had been in breach of its obligations to comply with provisions of its safeguard agreement. In 2005, the IAEA Board of Governors voted in a rare non-consensus decision to find Iran in non-compliance with its NPT Safeguards Agreement and to report that non-compliance to the UN Security Council. In response, the UN Security Council passed a series of resolutions citing concerns about the program. Iran's representative to the UN argues sanctions compel Iran to abandon its rights under the Nuclear Nonproliferation Treaty to peaceful nuclear technology. Iran says its uranium enrichment program is exclusively for peaceful purposes and has enriched uranium to \"less than 5 percent,\" consistent with fuel for a nuclear power plant and significantly below the purity of WEU (around 90%) typically used in a weapons program. The director general of the International Atomic Energy Agency, Yukiya Amano, said in 2009 he had not seen any evidence in IAEA official documents that Iran was developing nuclear weapons.\nIraq.\nUp to the late 1980s it was generally assumed that any undeclared nuclear activities would have to be based on the diversion of nuclear material from safeguards. States acknowledged the possibility of nuclear activities entirely separate from those covered by safeguards, but it was assumed they would be detected by national intelligence activities. There was no particular effort by IAEA to attempt to detect them.\nIraq had been making efforts to secure a nuclear potential since the 1960s. In the late 1970s a specialised plant, Osiraq, was constructed near Baghdad. The plant was attacked during the Iran\u2013Iraq War and was destroyed by Israeli bombers in June 1981.\nNot until the 1990 NPT Review Conference did some states raise the possibility of making more use of (for example) provisions for \"special inspections\" in existing NPT Safeguards Agreements. Special inspections can be undertaken at locations other than those where safeguards routinely apply, if there is reason to believe there may be undeclared material or activities.\nAfter inspections in Iraq following the UN Gulf War cease-fire resolution showed the extent of Iraq's clandestine nuclear weapons program, it became clear that the IAEA would have to broaden the scope of its activities. Iraq was an NPT Party, and had thus agreed to place all its nuclear material under IAEA safeguards. But the inspections revealed that it had been pursuing an extensive clandestine uranium enrichment programme, as well as a nuclear weapons design programme.\nThe main thrust of Iraq's uranium enrichment program was the development of technology for electromagnetic isotope separation (EMIS) of indigenous uranium. This uses the same principles as a mass spectrometer (albeit on a much larger scale). Ions of uranium-238 and uranium-235 are separated because they describe arcs of different radii when they move through a magnetic field. This process was used in the Manhattan Project to make the highly enriched uranium used in the Hiroshima bomb, but was abandoned soon afterwards.\nThe Iraqis did the basic research work at their nuclear research establishment at Tuwaitha, near Baghdad, and were building two full-scale facilities at Tarmiya and Ash Sharqat, north of Baghdad. However, when the war broke out, only a few separators had been installed at Tarmiya, and none at Ash Sharqat.\nThe Iraqis were also very interested in centrifuge enrichment, and had been able to acquire some components including some carbon-fibre rotors, which they were at an early stage of testing. In May 1998, \"Newsweek\" reported that Abdul Qadeer Khan had sent Iraq centrifuge designs, which were apparently confiscated by the UNMOVIC officials. Iraqi officials said \"the documents were authentic but that they had not agreed to work with A. Q. Khan, fearing an ISI sting operation, due to strained relations between two countries. The Government of Pakistan and A. Q. Khan strongly denied this allegation whilst the government declared the evidence to be \"fraudulent\".\nThey were clearly in violation of their NPT and safeguards obligations, and the IAEA Board of Governors ruled to that effect. The UN Security Council then ordered the IAEA to remove, destroy or render harmless Iraq's nuclear weapons capability. This was done by mid-1998, but Iraq then ceased all cooperation with the UN, so the IAEA withdrew from this work.\nThe revelations from Iraq provided the impetus for a very far-reaching reconsideration of what safeguards are intended to achieve.\nLibya.\nLibya possesses ballistic missiles and previously pursued nuclear weapons under the leadership of Muammar Gaddafi. On 19 December 2003, Gaddafi announced that Libya would voluntarily eliminate all materials, equipment and programs that could lead to internationally proscribed weapons, including weapons of mass destruction and long-range ballistic missiles. Libya signed the Nuclear Non-Proliferation Treaty (NPT) in 1968 and ratified it in 1975, and concluded a safeguards agreement with the International Atomic Energy Agency (IAEA) in 1980. In March 2004, the IAEA Board of Governors welcomed Libya's decision to eliminate its formerly undeclared nuclear program, which it found had violated Libya's safeguards agreement, and approved Libya's Additional Protocol. The United States and the United Kingdom assisted Libya in removing equipment and material from its nuclear weapons program, with independent verification by the IAEA.\nMyanmar.\nA report in the \"Sydney Morning Herald\" and \"Searchina\", a Japanese newspaper, report that two Myanma defectors saying that the State Peace and Development Council junta was secretly building a nuclear reactor and plutonium extraction facility with North Korea's help, with the aim of acquiring its first nuclear bomb in five years. According to the report, \"The secret complex, much of it in caves tunnelled into a mountain at Naung Laing in northern Burma, runs parallel to a civilian reactor being built at another site by Russia that both the Russians and Burmese say will be put under international safeguards.\" In 2002, Myanmar had notified IAEA of its intention to pursue a civilian nuclear programme. Later, Russia announced that it would build a nuclear reactor in Myanmar. There have also been reports that two Pakistani scientists, from the AQ Khan stable, had been dispatched to Myanmar where they had settled down, to help Myanmar's project. Recently, the David Albright-led Institute for Science and International Security (ISIS) rang alarm bells about Myanmar attempting a nuclear project with North Korean help. If true, the full weight of international pressure will be brought against Myanmar, said officials familiar with developments. But equally, the information that has been peddled by the defectors is also \"preliminary\" and could be used by the west to turn the screws on Myanmar\u2014on democracy and human rights issues\u2014in the run-up to the elections in the country in 2010. During an ASEAN meeting in Thailand in July 2009, US secretary of state Hillary Clinton highlighted concerns of the North Korean link. \"We know there are also growing concerns about military cooperation between North Korea and Burma which we take very seriously,\" Clinton said. However, in 2012, after contact with the American president, Barack Obama, the Burmese leader, Thein Sein, renounced military ties with DPRK (North Korea).\nNorth Korea.\nThe Democratic People's Republic of Korea (DPRK) acceded to the NPT in 1985 as a condition for the supply of a nuclear power station by the USSR. However, it delayed concluding its NPT Safeguards Agreement with the IAEA, a process which should take only 18 months, until April 1992.\nDuring that period, it brought into operation a small gas-cooled, graphite-moderated, natural-uranium (metal) fuelled \"Experimental Power Reactor\" of about 25 MWt (5 MWe), based on the UK Magnox design. While this was a well-suited design to start a wholly indigenous nuclear reactor development, it also exhibited all the features of a small plutonium production reactor for weapons purposes. North Korea also made substantial progress in the construction of two larger reactors designed on the same principles, a prototype of about 200 MWt (50 MWe), and a full-scale version of about 800 MWt (200 MWe). They made only slow progress; construction halted on both in 1994 and has not resumed. Both reactors have degraded considerably since that time and would take significant efforts to refurbish.\nIn addition, it completed and commissioned a reprocessing plant that makes the Magnox spent nuclear fuel safe, recovering uranium and plutonium. That plutonium, if the fuel was only irradiated to a very low burn-up, would have been in a form very suitable for weapons. Although all these facilities at the Yongbyon Nuclear Scientific Research Center were to be under safeguards, there was always the risk that at some stage, the DPRK would withdraw from the NPT and use the plutonium for weapons.\nOne of the first steps in applying NPT safeguards is for the IAEA to verify the initial stocks of uranium and plutonium to ensure that all the nuclear materials in the country have been declared for safeguards purposes. While undertaking this work in 1992, IAEA inspectors found discrepancies that indicated that the reprocessing plant had been used more often than the DPRK had declared, which suggested that the DPRK could have weapons-grade plutonium which it had not declared to the IAEA. Information passed to the IAEA by a Member State (as required by the IAEA) supported that suggestion by indicating that the DPRK had two undeclared waste or other storage sites.\nIn February 1993 the IAEA called on the DPRK to allow special inspections of the two sites so that the initial stocks of nuclear material could be verified. The DPRK refused, and on 12 March announced its intention to withdraw from the NPT (three months' notice is required). In April 1993 the IAEA Board concluded that the DPRK was in non-compliance with its safeguards obligations and reported the matter to the UN Security Council. In June 1993 the DPRK announced that it had \"suspended\" its withdrawal from the NPT, but subsequently claimed a \"special status\" with respect to its safeguards obligations. This was rejected by IAEA.\nOnce the DPRK's non-compliance had been reported to the UN Security Council, the essential part of the IAEA's mission had been completed. Inspections in the DPRK continued, although inspectors were increasingly hampered in what they were permitted to do by the DPRK's claim of a \"special status\". However, some 8,000 corroding fuel rods associated with the experimental reactor have remained under close surveillance.\nFollowing bilateral negotiations between the United States and the DPRK, and the conclusion of the Agreed Framework in October 1994, the IAEA has been given additional responsibilities. The agreement requires a freeze on the operation and construction of the DPRK's plutonium production reactors and their related facilities, and the IAEA is responsible for monitoring the freeze until the facilities are eventually dismantled. The DPRK remains uncooperative with the IAEA verification work and has yet to comply with its safeguards agreement.\nWhile Iraq was defeated in a war, allowing the UN the opportunity to seek out and destroy its nuclear weapons programme as part of the cease-fire conditions, the DPRK was not defeated, nor was it vulnerable to other measures, such as trade sanctions. It can scarcely afford to import anything, and sanctions on vital commodities, such as oil, would either be ineffective or risk provoking war.\nUltimately, the DPRK was persuaded to stop what appeared to be its nuclear weapons programme in exchange, under the agreed framework, for about US$5 billion in energy-related assistance. This included two 1000 MWe light-water nuclear power reactors based on an advanced U.S. System-80 design.\nIn January 2003 the DPRK withdrew from the NPT. In response, a series of discussions among the DPRK, the United States, and China, a series of six-party talks (the parties being the DPRK, the ROK, China, Japan, the United States and Russia) were held in Beijing; the first beginning in April 2004 concerning North Korea's weapons program.\nOn 10 January 2005, North Korea declared that it was in the possession of nuclear weapons. On 19 September 2005, the fourth round of the Six-Party Talks ended with a joint statement in which North Korea agreed to end its nuclear programs and return to the NPT in exchange for diplomatic, energy and economic assistance. However, by the end of 2005 the DPRK had halted all six-party talks because the United States froze certain DPRK international financial assets such as those in a bank in Macau.\nOn 9 October 2006, North Korea announced that it has performed its first-ever nuclear weapon test. On 18 December 2006, the six-party talks finally resumed. On 13 February 2007, the parties announced \"Initial Actions\" to implement the 2005 joint statement including shutdown and disablement of North Korean nuclear facilities in exchange for energy assistance. Reacting to UN sanctions imposed after missile tests in April 2009, North Korea withdrew from the six-party talks, restarted its nuclear facilities and conducted a second nuclear test on 25 May 2009.\nOn 12 February 2013, North Korea conducted an underground nuclear explosion with an estimated yield of 6 to 7 kilotonnes. The detonation registered a magnitude 4.9 disturbance in the area around the epicenter.\nRussia.\nSecurity of nuclear weapons in Russia remains a matter of concern. According to high-ranking Russian SVR defector Tretyakov, he had a meeting with two Russian businessmen representing a state-created \"C-W\" corporation in 1991. They came up with a project of destroying large quantities of chemical wastes collected from Western countries at the island of Novaya Zemlya (a test place for Soviet nuclear weapons) using an underground nuclear blast. The project was rejected by Canadian representatives, but one of the businessmen told Tretyakov that he keeps his own nuclear bomb at his dacha outside Moscow. Tretyakov thought that man was insane, but the \"businessmen\" (Vladimir K. Dmitriev) replied: \"Do not be so naive. With economic conditions the way they are in Russia today, anyone with enough money can buy a nuclear bomb. It's no big deal really\".\nSouth Africa.\nIn 1991, South Africa acceded to the NPT, concluded a comprehensive safeguards agreement with the IAEA, and submitted a report on its nuclear material subject to safeguards. At the time, the state had a nuclear power programme producing nearly 10% of the country's electricity, whereas Iraq and North Korea only had research reactors.\nThe IAEA's initial verification task was complicated by South Africa's announcement that between 1979 and 1989 it built and then dismantled a number of nuclear weapons. South Africa asked the IAEA to verify the conclusion of its weapons programme. In 1995 the IAEA declared that it was satisfied all materials were accounted for and the weapons programme had been terminated and dismantled.\nSouth Africa has signed the NPT, and now holds the distinction of being the only known state to have indigenously produced nuclear weapons, and then verifiably dismantled them.\nSweden.\nAfter World War II, Sweden considered building nuclear weapons to deter a Soviet invasion. From 1945 to 1972 the Swedish government ran a clandestine nuclear weapons program under the guise of civilian defense research at the Swedish National Defence Research Institute. By the late 1950s, the work had reached the point where underground testing was feasible. However, at that time the Riksdag prohibited research and development of nuclear weapons, pledging that research should be done only for the purpose of defense against nuclear attack. The option to continue development was abandoned in 1966, and Sweden subsequently signed the Non-Proliferation Treaty in 1968. The program was finally concluded in 1972.\nSyria.\nOn 6 September 2007, Israel bombed an officially unidentified site in Syria which it later asserted was a nuclear reactor under construction (\"see Operation Outside the Box\"). The alleged reactor was not asserted to be operational and it was not asserted that nuclear material had been introduced into it. Syria said the site was a military site and was not involved in any nuclear activities. The IAEA requested Syria to provide further access to the site and any other locations where the debris and equipment from the building had been stored. Syria denounced what it called the Western \"fabrication and forging of facts\" in regards to the incident. IAEA Director General Mohamed ElBaradei criticized the strikes and deplored that information regarding the matter had not been shared with his agency earlier.\nTaiwan.\nDuring the Cold War, the United States deployed nuclear weapons at Tainan Air Force Base of Taiwan as part of the United States Taiwan Defense Command. Nonetheless, Taiwan began its own nuclear weapon program under the auspices of the Institute of Nuclear Energy Research (INER) at the Chungshan Institute of Science and Technology since 1967. Taiwan was able to acquire nuclear technology from abroad (including a research reactor from Canada and low-grade plutonium from the United States), which were subject to International Atomic Energy Agency (IAEA) safeguards, but which Taiwan used for its nuclear weapon program. In 1972, US president ordered to remove the nuclear weapons from Taiwan by 1974.\nThen recognized as the Republic of China, Taiwan ratified the NPT in 1970. After the IAEA found evidences of Taiwan's efforts to produce the weapons-grade plutonium, Taiwan agreed to dismantle its nuclear weapon program under U.S. pressure in September 1976. The nuclear reactor was shut down and the plutonium mostly returned to the U.S. However secret nuclear activities were exposed after the Lieyu massacre by Colonel Chang Hsien-yi, deputy director of INER, who defected to the U.S. in December 1987 and produced a cache of incriminating documents. This program was also halted under the U.S. pressure.\nBreakout capability.\nFor a state that does not possess nuclear weapons, the capability to produce one or more weapons quickly and with little warning is called a breakout capability.\nArguments for and against proliferation.\nThere has been much debate in the academic study of international security as to the advisability of proliferation. In the late 1950s and early 1960s, Gen. Pierre Marie Gallois of France, an adviser to Charles DeGaulle, argued in books like \"The Balance of Terror: Strategy for the Nuclear Age\" (1961) that mere possession of a nuclear arsenal, what the French called the \"Force de frappe\", was enough to ensure deterrence, and thus concluded that the spread of nuclear weapons could increase international stability.\nSome very prominent neo-realist scholars, such as Kenneth Waltz, emeritus Professor of Political Science at the University of California, Berkeley and Adjunct Senior Research Scholar at Columbia University, and John Mearsheimer, R. Wendell Harrison Distinguished Service Professor of Political Science at the University of Chicago, continue to argue along the lines of Gallois in a separate development. Specifically, these scholars advocate some forms of nuclear proliferation, arguing that it will decrease the likelihood of war, especially in troubled regions of the world. Aside from the majority opinion which opposes proliferation in any form, there are two schools of thought on the matter: those, like Mearsheimer, who favor selective proliferation, and those such as Waltz, who advocate a laissez-faire attitude to programs like North Korea's.\nTotal proliferation.\nIn embryo, Waltz argues that the logic of mutually assured destruction (MAD) should work in all security environments, regardless of historical tensions or recent hostility. He sees the Cold War as the ultimate proof of MAD logic\u2014the only occasion when enmity between two Great Powers did not result in military conflict. This was, he argues, because nuclear weapons promote caution in decision-makers. Neither Washington nor Moscow would risk a nuclear apocalypse to advance territorial or power goals, hence a peaceful stalemate ensued (Waltz and Sagan (2003), p.\u00a024). Waltz believes there to be no reason why this effect would not occur in all circumstances.\nTodd Sechser and Matthew Fuhrmann find that nuclear weapons do not necessarily lead states to be more successful in coercive diplomacy. They argue that nuclear weapons are useful for defense, but are not effective offensive tools. As a consequence, they write that nuclear proliferation may \"be less harmful for international security than many believe\" while cautioning that nuclear proliferation may still be harmful due to miscalculation, terrorism and sabotage.\nSelective proliferation.\nJohn Mearsheimer would not support Waltz's optimism in the majority of potential instances; however, he has argued for nuclear proliferation as policy in certain places, such as post\u2013Cold War Europe. In two famous articles, Mearsheimer opined that Europe was bound to return to its pre\u2013Cold War environment of regular conflagration and suspicion at some point in the future. He advocated arming both Germany and Ukraine with nuclear weaponry in order to achieve a balance of power between these states in the east and France/UK in the west and predicted that otherwise war would eventually break out on the European continent Russia did invade Ukraine in 2022.\nAnother separate argument against Waltz's open proliferation and in favor of Mearsheimer's selective distribution is the possibility of nuclear terrorism. Some countries included in the aforementioned laissez-faire distribution could predispose the transfer of nuclear materials or a bomb falling into the hands of groups not affiliated with any governments. Such countries would not have the political will or ability to safeguard attempts at devices being transferred to a third party. Not being deterred by self-annihilation, terrorism groups could push forth their own nuclear agendas or be used as shadow fronts to carry out the attack plans by mentioned unstable governments.\nArguments against both positions.\nThere are numerous arguments presented against both selective and total proliferation, generally targeting the very neorealist assumptions (such as the primacy of military security in state agendas, the weakness of international institutions, and the long-run unimportance of economic integration and globalization to state strategy) its proponents tend to make. With respect to Mearsheimer's specific example of Europe, many economists and neoliberals argue that the economic integration of Europe through the development of the European Union has made war in most of the European continent so disastrous economically so as to serve as an effective deterrent. Constructivists take this one step further, frequently arguing that the development of EU political institutions has led or will lead to the development of a nascent European identity, which most states on the European continent wish to partake in to some degree or another, and which makes all states within or aspiring to be within the EU regard war between them as unthinkable.\nAs for Waltz, the general opinion is that most states are not in a position to safely guard against nuclear use, that he underestimates the long-standing antipathy in many regions, and that weak states will be unable to prevent\u2014or will actively provide for\u2014the disastrous possibility of nuclear terrorism. Waltz has dealt with all of these objections at some point in his work, though some scholars feel he has not adequately responded (e.g.: Betts, 2000).\nThe Learning Channel documentary Doomsday: \"On The Brink\" illustrated 40 years of U.S. and Soviet nuclear weapons accidents. Even the 1995 Norwegian rocket incident demonstrated a potential scenario in which Russian democratization and military downsizing at the end of the Cold War did not eliminate the danger of accidental nuclear war through command and control errors. After asking: might a future Russian ruler or renegade Russian general be tempted to use nuclear weapons to make foreign policy? The documentary writers revealed a greater danger of Russian security over its nuclear stocks, but especially the ultimate danger of human nature to want the ultimate weapon of mass destruction to exercise political and military power. According to the documentary, the Soviets, Russians, and Americans came very close to global catastrophe. History and military experts agree that proliferation can be slowed, but never stopped (technology cannot be uninvented).\nProliferation begets proliferation.\n'Proliferation begets proliferation' is a concept described by professor of political science Scott Sagan in his article, \"Why Do States Build Nuclear Weapons?\". This concept can be described as a strategic chain reaction. If one state produces a nuclear weapon it creates almost a domino effect within the region. States in the region will seek to acquire nuclear weapons to balance or eliminate the security threat. Sagan describes this reaction in his article where he states, \"Every time one state develops nuclear weapons to balance against its main rival, it also creates a nuclear threat to another region, which then has to initiate its own nuclear weapons program to maintain its national security\". Going back through history we can see how this has taken place. When the United States demonstrated that it had nuclear power capabilities after the bombing of Hiroshima and Nagasaki, the Russians started to develop their program in preparation for the Cold War. With the Russian military buildup, France and the United Kingdom perceived this as a security threat and therefore they pursued nuclear weapons (Sagan, p.\u00a071). Even though proliferation causes proliferation, this does not guarantee that other states will successfully develop nuclear weapons because the economic stability of a state plays an important role in whether the state will successfully be able to acquire nuclear weapons. The article written by Dong-Jong Joo and Erik Gartzke discusses how the economy of a country determines whether they will successfully acquire nuclear weapons.\nIran.\nFormer Iranian President Mahmoud Ahmadinejad has been a frequent critic of the concept of \"nuclear apartheid\" as it has been put into practice by several countries, particularly the United States. In an interview with CNN's Christiane Amanpour, Ahmadinejad said that Iran was \"against 'nuclear apartheid,' which means some have the right to possess it, use the fuel, and then sell it to another country for 10 times its value. We're against that. We say clean energy is the right of all countries. But also it is the duty and the responsibility of all countries, including ours, to set up frameworks to stop the proliferation of it.\" Hours after that interview, he spoke passionately in favor of Iran's right to develop nuclear technology, claiming the nation should have the same liberties.\nIran is a signatory of the Nuclear Non-Proliferation Treaty and claims that any work done in regards to nuclear technology is related only to civilian uses, which is acceptable under the treaty. In 2005, the International Atomic Energy Agency found that Iran violated its safeguards obligations under the treaty by performing uranium-enrichment in secret, after which the United Nations Security Council ordered Iran to suspend all uranium-enrichment until July 2015.\nIndia.\nIndia has also been discussed in the context of \"nuclear apartheid\". India has consistently attempted to pass measures that would call for full international disarmament, however, they have not succeeded due to protests from those states that already have nuclear weapons. In light of this, India viewed nuclear weapons as a necessary right for all nations as long as certain states were still in possession of nuclear weapons. India stated that nuclear issues were directly related to national security.\nYears before India's first underground nuclear test in 1998, the Comprehensive Nuclear-Test-Ban Treaty was passed. Some have argued that coercive language was used in an attempt to persuade India to sign the treaty, which was pushed for heavily by neighboring China. India viewed the treaty as a means for countries that already had nuclear weapons, primarily the five nations of the United Nations Security Council, to keep their weapons while ensuring that no other nations could develop them.\nSecurity guarantees.\nIn their article, \"The Correlates of Nuclear Proliferation,\" Sonali Singh and Christopher R. Way argue that states protected by a security guarantee from a great power, particularly if backed by the \"nuclear umbrella\" of extended deterrence, have less of an incentive to acquire their own nuclear weapons. States that lack such guarantees are more likely to feel their security threatened and so have greater incentives to bolster or assemble nuclear arsenals. As a result, it is then argued that bipolarity may prevent proliferation whereas multipolarity may actually influence proliferation.\nArtificial intelligence.\nConcerns have been raised that widespread use of large language models (LLMs) since 2023 could assist in the technical understanding of nuclear weapons for terrorism or espionage purposes. The company Anthropic, which maintains the public LLM Claude, has since 2024 collaborated with the National Nuclear Security Administration of the US Department of Energy, to develop nuclear technology-related filters, intended to be shared with the Frontier Model Forum, which includes AI giants Amazon, Google, OpenAI, Meta, and Microsoft. The filters can distinguish specifically nuclear weapons-related inquiries, from an opposing example of a scientist's inquiry on civilian nuclear power. The NNSA carried out a year of red-teaming tests, leading to a filter with a 94.8% true positive rate for \"harmful conversations\", a 5.2% false negative rate, allowing \"harmful conversations\" as benign, and a 0% false positive rate. LLMs, being purely trained on large data sets of human-written text, may suffer from limitations on the accuracy of physics-related generated answers, while in March 2025 it was reported that Nvidia was developing a \"world model\", distinct from LLMs and trained on physical data.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22159", "revid": "1960810", "url": "https://en.wikipedia.org/wiki?curid=22159", "title": "NPT", "text": "NPT may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "22161", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=22161", "title": "Nuclear energy", "text": "Nuclear energy may refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "22164", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=22164", "title": "Netlist", "text": "Representation of electronic circuit components\nIn electronic design, a netlist is a description of the connectivity of an electronic circuit. In its simplest form, a netlist consists of a list of the electronic components in a circuit and a list of the nodes they are connected to. A network (net) is a collection of two or more interconnected components.\nThe structure, complexity and representation of netlists can vary considerably, but the fundamental purpose of every netlist is to convey connectivity information. Netlists usually provide nothing more than instances, nodes, and perhaps some attributes of the components involved. If they express much more than this, they are usually considered to be a hardware description language such as Verilog or VHDL, or one of several languages specifically designed for input to simulators or hardware compilers (such as SPICE analog simulation netlists).\nTypes of netlists.\nNetlists can be:\nContents and structure of a netlist.\nMost netlists either contain or refer to descriptions of the parts or devices used. Each time a part is used in a netlist, this is called an \"instance\".\nThese descriptions will usually list the connections that are made to that kind of device, and some basic properties of that device. These connection points are called \"terminals\" or \"pins\", among several other names.\nAn \"instance\" could be anything from a MOSFET transistor or a bipolar junction transistor, to a resistor, a capacitor, or an integrated circuit chip.\nInstances have \"terminals\". In the case of a vacuum cleaner, these terminals would be the three metal prongs in the plug. Each terminal has a name, and in continuing the vacuum cleaner example, they might be \"Neutral\", \"Live\" and \"Ground\". Usually, each instance will have a unique name, so that if you have two instances of vacuum cleaners, one might be \"vac1\" and the other \"vac2\". Besides their names, they might otherwise be identical.\nNetworks (nets) are the \"wires\" that connect things together in the circuit. There may or may not be any special attributes associated with the nets in a design, depending on the particular language the netlist is written in, and that language's features.\nInstance based netlists usually provide a list of the instances used in a design.\nAlong with each instance, either an ordered list of net names is provided, or a list of pairs provided, of an instance port name, along with the net name to which that port is connected. In this kind of description, the list of nets can be gathered from the connection lists, and there is no place to associate particular attributes with the nets themselves. SPICE is an example of instance-based netlists.\nNet-based netlists usually describe all the instances and their attributes, then describe each net, and say which port they are connected on each instance. This allows for attributes to be associated with nets.\nEDIF is probably the most famous of the net-based netlists.\nHierarchy.\nIn large designs, it is a common practice to split the design into pieces, each piece becoming a \"definition\" which can be used as instances in the design. In the vacuum cleaner analogy, one might have a vacuum cleaner definition with its ports, but now this definition would also include a full description of the machine's internal components and how they connect (motors, switches, etc.), like a wiring diagram does.\nA definition which includes no instances is called a \"primitive\" (or a \"leaf\", or other names); whereas a definition which includes instances is \"hierarchical\".\nA \"folded\" hierarchy allows a single definition to be represented several times by instances. An \"unfolded\" hierarchy does not allow a definition to be used more than once in the hierarchy.\nFolded hierarchies can be extremely compact. A small netlist of just a few instances can describe designs with a very large number of instances. For example, suppose definition A is a simple primitive, like a memory cell. Then suppose definition B contains 32 instances of A; C contains 32 instances of B; D contains 32 instances of C; and E contains 32 instances of D. The design now contains 5 definitions (A through E) and 128 instances. Yet, E describes a circuit that contains over a million memory cells.\nUnfolding.\nIn a \"flat\" design, only primitives are instanced. Hierarchical designs can be recursively \"exploded\" (\"flattened\") by creating a new copy (with a new name) of each definition each time it is used. If the design is highly folded, expanding it like this will result in a much larger netlist database, but preserves the hierarchy dependencies. Given a hierarchical netlist, the list of instance names in a path from the root definition to a primitive instance specifies the single unique path to that primitive. The paths to every primitive, taken together, comprise a large but flat netlist that is exactly equivalent to the compact hierarchical version.\nBackannotation.\nBackannotation is data that could be added to a hierarchical netlist. Usually they are kept separate from the netlist, because several such alternate sets of data could be applied to a single netlist. These data may have been extracted from a physical design, and might provide extra information for more accurate simulations. Usually the data are composed of a hierarchical path and a piece of data for that primitive or finding the values of RC delay due to interconnection.\nInheritance.\nAnother concept often used in netlists is that of inheritance. Suppose a definition of a capacitor has an associated attribute called \"Capacitance\", corresponding to the physical property of the same name, with a default value of \"100 pF\" (100 picofarads). Each instance of this capacitor might also have such an attribute, only with a different value of capacitance. And other instances might not associate any capacitance at all. In the case where no capacitance is specified for an instance, the instance will \"inherit\" the 100 pF value from its definition. A value specified will \"override\" the value on the definition. If a great number of attributes end up being the same as on the definition, a great amount of information can be \"inherited\", and not have to be redundantly specified in the netlist, saving space, and making the design easier to read by both machines and people.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22165", "revid": "48736052", "url": "https://en.wikipedia.org/wiki?curid=22165", "title": "Nuclear disarmament", "text": "Act of eliminating nuclear weapons\nNuclear disarmament is the act of reducing or eliminating nuclear weapons. Its end state can also be a nuclear-weapons-free world, in which nuclear weapons are completely eliminated. The term denuclearization is also used to describe the process leading to complete nuclear disarmament.\nDisarmament and non-proliferation treaties have been agreed upon because of the extreme danger intrinsic to nuclear war and the possession of nuclear weapons.\nProponents of nuclear disarmament say that it would lessen the probability of nuclear war occurring, especially considering accidents or retaliatory strikes from false alarms. Critics of nuclear disarmament say that it would undermine deterrence and make conventional wars more common.\nOrganizations.\nNuclear disarmament groups include the Campaign for Nuclear Disarmament, Peace Action, Pugwash Conferences on Science and World Affairs, Greenpeace, Soka Gakkai International, International Physicians for the Prevention of Nuclear War, Mayors for Peace, Global Zero, the International Campaign to Abolish Nuclear Weapons, and the Nuclear Age Peace Foundation. There have been many large anti-nuclear demonstrations and protests. On June 12, 1982, one million people demonstrated in New York City's Central Park against nuclear weapons and for an end to the Cold War arms race. It was the largest anti-nuclear protest and the largest political demonstration in American history.\nIn recent years, some U.S. elder statesmen have also advocated nuclear disarmament. Sam Nunn, William Perry, Henry Kissinger, and George Shultz have called upon governments to embrace the vision of a world free of nuclear weapons, and in various op-ed columns have proposed an ambitious program of urgent steps to that end. The four have created the Nuclear Security Project to advance this agenda. Organisations such as Global Zero, an international non-partisan group of 300 world leaders dedicated to eliminating all nuclear weapons, have also been established.\nHistory.\nIn 1945 in the New Mexico desert, American scientists conducted \"Trinity\", the first nuclear weapons test, marking the beginning of the atomic age. Even before the Trinity test, national leaders debated the impact of nuclear weapons on domestic and foreign policy. Also involved in the debate about nuclear weapons policy was the scientific community, through professional associations such as the Federation of Atomic Scientists and the Pugwash Conference on Science and World Affairs.\nOn August 6, 1945, towards the end of World War II, the \"Little Boy\" device was detonated over the Japanese city of Hiroshima. Exploding with a yield equivalent to 12,500\u00a0tonnes of TNT, the blast and thermal wave of the bomb destroyed nearly 50,000 buildings (including the headquarters of the 2nd General Army and Fifth Division) and killed 70,000\u201380,000 people outright, with total deaths being around 90,000\u2013146,000. Detonation of the \"Fat Man\" device exploded over the Japanese city of Nagasaki three days later on August 9, 1945, destroying 60% of the city and killing 35,000\u201340,000 people outright, though up to 40,000 additional deaths may have occurred over some time after that. Subsequently, the world's nuclear weapons stockpiles grew.\nIn 1946 the Truman administration commissioned the Acheson-Lilienthal Report, which proposed the international control of the nuclear fuel cycle, revealing atomic energy technology to the USSR, and the decommissioning of all existing nuclear weapons through the new United Nations (UN) system, via the United Nations Atomic Energy Commission (UNAEC). With key modifications, the report became US policy in the form of the Baruch Plan, which was presented to the UNAEC during its first meeting in June 1946. As Cold War tensions emerged, it became clear that Stalin wanted to develop his own atomic bomb and that the United States insisted on an enforcement regime that would have overridden the UN Security Council veto. This soon led to deadlock in the UNAEC.\nOperation Crossroads was a series of nuclear weapon tests conducted by the United States at Bikini Atoll in the Pacific Ocean in the summer of 1946. Its purpose was to test the effect of nuclear weapons on naval ships. Pressure to cancel Operation Crossroads came from scientists and diplomats. Manhattan Project scientists argued that further nuclear testing was unnecessary and environmentally dangerous. A Los Alamos study warned \"the water near a recent surface explosion will be a 'witch's brew' of radioactivity\". To prepare the atoll for the nuclear tests, Bikini's native residents were evicted from their homes and resettled on smaller, uninhabited islands where they were unable to sustain themselves.\nRadioactive fallout from nuclear weapons testing was first drawn to public attention in 1954 when an American hydrogen bomb test in the Pacific contaminated the crew of the Japanese fishing boat \"Lucky Dragon\". One of the fishermen died in Japan seven months later. The incident caused widespread concern around the world and \"provided a decisive impetus for the emergence of the anti-nuclear weapons movement in many countries\". The anti-nuclear weapons movement grew rapidly because for many people the atomic bomb \"encapsulated the very worst direction in which society was moving\".\nNuclear disarmament movement.\nPeace movements emerged in Japan and in 1954 they converged to form a unified \"Japanese Council Against Atomic and Hydrogen Bombs\". Japanese opposition to the Pacific nuclear weapons tests was widespread, and \"an estimated 35 million signatures were collected on petitions calling for bans on nuclear weapons\". In the United Kingdom, the first Aldermaston March organised by the Direct Action Committee and supported by the Campaign for Nuclear Disarmament took place on Easter 1958, when several thousand people marched for four days from Trafalgar Square, London, to the Atomic Weapons Research Establishment close to Aldermaston in Berkshire, England, to demonstrate their opposition to nuclear weapons. CND organised Aldermaston marches into the late 1960s when tens of thousands of people took part in the four-day events.\nOn November 1, 1961, at the height of the Cold War, about 50,000 women brought together by Women Strike for Peace marched in 60 cities in the United States to demonstrate against nuclear weapons. It was the largest national women's peace protest of the 20th century.\nIn 1958, Linus Pauling and his wife presented the United Nations with the petition signed by more than 11,000 scientists calling for an end to nuclear-weapon testing. The \"Baby Tooth Survey\", headed by Louise Reiss, demonstrated conclusively in 1961 that above-ground nuclear testing posed significant public health risks in the form of radioactive fallout spread primarily via milk from cows that had ingested contaminated grass. Public pressure and the research results subsequently led to a moratorium on above-ground nuclear weapons testing, followed by the Partial Test Ban Treaty, signed in 1963 by John F. Kennedy and Nikita Khrushchev. On the day that the treaty went into force, the Nobel Prize Committee awarded Pauling the Nobel Peace Prize, describing him as \"Linus Carl Pauling, who ever since 1946 has campaigned ceaselessly, not only against nuclear weapons tests, not only against the spread of these armaments, not only against their very use, but against all warfare as a means of solving international conflicts.\" Pauling started the International League of Humanists in 1974. He was president of the scientific advisory board of the World Union for Protection of Life and also one of the signatories of the Dubrovnik-Philadelphia Statement.\nIn the 1980s, a movement for nuclear disarmament again gained strength in the light of the weapons build-up and statements of US President Ronald Reagan. Reagan had \"a world free of nuclear weapons\" as his personal mission, and was largely scorned for this in Europe. Reagan was able to start discussions on nuclear disarmament with Soviet Union. He changed the name \"SALT\" (Strategic Arms Limitation Talks) to \"START\" (Strategic Arms Reduction Talks).\nOn June 3, 1981, William Thomas launched the White House Peace Vigil in Washington, D.C. He was later joined on the vigil by anti-nuclear activists Concepcion Picciotto and Ellen Benjamin.\nOn June 12, 1982, one million people demonstrated in New York City's Central Park against nuclear weapons and for an end to the cold war arms race. It was the largest anti-nuclear protest and the largest political demonstration in American history. International Day of Nuclear Disarmament protests were held on June 20, 1983, at 50 sites across the United States. Large demonstrations and the disruption of US naval visits led the New Zealand government to ban nuclear-armed and powered ships from entering the country's territorial waters in 1984. Hundreds of thousands of people took part in Palm Sunday and other demonstrations for peace and nuclear disarmament in Australia during the mid-1980s. In 1986, hundreds of people walked from Los Angeles to Washington, D.C. in the Great Peace March for Global Nuclear Disarmament. There were many Nevada Desert Experience protests and peace camps at the Nevada Test Site during the 1980s and 1990s.\nOn May 1, 2005, 40,000 anti-nuclear/anti-war protesters marched past the United Nations in New York, 60 years after the atomic bombings of Hiroshima and Nagasaki. In 2008, 2009, and 2010, there have been protests about, and campaigns against, several new nuclear reactor proposals in the United States.\nThere is an annual protest against U.S. nuclear weapons research at Lawrence Livermore National Laboratory in California and in the 2007 protest, 64 people were arrested. There have been a series of protests at the Nevada Test Site and in the April 2007 Nevada Desert Experience protest, 39 people were cited by police. There have been anti-nuclear protests at Naval Base Kitsap for many years, and several in 2008.\nIn 2017, the International Campaign to Abolish Nuclear Weapons was awarded the Nobel Peace Prize \"for its work to draw attention to the catastrophic humanitarian consequences of any use of nuclear weapons and for its ground-breaking efforts to achieve a treaty-based prohibition of such weapons\".\nWorld Peace Council.\nOne of the earliest peace organisations to emerge after the Second World War was the World Peace Council, which was directed by the Communist Party of the Soviet Union through the Soviet Peace Committee. Its origins lay in the Communist Information Bureau's (Cominform) doctrine, put forward 1947, that the world was divided between peace-loving progressive forces led by the Soviet Union and warmongering capitalist countries led by the United States. In 1949, Cominform directed that peace \"should now become the pivot of the entire activity of the Communist Parties\", and most western Communist parties followed this policy. Lawrence Wittner, a historian of the post-war peace movement, argues that the Soviet Union devoted great efforts to the promotion of the WPC in the early post-war years because it feared an American attack and American superiority of arms at a time when the USA possessed the atom bomb but the Soviet Union had not yet developed it.\nIn 1950, the WPC launched its Stockholm Appeal calling for the absolute prohibition of nuclear weapons. The campaign won support, collecting, it is said, 560 million signatures in Europe, most from socialist countries, including 10 million in France (including that of the young Jacques Chirac), and 155 million signatures in the Soviet Union \u2013 the entire adult population. Several non-aligned peace groups who had distanced themselves from the WPC advised their supporters not to sign the Appeal.\nThe WPC had uneasy relations with the non-aligned peace movement and has been described as being caught in contradictions as \"it sought to become a broad world movement while being instrumentalized increasingly to serve foreign policy in the Soviet Union and nominally socialist countries.\" From the 1950s until the late 1980s it tried to use non-aligned peace organizations to spread the Soviet point of view. At first there was limited co-operation between such groups and the WPC, but western delegates who tried to criticize the Soviet Union or the WPC's silence about Russian armaments were often shouted down at WPC conferences and by the early 1960s they had dissociated themselves from the WPC.\nArms reduction treaties.\nAfter the 1986 Reykjav\u00edk Summit between U.S. President Ronald Reagan and the new Soviet General Secretary Mikhail Gorbachev, the United States and the Soviet Union concluded two important nuclear arms reduction treaties: the INF Treaty (1987) and START I (1991). After the end of the Cold War, the United States and the Russian Federation concluded the Strategic Offensive Reductions Treaty (2003) and the New START Treaty (2010). The US withdrew from the INF Treaty in 2019 under president Donald Trump, and launched the United States\u2013Russia Strategic Stability Dialogue (SSD) in 2021 under president Joe Biden.\nWhen the extreme danger intrinsic to nuclear war and the possession of nuclear weapons became apparent to all sides during the Cold War, a series of disarmament and nonproliferation treaties were agreed upon between the United States, the Soviet Union, and several other states throughout the world. Many of these treaties involved years of negotiations, and seemed to result in important steps in arms reductions and reducing the risk of nuclear war.\nKey treaties.\nOnly one country (South Africa) has been known to ever dismantle an indigenously developed nuclear arsenal completely. The apartheid government of South Africa produced half a dozen crude fission weapons during the 1980s, but they were dismantled in the early 1990s.\nUnited Nations.\nIn its landmark resolution 1653 of 1961, \"Declaration on the prohibition of the use of nuclear and thermo-nuclear weapons,\" the UN General Assembly stated that use of nuclear weaponry \"would exceed even the scope of war and cause indiscriminate suffering and destruction to mankind and civilization and, as such, is contrary to the rules of international law and to the laws of humanity\".\nThe UN Office for Disarmament Affairs (UNODA) is a department of the United Nations Secretariat established in January 1998 as part of the United Nations Secretary-General Kofi Annan's plan to reform the UN as presented in his report to the General Assembly in July 1997.\nIts goal is to promote nuclear disarmament and non-proliferation and the strengthening of the disarmament regimes in respect to other weapons of mass destruction, chemical and biological weapons. It also promotes disarmament efforts in the area of conventional weapons, especially land mines and small arms, which are often the weapons of choice in contemporary conflicts.\nFollowing the retirement of Sergio Duarte in February 2012, Angela Kane was appointed as the new High Representative for Disarmament Affairs.\nOn July 7, 2017, a UN conference adopted the Treaty on the Prohibition of Nuclear Weapons with the backing of 122 states. It opened for signature on September 20, 2017.\nThe 2022 United Nations Disarmament Yearbook described highlights and challenges in the previous year. As reported by the UN Press, \"On the one hand, we saw record levels of military spending and division within important arms-control frameworks, including the Treaty on the Non-Proliferation of Nuclear Weapons. \u00a0On the other hand, we also saw the first-ever Meeting of States Parties to the Treaty on the Prohibition of Nuclear Weapons\"\nU.S. nuclear policy.\nDespite a general trend toward disarmament in the early 2000s, the George W. Bush administration repeatedly pushed to fund policies that would allegedly make nuclear weapons more usable in the post\u2013Cold War environment. To date the U.S. Congress has refused to fund many of these policies. However, some feel that even considering such programs harms the credibility of the United States as a proponent of nonproliferation.\nControversial U.S. nuclear policies.\nFormer U.S. officials Henry Kissinger, George Shultz, Bill Perry, and Sam Nunn (aka 'The Gang of Four' on nuclear deterrence) proposed in January 2007 that the United States rededicate itself to the goal of eliminating nuclear weapons, concluding: \"We endorse setting the goal of a world free of nuclear weapons and working energetically on the actions required to achieve that goal.\" Arguing a year later that \"with nuclear weapons more widely available, deterrence is decreasingly effective and increasingly hazardous,\" the authors concluded that although \"it is tempting and easy to say we can't get there from here, [...] we must chart a course toward that goal.\" During his presidential campaign, former U.S. President Barack Obama pledged to \"set a goal of a world without nuclear weapons, and pursue it.\"\nU.S. programs to reduce risk of nuclear terrorism.\nThe United States has taken the lead in ensuring that nuclear materials globally are properly safeguarded. A popular program that has received bipartisan domestic support for over a decade is the Cooperative Threat Reduction Program (CTR). While this program has been deemed a success, many believe that its funding levels need to be increased so as to ensure that all dangerous nuclear materials are secured in the most expeditious manner possible. The CTR program has led to several other innovative and important nonproliferation programs that need to continue to be a budget priority in order to ensure that nuclear weapons do not spread to actors hostile to the United States.\nKey programs:\nOther states.\nList of countries' nuclear weapons development status represented by color.\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Five \"nuclear weapons states\" from the NPT\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Other states known to possess nuclear weapons (India, Pakistan and North Korea)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Other presumed nuclear powers (Israel) \n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0States formerly possessing nuclear weapons (Belarus, Kazakhstan, South Africa and Ukraine)\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0States suspected of being in the process of developing nuclear weapons and/or nuclear programs\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0States which at one point had nuclear weapons and/or nuclear weapons research programs\nWhile the vast majority of states have adhered to the stipulations of the Nuclear Nonproliferation Treaty, a few states have either refused to sign the treaty or have pursued nuclear weapons programs while not being members of the treaty. Many view the pursuit of nuclear weapons by these states as a threat to nonproliferation and world peace.\n*Indian nuclear weapons: 172 active warheads\n*Pakistani nuclear weapons: 170 active warheads\n*North Korean nuclear weapons: 50 active warheads\n*Israeli nuclear weapons: 90\u2013300 active warheads\n*South African nuclear weapons: disarmed from 1989\u20131993\n*Belarus\n*Kazakhstan\n*Ukraine\n*Iran\n*Libya\nSemiotics.\nThe precise use of terminology in the context of disarmament may have important implications for political Signaling theory. In the case of North Korea, \"denuclearization\" has historically been interpreted as different from \"disarmament\" by including withdrawal of American nuclear capabilities from the region. More recently, this term has become provocative due to its comparisons to the collapse of the Gaddafi regime after disarmament. The Biden administration has been criticized for its reaffirming of a strategy of denuclearization with Korea and Japan, as opposed to a \"freeze\" or \"pause\" on new nuclear developments.\nSimilarly, the term \"irreversible\" has been argued to set an impossible standard for states to disarm.\nRecent developments.\nEliminating nuclear weapons has long been an aim of the pacifist left. But now many mainstream politicians, academic analysts, and retired military leaders also advocate nuclear disarmament. Sam Nunn, William Perry, Henry Kissinger, and George Shultz have called upon governments to embrace the vision of a world free of nuclear weapons, and in three op-eds in \"The Wall Street Journal\" proposed an ambitious program of urgent steps to that end. The four have created the Nuclear Security Project to advance this agenda. Nunn reinforced that agenda during a speech at the Harvard Kennedy School on October 21, 2008, saying, \"I'm much more concerned about a terrorist without a return address that cannot be deterred than I am about deliberate war between nuclear powers. You can't deter a group who is willing to commit suicide. We are in a different era. You have to understand the world has changed.\" In 2010, the four were featured in a documentary film entitled \"Nuclear Tipping Point\". The film is a visual and historical depiction of the ideas laid forth in \"The Wall Street Journal\" op-eds and reinforces their commitment to a world without nuclear weapons and the steps that can be taken to reach that goal.\nGlobal Zero is an international non-partisan group of 300 world leaders dedicated to achieving nuclear disarmament. The initiative, launched in December 2008, promotes a phased withdrawal and verification for the destruction of all devices held by official and unofficial members of the nuclear club. The Global Zero campaign works toward building an international consensus and a sustained global movement of leaders and citizens for the elimination of nuclear weapons. Goals include the initiation of United States-Russia bilateral negotiations for reductions to 1,000 total warheads each and commitments from the other key nuclear weapons countries to participate in multilateral negotiations for phased reductions of nuclear arsenals. Global Zero works to expand the diplomatic dialogue with key governments and continue to develop policy proposals on the critical issues related to the elimination of nuclear weapons.\nThe International Conference on Nuclear Disarmament took place in Oslo in February 2008, and was organized by The Government of Norway, the Nuclear Threat Initiative and the Hoover Institute. The Conference was entitled \"Achieving the Vision of a World Free of Nuclear Weapons\" and had the purpose of building consensus between nuclear weapon states and non-nuclear weapon states in relation to the Nuclear Non-proliferation Treaty.\nThe Tehran International Conference on Disarmament and Non-Proliferation took place in Tehran in April 2010. The conference was held shortly after the signing of the New START, and resulted in a call of action toward eliminating all nuclear weapons. Representatives from 60 countries were invited to the conference. Non-governmental organizations were also present.\nAmong the prominent figures who have called for the abolition of nuclear weapons are \"the philosopher Bertrand Russell, the entertainer Steve Allen, CNN's Ted Turner, former Senator Claiborne Pell, Notre Dame president Theodore Hesburgh, South African Bishop Desmond Tutu and the Dalai Lama\".\nOthers have argued that nuclear weapons have made the world relatively safer, with peace through deterrence and through the stability\u2013instability paradox, including in south Asia. Kenneth Waltz has argued that nuclear weapons have created a nuclear peace, and further nuclear weapon proliferation might even help avoid the large scale conventional wars that were so common prior to their invention at the end of World War II. In the July 2012 issue of Foreign Affairs Waltz took issue with the view of most U.S., European, and Israeli, commentators and policymakers that a nuclear-armed Iran would be unacceptable. Instead Waltz argues that it would probably be the best possible outcome, as it would restore stability to the Middle East by balancing Israel's regional monopoly on nuclear weapons. Professor John Mueller of Ohio State University, the author of \"Atomic Obsession\", has also dismissed the need to interfere with Iran's nuclear program and expressed that arms control measures are counterproductive. During a 2010 lecture at the University of Missouri, which was broadcast by C-SPAN, Mueller has also argued that the threat from nuclear weapons, especially nuclear terrorism, has been exaggerated, both in the popular media and by officials.\nFormer Secretary Kissinger says there is a new danger, which cannot be addressed by deterrence: \"The classical notion of deterrence was that there was some consequences before which aggressors and evildoers would recoil. In a world of suicide bombers, that calculation doesn't operate in any comparable way\". George Shultz has said, \"If you think of the people who are doing suicide attacks, and people like that get a nuclear weapon, they are almost by definition not deterrable\".\nAndrew Bacevich wrote that there is no feasible scenario under which the US could sensibly use nuclear weapons:For the United States, they are becoming unnecessary, even as a deterrent. Certainly, they are unlikely to dissuade the adversaries most likely to employ such weapons against us \u2013 Islamic extremists intent on acquiring their own nuclear capability. If anything, the opposite is true. By retaining a strategic arsenal in readiness (and by insisting without qualification that the dropping of atomic bombs on two Japanese cities in 1945 was justified), the United States continues tacitly to sustain the view that nuclear weapons play a legitimate role in international politics ...In \"The Limits of Safety\", Scott Sagan documented numerous incidents in US military history that could have produced a nuclear war by accident. He concluded:while the military organizations controlling U.S. nuclear forces during the Cold War performed this task with less success than we know, they performed with more success than we \"should\" have reasonably predicted. The problems identified in this book were not the product of incompetent organizations. They reflect the inherent limits of organizational safety. Recognizing that simple truth is the first and most important step toward a safer future.\nOn January 3, 2022, the permanent members of the United Nations Security Council, China, France, Russia, Britain, and the United States issued a statement on prevention of nuclear war, affirming that \"a nuclear war cannot be won and must never be fought.\"\nOn February 21, 2023, Russian President Vladimir Putin suspended Russia's participation in the New START nuclear arms reduction treaty with the United States.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;"}
{"id": "22166", "revid": "37052726", "url": "https://en.wikipedia.org/wiki?curid=22166", "title": "NUTS", "text": ""}
{"id": "22169", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=22169", "title": "Nuclear Non-proliferation Treaty", "text": ""}
{"id": "22170", "revid": "50923714", "url": "https://en.wikipedia.org/wiki?curid=22170", "title": "Net (mathematics)", "text": "Generalization of a sequence of points\nIn mathematics, more specifically in general topology and related branches, a net or Moore\u2013Smith sequence is a function whose domain is a directed set. The codomain of this function is usually some topological space. Nets directly generalize the concept of a sequence in a metric space. Nets are primarily used in the fields of analysis and topology, where they are used to characterize many important topological properties that (in general), sequences are unable to characterize (this shortcoming of sequences motivated the study of sequential spaces and Fr\u00e9chet\u2013Urysohn spaces). Nets are in one-to-one correspondence with filters.\nHistory.\nThe concept of a net was first introduced by E. H. Moore and Herman L. Smith in 1922. The term \"net\" was coined by John L. Kelley.\nThe related concept of a filter was developed in 1937 by Henri Cartan.\nDefinitions.\nA directed set is a non-empty set formula_1 together with a preorder, typically automatically assumed to be denoted by formula_2 (unless indicated otherwise), with the property that it is also (upward) directed, which means that for any formula_3 there exists some formula_4 such that formula_5 and formula_6 \nIn words, this property means that given any two elements (of formula_1), there is always some element that is \"above\" both of them (greater than or equal to each); in this way, directed sets generalize the notion of \"a direction\" in a mathematically rigorous way. Importantly though, directed sets are not required to be total orders or even partial orders. A directed set may have the greatest element. In this case, the conditions formula_5 and formula_9 cannot be replaced by the strict inequalities formula_10 and formula_11, since the strict inequalities cannot be satisfied if \"a\" or \"b\" is the greatest element.\nA net in formula_12, denoted formula_13, is a function of the form formula_14 whose domain formula_1 is some directed set, and whose values are formula_16. Elements of a net's domain are called its indices. When the set formula_12 is clear from context it is simply called a net, and one assumes formula_1 is a directed set with preorder formula_19 Notation for nets varies, for example using angled brackets formula_20. As is common in algebraic topology notation, the filled disk or \"bullet\" stands in place of the input variable or index formula_21.\nLimits of nets.\nA net formula_13 is said to be eventually or residually in a set formula_23 if there exists some formula_21 such that for every formula_25 with formula_26 the point formula_27 A point formula_28 is called a or of the net formula_29 in formula_12 whenever:\nfor every open neighborhood formula_31 of formula_32 the net formula_29 is eventually in formula_31,\nexpressed equivalently as: the net or has formula_35 as a limit; and variously denoted as:formula_36If formula_12 is clear from context, it may be omitted from the notation.\nIf formula_38 and this limit is unique (i.e. formula_39 only for formula_40) then one writes:formula_41using the equal sign in place of the arrow formula_42 In a Hausdorff space, every net has at most one limit, and the limit of a convergent net is always unique.\nSome authors do not distinguish between the notations formula_43 and formula_38, but this can lead to ambiguities if the ambient space \"formula_12\" is not Hausdorff.\nCluster points of nets.\nA net formula_13 is said to be or formula_23 if for every formula_21 there exists some formula_25 such that formula_50 and formula_27 A point formula_28 is said to be an or \"cluster point\" of a net if for every neighborhood formula_31 of formula_32 the net is frequently/cofinally in formula_55 In fact, formula_28 is a cluster point if and only if it has a subnet that converges to formula_57 The set formula_58 of all cluster points of formula_29 in formula_12 is equal to formula_61 for each formula_62, where formula_63.\nSubnets.\nThe analogue of \"subsequence\" for nets is the notion of a \"subnet\". There are several different non-equivalent definitions of \"subnet\" and this article will use the definition introduced in 1970 by Stephen Willard, which is as follows: \nIf formula_13 and formula_65 are nets then formula_66 is called a subnet or of formula_29 if there exists an order-preserving map formula_68 such that formula_69 is a cofinal subset of formula_1 and \nformula_71 \nThe map formula_68 is called order-preserving and an order homomorphism if whenever formula_73 then formula_74 \nThe set formula_69 being cofinal in formula_1 means that for every formula_77 there exists some formula_78 such that formula_79\nIf formula_28 is a cluster point of some subnet of formula_29 then formula_35 is also a cluster point of formula_83\nUltranets.\nA net formula_29 in set formula_12 is called a or an if for every subset formula_86 formula_29 is eventually in formula_23 or formula_29 is eventually in the complement formula_90 \nEvery constant net is a (trivial) ultranet. Every subnet of an ultranet is an ultranet. Assuming the axiom of choice, every net has some subnet that is an ultranet, but no nontrivial ultranets have ever been constructed explicitly. \nIf formula_13 is an ultranet in formula_12 and formula_93 is a function then formula_94 is an ultranet in formula_95 \nGiven formula_96 an ultranet clusters at formula_35 if and only if it converges to formula_57\nCauchy nets.\nA Cauchy net generalizes the notion of Cauchy sequence to nets defined on uniform spaces.\nA net formula_13 is a if for every entourage formula_100 there exists formula_4 such that for all formula_102 formula_103 is a member of formula_104 More generally, in a Cauchy space, a net formula_29 is Cauchy if the filter generated by the net is a Cauchy filter.\nA topological vector space (TVS) is called complete if every Cauchy net converges to some point. A normed space, which is a special type of topological vector space, is a complete TVS (equivalently, a Banach space) if and only if every Cauchy sequence converges to some point (a property that is called sequential completeness). Although Cauchy nets are not needed to describe completeness of normed spaces, they are needed to describe completeness of more general (possibly non-normable) topological vector spaces.\nCharacterizations of topological properties.\nVirtually all concepts of topology can be rephrased in the language of nets and limits. This may be useful to guide the intuition since the notion of limit of a net is very similar to that of limit of a sequence. The following set of theorems and lemmas help cement that similarity:\nClosed sets and closure.\nA subset formula_106 is closed in formula_12 if and only if every limit point in formula_12 of a net in formula_23 necessarily lies in formula_23.\nExplicitly, this means that if formula_111 is a net with formula_112 for all formula_62, and formula_114 in formula_115 then formula_116\nMore generally, if formula_106 is any subset, the closure of formula_23 is the set of points formula_119 with formula_120 for some net formula_121 in formula_23. \nOpen sets and characterizations of topologies.\nA subset formula_106 is open if and only if no net in formula_124 converges to a point of formula_125 Also, subset formula_106 is open if and only if every net converging to an element of formula_23 is eventually contained in formula_125 \nIt is these characterizations of \"open subset\" that allow nets to characterize topologies. \nTopologies can also be characterized by closed subsets since a set is open if and only if its complement is closed. So the characterizations of \"closed set\" in terms of nets can also be used to characterize topologies.\nContinuity.\nA function formula_93 between topological spaces is continuous at a point formula_35 if and only if for every net formula_13 in the domain, formula_132 in formula_12 implies formula_134 in formula_95 \nBriefly, a function formula_93 is continuous if and only if formula_137 in formula_12 implies formula_139 in formula_95 \nIn general, this statement would not be true if the word \"net\" was replaced by \"sequence\"; that is, it is necessary to allow for directed sets other than just the natural numbers if formula_12 is not a first-countable space (or not a sequential space).\nCompactness.\nA space formula_12 is compact if and only if every net formula_13 in formula_12 has a subnet with a limit in formula_145 This can be seen as a generalization of the Bolzano\u2013Weierstrass theorem and Heine\u2013Borel theorem.\nCluster and limit points.\nThe set of cluster points of a net is equal to the set of limits of its convergent subnets.\nA net has a limit if and only if all of its subnets have limits. In that case, every limit of the net is also a limit of every subnet.\nOther properties.\nIn general, a net in a space formula_12 can have more than one limit, but if formula_12 is a Hausdorff space, the limit of a net, if it exists, is unique. Conversely, if formula_12 is not Hausdorff, then there exists a net on formula_12 with two distinct limits. Thus the uniqueness of the limit is equivalent to the Hausdorff condition on the space, and indeed this may be taken as the definition. This result depends on the directedness condition; a set indexed by a general preorder or partial order may have distinct limit points even in a Hausdorff space.\nRelation to filters.\nA filter is a related idea in topology that allows for a general definition for convergence in general topological spaces. The two ideas are equivalent in the sense that they give the same concept of convergence. More specifically, every filter base induces an associated net using the filter's pointed sets, and convergence of the filter base implies convergence of the associated net. Similarly, any net formula_150 in formula_12 induces a filter base of tails formula_152 where the filter in formula_12 generated by this filter base is called the net's eventuality filter. Convergence of the net implies convergence of the eventuality filter. This correspondence allows for any theorem that can be proven with one concept to be proven with the other. For instance, continuity of a function from one topological space to the other can be characterized either by the convergence of a net in the domain implying the convergence of the corresponding net in the codomain, or by the same statement with filter bases.\nRobert G. Bartle argues that despite their equivalence, it is useful to have both concepts. He argues that nets are enough like sequences to make natural proofs and definitions in analogy to sequences, especially ones using sequential elements, such as is common in analysis, while filters are most useful in algebraic topology. In any case, he shows how the two can be used in combination to prove various theorems in general topology.\nThe learning curve for using nets is typically much less steep than that for filters, which is why many mathematicians, especially analysts, prefer them over filters. However, filters, and especially ultrafilters, have some important technical advantages over nets that ultimately result in nets being encountered much less often than filters outside of the fields of analysis and topology.\nAs generalization of sequences.\nEvery non-empty totally ordered set is directed. Therefore, every function on such a set is a net. In particular, the natural numbers formula_154 together with the usual integer comparison formula_2 preorder form the archetypical example of a directed set. A sequence is a function on the natural numbers, so every sequence formula_156 in a topological space formula_12 can be considered a net in formula_12 defined on formula_159 Conversely, any net whose domain is the natural numbers is a sequence because by definition, a sequence in formula_12 is just a function from formula_161 into formula_145 It is in this way that nets are generalizations of sequences: rather than being defined on a countable linearly ordered set (formula_154), a net is defined on an arbitrary directed set. Nets are frequently denoted using notation that is similar to (and inspired by) that used with sequences. For example, the subscript notation formula_164 is taken from sequences.\nSimilarly, every limit of a sequence and limit of a function can be interpreted as a limit of a net. Specifically, the net is eventually in a subset formula_23 of formula_12 if there exists an formula_167 such that for every integer formula_168 the point formula_169 is in formula_125 So formula_171 if and only if for every neighborhood formula_100 of formula_173 the net is eventually in formula_104 The net is frequently in a subset formula_23 of formula_12 if and only if for every formula_167 there exists some integer formula_178 such that formula_179 that is, if and only if infinitely many elements of the sequence are in formula_125 Thus a point formula_181 is a cluster point of the net if and only if every neighborhood formula_100 of formula_183 contains infinitely many elements of the sequence.\nIn the context of topology, sequences do not fully encode all information about functions between topological spaces. In particular, the following two conditions are, in general, not equivalent for a map formula_184 between topological spaces formula_12 and formula_186:\nWhile condition 1 always guarantees condition 2, the converse is not necessarily true. The spaces for which the two conditions are equivalent are called sequential spaces. All first-countable spaces, including metric spaces, are sequential spaces, but not all topological spaces are sequential. Nets generalize the notion of a sequence so that condition 2 reads as follows:\nWith this change, the conditions become equivalent for all maps of topological spaces, including topological spaces that do not necessarily have a countable or linearly ordered neighbourhood basis around a point. Therefore, while sequences do not encode sufficient information about functions between topological spaces, nets do, because collections of open sets in topological spaces are much like directed sets in behavior.\nFor an example where sequences do not suffice, interpret the set formula_194 of all functions with prototype formula_195 as the Cartesian product formula_196 (by identifying a function formula_184 with the tuple formula_198 and conversely) and endow it with the product topology. This (product) topology on formula_194 is identical to the topology of pointwise convergence. Let formula_200 denote the set of all functions formula_201 that are equal to formula_202 everywhere except for at most finitely many points (that is, such that the set formula_203 is finite). Then the constant formula_204 function formula_205 belongs to the closure of formula_200 in formula_207 that is, formula_208 This will be proven by constructing a net in formula_200 that converges to formula_210 However, there does not exist any sequence in formula_200 that converges to formula_212 which makes this one instance where (non-sequence) nets must be used because sequences alone can not reach the desired conclusion. Compare elements of formula_194 pointwise in the usual way by declaring that formula_214 if and only if formula_215 for all formula_57 This pointwise comparison is a partial order that makes formula_217 a directed set since given any formula_218 their pointwise minimum formula_219 belongs to formula_200 and satisfies formula_221 and formula_222 This partial order turns the identity map formula_223 (defined by formula_224) into an formula_200-valued net. This net converges pointwise to formula_226 in formula_227 which implies that formula_226 belongs to the closure of formula_200 in formula_230\nMore generally, a subnet of a sequence is not necessarily a sequence. Moreso, a subnet of a sequence may be a sequence, but not a subsequence. But, in the specific case of a sequential space, every net induces a corresponding sequence, and this relationship maps subnets to subsequences. Specifically, for a first-countable space, the net formula_150 induces the sequence formula_232 where formula_233 is defined as the formula_234 smallest value in formula_1\u00a0\u2013 that is, let formula_236 and let formula_237 for every integer formula_238.\nExamples.\nSubspace topology.\nIf the set formula_239 is endowed with the subspace topology induced on it by formula_115 then formula_132 in formula_12 if and only if formula_132 in formula_125 In this way, the question of whether or not the net formula_29 converges to the given point formula_35 depends solely on this topological subspace formula_23 consisting of formula_35 and the image of (that is, the points of) the net formula_83\nNeighborhood systems.\nIntuitively, convergence of a net formula_150 means that the values formula_164 come and stay as close as we want to formula_35 for large enough formula_253 Given a point formula_35 in a topological space, let formula_255 denote the set of all neighbourhoods containing formula_57 Then formula_255 is a directed set, where the direction is given by reverse inclusion, so that formula_258 if and only if formula_23 is contained in formula_260 For formula_261 let formula_262 be a point in formula_125 Then formula_264 is a net. As formula_23 increases with respect to formula_266 the points formula_262 in the net are constrained to lie in decreasing neighbourhoods of formula_32. Therefore, in this neighborhood system of a point formula_35, formula_262 does indeed converge to formula_35 according to the definition of net convergence.\nGiven a subbase formula_272 for the topology on formula_12 (where note that every base for a topology is also a subbase) and given a point formula_96 a net formula_29 in formula_12 converges to formula_35 if and only if it is eventually in every neighborhood formula_278 of formula_57 This characterization extends to neighborhood subbases (and so also neighborhood bases) of the given point formula_57\nLimits in a Cartesian product.\nA net in the product space has a limit if and only if each projection has a limit.\nExplicitly, let formula_281 be topological spaces, endow their Cartesian product \nformula_282\nwith the product topology, and that for every index formula_283 denote the canonical projection to formula_284 by\nformula_285\nLet formula_286 be a net in formula_287 directed by formula_1 and for every index formula_289 let \nformula_290\ndenote the result of \"plugging formula_291 into formula_292\", which results in the net formula_293 \nIt is sometimes useful to think of this definition in terms of function composition: the net formula_294 is equal to the composition of the net formula_295 with the projection formula_296 that is, formula_297\nFor any given point formula_298 the net formula_291 converges to formula_300 in the product space formula_287 if and only if for every index formula_289 formula_303 converges to formula_304 in formula_305 \nAnd whenever the net formula_291 clusters at formula_300 in formula_287 then formula_294 clusters at formula_304 for every index formula_311 However, the converse does not hold in general. For example, suppose formula_312 and let formula_313 denote the sequence formula_314 that alternates between formula_315 and formula_316 Then formula_317 and formula_318 are cluster points of both formula_319 and formula_320 in formula_321 but formula_322 is not a cluster point of formula_291 since the open ball of radius formula_202 centered at formula_325 does not contain even a single point formula_291 \nTychonoff's theorem and relation to the axiom of choice.\nIf no formula_327 is given but for every formula_289 there exists some formula_329 such that formula_330 in formula_331 then the tuple defined by formula_332 will be a limit of formula_291 in formula_145 \nHowever, the axiom of choice might need to be assumed to conclude that this tuple formula_300 exists; the axiom of choice is not needed in some situations, such as when formula_336 is finite or when every formula_329 is the unique limit of the net formula_294 (because then there is nothing to choose between), which happens for example, when every formula_331 is a Hausdorff space. If formula_336 is infinite and formula_341 is not empty, then the axiom of choice would (in general) still be needed to conclude that the projections formula_342 are surjective maps.\nThe axiom of choice is equivalent to Tychonoff's theorem, which states that the product of any collection of compact topological spaces is compact. \nBut if every compact space is also Hausdorff, then the so called \"Tychonoff's theorem for compact Hausdorff spaces\" can be used instead, which is equivalent to the ultrafilter lemma and so strictly weaker than the axiom of choice. \nNets can be used to give short proofs of both version of Tychonoff's theorem by using the characterization of net convergence given above together with the fact that a space is compact if and only if every net has a convergent subnet.\nLimit superior/inferior.\nLimit superior and limit inferior of a net of real numbers can be defined in a similar manner as for sequences. Some authors work even with more general structures than the real line, like complete lattices.\nFor a net formula_343 put\nformula_344\nLimit superior of a net of real numbers has many properties analogous to the case of sequences. For example,\nformula_345\nwhere equality holds whenever one of the nets is convergent.\nRiemann integral.\nThe definition of the value of a Riemann integral can be interpreted as a limit of a net of Riemann sums where the net's directed set is the set of all partitions of the interval of integration, partially ordered by inclusion.\nMetric spaces.\nSuppose formula_346 is a metric space (or a pseudometric space) and formula_347 is endowed with the metric topology. If formula_348 is a point and formula_349 is a net, then formula_350 in formula_346 if and only if formula_352 in formula_353 where formula_354 is a net of real numbers. \nIn plain English, this characterization says that a net converges to a point in a metric space if and only if the distance between the net and the point converges to zero. \nIf formula_355 is a normed space (or a seminormed space) then formula_350 in formula_355 if and only if formula_358 in formula_359 where formula_360\nIf formula_346 has at least two points, then we can fix a point formula_362 (such as formula_363 with the Euclidean metric with formula_364 being the origin, for example) and direct the set formula_365 reversely according to distance from formula_366 by declaring that formula_73 if and only if formula_368 In other words, the relation is \"has at least the same distance to formula_366 as\", so that \"large enough\" with respect to this relation means \"close enough to formula_366\". \nGiven any function with domain formula_371 its restriction to formula_365 can be canonically interpreted as a net directed by formula_373 \nA net formula_374 is eventually in a subset formula_23 of a topological space formula_12 if and only if there exists some formula_377 such that for every formula_378 satisfying formula_379 the point formula_380 is in formula_125 \nSuch a net formula_184 converges in formula_12 to a given point formula_327 if and only if formula_385 in the usual sense (meaning that for every neighborhood formula_100 of formula_173 formula_184 is eventually in formula_100). \nThe net formula_374 is frequently in a subset formula_23 of formula_12 if and only if for every formula_377 there exists some formula_378 with formula_395 such that formula_380 is in formula_125\nConsequently, a point formula_327 is a cluster point of the net formula_184 if and only if for every neighborhood formula_100 of formula_173 the net is frequently in formula_104\nFunction from a well-ordered set to a topological space.\nConsider a well-ordered set formula_403 with limit point formula_404 and a function formula_184 from formula_406 to a topological space formula_145 This function is a net on formula_408\nIt is eventually in a subset formula_100 of formula_12 if there exists an formula_411 such that for every formula_412 the point formula_413 is in formula_104\nSo formula_415 if and only if for every neighborhood formula_100 of formula_173 formula_184 is eventually in formula_104\nThe net formula_184 is frequently in a subset formula_100 of formula_12 if and only if for every formula_411 there exists some formula_412 such that formula_425\nA point formula_181 is a cluster point of the net formula_184 if and only if for every neighborhood formula_100 of formula_429 the net is frequently in formula_104\nThe first example is a special case of this with formula_431\nSee also ordinal-indexed sequence.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22171", "revid": "35125200", "url": "https://en.wikipedia.org/wiki?curid=22171", "title": "Nuclear winter", "text": "Hypothetical climatic effect of nuclear war\nNuclear winter is a severe and prolonged global climatic cooling effect that is hypothesized to occur after widespread urban firestorms following a large-scale nuclear war. The hypothesis is based on the fact that such fires can inject soot into the stratosphere, where it can block some direct sunlight from reaching the surface of the Earth. It is speculated that the resulting cooling, typically lasting a decade, would lead to widespread crop failure, a global nuclear famine, and an animal mass extinction event.\nClimate researchers study nuclear winter via computer models and scenarios. Results are highly dependent on nuclear yields, whether and how many cities are targeted, their flammable material content, and the firestorms' atmospheric environments, convections, and durations. Firestorm case studies include the World War II bombings of Hiroshima, Tokyo, Hamburg, Dresden, and London, and modern observations from large-area wildfires such as the 2021 British Columbia wildfires.\nStudies suggest that a full-scale nuclear war, expending thousands of weapons in the largest arsenals in Russia and the United States, could cool global temperatures by more than 5\u00a0\u00b0C, exceeding the last ice age. According to these models, five billion people would die from famine within two years, and 40\u201350% of animal species would go extinct. Studies of a regional nuclear war involving hundreds of weapons, such as between India and Pakistan, could also cause cooling of a few degrees, threatening up to two billion people and making 10\u201320% of animal species extinct. However, many gaps remain in the understanding and modeling the effects of nuclear war.\nGeneral.\n\"Nuclear winter\", or as it was initially termed, \"nuclear twilight\", began to be considered as a scientific concept in the 1980s after it became clear that an earlier hypothesis predicting that fireball generated NOx emissions would devastate the ozone layer was losing credibility. It was within this context that the climatic effects of soot from fires became the new focus of the climatic effects of nuclear war. In these model scenarios, various soot clouds containing uncertain quantities of soot were assumed to form over cities, oil refineries, and more rural missile silos. Once the quantity of soot is decided upon by the researchers, the climate effects of these soot clouds are then modeled. The term \"nuclear winter\" was a neologism coined in 1983 by Richard P. Turco in reference to a one-dimensional computer model created to examine the \"nuclear twilight\" idea. This model projected that massive quantities of soot and smoke would remain aloft in the air for on the order of years, causing a severe planet-wide drop in temperature.\nAfter the failure of the predictions on the effects of the 1991 Kuwait oil fires that were made by the primary team of climatologists that advocate the hypothesis, over a decade passed without new published papers on the topic. More recently, the same team of prominent modellers from the 1980s have begun again to publish the outputs of computer models. These newer models produce the same general findings as their old ones, namely that the ignition of 100 firestorms, each comparable in intensity to that observed in Hiroshima in 1945, could produce a \"small\" nuclear winter. These firestorms would result in the injection of soot (specifically black carbon) into the Earth's stratosphere, producing an anti-greenhouse effect that would lower the Earth's surface temperature. The severity of this cooling in Alan Robock's model suggests that the cumulative products of 100 of these firestorms could cool the global climate by approximately 1\u00a0\u00b0C (1.8\u00a0\u00b0F), largely eliminating the magnitude of anthropogenic global warming for the next roughly two or three years. Robock and his collaborators have modeled the effect on global food production, and project that the injection of more than 5\u2009Tg of soot into the stratosphere would lead to mass food shortages persisting for several years. According to their model, livestock and aquatic food production would be unable to compensate for reduced crop output in almost all countries, and adaptation measures such as food waste reduction would have limited impact on increasing available calories.\nAs nuclear devices need not be detonated to ignite a firestorm, the term \"nuclear winter\" is something of a misnomer. The majority of papers published on the subject state that without qualitative justification, nuclear explosions are the cause of the modeled firestorm effects. The only phenomenon that is modeled by computer in the nuclear winter papers is the climate forcing agent of firestorm-soot, a product which can be ignited and formed by myriad means. Although rarely discussed, the proponents of the hypothesis state that the same \"nuclear winter\" effect would occur if 100 large scale conventional firestorms were ignited.\nA much larger number of firestorms, in the thousands, was the initial assumption of the computer modelers who coined the term in the 1980s. These were speculated to be a possible result of any large scale employment of counter-value airbursting nuclear weapon use during an American-Soviet total war. This larger number of firestorms, which are not in themselves modeled, are presented as causing nuclear winter conditions as a result of the smoke inputted into various climate models, with the depths of severe cooling lasting for as long as a decade. During this period, summer drops in average temperature could be up to 20\u00a0\u00b0C (36\u00a0\u00b0F) in core agricultural regions of the US, Europe, and China, and as much as 35\u00a0\u00b0C (63\u00a0\u00b0F) in Russia. This cooling would be produced due to a 99% reduction in the natural solar radiation reaching the surface of the planet in the first few years, gradually clearing over the course of several decades.\nSince the advent of photography that captured evidence of tall clouds, it has been known that firestorms could inject soot smoke and aerosols into the stratosphere, but the longevity of this slew of aerosols was a major unknown. Independent of the team that continue to publish theoretical models on nuclear winter, in 2006, Mike Fromm of the Naval Research Laboratory, experimentally found that each natural occurrence of a massive wildfire firestorm, much larger than that observed at Hiroshima, can produce minor \"nuclear winter\" effects, with short-lived, approximately one month of a nearly immeasurable drop in surface temperatures, confined to the hemisphere that they burned in. This is somewhat analogous to the frequent volcanic eruptions that inject sulfates into the stratosphere and thereby produce minor, even negligible, volcanic winter effects.\nA suite of satellite and aircraft-based firestorm-soot-monitoring instruments are at the forefront of attempts to accurately determine the lifespan, quantity, injection height, and optical properties of this smoke. Information regarding all of these properties is necessary to truly ascertain the length and severity of the cooling effect of firestorms, independent of the nuclear winter computer model projections.\nCurrently, from satellite tracking data, it appears that stratospheric smoke aerosols dissipate in a time span under approximately two months. The existence of a tipping point into a new stratospheric condition where the aerosols would not be removed within this time frame remains to be determined.\nMechanism.\nThe nuclear winter scenario assumes that 100 or more city firestorms are ignited by nuclear explosions, and that the firestorms lift large amounts of sooty smoke into the upper troposphere and lower stratosphere by the movement offered by the pyrocumulonimbus clouds that form during a firestorm. At above the Earth's surface, the absorption of sunlight could further heat the soot in the smoke, lifting some or all of it into the stratosphere, where the smoke could persist for years if there is no rain to wash it out. This aerosol of particles could heat the stratosphere and prevent a portion of the sun's light from reaching the surface, causing surface temperatures to drop drastically. In this scenario it is predicted that surface air temperatures would be the same as, or colder than, a given region's winter for months to years on end.\nThe modeled stable inversion layer of hot soot between the troposphere and high stratosphere that produces the anti-greenhouse effect was dubbed the \"Smokeosphere\" by Stephen Schneider et al. in their 1988 paper.\nAlthough it is common in the climate models to consider city firestorms, these need not be ignited by nuclear devices; more conventional ignition sources can instead be the spark of the firestorms. Prior to the previously mentioned solar heating effect, the soot's injection height is controlled by the rate of energy release from the firestorm's fuel, not the size of an initial nuclear explosion. For example, the mushroom cloud from the bomb dropped on Hiroshima reached a height of six kilometers (middle troposphere) within a few minutes and then dissipated due to winds, while the individual fires within the city took almost three hours to form into a firestorm and produce a pyrocumulus cloud, a cloud that is assumed to have reached upper tropospheric heights, as over its multiple hours of burning, the firestorm released an estimated 1000 times the energy of the bomb.\nAs the incendiary effects of a nuclear explosion do not present any especially characteristic features, it is estimated by those with strategic bombing experience that as the city was a firestorm hazard, the same fire ferocity and building damage produced at Hiroshima by one 16-kiloton nuclear bomb from a single B-29 bomber could have been produced instead by the conventional use of about 1.2 kilotons of incendiary bombs from 220 B-29s distributed over the city.\nWhile the firestorms of Dresden and Hiroshima and the mass fires of Tokyo and Nagasaki occurred within mere months in 1945, the more intense and conventionally lit Hamburg firestorm occurred in 1943. Despite the separation in time, ferocity and area burned, leading modelers of the hypothesis state that these five fires potentially placed five percent as much smoke into the stratosphere as the hypothetical 100 nuclear-ignited fires discussed in modern models. While it is believed that the modeled climate-cooling-effects from the mass of soot injected into the stratosphere by 100 firestorms (one to five million metric tons) would have been detectable with technical instruments in WWII, five percent of that would not have been possible to observe at that time.\nAerosol removal timescale.\nThe exact timescale for how long this smoke remains, and thus how severely this smoke affects the climate once it reaches the stratosphere, is dependent on both chemical and physical removal processes.\nThe most important physical removal mechanism is \"rainout\", both during the \"fire-driven convective column\" phase, which produces \"black rain\" near the fire site, and rainout after the convective plume's dispersal, where the smoke is no longer concentrated and thus \"wet removal\" is believed to be very efficient. However, these efficient removal mechanisms in the troposphere are avoided in the Robock 2007 study, where solar heating is modeled to quickly loft the soot into the stratosphere, \"detraining\" or separating the darker soot particles from the fire clouds' whiter water condensation.\nOnce in the stratosphere, the physical removal mechanisms affecting the timescale of the soot particles' residence are how quickly the aerosol of soot collides and coagulates with other particles via Brownian motion, and falls out of the atmosphere via gravity-driven dry deposition, and the time it takes for the \"phoretic effect\" to move coagulated particles to a lower level in the atmosphere. Whether by coagulation or the phoretic effect, once the aerosol of smoke particles are at this lower atmospheric level, cloud seeding can begin, permitting precipitation to wash the smoke aerosol out of the atmosphere by the wet deposition mechanism.\nThe chemical processes that affect the removal are dependent on the ability of atmospheric chemistry to oxidize the carbonaceous component of the smoke, via reactions with oxidative species such as ozone and nitrogen oxides, both of which are found at all levels of the atmosphere, and which also occur at greater concentrations when air is heated to high temperatures.\nHistorical data on residence times of aerosols, albeit a different mixture of aerosols, in this case stratospheric sulfur aerosols and volcanic ash from megavolcano eruptions, appear to be in the one-to-two-year time scale, however aerosol\u2013atmosphere interactions are still poorly understood.\nSoot properties.\nSooty aerosols can have a wide range of properties, as well as complex shapes, making it difficult to determine their evolving atmospheric optical depth value. The conditions present during the creation of the soot are believed to be considerably important as to their final properties, with soot generated on the more efficient spectrum of burning efficiency considered almost \"elemental carbon black,\" while on the more inefficient end of the burning spectrum, greater quantities of partially burnt/oxidized fuel are present. These partially burnt \"organics\" as they are known, often form tar balls and brown carbon during common lower-intensity wildfires, and can also coat the purer black carbon particles. However, as the soot of greatest importance is that which is injected to the highest altitudes by the pyroconvection of the firestorm \u2013 a fire being fed with storm-force winds of air \u2013 it is estimated that the majority of the soot under these conditions is the more oxidized black carbon.\nConsequences.\nClimatic effects.\nA study presented at the annual meeting of the American Geophysical Union in December 2006 found that even a small-scale, regional nuclear war could disrupt the global climate for a decade or more. In a regional nuclear conflict scenario where two opposing nations in the subtropics would each use 50 Hiroshima-sized nuclear weapons (about 15 kilotons each) on major population centers, the researchers estimated as much as five million tons of soot would be released, which would produce a cooling of several degrees over large areas of North America and Eurasia, including most of the grain-growing regions. The cooling would last for years, and, according to the research, could be \"catastrophic\", disrupting agricultural production and food gathering in particular in higher latitude countries.\nOzone depletion.\nNuclear detonations produce large amounts of nitrogen oxides by combining elements in the surrounding air. These are then lifted upwards by thermal convection. As they reach the stratosphere, these nitrogen oxides are capable of catalytically breaking down the ozone present in this part of the atmosphere. Ozone depletion would allow a much greater intensity of harmful ultraviolet radiation from the sun to reach the ground.\nA 2008 study by Michael J. Mills et al., published in the Proceedings of the National Academy of Sciences, found that a nuclear weapons exchange between Pakistan and India using their current arsenals could create a near-global ozone hole, triggering human health problems and causing environmental damage for at least a decade. The computer-modeled study looked at a nuclear war between the two countries involving 50 Hiroshima-sized nuclear devices on each side, producing massive urban fires and lofting as much as five million metric tons of soot about into the stratosphere. The soot would absorb enough solar radiation to heat surrounding gases, increasing the breakdown of the stratospheric ozone layer protecting Earth from harmful ultraviolet radiation, with up to 70% ozone loss at northern high latitudes.\nNuclear summer.\nA \"nuclear summer\" is a hypothesized scenario in which, after a nuclear winter caused by aerosols inserted into the atmosphere that would prevent sunlight from reaching lower levels or the surface, has abated, a greenhouse effect then occurs due to carbon dioxide released by combustion and methane released from the decay of the organic matter such as corpses that froze during the nuclear winter.\nAnother more sequential hypothetical scenario, following the settling out of most of the aerosols in 1\u20133 years, the cooling effect would be overcome by a heating effect from greenhouse warming, which would raise surface temperatures rapidly by many degrees, enough to cause the death of much if not most of the life that had survived the cooling, much of which is more vulnerable to higher-than-normal temperatures than to lower-than-normal temperatures. The nuclear detonations would release CO2 and other greenhouse gases from burning, followed by more released from the decay of dead organic matter. The detonations would also insert nitrogen oxides into the stratosphere that would then deplete the ozone layer around the Earth.\nOther more straightforward hypothetical versions exist of the hypothesis that nuclear winter might give way to a nuclear summer. The high temperatures of the nuclear fireballs could destroy the ozone gas of the middle stratosphere.\nHistory.\nEarly work.\nIn 1952, a few weeks prior to the Ivy Mike (10.4 megaton) bomb test on Elugelab Island, there were concerns that the aerosols lifted by the explosion might cool the Earth. Major Norair Lulejian, USAF, and astronomer Natarajan Visvanathan studied this possibility, reporting their findings in \"Effects of Superweapons Upon the Climate of the World\", the distribution of which was tightly controlled. This report is described in a 2013 report by the Defense Threat Reduction Agency as the initial study of the \"nuclear winter\" concept. It indicated no appreciable chance of explosion-induced climate change.\nThe implications for civil defense of numerous surface bursts of high yield hydrogen bomb explosions on Pacific Proving Ground islands such as those of Ivy Mike in 1952 and Castle Bravo (15 Mt) in 1954 were described in a 1957 report on \"The Effects of Nuclear Weapons\", edited by Samuel Glasstone. A section in that book entitled \"Nuclear Bombs and the Weather\" states: \"The dust raised in severe volcanic eruptions, such as that at Krakatoa in 1883, is known to cause a noticeable reduction in the sunlight reaching the earth ... The amount of [soil or other surface] debris remaining in the atmosphere after the explosion of even the largest nuclear weapons is probably not more than about one percent or so of that raised by the Krakatoa eruption. Further, solar radiation records reveal that none of the nuclear explosions to date has resulted in any detectable change in the direct sunlight recorded on the ground.\" The US Weather Bureau in 1956 regarded it as conceivable that a large enough nuclear war with megaton-range surface detonations could lift enough soil to cause a new ice age.\nThe 1966 RAND corporation memorandum \"The Effects of Nuclear War on the Weather and Climate\" by E. S. Batten, while primarily analysing potential dust effects from surface bursts, notes that \"in addition to the effects of the debris, extensive fires ignited by nuclear detonations might change the surface characteristics of the area and modify local weather patterns ... however, a more thorough knowledge of the atmosphere is necessary to determine their exact nature, extent, and magnitude.\"\nIn the United States National Research Council (NRC) book \"Long-Term Worldwide Effects of Multiple Nuclear-Weapons Detonations\" published in 1975, it states that a nuclear war involving 4,000 Mt from \"present arsenals\" would probably deposit much less dust in the stratosphere than the Krakatoa eruption, judging that the effect of dust and oxides of nitrogen would probably be slight climatic cooling which \"would probably lie within normal global climatic variability, but the possibility of climatic changes of a more dramatic nature cannot be ruled out\".\nIn the 1985 report, \"The Effects on the Atmosphere of a Major Nuclear Exchange\", the Committee on the Atmospheric Effects of Nuclear Explosions argues that a \"plausible\" estimate on the amount of stratospheric dust injected following a surface burst of 1 Mt is 0.3 teragrams, of which 8 percent would be in the micrometer range. The potential cooling from soil dust was again looked at in 1992, in a US National Academy of Sciences (NAS) report on geoengineering, which estimated that about 1010 kg (10 teragrams) of stratospheric injected soil dust with particulate grain dimensions of 0.1 to 1 micrometer would be required to mitigate the warming from a doubling of atmospheric carbon dioxide, that is, to produce ~2\u00a0\u00b0C of cooling.\nIn 1969, Paul Crutzen discovered that oxides of nitrogen (NOx) could be an efficient catalyst for the destruction of the ozone layer/stratospheric ozone. Following studies on the potential effects of NOx generated by engine heat in stratosphere flying Supersonic Transport (SST) airplanes in the 1970s, in 1974, John Hampson suggested in the journal \"Nature\" that due to the creation of atmospheric NOx by nuclear fireballs, a full-scale nuclear exchange could result in depletion of the ozone shield, possibly subjecting the earth to ultraviolet radiation for a year or more. In 1975, Hampson's hypothesis \"led directly\" to the United States National Research Council (NRC) reporting on the models of ozone depletion following nuclear war in the book \"Long-Term Worldwide Effects of Multiple Nuclear-Weapons Detonations\".\nIn the section of this 1975 NRC book pertaining to the issue of fireball generated NOx and ozone layer loss therefrom, the NRC presented model calculations from the early-to-mid 1970s on the effects of a nuclear war with the use of large numbers of multi-megaton yield detonations, which returned conclusions that this could reduce ozone levels by 50 percent or more in the northern hemisphere.\nHowever, independent of the computer models presented in the 1975 NRC works, a paper in 1973 in the journal \"Nature\" depicts the stratospheric ozone levels worldwide overlaid upon the number of nuclear detonations during the era of atmospheric testing. The authors conclude that neither the data nor their models show any correlation between the approximate 500 Mt in historical atmospheric testing and an increase or decrease of ozone concentration. In 1976, a study on the experimental measurements of an earlier atmospheric nuclear test as it affected the ozone layer also found that nuclear detonations are exonerated of depleting ozone, after the at first alarming model calculations of the time. Similarly, a 1981 paper found that the models on ozone destruction from one test and the physical measurements taken were in disagreement, as no destruction was observed.\nIn total, about 500 Mt were atmospherically detonated between 1945 and 1971, peaking in 1961\u20131962, when 340 Mt were detonated in the atmosphere by the United States and Soviet Union. During this peak, with the multi-megaton range detonations of the two nations nuclear test series, in exclusive examination, a total yield estimated at 300 Mt of energy was released. Due to this, 3 \u00d7 1034 additional molecules of nitric oxide (about 5,000 tons per Mt, 5 \u00d7 109 grams per megaton) are believed to have entered the stratosphere, and while ozone depletion of 2.2 percent was noted in 1963, the decline had started prior to 1961 and is believed to have been caused by other meteorological effects.\nIn 1982 journalist Jonathan Schell in his popular and influential book \"The Fate of the Earth\", introduced the public to the belief that fireball generated NOx would destroy the ozone layer to such an extent that crops would fail from solar UV radiation and then similarly painted the fate of the Earth, as plant and aquatic life going extinct. In the same year, 1982, Australian physicist Brian Martin, who frequently corresponded with John Hampson who had been greatly responsible for much of the examination of NOx generation, penned a short historical synopsis on the history of interest in the effects of the direct NOx generated by nuclear fireballs, and in doing so, also outlined Hampson's other non-mainstream viewpoints, particularly those relating to greater ozone destruction from upper-atmospheric detonations as a result of any widely used anti-ballistic missile (ABM-1 Galosh) system. However, Martin ultimately concludes that it is \"unlikely that in the context of a major nuclear war\" ozone degradation would be of serious concern. Martin describes views about potential ozone loss and therefore increases in ultraviolet light leading to the widespread destruction of crops, as advocated by Jonathan Schell in \"The Fate of the Earth\", as highly unlikely.\nMore recent accounts on the specific ozone layer destruction potential of NOx species are much less than earlier assumed from simplistic calculations, as \"about 1.2 million tons\" of natural and anthropogenic generated stratospheric NOx is believed to be formed each year according to Robert P. Parson in the 1990s.\nScience fiction.\nThe first published suggestion that cooling of the climate could be an effect of a nuclear war, appears to have been originally put forth by Poul Anderson and F. N. Waldrop in their story \"Tomorrow's Children\", in the March 1947 issue of the \"Astounding Science Fiction\" magazine. The story, primarily about a team of scientists hunting down mutants, warns of a \"Fimbulwinter\" caused by dust that blocked sunlight after a recent nuclear war and speculated that it may even trigger a new Ice Age. Anderson went on to publish a novel based partly on this story in 1961, titling it \"Twilight World\". Similarly in 1985 it was noted by T. G. Parsons that the story \"Torch\" by C. Anvil, which also appeared in \"Astounding Science Fiction\" magazine, but in the April 1957 edition, contains the essence of the \"Twilight at Noon\"/\"nuclear winter\" hypothesis. In the story, a nuclear warhead ignites an oil field, and the soot produced \"screens out part of the sun's radiation\", resulting in Arctic temperatures for much of the population of North America and the Soviet Union.\n1980s.\nThe 1988 Air Force Geophysics Laboratory publication, \"An assessment of global atmospheric effects of a major nuclear war\" by H. S. Muench, et al., contains a chronology and review of the major reports on the nuclear winter hypothesis from 1983 to 1986. In general, these reports arrive at similar conclusions as they are based on \"the same assumptions, the same basic data\", with only minor model-code differences. They skip the modeling steps of assessing the possibility of fire and the initial fire plumes and instead start the modeling process with a \"spatially uniform soot cloud\" which has found its way into the atmosphere.\nAlthough never openly acknowledged by the multi-disciplinary team who authored the most popular 1980s TTAPS model, in 2011 the American Institute of Physics states that the TTAPS team (named for its participants, who had all previously worked on the phenomenon of dust storms on Mars, or in the area of asteroid impact events: Richard P. Turco, Owen Toon, Thomas P. Ackerman, James B. Pollack and Carl Sagan) announcement of their results in 1983 \"was with the explicit aim of promoting international arms control\". However, \"the computer models were so simplified, and the data on smoke and other aerosols were still so poor, that the scientists could say nothing for certain\".\nIn 1981, William J. Moran began discussions and research in the National Research Council (NRC) on the airborne soil/dust effects of a large exchange of nuclear warheads, having seen a possible parallel in the dust effects of a war with that of the asteroid-created K-T boundary and its popular analysis a year earlier by Luis Alvarez in 1980. An NRC study panel on the topic met in December 1981 and April 1982 in preparation for the release of the NRC's \"The Effects on the Atmosphere of a Major Nuclear Exchange\", published in 1985.\nAs part of a study on the creation of oxidizing species such as NOx and ozone in the troposphere after a nuclear war, launched in 1980 by \"Ambio\", a journal of the Royal Swedish Academy of Sciences, Paul J. Crutzen and John W. Birks began preparing for the 1982 publication of a calculation on the effects of nuclear war on stratospheric ozone, using the latest models of the time. However, they found that as a result of the trend towards more numerous but less energetic, sub-megaton range nuclear warheads (made possible by the march to increase ICBM warhead accuracy), the ozone layer danger was \"not very significant\".\nIt was after being confronted with these results that they \"chanced\" upon the notion, as \"an afterthought\" of nuclear detonations igniting massive fires everywhere and, crucially, the smoke from these conventional fires then going on to absorb sunlight, causing surface temperatures to plummet. In early 1982, the two circulated a draft paper with the first suggestions of alterations in short-term climate from fires presumed to occur following a nuclear war. Later in the same year, the special issue of \"Ambio\" devoted to the possible environmental consequences of nuclear war by Crutzen and Birks was titled \"The Atmosphere after a Nuclear War: Twilight at Noon\", and largely anticipated the nuclear winter hypothesis. The paper looked into fires and their climatic effect and discussed particulate matter from large fires, nitrogen oxide, ozone depletion and the effect of nuclear twilight on agriculture. Crutzen and Birks' calculations suggested that smoke particulates injected into the atmosphere by fires in cities, forests and petroleum reserves could prevent up to 99 percent of sunlight from reaching the Earth's surface. This darkness, they said, could exist \"for as long as the fires burned\", which was assumed to be many weeks, with effects such as: \"The normal dynamic and temperature structure of the atmosphere would...change considerably over a large fraction of the Northern Hemisphere, which will probably lead to important changes in land surface temperatures and wind systems.\" An implication of their work was that a successful nuclear decapitation strike could have severe climatic consequences for the perpetrator.\nAfter reading a paper by N. P. Bochkov and E. I. Chazov, published in the same edition of \"Ambio\" that carried Crutzen and Birks's paper \"Twilight at Noon\", Soviet atmospheric scientist Georgy Golitsyn applied his research on Mars dust storms to soot in the Earth's atmosphere. The use of these influential Martian dust storm models in nuclear winter research began in 1971, when the Soviet spacecraft Mars 2 arrived at the red planet and observed a global dust cloud. The orbiting instruments together with the 1971 Mars 3 lander determined that temperatures on the surface of the red planet were considerably colder than temperatures at the top of the dust cloud. Following these observations, Golitsyn received two telegrams from astronomer Carl Sagan, in which Sagan asked Golitsyn to \"explore the understanding and assessment of this phenomenon\". Golitsyn recounts that it was around this time that he had \"proposed a theory to explain how Martian dust may be formed and how it may reach global proportions.\"\nIn the same year Alexander Ginzburg, an employee in Golitsyn's institute, developed a model of dust storms to describe the cooling phenomenon on Mars. Golitsyn felt that his model would be applicable to soot after he read a 1982 Swedish magazine dedicated to the effects of a hypothetical nuclear war between the USSR and the US. Golitsyn would use Ginzburg's largely unmodified dust-cloud model with soot assumed as the aerosol in the model instead of soil dust and in an identical fashion to the results returned, when computing dust-cloud cooling in the Martian atmosphere, the cloud high above the planet would be heated while the planet below would cool drastically. Golitsyn presented his intent to publish this Martian-derived Earth-analog model to the Andropov instigated \"Committee of Soviet Scientists in Defence of Peace Against the Nuclear Threat\" in May 1983, an organization that Golitsyn would later be appointed vice-chairman. The establishment of this committee was done with the expressed approval of the Soviet leadership with the intent \"to expand controlled contacts with Western \"nuclear freeze\" activists\". Having gained this committees approval, in September 1983, Golitsyn published the first computer model on the nascent \"nuclear winter\" effect in the widely read \"Herald of the Russian Academy of Sciences\".\nOn 31 October 1982, Golitsyn and Ginsburg's model and results were presented at the conference on \"The World after Nuclear War\", hosted in Washington, D.C.\nBoth Golitsyn and Sagan had been interested in the cooling on the dust storms on the planet Mars in the years preceding their focus on \"nuclear winter\". Sagan had also worked on Project A119 in the 1950s\u20131960s, in which he attempted to model the movement and longevity of a plume of lunar soil.\nAfter the publication of \"Twilight at Noon\" in 1982, the TTAPS team have said that they began the process of doing a 1-dimensional computational modeling study of the atmospheric consequences of nuclear war/soot in the stratosphere, though they would not publish a paper in \"Science\" magazine until late-December 1983. The phrase \"nuclear winter\" had been coined by Turco just prior to publication. In this early paper, TTAPS used assumption-based estimates on the total smoke and dust emissions that would result from a major nuclear exchange, and with that, began analyzing the subsequent effects on the atmospheric radiation balance and temperature structure as a result of this quantity of assumed smoke. To compute dust and smoke effects, they employed a one-dimensional microphysics/radiative-transfer model of the Earth's lower atmosphere (up to the mesopause), which defined only the vertical characteristics of the global climate perturbation.\nInterest in the environmental effects of nuclear war, however, had continued in the Soviet Union after Golitsyn's September paper, with Vladimir Alexandrov and G. I. Stenchikov also publishing a paper in December 1983 on the climatic consequences, although in contrast to the contemporary TTAPS paper, this paper was based on simulations with a three-dimensional global circulation model. (Two years later Alexandrov disappeared under mysterious circumstances). Richard Turco and Starley L. Thompson were both critical of the Soviet research. Turco called it \"primitive\" and Thompson said it used obsolete US computer models. Later they were to rescind these criticisms and instead applauded Alexandrov's pioneering work, saying that the Soviet model shared the weaknesses of all the others.\nIn 1984, the World Meteorological Organization (WMO) commissioned Golitsyn and N. A. Phillips to review the state of the science. They found that studies generally assumed a scenario where half of the world's nuclear weapons would be used, ~5000 Mt, destroying approximately 1,000 cities, and creating large quantities of carbonaceous smoke \u2013 1\u2013 being most likely, with a range of 0.2\u2013 (NAS; TTAPS assumed ). The smoke resulting would be largely opaque to solar radiation but transparent to infrared, thus cooling the Earth by blocking sunlight, but not creating warming by enhancing the greenhouse effect. The optical depth of the smoke can be much greater than unity. Forest fires resulting from non-urban targets could increase aerosol production further. Dust from near-surface explosions against hardened targets also contributes; each megaton-equivalent explosion could release up to five million tons of dust, but most would quickly fall out; high altitude dust is estimated at 0.1\u20131 million tons per megaton-equivalent of explosion. Burning of crude oil could also contribute substantially.\nThe 1-D radiative-convective models used in these studies produced a range of results, with cooling up to 15\u201342\u00a0\u00b0C between 14 and 35 days after the war, with a \"baseline\" of about 20\u00a0\u00b0C. Somewhat more sophisticated calculations using 3-D GCMs produced similar results: temperature drops of about 20\u00a0\u00b0C, though with regional variations.\nAll calculations show large heating (up to 80\u00a0\u00b0C) at the top of the smoke layer at about ; this implies a substantial modification of the circulation there and the possibility of advection of the cloud into low latitudes and the southern hemisphere.\n1990.\nIn a 1990 paper entitled \"Climate and Smoke: An Appraisal of Nuclear Winter\", TTAPS gave a more detailed description of the short- and long-term atmospheric effects of a nuclear war using a three-dimensional model:\nFirst one to three months:\nFollowing one to three years:\nKuwait wells in the first Gulf War.\nOne of the major results of TTAPS' 1990 paper was the re-iteration of the team's 1983 model that 100 oil refinery fires would be sufficient to bring about a small scale, but still globally deleterious nuclear winter.\nFollowing Iraq's invasion of Kuwait and Iraqi threats of igniting the country's approximately 800 oil wells, speculation on the cumulative climatic effect of this, presented at the World Climate Conference in Geneva that November in 1990, ranged from a nuclear winter type scenario, to heavy acid rain and even short term immediate global warming.\nIn articles printed in the \"Wilmington Morning Star\" and the \"Baltimore Sun\" newspapers in January 1991, prominent authors of nuclear winter papers \u2013 Richard P. Turco, John W. Birks, Carl Sagan, Alan Robock and Paul Crutzen \u2013 collectively stated that they expected catastrophic nuclear winter like effects with continental-sized effects of sub-freezing temperatures as a result of the Iraqis going through with their threats of igniting 300 to 500 pressurized oil wells that could subsequently burn for several months.\nAs threatened, the wells were set on fire by the retreating Iraqis in March 1991, and the 600 or so burning oil wells were not fully extinguished until November 6, 1991, eight months after the end of the war, and they consumed an estimated six million barrels of oil per day at their peak intensity.\nWhen Operation Desert Storm began in January 1991, coinciding with the first few oil fires being lit, Dr. S. Fred Singer and Carl Sagan discussed the possible environmental effects of the Kuwaiti petroleum fires on the ABC News program \"Nightline\". Sagan again argued that some of the effects of the smoke could be similar to the effects of a nuclear winter, with smoke lofting into the stratosphere, beginning around above sea level in Kuwait, resulting in global effects. He also argued that he believed the net effects would be very similar to the 1815 eruption of Mount Tambora in Indonesia, which resulted in the year 1816 being known as the \"Year Without a Summer\".\nSagan listed modeling outcomes that forecast effects extending to South Asia, and perhaps to the Northern Hemisphere as well. Sagan stressed this outcome was so likely that \"It should affect the war plans.\" Singer, on the other hand, anticipated that the smoke would go to an altitude of about and then be rained out after about three to five days, thus limiting the lifetime of the smoke. Both height estimates made by Singer and Sagan turned out to be wrong, albeit with Singer's narrative being closer to what transpired, with the comparatively minimal atmospheric effects remaining limited to the Persian Gulf region, with smoke plumes, in general, lofting to about and a few as high as .\nSagan and his colleagues expected that a \"self-lofting\" of the sooty smoke would occur when it absorbed the sun's heat radiation, with little to no scavenging occurring, whereby the black particles of soot would be heated by the sun and lifted/lofted higher and higher into the air, thereby injecting the soot into the stratosphere, a position where they argued it would take years for the sun-blocking effect of this aerosol of soot to fall out of the air, and with that, catastrophic ground level cooling and agricultural effects in Asia and possibly the Northern Hemisphere as a whole. In a 1992 follow-up, Peter V. Hobbs and others had observed no appreciable evidence for the nuclear winter team's predicted massive \"self-lofting\" effect and the oil-fire smoke clouds contained less soot than the nuclear winter modelling team had assumed.\nThe atmospheric scientist tasked with studying the atmospheric effect of the Kuwaiti fires by the National Science Foundation, Peter V. Hobbs, stated that the fires' modest impact suggested that \"some numbers [used to support the Nuclear Winter hypothesis]... were probably a little overblown.\"\nHobbs found that at the peak of the fires, the smoke absorbed 75 to 80% of the sun's radiation. The particles rose to a maximum of , and when combined with scavenging by clouds the smoke had a short residency time of a maximum of a few days in the atmosphere.\nPre-war claims of wide scale, long-lasting, and significant global environmental effects were thus not borne out, and found to be significantly exaggerated by the media and speculators, with climate models by those not supporting the nuclear winter hypothesis at the time of the fires predicting only more localized effects such as a daytime temperature drop of ~10\u00a0\u00b0C within 200\u00a0km of the source.\nSagan later conceded in his book \"The Demon-Haunted World\" that his predictions obviously did not turn out to be correct: \"it \"was\" pitch black at noon and temperatures dropped 4\u20136\u00a0\u00b0C over the Persian Gulf, but not much smoke reached stratospheric altitudes and Asia was spared.\"\nThe idea of oil well and oil reserve smoke pluming into the stratosphere serving as a main contributor to the soot of a nuclear winter was a central idea of the early climatology papers on the hypothesis; they were considered more of a possible contributor than smoke from cities, as the smoke from oil has a higher ratio of black soot, thus absorbing more sunlight. Hobbs compared the papers' assumed \"emission factor\" or soot generating efficiency from ignited oil pools and found, upon comparing to measured values from oil pools at Kuwait, which were the greatest soot producers, the emissions of soot assumed in the nuclear winter calculations were still \"too high\". Following the results of the Kuwaiti oil fires being in disagreement with the core nuclear winter promoting scientists, 1990s nuclear winter papers generally attempted to distance themselves from suggesting oil well and reserve smoke will reach the stratosphere.\nIn 2007, a nuclear winter study noted that modern computer models have been applied to the Kuwait oil fires, finding that individual smoke plumes are not able to loft smoke into the stratosphere, but that smoke from fires covering a large area, like some forest fires, can lift smoke into the stratosphere, and recent evidence suggests that this occurs far more often than previously thought. The study also suggested that the burning of the comparably smaller cities, which would be expected to follow a nuclear strike, would also loft significant amounts of smoke into the stratosphere:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nHowever, the above simulation notably contained the assumption that no dry or wet deposition would occur.\nRecent modeling.\nBetween 1990 and 2003, commentators noted that no peer-reviewed papers on \"nuclear winter\" were published.\nBased on new work published in 2007 and 2008 by some of the authors of the original studies, several new hypotheses have been put forth, primarily the assessment that as few as 100 firestorms would result in a nuclear winter. However, far from the hypothesis being \"new\", it drew the same conclusion as earlier 1980s models, which similarly regarded 100 or so city firestorms as a threat.\nCompared to climate change for the past millennium, even the smallest exchange modeled would plunge the planet into temperatures colder than the Little Ice Age (the period of history between approximately 1600 and 1850 AD). This would take effect instantly, and agriculture would be severely threatened. Larger amounts of smoke would produce larger climate changes, making agriculture impossible for years. In both cases, new climate model simulations show that the effects would last for more than a decade.\n2007 study on global nuclear war.\nA study published in the \"Journal of Geophysical Research\" in July 2007, titled \"Nuclear winter revisited with a modern climate model and current nuclear arsenals: Still catastrophic consequences\", used current climate models to look at the consequences of a global nuclear war involving most or all of the world's current nuclear arsenals (which the authors judged to be one similar to the size of the world's arsenals twenty years earlier). The authors used a global circulation model, ModelE from the NASA Goddard Institute for Space Studies, which they noted \"has been tested extensively in global warming experiments and to examine the effects of volcanic eruptions on climate\". The model was used to investigate the effects of a war involving the entire current global nuclear arsenal, projected to release about 150 Tg of smoke into the atmosphere, as well as a war involving about one third of the current nuclear arsenal, projected to release about 50 Tg of smoke. In the 150 Tg case they found that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;A global average surface cooling of \u22127 \u00b0C to \u22128 \u00b0C persists for years, and after a decade the cooling is still \u22124 \u00b0C (Fig. 2). Considering that the global average cooling at the depth of the last ice age 18,000 yr ago was about \u22125 \u00b0C, this would be a climate change unprecedented in speed and amplitude in the history of the human race. The temperature changes are largest over land ... Cooling of more than \u221220 \u00b0C occurs over large areas of North America and of more than \u221230 \u00b0C over much of Eurasia, including all agricultural regions.\nIn addition, they found that this cooling caused a weakening of the global hydrological cycle, reducing global precipitation by about 45%. As for the 50 Tg case involving one third of current nuclear arsenals, they said that the simulation \"produced climate responses very similar to those for the 150 Tg case, but with about half the amplitude,\" but that \"the time scale of response is about the same\". They did not discuss the implications for agriculture in depth, but noted that a 1986 study which assumed no food production for a year projected that \"most of the people on the planet would run out of food and starve to death by then\" and commented that their own results show that, \"This period of no food production needs to be extended by many years, making the impacts of nuclear winter even worse than previously thought.\"\n2014.\nIn 2014, Michael J. Mills (at the US National Center for Atmospheric Research, NCAR), et al., published \"Multi-decadal global cooling and unprecedented ozone loss following a regional nuclear conflict\" in the journal \"Earth's Future\". The authors used computational models developed by NCAR to simulate the climatic effects of a soot cloud that they suggest would be a result of a regional nuclear war in which 100 \"small\" (15 Kt) weapons are detonated over cities. The model had outputs, due to the interaction of the soot cloud:\n...global ozone losses of 20\u201350% over populated areas, levels unprecedented in human history, would accompany the coldest average surface temperatures in the last 1000 years. We calculate summer enhancements in UV indices of 30\u201380% over Mid-Latitudes, suggesting widespread damage to human health, agriculture, and terrestrial and aquatic ecosystems. Killing frosts would reduce growing seasons by 10\u201340 days per year for 5 years. Surface temperatures would be reduced for more than 25 years, due to thermal inertia and albedo effects in the ocean and expanded sea ice. The combined cooling and enhanced UV would put significant pressures on global food supplies and could trigger a global nuclear famine.\n2018.\nResearchers at Los Alamos National Laboratory published the results of a multi-scale study of the climate impact of a regional nuclear exchange, the same scenario considered by Robock et al. and by Toon et al. in 2007. Unlike previous studies, this study simulated the processes whereby black carbon would be lofted into the atmosphere and found that very little would be lofted into the stratosphere and, as a result, the long-term climate impacts were much lower than those studies had concluded. In particular, \"none of the simulations produced a nuclear winter effect\", and \"the probability of significant global cooling from a limited exchange scenario as envisioned in previous studies is highly unlikely\". This study has been contradicted by results in several subsequent studies claiming the 2018 study to be flawed.\nResearch published in the peer-reviewed journal \"Safety\" suggested that no nation should possess more than 100 nuclear warheads because of the blowback effect on the aggressor nation's own population because of \"nuclear autumn\".\n2019.\n2019 saw the publication of two studies on nuclear winter that build on previous modeling and describe new scenarios of nuclear winter from smaller exchanges of nuclear weapons than have been previously simulated.\nAs in the 2007 study by Robock \"et al.\", a 2019 study by Coupe \"et al.\" models a scenario in which 150 Tg of black carbon is released into the atmosphere following an exchange of nuclear weapons between the United States and Russia where both countries use all of the nuclear weapons treaties permit them to. This amount of black carbon far exceeds that which has been emitted in the atmosphere by all volcanic eruptions in the past 1,200 years but is less than the asteroid impact which caused a mass extinction event 66 million years ago. Coupe \"et al.\" used the \"whole atmosphere community climate model version 4\" (WACCM4), which has a higher resolution and is more effective at simulating aerosols and stratospheric chemistry than the ModelE simulation used by Robock \"et al\".\nThe WACCM4 model simulates that black carbon molecules increase to ten times their normal size when they reach the stratosphere. ModelE did not account for this effect. This difference in black carbon particle size results in a greater optical depth in the WACCM4 model across the world for the first two years after the initial injection due to greater absorption of sunlight in the stratosphere. This will have the effect of increasing stratospheric temperatures by 100K and result in ozone depletion that is slightly greater than ModelE predicted. Another consequence of the larger particle size is accelerating the rate at which black carbon molecules fall out of the atmosphere; after ten years from the injection of black carbon into the atmosphere, WACCM4 predicts 2 Tg will remain, while ModelE predicted 19 Tg.\nThe 2019 model and the 2007 model both predict significant temperature decreases across the globe, however the increased resolution and particle simulation in 2019 predict a greater temperature anomaly in the first six years after injection but a faster return to normal temperatures. Between a few months after the injection to the sixth year of anomaly, the WACCM4 predicts cooler global temperatures than ModelE, with temperatures more than 20K below normal leading to freezing temperatures during the summer months over much of the northern hemisphere leading to a 90% reduction in agricultural growing seasons in the midlatitudes, including the midwestern United States. WACCM4 simulations also predict a 58% reduction in global annual precipitation from normal levels in years three and four after injection, a 10% higher reduction than predicted in ModelE.\nToon \"et al.\" simulated a nuclear scenario in 2025 where India and Pakistan engage in a nuclear exchange in which 100 urban areas in Pakistan and 150 urban areas in India are attacked with nuclear weapons ranging from 15 kt to 100 kt and examined the effects of black carbon released into the atmosphere from airburst-only detonations. The researchers modeled the atmospheric effects if all weapons were 15 kt, 50 kt, and 100 kt, providing a range where a nuclear exchange would likely fall into given the recent nuclear tests performed by both nations. The ranges provided are large because neither India nor Pakistan is obligated to provide information on their nuclear arsenals, so their extent remains largely unknown.\nToon \"et al.\" assume that either a firestorm or conflagration will occur after each detonation of the weapons, and the amount of black carbon inserted into the atmosphere from the two outcomes will be equivalent and of a profound extent; in Hiroshima in 1945, it is predicted that the firestorm released 1,000 times more energy than was released during the nuclear explosion. Such a large area being burned would release large amounts of black carbon into the atmosphere. The amount released ranges from 16.1 Tg if all weapons were 15 kt or less to 36.6 Tg for all 100 kt weapons. For the 15 kt and 100kt range of weapons, the researchers modeled global precipitation reductions of 15% to 30%, temperature reductions between 4K and 8K, and ocean temperature decreases of 1K to 3K. If all weapons used were 50 kt or more, Hadley cell circulation would be disrupted and cause a 50% decrease in precipitation in the American midwest. Net primary productivity (NPP) for oceans decreases from 10% to 20% for the 15 kt and 100 kt scenarios, respectively, while land NPP decreases between 15% and 30%; particularly affected are midlatitude agricultural regions in the United States and Europe, experiencing 25-50% reductions in NPP. As predicted by other literature, once the black carbon is removed from the atmosphere after ten years, temperatures and NPP will return to normal.\n2021.\nCoupe et al. report the simulation of a El Ni\u00f1o effect lasting several years after six nuclear scenarios ranging from 5 to 150 Tg soot under the CESM-WACCM4 model. They term the change a \"Nuclear Ni\u00f1o\" and describe various changes in the ocean currents.\n2022.\nAccording to a peer-reviewed study published in the journal \"Nature Food\" in August 2022, a full-scale nuclear war between the United States and Russia, which together hold more than 90% of the world's nuclear weapons, would kill 360 million people directly and more than 5 billion indirectly by starvation during a nuclear winter.\nAnother paper published that year, from the Tohoku University Earth science scholar Kunio Kaiho, compared the impact of nuclear winter scenarios on marine and terrestrial animal life with that of historical extinction events. Kaiho estimated that a \"minor\" nuclear war (which he defined as a nuclear exchange between India and Pakistan or an event of equivalent magnitude) would cause extinctions of 10\u201320% of species on its own, while a \"major\" nuclear war (defined as a nuclear exchange between United States and Russia) would cause the extinctions of 40\u201350% of animal species, which is comparable to some of the \"Big Five\" mass extinction events. For comparison, what he considered the most likely scenario of anthropogenic climate change, with of warming by 2100 and by 2500, would send around 12\u201314% of animal species extinct under the same methodology.\n2023.\nSince 2023, the U.S. National Academies of Science, Engineering, and Medicine has established an Independent Study on Potential Environmental Effects of Nuclear War. The aim is to evaluate all research on nuclear winter, and the final report was planned for a 2024 release date.\nAs of 2025,[ [update]] the committee was still working on the report.\"Past Events\"\n2025 study - Impact on global agriculture.\nIn 2025, researchers at Pennsylvania State University used the Cycles agroecosystem model to simulate how a nuclear winter could impact global corn yields (\"Zea mays\"), treating corn as a proxy for global staple crops. The study modeled production across 38,572 locations under six scenarios of soot injection into the upper atmosphere, ranging from about 5 million to 165 million tonnes.\nA regional nuclear war (~5.5 Mt soot) could reduce worldwide corn production by about 7%, while a full-scale global conflict (~165 Mt soot) might cut yields by around 80%.\nThe researchers also estimated that ozone depletion following a large-scale conflict would increase ultraviolet-B radiation, peaking six to eight years later, causing an additional ~7 % decline in corn yields. In the worst-case scenario, this would bring the total reduction to roughly 87%.\nGlobal agricultural recovery was projected to take between seven and twelve years, depending on the severity of the conflict and location, with longer delays at higher latitudes. To help mitigate such impacts, the authors suggested \"agricultural resilience kits,\" containing seeds of fast-growing, cold-tolerant crops suited to different regions.\nCriticism and debate.\nThe five major and largely independent underpinnings that the nuclear winter concept has and continues to receive criticism over are regarded as:\nWhile the highly popularized initial 1983 TTAPS 1-dimensional model forecasts were widely reported and criticized in the media, in part because every later model predicts far less of its \"apocalyptic\" level of cooling, most models continue to suggest that some deleterious global cooling would still result, under the assumption that a large number of fires occurred in the spring or summer. Starley L. Thompson's less primitive mid-1980s 3-dimensional model, which notably contained the very same general assumptions, led him to coin the term \"nuclear autumn\" to more accurately describe the climate results of the soot in this model, in an on camera interview in which he dismisses the earlier \"apocalyptic\" models.\nA major criticism of the assumptions that continue to make these model results possible appeared in the 1987 book \"Nuclear War Survival Skills\" (\"NWSS\"), a civil defense manual by Cresson Kearny for the Oak Ridge National Laboratory. According to the 1988 publication \"An assessment of global atmospheric effects of a major nuclear war\", Kearny's criticisms were directed at the excessive amount of soot that the modelers assumed would reach the stratosphere. Kearny cited a Soviet study that modern cities would not burn as firestorms, as most flammable city items would be buried under non-combustible rubble and that the TTAPS study included a massive overestimate on the size and extent of non-urban wildfires that would result from a nuclear war. The TTAPS authors responded that, amongst other things, they did not believe target planners would intentionally blast cities into rubble, but instead argued fires would begin in relatively undamaged suburbs when nearby sites were hit, and partially conceded his point about non-urban wildfires. Dr. Richard D. Small, director of thermal sciences at the Pacific-Sierra Research Corporation similarly disagreed strongly with the model assumptions, in particular the 1990 update by TTAPS that argues that some 5,075 Tg of material would burn in a total US-Soviet nuclear war, as analysis by Small of blueprints and real buildings returned a maximum of 1,475 Tg of material that could be burned, \"assuming that all the available combustible material was actually ignited\".\nAlthough Kearny was of the opinion that future more accurate models would, \"indicate there will be even smaller reductions in temperature\", including future potential models that did not so readily accept that firestorms would occur as dependably as nuclear winter modellers assume, in \"NWSS\" Kearny summarized the comparatively moderate cooling estimate of no more than a few days, from the 1986 \"Nuclear Winter Reappraised\" model by Starley Thompson and Stephen Schneider. This was done in an effort to convey to his readers that contrary to the popular opinion at the time, in the conclusion of these two climate scientists, \"on scientific grounds the global apocalyptic conclusions of the initial nuclear winter hypothesis can now be relegated to a vanishing low level of probability\".\nHowever, a 1988 article by Brian Martin in \"Science and Public Policy\" states that\u2014although \"Nuclear Winter Reappraised\" concluded the US-Soviet \"nuclear winter\" would be much less severe than originally thought, with the authors describing the effects more as a \"nuclear autumn\"\u2014other statements by Thompson and Schneider show that they, \"resisted the interpretation that this means a rejection of the basic points made about nuclear winter\". In the Alan Robock et al. 2007 paper, they write that, \"because of the use of the term 'nuclear autumn' by Thompson and Schneider [1986], even though the authors made clear that the climatic consequences would be large, in policy circles the theory of nuclear winter is considered by some to have been exaggerated and disproved [e.g., Martin, 1988].\" In 2007 Schneider expressed his tentative support for the cooling results of the limited nuclear war (Pakistan and India) analyzed in the 2006 model, saying, \"The sun is much stronger in the tropics than it is in mid-latitudes. Therefore, a much more limited war [there] could have a much larger effect, because you are putting the smoke in the worst possible place\", and \"anything that you can do to discourage people from thinking that there is any way to win anything with a nuclear exchange is a good idea\".\nThe contribution of smoke from the ignition of live non-desert vegetation, living forests, grasses and so on, nearby to many missile silos is a source of smoke originally assumed to be very large in the initial \"Twilight at Noon\" paper, and also found in the popular TTAPS publication. However, this assumption was examined by Bush and Small in 1987 and they found that the burning of live vegetation could only conceivably contribute very slightly to the estimated total \"nonurban smoke production\". With the vegetation's potential to sustain burning only probable if it is within a radius or two from the surface of the nuclear fireball, which is at a distance that would also experience extreme blast winds that would influence any such fires. This reduction in the estimate of the non-urban smoke hazard is supported by the earlier preliminary \"Estimating Nuclear Forest Fires\" publication of 1984, and by the 1950\u20131960s in-field examination of surface-scorched, mangled but never burnt-down tropical forests on the surrounding islands from the shot points in the Operation Castle and Operation Redwing test series.\nA paper by the United States Department of Homeland Security, finalized in 2010, states that after a nuclear detonation targeting a city \"If fires are able to grow and coalesce, a firestorm could develop that would be beyond the abilities of firefighters to control. However experts suggest in the nature of modern US city design and construction may make a raging firestorm unlikely\". The nuclear bombing of Nagasaki for example, did not produce a firestorm. This was similarly noted as early as 1986\u20131988, when the assumed quantity of fuel \"mass loading\" (the amount of fuel per square meter) in cities underpinning the winter models was found to be too high and intentionally creates heat fluxes that loft smoke into the lower stratosphere, yet assessments \"more characteristic of conditions\" to be found in real-world modern cities, had found that the fuel loading, and hence the heat flux that would result from efficient burning, would rarely loft smoke much higher than 4\u00a0km.\nRussell Seitz, Associate of the Harvard University Center for International Affairs, argues that the winter models' assumptions give results which the researchers want to achieve and is a case of \"worst-case analysis run amok\". In September 1986, Seitz published \"Siberian fire as 'nuclear winter' guide\" in the journal \"Nature\", in which he investigated the 1915 Siberian fire, which started in the early summer months and was caused by the worst drought in the region's recorded history. The fire ultimately devastated the region, burning the world's largest boreal forest, the size of Germany. While approximately 8\u02daC of daytime summer cooling occurred under the smoke clouds during the weeks of burning, no increase in potentially devastating agricultural night frosts occurred. Following his investigation into the Siberian fire of 1915, Seitz criticized the \"nuclear winter\" model results for being based on successive worst-case events:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nSeitz cited Carl Sagan, adding an emphasis: \"\"In almost any realistic case\" involving nuclear exchanges between the superpowers, global environmental changes sufficient to cause an extinction event equal to or more severe than that of the close of the Cretaceous when the dinosaurs and many other species died out are likely.\" Seitz comments: \"The ominous rhetoric italicized in this passage puts even the 100 megaton [the original 100 city firestorm] scenario ... on a par with the 100 million megaton blast of an asteroid striking the Earth. This [is] astronomical mega-hype ...\" Seitz concludes:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;As the science progressed and more authentic sophistication was achieved in newer and more elegant models, the postulated effects headed downhill. By 1986, these worst-case effects had melted down from a year of arctic darkness to warmer temperatures than the cool months in Palm Beach! A new paradigm of broken clouds and cool spots had emerged. The once global hard frost had retreated back to the northern tundra. Mr. Sagan's elaborate conjecture had fallen prey to Murphy's lesser-known Second Law: If everything MUST go wrong, don't bet on it.\nSeitz's opposition caused the proponents of nuclear winter to issue responses in the media. The proponents believed it was simply necessary to show only the possibility of climatic catastrophe, often a worst-case scenario, while opponents insisted that to be taken seriously, nuclear winter should be shown as likely under \"reasonable\" scenarios. One of these areas of contention, as elucidated by Lynn R. Anspaugh, is upon the question of which season should be used as the backdrop for the US-USSR war models. Most models choose the summer in the Northern Hemisphere as the start point to produce the maximum soot lofting and therefore eventual winter effect. However, it has been pointed out that if the same number of firestorms occurred in the autumn or winter months, when there is much less intense sunlight to loft soot into a stable region of the stratosphere, the magnitude of the cooling effect would be negligible, according to a January model run by Covey et al. Schneider conceded the issue in 1990, saying \"a war in late fall or winter would have no appreciable [cooling] effect\".\nAnspaugh also expressed frustration that although a managed forest fire in Canada on 3 August 1985 is said to have been lit by proponents of nuclear winter, with the fire potentially serving as an opportunity to do some basic measurements of the optical properties of the smoke and smoke-to-fuel ratio, which would have helped refine the estimates of these critical model inputs, the proponents did not indicate that any such measurements were made. Peter V. Hobbs, who would later successfully attain funding to fly into and sample the smoke clouds from the Kuwait oil fires in 1991, also expressed frustration that he was denied funding to sample the Canadian, and other forest fires in this way. Turco wrote a 10-page memorandum with information derived from his notes and some satellite images, claiming that the smoke plume reached 6\u00a0km in altitude.\nIn 1986, atmospheric scientist Joyce Penner from the Lawrence Livermore National Laboratory published an article in \"Nature\" in which she focused on the specific variables of the smoke's optical properties and the quantity of smoke remaining airborne after the city fires. She found that the published estimates of these variables varied so widely that depending on which estimates were chosen the climate effect could be negligible, minor or massive. The assumed optical properties for black carbon in more recent nuclear winter papers in 2006 are still \"based on those assumed in earlier nuclear winter simulations\".\nJohn Maddox, editor of the journal \"Nature\", issued a series of skeptical comments about nuclear winter studies during his tenure. Similarly S. Fred Singer was a long term vocal critic of the hypothesis in the journal and in televised debates with Carl Sagan.\nCritical response to the more modern papers.\nIn a 2011 response to the more modern papers on the hypothesis, Russell Seitz published a comment in \"Nature\" challenging Alan Robock's claim that there has been no real scientific debate about the \"nuclear winter\" concept. In 1986 Seitz also contends that many others are reluctant to speak out for fear of being stigmatized as \"closet Dr. Strangeloves\"; physicist Freeman Dyson of Princeton for example stated \"It's an absolutely atrocious piece of science, but I quite despair of setting the public record straight.\" According to the Rocky Mountain News, Stephen Schneider had been called a fascist by some disarmament supporters for having written his 1986 article \"Nuclear Winter Reappraised.\" MIT meteorologist Kerry Emanuel similarly wrote in a review in \"Nature\" that the winter concept is \"notorious for its lack of scientific integrity\" due to the unrealistic estimates selected for the quantity of fuel likely to burn, the imprecise global circulation models used. Emanuel ends by stating that the evidence of other models point to substantial scavenging of the smoke by rain. Emanuel also made an \"interesting point\" about questioning proponents' objectivity when it came to strong emotional or political views that they hold.\nWilliam R. Cotton, Professor of Atmospheric Science at Colorado State University, specialist in cloud physics modeling and co-creator of the highly influential and previously mentioned RAMS atmosphere model, had in the 1980s worked on soot rain-out models and supported the predictions made by his own and other nuclear winter models. However, he has since reversed this position, according to a book co-authored by him in 2007, stating that, amongst other systematically examined assumptions, far more rain out/wet deposition of soot will occur than is assumed in modern papers on the subject: \"We must wait for a new generation of GCMs to be implemented to examine potential consequences quantitatively\". He also states that, in his view, \"nuclear winter was largely politically motivated from the beginning\".\nPolicy implications.\nDuring the Cuban Missile Crisis, Fidel Castro and Che Guevara called on the USSR to launch a nuclear first strike against the US in the event of a US invasion of Cuba. In the 1980s, Castro was pressuring the Kremlin to adopt a harder line against the US under President Ronald Reagan, even arguing for the potential use of nuclear weapons. As a direct result of this, a Soviet official was dispatched to Cuba in 1985 with an entourage of \"experts\", who detailed the ecological effect on Cuba in the event of nuclear strikes on the United States. Soon after, the Soviet official recounts, Castro lost his prior \"nuclear fever\". In 2010, Alan Robock was summoned to Cuba to help Castro promote his new view that nuclear war would bring about Armageddon. Robock's 90 minute lecture was later aired on the nationwide state-controlled television station in the country.\nHowever, according to Robock, insofar as getting US government attention and affecting nuclear policy, he has failed. In 2009, together with Owen Toon, he gave a talk to the United States Congress, but nothing transpired from it and the then-presidential science adviser, John Holdren, did not respond to their requests in 2009 or at the time of writing in 2011.\nIn a 2012 \"Bulletin of the Atomic Scientists\" feature, Robock and Toon, who had routinely mixed their disarmament advocacy into the conclusions of their \"nuclear winter\" papers, argue in the political realm that the hypothetical effects of nuclear winter necessitates that the doctrine they assume is active in Russia and US, \"mutually assured destruction\" (MAD), should instead be replaced with their own \"self-assured destruction\" (SAD) concept, because, regardless of whose cities burned, the effects of the resultant nuclear winter that they advocate would be, in their view, catastrophic. In a similar vein, in 1989 Carl Sagan and Richard Turco wrote a policy implications paper that appeared in \"Ambio\" that suggested that as nuclear winter is a \"well-established prospect\", both superpowers should jointly reduce their nuclear arsenals to \"Canonical Deterrent Force\" levels of 100\u2013300 individual warheads each, such that in \"the event of nuclear war [this] would minimize the likelihood of [extreme] nuclear winter.\"\nAn originally classified 1984 US interagency intelligence assessment states that in both the preceding 1970s and 1980s, the Soviet and US military were already following the \"existing trends\" in warhead miniaturization, of higher accuracy and lower yield nuclear warheads. This is seen when assessing the most numerous physics packages in the US arsenal, which in the 1960s were the B28 and W31, however, both quickly became less prominent with the 1970s mass production runs of the 50 Kt W68, the 100 Kt W76 and in the 1980s, with the B61. This trend towards miniaturization, enabled by advances in inertial guidance and accurate GPS navigation etc., was motivated by a multitude of factors, namely the desire to leverage the physics of equivalent megatonnage that miniaturization offered; of freeing up space to fit more MIRV warheads and decoys on each missile. Alongside the desire to still destroy hardened targets but while reducing the severity of fallout collateral damage depositing on neighboring, and potentially friendly, countries. As it relates to the likelihood of nuclear winter, the range of potential thermal radiation ignited fires was already reduced with miniaturization. For example, the most popular nuclear winter paper, the 1983 TTAPS paper, had described a 3000 Mt counterforce attack on ICBM sites with each individual warhead having approximately one Mt of energy; however not long after publication, Michael Altfeld of Michigan State University and political scientist Stephen Cimbala of Pennsylvania State University argued that the then already developed and deployed smaller, more accurate warheads (e.g. W76), together with lower detonation heights, could produce the same counterforce strike with a total of only 3 Mt of energy being expended. They continue that, \"if\" the nuclear winter models prove to be representative of reality, then far less climatic-cooling would occur, even if firestorm prone areas existed in the target list, as lower fusing heights such as surface bursts would also limit the range of the burning thermal rays due to terrain masking and shadows cast by buildings, while also temporarily lofting far more localized fallout when compared to airburst fuzing \u2013 the standard mode of employment against un-hardened targets. This logic is similarly reflected in the originally classified 1984 \"Interagency Intelligence assessment\", which suggests that targeting planners would simply have to consider target combustibility along with yield, height of burst, timing and other factors to reduce the amount of smoke to safeguard against the potentiality of a nuclear winter. Therefore, as a consequence of attempting to limit the target fire hazard by reducing the range of thermal radiation with fuzing for surface and sub-surface bursts, this will result in a scenario where the far more concentrated, and therefore deadlier, \"local\" fallout that is generated following a surface burst forms, as opposed to the comparatively dilute \"global\" fallout created when nuclear weapons are fuzed in air burst mode.\nAltfeld and Cimbala also argued that belief in the possibility of nuclear winter would actually make nuclear war more likely, contrary to the views of Sagan and others, because it would serve yet further motivation to follow the \"existing trends\", towards the development of more accurate, and even lower explosive yield, nuclear weapons. As the winter hypothesis suggests that the replacement of the then Cold War viewed strategic nuclear weapons in the multi-megaton yield range, with weapons of explosive yields closer to tactical nuclear weapons, such as the Robust Nuclear Earth Penetrator (RNEP), would safeguard against the nuclear winter potential. With the latter capabilities of the then, largely still conceptual RNEP, specifically cited by the influential nuclear warfare analyst Albert Wohlstetter. Tactical nuclear weapons, on the low end of the scale have yields that overlap with large conventional weapons and are therefore often viewed \"as blurring the distinction between conventional and nuclear weapons\", making the prospect of using them \"easier\" in a conflict.\nAlleged Soviet exploitation.\nIn an interview in 2000 with Mikhail Gorbachev (the leader of the Soviet Union from 1985 to 1991), the following statement was posed to him: \"In the 1980s, you warned about the unprecedented dangers of nuclear weapons and took very daring steps to reverse the arms race\", with Gorbachev replying \"Models made by Russian and American scientists showed that a nuclear war would result in a nuclear winter that would be extremely destructive to all life on Earth; the knowledge of that was a great stimulus to us, to people of honor and morality, to act in that situation.\"\nHowever, a 1984 US Interagency Intelligence Assessment expresses a far more skeptical and cautious approach, stating that the hypothesis is not scientifically convincing. The report predicted that Soviet nuclear policy would be to maintain their strategic nuclear posture, such as their fielding of the high throw-weight SS-18 missile and they would merely attempt to exploit the hypothesis for propaganda purposes, such as directing scrutiny on the US portion of the nuclear arms race. Moreover, it goes on to express the belief that if Soviet officials did begin to take nuclear winter seriously, it would probably make them demand exceptionally high standards of scientific proof for the hypothesis, as the implications of it would undermine their military doctrine \u2013 a level of scientific proof which perhaps could not be met without field experimentation. The un-redacted portion of the document ends with the suggestion that substantial increases in Soviet Civil defense food stockpiles might be an early indicator that Nuclear Winter was beginning to influence Soviet upper echelon thinking.\nIn 1985, \"Time\" magazine noted \"the suspicions of some Western scientists that the nuclear winter hypothesis was promoted by Moscow to give anti-nuclear groups in the U.S. and Europe some fresh ammunition against America's arms buildup.\" In 1985, the United States Senate met to discuss the science and politics of nuclear winter. During the congressional hearing, the influential analyst Leon Gour\u00e9 presented evidence that perhaps the Soviets have simply echoed Western reports rather than producing unique findings. Gour\u00e9 hypothesized that Soviet research and discussions of nuclear war may serve only Soviet political agendas, rather than to reflect actual opinions of Soviet leadership.\nIn 1986, the Defense Nuclear Agency document \"An update of Soviet research on and exploitation of Nuclear winter 1984\u20131986\" charted the minimal [public domain] research contribution on, and Soviet propaganda usage of, the nuclear winter phenomenon.\nThere is some doubt as to when the Soviet Union began modelling fires and the atmospheric effects of nuclear war. Former Soviet intelligence officer Sergei Tretyakov claimed that, under the directions of Yuri Andropov, the KGB invented the concept of \"nuclear winter\" in order to stop the deployment of NATO Pershing II missiles. They are said to have distributed to peace groups, the environmental movement and the journal \"Ambio\" disinformation based on a faked \"doomsday report\" by the Soviet Academy of Sciences by Georgii Golitsyn, Nikita Moiseyev and Vladimir Alexandrov concerning the climatic effects of nuclear war. Although it is accepted that the Soviet Union exploited the nuclear winter hypothesis for propaganda purposes, Tretyakov's inherent claim that the KGB funnelled disinformation to \"Ambio\", the journal in which Paul Crutzen and John Birks published the 1982 paper \"Twilight at Noon\", has not been corroborated as of 2009[ [update]]. In an interview in 2009 conducted by the National Security Archive, Vitalii Nikolaevich Tsygichko (a Senior Analyst at the Soviet Academy of Sciences and military mathematical modeler) stated that Soviet military analysts were discussing the idea of \"nuclear winter\" years before U.S. scientists, although they did not use that exact term.\nMitigation techniques.\nA number of solutions have been proposed to mitigate the potential harm of a nuclear winter if one appears inevitable. The problem has been attacked at both ends; some solutions focus on preventing the growth of fires and therefore limiting the amount of smoke that reaches the stratosphere in the first place, and others focus on food production with reduced sunlight, with the assumption that the very worst-case analysis results of the nuclear winter models prove accurate and no other mitigation strategies are fielded.\nFire control.\nIn a report from 1967, techniques included various methods of applying liquid nitrogen, dry ice, and water to nuclear-caused fires. The report considered attempting to stop the spread of fires by creating firebreaks by blasting combustible material out of an area, possibly even using nuclear weapons, along with the use of preventative Hazard Reduction Burns. According to the report, one of the most promising techniques investigated was initiation of rain from seeding of mass-fire thunderheads and other clouds passing over the developing, and then stable, firestorm.\nProducing food without sunlight.\nIn the book \"Feeding Everyone No Matter What\", under the worst-case scenario predictions of nuclear winter, the authors present various unconventional food possibilities. These include natural-gas-digesting bacteria, the most well known being \"Methylococcus capsulatus\", that is presently used as a feed in fish farming; bark bread, a long-standing famine food using the edible inner bark of trees, and part of Scandinavian history during the Little Ice Age; increased fungiculture or mushrooms such as the honey fungi that grow directly on moist wood without sunlight; and variations of wood or cellulosic biofuel production, which typically already creates edible sugars/xylitol from inedible cellulose, as an intermediate product before the final step of alcohol generation. One of the book's authors, mechanical engineer David Denkenberger, states that mushrooms could theoretically feed everyone for three years. Seaweed, like mushrooms, can also grow in low-light conditions. Dandelions and tree needles could provide Vitamin C, and bacteria could provide Vitamin E. More conventional cold-weather crops such as potatoes might get sufficient sunlight at the equator to remain feasible.\nLarge-scale food stockpiling.\nTo feed portions of civilization through a nuclear winter, large stockpiles of food storage prior to the event would have to be accomplished. Such stockpiles should be placed underground, at higher elevations and near the equator to mitigate high altitude UV and radioactive isotopes. Stockpiles should also be placed near populations most likely to survive the initial catastrophe. One consideration is who would sponsor the stockpiling. \"There may be a mismatch between those most able to sponsor the stockpiles (i.e., the pre-catastrophe wealthy) and those most able to use the stockpiles (the pre-catastrophe rural poor).\" The minimum annual global wheat storage is approximately 2 months.\nClimate engineering.\nDespite the name \"nuclear winter\", nuclear events are not necessary to produce the modeled climatic effect. In an effort to find a quick and cheap solution to the global warming projection of at least 2 \u02daC of surface warming as a result of the doubling in CO2 levels within the atmosphere, through solar radiation management (a form of climate engineering) the underlying nuclear winter effect has been looked at as perhaps holding potential. Besides the more common suggestion to inject sulfur compounds into the stratosphere to approximate the effects of a volcanic winter, the injection of other chemical species such as the release of a particular type of soot particle to create minor \"nuclear winter\" conditions, has been proposed by Paul Crutzen and others. According to the threshold \"nuclear winter\" computer models, if one to five teragrams of firestorm-generated soot is injected into the low stratosphere, it is modeled, through the anti-greenhouse effect, to heat the stratosphere but cool the lower troposphere and produce 1.25\u00a0\u00b0C cooling for two to three years; and after 10 years, average global temperatures would still be 0.5\u00a0\u00b0C lower than before the soot injection.\nPotential climatic precedents.\nSimilar climatic effects to \"nuclear winter\" followed historical supervolcano eruptions, which plumed sulfate aerosols high into the stratosphere, with this being known as a volcanic winter. The effects of smoke in the atmosphere (short wave absorption) are sometimes termed an \"antigreenhouse\" effect, and a strong analog is the hazy atmosphere of Titan. Pollack, Toon and others were involved in developing models of Titan's climate in the late 1980s, at the same time as their early nuclear winter studies.\nSimilarly, extinction-level comet and asteroid impacts are also believed to have generated impact winters by the pulverization of massive amounts of fine rock dust. This pulverized rock can also produce \"volcanic winter\" effects, if sulfate-bearing rock is hit in the impact and lofted high into the air, and \"nuclear winter\" effects, with the heat of the heavier rock ejecta igniting regional and possibly even global forest firestorms.\nThis global \"impact firestorms\" hypothesis, initially supported by Wendy Wolbach, H. Jay Melosh and Owen Toon, suggests that as a result of massive impact events, the small sand-grain-sized ejecta fragments created can meteorically re-enter the atmosphere forming a hot blanket of global debris high in the air, potentially turning the entire sky red-hot for minutes to hours, and with that, burning the complete global inventory of above-ground carbonaceous material, including rain forests. This hypothesis is suggested as a means to explain the severity of the Cretaceous\u2013Paleogene extinction event, as the earth impact of an asteroid about 10 km wide which precipitated the extinction is not regarded as sufficiently energetic to have caused the level of extinction from the initial impact's energy release alone.\nThe global firestorm winter, however, has been questioned in more recent years (2003\u20132013) by Claire Belcher, Tamara Goldin and Melosh, who had initially supported the hypothesis, with this re-evaluation being dubbed the \"Cretaceous-Palaeogene firestorm debate\" by Belcher.\nThe issues raised by these scientists in the debate are the perceived low quantity of soot in the sediment beside the fine-grained iridium-rich asteroid dust layer, if the quantity of re-entering ejecta was perfectly global in blanketing the atmosphere, and if so, the duration and profile of the re-entry heating, whether it was a high thermal pulse of heat or the more prolonged and therefore more incendiary \"oven\" heating, and finally, how much the \"self-shielding effect\" from the first wave of now-cooled meteors in dark flight contributed to diminishing the total heat experienced on the ground from later waves of meteors.\nIn part due to the Cretaceous period being a high-atmospheric-oxygen era, with concentrations above that of the present day, Owen Toon et al. in 2013 were critical of the re-evaluations the hypothesis is undergoing.\nIt is difficult to successfully ascertain the percentage contribution of the soot in this period's geological sediment record from living plants and fossil fuels present at the time, in much the same manner that the fraction of the material ignited directly by the meteor impact is difficult to determine.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral references.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22172", "revid": "50294939", "url": "https://en.wikipedia.org/wiki?curid=22172", "title": "Ode", "text": "Type of lyric poem\nAn ode (from ) is a type of lyric poetry, with its origins in Ancient Greece. Odes are elaborately structured poems praising or glorifying an event or individual, describing nature intellectually as well as emotionally. A classic ode is structured in three major parts: the \"strophe\", the \"antistrophe\", and the \"epode\". Different forms such as the \"homostrophic ode\" and the \"irregular ode\" also enter.\nGreek odes were originally poetic pieces performed with musical accompaniment. As time passed on, they gradually became known as personal lyrical compositions whether sung (with or without musical instruments) or merely recited (always with accompaniment). The primary instruments used were the aulos and the lyre (the latter was the most revered instrument to the ancient Greeks).\nThere are three typical forms of odes: the Pindaric, Horatian, and irregular. Pindaric odes follow the form and style of Pindar. Horatian odes follow conventions of Horace; the odes of Horace deliberately imitated the Greek lyricists such as Alcaeus and Anacreon. Irregular odes use rhyme, but not the three-part form of the Pindaric ode, nor the two- or four-line stanza of the Horatian ode. The ode is a lyric poem. It conveys exalted and inspired emotions. It is a lyric in an elaborate form, expressed in a language that is imaginative, dignified and sincere.\nStructure.\nPindaric Odes.\nPindaric odes, also called Greek odes, follow the form and style of the Ancient Greek poet Pindar. These employ a tripartite structure, consisting of the \"strophe\", the \"antistrophe\", and the \"epode\".\nIn Ancient Greece, odes were typically performed on a stage to musical accompaniment. The chorus (or performers of the ode) would deliver the strophe from one side of the stage, then move to the opposite side to deliver the antistrophe, and finally to centerstage for the epode.\nThis reflects the three-part nature of the ode: the strophe sets up a theme, the antistrophe balances it with a contrary perspective, and the epode summarises.\nPindaric odes do not follow strict metrical conventions, meaning they are often irregular in their rhyme and line length. However, the strophe and antistrophe are typically identical in structure, with the epode varying the form.\nWilliam Wordsworth's \"\" (1807) and Thomas Gray's \"The Progress of Poesy:\" \"A Pindaric Ode\" (1757) are both written in the Pindaric style. \nGray's \"The Bard: A Pindaric Ode\" (1757) is a Pindaric ode where the three-part structure is thrice repeated, yielding a longer poem of nine stanzas.\nHoratian Odes.\nHoratian odes, sometimes called homostrophic odes, follow the conventions of the Roman poet Horace. Unlike the Pindaric ode, the Horatian ode is made up of any number of stanzas (usually quatrains) which all follow the same rhyme scheme and metre. \nIn contrast with the very formal panegyric style of many of Pindar's odes, Horatian odes often tackle more intimate subjects, such as love and friendship, and were not written for public performance.\nSome of the most renowned Horatian odes were written by English Romantic poet John Keats, most famously \"Ode to a Nightingale\" (1819).\nIrregular Odes.\nIrregular odes further break down the ode's formal conventions. They are sometimes called Cowleyan odes after the English Enlightenment poet Abraham Cowley, who revived the form in England with his publication of fifteen \"Pindarique Odes\" in 1656. Though this title derives from Pindar, it is a misunderstanding of the Pindaric ode on Cowley's part. In fact, Cowley's odes are very different from the strictly formal Pindaric ode.\nIn Cowley's poetry, the ode follows an iambic metre, but employs no regular rhyme or line length.\nThe 'pindarique' was employed by John Milton in the chorus of his lyrical tragedy, Samson Agonistes (1670/71). However, he corrects Cowley's misunderstanding of the form as Pindaric in his 'Preface':\n \"The measure of verse used in the chorus is of all sorts, called by the Greeks 'monostrophic', or rather 'apolelymenon', without regard had to strophe, antistrophe or epode, which were a kind of stanzas framed only for the music, then used with the chorus that sung; not essential to the poem and therefore not material; or, being divided into stanzas or pauses, they may be called 'alloeostropha'.\"\nEnglish ode.\nThe lyrics can be on various themes. The earliest odes in the English language, using the word in its strict form, were the \"Epithalamium\" and \"Prothalamium\" of Edmund Spenser.\nIn the 17th century, the original odes in English were by Abraham Cowley. These were iambic, but had irregular line length patterns and rhyme schemes. Cowley based the principle of his \"Pindariques\" on an apparent misunderstanding of Pindar's metrical practice but, nonetheless, others widely imitated his style, with notable success by John Dryden.\nWith Pindar's metre being better understood in the 18th century, the fashion for Pindaric odes faded, though there are notable actual Pindaric odes by Thomas Gray, http:// and http://.\nAround 1800, William Wordsworth revived Cowley's Pindaric for one of his finest poems, the \"\" ode:\n&lt;poem&gt;\nThere was a time when meadow, grove, and stream,\nThe earth, and every common sight,\nTo me did seem\nApparelled in celestial light,\nThe glory and the freshness of a dream.\nIt is not now as it hath been of yore;\u2014\nTurn wheresoe'er I may,\nBy night or day,\nThe things which I have seen I now can see no more...\nOur birth is but a sleep and a forgetting:\nThe Soul that rises with us, our life's Star,\nHath had elsewhere its setting,\nAnd cometh from afar:\nNot in entire forgetfulness,\nAnd not in utter nakedness,\nBut trailing clouds of glory do we come\nFrom God, who is our home...\n&lt;/poem&gt;\nOthers also wrote odes: Samuel Taylor Coleridge, John Keats, and Percy Bysshe Shelley who wrote odes with regular stanza patterns. Shelley's \"Ode to the West Wind\", written in fourteen line terza rima stanzas, is a major poem in the form. Among the most celebrated odes of the 19th century are Keats's \"Five Great Odes of 1819\", which included \"Ode to a Nightingale\", \"Ode on Melancholy\", \"Ode on a Grecian Urn\", \"Ode to Psyche\", and \"To Autumn\". After Keats, there have been comparatively few major odes in English. One major exception is the fourth verse of the poem \"For the Fallen\" by Laurence Binyon, which is often known as \"The Ode to the Fallen\", or simply as \"The Ode\".\nW.H. Auden also wrote \"Ode\", one of the most popular poems from his earlier career when he lived in London, in opposition to people's ignorance over the reality of war. In an interview, Auden once stated that he had intended to title the poem \"My Silver Age\" in mockery of England's supposed imperial golden age, however chose \"Ode\" as it seemed to provide a more sensitive exploration of warfare.\n\"Ode on a Grecian Urn\", while an ekphrasis, also functions as an ode to the artistic beauty the narrator observes. The English ode's most common rhyme scheme is ABABCDECDE.\nCenturies were occasionally set to music. Composers such as Purcell, H\u00e4ndel and Boyce all set English odes to music.\nNotable practitioners.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22174", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=22174", "title": "OldTestament", "text": ""}
{"id": "22175", "revid": "25859633", "url": "https://en.wikipedia.org/wiki?curid=22175", "title": "OpenContent", "text": ""}
{"id": "22178", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=22178", "title": "OneTimePads", "text": ""}
{"id": "22179", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=22179", "title": "ObjectivisM", "text": ""}
{"id": "22180", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=22180", "title": "OntOlogy", "text": ""}
{"id": "22184", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=22184", "title": "OpenSource", "text": ""}
{"id": "22186", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=22186", "title": "ObservationalError", "text": ""}
{"id": "22189", "revid": "6463349", "url": "https://en.wikipedia.org/wiki?curid=22189", "title": "Temple of Olympian Zeus, Athens", "text": "Ancient Greek temple in Athens\nThe Temple of Olympian Zeus (, ), also known as the Olympieion or Columns of the Olympian Zeus, is a colossal temple in the centre of Athens, now in ruins. It was dedicated to \"Olympian\" Zeus, a name originating from his position as head of the Olympian gods. Construction began in the 6th century BC during the rule of the Athenian tyrants, who envisioned building the greatest temple in the ancient world, but it was not completed until the reign of Roman Emperor Hadrian in the 2nd century AD, some 638 years after the project had begun. During the Roman period, the temple, which included 104 colossal columns, was renowned as the largest temple in Greece and housed one of the largest cult statues in the ancient world.\nThe temple's glory was short-lived, as it fell into disuse after being pillaged during a Germanic invasion in 267 AD, just about a century after its completion. It was probably never repaired, and was reduced to ruins thereafter. In the centuries after the fall of the Roman Empire, it was extensively quarried for building materials to supply building projects elsewhere in the city. Today, a substantial part of the temple remains intact, notably 16 of the original gigantic columns, and it is now the center of a historical precinct.\nHistory.\nClassical and Hellenistic periods.\nThe temple is about south-east of the Acropolis (in the middle between Acropolis and Ardittos hill), and about south of the center of Athens, Syntagma Square. Its foundations were laid on the site of an ancient outdoor sanctuary dedicated to Zeus. An earlier temple had stood there, constructed by the tyrant Peisistratus around 550 BC. The building was demolished after the death of Peisistratus and the construction of a colossal new Temple of Olympian Zeus was begun around 520 BC by his sons, Hippias and Hipparchos. They sought to surpass two famous contemporary temples, the Heraion of Samos and the second Temple of Artemis at Ephesus. Designed by the architects Antistates, Callaeschrus, Antimachides and Phormos, the Temple of Olympian Zeus was intended to be built of local limestone in the Doric style on a colossal platform measuring by . It was to be flanked by a double colonnade of eight columns across the front and back and twenty-one on the flanks, surrounding the cella.\nThe work was abandoned when the tyranny was overthrown and Hippias was expelled in 510 BC. Only the platform and some elements of the columns had been completed by that point, and the temple remained in that state for 336 years. The temple was left unfinished during the years of Athenian democracy, apparently because the Greeks thought it was hubris to build on such a scale. In his treatise \"Politics\", Aristotle cited the temple as an example of how tyrannies engaged the populace in great works for the state (like a white elephant) and left them no time, energy or means to rebel.\nIt was not until 174 BC that the Seleucid king Antiochus IV Epiphanes, who presented himself as the earthly embodiment of Zeus, revived the project and placed the Roman architect Decimus Cossutius in charge. The design was changed to have three rows of eight columns across the front and back of the temple and a double row of twenty on the flanks, for a total of 104 columns. The columns would stand high and in diameter. The building material was changed to the expensive but high-quality Pentelic marble and the order was changed from Doric to Corinthian, marking the first time that this order had been used on the exterior of a major temple. However, the project ground to a halt again in 164 BC with the death of Antiochus. The temple was still only half-finished by that stage.\nSerious damage was inflicted on the partly built temple by Lucius Cornelius Sulla's sack of Athens in 86 BC. While looting the city, Sulla seized some of the incomplete columns and transported them to Rome, where they were re-used in the Temple of Jupiter on the Capitoline Hill. A half-hearted attempt was made to complete the temple during Augustus' reign as the first Roman emperor, but it was not until the accession of Hadrian in the 2nd century AD that the project was finally completed, around 638 years after it had begun.\nRoman era.\nIn 124\u2013125 AD, when the Philhellene Hadrian visited Athens, a massive building programme was begun that included the completion of the Temple of Olympian Zeus. A walled marble-paved precinct was constructed around the temple, making it a central focus of the ancient city. Cossutius' design was used with few changes and the temple was formally dedicated by Hadrian in 132, who took the title of \"Panhellenios\" in commemoration of the occasion. The temple and the surrounding precinct were adorned with numerous statues depicting Hadrian, the gods, and personifications of the Roman provinces. A colossal statue of Hadrian was raised behind the building by the people of Athens in honor of the emperor's generosity. An equally colossal chryselephantine statue of Zeus occupied the cella of the temple. The statue's form of construction was unusual, as the use of chryselephantine was by this time regarded as archaic. Hadrian may have been imitating Phidias' famous statue of Athena Parthenos in the Parthenon, seeking to draw attention to the temple and himself by doing so.\nPausanias describes the temple as it was in the 2nd century:\nBefore the entrance to the sanctuary of Zeus Olympios [in Athens] \u2013 Hadrian the Roman emperor dedicated the temple and the statue, one worth seeing, which in size exceeds all other statues save the colossi at Rhodes and Rome, and is made of ivory and gold with an artistic skill which is remarkable when the size is taken into account \u2013 before the entrance, I say, stand statues of Hadrian, two of Thasian stone, two of Egyptian. Before the pillars stand bronze statues which the Athenians call \u2018colonies.\u2019 The whole circumference of the precincts is about four states, and they are full of statues; for every city has dedicated a likeness of the emperor Hadrian, and the Athenians have surpassed them in dedicating, behind the temple, the remarkable colossus. Within the precincts are antiquities: a bronze Zeus, a temple of Kronos and Rhea and an enclosure of Gaia (Earth) surnamed Olympias. Here the floor opens to the width of a cubit, and they say that along this bed flowed off the water after the deluge that occurred in the time of [the mythical king] Deukalion, and into it, they cast every year wheat meal mixed with honey. On a pillar is a statue of Isokrates . . . There are also statues in Phrygian marble of Persians supporting a bronze tripod; both the figures and the tripod are worth seeing. The ancient sanctuary of Zeus Olympios the Athenians say was built by Deukalion, and they cite as evidence that Deukalion lived at Athens a grave which is not far from the present temple. Hadrian constructed other buildings also for the Athenians: a temple of Hera and Zeus Panellenios (Common to all Greeks).\nThe temple was badly damaged during the sack of Athens by the Heruli in 267 AD. It is unlikely to have been repaired, given the extent of the damage to the rest of the city and was completely destroyed by an earthquake in the 5th century. Material from the ruined building was incorporated into a basilica constructed nearby during the 5th or 6th century.\nMedieval and modern periods.\nOver the following centuries, the temple was systematically quarried to provide building materials and material for the houses and churches of medieval Athens. By the end of the Byzantine period, it had been almost totally destroyed; when Ciriaco de' Pizzicolli (Cyriacus of Ancona) visited Athens in 1436 he found only 21 of the original 104 columns still standing.\nThe fate of one of the columns is recorded by a Greek inscription on one of the surviving columns, which states that \"on 27 April 1759 he pulled down the column\". This refers to the Turkish governor of Athens, Mustapha Agha Tzistarakis, who is recorded by a chronicler as having \"destroyed one of Hadrian's columns with gunpowder\" in order to re-use the marble to make plaster for the Tzistarakis Mosque that he was building in the Monastiraki district of the city. During the Ottoman period the temple was known to the Greeks as the Palace of Hadrian, while the Turks called it the Palace of Belkis, from a Turkish legend that the temple had been the residence of Solomon's wife.\nFifteen columns remain standing today and a sixteenth column lies on the ground where it fell during a storm in 1852. Nothing remains of the cella or the great statue that it once housed.\nExcavation.\nThe temple was excavated in 1889\u20131896 by Francis Penrose of the British School in Athens (who also played a leading role in the restoration of the Parthenon), in 1922 by the German archaeologist Gabriel Welter and in the 1960s by Greek archaeologists led by Ioannes Travlos. The temple, along with the surrounding ruins of other ancient structures, is a historical precinct administered by Ephorate of Antiquities of the Greek Interior Ministry.\nPresent.\nToday, the temple is an open-air museum, part of the unification of the archaeological sites of Athens. As a historical site it is protected and supervised by the Ephorate of Antiquities.\nMythodea 2001.\nOn 28 June 2001, Vangelis organized the Mythodea Chorus at the Temple of Olympian Zeus in the context of NASA's Mars mission. Sopranos Jessye Norman and Kathleen Battle participated in the concert which was covered by 20 television networks from America, Australia, Canada, Japan and European countries, under the direction of Irish filmmaker Declan Lowney. The chorus arrangement brought thousands of people inside the Olympic venues, and outside the temple, into the empty streets of Athens. Joining Norman and Battle were the London Metropolitan Orchestra and the Greek National Opera, as well as over a hundred people dressed in ancient Greek clothing. The screen mounted at the Olympia connected visual images of ancient Greek performances \u2014 vases, frescoes and statues \u2014 that invested music with images of the planet Mars.\nEllinais 2007.\nOn 21 January 2007, a group of Greek pagans held a ceremony honoring Zeus on the grounds of the temple. The event was organized by Ellinais, an organization which won a court battle to obtain recognition for Ancient Greek religious practices in the fall of 2006.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22190", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=22190", "title": "Organic electronics", "text": "Field of materials science\nOrganic electronics is a field of materials science concerning the design, synthesis, characterization, and application of organic molecules or polymers that show desirable electronic properties such as conductivity. Unlike conventional inorganic conductors and semiconductors, organic electronic materials are constructed from organic (carbon-based) molecules or polymers using synthetic strategies developed in the context of organic chemistry and polymer chemistry.\nOne of the promised benefits of organic electronics is their potential low cost compared to traditional electronics. Attractive properties of polymeric conductors include their electrical conductivity (which can be varied by the concentrations of dopants) and comparatively high mechanical flexibility. Challenges to the implementation of organic electronic materials are their inferior thermal stability, high cost, and diverse fabrication issues.\nHistory.\nElectrically conductive polymers.\nTraditional conductive materials are inorganic, especially metals such as copper and aluminum as well as many alloys.\nIn 1862 Henry Letheby described polyaniline, which was subsequently shown to be electrically conductive. Work on other polymeric organic materials began in earnest in the 1960s. For example in 1963, a derivative of tetraiodopyrrole was shown to exhibit conductivity of 1 S/cm (S = Siemens). In 1977, it was discovered that oxidation enhanced the conductivity of polyacetylene. The 2000 Nobel Prize in Chemistry was awarded to Alan J. Heeger, Alan G. MacDiarmid, and Hideki Shirakawa jointly for their work on polyacetylene and related conductive polymers. Many families of electrically conducting polymers have been identified including polythiophene, polyphenylene sulfide, and others.\nJ.E. Lilienfeld first proposed the field-effect transistor in 1930, but the first OFET was not reported until 1987, when Koezuka et al. constructed one using Polythiophene which shows extremely high conductivity. Other conductive polymers have been shown to act as semiconductors, and newly synthesized and characterized compounds are reported weekly in prominent research journals. Many review articles exist documenting the development of these materials.\nIn 1987, the first organic diode was produced at Eastman Kodak by Ching W. Tang and Steven Van Slyke.\nElectrically conductive charge transfer salts.\nIn the 1950s, organic molecules were shown to exhibit electrical conductivity. Specifically, the organic compound pyrene was shown to form semiconducting charge-transfer complex salts with halogens. In 1972, researchers found metallic conductivity (conductivity comparable to a metal) in the charge-transfer complex TTF-TCNQ.\nLight and electrical conductivity.\nAndr\u00e9 Bernanose was the first person to observe electroluminescence in organic materials. Ching W. Tang and Steven Van Slyke, reported fabrication of the first practical OLED device in 1987. The OLED device incorporated a double-layer structure motif composed of copper phthalocyanine and a derivative of perylenetetracarboxylic dianhydride.\nIn 1990, a polymer light emitting diodes was demonstrated by Bradley, Burroughes, Friend. Moving from molecular to macromolecular materials solved the problems previously encountered with the long-term stability of the organic films and made high-quality films easy to produce. In the late 1990's, highly efficient electroluminescent dopants were shown to dramatically increase the light-emitting efficiency of OLEDs These results suggested that electroluminescent materials could displace traditional hot-filament lighting. Subsequent research developed multilayer polymers and the new field of plastic electronics and organic light-emitting diodes (OLED) research and device production grew rapidly.\nConductive organic materials.\nOrganic conductive materials can be grouped into two main classes: polymers and conductive molecular solids and salts. Polycyclic aromatic compounds such as pentacene and rubrene often form semiconducting materials when partially oxidized.\nConductive polymers are often typically intrinsically conductive or at least semiconductors. They sometimes show mechanical properties comparable to those of conventional organic polymers. Both organic synthesis and advanced dispersion techniques can be used to tune the electrical properties of conductive polymers, unlike typical inorganic conductors. Well-studied class of conductive polymers include polyacetylene, polypyrrole, polythiophenes, and polyaniline. Poly(p-phenylene vinylene) and its derivatives are electroluminescent semiconducting polymers. Poly(3-alkythiophenes) have been incorporated into prototypes of solar cells and transistors.\nOrganic light-emitting diode.\nAn OLED (organic light-emitting diode) consists of a thin film of organic material that emits light under stimulation by an electric current. A typical OLED consists of an anode, a cathode, OLED organic material and a conductive layer.\nOLED organic materials can be divided into two major families: small-molecule-based and polymer-based. Small molecule OLEDs (SM-OLEDs) include tris(8-hydroxyquinolinato)aluminium fluorescent and phosphorescent dyes, and conjugated dendrimers. Fluorescent dyes can be selected according to the desired range of emission wavelengths; compounds like perylene and rubrene are often used. Devices based on small molecules are usually fabricated by thermal evaporation under vacuum. While this method enables the formation of well-controlled homogeneous film; is hampered by high cost and limited scalability.\n Polymer light-emitting diodes (PLEDs) are generally more efficient than SM-OLEDs. Common polymers used in PLEDs include derivatives of poly(p-phenylene vinylene) and polyfluorene. The emitted color is determined by the structure of the polymer. Compared to thermal evaporation, solution-based methods are more suited to creating films with large dimensions.\nOrganic field-effect transistor.\nAn organic field-effect transistor (OFET) is a field-effect transistor utilizing organic molecules or polymers as the active semiconducting layer. A field-effect transistor (FET) is any semiconductor material that utilizes electric field to control the shape of a channel of one type of charge carrier, thereby changing its conductivity. Two major classes of FET are n-type and p-type semiconductor, classified according to the charge type carried. In the case of organic FETs (OFETs), p-type OFET compounds are generally more stable than n-type due to the susceptibility of the latter to oxidative damage.\nAs for OLEDs, some OFETs are molecular and some are polymer-based system. Rubrene-based OFETs show high carrier mobility of 20\u201340\u00a0cm2/(V\u00b7s). Another popular OFET material is Pentacene. Due to its low solubility in most organic solvents, it's difficult to fabricate thin film transistors (TFTs) from pentacene itself using conventional spin-cast or, dip coating methods, but this obstacle can be overcome by using the derivative TIPS-pentacene.\nOrganic electronic devices.\nOrganic solar cells could cut the cost of solar power compared with conventional solar-cell manufacturing. Silicon thin-film solar cells on flexible substrates allow a significant cost reduction of large-area photovoltaics for several reasons:\nInexpensive polymeric substrates like polyethylene terephthalate (PET) or polycarbonate (PC) have the potential for further cost reduction in photovoltaics. Protomorphous solar cells prove to be a promising concept for efficient and low-cost photovoltaics on cheap and flexible substrates for large-area production as well as small and mobile applications.\nOne advantage of printed electronics is that different electrical and electronic components can be printed on top of each other, saving space and increasing reliability and sometimes they are all transparent. One ink must not damage another, and low temperature annealing is vital if low-cost flexible materials such as paper and plastic film are to be used. There is much sophisticated engineering and chemistry involved here, with iTi, Pixdro, Asahi Kasei, Merck &amp; Co.|Merck, BASF, HC Starck, Sunew, Hitachi Chemical, and Frontier Carbon Corporation among the leaders.\nElectronic devices based on organic compounds are now widely used, with many new products under development. Sony reported the first full-color, video-rate, flexible, plastic display made purely of organic materials; television screen based on OLED materials; biodegradable electronics based on organic compound and low-cost organic solar cell are also available.\nFabrication methods.\nSmall molecule semiconductors are often insoluble, necessitating deposition via vacuum sublimation. Devices based on conductive polymers can be prepared by solution processing methods. Both solution processing and vacuum based methods produce amorphous and polycrystalline films with variable degree of disorder. \"Wet\" coating techniques require polymers to be dissolved in a volatile solvent, filtered and deposited onto a substrate. Common examples of solvent-based coating techniques include drop casting, spin-coating, doctor-blading, inkjet printing and screen printing. Spin-coating is a widely used technique for small area thin film production. It may result in a high degree of material loss. The doctor-blade technique results in a minimal material loss and was primarily developed for large area thin film production. Vacuum based thermal deposition of small molecules requires evaporation of molecules from a hot source. The molecules are then transported through vacuum onto a substrate. The process of condensing these molecules on the substrate surface results in thin film formation. Wet coating techniques can in some cases be applied to small molecules depending on their solubility.\nOrganic solar cells.\nOrganic semiconductor diodes convert light into electricity. Figure to the right shows five commonly used organic photovoltaic materials. Electrons in these organic molecules can be delocalized in a delocalized \u03c0 orbital with a corresponding \u03c0* antibonding orbital. The difference in energy between the \u03c0 orbital, or highest occupied molecular orbital (HOMO), and \u03c0* orbital, or lowest unoccupied molecular orbital (LUMO) is called the band gap of organic photovoltaic materials. Typically, the band gap lies in the range of 1-4eV.\nThe difference in the band gap of organic photovoltaic materials leads to different chemical structures and forms of organic solar cells. Different forms of solar cells includes single-layer organic photovoltaic cells, bilayer organic photovoltaic cells and heterojunction photovoltaic cells. However, all three of these types of solar cells share the approach of sandwiching the organic electronic layer between two metallic conductors, typically indium tin oxide.\nOrganic field-effect transistors.\nAn organic field-effect transistor is a three terminal device (source, drain and gate). The charge carriers move between source and drain, and the gate serves to control the path's conductivity. There are mainly two types of organic field-effect transistor, based on the semiconducting layer's charge transport, namely p-type (such as dinaphtho[2,3-\"b\":2\u2032,3\u2032-\"f\"]thieno[3,2-\"b\"]thiophene, DNTT), and n-type (such phenyl C61 butyric acid methyl ester, PCBM). Certain organic semiconductors can also present both p-type and n-type (i.e., ambipolar) characteristics.\nSuch technology allows for the fabrication of large-area, flexible, low-cost electronics. One of the main advantages is that being mainly a low temperature process compared to CMOS, different type of materials can be utilized. This makes them in turn great candidates for sensing.\nFeatures.\nConductive polymers are lighter, more flexible, and less expensive than inorganic conductors. This makes them a desirable alternative in many applications. It also creates the possibility of new applications that would be impossible using copper or silicon.\nOrganic electronics not only includes organic semiconductors, but also organic dielectrics, conductors and light emitters.\nNew applications include smart windows and electronic paper. Conductive polymers are expected to play an important role in the emerging science of molecular computers.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22191", "revid": "90", "url": "https://en.wikipedia.org/wiki?curid=22191", "title": "O Brother Where Are Thou", "text": ""}
{"id": "22194", "revid": "25427528", "url": "https://en.wikipedia.org/wiki?curid=22194", "title": "Operating system", "text": "Software that manages computer hardware resources\nAn operating system (OS) is system software that manages computer hardware and software resources, and provides common services for computer programs.\nTime-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, peripherals, and other resources.\nFor hardware functions such as input and output and memory allocation, the operating system acts as an intermediary between programs and the computer hardware, although the application code is usually executed directly by the hardware and frequently makes system calls to an OS function or is interrupted by it. Operating systems are found on many devices that contain a computer\u00a0\u2013 from cellular phones and video game consoles to web servers and supercomputers.\nAs of \u00a02025[ [update]], Android is the most popular operating system with a 38% market share, followed by Microsoft Windows at 31%, iOS and iPadOS at 15%, macOS at 7%, and Linux at 1%. Android, iOS, and iPadOS are operating systems for mobile devices such as smartphones, while Windows, macOS, and Linux are for desktop computers. Linux distributions are dominant in the server and supercomputing sectors. Other specialized classes of operating systems (special-purpose operating systems), such as embedded and real-time systems, exist for many applications. Security-focused operating systems also exist. Some operating systems have low system requirements (e.g. light-weight Linux distribution). Others may have higher system requirements.\nSome operating systems require installation or may come pre-installed with purchased computers (OEM-installation), whereas others may run directly from media (i.e. live CD) or flash memory (i.e. a LiveUSB from a USB stick).\nDefinition and purpose.\nAn operating system is difficult to define, but has been called \"the layer of software that manages a computer's resources for its users and their applications\". Operating systems include the software that is always running, called a kernel\u2014but can include other software as well. The two other types of programs that can run on a computer are system programs\u2014which are associated with the operating system, but may not be part of the kernel\u2014and applications\u2014all other software.\nThere are three main purposes that an operating system fulfills:\nTypes of operating systems.\nMulticomputer operating systems.\nWith multiprocessors multiple CPUs share memory. A multicomputer or cluster computer has multiple CPUs, each of which has its own memory. Multicomputers were developed because large multiprocessors are difficult to engineer and prohibitively expensive; they are universal in cloud computing because of the size of the machine needed. The different CPUs often need to send and receive messages to each other; to ensure good performance, the operating systems for these machines need to minimize this copying of packets. Newer systems are often multiqueue\u2014separating groups of users into separate queues\u2014to reduce the need for packet copying and support more concurrent users. Another technique is remote direct memory access, which enables each CPU to access memory belonging to other CPUs. Multicomputer operating systems often support remote procedure calls where a CPU can call a procedure on another CPU, or distributed shared memory, in which the operating system uses virtualization to generate shared memory that does not physically exist.\nDistributed systems.\nA distributed system is a group of distinct, networked computers\u2014each of which might have their own operating system and file system. Unlike multicomputers, they may be dispersed anywhere in the world. Middleware, an additional software layer between the operating system and applications, is often used to improve consistency. Although it functions similarly to an operating system, it is not a true operating system.\nEmbedded.\nEmbedded operating systems are designed to be used in embedded computer systems, whether they are internet of things objects or not connected to a network. Embedded systems include many household appliances. The distinguishing factor is that they do not load user-installed software. Consequently, they do not need protection between different applications, enabling simpler designs. Very small operating systems might run in less than 10 kilobytes, and the smallest are for smart cards. Examples include Embedded Linux, QNX, VxWorks, and the extra-small systems RIOT and TinyOS.\nReal-time.\nA real-time operating system is an operating system that guarantees to process events or data by or at a specific moment in time. Hard real-time systems require exact timing and are common in manufacturing, avionics, military, and other similar uses. With soft real-time systems, the occasional missed event is acceptable; this category often includes audio or multimedia systems, as well as smartphones. In order for hard real-time systems be sufficiently exact in their timing, often they are just a library with no protection between applications, such as eCos.\nHypervisor.\nA hypervisor is an operating system that runs a virtual machine. The virtual machine is an application that emulates hardware; in other words, it operates as much as possible like the actual hardware the operating system was designed to run on. Virtual machines can be paused, saved, and resumed, making them useful for operating systems research, development, and debugging. They also enhance portability by enabling applications to be run on a computer even if they are not compatible with the base operating system.\nLibrary.\nA \"library operating system\" (libOS) is one in which the services that a typical operating system provides, such as networking, are provided in the form of libraries and composed with a single application and configuration code to construct a unikernel:\n a specialized (only the absolute necessary pieces of code are extracted from libraries and bound together\n), single address space, machine image that can be deployed to cloud or embedded environments.\nThe operating system code and application code are not executed in separated protection domains (there is only a single application running, at least conceptually, so there is no need to prevent interference between applications) and OS services are accessed via simple library calls (potentially inlining them based on compiler thresholds), without the usual overhead of context switches,\n in a way similarly to embedded and real-time OSes. Note that this overhead is not negligible: to the direct cost of mode switching it's necessary to add the indirect pollution of important processor structures (like CPU caches, the instruction pipeline, and so on) which affects both user-mode and kernel-mode performance.\nHistory.\nThe first computers in the late 1940s and 1950s were directly programmed either with plugboards or with machine code inputted on media such as punch cards, without programming languages or operating systems. After the introduction of the transistor in the mid-1950s, mainframes began to be built. These still needed professional operators who manually do what a modern operating system would do, such as scheduling programs to run, but mainframes still had rudimentary operating systems such as Fortran Monitor System (FMS) and IBSYS. In the 1960s, IBM introduced the first series of intercompatible computers (System/360). All of them ran the same operating system\u2014OS/360\u2014which consisted of millions of lines of assembly language that had thousands of bugs. The OS/360 also was the first popular operating system to support multiprogramming, such that the CPU could be put to use on one job while another was waiting on input/output (I/O). Holding multiple jobs in memory necessitated memory partitioning and safeguards against one job accessing the memory allocated to a different one.\nAround the same time, teleprinters began to be used as terminals so multiple users could access the computer simultaneously. The operating system MULTICS was intended to allow hundreds of users to access a large computer. Despite its limited adoption, it can be considered the precursor to cloud computing. The UNIX operating system originated as a development of MULTICS for a single user. Because UNIX's source code was available, it became the basis of other, incompatible operating systems, of which the most successful were AT&amp;T's System V and the University of California's Berkeley Software Distribution (BSD). To increase compatibility, the IEEE released the POSIX standard for operating system application programming interfaces (APIs), which is supported by most UNIX systems. MINIX was a stripped-down version of UNIX, developed in 1987 for educational uses, that inspired the commercially available, free software Linux. Since 2008, MINIX is used in controllers of most Intel microchips, while Linux is widespread in data centers and Android smartphones.\nMicrocomputers.\nThe invention of large scale integration enabled the production of personal computers (initially called microcomputers) from around 1980. For around five years, the CP/M (Control Program for Microcomputers) was the most popular operating system for microcomputers. Later, IBM bought a disk operating system from Microsoft, which IBM sold as IBM PC DOS and Microsoft branded as MS-DOS (MicroSoft Disk Operating System) and was widely used on IBM PC compatible microcomputers. Later versions increased their sophistication, in part by borrowing features from UNIX.\nApple's Macintosh was the first popular computer to use a graphical user interface (GUI). The GUI proved much more user friendly than the text-only command-line interface earlier operating systems had used. Following the success of Macintosh, MS-DOS was updated with a GUI overlay called Windows. Windows later was rewritten as a stand-alone operating system, borrowing so many features from another (VAX VMS) that a large legal settlement was paid. In the twenty-first century, Windows continues to be popular on personal computers but has less market share of servers. UNIX operating systems, especially Linux, are the most popular on enterprise systems and servers but are also used on mobile devices and many other computer systems.\nOn mobile devices, Symbian OS was dominant at first, being usurped by BlackBerry OS (introduced 2002) and iOS for iPhones (from 2007). Later on, the open-source Android operating system (introduced 2008), with a Linux kernel and a C library (Bionic) partially based on BSD code, became most popular.\nComponents.\nThe components of an operating system are designed to ensure that various parts of a computer function cohesively. With the de facto obsoletion of DOS, all user software must interact with the operating system to access hardware.\nKernel.\nThe kernel is the part of the operating system that provides protection between different applications and users. This protection is key to improving reliability by keeping errors isolated to one program, as well as security by limiting the power of malicious software and protecting private data, and ensuring that one program cannot monopolize the computer's resources. Most operating systems have two modes of operation: in user mode, the hardware checks that the software is only executing legal instructions, whereas the kernel has unrestricted powers and is not subject to these checks. The kernel also manages memory for other processes and controls access to input/output devices.\nProgram execution.\nThe operating system provides an interface between an application program and the computer hardware, so that an application program can interact with the hardware only by obeying rules and procedures programmed into the operating system. The operating system is also a set of services which simplify development and execution of application programs. Executing an application program typically involves the creation of a process by the operating system kernel, which assigns memory space and other resources, establishes a priority for the process in multi-tasking systems, loads program binary code into memory, and initiates execution of the application program, which then interacts with the user and with hardware devices. However, in some systems an application can request that the operating system execute another application within the same process, either as a subroutine or in a separate thread, e.g., the LINK and ATTACH facilities of OS/360 and successors.\nInterrupts.\nAn interrupt (also known as an abort, exception, \"fault\", signal, or \"trap\") provides an efficient way for most operating systems to react to the environment. Interrupts cause the central processing unit (CPU) to have a control flow change away from the currently running program to an interrupt handler, also known as an interrupt service routine (ISR). An interrupt service routine may cause the central processing unit (CPU) to have a context switch. The details of how a computer processes an interrupt vary from architecture to architecture, and the details of how interrupt service routines behave vary from operating system to operating system. However, several interrupt functions are common. The architecture and operating system must:\nSoftware interrupt.\nA software interrupt is a message to a process that an event has occurred. This contrasts with a \"hardware interrupt\" \u2014 which is a message to the central processing unit (CPU) that an event has occurred. Software interrupts are similar to hardware interrupts \u2014 there is a change away from the currently running process. Similarly, both hardware and software interrupts execute an interrupt service routine.\nSoftware interrupts may be normally occurring events. It is expected that a time slice will occur, so the kernel will have to perform a context switch. A computer program may set a timer to go off after a few seconds in case too much data causes an algorithm to take too long.\nSoftware interrupts may be error conditions, such as a malformed machine instruction. However, the most common error conditions are division by zero and accessing an invalid memory address.\nUsers can send messages to the kernel to modify the behavior of a currently running process. For example, in the command-line environment, pressing the \"interrupt character\" (usually Control-C) might terminate the currently running process.\nTo generate \"software interrupts\" for x86 CPUs, the INT assembly language instruction is available. The syntax is codice_1, where codice_2 is the offset number (in hexadecimal format) to the interrupt vector table.\nSignal.\nTo generate \"software interrupts\" in Unix-like operating systems, the codice_3 system call will send a signal to another process. codice_4 is the process identifier of the receiving process. codice_5 is the signal number (in mnemonic format) to be sent. (The abrasive name of codice_6 was chosen because early implementations only terminated the process.)\nIn Unix-like operating systems, \"signals\" inform processes of the occurrence of asynchronous events. To communicate asynchronously, interrupts are required. One reason a process needs to asynchronously communicate to another process solves a variation of the classic reader/writer problem. The writer receives a pipe from the shell for its output to be sent to the reader's input stream. The command-line syntax is codice_7. codice_8 will write to the pipe when its computation is ready and then sleep in the wait queue. codice_9 will then be moved to the ready queue and soon will read from its input stream. The kernel will generate \"software interrupts\" to coordinate the piping.\n\"Signals\" may be classified into 7 categories. The categories are:\nHardware interrupt.\nInput/output (I/O) devices are slower than the CPU. Therefore, it would slow down the computer if the CPU had to wait for each I/O to finish. Instead, a computer may implement interrupts for I/O completion, avoiding the need for polling or busy waiting.\nSome computers require an interrupt for each character or word, costing a significant amount of CPU time. Direct memory access (DMA) is an architecture feature to allow devices to bypass the CPU and access main memory directly. (Separate from the architecture, a device may perform direct memory access to and from main memory either directly or via a bus.)\nInput/output.\nInterrupt-driven I/O.\nWhen a computer user types a key on the keyboard, typically the character appears immediately on the screen. Likewise, when a user moves a mouse, the cursor immediately moves across the screen. Each keystroke and mouse movement generates an \"interrupt\" called \"Interrupt-driven I/O\". An interrupt-driven I/O occurs when a process causes an interrupt for every character or word transmitted.\nDirect memory access.\nDevices such as hard disk drives, solid-state drives, and magnetic tape drives can transfer data at a rate high enough that interrupting the CPU for every byte or word transferred, and having the CPU transfer the byte or word between the device and memory, would require too much CPU time. Data is, instead, transferred between the device and memory independently of the CPU by hardware such as a channel or a direct memory access controller; an interrupt is delivered only when all the data is transferred.\nIf a computer program executes a system call to perform a block I/O \"write\" operation, then the system call might execute the following instructions:\nWhile the writing takes place, the operating system will context switch to other processes as normal. When the device finishes writing, the device will \"interrupt\" the currently running process by \"asserting\" an interrupt request. The device will also place an integer onto the data bus. Upon accepting the interrupt request, the operating system will:\n* Access the device-status table.\n* Extract the process control block.\n* Perform a context switch back to the writing process.\nWhen the writing process has its time slice expired, the operating system will:\nWith the program counter now reset, the interrupted process will resume its time slice.\nMemory management.\nAmong other things, a multiprogramming operating system kernel must be responsible for managing all system memory which is currently in use by the programs. This ensures that a program does not interfere with memory already in use by another program. Since programs time share, each program must have independent access to memory.\nCooperative memory management, used by many early operating systems, assumes that all programs make voluntary use of the kernel's memory manager, and do not exceed their allocated memory. This system of memory management is almost never seen anymore, since programs often contain bugs which can cause them to exceed their allocated memory. If a program fails, it may cause memory used by one or more other programs to be affected or overwritten. Malicious programs or viruses may purposefully alter another program's memory, or may affect the operation of the operating system itself. With cooperative memory management, it takes only one misbehaved program to crash the system.\nMemory protection enables the kernel to limit a process' access to the computer's memory. Various methods of memory protection exist, including memory segmentation and paging. All methods require some level of hardware support (such as the 80286 MMU), which does not exist in all computers.\nIn both segmentation and paging, certain protected mode registers specify to the CPU what memory address it should allow a running program to access. Attempts to access other addresses trigger an interrupt, which causes the CPU to re-enter supervisor mode, placing the kernel in charge. This is called a segmentation violation or Seg-V for short, and since it is both difficult to assign a meaningful result to such an operation, and because it is usually a sign of a misbehaving program, the kernel generally resorts to terminating the offending program, and reports the error.\nWindows versions 3.1 through ME had some level of memory protection, but programs could easily circumvent the need to use it. A general protection fault would be produced, indicating a segmentation violation had occurred; however, the system would often crash anyway.\nVirtual memory.\nThe use of virtual memory addressing (such as paging or segmentation) means that the kernel can choose what memory each program may use at any given time, allowing the operating system to use the same memory locations for multiple tasks.\nIf a program tries to access memory that is not accessible memory, but nonetheless has been allocated to it, the kernel is interrupted &lt;templatestyles src=\"Crossreference/styles.css\" /&gt;. This kind of interrupt is typically a page fault.\nWhen the kernel detects a page fault it generally adjusts the virtual memory range of the program which triggered it, granting it access to the memory requested. This gives the kernel discretionary power over where a particular application's memory is stored, or even whether or not it has been allocated yet.\nIn modern operating systems, memory which is accessed less frequently can be temporarily stored on a disk or other media to make that space available for use by other programs. This is called swapping, as an area of memory can be used by multiple programs, and what that memory area contains can be swapped or exchanged on demand.\nVirtual memory provides the programmer or the user with the perception that there is a much larger amount of RAM in the computer than is really there.\nConcurrency.\nConcurrency refers to the operating system's ability to carry out multiple tasks simultaneously. Virtually all modern operating systems support concurrency.\nThreads enable splitting a process' work into multiple parts that can run simultaneously. The number of threads is not limited by the number of processors available. If there are more threads than processors, the operating system kernel schedules, suspends, and resumes threads, controlling when each thread runs and how much CPU time it receives. During a context switch a running thread is suspended, its state is saved into the thread control block and stack, and the state of the new thread is loaded in. Historically, on many systems a thread could run until it relinquished control (cooperative multitasking). Because this model can allow a single thread to monopolize the processor, most operating systems now can interrupt a thread (preemptive multitasking).\nThreads have their own thread ID, program counter (PC), a register set, and a stack, but share code, heap data, and other resources with other threads of the same process. Thus, there is less overhead to create a thread than a new process. On single-CPU systems, concurrency is switching between processes. Many computers have multiple CPUs. Parallelism with multiple threads running on different CPUs can speed up a program, depending on how much of it can be executed concurrently.\nFile system.\nPermanent storage devices used in twenty-first century computers, unlike volatile dynamic random-access memory (DRAM), are still accessible after a crash or power failure. Permanent (non-volatile) storage is much cheaper per byte, but takes several orders of magnitude longer to access, read, and write. The two main technologies are a hard drive consisting of magnetic disks, and flash memory (a solid-state drive that stores data in electrical circuits). The latter is more expensive but faster and more durable.\nFile systems are an abstraction used by the operating system to simplify access to permanent storage. They provide human-readable filenames and other metadata, increase performance via amortization of accesses, prevent multiple threads from accessing the same section of memory, and include checksums to identify corruption. File systems are composed of files (named collections of data, of an arbitrary size) and directories (also called folders) that list human-readable filenames and other directories. An absolute file path begins at the root directory and lists subdirectories divided by punctuation, while a relative path defines the location of a file from a directory.\nSystem calls (which are sometimes wrapped by libraries) enable applications to create, delete, open, and close files, as well as link, read, and write to them. All these operations are carried out by the operating system on behalf of the application. The operating system's efforts to reduce latency include storing recently requested blocks of memory in a cache and prefetching data that the application has not asked for, but might need next. Device drivers are software specific to each input/output (I/O) device that enables the operating system to work without modification over different hardware.\nAnother component of file systems is a dictionary that maps a file's name and metadata to the data block where its contents are stored. Most file systems use directories to convert file names to file numbers. To find the block number, the operating system uses an index (often implemented as a tree). Separately, there is a free space map to track free blocks, commonly implemented as a bitmap. Although any free block can be used to store a new file, many operating systems try to group together files in the same directory to maximize performance, or periodically reorganize files to reduce fragmentation.\nMaintaining data reliability in the face of a computer crash or hardware failure is another concern. File writing protocols are designed with atomic operations so as not to leave permanent storage in a partially written, inconsistent state in the event of a crash at any point during writing. Data corruption is addressed by redundant storage (for example, RAID\u2014redundant array of inexpensive disks) and checksums to detect when data has been corrupted. With multiple layers of checksums and backups of a file, a system can recover from multiple hardware failures. Background processes are often used to detect and recover from data corruption.\nSecurity.\nSecurity means protecting users from other users of the same computer, as well as from those who seeking remote access to it over a network. Operating systems security rests on achieving the CIA triad: confidentiality (unauthorized users cannot access data), integrity (unauthorized users cannot modify data), and availability (ensuring that the system remains available to authorized users, even in the event of a denial of service attack). As with other computer systems, isolating security domains\u2014in the case of operating systems, the kernel, processes, and virtual machines\u2014is key to achieving security. Other ways to increase security include simplicity to minimize the attack surface, locking access to resources by default, checking all requests for authorization, principle of least authority (granting the minimum privilege essential for performing a task), privilege separation, and reducing shared data.\nSome operating system designs are more secure than others. Those with no isolation between the kernel and applications are least secure, while those with a monolithic kernel like most general-purpose operating systems are still vulnerable if any part of the kernel is compromised. A more secure design features microkernels that separate the kernel's privileges into many separate security domains and reduce the consequences of a single kernel breach. Unikernels are another approach that improves security by minimizing the kernel and separating out other operating systems functionality by application.\nMost operating systems are written in C or C++, which create potential vulnerabilities for exploitation. Despite attempts to protect against them, vulnerabilities are caused by buffer overflow attacks, which are enabled by the lack of bounds checking. Hardware vulnerabilities, some of them caused by CPU optimizations, can also be used to compromise the operating system. There are known instances of operating system programmers deliberately implanting vulnerabilities, such as back doors.\nOperating systems security is hampered by their increasing complexity and the resulting inevitability of bugs. Because formal verification of operating systems may not be feasible, developers use operating system hardening to reduce vulnerabilities, e.g. address space layout randomization, control-flow integrity, access restrictions, and other techniques. There are no restrictions on who can contribute code to open source operating systems; such operating systems have transparent change histories and distributed governance structures. Open source developers strive to work collaboratively to find and eliminate security vulnerabilities, using code review and type checking to expunge malicious code. Andrew S. Tanenbaum advises releasing the source code of all operating systems, arguing that it prevents developers from placing trust in secrecy and thus relying on the unreliable practice of security by obscurity.\nUser interface.\nA user interface (UI) is essential to support human interaction with a computer. The two most common user interface types for any computer are\nFor personal computers, including smartphones and tablet computers, and for workstations, user input is typically from a combination of keyboard, mouse, and trackpad or touchscreen, all of which are connected to the operating system with specialized software. Personal computer users who are not software developers or coders often prefer GUIs for both input and output; GUIs are supported by most personal computers. The software to support GUIs is more complex than a command line for input and plain text output. Plain text output is often preferred by programmers, and is easy to support.\nNetworking.\nA modern operating system is usually offers network stack features, for example TCP/IP protocol stack.\nDrivers.\nA modern operating system is usually utilise device drivers to access hardware.\nOperating system development as a hobby.\nA hobby operating system may be classified as one whose code has not been directly derived from an existing operating system, and has few users and active developers.\nIn some cases, hobby development is in support of a \"homebrew\" computing device, for example, a simple single-board computer powered by a 6502 microprocessor. Or, development may be for an architecture already in widespread use. Operating system development may come from entirely new concepts, or may commence by modeling an existing operating system. In either case, the hobbyist is her/his own developer, or may interact with a small and sometimes unstructured group of individuals who have like interests.\nExamples of hobby operating systems include Syllable and TempleOS.\nDiversity of operating systems and portability.\nIf an application is written for use on a specific operating system, and is ported to another OS, the functionality required by that application may be implemented differently by that OS (the names of functions, meaning of arguments, etc.) requiring the application to be adapted, changed, or otherwise maintained.\nThis cost in supporting operating systems diversity can be avoided by instead writing applications for software platforms such as Java or Qt. These abstractions have already borne the cost of adaptation to specific operating systems and their system libraries.\nAnother approach is for operating system vendors to adopt standards. For example, POSIX and OS abstraction layers provide commonalities that reduce porting costs.\nPopular operating systems.\nAs of \u00a02025[ [update]], Android, based on the Linux kernel, is the most popular operating system with a 38% market share, followed by Microsoft Windows at 31%, iOS and iPadOS at 15%, macOS at 7%, and Linux at 1%. Android, iOS, and iPadOS are mobile operating systems, while Windows, macOS, and Linux are desktop operating systems.\nLinux.\nLinux is free software distributed under the GNU General Public License (GPL), which means that all of its derivatives are legally required to release their source code. Linux was designed by programmers for their own use, thus emphasizing simplicity and consistency, with a small number of basic elements that can be combined in nearly unlimited ways, and avoiding redundancy.\nIts design is similar to other UNIX systems not using a microkernel. It is written in C and uses UNIX System V syntax, but also supports BSD syntax. Linux supports standard UNIX networking features, as well as the full suite of UNIX tools, while supporting multiple users and employing preemptive multitasking. Initially of a minimalist design, Linux is a flexible system that can work in under 16 MB of RAM, but still is used on large multiprocessor systems. Similar to other UNIX systems, Linux distributions are composed of a kernel, system libraries, and system utilities. Linux has a graphical user interface (GUI) with a desktop, folder and file icons, as well as the option to access the operating system via a command line.\nAndroid is a partially open-source operating system closely based on Linux and has become the most widely used operating system by users, due to its popularity on smartphones and, to a lesser extent, embedded systems needing a GUI, such as \"smart watches, automotive dashboards, airplane seatbacks, medical devices, and home appliances\". Unlike Linux, much of Android is written in Java and uses object-oriented design.\nMicrosoft Windows.\nWindows is a proprietary operating system that is widely used on desktop computers, laptops, tablets, phones, workstations, enterprise servers, and Xbox consoles. The operating system was designed for \"security, reliability, compatibility, high performance, extensibility, portability, and international support\"\u2014later on, energy efficiency and support for dynamic devices also became priorities.\nWindows Executive works via kernel-mode objects for important data structures like processes, threads, and sections (memory objects, for example files). The operating system supports demand paging of virtual memory, which speeds up I/O for many applications. I/O device drivers use the Windows Driver Model. The NTFS file system has a master table and each file is represented as a record with metadata. The scheduling includes preemptive multitasking. Windows has many security features; especially important are the use of access-control lists and integrity levels. Every process has an authentication token and each object is given a security descriptor. Later releases have added even more security features.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "22195", "revid": "40123752", "url": "https://en.wikipedia.org/wiki?curid=22195", "title": "Operating System", "text": ""}
{"id": "22196", "revid": "49364944", "url": "https://en.wikipedia.org/wiki?curid=22196", "title": "Orson Welles", "text": "American actor and filmmaker (1915\u20131985)\nGeorge Orson Welles (May 6, 1915 \u2013 October 10, 1985) was an American actor and filmmaker. Remembered for his innovative work in film, radio, and theatre, he is considered among the greatest and most influential filmmakers of all time.\nAged 21, Welles directed high-profile stage productions for the Federal Theatre Project in New York City\u2014starting with a celebrated 1936 adaptation of \"Macbeth\" with an African-American cast, and ending with the political musical \"The Cradle Will Rock\" in 1937. He and John Houseman founded the Mercury Theatre, an independent repertory theatre company that presented productions on Broadway through 1941, including a modern, politically charged \"Caesar\" (1937). In 1938, his radio anthology series \"The Mercury Theatre on the Air\" gave Welles the platform to find international fame as the director and narrator of a radio adaptation of H. G. Wells's novel \"The War of the Worlds\", which caused some listeners to believe a Martian invasion was occurring. The event rocketed the 23-year-old to notoriety.\nHis first film was \"Citizen Kane\" (1941), which he co-wrote, produced, directed and starred in as the title character, Charles Foster Kane. Cecelia Ager, reviewing it in \"PM Magazine\", wrote: \"Seeing it, it's as if you never really saw a movie before.\" It has been consistently ranked as one of the greatest films ever made. He directed twelve other features, the most acclaimed of which include \"The Magnificent Ambersons\" (1942), \"Othello\" (1951), \"Touch of Evil\" (1958), \"The Trial\" (1962), and \"Chimes at Midnight\" (1966). Welles also acted in other directors' films, playing Rochester in \"Jane Eyre\" (1943), Harry Lime in \"The Third Man\" (1949), and Cardinal Wolsey in \"A Man for All Seasons\" (1966).\nHis distinctive directorial style featured layered and nonlinear narrative forms, dramatic lighting, unusual camera angles, sound techniques borrowed from radio, deep focus shots and long takes. He has been praised as \"the ultimate \". Welles was an outsider to the studio system and struggled for creative control on his projects. He received an Academy Award and three Grammy Awards among other honors and accolades such as the Golden Lion in 1947, the Palme D'Or in 1952, the Academy Honorary Award in 1970, the AFI Life Achievement Award in 1975, and the British Film Institute Fellowship in 1983. British Film Institute polls in 2002 voted him the greatest film director ever. In 2018, he was included in the list of the greatest Hollywood actors of all time by \"The Daily Telegraph\". Miche\u00e1l Mac Liamm\u00f3ir, who worked with the 16-year-old Welles in Dublin's Gate Theatre and played Iago in his film \"Othello\" (1951), wrote that \"Orson's courage, like everything else about him, imagination, egotism, generosity, ruthlessness, forbearance, impatience, sensitivity, grossness and vision is magnificently out of proportion.\"\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nEarly life (1915\u20131931).\nGeorge Orson Welles was born May 6, 1915, in Kenosha, Wisconsin, the younger of two sons of Richard Head Welles and Beatrice Ives Welles (\"n\u00e9e\" Beatrice Lucy Ives). He was named after one of his great-grandfathers, Kenosha attorney Orson S. Head, and his brother George Head.\nOrson had a brother ten years older than himself, Richard Ives Welles (1905\u20131970s), who struggled all his life with mental health issues and was often institutionalized.\nDespite his family's affluence, Welles encountered hardship when his parents separated and moved to Chicago in 1919. His father, who made a fortune as the inventor of a type of bicycle lamp, became an alcoholic and stopped working. Welles's mother was a concert pianist who had studied with the pianist-composer Leopold Godowsky. She played during lectures by Dudley Crafts Watson at the Art Institute of Chicago to support her son and herself. Welles received piano and violin lessons arranged by his mother. His elder brother \"Dickie\" was institutionalized because he had learning difficulties. Beatrice died of hepatitis in a Chicago hospital on May 10, 1924, just after Welles's ninth birthday. The Gordon String Quartet, a predecessor to the Berkshire String Quartet, which had made its first appearance at her home in 1921, played at Beatrice's funeral.\nAfter his mother died, Welles ceased pursuing a musical career. It was decided he would spend the summer with the Watson family at a private art colony established by Lydia Avery Coonley Ward in the village of Wyoming in the Finger Lakes Region of New York. There, he played and became friends with the children of the Aga Khan, including the 12-year-old Prince Aly Khan. Then, in what Welles later described as \"a hectic period\", he lived in a Chicago apartment with his father and Maurice Bernstein, a Chicago physician who had been a close friend of his parents. Welles attended public school before his alcoholic father left business altogether and took him along on travels to Jamaica and the Far East. When they returned, they settled in a hotel his father owned in Grand Detour, Illinois. When the hotel burned down, Welles and his father took to the road again.\n\"During the three years that Orson lived with his father, some observers wondered who took care of whom\", wrote biographer Frank Brady.\n\"In some ways, he was never really a young boy, you know\", said Roger Hill, who became Welles's teacher and lifelong friend.\nWelles attended public school in Madison, Wisconsin, enrolled in the fourth grade. On September 15, 1926, he entered the Todd Seminary for Boys, an expensive independent school in Woodstock, Illinois, that his older brother Richard Ives Welles had attended ten years earlier, until he was expelled. At Todd School, Welles came under the influence of Roger Hill, a teacher who was later the school's headmaster. Hill provided Welles with an \"ad hoc\" educational environment that proved invaluable to his creative experience, allowing Welles to concentrate on subjects that interested him. Welles performed and staged theatrical experiments and productions.\n\"Todd provided Welles with many valuable experiences\", wrote critic Richard France. \"He was able to explore and experiment in an atmosphere of acceptance and encouragement. In addition to a theatre, the school's own radio station was at his disposal.\" Welles's first radio experience was on that station, performing his own adaptation of \"Sherlock Holmes\".\nOn December 28, 1930, when Welles was 15, his father died of heart and kidney failure in a hotel in Chicago, aged 58. Shortly before, Welles had told his father that he refused to see him until he stopped drinking. Welles suffered lifelong guilt and despair that he was unable to express. \"That was the last I ever saw of him\", Welles told biographer Barbara Leaming 53 years later. \"I've never, never ... I don't want to forgive myself.\" His father's will left Welles to name his own guardian. When Roger Hill declined, he chose Dr. Maurice Bernstein, a physician and friend of the family.&lt;ref name=\"newyorker/ageless-soul\"&gt;&lt;/ref&gt;&lt;ref name=\"umich.edu/never-before-seen\"&gt;&lt;/ref&gt;\nFollowing graduation from Todd in May 1931, Welles was awarded a scholarship to Harvard College; his mentor Roger Hill advised him to attend Cornell College in Iowa. Instead, Welles chose travel. He studied for a few weeks at the Art Institute of Chicago with Boris Anisfeld, who encouraged him to pursue painting.\nWelles occasionally returned to Woodstock. He was asked in a 1960 interview, \"Where is home?\" and replied, \"I suppose it's Woodstock, Illinois, if it's anywhere. I went to school there for four years. If I try to think of a home, it's that.\"\nEarly career (1931\u20131935).\nAfter his father's death, Welles traveled to Europe using a portion of his inheritance. Welles said that while on a walking and painting trip through Ireland, he strode into the Gate Theatre in Dublin and claimed he was a Broadway star. The manager of the Gate, Hilton Edwards, later said he had not believed Welles but was impressed by his brashness and an impassioned audition. Welles made his stage debut at the Gate Theatre on October 13, 1931, appearing in Ashley Dukes's adaptation of \"Jud S\u00fc\u00df\" as Duke Karl Alexander of W\u00fcrttemberg. He performed supporting roles in Gate productions, and produced and designed productions of his own. In March 1932, Welles performed in W. Somerset Maugham's \"The Circle\" at Dublin's Abbey Theatre and traveled to London to find work in the theatre. Unable to obtain a work permit, he returned to the U.S.\nWelles found his fame ephemeral and turned to a writing project at Todd School that became immensely successful, first entitled \"Everybody's Shakespeare\",&lt;ref name=\"10.1080/17450910600983828\"&gt;&lt;/ref&gt;&lt;ref name=\"oldfloridabookshop/11971\"&gt;&lt;/ref&gt; for the first three volumes,&lt;ref name=\"lib.uiowa/\"&gt;&lt;/ref&gt; and subsequently, \"The Mercury Shakespeare\". In Spring 1933, Welles traveled via the \"SS Exermont\", a tramp steamer, writing the introduction for the books while onboard. After landing at Morocco, he stayed as the guest of Thami El Glaoui, in the Atlas mountains surrounding Tangier, while working on thousands of illustrations for the \"Everybody's Shakespeare\" series of educational books, a series that remained in print for decades.\nIn 1933, Hortense and Roger Hill invited Welles to a party in Chicago, where Welles met Thornton Wilder. Wilder arranged for Welles to meet Alexander Woollcott in New York so he could be introduced to Katharine Cornell, who was assembling a theatre company for a seven-month transcontinental repertory tour. Cornell's husband, director Guthrie McClintic, immediately put Welles under contract and cast him in three plays. \"Romeo and Juliet\", \"The Barretts of Wimpole Street\" and \"Candida\" began touring in repertory in November 1933, with the first of more than 200 performances taking place in Buffalo, New York.\nIn 1934, Welles got his first job on radio\u2014with \"The American School of the Air\"\u2014through actor-director Paul Stewart, who introduced him to director Knowles Entrikin. That summer, Welles staged a drama festival with the Todd School at the Opera House in Woodstock, Illinois, inviting Miche\u00e1l Mac Liamm\u00f3ir and Hilton Edwards from Dublin's Gate Theatre to appear along with New York stage luminaries in productions including \"Trilby\", \"Hamlet\", \"The Drunkard\" and \"Tsar Paul\". At the old firehouse in Woodstock, he also shot his first film, an eight-minute short titled \"The Hearts of Age\".\nOn November 14, 1934, Welles married Chicago socialite and actress Virginia Nicolson in a civil ceremony in New York. To appease the Nicolsons, who were furious at the elopement, a formal ceremony took place December 23, 1934, at the New Jersey mansion of the bride's godmother. Welles wore a cutaway borrowed from his friend George Macready.\nA revised production of Katharine Cornell's \"Romeo and Juliet\" opened December 20, 1934, at the Martin Beck Theatre in New York. The Broadway production brought the 19-year-old Welles to the notice of John Houseman, a theatrical producer who was casting the lead in the debut production of one of Archibald MacLeish's verse plays, \"Panic\". On March 22, 1935, Welles made his debut on the CBS Radio series \"The March of Time\", performing a scene from \"Panic\" for a news report on the stage production.\nBy 1935, Welles was supplementing his earnings in the theatre as a radio actor in Manhattan, working with many actors who later formed the core of his Mercury Theatre on programs including \"America's Hour\", \"Cavalcade of America\", \"Columbia Workshop\" and \"The March of Time\". \"Within a year of his debut Welles could claim membership in that elite band of radio actors who commanded salaries second only to the highest paid movie stars,\" wrote critic Richard France.\nTheatre (1936\u201338).\nFederal Theatre Project.\nPart of the Works Progress Administration, the Federal Theatre Project (1935\u201339) was a New Deal program to fund theatre and other live artistic performances and entertainment programs in the US during the Great Depression. It was created as a relief measure to employ artists, writers, directors and theatre workers. Under national director Hallie Flanagan it was shaped into a national theatre that created relevant art, encouraged experimentation and innovation, and made it possible for millions of Americans to see live theatre for the first time.\nJohn Houseman, director of the Negro Theatre Unit in New York, invited Welles to join the Federal Theatre Project in 1935. Far from unemployed\u2014\"I was so employed I forgot how to sleep\"\u2014Welles put a large share of his $1,500-a-week radio earnings into his stage productions, bypassing administrative red tape and mounting the projects more quickly and professionally. \"Roosevelt once said that I was the only operator in history who ever illegally siphoned money \"into\" a Washington project,\" Welles said.\nThe Federal Theatre Project was the ideal environment in which Welles could develop his art. Its purpose was employment, so he was able to hire many artists, craftsmen and technicians, and he filled the stage with performers. The company for the first production, an adaptation of Shakespeare's \"Macbeth\" with an African-American cast, numbered 150. The production became known as the \"Voodoo Macbeth\" because Welles changed the setting to a mythical island suggesting the Haitian court of King Henri Christophe, with Haitian \"vodou\" fulfilling the role of Scottish witchcraft. The play opened April 14, 1936, at the Lafayette Theatre in Harlem and was received rapturously. At 20, Welles was hailed as a prodigy. The production then made a 4,000-mile national tour that included two weeks at the Texas Centennial Exposition in Dallas.\nNext mounted was the farce \"Horse Eats Hat\", an adaptation by Welles and Edwin Denby of \"The Italian Straw Hat\", an 1851 five-act farce by Eug\u00e8ne Marin Labiche and Marc-Michel. The play was presented September 26 \u2013 December 5, 1936, at Maxine Elliott's Theatre, New York, and featured Joseph Cotten in his first starring role. It was followed by an adaptation of \"Dr. Faustus\" that used light as a prime unifying scenic element in a nearly black stage, presented January 8 \u2013 May 9, 1937, at Maxine Elliott's Theatre.\nOutside the scope of the Federal Theatre Project, American composer Aaron Copland chose Welles to direct \"The Second Hurricane\" (1937), an operetta with a libretto by Edwin Denby. Presented at the Henry Street Settlement Music School in New York for the benefit of high school students, the production opened April 21, 1937, and ran its scheduled three performances.\nIn 1937, Welles rehearsed Marc Blitzstein's political opera, \"The Cradle Will Rock\". It was originally scheduled to open June 16, 1937, in its first public preview. Because of cutbacks in the WPA projects, the premiere at the Maxine Elliott Theatre was canceled. The theater was locked, and guarded, to prevent any government-purchased materials from being used for a commercial production of the work. In a last-minute move, Welles announced to ticket-holders that the show was being transferred to the Venice, 20 blocks away. Some cast, crew and audience, walked on foot. The union musicians refused to perform in a commercial theater for lower non-union government wages. The actors' union stated that the production belonged to the Federal Theatre Project, and could not be performed outside that context without permission. Lacking participation of the union members, \"The Cradle Will Rock\" began with Blitzstein introducing it and playing the piano accompaniment on stage, with some cast members performing from the audience. This impromptu performance was well received by its audience.\nMercury Theatre.\nBreaking with the Federal Theatre Project in 1937, Welles and Houseman founded a repertory company, called the Mercury Theatre. The name was inspired by the title of the iconoclastic magazine \"The American Mercury\". Welles was executive producer, and the original company included such actors as Joseph Cotten, George Coulouris, Geraldine Fitzgerald, Arlene Francis, Martin Gabel, John Hoyt, Norman Lloyd, Vincent Price, Stefan Schnabel and Hiram Sherman.\n\"I think he was the greatest directorial talent we've ever had in the [American] theater\", Lloyd said of Welles in 2014. \"When you saw a Welles production, you saw the text had been affected, the staging was remarkable, the sets were unusual, music, sound, lighting, a totality of everything. We had not had such a man in our theater. He was the first and remains the greatest.\"\nThe Mercury Theatre opened November 11, 1937, with \"Caesar\", Welles's modern-dress adaptation of Shakespeare's \"Julius Caesar\"\u2014streamlined into an anti-fascist tour de force that Joseph Cotten later described as \"so vigorous, so contemporary that it set Broadway on its ear\". The set was completely open with no curtain, and the brick stage wall was painted dark red. Scene changes were achieved by lighting alone. On the stage was a series of risers; squares were cut into one at intervals and lights, designed by Jean Rosenthal, were set beneath it, pointing straight up to evoke the \"cathedral of light\" at the Nuremberg Rallies. \"He staged it like a political melodrama that happened the night before,\" said Lloyd.\nBeginning January 1, 1938, \"Caesar\" was performed in repertory with \"The Shoemaker's Holiday\"; both productions moved to the larger National Theatre. They were followed by \"Heartbreak House\" (April 29, 1938) and \"Danton's Death\" (November 5, 1938). As well as being presented in a pared-down oratorio version at the Mercury Theatre in December 1937, \"The Cradle Will Rock\" was at the Windsor Theatre January 4 \u2013 April 2, 1938. Such was the success of the Mercury Theatre that Welles appeared on the cover of \"Time\", in full makeup as Captain Shotover in \"Heartbreak House\", on May 9\u2014three days after his 23rd birthday.\nRadio (1936\u20131940).\nSimultaneously with his work in the theatre, Welles worked extensively in radio as an actor, writer, director, and producer, often without credit. Between 1935\u201337 he was earning as much as $2,000 a week, shuttling between studios at such a pace that he would arrive barely in time for a scan of his lines before he was on the air. While he was directing the \"Voodoo Macbeth\" Welles was dashing between Harlem and midtown Manhattan three times a day to meet his radio commitments.\nIn addition to continuing as a repertory player on \"The March of Time\", in the fall of 1936 Welles adapted and performed \"Hamlet\" in an episode of CBS Radio's \"Columbia Workshop\". His performance as the announcer in the series' April 1937 presentation of Archibald MacLeish's verse drama \"The Fall of the City\" was an important development in his radio career and made the 21-year-old Welles an overnight star.\nIn July 1937, the Mutual Network gave Welles a seven-week series to adapt \"Les Mis\u00e9rables\". It was his first job as a writer-director for radio, the debut of the Mercury Theatre, and one of Welles's finest achievements. He invented the use of narration in radio.\n\"By making himself the center of the storytelling process, Welles fostered the impression of self-adulation that was to haunt his career to his dying day\", wrote critic Andrew Sarris. \"For the most part, however, Welles was singularly generous to the other members of his cast and inspired loyalty from them above and beyond the call of professionalism.\"\nThat September, Mutual chose Welles to play Lamont Cranston, also known as The Shadow. He performed the role through mid-September 1938.\n\"The Mercury Theatre on the Air\".\nAfter the theatrical successes of the Mercury Theatre, CBS Radio invited Welles to create a summer show for 13 weeks. The series began July 11, 1938, with the formula that Welles would play the lead in each show. The weekly hour-long show presented radio plays based on classic literary works, with original music composed and conducted by Bernard Herrmann.\nThe Mercury Theatre's radio adaptation of \"The War of the Worlds\" by H. G. Wells October 30, 1938, brought Welles instant fame. The combination of the news bulletin form of the performance, with the between-breaks dial-spinning habits of listeners, created confusion among listeners who failed to hear the introduction, although the extent of this confusion has come into question. Panic was reportedly spread among listeners who believed the fictional news reports of a Martian invasion. The myth of the result created by the combination was reported as fact around the world and disparagingly mentioned by Adolf Hitler in a speech.\nWelles's growing fame drew Hollywood offers, lures that the independent-minded Welles resisted at first. \"The Mercury Theatre on the Air\", which had been a sustaining show (without sponsorship), was picked up by Campbell Soup and renamed \"The Campbell Playhouse\". \"The Mercury Theatre on the Air\" made its last broadcast on December 4, 1938, and \"The Campbell Playhouse\" began five days later.\nWelles began commuting from California to New York for the Sunday broadcasts of \"The Campbell Playhouse\" after signing a film contract with RKO Pictures in August 1939. In November, production of the show moved to Los Angeles. After 20 shows, Campbell began to exercise more creative control and had complete control over story selection. As his contract with Campbell came to an end, Welles chose not to sign on for another season. After the broadcast of March 31, 1940, Welles and Campbell parted amicably.\nHollywood (1939\u20131948).\nRKO Radio Pictures president George J. Schaefer ultimately offered Welles what generally is considered the greatest contract offered to a filmmaker, much less to one who was untried. Engaging him to write, produce, direct and perform in two pictures, the contract subordinated the studio's financial interests to Welles's creative control, and broke precedent by granting Welles final cut. After signing a summary agreement with RKO on July 22, Welles signed a full-length 63-page contract August 21, 1939. The agreement was bitterly resented by the Hollywood studios and persistently mocked in the trade press.\n\"Citizen Kane\".\nRKO rejected Welles's first two movie proposals, but agreed on the third\u2014\"Citizen Kane\". Welles co-wrote, produced, directed and starred in it. Welles conceived the project with screenwriter Herman J. Mankiewicz, who was writing radio plays for \"The Campbell Playhouse\". Mankiewicz based the original outline of the film script on the life of William Randolph Hearst, whom he knew and came to hate after being exiled from Hearst's circle.\nAfter agreeing on the storyline and character, Welles supplied Mankiewicz with 300 pages of notes and put him under contract to write the first-draft screenplay under the supervision of John Houseman. Welles wrote his own draft, then drastically condensed and rearranged both versions and added scenes of his own. The industry accused Welles of underplaying Mankiewicz's contribution to the script, but Welles countered the attacks by saying, \"At the end, naturally, I was the one making the picture, after all\u2014who had to make the decisions. I used what I wanted of Mank's and, rightly or wrongly, kept what I liked of my own.\"\nFor the cast, Welles primarily used actors from his Mercury Theatre, including William Alland, Ray Collins, Joseph Cotten, Agnes Moorehead, Erskine Sanford, Everett Sloane and Paul Stewart in their film debuts. Welles's project attracted some of Hollywood's best technicians, including cinematographer Gregg Toland. Welles and Toland made extensive use of deep focus photography, in which everything in the frame is in focus. Toland explained that he and Welles thought \"that if it was possible, the picture should be brought to the screen in such a way that the audience would feel it was looking at reality, rather than merely at a movie.\" They composed \"our angles and compositions so that action which ordinarily would be shown in direct cuts would be shown in a single, longer scene--often one in which important action might take place simultaneously in widely separated points in extreme foreground and background.\"\nToland explained their use of deep (or pan) focus: Through its use, it is possible to photograph action from a range of eighteen inches from the camera lens to over two hundred feet away, with extreme foreground and background figures and action both recorded in sharp relief. Hitherto, the camera had to be focused either for a close or a distant shot, all efforts to encompass both at the same time resulting in one or the other being out of focus. This handicap necessitated the breaking up of a scene into long and short angles, with much consequent loss of realism. With pan-focus, the camera, like the human eye, sees an entire panorama at once, with everything clear and lifelike.\nWelles called Toland \"the greatest gift any director\u2014young or old\u2014could ever, ever have. And he never tried to impress on us that he was performing miracles. He just went ahead and performed them. I was calling on him to do things only a beginner could be ignorant enough to think anybody could ever do, and there he was, \"doing\" them.\" When asked why he and Toland used depth of focus, Welles explained: \"Well, in life you see everything in focus at the same time, so why not in the movies?\"\nIt was the first film scored by Bernard Herrmann, who had worked with Welles in radio. Hermann recalled: \"two full weeks were spent in the dubbing room, and music under our supervision was often re-recorded six or seven times before the proper dynamic level was achieved. The result is an exact projection of the original musical ideas in the score. Technically, no composer could ask for more.\" Filming \"Citizen Kane\" took ten weeks.\nHearst's newspapers barred all reference to \"Citizen Kane\" and exerted enormous pressure on the Hollywood film community to force RKO to shelve the film. RKO chief George J. Schaefer received a cash offer from MGM's Louis B. Mayer and other major studio executives if he would destroy the negative and existing prints of the film.\nWhile waiting for \"Citizen Kane\" to be released, Welles produced and directed the original Broadway production of \"Native Son\", a drama written by Paul Green and Richard Wright based on Wright's novel. Starring Canada Lee, the show ran March 24 \u2013 June 28, 1941, at the St. James Theatre. The Mercury Production was the last time Welles and Houseman worked together.\nAlthough \"Citizen Kane\" was given a limited release, it received overwhelming critical praise. It was voted the best picture of 1941 by the National Board of Review and New York Film Critics Circle. The film garnered nine Academy Award nominations but won only Best Original Screenplay, shared by Mankiewicz and Welles. \"Variety\" reported that block voting by extras deprived \"Citizen Kane\" of Oscars for Best Picture and Best Actor (Welles), and similar prejudices were likely to have been responsible for the film receiving no technical awards. Bosley Crowther wrote that Welles \"has made a picture of tremendous and overpowering scope, not in physical extent so much as in its rapid and graphic rotation of thoughts. Mr. Welles has put upon the screen a motion picture that really moves.\" Cecelia Ager, in \"PM Magazine\", wrote: \"Before \"Citizen Kane\", it's as if the motion picture were a slumbering monster, a mighty force stupidly sleeping, lying there...awaiting a fierce young man to come kick it to life, to rouse it, shake it, awaken it to its potentialities ... Seeing it, it's as if you never really saw a movie before.\"\nThe delay in the film's release and uneven distribution contributed to mediocre results at the box office. After it ran its course theatrically, \"Citizen Kane\" was retired to the vault in 1942. In France, however, its reputation grew after it was seen there for the first time in 1946. In the US, it began to be re-evaluated after it appeared on television in 1956. That year it was re-released theatrically, and film critic Andrew Sarris described it as \"the great American film\" and \"the work that influenced the cinema more profoundly than any American film since \"The Birth of a Nation\".\" \"Citizen Kane\" is now widely hailed as one of the greatest films ever made. From 1962 to 2012, it topped the decennial \"Sight and Sound\" poll of the Greatest Films of All Time.\n\"The Magnificent Ambersons\".\n\"The fate of \"The Magnificent Ambersons\" is one of film history's great tragedies,\" wrote film historian Robert L. Carringer. It was Welles's second film for RKO, adapted by Welles from Booth Tarkington's Pulitzer Prize-winning 1918 novel about the declining fortunes of a wealthy Midwestern family and the social changes brought by the automobile age. Toland was unavailable, so Stanley Cortez was named cinematographer. The meticulous Cortez worked slowly and the film lagged behind schedule and over budget. In contract renegotiations with RKO over a film he was obliged to direct, Welles had conceded final cut.\n\"The Magnificent Ambersons\" was in production October 28, 1941, to January 22, 1942, with a cast including Cotten, Collins, Moorehead, Dolores Costello, Anne Baxter and Tim Holt. RKO chief George Schaefer understood that presenting a downbeat period film without marquee stars was a risk, but he was reassured by a special screening of the film-in-progress Welles arranged for him on November 28. Schaefer was an expert in film distribution and attended to the marketing strategy.\nRequired to start filming the \"Carnaval\" segment of \"It's All True\" in early February 1942, Welles rushed to edit \"The Magnificent Ambersons\" and finish his acting scenes in \"Journey into Fear\". He ended his lucrative CBS radio show February 2, flew to Washington, D.C., for a briefing, and then lashed together a rough cut of \"Ambersons\" in Miami with editor Robert Wise.\nA finished 131-minute version, edited per Welles's detailed instructions, was previewed March 17, 1942, in Pomona. Schaefer was present, and was rattled by the audience response: 75 percent of the preview cards were negative. The film was received more favorably by a preview audience in the more upscale Pasadena on March 19, with only 25 percent of the preview cards negative. But the experience led Schaefer to authorize the studio to make whatever changes necessary to make \"The Magnificent Ambersons\" a commercial success.\nWise, whom Welles had left in charge of postproduction, removed nearly 50 minutes of footage from Welles's cut, and several scenes \u2014 including the ending \u2014 were rewritten and reshot. Over Welles's opposition, \"The Magnificent Ambersons\" was cut to 88 minutes. Like the film, Bernard Herrmann's score was heavily edited by RKO. When more than half the score was removed and replaced by music by Roy Webb, Herrmann bitterly severed his ties with the film and promised legal action if he was not removed from the credits.\nEven in its released form, \"The Magnificent Ambersons\" is considered one of the best films of all time. The film was nominated for four Academy Awards, including Best Picture, and added to the National Film Registry in 1991.\n\"Journey into Fear\".\nAt RKO's request, Welles worked on an adaptation of Eric Ambler's spy thriller \"Journey into Fear\", co-written with Cotten. In addition to acting in it, Welles was the producer. Direction was credited to Norman Foster. Welles later said they were in such a rush that the director of each scene was determined by whoever was closest to the camera. \"Journey into Fear\" was in production January 6 \u2013 March 12, 1942.\nWar work.\nGoodwill ambassador.\nIn late November 1941, Welles was appointed as a goodwill ambassador to Latin America by Nelson Rockefeller, U.S. Coordinator of Inter-American Affairs and a principal stockholder in RKO Radio Pictures. The mission of the OCIAA was cultural diplomacy, promoting hemispheric solidarity and countering the growing influence of the Axis powers in Latin America. John Hay Whitney, head of the agency's Motion Picture Division, was asked by the Brazilian government to produce a documentary of the annual Rio Carnival taking place in early February 1942. In a telegram on December 20, 1941, Whitney wrote Welles, \"Personally believe you would make great contribution to hemisphere solidarity with this project.\"\nThe OCIAA sponsored cultural tours to Latin America and appointed goodwill ambassadors including George Balanchine and the American Ballet, Bing Crosby, Aaron Copland, Walt Disney, John Ford and Rita Hayworth. Welles was briefed in Washington, D.C., immediately before departure for Brazil, and film scholar Catherine L. Benamou, finds it likely he was among the goodwill ambassadors asked to gather intelligence for the U.S. government. She concludes that Welles's acceptance of Whitney's request was \"a logical and patently patriotic choice\".\nIn addition to working on his ill-fated film \"It's All True\", Welles was responsible for radio programs, lectures, interviews and informal talks as part of his OCIAA-sponsored cultural mission, which was regarded as a success. He spoke on topics ranging from Shakespeare to visual art at gatherings of Brazil's elite, and his intercontinental radio broadcasts in April 1942 were particularly intended to tell U.S. audiences that President Get\u00falio Vargas was a partner with the Allies. Welles's ambassadorial mission was extended to permit his travel to Argentina, Bolivia, Chile, Colombia, Ecuador, Guatemala, Mexico, Peru and Uruguay. Welles worked for more than 6 months with no compensation.\nWelles's own expectations for the film were modest. \"\"It's All True\" was not going to make any cinematic history, nor was it intended to,\" he later said. \"It was intended to be a perfectly honorable execution of my job as a goodwill ambassador, bringing entertainment to the Northern Hemisphere that showed them something about the Southern one.\"\n\"It's All True\".\nIn July 1941, Welles conceived \"It's All True\" as an omnibus film mixing documentary and docufiction in a project that emphasized the dignity of labor and celebrated the cultural and ethnic diversity of North America. It was to have been his third film for RKO, following \"Citizen Kane\" (1941) and \"The Magnificent Ambersons\" (1942). Duke Ellington was put under contract to score a segment with the working title, \"The Story of Jazz\", drawn from Louis Armstrong's 1936 autobiography, \"Swing That Music\". Armstrong was cast to play himself in the dramatization of the history of jazz performance, from its roots to its place in American culture. \"The Story of Jazz\" was to go into production in December 1941.\nMercury Productions purchased the stories for other segments\u2014\"My Friend Bonito\" and \"The Captain's Chair\"\u2014from documentary filmmaker Robert J. Flaherty. Adapted by Norman Foster and John Fante, \"My Friend Bonito\" was the only segment of the original \"It's All True\" to go into production. Filming took place in Mexico September\u2013December 1941, with Norman Foster directing under Welles's supervision.\nIn December 1941, the Office of the Coordinator of Inter-American Affairs asked Welles to make a film in Brazil that would showcase the Carnaval in Rio. With filming of \"My Friend Bonito\" about two-thirds complete, Welles decided he could shift the geography of \"It's All True\" and incorporate Flaherty's story into an omnibus film about Latin America\u2014supporting the Roosevelt administration's Good Neighbor policy, which Welles advocated. In this revised concept, \"The Story of Jazz\" was replaced by the story of samba, a musical form with a comparable history and one that came to fascinate Welles. He decided to do a ripped-from-the-headlines episode about the epic voyage of four poor Brazilian fishermen, the jangadeiros, who had become national heroes. Welles later said this was the most valuable story.\nRequired to film the Carnaval in Rio in early February 1942, Welles rushed to edit \"The Magnificent Ambersons\" and finish his acting scenes in \"Journey into Fear\". He ended his lucrative CBS radio show February 2, flew to Washington, D.C., for a briefing, and then lashed together a rough cut of \"Ambersons\" in Miami with editor Robert Wise. Welles recorded the film's narration the night before he left for South America: \"I went to the projection room at about four in the morning, did the whole thing, and then got on the plane and off to Rio\u2014and the end of civilization as we know it.\"\nWelles left for Brazil on February 4 and began filming in Rio on February 8, 1942. It did not seem that Welles's other film projects would be disrupted, but as film historian Catherine L. Benamou wrote, \"the ambassadorial appointment would be the first in a series of turning points leading\u2014in 'zigs' and 'zags,' rather than in a straight line\u2014to Welles's loss of complete directorial control over \"The Magnificent Ambersons\" and \"It's All True\", the cancellation of his contract at RKO Radio Studio, the expulsion of his company Mercury Productions from the RKO lot, and the total suspension of \"It's All True\".\"\nIn 1942 RKO Pictures underwent changes under new management. Nelson Rockefeller, the primary backer of the Brazil project, left its board, and Welles's principal sponsor at RKO, studio president George Schaefer, resigned. RKO took control of \"Ambersons\" and edited it into what RKO considered a commercial format. Welles's attempts to protect his version failed. In South America, Welles requested resources to finish \"It's All True\". Given a limited amount of black-and-white film stock and a silent camera, he was able to finish shooting the episode about the jangadeiros, but RKO refused to support further production.\n\"So I was fired from RKO,\" Welles recalled. \"And they made a great publicity point of the fact that I had gone to South America without a script and thrown all this money away. I never recovered from that attack.\" Later in 1942, when RKO Pictures began promoting its new corporate motto, \"Showmanship In Place of Genius: A New Deal at RKO\", Welles understood it as a reference to him.\nRadio (1942\u20131943).\nWelles returned to the US on August 22, 1942, after more than six months in South America. A week after his return he produced and emceed the first two hours of a seven-hour coast-to-coast War Bond drive broadcast titled \"I Pledge America\". Airing August 29, 1942, on the Blue Network, the program was presented in cooperation with the United States Department of the Treasury, Western Union and the American Women's Voluntary Services. Featuring 21 dance bands and a score of stage and screen and radio stars, the broadcast raised more than $10\u00a0million\u2014more than $146\u00a0million today\u2014for the war effort.\nOn October 12, 1942, \"Cavalcade of America\" presented Welles's radio play, \"Admiral of the Ocean Sea\", an entertaining and factual look at the legend of Christopher Columbus. \"It belongs to a period when hemispheric unity was a crucial matter and many programs were being devoted to the common heritage of the Americas,\" wrote broadcasting historian Erik Barnouw. \"Many such programs were being translated into Spanish and Portuguese and broadcast to Latin America, to counteract many years of successful Axis propaganda to that area. The Axis, trying to stir Latin America against Anglo-America, had constantly emphasized the differences between the two. It became the job of American radio to emphasize their common experience and essential unity.\"\n\"Admiral of the Ocean Sea\", also known as \"Columbus Day\", begins with the words, \"Hello Americans\"\u2014the title Welles would choose for his own series five weeks later.\n\"Hello Americans\", a CBS Radio series broadcast November 15, 1942 \u2013 January 31, 1943, was produced, directed and hosted by Welles under the auspices of the Office of the Coordinator for Inter-American Affairs. The 30-minute weekly program promoted inter-American understanding and friendship, drawing upon the research amassed for the ill-fated film, \"It's All True\". The series was produced concurrently with Welles's other CBS series, \"Ceiling Unlimited\" (November 9, 1942 \u2013 February 1, 1943), sponsored by the Lockheed-Vega Corporation. The program was conceived to glorify the aviation industry and dramatize its role in World War II. Welles's shows were regarded as significant contributions to the war effort.\nThroughout the war Welles worked on patriotic radio programs including \"Command Performance\", \"G.I. Journal\", \"Mail Call\", \"Nazi Eyes on Canada\", \"Stage Door Canteen\" and \"Treasury Star Parade\".\n\"The Mercury Wonder Show\".\nIn early 1943, the two concurrent radio series (\"Ceiling Unlimited\", \"Hello Americans\") that Welles created for CBS to support the war effort had ended. Filming had wrapped on the 1943 film adaptation of \"Jane Eyre\", for which he received $100,000; that fee, in addition to the income from his guest-star roles in radio, made it possible for Welles to fulfill a lifelong dream. He approached the War Assistance League of Southern California and proposed a show that evolved into a big-top spectacle, part circus and part magic show. He offered his services as magician and director, and invested $40,000 in an extravaganza he co-produced with his friend Cotten: \"The Mercury Wonder Show for Service Men\". Members of the armed forces were admitted free of charge, while the public had to pay. The show entertained 1,000 service members each night, and proceeds went to the War Assistance League, a charity for military service personnel.\nThe development of the show coincided with the resolution of Welles's oft-changing draft status in May 1943, when he was finally declared 4-F\u2014unfit for military service\u2014for medical reasons. \"I felt guilty about the war,\" Welles told biographer Barbara Leaming. \"I was guilt-ridden about my civilian status.\" He had been publicly hounded about his patriotism since \"Citizen Kane\", when the Hearst press began persistent inquiries about why Welles had not been drafted.\n\"The Mercury Wonder Show\" ran August 3 \u2013 September 9, 1943, in an 80-by-120-foot tent located at 900 Cahuenga Boulevard, in the heart of Hollywood. At intermission on September 7, 1943, KMPC radio interviewed audience and cast members of \"The Mercury Wonder Show\"\u2014including Welles and Rita Hayworth, who were married earlier that day. Welles remarked that \"The Mercury Wonder Show\" had been performed for 48,000 members of the armed forces.\nRadio (1944\u201345).\nThe idea of doing a radio variety show occurred to Welles after his success as substitute host of consecutive episodes (March 14 \u2013 April 4, 1943) of \"The Jack Benny Program\", radio's most popular show, when Benny contracted pneumonia on a performance tour of military bases. A half-hour variety show broadcast January 26 \u2013 July 19, 1944, on the Columbia Pacific Network, \"The Orson Welles Almanac\" presented sketch comedy, magic, mindreading, music and readings from classic works. Many of the shows originated on U.S. military camps, where Welles and his repertory company and guests entertained the troops with a reduced version of \"The Mercury Wonder Show\". The performances of the all-star jazz group Welles brought together for the show were so popular that the band became a regular feature and was an important force in reviving interest in traditional New Orleans jazz.\nWelles was placed on the U.S. Treasury payroll on May 15, 1944, as an expert consultant for the duration of the war, with a retainer of $1 a year. On the recommendation of President Franklin D. Roosevelt, Secretary of the Treasury Henry Morgenthau asked Welles to lead the Fifth War Loan Drive, which opened June 12 with a radio show on all four networks, broadcast from Texarkana, Texas. Including a statement by the President, the program defined the causes of the war and encouraged Americans to buy $16\u00a0billion in bonds to finance the Normandy landings. Welles produced additional war loan drive broadcasts on June 14 from the Hollywood Bowl, and June 16 from Soldier Field, Chicago. Americans purchased $21\u00a0billion in War Bonds during the Fifth War Loan Drive, which ended on July 8, 1944.\nWelles campaigned ardently for Roosevelt in 1944. A longtime supporter and campaign speaker for FDR, he occasionally sent the president ideas and phrases that were sometimes incorporated into what Welles characterized as \"less important speeches\". One of these was the joke in what came to be called the Fala speech, Roosevelt's nationally broadcast September 23 address to the International Teamsters Union which opened the 1944 presidential campaign.\nWelles campaigned for the Roosevelt\u2013Truman ticket almost full-time in the fall of 1944, traveling to nearly every state to the detriment of his health and at his own expense. In addition to his radio addresses he filled in for Roosevelt, opposite Republican presidential nominee Thomas E. Dewey, at \"The New York Herald Tribune Forum\" broadcast October 18 on the Blue Network. Welles accompanied FDR to his last campaign rally, speaking at an event November 4 at Boston's Fenway Park before 40,000 people, and took part in a historic election-eve campaign broadcast November 6 on all four radio networks.\nOn November 21, 1944, Welles began his association with \"This Is My Best\", a CBS radio series he would produce, direct, write and host (March 13 \u2013 April 24, 1945). He wrote a political column called \"Orson Welles' Almanac\" (later titled \"Orson Welles Today\") for \"The New York Post\" January\u2013November 1945, and advocated the continuation of FDR's New Deal policies and international vision, particularly the establishment of the UN and world peace.\nOn April 12, 1945, the day Roosevelt died, the Blue-ABC network marshalled its executive staff and national leaders to pay homage to the president. \"Among the outstanding programs which attracted wide attention was a special tribute delivered by Orson Welles\", reported \"Broadcasting\" magazine. Welles spoke at 10:10 p.m Eastern War Time, from Hollywood, and stressed the importance of continuing FDR's work: \"He has no need for homage and we who loved him have no time for tears ... Our fighting sons and brothers cannot pause tonight to mark the death of him whose name will be given to the age we live in.\" Welles presented another special broadcast on the Roosevelt's death the following evening: \"We must move on beyond mere death to that free world which was the hope and labor of his life.\"\nHe dedicated the April 17 episode of \"This Is My Best\" to Roosevelt and the future of America on the eve of the United Nations Conference on International Organization. Welles was an advisor and correspondent for the Blue-ABC radio network's coverage of the San Francisco conference that formed the UN, taking place April 24 \u2013 June 23, 1945. He presented a half-hour dramatic program written by Ben Hecht on the opening day of the conference, and on Sunday afternoons (April 29 \u2013 June 10) he led a weekly discussion from the San Francisco Civic Auditorium.\n\"The Stranger\".\nIn the fall of 1945 Welles began work on \"The Stranger\" (1946), a film noir drama about a war crimes investigator who tracks a high-ranking Nazi fugitive to an idyllic New England town. Edward G. Robinson, Loretta Young and Welles star.\nProducer Sam Spiegel initially planned to hire director John Huston, who had rewritten the screenplay by Anthony Veiller. When Huston entered the military, Welles was given the chance to direct and prove himself able to make a film on schedule and under budget\u2014something he was so eager to do that he accepted a disadvantageous contract. One of its concessions was that he would defer to the studio in any creative dispute.\n\"The Stranger\" was Welles's first job as a film director in four years. He was told that if the film was successful he could sign a four-picture deal with International Pictures, making films of his own choosing. Welles was given some creative control, and endeavored to personalize the film and develop a nightmarish tone. He worked on the general rewrite of the script and wrote scenes at the beginning of the picture shot, but cut by producers. He filmed in long takes that largely thwarted the control given to editor Ernest J. Nims under the terms of the contract.\n\"The Stranger\" was the first commercial film to use documentary footage from the concentration camps. Welles had seen the footage in early May 1945 in San Francisco, as a correspondent and discussion moderator at the UN Conference on International Organization. He wrote of the Holocaust footage in his syndicated \"New York Post\" column May 7, 1945.\nCompleted a day ahead of schedule and under budget, \"The Stranger\" was the only film made by Welles to have been a \"bona fide\" box office success upon its release. Its cost was $1.03\u00a0million; 15 months after its release it had grossed $3.2\u00a0million. Within weeks of the completion of the film, International Pictures backed out of its promised four-picture deal with Welles. No reason was given, but the impression was left that \"The Stranger\" would not make money.\n\"Around the World\".\nIn the summer of 1946, Welles moved to New York to direct the Broadway musical \"Around the World\", a stage adaptation of Jules Verne's novel \"Around the World in Eighty Days\" with a book by Welles and music by Cole Porter. Producer Mike Todd, who would produce the successful 1956 film adaptation, pulled out from the lavish and expensive production, leaving Welles to support the finances. When Welles ran out of money he convinced Columbia Pictures president Harry Cohn to send enough to continue the show, and in exchange Welles promised to write, produce, direct and star in a film for Cohn for no further fee. The stage show soon failed due to poor box-office, with Welles unable to claim the losses on his taxes. Inspired by magician and cinema pioneer Georges M\u00e9li\u00e8s, the show required 55 stagehands and used films to bridge scenes. Welles said it was his favorite of his stage productions. Regarding its extravagance, critic Robert Garland said it had \"everything but the kitchen sink.\" The next night, Welles brought out a kitchen sink.\nRadio (1946).\nIn 1946, Welles began two new radio series\u2014\"The Mercury Summer Theatre of the Air\" for CBS, and \"Orson Welles Commentaries\" for ABC. While \"Mercury Summer Theatre\" featured half-hour adaptations of some classic Mercury radio shows from the 1930s, the first episode was a condensation of his \"Around the World\" stage play, and is the only record of Cole Porter's music for the project. Several original Mercury actors returned for the series, as well as Bernard Herrmann. Welles invested his earnings into his failing stage play. \"Commentaries\" was a political vehicle, continuing the themes from his \"New York Post\" column. Again, Welles lacked a clear focus, until the NAACP brought to his attention the case of Isaac Woodard. Welles brought significant attention to Woodard's cause.\nThe last broadcast of \"Orson Welles Commentaries\" on October 6, 1946, marked the end of Welles's own radio shows.\n\"The Lady from Shanghai\".\nThe film that Welles was obliged to make in exchange for Harry Cohn's help in financing the stage production \"Around the World\" was \"The Lady from Shanghai\", filmed in 1947 for Columbia Pictures. Welles intended it to be a modest thriller, but the budget skyrocketed after Cohn suggested that Welles's then-estranged wife Rita Hayworth star.\nCohn disliked Welles's rough cut, particularly the confusing plot and lack of close-ups, and was not in sympathy with Welles's Brechtian use of irony and black comedy, especially in a farcical courtroom scene. Cohn ordered extensive editing and re-shoots. After heavy editing by the studio, approximately one hour of Welles's first cut was removed, including much of a climactic confrontation scene in an amusement park funhouse. While expressing displeasure at the cuts, Welles was particularly appalled with the score. The film was considered a disaster in America when released, though the closing shootout in a hall of mirrors (the use of mirrors being a recurrent motif of Welles's, starting with \"Kane\") has become a touchstone of film noir. Not long after release, Welles and Hayworth finalized their divorce.\nAlthough \"The Lady from Shanghai\" was acclaimed in Europe, it was not embraced until decades later in the U.S., where it is now regarded as a classic of film noir.\n\"Macbeth\".\nPrior to 1948, Welles convinced Republic Pictures to let him direct a low-budget version of \"Macbeth\", featuring highly stylized sets and costumes, and a cast of actors lip-syncing to a pre-recorded soundtrack, one of many innovative cost-cutting techniques Welles deployed in an attempt to make an epic film from B-movie resources. The script, adapted by Welles, is a violent reworking of Shakespeare's original, freely cutting and pasting lines into new contexts via a collage technique and recasting \"Macbeth\" as a clash of pagan and proto-Christian ideologies. Some voodoo trappings of the famous Welles/Houseman Negro Theatre stage adaptation are visible, especially in the film's characterization of the Weird Sisters, who create an effigy of Macbeth as a charm to enchant him. Of all Welles's post-\"Kane\" Hollywood productions, \"Macbeth\" is stylistically closest to \"Kane\" in its long takes and deep focus photography.\nRepublic initially trumpeted the film as an important work but decided it did not care for the Scottish accents and held up general release for a year after early negative press reaction, including \"Life\"'s comment that Welles's film \"doth foully slaughter Shakespeare.\" Welles left for Europe, while co-producer and lifelong supporter Richard Wilson reworked the soundtrack. Welles returned and cut 20 minutes from the film at Republic's request and recorded narration to cover gaps. The film was decried as a disaster. \"Macbeth\" had influential fans in Europe, especially the French poet and filmmaker Jean Cocteau, who hailed the film's \"crude, irreverent power\" and careful shot design, and described the characters as haunting \"the corridors of some dreamlike subway, an abandoned coal mine, and ruined cellars oozing with water.\"\nEurope (1948\u201356).\nIn Italy he starred as Cagliostro in the 1949 film \"Black Magic\". His co-star, Akim Tamiroff, impressed Welles so much that Tamiroff would appear in four of Welles's productions during the 1950s and 60s.\nThe following year, Welles starred as Harry Lime in Carol Reed's \"The Third Man\", alongside Cotten, his friend and co-star from \"Citizen Kane\", with a script by Graham Greene and a memorable score by Anton Karas. In it, Welles makes what Roger Ebert called \"the most famous entrance in the movies, and one of the most famous speeches.\" Greene credited the speech to Welles. Radio producer Harry Alan Towers would resurrect Lime in the radio series \"The Adventures of Harry Lime\".\nWelles appeared as Cesare Borgia in the 1949 Italian film \"Prince of Foxes\", with Tyrone Power and Mercury Theatre alumnus Everett Sloane, and as the Mongol warrior Bayan in the 1950 film version of the novel \"The Black Rose\".\n\"Othello\".\nDuring this time, Welles was channeling his money from acting jobs into a self-financed film version of Shakespeare's \"Othello\". From 1949 to 1951, Welles worked on \"Othello\", filming on location in Italy and Morocco. The film featured Welles's friends Miche\u00e1l Mac Liamm\u00f3ir as Iago and Hilton Edwards as Desdemona's father Brabantio. Suzanne Cloutier starred as Desdemona and Campbell Playhouse alumnus Robert Coote appeared as Iago's associate Roderigo.\nFilming was suspended several times as Welles ran out of funds and left for acting jobs, accounted in detail in MacLiamm\u00f3ir's memoir \"Put Money in Thy Purse\". The American release prints had a technically flawed soundtrack, suffering from a dropout of sound at every quiet moment. Welles's daughter, Beatrice Welles-Smith, restored \"Othello\" in 1992 for a re-release. The restoration included reconstructing Angelo Francesco Lavagnino's original score, which was originally inaudible, and adding ambient stereo sound effects, which were not in the original. The restoration went on a successful theatrical run in America. David Thomson writes of Welles's \"Othello\", \"the poetry hangs in the air, like sea mist or incense.\" Anthony Lane writes that \"Some of the action was shot in Venice, and I occasionally wonder what crept into the camera casing; the movie looks blackened and silvery, like an aged mirror, or as if the emulsion of the print were already poised to decay. You can't tell what is or isn't Shakespeare, where his influence begins and ends.\" The movie premiered at the Cannes Film Festival, where it won the \"Grand Prix\" (precursor of the Palme d'Or).\nIn 1952, Welles continued finding work in England after the success of the \"Harry Lime\" radio show. Harry Alan Towers offered Welles another series, \"The Black Museum\", which ran a year with Welles as host and narrator. Director Herbert Wilcox offered Welles the part of the victim in \"Trent's Last Case\", based on Edmund Clerihew Bentley's novel. In 1953, the BBC hired Welles to read an hour of selections from Walt Whitman's \"Song of Myself\". Towers hired Welles again, to play Professor Moriarty in the radio series \"The Adventures of Sherlock Holmes\" starring John Gielgud and Ralph Richardson.\nWelles briefly returned to America to make his first appearance on television, starring in the \"Omnibus\" presentation of \"King Lear\", broadcast live on CBS October 18, 1953. Directed by Peter Brook, the production costarred Natasha Parry, Beatrice Straight and Arnold Moss.\nIn 1954, director George More O'Ferrall offered Welles the title role in the 'Lord Mountdrago' segment of \"Three Cases of Murder\", co-starring Alan Badel. Herbert Wilcox cast Welles as the antagonist in \"Trouble in the Glen\" opposite Margaret Lockwood, Forrest Tucker and Victor McLaglen. Old friend John Huston cast him as Father Mapple in his 1956 film adaptation of Herman Melville's \"Moby-Dick\", starring Gregory Peck.\n\"Mr. Arkadin\".\nWelles's next turn as director was \"Mr. Arkadin\" (1955), which was produced by his political mentor from the 1940s, Louis Dolivet. It was filmed in France, Germany, Spain and Italy on a limited budget. Based loosely on episodes of the Harry Lime radio show, it stars Welles as a billionaire who hires a man to delve into the secrets of his past. The film stars Robert Arden, who had worked on the Lime series; Welles's third wife, Paola Mori, whose voice was dubbed by actress Billie Whitelaw; and guest stars Akim Tamiroff, Michael Redgrave, Katina Paxinou and Mischa Auer. Frustrated by his slow progress in the editing room, producer Dolivet removed Welles from the project and finished it without him. Eventually, five different versions of the film would be released, two in Spanish and three in English. The version that Dolivet completed was retitled \"Confidential Report\". In 2005 Stefan Droessler of the Munich Film Museum oversaw a reconstruction of the surviving film elements.\nTelevision projects.\nIn 1955, Welles directed two television series for the BBC. The first was \"Orson Welles' Sketch Book\", six 15-minute shows featuring Welles drawing in a sketchbook to illustrate his reminiscences including the filming of \"It's All True\" and the Isaac Woodard case. The second was \"Around the World with Orson Welles\", six travelogues set in locations around Europe (such as Vienna, the Basque Country, and England). Welles served as host and interviewer, his commentary including documentary facts and his observations (a technique he would continue to explore in later works).\nDuring Episode 3 of \"Sketchbook\", Welles attacks abuse of police powers around the world. The episode starts with him telling the story of Isaac Woodard, an African-American veteran during World War II being falsely accused by a bus driver of being drunk and disorderly, who has a policeman remove the man from the bus. Woodard is not arrested right away, but beaten unconscious nearly to death and permanently blinded. Welles assures the audience that he saw to it that justice was served to the policeman though he does not mention what justice was delivered. Welles goes on to give other examples of police being given more power and authority than is necessary. The episode is titled \"The Police\".\nIn 1956, Welles completed \"Portrait of Gina\". He left the only copy of it in his room at the H\u00f4tel Ritz in Paris. The film cans would remain in a lost-and-found locker at the hotel for decades, where they were discovered in 1986, after his death.\nReturn to Hollywood (1956\u201359).\nIn 1956, Welles returned to Hollywood. He began filming a projected pilot for Desilu, owned by Lucille Ball and her husband Desi Arnaz, who had purchased the former RKO studios. The film was \"The Fountain of Youth\", based on a story by John Collier. Originally deemed not viable as a pilot, the film was not aired until 1958\u2014and won the Peabody Award for excellence.\nWelles guest-starred on television shows including \"I Love Lucy\". On radio, he was narrator of \"Tomorrow\" (October 17, 1956), a nuclear holocaust drama produced and syndicated by ABC and the Federal Civil Defense Administration. Welles's next feature role was in \"Man in the Shadow\" for Universal Pictures in 1957, starring Jeff Chandler.\n\"Touch of Evil\".\nWelles stayed on at Universal to co-star with Charlton Heston in \"Touch of Evil\", based on Whit Masterson's novel \"Badge of Evil\". Originally hired as an actor, Welles was promoted to director by Universal Studios at the insistence of Heston. The film reunited actors and technicians with whom Welles had worked in Hollywood in the 1940s, including cameraman Russell Metty (\"The Stranger\"), makeup artist Maurice Seiderman (\"Citizen Kane\"), and actors Cotten, Marlene Dietrich and Akim Tamiroff. Filming proceeded smoothly, with Welles finishing on schedule and budget, and the studio bosses praising the daily rushes. Nevertheless, after production, the studio re-edited the film, re-shot scenes, and shot new exposition scenes to clarify the plot. Welles wrote a 58-page memo outlining suggestions and objections, stating that the film was no longer his version\u2014it was the studio's, but as such, he was still prepared to help with it. The movie was shown at the 1958 Brussels World's Fair, where it won the grand prize. Fran\u00e7ois Truffaut saw the film in Brussels, and it influenced his debut \"The 400 Blows\", one of the seminal films of the French New Wave.\nIn 1978, a longer preview version of the film was discovered and released. In 1998, Walter Murch reedited the film according to Welles's specifications in his memo. Murch said \"I'm just flabbergasted when I read his memos, thinking that he was writing these ideas forty years ago, because, if I was working on a film now and a director came up with ideas like these, I'd be amazed\u2014pleased but amazed\u2014to realize that someone was thinking that hard about sound\u2014which is all too rare\". The film was influential in its use of a handheld camera, notably in the scene in the elevator. Murch says that \"I'm sure Godard and Truffaut, who were big fans of \"Touch of Evil\", learned from that scene how they could achieve exactly what they wanted\u2014at once both a fresh sense of reality and ingenuity.\"\nAs Universal reworked \"Touch of Evil\", Welles began filming his adaptation of Miguel de Cervantes's \"Don Quixote\" in Mexico, starring Mischa Auer as Quixote and Akim Tamiroff as Sancho Panza.\nReturn to Europe (1959\u20131970).\nHe continued shooting \"Don Quixote\" in Spain and Italy, but replaced Mischa Auer with Francisco Reiguera, and resumed acting jobs.\nIn Italy in 1959, Welles directed his scenes as King Saul in Richard Pottier's film \"David and Goliath\". In Hong Kong, he co-starred with Curt J\u00fcrgens in Lewis Gilbert's film \"Ferry to Hong Kong\". In 1960, in Paris he co-starred in Richard Fleischer's film \"Crack in the Mirror\". In Yugoslavia he starred in Richard Thorpe's film \"The Tartars\" and Veljko Bulaji\u0107's \"Battle of Neretva\".\nThroughout the 1960s, filming continued on \"Quixote\" on-and-off, as Welles evolved the concept, tone and ending several times. Although he had a complete version shot and edited at least once, he would continue toying with the editing well into the 1980s; he never completed a version he was fully satisfied with and would junk existing footage and shoot new footage. In one case, he had a complete cut ready in which Quixote and Sancho Panza end up going to the Moon, but felt the ending was rendered obsolete by the 1969 Moon landings and burned 10 reels of this version. As the process went on, Welles gradually voiced all the characters and provided narration. In 1992, the director Jes\u00fas Franco constructed a film out of the portions of \"Quixote\" left by Welles. Some of the film stock had decayed badly. While the Welles footage was greeted with interest, the post-production by Franco was met with criticism.\nIn 1961, Welles directed \"In the Land of Don Quixote\", eight half-hour episodes for the Italian television network RAI. Similar to \"Around the World with Orson Welles\", they presented travelogues of Spain and included Welles's wife, Paola, and their daughter, Beatrice. Though Welles was fluent in Italian, the network was not interested in him providing narration because of his accent, and the series sat unreleased until 1964, by when the network had added its own Italian narration. Ultimately, versions of the episodes were released with the original musical score Welles had approved, but without the narration.\n\"The Trial\".\nIn 1962, Welles directed his adaptation of \"The Trial\", based on the novel by Franz Kafka and produced by Michael and Alexander Salkind. The cast included Jeanne Moreau, Romy Schneider, Paola Mori, Akim Tamiroff and Anthony Perkins as Josef K. While filming exteriors in Zagreb, Welles was informed that the Salkinds had run out of money, meaning there could be no set construction. No stranger to shooting on found locations, Welles soon filmed the interiors in the Gare d'Orsay, then an abandoned station in Paris. Welles thought the location possessed a \"Jules Verne modernism\" and a melancholy sense of \"waiting\", both suitable for Kafka. To remain in the spirit of Kafka, Welles set up the cutting room with the editor, Frederick Muller (as Fritz Muller), in the old unused, cold, depressing, station master office. The film failed at the box-office. Peter Bogdanovich observed that Welles found it riotously funny. Welles told a BBC interviewer that it was his best film. While filming \"The Trial\" Welles met Oja Kodar, who became his partner and collaborator for the last 20 years of his life.\nWelles played a film director in \"La ricotta\" (1963), Pier Paolo Pasolini's segment of the \"Ro.Go.Pa.G.\" movie, although his renowned voice was dubbed by writer Giorgio Bassani. He continued taking what work he could find acting, narrating or hosting other people's work, and began filming \"Chimes at Midnight\", which was completed in 1965.\n\"Chimes at Midnight\".\nFilmed in Spain, \"Chimes at Midnight\" was based on Welles's play, \"Five Kings\", in which he drew material from six Shakespeare plays to tell the story of Sir John Falstaff (Welles) and his relationship with Prince Hal (Keith Baxter). The cast includes John Gielgud, Jeanne Moreau, Fernando Rey and Margaret Rutherford; the film's narration, spoken by Ralph Richardson, is taken from the chronicler Raphael Holinshed. Welles held the film in high regard: \"It's my favorite picture, yes. If I wanted to get into heaven on the basis of one movie, that's the one I would offer up.\" Anthony Lane writes that \"what Welles means to conjure up is not just historical continuity\u2014the very best of Sir John\u2014but a sense that the Complete Works of Shakespeare constitute, as it were, one vast poem, from which his devoted and audacious interpreters are free to quote... the picture both honors Shakespeare and spurns the industry, academic and theatrical, that has encrusted him over time.\"\nIn 1966, Welles directed a film for French television, an adaptation of \"The Immortal Story\", by Karen Blixen. Released in 1968, it stars Jeanne Moreau, Roger Coggio and Norman Eshley. The film had a successful run in French theaters. At this time Welles met Oja Kodar again, and gave her a letter he had written to her and been keeping for four years; they would not be parted again. They immediately began a collaboration both personal and professional. The first of these was an adaptation of Blixen's \"The Heroine\", meant to be a companion piece to \"The Immortal Story\" and starring Kodar. Unfortunately, funding disappeared after one day's shooting. After completing this film, he appeared in a cameo as Cardinal Wolsey in Fred Zinnemann's adaptation of \"A Man for All Seasons\"\u2014a role for which he won acclaim.\nIn 1967, Welles began directing \"The Deep\", based on the novel \"Dead Calm\" by Charles Williams and filmed off the shore of Yugoslavia. The cast included Moreau, Kodar and Laurence Harvey. Personally financed by Welles and Kodar, they could not obtain the funds to complete the project, and it was abandoned a few years later after the death of Harvey. The surviving footage was eventually edited and released by the Filmmuseum M\u00fcnchen. In 1968 Welles began filming a TV special for CBS under the title \"Orson's Bag\", combining travelogue, comedy skits and a condensation of Shakespeare's \"The Merchant of Venice\" with Welles as Shylock. In 1969 Welles asked editor Frederick Muller to work with him re-editing the material and they set up cutting rooms at the Safa Palatino Studios in Rome. Funding for the show sent by CBS to Welles in Switzerland was seized by the IRS. Without funding, the show was not completed. The surviving film clips portions were eventually released by the Filmmuseum M\u00fcnchen.\nIn 1969, Welles authorized the use of his name for a cinema in Cambridge, Massachusetts. The Orson Welles Cinema remained in operation until 1986, with Welles making a personal appearance there in 1977. Also in 1969, he played a supporting role in John Huston's \"The Kremlin Letter\". Drawn by the offers he received to work in television and films, and upset by a tabloid scandal reporting his affair with Kodar, Welles abandoned the editing of \"Don Quixote\" and moved back to America in 1970.\nLater career (1970\u20131985).\nWelles returned to Hollywood, where he continued to self-finance his film and television projects. While offers to act, narrate and host continued, Welles found himself in demand on talk shows. In 1967, he played Le Chiffre in the James Bond spoof \"Casino Royale\". Due to a feud between Welles and co-star Peter Sellers, the two refused to be on set with each other, meaning their scenes had to be shot separately with body stand-ins. Welles made appearances for Dick Cavett, Johnny Carson, Dean Martin, Jackie Gleason and Merv Griffin. Welles's focus during his final years was \"The Other Side of the Wind\", a project that was filmed intermittently between 1970\u201376. Co-written by Welles and Oja Kodar, it is the story of an aging film director (John Huston) looking for funds to complete his final film. The cast includes Peter Bogdanovich, Susan Strasberg, Norman Foster, Edmond O'Brien, Cameron Mitchell and Dennis Hopper. Financed by Iranian backers, ownership fell into a legal quagmire after the Shah of Iran was deposed. The legal disputes kept the film in its unfinished state until 2017 and it was finally released in 2018.\n Welles portrayed King Louis XVIII in the 1970 film \"Waterloo\", and narrated the beginning and ending scenes of the historical comedy \"Start the Revolution Without Me\" (1970).\nIn 1971, Welles directed a short adaptation of \"Moby-Dick\", a one-man performance on a bare stage, reminiscent of his 1955 stage production \"Moby Dick \u2013 Rehearsed\". Never completed, it was released by the Filmmuseum M\u00fcnchen. He appeared in \"Ten Days' Wonder\", co-starring with Anthony Perkins and directed by Claude Chabrol, based on a detective novel by Ellery Queen. That same year, the Academy of Motion Picture Arts and Sciences gave him an Academy Honorary Award \"for superlative artistry and versatility in the creation of motion pictures.\" Welles pretended to be out of town and sent Huston to claim it, thanking the Academy on film. In his speech, Huston criticized the Academy for presenting the award while refusing to support Welles's projects. In 1972, Welles acted as on-screen narrator for the documentary version of Alvin Toffler's 1970 book \"Future Shock\". Working again for a British producer, Welles played Long John Silver in director John Hough's \"Treasure Island\" (1972), an adaptation of Robert Louis Stevenson's novel, which had been the second story broadcast by \"The Mercury Theatre on the Air\" in 1938. This was the last time he played the lead role in a major film. Welles contributed to the script, although his writing credit was attributed to the pseudonym 'O. W. Jeeves'. In some versions of the film Welles's original recorded dialog was redubbed by Robert Rietty.\nIn 1973, Welles completed \"F for Fake\", a personal essay film about art forger Elmyr de Hory and biographer Clifford Irving. Based on an existing documentary by Fran\u00e7ois Reichenbach, it included new material with Oja Kodar, Joseph Cotten, Paul Stewart and William Alland. An excerpt of Welles's 1930s \"War of the Worlds\" broadcast was recreated for this film; however, none of the dialogue heard in the film actually matches what was originally broadcast. Welles filmed a five-minute trailer, rejected in the U.S., that featured shots of a topless Kodar. Welles hosted a British syndicated anthology series, \"Orson Welles Great Mysteries\", during the 1973\u201374 television season. His introductions to the 26 half-hour episodes were shot in July 1973 by Gary Graver. 1974 saw Welles lending his voice to \"And Then There Were None\" produced by his former associate, Harry Alan Towers and starring an international cast that included Oliver Reed, Elke Sommer and Herbert Lom. In 1975, Welles narrated the documentary \"\", focusing on Warner Bros. cartoons from the 1940s. The American Film Institute presented Welles with its third Lifetime Achievement Award. At the ceremony, Welles screened scenes from the nearly finished \"The Other Side of the Wind\".\nIn 1976, Paramount Television purchased the rights for the entire corpus of Nero Wolfe stories for Welles. Welles had once wanted to make a series of Nero Wolfe movies, but author Rex Stout\u2014who was leery of Hollywood adaptations after two disappointing 1930s films\u2014turned him down. Paramount planned to begin with an ABC-TV movie and hoped to persuade Welles to continue the role in a miniseries. Frank D. Gilroy was signed to write the television script and direct the TV movie on the assurance that Welles would star, but by April 1977 Welles had bowed out. In 1980 the Associated Press reported \"the distinct possibility\" that Welles would star in a Nero Wolfe TV series for NBC television. Again, Welles left the project due to creative differences with Paramount. William Conrad was cast in the role.\nIn 1979, Welles completed his documentary \"Filming Othello\", featuring Michael MacLiammoir and Hilton Edwards. Made for West German television, it was also released in theaters. Welles completed his self-produced pilot for \"The Orson Welles Show\", featuring interviews with Burt Reynolds, Jim Henson and Frank Oz and guest-starring the Muppets and Angie Dickinson. Unable to find network interest, the pilot was never broadcast. Welles appeared in the biopic \"The Secret of Nikola Tesla\", and made a cameo in \"The Muppet Movie\". Beginning in the late 1970s, Welles participated in a series of famous television advertisements. For two years he was on-camera spokesman for the Paul Masson Vineyards, and sales grew by one third during the time Welles intoned what became a popular catchphrase: \"We will sell no wine before its time.\" Years later, the commercials regained notoriety when a bootleg recording of out-takes was distributed, showing an apparently inebriated Welles on set. He was the voice behind the long-running Carlsberg \"Probably the best lager in the world\" campaign, promoted Domecq sherry on British television and provided narration on adverts for Findus, though they have been overshadowed by a blooper reel of voice recordings, known as the Frozen Peas reel. He did commercials for the Preview Subscription Television Service seen on stations around the country.\nIn 1981, Welles hosted the documentary \"The Man Who Saw Tomorrow\", about Nostradamus. In 1982, the BBC broadcast \"The Orson Welles Story\" in the \"Arena\" series. Interviewed by Leslie Megahey, Welles examined his past in detail, and people from his professional past were interviewed. It was reissued in 1990 as \"With Orson Welles: Stories of a Life in Film\". Welles provided narration for a 1982 documentary on American public television, the tracks \"Defender\" from Manowar's 1987 album \"Fighting the World\" and \"Dark Avenger\" on their 1982 album, \"Battle Hymns\". He recorded the concert introduction for the live performances of Manowar that says, \"Ladies and gentlemen, from the United States of America, all hail Manowar.\" Manowar have used this introduction for all their concerts since. During the 1980s, Welles worked on such film projects as \"The Dreamers\", based on two stories by Isak Dinesen and starring Oja Kodar, and \"Orson Welles' Magic Show\", which reused material from his failed TV pilot. Another project was \"Filming the Trial\", the second in a proposed series of documentaries examining his feature films. While much was shot, none was completed. All were eventually released by the Filmmuseum M\u00fcnchen.\nIn the mid-1980s, Henry Jaglom taped lunch conversations with Welles at Los Angeles's Ma Maison, and in New York. Recordings were edited by Peter Biskind and published in the 2013 book \"My Lunches With Orson\".\nIn 1984, Welles narrated the short-lived television series \"Scene of the Crime\". During the early years of \"Magnum, P.I.\", Welles was the voice of the unseen character Robin Masters, a writer and playboy. Welles's death forced this character to be written out of the series. In an oblique homage to Welles, the \"Magnum, P.I.\" producers ambiguously concluded that story arc by having a character accuse another of having hired an actor to portray Robin Masters. He also released a music single, titled \"I Know What It Is to Be Young (But You Don't Know What It Is to Be Old)\", which he recorded under Italian label Compagnia Generale del Disco. The song was performed with the Nick Perito Orchestra and the Ray Charles Singers and produced by Jerry Abbott.\nThe last film roles before Welles's death included voice work in the animated films \"Enchanted Journey\" (1984) and \"\" (1986), in which he provided the voice for the planet-eating supervillain Unicron. His last film appearance was in Henry Jaglom's 1987 independent film \"Someone to Love\", released two years after his death but produced before his voice-over in \"Transformers: The Movie\". His last television appearance was on \"Moonlighting\". He recorded an introduction to an episode entitled \"The Dream Sequence Always Rings Twice\", which was partially filmed in black and white. The episode aired five days after his death and was dedicated to his memory.\nPersonal life.\nRelationships and family.\nWelles and Chicago-born actress and socialite Virginia Nicolson were married on November 14, 1934. \"Regardless of his later comments, the two were very much in love,\" wrote biographer Patrick McGilligan, \"and she was his salvation.\" The couple separated in December 1939 and divorced in February 1940. A few months later, on May 18, 1940, Virginia married Marion Davies's nephew Charles Lederer.\nAfter bearing with Welles's romances in New York, Virginia had learned that Welles had fallen in love with Mexican actress Dolores del R\u00edo. Infatuated with her since adolescence, Welles met del R\u00edo at Darryl Zanuck's ranch soon after he moved to Hollywood in 1939. Their relationship was kept secret until 1941, when del R\u00edo filed for divorce from her second husband. They openly appeared together in New York while Welles was directing the Mercury stage production \"Native Son\". They acted together in the movie \"Journey into Fear\" (1943). Their relationship came to an end due, among other things, to Welles's infidelities. Del R\u00edo returned to Mexico in 1943, shortly before Welles married Rita Hayworth. \nWelles married Hayworth on September 7, 1943. They were divorced on November 10, 1947. During his last interview, recorded for \"The Merv Griffin Show\" on the evening before his death, Welles called Hayworth \"one of the dearest and sweetest women that ever lived ... and we were a long time together\u2014I was lucky enough to have been with her longer than any of the other men in her life.\"\nIn 1955, Welles married actress Paola Mori, an Italian aristocrat who starred as Raina Arkadin in his film \"Mr. Arkadin\". The couple began an affair, and were married at her parents' insistence. They were wed in London on May 8, 1955, and never divorced.\nCroatian-born artist and actress Oja Kodar became Welles's longtime companion and mistress both personally and professionally from 1966 onward. They lived together for some of the last 20 years of his life.\nWelles had three daughters from his marriages: Christopher Welles Feder (born 1938, with Virginia Nicolson); Rebecca Welles Manning (1944\u20132004, with Rita Hayworth); and Beatrice Welles (born 1955, with Paola Mori).\nWelles has been thought to have had a son, British director Michael Lindsay-Hogg (born 1940), with Irish actress Geraldine Fitzgerald, then the wife of Sir Edward Lindsay-Hogg, 4th baronet. When Lindsay-Hogg was 16, his mother reluctantly divulged pervasive rumors that his father was Welles, and she denied them\u2014but in such detail that he doubted her veracity. Fitzgerald evaded the subject for the rest of her life. Lindsay-Hogg knew Welles, worked with him in the theatre and met him at intervals throughout Welles's life. After learning that Welles's oldest daughter, Chris, his childhood playmate, had long suspected that he was her brother, Lindsay-Hogg initiated a DNA test that proved inconclusive. In his 2011 autobiography, Lindsay-Hogg reported that his questions were resolved by his mother's close friend Gloria Vanderbilt, who wrote that Fitzgerald had told her that Welles was his father. A 2015 Welles biography by Patrick McGilligan, however, reports the impossibility of Welles's paternity: Fitzgerald left the U.S. for Ireland in May 1939, and her son was conceived before her return in late October, whereas Welles did not travel overseas during that period.\nAfter the death of Rebecca Welles Manning, a man named Marc McKerrow was revealed to be her son\u2014and therefore a direct descendant of Welles and Hayworth\u2014after he requested his adoption records unsealed. While McKerrow and Rebecca were never able to meet due to her cancer, they were in touch before her death, and he attended her funeral. McKerrow's reactions to the revelation and his meeting with Kodar are documented in the 2008 \"Prodigal Sons\", produced and directed by his sister Kimberly Reed. In 2010, McKerrow, 44, died in his sleep. His death was related to injuries he received in a car accident when younger.\nIn the 1940s, Welles had a brief relationship with Maila Nurmi. According to the biography \"Glamour Ghoul: The Passions and Pain of the Real Vampira, Maila Nurmi\", she became pregnant; since Welles was then married to Hayworth, Nurmi gave the child up for adoption. However, the child mentioned in the book was born in 1944. Nurmi revealed in an interview weeks before her death in 2008 that she met Welles in a New York casting office in spring 1946.\nDespite an urban legend promoted by Welles, he is not related to Abraham Lincoln's wartime Secretary of the Navy, Gideon Welles. The myth dates back to the first newspaper feature ever written about Welles\u2014\"Cartoonist, Actor, Poet and only 10\"\u2014in the February 19, 1926, issue of \"The Capital Times\". The article falsely states he was descended from \"Gideon Welles, who was a member of President Lincoln's cabinet\". As presented by Charles Higham in a genealogical chart that introduces his 1985 biography of Welles, Welles's father was Richard Head Welles (born Wells), son of Richard Jones Wells, son of Henry Hill Wells (who had an uncle named Gideon \"Wells\"), son of William Hill Wells, son of Richard Wells (1734\u20131801).\nPhysical characteristics.\nPeter Noble's 1956 biography describes Welles as \"a magnificent figure of a man, over six feet tall, handsome, with flashing eyes and a gloriously resonant speaking-voice\". Welles said that a voice specialist once told him he was born to be a heldentenor, a heroic tenor, but that when he was young and working at the Gate Theatre in Dublin, he forced his voice down into a bass-baritone.\nEven as a baby, Welles was prone to illness, including diphtheria, measles, whooping cough, and malaria. From infancy he suffered from asthma, sinus headaches, and backache later found to result from congenital spinal anomalies. Flat feet caused him foot and ankle trouble throughout his life. \"As he grew older\", Brady wrote, \"his ill health was exacerbated by the late hours he was allowed to keep [and] an early penchant for alcohol and tobacco\".\nIn 1928, aged 13, Welles was already six feet tall (1.83 meters) and weighed over . His passport recorded his height as , with brown hair and green eyes. \"Crash diets, [pharmaceutical] drugs, and corsets had slimmed him for his early film roles\", wrote biographer Barton Whaley. \"Then always back to gargantuan consumption of high-caloric food and booze. By summer 1949, when he was 34, his weight had crept up to a stout . In 1953, he ballooned from . After 1960, he remained permanently obese.\"\nReligious beliefs.\nWhen Peter Bogdanovich once asked him about his religion, Welles gruffly replied that it was none of his business, then misinformed him that he was raised Catholic. Although the Welles family was no longer devout, it was fourth-generation Episcopalian and before that, Quaker and Puritan. In 1982, when interviewer Merv Griffin asked about his religious beliefs, Welles replied, \"I try to be a Christian. I don't pray really, because I don't want to bore God.\"\nNear the end of his life, Welles was dining at Ma Maison, his favorite restaurant in Los Angeles, when proprietor Patrick Terrail conveyed an invitation from the head of the Greek Orthodox Church, who asked Welles to be his guest of honor at divine liturgy at Saint Sophia Cathedral. Welles replied, \"Please tell him I really appreciate that offer, but I am an atheist.\"\n\"Orson never joked or teased about the religious beliefs of others\", wrote biographer Barton Whaley. \"He accepted it as a cultural artifact, suitable for the births, deaths, and marriages of strangers and even some friends\u2014but without emotional or intellectual meaning for himself.\"\nPolitics and activism.\nWelles was politically active from the beginning of his career. He remained aligned with left-wing politics and the American Left, and always defined his political orientation as \"progressive\". A Democrat, he was an outspoken critic of racism in the United States and segregation. He was a strong supporter of Franklin D. Roosevelt and the New Deal and often spoke out on radio in support of progressive politics. He campaigned for Roosevelt in the 1944 election.\nIn a 1983 conversation with his friend Roger Hill, Welles recalled: \"During a White House dinner, when I was campaigning for Roosevelt, in a toast, with considerable tongue in cheek, he said, 'Orson, you and I are the two greatest actors alive today.' In private that evening, and on several other occasions, he urged me to run for a Senate seat in either California or Wisconsin. He wasn't alone.\" In the 1980s, Welles expressed admiration for Roosevelt but described his presidency as \"a semidictatorship\".\nDuring a 1970 appearance on \"The Dick Cavett Show\", Welles claimed to have met Hitler while hiking in Austria with a teacher who was a \"budding Nazi\". He said that Hitler made no impression on him and that he could not remember anything of him from the encounter. He said that he had no personality at all: \"He was invisible. There was nothing there until there were 5,000 people yelling sieg heil.\"\nIn 1946, Welles took to the airwaves in a series of radio broadcasts demanding justice for a decorated black veteran, Isaac Woodard, who had been beaten and blinded by white police officers. Welles devoted his July 28, 1946, program to reading Woodard's affidavit and vowing to bring\u00a0the officer responsible to justice.\u00a0He continued his crusade over subsequent Sunday afternoon broadcasts on ABC Radio. \"The NAACP felt that these broadcasts did more than anything else to prompt the Justice Department to act on the case,\" the Museum of Broadcasting stated in its 1988 retrospective \"Orson Welles on the Air: The Radio Years\".\nFor several years, he wrote a newspaper column on political issues and considered running for the U.S. Senate in 1946, representing his home state of Wisconsin\u2014a seat ultimately won by Joseph McCarthy.\nWelles's political activities were reported on pages 155\u2013157 of \"Red Channels\", the anti-Communist publication that, in part, fueled the already flourishing Hollywood Blacklist. He was in Europe during the height of the Red Scare, thereby adding another reason for the Hollywood establishment to ostracize him.\nIn 1970, Welles narrated (but did not write) a satirical political record on the rise of President Richard Nixon titled \"The Begatting of the President\". In the late 1970s, Welles referred to Josip Broz Tito as \"the greatest man in the world today\" on Yugoslav television.\nWelles spoke before a crowd of 700,000 at a nuclear disarmament rally in Central Park on June 12, 1982, and attacked the policies of Ronald Reagan and the Republican Party.\n\"\", a documentary by Danny Wu that looks at Welles's life against the political landscape of the 1930s and 40s, had its premiere at the Newport Beach Film Festival in 2022.\nDeath and tributes.\nOn the evening of October 9, 1985, Welles recorded his final interview on the syndicated TV program \"The Merv Griffin Show\", appearing with biographer Barbara Leaming. \"Both Welles and Leaming talked of Welles's life, and the segment was a nostalgic interlude,\" wrote biographer Frank Brady. Welles returned to his house in Hollywood and worked into the early hours typing stage directions for the project he and Gary Graver were planning to shoot at UCLA the following day. Welles died on the morning of October 10, following a heart attack. He was found by his chauffeur at around 10 a.m.\nHe was cremated by prior agreement with the executor of his estate, Greg Garrison, whose advice about making lucrative TV appearances in the 1970s made it possible for Welles to pay off a portion of the taxes he owed the IRS. A private funeral was attended by Paola Mori and Welles's three daughters\u2014the first time they had been together. Only close friends were invited: Garrison, Graver, Roger Hill and Prince Alessandro Tasca di Cuto.\nA public memorial tribute took place November 2, 1985, at the Directors Guild of America Theater in LA. Host Peter Bogdanovich introduced speakers including Charles Champlin, Geraldine Fitzgerald, Greg Garrison, Charlton Heston, Roger Hill, Henry Jaglom, Arthur Knight, Oja Kodar, Barbara Leaming, Janet Leigh, Norman Lloyd, Dan O'Herlihy, Patrick Terrail and Robert Wise.\nJoseph Cotten later wrote, \"He did not want a funeral; he wanted to be buried quietly in a little place in Spain.\" Cotten declined to attend the memorial program; instead, he sent a short message, ending with the last two lines of a Shakespeare sonnet that Welles had sent him on his most recent birthday:\nBut if the while I think on thee, dear friend,All losses are restored and sorrows end.\nIn 1987, Welles's ashes were taken to Ronda, Spain, and buried in an old well on the rural estate of a longtime friend, bullfighter Antonio Ord\u00f3\u00f1ez.\nLegacy and reception.\nDavid Thomson credits Welles with \"the creation of a visual style that is simultaneously baroque and precise, overwhelmingly emotional, and unerringly founded in reality.\" Peter Bogdanovich, who was directed by Welles in \"The Other Side of the Wind\", wrote: being directed by Welles was like breathing pure oxygen all day long. He was so totally in control that he never had to prove a point out of any kind. I never saw him get angry or impatient, or raise his voice in any way but hilarity... Sometimes Orson was holding the camera himself, but wherever the camera was, he had put it there, and all the lights were placed exactly where he said they were to be put. There wasn't anything seen or heard in any scene that wasn't there because Orson wanted it that way, but he was never dictatorial. Welles was a lifelong lover of Shakespeare, and Bogdanovich writes that \"Chimes at Midnight\", in which Welles plays John Falstaff, is \"arguably his best film, and his own personal favorite\"; Joseph McBride and Jonathan Rosenbaum have called it Welles's masterpiece, and Vincent Canby wrote \"it may be the greatest Shakespearean film ever made.\"\nAfter Welles went to South America to film the documentary \"It's All True\", RKO cut more than forty minutes from \"Ambersons\" and added a happier ending, against his wishes. The missing footage has been called a \"holy grail\" of cinema. Welles wrote a 58-page memo to Universal about the editing of \"Touch of Evil\", which they disregarded. In 1998, Walter Murch reedited the film according to Welles's specifications.\nKnown for his baritone voice, Welles performed extensively across theatre, radio, and film. He was a lifelong magician, presenting troop variety shows in the war years.\nAccolades.\nWelles received numerous accolades including an Academy Award, Peabody Award and Grammy Award as well as nominations for a BAFTA Award and Golden Globe Award. In 1972 he was in the first set of members elected to the American Theater Hall of Fame. His other honors include the AFI Life Achievement Award in 1975, the British Film Institute Fellowship in 1983, and the Directors Guild of America Lifetime Achievement Award in 1984. He was inducted into both the National Association of Broadcasters Hall of Fame in 1979, and the National Radio Hall of Fame in 1988. Welles was presented with France's Legion of Honour in 1982.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22197", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=22197", "title": "Open content", "text": ""}
{"id": "22199", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=22199", "title": "Ohio", "text": "U.S. state\nOhio ( ) is a state in the Midwestern region of the United States. It borders Lake Erie to the north, Pennsylvania to the east, West Virginia to the southeast, Kentucky to the southwest, Indiana to the west, and Michigan to the northwest. Of the 50 U.S. states, it is the 34th-largest by area. With a population of nearly 11.9 million, Ohio is the seventh-most populous and tenth-most densely populated state. Its capital and most populous city is Columbus, with other major metropolitan centers including Cleveland and Cincinnati, as well as Dayton, Akron, and Toledo. Ohio is nicknamed the \"Buckeye State\" after its Ohio buckeye trees, and Ohioans are also known as \"Buckeyes\".\nOhio derives its name from the Ohio River that forms its southern border, which, in turn, originated from the Seneca word \"\", meaning \"good river\", \"great river\", or \"large creek\". The state was home to several ancient indigenous civilizations, with humans present as early as 10,000 BC. It arose from the lands west of the Appalachian Mountains that were contested by various native tribes and European colonists from the 17th century through the Northwest Indian Wars of the late 18th century. Ohio was partitioned from the Northwest Territory, the first frontier of the new United States, becoming the 17th state admitted to the Union on March 1, 1803, and the first under the Northwest Ordinance. It was the first post-colonial free state admitted to the union and became one of the earliest and most influential industrial powerhouses during the 20th century.\nAlthough Ohio has shifted to a more information and service-based economy in the 21st century, it remains an industrial state, ranking seventh in GDP as of 2019[ [update]], with the third-largest manufacturing sector and second-largest automobile production. Seven presidents of the United States have come from the state, earning it the moniker \"the Mother of Presidents\".\nHistory.\nIndigenous settlement.\nArcheological evidence of spear points of both the Folsom and Clovis types indicate that the Ohio Valley was inhabited by nomadic people as early as 13,000\u00a0BC. These early nomads disappeared from Ohio by 1,000\u00a0BC. Between 1,000 and 800\u00a0BC, the sedentary Adena culture emerged. The Adena established \"semi-permanent\" villages because they domesticated plants, including sunflowers, and \"grew squash and possibly corn\"; with hunting and gathering, this cultivation supported more settled, complex villages. The most notable remnant of the Adena culture is the Great Serpent Mound, located in Adams County, Ohio.\nAround 100\u00a0BC, the Adena evolved into the Hopewell people, who were also mound builders. Their complex, large and technologically sophisticated earthworks can be found in modern-day Marietta, Newark, and Circleville. They were also a prolific trading society, their trading network spanning a third of the continent. The Hopewell disappeared from the Ohio Valley about 600\u00a0AD. The Mississippian culture rose as the Hopewell culture declined. Many Siouan-speaking peoples from the plains and east coast claim them as ancestors and say they lived throughout the Ohio region until approximately the 13th century.\nThere were three other cultures contemporaneous with the Mississippians: the Fort Ancient people, the Whittlesey Culture and the Monongahela Culture. All three disappeared in the 17th century. Their origins are unknown. The Shawnees may have absorbed the Fort Ancient people. It is also possible that the Monongahela held no land in Ohio during the Colonial Era. The Mississippian culture was close to and traded extensively with the Fort Ancient people.\nIndians in the Ohio Valley were greatly affected by the aggressive tactics of the Iroquois Confederation, based in central and western New York. After the Beaver Wars in the mid-17th century, the Iroquois claimed much of the Ohio country as hunting and, more importantly, beaver-trapping ground. After the devastation of epidemics and war in the mid-17th century, which largely emptied the Ohio country of Indigenous people by the mid-to-late 17th century, the land gradually became repopulated by the mostly Algonquian. Many of these Ohio-country nations were multiethnic (sometimes multi-linguistic) societies born out of the earlier devastation brought about by disease, war, and subsequent social instability. They subsisted on agriculture (corn, sunflowers, beans, etc.) supplemented by seasonal hunts. By the 18th century, they were part of a larger global economy brought about by European entry into the fur trade.\nSome of the Indigenous nations that historically inhabited Ohio include the Iroquoian, the Algonquian, and the Siouan. Ohio country was also the site of Indian massacres, such as the Yellow Creek massacre and the Gnadenhutten massacre. After the War of 1812, when Natives suffered serious losses such as at Tippecanoe, most Native tribes either left Ohio or had to live on only limited reservations. By 1842, all remaining Natives were forced out of the state.\nColonial and Revolutionary eras.\nDuring the 18th century, the French set up a system of trading posts to control the fur trade in the region. Beginning in 1754, the Kingdom of France and Kingdom of Great Britain fought in the French and Indian War, with various Native American tribes on each side. As a result of the Treaty of Paris, the French ceded control of Ohio and the remainder of the Old Northwest to Great Britain in 1763.\nBefore the American Revolution, Britain thinly exercised sovereignty over Ohio Country by lackadaisical garrisoning of the French forts. Just beyond Ohio Country was the great Miami capital of Kekionga, which became the center of British trade and influence in Ohio Country and throughout the future Northwest Territory. By the Royal Proclamation of 1763, British lands west of Appalachia were forbidden to settlement by colonists. The Treaty of Fort Stanwix in 1768 explicitly reserved lands north and west of the Ohio as Native lands. British military occupation in the region contributed to the outbreak of Pontiac's War in 1763. \nOhio tribes participated in the war until an armed expedition in Ohio led by Brigadier General Henry Bouquet brought about a truce. Another colonial military expedition into the Ohio Country in 1774 brought Lord Dunmore's War, kicked off by the Yellow Creek massacre in Ohio, to a conclusion. In 1774, Britain passed the Quebec Act, which formally annexed Ohio and other western lands to the Province of Quebec in order to provide a civil government and to centralize British administration of the Montreal-based fur trade. The prohibition of settlement west of the Appalachians remained, contributing to the American Revolution.\nBy the start of the American Revolutionary War, the movement of Natives and Americans between the Ohio Country and Thirteen Colonies had resulted in tension. Fort Pitt in Pennsylvania had become the main fort where expeditions into Ohio started. Intrusions into the area included General Edward Hand's 1778 movement of 500 Pennsylvania militiamen from Fort Pitt towards Mingo towns on the Cuyahoga River, where the British stored military supplies which they distributed to Indian raiding parties; Colonel Daniel Brodhead's invasion in 1780 and destruction of the Lenape Indian capital of Coshocton; a detachment of one hundred of George Rogers Clark's troops that were ambushed near the Ohio River by Indians led by Joseph Brant in the same year; a British and Native American attack on the U.S.' Fort Laurens; and the 1782 detainment and murder of 96 Moravian Lenape pacifists by Pennsylvania militiamen in the Gnadenhutten massacre.\nThe western theatre never had a decisive victor. In the Treaty of Paris in 1783, Britain ceded all claims to Ohio Country to the new United States after its victory in the American Revolutionary War.\nNorthwest Territory.\nThe United States created the Northwest Territory under the Northwest Ordinance of 1787. Slavery was not permitted in the new territory. Settlement began with the founding of Marietta by the Ohio Company of Associates, which had been formed by a group of American Revolutionary War veterans. Following the Ohio Company, the Miami Company (also referred to as the \"Symmes Purchase\") claimed the southwestern section, and the Connecticut Land Company surveyed and settled the Connecticut Western Reserve in present-day Northeast Ohio. Territorial surveyors from Fort Steuben began surveying an area of eastern Ohio called the Seven Ranges at about the same time.\nThe old Northwest Territory originally included areas previously known as Ohio Country and Illinois Country. As Ohio prepared for statehood, the Indiana Territory was created, reducing the Northwest Territory to approximately the size of present-day Ohio plus the eastern half of the Lower Peninsula of Michigan and the eastern tip of the Upper Peninsula and a sliver of southeastern Indiana called \"The Gore\".\nThe coalition of Native American tribes, known as the Western Confederacy, was forced to cede extensive territory, including much of present-day Ohio, in the Treaty of Greenville in 1795.\nUnder the Northwest Ordinance, areas could be defined and admitted as states once their population reached 60,000. Although Ohio's population was only 45,000 in December 1801, Congress determined that it was growing rapidly enough and accelerated the process via the Enabling Act of 1802. In regard to the Leni Lenape natives, Congress decided that 10,000 acres on the Muskingum River in the present state of Ohio would \"be set apart and the property thereof be vested in the Moravian Brethren\u00a0... or a society of the said Brethren for civilizing the Indians and promoting Christianity\".\nRufus Putnam, the \"Father of Ohio\".\nRufus Putnam served in important military capacities in both the French and Indian War and the American Revolutionary War. He was one of the most highly respected men in the early years of the United States.\nIn 1776, Putnam created a method of building portable fortifications, which enabled the Continental Army to drive the British from Boston. George Washington was so impressed that he made Putnam his chief engineer. After the war, Putnam and Manasseh Cutler were instrumental in creating the Northwest Ordinance, which opened up the Northwest Territory for settlement. This land was used to serve as compensation for what was owed to Revolutionary War veterans. Putnam organized and led the Ohio Company of Associates, who settled at Marietta, Ohio, where they built a large fort, Campus Martius. \nPutnam set substantial amounts of land aside for schools. In 1798, he created the plan for the construction of the Muskingum Academy, now Marietta College. In 1780, the directors of the Ohio Company appointed him superintendent of all its affairs relating to the settlement north of the Ohio River. In 1796, President George Washington commissioned him as Surveyor-General of United States Lands. In 1788, he served as a judge in the Northwest Territory's first court. In 1802, he served in the convention to form a constitution for the State of Ohio.\nStatehood and early years.\nOn February 19, 1803, U.S. president Thomas Jefferson signed an act of Congress that approved Ohio's boundaries and constitution. But Congress had not passed a formal resolution admitting Ohio as the 17th state. Although no formal resolution of admission was required, when the oversight was discovered in 1953, as Ohio began preparations for celebrating its sesquicentennial, Ohio congressman George H. Bender introduced a bill in Congress to admit Ohio to the Union retroactive to March 1, 1803, the date on which the Ohio General Assembly first convened. At a special session at the old state capital in Chillicothe, the Ohio state legislature approved a new petition for statehood, which was delivered to Washington, D.C., on horseback, and approved that August.\nOhio has had three capital cities: Chillicothe, Zanesville, and Columbus. Chillicothe was the capital from 1803 to 1810. The capital was then moved to Zanesville for two years as part of a state legislative compromise to get a bill passed. The capital was then moved back to Chillicothe from 1812 to 1816. Finally, the capital was moved to Columbus, to be near the state's geographic center.\nAlthough many Native Americans migrated west to evade American encroachment, others remained in the state, sometimes assimilating in part. Starting around 1809, the Shawnee pressed resistance to encroachment again. Under Chief Tecumseh, Tecumseh's War officially began in Ohio in 1811. When the War of 1812 began, the British decided to attack from Upper Canada into Ohio and merge their forces with the Shawnee. This continued until Tecumseh was killed at the Battle of the Thames in 1813. Most of the Shawnee, excluding the Pekowi in Southwest Ohio, were forcibly moved west. Ohio played a key role in the War of 1812, as it was on the front line in the Western theater and the scene of several notable battles both on land and in Lake Erie. On September 10, 1813, the Battle of Lake Erie, one of the major battles, took place near Put-in-Bay, Ohio. The British eventually surrendered to Oliver Hazard Perry.\nUltimately, after the U.S. government used the Indian Removal Act of 1830 to force countless Native American tribes on the Trail of Tears, where all the southern states except for Florida were emptied of Native peoples, the government panicked because most tribes did not want to be forced out of their own lands. Fearing further wars between Native tribes and American settlers, they pushed all remaining Native tribes in the East to migrate west against their will, including all remaining tribes in Ohio.\nIn 1835, Ohio fought with the Michigan Territory in the Toledo War, a mostly bloodless boundary war over the Toledo Strip. Only one person was injured in the conflict. Congress intervened, making Michigan's admittance as a state conditional on ending the conflict. In exchange for giving up its claim to the Toledo Strip, Michigan was given the western two-thirds of the Upper Peninsula, in addition to the eastern third, which was already considered part of the territory.\nCivil War and industrialization.\nOhio's central position and its population gave it an important place in the Civil War. The Ohio River was a vital artery for troop and supply movements, as were Ohio's railroads. Ohio's industry made it one of the most important states in the Union during the war. It contributed more soldiers per capita than any other state in the Union. In 1862, the state's morale was badly shaken in the aftermath of the Battle of Shiloh, a costly victory in which Ohio forces suffered 2,000 casualties. Later that year, when Confederate troops under the leadership of Stonewall Jackson threatened Washington, D.C., Ohio governor David Tod recruited 5,000 volunteers to provide three months of service. \nIn July 1863, towns along the Ohio River were attacked and ransacked in Morgan's Raid, starting in Harrison in the west and culminating in the Battle of Salineville near West Point in the far east. While this raid was overall insignificant to the Confederacy, it aroused fear among people in Ohio and Indiana as it was the furthest advancement of troops from the South in the war. Almost 35,000 Ohioans died in the conflict, and 30,000 were physically wounded. By the end of the Civil War, the Union's top three generals\u2014Ulysses S. Grant, William Tecumseh Sherman, and Philip Sheridan\u2014were all from Ohio.\nDuring much of the 19th century, industry was rapidly introduced to complement an existing agricultural economy. One of the first iron manufacturing plants, Hopewell Furnace, opened near Youngstown in 1804. By the mid-19th century, 48 blast furnaces were operating in Ohio, most in the southern part of the state. Discovery of coal deposits aided the further development of Ohio's steel industry, and by 1853 Cleveland was the nation's third-largest iron and steel producer. The first Bessemer converter was purchased by the Cleveland Rolling Mill Company, which became part of the U.S. Steel Corporation after the merger of Federal Steel Company and Carnegie Steel, the first billion-dollar American corporation. The first open-hearth furnace used for steel production was constructed by the Otis Steel Company in Cleveland, and by 1892, Ohio was the second-largest steel-producing state, behind Pennsylvania. Republic Steel was founded in Youngstown in 1899 and was at one point the nation's third-largest producer. Armco, now AK Steel, was founded in Middletown in 1899.\n20th century.\nThe state legislature officially adopted the flag of Ohio on May 9, 1902. Dayton natives Orville and Wilbur Wright made four brief flights at Kitty Hawk, North Carolina, on December 17, 1903, inventing the first successful airplane. Ohio was hit by its greatest natural disaster in the Great Flood of 1913, resulting in at least 428 fatalities and hundreds of millions of dollars in property damage, particularly around the Great Miami River basin.\nThe National Football League was originally founded in Canton, Ohio in 1920 as the American Professional Football Conference. It included Ohio League teams in five Ohio cities (Akron, Canton, Cleveland, Columbus, and Dayton), none of which still exist. The first official game occurred on October 3, 1920, when the Dayton Triangles beat the Columbus Panhandles 14\u20130 in Dayton. Canton was enshrined as the home of the Pro Football Hall of Fame in 1963.\nIn the 1930s, the Great Depression struck the state hard. By 1933, more than 40% of factory workers and 67% of construction workers were unemployed in Ohio. Approximately 50% of industrial workers in Cleveland and 80% in Toledo became unemployed, with the state unemployment rate reaching a high of 37.3%. American Jews watched the rise of Nazi Germany with apprehension. Cleveland residents Jerry Siegel and Joe Shuster created the Superman comic character in the spirit of the Jewish golem. Many of their comics portrayed Superman fighting and defeating the Nazis. Approximately 839,000 Ohioans served in the U.S. armed forces during World War II, of whom over 23,000 died or were missing in action.\nArtists, writers, musicians and actors developed in the state throughout the 20th century and often moved to other cities that were larger centers for their work. They included Zane Grey, Milton Caniff, George Bellows, Art Tatum, Roy Lichtenstein, and Roy Rogers. Alan Freed, who emerged from the swing dance culture in Cleveland, hosted the first live rock 'n roll concert in Cleveland in 1952. Famous filmmakers include Steven Spielberg, Chris Columbus and the original Warner Brothers, who set up their first movie theatre in Youngstown before the company relocated to California. The state produced many popular musicians, including Dean Martin, Doris Day, The O'Jays, Marilyn Manson, Dave Grohl, Devo, Macy Gray and The Isley Brothers.\nTwo Ohio astronauts completed significant milestones in the space race in the 1960s: John Glenn becoming the first American to orbit the Earth, and Neil Armstrong becoming the first human to walk on the Moon. In 1967, Carl Stokes was elected mayor of Cleveland and became the first African American mayor of one of the nation's 10 most populous cities.\nIn 1970, an Ohio Army National Guard unit fired at students during an antiwar protest at Kent State University, killing four and wounding nine. The Guard had been called onto campus after several protests in and around campus became violent, including a riot in downtown Kent and the burning of an ROTC building. The main cause of the protests was the United States' invasion of Cambodia during the Vietnam War.\nOhio was an important state in the developing ties between the United States and the People's Republic of China in the late 1970s and early 1980s.59 Relations between the two countries normalized in 1979, during the second term of Ohio governor Jim Rhodes.112 Rhodes sought to encourage economic ties, viewing China as a potential market for Ohio machinery exports.112 In July 1979, Rhodes led a State of Ohio Trade Mission to China.112 The trip resulted in developing economic ties, a sister state-province relationship with Hubei province, long-running Chinese exhibitions at the Ohio State Fair, and major academic exchanges between Ohio State University and Wuhan University.113 Beginning in the 1980s, the state entered into international economic and resource cooperation treaties and organizations with other Midwestern states, as well as New York, Pennsylvania, Ontario, and Quebec, including the Great Lakes Charter, Great Lakes Compact, and the Council of Great Lakes Governors.\n21st century.\nOhio's economy has undergone significant change in the 21st century, as the trend of deindustrialization has greatly impacted the American Midwest and the Rust Belt. Manufacturing in the Midwest experienced a stark decline during the early 21st century, a trend that greatly impacted Ohio. From 1990 to 2019, it lost over 300,000 manufacturing jobs, but added over 1,000,000 non-manufacturing jobs. Coinciding with this decline, Ohio has seen a large decline in union membership: 17.4% of Ohioan workers were union members in 2000, while 12.8% were union members in 2022.\nIn the wake of these economic changes, Ohio's state government has looked to promoting new industries to offset manufacturing losses, such as the production of solar energy and electric vehicles. One major program the state government launched was the \"Third Frontier\" program, created during the governorship of Bob Taft, which aimed to increase investment in Ohio and boost its technology sector. As of 2010, the Ohio Department of Development attributes the creation of 9,500 jobs to this program, with an average salary of $65,000, while having a $6.6 billion economic impact with a return on investment of 9:1. In 2010 the state won the International Economic Development Council's Excellence in Economic Development Award, celebrated as a national model of success.\nOhio's economy was also heavily afflicted by the Great Recession, as the state's unemployment rate rose from 5.6% in the first two months of 2008 up to a peak of 11.1% in December 2009 and January 2010. It took until August 2014 for the unemployment rate to return to 5.6%. From December 2007 to September 2010, Ohio lost 376,500 jobs. In 2009, Ohio had 89,053 foreclosures filings, a then-record for the state. The median household income dropped 7% from 2006\u201307 to 2008\u201309, and the poverty rate ballooned to 13.5% by 2009. By 2015, Ohio gross domestic product was $608.1 billion, the seventh-largest economy among the 50 states. In 2015, Ohio's total GDP accounted for 3.4% of U.S. GDP and 0.8% of world GDP.\nPolitically, Ohio has been long regarded as a swing state, but the success of many Republican candidates in Ohio since the late 2000s has led many to question whether Ohio remains an electoral battleground.\nOn March 9, 2020, the COVID-19 pandemic reached Ohio, with three cases reported. As of February 2023, over 41,600 Ohioans have died from COVID-19. Ohio's economy was also heavily impacted by the pandemic, as the state saw large job losses in 2020, as well as large amounts of subsequent stimulus spending.\nGeography.\nOhio's location has proven to be an asset for economic growth and expansion. Because it links the Northeast to the Midwest, much cargo and business traffic passes through its borders along its well-developed highways. Ohio has the nation's 10th-largest highway network and is within a one-day drive of 50% of North America's population and 70% of North America's manufacturing capacity. To the north, Ohio has of coastline with Lake Erie, which allows for numerous cargo ports such as Cleveland and Toledo. Ohio's southern border is defined by the Ohio River. Ohio's neighbors are Pennsylvania to the east, Michigan to the northwest, Lake Erie to the north, Indiana to the west, Kentucky on the south, and West Virginia on the southeast. Ohio's borders were defined by metes and bounds in the Enabling Act of 1802 as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Bounded on the east by the Pennsylvania line, on the south by the Ohio River, to the mouth of the Great Miami River, on the west by the line drawn due north from the mouth of the Great Miami aforesaid, and on the north by an east and west line drawn through the southerly extreme of Lake Michigan, running east after intersecting the due north line aforesaid, from the mouth of the Great Miami until it shall intersect Lake Erie or the territorial line, and thence with the same through Lake Erie to the Pennsylvania line aforesaid.\nOhio is bounded by the Ohio River, but nearly all of the river belongs to Kentucky and West Virginia. In 1980, the U.S. Supreme Court held that, based on the wording of the cessation of territory by Virginia (which at the time included what is now Kentucky and West Virginia), the boundary between Ohio and Kentucky (and, by implication, West Virginia) is the northern low-water mark of the river as it existed in 1792. Ohio has only that portion of the river between the river's 1792 low-water mark and the present high-water mark. The border with Michigan has also changed, as a result of the Toledo War, to angle slightly northeast to the north shore of the mouth of the Maumee River.\nMuch of Ohio features glaciated till plains, with an exceptionally flat area in the northwest being known as the Great Black Swamp. This glaciated region in the northwest and central state is bordered to the east and southeast first by a belt known as the glaciated Allegheny Plateau, and then by another belt known as the unglaciated Allegheny Plateau. Most of Ohio is of low relief, but the unglaciated Allegheny Plateau features rugged hills and forests.\nOhio's rugged southeastern quadrant, stretching in an outward bow-like arc along the Ohio River from the West Virginia Panhandle to the outskirts of Cincinnati, forms a distinct socioeconomic unit. Geologically similar to parts of West Virginia and southwestern Pennsylvania, this area's coal mining legacy, dependence on small pockets of old manufacturing establishments, and distinctive regional dialect set this section off from the rest of the state. In 1965, Congress passed the Appalachian Regional Development Act, an attempt to \"address the persistent poverty and growing economic despair of the Appalachian Region\". It defines 29 Ohio counties as part of Appalachia. While 1/3 of Ohio's land mass is part of the federally defined Appalachian region, only 12.8% of Ohioans live there (1.476\u00a0million people.)\nSignificant Ohio rivers include the Cuyahoga River, Great Miami River, Maumee River, Muskingum River, and Scioto River. The rivers in northern Ohio drain into the northern Atlantic Ocean via Lake Erie and the St. Lawrence River, and those in southern Ohio drain into the Gulf of Mexico via the Ohio River and the Mississippi. Ohio also includes Bass Islands and Kelleys Island. Grand Lake St. Marys in the west-central part of the state was constructed as a supply of water for canals in the canal-building era of 1820\u20131850. This body of water, over , was the largest artificial lake in the world when completed in 1845. were not the economic fiasco that similar efforts were in other states. Some cities, such as Dayton, owe their industrial emergence to their location on canals, and as late as 1910 interior canals carried much of the bulk freight of the state.\nAreas under the protection of the National Park Service include Cuyahoga Valley National Park, Hopewell Culture National Historical Park, Dayton Aviation Heritage National Historical Park, First Ladies National Historic Site, James A. Garfield National Historic Site, William Howard Taft National Historic Site, Charles Young Buffalo Soldiers National Monument, and Perry's Victory and International Peace Memorial.\nFauna and flora.\nOhio has wide variety of unique animal species. Rare and endangered species include the Eastern Hellbender, which is found in the Southeastern Appalachian region of Ohio and is classified as state endangered. The Eastern Hellbender is the 3rd largest amphibian in the world, and can grow up to 27 inches in length. It is fully aquatic and breathes almost entirely through its skin. Due to this, it is only found in pristine, cool, clear, fast flowing streams and rivers. It is highly threatened by habitat loss, water pollution, and sedimentation due to logging and other human activities.\nAlthough predominantly not in a subtropical climate, some warmer-climate flora and fauna reach well into Ohio. For instance, some trees with more southern ranges, such as the blackjack oak, \"Quercus marilandica\", are found at their northernmost in Ohio just north of the Ohio River. Also evidencing this climatic transition from a subtropical to a continental climate, several plants such as the Southern magnolia \"(Magnolia grandiflora)\", Albizia julibrissin (mimosa), Crape Myrtle, and even the occasional Needle Palm are hardy landscape materials regularly used as street, yard, and garden plantings in the Bluegrass region of Ohio. These same plants will simply not thrive in much of the rest of the state. This interesting change may be observed while traveling through Ohio on Interstate 75 from Cincinnati to Toledo. The observant traveler of this diverse state may even catch a glimpse of Cincinnati's common wall lizard, one of the few examples of permanent \"subtropical\" fauna in Ohio.\nClimate.\nThe climate of Ohio is a humid continental climate (K\u00f6ppen climate classification \"Dfa/Dfb\") throughout most of the state, except in the extreme southern counties of Ohio's Bluegrass region section, which are located on the northern periphery of the humid subtropical climate (\"Cfa\") and Upland South region of the United States. Summers are typically hot and humid throughout Ohio. Winters generally range from cool to cold. Precipitation in Ohio is moderate year-round. Severe weather is not uncommon in the state, although there are typically fewer tornado reports in Ohio than in states located in what is known as the Tornado Alley. Severe lake effect snowstorms are not uncommon on the southeast shore of Lake Erie, which is located in an area designated as the Snowbelt.\nThe highest recorded temperature was , near Gallipolis on July 21, 1934. The lowest recorded temperature was , at Milligan on February 10, 1899, during the Great Blizzard of 1899.\nThe worst weather disaster in Ohio history occurred along the Great Miami River in 1913. Known as the Great Dayton Flood, the entire Miami River watershed flooded, including the downtown business district of Dayton. As a result, the Miami Conservancy District was created as the first major floodplain engineering project in Ohio and the United States.\nAlthough few have registered as noticeable to the average resident, more than 200 earthquakes with a magnitude of 2.0 or higher have occurred in Ohio since 1776. The Western Ohio Seismic Zone and a portion of the Southern Great Lakes Seismic Zone are located in the state, and numerous faults lie under the surface.\nThe most substantial known earthquake in Ohio history was the Anna (Shelby County) earthquake, which occurred on March 9, 1937. It was centered in western Ohio, with a magnitude of 5.4, and was of intensity VIII. Other significant earthquakes in Ohio include: one of magnitude 4.8 near Lima on September 19, 1884; one of magnitude 4.2 near Portsmouth on May 17, 1901; and one of 5.0 in LeRoy Township in Lake County on January 31, 1986, which continued to trigger 13 aftershocks of magnitude 0.5 to 2.4 for two months.\nNotable Ohio earthquakes in the 21st century include one occurring on December 31, 2011, approximately northwest of Youngstown, and one occurring on June 10, 2019, approximately north-northwest of Eastlake under Lake Erie; both registered a 4.0 magnitude.\nCities.\nThere are 13 metropolitan statistical areas in Ohio, anchored by 16 cities, as defined by the U.S. Office of Management and Budget. Additionally, 30 Ohio cities function as centers of micropolitan statistical areas, urban clusters smaller than that of metropolitan areas. Ohio's three largest cities are Columbus, Cleveland, and Cincinnati.\nColumbus is the capital of the state, near its geographic center, and is well known for Ohio State University. In 2019, the city had six corporations named to the U.S. Fortune 500 list: Alliance Data, Nationwide Mutual Insurance Company, American Electric Power, L Brands, Huntington Bancshares, and Cardinal Health in suburban Dublin. Other major employers include hospitals (among others, Wexner Medical Center and Nationwide Children's Hospital), high tech research and development including the Battelle Memorial Institute, information-based companies such as OCLC and Chemical Abstracts Service, manufacturer Worthington Industries, and financial institutions such as JPMorgan Chase and Huntington Bancshares. Fast food chains Wendy's and White Castle are also headquartered in Columbus.\nLocated in Northeast Ohio along the Lake Erie shore, Cleveland is characterized by its New England heritage, ethnic immigrant cultures, and history as a major American manufacturing and healthcare center. It anchors the Cleveland\u2013Akron\u2013Canton Combined Statistical Area, of which the industrial cities of Akron and Canton are constituent parts. Mansfield, Sandusky and Youngstown are also major cities in the region. Northeast Ohio is known for major industrial companies Goodyear Tire and Rubber and Timken, top-ranked colleges Case Western Reserve University, Oberlin College, and Kent State University, the Cleveland Clinic, and cultural attractions including the Cleveland Museum of Art, Big Five member Cleveland Orchestra, Cuyahoga Valley National Park, Playhouse Square, the Pro Football Hall of Fame, and the Rock and Roll Hall of Fame.\nCincinnati anchors Southwest Ohio and the Cincinnati metropolitan area, which also encompasses counties in Kentucky and Indiana. The metropolitan area is home to Miami University and the University of Cincinnati, Cincinnati Union Terminal, Cincinnati Symphony Orchestra, and various Fortune 500 companies, including Procter &amp; Gamble, Kroger, Macy's, Inc., and Fifth Third Bank. Dayton and Springfield are in the Miami Valley, which is home to the University of Dayton, the Dayton Ballet, and the extensive Wright-Patterson Air Force Base.\nToledo and Lima are the major cities in Northwest Ohio, an area known for its glass-making industry. It is home to Owens Corning and Owens-Illinois, two Fortune 500 corporations.\nSteubenville is the only metropolitan city in Appalachian Ohio, a region known for its mixed mesophytic forests. Other metropolitan areas that contain cities in Ohio but are primarily in other states include the Huntington, West Virginia and Wheeling, West Virginia areas. Ohio is the US state with the highest number of cities with the same name as UK cities.\n&lt;templatestyles src=\"Template:Largest_cities/styles.css\" /&gt;\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\nPopulation.\nFrom just over 45,000 residents in 1800, Ohio's population grew faster than 10% per decade (except for the 1940 census) until the 1970 census, which recorded just over 10.65 million Ohioans. Growth then slowed for the next four decades. The United States Census Bureau counted 11,808,848 in the 2020 census, a 2.4% increase since the 2010 United States census. Ohio's population growth lags that of the entire United States, and whites are found in a greater density than the U.S. average. As of 2000[ [update]], Ohio's center of population is located in Morrow County, in the county seat of Mount Gilead. This is approximately south and west of Ohio's population center in 1990.\n&lt;includeonly&gt;&lt;templatestyles src=\"Chart/styles.css\"/&gt; View .&lt;/includeonly&gt;\nAs of 2011, 27.6% of Ohio's children under the age of 1 belonged to minority groups. Approximately 6.2% of Ohio's population was under five years of age, 23.7% under 18 years of age, and 14.1% were 65 or older; females made up an estimated 51.2% of the population.\nAccording to HUD's 2022 Annual Homeless Assessment Report, there were an estimated 10,654 homeless people in Ohio.\nBirth data.\n\"Note: Births in table do not add up because Hispanics are counted both by their ethnicity and by their race, giving a higher overall number.\"\nAncestry.\nIn 2010, there were 469,700 foreign-born residents in Ohio, corresponding to 4.1% of the total population. Of these, 229,049 (2.0%) were naturalized U.S. citizens and 240,699 (2.1%) were not. The largest groups were: Mexico (54,166), India (50,256), China (34,901), Germany (19,219), Philippines (16,410), United Kingdom (15,917), Canada (14,223), Russia (11,763), South Korea (11,307), and Ukraine (10,681). Though predominantly white, Ohio has large black populations in all major metropolitan areas throughout the state, Ohio has a significant Hispanic population made up of Mexicans in Toledo and Columbus, and Puerto Ricans in Cleveland and Columbus, and also has a significant and diverse Asian population in Columbus.\nAncestry groups (which the census defines as not including racial terms) in the state were: 26.5% German, 14.1% Irish, 9.0% English, 6.4% Italian, 3.8% Polish, 2.5% French, 1.9% Scottish, 1.7% Hungarian, 1.6% Dutch, 1.5% Mexican, 1.2% Slovak, 1.1% Welsh, and 1.1% Scotch-Irish. Ancestries claimed by less than 1% of the population include Sub-Saharan African, Puerto Rican, Swiss, Swedish, Arab, Greek, Norwegian, Romanian, Austrian, Lithuanian, Finnish, West Indian, Portuguese and Slovene.\nLanguages.\nAbout 6.7% of the population age 5 years and older reported speaking a language other than English, with 2.2% of the population speaking Spanish, 2.6% speaking other Indo-European languages, 1.1% speaking Asian and Austronesian languages, and 0.8% speaking other languages. Numerically: 10,100,586 spoke English, 239,229 Spanish, 55,970 German, 38,990 Chinese, 33,125 Arabic, and 32,019 French. In addition, 59,881 spoke a Slavic language and 42,673 spoke another West Germanic language according to the 2010 census. Ohio also had the nation's largest population of Slovene speakers, second largest of Slovak speakers, second largest of Pennsylvania Dutch (German) speakers, and the third largest of Serbian speakers.\nReligion.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nAccording to Public Religion Research Institute's 2021 \"American Values Survey\", 64% of Ohioans identified as Christian. Specifically, 19% of Ohio's population identified as Mainline Protestant, 17% as Evangelical Protestant, 7% as Historically Black Protestant, and 18% as Catholic. Roughly 30% of the population were unaffiliated with any religious body. Small minorities of Jews (2%), Hindus (1%), Jehovah's Witnesses (&lt;1%), Muslims (&lt;1%), Buddhists (&lt;1%), Mormons (&lt;1%), and other faiths exist according to this study. Altogether, those identifying with a religion or spiritual tradition were 70% of the state's population.\nPer the Association of Religion Data Archives's (ARDA) 2020 study, Christianity remained the predominant religion. Non-denominational Christianity, numbering 1,411,863, were the largest Protestant cohort, although Catholicism remained the single-largest denomination with 1,820,233 adherents. According to the ARDA, in 2010 the largest Christian denominations by adherents were the Catholic Church with 1,992,567; the United Methodist Church with 496,232; the Evangelical Lutheran Church in America with 223,253, the Southern Baptist Convention with 171,000, the Christian Churches and Churches of Christ with 141,311, the United Church of Christ with 118,000, and the Presbyterian Church (USA) with 110,000. With about 80,000 adherents in 2020, Ohio had the second largest Amish population of all U.S. states, only behind neighboring Pennsylvania.\nAccording to a Pew Forum poll in 2014, a majority of Ohioans, 56%, felt religion was \"very important\", 25% that it was \"somewhat important\", and 19% that religion was \"not too important/not important at all\". Among them, 38% of Ohioans indicate that they attend religious services at least once weekly, 32% occasionally, and 30% seldom or never.\nEconomy.\nAccording to the U.S. Census Bureau, the total number of people employed in 2023 was 5,081,279. The total number of unique employer establishments was 255,049, while the total number of non-employer establishments was 909,227. In 2010, Ohio was ranked second in the country for best business climate by Site Selection magazine, based on a business-activity database. The state has also won three consecutive Governor's Cup awards from the magazine, based on business growth and developments. Ohio's gross domestic product (GDP) was $626\u00a0billion in 2016. This ranks Ohio's economy as the seventh-largest among all 50 states and Washington, D.C.\nOhio's unemployment rate stands at 4.5% as of February 2018, down from 10.7% in May 2010. The state still lacks 45,000 jobs compared to the pre-recession numbers of 2007. The labor force participation as of April 2015 is 63%, slightly above the national average. As of 2023[ [update]], Ohio's per capita income was $60,402, ranking 38th in the U.S., and the state's median household income was $65,720. Also in 2023, 13.4% of the population was living below the poverty line.\nThe manufacturing and financial activities sectors each compose 18.3% of Ohio's GDP, making them Ohio's largest industries by percentage of GDP. Ohio has the third largest manufacturing workforce behind California and Texas. Ohio has the largest bioscience sector in the Midwest, and is a national leader in the \"green\" economy. Ohio is the largest producer in the country of plastics, rubber, fabricated metals, electrical equipment, and appliances. 5,212,000 Ohioans are currently employed by wage or salary.\nBy employment, Ohio's largest sector is trade/transportation/utilities, which employs 1,010,000 Ohioans, or 19.4% of Ohio's workforce, while the health care and education sector employs 825,000 Ohioans (15.8%). Government employs 787,000 Ohioans (15.1%), manufacturing employs 669,000 Ohioans (12.9%), and professional and technical services employs 638,000 Ohioans (12.2%). Ohio's manufacturing sector is the third-largest of all fifty United States states in terms of gross domestic product. Fifty-nine of the United States' top 1,000 publicly traded companies (by revenue in 2008) are headquartered in Ohio, including Procter &amp; Gamble, Goodyear Tire &amp; Rubber, AK Steel, Timken, Abercrombie &amp; Fitch, and Wendy's.\nOhio is also one of 41 states with its own lottery, the Ohio Lottery. As of 2020[ [update]], the Ohio Lottery has contributed more than $26 billion to education beginning in 1974.\nIncome inequality in Ohio, both before and after taxes, has risen significantly since the 1970s. Ohio's overall income grew in Ohio from 2009 to 2012, with an overall 7.1% increase in income growth. The top 1% had a 37.0% in income growth, while the bottom 99% grew their income by only 2.3%. The top 1% accounted for 71.9% of the overall shared income during this period. The burden of income tax falls disproportionately on lower-income tax brackets. In 2018, the bottom 20% of earners contributed 12.3% of their income towards various taxes, while the top 1% only paid 6.5%.\nCulture.\nArt.\nOhio is home to 30 art institutions, including the Columbus Museum of Art, Cincinnati Art Museum, Cleveland Museum of Art, and other entities. The full list includes:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nThe Cincinnati Art Museum holds over 100,000 works spanning 6,000 years of human history, being among the most comprehensive collections in the Midwest. Among its notable collections are works by Master of San Baudelio, Jorge Ingles, Sandro Botticelli (\"Judith with Head of Holofernes\"), Matteo di Giovanni, Domenico Tintoretto (\"Portrait of Venetian dux Marino Grimani\"), Mattia Preti, Bernardo Strozzi, Frans Hals, Bartolom\u00e9 Esteban Murillo (\"St. Thomas of Villanueva\"), Peter Paul Rubens (\"Samson and Delilah\") and Aert van der Neer. The collection also includes works by Jean-Baptiste-Camille Corot, Pierre-Auguste Renoir, Camille Pissarro, Claude Monet (\"Rocks At Belle Isle\"), and Pablo Picasso. The museum also has a large collection of paintings by American painter Frank Duveneck (\"Elizabeth B. Duveneck\").\nThe Cleveland Museum of Art is internationally renowned for its substantial holdings of Asian and Egyptian art, and has a permanent collection of more than 61,000 works from around the world. It is the fourth-wealthiest art museum in the United States.\nThe Columbus Museum of Art holds nineteenth and early twentieth-century American and European art, including early Cubist paintings by Pablo Picasso and Juan Gris, works by Fran\u00e7ois Boucher, Paul C\u00e9zanne, Mary Cassatt, Jean Auguste Dominique Ingres, Edgar Degas, Henri Matisse, Claude Monet, Edward Hopper, and Norman Rockwell, and installations by Mel Chin, Josiah McElheny, Susan Philipsz, and Allan Sekula. Also in Columbus, the Billy Ireland Cartoon Library &amp; Museum collection includes 450,000 original cartoons, 36,000 books, 51,000 serial titles, and of manuscript materials, plus 2.5\u00a0million comic strip clippings and tear sheets, making it the largest research library for cartoon art.\nYoungstown's Butler Institute of American Art was the first museum dedicated exclusively to American art.\nPlayhouse Square in downtown Cleveland is the nation's second-largest performing arts center, home to ten theaters. The Columbus Association for the Performing Arts manages seven historic Columbus area theaters.\nCuisine.\nBuckeyes are a variation of standard peanut butter cups popular in Ohio. Coated in chocolate with a partially exposed center of peanut butter fudge, the candy resembles the appearance of the nut that grows on the state tree, commonly known as the buckeye. The Klondike bar originated in Mansfield in 1922. Dum Dums lollipops were originally produced in Bellevue, Ohio in 1924, and have been made by Spangler Candy Company in Bryan, Ohio since 1953.\nCincinnati-style chili is a Greek-inspired meat sauce used as a topping for spaghetti or hot dogs. Additionally, red beans, chopped onions, and shredded cheese are offered as extra toppings referred to as \"ways\". German immigrants in Cincinnati invented goetta, a breakfast sausage made of meat scraps, spices, and oats. It is typically eaten fried.\nThe Polish Boy, \"the signature sandwich of Cleveland\", is a kielbasa sausage topped with coleslaw, French fries, and barbecue sauce and served on a bun.\nJohnny Marzetti is a casserole dish thought to have originated from Columbus and consisting of some variation of noodles, ground beef, tomatoes, and cheese.\nOhio has hosted nationwide fast food companies, including the first Arby's, Buffalo Wild Wings, Stewart's, and Wendy's; the latter is headquartered in Dublin, Ohio. The hamburger chain White Castle is also based in Columbus.\nMusic.\nThe Rock and Roll Hall of Fame and the Rhythm and Blues Music Hall of Fame are both located in Cleveland. Cleveland disc jockey Alan Freed is credited with coining the term and promoting rock and roll in the early 1950s. Cincinnati is home to the American Classical Music Hall of Fame and Museum. Six Ohio musicians are Rock and Roll Hall of Fame members, Dave Grohl (Nirvana and Foo Fighters), the Isley Brothers, Nine Inch Nails, Bobby Womack, Benjamin Orr (The Cars), and Chrissie Hynde (The Pretenders), in addition to Alan Freed.\nOther popular musicians from Ohio include Mamie Smith, Dean Martin, Tyler Joseph and Josh Dun of Twenty One Pilots, Frankie Yankovic, Doris Day, the McGuire Sisters, Howard Hewett, Shirley Murdock, Boz Scaggs, John Legend, Marilyn Manson, Starset, Dan Auerbach and Patrick Carney of the Black Keys, Griffin Layne, Joe Dolce, Kid Cudi, William \"Bootsy\" Collins, Stephanie Eulinberg of Kid Rock's Twisted Brown Trucker Band, and Devo.\nThe Cleveland Orchestra is one of the historic Big Five orchestras in the U.S. and considered among the best worldwide. Many other Ohio cities are home to their own orchestras, including Akron, Blue Ash, Canton, Cincinnati, Columbus, Dayton, Toledo, and Youngstown. Cincinnati is home to its own ballet, symphony orchestra, pops orchestra, and opera, all housed at the Cincinnati Music Hall. Dayton is also home to a ballet, orchestra, and opera, collectively known as the Dayton Performing Arts Alliance.\nWithin the marching arts, Winter Guard International has hosted national championships in performing arts at the University of Dayton 18 times between 1983 and 2003, and has permanently since 2005. The Bluecoats Drum and Bugle Corps are Ohio's highest fielding drum corps, competing in the Drum Corps International World Class circuit out of Canton.\nSports.\nProfessional sports.\nOhio is home to eight professional sports teams across the five different major leagues in the United States. Current teams include the Cincinnati Reds and Cleveland Guardians of Major League Baseball, the Columbus Crew and FC Cincinnati of Major League Soccer, the Cleveland Cavaliers of the National Basketball Association, the Cincinnati Bengals and Cleveland Browns of the National Football League, and the Columbus Blue Jackets of the National Hockey League.\nOhio has brought home seven World Series titles (Reds 1919, 1940, 1975, 1976, 1990; Indians 1920, 1948), three MLS Cups (Crew 2008, 2020, 2023), one NBA Championship (Cavaliers 2016), and nine NFL Championships (Pros 1920; Bulldogs 1922, 1923, 1924; Rams 1945; Browns 1950, 1954, 1955, 1964). Despite this success in the NFL in the first half of the 20th century, no Ohio team has won the Super Bowl since its inception in 1967. No Ohio team has made an appearance in the Stanley Cup Finals.\nOhio played a central role in the development of both Major League Baseball and the National Football League. Baseball's first fully professional team, the Cincinnati Red Stockings of 1869, were organized in Ohio. An informal early-20th-century American football association, the Ohio League, was the direct predecessor of the modern NFL, although neither of Ohio's modern NFL franchises trace their roots to an Ohio League club. The NFL itself was founded in Canton in 1920 as the American Professional Football Conference. The first official game occurred on October 3, 1920, when the Dayton Triangles beat the Columbus Panhandles 14\u20130 in Dayton. Canton was enshrined as the home of the Pro Football Hall of Fame in 1963.\nOn a smaller scale, Ohio hosts minor league baseball, arena football, indoor football, mid-level hockey, and lower division soccer.\nIndividual sports.\nThe Mid-Ohio Sports Car Course has hosted several auto racing championships, including CART World Series, IndyCar Series, NASCAR Nationwide Series, Can-Am, Formula 5000, IMSA GT Championship, American Le Mans Series and Rolex Sports Car Series. The Grand Prix of Cleveland also hosted CART races from 1982 to 2007. The Eldora Speedway is a major dirt oval that hosts NASCAR Camping World Truck Series, World of Outlaws Sprint Cars and USAC Silver Crown Series races.\nOhio hosts two PGA Tour events, the WGC-Bridgestone Invitational and Memorial Tournament. The Cincinnati Open is an ATP World Tour Masters 1000 and WTA 1000 tennis tournament.\nCollege sports.\nOhio has eight NCAA Division I Football Bowl Subdivision college football teams, divided among three different conferences. It has also experienced considerable success in the secondary and tertiary tiers of college football divisions.\nThere are two programs in the Power Five conferences; the Ohio State Buckeyes of the Big Ten Conference and the Cincinnati Bearcats of the Big 12 Conference. The Ohio State Buckeyes football team is second in all-time winning percentage, with a 977\u2013335\u201353 overall record and a 30\u201329 bowl record as of 2024. The program has produced seven Heisman Trophy winners, forty-one conference titles, and nine undisputed national championships. The men's basketball program has appeared in the NCAA Division I men's basketball tournament 27 times.\nThe Cincinnati Bearcats men's basketball team has over 1,800 wins and 33 March Madness appearances, whilst the Bearcats football team became the first so-called \"Group of Five\" team to qualify to the College Football Playoff in 2022.\nIn the Group of Five conferences, six teams are represented in the Mid-American Conference: the Akron Zips, Bowling Green Falcons, Kent State Golden Flashes, Miami RedHawks, Ohio Bobcats and the Toledo Rockets. The MAC headquarters are in Cleveland. The Cincinnati\u2013Miami rivalry game has been played in southwest Ohio every year since 1888 and is the oldest current non-conference NCAA football rivalry. Other Division I schools, either part of the NCAA Division I Football Championship Subdivision or not fielding in football include the Cleveland State Vikings, Xavier Musketeers, Wright State Raiders, and Youngstown State Penguins. Xavier's men's basketball has performed particularly well, with 27 March Madness appearances. Youngstown State's football has the third most NCAA Division I Football Championship wins, with 3.\nThere are 12 NCAA Division II universities and 22 NCAA Division III universities in Ohio.\nGovernment and politics.\nState government.\nThe state government of Ohio consists of the executive, legislative, and judicial branches.\nThe executive branch is headed by the governor of Ohio. The current governor is Mike DeWine since 2019, a member of the Republican Party. A lieutenant governor succeeds the governor in the event of any removal from office, and performs any duties assigned by the governor. The current lieutenant governor is Jim Tressel. The other elected constitutional offices in the executive branch are the secretary of state (Frank LaRose), auditor (Keith Faber), treasurer (Robert Sprague), and attorney general (Dave Yost). There are 21 state administrative departments in the executive branch.\nThe Ohio General Assembly is a bicameral legislature consisting of the Senate and House of Representatives. The Senate is composed of 33 districts, each of which is represented by one senator. Each senator represents approximately 330,000 constituents. The House of Representatives has 99 members. The Republican Party is the majority party in both houses as of the 2022 election cycle.\nIn order to be enacted into law, a bill must be adopted by both houses of the General Assembly and signed by the governor. If the governor vetoes a bill, the General Assembly can override the veto with a three-fifths supermajority of both houses. A bill will also become a law if the governor fails to sign or veto it within 10 days of its being presented. The session laws are published in the official \"Law of Ohio\". These in turn have been codified in the \"Ohio Revised Code\". The General Assembly, with the approval of the governor, draws the U.S. congressional district lines for Ohio's 16 seats in the United States House of Representatives. The Ohio Apportionment Board draws state legislative district lines in Ohio.\nThere are three levels of the Ohio state judiciary. The lowest is the court of common pleas: each county maintains its own constitutionally mandated court of common pleas, which maintain jurisdiction over \"all justiciable matters\". The intermediate-level court system is the district court system. Twelve courts of appeals exist, each retaining jurisdiction over appeals from common pleas, municipal, and county courts in a set geographical area. A case heard in this system is decided by a three-judge panel, and each judge is elected.\nThe state's highest-ranking court is the Ohio Supreme Court. A seven-justice panel composes the court, which, by its own discretion, hears appeals from the courts of appeals, and retains original jurisdiction over limited matters.\nLocal government.\nThere are also several levels of local government in Ohio: counties, municipalities (cities and villages), townships, special districts, and school districts.\nOhio is divided into 88 counties. Ohio law defines a structure for county government, although they may adopt charters for home rule. Summit County and Cuyahoga County have chosen an alternate form of government. The other counties have a government with a three-member board of county commissioners, a sheriff, coroner, auditor, treasurer, clerk of the court of common pleas prosecutor, engineer, and recorder.\nThere are two kinds of incorporated municipalities, 251 cities and 681 villages. If a municipality has five thousand or more residents as of the last United States Census it is a city, otherwise it is a village. Municipalities have full home rule powers, may adopt a charter, ordinances and resolutions for self-government. Each municipality chooses its own form of government, but most have elected mayors and city councils or city commissions. City governments provide much more extensive services than county governments, such as police forces and paid (as opposed to volunteer) fire departments.\nThe entire area of the state is encompassed by townships. When the boundaries of a township are coterminous with the boundaries of a city or village, the township ceases to exist as a separate government (called a paper township). Townships are governed by a three-member board of township trustees. Townships may have limited home rule powers.\nThere are more than 600 city, local, and exempted village school districts providing K-12 education in Ohio, as well as about four dozen joint vocation school districts, which are separate from the K-12 districts. Each city school district, local school district, or exempted village school district is governed by an elected board of education. A school district previously under state supervision (municipal school district) may be governed by a board whose members either are elected or appointed by the mayor of the municipality containing the greatest portion of the district's area.\nPolitics.\nHistorian R. Douglas Hurt asserts that not since Virginia \"had a state made such a mark on national political affairs\" as Ohio. \"The Economist\" notes that \"This slice of the mid-west contains a bit of everything American\u2014part north-eastern and part southern, part urban and part rural, part hardscrabble poverty and part booming suburb\".\nOhio is considered a moderately Republican-leaning state politically. It had been a swing state in the late 20th and early 21st centuries; this status was called into question after the state voted for Republican Donald Trump at larger margins than the nation as a whole in the 2016, 2020 and 2024 presidential elections. It is also considered a bellwether state. Since 1896, Ohio has had only three misses in the general election (1944, 1960, 2020) and had the longest perfect streak of any state, voting for the winning presidential candidate in each election from 1964 to 2016 and in 34 of the 39 held since the American Civil War. No Republican has ever won the presidency without winning Ohio.\nAs of 2024, there are more than 8\u00a0million registered Ohioan voters, of which over 70% are not affiliated with any political party. They are disproportionate in age, with a million more over 65 than there are 18- to 24-year-olds. Since the 2010 midterm elections, Ohio's voter demographic has leaned towards the Republican Party.\nThe governor, Mike DeWine, is Republican, as are all other non-judicial statewide elected officials. In the Ohio State Senate the Republicans are the majority, 25\u20138, and in the Ohio House of Representatives the Republicans control the delegation 64\u201335.\nFollowing the 2020 census, Ohio has 15 seats in the U.S. House of Representatives. As of the 2024 election cycle, ten federal representatives are Republicans while five are Democrats. Marcy Kaptur (D-09) is the most senior member of the Ohio delegation to the U.S. House of Representatives. The senior U.S. senator is Bernie Moreno and the junior is Jon Husted. Both are Republicans.\nIn 2023, Ohioans approved a constitutional amendment strengthening abortion rights.\n\"Mother of presidents\".\nSix U.S. presidents hailed from Ohio at the time of their elections, giving rise to its nickname \"mother of presidents\", a sobriquet it shares with Virginia. It is also termed \"modern mother of presidents\", in contrast to Virginia's status as the origin of presidents earlier in American history. Virginia-born William Henry Harrison lived much of his life in North Bend, Ohio, was elected from the state and is also buried there. The other five presidents are Rutherford B. Hayes, James A. Garfield, William McKinley, William Howard Taft and Warren G. Harding. Seven presidents were born in Ohio, making it second to Virginia's eight; in addition to the aforementioned five, Ulysses S. Grant was elected from Illinois and Benjamin Harrison was elected from Indiana.\nAllegations of voter suppression.\nIn a 2020 study, Ohio was ranked as the 17th hardest state for citizens to vote in. Since 1994, the state has had a policy of purging infrequent voters from its rolls. In April 2016, a lawsuit was filed, challenging this policy on the grounds that it violated the National Voter Registration Act (NVRA) of 1993 and the Help America Vote Act of 2002. In June, the federal district court ruled for the plaintiffs and entered a preliminary injunction applicable only to the November 2016 election. The preliminary injunction was upheld in September by the Court of Appeals for the Sixth Circuit. Had it not been upheld, thousands of voters would have been purged from the rolls just a few weeks before the election.\nEducation.\nOhio's system of public education is outlined in Article VI of the state constitution, and in Title XXXIII of the Ohio Revised Code. Substantively, Ohio's system is similar to those found in other states. At the State level, the Ohio Department of Education governs primary and secondary educational institutions. At the municipal level, there are approximately 700 school districts statewide. The Ohio Board of Regents coordinates and assists with Ohio's institutions of higher education.\nOhio is home to several public and private institutions of higher learning. Prior to statehood, the Northwest Ordinance of 1787 included a provision to establish an institution of higher education in the region, resulting in the establishment of Ohio University in 1804 as Ohio's first college. The University System of Ohio includes all of Ohio's public institutions of higher education. It includes 14 four-year research universities, 24 branch and regional campuses, and 23 community colleges and technical colleges. Ohio State University is the largest of the system, with over 60,000 students at its main campus in Columbus.\nKenyon College is the state's oldest private liberal arts college, established in 1824 by an Episcopal bishop to train clergy on the Ohio frontier. Oberlin College, established in 1833, was among the earliest colleges in the US to admit African Americans in 1835, and became the first to admit women in 1837.\nThe Carnegie Foundation classifies seven of the state's institutions as tier 1 research universities: Case Western Reserve University, University of Cincinnati, University of Dayton, Kent State University, Ohio State University, Ohio University, and University of Toledo.\nLibraries.\nOhio is home to some of the nation's highest-ranked public libraries. Major metropolitan public library systems include the Cleveland Public Library, the Cuyahoga County Public Library, the Cincinnati and Hamilton County Public Library, and the Columbus Metropolitan Library. The Ohio Public Library Information Network provides Ohio residents with internet access to their 251 public libraries. It also provides Ohioans with free home access to high-quality, subscription research databases.\nThe OhioLINK library consortium provides Ohio's college and university libraries with mutual access to their collections. The program allows researchers access to books and other media that might not be otherwise available. CLEVNET, another major library consortium, is based at the Cleveland Public Library and includes 47 public library systems in Northeast Ohio.\nTransportation.\nRoads.\nMany major east\u2013west transportation corridors go through Ohio. One of those pioneer routes, known in the early 20th century as \"Main Market Route 3\", was chosen in 1913 to become part of the historic Lincoln Highway which was the first road across America, connecting New York City to San Francisco. In Ohio, the Lincoln Highway linked many towns and cities together, including Canton, Mansfield, Wooster, Lima, and Van Wert. The Lincoln Highway's arrival in Ohio was a major influence on the state's development. Upon the advent of the federal numbered highway system in 1926, the Lincoln Highway through Ohio became U.S. Route 30.\nOhio is home to of the National Road, now U.S. Route 40.\nOhio has a highly developed network of roads and interstate highways. Major east-west through routes include the Ohio Turnpike (I-80/I-90) in the north, I-76 through Akron to Pennsylvania, I-70 through Columbus and Dayton, and the Appalachian Highway (State Route 32) running from West Virginia to Cincinnati. Major north\u2013south routes include I-75 in the west through Toledo, Dayton, and Cincinnati, I-71 through the middle of the state from Cleveland through Columbus and Cincinnati into Kentucky, and I-77 in the eastern part of the state from Cleveland through Akron, Canton, New Philadelphia and Marietta south into West Virginia. Interstate 75 between Cincinnati and Dayton is one of Ohio's most heavily traveled sections of interstate.\nTrails.\nOhio has a highly developed network of signed state bicycle routes. Many of them follow rail trails, with conversion ongoing. The Ohio to Erie Trail (route 1) connects Cincinnati, Columbus, and Cleveland. U.S. Bicycle Route 50 traverses Ohio from Steubenville to the Indiana state line outside Richmond.\nOhio has several long-distance hiking trails, the most prominent of which is the Buckeye Trail, which extends in a loop around the state. Part of it is on roads and part on wooded trail. Additionally, the North Country Trail (the longest of the 11 National Scenic Trails authorized by Congress) and the American Discovery Trail (a system of recreational trails and roads that collectively form a coast-to-coast route across the mid-tier of the United States) pass through Ohio. Much of these two trails coincide with the Buckeye Trail.\nRail.\n&lt;templatestyles src=\"Routemap/styles.css\"/&gt;\nOhio has an extensive rail network, though today most lines carry only freight traffic. Three Class I freight railroads operate in Ohio: CSX Transportation, Norfolk Southern Railway, and Canadian National Railway. Many local freight carriers also exist in the state.\nAmtrak, the national passenger railroad, operates three long-distance rail routes through Ohio. The \"Lake Shore Limited\" serves , , , , and . The \"Capitol Limited\" stops in those cities as well as in . The \"Cardinal\" serves Cincinnati Union Terminal. From Ohio, passengers can ride directly to , , Boston, , , , , and dozens of destinations in-between.\nColumbus is the largest city in the U.S. with no passenger rail. Its Union Station was last served in 1979 by the \"National Limited.\"\nOhio is home to several scenic railways and museums, including the Cuyahoga Valley Scenic Railroad through Cuyahoga Valley National Park, the Age of Steam Roundhouse museum, and the Hocking Valley Scenic Railway near Hocking Hills State Park.\nTransit.\nMass transit exists in many forms in Ohio cities, primarily through bus systems. The Greater Cleveland Regional Transit Authority (GCRTA) operates the RTA Rapid Transit system, which consists of one heavy rail line, three light rail lines, and three bus rapid transit lines. Cincinnati is served by the Southwest Ohio Regional Transit Authority (SORTA) bus network as well as a streetcar line, the Cincinnati Bell Connector. Other major transit agencies in Ohio include the Central Ohio Transit Authority (COTA) serving Columbus and the Greater Dayton Regional Transit Authority (GDRTA) serving Dayton.\nAir travel.\nOhio has four international airports, four commercial, and two military. The four international include Cleveland Hopkins International Airport, John Glenn Columbus International Airport, Dayton International Airport, and Rickenbacker International Airport (one of two military airfields). The other military airfield is Wright Patterson Air Force Base which is one of the largest Air Force bases in the United States. Other major airports are in Toledo and Akron. Cincinnati's main airport, Cincinnati/Northern Kentucky International Airport, is in Hebron, Kentucky, and therefore is not included in Ohio airport lists.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22201", "revid": "30438843", "url": "https://en.wikipedia.org/wiki?curid=22201", "title": "Orbital", "text": "Orbital may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "22202", "revid": "40123752", "url": "https://en.wikipedia.org/wiki?curid=22202", "title": "Organic Chemistry", "text": ""}
{"id": "22203", "revid": "50247210", "url": "https://en.wikipedia.org/wiki?curid=22203", "title": "Organic compound", "text": "Carbon-containing chemical compound\nOrganic compounds are a subclass of chemical compounds of carbon. Little consensus exists among chemists on the exact definition of organic compound; the only universally accepted definition is the quasi-tautological \"organic compounds are the subject matter of organic chemistry\". \nGenerally, any large chemical compound containing a carbon\u2013hydrogen or carbon\u2013carbon bond is accepted as an organic compound. Thus alkanes (e.g. ethane, ) and their derivatives are typically considered organic. For historical and disciplinary reasons, small molecules containing carbon are generally not accepted: cyanide ion (), hydrogen cyanide (), chloroformic acid (), carbon dioxide (), and carbonate ion () may all be excluded.\nDue to carbon's ability to catenate (form chains with other carbon atoms), millions of organic compounds are known. \nAlthough organic compounds make up only a small percentage of Earth's crust, they are of central importance because all known life is based on organic compounds. Living things incorporate inorganic carbon compounds into organic compounds through a network of processes (the carbon cycle) that convert carbon dioxide and a hydrogen source like water into simple sugars and other organic molecules. \nIn the chemical industry, synthetic organic compounds are ultimately derived from petrochemicals, mainly hydrocarbons. Petrochemicals are themselves formed from the geologic degradation of biological matter at high pressures and temperatures underground. \nHistorically, organic compounds were defined as compounds originating in living things, an expression of early-modern scientific vitalism. As vitalism became increasingly untenable, organic chemistry broadened its scope to study all large molecules; at the time, all known large molecules contained carbon. Organic molecules discovered in biological contexts are now known as natural products. In the 20th century, chemists discovered new large molecular species amongst the metal complexes. Such objects are not admitted into general organic chemistry unless they also contain carbon; otherwise their study is a new and separate field, metalorganic chemistry. \nIn chemical nomenclature, an organyl group, frequently represented by the letter R, refers to any monovalent substituent whose open valence is on a carbon atom.\nDefinition.\nFor historical reasons discussed below, a few types of carbon-containing compounds, such as carbides, carbonates (excluding carbonate esters), simple oxides of carbon (for example, CO and ) and cyanides are generally considered inorganic compounds. Different forms (allotropes) of pure carbon, such as diamond, graphite, fullerenes and carbon nanotubes are also excluded because they are simple substances composed of a single element and so not generally considered chemical compounds. The word \"organic\" in this context does not mean \"natural\".\nHistory.\nVitalism.\nVitalism was a widespread conception that substances found in organic nature are formed from the chemical elements by the action of a \"vital force\" or \"life-force\" (\"vis vitalis\") that only living organisms possess.\nIn the 1810s, J\u00f6ns Jacob Berzelius argued that a regulative force must exist within living bodies. Berzelius also contended that compounds could be distinguished by whether they required any organisms in their synthesis (organic compounds) or whether they did not (inorganic compounds). Vitalism taught that formation of these \"organic\" compounds were fundamentally different from the \"inorganic\" compounds that could be obtained from the elements by chemical manipulations in laboratories.\nVitalism survived for a short period after the formulation of modern ideas about the atomic theory and chemical elements. It first came under question in 1824, when Friedrich W\u00f6hler synthesized oxalic acid, a compound known to occur only in living organisms, from cyanogen. A further experiment was W\u00f6hler's 1828 synthesis of urea from the inorganic salts potassium cyanate and ammonium sulfate. Urea had long been considered an \"organic\" compound, as it was known to occur only in the urine of living organisms. W\u00f6hler's experiments were followed by many others, in which increasingly complex \"organic\" substances were produced from \"inorganic\" ones without the involvement of any living organism, thus disproving vitalism.\nModern classification and ambiguities.\nAlthough vitalism has been discredited, scientific nomenclature retains the distinction between \"organic\" and \"inorganic\" compounds. The modern meaning of \"organic compound\" is any compound that contains a significant amount of carbon\u2014even though many of the organic compounds known today have no connection to any substance found in living organisms. The term \"carbogenic\" has been proposed by E. J. Corey as a modern alternative to \"organic\", but this neologism remains relatively obscure.\nThe organic compound -isoleucine molecule presents some features typical of organic compounds: carbon\u2013carbon bonds, carbon\u2013hydrogen bonds, as well as covalent bonds from carbon to oxygen and to nitrogen.\nAs described in detail below, any definition of organic compound that uses simple, broadly-applicable criteria turns out to be unsatisfactory, to varying degrees. The modern, commonly accepted definition of organic compound essentially amounts to any carbon-containing compound, excluding several classes of substances traditionally considered \"inorganic\". The list of substances so excluded varies from author to author. Still, it is generally agreed upon that there are (at least) a few carbon-containing compounds that should not be considered organic. For instance, almost all authorities would require the exclusion of alloys that contain carbon, including steel (which contains cementite, ), as well as other metal and semimetal carbides (including \"ionic\" carbides, e.g, and and \"covalent\" carbides, e.g. and SiC, and graphite intercalation compounds, e.g. ). Other compounds and materials that are considered 'inorganic' by most authorities include: metal carbonates, simple oxides of carbon (CO, , and arguably, ), the allotropes of carbon, cyanide derivatives not containing an organic residue (e.g., KCN, , BrCN, cyanate anion , etc.), and heavier analogs thereof (e.g., cyaphide anion , , COS; although carbon disulfide is often classed as an \"organic\" solvent). Halides of carbon without hydrogen (e.g., and ), phosgene (), carboranes, metal carbonyls (e.g., nickel tetracarbonyl), mellitic anhydride (), and other exotic oxocarbons are also considered inorganic by some authorities.\nNickel tetracarbonyl () and other metal carbonyls are often volatile liquids, like many organic compounds, yet they contain only carbon bonded to a transition metal and to oxygen, and are often prepared directly from metal and carbon monoxide. Nickel tetracarbonyl is typically classified as an \"organometallic compound\" as it satisfies the broad definition that organometallic chemistry covers all compounds that contain at least one carbon to metal covalent bond; it is unknown whether organometallic compounds form a subset of organic compounds. For example, the evidence of covalent Fe-C bonding in cementite, a major component of steel, places it within this broad definition of organometallic, yet steel and other carbon-containing alloys are seldom regarded as organic compounds. Thus, it is unclear whether the definition of organometallic should be narrowed, whether these considerations imply that organometallic compounds are not necessarily organic, or both.\nMetal complexes with organic ligands but no carbon-metal bonds (e.g., ) are not considered organometallic; instead, they are called metal-organic compounds (and might be considered organic).\nThe relatively narrow definition of organic compounds as those containing C\u2013H bonds excludes compounds that are (historically and practically) considered organic. Neither urea nor oxalic acid are organic by this definition, yet they were two key compounds in the vitalism debate. However, the IUPAC Blue Book on organic nomenclature specifically mentions urea and oxalic acid as organic compounds. Other compounds lacking C\u2013H bonds but traditionally considered organic include benzenehexol, mesoxalic acid, and carbon tetrachloride. Mellitic acid, which contains no C\u2013H bonds, is considered a possible organic compound in Martian soil. Terrestrially, it, and its anhydride, mellitic anhydride, are associated with the mineral mellite ().\nA slightly broader definition of the organic compound includes all compounds bearing C\u2013H or C\u2013C bonds. This would still exclude urea. Moreover, this definition still leads to somewhat arbitrary divisions in sets of carbon-halogen compounds. For example, and would be considered by this rule to be \"inorganic\", whereas , , and would be organic, though these compounds share many physical and chemical properties.\nClassification.\nOrganic compounds may be classified in a variety of ways. One major distinction is between natural and synthetic compounds. Organic compounds can also be classified or subdivided by the presence of heteroatoms, e.g., organometallic compounds, which feature bonds between carbon and a metal, and organophosphorus compounds, which feature bonds between carbon and a phosphorus.\nAnother distinction, based on the size of organic compounds, distinguishes between small molecules and polymers.\nNatural compounds.\nNatural compounds refer to those that are produced by plants or animals. Many of these are still extracted from natural sources because they would be more expensive to produce artificially. Examples include most sugars, some alkaloids and terpenoids, certain nutrients such as vitamin B12, and, in general, those natural products with large or stereoisometrically complicated molecules present in reasonable concentrations in living organisms.\nFurther compounds of prime importance in biochemistry are antigens, carbohydrates, enzymes, hormones, lipids and fatty acids, neurotransmitters, nucleic acids, proteins, peptides and amino acids, lectins, vitamins, and fats and oils.\nSynthetic compounds.\nCompounds that are prepared by reaction of other compounds are known as \"synthetic\". They may be either compounds that are already found in plants/animals or those artificial compounds that do not occur naturally.\nMost polymers (a category that includes all plastics and rubbers) are organic synthetic or semi-synthetic compounds.\nBiotechnology.\nMany organic compounds\u2014two examples are ethanol and insulin\u2014are manufactured industrially using organisms such as bacteria and yeast. Typically, the DNA of an organism is altered to express compounds not ordinarily produced by the organism. Many such biotechnology-engineered compounds did not previously exist in nature.\nDatabases.\nA great number of more specialized databases exist for diverse branches of organic chemistry.\nStructure determination.\nThe main tools are proton and carbon-13 NMR spectroscopy, IR spectroscopy, mass spectrometry, UV-Vis spectroscopy and X-ray crystallography.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
