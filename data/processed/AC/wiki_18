{"id": "22018", "revid": "48680153", "url": "https://en.wikipedia.org/wiki?curid=22018", "title": "Nashville, Tennessee", "text": "Capital and largest city of Tennessee, United States\nNashville is the capital and most populous city in the U.S. state of Tennessee. It is the seat of Davidson County in Middle Tennessee, located on the Cumberland River. It is the 21st-most populous city in the United States and fourth-most populous city in the Southeast, with a population of 689,447 at the 2020 census (estimated at 704,963 in 2024). The Nashville metropolitan area, with over 2.15 million people, is the 35th-largest metropolitan area in the country. Nashville is among the fastest-growing cities in the U.S.\nNamed for Francis Nash, a general of the Continental Army during the American Revolutionary War, the city was founded in 1779 when this territory was still considered part of North Carolina. The city grew quickly due to its strategic location as a port on the Cumberland River and, in the 19th century, a railroad center. Nashville as part of Tennessee seceded during the American Civil War; in 1862 it was the first state capital in the Confederacy to be taken by Union forces. It was occupied through the end of the war. After the war, the city gradually reclaimed its stature. It became a center of trade and developed a manufacturing base.\nSince 1963, Nashville has had a consolidated city-county government, which is composed of six smaller municipalities in a two-tier system. The city is governed by a mayor, a vice-mayor, and a 40-member metropolitan council. Thirty-five of the members are elected from single-member districts, while five are elected at-large. Reflecting the city's position in state government, Nashville is home to the Tennessee Supreme Court's courthouse for Middle Tennessee, one of the state's three divisions.\nAs of 2020, Nashville is considered a global city, type \"Gamma\" by the GaWC. The city is a major center for the music industry, especially country music, and as such is commonly referred to as Music City. It is home to three major professional sports teams: the Predators, Titans, and Nashville SC. The city is also the home of many colleges and universities including Tennessee State University, Vanderbilt University, Belmont University, Fisk University, Trevecca Nazarene University, and Lipscomb University. Nashville is sometimes referred to as the \"Athens of the South\" due to the large number of educational institutions. The city is also a major center for the healthcare, publishing, banking, automotive, and technology industries. Entities with headquarters in the city include AllianceBernstein, Asurion, Bridgestone Americas, Captain D's, Concord, Gideons International, Hospital Corporation of America, LifeWay Christian Resources, Logan's Roadhouse, and Ryman Hospitality Properties.\nHistory.\n18th and 19th centuries.\nIn 1689, French-Canadian trader Martin Chartier established a trading post on the Cumberland River, near the present-day site of the city. In 1714, a group of French traders under the command of Charles Charleville established a settlement and trading post at the present location of downtown Nashville, which became known as French Lick. These settlers quickly established an extensive fur trading network with the local Native Americans, but by the 1740s the settlement had largely been abandoned.\nIn 1779, explorers James Robertson and John Donelson led a party of Overmountain Men to the site of French Lick, and constructed Fort Nashborough. It was named for Francis Nash, the American Revolutionary War hero. Nashville quickly grew because of its strategic location as a port on the Cumberland River, a tributary of the Ohio River; and its later status as a major railroad center. By 1800, the city had 345 residents, including 136 enslaved African Americans and 14 free African Americans. In 1806, Nashville was incorporated as a city and became the county seat of Davidson County, Tennessee. In 1843, the city was named as the permanent capital of the state of Tennessee. Knoxville, Kingston &amp; Murfreesboro were prior locations of the state capital.\nThe city government of Nashville owned 24 slaves by 1831, and 60 prior to the Civil War. They were \"put to work to build the first successful water system and maintain the streets.\" Auction blocks and brokers' offices were part of the slave market at the heart of the city. It was the center of plantations cultivating tobacco and hemp as commodity crops, in addition to the breeding and training of thoroughbred horses, and other livestock. For years, Nashville was considered one of the wealthiest southern capitals and a large portion of its prominence was from the iron business. Nashville led the south for iron production.\nThe cholera epidemic that struck Nashville in 1849\u20131850 took the life of former U.S. President James K. Polk and resulted in high fatalities. There were 311 deaths from cholera in 1849 and an estimated 316 to about 500 in 1850.\nBefore the Civil War, about 700 free Blacks lived in small enclaves in northern Nashville. More than 3,200 enslaved African Americans lived in the city. By 1860, when the first rumblings of secession began to be heard across the South, antebellum Nashville was a prosperous city.\nThe city's significance as a shipping port and rail center made it a desirable prize for competing military forces that wanted to control the region's important river and railroad transportation routes. In February 1862, Nashville became the first Confederate state capital to fall to U.S. troops, and the state was occupied by the U.S. Army for the duration of the war. Many enslaved African Americans from Middle Tennessee fled as refugees to Union lines; they were housed in contraband camps around military installations in Nashville's eastern, western, and southern borders. The Battle of Nashville (December 15\u201316, 1864) was a significant Union victory and perhaps the most decisive tactical victory gained by either side in the war; it was also the war's final major military action in which Tennessee regiments played a large part on both sides of the battle. Afterward, the Confederates conducted a war of attrition, making guerrilla raids and engaging in small skirmishes. Confederate forces in the Deep South were almost constantly in retreat.\nIn 1868, three years after the end of the Civil War, the Nashville chapter of the Ku Klux Klan was founded by Confederate veteran John W. Morton. He was reported to have initiated General Nathan Bedford Forrest into the white-supremacist organization. The latter became Grand Wizard of the organization, which had chapters of this secret, insurgent group forming throughout the state and across the South. They opposed voting and political organizing by freedmen, tried to control their behavior by threats, violence and murder, and sometimes also attacked their White allies, including schoolteachers from the North and Freedman's Bureau officials.\nWhites directed violence against freedmen and their descendants both during and after the Reconstruction era. Two freedmen, David Jones and Jo Reed, were lynched in Nashville by White mobs in 1872 and 1875, respectively. Reed was hanged from a bridge over the river, but survived after the rope broke and he fell into the water. He successfully escaped the city soon thereafter.\nIn the aftermath of the Civil War, the Fisk Jubilee Singers of Fisk University in Nashville emerged as a beacon of hope and cultural pride. By 1871, this ensemble began touring the U.S. and Europe, earning international acclaim for their performances of Negro spirituals. Their success not only provided vital funding for their university but also marked Nashville as a significant center for African American music and culture, laying the groundwork for the city's enduring musical legacy.\nIn 1873, Nashville suffered another cholera epidemic, along with towns throughout Sumner County along railroad routes and the Cumberland River. This was part of a larger epidemic that struck the Mississippi Valley system and other areas of the United States, such as New York and towns along its major lakes and rivers. The epidemic is estimated to have killed around 1,000 people in Nashville, and 50,000 total.\nMeanwhile, the city had reclaimed its important shipping and trading position and developed a solid manufacturing base. The post\u2013Civil War years of the late 19th century brought new prosperity to Nashville and Davidson County. Wealthy planters and businessmen built grand, classical-style buildings. A replica of the Parthenon was constructed in Centennial Park, near downtown.\nOn April 30, 1892, Ephraim Grizzard, an African-American man, was lynched in a spectacle murder in front of a white mob of 10,000 in Nashville. He was a suspect in the assault of two white sisters. His lynching was described by journalist Ida B. Wells as: \"A naked, bloody example of the blood-thirstiness of the nineteenth century civilization of the Athens of the South.\" His brother, Henry Grizzard, had been lynched and hanged on April 24, 1892, in nearby Goodlettsville as a suspect in the same assault incident. From 1877 to 1950, a total of six lynchings of Blacks were conducted in Davidson County, four before the turn of the century.\nEarlier 20th century.\nBy the turn of the century, Nashville was home to numerous organizations and individuals associated with revisionist Lost Cause of the Confederacy pseudohistory, and it has been referred to as the \"cradle of the Lost Cause\". In 1893, the magazine \"Confederate Veteran\" began publication in the city. In 1894, the first chapter of United Daughters of the Confederacy was founded in the city, and it hosted the first two conventions of the organization. Prominent proponents of the mythology, the so-called \"guardians of the Lost Cause\", were concentrated Downtown and in the West End, near Centennial Park.\nAt the same time, Jefferson Street became the historic center of the African American community, with similar districts developing in the Black neighborhoods in East and North Nashville. In 1912, the Tennessee Agricultural and Industrial and Normal School was moved to Jefferson Street. The first Prince's Hot Chicken Shack originated at the corner of Jefferson Street and 28th Avenue in 1945. Jefferson Street became a destination for jazz and blues musicians, and remained so until the federal government split the area by construction of Interstate 40 in the late 1960s.\nIn 1925, the establishment of the Grand Ole Opry marked the beginning of Nashville's journey as the 'Country Music Capital of the World', drawing musicians and fans alike to the city and setting the stage for its future as a country music powerhouse.\nMid-20th Century.\nIn 1950, the state legislature approved a new city charter that provided for the election of city council members from single-member districts, rather than at-large voting. This change was supported because at-large voting required candidates to gain a majority of votes from across the city. The previous system prevented the minority population, which then tended to support Republican candidates, from being represented by candidates of their choice; apportionment under single-member districts meant that some districts in Nashville had Black majorities. In 1951, after passage of the new charter, African American attorneys Z. Alexander Looby and Robert E. Lillard were elected to the city council.\nIn the late-1940's, recording studios began to set up shop in Nashville to record artists who performed at the Grand Ole Opry. Then in 1950, the radio announcer David Cobb ad libbed on air \u201cthe sounds listeners were hearing on WSM radio were coming from \u2018Music City, U.S.A.\u2019 \u201d coining the moniker \"Music City\".\nDuring the mid-1950s, Nashville underwent a musical transformation with the emergence of the 'Nashville Sound,' which was characterized by \"smooth strings and choruses\", \"sophisticated background vocals\" and \"smooth tempos\" associated with traditional pop. The new sound broadened country music's appeal and solidified Nashville's status as a music recording and production center.\nWith the United States Supreme Court ruling in 1954 that public schools had to desegregate with \"all deliberate speed\", the family of student Robert Kelley filed a lawsuit in 1956, arguing that Nashville administrators should open all-White East High School to him. A similar case was filed by Reverend Henry Maxwell due to his children having to take a 45-minute bus ride from South Nashville to the north end of the city. These suits caused the courts to announce what became known as the \"Nashville Plan\", where the city's public schools would desegregate one grade per year beginning in the fall of 1957.\nUrban redevelopment accelerated over the next several decades, and the city grew increasingly segregated. An interstate was placed on the edge of East Nashville while another highway was built through Edgehill, a lower-income, predominantly minority community.\nPostwar development to end of 20th century.\nRapid suburbanization occurred during the years immediately after World War II, as new housing was being built outside city limits. This resulted in a demand for many new schools and other support facilities, which the county found difficult to provide. At the same time, suburbanization led to a declining tax base in the city, although many suburban residents used unique city amenities and services that were supported financially only by city taxpayers. After years of discussion, a referendum was held in 1958 on the issue of consolidating city and county government. It failed to gain approval although it was supported by the then-elected leaders of both jurisdictions, County Judge Beverly Briley and Mayor Ben West.\nFollowing the referendum's failure, Nashville annexed some 42 square miles of suburban jurisdictions to expand its tax base. This increased uncertainty among residents, and created resentment among many suburban communities. Under the second charter for metropolitan government, which was approved in 1962, two levels of service provision were proposed: the General Services District and the Urban Services District, to provide for a differential in tax levels. Residents of the Urban Services District had a full range of city services. The areas that made up the General Services District, however, had a lower tax rate until full services were provided. This helped reconcile aspects of services and taxation among the differing jurisdictions within the large metro region.\nIn the early 1960s, Tennessee still had racial segregation of public facilities, including lunch counters and department store fitting rooms. Hotels and restaurants were also segregated. Between February 13 and May 10, 1960, a series of sit-ins were organized at lunch counters in downtown Nashville by the Nashville Student Movement and Nashville Christian Leadership Council, and were part of a broader sit-in movement in the southeastern United States as part of an effort to end racial segregation of public facilities. On February 13, 1960, the Nashville sit-ins began, although the Nashville students, trained by activists and nonviolent teachers James Lawson and Myles Horton, had been doing preliminary groundwork towards the action for two months. On April 19, 1960, the house of Z. Alexander Looby, an African American attorney and council member, was bombed by segregationists. Protesters marched to the city hall the next day, when Mayor Ben West said he supported the desegregation of lunch counters, which civil rights activists had called for. The sit-in ended successfully in May, under Mayor West.\nIn 1963, Nashville consolidated its government with Davidson County, forming a metropolitan government. The membership on the Metro Council, the legislative body, was increased from 21 to 40 seats. Of these, five members are elected at-large and 35 are elected from single-member districts, each to serve a term of four years.\nAs Nashville evolved in the 1960s, its music scene diversified, welcoming rock, pop, and other genres and the 'Nashville Sound' transformed into 'Countrypolitan'. Artists like Bob Dylan and Johnny Cash came to Nashville to record, reflecting the city's expanding influence in the music industry. In 1960, \"Time\" reported that Nashville had \"nosed out Hollywood as the nation's second biggest (after New York) record-producing center.\"\nIn 1957 Nashville desegregated its school system using an innovative grade a year plan, in response to a class action suit \"Kelly vs. Board of Education of Nashville\". By 1966 the Metro Council abandoned the grade a year plan and completely desegregated the entire school system at one time.\nCongress passed civil rights legislation in 1964 and 1965, but tensions continued as society was slow to change. On April 8, 1967, a riot broke out on the college campuses of Fisk University and Tennessee State University, historically Black colleges, after Stokely Carmichael spoke about Black Power at Vanderbilt University. Although it was viewed as a \"race riot\", it had classist characteristics.\nIn 1979, the Ku Klux Klan burnt crosses outside two African American sites in Nashville, including the city headquarters of the NAACP.\nHistorically, Nashville zoning permitted the construction of duplex housing. In the 1980s and 1990s, Nashville lawmakers downzoned sections of Nashville to exclusively permit single-family housing. Proponents of these downzonings said they would raise home values.\nSince the 1970s, the city and county have undergone tremendous growth, particularly during the economic boom of the 1990s under the leadership of then-Mayor and later-Tennessee Governor, Phil Bredesen. Making urban renewal a priority, Bredesen fostered the construction or renovation of several city landmarks, including the Country Music Hall of Fame and Museum, the downtown Nashville Public Library, the Bridgestone Arena, and Nissan Stadium.\nNissan Stadium (formerly Adelphia Coliseum and LP Field) was built after the National Football League's (NFL) Houston Oilers agreed to move to the city in 1995. The NFL team debuted in Nashville in 1998 at Vanderbilt Stadium, and Nissan Stadium opened in the summer of 1999. The Oilers changed their name to the Tennessee Titans and finished the season with the Music City Miracle and a close Super Bowl game. The St. Louis Rams won on the last play of the game.\nIn 1997, Nashville was awarded a National Hockey League expansion team; this was named the Nashville Predators. Since the 2003\u201304 season, the Predators have made the playoffs in all but four seasons. In 2017, they made the Stanley Cup Finals for the first time in franchise history, but ultimately fell to the Pittsburgh Penguins, 4games to 2, in the best-of-seven series.\n21st century.\nOn January 22, 2009, residents rejected Nashville Charter Amendment 1, which sought to make English the official language of the city.\nBetween May 1 and 7, 2010, much of Nashville was extensively flooded as part of a series of 1,000 year floods throughout Middle and West Tennessee. Much of the flooding took place in areas along the Cumberland and Harpeth Rivers and Mill Creek, and caused extensive damage to the many buildings and structures in the city, including the Grand Ole Opry House, Gaylord Opryland Resort &amp; Convention Center, Opry Mills Mall, Schermerhorn Symphony Center, Bridgestone Arena, and Nissan Stadium. Sections of Interstate 24 and Briley Parkway were also flooded. Eleven people died in the Nashville area as a result of the flooding, and damages were estimated to be over $2 billion.\nThe city recovered after the Great Recession. In March 2012, a Gallup poll ranked Nashville in the top five regions for job growth. In 2013, Nashville was described as \"Nowville\" and \"It City\" by \"GQ\", \"Forbes\", and \"The New York Times\".\nNashville elected its first female mayor, Megan Barry, on September 25, 2015. As a council member, Barry had officiated at the city's first same-sex wedding on June 26, 2015.\nIn 2017, Nashville's economy was deemed the third fastest-growing in the nation, and the city was named the \"hottest housing market in the US\" by Freddie Mac realtors. In May 2017, census estimates showed Nashville had passed Memphis to become most populated city in Tennessee. Nashville has also made national headlines for its \"homelessness crisis\". Rising housing prices and the opioid crisis have resulted in more people being out on the streets: as of 2018[ [update]], between 2,300 and 20,000 Nashvillians are homeless.\nOn March 6, 2018, due to felony charges filed against Mayor Barry relating to the misuse of public funds, she resigned before the end of her term. A special election was called. Following a ruling by the Tennessee Supreme Court, the Davidson County Election Commission set the special election for May 24, 2018, to meet the requirement of 75 to 80 days from the date of resignation. David Briley, who was Vice Mayor during the Barry administration and Acting Mayor after her resignation, won the special election with just over 54% of the vote, becoming the 70th mayor of Nashville.\nOn May 1, 2018, voters rejected Let's Move Nashville, a referendum which would have funded construction of an $8.9 billion mass transit system under the Nashville Metropolitan Transit Authority (now WeGo Public Transit) by a 2 to 1 margin.\nOn September 28, 2019, John Cooper became the ninth mayor of Metropolitan Government of Nashville and Davidson County.\nBetween 2010 and 2020, the city experienced significant changes and growth in population. For example, the median home price in North Nashville increased from $100,710 in 2010 to $532,121 in 2020. During this period, four census tracts in the city transitioned from majority Black to majority non-Black. By 2020, 99% of Nashville's neighborhoods were considered unaffordable for Black and Hispanic families earning median incomes.\nOn March 3, 2020, a tornado tracked west to east, just north of the downtown Nashville area, killing at least 25 people and leaving tens of thousands without electricity. Neighborhoods impacted included North Nashville, Germantown, East Nashville, Donelson, and Hermitage.\nOn December 25, 2020, a vehicle exploded on Second Avenue, killing the perpetrator and injuring eight others.\nOn March 27, 2023, a gunman killed three children and three staff at the Covenant School, before being fatally gunned down by police.\nFreddie O'Connell became the tenth mayor of Metropolitan Government of Nashville and Davidson County on September 25, 2023. His election platform focused on improving transportation, and became a 2024 referendum called Choose How You Move. The referendum passed on November 5, 2024, to establish a dedicated funding source for transportation and associated infrastructure.\nOn December 9, 2023, tornadoes caused considerable destruction and left three people dead.\nGeography.\nTopography.\nNashville lies on the Cumberland River in the northwestern portion of the Nashville Basin. Nashville's elevation ranges from its lowest point, above sea level at the Cumberland River, to its highest point, above sea level in the Radnor Lake State Natural Area. Nashville also sits at the start of the Highland Rim, a geophysical region of very hilly land. Because of this, Nashville is very hilly. Nashville also has some stand alone hills around the city such as the hill on which the Tennessee State Capitol building sits. \nThe higher elevations of the Highland Rim encircle the Nashville Basin with the Eastern and Western Highland Rim portions being the largest expanses. Part of the Western Highland Rim slopes down and wraps the hills along the western flanks of the city in a contiguous forest thought to be one of the largest of such forest habitats in Middle Tennessee. Nashville's Highland Rim Forest connects Beaman Park, Bells Bend Park, Warner Parks, and Radnor Lake State Park.\nAccording to the United States Census Bureau, the city has a total area of , of which of it is land and of it (4.53%) is water.\nCityscape.\nNashville's downtown area features a diverse assortment of entertainment, dining, cultural and architectural attractions. The Broadway and 2nd Avenue areas feature entertainment venues, bars, night clubs, retail, and an assortment of restaurants. North of Broadway lie Nashville's central business district, Legislative Plaza, Capitol Hill and the Tennessee Bicentennial Mall. Cultural and architectural attractions can be found throughout the city.\nThree major interstate highways (I-40, I-65 and I-24) converge near the core area of downtown, and many regional cities are within a day's driving distance.\nNashville's first skyscraper, the Life &amp; Casualty Tower, was completed in 1957 and launched the construction of other high rises in downtown Nashville. After the construction of the AT&amp;T Building (commonly referred to by locals as the \"Batman Building\") in 1994, the downtown area saw little construction until the mid-2000s. The Pinnacle, a high rise office building which opened in 2010, was the first skyscraper in Nashville to be built in the preceding 15 years.\nSince 2000, Nashville has seen two urban construction booms (one prior to the Great Recession and the other after) that have yielded multiple high-rises (defined by Emporis as buildings of a minimum of 115 feet tall). Of the city's 33 towers of 300 feet tall or taller (as of April 2023), 24 have been completed since 2000. Of note, Nashville has a disproportionate number of buildings 300 feet and taller in relation to its overall metropolitan statistical area (MSA) population of about 2 million (2021 U.S. Census Bureau estimate). This is due, in large part, to the tourism-centric city's multiple hotel towers and to its many condominium high-rises having multiple unit owners who also own other residences in both Nashville and in other markets.\nMany civic and infrastructure projects are being planned, in progress, or recently completed. A new MTA bus hub was recently completed in downtown Nashville, as was the Music City Star (now known as the WeGo Star) pilot project. Several public parks have been constructed, such as the Public Square. Riverfront Park is scheduled to be extensively updated. The Music City Center opened in May 2013. It is a convention center with of exhibit space.\nNeighborhoods.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFlora.\nNashville, with 56% of the ground surface within its city limits covered in urban tree canopy, has the largest percentage of forested area of any city in the U.S. With Nashville's 320,000 total acres, this translates into over 170,000 wooded acres that may earn it the largest urban tree canopy by area, as well. The nearby city of Lebanon is notable and even named for its so-called \"cedar glades\", which occur on soils too poor to support most trees and are instead dominated by Virginian juniper. Blackberry bushes, Virginia pine, loblolly pine, sassafras, red maple, river birch, American beech, river cane, mountain laurel and sycamore are all common native trees, along with many others.\nIn addition to the native forests, the combination of hot summers, abundant rainfall and mild winters permit a wide variety of both temperate and subtropical plants to be cultivated easily. Southern magnolia and cherry blossom trees are commonly cultivated here, with the city having an annual cherry blossom festival. Crepe myrtles and yew bushes are also commonly grown throughout Metro Nashville, and the winters are mild enough that sweetbay magnolia is evergreen whenever it is cultivated. The pansy flower is popular to plant during the autumn, and some varieties will flower overwinter in Nashville's subtropical climate. However, many hot-weather plants like petunia and even papyrus thrive as annuals, and Japanese banana will die aboveground during winter but re-sprout after the danger of frost is over. Unbeknownst to most Tennesseans, even cold-hardy palms, particularly needle palm and dwarf palmetto, are grown uncommonly but often successfully, while the taller windmill palm is more marginal, perishing below about without protection. High desert plants like Colorado spruce and prickly pear cactus are also grown somewhat commonly, as are \"Yucca filamentosa\" and the trunking \"Yucca rostrata\".\nClimate.\nNashville International Airport in Donelson has a humid subtropical climate (K\u00f6ppen \"Cfa\", Trewartha \"Cf\"), with hot, humid summers and generally cool winters typical of the Upper South.\nSnowfall occurs during the winter months, but it is usually not heavy. Average annual snowfall is about , falling mostly in January and February and occasionally in March, November and December. The largest snow event since 2003 was on January 22, 2016, when Nashville received of snow in a single storm; the largest overall was , received on March 17, 1892, during the St. Patrick's Day Snowstorm.\nRainfall is typically greater in solar spring (Feb-Apr) and summer (May-Jul), while the solar autumn months (Aug-Oct) are the driest on average. Spring and fall are prone to severe thunderstorms, which may bring tornadoes, large hail, flash floods and damaging wind, with recent major events on April 16, 1998; April 7, 2006; February 5, 2008; April 10, 2009; May 1\u20132, 2010; and March 3, 2020. Relative humidity in Nashville averages 83% in the mornings and 60% in the afternoons, which is considered moderate for the Southeastern United States. In recent decades, due to urban development, Nashville has developed an urban heat island; especially on cool, clear nights, temperatures are up to warmer in the heart of the city than in rural outlying areas. The Nashville region lies within USDA Plant Hardiness Zone 7b. From 1970 to 2020 the average summer temperature has risen 2.8 degrees F (1.5 C).\nNashville's long springs and autumns combined with a diverse array of trees and grasses can often make it uncomfortable for allergy sufferers. In 2008, Nashville was ranked as the 26th-worst spring allergy city in the U.S. by the Asthma and Allergy Foundation of America.\nThe coldest temperature ever officially recorded in Nashville was on January 21, 1985, and the hottest was on June 29, 2012. Nashville allegedly had a low of on January 26, 1832, but this was decades before record-keeping began and isn't counted as the official record low.\nDonelson.\nThe mean annual temperature at Nashville International Airport is . Monthly averages range from in January to in July, with a diurnal temperature variation of . Diurnal temperature variation is highest in April and lowest in December, but it is also relatively high in October and relatively low in January. Donelson's climate classifications are K\u00f6ppen \"Cfa\" and Trewartha \"Cfak\" thanks to its hot summers (average over ), cool winters (average over ) and long (8+ months) growing seasons (average over ). Precipitation is abundant year-round without any major difference, but there is still slight variation. The wet season runs from February through July, reaching its zenith in May with 128\u00a0mm of rain. The dry season runs from August through January with an October nadir of 85\u00a0mm and secondary December peak of 113\u00a0mm.\nOld Hickory.\nThe mean annual temperature at Old Hickory Dam is . Monthly averages range from in January to in August, with a diurnal temperature variation of . Diurnal temperature variation is highest in April and lowest in January. Old Hickory's climate classifications are K\u00f6ppen \"Cfa\" and Trewartha \"Doak\" thanks to its hot summers (average over ), cool winters (average over ) and mediocre (4\u20137 months) growing seasons (average over ). Precipitation is abundant year-round without any major difference, but there is still slight variation. The wet season runs from February through July, reaching its zenith in April with 120\u00a0mm of rain. The dry season runs from August through January with an October/November nadir of 85\u00a0mm and secondary December peak of 113\u00a0mm. Data for record temperatures is spotty before June 2007 with another brief gap in data in January 2024, but temperatures in Old Hickory have been known to range from in January 1966 to in June and July 2012.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\nAs of the 2020 United States census, there were 689,447 people, 279,545 households, and 146,241 families residing in the city. The population increase of 88,225, or 14.67% over the 2010 figure of 601,222 residents, represented the largest net population increase in the city's history. The population density was .\nIn 2010, there were 254,651 households and 141,469 families (55.6% of households). Of households with families, 37.2% had married couples living together, 14.1% had a female householder with no husband present, and 4.2% had a male householder with no wife present. 27.9% of all households had children under the age of 18, and 18.8% had at least one member 65 years of age or older. Of the 44.4% of households that are non-families, 36.2% were individuals, and 8.2% had someone living alone who was 65 years of age or older. The average household size was 2.38 and the average family size was 3.16.\nThe age distribution was 22.2% under 18, 10.3% from 18 to 24, 32.8% from 25 to 44, 23.9% from 45 to 64, and 10.7% who were 65 or older. The median age was 34.2 years. For every 100 females, there were 94.1 males. For every 100 females age 18 and over, there were 91.7 males.\nThe median income for a household in the city was $46,141, and the median income for a family was $56,377. Males with a year-round, full-time job had a median income of $41,017 versus $36,292 for females. The per capita income for the city was $27,372. About 13.9% of families and 18.2% of the population were below the poverty line, including 29.5% of those under age 18 and 9.9% of those age 65 or over. Of residents 25 or older, 33.4% have a bachelor's degree or higher.\nBecause of its relatively low cost of living and large job market, Nashville has become a popular city for immigrants. Nashville's foreign-born population more than tripled in size between 1990 and 2000, increasing from 12,662 to 39,596. The city's largest immigrant groups include Mexicans, Kurds, Vietnamese, Laotians, Arabs, and Somalis. There are also smaller communities of Pashtuns from Afghanistan and Pakistan concentrated primarily in Antioch. Nashville has the largest Kurdish community in the United States, numbering approximately 15,000. In 2009, about 60,000 Bhutanese refugees were being admitted to the U.S., and some were expected to resettle in Nashville. During the Iraqi election of 2005, Nashville was one of the few international locations where Iraqi expatriates could vote. The American Jewish community in Nashville dates back over 150 years, and numbered about 8,000 in 2015, plus 2,000 Jewish college students.\nIn 1779, approximately 20 percent of the settlers in Fort Nashborough were enslaved and free individuals of African descent. From this period until the Civil War, a burgeoning African American community in Nashville, under the guidance of a select few black leaders, diligently laid the groundwork for a prosperous society. They established educational institutions, places of worship, and enterprises, all contributing to the development and progress of the city.\nMetropolitan area.\nAs of 2020[ [update]], Nashville has the largest metropolitan area in the state of Tennessee, with a population of 2,014,444. The Nashville metropolitan area encompasses 13 of 41 Middle Tennessee counties: Cannon, Cheatham, Davidson, Dickson, Macon, Maury, Robertson, Rutherford, Smith, Sumner, Trousdale, Williamson, and Wilson. The 2020 population of the Nashville-Davidson\u2013Murfreesboro\u2013Columbia combined statistical area was 2,118,233.\nReligion.\n59.6% of people in Nashville claim religious affiliation according to information compiled by Sperling's BestPlaces. The dominant religion in Nashville is Christianity, accounting for 57.7% of the population. The Christian population is broken down into 20.6% Baptists, 6.2% Catholics, 5.6% Methodists, 3.4% Pentecostals, 3.4% Presbyterians, 0.8% Mormons, and 0.5% Lutherans. 15.7% identify with other forms of Christianity, including the Orthodox Church and Disciples of Christ. Islam is the second largest religion, with 0.8% of the population. 0.6% of the population adhere to eastern religions such as Buddhism, Sikhism, Jainism and Hinduism, and 0.3% follow Judaism.\nEconomy.\nIn the 21st century's second decade, Nashville was described as a \"southern boomtown\" by numerous publications. In 2017, it had the third-fastest-growing metropolitan economy in the United States and \"adds an average of 100 people a day to its net population increase\". The Nashville region was also said to be the \"Number One\" Metro Area for Professional and Business Service Jobs in America; Zillow said it had the \"hottest Housing market in America\". In 2013, the city ranked No. 5 on \"Forbes\"' list of the Best Places for Business and Careers. In 2015, \"Forbes\" put Nashville as the fourth Best City for White Collar Jobs. In 2015, Business Facilities' 11th Annual Rankings report named Nashville the number one city for Economic Growth Potential.\nFortune 500 companies with offices within Nashville include BNY Mellon, Bridgestone Americas, Ernst &amp; Young, Community Health Systems, Dell, Deloitte, Dollar General, Hospital Corporation of America, Nissan North America, Philips, Tractor Supply Company, and UBS. Of these, Community Health Systems, Dollar General, SmileDirectClub, Hospital Corporation of America, and Tractor Supply Company are headquartered in the city. Many popular food companies are based in Nashville including Captain D's, Hunt Brothers Pizza, O'Charley's, Logan's Roadhouse, J. Alexander's, and Stoney River Legendary Steaks.\nAs the \"home of country music\", Nashville has become a major music recording and production center. The Big Three record labels, as well as numerous independent labels, have offices in Nashville, mostly in the Music Row area. Nashville has been the headquarters of guitar company Gibson since 1984. Since the 1960s, Nashville has been the second-largest music production center (after New York City) in the United States. Nashville's music industry is estimated to have a total economic impact of about $10billion per year and to contribute about 56,000 jobs to the Nashville area.\nBeyond its major industries, Nashville has hosted significant standardization events. In May 1997, the city was the site of a pivotal moment for the garage door industry during the International Garage Door Exposition, where the newly formed Institute of Door Dealer Education and Accreditation (IDEA) administered its inaugural professional certification examinations. Trade publications confirm this event established the industry's first cohort of accredited professionals.\nThe area's largest industry is health care. Nashville is home to more than 300 health care companies, including Hospital Corporation of America (HCA), the world's largest private operator of hospitals. As of 2012[ [update]], it was estimated the health care industry contributes US$ per year and 200,000 jobs to the Nashville-area economy.\nCoreCivic, formerly known as Corrections Corporation of America and one of the largest private corrections company in the United States, was founded in Nashville in 1983, but moved out of the city in 2019. Vanderbilt University was one of its investors before the company's initial public offering. The City of Nashville's pension fund included \"a $921,000 stake\" in the company in 2017. The \"Nashville Scene\" notes that, \"A drop in CoreCivic stock value, however minor, would have a direct impact on the pension fund that represents nearly 25,000 current and former Metro employees.\"\nThe automotive industry is also becoming important for the Middle Tennessee region. Nissan North America moved its corporate headquarters in 2006 from Gardena, California (Los Angeles County) to Franklin, a suburb south of Nashville. Nissan's largest North American manufacturing plant is in Smyrna, another suburb of Nashville. Largely as a result of the increased development of Nissan and other Japanese economic interests in the region, Japan moved its former New Orleans consulate-general to Nashville's Palmer Plaza. General Motors operates an assembly plant in Spring Hill, about south of Nashville. Automotive parts manufacturer Bridgestone has its their North American headquarters in Nashville and manufacturing plants and a distribution center in nearby counties.\nOther major industries in Nashville include insurance, finance, and publishing (especially religious publishing). The city hosts headquarters operations for several Protestant denominations, including the United Methodist Church, Southern Baptist Convention, National Baptist Convention USA, and the National Association of Free Will Baptists.\nNashville is known for Southern confections, including Goo Goo Clusters, which have been made in Nashville since 1912.\nIn May 2018, AllianceBernstein pledged to build a private client office in the city by mid-2019 and to move its headquarters from New York City to Nashville by 2024.\nThe technology sector is an important and growing aspect of Nashville's economy. In November 2018, Amazon announced its plans to build an operations center in the Nashville Yards development to serve as the hub for their Retail Operations division. In April 2021, Oracle Corporation announced that it would construct a $1.2 billion campus in Nashville, which is expected to employ 8,500 by 2031.\nIn December 2019, iHeartMedia selected Nashville as the site of its second digital headquarters.\nReal estate is becoming a driver for the city's economy. Based on a survey of nearly 1,500 real estate industry professionals conducted by PricewaterhouseCoopers and the Urban Land Institute, Nashville ranked seventh nationally in terms of attractiveness to real estate investors for 2016. As of \u00a02015[ [update]], according to city figures, there is more than $2 billion in real estate projects underway or projected to start in 2016. Due to high yields available to investors, Nashville has been attracting a lot of capital from out-of-state. A key factor that has been attributed to the increase in investment is the adjustment to the city's zoning code. Developers can easily include a combination of residential, office, retail and entertainment space into their projects. Additionally, the city has invested heavily into public parks. Centennial Park is undergoing extensive renovations. The change in the zoning code and the investment in public space is consistent with the millennial generation's preference for walkable urban neighborhoods.\nTop employers.\nAccording to the Nashville Business Journal, the top employers in the city are:\nCulture.\nMuch of the city's cultural life has revolved around its large university community. Particularly significant in this respect were two groups of critics and writers who were associated with Vanderbilt University in the early 20th century: the Fugitives and the Agrarians.\nPopular destinations include Fort Nashborough and Fort Negley, the former being a reconstruction of the original settlement, the latter being a semi-restored Civil War battle fort; the Tennessee State Museum; and The Parthenon, a full-scale replica of the original Parthenon in Athens. The Tennessee State Capitol is one of the oldest working state capitol buildings in the nation. The Hermitage, the former home of President Andrew Jackson, is one of the largest presidential homes open to the public, and is also one of the most visited.\nMany of the significant sites that reflect the places that shaped Nashville's culture were identified in 2019 and placed in the national database of The Cultural Landscape Foundation, a nonprofit based in Washington, D.C. This list includes the Bicentennial Capital Mall, Public Square, Cheekwood Botanical Gardens and Museum of Art, Clover Bottom Mansion, Belmont Mansion, Travellers Rest Historic House Museum, Mount Olivet and Calvery Cemeteries, Music Row, Printer's Alley Historic District, The Gulch, Glen Leven Farm, and the WSM-AM Broadcasting Tower. These and many others are listed on https:// website.\nDining.\nSome of the more popular types of local cuisine include hot chicken, hot fish, barbecue, and meat and three.\nEntertainment and performing arts.\nNashville has a vibrant music and entertainment scene spanning a variety of genres. With a long history in the music scene, it is no surprise that city was nicknamed \"Music City\". The Tennessee Performing Arts Center is the major performing arts center of the city. It is the home of the Nashville Repertory Theatre and the Nashville Ballet. In September 2006, the Schermerhorn Symphony Center opened as the home of the Nashville Symphony.\nAs the city's name itself is a metonym for the country music industry, many popular attractions involve country music, including the Country Music Hall of Fame and Museum, Belcourt Theatre, and Ryman Auditorium. Hence, the city became known as America's \"Country Music Capital\". The Ryman was home to the \"Grand Ole Opry\" until 1974 when the show moved to the Grand Ole Opry House, east of downtown. The Opry plays there several times a week, except for an annual winter run at the Ryman.\nMany music clubs and honky-tonk bars are in downtown Nashville, particularly the area encompassing Lower Broadway, Second Avenue, and Printer's Alley, which is often referred to as \"the District\".\nEach June, the CMA Music Festival (formerly known as Fan Fair) brings thousands of country fans to the city. The Tennessee State Fair is also held annually in September.\nNashville was once home of television shows such as \"Hee Haw\" and \"Pop! Goes the Country\", as well as The Nashville Network and later, RFD-TV. Country Music Television and Great American Country currently operate from Nashville. The city was also home to the Opryland USA theme park, which operated from 1972 to 1997 before being closed by its owners (Gaylord Entertainment Company) and soon after demolished to make room for the Opry Mills mega-shopping mall.\nThe Contemporary Christian music industry is based along Nashville's Music Row, with a great influence in neighboring Williamson County. The Christian record companies include EMI Christian Music Group, Provident Label Group, and Word Records.\nMusic Row houses many gospel music and Contemporary Christian music companies centered around 16th and 17th Avenues South. On River Road, off Charlotte Pike in West Nashville, the \"CabaRay\" opened its doors on January 18, 2018. The performing venue of Ray Stevens, it offers a Vegas-style dinner and a show atmosphere. There is also a piano bar and a gift shop.\nAlthough Nashville was never known as a major jazz town, it did have many great jazz bands, including The Nashville Jazz Machine led by Dave Converse and its current version, the Nashville Jazz Orchestra, led by Jim Williamson, as well as The Establishment, led by Billy Adair. The Francis Craig Orchestra entertained Nashvillians from 1929 to 1945 from the Oak Bar and Grille Room in the Hermitage Hotel. Craig's orchestra was also the first to broadcast over local radio station WSM-AM and enjoyed phenomenal success with a 12-year show on the NBC Radio Network. In the late 1930s, he introduced a newcomer, Dinah Shore, a local graduate of Hume Fogg High School and Vanderbilt University.\nRadio station WMOT-FM in nearby Murfreesboro, which formerly programmed jazz, aided significantly in the recent revival of the city's jazz scene, as has the non-profit Nashville Jazz Workshop, which holds concerts and classes in a renovated building in the north Nashville neighborhood of Germantown. Fisk University also maintains a jazz station, WFSK.\nNashville has an active theatre scene and is home to several professional and community theatre companies. Nashville Children's Theatre, Nashville Repertory Theatre, the Nashville Shakespeare Festival, the Dance Theatre of Tennessee and the Tennessee Women's Theater Project are among the most prominent professional companies. One community theatre, Circle Players, has been in operation for over 60 years.\nThe Barbershop Harmony Society has its headquarters in Nashville.\nTourism.\nPerhaps the biggest factor in drawing visitors to Nashville is its association with country music, in which the Nashville sound played a role. Many visitors to Nashville attend live performances of the Grand Ole Opry, the world's longest-running live radio show. The Country Music Hall of Fame and Museum is another major attraction relating to the popularity of country music. The Gaylord Opryland Resort &amp; Convention Center, the Opry Mills regional shopping mall and the \"General Jackson\" showboat, are all located in what is known as Music Valley.\nCivil War history is important to the city's tourism industry. Sites pertaining to the Battle of Nashville and the nearby Battle of Franklin and Battle of Stones River can be seen, along with several well-preserved antebellum plantation houses such as Belle Meade Plantation, Carnton plantation in Franklin, and Belmont Mansion.\nNashville has many arts centers and museums, including the Frist Center for the Visual Arts, Cheekwood Botanical Garden and Museum of Art, the Tennessee State Museum, the Johnny Cash Museum, Fisk University's Van Vechten and Aaron Douglas Galleries, Vanderbilt University's Fine Art Gallery and Sarratt Gallery, the National Museum of African American Music, and the full-scale replica of the Parthenon. A sculpture of Athena Parthenos inside the Parthenon is the tallest indoor sculpture in the Western World \u2013 standing 42 feet high.\nNashville has become an increasingly popular destination for bachelor and bachelorette parties. In 2017, \"Nashville Scene\" counted 33 bachelorette parties on Lower Broadway (\"from Fifth Avenue down to the Cumberland River, it's their town\") in less than two hours on a Friday night, and stated that the actual number was likely higher. Downtown, the newspaper wrote, \"offers five blocks of bars with live music and no cover\". In 2018, \"The New York Times\" called Nashville \"the hottest destination for bachelorette parties in the country\" because of the honky-tonk bars' live music. City boosters welcome the bachelorette parties because temporary visitors may become permanent; \"BuzzFeed\" wrote, \"These women are at precisely the point in their lives when a move to Nashville is possible\". The city in 2022 began regulating party buses that provide transportainment in downtown, issuing dozens of permits and rejecting applications for dozens more. The CMT reality television series \"Bachelorette Weekend\" follows the employees at Bach Weekend, a Nashville company that designs and throws bachelor and bachelorette parties.\nNicknames.\nNashville is a colorful, well-known city in several different arenas. As such, it has earned various sobriquets, including:\nNashville has additionally earned the moniker \"The Hot Chicken Capital\", becoming known for the local specialty cuisine hot chicken. The Music City Hot Chicken Festival is hosted annually in Nashville and several restaurants make this spicy version of southern fried chicken. Due to a short-lived smokeless gunpowder plant in 1918, Nashville also had the nickname \"Powder City of the World\".\nSports.\nProfessional.\nNashville is home to four professional sports franchises. Three play at the highest professional level of their respective sports: the Tennessee Titans of the National Football League (NFL), the Nashville Predators of the National Hockey League (NHL), and Nashville SC of Major League Soccer (MLS). The city is also home to one minor league team: the Nashville Sounds of Minor League Baseball's International League. An investment group, Music City Baseball, seeks to secure a Major League Baseball expansion franchise or lure an existing team to the city. The Women's National Basketball Association rejected a bid for a franchise expansion to Nashville.\nThe Tennessee Titans moved to Nashville in 1998. Previously known as the Houston Oilers, which began play in 1960 in Houston, Texas, the team relocated to Tennessee in 1997. They played at the Liberty Bowl Memorial Stadium in Memphis for one season, then moved to Nashville in 1998 and played in Vanderbilt Stadium for one season. During those two years, the team was known as the Tennessee Oilers, but changed its name to Titans in 1999. The team now plays at Nissan Stadium in Nashville, which opened in 1999. Since moving to Nashville, the Titans have won five division championships (2000, 2002, 2008, 2020, and 2021) and one conference championship (1999). They competed in 1999's Super Bowl XXXIV, losing to the St. Louis Rams, 23\u201316. The city previously hosted the 1939 Nashville Rebels of the American Football League and two Arena Football League teams named the Nashville Kats (1997\u20132001 and 2005\u20132007).\nFrom April 25\u201327, 2019, Nashville hosted the 2019 NFL draft, which saw an estimated 200,000 fans attend each day.\nThe Nashville Predators joined the National Hockey League as an expansion team in the 1998\u201399 season. The team plays its home games at Bridgestone Arena. The Predators have won two division championships (2017\u201318 and 2018\u201319) and one conference championship (2016\u201317).\nNashville SC, a Major League Soccer franchise, began play in 2020 at Nissan Stadium. It moved into the newly completed soccer-specific stadium Geodis Park at the Nashville Fairgrounds in 2022.\nThe Nashville Sounds baseball team was established in 1978 as an expansion franchise of the Double-A Southern League. The Sounds won the league championship in 1979 and 1982. In 1985, the Double-A Sounds were replaced by a Triple-A team of the American Association. After the circuit dissolved in 1997, they joined the Triple-A Pacific Coast League in 1998 and won the league championship in 2005. The Sounds left their original ballpark, Herschel Greer Stadium, in 2015 for First Horizon Park, a new ballpark built on the site of the former Sulphur Dell ballpark. In 2021, they were placed in the Triple-A East, which became the International League in 2022. In total, the Sounds have won eleven division titles and three league championships.\nThe Music City Fire, an arena football team of the American Arena League began play at the Williamson County AgExpo Park in 2020.\nNashville is the home of the second-oldest continually operating racetrack in the United States, the Fairgrounds Speedway. It hosted NASCAR Winston Cup races from 1958 to 1984, NASCAR Busch Series and NASCAR Truck Series in the 1980s and 1990s, and later the NASCAR Whelen All-American Series and ARCA Racing Series.\nNashville Superspeedway is located southeast of Nashville in Gladeville, part of the Nashville Metropolitan Statistical Area. The track held NASCAR sanctioned events from 2001 to 2011 as well as IndyCar races from 2001 to 2008. Nashville Superspeedway reopened in 2021 and hosts the premier NASCAR Cup Series race Ally 400 annually.\nThe Nashville Invitational was a golf tournament on the PGA Tour from 1944 to 1946. The Sara Lee Classic was part of the LPGA Tour from 1988 to 2002. The BellSouth Senior Classic of the Champions Tour was held from 1994 to 2003. The Nashville Golf Open is part of the Web.com Tour since 2016. The 1961 Women's Western Open and 1980 U.S. Women's Open were also held in Nashville.\nCollege and amateur.\nNashville is also home to four Division I athletic programs. Nashville is also home to the NCAA college football Music City Bowl.\nNashville Roller Derby is Nashville's only women's flat track roller derby team. Established in 2006, Nashville Roller Derby competes on a regional and national level. They play their home games at the Nashville Fairgrounds Sports Arena. In 2014, they hosted the WFTDA Championships at Municipal Auditorium.\nThe Nashville Kangaroos are an Australian Rules Football team that compete in the United States Australian Football League. The Kangaroos play their home games at Elmington Park. The team is the reigning USAFL Central Region Champions.\nThree Little League Baseball teams from Nashville (one in 1970; one in 2013; and, one in 2014) have qualified for the Little League World Series. Teams from neighboring Goodlettsville qualified for the 2012 and 2016 series, giving the metropolitan area teams in three consecutive years to so qualify; and four teams in five years.\nParks and gardens.\nMetro Board of Parks and Recreation owns and manages of land and 99 parks and greenways (accounting for more than 3% of the total area of the county).\nWarner Parks, situated on of land, consists of a learning center, of scenic roads, of hiking trails, and of horse trails. It is also the home of the annual Iroquois Steeplechase.\nThe United States Army Corps of Engineers maintains parks on Old Hickory Lake and Percy Priest Lake. These parks are used for activities such as fishing, water skiing, sailing and boating. The Harbor Island Yacht Club makes its headquarters on Old Hickory Lake, and Percy Priest Lake is home to the Vanderbilt Sailing Club and Nashville Shores.\nOther parks in Nashville include Centennial Park, Shelby Park, Cumberland Park, and Radnor Lake State Natural Area. Four of Nashville's major parks are located in a forest of rolling hills along the city's western border. These are Beaman Park, Bells Bend Park, Warner Parks, and Radnor Lake State Park. With urban tree canopy covering 56% of Nashville's total land surface, the city places at the very top in forest cover among major U.S. cities. The vast majority of this canopy is in the suburban western hills containing the four parks noted above. The density and continuous canopy have earned it the name of Nashville's Highland Rim Forest. If omitting towns with smaller populations like Sitka, Alaska, with its huge city park, then Nashville has the largest urban tree canopy of major cities by area. In addition, with Nashville's being one of largest U.S. cities in geographic size at 320,000 acres, its 179,000 acres of forested surface may also rank it first in percentage of canopy cover at 56%.\nOn August 27, 2013, Nashville mayor Karl Dean revealed plans for two new riverfront parks on the east and west banks of the Cumberland River downtown. Construction on the east bank park began in the fall of 2013, and the projected completion date for the west bank park is 2015. Among many exciting benefits of this Cumberland River re-development project is the construction of a highly anticipated outdoor amphitheater. Located on the west bank, this music venue will be surrounded by a new park and will replace the previous thermal plant site. It will include room for 6,500 spectators with 2,500 removable seats and additional seating on an overlooking grassy knoll. In addition, the east bank park will include a river landing, providing people access to the river. In regard to the parks' benefits for Nashvillian civilians, Mayor Dean remarked that \"if done right, the thermal site can be an iconic park that generations of Nashvillians will be proud of and which they can enjoy\".\nLaw and government.\nThe city of Nashville and Davidson County merged in 1963 as a way for Nashville to combat the problems of urban sprawl. The combined entity is officially known as \"the Metropolitan Government of Nashville and Davidson County\", and is popularly known as \"Metro Nashville\" or simply \"Metro\". It offers services such as police, fire, electricity, water and sewage treatment. When the Metro government was formed in 1963, the government was split into two service districts\u2014the \"urban services district\" and the \"general services district\". The urban services district encompasses the 1963 boundaries of the former City of Nashville, approximately , and the general services district includes the remainder of Davidson County. There are six smaller municipalities within the consolidated city-county: Belle Meade, Berry Hill, Forest Hills, Oak Hill, Goodlettsville (partially), and Ridgetop (partially). These municipalities use a two-tier system of government, with the smaller municipality typically providing police services and the Metro Nashville government providing most other services. Previously, the city of Lakewood also had a separate charter. However, Lakewood residents voted in 2010 and 2011 to dissolve its city charter and join the metropolitan government, with both votes passing.\nNashville is governed by a mayor, vice-mayor, and 40-member Metropolitan Council. It uses the strong-mayor form of the mayor\u2013council system. The current mayor of Nashville is Freddie O'Connell. The Metropolitan Council is the legislative body of government for Nashville and Davidson County. There are five council members who are elected at large and 35 council members that represent individual districts. The Metro Council has regular meetings that are presided over by the vice-mayor, who is currently Jim Shulman. The Metro Council meets on the first and third Tuesday of each month at 6:00pm, according to the Metropolitan Charter.\nNashville is home to the Tennessee Supreme Court's courthouse for Middle Tennessee and the Estes Kefauver Federal Building and United States Courthouse, home of the United States District Court for the Middle District of Tennessee.\nPolitics.\nNashville has been a Democratic stronghold since at least the end of Reconstruction, and has remained staunchly Democratic even as the state as a whole has trended strongly Republican. Pockets of Republican influence exist in the wealthier portions of the city, but they are usually no match for the overwhelming Democratic trend in the rest of the city. The issue of school busing roiled politics for years but subsided after the 1990s. While local elections are officially nonpartisan, nearly all the city's elected officials are publicly known as Democrats. The city is split among 10 state house districts, all of which are held by Democrats. Three state senate districts and part of a fourth are within the county; three are held by Democrats and one by a Republican.\nIn the state legislature, Nashville politicians serve as leaders of both the Senate and House Democratic Caucuses. Representative Mike Stewart serves as Chairman of the House Caucus. Senator Jeff Yarbro serves as Chairman of the Senate Caucus.\nDemocrats are no less dominant at the federal level. Democratic presidential candidates have failed to carry Davidson County only five times since Reconstruction; in 1928, 1968, 1972, 1984 and 1988. In most years, Democrats have carried Nashville at the presidential level with relatively little difficulty, even in years when they lose Tennessee as a whole. This has been especially true in recent elections, as the state capitol has continued to trend more Democratic even as most of the rest of the state has become staunchly Republican. In the 2000 presidential election, Tennessean Democrat Al Gore carried Nashville with over 59% of the vote even as he narrowly lost his home state and thus the presidency. In the 2004 election, Democrat John Kerry carried Nashville with 55% of the vote while George W. Bush won the state by 14 points. In 2008, Barack Obama carried Nashville with 60% of the vote while Republican John McCain won Tennessee by 15 points.\nNashville was in a single congressional district, the 5th, for most of its history. A Republican had not represented a significant portion of Nashville since 1874, until 2023 when the GOP-controlled state legislature controversially split Nashville into parts of the 5th, 6th, and 7th districts in a partisan gerrymander an additional Republican to Tennessee's congressional delegation as part of the 2022 redistricting cycle. This Republican gerrymander 'cracked' the Democratic stronghold of Nashville across three otherwise Republican districts, ensuring three Republican representatives. This gerrymander 'diminished the influence of Black voters and other voters of color concentrated in Nashville', by splitting them up and adding portions of the Nashville community into districts that are overwhelmingly white and Republican, thus diluting the voting power of Black voters in the state.\nPrior to this gerrymander, Republicans made a few spirited challenges to the 5th district in the mid-1960s and early 1970s, almost winning the district in 1968. The last serious bid for the district while still a Democratic stronghold was in 1972, when the Republican candidate gained 38% of the vote even as Nixon carried the district in the presidential election by a large margin. The district's best-known congressman was probably Jo Byrns, who represented the district from 1909 to 1936 and was Speaker of the House for much of Franklin Roosevelt's first term as president. Another nationally prominent congressman from Nashville was Percy Priest, who represented the district from 1941 to 1956 and was House Majority Whip from 1949 to 1953. Former mayors Richard Fulton and Bill Boner also sat in the U.S. House before assuming the Metro mayoral office.\nFrom 2003 to 2013, a sliver of southwestern Nashville was located in the 7th District, represented by Republican Marsha Blackburn. This area was roughly coextensive with the portion of Nashville she had represented in the state senate from 1998 to 2002. However, the 5th regained all of Nashville after the 2010 census.\nCrime.\nAccording to the FBI's Uniform Crime Reporting database, Metropolitan Nashville has a violent crime rate approximately three times the national average, and a property crime rate approximately 1.6 times the average. The following table shows Nashville's crime rate per 100,000 inhabitants for seven UCR categories.\nEducation.\nThe city is served by Metropolitan Nashville Public Schools, also referred to as Metro Schools. This district is the second largest school district in Tennessee, and enrolls approximately 85,000 students at 169 schools. In addition, Nashville is home to numerous private schools, including Montgomery Bell Academy, Harpeth Hall School, University School of Nashville, Lipscomb Academy, The Ensworth School, Christ Presbyterian Academy, Father Ryan High School, Pope John Paul II High School, Franklin Road Academy, Davidson Academy, Nashville Christian School, Donelson Christian Academy, and St. Cecilia Academy. Combined, all of the private schools in Nashville enroll more than 15,000 students.\nColleges and universities.\nNashville has been labeled the \"Athens of the South\" due to the many colleges and universities in the metropolitan area. Total enrollment in post-secondary education in Nashville is around 43,000.\nThe largest is Vanderbilt University, with about 13,000 students. Vanderbilt is considered one of the nation's leading research universities and is particularly known for its medical, law, business, engineering, and education programs.\nNashville is home to more historically Black institutions of higher education than any other city save for Atlanta, Georgia: Fisk University, Tennessee State University, Meharry Medical College, and American Baptist College.\nOther schools based in Nashville include Belmont University, Lipscomb University, Trevecca Nazarene University, and John A. Gupton College. The Tennessee Board of Regents operates Nashville State Community College and the Nashville branch of the Tennessee Colleges of Applied Technology.\nOther nearby institutes of higher education include Murfreesboro's Middle Tennessee State University (MTSU) and Clarksville's Austin Peay University, both full-sized public university with Tennessee's second- and eighth-largest undergraduate populations, respectively; Daymar College in Franklin; and Cumberland University in Lebanon.\nMedia.\nThe daily newspaper in Nashville is \"The Tennessean\", which until 1998 competed with the \"Nashville Banner\", another daily paper that was housed in the same building under a joint-operating agreement. \"The Tennessean\" is the city's most widely circulated newspaper. Online news service \"NashvillePost.com\" competes with the printed dailies to break local and state news. Several weekly papers are also published in Nashville, including \"The Nashville Pride\", \"Nashville Business Journal\", \"Nashville Scene\" and \"The Tennessee Tribune\". Historically, \"The Tennessean\" was associated with a broadly liberal editorial policy, while \"The Banner\" carried staunchly conservative views in its editorial pages; \"The Banner\"'s heritage had been carried on, to an extent, by \"The City Paper\" which folded in August 2013 after having been founded in October 2000. The \"Nashville Scene\" is the area's alternative weekly broadsheet. \"The Nashville Pride\" is aimed towards community development and serves Nashville's entrepreneurial population. \"Nashville Post\" is an online news source covering business, politics and sports.\nNashville is home to eleven broadcast television stations, although most households are served by direct cable network connections. Comcast Cable has a monopoly on terrestrial cable service in Davidson County (but not throughout the entire media market). Nashville is ranked as the 26th largest television market in the United States. Major stations include WKRN-TV 2 (ABC), WSMV-TV 4 (NBC), WTVF 5 (CBS), WNPT 8 (PBS), WTNX-LD 15 (Telemundo), WZTV 17 (Fox, with The CW on DT2), WNPX-TV 28 (ion), WPGD-TV 50 (TBN), WLLC-LD 42 (Univision), WUXP-TV 30 (MyNetworkTV), (WJFB) 44 (MeTV), and WNAB 58 (Dabl).\nNashville is also home to cable networks Country Music Television (CMT) and RFD-TV, among others. CMT's master control facilities are located in New York City with other Viacom properties. The Top 20 Countdown and CMT Insider are taped in their Nashville studios. Shop at Home Network was once based in Nashville, but the channel signed off in 2008.\nSeveral FM and AM radio stations broadcast in the Nashville area, including five college stations and one LPFM community radio station. Nashville is ranked as the 39th largest radio market in the United States. WSM-FM is owned by Cumulus Media and is 95.5 FM. WSM-AM, owned by Gaylord Entertainment Company, is based on the Gaylord Opryland Resort &amp; Convention Center. WSM is famous for carrying live broadcasts of the Grand Ole Opry, through which it helped spread the popularity of country music in America, and continues to broadcast country music throughout its broadcast day. WLAC, whose over-the-air signal is heard at 1510 AM, is an iHeartMedia-owned talk station which was originally sponsored by the Life and Casualty Insurance Company of Tennessee, and its competitor WWTN is owned by Cumulus.\nSeveral major motion pictures have been filmed in Nashville, including \"The Green Mile\", \"The Matrix\", \"The Last Castle\", \"Gummo\", \"Starman\", \"The Thing Called Love\", \"Two Weeks\", \"Coal Miner's Daughter\", \"Nashville\", and \"Country Strong\", as well as the ABC television series \"Nashville\" and another upcoming ABC television series \"9-1-1 Nashville\".\nInfrastructure.\nTransportation.\nAccording to the 2016 American Community Survey, 78.1% of working Nashville residents commuted by driving alone, 9.8% carpooled, 2% used public transportation, and 2.2% walked. About 1.1% used all other forms of transportation, including taxicab, motorcycle, and bicycle. About 6.7% of working Nashville residents worked at home. In 2015, 7.9% of city of Nashville households were without a car; this figure decreased to 5.9% in 2016. The national average was 8.7 percent in 2016. Nashville averaged 1.72 cars per household in 2016, compared to a national average of 1.8 per household.\nHighways.\nNashville is centrally located at the crossroads of three Interstate Highways, I-40 (east-west), I-24 (northwest-southeast) and I-65 (north-south). I-40 connects the city between Memphis to the west and Knoxville to the east, I-24 connects between Clarksville to the northwest and Chattanooga to the southeast, and I-65 connects between Louisville to the north and Huntsville to the south. All three of these interstate highways, which also serve the suburbs, form brief concurrencies with each other in the city, and completely encircle downtown. I-440 is a bypass route connecting I-40, I-65, and I-24 south of Downtown Nashville. Briley Parkway, the majority of which is a freeway, forms a bypass around the north side of the city and its interstates. Ellington Parkway, a freeway made up of a section of US 31E, runs between east of downtown and Briley Parkway, serving as an alternative route to I-65. I-840 provides an outer southern bypass for the city and its suburbs. U.S. Routes 31, 31E, 31W, 31 Alternate, 41, 41 Alternate, 70, 70S, and 431 also serve Nashville, intersecting in the city's center as arterial surface roads and radiating outward. Most of these routes are called \"pikes\" and many carry the names of nearby towns to which they lead. Among these are Clarksville Pike, Gallatin Pike, Lebanon Pike, Murfreesboro Pike, Nolensville Pike, and Franklin Pike.\nPublic transit.\nWeGo Public Transit provides bus transit within the city. Routes utilize a hub and spoke method, centered around the Music City Central transit station in downtown. A 2018 expansion plan that included use of bus rapid transit and light rail service was rejected by voters. A subsequent expansion plan focused on improving sidewalks, adding smart signals, upgrading bus stops and transit centers, implementing a 24-hour bus service and adding 54 miles of high-capacity transit corridors was passed in 2024.\nNashville is considered a gateway city for rail and air traffic for the Piedmont Atlantic Megaregion.\nAir.\nThe city is served by Nashville International Airport (BNA), which is operated by the Metropolitan Nashville Airport Authority (MNAA). Nearly 23 million passengers visited the airport in 2023, making it the 29th busiest airport in the US. BNA is ranked the fastest growing airport among the top 50 airports in the United States. Nashville International Airport serves 600 daily flights to more than 100 nonstop markets.\nIn late 2014, BNA became the first major U.S. airport to establish dedicated pick-up and drop-off areas for vehicle for hire companies.\nThe airport authority also operates the John C. Tune Airport, a Class E airspace general aviation airport.\nIntercity rail.\nAlthough a major freight hub for CSX Transportation, Nashville is not currently served by Amtrak, the third-largest metropolitan area in the U.S. to have this distinction. Nashville's Union Station had once been a major intercity passenger rail center for the Louisville and Nashville Railroad; Nashville, Chattanooga and St. Louis Railway; and the Tennessee Central Railway, reaching Midwestern cities and cities on the Gulf of Mexico and the Atlantic Ocean. However, by the time of Amtrak's founding, service had been cut back to a single train, the \"Floridian\", which ran from Chicago to Miami and St. Petersburg, Florida. It served Union Station until its cancellation on October 9, 1979, due to poor track conditions resulting in late trains and low ridership, ending over 120 years of intercity rail service in Nashville.\nWhile there have been few proposals to restore Amtrak service to Nashville, there have been repeated calls from residents. In addition to scarce federal funding, Tennessee state officials do not believe that Nashville is large enough to support intercity rail. \"It would be wonderful to say I can be in Memphis and jump on a train to Nashville, but the volume of people who would do that isn't anywhere close to what the cost would be to provide the service,\" said Ed Cole, chief of environment and planning with the Tennessee Department of Transportation. Ross Capon, executive director of the National Association of Railroad Passengers, said rail trips would catch on if routes were expanded, but conceded that it would be nearly impossible to resume Amtrak service to Nashville without a substantial investment from the state. However, in 2020, Amtrak indicated it was considering a service that would run from Atlanta to Nashville by way of Chattanooga.\nNashville launched a passenger commuter rail system called the Music City Star (now the WeGo Star) on September 18, 2006. The only currently operational leg of the system connects the city of Lebanon to downtown Nashville at the Nashville Riverfront station. Legs to Clarksville, Murfreesboro and Gallatin are currently in the feasibility study stage. The system plan includes seven legs connecting Nashville to surrounding suburbs.\nBridges.\nBridges within the city include:\nUtilities.\nThe city of Nashville owns the Nashville Electric Service (NES), Metro Water Services (MWS) and Nashville District Energy System (NDES). The Nashville Electric Service provides electricity to the entirety of Davidson County and small portions of the six adjacent counties, and purchases its power from the Tennessee Valley Authority. Metro Water Services provides water, wastewater, and stormwater to Nashville and the majority of Davidson County, as well as water services to small portions of Rutherford and Williamson counties, and wastewater services to small portions of all of the surrounding counties except for Cheatham County. MWS sources its water from the Cumberland River and operates two water treatment plants and three wastewater treatment plants. Ten additional utility companies provide water and sewer service to Nashville and Davidson County. The Nashville District Energy System provides heating and cooling services to certain buildings in downtown, including multiple government buildings. Natural gas is provided by Piedmont Natural Gas, a subsidiary of Duke Energy.\nHealthcare.\nAs a major center for the healthcare industry, Nashville is home to several hospitals and other primary care facilities. Most hospitals in Nashville are operated by Vanderbilt University Medical Center, the TriStar Division of Hospital Corporation of America, and Ascension Saint Thomas. The Metropolitan Nashville Hospital Authority operates Nashville General Hospital, which is affiliated with Meharry Medical College.\nInternational relations.\nSister cities.\nNashville's sister cities are:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nConsulates.\nNashville is also home to consulates for the following countries:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22020", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=22020", "title": "Network protocol design principles", "text": ""}
{"id": "22022", "revid": "21640150", "url": "https://en.wikipedia.org/wiki?curid=22022", "title": "Nietzsche", "text": ""}
{"id": "22023", "revid": "38556235", "url": "https://en.wikipedia.org/wiki?curid=22023", "title": "Nicholas Copernicus", "text": ""}
{"id": "22024", "revid": "45397322", "url": "https://en.wikipedia.org/wiki?curid=22024", "title": "Novial", "text": "Constructed language\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nNovial is an international auxiliary language (IAL) created by Danish linguist Otto Jespersen in 1928. It was designed to facilitate communication between speakers of different native languages. The name of the language is a blend of the Novial word \"novi\" (meaning 'new\") and IAL.\nJespersen had been an early supporter of another international auxiliary language, Ido, a reformed version of Esperanto, before leaving to create his own language in 1928.\nNovial's vocabulary is borrowed largely from the Romance and Germanic languages, while its analytic grammar is influenced by English.\nNovial was introduced in Jespersen's book \"An International Language\" in 1928. It was updated in his dictionary \"Novial Lexike\" in 1930, and further modifications were proposed in the 1930s, but the language became dormant with Jespersen's death in 1943.\nPhonology.\nStress.\nThe basic rule is: stress the vowel before the last consonant. However, consonantal flexional endings (ie. -d, -m, -n, -s) do not count for this (e.g. but , not ; but , not ), so perhaps it is better to say that the vowel before the final consonant of the stem takes the stress.\nOrthography.\nThe digraphs \"ch\" and \"sh\" represent or , depending on the speaker. For example, would be pronounced either or . \"w\" is not used.\nGrammar.\nLike many constructed IALs, Novial has a simple and regular grammar. The main word order is SVO, which removes the need for marking the object of a sentence with accusative case (since the position normally tells what word is the object). There is however a way to mark accusative. There is no grammatical gender (but the sex or gender of referents can be marked). Verbs are conjugated regularly, without agreement (according to person or number).\nNouns mainly end in \"e\", \"a\", \"o\", \"u\" or \"um\" in the singular. There are definite forms of nouns marked with an article, and singular and plural forms, where the plural is marked with the suffix after vowels or after consonants. There is also a form for indefinite number (as in Mandarin Chinese and Japanese), expressed by removing the ending of the noun in the singular ( \u2013 lion, \u2013 'a/the lion is cruel', or 'lions are cruel').\nIf a noun refers to a living being, then the form ending in is neutral with regard to sex, that ending in female, and that ending in male. If based on an adjective, a nouns referring to a living being can be made with the previously mentioned rule, and furthermore nouns referring to concrete objects with , and abstractions with . The third-person pronouns follow the same rule, together with the definite article.\nReferring to an instrument \u2013 a tool or a means \u2013 a word that ends in is the tool or the means itself, a verb describing usage of the tool and so on, and a noun describing the act of that using:\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\nPersonal pronouns.\nThe standard word order in Novial is subject\u2013verb\u2013object, as in English. Therefore, the object need not be marked to distinguish it from the subject, and nominative (corresponding to \"I, he, she\" and so on) and accusative (corresponding to \"me, him, us\", etc) pronouns are identical:\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\nThe accusative (direct object) is therefore most often identical to the nominative (subject). However, for avoiding ambiguity, an optional accusative ending, ( after a consonant), is available; it is rarely used. The preposition is equivalent to this ending.\nThe genitive personal pronouns \u2013 whether dependent or independent (corresponding to \"my, their\", etc, or to \"mine, theirs\", etc, respectively) \u2013 are formed by adding or after a consonant :\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\nThe genitive pronouns are thus , , , etc., and , , etc. and . Such a relationship may also be expressed with the preposition : , , and so on.\nThe reflexive pronoun is : \u2013 'he admires himself'. The generic personal pronoun (similar to the English \"one\") is , with the genitive form .\nVerbs.\nVerb forms never change with person or number. Most verb tenses, moods and voices are expressed with auxiliary verbs preceding the root form of the main verb. The auxiliaries follow the same word order as the English equivalent. The following are examples of the verb forms:\nNovial clearly distinguishes the passive of becoming and the passive of being. In English the forms are often the same, using the auxiliary verb \"be\" followed by the past participle. However, the passive of becoming is also often expressed with the verb \"get\" which is used in the examples below.\nThe passive voice of becoming is formed with the auxiliary followed by the root verb form. It can then be conjugated into the previously mentioned forms, for example:\nThe passive voice of being is formed with the auxiliary followed by the past passive participle (stem + \"-t\"). For example:\nArticles.\nThe definite article is , which is invariant. It is used as in English.\nThere is no indefinite article, although ('one') can be used.\nNouns.\nThe plural noun is formed by adding to the singular ( after a consonant).\nThe accusative case is generally identical to the nominative but can optionally be marked with the ending ( after a consonant) with the plural being ( after a consonant) or with the preposition .\nThe genitive is formed with the ending ( after a consonant) with the plural being ( after a consonant) or with the preposition .\nOther cases are formed with prepositions.\nAdjectives.\nAll adjectives end in , but this may be dropped if it is easy enough to pronounce and no confusion will be caused. Adjectives precede the noun qualified. Adjectives do not agree with the noun but may be given noun endings if there is no noun present to receive them.\nComparative adjectives are formed by placing various particles (, , and ) in front of the adjective receiving the comparison. Likewise, the superlative particles ( and ) precede the adjective. The adjective does not receive an inflection to its ending.\nAdverbs.\nAn adjective is converted to a corresponding adverb by adding after the ending of the adjective.\nComparative and superlative adverbs are formed in the same manner as comparative and superlative adjectives: by placing a specific particle before the adverb receiving the comparison.\nVocabulary.\nAffixes.\nSee the and at the Novial Wikibook.\nNovial compared to Esperanto and Ido.\nJespersen was a professional linguist, unlike Esperanto's creator. He disliked the arbitrary and artificial character that he found in Esperanto and Ido. Additionally, he objected to those languages' inflectional systems, which he found needlessly complex. He sought to make Novial at once euphonious and regular while also preserving useful structures from natural languages.\nIn Novial:\nA major difference between Novial and Esperanto/Ido concerns noun endings. Jespersen rejected a single vowel to terminate all nouns (-o in Esperanto/Ido), finding it unnatural and potentially confusing. Instead, Novial nouns may end in , , , or or . These endings may be taken to indicate natural sex according to the custom in Romance languages, though there is no grammatical gender or requirement for adjectives to agree with nouns.\nLanguage sample for comparison.\nHere is the Lord's Prayer in Novial and several related languages:\nCriticism.\nAs Jespersen relates in his autobiography, in 1934 he proposed an orthographic reform to Novial, which displeased a faction of the users. Jespersen abandoned the essential principle of \"one sound, one letter\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I proposed some not inconsiderable amendments, especially by introducing an \"orthographic\" Novial alongside the original phonetically written language. (...) Thus the sound [k], besides being represented by the letters \"k\" and \"q\" and the first part of \"x\", also acquired the new sign \"c\" (before \"a, o, u\" and consonants), a practice with which nearly all Europeans, Americans, and Australians are familiar from childhood. (...) I know that this orthographic form has displeased several of Novial's old and faithful friends, but it is my impression that many others have applauded it.\nSome of Jespersen's colleagues among philologists jokingly referred to Novial as \"Jesperanto\", combining his surname with Esperanto, the prototypical auxiliary language.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22026", "revid": "50096184", "url": "https://en.wikipedia.org/wiki?curid=22026", "title": "Musical note", "text": "Representation of isolatable musical sound\nIn music, notes are distinct and isolatable sounds that act as the most basic building blocks for nearly all of music. This discretization facilitates performance, comprehension, and analysis. Notes may be visually communicated by writing them in musical notation.\nNotes can distinguish the general pitch class or the specific pitch played by a pitched instrument. Although this article focuses on pitch, notes for unpitched percussion instruments distinguish between different percussion instruments (and/or different manners to sound them) instead of pitch. Note value expresses the relative duration of the note in time. Dynamics for a note indicate how loud to play them. Articulations may further indicate how performers should shape the attack and decay of the note and express fluctuations in a note's timbre and pitch. Notes may even distinguish the use of different extended techniques by using special symbols.\nThe term \"note\" can refer to a specific musical event, for instance when saying the song \"Happy Birthday to You\", begins with two notes of identical pitch. Or more generally, the term can refer to a class of identically sounding events, for instance when saying \"the song begins with the same note repeated twice\".\nDistinguishing duration.\nA note can have a note value that indicates the note's duration relative to the musical meter. In order of halving duration, these values are:\nLonger note values (e.g. the longa) and shorter note values (e.g. the two hundred fifty-sixth note) do exist, but are very rare in modern times. These durations can further be subdivided using tuplets.\nA rhythm is formed from a sequence in time of consecutive notes (without particular focus on pitch) and rests (the time between notes) of various durations.\nDistinguishing pitch.\nDistinguishing pitches of a scale.\nMusic theory in most European countries and others use the solf\u00e8ge naming convention. Fixed do uses the syllables \"re\u2013mi\u2013fa\u2013sol\u2013la\u2013ti\" specifically for the C major scale, while movable do labels notes of \"any\" major scale with that same order of syllables.\nAlternatively, particularly in English- and some Dutch-speaking regions, and certainly in all of Germany, pitch classes are typically represented by the first seven letters of the Latin alphabet (A, B, C, D, E, F and G), corresponding to the A minor scale. Several European countries, including Germany and Czechia, use H instead of B (see for details). Byzantium used the names \"Pa\u2013Vu\u2013Ga\u2013Di\u2013Ke\u2013Zo\u2013Ni\" (\u03a0\u03b1\u2013\u0392\u03bf\u03c5\u2013\u0393\u03b1\u2013\u0394\u03b9\u2013\u039a\u03b5\u2013\u0396\u03c9\u2013\u039d\u03b7).\nIn traditional Indian music, musical notes are called svaras and commonly represented using the seven notes, Sa, Re, Ga, Ma, Pa, Dha and Ni.\nWriting notes on a staff.\nIn a score, each note is assigned a specific vertical position on a staff position (a line or space) on the staff, as determined by the clef. Each line or space is assigned a note name. These names are memorized by musicians and allow them to know at a glance the proper pitch to play on their instruments.\n&lt;score sound=\"1\"&gt;\n\\relative c' {\nc1 d1 e1 f1 g1 a1 b1 c1 b1 a1 g1 f1 e1 d1 c1\n\\layout {\n \\context {\n \\Staff\n \\remove Time_signature_engraver\n \\remove Bar_engraver\n } \n\\midi {\n \\tempo 1 = 120\n&lt;/score&gt;\nThe staff above shows the notes C, D, E, F, G, A, B, C and then in reverse order, with no key signature or accidentals.\nAccidentals.\nNotes that belong to the diatonic scale relevant in a tonal context are called \"diatonic notes\". Notes that do not meet that criterion are called \"chromatic notes\" or \"accidentals\". Accidental symbols visually communicate a modification of a note's pitch from its tonal context. Most commonly, the sharp symbol (\u266f) raises a note by a half step, while the flat symbol (\u266d) lowers a note by a half step. This half step interval is also known as a semitone (which has an equal temperament frequency ratio of 12\u221a2\u00a0\u2245\u00a01.0595). The natural symbol (\u266e) indicates that any previously applied accidentals should be cancelled. Advanced musicians use the double-sharp symbol () to raise the pitch by two semitones, the double-flat symbol () to lower it by two semitones, and even more advanced accidental symbols (e.g. for quarter tones). Accidental symbols are placed to \"the right\" of a note's letter when written in text (e.g. F\u266f is F-sharp, B\u266d is B-flat, and C\u266e is C natural), but are placed to \"the left\" of a note's head when drawn on a staff.\nSystematic alterations to any of the 7 lettered pitch classes are communicated using a key signature. When drawn on a staff, accidental symbols are positioned in a key signature to indicate that those alterations apply to all occurrences of the lettered pitch class corresponding to each symbol's position. Additional explicitly-noted accidentals can be drawn next to noteheads to override the key signature for all subsequent notes with the same lettered pitch class in that bar. However, this effect does not accumulate for subsequent accidental symbols for the same pitch class.\n12-tone chromatic scale.\nAssuming enharmonicity, accidentals can create pitch equivalences between different notes (e.g. the note B\u266f represents the same pitch as the note C). Thus, a 12-note chromatic scale adds 5 pitch classes in addition to the 7 lettered pitch classes.\nThe following chart lists names used in different countries for the 12 pitch classes of a chromatic scale built on C. Their corresponding symbols are in parentheses. Differences between German and English notation are highlighted in bold typeface. Although the English and Dutch names are different, the corresponding symbols are identical.\nDistinguishing pitches of different octaves.\nTwo pitches that are any number of octaves apart (i.e. their fundamental frequencies are in a ratio equal to a power of two) are perceived as very similar. Because of that, all notes with these kinds of relations can be grouped under the same pitch class and are often given the same name.\nThe top note of a musical scale is the bottom note's second harmonic and has double the bottom note's frequency. Because both notes belong to the same pitch class, they are often called by the same name. That top note may also be referred to as the \"octave\" of the bottom note, since an octave is the interval between a note and another with double frequency.\nScientific versus Helmholtz pitch notation.\nTwo nomenclature systems for differentiating pitches that have the same pitch class but which fall into different octaves are:\nFor instance, the standard 440\u00a0Hz tuning pitch is named A4 in scientific notation and instead named a\u2032 in Helmholtz notation.\nMeanwhile, the electronic musical instrument standard called MIDI doesn't specifically designate pitch classes, but instead names pitches by counting from its lowest note: number\u00a00 (C\u22121 \u2248 8.1758 Hz); up chromatically to its highest: number 127 (G9 \u2248 12,544 Hz). (Although the MIDI \"standard\" is clear, the octaves actually played by any one MIDI device don't necessarily match the octaves shown below, especially in older instruments.)\nPitch frequency in hertz.\nPitch is associated with the frequency of physical oscillations measured in hertz (Hz) representing the number of these oscillations per second. While notes can have any arbitrary frequency, notes in more consonant music tends to have pitches with simpler mathematical ratios to each other.\nWestern music defines pitches around a central reference \"concert pitch\" of A4, currently standardized as 440\u00a0Hz. Notes played \"in tune\" with the 12 equal temperament system will be an integer number formula_1 of half-steps above (positive formula_1) or below (negative formula_1) that reference note, and thus have a frequency of:\nformula_4\nOctaves automatically yield powers of two times the original frequency, since formula_1 can be expressed as formula_6 when formula_1 is a multiple of 12 (with formula_8 being the number of octaves up or down). Thus the above formula reduces to yield a power of 2 multiplied by 440\u00a0Hz:\nformula_9\nLogarithmic scale.\nThe base-2 logarithm of the above frequency\u2013pitch relation conveniently results in a linear relationship with formula_1 or formula_8:\nformula_12\nWhen dealing specifically with intervals (rather than absolute frequency), the constant formula_13 can be conveniently ignored, because the \"difference\" between any two frequencies formula_14 and formula_15 in this logarithmic scale simplifies to:\nformula_16\nCents are a convenient unit for humans to express finer divisions of this logarithmic scale that are &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u2044100th of an equally-tempered semitone. Since one semitone equals 100\u00a0cents, one octave equals 12\u00a0\u22c5\u00a0100\u00a0cents\u00a0=\u00a01200\u00a0cents. Cents correspond to a \"difference\" in this logarithmic scale, however in the regular linear scale of frequency, adding 1 cent corresponds to \"multiplying\" a frequency by 1200\u221a2\u00a0(\u2245\u00a0).\nMIDI.\nFor use with the MIDI (Musical Instrument Digital Interface) standard, a frequency mapping is defined by:\nformula_17\nwhere formula_18 is the MIDI note number. 69 is the number of semitones between C\u22121 (MIDI note 0) and A4.\nConversely, the formula to determine frequency from a MIDI note formula_18 is:\nformula_20\nPitch names and their history.\nMusic notation systems have used letters of the alphabet for centuries. The 6th\u00a0century philosopher Boethius is known to have used the first fourteen letters of the classical Latin alphabet (the letter J did not exist until the 16th\u00a0century),\nA \u00a0 B \u00a0 C \u00a0 D \u00a0 E \u00a0 F \u00a0 G \u00a0 H \u00a0 I \u00a0 K \u00a0 L \u00a0 M \u00a0 N \u00a0 O\nto signify the notes of the two-octave range that was in use at the time and in modern scientific pitch notation are represented as\nA2 \u00a0 B2 \u00a0 C3 \u00a0 D3 \u00a0 E3 \u00a0 F3 \u00a0 G3 \u00a0 A3 \u00a0 B3 \u00a0 C4 \u00a0 D4 \u00a0 E4 \u00a0 F4 \u00a0 G4\nThough it is not known whether this was his devising or common usage at the time, this is nonetheless called \"Boethian notation\". Although Boethius is the first author known to use this nomenclature in the literature, Ptolemy wrote of the two-octave range five centuries before, calling it the \"perfect system\" or \"complete system\" \u2013 as opposed to other, smaller-range note systems that did not contain all possible species of octave (i.e., the seven octaves starting from A, B, C, D, E, F, and G). A modified form of Boethius' notation later appeared in the \"Dialogus de musica\" (ca. 1000) by Pseudo-Odo, in a discussion of the division of the monochord.\nFollowing this, the range (or compass) of used notes was extended to three octaves, and the system of repeating letters A\u2013G in each octave was introduced, these being written as lower-case for the second octave (a\u2013g) and double lower-case letters for the third (aa\u2013gg). When the range was extended down by one note, to a G, that note was denoted using the Greek letter gamma (\u0393), the lowest note in Medieval music notation. (It is from this gamma that the French word for scale, derives, and the English word \"gamut\", from \"gamma-ut\".)\nThe remaining five notes of the chromatic scale (the black keys on a piano keyboard) were added gradually; the first being B\u266d, since B was flattened in certain modes to avoid the dissonant tritone interval. This change was not always shown in notation, but when written, B\u266d (B\u00a0flat) was written as a Latin, cursive \"\ud835\udcb7\", and B\u266e (B\u00a0natural) a Gothic script (known as Blackletter) or \"hard-edged\" \ud835\udd1f. These evolved into the modern flat (\u266d) and natural (\u266e) symbols respectively. The sharp symbol arose from a \u0180 (barred\u00a0b), called the \"cancelled\u00a0b\".\nB\u266d, B and H.\nIn parts of Europe, including Germany, the Czech Republic, Slovakia, Poland, Hungary, Norway, Denmark, Serbia, Croatia, Slovenia, Finland, and Iceland (and Sweden before the 1990s), the Gothic\u00a0\ud835\udd1f transformed into the letter h (possibly for \"hart\", German for \"harsh\", as opposed to \"blatt\", German for \"planar\", or just because the Gothic\u00a0\ud835\udd1f and \ud835\udd25 resemble each other). Therefore, in current German music notation, H is used instead of B\u266e (B\u00a0natural), and B instead of B\u266d (B\u00a0flat). Occasionally, music written in German for international use will use H for B\u00a0natural and Bb for B\u00a0flat (with a modern-script lower-case\u00a0b, instead of a flat sign, \u266d). Since a or B\u266d in Northern Europe (notated B in modern convention) is both rare and unorthodox (more likely to be expressed as Heses), it is generally clear what this notation means.\nSystem \"do\u2013re\u2013mi\u2013fa\u2013sol\u2013la\u2013si\".\nIn Italian, Portuguese, Spanish, French, Romanian, Greek, Albanian, Russian, Mongolian, Flemish, Persian, Arabic, Hebrew, Ukrainian, Bulgarian, Turkish and Vietnamese the note names are \"do\u2013re\u2013mi\u2013fa\u2013sol\u2013la\u2013si\" rather than C\u2013D\u2013E\u2013F\u2013G\u2013A\u2013B. These names follow the original names reputedly given by Guido d'Arezzo, who had taken them from the first syllables of the first six musical phrases of a Gregorian chant melody \"Ut queant laxis\", whose successive lines began on the appropriate scale degrees. These became the basis of the solf\u00e8ge system. For ease of singing, the name \"ut\" was largely replaced by \"do\" (most likely from the beginning of \"Dominus\", \"Lord\"), though \"ut\" is still used in some places. It was the Italian musicologist and humanist Giovanni Battista Doni (1595\u20131647) who successfully promoted renaming the name of the note from \"ut\" to \"do\". For the seventh degree, the name \"si\" (from \"Sancte Iohannes\", St.\u00a0John, to whom the hymn is dedicated), though in some regions the seventh is named \"ti\" (again, easier to pronounce while singing).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22028", "revid": "1291160813", "url": "https://en.wikipedia.org/wiki?curid=22028", "title": "Nephrology", "text": "Medical study concerned with the kidneys\nNephrology is a specialty for both adult internal medicine and pediatric medicine that concerns the study of the kidneys, specifically normal kidney function (renal physiology) and kidney disease (renal pathophysiology), the preservation of kidney health, and the treatment of kidney disease, from diet and medication to renal replacement therapy (dialysis and kidney transplantation). The word \"renal\" is an adjective meaning \"relating to the kidneys\", and its roots are French or late Latin. Whereas according to some opinions, \"renal\" and \"nephro-\" should be replaced with \"kidney\" in scientific writings such as \"kidney medicine\" (instead of \"nephrology\") or \"kidney replacement therapy\", other experts have advocated preserving the use of renal and nephro- as appropriate including in \"nephrology\" and \"renal replacement therapy\", respectively.\nNephrology also studies systemic conditions that affect the kidneys, such as diabetes and autoimmune disease; and systemic diseases that occur as a result of kidney disease, such as renal osteodystrophy and hypertension. A physician who has undertaken additional training and become certified in nephrology is called a \"nephrologist\".\nEtymology.\nThe term \"nephrology\" was first used in about 1960, according to the French \"n\u00e9phrologie\" proposed by Jean Hamburger in 1953, from the Greek , \"nephr\u00f3s\" (kidney). Before then, the specialty was usually referred to as \"kidney medicine\".\nScope.\nNephrology concerns the diagnosis and treatment of kidney diseases, including electrolyte disturbances and hypertension, and the care of those requiring renal replacement therapy, including dialysis and renal transplant patients.\nThe word \"dialysis\" is from the mid-19th century: via Latin from the Greek word \"dialusis\"; from \"dialuein\" (split, separate), from \"dia\" (apart) and \"luein\" (set free). In other words, dialysis replaces the primary (excretory) function of the kidney, which separates (and removes) excess toxins and water from the blood, placing them in the urine.\nMany diseases affecting the kidney are systemic disorders not limited to the organ itself, and may require special treatment. Examples include acquired conditions such as systemic vasculitides (e.g. ANCA vasculitis) and autoimmune diseases (e.g. lupus), as well as congenital or genetic conditions such as polycystic kidney disease.\nPatients are referred to nephrology specialists after a urinalysis, for various reasons, such as acute kidney injury, chronic kidney disease, hematuria, proteinuria, kidney stones, hypertension, and disorders of acid/base or electrolytes.\nNephrologist.\nA nephrologist is a physician who specializes in the care and treatment of kidney disease. Nephrology requires additional training to become an expert with advanced skills. Nephrologists may provide care to people without kidney problems and may work in general/internal medicine, transplant medicine, immunosuppression management, intensive care medicine, clinical pharmacology, perioperative medicine, or pediatric nephrology.\nNephrologists may further sub-specialise in dialysis, kidney transplantation, home therapies (home dialysis), cancer-related kidney diseases (onco-nephrology), structural kidney diseases (uro-nephrology), procedural nephrology or other non-nephrology areas as described above.\nProcedures a nephrologist may perform include native kidney and transplant kidney biopsy, dialysis access insertion (temporary vascular access lines, tunnelled vascular access lines, peritoneal dialysis access lines), fistula management (angiographic or surgical fistulogram and plasty), and bone biopsy. Bone biopsies are now unusual.\nTraining.\nIndia\nTo become a nephrologist in India, one has to complete an MBBS (5 and 1/2 years) degree, followed by an MD/DNB (3 years) either in medicine or paediatrics, followed by a DM/DNB (3 years) course in either nephrology or paediatric nephrology.\nAustralia and New Zealand.\nNephrology training in Australia and New Zealand typically includes completion of a medical degree (Bachelor of Medicine, Bachelor of Surgery: 4\u20136 years), internship (1 year), Basic Physician Training (3 years minimum), successful completion of the Royal Australasian College of Physicians written and clinical examinations, and Advanced Physician Training in Nephrology (3 years). The training pathway is overseen and accredited by the Royal Australasian College of Physicians, though the application process varies across states. Completion of a post-graduate degree (usually a PhD) in a nephrology research interest (3\u20134 years) is optional but increasingly common. Finally, many Australian and New Zealand nephrologists participate in career-long professional and personal development through bodies such as the Australian and New Zealand Society of Nephrology and the Transplant Society of Australia and New Zealand.\nUnited Kingdom.\nIn the United Kingdom, nephrology (often called renal medicine) is a subspecialty of general medicine. A nephrologist has completed medical school, foundation year posts (FY1 and FY2) and core medical training (CMT), specialist training (ST) and passed the Membership of the Royal College of Physicians (MRCP) exam before competing for a National Training Number (NTN) in renal medicine. The typical Specialty Training (when they are called a registrar, or an ST) is five years and leads to a Certificate of Completion of Training (CCT) in both renal medicine and general (internal) medicine. In those five years, they usually rotate yearly between hospitals in a region (known as a deanery). They are then accepted on to the Specialist Register of the General Medical Council (GMC). Specialty trainees often interrupt their clinical training to obtain research degrees (MD/PhD). After achieving CCT, the registrar (ST) may apply for a permanent post as Consultant in Renal Medicine. Subsequently, some Consultants practice nephrology alone. Others work in this area, and in Intensive Care (ICU), or General (Internal) or Acute Medicine.\nUnited States.\nNephrology training can be accomplished through one of two routes. The first path way is through an internal medicine pathway leading to an Internal Medicine/Nephrology specialty, and sometimes known as \"adult nephrology\". The second pathway is through Pediatrics leading to a speciality in Pediatric Nephrology. In the United States, after medical school adult nephrologists complete a three-year residency in internal medicine followed by a two-year (or longer) fellowship in nephrology. Complementary to an adult nephrologist, a pediatric nephrologist will complete a three-year pediatric residency after medical school or a four-year Combined Internal Medicine and Pediatrics residency. This is followed by a three-year fellowship in Pediatric Nephrology. Once training is satisfactorily completed, the physician is eligible to take the American Board of Internal Medicine (ABIM) or American Osteopathic Board of Internal Medicine (AOBIM) nephrology examination. Nephrologists must be approved by one of these boards. To be approved, the physician must fulfill the requirements for education and training in nephrology in order to qualify to take the board's examination. If a physician passes the examination, then he or she can become a nephrology specialist. Typically, nephrologists also need two to three years of training in an ACGME or AOA accredited fellowship in nephrology. Nearly all programs train nephrologists in continuous renal replacement therapy; fewer than half in the United States train in the provision of plasmapheresis. Only pediatric trained physicians are able to train in pediatric nephrology, and internal medicine (adult) trained physicians may enter general (adult) nephrology fellowships.\nDiagnosis.\nHistory and physical examination are central to the diagnostic workup in nephrology. The history typically includes the present illness, family history, general medical history, diet, medication use, drug use and occupation. The physical examination typically includes an assessment of volume state, blood pressure, heart, lungs, peripheral arteries, joints, abdomen and flank. A rash may be relevant too, especially as an indicator of autoimmune disease.\nExamination of the urine (urinalysis) allows a direct assessment for possible kidney problems, which may be suggested by appearance of blood in the urine (hematuria), protein in the urine (proteinuria), pus cells in the urine (pyuria) or cancer cells in the urine. A 24-hour urine collection used to be used to quantify daily protein loss (see proteinuria), urine output, creatinine clearance or electrolyte handling by the renal tubules. It is now more common to measure protein loss from a small random sample of urine.\nBasic blood tests can be used to check the concentration of hemoglobin, white count, platelets, sodium, potassium, chloride, bicarbonate, urea, creatinine, albumin, calcium, magnesium, phosphate, alkaline phosphatase and parathyroid hormone (PTH) in the blood. All of these may be affected by kidney problems. The serum creatinine concentration is the most important blood test as it is used to estimate the function of the kidney, called the creatinine clearance or estimated glomerular filtration rate (GFR).\nIt is a good idea for patients with longterm kidney disease to know an up-to-date list of medications, and their latest blood tests, especially the blood creatinine level. In the United Kingdom, blood tests can monitored online by the patient, through a website called RenalPatientView.\nMore specialized tests can be ordered to discover or link certain systemic diseases to kidney failure such as infections (hepatitis B, hepatitis C), autoimmune conditions (systemic lupus erythematosus, ANCA vasculitis), paraproteinemias (amyloidosis, multiple myeloma) and metabolic diseases (diabetes, cystinosis).\nStructural abnormalities of the kidneys are identified with imaging tests. These may include Medical ultrasonography/ultrasound, computed axial tomography (CT), scintigraphy (nuclear medicine), angiography or magnetic resonance imaging (MRI).\nIn certain circumstances, less invasive testing may not provide a certain diagnosis. Where definitive diagnosis is required, a biopsy of the kidney (renal biopsy) may be performed. This typically involves the insertion, under local anaesthetic and ultrasound or CT guidance, of a core biopsy needle into the kidney to obtain a small sample of kidney tissue. The kidney tissue is then examined under a microscope, allowing direct visualization of the changes occurring within the kidney. Additionally, the pathology may also stage a problem affecting the kidney, allowing some degree of prognostication. In some circumstances, kidney biopsy will also be used to monitor response to treatment and identify early relapse. A transplant kidney biopsy may also be performed to look for rejection of the kidney.\nTreatment.\nTreatments in nephrology can include medications, blood products, surgical interventions (urology, vascular or surgical procedures), renal replacement therapy (dialysis or kidney transplantation) and plasma exchange. Kidney problems can have significant impact on quality and length of life, and so psychological support, health education and advanced care planning play key roles in nephrology.\nChronic kidney disease is typically managed with treatment of causative conditions (such as diabetes), avoidance of substances toxic to the kidneys (nephrotoxins like radiologic contrast and non-steroidal anti-inflammatory drugs), antihypertensives, diet and weight modification and planning for end-stage kidney failure. Impaired kidney function has systemic effects on the body. An erythropoetin stimulating agent (ESA) may be required to ensure adequate production of red blood cells, activated vitamin D supplements and phosphate binders may be required to counteract the effects of kidney failure on bone metabolism, and blood volume and electrolyte disturbance may need correction. Diuretics (such as furosemide) may be used to correct fluid overload, and alkalis (such as sodium bicarbonate) can be used to treat metabolic acidosis.\nAuto-immune and inflammatory kidney disease, such as vasculitis or transplant rejection, may be treated with immunosuppression. Commonly used agents are prednisone, mycophenolate, cyclophosphamide, ciclosporin, tacrolimus, everolimus, thymoglobulin and sirolimus. Newer, so-called \"biologic drugs\" or monoclonal antibodies, are also used in these conditions and include rituximab, basiliximab and eculizumab. Blood products including intravenous immunoglobulin and a process known as plasma exchange can also be employed.\nWhen the kidneys are no longer able to sustain the demands of the body, end-stage kidney failure is said to have occurred. Without renal replacement therapy, death from kidney failure will eventually result. Dialysis is an artificial method of replacing some kidney function to prolong life. Renal transplantation replaces kidney function by inserting into the body a healthier kidney from an organ donor and inducing immunologic tolerance of that organ with immunosuppression. At present, renal transplantation is the most effective treatment for end-stage kidney failure although its worldwide availability is limited by lack of availability of donor organs. Generally speaking, kidneys from living donors are 'better' than those from deceased donors, as they last longer.\nMost kidney conditions are chronic conditions and so long term followup with a nephrologist is usually necessary. In the United Kingdom, care may be shared with the patient's primary care physician, called a General Practitioner (GP).\nOrganizations.\nThe world's first society of nephrology was the French 'Societe de Pathologie Renale'. Its first president was Jean Hamburger, and its first meeting was in Paris in February 1949. In 1959, Hamburger also founded the 'Soci\u00e9t\u00e9 de N\u00e9phrologie', as a continuation of the older society. It is now called Francophone Society of Nephrology, Dialysis and Transplantation (SFNDT). The second society of nephrologists, the UK Kidney Association (UKKA) was founded in 1950, originally named the Renal Association. Its first president was Arthur Osman and met for the first time, in London, on 30 March 1950. The Societ\u00e0 di Nefrologia Italiana was founded in 1957 and was the first national society to incorporate the phrase nephrologia (or nephrology) into its name.\nThe word 'nephrology' appeared for the first time in a conference, on 1\u20134 September 1960 at the \"Premier Congr\u00e8s International de N\u00e9phrologie\" in Evian and Geneva, the first meeting of the International Society of Nephrology (ISN, International Society of Nephrology). The first day (1.9.60) was in Geneva and the next three (2\u20134.9.60) were in Evian, France. The early history of the ISN is described by Robinson and Richet in 2005 and the later history by Barsoum in 2011. The ISN is the largest global society representing medical professionals engaged in advancing kidney care worldwide. It has an international office in Brussels, Belgium.\nIn the US, founded in 1964, the National Kidney Foundation is a national organization representing patients and professionals who treat kidney diseases. Founded in 1966, the American Society of Nephrology (ASN) is the world's largest professional society devoted to the study of kidney disease. The American Nephrology Nurses' Association (ANNA), founded in 1969, promotes excellence in and appreciation of nephrology nursing to make a positive difference for patients with kidney disease. The American Association of Kidney Patients (AAKP) is a non-profit, patient-centric group focused on improving the health and well-being of CKD and dialysis patients. The National Renal Administrators Association (NRAA), founded in 1977, is a national organization that represents and supports the independent and community-based dialysis providers. The American Kidney Fund directly provides financial support to patients in need, as well as participating in health education and prevention efforts. ASDIN (American Society of Diagnostic and Interventional Nephrology) is the main organization of interventional nephrologists. Other organizations include CIDA, VASA etc. which deal with dialysis vascular access. The Renal Support Network (RSN) is a nonprofit, patient-focused, patient-run organization that provides non-medical services to those affected by chronic kidney disease (CKD).\nIn the United Kingdom, UK National Kidney Federation and Kidney Care UK (previously known as British Kidney Patient Association, BKPA) represent patients, and the UK Kidney Association used to represent renal physicians and worked closely with a previous NHS policy directive called a National Service Framework for kidney disease.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22029", "revid": "13467261", "url": "https://en.wikipedia.org/wiki?curid=22029", "title": "Nntp", "text": ""}
{"id": "22030", "revid": "218358", "url": "https://en.wikipedia.org/wiki?curid=22030", "title": "Newtonian physics", "text": ""}
{"id": "22031", "revid": "47812778", "url": "https://en.wikipedia.org/wiki?curid=22031", "title": "Native Esperanto speakers", "text": "People who have acquired Esperanto as one of their native languages\nNative Esperanto speakers (Esperanto: \"denaskuloj\" or \"denaskaj esperantistoj\" ) are people who have acquired Esperanto as one of their native languages. As of 1996, there were 350 or so attested cases of families with native Esperanto speakers. Estimates from associations indicate that there were around 1,000 Esperanto-speaking families, involving perhaps 2,000 children in 2004. In the majority of such families, the parents had the same native language, though in many the parents had different native languages, and only Esperanto in common.\nHistory.\nRaising children in Esperanto occurred early in the history of the language, notably with the five children of Montagu Butler (1884\u20131970). Owing to this, some families have passed Esperanto on to their children over several generations. Also notable are young Holocaust victim Petr Ginz, whose drawing of the planet Earth as viewed from the Moon was carried aboard the Space Shuttle \"Columbia\", and Daniel Bovet, the recipient of the 1957 Nobel Prize in Physiology or Medicine.\nIn at least one instance, Esperanto was used as a bridge language for a family started by a couple who did not have a native language in common.\nEsperanto is not the primary language of any geographic region, though it is spoken at events such as conventions like the World Congress of Esperanto and isolated offices, such as the World Esperanto Association's central office in Rotterdam. Consequently, native speakers have limited opportunity to meet one another except where meetings are specially arranged. For that reason, many parents consider it important to bring their children regularly to Esperanto conventions such as the annual \"Renkonti\u011do de Esperanto-familioj\" (or \"Esperantistaj familioj\"; REF, since 1979). Similarly, the annual Children's Congress of Esperanto happens alongside the largest Esperanto convention, the World Congress of Esperanto (\"Universala Kongreso\").\nList of noted native speakers.\nBelow is a list of noted native speakers of Esperanto. The billionaire George Soros has often appeared on such lists, but Humphrey Tonkin, the translator of Soros's father Tivadar's memoir \"Maskerado \u0109irka\u016d la morto\" into English (under the title \"Masquerade: The Incredible True Story of How George Soros\u2019 Father Outsmarted the Gestapo\"), has disputed this. He has made no statements either way concerning Soros's brother, Paul. \nGrammatical characteristics.\nThe Esperanto of native-speaking children differs from the standard Esperanto spoken by their parents. In some cases this is due to interference from their other native language (the adstrate), but in others it appears to be an effect of acquisition.\nBergen (2001) found the following patterns in a study of eight native-speaking children, aged 6 to 14, who were bilingual in Hebrew (two siblings), Slovak (two siblings), French, Swiss German, Russian, and Croatian.\n\"Malheli\u011das kaj ili ankora\u016d estas \u0109e la pla\u011do.\" \u2013 It's becoming dark and they are still on the beach.\n\"En la sepa, unu infano prenis lian \u015dtrumpo.\" (Standard: \"lian \u015dtrumpon\") \u2013 At seven o'clock, a child took his sock.\nbut\n\"Poste li iris kaj poste li prenis en unu mano lia simio.\" (Standard: \"lian simion\") \u2013 Then he went and then he took in one hand his monkey.\nAmong children that do use the accusative, its usage may be regularized from adult usage, at least at young ages. For example, when a screw dropped out of a lock, a young (\u2264 5-year-old) child said it \"malvenis la pordon.\" Besides the novel use of \"mal-\" with \"veni\" 'to come' to mean 'come away from', the accusative is not used in adult speech for motion away, but only motion towards. However, in this case the child generalized the usage of the accusative for direct objects.\nLindstedt, on the other hand, referencing Bergen's study, contends that \"it is difficult to find convincing examples of changes introduced by the process of nativisation. All examples proposed seem rather to be due to (1) transfers from the children\u2019s other native languages, (2) differences between the spoken and written register of Esperanto and, in some cases, (3) incomplete acquisition.\" Some of the features, such as phonological reduction, can be found in the speech of some fluent non-native speakers, while some other, such as the attrition of the accusative, are completely absent from the speech of some native-speaking children.\nWord derivation.\nNative-speaking children, especially at a young age, may coin words that do not exist in the speech of their parents, often for concepts for which Esperanto has a word they do not yet know, by exploiting the morphology of the language. This is analogous to what adult speakers do for concepts where Esperanto lacks a word, and indicates that some of the grammatical alterations that adult learners may find difficult come easily to native-speaking children. For example,\nThe prefix \"mal-\" is extremely productive, and children extend it beyond the usage they hear:\n\"malmiksi\" 'to separate' (\"miksi\" to mix)\n\"malpluvi\" 'to stop raining' (\"pluvi\" to rain)\n\"malscias\" 'is ignorant of' (\"scias\" knows)\n\"malnuna\" 'past' (\"nuna\" present)\n\"malfari\" 'to break (un-make)' (\"fari\" to make)\n\"maltie\" 'here' (\"tie\" there)\n\"malstartas\" 'turn off (an engine)' (\"startas\" 'starts', standard Esperanto \"\u015daltas\" 'switches on')\n\"mal\u011dustigis\" 'broke' (\"\u011dustigis\" repaired, made right)\n\"malsandvi\u0109i\u011dis\" 'became (a shape) which isn't a sandwich anymore' (\"sandvi\u0109-i\u011dis\" 'became a sandwich', of a brother playing with cushions)\n\"malstelita\" 'not surrounded by stars' (of the moon; from \"stelita\" 'starred')\n\"malmateno\" 'evening' (\"mateno\" morning)\n\"malio\" 'nothing' (\"io\" 'something'; standard Esperanto \"nenio\" 'nothing')\n\"malinterne\" 'externally' (\"interne\" internally)\n\"malgraveda\" 'no longer pregnant' (\"graveda\" pregnant)\n\"elektrujo\" 'a battery' (\"elektro\" electricity)\n\"ventrema\" 'fat' (tending to belly-ness, from \"ventro\" 'belly')\n\"triciklejo\" 'a place for tricycles'\n\"penisino\" 'vagina' (\"peniso\" penis)\n\"maltajpilo\" 'delete key' (\"maltajpi\" to delete, un-type, from \"tajpi\" to type)\n\"nazas\" 'rubs noses' (\"nazo\" nose)\n\"bu\u015das\" 'kisses on the mouth' (\"bu\u015do\" mouth)\n\"langeti\" 'to give a little lick' (diminutive, from \"lango\" tongue)\n\"dentumado\" 'activity with teeth' (\"dento\" tooth, \"-umi\" doing something undefined with, \"-ado\" noun of action)\n\"kuvi\" 'to have a bath' (\"kuvo\" 'tub'; standard Esperanto \"bani sin\" 'to bathe oneself')\n\"mukis\" '(my nose) was running' (\"muko\" 'snot', by analogy with \"sangis\" 'bled', from \"sango\" 'blood')\n\"literi\u011das\" 'the letters are changing' (middle voice, from \"litero\" 'letter (of the alphabet)')\n\"ne se\u011du sur la divano\" 'don't sit on the couch' (\"se\u011do\" 'chair'; standard Esperanto \"sidu\" 'sit')\n\"muzi\" 'to museum' (from \"muzeo\" 'museum', misunderstood as \"muz-ejo\" 'a place for museuming')\n\"belos\" 'will be beautiful' (\"bela\" 'beautiful'; found in poetry, but not usual in adult speech)\n\"samante kiel mi\" 'being the same as me (you ...)' (\"sama\" same)\n\"rida\" '(often) laughing' (\"ridi\" 'to laugh'; standard Esperanto \"ridema\")\n\"ventuma\" 'making a breeze' (from \"ventum-ilo\" 'a fan')\n\"perblove\" 'by blowing' (\"per\" 'via', \"blovi\" 'to blow')\n\"mi superruli\u011dos vin\" 'I will roll over you' (an intransitive verb ending in \"-i\u011dos\" won't normally take an object in the accusative case, but here it is necessary because the preposition \"super\" 'over' has been moved to the verb \"rul\" 'roll'. Without the suffix \"-i\u011dos\", however, the meaning would be a transitive 'I will roll you over'.)\n\"Ege halte, ege pa\u016dze, ege salte\" 'very stoppingly, very pausingly, very jumpily'\n\"Ene estas akve\" 'inside is wet' (\"akvo\" 'water'; standard Esperanto is \"malseke\", an adverb being required because no specific thing is wet.)\n\"ludeblo\" 'the possibility of playing' (\"ludi\" to play, \"-ebla\" -able)\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22033", "revid": "15815756", "url": "https://en.wikipedia.org/wiki?curid=22033", "title": "Nicaragua v. United States", "text": "1986 International Court of Justice legal case\nThe Case Concerning the Military and Paramilitary Activities in and Against Nicaragua (Nicaragua v. United States of America) (1986) was a case where the International Court of Justice (ICJ) held that the U.S. had violated international law by supporting the Contras in their rebellion against the Sandinistas and by mining Nicaragua's harbors. The case was decided in favor of Nicaragua and against the United States with the awarding of reparations to Nicaragua.\nThe Court had 15 final decisions upon which it voted. The Court found in its verdict that the United States was \"in breach of its obligations under customary international law not to use force against another State\", \"not to intervene in its affairs\", \"not to violate its sovereignty\", \"not to interrupt peaceful maritime commerce\", and \"in breach of its obligations under Article XIX of the Treaty of Friendship, Commerce and Navigation between the Parties signed at Managua on 21 January 1956.\" In Statement 9, the Court stated that while the U.S. encouraged human rights violations by the Contras by the manual entitled \"Psychological Operations in Guerrilla Warfare\", this did not make such acts attributable to the U.S.\nThe United States refused to participate in the proceedings, arguing that the ICJ lacked jurisdiction to hear the case. The U.S. also blocked enforcement of the judgment by the United Nations Security Council and thereby prevented Nicaragua from obtaining any compensation. Nicaragua, under the later, post-FSLN government of Violeta Chamorro, withdrew the complaint from the court in September 1992 following a repeal of the law which had required the country to seek compensation.\nBackground and history of US intervention in Nicaragua.\nThe first armed intervention by the United States in Nicaragua occurred under President Taft. In 1909, he ordered the overthrow of Nicaraguan President Jos\u00e9 Santos Zelaya. During August and September 1912, a contingent of 2,300 U.S. Marines landed at the port of Corinto and occupied Le\u00f3n and the railway line to Granada. A pro-U.S. government was formed under the occupation. The 1914 Bryan\u2013Chamorro Treaty granted perpetual canal rights to the U.S. in Nicaragua and was signed ten days before the U.S.-operated Panama Canal opened for use, thus preventing anyone from building a competing canal in Nicaragua without U.S. permission.\nIn 1927, under Augusto C\u00e9sar Sandino, a major peasant uprising was launched against both the U.S. occupation and the Nicaraguan establishment. In 1933, the Marines withdrew and left the Nicaraguan National Guard in charge of internal security and elections. In 1934, Anastasio Somoza Garc\u00eda, the head of the National Guard, ordered his forces to capture and murder Sandino. In 1937, Somoza assumed the presidency, while still in control of the National Guard, and established a dictatorship that his family controlled until 1979.\nThe downfall of the regime is attributed to its embezzlement of millions of dollars in foreign aid that was given to the country in response to the devastating 1972 earthquake. Many moderate supporters of the dictatorship began abandoning it in the face of growing revolutionary sentiment. The Sandinista (FSLN) movement organized relief, began to expand its influence and assumed the leadership of the revolution. A popular uprising brought the FSLN to power in 1979. The United States had long been opposed to the socialist FSLN, and after the revolution the Carter administration moved quickly to support the Somocistas with financial and material aid. When Ronald Reagan took office, he augmented the direct support to an anti-Sandinista group, called the Contras, which included factions loyal to the former dictatorship. When Congress prohibited further funding to the Contras, Oliver North continued the funding through arms sales that were also prohibited by Congress.\nNicaragua's submissions.\nNicaragua charged:\n(a) That the United States, in recruiting, training, arming, equipping, financing, supplying and otherwise encouraging, supporting, aiding, and directing military and paramilitary actions in and against Nicaragua, had violated its treaty obligations to Nicaragua under:\n Article 2 (4) of the United Nations Charter;\n Articles 18 and 20 of the Charter of the Organization of American States;\n Article 8 of the Convention on the Rights and Duties of States;\n Article I, Third, of the Convention concerning the Duties and Rights of States in the Event of Civil Strife.\n(b) That the United States had breached customary international law by\n1. violating the sovereignty of Nicaragua by:\n armed attacks against Nicaragua by air, land and sea;\n incursions into Nicaraguan territorial waters;\n aerial trespass into Nicaraguan airspace;\n efforts by direct and indirect means to coerce and intimidate the Government of Nicaragua.\n2. using force and the threat of force against Nicaragua.\n3. intervening in the internal affairs of Nicaragua.\n4. infringing upon the freedom of the high seas and interrupting peaceful maritime commerce.\n5. killing, wounding and kidnapping citizens of Nicaragua.\nNicaragua demanded that all such actions cease and that the United States had an obligation to pay reparations to the government for damage to their people, property, and economy.\nIt is noteworthy that the United States, the respondent party, was the only member that put forward arguments against the validity of the judgment of the court, arguing that it passed a decision that it \"had neither the jurisdiction nor the competence to render.\" Members that sided with the United States in opposing Nicaragua's claims did not challenge the court's jurisdiction, its findings, nor the substantive merits of the case.\nJudgment.\nThe lengthy judgment first listed 291 points, among them that the United States had been involved in the \"unlawful use of force\". The violations included attacks on Nicaraguan facilities and naval vessels, the mining of Nicaraguan ports, the invasion of Nicaraguan air space, and the training, arming, equipping, financing and supplying of forces (the \"Contras\") and seeking to overthrow Nicaragua's Sandinista government. This was followed by the statements that the judges voted on.\nFindings.\nThe court found evidence of an arms flow between Nicaragua and insurgents in El Salvador between 1979 and 1981. However, there was not enough evidence to show that the Nicaraguan government was imputable for this or that the US response was proportional. The court also found that certain transborder incursions into the territory of Guatemala and Costa Rica, in 1982, 1983 and 1984, were imputable to the Government of Nicaragua. However, neither Guatemala nor Costa Rica had made any request for US intervention; El Salvador did in 1984, well after the US had intervened unilaterally.http:// \n\"As regards El Salvador, the Court considers that in customary international law the provision of arms to the opposition in another State does not constitute an armed attack on that State. As regards Honduras and Costa Rica, the Court states that, in the absence of sufficient information as to the transborder incursions into the territory of those two States from Nicaragua, it is difficult to decide whether they amount, singly or collectively, to an armed attack by Nicaragua. The Court finds that neither these incursions nor the alleged supply of arms may be relied on as justifying the exercise of the right of collective self-defence.\"\nRegarding human rights violations by the Contras, \"The Court has to determine whether the relationship of the contras to the United States Government was such that it would be right to equate the Contras, for legal purposes, with an organ of the United States Government, or as acting on behalf of that Government. The Court considers that the evidence available to it is insufficient to demonstrate the total dependence of the Contras on United States aid. A partial dependency, the exact extent of which the Court cannot establish, may be inferred from the fact that the leaders were selected by the United States, and from other factors such as the organisation, training and equipping of the force, planning of operations, the choosing of targets and the operational support provided. There is no clear evidence that the United States actually exercised such a degree of control as to justify treating the contras as acting on its behalf... Having reached the above conclusion, the Court takes the view that the Contras remain responsible for their acts, in particular the alleged violations by them of humanitarian law. For the United States to be legally responsible, it would have to be proved that that State had effective control of the operations in the course of which the alleged violations were committed.\"\nThe Court concluded that the United States was subject to the Court's jurisdiction. The Court had ruled on November 26, 1984 by 11 votes to 1 that it had jurisdiction in the case on the basis of either Article 36 of the Statute of the International Court of Justice or the 1956 Treaty of Friendship, Commerce and Navigation between the United States and Nicaragua. The Charter provides that it is for the Court itself to decide whether it has jurisdiction, and that each member of the United Nations undertakes to comply with the decision of the Court. The Court also ruled by unanimity that the present case was admissible. The United States then announced that it had \"decided not to participate in further proceedings in this case.\" After the Court's jurisdictional decision, the United States withdrew its consent to the Court's compulsory jurisdiction, in part because Nicaragua had not accepted compulsory jurisdiction except for this case, and mostly because few nations ever had (and all who did accept compulsory jurisdiction did so with significant conditions and reservations). The Declaration of acceptance of compulsory jurisdiction of the International Court of Justice terminated after a 6-month notice of termination delivered by the Secretary of State to the United Nations on October 7, 1985.\nAlthough the Court called on the United States to \"cease and to refrain\" from the unlawful use of force against Nicaragua and stated that the US was \"in breach of its obligation under customary international law not to use force against another state\" and ordered it to pay reparations, the United States refused to comply. As a permanent member of the Security Council, the U.S. has been able to block any enforcement mechanism attempted by Nicaragua. On November 3, 1986 the United Nations General Assembly passed, by a vote of 94-3 (El Salvador, Israel and the US voted against), a non-binding resolution urging the US to comply.\nThe ruling.\nOn June 27, 1986, the Court made the following ruling:\nThe Court\nLegal clarification and importance.\nThe ruling did in many ways clarify issues surrounding prohibition of the use of force and the right of self-defence. Arming and training the Contra was found to be in breach with principles of non-intervention and prohibition of use of force, as was laying mines in Nicaraguan territorial waters.\nNicaragua's dealings with the armed opposition in El Salvador, although it might be considered a breach with the principle of non-intervention and the prohibition of use of force, did not constitute \"an armed attack\", which is the wording in article 51 justifying the right of self-defence.\nThe Court considered also the United States claim to be acting in collective self-defence of El Salvador and found the conditions for this not reached as El Salvador never requested the assistance of the United States on the grounds of self-defence.\nIn regards to laying mines, \"...the laying of mines in the waters of another State without any warning or notification is not only an unlawful act but also a breach of the principles of humanitarian law underlying the Hague Convention No. VIII of 1907.\"\nHow the judges voted.\nVotes of Judges \u2013 Nicaragua v. United States\nDissent.\nJudge Schwebel argued that the Sandinista government came to power with support of foreign intervention similar to what it was now complaining about. He argued that the Sandinista government achieved international recognition and received large amounts of foreign aid in exchange for commitments they subsequently violated. He cited evidence that the Sandinista government had supported the rebels in El Salvador and wrote that Nicaragua's own CIA witness contradicted their assertions that they had never at any point supported the rebels in El Salvador. The CIA witness said that there was no evidence of weapon shipments since early 1981, but Schwebel argued that he could not credibly explain why opponents of Contra aid such as Congressman Boland, who also saw the evidence, believed that weapon shipments were ongoing. He further wrote that Daniel Ortega publicly admitted such shipments in statements in 1985 and 1986. He said there was no dispute that the leadership of the rebels operated in Nicaragua from time to time.\nHe stated that in August 1981 the U.S. offered to resume aid to Nicaragua and to not support regime change in exchange for Nicaraguan commitments to not support the rebels in El Salvador. These proposals were rejected by the Sandinistas, and Schwebel argued that the U.S. was entitled to take action in collective self-defense with El Salvador by authorizing Contra aid in December 1981. He stated that further U.S. proposals to resolve the issue made in early 1982 were also ignored by the Sandinistas. The Sandinista government in 1983 began advancing proposals in which it would undertake not to support the rebels. Schwebel said that these were coupled with demands that the U.S. cease supporting the lawful government of El Salvador.\nHe wrote that since early 1985 the U.S. had increasingly made regime change a primary objective but that this was not inconsistent with self-defense because it was reasonable to believe that Nicaragua would not maintain any commitments unless Sandinista power was diluted.\nThe judge said that both sides of the wars in Nicaragua and El Salvador had committed atrocities. He said the U.S. mining of Nicaraguan harbors was unlawful in regard to third parties, but not Nicaragua.\nCertain witnesses against the US.\nFirst witness: Commander Luis Carri\u00f3n.\nThe first witness called by Nicaragua was Nicaragua's first Vice Minister of the Interior, Commander Luis Carrion. Commander Carrion had overall responsibility for state security and was in charge of all government operations in the \"principal war zone\". He was responsible for monitoring United States involvement in military and paramilitary activities against Nicaragua, directing Nicaragua's military and intelligence efforts against the contra guerrillas.\nCommander Carrion began by explaining the condition of the contras prior to United States' aid in December 1981. Commander Carrion stated that the contras consisted of insignificant bands of poorly armed and poorly organized members of Somoza's National Guard, who carried out uncoordinated border raids and rustled cattle (presumably for food).\nIn December 1981, the U.S. Congress authorized an initial appropriation of 19 million dollars to finance paramilitary operations in Nicaragua and elsewhere in Central America. Because of this aid, Commander Carrion stated that the contras began to become centralized and received both training and weapons from the CIA. During 1982 the contra guerrillas engaged the Sandinista armed forces in a series of hit and run border raids and carried out a number of sabotage operations including:\nThe United States Central Intelligence Agency, and Argentine military officers financed by the CIA, were engaged in the training of the contra forces. The guerrillas received both basic infantry training as well as training in specialized sabotage and demolition for \"special operation groups\".\nThe U.S. Congress apportioned new funds for the contras to the amount of $30 million at the end of 1982. This made it possible for the contra forces to launch a military offensive against Nicaragua. According to Commander Carrion, the offensive known as \"C Plan\" had the objective of capturing the Nicaraguan border town of Jalapa in order to install a provisional government, which could receive international recognition. This plan failed.\nAfter the failure of the Jalapa offensive the contras changed their tactics from frontal assaults to economic warfare against State farms, coffee plantations, grain storage centers, road junctions, etc.\nThe CIA began to support the contras by setting up and coordinating a communications and logistical system. The CIA supplied aircraft and the construction of airfields in the Honduran border area next to Nicaragua. This allowed the contras to carry out deep penetration raids into the more developed and populated areas of the Nicaraguan interior. U.S. Army engineers created this airfield. The purpose of these deep penetration attacks upon economic targets was to weaken the Nicaraguan economy, causing a shortages of goods.\nAs a part of its training program for the contras, the CIA prepared and distributed a manual entitled Psychological Operations in Guerrilla Warfare. This manual included instructions in the \"use of implicit and explicit terror\", and in the \"selective use of violence for propaganda effects\". Commander Carrion explained that the manual was given to the Contras, \"All of these terrorist instructions have the main purpose of alienating the population from the Government through creating a climate of terror and fear, so that nobody would dare support the Government\". The manual calls for the \"neutralization\" (i.e. assassination) of Sandinista local government officials, judges, etc. for purposes of intimidation. It was openly admitted by the President Reagan in a press conference that the manual had been prepared by a CIA contract employee.\nAfter the United States Congress approved an additional $24 million aid to the contras in December 1983, a new offensive was launched, named Plan Sierra. This offensive involved approximately 7000 members of the contra forces. As in earlier attacks, the initial objective of this offensive was to capture the border town of Jalapa to install a provisional government, which the CIA informed the contras would be immediately recognized by the United States Government. But this contra offensive was also repulsed by the Nicaraguan government forces.\nIn the beginning of 1984, the contras made a major effort to prevent the harvesting of the coffee crop, which is one of Nicaragua's most important export products. Coffee plantations and state farms where coffee is grown were attacked, vehicles were destroyed, and coffee farmers were killed.\nCommander Carrion testified that the ability of the contras to carry out military operations was completely dependent upon United States funding, training and logistical support. Carrion stated that the U.S. Government supplied the contras with uniforms, weapons, communications equipment, intelligence, training, and coordination in using this material aid.\nIn September 1983, CIA operatives blew up Nicaragua's only oil pipeline, which was used to transport oil from off-loading facilities to storage tanks on shore. The United States was also directly involved in a large scale sabotage operation directed against Nicaragua's oil storage facilities. This last attack was carried out by CIA contract employees termed by that organization as \"Unilaterally Controlled Latin Assets\" (UCLAs). The CIA personnel were also directly involved in a helicopter attack on a Nicaraguan army training camp. One of the helicopters was shot down by Nicaraguan ground fire resulting in the death of two U.S. citizens.\nCommander Carrion testified that the United States was involved in the mining of Nicaragua's ports between February \u2013 April 1984. The mining operation was carried out by CIA ships directing the operation from international waters, while the actual mining was carried out by CIA employees on board speedboats operating inshore. After the mine-laying was completed the speedboats returned to the mother vessel.\nCarrion stated that 3,886 people had been killed and 4,731 wounded in the four years since the contras began their attacks. Carrion estimated property damage at $375 million.\nCommander Carrion stated if the United States stopped aid, support and training, this would result in the end of the contras military activities within three months. Asked why he was so sure of this, Commander Carrion answered, \"Well, because the contras are an artificial force, artificially set up by the United States, that exists only because it counts on United States direction, on United States training, on United States assistance, on United States weapons, on United States everything...Without that kind of support and direction the contras would simply disband, disorganize, and thus lose their military capacity in a very short time\".\nSecond witness: Dr. David MacMichael.\nDavid MacMichael was an expert on counter-insurgency, guerrilla warfare, and Latin American affairs, he was also a witness because he was closely involved with U.S. intelligence activities as a contract employee from March 1981 \u2013 April 1983. MacMichael worked for Stanford Research Institute, which was contracted by the U.S. Department of Defense. After this he worked two years for the CIA as a \"senior estimates officer\", preparing the National Intelligence Estimate. Dr. MacMichael's responsibility was centered upon Central America. He had top-secret clearance. He was qualified and authorized to have access to all relevant U.S. intelligence concerning Central America, including intelligence relating to alleged Nicaraguan support for, and arms shipments to the anti-Government insurgents in El Salvador. He took part in high level meetings of the Latin American affairs office of the CIA. Including a fall 1981 meeting, which submitted the initial plan to set up a 1500-man covert force on the Nicaraguan border, shipping arms from Nicaragua to the El Salvador insurgents. This plan was approved by President Reagan.\n\"The overall purpose (for the creation of the contras) was to weaken, even destabilize the Nicaraguan Government and thus reduce the menace it allegedly posed to the United States' interests in Central America...\"\nContra paramilitary actions would \"hopefully provoke cross-border attacks by Nicaraguan forces and thus serve to demonstrate Nicaragua's aggressive nature and possibly call into play the Organization of American States' provisions (regarding collective self-defense). It was hoped that the Nicaraguan Government would clamp down on civil liberties within Nicaragua itself, arresting its opposition, so demonstrating its allegedly inherent totalitarian nature and thus increase domestic dissent within the country, and further that there would be reaction against United States citizens, particularly against United States diplomatic personnel within Nicaragua and thus to demonstrate the hostility of Nicaragua towards the United States\".\n In response to repeated questions as to whether there was any substantial evidence of the supply of weapons to the guerrilla movement in El Salvador- either directly by the Nicaraguan Government itself-or with the knowledge, approval or authorization of the Nicaraguan Government of either non-official Nicaraguan sources, or by third country nationals inside or outside Nicaragua, using Nicaraguan territory for this purpose, Dr. MacMichael answered that there was no such evidence. In the opinion of the witness it would not have been possible for Nicaragua to send arms to the insurgents in El Salvador in significant amounts (as alleged by the U.S. Government) and over a prolonged period, without this being detected by the U.S. intelligence network in the area...Counsel for Nicaragua, asked the witness several times whether any detection of arms shipments by or through Nicaragua had taken place during the period he was employed by the CIA. (MacMichael) answered repeatedly that there was no such evidence. He also stated that after his employment had terminated, nothing had occurred that would cause him to change his opinion. He termed the evidence that had been publicly disclosed by the U.S. Government concerning Nicaraguan arms deliveries to the El Salvadoran insurgents as both \"scanty\" and \"unreliable\". The witness did however state that based on evidence, which had been gathered immediately prior to his employment with the CIA, evidence he had already actually seen, there was substantial evidence that arms shipments were reaching El Salvador from Nicaragua \u2013 with the probable involvement and complicity of the Nicaraguan Government \u2013 through late 1980 up until the spring of 1981...But this evidence, which most importantly had included actual seizures of weapons, which could be traced to Nicaragua, as well as documentary evidence and other sources, had completely ceased by early 1981. Since then, no evidence linking Nicaragua to shipments of arms in any substantial quantities had resumed coming in. \nThird witness: Professor Michael Glennon.\nMr. Glennon testified about a fact-finding mission he had conducted in Nicaragua to investigate alleged human rights violations committed by the Contra guerrillas, sponsored by the International Human Rights Law Group, and the Washington Office on Latin America. Glennon conducted the investigation with Mr. Donald T. Fox who is a New York attorney and a member of the International Commission of Jurists.\nThey traveled to Nicaragua, visiting the northern region where the majority of contra military operations took place. The two lawyers interviewed around 36 northern frontier residents who had direct experience with the contras. They also spoke with the U.S. Ambassador to Nicaragua, and with senior officials of the U.S. Department of State in Washington after returning to the United States.\nNo hearsay evidence was accepted. Professor Glennon stated that those interviewed were closely questioned, and their evidence was carefully cross-checked with available documentary evidence. Doubtful \"testimonies\" were rejected, and the results were published in April 1985.\nThe conclusions of the report were summarized by Glennon in Court:\nWe found that there is substantial credible evidence that the contras were engaged with some frequency in acts of terroristic violence directed at Nicaraguan civilians. These are individuals who have no connection with the war effort-persons with no economic, political or military significance. These are Individuals who are not caught in the cross-fire between Government and contra forces, but rather individuals who are deliberately targeted by the contras for acts of terror. \"Terror\" was used in the same sense as in recently enacted United States law, i.e. \"an activity that involves a violent act or an act dangerous to human life that Is a violation or the criminal law, and appears to be intended to intimidate or coerce a civilian population, to Influence the policy of a government by intimidation or coercion, or to affect the conduct of a government by assassination or kidnapping.\nIn talks with U.S. State Department officials, at those in Managua U.S. Embassy, and with officials in Washington, Professor Glennon had inquired whether the U.S. Government had ever investigated human rights abuses by the contras. Professor Glennon testified that no such investigation had ever been conducted, because in the words of a ranking State Department official who he could not name, the U.S. Government maintained a policy of \"intentional ignorance\" on the matter. State Department officials in Washington- had admitted to Glennon that \"it was clear that the level of atrocities was enormous\". Those words \"enormous\" and \"atrocities\" were the ranking State Department official's words.\nFourth witness: Father Jean Loison.\nFather Jean Loison was a French priest who worked as a nurse in a hospital in the northern frontier region close to Honduras.\nAsked whether the contras engaged in acts of violence directed against the civilian population, Father Loison answered:\nYes, I could give you several examples. Near Quilali, at about 30 kilometers east of Quilali, there was a little village called El Coco. The contras arrived, they devastated it, they destroyed and burned everything. They arrived in front of a little house and turned their machinegun fire on it, without bothering to check if there were any people inside. Two children, who had taken fright and hidden under a bed, were hit. I could say the same thing of a man and woman who were hit, this was in the little co-operative of Sacadias Olivas. It was just the same. They too had taken fright and got into bed. Unlike El Coco, the contras had just been on the attack, they had encountered resistance and were now in flight. During their flight they went into a house, and seeing that there were people there, they threw grenade. The man and the woman were killed and one of the children was injured.\nAbout contra kidnappings:\nI would say that kidnappings are one of the reasons why some of the peasants have formed themselves into groups. Here (indicates a point on the map) is Quilali. Between Quilali and Uilili, in this region to the north, there are hardly any peasants left of any age to bear arms, because they have all been carried off.\nFather Loison described many examples of violence, mostly indiscriminate, directed at the civilian population in the region where he resides. The picture that emerges from his testimony is that the contras engage in brutal violation of minimum standards of humanity. He described murders of unarmed civilians, including women and children, rape followed in many instances by torture or murder, and indiscriminate terror designed to coerce the civilian population. His testimony was similar to various reports including the International Human Rights Law Group, Amnesty International, and others.\nFifth witness: William H\u00fcper.\nWilliam H\u00fcper was Nicaragua's Minister of Finance. He testified about Nicaragua economic damage, including the loss of fuel as a result of the attack in the oil storage facilities at Corinto, the damage to Nicaragua's commerce as a result of the mining of its ports, and other economic damage.\nUN voting.\nAfter five vetoes in the Security Council between 1982 and 1985 of resolutions concerning the situation in Nicaragua, the United States made one final veto on 28 October 1986 (France, Thailand, and United Kingdom abstaining) of a resolution calling for full and immediate compliance with the judgment.\nNicaragua brought the matter to the U.N. Security Council, where the United States vetoed a resolution (11 to 1, 3 abstentions) calling on all states to observe international law. Nicaragua also turned to the General Assembly, which passed a resolution 94 to 3 calling for compliance with the World Court ruling. Two states, Israel and El Salvador, joined the United States in opposition. At that time, El Salvador was receiving substantial funding and military advice from the U.S., which was aiming to crush a Sandinista-like revolutionary movement by the FMLN. At the same session, Nicaragua called upon the U.N. to send an independent fact-finding mission to the border to secure international monitoring of the borders after a conflict there; the proposal was rejected by Honduras with U.S. backing. A year later, on November 12, 1987, the General Assembly again called for \"full and immediate compliance\" with the World Court decision. This time only Israel joined the United States in opposing adherence to the ruling.\nIn both 2023 and 2024, Nicaragua sent a letter to the United Nations still arguing for the obligation of the United States to compensate Nicaragua for the reparations from the 1986 ICJ court ruling.\nU.S. defense and response.\nThe United States refused to participate in the merits phase of the proceedings, but the Court found that the US refusal did not prevent it from deciding the case. The Court also rejected the United States defense that its action constituted collective self-defense.\nThe United States argued that the Court did not have jurisdiction, with U.S. ambassador to the United Nations Jeane Kirkpatrick dismissing the Court as a \"semi-legal, semi-juridical, semi-political body, which nations sometimes accept and sometimes don't.\"\nThe United States had signed the treaty accepting the Court's decision as binding, but with the exception that the court would not have the power to hear cases based on multilateral treaty obligations unless it involved all parties to the treaty affected by that decision or the United States specially agreed to jurisdiction. The court found that it was obliged to apply this exception and refused to take on claims by Nicaragua based on the United Nations Charter and Organization of American States charter, but concluded that it could still decide the case based on customary international law obligations with 11-4 majority.\nWhen a similar but crucially non-binding resolution was brought before the United Nations General Assembly on 3 November it was passed. Only El Salvador and Israel voted with the U.S. against it. El Salvador's ruling junta was at that time receiving substantial funding and military advisement from the U.S., which was aiming to crush a Sandinista-like revolutionary movement by the FMLN. In spite of this resolution, the U.S. still chose not to pay the fine.\nIn response to the ICJ's decision that US aid to the contra rebels violated international law, US State Department lawyer, Abraham Sofaer, said that the US would no longer recognize the ICJ's 'compulsory jurisdiction' authority. Sofaer said \"We felt the Nicaragua case was an unfortunate signal to us that we should be concerned about our security interests and about the use of the court for political-public relations purposes. . . . The President does not want the court used for those purposes--at the same time, he and others in this Administration want to continue to use the court for its intended purposes\". Paul Reichler, one of the lawyers representing Nicaragua in the case, said: \"It's another indication that this Administration has no regard for international law--when international law conflicts with a foreign policy objective of the Administration, they will throw international law into the waste basket\".\nSignificance.\nThird-party interpretations.\nProfessor of International Law, Anthony D'Amato, writing for the \"American Journal of International Law\" (Vol. 80, 1986), commented on this case, stating that \"law would collapse if defendants could only be sued when they agreed to be sued, and the proper measurement of that collapse would be not just the drastically diminished number of cases but also the necessary restructuring of a vast system of legal transactions and relations predicated on the availability of courts as a last resort. There would be talk of a return to the law of the jungle.\" The author also notes that the case resulted in an unusual candor. A month after the announced withdrawal, Secretary of State Shultz suggested, and President Reagan later confirmed in a press conference, that the goal of U.S. policy was to overthrow the Sandinista Government of Nicaragua. Although this was what Nicaragua had alleged to be the U.S. goal, while the case was actively pending, the United States could not concede that goal without serious risk of undermining its litigating position.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "22034", "revid": "45212325", "url": "https://en.wikipedia.org/wiki?curid=22034", "title": "Naturalistic planned language", "text": "A naturalistic planned language is an \"a posteriori\" constructed language specifically devised to reproduce the commonalities in morphology and vocabulary from a group of closely related languages, usually with the idea that such a language will be easier to use passively \u2013 in many cases, without prior study \u2013 by speakers of one or more languages in the group.\nThe term most commonly applies to planned languages that are predominantly based on the Romance languages, best known of which are Interlingue (previously known as \"Occidental\") and Interlingua. Both were designed to serve as international auxiliary languages. However, there are also languages intended for speakers of a particular language family (zonal constructed languages), including Pan-Romance, Pan-Germanic and Pan-Slavic naturalistic planned languages.\nSince the creation of such a language includes shared idiosyncrasies from the source languages, active use seems to be generally more difficult to learn than for schematic planned languages, though because of grammatical simplification considerably easier than for ethnic languages of the same type. \nAccording to Willem Anthony Veeloren Van Themaat, proponents of naturalistic planned languages argue that naturalistic planned languages are capable of being used as instruments of culture but schematic planned languages are not. The justification for this reasoning, he argues, is that naturalistic planned languages are able to carry the culture from their source languages while schematic planned languages are \"purely rational, without cultural value, unable to express feeling\" and \"unsuitable for literature.\" "}
{"id": "22035", "revid": "43646533", "url": "https://en.wikipedia.org/wiki?curid=22035", "title": "No-cloning theorem", "text": "Theorem in quantum information science\nIn physics, the no-cloning theorem states that it is impossible to create an independent and identical copy of an arbitrary unknown quantum state, a statement which has profound implications in the field of quantum computing among others. The theorem is an evolution of the 1970 no-go theorem authored by James L. Park, in which he demonstrates that a non-disturbing measurement scheme which is both simple and perfect cannot exist (the same result would be independently derived in 1982 by William Wootters and Wojciech H. Zurek as well as Dennis Dieks the same year). The aforementioned theorems do not preclude the state of one system becoming entangled with the state of another as cloning specifically refers to the creation of a separable state with identical factors. For example, one might use the controlled NOT gate and the Walsh\u2013Hadamard gate to entangle two qubits without violating the no-cloning theorem as no well-defined state may be defined in terms of a subsystem of an entangled state. The no-cloning theorem (as generally understood) concerns only pure states whereas the generalized statement regarding mixed states is known as the no-broadcast theorem. The no-cloning theorem has a time-reversed dual, the no-deleting theorem.\nHistory.\nAccording to Asher Peres and David Kaiser, the publication of the 1982 proof of the no-cloning theorem by Wootters and Zurek and by Dieks was prompted by a proposal of Nick Herbert for a superluminal communication device using quantum entanglement, and Giancarlo Ghirardi had proven the theorem 18 months prior to the published proof by Wootters and Zurek in his referee report to said proposal (as evidenced by a letter from the editor). However, Juan Ortigoso pointed out in 2018 that a complete proof along with an interpretation in terms of the lack of simple nondisturbing measurements in quantum mechanics was already delivered by Park in 1970.\nTheorem and proof.\nSuppose we have two quantum systems \"A\" and \"B\" with a common Hilbert space formula_1. Suppose we want to have a procedure to copy the state formula_2 of quantum system \"A\", over the state formula_3 of quantum system \"B,\" for any original state formula_2 (see bra\u2013ket notation). That is, beginning with the state formula_5, we want to end up with the state formula_6. To make a \"copy\" of the state \"A\", we combine it with system \"B\" in some unknown initial, or blank, state formula_3 independent of formula_2, of which we have no prior knowledge.\nThe state of the initial composite system is then described by the following tensor product:\nformula_9\n(in the following we will omit the formula_10 symbol and keep it implicit).\nThere are only two permissible quantum operations with which we may manipulate the composite system:\nThe no-cloning theorem answers the following question in the negative: Is it possible to construct a unitary operator \"U\", acting on formula_13, under which the state the system B is in always evolves into the state the system A is in, \"regardless\" of the state system A is in?\n&lt;templatestyles src=\"Math_theorem/styles.css\" /&gt;\n\\phi \\rangle_A&lt;/math&gt; and &lt;math&gt;\u2014There is no unitary operator \"U\" on formula_12 such that for all normalised states &lt;math&gt;\nThe extra phase factor expresses the fact that a quantum-mechanical state defines a normalised vector in Hilbert space only up to a phase factor i.e. as an element of projectivised Hilbert space.\nTo prove the theorem, we select an arbitrary pair of states formula_2 and formula_16 in the Hilbert space formula_17. Because \"U\" is supposed to be unitary, we would have\nformula_18\nSince the quantum state formula_19 is assumed to be normalized, we thus get\nformula_20\nThis implies that either formula_21 or formula_22. Hence by the Cauchy\u2013Schwarz inequality either formula_23 or formula_24 is orthogonal to formula_25. However, this cannot be the case for two \"arbitrary\" states. Therefore, a single universal \"U\" cannot clone a \"general\" quantum state. This proves the no-cloning theorem.\nTake a qubit for example. It can be represented by two complex numbers, called probability amplitudes (normalised to 1), that is three real numbers (two polar angles and one radius). Copying three numbers on a classical computer using any copy and paste operation is trivial (up to a finite precision) but the problem manifests if the qubit is unitarily transformed (e.g. by the Hadamard quantum gate) to be polarised (which unitary transformation is a surjective isometry). In such a case the qubit can be represented by just two real numbers (one polar angle and one radius equal to 1), while the value of the third can be arbitrary in such a representation. Yet a realisation of a qubit (polarisation-encoded photon, for example) is capable of storing the whole qubit information support within its \"structure\". Thus no single universal unitary evolution \"U\" can clone an arbitrary quantum state according to the no-cloning theorem. It would have to depend on the transformed qubit (initial) state and thus would not have been \"universal\".\nGeneralization.\nIn the statement of the theorem, two assumptions were made: the state to be copied is a pure state and the proposed copier acts via unitary time evolution. These assumptions cause no loss of generality. If the state to be copied is a mixed state, it can be \"purified,\" i.e. treated as a pure state of a larger system. Alternately, a different proof can be given that works directly with mixed states; in this case, the theorem is often known as the no-broadcast theorem. Similarly, an arbitrary quantum operation can be implemented via introducing an ancilla and performing a suitable unitary evolution. Thus the no-cloning theorem holds in full generality.\nImperfect cloning.\nEven though it is impossible to make perfect copies of an unknown quantum state, it is possible to produce imperfect copies. This can be done by coupling a larger auxiliary system to the system that is to be cloned, and applying a unitary transformation to the combined system. If the unitary transformation is chosen correctly, several components of the combined system will evolve into approximate copies of the original system. In 1996, V. Buzek and M. Hillery showed that a universal cloning machine can make a clone of an unknown state with the surprisingly high fidelity of 5/6.\nImperfect quantum cloning can be used as an eavesdropping attack on quantum cryptography protocols, among other uses in quantum information science.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;"}
{"id": "22036", "revid": "8372814", "url": "https://en.wikipedia.org/wiki?curid=22036", "title": "Norman Hackerman", "text": "American chemist, professor, and university President (1912\u20132007)\nNorman Hackerman (March 2, 1912 \u2013 June 16, 2007) was an American chemist, professor, and academic administrator who served as the 18th President of the University of Texas at Austin (1967\u20131970) and later as the 4th President of Rice University (1970\u20131985). He was an internationally known expert in metal corrosion.\nBiography.\nBorn in Baltimore, Maryland, he was the only son of Jacob Hackerman and Anna Raffel, immigrants from the Baltic regions of the Russian Empire that later became Estonia and Latvia, respectively.\nHackerman earned his bachelor's degree in 1932 and his doctor's degree in chemistry in 1935 from Johns Hopkins University. He taught at Johns Hopkins, Loyola College in Baltimore and the Virginia Polytechnic Institute and State University in Blacksburg, Virginia, before working on the Manhattan Project in World War II.\nHe joined the University of Texas in 1945 as an assistant professor of chemistry, became an associate professor in 1946, a full professor in 1950, a department chair in 1952, dean of research in 1960, vice president and provost in 1961, and vice chancellor for academic affairs for the University of Texas System in 1963. Hackerman left the University of Texas in 1970 for Rice, where he retired 15 years later. He was named professor emeritus of chemistry at the University of Texas in 1985 and taught classes until the end of his life.\nHe was a member of the National Academy of Sciences, the American Philosophical Society, and the American Academy of Arts and Sciences. Among his many honors are the Olin Palladium Award of the Electrochemical Society, the Gold Medal of the American Institute of Chemists (1978), the Charles Lathrop Parsons Award, the Vannevar Bush Award and the National Medal of Science. He was awarded the Acheson Award by the Electrochemical Society in 1984.\nHackerman served on advisory committees and boards of several technical societies and government agencies, including the National Science Board, the Texas Governor's Task Force on Higher Education and the Scientific Advisory Board of the Welch Foundation. He also served as editor of the \"Journal of the Electrochemical Society\" and as president of the Electrochemical Society.\nFamily.\nHackerman's wife of 61 years, Gene Coulbourn, died in 2002; they had three daughters and one son.\nLegacy.\nIn 1982 The Electrochemical Society created the https:// to honor the best paper published in the Journal of the Electrochemical Society for a topic in the field of electrochemical science and technology by a young author or authors. In 2000 the Welch Foundation created the Norman Hackerman Award in Chemical Research to recognize the work of young researchers in Texas. The Rice Board of Trustees established the Norman Hackerman Fellowship in Chemistry in honor of Hackerman's 90th birthday in 2002. In 2008, the original Experimental Science Building at the University of Texas at Austin campus was demolished and rebuilt as the Norman Hackerman Experimental Science Building in his name and honor. The building was completed in late 2010, with the opening and dedication ceremony on March 2, 2011, which was both Hackerman's 99th Birthday and the 175th Anniversary of Texas Independence. The main building at the J. Erik Jonsson Center of the National Academy of Sciences is Hackerman House, named in his honor. Hackerman House overlooks Quissett Harbor in Woods Hole MA, on Cape Cod."}
{"id": "22037", "revid": "1255061639", "url": "https://en.wikipedia.org/wiki?curid=22037", "title": "N-ray", "text": "Hypothetical form of radiation\n \nN-rays (or N rays) were a hypothesized form of radiation described by Prosper-Ren\u00e9 Blondlot in 1903. They were initially confirmed by others, but subsequently found to be illusory.\nBackground.\nThe N-ray affair occurred shortly after a series of major breakthroughs in experimental physics. Victor Schumann discovered vacuum ultraviolet radiation in 1893, Wilhelm R\u00f6ntgen discovered X-rays in 1895, Henri Becquerel discovered radioactivity in 1896, and, in 1897, J.\u00a0J. Thomson discovered electrons, showing that they were the constituents of cathode rays. This created an expectation within the scientific community that other forms of radiation might be discovered.\nAt this time, Prosper-Ren\u00e9 Blondlot was a professor of physics at the University of Nancy studying electromagnetic radiation. Blondlot was a respected member of the scientific community: he was one of eight physicists who were corresponding members of the French Academy of Sciences and was awarded the Academy's Gaston Plant\u00e9 prize in 1893 and the LaCaze prize in 1899. His attempts to measure the speed of electromagnetic waves were commended by Thomson and Henri Poincar\u00e9. Blondlot began investigating the nature of X-rays shortly after their discovery, trying to determine whether they behaved as particles or electromagnetic waves. (This was before wave-particle duality became widely accepted among scientists.)\nDiscovery.\nIn 1903, Blondlot announced his discovery while working at the University of Nancy and attempting to polarize X-rays. He had perceived changes in the brightness of an electric spark in a spark gap placed in an X-ray beam which he photographed, and he later attributed to the novel form of radiation, naming this the \"N-rays\" for the University of Nancy. Blondlot, Augustin Charpentier, Ars\u00e8ne d'Arsonval, and approximately 120 other scientists in 300 published articles claimed to be able to detect N-rays emanating from most substances, including the human body, with the peculiar exceptions that they were not emitted by green wood and by some treated metals. Most researchers of the subject at the time used the perceived light of a dim phosphorescent surface as \"detectors\", although work in the period clearly showed the change in brightness to be a physiological phenomenon rather than some actual change in the level of illumination. Physicists Gustave le Bon and P. Audollet and spiritualist Carl Huter even claimed the discovery as their own, leading to a commission of the Acad\u00e9mie des sciences to decide priority.\nResponse.\nThe \"discovery\" excited international interest and many physicists worked to replicate the effects. However, the notable physicists Lord Kelvin, William Crookes, Otto Lummer, and Heinrich Rubens failed to do so. Following his own failure, self-described as \"wasting a whole morning\", the American physicist Robert W. Wood, who had a reputation as a popular \"debunker\" of nonsense during the period, was prevailed upon by the British journal \"Nature\" to travel to Blondlot's laboratory in France to investigate further. Wood suggested that Rubens should go since he had been the most embarrassed when Kaiser Wilhelm II of Germany asked him to repeat the French experiments and, after two weeks, Rubens had to report his failure to do so. Rubens, however, felt it would look better if Wood went since Blondlot had been most polite in answering his many questions.\nIn the darkened room during Blondlot's demonstration, Wood surreptitiously removed an essential prism from the experimental apparatus, yet the experimenters still said that they observed N-rays. Wood also stealthily swapped a large file that was supposed to be giving off N-rays with an inert piece of wood, yet the N-rays were still \"observed\". His report on these investigations were published in \"Nature\",\nand they suggested that the N-rays were a purely subjective phenomenon, with the scientists involved having recorded data that matched their expectations. There is reason to believe that Blondlot in particular was misled by his laboratory assistant, who confirmed all observations. By 1905, no one outside of Nancy believed in N-rays, but Blondlot himself is reported to have still been convinced of their existence in 1926. Martin Gardner, making reference to Wood's biographer William Seabrook's account of the affair, attributed a subsequent decline in mental health and eventual death of Blondlot to the resulting scandal, but there is evidence that this is at least some exaggeration of the facts.\nThe term \"N-ray\" was added to dictionaries upon its announcement and was described as a real phenomenon until at least the 1940s. For instance, the 1946 Webster's Dictionary defined it as \"An emanation or radiation from certain hot bodies which increases the luminosity without increasing the temperature: as yet, not fully determined.\"\nSignificance.\nThe incident is used as a cautionary tale among scientists on the dangers of error introduced by experimenter bias. N-rays were cited as an example of pathological science by Irving Langmuir. Nearly identical properties of an equally unknown radiation had been recorded about 50 years before in another country by Carl Reichenbach in his treatise \"Researches on Magnetism, Electricity, Heat, Light, Crystallization, and Chemical Attraction in their relations to the Vital Force\" in 1850, and before that in Vienna by Franz Mesmer in his \"M\u00e9moire on the Discovery of Animal-Magnetism\" in 1779. It is clear that Reichenbach was aware of Mesmer's work and that researchers in Paris working with Blondlot were aware of Reichenbach's work, although there is no proof that Blondlot was personally aware of it.\nA park in central Nancy is named after Blondlot. He left his house and garden to the city, which transformed it into a public park. James Randi reported that many citizens of Nancy and members of the faculty at the university did not remember having heard about N-rays or of Blondlot.\nIn the 2018 book \"The Skeptics' Guide to the Universe\", the section titled \"Iconic Cautionary Tales from History\" recounts the story of the \"discovery\" of N-rays. A review of the book in \"Skeptical Inquirer\" reported that the book uses the N-rays incident to reveal the danger of \"scientists insufficiently applying skepticism\", because \"Three hundred scientific papers were published by one hundred experimenters over three years, all declaring this imaginary phenomenon to be real.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22038", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=22038", "title": "N-rays", "text": ""}
{"id": "22039", "revid": "1312054389", "url": "https://en.wikipedia.org/wiki?curid=22039", "title": "Nikolai Kuznetsov (admiral)", "text": "Soviet naval officer (1904\u20131974)\nNikolai Gerasimovich Kuznetsov (; 24 July 1904 \u2013 6 December 1974) was a Soviet naval officer who achieved the rank of Admiral of the Fleet of the Soviet Union and served as People's Commissar of the Navy during the Winter War and the Second World War. The N. G. Kuznetsov Naval Academy and the Russian aircraft carrier , as well as the Kuznetsov-class carrier class, are named in his honor.\nBiography.\nEarly years and career.\nKuznetsov was born in a peasant family of Serbian paternal ancestry in the village of Medvedki, Velikoustyuzhsky Uyezd, Vologda Governorate, Russian Empire (now in Kotlassky District of Arkhangelsk Oblast, Russia).\nIn 1919, Kuznetsov joined the Northern Dvina Naval Flotilla, having added two years to his age to make himself eligible to serve. In 1920, he was stationed at Petrograd and in 1924, as a member of a naval unit, he attended the funeral ceremony of Vladimir Lenin.\nThat same year, he joined the Communist Party.\nUpon graduation from the Frunze Higher Naval School in 1926, Kuznetsov served on the cruiser , first as watch officer and then as First Lieutenant. In 1932, he graduated from the Naval College after studying operational tactics. Upon graduation, he was offered two options \u2013 a desk job with the general staff or a command post on a ship.\nKuznetsov successfully applied for the post of executive officer on the cruiser . Within a year, the young officer earned his next promotion. In 1934, he returned to the \"Chervona Ukraina\", this time as her commander. Under Kuznetsov, the ship became an outstanding example of discipline and organization, quickly drawing attention to her young captain.\nFrom 5 September 1936 to 15 August 1937, Kuznetsov served as the Soviet naval attach\u00e9 and chief naval advisor to Republican Spain. During the early stages of the Spanish Civil War of 1936-1939 he developed a strong dislike of fascism.\nOn returning home, on January 10, 1938, he was promoted to the rank of flag officer, 2nd rank, and given command of the Pacific Fleet. While in this position, he came face to face with Stalin's purge of the military. Kuznetsov himself was never implicated, but many of the officers under his command were. Kuznetsov resisted the purges at every step, and his intervention saved the lives of many Soviet officers.\nOn 28 April 1939, Kuznetsov, still only thirty-four, was appointed the People's Commissar (Minister) of the Navy, a post he would hold throughout the Second World War until 1946. In 1939, despite Stalin's negative attitude to the Nikolaevsky Engineering Academy, Nikolay Gerasimovich Kuznetsov ordered the return of the Naval Engineering faculty from Moscow to Leningrad, and set up the Military Engineering-Technical University to educate engineers for the construction of naval bases.\nThe Second World War.\nKuznetsov played a crucial role during the first hours of the war \u2013 at this pivotal moment, his resolve and blatant disregard for orders averted the destruction of the Soviet Navy. By June 21, 1941, Kuznetzov was convinced of the inevitability of war with Nazi Germany. On the same day Semyon Timoshenko and Georgy Zhukov issued a directive prohibiting Soviet commanders from responding to \"German provocations\". The Navy, however, constituted a distinct ministry (narkomat), and thus Kuznetsov held a position which was technically outside the direct chain of command. He utilized this fact in a very bold move.\nShortly after midnight on the morning of June 22, Kuznetsov ordered all Soviet fleets to battle readiness. At 3:15 am that same morning, the Wehrmacht began Operation Barbarossa. The Soviet Navy was the only branch of the military in the highest state of combat readiness at the start of the initial German push.\nIn the following two years, Kuznetsov's primary concern was the protection of the Caucasus from a German invasion. Throughout the war, the Black Sea remained the primary theater of operations for the Soviet Navy. During the war years Kuznetsov honed Soviet methods of amphibious assault. A notable subordinate in the Black Sea and in command of the Azov Flotilla was S.G. Gorshkov who would later succeed him as Commander-in-Chief of the Navy. In May 1944 he was given the rank of Admiral of the Fleet \u2013 a newly created position initially equated to that of a four-star general. In the same year, Kuznetsov was given the title of Hero of the Soviet Union. On May 31, 1945, his rank was equated to the rank of Marshal of the Soviet Union with a similar insignia. In August 1945, he took part in Operation August Storm in the Far East, helping to provide functions for the Soviet Navy fleet for Commander-in-Chief of USSR Forces in the Far East Marshal Aleksandr Vasilevsky.\nThe first fall.\nFrom 1946 to 1947 he was the Deputy Minister of the USSR Armed Forces and Commander-in-Chief of the Naval Forces.\nIn 1947 he was removed from his post on Stalin's orders and in 1948 he, as well as several other admirals were put on trial by the Naval Tribunal. Kuznetsov was demoted to vice-admiral, while the other admirals received prison sentences of varying length.\nIn 1951 Stalin ended Kuznetsov's pariah status, once again placing him in command of the Navy (as the Minister of the Navy of the USSR), but without restoring his military rank, which was returned to him upon Stalin's death in 1953. In the same year, he became the First Deputy Minister of Defense of the USSR. In 1955, Kuznetsov was made Commander-in-Chief of the Naval Forces. His rank was raised to Admiral of the Fleet of the Soviet Union and he was awarded the Marshal's Star.\nThe second fall and retirement.\nHis newfound prominence brought him into direct conflict with now Defense Minister Marshal Zhukov, with whom he had clashed during the war years. On December 8, 1955, using the loss of the battleship as a pretext, Zhukov removed the Admiral from his post. The commission that inspected the ship's loss was headed by Vyacheslav Malyshev and its findings were used by Zhukov to blame Kuznetsov. In February 1956 he was again demoted to the rank of vice-admiral, retired and expressly forbidden \"any and all work connected with the navy.\"\nDuring his retirement he wrote and published many essays and articles, as well as several longer works, including his memoirs and an officially sanctioned book, \"With a Course for Victory\", which dealt with the Patriotic War. His memoirs, unlike those of many other prominent leaders, were written by him personally and are noted for their style.\nKuznetsov also authored several books on the war, on Stalin's repressions, and on the navy which were published posthumously. In these he was highly critical of the Party's interference in the internal affairs of the military, and insisted that \"the state must be ruled by law.\"\nRehabilitation and legacy.\nAfter the retirement of Zhukov in 1957, and of Khrushchev in 1964, a group of naval veterans began a campaign addressed to the Soviet leadership to restore Kuznetsov's rank, with all benefits, and to make him one of the General Inspectors of the Ministry of Defence. Not until July 26, 1988, under Andrey Gromyko did the Presidium of the Supreme Soviet of the USSR reinstate Kuznetsov to his former rank of Admiral of the Fleet of the Soviet Union. Kuznetsov is now recognized as one of the most prominent men in the history of the Soviet and, today, of the Russian Navy. In recognition, the Russian Navy's largest surface warship, its only remaining aircraft carrier, is named in his honor.\nDeath.\nKuznetsov died on 6 December 1974 in Moscow, at aged 70 and was buried with full military honors at the Novodevichy Cemetery.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22042", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=22042", "title": "Nuon (DVD technology)", "text": "Video game console\nNuon (stylized as NUON) is a technology developed by VM Labs that adds features to a DVD player. In addition to viewing DVDs, one can play 3D video games and use enhanced DVD navigational tools such as zoom and smooth scanning of DVD playback. One could also play CDs while the Nuon graphics processor generates synchronized graphics on the screen. There were plans to provide Internet access capability in the next generation of Nuon-equipped DVD players.\nHistory.\nNuon was first unveiled under the codename \"Project X\", set for a release during the 1998 Christmas shopping season, and was featured in \"Electronic Gaming Monthly\"'s 1999 Video Game Buyer's Guide. One of the Nuon's main software developers was Jeff Minter, who created a version of \"Tempest\" titled \"Tempest 3000\" for the system and the built-in VLM-2 audio visualizer. Manufacturing of the hardware was handled by several original equipment manufacturers.\nThe system's software development kit (SDK) was priced at roughly one-third of that of the PlayStation SDK, and following a strong showing at the 1998 Consumer Electronics Show, VM Labs shipped out several dozen SDKs to developers.\nWhen it was first announced, the Nuon's creators envisioned it as a competitor for the upcoming video game consoles from the leading manufacturers. However, the Nuon platform was primarily marketed as an expanded DVD format. A large majority of Nuon players that were sold in fact resembled typical consumer DVD players with the only noticeable difference being a Nuon logo. Nuon players offered a number of features that were not available on other DVD players when playing standard DVD-formatted titles. These included very smooth forward and reverse functionality and the ability to smoothly zoom in and out of sections of the video image. In addition, Nuon provided a software platform to DVD authors to provide interactive software like features to their titles.\nIn North America, Nuon was used in the Samsung DVD-N501 and DVD-N2000 models; they also released several models in other parts of the world: DVD-N504 (Europe), DVD N505 (Europe), and DVD-N591 (Korea). Toshiba released the SD-2300 DVD player, and there are two RCA models, the DRC300N and DRC480N. The Nuon was also used in Motorola's Streamaster 5000 \"Digital DNA\" set-top box.\nNuon was created by VM Labs, whose assets were sold to Genesis Microchip in April 2002. By November 2004, there were no Nuon-enabled DVD players shipping and no new Nuon software titles released or in development.\nPeripherals and accessories.\nPeripherals for Nuon-enhanced DVD players included the following:\nReleased movies.\nOnly four DVD releases utilized Nuon technology. All of them were released by 20th Century Fox Home Entertainment:\nReleased games.\nOnly eight games were officially released for the Nuon:\nProposed games.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nHomebrew development.\nIn late 2001, VM Labs released an SDK which allowed developers to program apps/games for their Nuon system. Only the Samsung DVD-N501/\u200bDVDN504/\u200bDVDN505 and RCA DRC300N/\u200bDRC480N can load homebrew games.\nSome homebrew titles have been created for or ported to Nuon. They are not commercially available and require the user to burn the material to a Nuon-compatible CD-R.\nNotes.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22045", "revid": "1289606", "url": "https://en.wikipedia.org/wiki?curid=22045", "title": "Nashville (disambiguation)", "text": "Nashville is the capital of the U.S. state of Tennessee.\nNashville may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "22048", "revid": "50966387", "url": "https://en.wikipedia.org/wiki?curid=22048", "title": "Cuisine of New England", "text": "Northeastern US food culture\nThe cuisine of New England is an American cuisine which originated in the New England region of the United States, and traces its roots to traditional English cuisine and Native American cuisine of the Abenaki, Narragansett, Niantic, Wabanaki, Wampanoag, and other native peoples. It also includes influences from Irish, French-Canadian, Italian, and Portuguese cuisine, among others. It is characterized by extensive use of potatoes, beans, dairy products and seafood, resulting from its historical reliance on its seaports and fishing industry. Corn, the major crop historically grown by Native American tribes in New England, continues to be grown in all New England states, primarily as sweet corn although flint corn is grown as well. It is traditionally used in hasty puddings, cornbreads and corn chowders.\nMany of New England's earliest Puritan settlers were from eastern England, where baking foods (for instance, pies, beans, and turkey) was more common than frying, as was the tradition elsewhere.\nThree prominent characteristic foodstuffs native to New England are maple syrup, cranberries and blueberries. The traditional standard starch is potato, though rice has a somewhat increased popularity in modern cooking. Traditional New England cuisine is known for a lack of strong spices, which is because of local 19th century health reformers, most prominently Sylvester Graham, who advocated eating bland food. Ground black pepper, parsley, garlic, and sage are common, with a few Caribbean additions, such as nutmeg, plus several Italian spices.\nThe use of cream is common, due to the reliance on dairy. The favored cooking techniques are stewing, steaming, and baking. Many local ingredients, such as squash, corn and local beans, sunflowers, wild turkey, maple syrup, cranberries and dishes such as cornbread, Johnnycakes and Indian pudding were adopted from Native American cuisine.\nHistory.\nEarly history.\nThe traditional diet of the Wampanoag Indians included chestnuts, beechnuts, walnuts, beans, multi-colored corn (called \"flint corn\"), and varieties of squash and pumpkins. Not strictly vegetarian, the traditional diet of the Wabanaki people is plant-centric and based on corn, beans, squash, sunflower seeds, sunchokes and groundcherries. The Wabanaki tribal nations did make plant milk and infant formula from nuts.\nAmerican colonies.\nIn 1620, the newly arrived Pilgrims faced the prospect of surviving their first winter in Plymouth Colony. The climate was harsh and the growing season was shorter than they were accustomed to due to the long and frosty winters. The newly arrived colonists brought vital techniques of food preservation, like smoking, curing and drying, that helped them survive the harsh New England winter. They also received help from the Wampanoag, who taught the newly arrived Pilgrims how to grow the staple crops of squash, beans and corn. It is not known for certain what crops were grown in early colonial gardens, but later sources mention turnips, onions, carrots, garlic and pumpkins.\nThe Pilgrims used corn to make hasty pudding and Wampanoag recipes like popcorn, \"sagamite\" and \"nasaump\". The Wampanoag Indians also taught the Pilgrims to bake in hot ashes, and ash cakes (also called johnny cakes or breakfast bannocks) became a staple breakfast bread. Beans were used to make stews or combined with corn to make succotash.\nMany of Massachusetts Bay's earliest Puritan settlers were from eastern England and brought the traditions of English cuisine with them. Puritans typically avoided much of the food native to New England (such as oysters, lobsters, salmon, and plants like glasswort and fiddleheads) unless driven to starvation. Roast duck, goose, lamb, and hams were brought as farmyard stock as soon as the colonies began to prosper. One typical dish of the Puritans was boiled dinner: a meal where the meat and vegetables were boiled simultaneously in the same pot (a unique method inherited from Eastern England). Another dish was pease porridge, a meal of \"boiled or baked\" split peas cooked with herbs and bacon that was eaten both warm or cold. Dark beer and fermented apple cider were often drunk alongside the settlers' meals. \nAn important element of the Puritan settlers inherited cooking style was the use of baking. Brick ovens were used to bake a type of crusty brown bread out of cornmeal and rye, which became known as \"rye n' injun\". Another example of the use of the oven is the typical Puritan Thanksgiving meal, which featured baked turkey. Desserts enjoyed by Puritans were also baked goods, such as cakes and fruit pies. \nEven today, traditional English cuisine remains a strong part of New England's identity. Some of its plates are now enjoyed by the entire United States, including baked beans, apple pies, pease porridge, and steamed puddings.\n19th century.\nSince the 1800s, New England's culinary traditions have been influenced by the arrival of Irish Americans, Portuguese Americans, and Italian Americans.\n\"Country stores\" sold homemade jams, fruit preserves and penny candy. Common crackers are still made with the original recipe dating to 1828.\nVegetarianism was practiced during the 18th and 19th century by individuals and families in Maine before the start of the modern vegetarian movement in 1817 in Philadelphia.\n20th century.\nIn the post-World War II era, July 4 celebrations frequently featured steak, hot dogs, hamburgers and grilled chicken. In the more distant past lamb was more traditional inland, and coastal communities in New England typically served salmon with dill mayo, peas, new potatoes and corn on the cob. Dessert often includes seasonal fruit, for example strawberry shortcake and blueberry pie.\n21st century.\nIn the 21st century, more people in New England were eating vegan and vegetarian meals and more restaurants were serving them. In a \"Boston Globe\" article in 2022, it was reported how that four of the most traditional foods of New England cuisine (lobsters, corn, blueberries, and coffee) are among crops affected most by climate change and temperature and humidity changes.\nTraditional foods and drinks.\nBeer and alcohol.\nDrinks in the Colonial era were made with local ingredients like honey, molasses, apples, hops and wild berries. These drinks included apple brandy (applejack), fruit wines, rum and mead. Some of the finest rum distilleries were located in New England prior to Prohibition.\nThe hot ale flip is a traditional drink historically made by mixing a pitcher of beer with rum, frothy eggs and a sweetener like dried pumpkin, maple syrup or molasses. The beverage was warmed by plunging a hot poker into the drink to caramelize the sugars creating the drink's characteristic hot froth.\nLike the flip, the Rattle-Skull was a mix of beer (in this case a dark beer like porter) and hard liquor\u2014usually a mix of rum and brandy. The beverage is flavored with lime and garnished with nutmeg.\nThe Stone Fence was a mix of hard cider and rum. Reportedly, Ethan Allen and his men drank it before their raid of Fort Ticonderoga in 1775. Egg cider was made by cracking eggs into heated cider and adding a sweetener like molasses.\nThe cider-based beverage syllabub was made with rum, cream and sweetener. Mulled cider could be made with sweetener, spices, rum and egg yolks.\nBirch beer, made with sap from the \"betula lenta\" tree, was made by both the English and early American colonists. The \"betula lenta\" is known for producing a fragrant sap with a unique minty flavor. John Mortimer wrote that birch beer was usually made by the poor by boiling birch sap with sugar and fermenting it with yeast.\nMany local breweries produce lagers and ales. Notable examples include Samuel Adams of the Boston Beer Company in Boston (even though the recipe for the beer does not come from New England); Sea Dog Brewing Company of Bangor; Shipyard Brewing Company of Portland; Smuttynose Brewing Company of Portsmouth, New Hampshire; and Narragansett Brewing Company of Providence. Vermont-based Woodchuck Draft Cider is a popular alcoholic cider.\nNew England has also played a major role in the craft beer revolution, with Maine, Connecticut, Massachusetts, and Vermont having notable breweries such as Harpoon Brewery, Allagash Brewing Company, Treehouse Brewing Company, Trillium Brewing Company, The Alchemist Brewery, Jack's Abby Brewing Company, Long Trail Brewing Company, Kent Falls Brewing Company and Two Roads Brewing Company.\nBaked beans.\nColonists learned to make baked beans from the Native American people. Baked beans are slowed cooked in an oven at a low temperature. They are sweetened, traditionally with maple syrup or molasses. The molasses is what sets them apart as New England baked beans. The Pilgrims and other early colonists were forbidden from cooking on Sundays, when these Christian communities observed the Sabbath, and this made baked beans a meal that is common for Saturday night dinner and all day Sunday. Two regional styles are Boston Baked Beans and Maine Baked Beans. The difference between the two styles is that Boston beans are made with small white navy beans or pea beans with thin skin while Maine beans are made with native bean varieties with thicker skins. These varieties are Marifax, soldier beans, and the most popular baked bean variety in Maine is the yellow-eye bean.\nCasseroles, soups and stews.\nThe custom of bringing one-dish casseroles (also called hot dishes) to barn raisings and church suppers was not exclusive to New England, but included traditional variations of baked beans and succotash. Modern recipes can be made with any ingredients available at markets. Seafood casseroles are made with cream sauce and bread crumb topping.\nAmerican chop suey is a casserole dish made with ground beef, macaroni and a seasoned tomato sauce. Though unrelated to Hungarian goulash, in other regions of the United States it may be called American goulash amongst other names. \nFruits.\nBlueberries are made into jams and jellies and feature in breads and regional desserts like pies, cobblers and cakes.\nWild beach plums are foraged and used to make fruit preserves like jams and jellies. Beach plums were cultivated and used for the commercial manufacture of beach plum jelly in the 1930s, but beach plum products are no longer widely available in commercial markets.\nThe local purple concord grapes are a cross between native and European grapes. The large grapes are prized for their juiciness and used in the production of commercial grape juice, wine and grape jelly. It is a common ingredient in peanut butter and jelly sandwiches.\nUntil the pilgrims planted apple seeds from Europe, the only regional apples were crab apples. Cross-pollination altered the results of these first attempts, but over the years thousands of new varieties were bred by the pilgrims. Massachusetts native John Chapman, known as Johnny Appleseed, was a nurseryman who spread apple trees across the midwest.\nWilliam Blaxton planted the first apple orchard in 1625. The earliest apple varieties produced in New England included Lady (1628), Roxbury Russet (1630), Pomme Grise (1650), Baldwin (1740), Porter (1800), Mother (1844) and Wright (1875). In modern times apples are grown commercially throughout Massachusetts.\nThe first attempts at commercial cranberry growing were pioneered by Captain Henry Hall, who developed the technique of covering the vines with sand to accelerate the plant's growth.\nHot dogs.\nNew England\u2013style hot dog buns are split on top instead of on the side, and have a more rectangular shape. While smaller than common hot dog rolls, New England hot dog rolls have a larger soft surface area which allows for buttering and toasting, which are also commonly used for convenient serving of seafood like lobster or fried clams. Hot dog stands in Maine have long sold vegetarian hot dogs, but the region's most famous hot dog variation is the \"Red Snapper\"\u2013 a natural-casing hotdog with a signature bright red coloration and snappy bite.\nMaple syrup.\nMaple sap is collected annually during New England's \"sugaring season\". The new sap is reduced and thickened to form syrup. An issue of \"Yankee\" dating from 1939 gives some details on seasonal recipes with recipes for maple-butternut fudge, maple-sauce ice cream and \"Sugar on Snow\". Sugar on Snow, a regional specialty also called maple syrup taffy, is made by pouring freshly heated maple syrup on fresh snow, forming candy with a taffy consistency as the syrup hardens.\nDesserts like cobbler and maple custard pie were made with local sweeteners like maple sugar instead of sugar.\nMolasses and rum were common in New England cuisine, due to New England's involvement in the Triangle Trade in the 18th century. Molasses from the Caribbean and honey were staple sweeteners for all but the upper class well into the 19th century.\nSandwiches.\nSandwiches typical of New England's cuisine include baked bean on Boston brown bread; the Fluffernutter with Fluff marshmallow creme and peanut butter, usually served on Wonder bread, and the Maine Italian sandwich prepared using a long bread roll or bun with meats such as salami, mortadella, capicolla and ham along with provolone, tomato, onion, green bell pepper, Greek olives, olive oil or salad oil, salt and cracked black pepper.\nServed cold or hot, lobster rolls can optionally include fixings like mayo or warmed butter, clam rolls dressed with tartar or cocktail sauce on a New England\u2013style hot dog bun, and chow mein sandwich with noodles, celery, onions, meat and sauce in a hamburger bun, from Fall River, Massachusetts.\nSeafood.\nThe waters of the Gulf of Maine and Long Island Sound provide a rich variety of fish and shellfish that are a signature of the cuisine in New England.\nCommercial cod fishing along Cape Ann dates back as far as 1623 when salt cod was carried by merchant vessels to Africa, which returned with slaves for plantations in the Caribbean before carrying sugar back to New England. Cod, the fish for which Cape Cod is named, remains a staple of the regional cuisine to this day.\nBluefish can be found throughout Cape Cod and Nantucket during the summer months and is consumed smoked, broiled or sauteed. American lobster is usually consumed grilled, steamed, or boiled.\nBreaded deep-fried clams are popular pub fare in New England. Regional clam varieties can be soft shell or hard shell and include razor clams, the latter of these is more likely to be caught by hand owing to how difficult it is to harvest them without damaging the beach upon which they dwell.\nHard-shell clams are sometimes called littlenecks, cherrystones or quahogs depending on their size. These are used to make New England\u2013style clam chowder, and may also be consumed steamed or even raw. The preferred methods of preparing soft-shell clams (also called steamers) are frying or steaming.\nAdapted from the American Indians, the clambake is a traditional meal in New England where clams, lobsters and corn are cooked over a firepit. Modern versions of the dish may include mussels, fish, crabs and non-seafood ingredients like chicken, sausage, potatoes and other root vegetables.\nThe official state fish are as follows:\nSeasonings.\nMany herbs were uncommon, particularly Mediterranean herbs, which are not hardy in much of New England away from the coast. As a result, most savory New England dishes do not have much strong seasoning, aside from salt and ground black pepper, nor are there many particularly spicy staple items.\nIndigenous recipes and meals were numerous and encompassed many spices from native plant species such as spice bush, wild ginger, and sassafras. There are countless native herbs that contributed to the flavors of the area pre-colonialism. \nOther dishes meant as desserts often contain ingredients such as nutmeg, cinnamon, allspice, cloves, and ground ginger which are a legacy of trade with the Caribbean region beginning in the 17th century, lasting well into the 19th.\nPizza.\nMuch of the pizza in New England is Greek pizza, owing to the strong presence of Greek immigrants and Greek Americans in the food-service industry in New England. Greek pizza (as understood in New England) is typified by its chewy, bready crust similar to focaccia, which is baked in shallow, round metal pan liberally coated with olive oil. Greek-style pizzerias in New England are often found under the name House of Pizza or Pizza House.\nItalians emigrated to New England beginning a little over a century ago, \nand Southern New England pizza tends to be more Italian influenced. World-famous restaurants such as Pepe's Pizza in New Haven, CT serve a thin, coal-fired hand-tossed style of pie. New Haven\u2013style pizza is typified by a slightly burnt, crunchy exterior crust and soft, slightly chewy interior. Southern New England pizza (or apizza) is closely related to Neapolitan-style pizza.\nRegional specialties.\nConnecticut.\nIn Connecticut, Irish-American influences are common in the interior portions of the state, including the Hartford area. During the 18th century the Hartford election cake was a spicy, boozy yeast-leavened cake based on a traditional English holiday cake.\nDuring the colonial era, elections were celebrated with a drink and a huge celebration cake large enough to feed the entire community, and the recipe as given by Amelia Simmons in 1796 called for butter, sugar, raisins, eggs, wine and spices in enormous quantities. Hasty pudding is sometimes found in rural communities, particularly around Thanksgiving.\nItalian-inspired cuisine is dominant in the New Haven area, which is known for charred thin-crust New Haven-style pizza baked in coal-fired ovens. The well-known white clam pie is made with fresh clams, olive oil, fresh garlic, oregano and grated Romano cheese.\nSome pizza places also offer subs on Italian bread (\"grinders\") and standard Italian fare like eggplant rollatini, manicotti, baked ziti and chicken parmesan. Well-known pizzerias include Pepe's Pizza, Sally's Apizza and Modern Apizza.\nThe cuisine of Southeastern Connecticut is heavily based on the local fishing industry. Typical New England seafood dishes are available at local restaurants like Abbot's Lobster in the Rough. Lobster rolls, crab cakes, oysters, clam chowder, steamer clams and mussels are served with sides like potato chips, remoulade sauce and coleslaw.\nShad is the state fish and is cooked on planks (usually hickory, oak, or cedar) by the fire, called a \"shad bake\", deboning the fish requires some skill with a boning knife.\nLouis' Lunch began as a lunch wagon started by Danish immigrant Louis Lassen in 1895. Their burgers are still cooked in the original antique cast-iron broiler.\nA local specialty of Meriden, Connecticut, steamed cheeseburgers started as simple steamed cheese on a roll sandwiches sold off horse-drawn food carts in the 1900s. Some believe the hamburger originated in New Haven at Louis', and like the butter burger and deep-fried hamburger, the steamed version may be a remnant of an earlier time before the broiled hamburger on a bun became the standard form.\nIce cream is made with milk from local creameries at UCONN Dairy Bar using a century-old recipe to produce 24 different flavors of ice cream. Ferris Acres Creamery is a 150-year-old dairy farm offering 50 flavors of ice cream. The most popular is the \"Cow Trax\", a base of vanilla with peanut butter swirls and chocolate chips.\nMaine.\nMaine is known for two sandwiches, the lobster roll\u2014lobster meat mixed with mayonnaise and other ingredients, served in a grilled hot dog roll in the summer, particularly on the coast in locations that serve tourists\u2014and the Maine Italian sandwich\u2014a submarine sandwich. Baked beans are very popular in Maine. Early white settlers learned to make baked beans from the Wabanaki. They were originally sweetened with maple syrup. The Atlantic Triangular Trade caused colonists to swap molasses for maple syrup. Maine cooks prefer old style bean varieties such as Yellow Eyes, Jacobs Cattle, Soldier, and Marafax. Bean-hole beans were a staple at Maine lumber camps.\nBuckwheat pancakes called ployes are popular in Maine. Ployes are an Acadian pancake-type mix of buckwheat flour, wheat flour, baking powder and water, which is extremely popular in the Madawaska region, in New Brunswick and in Maine. With local toppings, such as maple syrup or cretons, ployes can vary in taste. This staple is popular with vegans and is often eaten with baked beans.\nWabanaki influences are common in Maine, and many staple foods including beans, corn, squash, wild blueberries, maple syrup, and seafood are part of traditional Wabanaki cuisine. Fiddlehead ferns are part of Wabanaki cuisine and are still prized in Maine, where they are gathered in springtime. Foraging remains popular in Maine and people also forage for mushrooms, hazelnuts, acorns, elderberries, dandelions and ramps. Maine is known for its seaweed that is used in many dishes as a seasoning and even included in snack bars.\nMaine has a high number or organic farms. Maine is home to the Maine Organic Farmers and Gardeners Association, founded in 1971 and is the oldest organic farming organization in the country. The 1970 book \"Living the Good Life\" by Maine residents Helen Nearing and Scott Nearing caused many young people to move to Maine and engage in small-scale farming and homesteading and this increased the population of the state and the access to local vegetables. Maine is home to over 100 summer farmers' markets and over 30 winter farmers' markets.\nNorthern Maine produces potato crops, second only to Idaho in the United States. Because of this potatoes are very popular in Maine food and even an ingredient in sweets, like doughnuts and chocolate candy. Poutine is popular throughout Maine.\nMaine is the only state with a commercial wild blueberry industry, where growers harvested 105 million pounds in 2021. Wild blueberries are a common ingredient or garnish, and blueberry pie is the official state dessert (when made with wild Maine blueberries). Wild blueberry pancakes, muffins, doughnuts and ice cream are popular in Maine. Apple picking and apple desserts, particularly apple pie and apple cider doughnuts, are popular in Maine. Apples have been grown in Maine since the earliest colonial settlements. One of the earliest recorded Maine orchards was Anthony Brackett's farm and orchard in Portland. Brackett's orchard was near the current Deering Oaks and it was destroyed in 1689 during a major battle of the French and Indian Wars.\nMaple syrup, maple sugar and maple candies are regularly eaten in Maine. Maine grist mills grind yellow field peas to create a flour chefs use to make gluten-free and vegan foods such as mayonnaise. Moxie was America's first mass-produced soft drink and is the official state soft drink. Moxie is known for its strong aftertaste and is found throughout New England.\nMainers consume the second most ice cream per capita in the United States, and many Maine ice cream shops make and sell vegan ice creams. Ice cream was first made in Maine in 1825 at the Portland home of Asa Clapp to honor a visit to the city by Marquis de Lafayette. The whoopie pie, which is also a staple in the Philadelphia/Pennsylvania Dutch cuisine, is the official state treat. The first documented bakery in America to sell whoopie pies was Labadie's Bakery in Lewiston, which first sold them in 1925 (although possibly as early as 1918). Maine sea captain Hansen Gregory claimed to have invented the doughnut with a hole in the center in 1847, and there is a plaque dedicated to him in his birthplace Rockport. Maine is known for varieties ranging from potato doughnuts to vegan doughnuts. Maine is the place of origin for the needham, a dessert bar made from chocolate, coconut, and potato. Wax-wrapped salt water taffy is a popular item sold in tourist areas, although it is originally from New Jersey.\nThe city of Portland has been recognized for its restaurant scene. \"Bon Appetit\" magazine recognized Portland as the \"2018 Restaurant City of the Year\". The city has the Portland Farmers Market, founded in 1768, and the city ranks as a top city for vegans and vegetarians. The Francophone part of northern Maine in the St. John Valley has a lot of Acadian influences in their cuisine. A popular dish among all Acadians in this region is \"tourti\u00e8re\" or meat pies. These are especially popular around Christmas time.\nMassachusetts.\nCoastal Massachusetts is known for its clams, haddock, and cranberries, and previously cod. Massachusetts had similar immigrant influences as the coastal regions, though historically strong Eastern European populations instilled kielbasa and pierogi as common dishes.\nNamed after the town of Newton, Fig Newtons were first made in 1891 using a machine invented by James Mitchell to fill cookie dough with fig jam. The small round Necco Wafers, made with the first American candy machine, similarly originated in Cambridge. Graham bread was first made in 19th-century Massachusetts by Sylvester Graham. Tollhouse cookies, the original chocolate chip cookie and official state cookie of Massachusetts were created in 1930 at the Toll House Inn, located in Whitman.\nBoston is known for baked beans (hence the nickname \"Beantown\"), bulkie rolls, and various pastries. Boston cream pie is not a pie but a cake with custard filling. The origins are mysterious, but it is likely that antecedent cakes were made with either a sponge cake or a pound cake.\nParker's Restaurant, located inside the Parker House Hotel, was the premier dining establishment in Boston in the 19th century and remains a fine-dining establishment in Boston's Government Center area. The a-la-carte menu from 1865 included a range of local seafood offerings like oysters, fried clams, mackerel, shad, salmon in anchovy sauce, cod in oyster sauce, and soft-shell crab. Other meat dishes included chicken fricassee, potted pigeons, corned beef and baked beans with pork. Sides included corn, rice, macaroni, potatoes, asparagus, green peas, radishes and fried bananas. Sweet pastry and puddings were also served such as Indian pudding, custard, apple pie, rhubarb pie, Washington pie, Charlotte Russe, and blancmange. The restaurant was also famous for creating the Parker House roll, which is now popular throughout the United States.\nThe North Shore area is locally known for its roast beef sandwich shops, typically serving roast beef sandwiches consisting of thin-sliced roast beef on a hamburger bun. It may be served with condiments such as lettuce, tomato, onion, cheese, and sauces such as mayo and barbecue. Most pizza and roast beef sandwich shops also serve \"steak tips\" (marinated cubes of sirloin), a common menu item at pizza establishments and backyard cookouts.\nMarshmallow Fluff was invented in Somerville, Massachusetts and manufactured in Lynn, Massachusetts throughout the 20th century. Fluffernutter sandwiches, combining peanut butter with marshmallow fluff, are popular.\nThe South Shore area maintains a following for bar pizza, with many popular restaurants serving these crisp, thin, often heavily topped creations.\nCommon plant foods in Massachusetts are similar to those of interior northern New England, because of the landlocked, hilly terrain, including potatoes, maple syrup, and wild blueberries. Dairy production is also prominent in this central and western area.\nNew Hampshire.\nSouthern New Hampshire cuisine is similar to that of the Boston area, featuring fish, shellfish, and local apples. As with Maine and Vermont, French-Canadian dishes are popular, including \"tourti\u00e8re\", which is traditionally served on Christmas Eve, and poutine. Corn chowder is also common, which is similar to clam chowder but with corn and bacon replacing the clams. Portsmouth is known for its orange cake.\nRhode Island.\nRhode Island is known for johnnycakes, doughboys, and clam cakes.\nJohnnycakes, variously and contentiously known as jonnycakes, journeycakes and Shawnee cakes, can vary in thickness and preparation, and disagreements over whether they should be made with milk or water persist.\nEast of Narragansett Bay, johnnycakes are made with cold milk and a little butter, but around South County the batter is sweetened and made with scalded cornmeal. One attempt by the Rhode Island Legislature to settle on an \"authentic\" recipe ended in a fistfight.\nThey were traditionally served as a flatbread alongside chipped beef or baked beans, but in modern times they are usually eaten for breakfast with butter and maple syrup.\nAccording to The Society for the Propagation of the Johnnycake Tradition in Rhode Island, authentic johnnycakes must be made with whitecap flint corn historically grown in the region around Narrangasett Bay. Stone-ground flint corn is not commercially available, but can still be found at a few historic gristmills like the Prescott Farm museum in Middletown.\nSweetened coffee-flavored dairy products are popular in Rhode Island. Coffee ice cream is popular and a locally produced coffee gelatin dessert mix can be found at supermarkets. Coffee milk has been the official state drink since 1993. While the origins may date to the 1930s, when some shopkeeps sweetened leftover coffee ground with milk and sugar, its now made with coffee extract syrups like those produced by Autocrat.\nAlso popular in the state are clear clam chowder known as Rhode Island clam chowder, quahogs, milkshakes (called cabinets), submarine sandwiches (called grinders), pizza strips, the chow mein sandwich, and Del's Frozen Lemonade. Italian cooking is long established in the region.\nIn Rhode Island and other parts of New England with a large Portuguese American population, Portuguese foods are common, including \"lingui\u00e7a\", \"chouri\u00e7o\", \"caldo verde\", \"malasadas\", and Portuguese sweet bread.\nVermont.\nVermont produces cheddar cheese and other dairy products. Small cheesemakers recognized for producing hand-crafted cheddar cheeses include the Crowley Cheese Factory Grafton Village Cheese Company, and Shelburne Farms.\nThe Vermonter sandwich is made with cold cuts (often turkey and ham), apple, sharp Vermont cheddar and maple mustard (a mix of maple syrup and grainy mustard). The toasted sandwich is served warm.\nIt is known in and outside of New England for its maple syrup. Maple syrup is used as an ingredient in some Vermont dishes, including baked beans. Rhubarb pie is a common dessert and has been combined with strawberries in late spring.\nRestaurants and pubs.\nThe oldest continuously operating restaurant in the United States is the Union Oyster House (1826) located in Boston. The oldest operating restaurant is the White Horse Tavern in Newport, Rhode Island (it had, at one point closed for renovations since its inception).\nLegal Sea Foods is a chain restaurant that began by selling fresh fish and fish and chips. The original 1950 shop was located at Cambridge's Inman Square.\nWoodman's of Essex began selling homemade potato chips in 1914. Their signature dish of fried clams was introduced only a few years later, in 1916. Their chowder has won prizes at the annual Essex Clamfest.\nFriendly's was founded in 1935 during the Great Depression in Springfield, Massachusetts, as an ice-cream parlor selling two scoops for a nickel. By 1960, the company offered 63 flavors of ice cream. They were producing 25 million gallons per year and had moved their headquarters to Wilbraham. It only becomes a full-service chain restaurant after being acquired by Donald Smith in 1988.\nAt local shops along the North Shore of Massachusetts, \"three-way\" roast beef sandwiches are often served on an onion roll and topped with mayo, barbecue sauce and white American cheese. Kelly's Roast Beef claims to have originated the first roast beef sandwich. Open-faced roast beef sandwiches predate Kelly's version but are typically eaten with a knife and fork. Other well-known North Shore roast beef shops include Londi's and Bill &amp; Bob's.\nD\u2019Angelo\u2019s is a regional chain with locations in Connecticut, Maine, Rhode Island, New Hampshire, and Massachusetts specializing in subs (called heroes in New York and hoagies in Philadelphia). Their first shop opened in Dedham, Massachusetts, in 1967. They serve foot-long lobster rolls and other sandwich varieties like steak and cheese.\nItalian sandwiches are the specialty of Moe's Italian Sandwiches, founded in Portsmouth, New Hampshire, in 1959. Based on a family recipe, their sandwich is made with salami, provolone, veggies, spices and olive oil. Amato's claims to have originated the Maine Italian sandwich, made with ham, American cheese, onion, sour pickles, tomatoes, black olives, green peppers and olive oil.\nFood and dairy industries.\nFluff marshmallow creme, used to make Fluffernutter sandwiches, is made in Lynn, Massachusetts. Welch's, headquartered in Concord, Massachusetts, produces grape juices, jellies and jams from purple Concord grapes. The company has been owned by the National Grape Cooperative Association since 1956.\nAutocrat is a company based in Lincoln, Rhode Island, that produces coffee and tea extracts. Their coffee syrups are used to make coffee milk which became the official state drink of Rhode Island in 1993.\nThe Moxie Beverage Company of Bedford, New Hampshire, acquired by the Coca-Cola Company in 2018, produces the Moxie soft drink. Flavored with gentian root extract, Moxie has been the official soft drink of Maine since May 10, 2005.\nOrganic dairy company Stonyfield Farm, owned by the French dairy company Lactalis, is located in Londonderry, New Hampshire. Ice-cream company Ben &amp; Jerry's, purchased in 2000 by the Anglo-Dutch company Unilever, was founded in 1978 in Burlington, Vermont.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "22049", "revid": "8524693", "url": "https://en.wikipedia.org/wiki?curid=22049", "title": "Neil Simon", "text": "American playwright, writer, and academic (1927\u20132018)\nMarvin Neil Simon (July 4, 1927\u00a0\u2013 August 26, 2018) was an American playwright, screenwriter and author. He wrote more than 30 plays and nearly the same number of movie screenplays, mostly film adaptations of his plays. He received three Tony Awards and a Golden Globe Award, as well as nominations for four Academy Awards and four Primetime Emmy Awards. He was awarded a Special Tony Award in 1975, the Pulitzer Prize for Drama in 1991, the Kennedy Center Honors in 1995 and the Mark Twain Prize for American Humor in 2006.\nSimon grew up in New York City during the Great Depression. His parents' financial difficulties affected their marriage, giving him a mostly unhappy and unstable childhood. He often took refuge in movie theaters, where he enjoyed watching early comedians like Charlie Chaplin. After graduating from high school and serving a few years in the Army Air Force Reserve, he began writing comedy scripts for radio programs and popular early television shows. Among the latter were Sid Caesar's \"Your Show of Shows\" (where in 1950 he worked alongside other young writers including Carl Reiner, Mel Brooks, Woody Allen, Larry Gelbart and Selma Diamond), and \"The Phil Silvers Show\", which ran from 1955 to 1959.\nHis first produced play was \"Come Blow Your Horn\" (1961). It took him three years to complete and ran for 678 performances on Broadway. It was followed by two more successes, \"Barefoot in the Park\" (1963) and \"The Odd Couple\" (1965). He won a Tony Award for the latter. It made him a national celebrity and \"the hottest new playwright on Broadway\". From the 1960s to the 1980s, he wrote for stage and screen; some of his screenplays were based on his own works for the stage. His style ranged from farce to romantic comedy to more serious dramatic comedy.\nOverall, he garnered 17 Tony nominations and won three awards. In 1966, he had four successful productions running on Broadway at the same time and, in 1983, he became the only living playwright to have a New York theatre, the Neil Simon Theatre, named in his honor.\nEarly years.\nNeil Simon was born on July 4, 1927, in The Bronx, New York City, to Jewish parents. His father, Irving Simon, was a garment salesman, and his mother, Mamie (Levy) Simon, was mostly a homemaker. Neil had one brother, eight years his senior, television writer and comedy teacher Danny Simon. He grew up in Washington Heights, Manhattan, and graduated from DeWitt Clinton High School when he was sixteen. He was nicknamed 'Doc', and the school yearbook described him as extremely shy.\nSimon's childhood was marked by his parents' \"tempestuous marriage\" and the financial hardship caused by the Depression. Sometimes at night he blocked out their arguments by putting a pillow over his ears. His father often abandoned the family for months at a time, causing them further financial and emotional suffering. As a result, the family took in boarders, and Simon and his brother Danny were sometimes forced to live with different relatives.\nDuring an interview with writer Lawrence Grobel, Simon said: \"To this day I never really knew what the reason for all the fights and battles were about between the two of them\u00a0... She'd hate him and be very angry, but he would come back and she would take him back. She really loved him.\" Simon has said that one of the reasons he became a writer was to fulfill a need to be independent of such emotional family issues, a need he recognized when he was seven or eight: \"I'd better start taking care of myself somehow\u00a0... It made me strong as an independent person.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I think part of what made me a comedy writer is the blocking out of some of the really ugly, painful things in my childhood and covering it up with a humorous attitude\u00a0... do something to laugh until I was able to forget what was hurting.\nHe was able to do that at the movies, in the work of stars like Charlie Chaplin, Buster Keaton, and Laurel and Hardy. \"I was constantly being dragged out of movies for laughing too loud.\" Simon acknowledged these childhood films as his inspiration: \"I wanted to make a whole audience fall onto the floor, writhing and laughing so hard that some of them pass out.\" He made writing comedy his long-term goal, and also saw it as a way to connect with people. \"I was never going to be an athlete or a doctor.\" He began writing for pay while still in high school: At the age of fifteen, Simon and his brother created a series of comedy sketches for employees at an annual department store event. To help develop his writing skill, he often spent three days a week at the library reading books by famous humorists such as Mark Twain, Robert Benchley, George S. Kaufman and S. J. Perelman.\nSoon after graduating from high school, he signed up with the Army Air Force Reserve at New York University. He attained the rank of corporal and was eventually sent to Colorado. During those years in the Reserve, Simon wrote professionally, starting as a sports editor. He was assigned to Lowry Air Force Base during 1945 and attended the University of Denver from 1945 to 1946.\nWriting career.\nTelevision.\nSimon quit his job as a mailroom clerk in the Warner Brothers offices in Manhattan to write radio and television scripts with his brother Danny Simon, under the tutelage of radio humorist Goodman Ace, who ran a short-lived writing workshop for CBS. Their work for the radio series \"The Robert Q. Lewis Show\" led to other writing jobs. Max Liebman hired the duo for the writing team of his popular television comedy series \"Your Show of Shows.\" The program received Emmy Award nominations for Best Variety Show in 1951, 1952, 1953, and 1954, and won in 1952 and 1953. Simon later wrote scripts for \"The Phil Silvers Show\", for episodes broadcast during 1958 and 1959.\nSimon later recalled the importance of these two writing jobs to his career: \"Between the two of them, I spent five years and learned more about what I was eventually going to do than in any other previous experience.\" \"I knew when I walked into \"Your Show of Shows\", that this was the most talented group of writers that up until that time had ever been assembled together.\"\nSimon described a typical writing session:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;There were about seven writers, plus Sid, Carl Reiner, and Howie Morris\u00a0... Mel Brooks and maybe Woody Allen would write one of the other sketches\u00a0... everyone would pitch in and rewrite, so we all had a part of it\u00a0... It was probably the most enjoyable time I ever had in writing with other people.\nSimon incorporated some of these experiences into his play \"Laughter on the 23rd Floor\" (1993). A 2001 TV adaptation of the play won him two Emmy Award nominations.\nStage.\nHis first Broadway experience was on \"Catch a Star!\" (1955); he collaborated on sketches with his brother, Danny.\nIn 1961, Simon's first Broadway play, \"Come Blow Your Horn\", ran for 678 performances at the Brooks Atkinson Theatre. Simon took three years to create that first play, partly because he was also working on television scripts. He rewrote it at least twenty times from beginning to end: \"It was the lack of belief in myself\", he recalled. \"I said, 'This isn't good enough. It's not right.'\u00a0... It was the equivalent of three years of college.\" Besides being a \"monumental effort\" for Simon, that play was a turning point in his career: \"The theater and I discovered each other.\"\n\"Barefoot in the Park\" (1963) and \"The Odd Couple\" (1965), for which he won a Tony Award, brought him national celebrity, and he was considered \"the hottest new playwright on Broadway\", according to Susan Koprince. Those successes were followed by others. During 1966, Simon had four shows playing simultaneously at Broadway theatres: \"Sweet Charity\", \"The Star-Spangled Girl\", \"The Odd Couple\" and \"Barefoot in the Park\". These earned him royalties of $1 million a year. His professional association with producer Emanuel Azenberg began with \"The Sunshine Boys\" and continued with \"The Good Doctor\", \"God's Favorite\", \"Chapter Two\", \"They're Playing Our Song\", \"I Ought to Be in Pictures\", \"Brighton Beach Memoirs\", \"Biloxi Blues\", \"Broadway Bound\", \"Jake's Women\", \"The Goodbye Girl\" and \"Laughter on the 23rd Floor\", among others. His work ranged from romantic comedies to serious drama. Overall, he received seventeen Tony nominations and won three awards.\nSimon also adapted material originated by others, such as the musical \"Little Me\" (1962), based on the novel by Patrick Dennis; \"Sweet Charity\" (1966) from the screenplay for the film \"Nights of Cabiria (\"1957), written by Federico Fellini and others; and \"Promises, Promises\" (1968) a musical version of Billy Wilder's film, \"The Apartment\". By the time of \"Last of the Red Hot Lovers\" in 1969, Simon was reputedly earning $45,000 a week from his shows (excluding sale of rights), making him the most financially successful Broadway writer ever. Simon also served as an uncredited \"script doctor\", helping to hone the books of Broadway-bound plays or musicals under development, as he did for \"A Chorus Line\" (1975). During the 1970s, he wrote a string of successful plays; sometimes more than one was playing at the same time, to standing room only audiences. Although he was, by then, recognized as one of the country's leading playwrights, his inner drive kept him writing:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Did I relax and watch my boyhood ambitions being fulfilled before my eyes? Not if you were born in the Bronx, in the Depression and Jewish, you don't.\nSimon drew \"extensively on his own life and experience\" for his stories. His settings are typically working-class New York City neighborhoods, similar to the ones in which he grew up. In 1983, he began writing the first of three autobiographical plays, \"Brighton Beach Memoirs\" (1983), which would be followed by \"Biloxi Blues\" (1985) and \"Broadway Bound\" (1986). He received his greatest critical acclaim for this trilogy. He received a https:// for his follow-up play, \"Lost in Yonkers\" (1991), which starred Mercedes Ruehl and was a success on Broadway.\nFollowing \"Lost in Yonkers\", Simon's next several plays did not meet with commercial success. \"The Dinner Party\" (2000), which starred Henry Winkler and John Ritter, was \"a modest hit\". Simon's final play, \"Rose's Dilemma\", premiered in 2003 and received poor reviews.\nSimon is credited as playwright and contributing writer to at least 49 Broadway plays.\nScreen.\nSimon chose not to write the screenplay for the first film adaptation of his work, \"Come Blow Your Horn\" (1963), preferring to focus on his playwriting. However, he was disappointed with the picture, and thereafter tried to control the conversion of his works. Simon wrote screenplays for more than twenty films and received four Academy Award nominations\u2014for \"The Odd Couple\" (1969), \"The Sunshine Boys\" (1975), \"The Goodbye Girl\" (1977) and \"California Suite\" (1978). Other movies include \"The Out-of-Towners\" (1970) and \"Murder by Death\" (1976). Although most of his films were successful, movies were always of secondary importance to his plays:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I always feel more like a writer when I'm writing a play, because of the tradition of the theater\u00a0... there is no tradition of the screenwriter, unless he is also the director, which makes him an \"auteur\". So I really feel that I'm writing for posterity with plays, which have been around since the Greek times.\nMany of his earlier adaptations of his own work were very similar to the original plays. Simon observed in hindsight: \"I really didn't have an interest in films then. I was mainly interested in continuing writing for the theater\u00a0... The plays never became cinematic\". \"The Odd Couple\" (1968), was one highly successful early adaptation, faithful to the stage play but also opened out, with more scenic variety.\nWriting style and subject matter.\nThe key aspect most consistent in Simon's writing style is comedy, situational and verbal, and presents serious subjects in a way that makes audiences \"laugh to avoid weeping\". He achieved this with rapid-fire jokes and wisecracks, in a wide variety of urban settings and stories. This creates a \"sophisticated, urban humor\", says editor Kimball King, and results in plays that represent \"middle America\". Simon created everyday, apparently simple conflicts with his stories, which became comical premises for problems which needed be solved.\nAnother feature of his writing is his adherence to traditional values regarding marriage and family. McGovern states that this thread of the monogamous family runs through most of Simon's work, and is one he feels is necessary to give stability to society. Some critics have therefore described his stories as somewhat old fashioned, although Johnson points out that most members of his audiences \"are delighted to find Simon upholding their own beliefs\". And where infidelity is the theme in a Simon play, rarely, if ever, do those characters gain happiness: \"In Simon's eyes,\" adds Johnson, \"divorce is never a victory.\"\nAnother aspect of Simon's style is his ability to combine both comedy and drama. \"Barefoot in the Park\", for example, is a light romantic comedy, while portions of \"Plaza Suite\" were written as \"farce\", and portions of \"California Suite\" are \"high comedy\".\nSimon was willing to experiment and take risks, often moving his plays in new and unexpected directions. In \"The Gingerbread Lady\", he combined comedy with tragedy; \"Rumors\" (1988) is a full-length farce; in \"Jake's Women\" and \"Brighton Beach Memoirs\" he used dramatic narration; in \"The Good Doctor\", he created a \"pastiche of sketches\" around various stories by Chekhov; and \"Fools\" (1981), was written as a fairy-tale romance similar to stories by Sholem Aleichem. Although some of these efforts failed to win approval from many critics, Koprince claims that they nonetheless demonstrate Simon's \"seriousness as a playwright and his interest in breaking new ground.\"\nCharacters.\nSimon's characters are typically \"imperfect, unheroic figures who are at heart decent human beings\", according to Koprince, and she traces Simon's style of comedy back to that of Menander, a playwright of ancient Greece. Menander, like Simon, also used average people in domestic life settings, and also blended humor and tragedy into his themes. Many of Simon's most memorable plays are built around two-character scenes, as in segments of \"California Suite\" and \"Plaza Suite\".\nBefore writing, Simon tried to create an image of his characters. He said that the play \"Star Spangled Girl\", which was a box-office failure, was \"the only play I ever wrote where I did not have a clear visual image of the characters in my mind as I sat down at the typewriter.\" Simon considered \"character building\" an obligation, stating that the \"trick is to do it skillfully\". While other writers have created vivid characters, they have not created nearly as many as Simon did: \"Simon has no peers among contemporary comedy playwrights\", stated biographer Robert Johnson.\nSimon's characters often amuse the audience with sparkling \"zingers\", made believable by Simon's skillful writing of dialogue. He reproduces speech so \"adroitly\" that his characters are usually plausible and easy for audiences to identify with and laugh at. His characters may also express \"serious and continuing concerns of mankind\u00a0... rather than purely topical material\". McGovern notes that his characters are always impatient \"with phoniness, with shallowness, with amorality\", adding that they sometimes express \"implicit and explicit criticism of modern urban life with its stress, its vacuity, and its materialism.\" However, Simon's characters are never seen thumbing their noses at society.\"\nThemes and genres.\nTheater critic John Lahr believes that Simon's primary theme is \"the silent majority\", many of whom are \"frustrated, edgy, and insecure\". Simon's characters are \"likable\" and easy for audiences to identify with. They often have difficult relationships in marriage, friendship or business, as they \"struggle to find a sense of belonging\". According to biographer Edythe McGovern, there is always \"an implied seeking for solutions to human problems through relationships with other people, [and] Simon is able to deal with serious topics of universal and enduring concern\", while still making people laugh.\nMcGovern adds that one of Simon's hallmarks is his \"great compassion for his fellow human beings\", an opinion shared by author Alan Cooper, who observes that Simon's plays \"are essentially about friendships, even when they are about marriage or siblings or crazy aunts\u00a0...\"\nMany of Simon's plays are set in New York City, with a resulting urban flavor. Within that setting, Simon's themes include marital conflict, infidelity, sibling rivalry, adolescence, bereavement and fear of aging. Despite the serious nature of these ideas, Simon always manages to tell the stories with humor, embracing both realism and comedy. Simon would tell aspiring comedy playwrights \"not to try to make it funny\u00a0... try and make it real and then the comedy will come.\"\n\"When I was writing plays\", he said, \"I was almost always (with some exceptions) writing a drama that was funny\u00a0... I wanted to tell a story about real people.\" Simon explained how he managed this combination:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;My view is, \"how sad and funny life is.\" I can't think of a humorous situation that does not involve some pain. I used to ask, \"What is a funny situation?\" Now I ask, \"What is a sad situation and how can I tell it humorously?\"\nHis comedies often portray struggles with marital difficulties or fading love, sometimes leading to separation, divorce and child custody issues. After many twists in the plot, the endings typically show renewal of the relationships.\nPolitics seldom plays in Simon's stories, and his characters avoid confronting society as a whole, despite their personal problems. \"Simon is simply interested in showing human beings as they are\u2014with their foibles, eccentricities, and absurdities.\" Drama critic Richard Eder noted that Simon's popularity relies on his ability to portray a \"painful comedy\", where characters say and do funny things in extreme contrast to the unhappiness they are feeling.\nSimon's plays are generally semi-autobiographical, often portraying aspects of his troubled childhood and first marriages. According to Koprince, Simon's plays also \"invariably depict the plight of white middle-class Americans, most of whom are New Yorkers and many of whom are Jewish, like himself.\" He has said, \"I suppose you could practically trace my life through my plays.\" In \"Lost in Yonkers\", Simon suggests the necessity of a loving marriage (as opposed to his parents'), and how children who are deprived of it in their home, \"end up emotionally damaged and lost\".\nAccording to Koprince, Simon's Jewish heritage is a key influence on his work, although he is unaware of it when writing. For example, in the \"Brighton Beach\" trilogy, she explains, the lead character is a \"master of self-deprecating humor, cleverly poking fun at himself and at his Jewish culture as a whole.\" Simon himself has said that his characters are people who are \"often self-deprecating and [who] usually see life from the grimmest point of view\", explaining, \"I see humor in even the grimmest of situations. And I think it's possible to write a play so moving it can tear you apart and still have humor in it.\" This theme in writing, notes Koprince, \"belongs to a tradition of Jewish humor\u00a0... a tradition which values laughter as a defense mechanism and which sees humor as a healing, life-giving force.\"\nCritical response.\nDuring most of his career, Simon's work received mixed reviews, with many critics admiring his comedy skills, much of it a blend of \"humor and pathos\". Other critics were less complimentary, noting that much of his dramatic structure was weak and sometimes relied too heavily on gags and one-liners. As a result, notes Kopince, \"literary scholars had generally ignored Simon's early work, regarding him as a commercially successful playwright rather than a serious dramatist.\" Clive Barnes, theater critic for \"The New York Times\", wrote that like his British counterpart No\u00ebl Coward, Simon was \"destined to spend most of his career underestimated\", but nonetheless very \"popular\".\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nSimon towers like a Colossus over the American Theater. When Neil Simon's time comes to be judged among successful playwrights of the twentieth century, he will definitely be first among equals. No other playwright in history has had the run he has: fifteen \"Best Plays\" of their season.\n\u2014Lawrence Grobel\nThis attitude changed after 1991, when he won a Pulitzer Prize for drama with \"Lost in Yonkers\". McGovern writes that \"seldom has even the most astute critic recognized what depths really exist in the plays of Neil Simon.\" When \"Lost in Yonkers\" was considered by the Pulitzer Advisory Board, board member Douglas Watt noted that it was the only play nominated by all five jury members, and that they judged it \"a mature work by an enduring (and often undervalued) American playwright.\"\nMcGovern compares Simon with noted earlier playwrights, including Ben Jonson, Moli\u00e8re, and George Bernard Shaw, pointing out that those playwrights had \"successfully raised fundamental and sometimes tragic issues of universal and therefore enduring interest without eschewing the comic mode.\" She concludes, \"It is my firm conviction that Neil Simon should be considered a member of this company\u00a0... an invitation long overdue.\" McGovern attempts to explain the response of many critics:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Above all, his plays which may appear simple to those who never look beyond the fact that they are amusing are, in fact, frequently more perceptive and revealing of the human condition than many plays labeled complex dramas.\nSimilarly, literary critic Robert Johnson explains that Simon's plays have given us a \"rich variety of entertaining, memorable characters\" who portray the human experience, often with serious themes. Although his characters are \"more lifelike, more complicated and more interesting\" than most of the characters audiences see on stage, Simon has \"not received as much critical attention as he deserves.\" Lawrence Grobel, in fact, calls him \"the Shakespeare of his time\", and possibly the \"most successful playwright in history.\" He states:\nBroadway critic Walter Kerr tries to rationalize why Simon's work has been underrated:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Because Americans have always tended to underrate writers who make them laugh, Neil Simon's accomplishment have not gained as much serious critical praise as they deserve. His best comedies contain not only a host of funny lines, but numerous memorable characters and an incisively dramatized set of beliefs that are not without merit. Simon is, in fact, one of the finest writers of comedy in American literary history.\nPersonal life.\nSimon was married five times. For 20 years (1953\u201373), he was married to Joan Baim, a Martha Graham dancer; they had two daughters. Simon became a widower in 1973 when Baim died of bone cancer at age 41. One daughter, Ellen, wrote a semi-autobiographical play which was subsequently filmed as \"Moonlight and Valentino\". Simon married actress Marsha Mason (1973\u20131983), that same year. After his divorce from Mason, he married actress Diane Lander two separate times (1987\u20131988 and 1990\u20131998). He adopted Lander's daughter from a previous relationship. His subsequent marriage to actress Elaine Joyce in 1999 lasted until his death.\nSimon's nephew is U.S. District Judge Michael H. Simon and his niece-in-law is U.S. Congresswoman Suzanne Bonamici.\nSimon was on the board of selectors of Jefferson Awards for Public Service.\nIn 2004, Simon received a kidney transplant from his long-time friend and publicist Bill Evans.\nSimon died from pneumonia at New York-Presbyterian Hospital in Manhattan on August 26, 2018, while hospitalized for kidney failure. He was 91 and also had Alzheimer's disease.\nAwards and honors.\nSimon held three honorary degrees: a Doctor of Humane Letters from Hofstra University, a Doctor of Letters from Marquette University and a Doctor of Law from Williams College. In 1983 Simon became the only living playwright to have a New York City theatre named after him. The Alvin Theatre on Broadway was renamed the Neil Simon Theatre in his honor, and he was an honorary board of trustees member of the Walnut Street Theatre, Philadelphia, America's oldest theatre. Also in 1983, Simon was inducted into the American Theater Hall of Fame.\nIn 1965, he won the Tony Award for Best Playwright (\"The Odd Couple\"), and in 1975, a special Tony Award for his overall contribution to American theater. Simon won the 1978 Golden Globe Award for Best Motion Picture Screenplay for \"The Goodbye Girl\". For \"Brighton Beach Memoirs\" (1983), he was awarded the New York Drama Critics' Circle Award, followed by another Tony Award for Best Play of 1985, \"Biloxi Blues\". In 1991, he won the Pulitzer Prize along with the Tony Award for \"Lost in Yonkers\" (1991).\nThe Neil Simon Festival is a professional summer repertory theatre devoted to preserving the works of Simon and his contemporaries. The Neil Simon Festival was founded by Richard Dean Bugg in 2003.\nIn 2006, Simon received the Mark Twain Prize for American Humor.\nBibliography.\nTelevision.\n Television series \nSimon, as a member of a writing staff, penned material for the following shows:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n Movies made for television \nThe following made-for-TV movies were all written solely by Simon, and all based on his earlier plays or screenplays\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nTheatre.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n\u2020 marks musicals\nIn addition to these plays and musicals, Simon has twice rewritten or updated his 1965 play \"The Odd Couple\". Both updated versions have run under new titles: \"The Female Odd Couple\" (1985) and \"Oscar and Felix: A New Look at the Odd Couple\" (2002).\nScreenplays.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22050", "revid": "45230466", "url": "https://en.wikipedia.org/wiki?curid=22050", "title": "North American Free Trade Agreement", "text": "Trade bloc in North America (1994\u20132020)\nThe North American Free Trade Agreement (, TLCAN; , AL\u00c9NA), referred to colloquially in the Anglosphere as NAFTA, ( ) was an agreement signed by Canada, Mexico, and the United States that created a trilateral trade bloc in North America. The agreement came into force on January 1, 1994, and superseded the 1988 Canada\u2013United States Free Trade Agreement between the United States and Canada. The NAFTA trade bloc formed one of the largest trade blocs in the world by gross domestic product.\nThe impetus for a North American free trade zone began with U.S. president Ronald Reagan, who made the idea part of his 1980 presidential campaign. After the signing of the Canada\u2013United States Free Trade Agreement in 1988, the administrations of U.S. president George H. W. Bush, Mexican president Carlos Salinas de Gortari, and Canadian prime minister Brian Mulroney agreed to negotiate what became NAFTA. Each submitted the agreement for ratification in their respective capitals in December 1992, but NAFTA faced significant opposition in both the United States and Canada. All three countries ratified NAFTA in 1993 after the addition of two side agreements, the North American Agreement on Labor Cooperation (NAALC) and the North American Agreement on Environmental Cooperation (NAAEC).\nPassage of NAFTA resulted in the elimination or reduction of barriers to trade and investment between the United States, Canada, and Mexico. The effects of the agreement regarding issues such as employment, the environment, and economic growth have been the subject of political disputes. Most economic analyses indicated that NAFTA was beneficial to the North American economies and the average citizen, but harmed a small minority of workers in industries exposed to trade competition. Economists held that withdrawing from NAFTA or renegotiating NAFTA in a way that reestablished trade barriers would have adversely affected the U.S. economy and cost jobs. However, Mexico would have been much more severely affected by job loss and reduction of economic growth in both the short term and long term.\nAfter U.S. president Donald Trump took office in January 2017, he sought to replace NAFTA with a new agreement, beginning negotiations with Canada and Mexico. In September 2018, the United States, Mexico, and Canada reached an agreement to replace NAFTA with the United States\u2013Mexico\u2013Canada Agreement (USMCA), and all three countries had ratified it by March 2020. NAFTA remained in force until USMCA was implemented. In April 2020, Canada and Mexico notified the U.S. that they were ready to implement the agreement. The USMCA took effect on July 1, 2020, replacing NAFTA.\nNegotiation, signing, ratification, and revision (1988\u201394).\nNegotiation.\nThe impetus for a North American free trade zone began with U.S. president Ronald Reagan, who made the idea part of his campaign when he announced his candidacy for the presidency in November 1979. Canada and the United States signed the Canada\u2013United States Free Trade Agreement (FTA) in 1988, and shortly afterward Mexican president Carlos Salinas de Gortari decided to approach U.S. president George H. W. Bush to propose a similar agreement in an effort to bring in foreign investment following the Latin American debt crisis. As the two leaders began negotiating, the Canadian government under Prime Minister Brian Mulroney feared that the advantages Canada had gained through the Canada\u2013US FTA would be undermined by a US\u2013Mexican bilateral agreement, and asked to become a party to the US\u2013Mexican talks.\nSigning.\nFollowing diplomatic negotiations dating back to 1990, the leaders of the three nations signed the agreement in their respective capitals on December 17, 1992. The signed agreement then needed to be ratified by each nation's legislative or parliamentary branch.\nRatification.\nCanada.\nThe earlier Canada\u2013United States Free Trade Agreement had been controversial and divisive in Canada, and featured as an issue in the 1988 Canadian election. In that election, more Canadians voted for anti-free trade parties (the Liberals and the New Democrats), but the split of the votes between the two parties meant that the pro-free trade Progressive Conservatives (PCs) came out of the election with the most seats and so took power. Mulroney and the PCs had a parliamentary majority and easily passed the 1987 Canada\u2013US FTA and NAFTA bills. However, Mulroney was replaced as Conservative leader and prime minister by Kim Campbell. Campbell led the PC party into the 1993 election where they were decimated by the Liberal Party under Jean Chr\u00e9tien, who campaigned on a promise to renegotiate or abrogate NAFTA. Chr\u00e9tien subsequently negotiated two supplemental agreements with Bush, who had subverted the LAC advisory process and worked to \"fast track\" the signing prior to the end of his term, ran out of time and had to pass the required ratification and signing of the implementation law to incoming president Bill Clinton.\nUnited States.\nBefore sending it to the United States Senate, Clinton added two side agreements, the North American Agreement on Labor Cooperation (NAALC) and the North American Agreement on Environmental Cooperation (NAAEC), to protect workers and the environment, and to also allay the concerns of many House members. The U.S. required its partners to adhere to environmental practices and regulations similar to its own. After much consideration and emotional discussion, the U.S. House of Representatives passed the North American Free Trade Agreement Implementation Act on November 17, 1993, 234\u2013200. The agreement's supporters included 132 Republicans and 102 Democrats. The bill passed the Senate on November 20, 1993, 61\u201338. Senate supporters were 34 Republicans and 27 Democrats. Republican Representative David Dreier of California, a strong proponent of NAFTA since the Reagan administration, played a leading role in mobilizing support for the agreement among Republicans in Congress and across the country.\nChicago Congressman Luis Guti\u00e9rrez in particular was a vocal opponent of NAFTA, ultimately voting against the measure because of what he considered its failure to sufficiently provide for displaced worker retraining, protections against American job loss, and protections of collective bargaining rights for Mexican workers. He criticized the role of Rahm Emanuel in particular for the deficiencies.\nThe U.S. required its partners to adhere to environmental practices and regulations similar to its own.\nClinton signed it into law on December 8, 1993; the agreement went into effect on January 1, 1994. At the signing ceremony, Clinton recognized four individuals for their efforts in accomplishing the historic trade deal: Vice President Al Gore, Chairwoman of the Council of Economic Advisers Laura Tyson, Director of the National Economic Council Robert Rubin, and Republican Congressman David Dreier. Clinton also stated that \"NAFTA means jobs. American jobs, and good-paying American jobs. If I didn't believe that, I wouldn't support this agreement.\" NAFTA replaced the previous Canada-US FTA.\nMexico.\nNAFTA (TLCAN in Spanish) was approved by the Mexican Senate on November 22, 1993, and was published in the Official Gazette of the Federation on December 8, 1993.\nThe decree implementing NAFTA and the various changes to accommodate NAFTA in Mexican law was promulgated on December 14, 1993, with entry into force on January 1, 1994.\nProvisions.\nThe goal of NAFTA was to eliminate barriers to trade and investment between the United States, Canada and Mexico. The implementation of NAFTA on January 1, 1994, brought the immediate elimination of tariffs on more than one-half of Mexico's exports to the U.S. and more than one-third of U.S. exports to Mexico. Within 10 years of the implementation of the agreement, all U.S.\u2013Mexico tariffs were to be eliminated except for some U.S. agricultural exports to Mexico, to be phased out within 15 years. Most U.S.\u2013Canada trade was already duty-free. NAFTA also sought to eliminate non-tariff trade barriers and to protect the intellectual property rights on traded products.\nChapter 20 provided a procedure for the international resolution of disputes over the application and interpretation of NAFTA. It was modeled after Chapter 69 of the Canada\u2013United States Free Trade Agreement.\nNAFTA is, in part, implemented by Technical Working Groups composed of government officials from each of the three partner nations.\nIntellectual property.\nThe North American Free Trade Agreement Implementation Act made some changes to the copyright law of the United States, foreshadowing the Uruguay Round Agreements Act of 1994 by restoring copyright (within the NAFTA nations) on certain motion pictures which had entered the public domain.\nEnvironment.\nThe Clinton administration negotiated a side agreement on the environment with Canada and Mexico, the North American Agreement on Environmental Cooperation (NAAEC), which led to the creation of the Commission for Environmental Cooperation (CEC) in 1994. To alleviate concerns that NAFTA, the first regional trade agreement between a developing country and two developed countries, would have negative environmental impacts, the commission was mandated to conduct ongoing \"ex post\" environmental assessment, It created one of the first \"ex post\" frameworks for environmental assessment of trade liberalization, designed to produce a body of evidence with respect to the initial hypotheses about NAFTA and the environment, such as the concern that NAFTA would create a \"race to the bottom\" in environmental regulation among the three countries, or that NAFTA would pressure governments to increase their environmental protections. The CEC has held four symposia to evaluate the environmental impacts of NAFTA and commissioned 47 papers on the subject from leading independent experts.\nLabor.\nProponents of NAFTA in the United States emphasized that the pact was a free-trade, not an economic-community, agreement. The freedom of movement it establishes for goods, services and capital did not extend to labor. In proposing what no other comparable agreement had attempted\u2014to open industrialized countries to \"a major Third World country\"\u2014NAFTA eschewed the creation of common social and employment policies. The regulation of the labor market and or the workplace remained the exclusive preserve of the national governments.\nA \"side agreement\" on enforcement of existing domestic labor law, concluded in August 1993, the North American Agreement on Labour Cooperation (NAALC), was highly circumscribed. Focused on health and safety standards and on child labor law, it excluded issues of collective bargaining, and its \"so-called [enforcement] teeth\" were accessible only at the end of \"a long and tortuous\" disputes process\". Commitments to enforce existing labor law also raised issues of democratic practice. The Canadian anti-NAFTA coalition, Pro-Canada Network, suggested that guarantees of minimum standards would be \"meaningless\" without \"broad democratic reforms in the [Mexican] courts, the unions, and the government\". Later assessment, however, did suggest that NAALC's principles and complaint mechanisms did \"create new space for advocates to build coalitions and take concrete action to articulate challenges to the status quo and advance workers\u2019 interests\".\nAgriculture.\nFrom the earliest negotiation, agriculture was a controversial topic within NAFTA, as it has been with almost all free trade agreements signed within the WTO framework. Agriculture was the only section that was not negotiated trilaterally; instead, three separate agreements were signed between each pair of parties. The Canada\u2013U.S. agreement contained significant restrictions and tariff quotas on agricultural products (mainly sugar, dairy, and poultry products), whereas the Mexico\u2013U.S. pact allowed for a wider liberalization within a framework of phase-out periods (it was the first North\u2013South FTA on agriculture to be signed).\nTransportation infrastructure.\nNAFTA established the CANAMEX Corridor for road transport between Canada and Mexico, also proposed for use by rail, pipeline, and fiber optic telecommunications infrastructure. This became a High Priority Corridor under the U.S. Intermodal Surface Transportation Efficiency Act of 1991.\nChapter 11 \u2013 investor-state dispute settlement procedures.\nAnother contentious issue was the investor-state dispute settlement obligations contained in Chapter 11 of NAFTA. Chapter 11 allowed corporations or individuals to sue Mexico, Canada or the United States for compensation when actions taken by those governments (or by those for whom they are responsible at international law, such as provincial, state, or municipal governments) violated international law.\nThis chapter has been criticized by groups in the United States, Mexico, and Canada for a variety of reasons, including not taking into account important social and environmental considerations. In Canada, several groups, including the Council of Canadians, challenged the constitutionality of Chapter 11. They lost at the trial level and the subsequent appeal.\nMethanex Corporation, a Canadian corporation, filed a US$970 million suit against the United States. Methanex claimed that a California ban on methyl \"tert\"-butyl ether (MTBE), a substance that had found its way into many wells in the state, was hurtful to the corporation's sales of methanol. The claim was rejected, and the company was ordered to pay US$3 million to the U.S. government in costs, based on the following reasoning: \"But as a matter of general international law, a non-discriminatory regulation for a public purpose, which is enacted in accordance with due process and, which affects, inter alios, a foreign investor or investment is not deemed expropriatory and compensable unless specific commitments had been given by the regulating government to the then putative foreign investor contemplating investment that the government would refrain from such regulation.\"\nIn another case, Metalclad, an American corporation, was awarded US$15.6 million from Mexico after a Mexican municipality refused a construction permit for the hazardous waste landfill it intended to construct in Guadalc\u00e1zar, San Luis Potos\u00ed. The construction had already been approved by the federal government with various environmental requirements imposed (see paragraph 48 of the tribunal decision). The NAFTA panel found that the municipality did not have the authority to ban construction on the basis of its environmental concerns.\nIn Eli Lilly and Company v. Government of Canada the plaintiff presented a US$500 million claim for the way Canada requires usefulness in its drug patent legislation. Apotex sued the U.S. for US$520 million because of opportunity it says it lost in an FDA generic drug decision.\nLone Pine Resources Inc. v. Government of Canada filed a US$250 million claim against Canada, accusing it of \"arbitrary, capricious and illegal\" behaviour, because Quebec intends to prevent fracking exploration under the St. Lawrence Seaway.\nLone Pine Resources is incorporated in Delaware but headquartered in Calgary, and had an initial public offering on the NYSE May 25, 2011, of 15 million shares each for $13, which raised US$195 million.\nBarutciski acknowledged \"that NAFTA and other investor-protection treaties create an anomaly in that Canadian companies that have also seen their permits rescinded by the very same Quebec legislation, which expressly forbids the paying of compensation, do not have the right (to) pursue a NAFTA claim\", and that winning \"compensation in Canadian courts for domestic companies in this case would be more difficult since the Constitution puts property rights in provincial hands\".\nA treaty with China would extend similar rights to Chinese investors, including SOEs.\nChapter 19 \u2013 countervailing duty.\nNAFTA's Chapter 19 was a trade dispute mechanism which subjects antidumping and countervailing duty (AD/CVD) determinations to binational panel review instead of, or in addition to, conventional judicial review. For example, in the United States, review of agency decisions imposing antidumping and countervailing duties are normally heard before the U.S. Court of International Trade, an Article III court. NAFTA parties, however, had the option of appealing the decisions to binational panels composed of five citizens from the two relevant NAFTA countries. The panelists were generally lawyers experienced in international trade law. Since NAFTA did not include substantive provisions concerning AD/CVD, the panel was charged with determining whether final agency determinations involving AD/CVD conformed with the country's domestic law. Chapter 19 was an anomaly in international dispute settlement since it did not apply international law, but required a panel composed of individuals from many countries to re-examine the application of one country's domestic law.\nA Chapter 19 panel was expected to examine whether the agency's determination was supported by \"substantial evidence\". This standard assumed significant deference to the domestic agency. Some of the most controversial trade disputes in recent years, such as the U.S.\u2013Canada softwood lumber dispute, have been litigated before Chapter 19 panels.\nDecisions by Chapter 19 panels could be challenged before a NAFTA extraordinary challenge committee. However, an extraordinary challenge committee did not function as an ordinary appeal. Under NAFTA, it only vacated or remanded a decision if the decision involved a significant and material error that threatens the integrity of the NAFTA dispute settlement system. Since January 2006, no NAFTA party had successfully challenged a Chapter 19 panel's decision before an extraordinary challenge committee.\nAdjudication.\nThe roster of NAFTA adjudicators included many retired judges, such as Alice Desjardins, John Maxwell Evans, Constance Hunt, John Richard, Arlin Adams, Susan Getzendanner, George C. Pratt, Charles B. Renfrew and Sandra Day O'Connor.\nImpact.\nCanada.\nHistorical context.\nIn 2008, Canadian exports to the United States and Mexico were at $381.3 billion, with imports at $245.1 billion. According to a 2004 article by University of Toronto economist Daniel Trefler, NAFTA produced a significant net benefit to Canada in 2003, with long-term productivity increasing by up to 15 percent in industries that experienced the deepest tariff cuts. While the contraction of low-productivity plants reduced employment (up to 12 percent of existing positions), these job losses lasted less than a decade; overall, unemployment in Canada has fallen since the passage of the act. Commenting on this trade-off, Trefler said that the critical question in trade policy is to understand \"how freer trade can be implemented in an industrialized economy in a way that recognizes both the long-run gains and the short-term adjustment costs borne by workers and others\".\nA study in 2007 found that NAFTA had \"a substantial impact on international trade volumes, but a modest effect on prices and welfare\".\nAccording to a 2012 study, with reduced NAFTA trade tariffs, trade with the United States and Mexico only increased by a modest 11% in Canada compared to an increase of 41% for the U.S. and 118% for Mexico. Moreover, the U.S. and Mexico benefited more from the tariff reductions component, with welfare increases of 0.08% and 1.31%, respectively, with Canada experiencing a decrease of 0.06%.\nCurrent issues.\nAccording to a 2017 report by the New York City based public policy think tank report, Council on Foreign Relations (CFR), bilateral trade in agricultural products tripled in size from 1994 to 2017 and is considered to be one of the largest economic effects of NAFTA on U.S.-Canada trade with Canada becoming the U.S. agricultural sectors' leading importer. Canadian fears of losing manufacturing jobs to the United States did not materialize with manufacturing employment holding \"steady\". However, with Canada's labour productivity levels at 72% of U.S. levels, the hopes of closing the \"productivity gap\" between the two countries were also not realized.\nAccording to a 2018 Sierra Club report, Canada's commitments under NAFTA and the Paris agreement conflicted. The Paris commitments were voluntary, and NAFTA's were compulsory.\nAccording to a 2018 report by Gordon Laxter published by the Council of Canadians, NAFTA's Article 605, energy proportionality rule ensures that Americans had \"virtually unlimited first access to most of Canada's oil and natural gas\" and Canada could not reduce oil, natural gas and electricity exports (74% its oil and 52% its natural gas) to the U.S., even if Canada was experiencing shortages. These provisions that seemed logical when NAFTA was signed in 1993 are no longer appropriate. The Council of Canadians promoted environmental protection and was against NAFTA's role in encouraging development of the tar sands and fracking.\nUS President Donald Trump, angered by Canada's dairy tax of \"almost 300%\", threatened to leave Canada out of the NAFTA. Since 1972, Canada has been operating on a \"supply management\" system, which the United States is attempting to pressure it out of, specifically focusing on the dairy industry. However, this has not yet taken place, as Quebec, which holds approximately half the country's dairy farms, still supports supply management.\nMexico.\nMaquiladoras (Mexican assembly plants that take in imported components and produce goods for export) became the landmark of trade in Mexico. They moved to Mexico from the United States, hence the debate over the loss of American jobs. Income in the maquiladora sector had increased 15.5% since the implementation of NAFTA in 1994. Other sectors also benefited from the free trade agreement, and the share of exports to the U.S. from non-border states increased in the last five years while the share of exports from border states decreased. This allowed for rapid growth in non-border metropolitan areas such as Toluca, Le\u00f3n, and Puebla, which were all larger in population than Tijuana, Ciudad Ju\u00e1rez, and Reynosa.\nThe overall effect of the Mexico\u2013U.S. agricultural agreement is disputed. Mexico did not invest in the infrastructure necessary for competition, such as efficient railroads and highways. This resulted in more difficult living conditions for the country's poor. Mexico's agricultural exports increased 9.4 percent annually between 1994 and 2001, while imports increased by only 6.9 percent a year during the same period.\nOne of the most affected agricultural sectors was the meat industry. Mexico went from a small player in the pre-1994 U.S. export market to the second largest importer of U.S. agricultural products in 2004, and NAFTA may have been a major catalyst for this change. Free trade removed the hurdles that impeded business between the two countries, so Mexico provided a growing market for meat for the U.S., and increased sales and profits for the U.S. meat industry. A coinciding noticeable increase in the Mexican per capita GDP greatly changed meat consumption patterns as per capita meat consumption grew.\nOne of concerns raised by the implementation of NAFTA in Mexico was wealth inequality. National Bureau of Economic Research found that NAFTA increased the wage gap between the lowest and highest earners, directly affecting wealth inequality. According to Global Trade Watch, under NAFTA Mexico observed a decline in real average annual wages, with this decline mainly affecting those who earned the least - the real average wage of minimum wage workers decreased by 14 percent. GTW concluded that \"inflation-adjusted wages for virtually every category of Mexican worker decreased over NAFTA\u2019s first six years, even as hundreds of thousands of manufacturing jobs were being shifted from the United States to Mexico\".\nProduction of corn in Mexico increased since NAFTA. However, internal demand for corn had increased beyond Mexico's supply to the point where imports became necessary, far beyond the quotas Mexico originally negotiated. Zahniser &amp; Coyle pointed out that corn prices in Mexico, adjusted for international prices, have drastically decreased, but through a program of subsidies expanded by former president Vicente Fox, production remained stable since 2000. Reducing agricultural subsidies, especially corn subsidies, was suggested as a way to reduce harm to Mexican farmers.\nA 2001 \"Journal of Economic Perspectives\" review of the existing literature found that NAFTA was a net benefit to Mexico. By 2003, 80% of the commerce in Mexico was executed only with the U.S. The commercial sales surplus, combined with the deficit with the rest of the world, created a dependency in Mexico's exports. These effects were evident in the 2001 recession, which resulted in either a low rate or a negative rate in Mexico's exports.\nA 2005 study found that Mexico's welfare increased by 1.31% as a result of the NAFTA tariff reductions and that Mexico's intra-bloc trade increased by 118%. Inequality and poverty fell in the most globalization-affected regions of Mexico. 2013 and 2015 studies showed that Mexican small farmers benefited more from NAFTA than large-scale farmers.\nNAFTA had also been credited with the rise of the Mexican middle class. A Tufts University study found that NAFTA lowered the average cost of basic necessities in Mexico by up to 50%. This price reduction increased cash-on-hand for many Mexican families, allowing Mexico to graduate more engineers than Germany each year.\nGrowth in new sales orders indicated an increase in demand for manufactured products, which resulted in expansion of production and a higher employment rate to satisfy the increment in the demand. The growth in the maquiladora industry and in the manufacturing industry was of 4.7% in August 2016. Three quarters of the imports and exports are with the U.S.\nTufts University political scientist Daniel W. Drezner argued that NAFTA made it easier for Mexico to transform to a real democracy and become a country that views itself as North American. This has boosted cooperation between the United States and Mexico.\nUnited States.\nEconomists generally agreed that the United States economy benefited overall from NAFTA as it increased trade. In a 2012 survey of the Initiative on Global Markets' Economic Experts Panel, 95% of the participants said that, on average, U.S. citizens benefited from NAFTA while none said that NAFTA hurt US citizens, on average. A 2001 \"Journal of Economic Perspectives\" review found that NAFTA was a net benefit to the United States. A 2015 study found that US welfare increased by 0.08% as a result of NAFTA tariff reductions, and that US intra-bloc trade increased by 41%.\nA 2014 study on the effects of NAFTA on US trade jobs and investment found that between 1993 and 2013, the US trade deficit with Mexico and Canada increased from $17.0 to $177.2 billion, displacing 851,700 US jobs.\nIn 2015, the Congressional Research Service concluded that the \"net overall effect of NAFTA on the US economy appears to have been relatively modest, primarily because trade with Canada and Mexico accounts for a small percentage of US GDP. However, there were worker and firm adjustment costs as the three countries adjusted to more open trade and investment among their economies.\" The report also estimated that NAFTA added $80 billion to the US economy since its implementation, equivalent to a 0.5% increase in US GDP.\nThe US Chamber of Commerce credited NAFTA with increasing U.S. trade in goods and services with Canada and Mexico from $337 billion in 1993 to $1.2 trillion in 2011, while the AFL\u2013CIO blamed the agreement for sending 700,000 American manufacturing jobs to Mexico over that time.\nUniversity of California, San Diego economics professor Gordon Hanson said that NAFTA helped the US compete against China and therefore saved US jobs. While some jobs were lost to Mexico as a result of NAFTA, considerably more would have been lost to China if not for NAFTA.\nTrade balances.\nThe US had a trade surplus with NAFTA countries of $28.3 billion for services in 2009 and a trade deficit of $94.6 billion (36.4% annual increase) for goods in 2010. This trade deficit accounted for 26.8% of all US goods trade deficit. A 2018 study of global trade published by the Center for International Relations identified irregularities in the patterns of trade of NAFTA ecosystem using network theory analytical techniques. The study showed that the US trade balance was influenced by tax avoidance opportunities provided in Ireland.\nA study published in the August 2008 issue of the \"American Journal of Agricultural Economics\", found NAFTA increased US agricultural exports to Mexico and Canada, even though most of the increase occurred a decade after its ratification. The study focused on the effects that gradual \"phase-in\" periods in regional trade agreements, including NAFTA, have on trade flows. Most of the increases in members' agricultural trade, which was only recently brought under the purview of the World Trade Organization, was due to very high trade barriers before NAFTA or other regional trade agreements.\nInvestment.\nThe U.S. foreign direct investment (FDI) in NAFTA countries (stock) was $327.5 billion in 2009 (latest data available), up 8.8% from 2008. The US direct investment in NAFTA countries was in non-bank holding companies and the manufacturing, finance/insurance, and mining sectors. The foreign direct investment of Canada and Mexico in the United States (stock) was $237.2 billion in 2009 (the latest data available), up 16.5% from 2008.\nEconomy and jobs.\nIn their May 24, 2017 report, the Congressional Research Service (CRS) wrote that the economic impacts of NAFTA on the U.S. economy were modest. In a 2015 report, the Congressional Research Service summarized multiple studies as follows: \"In reality, NAFTA did not cause the huge job losses feared by the critics or the large economic gains predicted by supporters. The net overall effect of NAFTA on the U.S. economy appears to have been relatively modest, primarily because trade with Canada and Mexico accounts for a small percentage of U.S. GDP. However, there were worker and firm adjustment costs as the three countries adjusted to more open trade and investment among their economies.\"\nMany American small businesses depended on exporting their products to Canada or Mexico under NAFTA. According to the U.S. Trade Representative, this trade supported over 140,000 small- and medium-sized businesses in the US.\nAccording to University of California, Berkeley professor of economics Brad DeLong, NAFTA had an insignificant impact on US manufacturing. The adverse impact on manufacturing was exaggerated in US political discourse according to DeLong and Harvard economist Dani Rodrik.\nAccording to a 2013 article by Jeff Faux published by the Economic Policy Institute, California, Texas, Michigan and other states with high concentrations of manufacturing jobs were most affected by job loss due to NAFTA. According to a 2011 article by EPI economist Robert Scott, about 682,900 U.S. jobs were \"lost or displaced\" as a result of the trade agreement. More recent studies agreed with reports by the Congressional Research Service that NAFTA only had a modest impact on manufacturing employment and automation explained 87% of the losses in manufacturing jobs.\nEnvironment.\nAccording to a study in the \"Journal of International Economics\", NAFTA reduced pollution emitted by the US manufacturing sector: \"On average, nearly two-thirds of the reductions in coarse particulate matter (PM10) and sulfur dioxide (SO2) emissions from the U.S. manufacturing sector between 1994 and 1998 can be attributed to trade liberalization following NAFTA.\"\nAccording to the Sierra Club, NAFTA contributed to large-scale, export-oriented farming, which led to the increased use of fossil fuels, pesticides and GMO. NAFTA also contributed to environmentally destructive mining practices in Mexico. It prevented Canada from effectively regulating its tar sands industry, and created new legal avenues for transnational corporations to fight environmental legislation. In some cases, environmental policy was neglected in the wake of trade liberalization; in other cases, NAFTA's measures for investment protection, such as Chapter 11, and measures against non-tariff trade barriers threatened to discourage more vigorous environmental policy. The most serious overall increases in pollution due to NAFTA were found in the base metals sector, the Mexican petroleum sector, and the transportation equipment sector in the United States and Mexico, but not in Canada.\nMobility of persons.\nAccording to the Department of Homeland Security Yearbook of Immigration Statistics, during fiscal year 2006 (October 2005 \u2013 September 2006), 73,880 foreign professionals (64,633 Canadians and 9,247 Mexicans) were admitted into the United States for temporary employment under NAFTA (i.e., in the TN status). Additionally, 17,321 of their family members (13,136 Canadians, 2,904 Mexicans, as well as a number of third-country nationals married to Canadians and Mexicans) entered the U.S. in the treaty national's dependent (TD) status. Because DHS counts the number of the new I-94 arrival records filled at the border, and the TN-1 admission is valid for three years, the number of non-immigrants in TN status present in the U.S. at the end of the fiscal year is approximately equal to the number of admissions during the year. (A discrepancy may be caused by some TN entrants leaving the country or changing status before their three-year admission period has expired, while other immigrants admitted earlier may change their status \"to\" TN or TD, or extend TN status granted earlier).\nAccording to the International Organization for Migration, deaths of migrants have been on the rise worldwide with 5,604 deaths in 2016. An increased number of undocumented farmworkers in California may be due to the initial passing of NAFTA.\nCanadian authorities estimated that on December 1, 2006, 24,830 U.S. citizens and 15,219 Mexican citizens were in Canada as \"foreign workers\". These numbers include both entrants under NAFTA and those who entered under other provisions of Canadian immigration law. New entries of foreign workers in 2006 totalled 16,841 U.S. citizens and 13,933 Mexicans.\nDisputes and controversies.\n1992 U.S. presidential candidate Ross Perot.\nIn the second 1992 presidential debate, Ross Perot argued:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We have got to stop sending jobs overseas. It's pretty simple: If you're paying $12, $13, $14 an hour for factory workers and you can move your factory south of the border, pay a dollar an hour for labor,\u00a0... have no health care\u2014that's the most expensive single element in making a car\u2014have no environmental controls, no pollution controls and no retirement, and you don't care about anything but making money, there will be a giant sucking sound going south.\n ... when [Mexico's] jobs come up from a dollar an hour to six dollars an hour, and ours go down to six dollars an hour, and then it's leveled again. But in the meantime, you've wrecked the country with these kinds of deals.\nPerot ultimately lost the election, and the winner, Bill Clinton, supported NAFTA, which went into effect on January 1, 1994.\nLegal disputes.\nIn 1996, the gasoline additive MMT was brought to Canada by Ethyl Corporation, an American company when the Canadian federal government banned imports of the additive. The American company brought a claim under NAFTA Chapter 11 seeking US$201 million, from the Canadian federal government as well as the Canadian provinces under the Agreement on Internal Trade (AIT). They argued that the additive had not been conclusively linked to any health dangers, and that the prohibition was damaging to their company. Following a finding that the ban was a violation of the AIT, the Canadian federal government repealed the ban and settled with the American company for US$13 million. Studies by Health and Welfare Canada (now Health Canada) on the health effects of MMT in fuel found no significant health effects associated with exposure to these exhaust emissions. Other Canadian researchers and the U.S. Environmental Protection Agency disagreed citing studies that suggested possible nerve damage.\nThe United States and Canada argued for years over the United States' 27% duty on Canadian softwood lumber imports. Canada filed many motions to have the duty eliminated and the collected duties returned to Canada. After the United States lost an appeal before a NAFTA panel, spokesperson for U.S. Trade Representative Rob Portman responded by saying: \"we are, of course, disappointed with the [NAFTA panel's] decision, but it will have no impact on the anti-dumping and countervailing duty orders.\" On July 21, 2006, the United States Court of International Trade found that imposition of the duties was contrary to U.S. law.\nChange in income trust taxation not expropriation.\nOn October 30, 2007, American citizens Marvin and Elaine Gottlieb filed a Notice of Intent to Submit a Claim to Arbitration under NAFTA, claiming thousands of U.S. investors lost a total of $5 billion in the fall-out from the Conservative Government's decision the previous year to change the tax rate on income trusts in the energy sector. On April 29, 2009, a determination was made that this change in tax law was not expropriation.\nImpact on Mexican farmers.\nSeveral studies rejected NAFTA responsibility for depressing the incomes of poor corn farmers. The trend existed more than a decade before NAFTA existed. Also, maize production increased after 1994, and there wasn't a measurable impact on the price of Mexican corn because of subsidized corn from the United States. The studies agreed that the abolition of U.S. agricultural subsidies would benefit Mexican farmers.\nZapatista Uprising in Chiapas, Mexico.\nPreparations for NAFTA included cancellation of Article 27 of Mexico's constitution, the cornerstone of Emiliano Zapata's revolution in 1910\u20131919. Under the historic Article 27, indigenous communal landholdings were protected from sale or privatization. However, this barrier to investment was incompatible with NAFTA. Indigenous farmers feared the loss of their remaining land and cheap imports (substitutes) from the US. The Zapatistas labelled NAFTA a \"death sentence\" to indigenous communities all over Mexico and later declared war on the Mexican state on January 1, 1994, the day NAFTA came into force.\nCriticism from 2016 U.S. presidential candidates.\nIn a \"60 Minutes\" interview in September 2015, 2016 presidential candidate Donald Trump called NAFTA \"the single worst trade deal ever approved in [the United States]\", and said that if elected, he would \"either renegotiate it, or we will break it\". Juan Pablo Casta\u00f1\u00f3n, president of the trade group Consejo Coordinador Empresarial, expressed concern about renegotiation and the willingness to focus on the car industry. A range of trade experts said that pulling out of NAFTA would have a range of unintended consequences for the United States, including reduced access to its biggest export markets, a reduction in economic growth, and higher prices for gasoline, cars, fruits, and vegetables. Members of the private initiative in Mexico noted that to eliminate NAFTA, many laws must be adapted by the U.S. Congress. The move would also eventually result in legal complaints by the World Trade Organization. The \"Washington Post\" noted that a Congressional Research Service review of academic literature concluded that the \"net overall effect of NAFTA on the U.S. economy appears to have been relatively modest, primarily because trade with Canada and Mexico accounts for a small percentage of U.S. GDP\".\nDemocratic candidate Bernie Sanders, opposing the Trans-Pacific Partnership trade agreement, called it \"a continuation of other disastrous trade agreements, like NAFTA, CAFTA, and permanent normal trade relations with China\". He believes that free trade agreements have caused a loss of American jobs and depressed American wages. Sanders said that America needs to rebuild its manufacturing base using American factories for well-paying jobs for American labor rather than outsourcing to China and elsewhere.\nPolicy of the Trump administration.\nRenegotiation.\nShortly after his election, U.S. President Donald Trump said he would begin renegotiating the terms of NAFTA, to resolve trade issues he had campaigned on. The leaders of Canada and Mexico had indicated their willingness to work with the Trump administration. Although vague on the exact terms he sought in a renegotiated NAFTA, Trump threatened to withdraw from it if negotiations failed.\nIn July 2017, the Trump administration provided a detailed list of changes that it would like to see to NAFTA. The top priority was a reduction in the United States' trade deficit. The administration also called for the elimination of provisions that allowed Canada and Mexico to appeal duties imposed by the United States and limited the ability of the United States to impose import restrictions on Canada and Mexico.\nBeing \"consistent with the president's stance on liking trade barriers, liking protectionism\", Chad P. Bown of the Peterson Institute for International Economics suggested that the proposed changes would make NAFTA \"in many respects less of a free-trade agreement.\" Additional concerns expressed by the US Trade Representative over subsidized state-owned enterprises and currency manipulation were not thought to apply to Canada and Mexico, but were intended rather to send a message to countries beyond North America.\nJohn Murphy, vice-president of the U.S. Chamber of Commerce declared that a number of the proposals tabled by the United States had \"little or no support\" from the U.S. business and agriculture community.\" Pat Roberts, the senior U.S. senator from Kansas, said it was not clear \"who they're intended to benefit\", and called for push back against the anti-NAFTA moves as the \"issues affect real jobs, real lives and real people\". Kansas is a major agricultural exporter, and farm groups warned that just threatening to leave NAFTA might cause buyers to minimize uncertainty by seeking out non-US sources.\nA fourth round of talks included a U.S. demand for a sunset clause that would end the agreement in five years, unless the three countries agreed to keep it in place, a provision U.S. Commerce Secretary Wilbur Ross has said would allow the countries to kill the deal if it was not working. Canadian Prime Minister Justin Trudeau met with the House Ways and Means Committee, since Congress would have to pass legislation rolling back the treaty's provisions if Trump tries to withdraw from the pact.\nFrom June to late August 2018, Canada was sidelined as the United States and Mexico held bilateral talks. On 27 August 2018 Mexico and the United States announced they had reached a bilateral understanding on a revamped NAFTA trade deal that included provisions that would boost automobile production in the U.S., a 10-year data protection period against generic drug production on an expanded list of products that benefits pharmaceutical companies, particularly US makers producers of high-cost biologic drugs, a sunset clause\u2014a 16-year expiration date with regular 6-year reviews to possibly renew the agreement for additional 16-year terms, and an increased \"de minimis\" threshold in which Mexico raised the \"de minimis\" value to $100 from $50 regarding online duty- and tax-free purchases.\nAccording to an August 30 article in \"The Economist\", Mexico agreed to increase the rules of origin threshold which would mean that 75% as opposed to the previous 62.5% of a vehicle's components must be made in North America to avoid tariffs. Since car makers currently import less expensive components from Asia, under the revised agreement, consumers would pay more for vehicles. As well, approximately 40 to 45 per cent of vehicle components must be made by workers earning a minimum of US$16 per hour, in contrast to the current US$2.30 an hour that a worker earns on average in a Mexican car manufacturing plant. \"The Economist\" described this as placing \"Mexican carmaking into a straitjacket\".\nTrudeau and Canadian Foreign Minister Chrystia Freeland announced that they were willing to join the agreement if it was in Canada's interests. Freeland returned from her European diplomatic tour early, cancelling a planned visit to Ukraine, to participate in NAFTA negotiations in Washington, D.C. in late August. According to an August 31 \"Canadian Press\" published in the \"Ottawa Citizen\", key issues under debate included supply management, Chapter 19, pharmaceuticals, cultural exemption, the sunset clause, and \"de minimis\" thresholds.\nAlthough president Donald Trump warned Canada on September 1 that he would exclude them from a new trade agreement unless Canada submitted to his demands, it is not clear that the Trump administration had the authority to do so without the approval of Congress.\nOn September 30, 2018, the day of the deadline for the Canada\u2013U.S. negotiations, a preliminary deal between the two countries was reached, thus preserving the trilateral pact when the Trump administration submits the agreement before Congress. The new name for the agreement was the \"United States\u2014Mexico\u2014Canada Agreement\" (USMCA) and came into effect on July 1, 2020.\nImpact of withdrawing from NAFTA.\nFollowing Donald Trump's election to the presidency, a range of trade experts said that pulling out of NAFTA as Trump proposed would have a range of unintended consequences for the U.S., including reduced access to the U.S.'s biggest export markets, a reduction in economic growth, and increased prices for gasoline, cars, fruits, and vegetables. The worst affected sectors would be textiles, agriculture and automobiles.\nAccording to Tufts University political scientist Daniel W. Drezner, the Trump administration's desire to return relations with Mexico to the pre-NAFTA era are misguided. Drezner argued that NAFTA made it easier for Mexico to transform to a real democracy and become a country that views itself as North American. If Trump acts on many of the threats that he has made against Mexico, it is not inconceivable that Mexicans would turn to left-wing populist strongmen, as several South American countries have. At the very least, US-Mexico relations would worsen, with adverse implications for cooperation on border security, counterterrorism, drug-war operations, deportations and managing Central American migration.\nAccording to Chad P. Bown (senior fellow at the Peterson Institute for International Economics), \"a renegotiated NAFTA that would reestablish trade barriers is unlikely to help workers who lost their jobs\u2014regardless of the cause\u2014take advantage of new employment opportunities\".\nAccording to Harvard economist Marc Melitz, \"recent research estimates that the repeal of NAFTA would not increase car production in the United States\". Melitz noted that this would cost manufacturing jobs.\nTrans-Pacific Partnership.\nIf the original Trans-Pacific Partnership (TPP) had come into effect, existing agreements such as NAFTA would be reduced to those provisions that do not conflict with the TPP, or that require greater trade liberalization than the TPP. However, only Canada and Mexico would have the prospect of becoming members of the TPP after U.S. President Donald Trump withdrew the United States from the agreement in January 2017. In May 2017, the 11 remaining members of the TPP, including Canada and Mexico, agreed to proceed with a revised version of the trade deal without U.S. participation.\nAmerican public opinion on NAFTA.\nThe American public was largely divided on its view of the North American Free Trade Agreement (NAFTA), with a wide partisan gap in beliefs. In a February 2018 Gallup Poll, 48% of Americans said NAFTA was good for the U.S., while 46% said it was bad.\nAccording to a journal from the \"Law and Business Review of the Americas (LBRA)\", U.S. public opinion of NAFTA centers around three issues: NAFTA's impact on the creation or destruction of American jobs, NAFTA's impact on the environment, and NAFTA's impact on immigrants entering the U.S.\nAfter president Trump's election in 2016, support for NAFTA became very polarized between Republicans and Democrats. Donald Trump expressed negative views of NAFTA, calling it \"the single worst trade deal ever approved in this country\". Republican support for NAFTA decreased from 43% support in 2008 to 34% in 2017. Meanwhile, Democratic support for NAFTA increased from 41% support in 2008 to 71% in 2017.\nThe political gap was especially large in concern to views on free trade with Mexico. As opposed to a favorable view of free trade with Canada, whom 79% of American described as a fair trade partner, only 47% of Americans believed Mexico practices fair trade. The gap widened between Democrats and Republicans: 60% of Democrats believed Mexico is practicing fair trade, while only 28% of Republicans did. This was the highest level from Democrats and the lowest level from Republicans ever recorded by the Chicago Council Survey. Republicans had more negative views of Canada as a fair trade partner than Democrats as well.\nNAFTA had strong support from young Americans. In a February 2017 Gallup poll, 73% of Americans aged 18\u201329 said NAFTA was good for the U.S., showing higher support than any other U.S. age group. It also had slightly stronger support from unemployed Americans than from employed Americans.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22051", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=22051", "title": "National Lampoon (magazine)", "text": "American humor magazine\nNational Lampoon was an American humor magazine that ran from 1970 to 1998. The magazine started out as a spinoff from \"The Harvard Lampoon\".\n\"National Lampoon\" magazine reached its height of popularity and critical acclaim during the 1970s, when it had a far-reaching effect on American humor and comedy. The magazine spawned films, radio, live theater, various sound recordings, and print products including books. Many members of the publication's creative staff went on to contribute creatively to successful media of all types.\nThe magazine often featured parody and surrealist content. Its issues often had long and short written pieces, a section of actual news items (dubbed \"True Facts\"), cartoons, and comic strips. Most issues also included \"Foto Funnies\" or fumetti, which often featured nudity. The magazine declined during the late 1980s and ceased publication in 1998.\nProjects that use the \"National Lampoon\" (NL) brand name continued to be produced, but under its production company successor, National Lampoon, Inc. The 50th anniversary of the magazine took place in 2020 and, to celebrate, the magazine was issued digitally for the first time by Solaris Entertainment Studio.\nOverview.\n\"National Lampoon\" writers joyfully targeted every kind of phoniness, and had no specific political stance (even though individual staff members had strong political views). The magazine's humor often pushed far beyond the boundaries of what was generally considered appropriate and acceptable. It was especially anarchic, satirically attacking what was considered holy and sacred. As Teddy Wayne described it, \"At its peak, the [\"National Lampoon\"] produced some of the bleakest and most controlled furious humor in American letters.\"\nThomas Carney, writing in \"New Times\", traced the history and style of the \"National Lampoon\" and the impact it had on comedy's new wave. \"The \"National Lampoon\"\", Carney wrote, \"was the first full-blown appearance of non-Jewish humor in years\u2014not anti-Semitic, just non-Jewish. Its roots were W.A.S.P. and Irish Catholic, with a weird strain of Canadian detachment... This was not Jewish street-smart humor as a defense mechanism; this was slash-and-burn stuff that alternated in pitch but moved very much on the offensive. It was always disrespect everything, mostly yourself, a sort of reverse deism.\"\nP. J. O'Rourke, editor-in-chief of the magazine in 1978, went even further in his characterization of the magazine's humor:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;What we do is oppressor comedy... \"Woody Allen says, 'I'm just a regular shmuck like you.\" Our kind of comedy says, \"I'm O.K.; you\u2019re an asshole.\" We are ruling class. We are the insiders who have chosen to stand in the doorway and criticize the organization. Our comic pose is superior. It says, \"I\u2019m better than you and I'm going to destroy you.\" It\u2019s an offensive, very aggressive form of humor.\nThe magazine was a springboard to the cinema of the United States for a generation of comedy writers, directors, and performers. Various alumni went on to create and write for \"Saturday Night Live,\" \"The David Letterman Show\", \"SCTV\", \"The Simpsons\", \"Married... with Children\", \"Night Court\", and various films, including \"National Lampoon's Animal House\", \"Caddyshack\", \"National Lampoon's Vacation\", and \"Ghostbusters\". The characteristic humor of \"Spy\" magazine, \"The Onion\", Judd Apatow, Jon Stewart, and Stephen Colbert were all influenced by \"National Lampoon\".\nAs co-founder Henry Beard described the experience years later: \"There was this big door that said, 'Thou shalt not.' We touched it, and it fell off its hinges.\"\nThe magazine.\nPublication history.\n\"National Lampoon\" was started in 1969 by Harvard graduates and \"Harvard Lampoon\" alumni Douglas Kenney, Henry Beard, and Robert Hoffman, when they first licensed the \"Lampoon\" name for a monthly national publication. While still with \"The Harvard Lampoon\", in the years 1966 to 1969, Kenney and Beard had published a number of one-shot parodies of \"Playboy\", \"Life\", and Time magazines; they had also written the popular Tolkien parody book \"Bored of the Rings\".\nThe \"National Lampoon\"'s first issue, dated April 1970, went on sale on March 19, 1970. Kenney (editor) and Beard (executive editor) oversaw the magazine's content, while Hoffman (managing editor) handled legal and business negotiations. After a shaky start, the magazine rapidly grew in popularity. Like \"The Harvard Lampoon,\" individual issues had themes, including such topics as \"The Future\", \"Back to School\", \"Death\", \"Self-Indulgence\", and \"Blight\". The sixth issue (September 1970), entitled \"Show Biz\", got the company in hot water with The Walt Disney Company after a lawsuit was threatened because of the issue's cover, which showed a drawing of Minnie Mouse topless, wearing pasties.\nThe magazine's finest period was from 1971 to 1975 (the point at which Beard, Hoffman, and a number of the original creators departed). The \"National Lampoon\"'s most successful sales period was 1973\u201375: Its national circulation peaked at 1,000,096 copies sold of the October 1974 \"Pubescence\" issue. The 1974 monthly average was 830,000, which was also a peak.\nAlthough the glory days of \"National Lampoon\" ended in 1975, the magazine remained popular and profitable long after that point. As some of the original creators departed, the magazine saw the emergence of John Hughes and editor-in-chief P.J. O'Rourke, along with artists and writers such as Gerry Sussman, Ellis Weiner, Tony Hendra, Ted Mann, Peter Kleinman, Chris Cluess, Stu Kreisman, John Weidman, Jeff Greenfield, Bruce McCall, and Rick Meyerowitz.\n\"National Lampoon\" continued to be produced on a monthly schedule throughout the 1970s and the early 1980s, and did well during that time.\nA more serious decline set in around the mid-1980s: as described in a \"New York Times\" profile of the magazine from August 1984, \"circulation of the magazine [had] fallen from a high of 638,000 to about 450,000. Publishing revenues were down to $9 million in 1983 from $12.5 million in 1981.\"\nIn 1985, company CEO Matty Simmons took over as the magazine's editor-in-chief. He fired the entire editorial staff, and appointed his two sons, Michael and Andy Simmons, as editors, and Larry \"Ratso\" Sloman as executive editor. Peter Kleinman returned to the magazine as creative director and editor. That year, each monthly issue was devoted to a single topic, with the first being \"A Misguided Tour of New York.\" In November 1986, \"National Lampoon\" moved to a bimonthly schedule, publishing six issues a year instead of every month.\nJ2 Communications bought the magazine and its properties in 1990. In 1991, an attempt at monthly publication was made; nine issues were produced that year, and cartoonist Drew Friedman came on board as comics editor, introducing the works of Daniel Clowes and Chris Ware to a wider audience.\nAfter this, J2 decided instead to focus on licensing the \"National Lampoon\" brand, exhibiting very little interest in the actual magazine, only publishing it sporadically and erratically. To retain the rights to the Lampoon name, J2 was contractually obligated to publish only one new issue of the magazine per year, so for the rest of the 1990s the number of issues per year declined precipitously. Only two issues were released in 1992. This was followed by one issue in 1993, five in 1994, and three in 1995. For the last three years of its existence, the magazine was published only once a year. The final issue was published in 1998.\nIn 2007, in association with Graphic Imaging Technology, Inc., National Lampoon, Inc. released a collection of the entire 246 issues of the magazine in PDF format. The cover of the DVD box featured a remake of the January 1973 \"Death\" issue, with the caption altered to read \"If You Don't Buy This DVD-ROM, We'll Kill This Dog\". The pages are viewable on both Windows (starting with Windows 2000) and Macintosh (starting with OSX) systems.\nCover art.\nThe magazine's original art directors were cartoonist Peter Bramley and Bill Skurski, founders of New York's Cloud Studio, an alternative-culture outfit known at the time for its eclectic style. Bramley created the \"Lampoon\"'s first cover and induced successful cartoonists Arnold Roth and Gahan Wilson to become regular contributors.\nBeginning with the eighth issue, the art direction of the magazine was taken over by Michael C. Gross, who directed the look of the magazine until 1974. Gross achieved a unified, sophisticated, and integrated look for the magazine, which greatly enhanced its humorous appeal. A number of the \"National Lampoon\"'s most acerbic and humorous covers were designed or overseen by Gross, including:\nMichael Gross and Doug Kenney chose a young designer from \"Esquire\" named Peter Kleinman to succeed the team of Gross and David Kaestle. During his\" Lampoon\" tenure, Kleinman was also the art director of \"Heavy Metal\" magazine, published by the same company. The best known of Kleinman's \"Lampoon\" covers were \"Stevie Wonder with 3-D Glasses\" painted by Sol Korby, a photographed \"Nose to The Grindstone\" cover depicting a man's face being pressed against a spinning grinder wheel for the \"Work\" issue, the \"JFK's First 6000 Days\" issue featuring a portrait of an old John F. Kennedy, the \"Fat Elvis\" cover which appeared a year before Elvis Presley died, and many of the Mara McAfee covers done in a classic Norman Rockwell style. Kleinman designed the logos for \"Animal House\" and \"Heavy Metal.\" Kleinman left in 1979 to open an ad agency.\nHe was succeeded by Skip Johnson, the designer responsible for the \"Sunday Newspaper Parody\" and the \"Arab Getting Punched in the Face\" cover of the \"Revenge\" issue. Johnson went on to \"The New York Times.\" He was followed by Michael Grossman, who changed the logo and style of the magazine.\nIn 1984, Kleinman returned as creative director and went back to the 1970s logo and style, bringing back many of the artists and writers from the magazine's heyday. He left four years later to pursue a career in corporate marketing. At that time, the \"National Lampoon\" magazine entered a period of precipitous decline.\nStaff and contributors.\nThe magazine was an outlet for some notable writing and drawing talents. Rick Meyerowitz, a longtime contributor, broke down the magazine's talent in this fashion:\nOther important contributors included Chris Rush, Derek Pell, Chris Cluess, Al Jean, and Mike Reiss. The work of many important cartoonists, photographers, and illustrators appeared in the magazine's pages, including Neal Adams, John E. Barrett, Vaughn Bod\u0113, Peter Bramley, Chris Callis, Frank Frazetta, Edward Gorey, Rich Grote, Robert Grossman, Buddy Hickerson, Jeff Jones, John Jonik, Raymond Kursar, Andy Lackow, Birney Lettick, Bobby London, Mara McAfee, David C. K. McClelland, Marvin Mattelson, Joe Orlando, Ralph Reese, Warren Sattler, Michael Sullivan, B. K. Taylor, Boris Vallejo, Mimi Pond, and Gahan Wilson.\nFeatures.\nEditorials.\nEvery regular monthly issue of the magazine had an editorial at the front of the magazine. This often appeared to be straightforward but was always a parody. It was written by whoever was the editor of that particular issue, since that role rotated among the staff; Douglas Kenney had been the main writer of them for the first few issues. Some issues were guest-edited.\nTrue Facts.\n\"True Facts\" was a section near the front of the magazine that contained true but ridiculous items from real life. Together with the masthead, it was one of the few parts of the magazine that was factual. As was explained in the introduction to the \"True Facts\" 1981 newsstand special, the \"True Facts\" column was started in 1972 by Henry Beard, and it was based on a feature called \"True Stories\" in the British publication \"Private Eye\". It was essentially a column of funny news briefs.\nP. J. O'Rourke created the first \"True Facts Section\" in August 1977. This section included photographs of unintentionally funny signage, extracts from ludicrous newspaper reports, strange headlines, and so on.\nIn 1981 and for many subsequent years John Bendel was in charge of the \"True Facts\" section of the magazine. Bendel produced the 1981 newsstand special mentioned above. Several \"True Facts\" compilation books were published during the 1980s and early 90s, and several all-True-Facts issues of the magazine were published during the 1980s.\nIn the early 2000s, Steven Brykman edited the \"True Facts\" section of the National Lampoon website.\nFoto Funnies.\nMost issues of the magazine featured one or more \"Foto Funny\" or fumetti, comic strips that use photographs instead of drawings as illustrations. The characters who appeared in the Lampoon's Foto Funnies were usually the male writers, editors, artists, photographers, or contributing editors of the magazine, often cast alongside nude or semi-nude female models. In 1980, a paperback compilation book, \"National Lampoon Foto Funnies\" which appeared as a part of \"National Lampoon Comics\", was published.\nFunny Pages.\nThe \"Funny Pages\" was a large section at the back of the magazine that was composed entirely of comic strips of various kinds. These included work from a number of artists who also had pieces published in the main part of the magazine, including Gahan Wilson, Ed Subitzky and Vaughn Bod\u0113, as well as artists whose work was only published in this section. The regular strips included \"Dirty Duck\" by Bobby London, \"Trots and Bonnie\" by Shary Flenniken, \"The Appletons\" and \"Timberland Tales\" by B. K. Taylor, \"Politeness Man\" by Ron Barrett, and many other strips. A compilation of Gahan Wilson's \"Nuts\" strip was published in 2011. The \"Funny Pages\" logo header art, which was positioned above Gahan Wilson's \"Nuts\" in each issue, and showed a comfortable, old-fashioned family reading newspaper-sized funny papers, was drawn by Michael Kaluta.\nCorporate history.\nTwenty First Century Communications.\nThe company that owned and published the magazine was called Twenty First Century Communications, Inc. At the outset, Gerald L. \"Jerry\" Taylor was the magazine's publisher, followed by William T. Lippe. The business side was controlled by Matty Simmons, who was chairman of the board and CEO of Twenty First Century Communications.\n1973\u20131975 creative and commercial zenith.\nThe magazine was considered by many to be at its creative zenith in the period 1973\u20131975. During this period, the magazine regularly published \"special editions\" which were sold simultaneously on newsstands. Some of the special editions were \"best-of\" omnibus collections; others were entirely original. Additional projects included a calendar, a songbook, a collection of transfer designs for T-shirts, and a number of books. From time to time, the magazine advertised Lampoon-related merchandise for sale, including specially designed T-shirts. The magazine sold yellow binders with the Lampoon logo, designed to store a year's worth of issues.\nIt was also during this time that \"National Lampoon: Lemmings\" show was staged and \"The National Lampoon Radio Hour\" was broadcast, bringing interest and acclaim to the National Lampoon brand with magazine talent like writer Michael O'Donoghue. Comedy stars John Belushi, Chevy Chase, Gilda Radner, Bill Murray, Brian Doyle Murray, Harold Ramis, and Richard Belzer first gained national attention for their performances in those productions.\n1975 founders exit.\nIn 1975, the three founders Kenney, Beard, and Hoffman left the magazine, taking advantage of a buyout clause in their contracts for a shared total of $7.5 million (although Kenney remained on the magazine's masthead as a senior editor until about 1976).\nAt about the same time, writers Michael O'Donoghue and Anne Beatts left NL to join \"Saturday Night Live\", as did Chase, Belushi, and Radner, who left the troupe to join the original septet of \"SNL\"'s Not Ready For Prime Time Players. Bill Murray replaced Chase when Chase left \"SNL\" after the first season, and Brian Doyle Murray later appeared as an \"SNL\" regular.\nHarold Ramis went on to star in the Canadian sketch show \"SCTV\" and assumed the role as its head writer, then left after season 1 to be a prolific director, writer, and actor, working on such films as \"Animal House\", \"Caddyshack\", \"Ghostbusters\", \"Groundhog Day\" and many more. Brian Doyle Murray has had roles in dozens of films, and Belzer was an Emmy Award-winning TV actor.\n\"Heavy Metal\" / HM Communications.\nAfter a European trip in 1975 by Tony Hendra expressing interest in European comics, NL's New York offices attracted significant European comics material. In September 1976 editor Sean Kelly singled out the relatively new French anthology \"M\u00e9tal hurlant\" (lit.\u2009'Howling Metal', though Kelly translated it as \"Screaming Metal\") and brought it to the attention of Twenty First Century Communications, Inc. president Leonard Mogel, who was departing for Germany and France to jump-start the French edition of \"National Lampoon\". Upon Mogel's return from Paris, he reported that the French publishers had agreed to an English-language version.\n\"Heavy Metal\" debuted in the US with an April 1977 issue, as a glossy, full-color monthly published by HM Communications, Inc., a subsidiary of Twenty First Century Communications, Inc. The cover of the initial issue declared itself to be \"From the people who bring you the \"National Lampoon\"\", and the issue primarily featured reprints from \"M\u00e9tal hurlant\", as well as material from \"National Lampoon\". Since the color pages from \"M\u00e9tal hurlant\" had already been shot in France, the budget to reproduce them in the US version was greatly reduced.\n\"Animal House\" and shift of focus.\nIn 1978, after the huge success of \"National Lampoon's Animal House\", the company shifted focus from the magazine to NL-produced films. According to Tony Hendra, \"...Matty Simmons decided this particular goose could lay larger, better quality gold eggs if it emulated what he saw as \"Animal House,\" by which he meant adolescent... The significance of the choice that was made in 1978 cannot be underestimated.\" In late 1979, now only publishing \"National Lampoon\" and \"Heavy Metal\", Twenty First Century Communications, Inc. was renamed National Lampoon, Inc.\nFrom 1982 to 1985, the company produced five more National Lampoon films: \"National Lampoon's Class Reunion\" (1982), \"National Lampoon's Movie Madness\" (1982), \"National Lampoon's Vacation\" (1983), \"National Lampoon's Joy of Sex\" (1984), and \"National Lampoon's European Vacation\" (1985).\nNational Lampoon, Inc. made itself available for sale in late 1986. Upstart video distributor Vestron Inc. attempted a takeover bid in December of that year, but board members rejected the offer. A short time later, the company board \"agreed to be acquired by a Los Angeles-based group of private investors in a deal valued at more than $12 million.\" The group, calling itself \"N.L. Acquisitions Inc.\" offered a bid of $7.25 per share (the company stock at that point trading at $6.125 a share). A few days later, \"Giggle Acquisition Partnership No. 1,\" whose members included actor Bruce Willis, \"hinted ... that it might make a hostile bid\" for the company. Ultimately, nothing came of these bids, and Simmons remained in control of the board.\nIn 1989, the company produced \"National Lampoon's Christmas Vacation\".\nGrodnik/Matheson takeover.\nIn 1988\u20131989, the company was the subject of a hostile takeover. On December 29, 1988, film producer Daniel Grodnik and actor Tim Matheson (who had played \"Otter\" in the magazine's first big hit, the 1978 film \"National Lampoon's Animal House\") filed with the SEC that their production company, Grodnick/Matheson Co., had acquired voting control of 21.3 percent of National Lampoon Inc. stock and wanted to gain management control. They were named to the company's board in January 1989, and eventually took control of the company by purchasing the ten-percent share of Simmons, who departed the company.\nGrodnik and Matheson became the co-chairmen/co-CEOs. During their tenure, the stock went up from under $2 to $6, and the magazine was able to double its monthly ad pages. The company moved its headquarters from New York to Los Angeles to focus on film and television. The publishing operation stayed in New York.\nJ2 Communications era.\nIn 1990, Grodnik and Matheson sold the company (and more importantly, the rights to the brand name \"National Lampoon\") to J2 Communications (a company previously known for marketing Tim Conway's \"Dorf\" videos), headed by James P. Jimirro. According to Jimirro, at that point, National Lampoon was \"a moribund company that had been losing money since the early 1980s.\"\nThe property was considered valuable only as a brand name that could be licensed out to other companies. The magazine itself was issued erratically and rarely from 1991 onwards; its final print publication was November 1998. (Meanwhile, in May 1992, J2 Communications sold \"Heavy Metal\" to cartoonist and publisher Kevin Eastman.)\nIn 1991, J2 Communications began selling film rights to the \"National Lampoon\" name; it was paid for the use of the brand on such films as \"National Lampoon's Loaded Weapon 1\" (1993), \"National Lampoon's Senior Trip\" (1995), \"National Lampoon's Golf Punks\" (1998), \"National Lampoon's Van Wilder\" (2002), \"National Lampoon's Repli-Kate\" (2002), \"National Lampoon's Blackball\" (2003), and \"\" (2003). During this period, the company also licensed the Lampoon brand for five made-for-television movies, and one direct-to-video production. Although the licensing deals salvaged the company from bankruptcy, many believe it damaged National Lampoon's reputation as a source of respected comedy.\nIn 1998, the magazine contract was renegotiated and, in a sharp reversal, J2 Communications was then prohibited from publishing future issues. J2, however, still owned the rights to the brand name, which it continued to franchise out to other users.\nNational Lampoon Inc..\nIn 2002, the use of the Lampoon brand name and the rights to republish old material were sold to a group of investors headed by Dan Laikin and Paul Skjodt. They formed a new, and otherwise unrelated, company called National Lampoon, Inc. Jimirro stayed on as CEO, serving until 2005.\nLaikin aimed to revive the brand's heyday spirit, engaging original contributors like Matty Simmons and Chris Miller. The company expanded, acquiring Burly Bear Network and initiating original programming. However, financial losses persisted, reaching millions annually. Amid chaotic office scenes, Laikin's inclusive hiring fostered camaraderie but struggled to attract top talent. Despite efforts to stabilize and relocate to Hollywood, financial woes persisted. Laikin stepped down in 2008, replaced by investor Tim Durham, who faced scrutiny for lavish spending and questionable tactics. Scandals plagued leadership, including Laikin's stock manipulation scheme and Durham's Ponzi scheme involvement. Legal battles ensued, culminating in first Laikin and then Durham's imprisonment.\nIn 2012, Alan Donnes took over and revitalized the company, distancing it from controversies.\nPalmStar Media.\nPalmStar Media acquired National Lampoon in 2017. In 2020, National Lampoon sued its then-president, Evan Shapiro, for fraud, alleging in New York federal court that he owed more than $3 million for surreptitiously funneling the company's intellectual property and money from deals with Quibi, Disney+, and Comedy Central Digital into companies he controlled. Shapiro later claimed that National Lampoon Co-CEO Kevin Frakes had bullied him out of a job.\nRelated media.\nDuring its most active period, c. 1971\u2013c. 1980, the magazine spun off numerous productions in a wide variety of media, including books, special issues, anthologies, and other print pieces:\nRecordings.\nVinyl and cassette tapes.\nNational Lampoon's Animal House\", soundtrack album from the movie\nCDs.\nMany of the older albums that were originally on vinyl have been re-issued as CDs and a number of tracks from certain albums are available as MP3s.\nRadio.\nFormer \"Lampoon\" editor Tony Hendra later revived this format in 2012 for \"The Final Edition Radio Hour\", which became a podcast for National Lampoon, Inc. in 2015.\nFilms.\nConsiderable ambiguity exists about what actually constitutes a \"National Lampoon\" film.\nDuring the 1970s and early 1980s, a few films were made as spin-offs from the original \"National Lampoon\" magazine, using its creative staff. The first theatrical release, and by far the most successful \"National Lampoon\" film was \"National Lampoon's Animal House\" (1978). Starring John Belushi and written by Doug Kenney, Harold Ramis, and Chris Miller, it became the highest-grossing comedy film of that time. Produced on a low budget, it was so enormously profitable that, from that point on for the next two decades, the name \"National Lampoon\" applied to the title of a movie was considered to be a valuable selling point in and of itself.\nNumerous movies were subsequently made that had \"National Lampoon\" as part of the title. Many of these were unrelated projects because, by that time, the name \"National Lampoon\" could simply be licensed on a one-time basis, by any company, for a fee. Critics such as the \"Orlando Sentinel\"'s Roger Moore and \"The New York Times\"' Andrew Adam Newman have written about the cheapening of the \"National Lampoon\"'s movie imprimatur; in 2006, an Associated Press review said: \"The National Lampoon, once a brand name above nearly all others in comedy, has become shorthand for pathetic frat boy humor.\" (For the purpose of this article, only films made as spin-offs from the original \"National Lampoon\" magazine, using some of the magazine's creative staff to put together the outline and script, and/or were cast using actors from \"The National Lampoon Radio Hour\" and \"National Lampoon's Lemmings\" are considered.)\nIn 1978, \"National Lampoon's Animal House\" was released. Made on a small budget, it did phenomenally well at the box office. In 2001, the United States Library of Congress considered the film \"culturally significant\" and preserved it in the National Film Registry.\nThe script had its origins in a series of short stories that had been previously published in the magazine. These included Chris Miller's \"Night of the Seven Fires\", which dramatized a fraternity initiation and included the characters Pinto and Otter, which contained prose versions of the toga party, the \"road trip\", and the dead horse incident. Another source was Doug Kenney's \"First Lay Comics\", which included the angel and devil scene and the grocery-cart affair. According to the authors, most of these elements were based on real incidents.\nThe film was of great cultural significance to its time, as \"The New York Times\" describes the magazine's 1970s period as \"Hedonism ... in full sway and political correctness in its infancy.\" \"Animal House\", as the article describes, was a crucial film manifestation of that culture. An article from \"The Atlantic\" describes how \"Animal House\" captures the struggle between an \"elitist [fraternity] who willingly aligned itself with the establishment, and the kind full of kooks who refused to be tamed.\" That concept was a crucial element of the original \"National Lampoon\" magazine, according to a \"New York Times\" article concerning its early years and co-founder Douglas Kenney's brand of comedy as a \"liberating response to a rigid and hypocritical culture.\"\nAlso known as \"National Lampoon's Movie Madness\", this commercially disappointing collection of three genre parodies was made in 1981, before \"National Lampoon's Class Reunion\" but released the following year.\nThis 1982 movie was an attempt by John Hughes to make something similar to \"Animal House\". \"National Lampoon's Class Reunion\" was not successful.\nReleased in 1983, the movie \"National Lampoon's Vacation\" was based upon John Hughes's \"National Lampoon\" story \"Vacation '58\". The movie's financial success gave rise to several follow-up films, including \"National Lampoon's European Vacation\" (1985), \"National Lampoon's Christmas Vacation\" (1989), based on John Hughes's \"Christmas '59\", \"Vegas Vacation\" (1997), and most recently \"Vacation\" (2015), all starring Chevy Chase and Beverly D'Angelo.\nSimilar films.\nThe Robert Altman film \"O.C. and Stiggs\" (1987) was based on two characters who had been featured in several written pieces in \"National Lampoon\" magazine, including an issue-long story from October 1982 entitled \"The Utterly Monstrous, Mind-Roasting Summer of O.C. and Stiggs.\" Completed in 1984, the film was not released until 1987, when it was shown in a small number of theaters and without the \"National Lampoon\" name. It was not a success.\nFollowing the success of \"Animal House\", \"MAD\" magazine lent its name to a 1980 comedy titled \"Up the Academy\". Although two of \"Animal House\"'s co-writers were the \"Lampoon\"'s Doug Kenney and Chris Miller, \"Up The Academy\" was strictly a licensing maneuver, with no creative input from \"Mad\"'s staff or contributors. It was a critical and commercial failure.\nFilm about the magazine.\nIn 2015, a documentary film was released called \"\". The film featured a great deal of content from the magazine, as well as interviews with staff members and fans, and it explains how the magazine changed the course of humor.\nThe 2018 film \"A Futile and Stupid Gesture\", a biography of co-founder Douglas Kenney, also depicts the magazine's early years. The film was described by a 2018 \"New York Times\" article as a \"snapshot of a moment where comedy's freshest counter-culture impulse was gleefully crass and willfully offensive.\" In the same article, Kenney was said to \"spot a comical hollowness and rot in the society he and his peers were trained to join.\"\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22052", "revid": "191875", "url": "https://en.wikipedia.org/wiki?curid=22052", "title": "Non-disclosure agreement", "text": "Contractual agreement not to disclose specified information\nA non-disclosure agreement (NDA), also known as a confidentiality agreement (CA), confidential disclosure agreement (CDA), proprietary information agreement (PIA), or secrecy agreement (SA), is a legal contract or part of a contract between at least two parties that outlines confidential material, knowledge, or information that the parties wish to share with one another for certain purposes, but wish to restrict access to. Doctor\u2013patient confidentiality (physician\u2013patient privilege), attorney\u2013client privilege, priest\u2013penitent privilege and bank\u2013client confidentiality agreements are examples of NDAs, which are often not enshrined in a written contract between the parties.\nIt is a contract through which the parties agree not to disclose any information covered by the agreement. An NDA creates a confidential relationship between the parties, typically to protect any type of confidential and proprietary information or trade secrets. As such, an NDA protects non-public business information. Like all contracts, they cannot be enforced if the contracted activities are illegal. NDAs are commonly signed when two companies, individuals, or other entities (such as partnerships, societies, etc.) are considering doing business and need to understand the processes used in each other's business for the purpose of evaluating the potential business relationship. NDAs can be \"mutual\", meaning both parties are restricted in their use of the materials provided, or they can restrict the use of materials by a single party. An employee can be required to sign an NDA or NDA-like agreement with an employer, protecting trade secrets. In fact, some employment agreements include a clause restricting employees' use and dissemination of company-owned confidential information. In legal disputes resolved by settlement, the parties often sign a confidentiality agreement relating to the terms of the settlement. Examples of such agreements are The Dolby Trademark Agreement with Dolby Laboratories, the Windows Insider Agreement, and the Halo CFP (Community Feedback Program) with Microsoft.\nIn some cases, employees who are dismissed following their complaints about unacceptable practices (whistleblowers), or discrimination against and harassment of themselves, may be paid compensation subject to an NDA forbidding them from disclosing the events complained about. Such conditions in an NDA may not be enforceable by law, although they may intimidate the former employee into silence.\nA similar concept is expressed in the term \"non-disparagement agreement\", which prevents one party from stating anything \"derogatory\" about the other party.\nGeneral types.\nA non-disclosure agreement (NDA) may be classified as unilateral, bilateral, or multilateral:\nUnilateral.\nA \"unilateral NDA\", sometimes referred to as a \"one-way NDA\", involves two parties where only one party (i.e., the disclosing party) anticipates disclosing certain information to the other party (i.e., the receiving party) and requires that the information be protected from further disclosure for some reason (e.g., maintaining the secrecy necessary to satisfy patent laws or legal protection for trade secrets, limiting disclosure of information prior to issuing a press release for a major announcement, or simply ensuring that a receiving party does not use or disclose information without compensating the disclosing party).\nBilateral.\nA bilateral NDA (sometimes referred to as a mutual NDA, MNDA, or a two-way NDA) involves two parties where both parties anticipate disclosing information to one another that each intends to protect from further disclosure. This type of NDA is common for businesses considering some kind of joint venture or merger.\nWhen presented with a unilateral NDA, some parties may insist upon a bilateral NDA, even though they anticipate that only one of the parties will disclose information under the NDA. This approach is intended to incentivize the drafter to make the provisions in the NDA more \"fair and balanced\" by introducing the possibility that a receiving party could later become a disclosing party or vice versa, which is not an entirely uncommon occurrence.\nMultilateral.\nA multilateral NDA involves three or more parties where at least one of the parties anticipates disclosing information to the other parties and requires that the information be protected from further disclosure. This type of NDA eliminates the need for separate unilateral or bilateral NDAs between only two parties. E.g., a single multiparty NDA entered into by three parties who each intend to disclose information to the other two parties could be used in place of three separate bilateral NDAs between the first and second parties, second and third parties, and third and first parties.\nA multilateral NDA can be advantageous because the parties involved review, execute, and implement just one agreement. This advantage can be offset by more complex negotiations that may be required for the parties involved to reach a unanimous consensus on a multilateral agreement.\nContent.\nA NDA can protect any type of information that is not generally known. They may also contain clauses that will protect the person receiving the information so that if they lawfully obtained the information through other sources they would not be obligated to keep the information secret. In other words, the NDA typically only requires the receiving party to maintain information in confidence when that information has been directly supplied by the disclosing party\nSome common issues addressed in an NDA include:\nAbuse of NDAs.\nWhile the purpose of NDAs is to prevent disclosure of confidential information, they are very often misused by powerful companies and people to prevent employees who have been abused, often sexually, harassed, or discriminated against from disclosing the fact, usually in return for payment. There have been high-profile cases linked to the #MeToo movement, and many cases involving workers in regular employment, who do not have the financial means or confidence to challenge their employers' \"gagging orders\".\nFor example, employees suffering abuse by Harvey Weinstein, co-founder and at the time co-chairman of Miramax Films, were forced to negotiate a non-disclosure agreement with Miramax with terms that prohibited them not only from public disclosure, but also from speaking to a doctor, counsellor or accountant without them also signing an NDA, which the employees would be held accountable to if a third party broke it. They were required to use their \"best endeavours\" not to disclose anything in a civil or criminal case brought against Weinstein.\nIn the United Kingdom there were plans from 2018 to introduce legislation to make confidentiality clauses in settlement agreements prohibiting a worker from making an allegation of harassment or discrimination null and void. In 2025 a bill progressing through Parliament would ban such clauses, while not banning legitimate commercial use to protect commercially sensitive information or intellectual property in business transactions.\nLaw and practice by jurisdiction.\nAustralia.\nDeeds of confidentiality and fidelity (also referred to as deeds of confidentiality or confidentiality deeds) are commonly used in Australia. These documents generally serve the same purpose as and contain provisions similar to NDAs used elsewhere.\nIndia.\nNDAs are used in India. They have been described as \"an increasingly popular way of restricting the loss of R&amp;D knowledge through employee turnover in Indian IT firms\". They are often used by companies from other countries who are outsourcing or offshoring work to companies in India. Companies outsourcing research and development of biopharma to India use them, and Indian companies in pharmaceuticals are \"competent\" in their use. In the space industry, NDAs \"are crucial\". \"Non-disclosure and confidentiality agreements ... are ... generally enforceable as long as they are reasonable.\" Sometimes NDAs have been anti-competitive and this has led to legal challenges.\nUnited Kingdom.\nIn the United Kingdom, the term \"back-to-back agreement\" refers to an NDA entered into with a third party who legitimately receives confidential information, putting them under similar non-disclosure obligations as the initial party granted the information. Case law in a 2013 Court of Appeal decision (\"Dorchester Project Management v BNP Paribas\") confirmed that a confidentiality agreement will be interpreted as a contract subject to the rules of contractual interpretation which generally apply in English courts.\nNDAs are often used as a condition of a financial settlement in an attempt to silence whistleblowing employees from making public the misdeeds of their former employers. There is a law, the Public Interest Disclosure Act 1998, which allows \"protected disclosure\" despite the existence of an NDA, although employers sometimes intimidate the former employee into silence despite this.\nIn some legal cases where the conditions of a confidentiality agreement have been breached, the successful party may choose between damages based on an account of the commercial profits which might have been earned if the agreement had been honoured, or damages based on the price of releasing the other party from its obligations under the agreement.\nCommercial entities entering into confidentiality agreements need to ensure that the scope of their agreement does not go beyond what is necessary to protect commercial information. In the case of \"Jones v Ricoh\", heard by the High Court in 2010, Jones brought an action against the photocopier manufacturer Ricoh for breach of their confidentiality agreement when Ricoh submitted a tender for a contract with a third party. Ricoh sought release from its obligations under the agreement via an application for summary judgment, and the court agreed that the relevant wording \"went further than could reasonably be required\" to protect commercial information. The agreement was held to be in breach of Article 101 of the Treaty on the Functioning of the European Union, which prohibits agreements which had the object or effect of distorting competition, and was therefore unenforceable.\nAs of 2025[ [update]] NDAs have long been misused in the UK to prevent people, usually employees, from reporting sexual and other abuse they have suffered. Parliament has consulted regarding proposed legislation to curb such use, with a debate on the use of NDAs by employers to cover up workplace abuse and discrimination. In July 2025 a bill progressing through Parliament would make confidentiality clauses in settlement agreements prohibiting a worker from making an allegation of harassment or discrimination null and void, while not banning legitimate commercial use to protect commercially sensitive information or intellectual property in business transactions. A survey of employers found that 48% of employers would support a ban, 18% opposed, 20% were ambivalent, and 14% did not know.\nIreland.\nIn Ireland, confidentiality agreements or non-disclsure agreements are affected by the Maternity Protection, Employment Equality and Preservation of Certain Records Act 2024.\nThe Act amends the Employment Equality Act 1998 by restricting the use of non-disclosure agreements (NDA).\nThe 2024 Act renders void any NDA that prohibits an employee from disclosing:\nUnited States.\nNDAs are very common in the United States, with more than one-third of jobs in America containing an NDA. Researchers estimate that between 33% and 57% of U.S. workers are constrained by an NDA or similar mechanism. The United States Congress passed the Speak Out Act in 2022, which prohibits them in regard to sexual harassment and sexual assault, and the bill was signed into law by President Joe Biden on December 7, 2022.\nSome states, including California, recognise special circumstances relating to NDAs and non-compete clauses. California's courts and legislature have signalled that they generally value an employee's mobility and entrepreneurship more highly than they do protectionist doctrine. California is also among five states outlawing NDAs in instances of child sexual abuse. In Missouri and Texas, this ban is known as Trey's Law, named after Trey Carlock, a Dallas resident who attended Kanakuk Kamps as a child. He took his own life after suffering abuse at the hands of a counselor.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "22053", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=22053", "title": "Network effect", "text": "Increasing value with increasing participation\nIn economics, a network effect (also called network externality or demand-side economies of scale) is the phenomenon by which the value or utility a user derives from a good or service depends on the number of users of compatible products. Network effects are typically positive feedback systems, resulting in users deriving more and more value from a product as more users join the same network. The adoption of a product by an additional user can be broken into two effects: an increase in the value to all other users (\"total effect\") and also the enhancement of other non-users' motivation for using the product (\"marginal effect\").\nNetwork effects can be direct or indirect. Direct network effects arise when a given user's utility increases with the number of other users of the same product or technology, meaning that adoption of a product by different users is complementary. This effect is separate from effects related to price, such as a benefit to existing users resulting from price decreases as more users join. Direct network effects can be seen with social networking services, including Twitter, Facebook, Airbnb, Uber, and LinkedIn; telecommunications devices like the telephone; and instant messaging services such as MSN, AIM or QQ. Indirect (or cross-group) network effects arise when there are \"at least two different customer groups that are interdependent, and the utility of at least one group grows as the other group(s) grow\". For example, hardware may become more valuable to consumers with the growth of compatible software.\nNetwork effects are commonly mistaken for economies of scale, which describe decreasing average production costs in relation to the total volume of units produced. Economies of scale are a common phenomenon in traditional industries such as manufacturing, whereas network effects are most prevalent in new economy industries, particularly information and communication technologies. Network effects are the demand side counterpart of economies of scale, as they function by increasing a customer's willingness to pay due rather than decreasing the supplier's average cost.\nUpon reaching critical mass, a bandwagon effect can result. As the network continues to become more valuable with each new adopter, more people are incentivised to adopt, resulting in a positive feedback loop. Multiple equilibria and a market monopoly are two key potential outcomes in markets that exhibit network effects. Consumer expectations are key in determining which outcomes will result.\nOrigins.\nNetwork effects were a central theme in the arguments of Theodore Vail, the first post-patent president of Bell Telephone, in gaining a monopoly on US telephone services. In 1908, when he presented the concept in Bell's annual report, there were over 4,000 local and regional telephone exchanges, most of which were eventually merged into the Bell System.\nNetwork effects were popularized by Robert Metcalfe, stated as Metcalfe's law. Metcalfe was one of the co-inventors of Ethernet and a co-founder of the company 3Com. In selling the product, Metcalfe argued that customers needed Ethernet cards to grow above a certain critical mass if they were to reap the benefits of their network. According to Metcalfe, the rationale behind the sale of networking cards was that the cost of the network was directly proportional to the number of cards installed, but the value of the network was proportional to the square of the number of users. This was expressed algebraically as having a cost of N, and a value of N2. While the actual numbers behind this proposition were never firm, the concept allowed customers to share access to expensive resources like disk drives and printers, send e-mail, and eventually access the Internet.\nThe economic theory of the network effect was advanced significantly between 1985 and 1995 by researchers Michael L. Katz, Carl Shapiro, Joseph Farrell, and Garth Saloner. Author, high-tech entrepreneur Rod Beckstrom presented a mathematical model for describing networks that are in a state of positive network effect at BlackHat and Defcon in 2009 and also presented the \"inverse network effect\" with an economic model for defining it as well. Because of the positive feedback often associated with the network effect, system dynamics can be used as a modelling method to describe the phenomena. Word of mouth and the Bass diffusion model are also potentially applicable. The next major advance occurred between 2000 and 2003 when researchers Geoffrey G Parker, Marshall Van Alstyne, Jean-Charles Rochet and Jean Tirole independently developed the two-sided market literature showing how network externalities that cross distinct groups can lead to free pricing for one of those groups.\nEvidence and consequences.\nWhile the diversity of sources is in decline, there is a countervailing force of continually increasing functionality with new services, products and applications \u2014 such as music streaming services (Spotify), file sharing programs (Dropbox) and messaging platforms (Messenger, WhatsApp and Snapchat). Another major finding was the dramatic increase in the \"infant mortality\" rate of websites \u2014 with the dominant players in each functional niche - once established guarding their turf more staunchly than ever.\nOn the other hand, growing network effect does not always bring proportional increase in returns. Whether additional users bring more value depends on the commoditization of supply, the type of incremental user and the nature of substitutes. For example, social networks can hit an inflection point, after which additional users do not bring more value. This could be attributed to the fact that as more people join the network, its users are less willing to share personal content and the site becomes more focused on news and public content.\nEconomics.\nNetwork economics refers to business economics that benefit from the network effect. This is when the value of a good or service increases when others buy the same good or service. Examples are website such as EBay, or iVillage where the community comes together and shares thoughts to help the website become a better business organization.\nIn sustainability, network economics refers to multiple professionals (architects, designers, or related businesses) all working together to develop sustainable products and technologies. The more companies are involved in environmentally friendly production, the easier and cheaper it becomes to produce new sustainable products. For instance, if no one produces sustainable products, it is difficult and expensive to design a sustainable house with custom materials and technology. But due to network economics, the more industries are involved in creating such products, the easier it is to design an environmentally sustainable building.\nAnother benefit of network economics in a certain field is improvement that results from competition and networking within an industry.\nAdoption and competition.\nCritical mass.\nIn the early phases of a network technology, incentives to adopt the new technology are low. After a certain number of people have adopted the technology, network effects become significant enough that adoption becomes a dominant strategy. This point is called critical mass. At the critical mass point, the value obtained from the good or service is greater than or equal to the price paid for the good or service.\nWhen a product reaches critical mass, network effects will drive subsequent growth until a stable balance is reached. Therefore, a key business concern must then be how to attract users prior to reaching critical mass. Critical quality is closely related to consumer expectations, which will be affected by price and quality of products or services, the company's reputation and the growth path of the network. Thus, one way is to rely on extrinsic motivation, such as a payment, a fee waiver, or a request for friends to sign up. A more natural strategy is to build a system that has enough value \"without\" network effects, at least to early adopters. Then, as the number of users increases, the system becomes even more valuable and is able to attract a wider user base.\nLimits to growth.\nNetwork growth is generally not infinite, and tends to plateau when it reaches market saturation (all customers have already joined) or diminishing returns make acquisition of the last few customers too costly.\nNetworks can also stop growing or collapse if they do not have enough capacity to handle growth. For example, an overloaded phone network that has so many customers that it becomes congested, leading to busy signals, the inability to get a dial tone, and poor customer support. This creates a risk that customers will defect to a rival network because of the inadequate capacity of the existing system. After this point, each additional user decreases the value obtained by every other user.\nPeer-to-peer (P2P) systems are networks designed to distribute load among their user pool. This theoretically allows P2P networks to scale indefinitely. The P2P based telephony service Skype benefited from this effect and its growth was limited primarily by market saturation.\nMarket tipping.\nNetwork effects give rise to the potential outcome of market tipping, defined as \"the tendency of one system to pull away from its rivals in popularity once it has gained an initial edge\". Tipping results in a market in which only one good or service dominates and competition is stifled, and can result in a monopoly. This is because network effects tend to incentivise users to coordinate their adoption of a single product. Therefore, tipping can result in a natural form of market concentration in markets that display network effects. However, the presence of network effects does not necessarily imply that a market will tip; the following additional conditions must be met:\nIf any of these three conditions are not satisfied, the market may fail to tip and multiple products with significant market shares may coexist. One such example is the U.S. instant messaging market, which remained an oligopoly despite significant network effects. This can be attributed to the low multi-homing and switching costs faced by users.\nMarket tipping does not imply permanent success in a given market. Competition can be reintroduced into the market due to shocks such as the development of new technologies. Additionally, if the price is raised above customers' willingness to pay, this may reverse market tipping.\nMultiple equilibria and expectations.\nNetworks effects often result in multiple potential market equilibrium outcomes. The key determinant in which equilibrium will manifest are the expectations of the market participants, which are self-fulfilling. Because users are incentivised to coordinate their adoption, user will tend to adopt the product that they expect to draw the largest number of users. These expectations may be shaped by path dependence, such as a perceived first-mover advantage, which can result in lock-in. The most commonly cited example of path dependence is the QWERTY keyboard, which owes its ubiquity to its establishment of an early lead in the keyboard layout industry and high switching costs, rather than any inherent advantage over competitors. Other key influences of adoption expectations can be reputational (e.g. a firm that has previously produced high-quality products may be favoured over a new firm).\nMarkets with network effects may result in inefficient equilibrium outcomes. With simultaneous adoption, users may fail to coordinate towards a single agreed-upon product, resulting in splintering among different networks, or may coordinate to lock-in to a different product than the one that is best for them.\nTechnology lifecycle.\nIf some existing technology or company whose benefits are largely based on network effects starts to lose market share against a challenger such as a disruptive technology or open standards based competition, the benefits of network effects will reduce for the incumbent, and increase for the challenger. In this model, a tipping point is eventually reached at which the network effects of the challenger dominate those of the former incumbent, and the incumbent is forced into an accelerating decline, whilst the challenger takes over the incumbent's former position.\nSony's Betamax and Victor Company of Japan (JVC)'s video home system (VHS) can both be used for video cassette recorders (VCRs), but the two technologies are not compatible. Therefore, the VCR that is suitable for one type of cassette cannot fit in another. VHS's technology gradually surpassed Betamax in the competition. In the end, Betamax lost its original market share and was replaced by VHS.\nNegative network externalities.\nNegative network externalities, in the mathematical sense, are those that have a negative effect compared to normal (positive) network effects. Just as positive network externalities (network effects) cause positive feedback and exponential growth, negative network externalities are also caused by positive feedback resulting in exponential decay. Negative network effect must not be confused with negative feedback. Negative feedback is the forces that pull towards equilibrium and are responsible for stability.\n Therefore, congestion occurs when the efficiency of a network decreases as more people use it, and this reduces the value to people already using it. Traffic congestion that overloads the freeway and network congestion on connections with limited bandwidth both display negative network externalities.\nBraess's paradox suggests that adding paths through a network can have a negative effect on performance of the network.\nInteroperability.\nInteroperability has the effect of making the network bigger and thus increases the external value of the network to consumers. Interoperability achieves this primarily by increasing potential connections and secondarily by attracting new participants to the network. Other benefits of interoperability include reduced uncertainty, reduced lock-in, commoditization and competition based on price.\nInteroperability can be achieved through standardization or other cooperation. Companies involved in fostering interoperability face a tension between cooperating with their competitors to grow the potential market for products and competing for market share.\nCompatibility and incompatibility.\nProduct compatibility is closely related to network externalities in company's competition, which refers to two systems that can be operated together without changing. Compatible products are characterized by better matching with customers, so they can enjoy all the benefits of the network without having to purchase products from the same company. However, not only products of compatibility will intensify competition between companies, this will make users who had purchased products lose their advantages, but also proprietary networks may raise the industry entry standards. Compared to large companies with better reputation or strength, weaker companies or small networks will more inclined to choose compatible products.\nBesides, the compatibility of products is conducive to the company's increase in market share. For example, the Windows system is famous for its operating compatibility, thereby satisfying consumers' diversification of other applications. As the supplier of Windows systems, Microsoft benefits from indirect network effects, which cause the growing of the company's market share.\nIncompatibility is the opposite of compatibility. Because incompatibility of products will aggravate market segmentation and reduce efficiency, and also harm consumer interests and enhance competition. The result of the competition between incompatible networks depends on the complete sequential of adoption and the early preferences of the adopters. Effective competition determines the market share of companies, which is historically important. Since the installed base can directly bring more network profit and increase the consumers' expectations, which will have a positive impact on the smooth implementation of subsequent network effects.\nOpen versus closed standards.\nIn communication and information technologies, open standards and interfaces are often developed through the participation of multiple companies and are usually perceived to provide mutual benefit. But, in cases in which the relevant communication protocols or interfaces are closed standards, the network effect can give the company controlling those standards monopoly power. The Microsoft corporation is widely seen by computer professionals as maintaining its monopoly through these means. One observed method Microsoft uses to put the network effect to its advantage is called Embrace, extend and extinguish.\nMirabilis is an Israeli start-up which pioneered instant messaging (IM) and was bought by America Online. By giving away their ICQ product for free and preventing interoperability between their client software and other products, they were able to temporarily dominate the market for instant messaging. The IM technology has completed the use from the home to the workplace, because of its faster processing speed and simplified process characteristics. Because of the network effect, new IM users gained much more value by choosing to use the Mirabilis system (and join its large network of users) than they would use a competing system. As was typical for that era, the company never made any attempt to generate profits from its dominant position before selling the company.\nNetwork effect as a competitive advantage.\nNetwork effect can significantly influence the competitive landscape of an industry. According to Michael E. Porter, strong network effect might decrease the threat of new entrants, which is one of the five major competitive forces that act on an industry. Persistent barriers to entry into a market may help incumbent companies to fend off competition and keep or increase their market share, while maintaining profitability and return on capital.\nThese attractive characteristics are one of the reasons that allowed platform companies like Amazon, Google or Facebook to grow rapidly and create shareholder value. On the other hand, network effect can result in high concentration of power in an industry, or even a monopoly. This often leads to increased scrutiny from regulators that try to restore healthy competition, as is often the case with large technology companies.\nExamples.\nTelephone.\nNetwork effects are the incremental benefit gained by each user for each new user that joins a network. An example of a direct network effect is the telephone. Originally when only a small number of people owned a telephone the value it provided was minimal. Not only did other people need to own a telephone for it to be useful, but it also had to be connected to the network through the users home. As technology advanced it became more affordable for people to own a telephone. This created more value and utility due to the increase in users. Eventually increased usage through exponential growth led to the telephone is used by almost every household adding more value to the network for all users. Without the network effect and technological advances the telephone would have nowhere near the amount of value or utility as it does today.\nFinancial exchanges.\nTransactions in the financial field may feature a network effect. As the number of sellers and buyers in the exchange, who have the symmetric information increases, liquidity increases, and transaction costs decrease. This then attracts a larger number of buyers and sellers to the exchange.\nThe network advantage of financial exchanges is apparent in the difficulty that startup exchanges have in dislodging a dominant exchange. For example, the Chicago Board of Trade has retained overwhelming dominance of trading in US Treasury bond futures despite the startup of Eurex US trading of identical futures contracts. Similarly, the Chicago Mercantile Exchange has maintained dominance in trading of Eurobond interest rate futures despite a challenge from Euronext.Liffe.\nCryptocurrencies and blockchains.\nCryptocurrencies such as Bitcoin and smart contract blockchains such as Ethereum also exhibit network effects.\nSmart contract blockchains can produce network effects through the social network of individuals that uses a blockchain for securing its transactions. Public infrastructure networks such as Ethereum and others can facilitate entities that do not explicitly trust one another to collaborate in meaningful way, incentivizing growth in the network. However, as of 2019, such networks grow more slowly due to missing particular requirements such as privacy and scalability.\nSoftware.\nThe widely used computer software benefits from powerful network effects. The software-purchase characteristic is that it is easily influenced by the opinions of others, so the customer base of the software is the key to realizing a positive network effect. Although customers' motivation for choosing software is related to the product itself, media interaction and word-of-mouth recommendations from purchased customers can still increase the possibility of software being applied to other customers who have not purchased it, thereby resulting in network effects.\nIn 2007 Apple released the iPhone followed by the app store. Most iPhone apps rely heavily on the existence of strong network effects. This enables the software to grow in popularity very quickly and spread to a large userbase with very limited marketing needed. The Freemium business model has evolved to take advantage of these network effects by releasing a free version that will not limit the adoption or any users and then charge for premium features as the primary source of revenue. Furthermore, some software companies will launch free trial versions during the trial period to attract buyers and reduce their uncertainty. The duration of free time is related to the network effect. The more positive feedback the company received, the shorter the free trial time will be.\nSoftware companies (for example Adobe or Autodesk) often give significant discounts to students. By doing so, they intentionally stimulate the network effect - as more students learn to use a particular piece of software, it becomes more viable for companies and employers to use it as well. And the more employers require a given skill, the higher the benefit that employees will receive from learning it. This creates a self-reinforcing cycle, further strengthening the network effect.\nWeb sites.\nMany web sites benefit from a network effect. One example is web marketplaces and exchanges. For example, eBay would not be a particularly useful site if auctions were not competitive. As the number of users grows on eBay, auctions grow more competitive, pushing up the prices of bids on items. This makes it more worthwhile to sell on eBay and brings more sellers onto eBay, which, in turn, drives prices down again due to increased supply. Increased supply brings even more buyers to eBay. Essentially, as the number of users of eBay grows, prices fall and supply increases, and more and more people find the site to be useful.\nNetwork effects were used as justification in business models by some of the dot-com companies in the late 1990s. These firms operated under the belief that when a new market comes into being which contains strong network effects, firms should care more about growing their market share than about becoming profitable. The justification was that market share would determine which firm could set technical and marketing standards and giving these companies a first-mover advantage.\nSocial networking websites are good examples. The more people register onto a social networking website, the more useful the website is to its registrants.\nGoogle uses the network effect in its advertising business with its Google AdSense service. AdSense places ads on many small sites, such as blogs, using Google technology to determine which ads are relevant to which blogs. Thus, the service appears to aim to serve as an exchange (or ad network) for matching many advertisers with many small sites. In general, the more blogs AdSense can reach, the more advertisers it will attract, making it the most attractive option for more blogs.\nBy contrast, the value of a news site is primarily proportional to the quality of the articles, not to the number of other people using the site. Similarly, the first generation of search engines experienced little network effect, as the value of the site was based on the value of the search results. This allowed Google to win users away from Yahoo! without much trouble, once users believed that Google's search results were superior. Some commentators mistook the value of the Yahoo! brand (which does increase as more people know of it) for a network effect protecting its advertising business.\nRail gauge.\nThere are strong network effects in the initial choice of rail gauge, and in gauge conversion decisions. Even when placing isolated rails not connected to any other lines, track layers usually choose a standard rail gauge so they can use off-the-shelf rolling stock. Although a few manufacturers make rolling stock that can adjust to different rail gauges, most manufacturers make rolling stock that only works with one of the standard rail gauges. This even applies to urban rail systems where historically tramways and to a lesser extent metros would come in a wide array of different gauges, nowadays virtually all new networks are built to a handful of gauges and overwhelmingly standard gauge.\nCredit cards.\nFor credit cards that are now widely used, large-scale applications on the market are closely related to network effects. Credit card, as one of the currency payment methods in the current economy, which was originated in 1949. Early research on the circulation of credit cards at the retail level found that credit card interest rates were not affected by macroeconomic interest rates and remained almost unchanged. Later, credit cards gradually entered the network level due to changes in policy priorities and became a popular trend in payment in the 1980s. Different levels of credit cards separate benefit from two types of network effects. The application of credit cards related to external network effects, which is because when this has become a payment method, and more people use credit cards. Each additional person uses the same credit card, the value of rest people who use the credit card will increase. Besides, the credit card system at the network level could be seen as a two-sided market. On the one hand, the number of cardholders attracts merchants to use credit cards as a payment method. On the other hand, an increasing number of merchants can also attract more new cardholders. In other words, the use of credit cards has increased significantly among merchants which leads to increased value. This can conversely increase the cardholder's credit card value and the number of users. Moreover, credit card services also display a network effect between merchant discounts and credit accessibility. When credit accessibility increases which greater sales can be obtained, merchants are willing to be charged more discounts by credit card issuers.\nVisa has become a leader in the electronic payment industry through the network effect of credit cards as its competitive advantage. Till 2016, Visa's credit card market share has risen from a quarter to as much as half in four years. Visa benefits from the network effect. Since every additional Visa cardholder is more attractive to merchants, and merchants can also attract more new cardholders through the brand. In other words, the popularity and convenience of Visa in the electronic payment market, lead more people and merchants choose to use Visa, which greatly increases the value of Visa.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22054", "revid": "50604617", "url": "https://en.wikipedia.org/wiki?curid=22054", "title": "Nuclear fission", "text": "Nuclear reaction splitting an atom into multiple parts\nNuclear fission is a reaction in which the nucleus of an atom splits into two or more smaller nuclei. The fission process often produces gamma photons, and releases a very large amount of energy even by the energetic standards of radioactive decay.\nNuclear fission was discovered by chemists Otto Hahn and Fritz Strassmann and physicists Lise Meitner and Otto Robert Frisch. Hahn and Strassmann proved that a fission reaction had taken place on 19 December 1938, and Meitner and her nephew Frisch explained it theoretically in January 1939. Frisch named the process \"fission\" by analogy with biological fission of living cells. In their second publication on nuclear fission in February 1939, Hahn and Strassmann predicted the existence and liberation of additional neutrons during the fission process, opening up the possibility of a nuclear chain reaction.\nFor heavy nuclides, it is an exothermic reaction which can release large amounts of energy both as electromagnetic radiation and as kinetic energy of the fragments (heating the bulk material where fission takes place). Like nuclear fusion, for fission to produce energy, the total binding energy of the resulting elements must be greater than that of the starting element. The fission barrier must also be overcome. Fissionable nuclides primarily split in interactions with fast neutrons, while fissile nuclides easily split in interactions with \"slow\" i.e. thermal neutrons, usually originating from moderation of fast neutrons. \nFission is a form of nuclear transmutation because the resulting fragments (or daughter atoms) are not the same element as the original parent atom. The two (or more) nuclei produced are most often of comparable but slightly different sizes, typically with a mass ratio of products of about 3 to 2, for common fissile isotopes. Most fissions are binary fissions (producing two charged fragments), but occasionally (2 to 4 times per 1000 events), \"three\" positively charged fragments are produced, in a ternary fission. The smallest of these fragments in ternary processes ranges in size from a proton to an argon nucleus.\nApart from fission induced by an exogenous neutron, harnessed and exploited by humans, a natural form of spontaneous radioactive decay (not requiring an exogenous neutron, because the nucleus already has an overabundance of neutrons) is also referred to as fission, and occurs especially in very high-mass-number isotopes. Spontaneous fission was discovered in 1940 by Flyorov, Petrzhak, and Kurchatov in Moscow. In contrast to nuclear fusion, which drives the formation of stars and their development, one can consider nuclear fission as negligible for the evolution of the universe. Nonetheless, natural nuclear fission reactors may form under very rare conditions. Accordingly, all elements (with a few exceptions, see \"spontaneous fission\") which are important for the formation of solar systems, planets and also for all forms of life are not fission products, but rather the results of fusion processes.\nThe unpredictable composition of the products (which vary in a broad probabilistic and somewhat chaotic manner) distinguishes fission from purely quantum tunneling processes such as proton emission, alpha decay, and cluster decay, which give the same products each time. Nuclear fission produces energy for nuclear power and drives the explosion of nuclear weapons. Both uses are possible because certain substances called nuclear fuels undergo fission when struck by fission neutrons, and in turn emit neutrons when they break apart. This makes a self-sustaining nuclear chain reaction possible, releasing energy at a controlled rate in a nuclear reactor or at a very rapid, uncontrolled rate in a nuclear weapon.\nThe amount of free energy released in the fission of an equivalent amount of 235U is a million times more than that released in the combustion of methane or from hydrogen fuel cells.\nThe products of nuclear fission, however, are on average far more radioactive than the heavy elements which are normally fissioned as fuel, and remain so for significant amounts of time, giving rise to a nuclear waste problem. However, the seven long-lived fission products make up only a small fraction of fission products. Neutron absorption which does not lead to fission produces plutonium (from 238U) and minor actinides (from both 235U and 238U) whose radiotoxicity is far higher than that of the long lived fission products. Concerns over nuclear waste accumulation and the destructive potential of nuclear weapons are a counterbalance to the peaceful desire to use fission as an energy source. The thorium fuel cycle produces virtually no plutonium and much less minor actinides, but 232U - or rather its decay products - are a major gamma ray emitter. All actinides are fertile or fissile and fast breeder reactors can fission them all albeit only in certain configurations. Nuclear reprocessing aims to recover usable material from spent nuclear fuel to both enable uranium (and thorium) supplies to last longer and to reduce the amount of \"waste\". The industry term for a process that fissions all or nearly all actinides is a \"closed fuel cycle\".\nPhysical overview.\nMechanism.\nYounes and Loveland define fission as, \"...a collective motion of the protons and neutrons that make up the nucleus, and as such it is distinguishable from other phenomena that break up the nucleus. Nuclear fission is an extreme example of large-amplitude collective motion that results in the division of a parent nucleus into two or more fragment nuclei. The fission process can occur spontaneously, or it can be induced by an incident particle.\" The energy from a fission reaction is produced by its fission products, though a large majority of it, about 85 percent, is found in fragment kinetic energy, while about 6 percent each comes from initial neutrons and gamma rays and those emitted after beta decay, plus about 3 percent from neutrinos as the product of such decay.\nRadioactive decay.\nNuclear fission can occur without neutron bombardment as a type of radioactive decay. This type of fission is called spontaneous fission, and was first observed in 1940.\nNuclear reaction.\nDuring induced fission, a compound system is formed after an incident particle fuses with a target. The resultant excitation energy may be sufficient to emit neutrons, or gamma-rays, and nuclear scission. Fission into two fragments is called binary fission, and is the most common nuclear reaction. Occurring least frequently is ternary fission, in which a third particle is emitted. This third particle is commonly an \u03b1 particle. Since in nuclear fission, the nucleus emits more neutrons than the one it absorbs, a chain reaction is possible.\nBinary fission may produce any of the fission products, at 95\u00b115 and 135\u00b115 daltons. One example of a binary fission event in the most commonly used fissile nuclide, 235U, is given as:\nformula_1\nHowever, the binary process happens merely because it is the most probable. In anywhere from two to four fissions per 1000 in a nuclear reactor, ternary fission can produce three positively charged fragments (plus neutrons) and the smallest of these may range from so small a charge and mass as a proton (\"Z\"\u00a0=\u00a01), to as large a fragment as argon (\"Z\"\u00a0=\u00a018). The most common small fragments, however, are composed of 90% helium-4 nuclei with more energy than alpha particles from alpha decay (so-called \"long range alphas\" at ~16 megaelectronvolts (MeV)), plus helium-6 nuclei, and tritons (the nuclei of tritium). Though less common than binary fission, it still produces significant helium-4 and tritium gas buildup in the fuel rods of modern nuclear reactors.\nBohr and Wheeler used their liquid drop model, the packing fraction curve of Arthur Jeffrey Dempster, and Eugene Feenberg's estimates of nucleus radius and surface tension, to estimate the mass differences of parent and daughters in fission. They then equated this mass difference to energy using Einstein's mass-energy equivalence formula. The stimulation of the nucleus after neutron bombardment was analogous to the vibrations of a liquid drop, with surface tension and the Coulomb force in opposition. Plotting the sum of these two energies as a function of elongated shape, they determined the resultant energy surface had a saddle shape. The saddle provided an energy barrier called the critical energy barrier. Energy of about 6 MeV provided by the incident neutron was necessary to overcome this barrier and cause the nucleus to fission. According to John Lilley, \"The energy required to overcome the barrier to fission is called the \"activation energy\" or \"fission barrier\" and is about 6 MeV for \"A\"\u00a0\u2248\u00a0240. It is found that the activation energy decreases as A increases. Eventually, a point is reached where activation energy disappears altogether...it would undergo very rapid spontaneous fission.\"\nMaria Goeppert Mayer later proposed the nuclear shell model for the nucleus. The nuclides that can sustain a fission chain reaction are suitable for use as nuclear fuels. The most common nuclear fuels are 235U (the isotope of uranium with mass number 235 and of use in nuclear reactors) and 239Pu (the isotope of plutonium with mass number 239). These fuels break apart into a bimodal range of chemical elements with atomic masses centering near 95 and 135 daltons (fission products). Most nuclear fuels undergo spontaneous fission only very slowly, decaying instead mainly via an alpha-beta decay chain over periods of millennia to eons. In a nuclear reactor or nuclear weapon, the overwhelming majority of fission events are induced by bombardment with another particle, a neutron, which is itself produced by prior fission events.\nFissionable isotopes such as uranium-238 require additional energy provided by fast neutrons (such as those produced by nuclear fusion in thermonuclear weapons). While \"some\" of the neutrons released from the fission of 238U are fast enough to induce another fission in 238U, \"most\" are not, meaning it can never achieve criticality. While there is a very small (albeit nonzero) chance of a thermal neutron inducing fission in 238U, neutron absorption is orders of magnitude more likely.\nEnergetics.\nInput.\nFission cross sections are a measurable property related to the probability that fission will occur in a nuclear reaction. Cross sections are a function of incident neutron energy, and those for 235U and 239Pu are a million times higher than 238U at lower neutron energy levels. Absorption of any neutron makes available to the nucleus binding energy of about 5.3\u00a0MeV. 238U needs a fast neutron to supply the additional 1\u00a0MeV needed to cross the critical energy barrier for fission. In the case of 235U however, that extra energy is provided when 235U adjusts from an odd to an even mass. In the words of Younes and Lovelace, \"...the neutron absorption on a 235U target forms a 236U nucleus with excitation energy greater than the critical fission energy, whereas in the case of \"n\" + 238U, the resulting 239U nucleus has an excitation energy below the critical fission energy.\"\nAbout 6\u00a0MeV of the fission-input energy is supplied by the simple binding of an extra neutron to the heavy nucleus via the strong force; however, in many fissionable isotopes, this amount of energy is not enough for fission. Uranium-238, for example, has a near-zero fission cross section for neutrons of less than 1\u00a0MeV energy. If no additional energy is supplied by any other mechanism, the nucleus will not fission, but will merely absorb the neutron, as happens when 238U absorbs slow and even some fraction of fast neutrons, to become 239U. The remaining energy to initiate fission can be supplied by two other mechanisms: one of these is more kinetic energy of the incoming neutron, which is increasingly able to fission a fissionable heavy nucleus as it exceeds a kinetic energy of 1\u00a0MeV or more (so-called fast neutrons). Such high energy neutrons are able to fission 238U directly (see thermonuclear weapon for application, where the fast neutrons are supplied by nuclear fusion). However, this process cannot happen to a great extent in a nuclear reactor, as too small a fraction of the fission neutrons produced by any type of fission have enough energy to efficiently fission 238U. (For example, neutrons from thermal fission of 235U have a mean energy of 2\u00a0MeV, a median energy of 1.6\u00a0MeV, and a mode of 0.75\u00a0MeV, and the energy spectrum for fast fission is similar.)\nAmong the heavy actinide elements, however, those isotopes that have an odd number of neutrons (such as 235U with 143 neutrons) bind an extra neutron with an additional 1 to 2\u00a0MeV of energy over an isotope of the same element with an even number of neutrons (such as 238U with 146 neutrons). This extra binding energy is made available as a result of the mechanism of neutron pairing effects, which itself is caused by the Pauli exclusion principle, allowing an extra neutron to occupy the same nuclear orbital as the last neutron in the nucleus. In such isotopes, therefore, no neutron kinetic energy is needed, for all the necessary energy is supplied by absorption of any neutron, either of the slow or fast variety (the former are used in moderated nuclear reactors, and the latter are used in fast-neutron reactors, and in weapons).\nAccording to Younes and Loveland, \"Actinides like 235U that fission easily following the absorption of a thermal (25 meV) neutron are called \"fissile\", whereas those like 238U that do not easily fission when they absorb a thermal neutron are called \"fissionable\".\"\nOutput.\nAfter an incident particle has fused with a parent nucleus, if the excitation energy is sufficient, the nucleus breaks into fragments. This is called scission, and occurs at about 10\u221220 seconds. The fragments can emit prompt neutrons at between 10\u221218 and 10\u221215 seconds. At about 10\u221211 seconds, the fragments can emit gamma rays. At 10\u22123 seconds \u03b2 decay, \u03b2-delayed neutrons, and gamma rays are emitted from the decay products.\nTypical fission events release about two hundred million eV (200\u00a0MeV) of energy for each fission event. The exact isotope which is fissioned, and whether or not it is fissionable or fissile, has only a small impact on the amount of energy released. This can be easily seen by examining the curve of binding energy (image below), and noting that the average binding energy of the actinide nuclides beginning with uranium is around 7.6\u00a0MeV per nucleon. Looking further left on the curve of binding energy, where the fission products cluster, it is easily observed that the binding energy of the fission products tends to center around 8.5\u00a0MeV per nucleon. Thus, in any fission event of an isotope in the actinide mass range, roughly 0.9\u00a0MeV are released per nucleon of the starting element. The fission of 235U by a slow neutron yields nearly identical energy to the fission of 238U by a fast neutron. This energy release profile holds for thorium and the various minor actinides as well.\nWhen a uranium nucleus fissions into two daughter nuclei fragments, about 0.1 percent of the mass of the uranium nucleus appears as the fission energy of ~200\u00a0MeV. For uranium-235 (total mean fission energy 202.79\u00a0MeV), typically ~169\u00a0MeV appears as the kinetic energy of the daughter nuclei, which fly apart at about 3% of the speed of light, due to Coulomb repulsion. Also, an average of 2.5\u00a0neutrons are emitted, with a mean kinetic energy per neutron of ~2\u00a0MeV (total of 4.8\u00a0MeV). The fission reaction also releases ~7\u00a0MeV in prompt gamma ray photons. The latter figure means that a nuclear fission explosion or criticality accident emits about 3.5% of its energy as gamma rays, less than 2.5% of its energy as fast neutrons (total of both types of radiation ~6%), and the rest as kinetic energy of fission fragments (this appears almost immediately when the fragments impact surrounding matter, as simple heat).\nSome processes involving neutrons are notable for absorbing or finally yielding energy \u2014 for example neutron kinetic energy does not yield heat immediately if the neutron is captured by a uranium-238 atom to breed plutonium-239, but this energy is emitted if the plutonium-239 is later fissioned. On the other hand, so-called delayed neutrons emitted as radioactive decay products with half-lives up to several minutes, from fission-daughters, are very important to reactor control, because they give a characteristic \"reaction\" time for the total nuclear reaction to double in size, if the reaction is run in a \"delayed-critical\" zone which deliberately relies on these neutrons for a supercritical chain-reaction (one in which each fission cycle yields more neutrons than it absorbs). Without their existence, the nuclear chain-reaction would be prompt critical and increase in size faster than it could be controlled by human intervention. In this case, the first experimental atomic reactors would have run away to a dangerous and messy \"prompt critical reaction\" before their operators could have manually shut them down (for this reason, designer Enrico Fermi included radiation-counter-triggered control rods, suspended by electromagnets, which could automatically drop into the center of Chicago Pile-1). If these delayed neutrons are captured without producing fissions, they produce heat as well.\nBinding energy.\nThe binding energy of the nucleus is the difference between the rest-mass energy of the nucleus and the rest-mass energy of the neutron and proton nucleons. The binding energy formula includes volume, surface and Coulomb energy terms that include empirically derived coefficients for all three, plus energy ratios of a deformed nucleus relative to a spherical form for the surface and Coulomb terms. Additional terms can be included such as symmetry, pairing, the finite range of the nuclear force, and charge distribution within the nuclei to improve the estimate. Normally binding energy is referred to and plotted as average binding energy per nucleon.\nAccording to Lilley, \"The binding energy of a nucleus B is the energy required to separate it into its constituent neutrons and protons.\"\nformula_2\nwhere A is mass number, Z is atomic number, mH is the atomic mass of a hydrogen atom, mn is the mass of a neutron, and c is the speed of light. Thus, the mass of an atom is less than the mass of its constituent protons and neutrons, assuming the average binding energy of its electrons is negligible. The binding energy B is expressed in energy units, using Einstein's mass-energy equivalence relationship. The binding energy also provides an estimate of the total energy released from fission.\nThe curve of binding energy is characterized by a broad maximum near mass number 60 at 8.6 MeV, then gradually decreases to 7.6 MeV at the highest mass numbers. Mass numbers higher than 238 are rare. At the lighter end of the scale, peaks are noted for helium-4, and the multiples such as beryllium-8, carbon-12, oxygen-16, neon-20 and magnesium-24. Binding energy due to the nuclear force approaches a constant value for large A, while the Coulomb acts over a larger distance so that electrical potential energy per proton grows as Z increases. Fission energy is released when a A is larger than approx. 60. Fusion energy is released when lighter nuclei combine.\nCarl Friedrich von Weizs\u00e4cker's semi-empirical mass formula may be used to express the binding energy as the sum of five terms, which are the volume energy, a surface correction, Coulomb energy, a symmetry term, and a pairing term:\nformula_3 \nwhere the nuclear binding energy is proportional to the nuclear volume, while nucleons near the surface interact with fewer nucleons, reducing the effect of the volume term. According to Lilley, \"For all naturally occurring nuclei, the surface-energy term dominates and the nucleus exists in a state of equilibrium.\" The negative contribution of Coulomb energy arises from the repulsive electric force of the protons. The symmetry term arises from the fact that effective forces in the nucleus are stronger for unlike neutron-proton pairs, rather than like neutron\u2013neutron or proton\u2013proton pairs. The pairing term arises from the fact that like nucleons form spin-zero pairs in the same spatial state. The pairing is positive if N and Z are both even, adding to the binding energy.\nIn fission there is a preference for fission fragments with even Z, which is called the odd\u2013even effect on the fragments' charge distribution. This can be seen in the empirical fragment yield data for each fission product, as products with even Z have higher yield values. However, no odd\u2013even effect is observed on fragment distribution based on their A. This result is attributed to nucleon pair breaking.\nIn nuclear fission events the nuclei may break into any combination of lighter nuclei, but the most common event is not fission to equal mass nuclei of about mass\u00a0120; the most common event (depending on isotope and process) is a slightly unequal fission in which one daughter nucleus has a mass of about 90 to 100 daltons and the other the remaining 130 to 140 daltons.\nStable nuclei, and unstable nuclei with very long half-lives, follow a trend of stability evident when Z is plotted against N. For lighter nuclei less than N = 20, the line has the slope N = Z, while the heavier nuclei require additional neutrons to remain stable. Nuclei that are neutron- or proton-rich have excessive binding energy for stability, and the excess energy may convert a neutron to a proton or a proton to a neutron via the weak nuclear force, a process known as beta decay.\nNeutron-induced fission of U-235 emits a total energy of 207 MeV, of which about 200 MeV is recoverable, Prompt fission fragments amount to 168 MeV, which are easily stopped with a fraction of a millimeter. Prompt neutrons total 5 MeV, and this energy is recovered as heat via scattering in the reactor. However, many fission fragments are neutron-rich and decay via \u03b2\u2212 emissions. According to Lilley, \"The radioactive decay energy from the fission chains is the second release of energy due to fission. It is much less than the prompt energy, but it is a significant amount and is why reactors must continue to be cooled after they have been shut down and why the waste products must be handled with great care and stored safely.\"\nChain reactions.\nJohn Lilley states, \"...neutron-induced fission generates extra neutrons which can induce further fissions in the next generation and so on in a chain reaction. The chain reaction is characterized by the \"neutron multiplication factor k\", which is defined as the ratio of the number of neutrons in one generation to the number in the preceding generation. If, in a reactor, \"k\" is less than unity, the reactor is subcritical, the number of neutrons decreases and the chain reaction dies out. If \"k\" &gt; 1, the reactor is supercritical and the chain reaction diverges. This is the situation in a fission bomb where growth is at an explosive rate. If \"k\" is exactly unity, the reactions proceed at a steady rate and the reactor is said to be critical. It is possible to achieve criticality in a reactor using natural uranium as fuel, provided that the neutrons have been efficiently moderated to thermal energies.\" Moderators include light water, heavy water, and graphite.\nAccording to John C. Lee, \"For all nuclear reactors in operation and those under development, the nuclear fuel cycle is based on one of three \"fissile\" materials, 235U, 233U, and 239Pu, and the associated isotopic chains. For the current generation of LWRs, the enriched U contains 2.5~4.5 wt% of 235U, which is fabricated into UO2 fuel rods and loaded into fuel assemblies.\"\nLee states, \"One important comparison for the three major fissile nuclides, 235U, 233U, and 239Pu, is their breeding potential. A \"breeder\" is by definition a reactor that produces more fissile material than it consumes and needs a minimum of two neutrons produced for each neutron absorbed in a fissile nucleus. Thus, in general, the \"conversion ratio (CR) is defined as the ratio of fissile material produced to that destroyed\"...when the CR is greater than 1.0, it is called the \"breeding ratio\" (BR)...233U offers a superior breeding potential for both thermal and fast reactors, while 239Pu offers a superior breeding potential for fast reactors.\"\nFission reactors.\nCritical fission reactors are the most common type of nuclear reactor. In a critical fission reactor, neutrons produced by fission of fuel atoms are used to induce yet more fissions, to sustain a controllable amount of energy release. Devices that produce engineered but non-self-sustaining fission reactions are subcritical fission reactors. Such devices use radioactive decay or particle accelerators to trigger fissions.\nCritical fission reactors are built for three primary purposes, which typically involve different engineering trade-offs to take advantage of either the heat or the neutrons produced by the fission chain reaction:\nWhile, in principle, all fission reactors can act in all three capacities, in practice the tasks lead to conflicting engineering goals and most reactors have been built with only one of the above tasks in mind. (There are several early counter-examples, such as the Hanford N reactor, now decommissioned).\nAs of 2019, the 448 nuclear power plants worldwide provided a capacity of 398 GWE, with about 85% being light-water cooled reactors such as pressurized water reactors or boiling water reactors. Energy from fission is transmitted through conduction or convection to the nuclear reactor coolant, then to a heat exchanger, and the resultant generated steam is used to drive a turbine or generator.\nFission bombs.\nThe objective of an atomic bomb is to produce a device, according to Serber, \"...in which energy is released by a fast neutron chain reaction in one or more of the materials known to show nuclear fission.\" According to Rhodes, \"Untamped, a bomb core even as large as twice the critical mass would completely fission less than 1 percent of its nuclear material before it expanded enough to stop the chain reaction from proceeding. Tamper always increased efficiency: it reflected neutrons back into the core and its inertia...slowed the core's expansion and helped keep the core surface from blowing away.\" Rearrangement of the core material's subcritical components would need to proceed as fast as possible to ensure effective detonation. Additionally, a third basic component was necessary, \"...an initiator\u2014a Ra + Be source or, better, a Po + Be source, with the radium or polonium attached perhaps to one piece of the core and the beryllium to the other, to smash together and spray neutrons when the parts mated to start the chain reaction.\" However, any bomb would \"necessitate locating, mining and processing hundreds of tons of uranium ore...\", while U-235 separation or the production of Pu-239 would require additional industrial capacity.\nHistory.\nDiscovery of nuclear fission.\nThe discovery of nuclear fission occurred in 1938 in the buildings of the Kaiser Wilhelm Society for Chemistry, today part of the Free University of Berlin, following over four decades of work on the science of radioactivity and the elaboration of new nuclear physics that described the components of atoms. In 1911, Ernest Rutherford proposed a model of the atom in which a very small, dense and positively charged nucleus of protons was surrounded by orbiting, negatively charged electrons (the Rutherford model). Niels Bohr improved upon this in 1913 by reconciling the quantum behavior of electrons (the Bohr model). In 1928, George Gamow proposed the Liquid drop model, which became essential to understanding the physics \nof fission.\nIn 1896, Henri Becquerel had found, and Marie Curie named, radioactivity. In 1900, Rutherford and Frederick Soddy, investigating the radioactive gas emanating from thorium, \"conveyed the tremendous and inevitable conclusion that the element thorium was slowly and spontaneously transmuting itself into argon gas!\"\nIn 1919, following up on an earlier anomaly Ernest Marsden noted in 1915, Rutherford attempted to \"break up the atom.\" Rutherford was able to accomplish the first artificial transmutation of nitrogen into oxygen, using alpha particles directed at nitrogen 14N + \u03b1 \u2192 17O + p.\u00a0 Rutherford stated, \"...we must conclude that the nitrogen atom is disintegrated,\" while the newspapers stated he had \"split the atom\". This was the first observation of a nuclear reaction, that is, a reaction in which particles from one decay are used to transform another atomic nucleus. It also offered a new way to study the nucleus. Rutherford and James Chadwick then used alpha particles to \"disintegrate\" boron, fluorine, sodium, aluminum, and phosphorus before reaching a limitation associated with the energy of his alpha particle source. Eventually, in 1932, a fully artificial nuclear reaction and nuclear transmutation was achieved by Rutherford's colleagues Ernest Walton and John Cockcroft, who used artificially accelerated protons against lithium-7, to split this nucleus into two alpha particles. The feat was popularly known as \"splitting the atom\", and would win them the 1951 Nobel Prize in Physics for \"Transmutation of atomic nuclei by artificially accelerated atomic particles\", although it was not the nuclear fission reaction later discovered in heavy elements.\nEnglish physicist James Chadwick discovered the neutron in 1932. Chadwick used an ionization chamber to observe protons knocked out of several elements \nby beryllium radiation, following up on earlier observations made by Joliot-Curies. In Chadwick's words, \"...In order to explain the great penetrating power of the radiation we must further assume that the particle has no net charge...\" The existence of the neutron was first postulated by Rutherford in 1920, and in the words of Chadwick, \"...how on earth were you going to build up a big nucleus with a large positive charge? And the answer was a neutral particle.\" Subsequently, he communicated his findings in more detail.\nIn the words of Richard Rhodes, referring to the neutron, \"It would therefore serve as a new nuclear probe of surpassing power of penetration.\" Philip Morrison stated, \"A beam of thermal neutrons moving at about the speed of sound...produces nuclear reactions in many materials much more easily than a beam of protons...traveling thousands of times faster.\" \nAccording to Rhodes, \"Slowing down a neutron gave it more time in the vicinity of the nucleus, and that gave it more time to be captured.\" Fermi's team, studying radiative capture which is the emission of gamma radiation after the nucleus captures a neutron, studied sixty elements, inducing radioactivity in forty. In the process, they discovered the ability of hydrogen to slow down the neutrons.\nEnrico Fermi and his colleagues in Rome studied the results of bombarding uranium with neutrons in 1934. Fermi concluded that his experiments had created new elements with 93 and 94 protons, which the group dubbed ausenium and hesperium. However, not all were convinced by Fermi's analysis of his results, though he would win the 1938 Nobel Prize in Physics for his \"demonstrations of the existence of new radioactive elements produced by neutron irradiation, and for his related discovery of nuclear reactions brought about by slow neutrons\". The German chemist Ida Noddack notably suggested in 1934 that instead of creating a new, heavier element 93, that \"it is conceivable that the nucleus breaks up into several large fragments.\" However, the quoted objection comes some distance down, and was but one of several gaps she noted in Fermi's claim. Although Noddack was a renowned analytical chemist, she lacked the background in physics to appreciate the enormity of what she was proposing.\nAfter the Fermi publication, Otto Hahn, Lise Meitner, and Fritz Strassmann began performing similar experiments in Berlin. Meitner, an Austrian Jew, lost her Austrian citizenship with the \"Anschluss\", the union of Austria with Germany in March 1938, but she fled in July 1938 to Sweden and started a correspondence by mail with Hahn in Berlin. By coincidence, her nephew Otto Robert Frisch, also a refugee, was also in Sweden when Meitner received a letter from Hahn dated 19 December describing his chemical proof that some of the product of the bombardment of uranium with neutrons was barium. Hahn suggested a \"bursting\" of the nucleus, but he was unsure of what the physical basis for the results were. Barium had an atomic mass 40% less than uranium, and no previously known methods of radioactive decay could account for such a large difference in the mass of the nucleus. Frisch was skeptical, but Meitner trusted Hahn's ability as a chemist. Marie Curie had been separating barium from radium for many years, and the techniques were well known. Meitner and Frisch then correctly interpreted Hahn's results to mean that the nucleus of uranium had split roughly in half. Frisch suggested the process be named \"nuclear fission\", by analogy to the process of living cell division into two cells, which was then called binary fission. Just as the term nuclear \"chain reaction\" would later be borrowed from chemistry, so the term \"fission\" was borrowed from biology.\nNews spread quickly of the new discovery, which was correctly seen as an entirely novel physical effect with great scientific\u2014and potentially practical\u2014possibilities. Meitner's and Frisch's interpretation of the discovery of Hahn and Strassmann crossed the Atlantic Ocean with Niels Bohr, who was to lecture at Princeton University. I.I. Rabi and Willis Lamb, two Columbia University physicists working at Princeton, heard the news and carried it back to Columbia. Rabi said he told Enrico Fermi; Fermi gave credit to Lamb. Bohr soon thereafter went from Princeton to Columbia to see Fermi. Not finding Fermi in his office, Bohr went down to the cyclotron area and found Herbert L. Anderson. Bohr grabbed him by the shoulder and said: \"Young man, let me explain to you about something new and exciting in physics.\"\nIt was clear to a number of scientists at Columbia that they should try to detect the energy released in the nuclear fission of uranium from neutron bombardment. On 25 January 1939, a Columbia University team conducted the first nuclear fission experiment in the United States, which was done in the basement of Pupin Hall. The experiment involved placing uranium oxide inside of an ionization chamber and irradiating it with neutrons, and measuring the energy thus released. The results confirmed that fission was occurring and hinted strongly that it was the isotope uranium 235 in particular that was fissioning. The next day, the fifth Washington Conference on Theoretical Physics began in Washington, D.C. under the joint auspices of the George Washington University and the Carnegie Institution of Washington. There, the news on nuclear fission was spread even further, which fostered many more experimental demonstrations.\nThe 6 January 1939 Hahn and Strassman paper announced the discover of fission. In their second publication on nuclear fission in February 1939, Hahn and Strassmann used the term \"Uranspaltung\" (uranium fission) for the first time, and predicted the existence and liberation of additional neutrons during the fission process, opening up the possibility of a nuclear chain reaction. The 11 February 1939 paper by Meitner and Frisch compared the process to the division of a liquid drop and estimated the energy released at 200 MeV. The 1 September 1939 paper by Bohr and Wheeler used this liquid drop model to quantify fission details, including the energy released, estimated the cross section for neutron-induced fission, and deduced 235U was the major contributor to that cross section and slow-neutron fission.\nFission chain reaction realized.\nDuring this period the Hungarian physicist Le\u00f3 Szil\u00e1rd realized that the neutron-driven fission of heavy atoms could be used to create a nuclear chain reaction. Such a reaction using neutrons was an idea he had first formulated in 1933, upon reading Rutherford's disparaging remarks about generating power from neutron collisions. However, Szil\u00e1rd had not been able to achieve a neutron-driven chain reaction using beryllium. Szilard stated, \"...if we could find an element which is split by neutrons and which would emit \"two\" neutrons when it absorbs \"one\" neutron, such an element, if assembled in sufficiently large mass, could sustain a nuclear chain reaction.\" On 25 January 1939, after learning of Hahn's discovery from Eugene Wigner, Szilard noted, \"...if enough neutrons are emitted...then it should be, of course, possible to sustain a chain reaction. All of the things which H. G. Wells predicted appeared suddenly real to me.\" After the Hahn-Strassman paper was published, Szilard noted in a letter to Lewis Strauss, that during the fission of uranium, \"the energy released in this new reaction must be very much higher than all previously known cases...,\" which might lead to \"large-scale production of energy and radioactive elements, unfortunately also perhaps to atomic bombs.\"\nSzilard now urged Fermi (in New York) and Fr\u00e9d\u00e9ric Joliot-Curie (in Paris) to refrain from publishing on the possibility of a chain reaction, lest the Nazi government become aware of the possibilities on the eve of what would later be known as World War II. With some hesitation Fermi agreed to self-censor. But Joliot-Curie did not, and in April 1939 his team in Paris, including Hans von Halban and Lew Kowarski, reported in the journal \"Nature\" that the number of neutrons emitted with nuclear fission of uranium was then reported at 3.5 per fission. Szilard and Walter Zinn found \"...the number of neutrons emitted by fission to be about two.\" Fermi and Anderson estimated \"a yield of about two neutrons per each neutron captured.\"\nWith the news of fission neutrons from uranium fission, Szil\u00e1rd immediately understood the possibility of a nuclear chain reaction using uranium. In the summer, Fermi and Szilard proposed the idea of a nuclear reactor (pile) to mediate this process. The pile would use natural uranium as fuel. Fermi had shown much earlier that neutrons were far more effectively captured by atoms if they were of low energy (so-called \"slow\" or \"thermal\" neutrons), because for quantum reasons it made the atoms look like much larger targets to the neutrons. Thus to slow down the secondary neutrons released by the fissioning uranium nuclei, Fermi and Szilard proposed a graphite \"moderator\", against which the fast, high-energy secondary neutrons would collide, effectively slowing them down. With enough uranium, and with sufficiently pure graphite, their \"pile\" could theoretically sustain a slow-neutron chain reaction. This would result in the production of heat, as well as the creation of radioactive fission products.\nIn August 1939, Szilard, Teller and Wigner thought that the Germans might make use of the fission chain reaction and were spurred to attempt to attract the attention of the United States government to the issue. Towards this, they persuaded Albert Einstein to lend his name to a letter directed to President Franklin Roosevelt. On 11 October, the Einstein\u2013Szil\u00e1rd letter was delivered via Alexander Sachs. Roosevelt quickly understood the implications, stating, \"Alex, what you are after is to see that the Nazis don't blow us up.\" Roosevelt ordered the formation of the Advisory Committee on Uranium.\nIn February 1940, encouraged by Fermi and John R. Dunning, Alfred O. C. Nier was able to separate U-235 and U-238 from uranium tetrachloride in a glass mass spectrometer. Subsequently, Dunning, bombarding the U-235 sample with neutrons generated by the Columbia University cyclotron, confirmed \"U-235 was responsible for the slow neutron fission of uranium.\"\nAt the University of Birmingham, Frisch teamed up with Peierls, who had been working on a critical mass formula. assuming isotope separation was possible, they considered 235U, which had a cross section not yet determined, but which was assumed to be much larger than that of natural uranium. They calculated only a pound or two in a volume less than a golf ball, would result in a chain reaction faster than vaporization, and the resultant explosion would generate temperature greater than the interior of the sun, and pressures greater than the center of the earth. Additionally, the costs of isotope separation \"would be insignificant compared to the cost of the war.\" By March 1940, encouraged by Mark Oliphant, they wrote the Frisch\u2013Peierls memorandum in two parts, \"On the construction of a 'super-bomb; based on a nuclear chain reaction in uranium,\" and \"Memorandum on the properties of a radioactive 'super-bomb.' \". On 10 April 1940, the first meeting of the MAUD Committee was held.\nIn December 1940, Franz Simon at Oxford wrote his Estimate of the size of an actual separation plant.\" Simon proposed gaseous diffusion as the best method for uranium isotope separation.\nOn 28 March 1941, Emilio Segr\u00e9 and Glen Seaborg reported on the \"strong indications that 239Pu undergoes fission with slow neutrons.\" This meant chemical separation was an alternative to uranium isotope separation. Instead, a nuclear reactor fueled with ordinary uranium could produce a plutonium isotope as a nuclear explosive substitute for 235U. In May, they demonstrated the cross section of plutonium was 1.7 times that of U235. When plutonium's cross section for fast fission was measured to be ten times that of U238, plutonium became a viable option for a bomb.\nIn October 1941, MAUD released its final report to the U.S. Government. The report stated, \"We have now reached the conclusion that it will be possible to make an effective uranium bomb...The material for the first bomb could be ready by the end of 1943...\"\nIn November 1941, John Dunning and Eugene T. Booth were able to demonstrate the enrichment of uranium through gaseous barrier diffusion. On 27 November, Bush delivered to third National Academy of Sciences report to Roosevelt. The report, amongst other things, called for parallel development of all isotope-separation systems. On 6 December, Bush and Conant reorganized the Uranium Committee's tasks, with Harold Urey developing gaseous diffusion, Lawrence developing electromagnetic separation, Eger V. Murphree developing centrifuges, and Arthur Compton responsible for theoretical studies and design.\nOn 23 April 1942, Met Lab scientists discussed seven possible ways to extract plutonium from irradiated uranium, and decided to pursue investigation of all seven. On 17 June, the first batch of uranium nitrate hexahydrate (UNH) was undergoing neutron bombardment in the Washington University in St. Louis cyclotron. On 27 July, the irradiated UNH was ready for Glenn T. Seaborg's team. On 20 August, using ultramicrochemistry techniques, they successfully extracted plutonium.\nIn April 1939, creating a chain reaction in natural uranium became the goal of Fermi and Szilard, as opposed to isotope separation. Their first efforts involved five hundred pounds of uranium oxide from the Eldorado Radium Corporation. Packed into fifty-two cans two inches in diameter and two feet long in a tank of manganese solution, they were able to confirm more neutrons were emitted than absorbed. However, the hydrogen within the water absorbed the slow neutrons necessary for fission. Carbon in the form of graphite, was then considered, because of its smaller capture cross section. In April 1940, Fermi was able to confirm carbon's potential for a slow-neutron chain reaction, after receiving National Carbon Company's graphite bricks at their Pupin Laboratories. In August and September, the Columbia team enlarged upon the cross section measurements by making a series of exponential \"piles\". The first piles consisted of a uranium-graphite lattice, consisting of 288 cans, each containing 60 pounds of uranium oxide, surrounded by graphite bricks. Fermi's goal was to determine critical mass necessary to sustain neutron generation. Fermi defined the reproduction factor k for assessing the chain reaction, with a value of 1.0 denoting a sustained chain reaction. In September 1941, Fermi's team was only able to achieve a k value of 0.87. In April 1942, before the project was centralized in Chicago, they had achieved 0.918 by removing moisture from the oxide. In May 1942, Fermi planned a full-scale chain reacting pile, Chicago Pile-1, after one of the exponential piles at Stagg Field reached a k of 0.995. Between 15 September and 15 November, Herbert L. Anderson and Walter Zinn built sixteen exponential piles. Acquisition of purer forms of graphite, without traces of boron and its large cross section, became paramount. Also important was the acquisition of highly purified forms of oxide from Mallinckrodt Chemical Works. Finally, acquiring pure uranium metal from the Ames process, meant the replacement of oxide pseudospheres with Frank Spedding's \"eggs\". Starting on 16 November 1942, Fermi had Anderson and Zinn working in two twelve-hours shifts, constructing a pile that eventually reached 57 layers by 1 Dec. The final pile consisted of 771,000 pounds of graphite, 80,590 pounds of uranium oxide, and 12,400 pounds of uranium metal, with ten cadmium control rods. Neutron intensity was measured with a boron trifluoride counter, with the control rods removed, after the end of each shift. On 2 Dec. 1942, with k approaching 1.0, Fermi had all but one of the control rod removed, and gradually removed the last one. The neutron counter clicks increased, as did the pen recorder, when Fermi announced \"The pile has gone critical.\" They had achieved a k of 1.006, which meant neutron intensity doubled every two minutes, in addition to breeding plutonium.\nManhattan Project and beyond.\nIn the United States, an all-out effort for making atomic weapons was begun in late 1942. This work was taken over by the U.S. Army Corps of Engineers in 1943, and known as the Manhattan Engineer District. The top-secret Manhattan Project, as it was colloquially known, was led by General Leslie R. Groves. Among the project's dozens of sites were: Hanford Site in Washington, which had the first industrial-scale nuclear reactors and produced plutonium; Oak Ridge, Tennessee, which was primarily concerned with uranium enrichment; and Los Alamos, in New Mexico, which was the scientific hub for research on bomb development and design. Other sites, notably the Berkeley Radiation Laboratory and the Metallurgical Laboratory at the University of Chicago, played important contributing roles. Overall scientific direction of the project was managed by the physicist J. Robert Oppenheimer.\nIn July 1945, the first atomic explosive device, dubbed \"The Gadget\", was detonated in the New Mexico desert in the Trinity test. It was fueled by plutonium created at Hanford. In August 1945, two more atomic devices \u2013 \"Little Boy\", a uranium-235 bomb, and \"Fat Man\", a plutonium bomb \u2013 were used against the Japanese cities of Hiroshima and Nagasaki.\nNatural fission chain-reactors on Earth.\nCriticality in nature is uncommon. At three ore deposits at Oklo in Gabon, sixteen sites (the so-called Oklo Fossil Reactors) have been discovered at which self-sustaining nuclear fission took place approximately 2\u00a0billion years ago. French physicist Francis Perrin discovered the Oklo Fossil Reactors in 1972, but it was postulated by Paul Kuroda in 1956. Large-scale natural uranium fission chain reactions, moderated by normal water, had occurred far in the past and would not be possible now. This ancient process was able to use normal water as a moderator only because 2\u00a0billion years before the present, natural uranium was richer in the shorter-lived fissile isotope 235U (about 3%), than natural uranium available today (which is only 0.7%, and must be enriched to 3% to be usable in light-water reactors).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22055", "revid": "47223990", "url": "https://en.wikipedia.org/wiki?curid=22055", "title": "Neil Gaiman", "text": "English writer (born 1960)\nNeil Richard MacKinnon Gaiman (; born Neil Richard Gaiman; 10 November 1960) is an English author of short fiction, novels, comic books, audio theatre, and screenplays. His works include the comic series \"The Sandman\" (1989\u20131996) and the novels \"Good Omens\" (1990), \"Stardust\" (1999), \"American Gods\" (2001), \"Coraline\" (2002), \"Anansi Boys\" (2005), \"The Graveyard Book\" (2008) and \"The Ocean at the End of the Lane\" (2013). He co-created the TV adaptations of \"Good Omens\" and \"The Sandman\".\nGaiman's awards include Hugo, Nebula, and Bram Stoker awards and Newbery and Carnegie medals. He is the first author to win the Newbery and the Carnegie medals for the same work, \"The Graveyard Book\". \"The Ocean at the End of the Lane\" was voted Book of the Year in the British National Book Awards, and it was adapted into an acclaimed stage play at the Royal National Theatre in London.\nBeginning in 2024, news outlets published sexual assault accusations against Gaiman by numerous women. This affected or halted production on several adaptations of his work. One accuser sued Gaiman and his estranged wife Amanda Palmer for rape and human trafficking. Gaiman has denied these allegations.\nPersonal life.\nEarly life and education.\nNeil Richard Gaiman was born on 10 November 1960 in Portchester, Hampshire. Gaiman's family is of Polish-Jewish and other Ashkenazi origins. His great-grandfather emigrated to England from Antwerp before 1914 and his grandfather settled in Portsmouth and established a chain of grocery stores, changing the family name from Chaiman to Gaiman. His father, David Bernard Gaiman, worked in the same chain of stores; his mother, Sheila Gaiman (n\u00e9e Goldman), was a pharmacist. Neil has two younger sisters, Claire and Lizzy.\nThe Gaimans moved in 1965 to the West Sussex town of East Grinstead, where his parents studied Dianetics at the Scientology centre in the town; one of Gaiman's sisters works for the Church of Scientology in Los Angeles. His other sister, Lizzy Calcioli, has said, \"Most of our social activities were involved with Scientology or our Jewish family. It would get very confusing when people would ask my religion as a kid. I'd say, 'I'm a Jewish Scientologist.'\" Gaiman says that he is not a Scientologist, and that like Judaism, Scientology is his family's religion. About his personal views, Gaiman has stated, \"I think we can say that God exists in the DC Universe. I would not stand up and beat the drum for the existence of God in this universe. I don't know, I think there's probably a 50/50 chance. It doesn't really matter to me.\"\nGaiman was able to read at the age of four. He said, \"I was a reader. I loved reading. Reading things gave me pleasure. I was very good at most subjects in school, not because I had any particular aptitude in them, but because normally on the first day of school, they'd hand out schoolbooks, and I'd read them\u2014which would mean that I'd know what was coming up because I'd read it.\" When he was about 10 years old, he read his way through the works of Dennis Wheatley; \"The Ka of Gifford Hillary\" and \"The Haunting of Toby Jugg\" made a special impact on him.\nAnother work that made a particular impression was J. R. R. Tolkien's \"The Lord of the Rings\", which he got from his school library. Although they only had the first two of the novel's three volumes, Gaiman consistently checked them out and read them. He later won the school English prize and the school reading prize, enabling him to finally acquire the third volume. For his seventh birthday, Gaiman received C. S. Lewis's \"The Chronicles of Narnia\". He later recalled that \"I admired his use of parenthetical statements to the reader, where he would just talk to you ... I'd think, 'Oh, my gosh, that is so cool! I want to do that! When I become an author, I want to be able to do things in parentheses.' I liked the power of putting things in brackets.\" \"Narnia\" also introduced him to literary awards, specifically the Carnegie Medal, won by the concluding volume in 1956. When Gaiman won the 2010 Medal himself, he said \"it had to be the most important literary award there ever was\" and \"if you can make yourself aged seven happy, you're really doing well \u2013 it's like writing a letter to yourself aged seven.\" Lewis Carroll's \"Alice's Adventures in Wonderland\" was another childhood favourite, and \"a favourite forever. Alice was default reading to the point where I knew it by heart.\" He also enjoyed Batman comics.\nGaiman was educated at several Church of England schools, including Fonthill School in East Grinstead, Ardingly College (1970\u20131974), and Whitgift School in Croydon (1974\u20131977). His father's position as a public relations official of the Church of Scientology was the cause of the seven-year-old Gaiman being forced to withdraw from Fonthill School and return to the school which he had previously attended. He lived in East Grinstead for many years, from 1965 to 1980 and again from 1984 to 1987.\nIn the 1970s, he spent three years as an auditor for the Church of Scientology, an unusually high-ranking position given his age. He also sang in a punk rock band Ex Execs, formerly called Chaos.\nHe met his first wife, Mary McGrath, while she was studying Scientology and living in a house in East Grinstead that was owned by his father. The couple were married in 1985 after having their first child.\nAdult life.\nGaiman moved near Menomonie, Wisconsin, in 1992 to be closer to the family of his then-wife, Mary McGrath, with whom he has three children. Gaiman has also lived in Cambridge, Massachusetts. He was close friends with fellow author Terry Pratchett until the latter's death in 2015. Gaiman met Amanda Palmer in 2008, and the two entered a relationship in 2009, marrying in 2011. They have one son together. The two had an open marriage, and encouraged one another to have affairs, including with fans of their work.\nGaiman, Palmer and their son moved to New Zealand in March 2020. Weeks later, their marriage collapsed and Gaiman left the country, travelling from New Zealand to his holiday home on the Isle of Skye, which broke COVID-19 lockdown rules. Ross, Skye and Lochaber MP Ian Blackford described Gaiman's behaviour as unacceptable and dangerous. Gaiman published an apology on his website, saying he had endangered the local community. After Gaiman's departure, Palmer announced on Patreon that she and Gaiman had separated. Gaiman stated the split was \"my fault, I'm afraid\", and requested privacy. The couple later released a joint statement clarifying that they were not getting divorced, reconciled in 2021, but confirmed they would divorce in a November 2022 joint statement. As of January\u00a02025[ [update]], in the fifth year of proceedings, negotiations had become \"ugly\", with Palmer moving in with her parents due to financial difficulties.\nBlog and social media.\nIn February 2001, when Gaiman had completed writing \"American Gods\", his publishers set up a promotional website featuring a weblog in which Gaiman described the day-to-day process of revising, publishing, and promoting the novel. After the novel was published, the website evolved into a more general Official Neil Gaiman Website. Gaiman generally posts to the blog describing the day-to-day process of being Neil Gaiman and writing, revising, publishing, or promoting whatever the current project is. He also posts reader emails and answers questions, which gives him unusually direct and immediate interaction with fans. One of his answers on why he writes the blog is \"because writing is, like death, a lonely business.\" The original \"American Gods\" blog was extracted for publication in the NESFA Press collection of Gaiman miscellany, \"Adventures in the Dream Trade\". To celebrate the seventh anniversary of the blog, the novel \"American Gods\" was provided free of charge online for a month.\nGaiman joined Twitter in 2008. In 2013, Gaiman was named by \"IGN\" as one of \"The Best Tweeters in Comics\", describing his posts as \"sublime\".\nOther personal relationships.\nGaiman is godfather to Tori Amos's daughter Tash, and wrote a poem called \"Blueberry Girl\" for Tori and Tash. The poem was adapted into a book by illustrator Charles Vess. Gaiman read the poem aloud to an audience at the Sundance Kabuki Theater in San Francisco on 5 October 2008 during his book reading tour for \"The Graveyard Book\". It was published in March 2009 with the title \"Blueberry Girl\".\nAdvocacy.\nIn 2016, Gaiman, along with several other celebrities, appeared in the video \"What They Took With Them\", from the United Nations High Commissioner for Refugees, to help raise awareness of the issue of global refugees.\nGaiman is a supporter of the Comic Book Legal Defense Fund and has served on its board of directors. In 2013, Gaiman was named co-chair of the organization's newly formed advisory board.\nIn 2022, during the Russian invasion of Ukraine, Gaiman supported Ukraine by announcing on Twitter that he does not want to renew contracts with Russian publishers. Gaiman also encouraged donating to Ukrainian refugees.\nIn 2023, Gaiman signed an open letter addressed to Russian president Vladimir Putin, alongside over 100 other public figures, calling for the release of Russian prisoner Alexei Navalny.\nCareer.\nJournalism, early writings, and literary influences.\nGaiman has mentioned several writers who have influenced his work, including Mary Shelley, Rudyard Kipling, Edgar Allan Poe, Michael Moorcock, Dave Sim, Alan Moore, Steve Ditko, Will Eisner, Ursula K. Le Guin, Harlan Ellison, John Crowley, Lord Dunsany, G. K. Chesterton and Gene Wolfe. A lifetime fan of the Monty Python comedy troupe, he owned a copy of \"Monty Python's Big Red Book\" as a teenager. During a trip to France when he was 13, Gaiman became fascinated with the visually fantastic world in the stories of \"M\u00e9tal Hurlant\", even though he could not understand the words. When he was 19 or 20 years old, he contacted his favourite science fiction writer, R. A. Lafferty, requesting advice on becoming an author and including a Lafferty pastiche he had written. Lafferty sent Gaiman an encouraging and informative letter back, along with literary advice.\nGaiman has named Roger Zelazny as the author who influenced him the most. Gaiman claims that other authors such as Samuel R. Delany and Angela Carter \"furnished the inside of my mind and set me to writing\". Gaiman takes inspiration from the folk tales tradition, citing Otta F Swire's book on the legends of the Isle of Skye as his inspiration for \"The Truth Is a Cave in the Black Mountains\".\nIn the early 1980s, Gaiman pursued journalism, conducting interviews and writing book reviews, as a means to learn about the world and to make connections that he hoped would later assist him in getting published. He wrote and reviewed extensively for the British Fantasy Society. His first professional short story publication was \"Featherquest\", a fantasy story, in \"Imagine\" magazine in May 1984.\nWhile waiting for a train at London's Victoria Station in 1984, Gaiman noticed a copy of \"Swamp Thing\" by Alan Moore, and read it. Moore's approach to comics had such an impact on Gaiman that he later wrote \"that was the final straw, what was left of my resistance crumbled. I proceeded to make regular and frequent visits to London's Forbidden Planet shop to buy comics\".\nIn 1984, he wrote his first book, a biography of the band Duran Duran, and co-edited \"Ghastly Beyond Belief\", a book of quotations, with Kim Newman. Although Gaiman thought he had done a terrible job, the book's first edition sold out very quickly. When he went to relinquish his rights to the book, he discovered the publisher had gone bankrupt. After this, he was offered a job by \"Penthouse\". He refused the offer.\nHe also wrote interviews and articles for many British magazines, including \"Knave.\" During this, he sometimes wrote under pseudonyms, including Gerry Musgrave, Richard Grey, and \"a couple of house names\". Gaiman has said he ended his journalism career in 1987 because British newspapers regularly publish untruths as fact.\nIn the late 1980s, he wrote \"\" in what he calls a \"classic English humour\" style.\nFollowing this, he wrote the opening of what became his collaboration with Terry Pratchett on the comic novel \"Good Omens\", about the impending apocalypse.\nComics.\nAfter forming a friendship with Alan Moore, who taught him how to write comic scripts, Gaiman started writing comic books and picked up \"Miracleman\" after Moore finished his run on the series. He continued his professional relationship with Moore by contributing quotations for the supplemental materials in the \"Watchmen\" comic book series.\nGaiman and artist Mark Buckingham collaborated on several issues of the series before its publisher, Eclipse Comics, collapsed, leaving the series unfinished. His first published comic strips were four short \"Future Shocks\" for \"2000 AD\" in 1986\u201387. He wrote three graphic novels with his favourite collaborator and long-time friend Dave McKean: \"Violent Cases\", \"Signal to Noise\", and \"The Tragical Comedy or Comical Tragedy of Mr. Punch\". Impressed with his work, DC Comics hired him in February 1987, and he wrote the limited series \"Black Orchid\". Karen Berger, who later became head of DC Comics's Vertigo, read \"Black Orchid\" and offered Gaiman a job: to re-write an old character, the Sandman, but to put his own spin on him.\n\"The Sandman\" tells the tale of the ageless, anthropomorphic personification of Dream that is known by many names, including Morpheus. The series began in January 1989 and concluded in March 1996. The various artists who contributed to the series include Sam Kieth, Mike Dringenberg, Jill Thompson, Shawn McManus, Marc Hempel, and Michael Zulli, with lettering by Todd Klein, colours by Daniel Vozzo, and covers by Dave McKean. The series became one of DC's top selling titles, eclipsing even \"Batman\" and \"Superman\". The 75 issues of the regular series, along with an illustrated prose text and a special containing seven short stories, have been collected into 12 volumes that remain in print.\nIn the eighth issue of \"The Sandman\", Gaiman and artist Mike Dringenberg introduced Death, the older sister of Dream, who became as popular as the series' title character. The limited series \"\" launched DC's Vertigo line in 1993.\nComics historian Les Daniels called Gaiman's work \"astonishing\" and noted that \"The Sandman\" was \"a mixture of fantasy, horror, and ironic humor such as comic books had never seen before\". DC Comics writer and executive Paul Levitz observed that \"\"The Sandman\" became the first extraordinary success as a series of graphic novel collections, reaching out and converting new readers to the medium, particularly young women on college campuses, and making Gaiman himself into an iconic cultural figure.\"\nGaiman and Jamie Delano were to become co-writers of the \"Swamp Thing\" series following Rick Veitch. An editorial decision by DC to censor Veitch's final storyline caused both Gaiman and Delano to withdraw from the title.\nGaiman produced two stories for DC's \"Secret Origins\" series in 1989: a Poison Ivy tale drawn by Mark Buckingham and a Riddler story illustrated by Bernie Mireault and Matt Wagner. A story that Gaiman originally wrote for \"Action Comics Weekly\" in 1989 was shelved due to editorial concerns but it was finally published in 2000 as \"\".\nIn 1990, Gaiman wrote \"The Books of Magic\", a four-part mini-series that provided a tour of the mythological and magical parts of the DC Universe through a frame story about an English teenager who discovers that he is destined to be the world's greatest wizard. The miniseries was popular, and sired an ongoing series written by John Ney Rieber.\nGaiman's adaptation of \"Sweeney Todd\", illustrated by Michael Zulli for Stephen R. Bissette's publication \"Taboo\", was stopped when the anthology itself was discontinued.\nIn the mid-1990s, he also created a number of new characters and a setting that was to be featured in a title published by Tekno Comix. The concepts were then altered and split between three titles set in the same continuity: \"Lady Justice\", \"Mr. Hero the Newmatic Man\", and \"Teknophage\", and tie-ins. Because the publisher aimed to expand their characters into other media such as television, Gaiman designed his concepts with potential TV and computer game adaptations in mind. Although his name appeared prominently as the creator of the characters, he was not involved in writing any of the above-mentioned books. \nGaiman wrote a semi-autobiographical story about a boy's fascination with Michael Moorcock's anti-hero Elric of Melnibon\u00e9 for Ed Kramer's anthology \"Tales of the White Wolf.\" In 1996, Gaiman and Kramer co-edited \"\". Nominated for the British Fantasy Award, the original fiction anthology featured stories and contributions by Tori Amos, Clive Barker, Gene Wolfe, Caitl\u00edn R. Kiernan, Tad Williams, and others.\nAsked why he likes comics more than other forms of storytelling, Gaiman said: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;One of the joys of comics has always been the knowledge that it was, in many ways, untouched ground. It was virgin territory. When I was working on \"Sandman\", I felt a lot of the time that I was actually picking up a machete and heading out into the jungle. I got to write in places and do things that nobody had ever done before. When I'm writing novels I'm painfully aware that I'm working in a medium that people have been writing absolutely jaw-droppingly brilliant things for, you know, three-four thousand years now. You know, you can go back. We have things like \"The Golden Ass\". And you go, well, I don't know that I'm as good as that and that's two and a half thousand years old. But with comics I felt like \u2013 I can do stuff nobody has ever done. I can do stuff nobody has ever thought of. And I could and it was enormously fun.\nGaiman wrote two series for Marvel Comics. \"Marvel 1602\" was an eight-issue limited series published from November 2003 to June 2004 with art by Andy Kubert and Richard Isanove. \"The Eternals\" was a seven-issue limited series drawn by John Romita Jr., which was published from August 2006 to March 2007.\nIn 2009, Gaiman wrote a two-part Batman story for DC Comics to follow \"Batman R.I.P.\" titled \"\" a play-off of the classic Superman story \"\" by Alan Moore. He contributed a twelve-part Metamorpho serial drawn by Mike Allred for \"Wednesday Comics\", a weekly newspaper-style series. Gaiman and Paul Cornell co-wrote \"Action Comics\" #894 (December 2010), which featured an appearance by Death. In October 2013, DC Comics released \"\" with art by J. H. Williams III. Gaiman's Angela character was introduced into the Marvel Universe in the last issue of the \"Age of Ultron\" miniseries in 2013.\nGaiman oversaw \"The Sandman Universe\", a line of comic books published by Vertigo. The four series \u2014 \"House of Whispers\", \"Lucifer\", \"The Books of Magic\", and \"The Dreaming\" \u2014 were written by new creative teams. The line launched on 8 August 2018.\nAfter teaming with Colleen Doran for a series of graphic novel adaptations based on his short stories \"Troll Bridge\", \"Chivalry\", and \"Snow, Glass, Apples\", Gaiman and the Terry Pratchett estate chose Doran to adapt \"Good Omens\" into graphic novel form, and to self publish the work via the Pratchett estate's Dunmanifestin label. It was financed on Kickstarter where it became a record-setter in less than a week as the top fan-supported and top-earning comics project in the history of the platform.\nNovels.\nIn a collaboration with author Terry Pratchett, best known for his series of \"Discworld\" novels, Gaiman's first novel \"Good Omens\" was published in 1990. In 2011, Pratchett said that while the entire novel was a collaborative effort and most of the ideas could be credited to both of them, Pratchett did a larger portion of writing and editing if for no other reason than Gaiman's scheduled involvement with \"Sandman\".\nThe 1996 novelisation of Gaiman's teleplay for the BBC mini-series \"Neverwhere\" was his first solo novel. The novel was released in tandem with the television series, though it presents some notable differences from the television series. Gaiman has since revised the novel twice, the first time for an American audience unfamiliar with the London Underground, the second time because he felt unsatisfied with the originals.\nIn 1999, the first printings of his fantasy novel \"Stardust\" were released. The novel has been released both as a standard novel and in an illustrated text edition. This novel was highly influenced by Victorian fairytales and culture.\n\"American Gods\" became one of Gaiman's best-selling and multi-award-winning novels upon its release in 2001. A special 10th Anniversary edition was released, with the \"author's preferred text\" 12,000 words longer than the original mass-market editions. Gaiman has not written a direct sequel to \"American Gods\" but he has revisited the characters. A glimpse at Shadow's travels in Europe is found in a short story which finds him in Scotland, applying the same concepts developed in \"American Gods\" to the story of \"Beowulf\". The 2005 novel \"Anansi Boys\" deals with Anansi ('Mr. Nancy'), tracing the relationship of his two sons, one semi-divine and the other an unassuming bookkeeper, as they explore their common heritage. It debuted at number one on \"The New York Times\" Best Seller list.\nIn 2002, Gaiman entered the world of children's books with the dark fairy tale \"Coraline\". In 2008 he released a young adult novel, \"The Graveyard Book\". It follows the adventures of a boy named Bod after his family is murdered and he is left to be brought up by a graveyard. It is heavily influenced by Rudyard Kipling's \"The Jungle Book\" and H. P. Lovecraft\u2019s \"The Dream-Quest of Unknown Kadath\". Literary critic Danel Olson defended it as one of the first canonical novels of 21st century Gothic literature. As of late January 2009[ [update]], it had been on \"The New York Times\" Bestseller children's list for fifteen weeks.\nIn 2013, \"The Ocean at the End of the Lane\" was voted Book of the Year in the British National Book Awards. The novel follows an unnamed man who returns to his hometown for a funeral and remembers events that began forty years earlier. Themes include the search for self-identity and the \"disconnect between childhood and adulthood\". It was later adapted into a critically acclaimed stage play at the Royal National Theatre in London.\nIn September 2016, Neil Gaiman announced that he had been working for some years on retellings of Norse mythology. \"Norse Mythology\" was released in February 2017.\nSeveral of his novels have been published as paperbacks with retro covers by artist Robert McGinnis.\nFilm and screenwriting.\nGaiman wrote the 1996 BBC dark fantasy television series \"Neverwhere\". He co-wrote the screenplay for the movie \"MirrorMask\" with his old friend Dave McKean for McKean to direct. In addition, he wrote the localised English language script for the anime movie \"Princess Mononoke\", based on a translation of the Japanese script.\nAfter his disappointment with the production limitations of \"Neverwhere\", Gaiman asked his agent to pull him out of an (unnamed) UK television series that was to begin production immediately afterwards. \"I didn't want to do it unless I had more control than you get as a writer: in fantasy, the tone of voice, the look and feel, the way something is shot and edited is vital, and I wanted to be in charge of that.\"\nHe co-wrote the script for Robert Zemeckis's \"Beowulf\" with Roger Avary, a collaboration that has proved productive for both writers. Gaiman has expressed interest in collaborating on a film adaptation of the \"Epic of Gilgamesh\".\nHe was the only person other than J. Michael Straczynski to write a \"Babylon 5\" script in the series' last three seasons, contributing to the season five episode \"Day of the Dead\". The series also features a recurring alien race called the Gaim, who resemble the character of Dream and are named after Gaiman.\nGaiman has also written at least three drafts of a screenplay adaptation of Nicholson Baker's novel \"The Fermata\" for director Robert Zemeckis, although the project was stalled while Zemeckis made \"The Polar Express\" and the Gaiman-Roger Avary-penned \"Beowulf\" film.\nNeil Gaiman was featured in the History Channel documentary \"Comic Book Superheroes Unmasked\".\nSeveral of Gaiman's original works have been optioned or greenlighted for film adaptation, most notably \"Stardust\", which premiered in August 2007 and stars Charlie Cox, Robert De Niro, Michelle Pfeiffer, Claire Danes and Mark Strong, directed by Matthew Vaughn. A stop-motion version of \"Coraline\" was released on 6 February 2009, directed by Henry Selick and starring the voices of Dakota Fanning and Teri Hatcher.\nIn 2007, Gaiman announced that after ten years in development, the feature film of \"\" would finally begin production with a screenplay by Gaiman that he would direct for Warner Independent. Gaiman said that he agreed to direct the film \"with the carrot dangled in front of me that I could direct it. And we'll see if that happens, and if I'm a good director or not.\" Don Murphy and Susan Montford were named as producers, and Guillermo del Toro was named as the film's executive producer. By 2010, it had been reported that the film was no longer in production.\nSeeing Ear Theatre performed two of Gaiman's audio theatre plays, \"Snow, Glass, Apples\", Gaiman's retelling of Snow White, and \"Murder Mysteries\", a story of heaven before the Fall in which the first crime is committed. Both audio plays were published in the collection \"Smoke and Mirrors\" in 1998.\nAt Guillermo del Toro's request, he rewrote the opening of \"\" to make it look more like a fairy tale.\nGaiman's 2009 Newbery Medal winning book \"The Graveyard Book\" will be made into a movie, with Ron Howard as the director.\nGaiman wrote an episode of the long-running BBC science fiction series \"Doctor Who\", broadcast in 2011 during Matt Smith's second series as the Doctor. Shooting began in August 2010 for this episode, the original title of which was \"The House of Nothing\" but which was eventually transmitted as \"The Doctor's Wife\". The episode won the 2012 Hugo Award for Best Dramatic Presentation (Short Form). Gaiman made his return to \"Doctor Who\" with an episode titled \"Nightmare in Silver\", broadcast on 11 May 2013.\nGaiman returned to the Whoniverse in 2020 for the web series \"\"; he wrote the mini-episode \"Rory's Story\" which saw Arthur Darvill reprise his role of Rory Williams. Also in 2011, it was announced that Gaiman would be writing the script to a new film version of \"Journey to the West\". Gaiman appeared as himself on \"The Simpsons\" episode \"The Book Job\", which was broadcast on 20 November 2011.\nIn 2015, Starz greenlighted a series adaptation of Gaiman's novel \"American Gods\". Bryan Fuller and Michael Green wrote and were showrunners for the series. Gaiman received a Best Dramatic Presentation, Long Form Hugo Award in 2020 for the TV miniseries adaptation of \"Good Omens\", for which he wrote the screenplay. He voiced Gef in the black comedy film \"Nandor Fodor and the Talking Mongoose\", one of the film's titular characters, in 2023.\nRadio.\nA six-part radio play of \"Neverwhere\" was broadcast in March 2013, adapted by Dirk Maggs for BBC Radio 4 and Radio 4 Extra. The performance featured James McAvoy as Richard, Natalie Dormer, Benedict Cumberbatch, Christopher Lee, Bernard Cribbens, and Johnny Vegas.\nIn September 2014, Gaiman and Terry Pratchett joined forces with BBC Radio 4 to make the first-ever dramatisation of their co-penned novel \"Good Omens\", which was broadcast in December in five half-hour episodes and culminated in an hour-long final apocalyptic showdown. In 2021, Gaiman was cast as Duke Aubrey in an adaptation of Hope Mirrlees' \"Lud-in-the-Mist\", a novel Gaiman had previously proclaimed one of his favourites (and to which he had contributed a foreword for an edition by Cold Spring Press), for BBC Radio 4.\nPublic performances.\nGaiman frequently performs public readings from his stories and poetry, and has toured with his wife, musician Amanda Palmer. In some of these performances he has also sung songs, in \"a novelist's version of singing\", despite having \"no kind of singing voice\".\nIn 2015, Gaiman delivered a 100-minute lecture for the Long Now Foundation entitled \"How Stories Last\" about the nature of storytelling and how stories persist in human culture. In April 2018, Gaiman made a guest appearance on the television show \"The Big Bang Theory\", and his tweet about the show's fictional comic book store became the central theme of the episode \"The Comet Polarization\".\nIntellectual property disputes.\nIn 1993, Gaiman was contracted by Todd McFarlane to write a single issue of \"Spawn\", for Image Comics, which McFarlane had recently co-founded. McFarlane was promoting his new title by having guest authors Gaiman, Alan Moore, Frank Miller, and Dave Sim each write a single issue.\nIn issue No. 9 of the series, Gaiman introduced the characters Angela, Cogliostro, and Medieval Spawn. Prior to this issue, Spawn was an assassin who worked for the government and came back as a reluctant agent of Hell but had no real direction in his actions. In Angela, a cruel and malicious angel, Gaiman introduced a character who threatened Spawn's existence, as well as providing a moral opposite. Cogliostro was introduced as a mentor character for exposition and instruction, providing guidance. Medieval Spawn introduced a history and precedent that not all Spawns were self-serving or evil, giving additional character development to Malebolgia, the demon that creates Hellspawn.\nAs intended, all three characters were used repeatedly throughout the next decade by Todd McFarlane within the wider \"Spawn\" universe. In papers filed by Gaiman in early 2002, however, he claimed that the characters were jointly owned by their scripter (himself) and artist (McFarlane), not merely by McFarlane in his role as the creator of the series. Disagreement over who owned the rights to a character was the primary motivation for McFarlane and other artists to form Image Comics (although that argument related more towards disagreements between writers and artists as character creators). As McFarlane used the characters without Gaiman's permission or royalty payments, Gaiman believed his copyrighted work was being infringed upon, which violated their original oral agreement. McFarlane initially agreed that Gaiman had not signed away any rights to the characters, and negotiated with Gaiman to effectively \"swap\" McFarlane's interest in the character Marvelman. McFarlane had purchased an interest in the character when Eclipse Comics was liquidated while Gaiman was interested in being able to continue his aborted run of the Marvelman title. McFarlane later changed his initial position, claiming that Gaiman's work had only been work-for-hire and that McFarlane owned all of Gaiman's creations entirely. The presiding judge, however, ruled against their agreement being work for hire, based in large part on the legal requirement that \"copyright assignments must be in writing.\"\nThe Seventh Circuit Court of Appeals upheld the district court ruling in February 2004 granting joint ownership of the characters to Gaiman and McFarlane. On the specific issue of Cogliostro, presiding Judge John C. Shabaz proclaimed, \"The expressive work that is the comic-book character Count Nicholas Cogliostro was the joint work of Gaiman and McFarlane\u2014their contributions strike us as quite equal\u2014and both are entitled to ownership of the copyright\". Similar analysis led to similar results for the other two characters, Angela and Medieval Spawn.\nThis legal battle was brought by Gaiman and the specifically formed Marvels and Miracles, LLC, which Gaiman had previously created to help sort out the legal rights surrounding Marvelman. Gaiman had written \"Marvel 1602 \"in 2003 to help fund this project and all of Gaiman's profits for the original issues of the series were donated to Marvels and Miracles. The rights to Marvelman were subsequently purchased, from original creator Mick Anglo, by Marvel Comics in 2009.\nGaiman returned to court again over the \"Spawn\" characters Dark Ages Spawn, Domina, and Tiffany, claiming that they were \"derivative of the three he co-created with McFarlane.\" The judge ruled that Gaiman was right in these claims as well and gave McFarlane until the beginning of September 2010 to settle the matter.\nSexual assault and misconduct allegations.\nIn July and August 2024, five women accused Gaiman of sexual assault and abuse. All five were interviewed on the Tortoise Media podcast \"Master: The Allegations Against Neil Gaiman\". One, using the pseudonym \"Claire\", was also interviewed by \"The New York Times\". Claire described non-consensual kissing and groping by Gaiman after meeting him at a book tour event, with Gaiman making a $60,000 payment to her in August 2022. A woman identified as \"K\", who also first met Gaiman at a book signing, said that during their relationship he subjected her to painful sex that she \"neither wanted nor enjoyed\".\nScarlett Pavlovich, a former nanny for Gaiman and Palmer's child, alleges that Gaiman sexually assaulted her within hours of their first meeting in February 2022. Pavlovich recalled that he said \"Amanda told me I couldn't have you\" after the assault; according to one of Palmer's friends, Palmer had previously told Gaiman \"You could really hurt this person and break her; keep your hands off of her\". Pavlovich said that Gaiman had anal sex with her in the presence of his son.\nCaroline Wallner, a former tenant of Gaiman's named, alleges that he demanded sexual favours in exchange for being allowed to continue living on his property. Wallner says that on one occasion, Gaiman grabbed her hand and placed it on his penis while his young son was asleep in the same bed. In 2021, Wallner, her ex-husband, and Gaiman signed a non-disclosure agreement (NDA), and Gaiman paid Wallner $. In early 2025, Gaiman and Wallner both requested arbitration, the dispute resolution method mandated by the NDA, each accusing the other of violating the agreement.\nThe writer Julia Hobsbawm accused Gaiman of \"an aggressive, unwanted pass\" and described how Gaiman pushed her onto a sofa and French kissed her in 1986.\nIn September 2024, Disney halted production on the film adaptation of \"The Graveyard Book\" due to a variety of factors, including the sexual assault allegations against Gaiman. That same month, production on season three of \"Good Omens\" was put on hold; Gaiman ultimately left the project in October.\nIn January 2025 \"New York\" magazine published a cover story detailing the allegations against Gaiman. This article, which was published online on \"Vulture\", included interviews with four of the women who had previously spoken to Tortoise Media, as well as four more women. Later the same month, Dark Horse Comics announced that they would cut ties with Gaiman over the allegations, including cancelling his ongoing comic adaptation of \"Anansi Boys\". Gaiman was also dropped as a client by his agent Casarotto Ramsay.\nIn February 2025, Scarlett Pavlovich filed three federal lawsuits in the US that alleged human trafficking under the Trafficking Victims Protection Act, alongside formal allegations of sexual assault and coercion. One named Gaiman and Palmer as co-defendants and two were against Palmer alone, seeking at least US$million in damages. In his response to the lawsuit, Gaiman claimed that the American court lacked jurisdiction to hear the case because the alleged assaults happened in New Zealand, and asked for the case to be dismissed. Gaiman also accused Pavlovich of lying, presenting text messages in which she appeared to confirm that no sexual abuse had taken place, and claimed that police in New Zealand had already investigated her claims and found them to be false.\nGaiman has denied engaging in non-consensual sex, and dismissed Hobsbawm's allegations as his misreading of the situation. Gaiman's representatives claim that Wallner initiated their sexual encounters and that none of these occurred in the presence of Gaiman's child. In a blog post responding to coverage of the allegations against him, Gaiman said there were \"moments I half-recognise and moments I don't\". He denies engaging in any non-consensual sexual activity, but said he could have \"done so much better\" and was \"trying to do the work needed\".\nArtistic work.\nLiterary allusions.\nGaiman's work is known for its use of allusions. Meredith Collins, for instance, has commented upon the degree to which his novel \"Stardust\" depends on allusions to Victorian fairy tales and culture. In \"The Sandman\", literary figures and characters appear often; the character of Fiddler's Green is modeled on G. K. Chesterton, and both William Shakespeare and Geoffrey Chaucer appear as characters, as do several characters from \"A Midsummer Night's Dream\" and \"The Tempest\". The comic also draws from numerous mythologies.\nAnalyzing Gaiman's \"The Graveyard Book\", bibliographer and librarian Richard Bleiler detects patterns of and allusions to the Gothic novel, from Horace Walpole's \"The Castle of Otranto\" to Shirley Jackson's \"The Haunting of Hill House\". He concludes that Gaiman is \"utilizing works, characters, themes, and settings that generations of scholars have identified and classified as Gothic... [yet] subverts them and develops the novel by focusing on the positive aspects of maturation, concentrating on the values of learning, friendship, and sacrifice.\" Regarding another work's assumed connection and allusions to this form, Gaiman himself quipped: \"I've never been able to figure out whether \"Sandman\" is a gothic.\"\nClay Smith has argued that this sort of allusiveness serves to situate Gaiman as a strong authorial presence in his own works, often to the exclusion of his collaborators. However, Smith's viewpoint is in the minority: to many, if there is a problem with Gaiman's scholarship and intertextuality it is that \"... his literary merit and vast popularity have propelled him into the nascent comics canon so quickly that there is not yet a basis of critical scholarship about his work.\"\nDavid Rudd takes a more generous view in his study of the novel \"Coraline\", where he argues that the work plays and riffs productively on Sigmund Freud's concept of \"Unheimlich\" (\"the Uncanny\").\nThough Gaiman's work is frequently seen as exemplifying the monomyth structure laid out in Joseph Campbell's \"The Hero with a Thousand Faces\", Gaiman says that he started reading \"The Hero with a Thousand Faces\" but refused to finish it: \"I think I got about halfway through \"The Hero with a Thousand Faces\" and found myself thinking if this is true \u2013 I don't want to know. I really would rather not know this stuff. I'd rather do it because it's true and because I accidentally wind up creating something that falls into this pattern than be told what the pattern is.\"\nAwards and honours.\nNote: Gaiman's Carnegie Medal win for \"The Graveyard Book\" made him the first author to have won both the Carnegie &amp; Newbery Medals for the same work.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22058", "revid": "49636717", "url": "https://en.wikipedia.org/wiki?curid=22058", "title": "Nymph", "text": "Greek and Roman mythological creature\nA nymph (; ; sometimes spelled nymphe) is a minor female nature deity in ancient Greek folklore. Distinct from other Greek goddesses, nymphs are generally regarded as personifications of nature; they are typically tied to a specific place, landform, or tree, and are usually depicted as maidens. Because of their association with springs, they were often seen as having healing properties; other divine powers of the nymphs included divination and shapeshifting. In spite of their divine nature, they were not immortal.\nNymphs are divided into various broad subgroups based on their habitat, such as the Meliae (ash tree nymphs), the Dryads (oak tree nymphs), the Alseids (grove nymphs), the Naiads (spring nymphs), the Nereids (sea nymphs), the Oceanids (ocean nymphs), and the Oreads (mountain nymphs). Other nymphs included the Hesperides (evening nymphs), the Hyades (rain nymphs), and the Pleiades (companions of Artemis).\nNymphs featured in classic works of art, literature, and mythology. They are often attendants of goddesses and frequently occur in myths with a love motif, being the lovers of heroes and other deities. Desirable and promiscuous, nymphs can rarely be tamed, their dealings with mortals often marked by capricious aggression. Since the Middle Ages, nymphs have been sometimes popularly associated or even confused with fairies.\nEtymology.\nThe Greek word has the primary meaning of \"young woman; bride, young wife\" but is not usually associated with deities in particular. Yet the etymology of the noun remains uncertain. The Doric and Aeolic (Homeric) form is ().\nModern usage more often applies to young women, contrasting with \"parthenos\" () \"a virgin (of any age)\", and generically as \"kore\" ( &lt; ) \"maiden, girl\". The term is sometimes used by women to address each other and remains the regular Modern Greek term for \"bride\".\nAncient Greek mythology.\nNymphs were sometimes beloved by many and dwelt in specific areas related to the natural environment: e.g. mountainous regions; forests; springs. Other nymphs were part of the retinue of a god (such as Dionysus, Hermes, or Pan) or of a goddess (generally the huntress Artemis).\nThe Greek nymphs were also spirits invariably bound to places, not unlike the Latin \"genius loci\", and sometimes this produced complicated myths like the cult of Arethusa to Sicily. In some of the works of the Greek-educated Latin poets, the nymphs gradually absorbed into their ranks the indigenous Italian divinities of springs and streams (Juturna, Egeria, Carmentis, Fontus) while the Lymphae (originally Lumpae), Italian water goddesses, owing to the accidental similarity of their names, could be identified with the Greek Nymphae. The classical mythologies of the Roman poets were unlikely to have affected the rites and cults of individual nymphs venerated by country people in the springs and clefts of Latium. Among the Roman literate class, their sphere of influence was restricted and they appear almost exclusively as divinities of the watery element.\nGreek folk religion.\nThe ancient Greek belief in nymphs survived in many parts of the country into the early years of the twentieth century when they were usually known as \"nereids\". Nymphs often tended to frequent areas distant from humans but could be encountered by lone travelers outside the village, where their music might be heard, and the traveler could spy on their dancing or bathing in a stream or pool, either during the noon heat or in the middle of the night. They might appear in a whirlwind. Such encounters could be dangerous, bringing dumbness, besotted infatuation, madness or stroke to the unfortunate man. When parents believed their child to be nereid-struck, they would pray to the Saint Artemius (Perhaps this saint in particular being chosen is due to a corruption of the name of the goddess Artemis. If this is the case, it would be an example of \"practical polytheism in the worship of the saints\").\nNymphs and fairies.\nNymphs are often depicted in classic works across art, literature, mythology, and fiction. They are often associated with the medieval romances or Renaissance literature of the elusive fairies or elves.\nSleeping nymph.\nA motif that entered European art during the Renaissance was the idea of a statue of a nymph sleeping in a grotto or spring. This motif supposedly came from an Italian report of a Roman sculpture of a nymph at a fountain above the River Danube. The report, and an accompanying poem supposedly on the fountain describing the sleeping nymph, are now generally concluded to be a fifteenth-century forgery, but the motif proved influential among artists and landscape gardeners for several centuries after, with copies seen at neoclassical gardens such as the grotto at Stourhead.\nList.\nAll the names for various classes of nymphs have plural feminine adjectives, most agreeing with the substantive numbers and groups of nymphai. There is no single adopted classification that could be seen as canonical and exhaustive. Some classes of nymphs tend to overlap, which complicates the task of precise classification. e.g. \"dryads\" and \"hamadryads\" as nymphs of trees generally, \"meliai\" as nymphs of ash trees. According to classicist Robin Hard, these terms \"were hardly proper names at all, but feminine adjectives that could be assigned to the noun at will\", adding that \"[n]o orthodox or exhaustive classification of such beings was ever attempted, and ancient authors were often careless or arbitrary in the application of such titles\".\nBy dwelling or affinity.\nThe following is not the authentic Greek classification, but is intended as a guide:\nBy location.\nThe following is a list of individual nymphs or groups thereof associated with this or that particular location. Nymphs in such groups could belong to any of the classes mentioned above (Naiades, Oreades, and so on).\nOthers.\nThe following is a selection of names of the nymphs whose class was not specified in the source texts. For lists of Naiads, Oceanids, Dryades etc., see respective articles.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22059", "revid": "431183", "url": "https://en.wikipedia.org/wiki?curid=22059", "title": "Norse", "text": "Norse is a demonym for Norsemen, a Medieval North Germanic ethnolinguistic group ancestral to modern Scandinavians, defined as speakers of Old Norse from about the 9th to the 13th centuries.\nNorse may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "22063", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=22063", "title": "Natural law", "text": "Legal and philosophical theory that there are values inherent in nature\nNatural law (, ) is a philosophical and legal theory that posits the existence of a set of inherent laws derived from nature and universal moral principles, which are discoverable through reason. In ethics, natural law theory asserts that certain rights and moral values are inherent in human nature and can be understood universally, independent of enacted laws or societal norms. In jurisprudence, natural law\u2014sometimes referred to as iusnaturalism or jusnaturalism\u2014holds that there are objective legal standards based on morality that underlie and inform the creation, interpretation, and application of human-made laws. This contrasts with \"positive law\" (as in legal positivism), which emphasizes that laws are rules created by human authorities and are not necessarily connected to moral principles. Natural law can refer to \"theories of ethics, theories of politics, theories of civil law, and theories of religious morality\", depending on the context in which naturally-grounded practical principles are claimed to exist.\nIn Western tradition, natural law was anticipated by the pre-Socratics, for example, in their search for principles that governed the cosmos and human beings. The concept of natural law was documented in ancient Greek philosophy, including Aristotle, and was mentioned in ancient Roman philosophy by Cicero. References to it are also found in the Old and New Testaments of the Bible, and were later expounded upon in the Middle Ages by Christian philosophers such as Albert the Great and Thomas Aquinas. The School of Salamanca made notable contributions during the Renaissance.\nAlthough the central ideas of natural law had been part of Christian thought since the Roman Empire, its foundation as a consistent system was laid by Aquinas, who synthesized and condensed his predecessors' ideas into his (lit.\u2009'natural law'). Aquinas argues that because human beings have reason, and because reason is a spark of the divine, all human lives are sacred and of infinite value compared to any other created object, meaning everyone is fundamentally equal and bestowed with an intrinsic basic set of rights that no one can remove.\nModern natural law theory took shape in the Age of Enlightenment, combining inspiration from Roman law, Christian scholastic philosophy, and contemporary concepts such as social contract theory. It was used in challenging the theory of the divine right of kings, and became an alternative justification for the establishment of a social contract, positive law, and government\u2014and thus legal rights\u2014in the form of classical republicanism. John Locke was a key Enlightenment-era proponent of natural law, stressing its role in the justification of property rights and the right to revolution. In the early decades of the 21st century, the concept of natural law is closely related to the concept of natural rights and has libertarian and conservative proponents. Indeed, many philosophers, jurists and scholars use natural law synonymously with natural rights () or natural justice; others distinguish between natural law and natural right.\nHistory.\nAncient Greece.\nPlato.\nPlato did not have an explicit theory of natural law, but his concept of nature, according to John Wild, contains some of the elements of many natural law theories. According to Plato, we live in an orderly universe. The basis of this orderly universe or nature are the forms, most fundamentally the Form of the Good, which Plato calls \"the brightest region of Being\". The Form of the Good is the cause of all things, and a person who sees it is led to act wisely. In the \"Symposium\", the Good is closely identified with the Beautiful, and Plato describes how Socrates's experience of the Beautiful enabled him to resist the temptations of wealth and sex. In the \"Republic\", the ideal community is \"a city which would be established in accordance with nature\".\nAristotle.\nGreek philosophy emphasized the distinction between \"nature\" and \"law\", \"custom\", or \"convention\". What the law commanded is expected to vary from place to place, but what is \"by nature\" should be the same everywhere. A \"law of nature\" therefore has the flavor more of a paradox than something that obviously existed. Against the conventionalism that the distinction between nature and custom could engender, Socrates and his philosophic heirs, Plato and Aristotle, posited the existence of natural justice or natural right. Aristotle is often said to be the father of natural law.\nAristotle's association with natural law may be due to Thomas Aquinas's interpretation of his work. But whether Aquinas correctly read Aristotle is in dispute. According to some, Aquinas conflates natural law and natural right, the latter of which Aristotle posits in Book V of the \"Nicomachean Ethics\" (Book IV of the \"Eudemian Ethics\"). According to this interpretation, Aquinas's influence was such as to affect a number of early translations of these passages in an unfortunate manner, though more recent translations render them more literally. Aristotle notes that natural justice is a species of political justice, specifically the scheme of distributive and corrective justice that would be established under the best political community; if this took the form of law, it could be called a natural law, though Aristotle does not discuss this and suggests in the \"Politics\" that the best regime may not rule by law at all.\nThe best evidence of Aristotle's having thought there is a natural law is in the \"Rhetoric\", where Aristotle notes that, aside from the \"particular\" laws that each people has set up for itself, there is a \"common\" law that is according to nature. Specifically, he quotes Sophocles and Empedocles:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nUniversal law is the law of Nature. For there really is, as every one to some extent divines, a natural justice and injustice that is binding on all men, even on those who have no association or covenant with each other. It is this that Sophocles' Antigone clearly means when she says that the burial of Polyneices was a just act in spite of the prohibition: she means that it was just by nature:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Not of to-day or yesterday it is,\nBut lives eternal: none can date its birth.\"\nAnd so Empedocles, when he bids us kill no living creature, he is saying that to do this is not just for some people, while unjust for others:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Nay, but, an all-embracing law, through the realms of the sky\nUnbroken it stretcheth, and over the earth's immensity.\"\nSome critics believe that this remark's context suggests only that Aristotle advised that it can be rhetorically advantageous to appeal to such a law, especially when the \"particular\" law of one's own city is averse to the case being made, not that there actually is such a law. Moreover, they write that Aristotle considered two of the three candidates for a universally valid, natural law provided in this passage to be wrong. Aristotle's paternity of natural law tradition is consequently disputed.\nStoic natural law.\nThe development of this tradition of natural justice into one of natural law is usually attributed to the Stoics. The rise of natural law as a universal system coincided with the rise of large empires and kingdoms in the Greek world. Whereas the \"higher\" law that Aristotle suggested one could appeal to was emphatically natural, in contradistinction to being the result of divine positive legislation, the Stoic natural law was indifferent to either the natural or divine source of the law: the Stoics asserted the existence of a rational and purposeful order to the universe (a divine or eternal law), and the means by which a rational being lived in accordance with this order was the natural law, which inspired actions that accorded with virtue.\nAs the English historian A. J. Carlyle notes:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;There is no change in political theory so startling in its completeness as the change from the theory of Aristotle to the later philosophical view represented by Cicero and Seneca\u00a0... We think that this cannot be better exemplified than with regard to the theory of the equality of human nature.\nCharles H. McIlwain likewise observes that \"the idea of the equality of men is the most profound contribution of the Stoics to political thought\" and that \"its greatest influence is in the changed conception of law that in part resulted from it.\nNatural law first appeared among the Stoics, who believed that God is everywhere and in everyone (see classical pantheism). According to this belief, there is a \"divine spark\" within us that helps us live in accordance with nature. The Stoics believed there is a way in which the universe has been designed, and that natural law helps us to harmonize with this.\nAncient Rome.\nIn his \"History of the Roman Republic\", Livy puts a formulation of the Natural Law into the mouth of Marcus Furius Camillus during the siege of the Falerii You, villain, have not come with your villainous offer to a nation or a commander like yourself. Between us and the Faliscans there is no fellowship based on a formal compact as between man and man, but the fellowship which is based on natural instincts exists between us, and will continue to do so. There are rights of war as there are rights of peace, and we have learnt to wage our wars with justice no less than with courage. We do not use our weapons against those of an age which is spared even in the capture of cities, but against those who are armed as we are, and who without any injury or provocation from us attacked the Roman camp at Veii. These men you, as far as you could, have vanquished by an unprecedented act of villainy; I shall vanquish them as I vanquished Veii, by Roman arts, by courage and strategy and force of arms.\nCicero wrote in his \"De Legibus\" that both justice and law originate from what nature has given to humanity, from what the human mind embraces, from the function of humanity, and from what serves to unite humanity. For Cicero, natural law obliges us to contribute to the general good of the larger society. The purpose of positive laws is to provide for \"the safety of citizens, the preservation of states, and the tranquility and happiness of human life\". In this view, \"wicked and unjust statutes\" are \"anything but 'laws'\", because \"in the very definition of the term 'law' there inheres the idea and principle of choosing what is just and true.\" Law, for Cicero, \"ought to be a reformer of vice and an incentive to virtue.\" Cicero expressed the view that \"the virtues which we ought to cultivate, always tend to our own happiness, and that the best means of promoting them consists in living with men in that perfect union and charity which are cemented by mutual benefits.\"\nIn \"De Re Publica\", he writes:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;There is indeed a law, right reason, which is in accordance with nature; existing in all, unchangeable, eternal. Commanding us to do what is right, forbidding us to do what is wrong. It has dominion over good men, but possesses no influence over bad ones. No other law can be substituted for it, no part of it can be taken away, nor can it be abrogated altogether. Neither the people or the senate can absolve from it. It is not one thing at Rome, and another thing at Athens: one thing to-day, and another thing to-morrow; but it is eternal and immutable for all nations and for all time.\nCicero influenced the discussion of natural law for many centuries to come, up through the era of the American Revolution. The jurisprudence of the Roman Empire was rooted in Cicero, who held \"an extraordinary grip ... upon the imagination of posterity\" as \"the medium for the propagation of those ideas which informed the law and institutions of the empire.\" Cicero's conception of natural law \"found its way to later centuries notably through the writings of Isidore of Seville and the Decretum of Gratian.\" Thomas Aquinas, in his summary of medieval natural law, quoted Cicero's statement that \"nature\" and \"custom\" were the sources of a society's laws.\nThe Renaissance Italian historian Leonardo Bruni praised Cicero as the person \"who carried philosophy from Greece to Italy, and nourished it with the golden river of his eloquence.\" The legal culture of Elizabethan England, exemplified by Sir Edward Coke, was \"steeped in Ciceronian rhetoric\". The Scottish moral philosopher Francis Hutcheson, as a student at Glasgow, \"was attracted most by Cicero, for whom he always professed the greatest admiration.\" More generally in eighteenth-century Great Britain, Cicero's name was a household word among educated people. Likewise, \"in the admiration of early Americans Cicero took pride of place as orator, political theorist, stylist, and moralist.\"\nThe British polemicist Thomas Gordon \"incorporated Cicero into the radical ideological tradition that travelled from the mother country to the colonies in the course of the eighteenth century and decisively shaped early American political culture.\" Cicero's description of the immutable, eternal, and universal natural law was quoted by Burlamaqui and later by the American revolutionary legal scholar James Wilson. Cicero became John Adams's \"foremost model of public service, republican virtue, and forensic eloquence\". Adams wrote of Cicero that \"as all the ages of the world have not produced a greater statesman and philosopher united in the same character, his authority should have great weight.\" Thomas Jefferson \"first encountered Cicero as a schoolboy while learning Latin, and continued to read his letters and discourses throughout his life. He admired him as a patriot, valued his opinions as a moral philosopher, and there is little doubt that he looked upon Cicero's life, with his love of study and aristocratic country life, as a model for his own.\" Jefferson described Cicero as \"the father of eloquence and philosophy.\"\nChristianity.\nPaul's Epistle to the Romans is generally considered the Scriptural authority for the Christian idea of natural law as something that was endowed in all men, contrasted with an idea of law as something revealed (for example, the law revealed to Moses by God).\nBecause of its origins in the Old Testament, early Church Fathers, especially those in the West, saw natural law as part of the natural foundation of Christianity. The most notable among these was Augustine of Hippo, who equated natural law with humanity's prelapsarian state; as such, a life according to unbroken human nature was no longer possible and persons needed instead to seek healing and salvation through the divine law and grace of Jesus Christ. Augustine was also among the earliest to examine the legitimacy of the laws of man, and attempt to define the boundaries of what laws and rights occur naturally based on wisdom and conscience, instead of being arbitrarily imposed by mortals, and if people are obligated to obey laws that are unjust.\nThe natural law was inherently teleological as well as deontological. For Christians, natural law is how human beings manifest the divine image in their life. This mimicry of Christ's own life is impossible to accomplish except by means of the power of grace. Thus, whereas deontological systems merely require certain duties be performed, Christianity explicitly states that no one can, in fact, perform any duties if grace is lacking. For Christians, natural law flows not from divine commands, but from the fact that humanity is made in God's image, humanity is empowered by God's grace. Living the natural law is how humanity displays the gifts of life and grace, the gifts of all that is good.\nConsequences are in God's hands, consequences are generally not within human control, thus in natural law, actions are judged by three things: (1) the person's intent, (2) the circumstances of the act and (3) the nature of the act. The apparent good or evil consequence resulting from the moral act is not relevant to the act itself. The specific content of the natural law is therefore determined by how each person's acts mirror God's internal life of love. Insofar as one lives the natural law, temporal satisfaction may or may not be attained, but salvation will be attained. The state, in being bound by the natural law, is conceived as an institution whose purpose is to assist in bringing its subjects to true happiness. True happiness derives from living in harmony with the mind of God as an image of the living God.\nAfter the Protestant Reformation, some Protestant denominations maintained parts of the Catholic concept of natural law. The English theologian Richard Hooker from the Church of England adapted Thomistic notions of natural law to Anglicanism five principles: to live, to learn, to reproduce, to worship God, and to live in an ordered society.\nCatholic natural law jurisprudence.\nEarly natural Christian law thinkers.\nIn Catholic countries in the tradition of the early Christian law and in the twelfth century, Gratian equated the natural law with divine law. Albertus Magnus would address the subject a century later, and his pupil, Thomas Aquinas, in his \"Summa Theologica\" I-II qq. 90\u2013106, restored natural law to its independent state, asserting natural law as the rational creature's participation in the eternal law. Yet, since human reason could not fully comprehend the eternal law, it needed to be supplemented by revealed divine law. (See also Biblical law in Christianity.)\nThomas Aquinas.\nAquinas taught that all human or positive laws were to be judged by their conformity to the natural law. An unjust law is not a law, in the full sense of the word. It retains merely the 'appearance' of law insofar as it is duly constituted and enforced in the same way a just law is, but is itself a 'perversion of law.' At this point, the natural law was not only used to pass judgment on the moral worth of various laws, but also to determine what those laws meant in the first place. This principle laid the seed for possible societal tension with reference to tyrants.\nThe Catholic Church holds the view of natural law introduced by Albertus Magnus and elaborated by Thomas Aquinas, particularly in his \"Summa Theologica\", and often as filtered through the School of Salamanca. This view is also shared by some Protestants, and was delineated by Anglican writer C. S. Lewis in his works \"Mere Christianity\" and \"The Abolition of Man\".\nThe Catholic Church understands human beings to consist of body and soul, and that the two are inextricably linked. Humans are capable of discerning the difference between good and evil because they have a conscience. There are many manifestations of the good that we can pursue. Some, like procreation, are common to other animals, while others, like the pursuit of truth, are inclinations peculiar to the capacities of human beings.\nTo know what is right, one must use one's reason and apply it to Thomas Aquinas' precepts. This reason is believed to be embodied, in its most abstract form, in the concept of a primary precept: \"Good is to be sought, evil avoided.\" Aquinas explains that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nthere belongs to the natural law, first, certain most general precepts, that are known to all; and secondly, certain secondary and more detailed precepts, which are, as it were, conclusions following closely from first principles. As to those general principles, the natural law, in the abstract, can nowise be blotted out from men's hearts. But it is blotted out in the case of a particular action, insofar as reason is hindered from applying the general principle to a particular point of practice, on account of concupiscence or some other passion, as stated above (77, 2). But as to the other, i.e., the secondary precepts, the natural law can be blotted out from the human heart, either by evil persuasions, just as in speculative matters errors occur in respect of necessary conclusions; or by vicious customs and corrupt habits, as among some men, theft, and even unnatural vices, as the Apostle states (Rm. i), were not esteemed sinful.\nHowever, while the primary and immediate precepts cannot be \"blotted out\", the secondary precepts can be. Therefore, for a deontological ethical theory they are open to a surprisingly large amount of interpretation and flexibility. Any rule that helps humanity to live up to the primary or subsidiary precepts can be a secondary precept, for example:\nNatural moral law is concerned with both exterior and interior acts, also known as action and motive. Simply doing the right thing is not enough; to be truly moral one's motive must be right as well. For example, helping an old lady across the road (good exterior act) to impress someone (bad interior act) is wrong. However, good intentions do not always lead to good actions. The motive must coincide with the cardinal or theological virtues. Cardinal virtues are acquired through reason applied to nature; they are:\nThe theological virtues are:\nAccording to Aquinas, to lack any of these virtues is to lack the ability to make a moral choice. For example, consider a person who possesses the virtues of justice, prudence, and fortitude, yet lacks temperance. Due to their lack of self-control and desire for pleasure, despite their good intentions, they will find themself swaying from the moral path.\nSchool of Salamanca.\nBased on the works of Thomas Aquinas, the members of the School of Salamanca were in the 16th and 17th centuries the first people to develop a modern approach of natural law, which greatly influence Grotius. For Leonardus Lessius, natural law ensues from the rational nature and the natural state of everything: that way it is immutable on the contrary of positive law, which stems from divine or human will.\nJurists and theologians claimed thus the right to observe the conformity of the positive law with natural law. For Domingo de Soto, the theologians task is to assess the moral foundations of civil law. Due to this review right based on natural law, Soto criticised the new Spanish charities' laws on the pretext that they violated the fundamental rights of the poors, or that Juan de Mariana considered that the consent of population was needed in matter of taxation or money alteration. Criticized by Protestant thinkers like Friedrich Balduin and Samuel von Pufendorf, this view was salvaged by Pope Leo XIII in the encyclical , in which he asked the members of clergy to analyze modern legislation in view of higher norms.\nNatural law played also a great role in the diffusion of a contractual consentualism. First recognize by glossators and postglossators before the ecclesiastic courts, it was only in the 16th century that civil law allowed the principle of the binding nature of contracts on the basis of pure consent. As Pedro de O\u00f1ate said, \"Consequently, natural law, canon law and Hispanic law entirely agree and innumerable difficulties, frauds, litigations and disputes have been removed thanks to such great consensus and clarity in the laws. To the contracting parties, liberty has very wisely been restored\".\nBesides, natural law also requires the respect of the commutative justice in contractual relations: both parties are bound to respect the notion of just prices on penalty of sin.\nModern catechism.\nThe Catechism of the Catholic Church describes it in the following way: \"The natural law expresses the original moral sense which enables man to discern by reason the good and the evil, the truth and the lie: 'The natural law is written and engraved in the soul of each and every man, because it is human reason ordaining him to do good and forbidding him to sin\u00a0... But this command of human reason would not have the force of law if it were not the voice and interpreter of a higher reason to which our spirit and our freedom must be submitted.'\"\nThe natural law consists, for the Catholic Church, of one universal principle from which are derived all natural moral obligations or duties. Thomas Aquinas resumes the various ideas of Catholic moral thinkers about what this principle is: since good is what primarily falls under the apprehension of the practical reason, the supreme principle of moral action must have the good as its central idea, and therefore the supreme principle is that good is to be done and evil avoided.\nIslamic natural law.\nAb\u016b Rayh\u0101n al-B\u012br\u016bn\u012b, a medieval scholar, scientist, and polymath, understood \"natural law\" as the survival of the fittest. He argued that the antagonism between human beings can be overcome only through a divine law, which he believed to have been sent through prophets. This is also said to be the general position of the Ashari school, the largest school of Sunni theology, as well as Ibn Hazm. Conceptualized thus, all \"laws\" are viewed as originating from subjective attitudes actuated by cultural conceptions and individual preferences, and so the notion of \"divine revelation\" is justified as some kind of \"divine intervention\" that replaces human positive \"laws\", which are criticized as being relative, with a single divine positive \"law\". This, however, also entails that anything may be included in \"the divine law\" as it would in \"human laws\", but unlike the latter, \"God's law\" is seen as binding regardless of the nature of the commands by virtue of \"God's might\": since God is not subject to human laws and conventions, He may command what He wills just as He may do what He wills.\nThe Maturidi school, the second-largest school of Sunni theology, as well as the Mu'tazilites, posits the existence of a form of natural, or \"objective\", law that humans can comprehend. Abu Mansur al-Maturidi stated that the human mind could know of the existence of God and the major forms of \"good\" and \"evil\" without the help of revelation. Al-Maturidi gives the example of stealing, which, he believes, is known to be evil by reason alone due to people's working hard for their property. Similarly, killing, fornication, and drunkenness are all \"discernible evils\" that the human mind could know of according to al-Maturidi. Likewise, Averroes (Ibn Rushd), in his treatise on \"Justice and Jihad\" and his commentary on Plato's \"Republic\", writes that the human mind can know of the unlawfulness of killing and stealing and thus of the five maqasid or higher intents of the Islamic sharia, or the protection of religion, life, property, offspring, and reason. His Aristotelian commentaries also influenced the subsequent Averroist movement and the writings of Thomas Aquinas.\nIbn Qayyim Al-Jawziyya also posited that human reason could discern between \"great sins\" and \"good deeds\". Nonetheless, he, like Ibn Taymiyah, emphasized the authority of \"divine revelation\" and asserted that it must be followed even if it \"seems\" to contradict human reason, though he stressed that most, if not all, of \"God's commands\" are both sensible (that is, rationalizable) and advantageous to humans in both \"this life\" and \"the hereafter\".\nThe concept of \"Istislah\" in Islamic law bears some similarities to the natural law tradition in the West, as exemplified by Thomas Aquinas. However, whereas natural law deems good what is self-evidently good, according as it tends towards the fulfillment of the person, \"istislah\" typically calls good whatever is related to one of five \"basic goods\". Many jurists, theologians, and philosophers attempted to abstract these \"basic and fundamental goods\" from legal precepts. Al-Ghazali, for instance, defined them as religion, life, reason, lineage, and property, while others add \"honor\" also.\nBrehon law.\nEarly Irish law, (The Great Tradition), mentions in a number of places or natural law. This is a concept predating European legal theory, and reflects a type of law that is universal and may be determined by reason and observation of natural action. Neil McLeod identifies concepts that law must accord with: (truth) and (right or entitlement). These two terms occur frequently, though Irish law never strictly defines them. Similarly, the term (law in accordance with proper order) occurs in some places, and even in the titles of certain texts. These were two very real concepts to the jurists and the value of a given judgment with respect to them was apparently ascertainable. McLeod has also suggested that most of the specific laws mentioned have passed the test of time and thus their truth has been confirmed, while other provisions are justified in other ways because they are younger and have not been tested over time.\nThe laws were written in the oldest dialect of the Irish language, called [Bairla-faina], which even at the time was so difficult that persons about to become brehons had to be specially instructed in it; the length of time from beginning to becoming a learned Brehon was usually 20 years. However, under the law any third person could fulfill the duty if both parties agreed, and both were sane. It has been included in an Ethno-Celtic breakaway subculture, as it has religious undertones and freedom of religious expression allows it to once again be used as a valid system in Western Europe.\nEnglish jurisprudence.\nHeinrich A. Rommen remarked upon \"the tenacity with which the spirit of the English common law retained the conceptions of natural law and equity which it had assimilated during the Catholic Middle Ages, thanks especially to the influence of Henry de Bracton (d. 1268) and Sir John Fortescue (d. cir. 1476).\" Bracton's translator notes that Bracton \"was a trained jurist with the principles and distinctions of Roman jurisprudence firmly in mind\"; but Bracton adapted such principles to English purposes rather than copying slavishly. In particular, Bracton turned the imperial Roman maxim that \"the will of the prince is law\" on its head, insisting that the king is \"under\" the law.\nThe legal historian Charles F. Mullett has noted Bracton's \"ethical definition of law, his recognition of justice, and finally his devotion to natural rights\". Bracton considered justice to be the \"fountain-head\" from which \"all rights arise\". For his definition of justice, Bracton quoted the twelfth-century Italian jurist Azo: \"Justice is the constant and unfailing will to give to each his right.\" Bracton's work was the second legal treatise studied by the American historical figure Thomas Jefferson as a young apprentice lawyer.\nFortescue stressed \"the supreme importance of the law of God and of nature\" in works that \"profoundly influenced the course of legal development in the following centuries.\" The legal scholar Ellis Sandoz has noted that \"the historically ancient and the ontologically higher law\u2014eternal, divine, natural\u2014are woven together to compose a single harmonious texture in Fortescue's account of English law.\" As the legal historian Norman Doe explains: \"Fortescue follows the general pattern set by Aquinas. The objective of every legislator is to dispose people to virtue. It is by means of law that this is accomplished. Fortescue's definition of law (also found in Accursius and Bracton), after all, was 'a sacred sanction commanding what is virtuous [] and forbidding the contrary'.\" Fortescue cited the great Italian Leonardo Bruni for his statement that \"virtue alone produces happiness\".\nChristopher St. Germain's \"The Doctor and Student\" was a classic of English jurisprudence. Norman Doe notes that St. Germain's view \"is essentially Thomist\", quoting Thomas Aquinas's definition of law as \"an ordinance of reason made for the common good by him who has charge of the community, and promulgated\".\nSir Edward Coke was the preeminent jurist of his time. Coke's preeminence extended across the ocean: \"For the American revolutionary leaders, 'law' meant Sir Edward Coke's custom and right reason.\" Coke defined law as \"perfect reason, which commands those things that are proper and necessary and which prohibits contrary things\". For Coke, human nature determined the purpose of law; and law was superior to any one person's reason or will. Coke's discussion of natural law appears in his report of \"Calvin's Case\" (1608): \"The law of nature is that which God at the time of creation of the nature of man infused into his heart, for his preservation and direction.\" In this case the judges found that \"the ligeance or faith of the subject is due unto the King by the law of nature: secondly, that the law of nature is part of the law of England: thirdly, that the law of nature was before any judicial or municipal law: fourthly, that the law of nature is immutable.\" To support these findings, the assembled judges (as reported by Coke, who was one of them) cited as authorities Aristotle, Cicero, and the Apostle Paul; as well as Bracton, Fortescue, and St. Germain.\nAfter Coke, the most famous common law jurist of the seventeenth century is Sir Matthew Hale. Hale wrote a treatise on natural law that circulated among English lawyers in the eighteenth century and survives in three manuscript copies. This natural-law treatise has been published as \"Of the Law of Nature\" (2015). Hale's definition of the natural law reads: \"It is the Law of Almighty God given by him to Man with his Nature discovering the morall good and moral evill of Moral Actions, commanding the former, and forbidding the latter by the secret voice or dictate of his implanted nature, his reason, and his concience.\"\nHe viewed natural law as antecedent, preparatory, and subsequent to civil government, and stated that human law \"cannot forbid what the Law of Nature injoins, nor Command what the Law of Nature prohibits.\" He cited as authorities Plato, Aristotle, Cicero, Seneca, Epictetus, and the Apostle Paul. He was critical of Hobbes's reduction of natural law to self-preservation and Hobbes's account of the state of nature, but drew positively on Hugo Grotius's \"De jure belli ac pacis\", Francisco Su\u00e1rez's \"Tractatus de legibus ac deo legislatore\", and John Selden's \"De jure naturali et gentium juxta disciplinam Ebraeorum\".\nAs early as the thirteenth century, it was held that \"the law of nature\u00a0... is the ground of all law.\" and by the Chancellor and Judges that \"it is required by the law of nature that every person, before he can be punish'd, ought to be present; and if absent by contumacy, he ought to be summoned and make default.\" Further, in 1824, we find it held that \"proceedings in our Courts are founded upon the law of England, and that law is again founded upon the law of nature and the revealed law of God. If the right sought to be enforced is inconsistent with either of these, the English municipal courts cannot recognize it.\"\nHobbes.\nBy the 17th century, the medieval teleological view came under intense criticism from some quarters. Thomas Hobbes instead founded a contractarian theory of legal positivism on what all men could agree upon: what they sought (happiness) was subject to contention, but a broad consensus could form around what they feared, such as violent death at the hands of another. The natural law was how a rational human being, seeking to survive and prosper, would act. Natural law, therefore, was discovered by considering humankind's natural rights, whereas previously it could be said that natural rights were discovered by considering the natural law.\nIn Hobbes' opinion, the only way natural law could prevail was for men to submit to the commands of the sovereign. Because the ultimate source of law now comes from the sovereign, and the sovereign's decisions need not be grounded in morality, legal positivism is born. Jeremy Bentham's modifications on legal positivism further developed the theory.\nAs used by Thomas Hobbes in his treatises \"Leviathan\" and \"De Cive\", natural law is \"a precept, or general rule, found out by reason, by which a man is forbidden to do, that, which is destructive of his life, or taketh away the means of preserving the same; and to omit, that, by which he thinketh it may best be preserved.\"\nAccording to Hobbes, there are nineteen Laws. The first two are expounded in chapter XIV of \"Leviathan\" (\"of the first and second natural laws; and of contracts\"); the others in chapter XV (\"of other laws of nature\").\nHobbes's philosophy includes a frontal assault on the founding principles of the earlier natural legal tradition, disregarding the traditional association of virtue with happiness, and likewise re-defining \"law\" to remove any notion of the promotion of the common good. Hobbes has no use for Aristotle's association of nature with human perfection, inverting Aristotle's use of the word \"nature\". Hobbes posits a primitive, unconnected state of nature in which men, having a \"natural proclivity\u00a0... to hurt each other\" also have \"a Right to every thing, even to one anothers body\"; and \"nothing can be Unjust\" in this \"warre of every man against every man\" in which human life is \"solitary, poore, nasty, brutish, and short.\"\nRejecting Cicero's view that people join in society primarily through \"a certain social spirit which nature has implanted in man\", Hobbes declares that men join in society simply for the purpose of \"getting themselves out from that miserable condition of Warre, which is necessarily consequent\u00a0... to the naturall Passions of men, when there is no visible Power to keep them in awe.\" As part of his campaign against the classical idea of natural human sociability, Hobbes inverts that fundamental natural legal maxim, the Golden Rule. Hobbes's version is \"Do not that to another, which thou wouldst not have done to thy selfe.\"\nCumberland's rebuttal of Hobbes.\nThe English cleric Richard Cumberland wrote a lengthy and influential attack on Hobbes's depiction of individual self-interest as the essential feature of human motivation. Historian Knud Haakonssen has noted that in the eighteenth century, Cumberland was commonly placed alongside Alberico Gentili, Hugo Grotius and Samuel Pufendorf \"in the triumvirate of seventeenth-century founders of the 'modern' school of natural law\". The eighteenth-century philosophers Shaftesbury and Hutcheson \"were obviously inspired in part by Cumberland\". Historian Jon Parkin likewise describes Cumberland's work as \"one of the most important works of ethical and political theory of the seventeenth century\".\nParkin observes that much of Cumberland's material \"is derived from Roman Stoicism, particularly from the work of Cicero, as \"Cumberland deliberately cast his engagement with Hobbes in the mould of Cicero's debate between the Stoics, who believed that nature could provide an objective morality, and Epicureans, who argued that morality was human, conventional and self-interested.\" In doing so, Cumberland de-emphasized the overlay of Christian dogma (in particular, the doctrine of \"original sin\" and the corresponding presumption that humans are incapable of \"perfecting\" themselves without divine intervention) that had accreted to natural law in the Middle Ages.\nBy way of contrast to Hobbes's multiplicity of laws, Cumberland states in the very first sentence of his \"Treatise of the Laws of Nature\" that \"all the Laws of Nature are reduc'd to that one, of Benevolence toward all Rationals.\" He later clarifies: \"By the name \"Rationals\" I beg leave to understand, as well \"God\" as \"Man\"; and I do it upon the Authority of Cicero.\" Cumberland argues that the mature development (\"perfection\") of human nature involves the individual human willing and acting for the common good.\nFor Cumberland, human interdependence precludes Hobbes's natural right of each individual to wage war against all the rest for personal survival. However, Haakonssen warns against reading Cumberland as a proponent of \"enlightened self-interest\". Rather, the \"proper moral love of humanity\" is \"a disinterested love of God through love of humanity in ourselves as well as others\". Cumberland concludes that actions \"principally conducive to our Happiness\" are those that promote \"the Honour and Glory of God\" and also \"Charity and Justice towards men\".\nCumberland emphasizes that desiring the well-being of our fellow humans is essential to the \"pursuit of our own Happiness\". He cites \"reason\" as the authority for his conclusion that happiness consists in \"the most extensive Benevolence\", but he also mentions as \"Essential Ingredients of Happiness\" the \"Benevolent Affections\", meaning \"Love and Benevolence towards others\", as well as \"that Joy, which arises from their Happiness\".\nAmerican jurisprudence.\nThe United States Declaration of Independence, authored primarily by Thomas Jefferson and ratified on 4 July 1776 by the Second Continental Congress in Philadelphia, states that it has become necessary for the people of the United States to assume \"the separate and equal station to which the Laws of Nature and of Nature's God entitle them\". Some early American lawyers and judges perceived natural law as too tenuous, amorphous, and evanescent a legal basis for grounding concrete rights and governmental limitations. Natural law did, however, serve as authority for legal claims and rights in some judicial decisions, legislative acts, and legal pronouncements. Robert Lowry Clinton argues that the Constitution of the United States rests on a common law foundation and the common law, in turn, rests on a classical natural law foundation.\nEuropean liberal natural law.\nLiberal natural law grew out of the medieval Christian natural law theories and out of Hobbes' revision of natural law, sometimes in an uneasy balance of the two.\nSir Alberico Gentili and Hugo Grotius based their philosophies of international law on natural law. In particular, Grotius's writings on freedom of the seas and just war theory directly appealed to natural law. About natural law itself, he wrote that \"even the will of an omnipotent being cannot change or abrogate\" natural law, which \"would maintain its objective validity even if we should assume the impossible, that there is no God or that he does not care for human affairs.\" (\"De iure belli ac pacis\", Prolegomeni XI). This is the famous argument \"etiamsi daremus\" (\"non esse Deum\"), that made natural law no longer dependent on theology. However, German church-historians Ernst Wolf and M. Elze disagreed and wrote that Grotius' concept of natural law did have a theological basis. In Grotius' view, the Old Testament contained moral precepts (e.g. the Decalogue) which Christ confirmed and therefore were still valid. Moreover, they were useful in explaining the content of natural law. Both biblical revelation and natural law originated in God and could therefore not contradict each other.\nIn a similar way, Samuel Pufendorf gave natural law a theological foundation and applied it to his concepts of government and international law.\nJohn Locke incorporated natural law into many of his theories and philosophy, especially in \"Two Treatises of Government\". There is considerable debate about whether his conception of natural law was more akin to that of Aquinas (filtered through Richard Hooker) or Hobbes' radical reinterpretation, though the effect of Locke's understanding is usually phrased in terms of a revision of Hobbes upon Hobbesian contractarian grounds. Locke turned Hobbes' prescription around, saying that if the ruler went against natural law and failed to protect \"life, liberty, and property,\" people could justifiably overthrow the existing state and create a new one.\nWhile Locke spoke in the language of natural law, the content of this law was by and large protective of natural rights, and it was this language that later liberal thinkers preferred. Political philosopher Jeremy Waldron has pointed out that Locke's political thought was based on \"a particular set of Protestant Christian assumptions.\" To Locke, the content of natural law was identical with biblical ethics as laid down especially in the Decalogue, Christ's teaching and exemplary life, and Paul's admonitions. Locke derived the concept of basic human equality, including the equality of the sexes (\"Adam and Eve\"), from http://, the starting-point of the theological doctrine of Imago Dei. One of the consequences is that as all humans are created equally free, governments need the consent of the governed.\nThomas Jefferson, arguably echoing Locke, appealed to unalienable rights in the \"Declaration of Independence\", \"We hold these truths to be self-evident, that all men are \"created\" equal, that they are endowed by their \"Creator\" with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness.\" The Lockean idea that governments need the consent of the governed was also fundamental to the Declaration of Independence, as the American Revolutionaries used it as justification for their separation from the British crown.\nThe Belgian philosopher of law Frank van Dun is one among those who are elaborating a secular conception of natural law in the liberal tradition. Anarcho-capitalist theorist Murray Rothbard argues that \"the very existence of a natural law discoverable by reason is a potentially powerful threat to the status quo and a standing reproach to the reign of blindly traditional custom or the arbitrary will of the State apparatus.\" Austrian school economist Ludwig von Mises states that he relaid the general sociological and economic foundations of the liberal doctrine upon utilitarianism, rather than natural law, but R. A. Gonce argues that \"the reality of the argument constituting his system overwhelms his denial.\" Murray Rothbard, however, says that Gonce makes a lot of errors and distortions in the analysis of Mises's works, including making confusions about the term which Mises uses to refer to scientific laws, \"laws of nature\", saying it characterizes Mises as a natural law philosopher. David Gordon notes, \"When most people speak of natural law, what they have in mind is the contention that morality can be derived from human nature. If human beings are rational animals of such-and-such a sort, then the moral virtues are...(filling in the blanks is the difficult part).\"\nNobel Prize winning Austrian economist and social theorist F. A. Hayek said that, originally, \"the term 'natural' was used to describe an orderliness or regularity that was not the product of deliberate human will. Together with 'organism' it was one of the two terms generally understood to refer to the spontaneously grown in contrast to the invented or designed. Its use in this sense had been inherited from the stoic philosophy, had been revived in the twelfth century, and it was finally under its flag that the late Spanish Schoolmen developed the foundations of the genesis and functioning of spontaneously formed social institutions.\"\nThe idea that 'natural' was \"the product of designing reason\" is a product of a seventeenth century rationalist reinterpretation of the law of nature. Luis Molina, for example, when referred to the 'natural' price, explained that it is \"so called because 'it results from the thing itself without regard to laws and decrees, but is dependent on many circumstances which alter it, such as the sentiments of men, their estimation of different uses, often even in consequence of whims and pleasures.\" And even John Locke, when talking about the foundations of natural law and explaining what he thought when citing \"reason\", said: \"By reason, however, I do not think is meant here that faculty of the understanding which forms traint of thought and deduces proofs, but certain definite principles of action from which spring all virtues and whatever is necessary for the proper moulding of morals.\"\nThis anti-rationalist approach to human affairs, for Hayek, was the same which guided Scottish enlightenment thinkers, such as Adam Smith, David Hume and Adam Ferguson, to make their case for liberty. For them, no one can have the knowledge necessary to plan society, and this \"natural\" or \"spontaneous\" order of society shows how it can efficiently \"plan\" bottom-up. Also, the idea that law is just a product of deliberate design, denied by natural law and linked to legal positivism, can easily generate totalitarianism: \"If law is wholly the product of deliberate design, whatever the designer decrees to be law is just by definition and unjust law becomes a contradiction in terms. The will of the duly authorized legislator is then wholly unfettered and guided solely by his concrete interests.\" This idea is wrong because law cannot be just a product of \"reason\": \"no system of articulated law can be applied except within a framework of generally recognized but often unarticulated rules of justice.\"\nHowever, a secular critique of the natural law doctrine was stated by Pierre Charron in his \"De la sagesse\" (1601): \"The sign of a natural law must be the universal respect in which it is held, for if there was anything that nature had truly commanded us to do, we would undoubtedly obey it universally: not only would every nation respect it, but every individual. Instead there is nothing in the world that is not subject to contradiction and dispute, nothing that is not rejected, not just by one nation, but by many; equally, there is nothing that is strange and (in the opinion of many) unnatural that is not approved in many countries, and authorized by their customs.\"\nContemporary jurisprudence.\nOne modern articulation of the concept of natural laws was given by Belina and Dzudzek:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;By constant repetition, those practices develop into structures in the form of discourses which can become so natural that we abstract from their societal origins, that the latter are forgotten and seem to be natural laws.\nIn jurisprudence, \"natural law\" can refer to the several doctrines:\nThese meanings can either oppose or complement each other, although they share the common trait that they rely on inherence as opposed to design in finding just laws.\nWhereas legal positivism would say that a law can be unjust without it being any less a law, a natural law jurisprudence would say that there is something legally deficient about an unjust norm.\nBesides utilitarianism and Kantianism, natural law jurisprudence has in common with virtue ethics that it is a live option for a first principles ethics theory in analytic philosophy.\nThe concept of natural law was very important in the development of the English common law. In the struggles between Parliament and the monarch, Parliament often made reference to the Fundamental Laws of England, which were at times said to embody natural law principles since time immemorial and set limits on the power of the monarchy. According to William Blackstone, however, natural law might be useful in determining the content of the common law and in deciding cases of equity, but was not itself identical with the laws of England. Nonetheless, the implication of natural law in the common law tradition has meant that the great opponents of natural law and advocates of legal positivism, like Jeremy Bentham, have also been staunch critics of the common law.\nToday, the most cited authors in literature related to natural law are, in their order: Aquinas, John Finnis, John Locke, Lon Fuller, Ronald Dworkin, and James Wilson, who participated in drafting the U.S. Declaration of Independence. It shows how Aquinas has still a significant influence on the topic. The second Australian professor at Oxford University, John Finnis, is the most prominent contemporary natural law jurist alive. Other authors, like the Americans Germain Grisez, Robert P. George, and Canadian Joseph Boyle and Brazilian Em\u00eddio Brasileiro are also constructing a new version of natural law. They created a school called \"New Natural Law\", originated by Grisez. It focuses on \"basic human goods\", such as human life, knowledge, and aesthetic experience, which are self-evidently and intrinsically worthwhile, and states that these goods reveal themselves as being incommensurable with one another.\nThe 19th-century anarchist and legal theorist Lysander Spooner was also a figure in the expression of modern natural law.\nThe tensions between natural law and positive law have played, and continue to play, a key role in the development of international law.\nU.S. Supreme Court justices Clarence Thomas and Neil Gorsuch are proponents of natural law.\nMethodology.\nThe authors and supporters of natural law use various methods to develop and articulate their ideas. Here are some of the commonly employed methods:\nNevertheless, Riofrio has detected in a quantitative and qualitative analysis of the most cited papers of natural law, that authors dedicated to natural law usually take into account some elements to deduce others. For instance, Finnis deduces legal principles and natural rights from the seven basic goods; Aquinas deduces the human goods from the human powers, and so on. The elements of the so-called \"Natural Law Formula\", are the following ones: being (of people and things) \u2013 potencies of human beings and things \u2013 aims and inclinations of those potencies; means \u2013 human values or goods \u2013 ethical and legal principles \u2013 rules \u2013 natural and positive rights \u2013 cases and circumstances.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "22064", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=22064", "title": "Nature versus nurture debate", "text": ""}
{"id": "22065", "revid": "7038407", "url": "https://en.wikipedia.org/wiki?curid=22065", "title": "Nestorianism", "text": "Umbrella term used for several related but distinct sets of Christian teachings\nNestorianism is a term used in Christian theology and Church history to refer to several mutually related but doctrinally distinct sets of teachings that fall under the umbrella term Dyophysitism, such as two natures in Christ (human and Divine) or two persons in Christ (the Man and the Word). The extent to which those two definitions are actually distinct is also debatable. The first meaning of the term is related to the teachings of Christian theologian Nestorius (d.\u2009) as according to his immediate opponents at the Council of Ephesus and traditionally used by Miaphysites. The second meaning of the term relates to a set of later theological teachings that were traditionally labeled as Nestorian by Chalcedonians but differ in the teachings of Nestorius in origin, scope and terminology. Per the latter definition, the \"Oxford English Dictionary\" defines Nestorianism as:\"The doctrine of Nestorius, Patriarch of Constantinople (appointed in 428), by which Christ is asserted to have had distinct human and divine persons.\"\nThe original definition of Nestorianism, as articulated by Nestorius himself, is preserved primarily in his surviving writings on topics such as Mariology and Christology. Although many of his works were lost or destroyed, others have been transmitted through his opponents or preserved in Church of the East libraries. Most notable among these is the \"Bazaar of Heracleides\", composed during his exile following the Council of Chalcedon. The modern rediscovery of the \"Bazaar\" has prompted renewed scholarly interest in reconstructing Nestorius\u2019s own theological positions, which appear to diverge in significant respects from the \u201ctwo\u2010person\u201d formulation of Christology attributed to him by both his contemporaries and later critics. His theology was influenced by teachings of Theodore of Mopsuestia (d.\u2009428), the most prominent theologian of the Antiochian School. Nestorian Mariology prefers the title \"Christotokos\", which encompasses the term \"Theotokos\" ('God-bearer') for Mary, thus emphasizing distinction between divine and human aspects of the Incarnation, and at the same time their unity in the person of Christ. Nestorian Christology promotes the concept of a prosopic union of two concrete realities (divine and human) in Jesus Christ, as opposed to the concept of a hypostatic union of two hypostases into one. The distinction is between 'two hypostases in one person' and 'two hypostases united into one hypostasis', respectively. Hypostasis is not seen as subject, but rather a nature existing in reality. This Christological position is viewed by the West as \"radical dyophysitism\", and, according to Chalcedonian Christianity, differs from their dyophysitism, which was reaffirmed at the Council of Chalcedon in 451. Such teachings brought Nestorius into conflict with other prominent church leaders, most notably Cyril of Alexandria, who issued 12 anathemas against him in 430. Nestorius and his teachings were eventually condemned as heretical at the Council of Ephesus in 431, and again at the Council of Chalcedon in 451. His teachings were considered as heretical not only in Chalcedonian Christianity, but even more so in Oriental Orthodoxy. The Church of the East would affirm the orthodoxy of Nestorius, lining up with the tradition of the School of Antioch of its time.\nAfter the condemnation, some supporters of Nestorius, who were followers of the Antiochian School and the School of Edessa, relocated to the Sasanian Empire, where they were affiliated with the local Assyrian community of the satrapy of Asuristan (Assyria), many who were followers of the Assyrian Church, known as the Church of the East, while others were Syriac Orthodox. During the period from 484 to 612, gradual development led to the creation of specific doctrinal views within the Church of the East. Evolution of those views was finalized by prominent East Syriac theologian Babai the Great (d.\u2009628) who was using the specific Syriac term () as a designation for dual (divine and human) substances within one prosopon (person) of Christ. Such views were officially adopted by the Church of the East at a council held in 612. \nOpponents of such views in the West inaccurately labeled them as \"Nestorian\", leading to the practice of mislabeling the Church of the East as Nestorian, and indeed the Assyrian people themselves as \"Nestorians\". However, in modern religious studies it has been criticized as improper and misleading, even though Nestorius is officially venerated as a saint in the Assyrian Church of the East. As a consequence, both in scholarly literature and in the field of inter-denominational relations, the term \"Nestorian\" increasingly focuses on its primary meaning, the original teachings of Nestorius, rather than referring to the far older-originating Assyrian Church of the East or its offshoot, the Chaldean Catholic Church.\nHistory.\nNestorianism was condemned as heresy at the Council of Ephesus (431). The Armenian Church rejected the Council of Chalcedon (451) because they believed Chalcedonian Definition was too similar to Nestorianism. The Persian Nestorian Church, on the other hand, supported the spread of Nestorianism in Persarmenia. The Armenian Church and other eastern churches saw the rise of Nestorianism as a threat to the independence of their Church. Peter the Iberian, a Georgian prince, also strongly opposed the Chalcedonian Creed. Thus, in 491, Catholicos Babken I of Armenia, along with the Albanian and Iberian bishops met in Vagharshapat and issued a condemnation of the Chalcedonian Definition.\nNestorians held that the Council of Chalcedon proved the orthodoxy of their faith and had started persecuting non-Chalcedonian or Miaphysite Syriac Christians during the reign of Peroz I. In response to pleas for assistance from the Syriac Church, Armenian prelates issued a letter addressed to Persian Christians reaffirming their condemnation of the Nestorianism as heresy.\nFollowing the exodus to Persia, scholars expanded on the teachings of Nestorius and his mentors, particularly after the relocation of the School of Edessa to the city of Nisibis under Persian control in 489, where it became known as the School of Nisibis. Nestorian monasteries propagating the teachings of the Nisibis school flourished in 6th century Persarmenia.\nDespite this initial Eastern expansion, the Nestorians' missionary success was eventually deterred. David J. Bosch observes, \"By the end of the fourteenth century, however, the Nestorian and other churches\u2014which at one time had dotted the landscape of all of Central and even parts of East Asia\u2014were all but wiped out. Isolated pockets of Christianity survived only in India. The religious victors on the vast Central Asian mission field of the Nestorians were Islam and Buddhism\".\nDoctrine.\nNestorianism is described as a radical form of dyophysitism that, according to Chalcedonians, differs from their version of dyophysitism on several points, mainly by opposition to the concept of hypostatic union. It can be seen as the antithesis to Eutychian Monophysitism, which emerged in reaction to Nestorianism after the conclusion of the Council of Ephesus. Where Nestorianism holds that Christ had two distinct natures, divine and human, Monophysitism holds that he had but a single nature, his human nature being absorbed into his divinity. A brief definition of Nestorian Christology can be given as: \"Jesus Christ, who is not identical with the Son but personally united with the Son, who lives in him, is one hypostasis and one nature: human.\" This contrasts with Nestorius' own teaching that the Word, which is eternal, and the Flesh, which is not, came together in a hypostatic union, 'Jesus Christ', Jesus thus being both fully man and God, of two \"ousia\" () (essences) but of one (person). Both Nestorianism and Monophysitism were condemned as heretical at the Council of Chalcedon and the Second Council of Ephesus.\nNestorius developed his Christological views as an attempt to understand and explain rationally the incarnation of the divine Logos, the Second Person of the Holy Trinity as the man Jesus. He had studied at the School of Antioch where his mentor had been Theodore of Mopsuestia; Theodore and other Antioch theologians had long taught a literalist interpretation of the Bible and stressed the distinctiveness of the human and divine natures of Jesus. Nestorius took his Antiochene leanings with him when he was appointed Patriarch of Constantinople by Byzantine emperor Theodosius II in 428.\nNestorius's teachings sparked controversy when he publicly challenged the long-established title of \"Theotokos\" ('God-Bearer') for the Virgin Mary. He argued that this title, while orthodox per se, was inadequate to fully encompass the nature of the Incarnation, as it singled out Christ's divinity with no reference to His humanity. To address this perceived limitation, he proposed the alternative title of \"Christotokos\" ('Christ-Bearer') as a more appropriate designation for Mary.\nHe also advanced the image of Jesus as a warrior-king and rescuer of Israel over the traditional image of the .\nNestorius' opponents found his teaching too close to the heresy of adoptionism \u2013 the idea that Christ had been born a man who had later been \"adopted\" as God's son. Nestorius was especially criticized by Cyril, Patriarch of Alexandria, who argued that Nestorius's teachings undermined the unity of Christ's divine and human natures at the Incarnation. Some of Nestorius's opponents argued that he put too much emphasis on the human nature of Christ, and others debated that the difference that Nestorius implied between the human nature and the divine nature created a fracture in the singularity of Christ, thus creating two Christ figures. Nestorius himself always insisted that his views were orthodox, though they were deemed heretical at the Council of Ephesus in 431, leading to the Nestorian Schism, when churches supportive of Nestorius and the rest of the Christian Church separated. However, this formulation was never adopted by all churches termed 'Nestorian'. Indeed, the modern Assyrian Church of the East, which reveres Nestorius, does not fully subscribe to Nestorian doctrine, though it does not employ the title \"Theotokos\".\nNestorian Schism.\nNestorianism became a distinct sect following the Nestorian Schism, beginning in the 430s. Nestorius had come under fire from Western theologians, most notably Cyril of Alexandria. Cyril had both theological and political reasons for attacking Nestorius; on top of feeling that Nestorianism was an error against true belief, he also wanted to denigrate the head of a competing patriarchate. Cyril and Nestorius asked Pope Celestine I to weigh in on the matter. Celestine found that the title \"Theotokos\" was sufficiently orthodox, and authorized Cyril to ask Nestorius to recant. Cyril, however, used the opportunity to further attack Nestorius, who pleaded with Emperor Theodosius II to call a council so that all grievances could be aired.\nIn 431 Theodosius II called the Council of Ephesus. The council ultimately sided with Cyril, who held that the Christ is of (not \"in\") two natures (\"hypostases)\" perfectly united into one nature (\"hypostasis\") without mixture or separation, and that the Virgin Mary, conceiving and bearing this divine person, is truly and sufficiently called the Mother of God (\"Theotokos\"). The council accused Nestorius of heresy, and deposed him as patriarch. Upon returning to his monastery in 436, he was banished to Upper Egypt. Nestorianism was officially anathematized, a ruling reiterated at the Council of Chalcedon in 451. However, a number of churches, particularly those associated with the School of Edessa, supported Nestorius \u2013 though not necessarily his doctrine \u2013 and broke with the churches of the West. Many of Nestorius' supporters relocated to the Sasanian Empire of Iran, home to a vibrant but persecuted Christian minority. In Upper Egypt, Nestorius wrote his \"Book of Heraclides\", responding to the two councils at Ephesus (431, 449).\nChristian denomination tree.\nMajor in Christianity:&lt;br&gt;\n\"Western Christianity\" \n\"Eastern Christianity\" \nProtestantism\nAnabaptism \nAnglicanism \nLutheranism \nReformed \n(Latin Church) \nCatholic Church\n(Eastern Catholic Churches) \nEastern Orthodox Church\nOriental Orthodox Churches\nChurch of the East\nSchism \"(1552)\"\nAssyrian Church of the East \nAncient Church of the East \nProtestant Reformation\n\"(16th century)\"\nGreat Schism \"(1054)\"\nNestorian Schism \"(431)\"\nChalcedonian Schism \"(451)\"\n\"Early Christianity\" \n\"Great Church\"\n(Full communion) \n(Not shown are ante-Nicene, nontrinitarian, and restorationist denominations.)\nChurch of the East.\nThe western provinces of the Persian Empire had been home to Christian communities, headed by metropolitans, and later patriarchs of Seleucia-Ctesiphon. The Christian minority in Persia was frequently persecuted by the Zoroastrian majority, which accused local Christians of political leanings towards the Roman Empire. In 424, the Church in Persia declared itself independent, in order to ward off allegations of any foreign allegiance. By the end of the 5th century, the Persian Church increasingly aligned itself with the teachings of Theodore of Mopsuestia and his followers, many of whom became dissidents after the Councils of Ephesus (431) and Chalcedon (451). The Persian Church became increasingly opposed to doctrines promoted by those councils, thus furthering the divide between Chalcedonian and Persian currents.\nIn 486, the Metropolitan Barsauma of Nisibis publicly accepted Nestorius' mentor Theodore of Mopsuestia as a spiritual authority. In 489, when the School of Edessa in Mesopotamia was closed by Byzantine Emperor Zeno for its pro-Nestorian teachings, the school relocated to its original home of Nisibis, becoming again the School of Nisibis, leading to the migration of a wave of Christian dissidents into Persia. The Persian patriarch Babai (497\u2013502) reiterated and expanded upon the church's esteem for Theodore of Mopsuestia.\nNow firmly established in Persia, with centers in Nisibis, Ctesiphon, and Gundeshapur, and several \"metropoleis\", the Persian Church began to branch out beyond the Sasanian Empire. However, through the sixth century, the church was frequently beset with internal strife and persecution by Zoroastrians. The infighting led to a schism, which lasted from 521 until around 539 when the issues were resolved. However, immediately afterward Roman-Persian conflict led to the persecution of the church by the Sassanid emperor Khosrow I; this ended in 545. The church survived these trials under the guidance of Patriarch Aba I, who had converted to Christianity from Zoroastrianism.\nThe church emerged stronger after this period of ordeal, and increased missionary efforts farther afield. Missionaries established dioceses in the Arabian Peninsula and India (the Saint Thomas Christians). They made some advances in Egypt, despite the strong Miaphysite presence there. Missionaries entered Central Asia and had significant success converting local Turkic tribes.\nThe Anuradhapura Cross discovered in Sri Lanka strongly suggests a strong presence of Nestorian Christianity in Sri Lanka during the 6th century AD according to Humphrey Codrington, who based his claim on a 6th-century manuscript, Christian Topography, that mentions of a community of Persian Christians who were known to reside in Taproban\u00ea (the Ancient Greek name for Sri Lanka).\nNestorian missionaries were firmly established in China during the early part of the Tang dynasty (618\u2013907); the Chinese source known as the Nestorian Stele records a mission under a Persian proselyte named Alopen as introducing Nestorian Christianity to China in 635. The Jingjiao Documents (also described by the Japanese scholar P. Y. Saeki as \"Nestorian Documents\") or Jesus Sutras are said to be connected with Alopen.\nFollowing the Arab conquest of Persia, completed in 644, the Persian Church became a community under the Rashidun Caliphate. The church and its communities abroad grew larger under the caliphate. By the 10th century it had 15 metropolitan sees within the caliphate's territories, and another five elsewhere, including in China and India. After that time, however, Nestorianism went into decline.\nAssyrian Church of the East.\nIn a 1996 article published in the \"Bulletin of the John Rylands Library\", Fellow of the British Academy Sebastian Brock wrote: \"the term 'Nestorian Church' has become the standard designation for the ancient oriental church which in the past called itself 'The Church of the East', but which today prefers the fuller title 'The Assyrian Church of the East'. The Common Christological Declaration between the Catholic Church and the Assyrian Church of the East signed by Pope John Paul II and Mar Dinkha IV underlines the Chalcedonian Christological formulation as the expression of the common faith of these Churches and recognizes the legitimacy of the title \"Theotokos\".\"\nIn a 2017 paper, Mar Awa Royel, Bishop of the Assyrian Church, stated the position of that church: \"After the Council of Ephesus (431), when Nestorius the patriarch of Constantinople was condemned for his views on the unity of the Godhead and the humanity in Christ, the Church of the East was branded as 'Nestorian' on account of its refusal to anathematize the patriarch.\"\nSeveral historical records suggest that the Assyrian Church of the East may have been in Sri Lanka between the mid-5th and 6th centuries.\nModern discourse.\nThe accusations of Nestorianism have been used in contemporary theological discourse. One notable example is the case of John MacArthur, as he has asserted that when Mary gave birth to Jesus, she did not give birth to God, but rather gave birth to Jesus in his humanity and that \"it\u2019s heretical to call the blood of Jesus Christ the blood of God.\" These statements have been critiqued as resembling Nestorianism by other Christians.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "22066", "revid": "1313169925", "url": "https://en.wikipedia.org/wiki?curid=22066", "title": "NCR", "text": "NCR may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "22067", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=22067", "title": "National Cash Register Corporation", "text": ""}
{"id": "22068", "revid": "50767869", "url": "https://en.wikipedia.org/wiki?curid=22068", "title": "Naomi Klein", "text": "Canadian author and activist (born 1970)\nNaomi Klein (born May 8, 1970) is a Canadian author, social activist, and filmmaker known for her political analyses, support of ecofeminism and organized labour, and criticism of corporate globalization, fascism and capitalism. In 2021, Klein took up the UBC Professorship in Climate Justice, joining the University of British Columbia's Department of Geography. She has been the co-director of the Centre for Climate Justice since it was launched in 2021.\nKlein first became known internationally for her alter-globalization book \"No Logo\" (1999). \"The Take\" (2004), a documentary film about Argentine workers' self-managed factories, written by her and directed by her husband Avi Lewis, further increased her profile. \"The Shock Doctrine\" (2007), a critical analysis of the history of neoliberal economics, solidified her standing as a prominent activist on the international stage and was adapted into a six-minute companion film by Alfonso and Jon\u00e1s Cuar\u00f3n, as well as a feature-length documentary by Michael Winterbottom. Klein's \"This Changes Everything: Capitalism vs. the Climate\" (2014) was a \"New York Times\" nonfiction bestseller and the winner of the Hilary Weston Writers' Trust Prize for Nonfiction.\nIn 2016, Klein was awarded the Sydney Peace Prize for her activism on climate justice. Klein frequently appears on global and national lists of top influential thinkers, including the 2014 Thought Leaders ranking compiled by the Gottlieb Duttweiler Institute, \"Prospect\" magazine's world thinkers 2014 poll, and Maclean's 2014 Power List. She was formerly a member of the board of directors of the climate activist group 350.org.\nFamily.\nNaomi Klein was born in Montreal, Quebec, into a Jewish family with a history of peace activism. Her parents were self-described hippies who emigrated from the United States in 1967 as war resisters to the Vietnam War. Her mother, documentary filmmaker Bonnie Sherr Klein, is best known for her anti-pornography film \"\". Her father, Michael Klein, is a physician and a member of Physicians for Social Responsibility. Her brother, Seth Klein, is an author and the former director of the British Columbia office of the Canadian Centre for Policy Alternatives.\nBefore World War II, her paternal grandparents were Communists, but they began to turn against the Soviet Union after the Molotov\u2013Ribbentrop Pact in 1939. In 1942, her grandfather, an animator at Disney, was fired after the 1941 strike, and had to switch to working in a shipyard instead. By 1956, they had abandoned communism. Klein's father grew up surrounded by ideas of social justice and racial equality, but found it \"difficult and frightening to be the child of Communists\", a so-called red diaper baby.\nKlein's husband, Avi Lewis, was born into a political and journalistic family. His grandfather, David Lewis, was an architect and leader of the federal New Democratic Party, while his father, Stephen Lewis, was a leader of the Ontario New Democratic Party. Avi's mother is Michelle Landsberg, journalist, feminist, and campaigner. Avi Lewis works as a TV journalist and documentary filmmaker. He is also an associate professor in the Department of Geography at the University of British Columbia. The couple have one son, Toma.\nEarly life and education.\nKlein spent much of her teenage years in shopping malls, obsessed with designer labels. As a child and teenager, she found it \"very oppressive to have a very public feminist mother,\" and she rejected politics, instead embracing \"full-on consumerism\".\nShe has attributed her change in worldview to two catalysts. One was when she was 17 and preparing for the University of Toronto, her mother had a stroke and became severely disabled. Naomi, her father, and her brother took care of Bonnie through the period in hospital and at home, making educational sacrifices to do so. That year off prevented her \"from being such a brat\". The next year, after she had begun her studies at the University of Toronto, the second catalyst occurred: the 1989 \u00c9cole Polytechnique massacre of female engineering students, which proved to be a wake-up call to feminism.\nKlein's writing career began with contributions to \"The Varsity\", a student newspaper, where she served as editor-in-chief. After her third year at the University of Toronto, she dropped out of university to take a job at \"The Globe and Mail\", followed by an editorship at \"This Magazine\". In 1995, she returned to the University of Toronto with the intention of finishing her degree but left to pursue an internship in journalism before acquiring the final credits required to complete her degree.\nWorks.\n\"No Logo\".\nIn 1999, Klein published the book \"No Logo\", which for many became a manifesto of the anti-globalization movement. In it, she attacks brand-oriented consumer culture and the operations of large corporations. She also accuses several such corporations of unethically exploiting workers in the world's poorest countries in pursuit of greater profits. In this book, Klein criticized Nike so severely that Nike published a point-by-point response. \"No Logo\" became an international bestseller, selling over one million copies in over 28 languages.\n\"Fences and Windows\".\nKlein's \"Fences and Windows\" (2002) is a collection of her articles and speeches written on behalf of the anti-globalization movement (all proceeds from the book go to benefit activist organizations through The Fences and Windows Fund).\n\"The Take\".\n\"The Take\" (2004), a documentary film collaboration by Klein and Lewis, concerns factory workers in Argentina who took over a closed plant and resumed production, operating as a collective. The first African screening was in the Kennedy Road shack settlement in the South African city of Durban, where the Abahlali baseMjondolo movement began.\nAn article in \"Z Communications\" criticized \"The Take\" for its portrayal of the Argentine general and politician Juan Domingo Per\u00f3n arguing that he was falsely portrayed as a social democrat.\n\"The Shock Doctrine\".\nKlein's third book, \"The Shock Doctrine: The Rise of Disaster Capitalism\", was published in 2007. The book argues that the free market policies of Nobel Laureate Milton Friedman and the Chicago School of Economics have risen to prominence in countries such as Chile under Pinochet, Poland, and Russia under Yeltsin. The book also argues that policy initiatives (for instance, the privatization of Iraq's economy under the Coalition Provisional Authority) were rushed through while the citizens of these countries were in shock from disasters, upheavals, or invasion. The book became an international and \"New York Times\" bestseller and was translated into 28 languages.\nCentral to the book's thesis is the contention that those who wish to implement unpopular free market policies now routinely do so by taking advantage of certain features of the aftermath of major disasters, be they economic, political, military or natural. The suggestion is that when a society experiences a major 'shock' there is a widespread desire for a rapid and decisive response to correct the situation; this desire for bold and immediate action provides an opportunity for unscrupulous actors to implement policies which go far beyond a legitimate response to disaster. The book suggests that when the rush to act means the specifics of a response will go unscrutinized, that is the moment when unpopular and unrelated policies will intentionally be rushed into effect. The book appears to claim that these shocks are in some cases intentionally encouraged or even manufactured.\nKlein identifies the \"shock doctrine\", elaborating on Joseph Schumpeter, as the latest in capitalism's phases of \"creative destruction\".\n\"The Shock Doctrine\" was adapted into a short film of the same name, released onto YouTube. The original is no longer available on the site; however, a duplicate was published in 2008. The film was directed by Jon\u00e1s Cuar\u00f3n, produced and co-written by his father Alfonso Cuar\u00f3n. The original video was viewed over one million times. The director Michael Winterbottom, alongside Mat Whitecross, also produced a documentary on the book which premiered in 2009.\nThe publication of \"The Shock Doctrine\" increased Klein's prominence, with \"The New Yorker\" judging her \"the most visible and influential figure on the American left\u2014what Howard Zinn and Noam Chomsky were thirty years ago.\" On February 24, 2009, the book was awarded the inaugural Warwick Prize for Writing from the University of Warwick in England. The prize carried a cash award of \u00a350,000.\n\"This Changes Everything: Capitalism vs. the Climate\".\nKlein's fourth book, \"This Changes Everything: Capitalism vs. the Climate\", was published in September 2014. The book puts forth the argument that the hegemony of neoliberal market fundamentalism is blocking any serious reforms to halt climate change and protect the environment. Questioned about Klein's claim that capitalism and controlling climate change were incompatible, Benoit Blarel, manager of the Environment and Natural Resources global practice at the World Bank, said that the write-off of fossil fuels necessary to control climate change \"will have a huge impact all over\" and that the World Bank was \"starting work on this\". The book won the 2014 Hilary Weston Writers' Trust Prize for Nonfiction, and was a shortlisted nominee for the 2015 Shaughnessy Cohen Prize for Political Writing.\n\"No Is Not Enough: Resisting Trump's Shock Politics and Winning the World We Need\".\nKlein's fifth book, \"No Is Not Enough: Resisting Trump's Shock Politics and Winning the World We Need\", was published in 2017. In a feature on Klein in \"Geographical\" magazine, Chris Fitch described her book as arguing for \"radical change, and for bold, ambitious policies, to provide a credible alternative to the world vision of the Trump White House, and avert the worst effects of climate change.\" Klein takes particular issue in \"No Is Not Enough\" with the concept of philanthrocapitalism: \"the idea that wealth attaches itself to wisdom and the capacity to solve problems on a global scale\". She attributes Trump's political rise in part to a misplaced public faith in oligarchs. She writes:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Trump's assertion that he knows how to fix America because he's rich is nothing more than the uncouth, vulgar echo of a dangerous idea we have been hearing for years; that Bill Gates can fix Africa. Or that Richard Branson and Michael Bloomberg can solve climate change.\n\"The Battle for Paradise: Puerto Rico Takes on the Disaster Capitalists\".\n\"The Battle for Paradise: Puerto Rico Takes on the Disaster Capitalists\" was released in June 2018 as a paperback and e-book. It covers what San Juan Mayor Carmen Yul\u00edn Cruz refers to as \"a fight for our lives. Hurricanes Irma and Mar\u00eda unmasked the colonialism we face in Puerto Rico, and the inequality it fosters, creating a fierce humanitarian crisis.\"&lt;ref name=\"Haymarket Books/The Battle for Paradise official page\"&gt;&lt;/ref&gt;\nIn the book, Klein applies principles outlined in \"The Shock Doctrine\" to describe the management of Puerto Rico in a post-Maria context. She criticizes the inadequate recovery efforts of the Puerto Rican government in the aftermath of the storm. She singles out officeholders like Gov. Ricardo Rossell\u00f3, who prioritized foreign investment interests while the island's residents were left to fend for themselves or seek refuge on the U.S. mainland. She notes that less than one year after the hurricane, Rossell\u00f3 \"told a business audience in New York that Maria had created a 'blank canvas'\", implying that Puerto Rico would cater to \"disaster capitalists\" who aimed to profit off the hurricane's devastating effects.\n\"On Fire: The (Burning) Case for a Green New Deal \".\nIn April 2019, Simon &amp; Schuster announced they would be publishing Klein's seventh book, \"On Fire: The (Burning) Case for a Green New Deal\", which was published on September 17, 2019. \"On Fire\" is a collection of essays focusing on climate change and the urgent actions needed to preserve the world. Klein relates her meeting with Greta Thunberg in the opening essay in which she discusses the entrance of young people into those speaking out for climate awareness and change. She supports the Green New Deal throughout the book and in the final essay she discusses the 2020 U.S. election stating: \"The stakes of the election are almost unbearably high. It's why I wrote the book and decided to put it out now and why I'll be doing whatever I can to help push people toward supporting a candidate with the most ambitious Green New Deal platform\u2014so that they win the primaries and then the general.\"\n\"Doppelganger: a Trip into the Mirror World\".\nReleased in September 2023, \"Doppelganger\" is a memoir and social critique that contrasts Klein's worldview with that of Naomi Wolf, a writer who is often mistaken for Klein and vice versa. In her introduction, Klein explains how she has been mistaken for the \"other Naomi\", with whom she \"has been chronically confused for over a decade... I have been confused with Other Naomi for so long and so frequently that I have often felt that she was following me\". For this reason, she started to follow what she calls Wolf's \"new alliances with some of the most dangerous men on the planet\", and wrote the book with the intention of using her doppelganger experience \"as a guide into and through what I have come to understand as our doppelganger culture\".\nKlein suggests that the Western world has fractured along political and ideological lines to such an extent that each side feels the other exists in a \"mirror world\". The book received primarily positive reviews and debuted at number 8 on \"The New York Times\" hardcover nonfiction weekly best seller list.\nIn 2024, \"Doppelganger\" won Klein the inaugural Women's Prize for Non-Fiction.\nViews.\nIraq War criticism.\nKlein has written about the Iraq War. In \"Baghdad Year Zero\" (\"Harper's Magazine\", September 2004), Klein argues that, contrary to popular belief, the George W. Bush administration \"did\" have a clear plan for post-invasion Iraq: to build a completely unconstrained free market economy. She describes plans to allow foreigners to extract wealth from Iraq and the methods used to achieve those goals. Her \"Baghdad Year Zero\" was one of the inspirations for the 2008 film \"War, Inc.\"\nKlein's \"Bring Najaf to New York\" (\"The Nation\", August 2004) argued that Muqtada Al Sadr's Mahdi Army \"represents the overwhelmingly mainstream sentiment in Iraq\" and that, if he were elected, \"Sadr would try to turn Iraq into a theocracy like Iran,\" although his immediate demands were for \"direct elections and an end to foreign occupation\".\nVenezuela.\nKlein signed a 2004 petition titled \"We would vote for Hugo Ch\u00e1vez\". In 2007, she described Venezuela under the Ch\u00e1vez government as a country where \"citizens had renewed their faith in the power of democracy to improve their lives\", and described Venezuela as a place sheltered by Ch\u00e1vez's policies from the economic shocks produced by capitalism. Rather, according to Klein, Ch\u00e1vez protected his country from financial crisis by building \"a zone of relative economic calm and predictability.\" According to reviewer Todd Gitlin, who described the overall argument of Klein's book \"The Shock Doctrine\" (2007) as \"more right than wrong,\" Klein is \"a romantic,\" who expected that the Ch\u00e1vez government would produce a bright future in which worker-controlled co-operatives would run the economy. \"The Shock Doctrine\" was consistent with her prior thinking about globalization, and in that book she describes Ch\u00e1vez' policies as an example of public control of some sectors of the economy as protecting poor people from harm caused by globalization. In 2017, Mark Milke and conservative writer James Kirchick criticized Klein for her support of Ch\u00e1vez.\nCriticism of Israel.\nIn 2008, Klein was the keynote speaker at the first national conference of the Alliance of Concerned Jewish Canadians (now Independent Jewish Voices). In January 2009, during the Gaza War, Klein supported the Boycott, Divestment and Sanctions (BDS) campaign against Israel, arguing that \"the best strategy to end the increasingly bloody occupation is for Israel to become the target of the kind of global movement that put an end to apartheid in South Africa.\"\nIn 2009, on the occasion of the publication of the Hebrew translation of her book \"The Shock Doctrine\", Klein visited Israel, the West Bank, and Gaza, combining the promotion of her book and the BDS campaign. In an interview with the Israeli newspaper \"Haaretz\", she emphasized that it was important \"not to boycott Israelis but rather to boycott the normalization of Israel and the conflict.\" In a speech in Ramallah on June 27, she apologized to Palestinians for not joining the BDS campaign earlier. Her remarks, particularly that \"[some Jews] even think we get one get-away-with-genocide-free card\" were characterized by Noam Schimmel, an op-ed columnist in \"The Jerusalem Post\", as \"violent\" and \"unethical\", and as the \"most perverse of aspersions on Jews, an age-old stereotype of Jews as intrinsically evil and malicious.\"\nKlein was also a spokesperson for the protest against the spotlight on Tel Aviv at the 2009 Toronto International Film Festival, a spotlight that Klein said was a very selective and misleading portrait of Israel.\nShe has also served on the advisory board of the organization Jewish Voice for Peace.\nIn 2023, in the context of the Gaza war, she wrote:\nAt a \u201cSeder in the Streets\" event in 2024, held near Senator Chuck Schumer's residence, Klein spoke about the contemporary meaning of Passover and its relation to the war. Using The Exodus story of Israelites worshipping the golden calf as an idol, she drew parallels to what she called \"the false idol of Zionism.\"\nShe said \"It is a false idol that takes our most profound biblical stories of justice and emancipation from slavery, the story of Passover itself, and turns them into brutalist weapons of colonial land theft, roadmaps for ethnic cleansing and genocide.\"\nEnvironmentalism.\n&lt;templatestyles src=\"Rquote/styles.css\"/&gt;{ class=\"rquote pullquote floatright\" role=\"presentation\" style=\"display:table; border-collapse:collapse; border-style:none; float:right; margin:0.5em 0.75em; width:33%; \"\nBy 2009, Klein's attention had turned to environmentalism, with particular focus on climate change, the subject of her book \"This Changes Everything\" (2014). According to her website in 2016, the book and its accompanying film (released in 2015) would be about \"how the climate crisis can spur economic and political transformation.\"\nShe served on the board of directors of the non-profit group 350.org from 2011, through the fiscal year ending September 2018, and took part in their \"Do the Math\" tour in 2013, encouraging a divestment movement.\nIn an interview by Graeme Greene in \"New Internationalist\", Klein rejected criticism that \"This Changes Everything\" politicized the climate issue and that the issue should be apolitical, asserting that such criticism reflected \"how blind so many within the mainstream climate discussion are to the fact that they themselves are fully immersed within the confines of neoliberalism; ... Its a fantasy that you could fundamentally shift the building blocks of your economy without engaging with politics.\"\nShe encouraged the Occupy movement to join forces with the environmental movement, saying the financial crisis and the climate crisis are similarly rooted in unrestrained corporate greed. She gave a speech at Occupy Wall Street where she described the world as \"upside down\", where we act as if \"there is no end to what is actually finite\u2014fossil fuels and the atmospheric space to absorb their emissions,\" and as if there are \"limits to what is actually bountiful\u2014the financial resources to build the kind of society we need.\"\nShe has been a particularly vocal critic of the Athabasca oil sands in Alberta, describing it in a TED talk as a form of \"terrestrial skinning.\" On September 2, 2011, she attended the demonstration against the Keystone XL pipeline outside the White House and was arrested. Klein celebrated Obama's decision to postpone a decision on the Keystone pipeline until 2013 pending an environmental review as a victory for the environmental movement.\nShe attended the Copenhagen Climate Summit of 2009. She put the blame for the failure of Copenhagen on President Barack Obama, and described her own country, Canada, as a \"climate criminal.\" She presented the Angry Mermaid Award (a satirical award designed to recognize the corporations who have best sabotaged the climate negotiations) to Monsanto.\nWriting in the wake of Hurricane Sandy, she warned that the climate crisis constitutes a massive opportunity for disaster capitalists and corporations seeking to profit from crisis. But equally, the climate crisis \"can be a historic moment to usher in the next great wave of progressive change,\" or a so-called \"People's Shock.\"\nIn 2016, following the election of Donald Trump as the 45th President of the United States, Klein called for an international campaign to impose economic sanctions on the United States if his administration refuses to abide by the terms of the Paris Agreement.\nIn October 2022, Klein published an article on \"The Intercept\" that addressed COP27 and the repression of the Egyptian government; the conference took place in Egypt, a country widely seen as repressive and autocratic. She goes on to state \"Sisi's Egypt is making a big show of solar panels and biodegradable straws ... but in reality, the regime imprisons activists and bans research. The climate movement should not play along,\" calling it greenwashing. In an interview with \"Democracy Now!\", she says \u201cwhat is not welcome would be pointing out this enormous lucrative network of deals that the military itself is engaged in that are linked to fossil fuels, that are linked to destroying remaining green space in cities like Cairo\u201d. Klein also stressed the release of prominent political prisoner and activist Alaa Abd El-Fattah, and wrote a foreword to \"You Have Not Yet Been Defeated\" (2021), his collected writings translated by an anonymous collective.\nOther activities.\nKlein contributes to \"The Nation\", \"In These Times\", \"The Globe and Mail\", \"This Magazine\", \"Harper's Magazine\", and \"The Guardian\". She is a senior contributor for \"The Intercept\". She hosts the monthly Zeteo podcast \"Unshocked with Naomi Klein.\"\nShe is a former Miliband Fellow and lectured at the London School of Economics on the anti-globalization movement. Her appointment as the inaugural Gloria Steinem Endowed Chair in Media, Culture and Feminist Studies at Rutgers University\u2013New Brunswick began in October 2018 and ran for 3 years.\nKlein ranked 11th in an internet poll of the top global intellectuals of 2005, a list of the world's top 100 public intellectuals compiled by the \"Prospect\" magazine in conjunction with \"Foreign Policy\" magazine. On Google Scholar which tracks academic articles, https:// and her publications have been cited in the scholarly literature over 49,000 times as of May 2023. She was involved in 2010 G-20 Toronto summit protests, condemning police force and brutality. She spoke to a rally seeking the release of protesters in front of police headquarters on June 28, 2010.\nIn October 2011, she visited Occupy Wall Street and gave a speech declaring the protest movement \"the most important thing in the world\". On November 10, 2011, she participated in a panel discussion about the future of Occupy Wall Street with four other panelists, including Michael Moore, William Greider, and Rinku Sen, in which she stressed the crucial nature of the evolving movement.\nKlein also made an appearance in the British radio show \"Desert Island Discs\" on BBC Radio 4 in 2017.\nKlein was a key instigator of the Leap Manifesto, a political manifesto issued in the context of the 2015 Canadian federal election focused on addressing the climate crisis through restructuring the Canadian economy and dealing with issues of income and wealth inequality, racism, and colonialism. The manifesto has been noted as an influence in the development of the Green New Deal and eventually led to the establishment of The Leap, an organization that works to promote the realization of the principles behind the original manifesto.\nIn 2019, along with other public figures, Klein signed a letter supporting Labour Party leader Jeremy Corbyn describing him as \"a beacon of hope in the struggle against emergent far-right nationalism, xenophobia and racism in much of the democratic world\" and endorsed him in the 2019 UK general election.\nIn 2025, Klein actively participated in New York canvasing for democratic mayoral candidate Zohran Mamdani. \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22071", "revid": "20204978", "url": "https://en.wikipedia.org/wiki?curid=22071", "title": "Nonsteroidal anti-inflammatory drug", "text": "Class of therapeutic drug for relieving pain and inflammation\nNon-steroidal anti-inflammatory drugs (NSAID) are members of a therapeutic drug class which reduces pain, decreases inflammation, decreases fever, and prevents blood clots. Side effects depend on the specific drug, its dose and duration of use, but largely include an increased risk of gastrointestinal ulcers and bleeds, heart attack, and kidney disease. The most prominent NSAIDs are aspirin, ibuprofen, diclofenac and naproxen, all available over the counter (OTC) in most countries. Paracetamol (acetaminophen) is generally not considered an NSAID because it has only minor anti-inflammatory activity.\nThe term \"non-steroidal\", common from around 1960, distinguishes these drugs from corticosteroids, another class of anti-inflammatory drugs, which during the 1950s had acquired a bad reputation due to overuse and side-effect problems after their introduction in 1948.\nNSAIDs work by inhibiting the activity of cyclooxygenase enzymes (the COX-1 and COX-2 isoenzymes). In cells, these enzymes are involved in the synthesis of key biological mediators, namely prostaglandins, which are involved in inflammation, and thromboxanes, which are involved in blood clotting.\nThere are two general types of NSAIDs available: non-selective and COX-2 selective. Most NSAIDs are non-selective, and inhibit the activity of both COX-1 and COX-2. These NSAIDs, while reducing inflammation, also inhibit platelet aggregation and increase the risk of gastrointestinal ulcers and bleeds. COX-2 selective inhibitors have fewer gastrointestinal side effects, but promote thrombosis, and some of these agents substantially increase the risk of heart attack. As a result, certain COX-2 selective inhibitors\u2014such as rofecoxib\u2014are no longer used due to the high risk of undiagnosed vascular disease. These differential effects are due to the different roles and tissue localisations of each COX isoenzyme. By inhibiting physiological COX activity, NSAIDs may cause deleterious effects on kidney function, and, perhaps as a result of water and sodium retention and decreases in renal blood flow, may lead to heart problems. In addition, NSAIDs can blunt the production of erythropoietin, resulting in anaemia, since haemoglobin needs this hormone to be produced.\nMedical uses.\nNSAIDs are often suggested for the treatment of acute or chronic conditions where pain and inflammation are present. NSAIDs are generally used for the symptomatic relief of the following conditions:&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nChronic pain and cancer-related pain.\nThe effectiveness of NSAIDs for treating non-cancer chronic pain and cancer-related pain in children and adolescents is not clear. There have not been sufficient numbers of high-quality randomised controlled trials conducted.\nInflammation.\nDifferences in anti-inflammatory activity between the various individual NSAIDs are small, but there is considerable variation among individual patients in therapeutic response and tolerance to these drugs. About 60% of patients will respond to any NSAID; of the others, those who do not respond to one may well respond to another. Pain relief starts soon after taking the first dose, and a full analgesic effect should normally be obtained within a week, whereas an anti-inflammatory effect may not be achieved (or may not be clinically assessable) for up to three weeks. If appropriate responses are not obtained within these times, another NSAID should be tried.\nSurgical pain.\nPain following surgery can be significant, and many people require strong pain medications such as opioids. There is some low-certainty evidence that starting NSAID painkiller medications in adults early, before surgery, may help reduce post-operative pain, and also reduce the dose or quantity of opioid medications required after surgery. Any increased risk of surgical bleeding, bleeding in the gastrointestinal system, myocardial infarctions, or injury to the kidneys has not been well studied. When used in combination with paracetamol, the analgesic effect on post-operative pain may be improved.\nAspirin.\nAspirin, the only NSAID able to irreversibly inhibit COX-1, is also indicated for antithrombosis through inhibition of platelet aggregation. This is useful for the management of arterial thrombosis, and prevention of adverse cardiovascular events like heart attacks. Aspirin inhibits platelet aggregation by inhibiting the action of thromboxane A2.\nDentistry.\nNSAIDs are useful in the management of post-operative dental pain following invasive dental procedures such as dental extraction. When not contra-indicated, they are favoured over the use of paracetamol alone due to the anti-inflammatory effect they provide. There is weak evidence suggesting that taking pre-operative analgesia can reduce the length of post operative pain associated with placing orthodontic spacers under local anaesthetic.\nAlzheimer's disease.\nBased on observational studies and randomized controlled trials, NSAID use is not effective for the treatment or prevention of Alzheimer's disease.\nContraindications.\nNSAIDs may be used with caution by people with the following conditions:\nNSAIDs should usually be avoided by people with the following conditions:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nAdverse effects.\nThe widespread use of NSAIDs has meant that the adverse effects of these drugs have become increasingly common. Use of NSAIDs increases the risk of a range of gastrointestinal (GI) problems, kidney disease, and adverse cardiovascular events. As commonly used for post-operative pain, there is evidence of increased risk of kidney complications. Their use following gastrointestinal surgery remains controversial, given mixed evidence of increased risk of leakage from any bowel anastomosis created.\nAn estimated 10\u201320% of people taking NSAIDs experience indigestion. In the 1990s, high doses of prescription NSAIDs were associated with serious upper gastrointestinal adverse events, including bleeding.\nNSAIDs, like all medications, may interact with other medications. For example, concurrent use of NSAIDs and quinolone antibiotics may increase the risk of the adverse central nervous system effects of quinolones including seizure.\nThere is an argument over the benefits and risks of NSAIDs for treating chronic musculoskeletal pain. Each drug has a benefit-risk profile, and balancing the risk of no treatment with the competing potential risks of various therapies should be considered. For people over the age of 65 years old, the balance between the benefits of pain-relief medications such as NSAIDs and the potential for adverse effects has not been well determined.\nThere is some evidence suggesting that, for some people, use of NSAIDs (or other anti-inflammatories) may contribute to the initiation of chronic pain.\nSide effects are dose-dependent, and in many cases, severe enough to pose the risk of ulcer perforation, upper gastrointestinal bleeding, and death, limiting the use of NSAID therapy. An estimated 10\u201320% of NSAID patients experience dyspepsia, and NSAID-associated upper gastrointestinal adverse events are estimated to result in 103,000 hospitalizations and 16,500 deaths per year in the United States, and represent 43% of drug-related emergency visits. Many of these events are avoidable; a review of physician visits and prescriptions estimated that unnecessary prescriptions for NSAIDs were written in 42% of visits.\nAspirin should not be taken by people who have salicylate intolerance or a more generalized drug intolerance to NSAIDs, and caution should be exercised in those with asthma or NSAID-precipitated bronchospasm. Owing to its effect on the stomach lining, manufacturers recommend people with peptic ulcers, mild diabetes, or gastritis seek medical advice before using aspirin. Use of aspirin during dengue fever is not recommended owing to increased bleeding tendency. People with kidney disease, hyperuricemia, or gout should not take aspirin because it inhibits the ability of the kidneys to excrete uric acid, and thus may exacerbate these conditions.\nCombinational risk.\nIf a COX-2 inhibitor is taken, a traditional NSAID (prescription or over-the-counter) should not be taken at the same time.\nRofecoxib (Vioxx) was shown to produce significantly fewer gastrointestinal adverse drug reactions (ADRs) compared with naproxen. The study, the VIGOR trial, raised the issue of the cardiovascular safety of the coxibs (COX-2 inhibitors). A statistically significant increase in the incidence of myocardial infarctions was observed in patients on rofecoxib. Further data, from the APPROVe trial, showed a statistically significant relative risk of cardiovascular events of 1.97 versus placebo\u2014which caused a worldwide withdrawal of rofecoxib in October 2004.\nUse of methotrexate together with NSAIDs in rheumatoid arthritis is safe if adequate monitoring is done.\nCardiovascular.\nNSAIDs, aside from aspirin, increase the risk of myocardial infarction and stroke. This occurs at least within a week of use. They are not recommended in those who have had a previous heart attack as they increase the risk of death or recurrent MI. Evidence indicates that naproxen may be the least harmful out of these.\nNSAIDs, aside from (low-dose) aspirin, are associated with a doubled risk of heart failure in people without a history of cardiac disease. In people with such a history, use of NSAIDs (aside from low-dose aspirin) was associated with a more than 10-fold increase in heart failure. If this link is proven causal, researchers estimate that NSAIDs would be responsible for up to 20 percent of hospital admissions for congestive heart failure. In people with heart failure, NSAIDs increase mortality risk (hazard ratio) by approximately 1.2\u20131.3 for naproxen and ibuprofen, 1.7 for rofecoxib and celecoxib, and 2.1 for diclofenac.\nOn 9 July 2015, the Food and Drug Administration (FDA) toughened warnings of increased heart attack and stroke risk associated with nonsteroidal anti-inflammatory drugs (NSAIDs) \"other than aspirin\".\nPossible erectile dysfunction risk.\nA 2005 Finnish survey study found an association between long-term (over three months) use of NSAIDs and erectile dysfunction.\nA 2011 publication in \"The Journal of Urology\" received widespread publicity. According to the study, men who used NSAIDs regularly were at significantly increased risk of erectile dysfunction. A link between NSAID use and erectile dysfunction still existed after controlling for several conditions. However, the study was observational and not controlled, with a low original participation rate, potential participation bias, and other uncontrolled factors. The authors warned against drawing any conclusions regarding cause.\nGastrointestinal.\nThe main adverse drug reactions (ADRs) associated with NSAID use relate to direct and indirect irritation of the gastrointestinal (GI) tract. NSAIDs cause a dual assault on the GI tract: the acidic molecules directly irritate the gastric mucosa, and inhibition of COX-1 and COX-2 reduces the levels of protective prostaglandins. Inhibition of prostaglandin synthesis in the GI tract causes increased gastric acid secretion, diminished bicarbonate secretion, diminished mucus secretion and diminished trophic effects on the epithelial mucosa.\nCommon gastrointestinal side effects include:\nClinical NSAID ulcers are related to the systemic effects of NSAID administration. Such damage occurs irrespective of the route of administration of the NSAID (e.g., oral, rectal, or parenteral) and can occur even in people who have achlorhydria.\nUlceration risk increases with therapy duration and with higher doses. To minimize GI side effects, it is prudent to use the lowest effective dose for the shortest period\u2014a practice that studies show is often not followed. Over 50% of patients who take NSAIDs have sustained some mucosal damage to their small intestine.\nThe risk and rate of gastric adverse effects are different depending on the type of NSAID medication a person is taking. Indomethacin, ketoprofen, and piroxicam use appears to lead to the highest rate of gastric adverse effects, while ibuprofen (lower doses) and diclofenac appear to have lower rates.\nCertain NSAIDs, such as aspirin, have been marketed in enteric-coated formulations that manufacturers claim reduce the incidence of gastrointestinal ADRs. Similarly, some believe that rectal formulations may reduce gastrointestinal ADRs. However, consistent with the systemic mechanism of such ADRs, and in clinical practice, these formulations have not demonstrated a reduced risk of GI ulceration.\nNumerous \"gastro-protective\" drugs have been developed to prevent gastrointestinal toxicity in people who need to take NSAIDs regularly. Gastric adverse effects may be reduced by taking medications that suppress acid production such as proton pump inhibitors (e.g.: omeprazole and esomeprazole), or by treatment with a drug that mimics prostaglandin to restore the lining of the GI tract (e.g.: a prostaglandin analog misoprostol). Diarrhea is a common side effect of misoprostol; however, higher doses of misoprostol have been shown to reduce the risk of a person having a complication related to a gastric ulcer while taking NSAIDs. While these techniques may be effective, they are expensive for maintenance therapy.\nHydrogen sulfide NSAID hybrids prevent the gastric ulceration/bleeding associated with taking the NSAIDs alone. Hydrogen sulfide is known to have a protective effect on the cardiovascular and gastrointestinal system.\nInflammatory bowel disease.\nNSAIDs should be used with caution in individuals with inflammatory bowel disease (e.g., Crohn's disease or ulcerative colitis) due to their tendency to cause gastric bleeding and form ulceration in the gastric lining.\nRenal.\nNSAIDs are also associated with a fairly high incidence of adverse drug reactions (ADRs) on the kidney and over time can lead to chronic kidney disease. The mechanism of these kidney ADRs is due to changes in kidney blood flow. Prostaglandins normally dilate the afferent arterioles of the glomeruli. This helps maintain normal glomerular perfusion and glomerular filtration rate (GFR), an indicator of kidney function. This is particularly important in kidney failure, where the kidney is trying to maintain renal perfusion pressure by elevated angiotensin II levels. At these elevated levels, angiotensin II also constricts the afferent arteriole into the glomerulus in addition to the efferent arteriole it normally constricts. Since NSAIDs block this prostaglandin-mediated effect of afferent arteriole dilation, particularly in kidney failure, NSAIDs cause unopposed constriction of the afferent arteriole and decreased RPF (renal perfusion flow) and GFR.\nCommon ADRs associated with altered kidney function include:\nThese agents may also cause kidney impairment, especially in combination with other nephrotoxic agents. Kidney failure is especially a risk if the patient is also concomitantly taking an ACE inhibitor (which removes angiotensin II's vasoconstriction of the efferent arteriole) and a diuretic (which drops plasma volume, and thereby RPF)\u2014the so-called \"triple whammy\" effect.\nIn rarer instances NSAIDs may also cause more severe kidney conditions:\nNSAIDs in combination with excessive use of phenacetin or paracetamol (acetaminophen) may lead to analgesic nephropathy.\nPhotosensitivity.\nPhotosensitivity is a commonly overlooked adverse effect of many of the NSAIDs. The 2-arylpropionic acids are the most likely to produce photosensitivity reactions, but other NSAIDs have also been implicated including piroxicam, diclofenac, and benzydamine.\nBenoxaprofen, since withdrawn due to its liver toxicity, was the most photoactive NSAID observed. The mechanism of photosensitivity, responsible for the high photoactivity of the 2-arylpropionic acids, is the ready decarboxylation of the carboxylic acid moiety. The specific absorbance characteristics of the different chromophoric 2-aryl substituents, affects the decarboxylation mechanism.\nDuring pregnancy.\nWhile NSAIDs as a class are not direct teratogens, use of NSAIDs in late pregnancy can cause premature closure of the fetal ductus arteriosus and kidney ADRs in the fetus. Thus, NSAIDs are not recommended during the third trimester of pregnancy because of the increased risk of premature constriction of the ductus arteriosus. Additionally, they are linked with premature birth and miscarriage. Aspirin, however, is used together with heparin in pregnant women with antiphospholipid syndrome. Additionally, indomethacin can be used in pregnancy to treat polyhydramnios by reducing fetal urine production via inhibiting fetal renal blood flow.\nIn contrast, paracetamol (acetaminophen) is regarded as being safe and well tolerated during pregnancy, but Leffers et al. released a study in 2010, indicating that there may be associated male infertility in the unborn. Doses should be taken as prescribed, due to risk of liver toxicity with overdoses.\nIn France, the country's health agency contraindicates the use of NSAIDs, including aspirin, after the sixth month of pregnancy.\nIn October 2020, the U.S. Food and Drug Administration (FDA) required the prescribing information to be updated for all nonsteroidal anti-inflammatory medications, to describe the risk of kidney problems in unborn babies which can then lead to low amniotic fluid levels, as a result of the use of NSAIDs. They are recommending avoiding the use of NSAIDs by pregnant women at 20 weeks or later in pregnancy.\nAllergy and allergy-like hypersensitivity reactions.\nA variety of allergic or allergic-like NSAID hypersensitivity reactions follow the ingestion of NSAIDs. These hypersensitivity reactions differ from the other adverse reactions listed here, which are toxicity reactions, i.e., unwanted reactions that result from the pharmacological action of a drug, are dose-related, and can occur in any treated individual; hypersensitivity reactions are idiosyncratic reactions to a drug. Some NSAID hypersensitivity reactions are truly allergic in origin: 1) repetitive IgE-mediated urticarial skin eruptions, angioedema, and anaphylaxis following immediately to hours after ingesting one structural type of NSAID but not after ingesting structurally unrelated NSAIDs; and 2) Comparatively mild to moderately severe T cell-mediated delayed onset (usually more than 24 hour), skin reactions such as maculopapular rash, fixed drug eruptions, photosensitivity reactions, delayed urticaria, and contact dermatitis; or 3) far more severe and potentially life-threatening t-cell-mediated delayed systemic reactions such as the DRESS syndrome, acute generalized exanthematous pustulosis, the Stevens\u2013Johnson syndrome, and toxic epidermal necrolysis. Other NSAID hypersensitivity reactions are allergy-like symptoms but do not involve true allergic mechanisms; rather, they appear due to the ability of NSAIDs to alter the metabolism of arachidonic acid in favor of forming metabolites that promote allergic symptoms. Affected individuals may be abnormally sensitive to these provocative metabolites or overproduce them and typically are susceptible to a wide range of structurally dissimilar NSAIDs, particularly those that inhibit COX-1. Symptoms, which develop immediately to hours after ingesting any of various NSAIDs that inhibit COX-1, are: 1) exacerbations of asthmatic and rhinitis (see aspirin-exacerbated respiratory disease) symptoms in individuals with a history of asthma or rhinitis and 2) exacerbation or first-time development of wheals or angioedema in individuals with or without a history of chronic urticarial lesions or angioedema.\nPossible effects on bone and soft tissue healing.\nIt has been hypothesized that NSAIDs may delay healing from bone and soft-tissue injuries by inhibiting inflammation. On the other hand, it has also been hypothesized that NSAIDs might speed recovery from soft tissue injuries by preventing inflammatory processes from damaging adjacent, non-injured muscles.\nThere is moderate evidence that they delay bone healing. Their overall effect on soft-tissue healing is unclear.\nOtotoxicity.\nLong-term use of NSAID analgesics and paracetamol is associated with an increased risk of hearing loss.\nOther.\nThe use of NSAIDs for analgesia following gastrointestinal surgery remains controversial, given mixed evidence of an increased risk of leakage from any bowel anastomosis created. This risk may vary according to the class of NSAID prescribed.\nCommon adverse drug reactions (ADR), other than those listed above, include: raised liver enzymes, headache, dizziness. Uncommon ADRs include an abnormally high level of potassium in the blood, confusion, spasm of the airways, and rash. Ibuprofen may also rarely cause irritable bowel syndrome symptoms. NSAIDs are also implicated in some cases of Stevens\u2013Johnson syndrome.\nMost NSAIDs penetrate poorly into the central nervous system (CNS). However, the COX enzymes are expressed constitutively in some areas of the CNS, meaning that even limited penetration may cause adverse effects such as somnolence and dizziness.\nNSAIDs may increase the risk of bleeding in patients with Dengue fever For this reason, NSAIDs are only available with a prescription in India.\nIn very rare cases, ibuprofen can cause aseptic meningitis.\nAs with other drugs, allergies to NSAIDs might exist. While many allergies are specific to one NSAID, up to 1 in 5 people may have unpredictable cross-reactive allergic responses to other NSAIDs as well.\nImmune response.\nAlthough small doses generally have little to no effect on the immune system, large doses of NSAIDs significantly suppress the production of immune cells. As NSAIDs affect prostaglandins, they affect the production of most fast-growing cells. This includes immune cells. Unlike corticosteroids, they do not directly suppress the immune system, and so their effect on the immune system is not immediately obvious. They suppress the production of new immune cells, but leave existing immune cells functional. Large doses slowly reduce the immune response as the immune cells are renewed at a much lower rate. Causing a gradual reduction of the immune system, much slower and less noticeable than the immediate effect of Corticosteroids. The effect significantly increases with dosage, at a nearly exponential rate. Doubling of dose reduced cells by nearly four times. Increasing the dose by five times reduced cell counts to only a few percent of normal levels. This is likely why the effect was not immediately obvious in low-dose trials, as the effect is not apparent until much higher dosages are tested.\nInteractions.\nNSAIDs reduce kidney blood flow and thereby decrease the efficacy of diuretics, and inhibit the elimination of lithium and methotrexate.\nNSAIDs cause decreased ability to form blood clots, which can increase the risk of bleeding when combined with other drugs that also decrease blood clotting, such as warfarin.\nNSAIDs may aggravate hypertension (high blood pressure) and thereby antagonize the effect of antihypertensives, such as ACE inhibitors.\nNSAIDs may interfere and reduce effectiveness of SSRI antidepressants through inhibiting TNF\u03b1 and IFN\u03b3, both of which are cytokine derivatives. NSAIDs, when used in combination with SSRIs, increase the risk of adverse gastrointestinal effects. NSAIDs, when used in combination with SSRIs, increase the risk of internal bleeding and brain hemorrhages.\nVarious widely used NSAIDs enhance endocannabinoid signaling by blocking the anandamide-degrading membrane enzyme fatty acid amide hydrolase (FAAH).\nNSAIDs may reduce the effectiveness of antibiotics. An in-vitro study on cultured bacteria found that adding NSAIDs to antibiotics reduced their effectiveness by around 20%.\nThe concomitant use of NSAIDs with alcohol and/or tobacco products significantly increases the already elevated risk of peptic ulcers during NSAID therapy.\nMechanism of action.\nMost NSAIDs act as nonselective inhibitors of the cyclooxygenase (COX) enzymes, inhibiting both the cyclooxygenase-1 (COX-1) and cyclooxygenase-2 (COX-2) isoenzymes. This inhibition is competitively reversible (albeit at varying degrees of reversibility), as opposed to the mechanism of aspirin, which is irreversible inhibition. COX catalyzes the formation of prostaglandins and thromboxane from arachidonic acid (itself derived from the cellular phospholipid bilayer by phospholipase A2). Prostaglandins act (among other things) as messenger molecules in the process of inflammation. This mechanism of action was elucidated in 1970 by John Vane (1927\u20132004), who received a Nobel Prize for his work (see Mechanism of action of aspirin).\nCOX-1 is a constitutively expressed enzyme with a \"house-keeping\" role in regulating many normal physiological processes. One of these is in the stomach lining, where prostaglandins serve a protective role, preventing the stomach mucosa from being eroded by its own acid. COX-2 is an enzyme facultatively expressed in inflammation, and it is inhibition of COX-2 that produces the desirable effects of NSAIDs.\nWhen nonselective COX-1/COX-2 inhibitors (such as aspirin, ibuprofen, and naproxen) lower stomach prostaglandin levels, ulcers of the stomach or duodenum and internal bleeding can result. The discovery of COX-2 led to research to the development of selective COX-2 inhibiting drugs that do not cause gastric problems characteristic of older NSAIDs.\nNSAIDs have been studied in various assays to understand how they affect each of these enzymes. While the assays reveal differences, unfortunately, different assays provide differing ratios.\nParacetamol (acetaminophen) is not considered an NSAID because it has little anti-inflammatory activity. It treats pain mainly by blocking COX-2, mostly in the central nervous system, but not much in the rest of the body.\nHowever, many aspects of the mechanism of action of NSAIDs remain unexplained, and for this reason, further COX pathways are hypothesized. The COX-3 pathway was believed to fill some of this gap, but recent findings make it appear unlikely that it plays any significant role in humans, and alternative explanation models are proposed.\nNSAIDs interact with the endocannabinoid system and its endocannabinoids, as COX-2 have been shown to utilize endocannabinoids as substrates, and may have a key role in both the therapeutic effects and adverse effects of NSAIDs, as well as in NSAID-induced placebo responses.\nNSAIDs are also used in the acute pain caused by gout because they inhibit urate crystal phagocytosis besides inhibition of prostaglandin synthase.\nAntipyretic activity.\nNSAIDs have antipyretic activity and can be used to treat fever. Fever is caused by elevated levels of prostaglandin E2 (PGE2), which alters the firing rate of neurons within the hypothalamus that control thermoregulation. Antipyretics work by inhibiting the enzyme COX, which causes the general inhibition of prostanoid biosynthesis (PGE2) within the hypothalamus. PGE2 signals to the hypothalamus to increase the body's thermal setpoint. Ibuprofen has been shown more effective as an antipyretic than paracetamol (acetaminophen).\nArachidonic acid is the precursor substrate for cyclooxygenase leading to the production of prostaglandins F, D, and E.\nClassification.\nNSAIDs can be classified based on their chemical structure or mechanism of action. Older NSAIDs were known long before their mechanism of action was elucidated and were, for this reason, classified by chemical structure or origin. Newer substances are more often classified by mechanism of action.\nSalicylates.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nPropionic acid derivatives.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nAcetic acid derivatives.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nEnolic acid (oxicam) derivatives.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nAnthranilic acid derivatives (Fenamates).\nThe following NSAIDs are derived from fenamic acid, which is a derivative of anthranilic acid, which in turn is a nitrogen isostere of salicylic acid, which is the active metabolite of aspirin.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSelective COX-2 inhibitors (Coxibs).\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nChirality.\nMost NSAIDs are chiral molecules; diclofenac and the oxicams are exceptions. However, the majority are prepared as racemic mixtures. Typically, only a single enantiomer is pharmacologically active. For some drugs (typically profens), an isomerase enzyme \"in vivo\" converts the inactive enantiomer into the active form, although its activity varies widely in individuals. This phenomenon is likely responsible for the poor correlation between NSAID efficacy and plasma concentration observed in older studies when specific analysis of the active enantiomer was not performed.\nIbuprofen and ketoprofen are now available in single-enantiomer preparations (dexibuprofen and dexketoprofen), which purport to offer quicker onset and an improved side-effect profile. Naproxen has always been marketed as the single active enantiomer.\nMain practical differences.\nNSAIDs within a group tend to have similar characteristics and tolerability. There is little difference in clinical efficacy among the NSAIDs when used at equivalent doses. Rather, differences among compounds usually relate to dosing regimens (related to the compound's elimination half-life), route of administration, and tolerability profile.\nRegarding adverse effects, selective COX-2 inhibitors have a lower risk of gastrointestinal bleeding. Except for naproxen, nonselective NSAIDs increase the risk of having a heart attack. Some data also supports that the partially selective nabumetone is less likely to cause gastrointestinal events.\nA consumer report noted that ibuprofen, naproxen, and salsalate are less expensive than other NSAIDs, and essentially as effective and safe when used appropriately to treat osteoarthritis and pain.\nPharmacokinetics.\nMost nonsteroidal anti-inflammatory drugs are weak acids, with a pKa of 3\u20135. They are absorbed well from the stomach and intestinal mucosa. They are highly protein-bound in plasma (typically &gt;95%), usually to albumin, so that their volume of distribution typically approximates to plasma volume. Most NSAIDs are metabolized in the liver by oxidation and conjugation to inactive metabolites that typically are excreted in the urine, though some drugs are partially excreted in bile. Metabolism may be abnormal in certain disease states, and accumulation may occur even with normal dosage.\nNSAIDs can also be divided into short-acting (plasma half-life less than 6 h) such as aspirin, diclofenac and ibuprofen and long-acting (half-life approximately greater than 10 h) such as naproxen, celecoxib.\nHistory.\nIt is widely believed that naturally occurring salicin in willow trees and other plants was used by the ancients as a form of analgesic or anti-inflammatory drug, but this story, although compelling, is not entirely true. Hippocrates does not mention willow at all. Dioscorides's \"De materia medica\" was arguably the most influential herbal from Roman to Medieval times but, if he mentions willow at all (there is doubt about the identity of 'Itea'), then he used the ashes, steeped in vinegar, as a treatment for corns, which corresponds well with modern uses of salicylic acid.\nWillow bark (from trees of the \"Salix\" genus) was widely known to be used as a medicine by multiple First Nations communities. The bark would be chewed or steeped in water for its pain relieving and antipyretic effects. The effects are a result of the bark's salicin content. Meadowsweet, another plant to contain salicin, has strong roots in British folk medicine for the same maladies. Willow bark was first reported in Western science by Edward Stone in 1763 as a treatment for ague (fever) according to the pseudoscientific doctrine of signatures.\nIn the body, salicin is turned into salicylic acid, which produces the antipyretic and analgesic effects that the plants are known for.\nSalicin was first isolated by Johann Andreas Buchner in 1827. By 1829, French chemist Henri Leroux had improved the extraction process to obtain about 30g of purified salicin from 1.5kg of willow bark. By hydrolysis, salicin releases glucose and salicyl alcohol which can be converted into salicylic acid, both in vivo and through chemical methods. In 1869, Hermann Kolbe synthesised salicylic acid, although it was too acidic for the gastric mucosa. The reaction used to synthesise aromatic acid from a phenol in the presence of CO2 is known as the Kolbe-Schmitt reaction.\nBy 1897, the German chemist Felix Hoffmann and the Bayer company prompted a new age of pharmacology by converting salicylic acid into acetylsalicylic acid\u2014named aspirin by Heinrich Dreser. Other NSAIDs like ibuprofen were developed from the 1950s forward.\nIn 2001, NSAIDs accounted for 70,000,000 prescriptions and 30billion over-the-counter doses sold annually in the United States.\nVeterinary use.\nResearch supports the use of NSAIDs for the control of pain associated with veterinary procedures such as dehorning and castration of calves. The best effect is obtained by combining a short-term local anesthetic such as lidocaine with an NSAID acting as a longer term analgesic. However, as different species have varying reactions to different medications in the NSAID family, little of the existing research data can be extrapolated to animal species other than those specifically studied, and the relevant government agency in one area sometimes prohibits uses approved in other jurisdictions.\nIn the United States, meloxicam is approved for use only in canines, whereas (due to concerns about kidney damage) it carries warnings against its use in cats except for one-time use during surgery. In spite of these warnings, meloxicam is frequently prescribed \"off-label\" for non-canine animals including cats and livestock species. In other countries, for example The European Union (EU), there is a label claim for use in cats.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22072", "revid": "13051", "url": "https://en.wikipedia.org/wiki?curid=22072", "title": "Narcotic analgesic", "text": ""}
{"id": "22073", "revid": "7098284", "url": "https://en.wikipedia.org/wiki?curid=22073", "title": "NC (complexity)", "text": "Class in computational complexity theory\n&lt;templatestyles src=\"Unsolved/styles.css\" /&gt;\nUnsolved problem in computer science\nMore unsolved problems in computer science\nIn computational complexity theory, the class NC (for \"Nick's Class\") is the set of decision problems decidable in polylogarithmic time on a parallel computer with a polynomial number of processors. In other words, a problem with input size \"n\" is in NC if there exist constants \"c\" and \"k\" such that it can be solved in time \"O\"((log \"n\")\"c\") using \"O\"(\"n\"\"k\") parallel processors. Stephen Cook coined the name \"Nick's class\" after Nick Pippenger, who had done extensive research on circuits with polylogarithmic depth and polynomial size. As in the case of circuit complexity theory, usually the class has an extra constraint that the circuit family must be \"uniform\" (see below).\nJust as the class P can be thought of as the tractable problems (Cobham's thesis), so NC can be thought of as the problems that can be efficiently solved on a parallel computer. NC is a subset of P because polylogarithmic parallel computations can be simulated by polynomial-time sequential ones. It is unknown whether NC = P, but most researchers suspect this to be false, meaning that there are probably some tractable problems that are \"inherently sequential\" and cannot significantly be sped up by using parallelism. Just as the class NP-complete can be thought of as \"probably intractable\", so the class P-complete, when using NC reductions, can be thought of as \"probably not parallelizable\" or \"probably inherently sequential\".\nThe parallel computer in the definition can be assumed to be a \"parallel, random-access machine\" (PRAM). That is a parallel computer with a central pool of memory, and any processor can access any bit of memory in constant time. The definition of NC is not affected by the choice of how the PRAM handles simultaneous access to a single bit by more than one processor. It can be CRCW, CREW, or EREW. See PRAM for descriptions of those models.\nEquivalently, NC can be defined as those decision problems decidable by a uniform Boolean circuit (which can be calculated from the length of the input, for NC, we suppose we can compute the Boolean circuit of size \"n\" in logarithmic space in \"n\") with polylogarithmic depth and a polynomial number of gates with a maximum fan-in of 2.\nRNC is a class extending NC with access to randomness.\nProblems in NC.\nAs with P, by a slight abuse of language, one might classify function problems and search problems as being in NC. NC is known to include many problems, including\nOften algorithms for those problems had to be separately invented and could not be na\u00efvely adapted from well-known algorithms \u2013 Gaussian elimination and Euclidean algorithm rely on operations performed in sequence. One might contrast ripple carry adder with a carry-lookahead adder.\nExample.\nAn example of problem in NC1 is the parity check on a bit string. The problem consists in counting the number of 1s in a string made of 1 and 0. A simple solution consists in summing all the string's bits. Since addition is associative, formula_1 Recursively applying such property, it is possible to build a binary tree of length formula_2 in which every sum between two bits formula_3 and formula_4 is expressible by means of basic logical operators, e.g. through the boolean expression formula_5.\nThe NC hierarchy.\nNC\"i\" is the class of decision problems decidable by uniform boolean circuits with a polynomial number of gates of at most two inputs and depth \"O\"((log \"n\")\"i\"), or the class of decision problems solvable in time \"O\"((log \"n\")\"i\") on a parallel computer with a polynomial number of processors. Clearly,\nformula_6\nwhich forms the NC-hierarchy.\nThe smallest class, NC\"0\", is the class of functions definable by boolean circuits with constant depth and bounded fan-in.\nThe next-smallest class, NC\"1\", is equal to BW4\"0\" , the set of all problems solvable by polynomial-size, bounded fan-in circuits of width 4 or less. This is true for both the uniform and nonuniform case (DLOGTIME-uniformity suffices).142\nOne can relate the NC classes to the space classes L, SL,137 NL, LOGCFL, and AC.\nformula_7\nThe NC classes are related to the AC classes, which are defined similarly, but with gates having unbounded fan-in. For each \"i\",\nformula_8\nAs an immediate consequence of this, NC = AC.\nAlso, formula_9.\nSimilarly, NC is equivalent to the problems solvable on an alternating Turing machine restricted to at most two options at each step with \"O\"(log \"n\") space and formula_10 alternations.\nIt is a major open question whether formula_11 . A significant partial result states that if there exists some formula_12, and a problem in formula_13, such that it requires at least formula_14 gates in formula_15, then this can be bootstrapped so that it requires superpolynomial gates, and thus not in formula_15.\nUniformity.\nThere are various levels of uniformity being considered. A family of boolean circuits is uniform if the schematics for any member of the family can be produced by a Turing machine under various resource constraints. With different levels of constraints, we would obtain possibly different complexity classes, with a more stringent constraint leading to a possibly smaller complexity class.\nIn the literature, the following uniformities have been considered for the NC\"1\" class, arranged according to strength:139\nBy default, the literature uses LOGSPACE uniformity.\nBecause it is possible that formula_18, researchers may use NC\"1\"-uniformity, since it is a possible strengthening. To avoid self-reference, NC\"1\"-uniform NC\"1\" is defined as follows: A NC\"1\" Boolean circuit family is NC\"1\"-uniform if the set of descriptions is decided by an ALOGTIME alternating Turing machine. The machine reads in a length-formula_19 description of a Boolean circuit, and halts in time formula_20.139\nFor higher classes NC\"2\", NC\"3\", ..., there are similar uniformities definable. However, for formula_21, NC\"k\"-uniform NC\"k\" and LOGSPACE-uniform NC\"k\" are equal, and both are equivalent to the following definition: The family is decided by an alternating Turing machine. The machine reads in a length-formula_19 description of a Boolean circuit, and halts in time formula_23 and space formula_20.139\nOpen problem: Is NC proper?\n&lt;templatestyles src=\"Unsolved/styles.css\" /&gt;\nUnsolved problem in computer science\nIs the formula_25 hierarchy proper?\nMore unsolved problems in computer science\nOne major open question in complexity theory is whether or not every containment in the NC hierarchy is proper. It was observed by Papadimitriou that, if NC\"i\" = NC\"i\"+1 for some \"i\", then NC\"i\" = NC\"j\" for all \"j\"\u00a0\u2265\u00a0\"i\", and as a result, NC\"i\" = NC. This observation is known as NC-hierarchy collapse because even a single equality in the chain of containments\nformula_26\nimplies that the entire NC hierarchy \"collapses\" down to some level \"i\". Thus, there are 2 possibilities:\nIt is widely believed that (1) is the case, although no proof as to the truth of either statement has yet been discovered.\nIf there exists a problem that is NC-complete under LOGSPACE or NC\"1\" reductions, then the NC hierarchy collapses.136\nBarrington's theorem.\nA branching program with \"n\" variables of width \"k\" and length \"m\" consists of a sequence of \"m\" instructions. Each of the instructions is a tuple (\"i\", \"p\", \"q\") where \"i\" is the index of variable to check (1 \u2264 \"i\" \u2264 \"n\"), and \"p\" and \"q\" are functions from {1, 2, ..., \"k\"} to {1, 2, ..., \"k\"}. Numbers 1, 2, ..., \"k\" are called states of the branching program. The program initially starts in state 1, and each instruction (\"i\", \"p\", \"q\") changes the state from \"x\" to \"p\"(\"x\") or \"q\"(\"x\"), depending on whether the \"i\"th variable is 0 or 1. The function mapping an input to a final state of the program is called the \"yield\" of the program (more precisely, the yield on an input is the function mapping any initial state to the corresponding final state). The program \"accepts\" a set formula_29 of variable values when there is some set of functions formula_30 such that a variable sequence formula_31 is in \"A\" precisely when its yield is in \"F\". \nA family of branching programs consists of a branching program with \"n\" variables for each \"n\". It accepts a language when the \"n\" variable program accepts the language restricted to length \"n\" inputs.\nIt is easy to show that every language \"L\" on {0,1} can be recognized by a family of branching programs of width 5 and exponential length, or by a family of exponential width and linear length.\nEvery regular language on {0,1} can be recognized by a family of branching programs of constant width and linear number of instructions (since a DFA can be converted to a branching program). BWBP denotes the class of languages recognizable by a family of branching programs of bounded width and polynomial length.\nBarrington's theorem says that BWBP is exactly nonuniform NC1. The proof uses the nonsolvability of the symmetric group S5.\nThe theorem is rather surprising. For instance, it implies that the majority function can be computed by a family of branching programs of constant width and polynomial size, while intuition might suggest that to achieve polynomial size, one needs a linear number of states.\nProof of Barrington's theorem.\nA branching program of constant width and polynomial size can be easily converted (via divide-and-conquer) to a circuit in NC1.\nConversely, suppose a circuit in NC1 is given. Without loss of generality, assume it uses only AND and NOT gates.\nCall a branching program \u03b1-computing a circuit \"C\" if it works as identity when C's output is 0, and as \u03b1 when C's output is 1.\nAs a consequence of Lemma 1 and the fact that all cycles of length 5 are conjugate, for any two 5-cycles \u03b1, \u03b2, if there exists a branching program \u03b1-computing a circuit \"C\", then there exists a branching program \u03b2-computing the circuit \"C\", of the same length.\n&lt;templatestyles src=\"Math_proof/styles.css\" /&gt;Proof\nWe will now prove Barrington's theorem by induction:\nSuppose we have a circuit \"C\" which takes inputs \"x\"1...,\"x\"\"n\" and assume that for all subcircuits \"D\" of \"C\" and 5-cycles \u03b1, there exists a branching program \u03b1-computing \"D\". We will show that for all 5-cycles \u03b1, there exists a branching program \u03b1-computing \"C\".\nBy assuming the subcircuits have branching programs so that they are \u03b1-computing for all 5-cycles , we have shown \"C\" also has this property, as required.\nThe size of the branching program is at most 4d, where \"d\" is the depth of the circuit. If the circuit has logarithmic depth, the branching program has polynomial length.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22075", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=22075", "title": "Nadir Khan", "text": ""}
{"id": "22076", "revid": "829949", "url": "https://en.wikipedia.org/wiki?curid=22076", "title": "Nori", "text": "Edible seaweed species of the red algae genus Pyropia\nNori is a dried edible seaweed used in Japanese cuisine, usually made from species of the red algae genus \"Pyropia\", including \"P. yezoensis\" and \"P. tenera\". It has a strong and distinctive flavor, and is generally made into flat sheets and used to wrap rolls of sushi or \"onigiri\" (rice balls).\nThe finished dried sheets are made by a shredding and rack-drying process that resembles papermaking. They are sold in packs in grocery stores for culinary purposes. Since nori sheets easily absorb water from the air and degrade, a desiccant is needed when storing nori for any significant time.\nNori\u2014despite not being cultivated by humans until the 1600s\u2014has been popular since the pre-modern era in Japan, having been used as currency, offerings at shrines, and food since the 700s.\nHistory.\nAncient.\nOriginally, the term \"nori\" was generic and referred to seaweeds, including \"hijiki\". One of the earliest descriptions of nori is dated to around the eighth century. In the Taih\u014d Code of 701 CE, \"nori\" was already included in the form of taxation. Local people were described as drying nori in the \"Hitachi Province Fudoki\" (721\u2013721 CE), and harvesting of nori was mentioned in the \"Izumo Province Fudoki\" (713\u2013733 CE). In the \"Utsubo Monogatari\", written around 987 CE, \"nori\" was recognized as a common food.\nModern.\nNori had been consumed as paste form until the sheet form (\"ita-nori\" \u677f\u6d77\u82d4) was invented in Asakusa, Tokyo, around 1750 in the Edo period through the method of Japanese paper-making.\nThe word \"\"nori\" first appeared in an English-language publication in \"C.\u00a0P. Thunberg's Trav.\", published in 1796. It was used in conjugation as \"Awa nori\", probably referring to what now is called \"aonori\"\", i.e., green laver.\nWhen Japan was in need of high food production after World War II, production of nori was in decline. They sought to cultivate nori in addition to traditional wild harvesting from the sea. Due to a lack of understanding of nori's three-stage life cycle, however, those attempting to produce nori artificially did not understand why their cultivation methods were not being productive with nori. The industry was rescued by knowledge derived from the work of British phycologist Kathleen Mary Drew-Baker, who had been researching the organism \"Porphyria umbilicalis\" that grew in the seas around Wales and was harvested for food (laverbread), as in Japan. Her work was discovered by Japanese scientists who applied it to artificial methods of seeding and growing the nori, rescuing the industry. Kathleen Baker was hailed in Japan as the \"Mother of the Sea\" and a statue was erected in her memory. She is still revered as the savior of the Japanese nori industry.\nThe word \"nori\" started to be used widely in the United States and the product (imported in dry form from Japan) became widely available at natural food stores and Asian-American grocery stores in the 1960s due to the macrobiotic movement and in the 1970s with the increase of sushi bars and Japanese restaurants.\nIn the 21st century, the Japanese nori industry faces a new decline due to increased competition from seaweed producers in China and Korea, and an increase in domestic sales tax.\nProduction.\nProduction and processing of \"nori\" is an advanced form of agriculture. The biology of \"Pyropia\", although complicated, now is well understood, and this knowledge is used to control the production process. Farming takes place in the sea where the \"Pyropia\" plants grow attached to nets suspended at the sea surface and where the farmers operate from boats. The plants grow rapidly, requiring approximately 45 days from \"seeding\" until the first harvest. Multiple harvests can be taken from a single seeding, typically at approximately ten-day intervals. Harvesting is accomplished using mechanical harvesters of a variety of configurations. Processing of raw product is mostly accomplished by highly automated machines that accurately duplicate traditional manual processing steps, but with much improved efficiency and consistency. The final product is a paper-thin, black, dried sheet of approximately and in weight.\nSeveral grades of nori are available in the United States. The most common (and least expensive) grades are imported from China, costing approximately six cents per sheet. At the high end, ranging up to 90 cents per sheet, are \"delicate \"shin-nori\"\" (\"nori\" from the first of the year's several harvests) cultivated in the Ariake Sea, off the island of Kyushu in Japan.\nIn Japan, more than of coastal waters are given to producing of nori, worth more than a billion dollars. China produces approximately a third of this amount.\nWild seaweed is still gathered to make nori, often found growing on rocks at the beach. Such wild nori is called \"iwanori\" (\"rock nori\"), and are known for their rougher texture and taste.\nCulinary uses.\nNori is commonly used as a wrap for sushi and \"onigiri\" (rice balls). The dry seaweed is used to pick up rice balls without getting the hands sticky. \"Senbei\" (rice crackers) sometimes contain a piece of nori as well.\nStrips or small sheets of nori are used as garnish for noodles, soups, and rice dishes. Flakes of nori are used in \"furikake\" seasonings, to be sprinkled over rice or added to \"onigiri\". Very small flakes or powdered nori can be dusted over a variety of savory foods.\nTypically, nori is toasted prior to consumption. Toasted nori is called \"yaki-nori\". A common secondary product is toasted and flavored nori (\"ajitsuke-nori\"), in which a flavoring mixture (variable, but typically soy sauce, sugar, sake, mirin, and seasonings) is applied in combination with the toasting process. Nori is also eaten by making it into a soy sauce-flavored paste, \"nori no tsukudani\" (). Sometimes it is also used as a form of food decoration, such as creating faces or anime characters in bento boxes.\nA related product, prepared from the unrelated green algae \"Monostroma\" and \"Enteromorpha\", is called \"aonori\" ( literally blue/green \"nori\") and it is used as an herb on everyday meals, such as \"okonomiyaki\" and \"yakisoba\".\nNutrition.\nRaw seaweed is 85% water, 6% protein, 5% carbohydrates, and has negligible fat. In a 100 gram reference amount, seaweed is a rich source (20% or more of the Daily Value, DV) of vitamin A, vitamin C, riboflavin, and folate. Seaweed is a moderate source (less than 20% DV) of niacin, iron, and zinc. Seaweed has a high content of iodine, providing a substantial amount in just one gram. A 2014 study reported that dried purple laver (\"nori\") contains vitamin B12 in sufficient quantities to meet the RDA requirement (Vitamin B12 content: 77.6 \u03bcg /100 g dry weight). By contrast, however, a 2017 review concluded that vitamin B12 may be destroyed during metabolism or is converted into inactive B12 analogs during drying and storage. The Academy of Nutrition and Dietetics stated in 2016 that nori is not an adequate source of vitamin B12 for humans. \nHealth risks.\nNori may contain toxic metals (arsenic and cadmium), depending upon the harvested seaweed's habitat and ecology. It also contains amphipod allergens that may cause serious allergic reactions, especially in highly sensitized crustacean-allergic people.\nSimilar food.\nThe red algae genera is also consumed in Korean cuisine as \"gim\", in Chinese cuisine as \"haitai\" (\u6d77\u82d4) or \"zicai\" (\u7d2b\u83dc), and in Wales and Ireland as laverbread.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22077", "revid": "23326194", "url": "https://en.wikipedia.org/wiki?curid=22077", "title": "Neutrinos", "text": ""}
{"id": "22080", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=22080", "title": "Netwar", "text": ""}
{"id": "22081", "revid": "42601261", "url": "https://en.wikipedia.org/wiki?curid=22081", "title": "Normative ethics", "text": "Branch of philosophical ethics that examines standards for morality\nNormative ethics is the study of ethical behaviour and is the branch of philosophical ethics that investigates questions regarding how one ought to act, in a moral sense.\nNormative ethics is distinct from metaethics in that normative ethics examines standards for the rightness and wrongness of actions, whereas meta-ethics studies the meaning of moral language and the metaphysics of moral facts. Likewise, normative ethics is distinct from applied ethics in that normative ethics is more concerned with \"who ought one be\" rather than the ethics of a specific issue (e.g. if, or when, abortion is acceptable). Normative ethics is also distinct from descriptive ethics, as descriptive ethics is an empirical investigation of people's moral beliefs. In this context normative ethics is sometimes called \"prescriptive\" (as opposed to \"descriptive\") ethics. However, on certain versions of the view of moral realism, moral facts are both descriptive and prescriptive at the same time.\nMost traditional moral theories rest on principles that determine whether an action is right or wrong. Classical theories in this vein include utilitarianism, Kantianism, and some forms of contractarianism. These theories mainly offered the use of overarching moral principles to resolve difficult moral decisions.\nNormative ethical theories.\nThere are disagreements about what precisely gives an action, rule, or disposition its ethical force. There are three competing views on how moral questions should be answered, along with hybrid positions that combine some elements of each: virtue ethics, deontological ethics, and consequentialism. Virtue ethics focuses on the character of those who are acting. In contrast, both deontological ethics and consequentialism focus on the status of the action, rule, or disposition itself, and come in various forms.\nVirtue ethics.\nVirtue ethics, advocated by Aristotle with some aspects being supported by Saint Thomas Aquinas, focuses on the inherent character of a person rather than on specific actions. There has been a significant revival of virtue ethics since the 1950s, through the work of such philosophers as G.\u00a0E.\u00a0M. Anscombe, Philippa Foot, Alasdair MacIntyre, and Rosalind Hursthouse.\nDeontological ethics.\nDeontology argues that decisions should be made considering the factors of one's duties and one's rights. Some deontological theories include:\nConsequentialism.\nConsequentialism argues that the morality of an action is contingent on the action's outcome or result. Consequentialist theories, varying in what they consider to be valuable (i.e., axiology), include:\nMorality as a binding force.\nIt can be unclear what it means to say that a person \"ought to do X because it is moral, whether they like it or not.\" Morality is sometimes presumed to have some kind of special binding force on behaviour, though some philosophers believe that, used this way, the word \"ought\" seems to wrongly attribute magic powers to morality. For instance, G. E. M. Anscombe worries that \"ought\" has become \"a word of mere mesmeric force.\" \n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nIf he is an amoral man he may deny that he has any reason to trouble his head over this or any other moral demand. Of course, he may be mistaken, and his life as well as others' lives may be most sadly spoiled by his selfishness. But this is not what is urged by those who think they can close the matter by an emphatic use of 'ought'. My argument is that they are relying on an illusion, as if trying to give the moral 'ought' a magic force.\n\u2014Philippa Foot\n The British ethicist Philippa Foot elaborates that morality does not seem to have any special binding force, and she clarifies that people only behave morally when motivated by other factors. Foot says \"People talk, for instance, about the 'binding force' of morality, but it is not clear what this means if not that we feel ourselves unable to escape.\" The idea is that, faced with an opportunity to steal a book because we can get away with it, moral obligation itself has no power to stop us unless we \"feel\" an obligation. Morality may therefore have no binding force beyond regular human motivations, and people must be motivated to behave morally. The question then arises: what role does reason play in motivating moral behaviour?\nMotivating morality.\nThe categorical imperative perspective suggests that proper reason always leads to particular moral behaviour. As mentioned above, Foot instead believes that humans are actually motivated by desires. Proper reason, on this view, allows humans to discover actions that get them what they want (i.e., hypothetical imperatives)\u2014not necessarily actions that are moral.\nSocial structure and motivation can make morality binding in a sense, but only because it makes moral norms feel inescapable, according to Foot.\nJohn Stuart Mill adds that external pressures, to please others for instance, also influence this felt binding force, which he calls human \"conscience\". Mill says that humans must first reason about what is moral, then try to bring the feelings of our conscience in line with our reason. At the same time, Mill says that a good moral system (in his case, utilitarianism) ultimately appeals to aspects of human nature\u2014which, must themselves be nurtured during upbringing. Mill explains:\nThis firm foundation is that of the social feelings of mankind; the desire to be in unity with our fellow creatures, which is already a powerful principle in human nature, and happily one of those which tend to become stronger, even without express inculcation, from the influences of advancing civilisation.\nMill thus believes that it is important to appreciate that it is feelings that drive moral behavior, but also that they may not be present in some people (e.g. psychopaths). Mill goes on to describe factors that help ensure people develop a conscience and behave morally.\nPopular texts such as Joseph Daleiden's \"The Science of Morality: The Individual, Community, and Future Generations\" (1998) describe how societies can use science to figure out how to make people more likely to be good.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22083", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=22083", "title": "Negotiation", "text": "Dialogue intended to reach an agreement\nNegotiation is a dialogue between two or more parties to resolve points of difference, gain an advantage for an individual or collective, or craft outcomes to satisfy various interests. The parties aspire to agree on matters of mutual interest. The agreement can be beneficial for all or some of the parties involved. The negotiators should establish their own needs and wants while also seeking to understand the wants and needs of others involved to increase their chances of closing deals, avoiding conflicts, forming relationships with other parties, or maximizing mutual gains. Distributive negotiations, or compromises, are conducted by putting forward a position and making concessions to achieve an agreement. The degree to which the negotiating parties trust each other to implement the negotiated solution is a major factor in determining the success of a negotiation.\nPeople negotiate daily, often without considering it a negotiation. Negotiations may occur in organizations, including businesses, non-profits, and governments, as well as in sales and legal proceedings, and personal situations such as marriage, divorce, parenting, friendship, etc. Professional negotiators are often specialized. Examples of professional negotiators include union negotiators, leverage buyout negotiators, peace negotiators, and hostage negotiators. They may also work under other titles, such as diplomats, legislators, or arbitrators. Negotiations may also be conducted by algorithms or machines in what is known as automated negotiation. In automated negotiation, the participants and process have to be modeled correctly. Recent negotiation embraces complexity.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nTypes.\nNegotiation can take a variety of forms in different contexts. These may include conferences between members of the United Nations to establish international norms, meetings between combatants to end a military conflict, meetings between representatives of businesses to bring about a transaction, and conversations between parents about how to manage childcare. Mediation is a form of negotiation where a third party helps the conflicting parties negotiate, usually when they are unable to do so by themselves. Mediated negotiation can be contrasted with arbitration, where conflicting parties commit to accepting the decision of a third party. Negotiations in the workplace can impact the entire organization's performance.\nNegotiation theorists generally distinguish between two primary types of negotiation: distributive negotiation and integrative negotiation. The type of negotiation that takes place is dependent on the mindset of the negotiators and the situation of the negotiation. For example, one-off encounters where lasting relationships do not occur are more likely to produce distributive negotiations whereas lasting relationships are more likely to require integrative negotiating. Theorists vary in their labeling and definition of these two fundamental types.\nDistributive negotiation.\nDistributive negotiation (also known as Win-lose game), compromise, positional negotiation, or hard-bargaining negotiation attempts to distribute a \"fixed pie\" of benefits. Distributive negotiation operates under zero-sum conditions, where it is assumed that any gain made by one party will be at the expense of the other. Haggling over prices on an open market, as in the purchase of a car or home, is an example of distributive negotiation.\nIn a distributive negotiation, each side often adopts an extreme or fixed position that they know will not be accepted, and then seeks to cede as little as possible before reaching a deal. Distributive bargainers conceive of negotiation as a process of distributing a fixed amount of value. A distributive negotiation often involves people who have never had a previous interactive relationship with each other and are unlikely to do so again shortly, although all negotiations usually have some distributive element. Since prospect theory indicates that people tend to prioritize the minimization of losses over the maximization of gains, this form of negotiation is likely to be more acrimonious and less productive in agreement.\nIntegrative negotiation.\nIntegrative negotiation is also called interest-based, merit-based, win-win, or principled negotiation. It is a set of techniques that attempts to improve the quality and likelihood of negotiated agreement by taking advantage of the fact that different parties often value various outcomes differently. While distributive negotiation assumes there is a fixed amount of value (a \"fixed pie\") to be divided between the parties, integrative negotiation attempts to create value in the course of the negotiation (\"expand the pie\") by either \"compensating\" the loss of one item with gains from another (\"trade-offs\" or logrolling), or by constructing or reframing the issues of the conflict in such a way that both parties benefit (\"win-win\" negotiation).\nHowever, even integrative negotiation is likely to have some distributive elements, especially when the different parties value some items to the same degree or when details are left to be allocated at the end of the negotiation. While concession by at least one party is always necessary for negotiations, research shows that people who concede more quickly are less likely to explore all integrative and mutually beneficial solutions. Therefore, early concession reduces the chance of an integrative negotiation.\nIntegrative negotiation often involves a higher degree of trust and the formation of a relationship, although INSEAD professor Horacio Falcao has stated that, counter-intuitively, trust is a helpful aid to successful win-win negotiation but not a necessary requirement: he argues that promotion of interdependence is a more effective strategy that development of trust. Integrative negotiation can also involve creative problem-solving in the pursuit of mutual gains. It sees a good agreement as one that provides optimal gain for both parties, rather than maximum individual gain. Each party seeks to allow the other party sufficient benefit that both will hold to the agreement.\nProductive negotiation focuses on the underlying interests of both parties rather than their starting positions and approaches negotiation as a shared problem-solving exercise rather than an individualized battle. Adherence to objective and principled criteria is the basis for productive negotiation and agreement.\nText-based negotiation.\nText-based negotiation refers to the process of working up the text of an agreement that all parties are willing to accept and sign. Negotiating parties may begin with a draft text, consider new textual suggestions, and work to find the middle ground among various differing positions.\nCommon examples of text-based negotiation include the redaction of a constitution, law or sentence by a constitutional assembly, legislature or court respectively. Other more specific examples are United Nations' negotiation regarding the reform of the UN Security Council and the formation of the international agreement underpinning the Regional Comprehensive Economic Partnership (RCEP) in the Asia-Pacific Region, where the parties involved failed in 2019 to agree on a text which would suit India.\nSuch negotiations are often founded on the principle that \"nothing is agreed until everything is agreed\". For example, this principle, also known as the single undertaking approach, is often used in World Trade Organization negotiations, although some negotiations relax this requirement. The principle formed part of the British negotiating approach for the Brexit deal following the UK's withdrawal from the European Union.\nIntegrated negotiation.\n\"Integrated negotiation\" is a strategic attempt to maximize value in any single negotiation through the astute linking and sequencing of other negotiations and decisions related to one's operating activities.\nThis approach in complex settings is executed by mapping out all potentially relevant negotiations, conflicts, and operating decisions to integrate helpful connections among them while minimizing any potentially harmful connections (see examples below).\n\"Integrated negotiation\" is not to be confused with \"integrative negotiation\", a different concept (as outlined above) related to a non-zero-sum approach to creating value in negotiations.\nIntegrated negotiation was first identified and labeled by the international negotiator and author Peter Johnston in his book \"Negotiating with Giants\".\nOne of the examples cited in Johnston's book is that of J. D. Rockefeller deciding where to build his first major oil refinery. Instead of taking the easier, cheaper route from the oil fields to refine his petroleum in Pittsburgh, Rockefeller chose to build his refinery in Cleveland, because he recognized that he would have to negotiate with the rail companies transporting his refined oil to market. Pittsburgh had just one major railroad, which would therefore be able to dictate prices in negotiations, while Cleveland had three railroads that Rockefeller knew would compete for his business, potentially reducing his costs significantly. The leverage gained in these rail negotiations more than offset the additional operating costs of sending his oil to Cleveland for refining, helping establish Rockefeller's empire, while undermining his competitors who failed to integrate their core operating decisions with their negotiation strategies.\nOther examples of integrated negotiation include the following:\nBad faith.\nWhen a party pretends to negotiate but secretly has no intention of compromising, the party is negotiating in bad faith; for example, when a political party sees political benefit in \"appearing\" to negotiate without having any intention of making the compromises necessary to settle.\nBad faith negotiations are often used in political science and political psychology to refer to negotiating strategies in which there is no real intention to reach compromise or a model of information processing. The \"inherent bad faith model\" of information processing is a theory in political psychology that was first put forth by Ole Holsti to explain the relationship between John Foster Dulles' beliefs and his model of information processing. It is the most widely studied model of one's opponent: A state is presumed implacably hostile, and contra-indicators of this are ignored. They are dismissed as propaganda ploys or signs of weakness. Examples are John Foster Dulles' position regarding the Soviet Union.\nNegotiation pie.\nThe total of advantages and disadvantages to be distributed in a negotiation is illustrated with the term negotiation pie. The course of the negotiation can either lead to an increase, shrinking, or stagnation of these values. If the negotiating parties can expand the total pie, a win-win situation is possible, assuming that both parties profit from the expansion of the pie. In practice, however, this maximization approach is oftentimes impeded by the so-called small pie bias, i.e. the psychological underestimation of the negotiation pie's size. Likewise, the possibility to increase the pie may be underestimated due to the so-called incompatibility bias. Contrary to enlarging the pie, the pie may also shrink during negotiations e.g. due to (excessive) negotiation costs.\nInternational negotiation.\nDue to different cultural lenses negotiation style differ worldwide. These differences comprise among others how the parties exchange information, the use of different strategies, conceptions of the nature of negotiation, the use of power, the use of options. Negotiations as they are often taught and used by practitioners in \"Western\" countries may not be effective or may even be counterproductive in \"non-Western\" countries \u2013 such as Asian countries. These cultural differences can lead to misunderstandings, misinterpretations, and conflicts that hinder effective deal-making. Overcoming these barriers requires cultural awareness, adaptability, and strategic communication.\nStrategies.\nThere are many different ways to categorize the essential elements of negotiation.\nOne view of negotiation involves three basic elements: \"process\", \"behavior,\" and \"substance\". The process refers to how the parties negotiate: the context of the negotiations, the parties to the negotiations, the tactics used by the parties, and the sequence and stages in which all of these play out. Behavior refers to the relationships among these parties, the communication between them, and the styles they adopt. The substance refers to what the parties negotiate over: the agenda, the issues (positions and \u2013 more helpfully \u2013 interests), the options, and the agreement(s) reached at the end.\nAnother view of negotiation comprises four elements: \"strategy\", \"process\", \"tools\", and \"tactics\". The Strategy comprises top-level goals. Which typically include the relationship and the outcome. Processes and tools include the steps to follow and roles to take in preparing for and negotiating with the other parties. Tactics include more detailed statements and actions and responses to others' statements and actions. Some add to this \"persuasion and influence\", asserting that these have become integral to modern-day negotiation success, and so should not be omitted.\nStrategic approaches to concession-making include consideration of the optimum time to make a concession, making concessions in installments, not all at once, and ensuring that the opponent is aware that a concession has been made, rather than a re-expression of a position already outlined, and aware of the cost incurred in making the concession, especially where the other party is generally less aware of the nature of the business or the product being negotiated.\nStages in the negotiation process.\nNegotiators do not need to sacrifice effective negotiation in favor of a positive relationship between parties. Rather than conceding, each side can appreciate that the other has emotions and motivations of their own and use this to their advantage in discussing the issue. Understanding perspectives can help move parties toward a more integrative solution. Fisher \"et al.\" illustrate a few techniques that effectively improve perspective-taking in the book \"Getting to Yes\", and through the following, negotiators can separate people from the problem itself:\nAdditionally, negotiators can use specific communication techniques to build stronger relationships and develop more meaningful negotiation solutions.\nEmploying an advocate.\nA skilled negotiator may serve as an advocate for one party to the negotiation. The advocate attempts to obtain the most favorable outcomes possible for that party. In this process, the negotiator attempts to determine the minimum outcome(s) the other party is (or parties are) willing to accept, then adjusts their demands accordingly. A \"successful\" negotiation in the advocacy approach is when the negotiator can obtain all or most of the outcomes their party desires, but without driving the other party to permanently break off negotiations.\nSkilled negotiators may use a variety of tactics ranging from negotiation hypnosis to a straightforward presentation of demands or setting of preconditions, to more deceptive approaches such as cherry picking. Intimidation and salami tactics may also play a part in swaying the outcome of negotiations.\nAnother negotiation tactic is the bad guy/good guy. Bad guy/good guy is when one negotiator acts as a bad guy by using anger and threats. The other negotiator acts as a good guy by being considerate and understanding. The good guy blames the bad guy for all the difficulties while soliciting concessions and agreement from the opponent.\nBATNA.\nThe best alternative to a negotiated agreement, or BATNA, is the most advantageous alternative course of action a negotiator can take should the current negotiation end without reaching an agreement. The quality of a BATNA has the potential to improve a party's negotiation outcome. Understanding one's BATNA can empower an individual and allow him or her to set higher goals when moving forward. Alternatives need to be actual and actionable to be of value. Negotiators may also consider the other party's BATNA and how it compares to what they are offering during the negotiation.\nConflict styles.\nKenneth W. Thomas identified five styles or responses to negotiation. These five strategies have been frequently described in the literature and are based on the dual-concern model. The dual-concern model of conflict resolution is a perspective that assumes individuals' preferred method of dealing with conflict is based on two themes or dimensions:\nBased on this model, individuals balance their concern for personal needs and interests with the needs and interests of others. The following five styles can be used based on individuals' preferences, depending on their pro-self or pro-social goals. These styles can change over time, and individuals can have strong dispositions toward numerous styles.\n&lt;templatestyles src=\"Glossary/styles.css\" /&gt;\nTypes of negotiators.\nThree basic kinds of negotiators have been identified by researchers involved in The Harvard Negotiation Project. These types of negotiators are soft bargainers, hard bargainers, and principled bargainers.\nResearchers from The Harvard Negotiation Project recommend that negotiators explore several tactics to reach the best solution for their problems, but this is often not the case (as when you may be dealing with an individual using soft or hard-bargaining tactics) (Forsyth, 2010).\n&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Tactics.\nTactics are always an important part of the negotiating process. More often than not they are subtle, difficult to identify, and used for multiple purposes. Tactics are more frequently used in distributive negotiations and when the focus is on taking as much value off the table as possible. Many negotiation tactics exist. Below are a few commonly used tactics.\nNonverbal communication.\nCommunication is a key element of negotiation. Effective negotiation requires that participants effectively convey and interpret information. Participants in a negotiation communicate information not only verbally but non-verbally through body language and gestures. By understanding how nonverbal communication works, a negotiator is better equipped to interpret the information other participants are leaking non-verbally while keeping secret those things that would inhibit his/her ability to negotiate.\nExamples.\nNon-verbal \"anchoring\".\nIn a negotiation, a person can gain the advantage by verbally expressing a position first. By anchoring one's position, one establishes the position from which the negotiation proceeds. Similarly, one can \"anchor\" and gain an advantage with nonverbal (body language) cues.\nReading non-verbal communication.\nBeing able to read the non-verbal communication of another person can significantly aid in the communication process. By being aware of inconsistencies between a person's verbal and non-verbal communication and reconciling them, negotiators can come to better resolutions. Examples of incongruity in body language include:\nConveying receptivity.\nThe way negotiation partners position their bodies relative to each other may influence how receptive each is to the other person's message and ideas.\nReceptive negotiators tend to appear relaxed with their hands open and palms visibly displayed.\nEmotion.\nEmotions play an important part in the negotiation process, although it is only in recent years that their effect is being studied. Emotions have the potential to play either a positive or negative role in negotiation. During negotiations, the decision as to whether or not to settle rests in part on emotional factors. Negative emotions can cause intense and even irrational behavior and can cause conflicts to escalate and negotiations to break down, but may be instrumental in attaining concessions. On the other hand, positive emotions often facilitate reaching an agreement and help to maximize joint gains, but can also be instrumental in attaining concessions. Positive and negative discrete emotions can be strategically displayed to influence task and relational outcomes and may play out differently across cultural boundaries.\nAffect effect.\nDispositions for effects affect various stages of negotiation: which strategies to use, which strategies are chosen, the way the other party and their intentions are perceived, their willingness to reach an agreement, and the final negotiated outcomes. Positive affectivity (PA) and negative affectivity (NA) of one or more of the negotiating sides can lead to very different outcomes.\nPositive affect.\nEven before the negotiation process starts, people in a positive mood have more confidence, and higher tendencies to plan to use a cooperative strategy. During the negotiation, negotiators who are in a positive mood tend to enjoy the interaction more, show less contentious behavior, use less aggressive tactics, and more cooperative strategies. This, in turn, increases the likelihood that parties will reach their instrumental goals, and enhance the ability to find integrative gains. Indeed, compared with negotiators with negative or natural affectivity, negotiators with positive affectivity reached more agreements and tended to honor those agreements more. Those favorable outcomes are due to better decision-making processes, such as flexible thinking, creative problem-solving, respect for others' perspectives, willingness to take risks, and higher confidence. The post-negotiation positive effect has beneficial consequences as well. It increases satisfaction with the achieved outcome and influences one's desire for future interactions. The PA aroused by reaching an agreement facilitates the dyadic relationship, which brings commitment that sets the stage for subsequent interactions. PA also has its drawbacks: it distorts the perception of self-performance, such that performance is judged to be relatively better than it is. Thus, studies involving self-reports on achieved outcomes might be biased.\nNegative affect.\nNegative affect has detrimental effects on various stages in the negotiation process. Although various negative emotions affect negotiation outcomes, by far the most researched is anger. Angry negotiators plan to use more competitive strategies and cooperate less, even before the negotiation starts. These competitive strategies are related to reduced joint outcomes.\nDuring negotiations, anger disrupts the process by reducing the level of trust, clouding parties' judgment, narrowing parties' focus of attention, and changing their central goal from reaching an agreement to retaliating against the other side. Angry negotiators pay less attention to the opponent's interests and are less accurate in judging their interests, thus achieving lower joint gains. Moreover, because anger makes negotiators more self-centered in their preferences, it increases the likelihood that they will reject profitable offers. Opponents who get angry (or cry, or otherwise lose control) are more likely to make errors.\nAnger does not help achieve negotiation goals either: it reduces joint gains and does not boost personal gains, as angry negotiators do not succeed. Moreover, negative emotions lead to acceptance of settlements that are not in a positive utility function but rather have a negative utility. However, the expression of negative emotions during negotiation can sometimes be beneficial: legitimately expressed anger can be an effective way to show one's commitment, sincerity, and needs. Moreover, although NA reduces gains in integrative tasks, it is a better strategy than PA in distributive tasks (such as zero-sum). In his work on negative affect arousal and white noise, Seidner found support for the existence of a negative affect arousal mechanism through observations regarding the devaluation of speakers from other ethnic origins. Negotiation may be negatively affected, in turn, by submerged hostility toward an ethnic or gender group.\nConditions for emotion affect.\nResearch indicates that a negotiator's emotions do not necessarily affect the negotiation process.\nAlbarrac\u0131n et al. (2003) suggested that there are two conditions for emotional affect, both related to the ability (presence of environmental or cognitive disturbances) and the motivation:\nAccording to this model, emotions affect negotiations only when one is high and the other is low. When both ability and motivation are low, the effect is identified, and when both are high the effect is identified but discounted as irrelevant to judgment.\nA possible implication of this model is, for example, that the positive effects of PA have on negotiations (as described above) are seen only when either motivation or ability is low.\nEffect of partner's emotions.\nMost studies on emotion in negotiations focus on the effect of the negotiator's own emotions on the process. However, what the other party feels might be just as important, as group emotions are known to affect processes both at the group and the personal levels.\nWhen it comes to negotiations, trust in the other party is a necessary condition for its emotion to effect, and visibility enhances the effect.\nEmotions contribute to negotiation processes by signaling what one feels and thinks and can thus prevent the other party from engaging in destructive behaviors and indicate what steps should be taken next: PA signals to keep in the same way, while NA points out that mental or behavioral adjustments are needed.\nPartner's emotions can have two basic effects on the negotiator's emotions and behavior: mimetic/ reciprocal or complementary. For example, disappointment or sadness might lead to compassion and more cooperation. In a study by Butt et al. (2005) that simulated real multi-phase negotiation, most people reacted to the partner's emotions in a reciprocal, rather than complementary, manner. Specific emotions were found to have different effects on the opponent's feelings and are strategies chosen:\nProblems with laboratory studies.\nNegotiation is a complex interaction. Capturing all its complexity is a very difficult task, let alone isolating and controlling only certain aspects of it. For this reason, most negotiation studies are done under laboratory conditions and focus only on some aspects. Although such studies have their advantages, they do have major drawbacks when studying emotions:\nGroup composition.\nMulti-party.\nWhile negotiations involving more than two parties are less often researched, some results from two-party negotiations still apply to more than two parties. One such result is that in negotiations it is common to see language similarity arise between the two negotiating parties. In three-party negotiations, language similarity still arose, and results were particularly efficient when the party with the most to gain from the negotiation adopted language similarities from the other parties.\nTeam.\nDue to globalization and growing business trends, negotiation in the form of teams is becoming widely adopted. Teams can effectively collaborate to break down a complex negotiation. There is more knowledge and wisdom dispersed in a team than in a single mind. Writing, listening, and talking, are specific roles team members must satisfy. The capacity base of a team reduces the number of blunders and increases familiarity in a negotiation.\nHowever, unless a team can appropriately utilize the full capacity of its potential, effectiveness can suffer. One factor in the effectiveness of team negotiation is a problem that occurs through solidarity behavior. Solidarity behavior occurs when one team member reduces his or her utility (benefit) to increase the benefits of other team members. This behavior is likely to occur when interest conflicts rise. When the utility/needs of the negotiation opponent do not align with every team member's interests, team members begin to make concessions and balance the benefits gained among the team.\nIntuitively, this may feel like a cooperative approach. However, though a team may aim to negotiate in a cooperative or collaborative nature, the outcome may be less successful than is possible, especially when integration is possible. The integrative potential is possible when different negotiation issues are of different importance to each team member. The integrative potential is often missed due to the lack of awareness of each member's interests and preferences. Ultimately, this leads to a poorer negotiation result.\nThus, a team can perform more effectively if each member discloses his or her preferences before the negotiation. This step will allow the team to recognize and organize the team's joint priorities, which they can take into consideration when engaging with the opposing negotiation party. Because a team is more likely to discuss shared information and common interests, teams must make an active effort to foster and incorporate unique viewpoints from experts from different fields. Research by Daniel Thiemann, which largely focused on computer-supported collaborative tasks, found that the Preference Awareness method is an effective tool for fostering knowledge about joint priorities and further helps the team judge which negotiation issues were of the highest importance.\nWomen.\nWomen often excel in collaborative and integrative negotiations, where they can leverage their strong communication skills and empathy to find mutually beneficial solutions. However, they may face challenges in competitive or distributive negotiations, where a more assertive and confrontational approach is typically required. Many of the implications of these findings have strong financial impacts in addition to the social backlash faced by self-advocating women in negotiations, as compared to other advocating women, self-advocating men, and other advocating men. Research in this area has been studied across platforms, in addition to more specific areas like women as physician assistants. The backlash associated with this type of behavior is attributed to the fact that to be self-advocated is considered masculine, whereas the alternative, being accommodating, is considered more feminine. Males, however, do not appear to face any type of backlash for not being self-advocating.\nThis research has been supported by multiple studies, including one which evaluated candidates participating in a negotiation regarding compensation. This study showed that women who initiated negotiations were evaluated more poorly than men who initiated negotiations. In another variation of this particular setup, men and women evaluated videos of men and women either accepting a compensation package or initiating negotiations. Men evaluated women more poorly for initiating negotiations, while women evaluated both men and women more poorly for initiating negotiations. In this particular experiment, women were less likely to initiate a negotiation with a male, citing nervousness, but there was no variation with the negotiation initiated with another female.\nResearch also supports the notion that the way individuals respond in a negotiation varies depending on the gender of the opposite party. In all-male groups, the use of deception showed no variation in the level of trust between negotiating parties, however in mixed-sex groups, there was an increase in deceptive tactics when it was perceived that the opposite party was using an accommodating strategy. In all-female groups, there were many shifts in when individuals did and did not employ deception in their negotiation tactics.\nAcademic negotiation.\nThe academic world contains a unique management system, wherein faculty members, some of whom have tenure, reside in academic units (e.g. departments), and are overseen by chairs, or heads. These chairs/heads are in turn supervised by deans of the college where their academic unit resides. Negotiation is an area where faculties, chairs/heads, and their deans have little preparation; their doctoral degrees are typically in a highly specialized area according to their academic expertise. However, the academic environment frequently presents situations where negotiation takes place. For example, many faculties are hired with the expectation that they will conduct research and publish scholarly works. For these faculties, where their research requires equipment, space, and/or funding, negotiation of a \"start-up\" package is critical for their success and future promotion. Also, department chairs often find themselves in situations, typically involving resource redistribution where they must negotiate with their dean, on behalf of their unit. And deans oversee colleges where they must optimize limited resources, such as research space or operating funds while at the same time creating an environment that fosters student success, research accomplishments, and more.\nIntegrative negotiation is the type predominately found in academic negotiation \u2013 where trust and long-term relationships between personnel are valued. Techniques found to be particularly useful in academic settings include: \nEtymology.\nThe word \"negotiation\" originated in the early 15th century from the Old French \"negociacion\" from Latin \"negotiatio\" from \"neg\"- \"no\" and \"otium\" \"leisure\". These terms mean \"business, trade, traffic\". By the late 1570s negotiation had the definition, \"to communicate in search of mutual agreement\". With this new introduction and this meaning, it showed a shift from \"doing business\" to \"bargaining about\" business.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "22085", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=22085", "title": "Fertility awareness", "text": "Methods to determine menstrual phases\nFertility awareness (FA) refers to a set of practices used to determine the fertile and infertile phases of a woman's menstrual cycle. Fertility awareness methods may be used to avoid pregnancy, to achieve pregnancy, or as a way to monitor gynecological health.\nMethods of identifying infertile days have been known since antiquity, but scientific knowledge gained during the past century has increased the number, variety, and especially accuracy of methods.\nSystems of fertility awareness rely on observation of changes in one or more of the primary fertility signs (basal body temperature, cervical mucus, and cervical position), tracking menstrual cycle length and identifying the fertile window based on this information, or both. Other signs may also be observed: these include breast tenderness and mittelschmerz (ovulation pains), urine analysis strips known as ovulation predictor kits (OPKs), and microscopic examination of saliva or cervical fluid. Also available are computerized fertility monitors.\nTerminology.\nSymptoms-based methods involve tracking one or more of the three primary fertility signs: basal body temperature, cervical mucus, and cervical position. Systems relying exclusively on cervical mucus include the Billings Ovulation Method, the Creighton Model, and the Two-Day Method. Symptothermal methods combine observations of basal body temperature (BBT), cervical mucus, and sometimes cervical position. Calendar-based methods rely on tracking a woman's cycle and identifying her fertile window based on the lengths of her cycles. The best known of these methods is the Standard Days Method. The Calendar-Rhythm method is also considered a calendar-based method, though it is not well defined and has many different meanings to different people.\nSystems of fertility awareness may be referred to as fertility awareness\u2013based methods; the term Fertility Awareness Method (FAM) refers specifically to the system taught by Toni Weschler. The term natural family planning is sometimes used to refer to any use of fertility awareness methods, the lactational amenorrhea method and periodic abstinence during fertile times. A method of fertility awareness may be used by natural family planning users to identify these fertile times.\nWomen who are breastfeeding a child and wish to avoid pregnancy may be able to practice the lactational amenorrhea method. The lactational amenorrhea method is distinct from fertility awareness, but because it also does not involve contraceptives, it is often presented alongside fertility awareness as a method of \"natural\" birth control.\nWithin the Catholic Church and some Protestant denominations, the term natural family planning is often used to refer to Fertility Awareness pointing out it is the only method of family planning approved by the Church.\nHistory.\nDevelopment of calendar-based methods.\nIt is not known exactly when it was first discovered that women have predictable periods of fertility and infertility. It is already clearly stated in the Talmud tractate Niddah, that a woman only becomes pregnant in specific periods in the month, which seemingly refers to ovulation. St. Augustine wrote about periodic abstinence to avoid pregnancy in the year 388 (the Manichaeans attempted to use this method to remain childfree, and Augustine condemned their use of periodic abstinence). One book states that periodic abstinence was recommended \"by a few secular thinkers since the mid-nineteenth century,\" but the dominant force in the twentieth century popularization of fertility awareness-based methods was the Roman Catholic Church.\nIn 1905 Theodoor Hendrik van de Velde, a Dutch gynecologist showed that women only ovulate once per menstrual cycle. In the 1920s, Kyusaku Ogino, a Japanese gynecologist, and Hermann Knaus, from Austria, independently discovered that ovulation occurs about fourteen days before the next menstrual period. Ogino used his discovery to develop a formula for use in aiding infertile women to time intercourse to achieve pregnancy. In 1930, John Smulders, a Roman Catholic physician from the Netherlands, used this discovery to create a method for \"avoiding\" pregnancy. Smulders published his work with the Dutch Roman Catholic medical association, and this was the first formalized system for periodic abstinence: the rhythm method.\nIntroduction of temperature and cervical mucus signs.\nIn the 1930s, Reverend Wilhelm Hillebrand, a Catholic priest in Germany, developed a system for avoiding pregnancy based on basal body temperature. This temperature method was found to be more effective at helping women avoid pregnancy than were calendar-based methods. Over the next few decades, both systems became widely used among Catholic women. Two speeches delivered by Pope Pius XII in 1951 gave the highest form of recognition to the Catholic Church's approval\u2014for couples who needed to avoid pregnancy\u2014of these systems. In the early 1950s, John Billings discovered the relationship between cervical mucus and fertility while working for the Melbourne Catholic Family Welfare Bureau. Billings and several other physicians, including his wife, Dr. Evelyn Billings, studied this sign for a number of years, and by the late 1960s had performed clinical trials and begun to set up teaching centers around the world.\nFirst symptoms-based teaching organizations.\nWhile Dr. Billings initially taught both the temperature and mucus signs, they encountered problems in teaching the temperature sign to largely illiterate populations in developing countries. In the 1970s they modified the method to rely on only mucus. The international organization founded by Dr. Billings is now known as the World Organization Ovulation Method Billings.\nThe first organization to teach a symptothermal method was founded in 1971. John and Sheila Kippley, lay Catholics, joined with Dr. Konald Prem in teaching an observational method that relied on all three signs: temperature, mucus, and cervical position. Their organization is now called Couple to Couple League International. The next decade saw the founding of other now-large Catholic organizations, Family of the Americas (1977), teaching the Billings method, and the Pope Paul VI Institute (1985), teaching a new mucus-only system called the Creighton Model.\nUp until the 1980s, information about fertility awareness was only available from Catholic sources. The first secular teaching organization was the Fertility Awareness Center in New York, founded in 1981. Toni Weschler started teaching in 1982 and published the bestselling book \"Taking Charge of Your Fertility\" in 1995. Justisse was founded in 1987 in Edmonton, Canada. These secular organizations all teach symptothermal methods. Although the Catholic organizations are significantly larger than the secular fertility awareness movement, independent secular teachers have become increasingly common since the 1990s.\nOngoing development.\nDevelopment of fertility awareness methods is ongoing. In the late 1990s, the Institute for Reproductive Health at Georgetown University introduced two new methods. The TwoDay Method, a mucus-only system, and CycleBeads and iCycleBeads (the digital version), based on the Standard Days Method, are designed to be both effective and simple to teach, learn, and use. In 2019, Urrutia et al. released a study as well as interactive graph over-viewing all studied fertility awareness based methods. Femtech companies such as Dot and Natural Cycles have also produced new studies and apps to help women avoid pregnancy. Natural Cycles is the first app of its kind to receive FDA approval.\nFertility signs.\nMost menstrual cycles have several days at the beginning that are infertile (pre-ovulatory infertility), a period of fertility, and then several days just before the next menstruation that are infertile (post-ovulatory infertility). The first day of red bleeding is considered day one of the menstrual cycle. Different systems of fertility awareness calculate the fertile period in slightly different ways, using primary fertility signs, cycle history, or both.\nPrimary fertility signs.\nThe three primary signs of fertility are \"basal body temperature\" (BBT), \"cervical mucus\", and \"cervical position\". A woman practicing symptoms-based fertility awareness may choose to observe one sign, two signs, or all three. Many women experience secondary fertility signs that correlate with certain phases of the menstrual cycle, such as abdominal pain and heaviness, back pain, breast tenderness, and mittelschmerz (ovulation pains).\nBasal body temperature.\nThis usually refers to a temperature reading collected when a person first wakes up in the morning (or after their longest sleep period of the day). The true BBT can only be obtained by continuous temperature monitoring through internally worn temperature sensors. In women, ovulation will trigger a rise in BBT between 0.2\u00ba and 0.5\u00a0\u00b0C. (0.5 and 1.\u00b0F) that lasts approximately until the next menstruation. This temperature shift may be used to determine the onset of post-ovulatory infertility. (See ref. 30)\nCervical mucus.\nThe appearance of cervical mucus and vulvar sensation are generally described together as two ways of observing the same sign. Cervical mucus is produced by the cervix, which connects the uterus to the vaginal canal. Fertile cervical mucus promotes sperm life by decreasing the acidity of the vagina, and also it helps guide sperm through the cervix and into the uterus. The production of fertile cervical mucus is caused by estrogen, the same hormone that prepares a woman's body for ovulation. By observing her cervical mucus and paying attention to the sensation as it passes the vulva, a woman can detect when her body is gearing up for ovulation, and also when ovulation has passed. When ovulation occurs, estrogen production drops slightly and progesterone starts to rise. The rise in progesterone causes a distinct change in the quantity and quality of mucus observed at the vulva.\nCervical position.\nThe cervix changes position in response to the same hormones that cause cervical mucus to be produced and to dry up. When a woman is in an infertile phase of her cycle, the cervix will be low in the vaginal canal; it will feel firm to the touch (like the tip of a person's nose); and the os\u2014the opening in the cervix\u2014will be relatively small, or \"closed\". As a woman becomes more fertile, the cervix will rise higher in the vaginal canal, it will become softer to the touch (more like a person's lips), and the os will become more open. After ovulation has occurred, the cervix will revert to its infertile position.\nCycle history.\nCalendar-based systems determine both pre-ovulatory and post-ovulatory infertility based on cycle history. When used to avoid pregnancy, these systems have higher perfect-use failure rates than symptoms-based systems but are still comparable with barrier methods, such as diaphragms and cervical caps.\nMucus- and temperature-based methods used to determine post-ovulatory infertility, when used to avoid conception, result in very low perfect-use pregnancy rates. However, mucus and temperature systems have certain limitations in determining pre-ovulatory infertility. A temperature record alone provides no guide to fertility or infertility before ovulation occurs. Determination of pre-ovulatory infertility may be done by observing the absence of fertile cervical mucus; however, this results in a higher failure rate than that seen in the period of post-ovulatory infertility. Relying only on mucus observation also means that unprotected sexual intercourse is not allowed during menstruation, since any mucus would be obscured.\nThe use of certain calendar rules to determine the length of the pre-ovulatory infertile phase allows unprotected intercourse during the first few days of the menstrual cycle while maintaining a very low risk of pregnancy. With mucus-only methods, there is a possibility of incorrectly identifying mid-cycle or anovulatory bleeding as menstruation. Keeping a basal body temperature chart enables accurate identification of menstruation, when pre-ovulatory calendar rules may be reliably applied. In temperature-only systems, a calendar rule may be relied on alone to determine pre-ovulatory infertility. In symptothermal systems, the calendar rule is cross-checked by mucus records: observation of fertile cervical mucus overrides any calendar-determined infertility.\nCalendar rules may set a standard number of days, specifying that (depending on a woman's past cycle lengths) the first three to six days of each menstrual cycle are considered infertile. Or, a calendar rule may require calculation, for example holding that the length of the pre-ovulatory infertile phase is equal to the length of a woman's shortest cycle minus 21 days. Rather than being tied to cycle length, a calendar rule may be determined from the cycle day on which a woman observes a thermal shift. One system has the length of the pre-ovulatory infertile phase equal to a woman's earliest historical day of temperature rise minus seven days.\nOther techniques.\nOvulation predictor kits can detect imminent ovulation from the concentration of luteinizing hormone (LH) in a woman's urine. A positive ovulation predictor kit result is usually followed by ovulation within 12\u201336 hours.\nSaliva microscopes, when correctly used, can detect ferning structures in the saliva that precede ovulation. Ferning is usually detected beginning three days before ovulation, and continuing until ovulation has occurred. During this window, ferning structures occur in cervical mucus as well as saliva.\nComputerized fertility monitors, such as Lady-Comp, are available under various brand names. These monitors may use BBT-only systems, they may analyze urine test strips, they may use symptothermal observations, they may monitor the electrical resistance of saliva and vaginal fluids, or a combination of any of these factors.\nA symptohormonal method of fertility awareness method developed at Marquette University uses the ClearBlue Easy fertility monitor to determine the fertile window. The monitor measures estrogen and LH to determine the peak day. This method is also applicable during postpartum, breastfeeding, and perimenopause, and requires less abstinence than other fertility awareness method methods. Some couples prefer this method because the monitor reading is objective and is not affected by sleep quality as basal body temperature can be.\nBenefits and drawbacks.\nFertility awareness has a number of unique characteristics:\nAs birth control.\nBy restricting unprotected sexual intercourse to the infertile portion of the menstrual cycle, a woman and her partner can prevent pregnancy. During the fertile portion of the menstrual cycle, the couple may use barrier contraception or abstain from sexual intercourse.\nEffectiveness.\nThe effectiveness of fertility awareness, as of most forms of contraception, can be assessed two ways. \"Perfect use\" or \"method\" effectiveness rates only include people who follow all observational rules, correctly identify the fertile phase, and refrain from unprotected intercourse on days identified as fertile. \"Actual use\" or \"typical use\" effectiveness rates include all women relying on fertility awareness to avoid pregnancy, including those who fail to meet the \"perfect use\" criteria. Rates are generally presented for the first year of use. Most commonly, the Pearl Index is used to calculate effectiveness rates, but some studies use decrement tables.\nThe failure rate of fertility awareness varies widely depending on the system used to identify fertile days, the instructional method, and the population being studied. Some studies have found actual failure rates of 25% per year or higher. At least one study has found a failure rate of less than 1% per year with continuous intensive coaching and monthly review, and several studies have found actual failure rates of 2%\u20133% per year.\nWhen used correctly and consistently (i.e., with perfect use) with ongoing coaching, under study conditions some studies have found some forms of FA to be 99% effective.\nFrom \"Contraceptive Technology\":\nReasons for lower typical-use effectiveness.\nSeveral factors account for typical-use effectiveness being lower than perfect-use effectiveness:\nThe most common reason for the lower actual effectiveness is not mistakes on the part of instructors or users, but conscious user non-compliance\u2014that is, the couple knowing that the woman is likely to be fertile at the time but engaging in sexual intercourse nonetheless. This is similar to failures of barrier methods, which are primarily caused by non-use of the method.\nTo achieve pregnancy.\nIntercourse timing.\nTiming intercourse with a person's estimated 'fertile window' is a practice sometimes called 'timed intercourse'. The effectiveness of timed intercourse is not entirely clear, however, timed intercourse using urine tests that predict ovulation may help improve the rate of pregnancy and live births for some couples trying to conceive such as those who have been trying for less than 12-months and who are under 40 years old. It is not clear from medical evidence if timed intercourse improves the rate of ultra-sound confirmed pregnancies and it is also not clear if timed intercourse has an effect on a person's level of stress or their quality of life. Pregnancy rates for sexual intercourse are also affected by several other factors. Regarding frequency, there are recommendations of sexual intercourse every 1 or 2 days, or every 2 or 3 days. Studies have shown no significant difference between different sex positions and pregnancy rate, as long as it results in ejaculation into the vagina. Social science research has found that timing intercourse can become a gendered 'chore' in heterosexual married couples trying to conceive, with women tracking their ovulation cycles and dictating to their husbands when they should have sexual intercourse.\nProblem diagnosis.\nRegular menstrual cycles are sometimes taken as evidence that a woman is ovulating normally, and irregular cycles as evidence she is not. However, many women with irregular cycles do ovulate normally, and some with regular cycles are actually anovulatory or have a luteal phase defect. Records of basal body temperatures, especially, but also of cervical mucus and position, can be used to accurately determine if a woman is ovulating, and if the length of the post-ovulatory (luteal) phase of her menstrual cycle is sufficient to sustain a pregnancy.\nFertile cervical mucus is important in creating an environment that allows sperm to pass through the cervix and into the fallopian tubes where they wait for ovulation. Fertility charts can help diagnose hostile cervical mucus, a common cause of infertility. If this condition is diagnosed, some sources suggest taking guaifenesin in the few days before ovulation to thin out the mucus.\nPregnancy testing and gestational age.\nPregnancy tests are not accurate until 1\u20132 weeks after ovulation. Knowing an estimated date of ovulation can prevent a woman from getting false negative results due to testing too early. Also, 18 consecutive days of elevated temperatures means a woman is almost certainly pregnant. Estimated ovulation dates from fertility charts are a more accurate method of estimating gestational age than the traditional pregnancy wheel or last menstrual period (LMP) method of tracking menstrual periods. Because of high rates of very early miscarriage (25% of pregnancies are lost within the first six weeks since the woman's last menstrual period), the methods used to detect pregnancy may lead to bias in conception rates. Less-sensitive methods will detect lower conception rates, because they miss the conceptions that resulted in early pregnancy loss.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22087", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=22087", "title": "Nicaraguan Canal and Development Project", "text": "Proposed shipping route across Nicaragua\nThe Nicaraguan Canal and Development Project, informally the Nicaragua Canal (, also referred to as the Nicaragua Grand Canal, or the Grand Interoceanic Canal) was a proposed shipping route through Nicaragua to connect the Caribbean Sea (and therefore the Atlantic Ocean) with the Pacific Ocean. Scientists were concerned about the project's environmental impact, as Lake Nicaragua is Central America's key freshwater reservoir while the project's viability was questioned by shipping experts and engineers.\nConstruction of a canal using the San Juan River as an access route to Lake Nicaragua was first proposed in the early colonial era. After the United States purchased the French interests in the Panama Canal in the early 20th century, it decided not to build in Nicaragua, but it secured rights and conducted studies for such a canal as a supplement.\nIn June\u00a02013, Nicaragua's National Assembly approved a bill to grant a 50-year concession to finance and manage the project to the HK Nicaragua Canal Development Investment Group (HKND) headed by Wang Jing, a Chinese businessman. The concession could have been extended for another 50 years once the waterway was operational.\nIn 2015, media reports suggested the project would be delayed and possibly cancelled because Wang's personal wealth declined greatly as a result of the 2015\u201316 Chinese stock market crash. \"Major works\" such as dredging were to take place after the finishing of a Pacific Ocean wharf, whose construction was planned to start in late 2016. The Nicaraguan government failed to present reliable information about whether or not the project could be financed, thus casting doubt over whether it would be completed. The HKND Group stated that financing would come from debt and equity sales and a potential initial public offering (IPO).\nBy May\u00a02017, no concrete action had been taken toward constructing the canal and further doubts were expressed about its financing. In February\u00a02018, analysts widely viewed the project as defunct, though the head of the project insisted work was on-going and HKND, which closed its offices in April\u00a02018, retained the legal rights to the concession for the canal and side projects.\nIn May 2024, Nicaragua's congress canceled the concession to HKND.\nHistory.\nUntil the beginning of the 20th century, before the opening of the Panama Canal, Nicaragua used to be the main overland trade route and hub of transshipment of goods between ocean-going vessels on the Atlantic side and those on the Pacific. In the meantime, the idea of constructing a man-made waterway through Central America has been thought about throughout history. The colonial administration of New Spain had conducted preliminary surveys. The routes suggested usually ran across Nicaragua, Panama, or the Isthmus of Tehuantepec in Mexico.\nThe history of attempts to build a canal across Nicaragua connecting the Caribbean Sea and thus the Atlantic Ocean and the Pacific Ocean goes back at least to 1825 when the Federal Republic of Central America hired surveyors to study a route via Lake Nicaragua, above sea level. Many other proposals have followed. Despite the operation of the Panama Canal, which opened in 1914, interest in a Nicaragua canal has continued. With emergence of globalization, an increase in commerce and the cost of fuel, and the limitations of the Panama Canal, the concept of a second canal across the American land bridge became more attractive, and in 2006 the president of Nicaragua, Enrique Bola\u00f1os, announced an intention to proceed with such a project. Even with the Panama Canal expansion project, which began commercial operation to allow modern New Panamax vessels on 26 June 2016, some ships would be too big for the Panama Canal.\nOn 26\u00a0September 2012, the Nicaraguan Government and the newly formed Hong Kong Nicaragua Canal Development Group (HKND) signed a memorandum of understanding that committed HKND to financing and building the \"Nicaraguan Canal and Development Project\". HKND Group is a private enterprise.\nThe Nicaraguan government subsequently approved the \"Master Concession Agreement\" with HKND on 13\u00a0June 2013 thereby granting \"the sole rights to the HKND Group to plan, design, construct and thereafter to operate and manage the Nicaragua Grand Canal and other related projects, including ports, a free trade zone, an international airport and other infrastructure development projects\". The agreement would have lasted for 50\u00a0years and was renewable for another 50\u00a0years. HKND would have paid the government of Nicaragua US$10M annually for 10\u00a0years, and thereafter a portion of the revenue starting at 1% and increasing later.\nStratfor indicated that after 10\u00a0years, ownership shares would periodically be handed over to Nicaragua, so that after 50\u00a0years Nicaragua would be the majority shareholder.\nThe HKND Group performed a preliminary study phase of development to assess the technological and economic feasibility of constructing a canal in Nicaragua, as well as the potential environmental, social, and regional implications of various routes. The canal and other associated projects would be financed by investors throughout the world and would generate jobs for Nicaragua and other Central American countries.\nInitial findings of the commercial analysis conducted by HKND Group indicate that the combined effect of growth in east\u2013west trade and in ship sizes could provide a compelling argument for the construction of a second canal, substantially larger than the expanded Panama Canal, across Central America. The projection at the time was that in the 2020s, growth in global maritime trade is expected to cause congestion and delays in transit through the Panama Canal without a complementary route through the isthmus, and by 2030, the volume of trade that a Nicaragua Canal could serve would have grown by 240%.\nOn 10 June 2013, The Associated Press reported that the National Assembly's Infrastructure Committee voted nearly unanimously in favor of the project, with four members abstaining. On 13 June, Nicaragua's legislature passed the legislation granting the concession. On 15\u00a0June, Nicaraguan President Daniel Ortega and the billionaire chairman of HKND Group, Wang Jing, signed the concession agreement giving HKND Group the rights to construct and manage the canal and associated projects for 50\u00a0years. An HKND Group press release read, \"HKND Group successfully obtains exclusive right to develop and manage Nicaragua Grand Canal for 100\u00a0years.\" Under the exclusive contract, Wang could skip building the canal (and making any payments to Nicaragua) and instead simply operate lucrative tax-free side projects.\nWang announced at a press briefing in June\u00a02013 that he had successfully attracted global investors to the $40\u00a0billion project. In January\u00a02014, Wang and Ortega issued a statement that the project's construction would begin in December\u00a02014 and end in 2019.\nOn 7\u00a0July 2014, a route for the Nicaragua Canal was approved. The proposed route started from the mouth of the Brito River on the Pacific side, passed through Lake Nicaragua, and ended in the Punta Gorda River on the Caribbean. The proposed canal would be between wide and deep. The \"Toronto Star\" noted that Chinese engineer Dong Yung Song said the canal's design called for the creation of a artificial lake. The water to fill the canal's giant locks would come from the artificial lake, not from Lake Nicaragua.\nOrtega, whose government approved the agreement within one week in June\u00a02013, reportedly perceived the canal as the second phase of the Nicaraguan Revolution, predicting that it would pull Nicaragua out of poverty and lead to the creation of 250,000\u00a0jobs; HKND said the project would create 50,000\u00a0jobs, about half from abroad, mainly China.\n\"The Moscow Times\" reported in 2014 that Russia was willing to help build the Nicaragua Canal, viewing the project in part as an opportunity to pursue strategic interests in the region. Construction was to begin on 29\u00a0December 2014, and officially started a week earlier. However, owing to Nicaragua's volatile climate and seismic activity, feasibility concerns emerged over the project's future. In November\u00a02015, HKND announced that they would postpone the construction of locks and excavations to late 2016 to fine-tune the design.\nThe Nicaraguan Canal and Development Project saw business rivalry greatly intensify in late 2014. China Harbor Engineering Company, an experienced construction company, offered to design, construct, and finance a fourth set of locks in Panama, where it opened a regional headquarters. If built to the width of the proposed Nicaragua Canal, it would cut across a far shorter distance, and still cost only $10\u00a0billion, according to the firm. Panama is in a better financial situation than Nicaragua to afford taking on this project in that it already has a stream of income from its existing canals.\nAlternative motives have been explored and other projects have taken priority against the water transportation venture. Bloomberg reported in 2015 that \"conspiracy theories abound\" including the project was a land grab by Ortega, an attempt by Ortega to \"whip up\" support in elections, and part of a Chinese plan to gain influence in the region.\nBy November\u00a02016, the president of the canal commission, Manual Coronel Kautz said \"According to our schedule, we should initiate major works by the end of the year.\" However, Carlos Fernando Chamorro, editor of the Confidencial newspaper, said \"If the People's Republic of China does not step forward, it won't happen. Wang Jing does not have the reputation to push this through. If it is just him, then the chances of this happening are zero. If the PRC steps in, then it is a big possibility.\"\nFollowing financial difficulties, HKND finally closed its headquarters offices in China in April\u00a02018, leaving no forwarding address or telephone numbers to be reached.\nOpposition.\nProtests against the canal's construction occurred shortly after the official ceremony marking its beginning. Farmers feared it could cause their eviction and land expropriation.\nThe vast land expropriations () under land expropriation Canal Law\u00a0840 enacted in 2013 include a concession for carrying out seven sub-projects, among them ports, oil pipelines, free-trade zones, and developing tourist areas that could be realized in any part of the national territory. In particular, this law denies any right to appeal against the expropriation decision and provides a derisory level of compensation. It also allows the investor (HKND) to buy and sell its rights over the various sub-projects \"in parts\", which is a highly profitable enterprise. This has been called a \"land grab\" and it has prompted protests, and some violent confrontations against security forces. Activists noted that the canal contract established that it must be dissolved in 72\u00a0months, if the investor has not obtained the money to start the project; that deadline was 14\u00a0June 2019, so they assert that the Law\u00a0840 must be repealed.\nOpposition leader Eliseo Nu\u00f1ez has called the deal \"part of one of the biggest international scams in the world\". Legal challenges that the deal violates constitutional rights were rejected by the Supreme Court of Nicaragua and a retrospective rewriting of the Constitution of Nicaragua placed HKND beyond legal challenge. HKND has been granted the right to expropriate land within on each side of the canal and pay only cadastral value, not market value, for property. Wang, however, promised to pay fair market value. The estimates of the number of people who would be displaced range from 29,000 to more than 100,000. There are indications of local opposition to intended expropriations. Thus, according to an activist leader, an unrest in Rivas in December\u00a02014, in opposition to the canal, left two protesters dead, although no evidence was ever produced to justify his claim. The CIDH, Nicaragua's Human Rights Commission, has strongly criticized the government for not looking into the project's effect on citizens, amid claims that citizens were not involved in decision-making. The British firm ERM, who carried out the Environmental Impact Assessment, claims it held consultations with around 6,000\u00a0people in the communities along its planned route, and estimated that the property of about 30,000\u00a0people would be affected. National opinion polls show that support for the project is about 70%.\nReported end to the canal project.\nInvestor Wang had financial setbacks unrelated to the Nicaragua project, losing 80% of his net worth during the 2015\u201316 Chinese stock market turbulence. In March\u00a02017, the \"Havana Times\" reported that the public relations agency handling Wang's interests in Nicaragua had been let go, in absence of any developments on the project to report, and Wang had not been in the country in more than two years. In May\u00a02017, the \"PanAm Post\" indicated that \"no concrete action has been taken to begin the project\" and suggested that the project was either \"paralyzed, or nonexistent.\" In September\u00a02017 Agence France-Presse reported that the work had been \"pushed back indefinitely,\" although the government renewed the project's environmental permit in April\u00a02017.\nIn February\u00a02018, Manuel Coronel Kautz, head of Interoceanic Grand Canal Authority of Nicaragua, told Agence France-Presse work on the canal was still ongoing, but by that point analysts and activists widely viewed the canal project as defunct, with China having shifted its investment focus to Panama, the main competitor to a Nicaraguan canal. Following financial difficulties, HKND finally closed its offices in April\u00a02018, leaving no forwarding address or telephone numbers to be reached.\nAbsent a 60% vote to revoke the legislation, HKND maintains the legal concessions established by the 2013 law, including for other infrastructures projects in Nicaragua, including ports, roads, railway and an airport.\nIn November 2024 the Nicaraguan Canal idea has been revived.\nDescription.\nThe construction company provided a project description for review on open source, dated December 2014. The canal as planned would have been and would have three sections. The West Canal runs from Brito on the Pacific Ocean up the Rio Brito valley, crosses the continental divide, and after passing through the Rio Las Lajas valley enters Lake Nicaragua; its length would be . The Lake Nicaragua section measures and runs from south of San Jorge to south of San Miguelito. The East Canal would be the longest section at and would be built along the Rio Tule valley through the Caribbean highland to the Rio Punta Gorda valley to meet the Caribbean Sea. A channel would have to be dug in the bottom of Lake Nicaragua, as it is not deep enough for large vessels to transit the canal.\nBoth the West Canal and the East Canal would each have one lock with 3 consecutive chambers to raise ships to the level of Lake Nicaragua, which has an average water elevation of , with a range between . The western Brito Lock would be inland from the Pacific, and the eastern Camilo Lock would be inland from the Caribbean Sea. The dimensions of each of the locks' chambers are long, wide, and threshold depth. As locks generally define the limit on the size of ships that can be handled, the Nicaragua Canal would have allowed passage for larger ships than those that pass through the Panama Canal. For comparison the Panama Canal, after its 2016 expansion, is only long, wide, and deep.\nNo water from Lake Nicaragua was planned to be used to flood the locks; water would have come from local rivers and recycling using water-saving basins. The Camilo lock would have been built adjacent to a new dam of the upper Punta Gorda River that creates a reservoir. This Atlanta Reservoir (or Lake Atlanta) would have a surface area of . West of the Atlanta reservoir, the Rio Agua Zarca would have been dammed to create a second reservoir. This reservoir would have had a surface area of and hold . A hydropower facility would be built at the dam and would have generated over 10\u00a0megawatts of power to be used for Camilo Lock operations. Both locks would also be connected to the country's power grid and have back-up generator facilities. It was estimated that each lock would have used about 9\u00a0megawatts of power.\nAt each oceanic canal entrance, breakwaters and port facilities would have been constructed. The Pacific port would be named Brito Port and the Caribbean one Aguila Port. Initially these two ports would have helped during construction and later become international ports. Their design capacity was 1.68\u00a0million TEU/year and 2.5\u00a0million TEU/year, respectively. Existing port facilities at Corinto and Bluefields would have been improved to allow for shipment of material to the entry ports under construction. Fuel storage sites would be placed at the two port sites. Four lighthouses would be constructed at the entrances to the East and West Canals. In addition, the channel entrance on sea would have been be marked on both sides with a large sailing buoy about offshore and 2 light buoys would mark the passage through Lake Nicaragua.\nA free trade zone with commercial facilities as well as tourist hotels and an international airport at Rivas were planned to be built when canal construction was advanced.\nAppropriate road improvements were planned. The Pan-American Highway would have crossed the canal via a bridge. Nicaragua Route 25 (Acoyapa-San Carlos) on the eastern side of Lake Nicaragua would have gotten a ferry service. Both ports would get public road connections. HKND planned to construct a private gravel maintenance road on both sides of the canal.\nThe estimate for the workforce in 2020 was 3,700\u00a0people, and 12,700 in 2050 when traffic had increased.\nTransit time would have been about 30\u00a0hours. It was projected that by 2020 3,576\u00a0ships would have transited the canal annually. The transit rate was expected to increase to 4,138 by 2030, and to 5,097 by 2050. For comparison, the Panama Canal handled 12,855\u00a0transits in 2009.\nConstruction.\nNo significant construction took place. No \"major works\" such as dredging were planned to take place until after a Pacific Ocean wharf was built.\nThe apparent lack of experience of Wang and his HKND in large-scale engineering was cited as a risk.\nOn 22 December 2014, Wang announced construction started in Rivas, Nicaragua. Wang spoke during the starting ceremony of the first works of the Interoceanic Grand Canal in Brito town. Construction of the new waterway would have been by HKND Group\u2014Hong Kong\u2013based HK Nicaragua Canal Development Investment Co Ltd., which is controlled by Wang. According to HKND's announced plans in 2015, the project entailed the canal's development and building, and supporting infrastructure. There would have been four main phases. The preconstruction phase included getting permits, acquiring land and machinery, and finalizing designs and plans. The early construction phase, started in December\u00a02014, lasted through September 2015; it secured access to construction sites, but it did not provide the critical infrastructure nor mobilize the workforce. During the construction phase from September\u00a02015 to March\u00a02020, the canal would have been dug and the locks built along with accompanying infrastructure. The commissioning phase projected from April\u00a02020 to June\u00a02020 included lock testing and lock and tug boat operator training.\nHKND described the project as the largest civil earth-moving operation in history. Most of this would have consisted of dry excavation to form the canal with an estimate of 4,019\u00a0MCM of rock and soil. There would have been 739\u00a0MCM of freshwater dredging (Lake Nicaragua) and 241\u00a0MCM of marine dredging. Marine dredging of the oceanic access canal would be required on the Pacific side for and on the Caribbean Sea side for . Disposal of excavation material would have been done along the canal in designated disposal areas typically within of the canal.\nTwo concrete plants and a steel plant were planned to support the project. While cement would have likely been imported, construction aggregate would have come from local quarries near the two locks.\nHKND estimates that about 50,000\u00a0people would be employed during the five-year construction, about half of them from Nicaragua, 25% from China, and the remainder from various other countries. 1,400\u00a0workers would be in office or administrative positions and the rest in the field. The management offices would be rented or purchased near Rivas. Workers would live in one of nine camps, which besides food and shelter would also provide health care and security. These are \"closed\" camps \u2014 that is, workers cannot leave the camp unless part of an organized activity. The work schedule calls for 12\u00a0hour shifts for 7\u00a0days a week. Domestic workers work two weeks and get one week off, while foreign workers are 6\u00a0weeks on and get 2\u00a0weeks off (management) or 22\u00a0weeks on, 4\u00a0weeks off (blue collar workers).\nOn 2\u00a0September 2015, Pang Wai Kwok (executive VP of HKND Group) was interviewed by Nicaraguan journalist Carlos Solis and said up to 3,000\u00a0people might be employed on the canal project within the year. However, the labor force depends on the contract bid's winner and Kwok said anyone in the world is eligible to work on the canal.\nFinancing.\nProject costs were estimated in the region of $40\u00a0billion to $50\u00a0billion. Beside private money provided by Wang at the start-up, further influx of financial support was expected from investors. An IPO was reported to be in preparation by the end of 2014. XCMG, a state-owned Chinese construction company would have provided machinery and taken 1.5% to 3% of HKND shares in return.\nBy the end of 2014, no major investors had been named. There had been speculation that the Chinese government would provide financial backing for the project, but China, as well as Wang, denied this. Wang lost nearly 85% of his wealth during the 2015 Chinese stock market crash, according to the Bloomberg Billionaires Index. In addition, Wang has had a string of setbacks for projects around the world since 2014. The economic development potential for the canal project is relatively measurable with Panama; however, the World Bank describes the country of Nicaragua as the second poorest in Latin America and the Caribbean. The World Bank has compiled a data list of projects that the impoverished nation has on record and the majority of the efforts are geared towards infrastructure and agricultural needs, but there is no explicit title project that would support the canal line of effort.\nWang admitted that the project has financial, political, and engineering risks. With the high cost of the project that independently has been estimated to be about $100\u00a0billion, it was not fully funded. The project was expected in 2014 to be completed in 2020, but Stratfor, an analyst agency, stated then that was an \"unrealistic goal.\"\nWhile the Nicaraguan National Bank reserves served as collateral on the part of Nicaragua, HKND had no such potential liability.\nImpact.\nEnvironmental.\nSome of the natural habitat of at least 22\u00a0endangered species would be destroyed in the construction. Another major environmental concern is the project's impact on Lake Nicaragua, the largest source of freshwater in Nicaragua. An oil spill would have serious and lasting consequences. Other problems include the possibility of dredging bringing up toxic sediments, the disruption of migration patterns of animal species, and the potential to introduce invasive species to the lake. Environmental studies had not been released by HKND when the project officially started in December\u00a02014. The Nicaraguan Academy of Sciences noted that hundreds of thousands of hectares of pristine forests and wetlands would be destroyed and pointed out that the environmental study performed for the canal was not independent.\nPresident Daniel Ortega stated that he is \"not concerned about harming the lake because it is already contaminated.\" Protesters fear that the canal would bring massive environmental destruction to Lake Nicaragua and the Atlantic Autonomous Regions. 400,000\u00a0hectares of tropical rain forest and wetlands would be destroyed. It would also encroach upon the habitats of animals such as Baird's tapir, the spider monkey, and the jaguar.\nSafety.\nRichard Condit, from the Smithsonian Tropical Research Institute, believes that the project could be used as leverage for forest protection in a country that currently lacks \"institutional capacity\" to meet conservation needs. A Canadian pilot was the first fatality during the canal project. The pilot was flying alone on the western side of Lake Nicaragua during an aerial survey.\nSustainability.\nThe survey site was on the same side as NicarAgua\u2013Dulce, which is the only ecotourism group in Nicaragua that is affiliated with The International Ecotourism Society, and it is located north of the proposed canal site. Falling in line with ecotourism, Nicaragua's Ministry of Environment and Natural Resources has promoted formal workshops at each level of education (primary, secondary, and post-secondary); however, there is no curriculum relevant to the pending canal project. The American-led Foundation for Sustainable Development is another partner that provides training initiatives to Nicaraguans that cannot access formal education. One of FSD's support sites is located at Tola, which is within close proximity of the proposed Brito\u2013Pacific canal opening.\nEconomic.\nAs the original Panama Canal still has capacity for Panamax-sized shipping and Panama has completed its Panama Canal expansion project, adding more capacity and allowing transit for even larger New Panamax size ships, projections for the Nicaragua Canal's traffic may be optimistic. While the proposed Nicaragua Canal would be wide enough to accommodate Triple E class mega container ships, which are too wide for the expanded Panama Canal, few ports are able to accommodate these ships at the present time. Further, a coast-to-coast railway line may be built by China in Honduras and could affect use of the Nicaragua Canal. Also, North American overland shipping through Pacific ports in Mexico and the United States will compete in the traffic between Asia and the U.S. east coast. The collective effect of the above is that competition may undermine the Nicaragua Canal's economic viability if it were ever built. On the other hand, the combined effect of climate change and poor water-management of the 2016 Panama Canal expansion has resulted in severe bottlenecks which are expected to be exacerbated by future drought conditions. With better water management, and the ability to accommodate dramatically larger vessels, the Nicaragua Canal could supplant other freight options over the next 50 years. \nThe canal would affect neighboring economies, like Honduras and El Salvador, as they are part of the commercial treaty known as the Northern Triangle of Central America (Tri\u00e1ngulo Norte de Centroam\u00e9rica). The GDP of each nation would be influenced by expanded export / import operations and trade cooperation through agencies like the promotion authority in El Salvador.\nSocial.\nAccording to the official Environmental Impact Assessment carried out by ERM, the canal would require the relocation of around 30,000\u00a0people. However, according to human rights group Amnesty International it would \"forcibly displace an estimated 120,000\u00a0people, including Rama and Creole communities, from protected indigenous territories on the Caribbean coast.\" The report claims that communities established in proposed canal area have been visited by foreigners, guarded by Nicaraguan authorities, measuring the lands of the inhabitants, and that legislation passed by the Ortega government \"authorizes HKND to expropriate whatever land it wants, while denying displaced families the right to appeal.\" Amnesty International goes on to say that \"...excessive forces and unjust arrests have been performed by Nicaraguan officials\". The Nicaraguan government's 2015 report on the canal counters that, while people will be moved from their current villages, \"The Nicaraguan government and HKND will guarantee that persons and families on the route of the canal's construction will have living conditions \"superior to\" those they currently have.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22090", "revid": "51025853", "url": "https://en.wikipedia.org/wiki?curid=22090", "title": "Nu metal", "text": "Subgenre of alternative metal\nNu metal (sometimes stylized as n\u00fc-metal, with a metal umlaut) is a subgenre of alternative metal that combines elements of heavy metal music with elements of other music genres such as hip hop, funk, industrial, and grunge. Nu metal rarely features guitar solos or other displays of musical technique and emphasizes rhythm with instrumentation that is heavily syncopated. Nu metal guitarists often use seven-string guitars that are down-tuned to produce a heavier sound. Vocal styles are often rhythmic and influenced by hip hop, and include singing, rapping, screaming and sometimes growling. DJs are occasionally featured to provide instrumentation such as sampling, turntable scratching and electronic background music. Nu metal is one of the key genres of the new wave of American heavy metal. \nIn the late 1980s and early 1990s, bands like Pantera, Helmet, and Faith No More were influential in the development of nu-metal with their groove metal and alternative metal styles. Korn is often credited as pioneering the subgenre in the mid-1990s with their self-titled debut album. Nu metal became popular in the late 1990s, with bands and artists such as Korn, Limp Bizkit, and Slipknot all releasing albums that sold millions of copies. \nIts popularity continued through the early 2000s, with bands such as Papa Roach, Staind, and P.O.D. all selling multi-platinum albums. The popularity of nu metal came to a peak in 2001 with Linkin Park's diamond-selling album \"Hybrid Theory\". By the mid-2000s, however, the oversaturation of bands, combined with the underperformance of several high-profile releases, signaled the subgenre's decline. Many nu-metal bands disbanded or changed their sound in favor of other genres.\nThe 2010s brought a nu-metal revival; many bands that combined it with other genres (for example, metalcore and deathcore) emerged, and some nu-metal bands from the 1990s and early 2000s returned to the nu-metal sound. Bands such as Of Mice &amp; Men, Emmure, Issues, My Ticket Home, and Bring Me the Horizon combined nu metal with metalcore or deathcore. Artists like Grimes, Poppy, and Rina Sawayama integrated nu-metal sounds into electronic pop music in the late 2010s and early 2020s, and interest in nu metal rose in the early 2020s.\nCharacteristics and fashion.\nTerminology and origins.\nNu metal is a subgenre of alternative metal. Sometimes stylized as n\u00fc-metal, the genre has also been dubbed aggro-metal or simply aggro. MTV states that the early nu metal group Korn \"arrived in 1993 into the burgeoning alternative metal scene, which would morph into n\u00fc-metal the way college rock became alternative rock.\" \"Stereogum\" similarly said that nu metal was a \"weird outgrowth of the Lollapalooza-era alt-metal scene\". Nu metal merges elements of heavy metal music with elements of other music genres such as hip hop, grunge, funk, and alternative rock according to Blabbermouth.net. Nu metal bands use many elements of heavy metal genres such as rap metal, groove metal, and funk metal. Some nu metal bands, such as Static-X and Dope, made nu metal music with elements of industrial metal. In contrast with other heavy metal subgenres, nu metal tends to use the same structure of verses, choruses, and bridges as those in pop music.\nMusical characteristics.\nInstrumentation.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n Then a funny thing happened: myopic anti-rap sentiment within more conservative heavy metal quarters saw a slew of new bands already busy blurring these genre lines (Faith No More, Infectious Grooves, etc.) repositioned as \u201cfunk metal\u201d; but this did nothing to slow down the increasing cross-pollination, as some bands added record-scratching DJs to their arsenal. Finally, a generation of groove metal bands led by Texas\u2019 Pantera brought a new level (pun intended) of rhythmic elements into heavy metal, and most of the ingredients were finally in place for bands like Korn, Deftones, Slipknot and Limp Bizkit to kickstart and coalesce the Nu-Metal craze.\n Eduardo Rivadavia of \"Loudwire\" (October 27, 2017) https://\nInstrumentation in nu metal is heavily syncopated and is based mostly on guitar riffs, although these riffs are prominent, guitar solos are not integrated heavily within the genre. These riffs often being inspired by groove metal. Mid-song bridges and the general lack of guitar solos contrasts it with other genres of heavy metal. Kory Grow of \"Revolver\" wrote, \"...\u00a0[i]n its efforts to tune down and simplify riffs, nu-metal effectively drove a stake through the heart of the guitar solo\". Another contrast with other heavy metal genres is nu metal's emphasis on rhythm, rather than on complexity or mood. The wah pedal is occasionally featured in nu metal music.\nNu metal bassists and drummers are often influenced by funk and hip hop, respectively, adding to nu metal's rhythmic nature. Blast beats and double bass drumming, which are both common in heavy metal subgenres such as black metal, thrash metal and death metal, are uncommon in nu metal, with drummers such as Slipknot's Joey Jordison and Mudvayne's Matt McDonough being notable exceptions. \nNu metal's similarities with many heavy metal subgenres include its use of common time, distorted guitars, and power chords and note structures primarily revolving around Dorian, Aeolian or Phrygian modes. While loud and heavily distorted electric guitars are a core feature of all metal genres, nu metal guitarists took the sounds of \"violence and destruction\" to new levels with their overdriven guitar tone, which music journalists Kitts and Tolinski compared to the \"...sound [of] a Mack truck being crushed by a collapsing skyscraper.\"\nSome nu metal bands use seven-string guitars that are generally down-tuned, rather than traditional six-string guitars. Likewise, some bass guitarists use five-string and six-string instruments. Bass guitar-playing in nu metal often features an emphasis on funk elements. In nu metal music, DJs are sometimes featured to provide instrumentation such as sampling, turntable scratching and electronic backgrounds. Nu metal tends to have hip hop grooves and rhythms.\nVocals.\nVocal styles used in nu metal music include singing, rapping, screaming and growling. Vocals in nu metal are often rhythmic and influenced by hip hop. While some nu metal bands, such as Limp Bizkit and Linkin Park, have rapping in their music, other nu metal bands, such as Godsmack and Staind, do not.\nNu metal bands occasionally feature hip hop musicians as guests in their songs; Korn's song \"Children of the Korn\" features the rapper Ice Cube, who performed on the band's 1998 Family Values Tour. The hip hop musician Nas was featured on Korn's song \"Play Me\", which is on the band's album \"Take a Look in the Mirror\". Limp Bizkit has recorded with multiple hip hop musicians including Method Man, Lil Wayne, Xzibit, Redman, DMX and Snoop Dogg. Linkin Park collaborated with hip hop musician Jay-Z on their 2004 extended play \"Collision Course\". Kid Rock has recorded with hip hop musicians Eminem and Snoop Dogg. Trevor Baker of \"The Guardian\" wrote, \"Bands such as Linkin Park, Korn and even the much reviled Limp Bizkit\u00a0... did far more to break down the artificial barriers between 'urban music' and rock than any of their more critically acceptable counterparts.\"\nLyrics.\nLyrics in nu metal songs are often angry or nihilistic; many of the genre's lyrics focus on topics such as pain, angst, bullying, emotional issues, abandonment, betrayal, and personal alienation, in a way similar to those of grunge. Many nu metal lyrics that are about these topics tend to be in a very direct tone. However, some nu metal songs have lyrics that are about other topics. P.O.D. has used positive lyrics about promise and hope. The nu metal song \"Bodies\" by Drowning Pool is about moshing. \"The Michigan Daily\" wrote about Limp Bizkit's lyrics, writing that the band \"used the nu-metal sound as a way to spin testosterone fueled fantasies into snarky white-boy rap. Oddly, audiences took frontman Fred Durst more seriously than he wanted, failing to see the intentional silliness in many of his songs\". Limp Bizkit's lyrics have also been described as misogynistic. Dope's lyrics are usually about sex, drugs, parties, women, violence, and relationships. In contrast, according to Josh Chesler of the \"Phoenix New Times\", the lyrics of Deftones, who were once considered a nu metal band, \"tend to have complex allusions and leave the songs open to many different interpretations.\"\nFashion.\nNu metal clothing typically consists of baggy pants, shirts, and shorts, JNCO jeans, Adidas tracksuits, sports jerseys, baseball caps, baggy hoodies, cargo pants, and sweatpants. Nu metal hairstyles and facial hairstyles include dreadlocks, braids, spiky hair, chin beards, bald heads, goatees, frosted tips, and bleached or dyed hair. Common accessories in nu metal fashion include wallet chains, tattoos, and piercings, especially facial piercings. Nu metal fashion has been compared to hip hop fashion.\nSome nu metal bands such as Motograter, Mushroomhead, Mudvayne, and Slipknot wear masks, jumpsuits, costumes, face paint, corpse paint or body paint. A few nu metal bands, such as Coal Chamber, and Kittie are known for having gothic appearances.\nHistory.\n1980s\u20131993: Precursors and origins.\nThrash metal band Anthrax was an influence on nu metal by combining hip hop and metal on their 1987 rap metal EP \"I'm the Man\"; this laid groundwork for nu metal's development. Nu metal bands often borrowed their metal influence from groove metal band Pantera, with the pioneering nu metal band Korn's lead vocalist Jonathan Davis saying of Pantera guitarist Dimebag Darrell, \"if there was no Dimebag Darrell, there would be no Korn\". Alternative metal musician Mike Patton of Faith No More and Mr. Bungle was a major influence on many nu metal vocalists due to his wide range of vocal styles.\n1993\u20131997: Early years.\nJoel McIver acknowledged Korn as the band that created and pioneered the nu metal genre with its demo \"Neidermayer's Mind\", which was released in 1993. McIver also acknowledged Korn as the band that started the new wave of American heavy metal, which is a heavy metal music movement that started in the 1990s. The aggressive riffs of Korn, the rapping of Limp Bizkit, and the melodic ballads of Staind created the sonic template for nu metal. The origins of the term \"nu metal\" are often attributed to the work of producer Ross Robinson, who has been called \"The Godfather of Nu Metal\" between producers. Robinson has produced for nu metal bands such as Korn, Limp Bizkit and Slipknot. Many of the first nu metal bands, such as Korn and Deftones, came from California; however, the genre soon spread across the United States and many bands arose from various states, including Limp Bizkit from Florida, Staind from Massachusetts, and Slipknot from Iowa. In the book \"Brave Nu World\", Tommy Udo wrote about the nu metal band Coal Chamber, \"There's some evidence to suggest that Coal Chamber were the first band to whom the tag 'nu metal' was actually applied, in a live review in \"Spin\" magazine.\"\nIn 1994, Korn released their self-titled debut album, which is widely considered the first nu metal album. Korn had experienced underground popularity at this time; their debut album peaked at number 72 on the \"Billboard\" 200. In 1995, the band Sugar Ray released its debut studio album \"Lemonade and Brownies\", an album described as both funk metal and nu metal. In 1995, Deftones released their debut album \"Adrenaline\". The album peaked at number 23 on the Heatseekers Albums chart on October 5, 1996. Deftones also were temporarily controversial in 1996 when their vocalist Chino Moreno was blamed by TV news reports for a riot that occurred at the 1996 U-Fest festival on October 5, 1996. \"Adrenaline\" was certified gold by the Recording Industry Association of America (RIAA) in the summer of 1999. It was also certified platinum by the RIAA in September 2008.\nSepultura's 1996 album \"Roots\" features nu metal elements that were considered influential to the genre, while \"Roots\" itself was influenced by Korn's self-titled debut album. Nu metal continued to rise in popularity when Korn's 1996 album \"Life Is Peachy\" peaked at number 3 on the \"Billboard\" 200 and sold 106,000 copies in its first week of release. Attention through Ozzy Osbourne's 1996 introduction of Ozzfest was integral to boosting the careers of many nu metal bands, including Limp Bizkit.\n1997\u20132001: Mainstream breakthrough.\nFew artists were playing nu metal until 1997 when bands such as Sevendust, Coal Chamber, Limp Bizkit, and Papa Roach all released their debut albums, in what \"Billboard\" writer William Goodman calls a \"banner year\" for the genre. Limp Bizkit released their debut \"Three Dollar Bill, Y'all\" in July 1997. The album's popularity grew in 1999 as the band's mainstream profile began to increase; in March of that year, it went platinum in the United States, and eventually went double platinum in July 2001. Coal Chamber released its self-titled debut album in 1997, which was a minor hit, being certified gold in the United States in 1999. The album was frequently compared to Korn, and Coal Chamber's appearance on Ozzfest in 1996 gave the band attention. Coal Chamber appeared on Ozzfest during the next two years. Also in 1997, Sugar Ray released its second studio album \"Floored\". The album achieved mainstream success quickly and was certified 2\u00d7 platinum by the RIAA on February 20, 1998. Although \"Floored\" is a nu metal album, the only song from the album that achieved chart success was the single \"Fly\", which is instead a reggae-oriented song. Although Sugar Ray continued to be extremely popular, the band abandoned the nu metal genre and became a pop rock band with its 1999 studio album \"\". Deftones' second album \"Around the Fur\", also released in 1997, peaked at number 29 on the \"Billboard\" 200 on November 15, 1997. The album was certified gold by the Recording Industry Association of America (RIAA) in the summer of 1999, and certified platinum by the RIAA in June 2011.\nIn 1998, nu metal's popularity fully coalesced into mainstream success. \"Billboard\" cited August 18, 1998, as the \"Biggest Day in Nu-Metal History\", which saw the release of Korn's third album \"Follow the Leader\", Kid Rock's major label debut \"Devil Without a Cause\" and Orgy's debut album \"Candyass\". \"Follow the Leader\" peaked at number 1 on the \"Billboard\" 200, was certified 5\u00d7 platinum by the RIAA, and paved the way for the success of other nu metal bands. At this point, many nu metal bands were signed to major record labels, and were using elements of heavy metal, hip hop, industrial, or grunge. Hip hop artists Vanilla Ice and Cypress Hill, along with heavy metal bands Sepultura, Primus, Fear Factory, Machine Head, and Slayer released albums that draw from the nu metal genre. In 1999, Korn's fourth studio album \"Issues\" peaked at number 1 on the \"Billboard\" 200. The album was certified 3\u00d7 platinum by the RIAA in one month. The album sold at least 573,000 copies in its first week of release. During the late 1990s and early 2000s, multiple nu metal bands such as Korn, Limp Bizkit and P.O.D. appeared repeatedly on \"Total Request Live\". As nu metal became popular, it especially appealed to certain groups of young people. Although Limp Bizkit was particularly popular among \"jocks\" and fraternity men due to its hedonistic, hypermasculine lyrics, many other nu metal bands, especially the bands with heavier music, instead appealed particularly to mall goths and outsiders who identified with the genre's typically angsty lyrics.\nThe Woodstock 1999 festival featured multiple nu metal artists and bands such as Korn, Limp Bizkit and Sevendust. During and after Limp Bizkit's performance at the festival, violence occurred and people tore plywood from the walls during the performance of the band's song \"Break Stuff\". Several sexual assaults were reported to have happened during the festival; a rape that was reported during Limp Bizkit's performance, and gang rape was reported to have occurred during Korn's set at the festival. Despite the incidents at the festival, Limp Bizkit's popularity and the sales of their then-recent album \"Significant Other\" were not affected. The album peaked at number 1 on the \"Billboard\" 200, selling 643,874 copies in its first week of release, topping over one million sold in two weeks, and eventually being certified 7\u00d7 platinum in 2001. \"Significant Other\" sold at least 7,237,123 copies in the United States.\nIn 1999, Slipknot emerged with an extremely heavy nu metal sound, releasing their self-titled album, which was certified platinum in 2000 and 2\u00d7 platinum in 2005. In a review of the band's self-titled album, Rick Anderson of AllMusic wrote about Slipknot, \"You thought Limp Bizkit was hard? They're the Osmonds. These guys are something else entirely.\" Anderson noted the death metal influence on the album. Slipknot drummer Joey Jordison, noted by Anderson for his death metal-influenced drumming, said of Slipknot's music: \"The roots are death metal, thrash, speed metal, and I could go on and on about all those bands.\"\nIn 1999, Staind's second album \"Dysfunction\" was released; the track \"Mudshovel\" peaked at number 10 on the Mainstream Rock chart. \"Dysfunction\" was certified platinum by the RIAA in 2000 and 2\u00d7 platinum in 2004. In 2000, Limp Bizkit's third studio album \"Chocolate Starfish and the Hot Dog Flavored Water\" set a record for highest week-one sales of a rock album, selling over 1,000,000 copies in the United States in its first week of release\u2014400,000 of which sold on its first day of release, making it the fastest-selling rock album ever and breaking the world record held for seven years by Pearl Jam's \"Vs.\" \"Chocolate Starfish and the Hot Dog Flavored Water\" by Limp Bizkit was certified 6\u00d7 platinum by the RIAA. That same year, both Papa Roach's second studio album \"Infest\" and Disturbed's debut studio album \"The Sickness\" were released. Both albums became multi-platinum hits. In 2000, P.O.D.'s album \"The Fundamental Elements of Southtown\" went platinum in the United States and was the 143rd best-selling album of 2000. During the late 1990s and early 2000s, many nu metal bands performed at Ozzfest, including Kittie, Disturbed, Mudvayne, Linkin Park, Slipknot, Papa Roach, Otep, Static-X, Methods of Mayhem, Taproot and Drowning Pool. Ozzfest was successful, with Ozzfest 2000, for example, selling out and having 19,000 audience members. During that same year, nu metal bands like Papa Roach and Limp Bizkit joined rappers like Eminem and Xzibit on Eminem's Anger Management Tour, which had sold-out concerts.\nLate in 2000, Linkin Park released their debut album \"Hybrid Theory\", which was the best-selling debut album by any artist of any genre in the 21st century and nu metal's popularity peak. The album was also the best-selling album of 2001. Linkin Park earned a Grammy Award for their second single \"Crawling\". Their fourth single, \"In the End\", was released late in 2001 and peaked at number 2 on the \"Billboard\" Hot 100 in March 2002. In 2001, Linkin Park's album \"Hybrid Theory\" sold 4,800,000 copies in the United States, making it the highest-selling album of the year. Linkin Park's album \"Hybrid Theory\" was certified 12\u00d7 platinum by the RIAA and sold at least 10,222,000 copies in the United States.\nCrazy Town's debut album \"The Gift of Game\" peaked at number 9 on the \"Billboard\" 200, went platinum in February 2001, and sold at least 1,500,000 copies in the United States. Worldwide, the album sold at least 2,500,000 copies. Staind's 2001 album \"Break the Cycle\" debuted at number 1 on the Billboard 200 with at least 716,000 copies sold in its first week of release. \"Break the Cycle\" by Staind was certified 5\u00d7 platinum by the RIAA, with 4,240,000 copies sold in 2001 in the United States. Although the album featured nu metal tracks, a lot of the album showed Staind moving to a softer sound. Noting Staind's change in style to a softer sound, Tommy Udo of \"Brave Nu World\" wrote: \"It's often said that nobody over the age of 24 could possibly like Limp Bizkit or Korn, but Staind are a more mainstream band and their songs are likely to appeal to a much bigger fanbase.\"\nIn August 2001, Slipknot released their album \"Iowa\", which peaked at number 3 on the \"Billboard\" 200 and went platinum in October 2001. Critic John Mulvey called the album the \"absolute triumph of nu metal\". P.O.D.'s 2001 album \"Satellite\" went and peaked at number 6 on the \"Billboard\" 200. P.O.D.'s popularity continued in the year 2002. On June 5, 2001, Drowning Pool released a nu metal album titled \"Sinner\", which features the song \"Bodies\". The album went platinum on August 23, 2001 and its song \"Bodies\" became one of the most frequently played videos on MTV for new bands. \"Bodies\" went to number 6 on the Mainstream Rock chart. In 2001, System of a Down's album \"Toxicity\" peaked at number 1 on the \"Billboard\" 200. The album was certified 6\u00d7 platinum in the United States. System of a Down blended nu metal with occasional influences of Middle Eastern music, Greek music, Armenian music, and jazz music, and the band featured political lyrics.\n2001\u20132004: Continued success and early signs of decline.\nIn 2003, MTV wrote that nu metal's mainstream popularity was declining in 2002, citing that Korn's fifth album \"Untouchables\" and Papa Roach's third album \"Lovehatetragedy\" both sold less than the bands' previous releases. Korn's lead vocalist Jonathan Davis believed music piracy was the reason for the lower amount of sales of \"Untouchables\" compared to \"Follow the Leader\" and \"Issues\" because \"Untouchables\" had been leaked to the Internet more than four months before its official release date. MTV also wrote that nu metal bands were played less frequently on radio stations and MTV began focusing on other musical genres. MTV wrote that Papa Roach's third album \"Lovehatetragedy\" has less hip hop elements than the band's previous album \"Infest\" and also said that Saliva's 2002 album \"Back into Your System\" has less hip hop elements than the band's 2001 album \"Every Six Seconds\". MTV also wrote that Crazy Town's second album \"Darkhorse\" had no hit singles and sold less than the band's previous album \"The Gift of Game\". MTV wrote that although Kid Rock's album \"Cocky\" had characteristics of the musician's 1998 album \"Devil Without a Cause\", \"Cocky\"'s song \"Forever\", which featured the style of Kid Rock's song \"Bawitdaba\", was not as popular as \"Cocky\"'s country song \"Picture\". MTV also wrote, \"Another cause for n\u00fc-metal and rap-rock's slip from the spotlight could be a diluted talent pool caused by so many similar-sounding bands. American Head Charge, Primer 55, Adema, Cold, the Union Underground, Dope, Apartment 26, Hed (Planet Earth) and Skrape\u2014all of whom released albums between 2000 and 2001\u2014left more of a collective impression than individual ones\".\nDespite what MTV wrote, the RIAA certified Korn's album \"Untouchables\" platinum in July 2002, and one of the album's singles, \"Here to Stay\", received a lot of radio play and peaked at number one on MTV's \"Total Request Live\" twice. \"Untouchables\" sold at least 434,000 copies in first week of release and peaked at number 2 on the Billboard 200. However, \"Untouchables\" still did not sell as many copies as Korn's most commercially successful album, \"Follow the Leader\". Linkin Park's remix album \"Reanimation\" was released in July 2002 and sold more than a million copies that year, which MTV described as \"impressive for a remix album\". Additionally, P.O.D.'s popularity continued into 2002 with its 2001 album \"Satellite\".\nIn 2003, Linkin Park's album \"Meteora\" peaked at number 1 on the \"Billboard\" 200 and sold at least 810,000 copies in its first week of being released. \"Meteora\" by Linkin Park was certified multi-platinum in the United States and sold at least 6,100,000 copies in the United States. Limp Bizkit's 2003 album \"Results May Vary\", which features a change in sound with many alternative rock songs alongside nu metal songs, peaked at number 3 on the \"Billboard\" 200, with sales of at least 325,000 copies in its first week of being released. In 2004, Blabbermouth.net reported that, according to Nielsen SoundScan, \"Results May Vary\" sold 1,337,356 copies in the United States. However, the album garnered very poor critical reception and consequently performed much weaker than previous Limp Bizkit albums such as \"Significant Other\" and \"Chocolate Starfish and the Hot Dog Flavored Water\". Korn's 2003 album \"Take a Look in the Mirror\" sold less than previous Korn albums like \"Issues\" and \"Untouchables\". Despite the ongoing decline of the genre, several international bands began to experience success with nu metal, such as Three Days Grace from Canada, and Lostprophets from Wales. Three Days Grace managed to land a hit single in April 2003 with the song \"I Hate Everything About You\", while Lostprophets managed a hit single in December 2003 with the song \"Last Train Home\", becoming the highest-charting single from a UK-based rock band that year. The Lostprophets' 2004 album \"Start Something\" was successful, peaking at number 4 on the UK Album Charts and number 33 on the U.S. \"Billboard\" 200.\n2004\u20132010: Further decline and new directions.\nAlthough nu metal's popularity survived into 2002 and 2003, much of it had dropped significantly by 2004. By this point in time, indie and garage rock revival bands such as the Strokes, The White Stripes, and Jet were achieving mainstream success as nu metal's popularity started to decline, and by the mid-late 2000s, the popularity of emo exceeded that of nu metal. Also during this time, metalcore, a fusion of extreme metal and hardcore punk, became one of the most popular genres in the new wave of American heavy metal, with the success of bands like Killswitch Engage, Shadows Fall, God Forbid, Unearth, Trivium, and Bullet for My Valentine. Groove metal band Lamb of God also became successful in the heavy metal genre. Stephen Hill of \"Louder Sound\" called the rise of metalcore after the decline of nu metal \"the metalcore revolution\".\nBy 2004, several nu metal bands had begun to experiment with other genres to adapt to the changes in trends. Linkin Park's third studio album \"Minutes to Midnight\", released in 2007, was noted for its near-complete departure from the band's nu metal sound. Describing the album's style, singer Chester Bennington stated, \"We've really moved away from anything that sounds like nu-metal.\" Nu metal bands such as Disturbed, Soulfly, Drowning Pool, and Slipknot had begun to utilize heavier elements of groove metal, death metal and thrash metal into their music. Similarly to Limp Bizkit; Staind and Papa Roach had also begun experimenting with Alternative Rock into their sound. Staind's 2003 album \"14 Shades of Grey\" was significantly less heavy than previous albums and shows the band's departure from nu metal and a movement towards a lighter sound. Papa Roach abandoned the nu metal genre entirely with their 2004 album \"Getting Away with Murder\", moving to a hard rock style. System of a Down released two albums in 2005, \"Mezmerize\" and \"Hypnotize\". Both did well commercially and critically, but the band took a more alternative metal approach to the two albums compared to their past three efforts. In 2005, Limp Bizkit released an EP called \"The Unquestionable Truth (Part 1)\" which had little promotion and advertising. The album was not very popular; its sales fell 67% during its second week of release. In 2006, Limp Bizkit went on hiatus. In 2012, vocalist Fred Durst said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Here's the deal: say in 2000, there were 35 million people who connected to this band. Twelve years later, lots of those people have moved on. We were a moment in time and it's over.\"\n2010\u20132020: Underground revival.\nDuring the mid-2010s, there was a discussion within media of a possible nu metal revival because of bands fusing nu metal with other genres. Despite the lack of radio play and popularity, some nu metal bands recaptured some of their former popularity as they released albums in a nu metal style. Many metalcore and deathcore groups gained moderate popularity in the 2010s and used elements from nu metal. This fusion is nu metalcore. Suicide Silence's 2011 album \"The Black Crown\", which features elements of nu metal and deathcore, peaked at number 28 on the \"Billboard\" 200. In 2014, Issues' self-titled debut album peaked at number 9 on the same chart. The album features elements of metalcore, nu metal, pop and R&amp;B. Of Mice &amp; Men's 2014 album \"Restoring Force\", which features elements of nu metal, peaked at number 4 on the \"Billboard\" 200. Bring Me the Horizon, often described as a metalcore band, released their fifth album \"That's the Spirit\", which peaked at number 2 on the \"Billboard\" 200, in 2015. The album draws from multiple genres including nu metal and would experiment further with nu metal on their 2020 album \"\". The band's keyboardist has described them as a nu metal band. Motionless In White in \"Graveyard Shift\" and \"Disguise\" features elements of industrial, gothic, metalcore and nu metal.\nSome media outlets viewed a nu metal revival as beginning in the 2010s with groups like Blood Youth, Cane Hill, Stray From The Path, Sworn In, DangerKids, Islander, and Blind Channel. Within this movement, nu metalcore became increasingly prominent through the popularity of groups like Vein.fm, Loathe and Code Orange. According to \"PopMatters\" writer Ethan Stewart, Code Orange's 2017 album \"Forever\" led to nu metalcore becoming \"one of the most prominent flavors of contemporary metal\".\n2020\u2013present: Mainstream revival and influence on other genres.\nWhile some media outlets believed these 2010s artists marked the start of a nu metal revival, \"Metal Hammer\" writer Dannii Leivers cited the aforementioned groups as simply hinting towards a revival, instead claiming a revival began in 2021, \"a crop of young revivalists... looking to put a brand-new spin on the music of their formative years\", namely Tetrarch. Other notable acts in this wave include Tallah, Orthodox, Vended, and Wargasm.\nElectronic and art pop singer-songwriters incorporated nu metal into their sound in the late 2010s and early 2020s. Poppy has incorporated nu metal on her albums \"Am I a Girl?\" and \"I Disagree\", Grimes on album \"Miss Anthropocene\" and Rina Sawayama on \"Sawayama\". The songs \"We Appreciate Power\" and \"Play Destroy\" were pioneering examples. Poppy has described this fusion as \"nu-Poppy\" or \"Poppymetal\". \"I Disagree\" received critical acclaim for this fusion, with single \"Bloodmoney\" nominated for the 2021 Grammy Award for Best Metal Performance, making her the first female solo artist to be nominated for the award in its history. Dorian Electra incorporated nu metal influences on their album \"My Agenda\", as did Ashnikko on \"Demidevil\", particularly on single \"Cry\". \"The Guardian\" noted that these mostly female artists have revived nu metal, a mostly male genre, and successfully adapted it to showcase a female perspective. Rina Sawayama said \"metal itself lends itself to toxic masculine tropes, but it's also almost taking the piss out of a very masculine expression of emotion\". Smaller bands have also rose to the scene in the early 2020s with the genre, including London-based Wargasm, who have been \"validated by the nu-metal daddies,\" after Korn vocalist Jonathan Davis described them as \"his new favourite band.\"\nIn the early 2020s, several media outlets noted that nu metal has undergone a resurgence in interest among Generation Z listeners. In 2023, Google Searches for the term \"nu metal\" were reported as being at their highest in \"nearly 20 years\". Deftones and Slipknot began gaining popularity among Generation Z in the early 2020s when their music was featured in videos on the app\nTikTok. Also, several nu metal bands returned and released new music after decades like Staind, Adema, Alien Ant Farm and Kittie. Late 2024 saw the surprise revival of Linkin Park after a seven-year hiatus following the death of frontman Chester Bennington in 2017. With new singer Emily Armstrong of the rock band Dead Sara and new drummer Colin Brittain, the band released their eighth studio album \"From Zero\" on November 15. Several songs on the album, such as lead single \"The Emptiness Machine\", \"Heavy Is the Crown\", and \"Two Faced\" call back to their earlier nu metal sound prominently featured on \"Hybrid Theory\" and \"Meteora\".\nLegacy.\nReception.\nDespite its popularity in the late 1990s and early 2000s, nu metal has often been criticized by many fans of heavy metal music, often being labelled with derogatory terms such as \"mallcore\" and \"whinecore\". Gregory Heaney of AllMusic called nu metal \"one of metal's more unfortunate pushes into the mainstream\". Lucy Jones of \"NME\" called nu metal \"the worst genre of all time\". In \"Metal: The Definitive Guide : Heavy, NWOBH, Progressive, Thrash, Death\u00a0... \", Garry Sharpe-Young described nu metal as \"a dumbed-down and\u2014thankfully short[-]lived exercise\". When Machine Head moved to the nu metal genre with their album \"The Burning Red\" and their vocalist Robb Flynn spiked his hair in the fashion of many nu metal musicians, the band were accused of \"selling out\" and many fans criticized their change of appearance and musical style. Machine Head's drummer Dave McClain said, \"Pissing people off isn't a bad thing, you know? For people to be narrow-minded is bad\u00a0... [i]t doesn't bother us at all, we know we're going to piss people off with this record, but some people hopefully will actually sit down and listen to the whole record\". Robb Flynn, Machine Head's vocalist, said &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;There's a minute and a half of rapping on that album. The other 53 minutes of the record are like a giant scar being ripped open while I projectile-vomit through it. If all that people got out of [\"The Burning Red\"] was rap-metal, then they didn't fucking listen to it.\nJonathan Davis, the vocalist of Korn, spoke about the criticism of nu metal from heavy metal fans, saying: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;There's a lot of closed-minded metal purists that would hate something because it's not true to metal or whatever, but Korn has never been a metal band, dude. We're not a metal band. We've always been looked at as what they called the nu-metal thing. But we've always been the black sheep and we never fitted into that kind of thing so\u00a0... We're always ever evolving, and we always piss fans off and we're gaining other fans and it is how it is. Lamb of God's vocalist Randy Blythe criticized the nu metal genre and spoke about its loss of popularity in 2004, saying: \"Nu-metal sucks, so that's why that's dying off. And I think... people are ready for angrier music. I think people are ready for something that's real, not, you know, 'I did it all for the nookie.'\" Megadeth frontman Dave Mustaine said he would \"rather have his eyelids pulled out\" than listen to nu metal. Guitarist Gary Holt of Exodus and Slayer said that he \"was so glad about\" the decline of nu metal.\nSome musicians who influenced nu metal have tried to distance themselves from the subgenre and its bands. Mike Patton, the vocalist of Faith No More and Mr. Bungle, tried to distance himself from the subgenre and criticized it, even though he is featured on the song \"Lookaway\" on Sepultura's album \"Roots\", which is often considered a nu metal album. Patton said of his music's influence on nu metal, \"I feel no responsibility for that, it's their mothers' fault, not mine\". Helmet frontman Page Hamilton said, \"It's frustrating that people write [us] off because we're affiliated with or credited with or discredited with creating nu-metal and rap metal\u00a0... which we sound nothing like\".\nTrent Reznor of Nine Inch Nails has said he knows some Korn members and that he thinks they are \"cool guys\", but he remains critical of nu metal, saying:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;When I'm asked what do I think of a lot of the nu-metal bands that are out there, my response is that it seems really insincere to me. 'I've had a really shitty childhood and I'm really upset and I'm really ugly and I've put a lot of make-up on and I'm harder and faster and my voice sounds more like the cookie monster's than yours does'. To me it all comes across as being comical, as being a parody of itself.\nIn response to reports that Fred Durst, lead singer of Limp Bizkit, is a big fan of Tool, the latter's vocalist Maynard James Keenan said, \"If the lunch-lady in high school hits on you, you appreciate the compliment, but you're not really gonna start dating the lunch-lady, are ya?\" While Durst has cited Rage Against the Machine as a major influence, Rage Against the Machine's bassist Tim Commerford is open about his hatred of Limp Bizkit, describing them as \"one of the dumbest bands in the history of music\". At the 2000 MTV Video Music Awards, Limp Bizkit won the Best Rock Video category for their song \"Break Stuff\", beating Rage Against the Machine's \"Sleep Now in the Fire\". When Limp Bizkit accepted their award, Commerford went on stage and climbed up a backdrop, rocking back and forth. After the incident, Commerford was arrested and spent a night in jail. Commerford said in 2015, \"I do apologize for Limp Bizkit. I really do. I feel really bad that we inspired such bullshit\u00a0... They're gone, though. That's the beautiful thing.\"\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"After Korn's 'Follow the Leader' blew the whole movement into orbit in 1998, nu-metal produced some ridiculous bands, to be sure. And to be fair, plenty of them dwelled in the realms of corny rap-rock and dull alternative radio rock with the occasional heavy riff or tendency to scream, making their designation as 'metal' quite dubious indeed\u00a0... [b]ut the movement also produced plenty of heavier bands with primarily metal influences\".\n\"Metal Underground\" on nu metal's association with heavy metal.\nJody MacGregor of FasterLouder called nu metal \"music's most hated genre\"; conversely, he also wrote that nu metal is \"not as bad as people think\", praising several examples of the genre. Although multiple nu metal musicians rejected the nu metal label, Limp Bizkit's vocalist Fred Durst defended it, saying \"Nu metal let people open up and it meant something to people. It really did.\" Slipknot's vocalist Corey Taylor also defended nu metal, saying \"I'd like to think that that whole nu-metal wave was so important to that next wave of American heavy metal, to be honest.\" Coal Chamber's vocalist Dez Fafara also defended nu metal. He said he is proud to be associated with the subgenre and that nu metal bands \"broke new musical ground\" saying, \"I think 'hair metal' was cheesy. [But] I think 'nu metal' was different. I think what's beautiful about 'nu metal' is it's different. And you've got so many different influences.\" The Smashing Pumpkins vocalist Billy Corgan praised nu metal, saying \"I think it's fantastic. I think the more people are cross-pollinating between different musical styles\u2026 it not only has musical implications but it has cultural ones as well.\" Sevendust vocalist Lajon Witherspoon, when asked about the 2020s resurgence of the genre, also spoke highly: \"It's funny. I don't mind being in that category because I feel it's awesome that music is resurging and we're not letting a movement get away from us and get so far away that we don't even like it or listen to it anymore.\"\nJack Porter of \"The Michigan Daily\" defended nu metal, writing &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Unfortunately, some barriers prevent listeners from understanding nu-metal bands apart from the identity that genre label has given them\u2014picture a bone-headed suburban white kid sporting a backwards baseball cap. What used to be a descriptor for a specific strain of alternative metal turned into a ghetto for every band that a) plays extremely heavy yet radio-friendly music and b) sucks. Because the genre came to be defined by its lack of quality, many 'serious' music fans have missed out on what it has to offer.Writing for \"Loudwire\", music journalist Eduardo Rivadavia credited the subgenre for rejuvenating the commercial viability of heavy metal in the late 1990s, which he believes led to the emergence of several other new musical movements: \"If nothing else, nu metal did signal heavy metal\u2019s commercial rebound from the depths of post-grunge disrespect and led to the so-called New Wave of American Metal later in the decade, metalcore, post-metal and any number of worthy developments.\"\nRejection of nu metal label by nu metal musicians.\nSome nu metal musicians have rejected the label nu metal and have tried to distance themselves from it. Slipknot prefer to distance themselves from other nu metal groups, describing their music as \"metal metal\" and equating their link to nu metal as a coincidence of their time of emergence.\nJonathan Davis had originally rejected the nu metal label, saying \"We're not 'rap rock,' we're not 'nu-metal'\u00a0... We might have invented a new genre of heavy music or rock, but I believe the term 'nu-metal' was made up for all the bands that followed us. Those guys to me are nu-metal. And we're just Korn.\" In 2014, Davis spoke about the nu metal label, saying:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I've always rejected [Korn's pigeonholing] into some kind of genre that we helped create. It seems like when a band comes out and we do something new and something different, that's all great. When a whole bunch of bands jump on the bandwagon and start copying what that one band did, then it gets called something and those bands are cheap knockoffs of what the original thing was. So, to me, that's why I never liked the 'nu metal' term.\nDavis has since become more accepting of the term. In a 2019 interview, he remarked, \"If we invented nu-metal then fuck yeah, cool. It's pretty cool to say we helped invent some kind of movement, that's pretty insane.\" Expressing positive views of the genre's return to popularity in a 2020 interview, he endorsed Wargasm as a personal favourite.\nStaind's vocalist Aaron Lewis rejected the nu metal label, saying, \"If we get called a 'nu metal' band one more time, I don't even know what I'm going to do!\" In 2003, Chino Moreno, vocalist of Deftones, rejected the nu metal label saying \"We told motherfuckers not to lump us in with nu metal because when those bands go down we aren't going to be with them\". As Deftones abandoned the nu metal sound of their early work, Moreno tried to distance himself from nu metal bands and began to criticize the bands and their albums, including Korn's 2002 album \"Untouchables\"; he said, \"As Korn go on, it's the same things\u2014bad childhoods and mean moms. It gets too old after a while. How old is Jonathan [Davis]? Thirty? How long has it been since he lived with his parents?\" Davis responded saying, \"Obviously, Chino hasn't listened to the words on the rest of my albums because they're nothing about my parents or my childhood.\" Moreno also said, \"A big problem for me was opening for Limp Bizkit and Linkin Park, two bands that wouldn't exist if it weren't for me, straight up!\". Mike Shinoda of Linkin Park spoke about the nu metal label in an interview with \"NME\", saying \"We never held the flag for nu-metal\u2014it was associated with frat rock. Arrogant, misogynistic, and full of testosterone; we were reacting against that.\" Wes Borland of Limp Bizkit said that he \"never liked or condoned\" the term \"nu metal\" in any way, and said he does not understand \"how so many bands that sound nothing alike can be put into\" the nu metal genre. Mike Wengren of Disturbed said that he doesn't think Disturbed \"were ever a nu-metal band to begin with\".\nChester Bennington of Linkin Park initially disliked the band being labeled as nu metal, saying in 2007, \"I know that we kind of helped create, I guess, the sound of that genre, but I hate that genre. I'm not going to speak for everyone, but I can personally tell you that I am not a big fan of almost everybody in that category. There are a few bands that I don't really believe belong in there, and we're one of those bands.\" However, by 2012 Bennington said he accepted the nu metal label:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I think for the first time in our history, we're actually OK with being recognized as a nu metal band, especially for what we did early in our careers because the truth is that when we were first doing it, nobody else really was, especially in terms of the hip-hop thing.\nAssociation with heavy metal.\nIn addition to criticizing nu metal, many heavy metal musicians have rejected nu metal as a legitimate subgenre of heavy metal, saying it is not \"true heavy metal\". Some nu metal musicians have tried to distance themselves from being heavy metal at all. For example, Korn's Jonathan Davis rejected the \"heavy metal\" label. When talking with \"Vice\", Davis spoke about Korn being called a heavy metal band, saying, \"I never thought of us to be metal to begin with. Yeah, we're heavy and downtuned, but metal, to me, is like Judas Priest and Iron Maiden. That's metal, man. I always thought of us as a funk band. That funky, groovy shit.\" Godsmack's vocalist Sully Erna also rejected the \"heavy metal\" label and said he views Godsmack as a hard rock band. Linkin Park's vocalist Chester Bennington, though eventually accepting of the nu metal label, had expressed some disagreement with his band being labeled a heavy metal or nu metal group because he felt the term limited the scope of the band's actual style, particularly on their later albums. He elaborated:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[We] wanted to make clear from the very beginning when we were kind of tagged as a 'nu metal' band. Not that we have anything against metal\u00a0... [w]e aren't just one thing. So there are elements of the band that are metal, there are elements of the band that are pop, there are elements that are electronic, and hip-hop as well. And we've kind of always felt like we weren't bound to just one genre. So after we made \"Hybrid Theory\" and \"Meteora\", we really wanted to take risks beyond what we had already done on those first two records, creatively, and show the world that we can do a lot more than just make nu-metal songs.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22091", "revid": "49964380", "url": "https://en.wikipedia.org/wiki?curid=22091", "title": "Ncurses", "text": "Text-based user interface API\nncurses (new curses) is a programming library for creating textual user interfaces (TUIs) that work across a wide variety of terminals. It is written in a way that attempts to optimize the commands that are sent to the terminal, to reduce the latency experienced when updating the displayed content.\nncurses is a free and open-source software emulation of curses from System V Release 4.0 (SVr4).\nThere are bindings for ncurses in a variety of programming languages, including Ada, Common Lisp, Python, Gambas, Ruby, PHP, JavaScript, Perl, Object REXX (ooRexx) and Rust.\nHistory.\nAs the new version, ncurses is a free and open-source software emulation of the System V Release 4.0 (SVr4) curses, which was an enhancement over the discontinued 4.4 BSD curses. The XSI Curses standard issued by X/Open is explicitly and closely modeled on UNIX System V.\ncurses.\nThe first curses library was developed at the University of California at Berkeley, for a BSD operating system, around 1980 to support Rogue, a text-based adventure game. It originally used the termcap library, which was used in other programs, such as the vi editor.\nThe success of the BSD curses library prompted Bell Labs to release an enhanced curses library in their System V Release 2 Unix systems. This library was more powerful and instead of using termcap, it used terminfo. However, due to AT&amp;T's policy regarding the distribution of source code, the improved curses library was not widely adopted in the BSD community.\npcurses.\nAround 1982, Pavel Curtis started work on a freeware clone of the Bell Labs curses, named pcurses, which was maintained by various people through 1986.\nncurses.\nThe pcurses library was further improved when Zeyd Ben-Halim took over the development effort in late 1991. The new library was released as ncurses in November 1993, with version 1.8.1 as the first major release. Subsequent work, through version 1.8.8 (M1995), was driven by Eric S. Raymond, who added the form and menu libraries written by Juergen Pfeifer. Since 1996, it has been maintained by Thomas E. Dickey.\nMost ncurses calls can be easily ported to the old curses. System V curses implementations can support BSD curses programs with just a recompilation. However, a few areas are problematic, such as handling terminal resizing, since no counterpart exists in the old curses.\nTerminal database.\nncurses can use either terminfo (with extensible data) or termcap. Other implementations of curses generally use terminfo; a minority use termcap. Few (mytinfo was an older exception) use both.\nLicense.\nncurses is a part of the GNU Project, but is not distributed under the GNU General Public License (GPL) or GNU Lesser General Public License (LGPL). Instead, it is distributed under a permissive free software licence: the MIT License. This is due to the agreement made with the Free Software Foundation at the time the developers assigned their copyright.\nWhen the agreement was made to pass on the rights to the FSF, there was a clause that stated:\nThe Foundation promises that all distribution of the Package, or of any work \"based on the Package\", that takes place under the control of the Foundation or its agents or assignees, shall be on terms that explicitly and perpetually permit anyone possessing a copy of the work to which the terms apply, and possessing accurate notice of these terms, to redistribute copies of the work to anyone on the same terms.\nAccording to the maintainer Thomas E. Dickey, this precludes relicensing to the GPL in any version, since it would place restrictions on the programs that will be able to link to the libraries.\nPrograms using ncurses.\nHundreds of programs use ncurses. Some, such as GNU Screen and w3m, use only the termcap interface and perform screen management themselves. Others, such as GNU Midnight Commander and Yet another Setup Tool (YaST), use the curses programming interface.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22092", "revid": "47555821", "url": "https://en.wikipedia.org/wiki?curid=22092", "title": "NBA (disambiguation)", "text": "NBA (National Basketball Association) is a North American sports league.\nNBA may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "22093", "revid": "19992876", "url": "https://en.wikipedia.org/wiki?curid=22093", "title": "National Basketball Association", "text": "North American professional basketball league\nThe National Basketball Association (NBA) is a professional basketball league in North America composed of 30 teams (29 in the United States and 1 in Canada). The NBA is one of the major professional sports leagues in the United States and Canada and is considered the premier professional basketball league in the world. The league is headquartered in Midtown Manhattan.\nThe NBA was created on August 3, 1949, with the merger of the Basketball Association of America (BAA) and the National Basketball League (NBL). The league later adopted the BAA's history and considers its founding on June 6, 1946, as its own. In 1976, the NBA and the American Basketball Association (ABA) merged, adding four franchises to the NBA. The NBA's regular season runs from October to April, with each team playing 82 games. The league's playoff tournament extends into June, culminating with the NBA Finals championship series.\nThe NBA is an active member of USA Basketball (USAB), which is recognized by the International Basketball Federation (FIBA) as the governing body for basketball in the United States. The NBA is the second-wealthiest professional sports league in the world by revenue after the National Football League (NFL). As of 2020[ [update]], NBA players are the world's highest paid athletes by average annual salary per player.\nThe Boston Celtics have the most NBA championships with 18, most recently winning in 2024. The Oklahoma City Thunder are the reigning league champions, having defeated the Indiana Pacers in the 2025 NBA Finals for their first title since moving to Oklahoma City in 2008, and their second ever, having won in 1979 as the Seattle SuperSonics.\nHistory.\nCreation and BAA\u2013NBL merger (1946\u20131956).\nThe NBA traces its roots to the Basketball Association of America which was founded in 1946 by owners of the major ice hockey arenas in the Northeastern and Midwestern United States and Canada. On November 1, 1946, in Toronto, Ontario, Canada, the Toronto Huskies hosted the New York Knickerbockers at Maple Leaf Gardens, in a game the NBA now refers to as the first game played in NBA history. The first basket was made by Ossie Schectman of the Knickerbockers.\nAlthough there had been earlier attempts at professional basketball leagues, including the American Basketball League (ABL) and the National Basketball League (NBL), the BAA was the first league to attempt to play primarily in large arenas in major cities. During its early years, the quality of play in the BAA was not significantly better than in competing leagues or among leading independent clubs such as the Harlem Globetrotters. For instance, the 1947 ABL finalist Baltimore Bullets moved to the BAA and won that league's 1948 title, and the 1948 NBL champion Minneapolis Lakers won the 1949 BAA title.\nPrior to the 1948\u201349 season, the BAA lured away the Fort Wayne Pistons, Indianapolis Kautskys, Minneapolis Lakers, and Rochester Royals from the NBL with the prospect of playing in major venues such as Boston Garden and Madison Square Garden. The NBL hit back by outbidding the BAA for the services of several players, including Al Cervi, rookie Dolph Schayes and five stars from the University of Kentucky while also gaining the upper hand in Indianapolis with the creation of the Indianapolis Olympians while the Kautskys folded. With several teams facing financial difficulties, the BAA and the NBL agreed on a merger on August 3, 1949, to create the National Basketball Association. Maurice Podoloff, the president of BAA, became the president of the NBA while Ike Duffey, president of the NBL, became the chairman. The NBA later adopted the BAA's history and statistics as its own but did not do the same for NBL records and statistics.\nThe new league had seventeen franchises located in a mix of large and small cities, as well as large arenas and smaller gymnasiums and armories. In 1950, the NBA consolidated to eleven franchises, a process that continued until 1954\u201355, when the league reached its smallest size of eight franchises: the New York Knicks, Boston Celtics, Philadelphia Warriors, Minneapolis Lakers, Rochester Royals, Fort Wayne Pistons, Milwaukee Hawks, and Syracuse Nationals, all of which remain in the league today, although the latter six all did eventually relocate. The process of contraction saw the league's smaller-city franchises move to larger cities. The Hawks had shifted from the Tri-Cities to Milwaukee in 1951, and later shifted to St. Louis in 1955. In 1957, the Rochester Royals moved from Rochester, New York, to Cincinnati and the Pistons moved from Fort Wayne, Indiana, to Detroit.\nJapanese-American Wataru Misaka is considered to have broken the NBA color barrier in the 1947\u201348 season when he played for the New York Knicks in the BAA. He remained the only non-white player in league history prior to the first African-American, Harold Hunter, signing with the Washington Capitols in 1950. Hunter was cut from the team during training camp, but several African-American players did play in the league later that year, including Chuck Cooper with the Celtics, Nathaniel \"Sweetwater\" Clifton with the Knicks, and Earl Lloyd with the Washington Capitols. During this period, the Minneapolis Lakers won five NBA championships and established themselves as the league's first dynasty; their squad was led by center George Mikan who was the NBA's first superstar. To encourage shooting and discourage stalling, the league introduced the 24-second shot clock in 1954.\nCeltics' dominance, league expansion and competition (1956\u20131979).\nIn 1957, rookie center Bill Russell joined the Boston Celtics, which already featured guard Bob Cousy and coach Red Auerbach, and went on to lead the franchise to eleven NBA titles in thirteen seasons. Center Wilt Chamberlain entered the league with the Warriors in 1959 and became a dominant individual star of the 1960s, setting new single-game records in scoring (100) and rebounding (55). Russell's rivalry with Chamberlain became one of the greatest rivalries in the history of American team sports.\nThe 1960s were dominated by the Celtics. Led by Russell, Cousy, and Auerbach, Boston won eight straight championships in the NBA from 1959 to 1966. This championship streak is the longest in the history of American professional sports. They did not win the title in 1966\u201367, but regained it in the 1967\u201368 season and repeated in 1969. The domination totaled nine of the ten championship banners of the 1960s.\nThrough this period, the NBA continued to evolve with the shift of the Minneapolis Lakers to Los Angeles, the Philadelphia Warriors to San Francisco, the Syracuse Nationals to Philadelphia to become the Philadelphia 76ers, and the St. Louis Hawks moving to Atlanta, as well as the addition of its first expansion franchises. The Chicago Packers (now Washington Wizards) became the ninth NBA team in 1961. From 1966 to 1968, the league expanded from 9 to 14 teams, introducing the Chicago Bulls, Seattle SuperSonics (now Oklahoma City Thunder), San Diego Rockets (who moved to Houston four years later), Milwaukee Bucks, and Phoenix Suns.\nIn 1967, the league faced a new external threat with the formation of the American Basketball Association (ABA). The leagues engaged in a bidding war. The NBA landed the most important college star of the era, Kareem Abdul-Jabbar (then known as Lew Alcindor), who went on to become the league's best player of the 1970s. However, the NBA's leading scorer, Rick Barry, jumped to the ABA, as did four veteran referees\u2014Norm Drucker, Earl Strom, John Vanak, and Joe Gushue.\nIn 1969, Alan Siegel, who oversaw the design of Jerry Dior's Major League Baseball logo a year prior, created the modern NBA logo inspired by the MLB's. It incorporates the silhouette of Jerry West, based on a photo by Wen Roberts. The NBA would not confirm that a particular player was used because, according to Siegel, \"They want to institutionalize it rather than individualize it. It's become such a ubiquitous, classic symbol and focal point of their identity and their licensing program that they don't necessarily want to identify it with one player.\" The logo debuted in 1971 (with a small change to the typeface on the NBA wordmark in 2017) and would remain a fixture of the NBA brand.\nThe ABA succeeded in signing a number of major stars in the 1970s, including Julius Erving of the Virginia Squires, in part because it allowed teams to sign college undergraduates. The NBA expanded rapidly during this period. From 1966 to 1974, the NBA grew from nine franchises to 18. In 1970, the Portland Trail Blazers, Cleveland Cavaliers, and Buffalo Braves (now the Los Angeles Clippers) all made their debuts expanding the league to 17. The New Orleans Jazz (now in Utah) came aboard in 1974 bringing the total to 18. Following the 1976 season, the leagues reached a settlement that provided for the addition of four ABA franchises to the NBA, raising the number of franchises in the league at that time to 22. The franchises added were the San Antonio Spurs, Denver Nuggets, Indiana Pacers, and New York Nets (now the Brooklyn Nets). Some of the biggest stars of this era were Abdul-Jabbar, Barry, Dave Cowens, Erving, Elvin Hayes, Walt Frazier, Moses Malone, Artis Gilmore, George Gervin, Dan Issel, and Pete Maravich. The end of the decade, however, saw declining television ratings, low attendance and drug-related player issues \u2013 both perceived and real \u2013 that threatened to derail the league.\nSurging popularity and Bulls' dynasty (1979\u20131998).\nThe league added the ABA's three-point field goal beginning in 1979. That same year, rookies Larry Bird and Magic Johnson joined the Boston Celtics and Los Angeles Lakers respectively, initiating a period of significant growth of fan interest in the NBA. The two had faced each other in the 1979 NCAA Division I Basketball Championship Game, and they later played against each other in three NBA Finals (1984, 1985, and 1987). In the 10 seasons of the 1980s, Johnson led the Lakers to five titles while Bird led the Celtics to three titles. Also in the early 1980s, the NBA added one more expansion franchise, the Dallas Mavericks, bringing the total to 23 teams. Later on, Larry Bird won the first three three-point shooting contests. On February 1, 1984 David Stern became commissioner of the NBA. Stern has been recognized as playing a major role in the growth of the league during his career.\nMichael Jordan entered the league in 1984 with the Chicago Bulls, spurring more interest in the league. In 1988 and 1989, four cities got their wishes as the Charlotte Hornets, Miami Heat, Orlando Magic, and Minnesota Timberwolves made their NBA debuts, bringing the total to 27 teams. The Detroit Pistons won back-to-back NBA championships in 1989 and 1990, led by coach Chuck Daly and guard Isiah Thomas. Jordan and Scottie Pippen led the Bulls to two three-peats in eight years during the 1991\u20131998 seasons. Hakeem Olajuwon won back-to-back titles with the Houston Rockets in 1994 and 1995.\nThe 1992 Olympic basketball Dream Team, the first to use current NBA stars, featured Michael Jordan as the anchor, along with Bird, Johnson, David Robinson, Patrick Ewing, Scottie Pippen, Clyde Drexler, Karl Malone, John Stockton, Chris Mullin, Charles Barkley, and star NCAA amateur Christian Laettner. The team was elected to the Naismith Memorial Basketball Hall of Fame, while 11 of the 12 players (along with three out of four coaches) have been inducted as individuals in their own right.\nIn 1995, the NBA expanded to Canada with the addition of the Vancouver Grizzlies and the Toronto Raptors. In 1996, the NBA created a women's league, the Women's National Basketball Association (WNBA).\nLakers' and Spurs' dynasties (1998\u20132014).\nIn 1998, the NBA owners began a lockout that suspended all league business until a new labor agreement could be reached, which led to the season being shortened to 50 games.\nAfter the breakup of the Chicago Bulls championship roster in the summer of 1998, the Western Conference dominated much of the next two decades. The Los Angeles Lakers, coached by Phil Jackson, and the San Antonio Spurs, coached by Gregg Popovich, combined to make 13 Finals in 16 seasons, with 10 titles. \"Twin Towers\" Tim Duncan and David Robinson won the 1999 championship with the Spurs, becoming the first former ABA team to win the NBA championship. Shaquille O'Neal and Kobe Bryant started the 2000s with three consecutive championships for the Lakers. The Spurs reclaimed the title in 2003 against the Nets. In 2004, the Lakers returned to the Finals, only to lose in five games to the Detroit Pistons.\nAfter the Hornets' moved to New Orleans in 2002, the NBA returned to North Carolina, as the Charlotte Bobcats were formed as an expansion team in 2004. New Orleans then temporarily moved to Oklahoma City in 2005 for two seasons due to damage caused to their arena by Hurricane Katrina. The team returned to New Orleans in 2007.\nThe league's image was marred by a violent incident between players and fans in a November 2004 game between the Indiana Pacers and Detroit Pistons. In response, players were suspended for a total of 146 games with $11\u00a0million total lost in salary, and the league tightened security and limited the sale of alcohol.\nOn May 19, 2005, Commissioner Stern testified before the U.S. House of Representatives' Committee on Government Reform about the NBA's actions to combat the use of steroids and other performance-enhancing drugs. The NBA started its drug-testing program in 1983 and substantially improved it in 1999. In the 1999\u20132000 season, all players were randomly tested during training camp, and all rookies were additionally tested three more times during the regular season. Of the nearly 4,200 tests for steroids and performance-enhancing drugs conducted over six seasons, only three players were confirmed positive for NBA's drug program, all were immediately suspended, and as of the time of the testimony, none were playing in the NBA.\nAfter the Spurs won the championship again in 2005, the 2006 Finals featured two franchises making their inaugural Finals appearances. The Miami Heat, led by their star shooting guard, Dwyane Wade, and Shaquille O'Neal, who had been traded from the Lakers during the summer of 2004, won the series over the Dallas Mavericks. The Lakers/Spurs dominance continued in 2007 with a four-game sweep by the Spurs over the LeBron James-led Cleveland Cavaliers. The 2008 Finals saw a rematch of the league's highest profile rivalry, the Boston Celtics and Los Angeles Lakers, with the Celtics winning their 17th championship.\nThe NBA Board of Governors approved the request of the Seattle SuperSonics to move to Oklahoma City on April 18, 2008. The team, however, could not move until it had settled a lawsuit filed by the city of Seattle, which was intended to keep the SuperSonics in Seattle for the remaining two seasons of the team's lease at KeyArena. Following a court case, the city of Seattle settled with the ownership group of the SuperSonics on July 2, 2008, allowing the team to move to Oklahoma City immediately in exchange for terminating the final two seasons of the team's lease at KeyArena. The Oklahoma City Thunder began playing in the 2008\u201309 season.\nThe Lakers won back-to-back championships in 2009 and 2010, against the Orlando Magic and the Celtics. The 2010 NBA All-Star Game was held at Cowboys Stadium in front of the largest crowd ever: 108,713.\nA referee lockout began on September 1, 2009, when the contract between the NBA and its referees expired. The first preseason games were played on October 1, 2009, and replacement referees from the WNBA and NBA Development League were used, the first time replacement referees had been used since the beginning of the 1995\u201396 season. The NBA and the regular referees reached a deal on October 23, 2009.\nAt the start of the 2010\u201311 season, free agents LeBron James and Chris Bosh signed with the Miami Heat, joining Dwyane Wade to form the \"Big Three\". The Heat dominated the league, reaching the Finals for four straight years. In 2011, they faced a re-match with the Dallas Mavericks but lost to the Dirk Nowitzki-led team. They won back-to-back titles in 2012 and 2013 against the Oklahoma City Thunder and the Spurs, and lost in a re-match with the Spurs in the 2014 Finals.\nThe 2011\u201312 season began with another lockout, the league's fourth. After the first few weeks of the season were canceled, the players and owners ratified a new collective bargaining agreement on December 8, 2011, setting up a shortened 66-game season.\nAfter the 2012\u201313 season, the New Orleans Hornets were renamed the Pelicans. By May 2014, the Bobcats officially reclaimed the Hornets name, and by agreement with the league and the Pelicans, also received sole ownership of all history, records, and statistics from the Pelicans' time in Charlotte. As a result, the Hornets are now officially considered to have been founded in 1988, suspended operations in 2002, and resumed in 2004 as the Bobcats, while the Pelicans are officially treated as a 2002 expansion team. (This is somewhat similar to the relationship between the Cleveland Browns and Baltimore Ravens in the NFL.)\nOn February 1, 2014, commissioner David Stern retired after 30 years in the position, and was succeeded by his deputy, Adam Silver.\nWarriors' dynasty (2014\u20132022).\nAfter four seasons with the Miami Heat, LeBron James returned to the Cleveland Cavaliers for the 2014\u201315 season. He led the team to their second Finals appearance with the help of Kyrie Irving and Kevin Love. The Golden State Warriors defeated the Cavaliers in six games, led by the \"Splash Brothers\" Stephen Curry and Klay Thompson. The Cavaliers and the Warriors faced each other in the Finals a record four consecutive times. In the 2015\u201316 season, the Warriors finished the season 73\u20139, the best season record in NBA history. However, the Cavaliers overcame a 3\u20131 deficit in the Finals to win their first championship that season, and end a 52-year professional sports championship drought for the city of Cleveland. In the 2016\u201317 season, the Warriors recruited free agent Kevin Durant and went on to win the 2017 and 2018 Finals against the Cavaliers.\nAfter the departure of James in free agency in 2018, the Cavaliers' streak of playoff and Finals appearances ended. The Warriors returned for a fifth consecutive Finals appearance in 2019 but lost to the Toronto Raptors, who won their first championship after acquiring Kawhi Leonard in a trade.\nThe 2019\u201320 season was suspended indefinitely on March 11, 2020, due to the COVID-19 pandemic, after Utah Jazz center Rudy Gobert tested positive for the coronavirus. On June 4, 2020, the NBA Board of Governors voted to resume the season in a 22-team format with 8 seeding games per team and a regular playoffs format, with all games played in a \"bubble\" in Walt Disney World without any fans present.\nThis era also saw the continuous near year-over-year decline in NBA viewership. Between 2012 and 2019, the league lost 40 to 45 percent of its viewership. While some of it can be attributed to \"cable-cutting\", other professional leagues, like the NFL and MLB have retained stable viewership demographics. The opening game of the 2020 Finals between the Los Angeles Lakers and Miami Heat brought in only 7.41\u00a0million viewers to ABC, according to The Hollywood Reporter. That is reportedly the lowest viewership seen for the Finals since at least 1994, when total viewers began to be regularly recorded and is a 45 percent decline from game one between the Golden State Warriors and Toronto Raptors, which had 13.51\u00a0million viewers a year earlier. Some attribute this decline to the political stances the league and its players are taking, while others consider load management, the uneven talent distribution between the conferences and the cord-cutting of younger viewers as the main reason for the decline.\nDuring the 2020\u201321 and 2021\u201322 seasons, the Milwaukee Bucks would defeat the Phoenix Suns in the 2021 NBA Finals, securing their second NBA championship since 1971, and the Golden State Warriors made their sixth appearance in the finals defeating the Boston Celtics in the 2022 NBA Finals, their fourth championship in eight years.\nParity era (2023\u2013present).\n2023 saw the ratification of a new collective bargaining agreement, which will penalize teams who exceed the luxury tax above certain \"apron\" thresholds, making it significantly more difficult for teams to sign multiple superstars to maximum contracts. Seven different champions were crowned in seven years from 2019 to 2025, the longest such stretch in league history, leading numerous outlets to dub this the \"parity era\" in contrast to the dynasties which dominated previous decades.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We set out to create a system that allowed for more competition around the league. The goal being to have 30 teams all in the position, if well managed, to compete for championships. And that's what we're seeing here.\u2014\u200a\nThe 2022\u201323 season saw the Denver Nuggets, led by center Nikola Joki\u0107, make the franchise's first NBA Finals appearance and defeat the Miami Heat in five games to win their first NBA championship.\nThe 2023\u201324 NBA season saw the star-studded Boston Celtics, winning a championship over the Dallas Mavericks, after five conference finals appearances, and a finals appearance marking their 18th championship, their first since 2008.\nThe 2025 NBA playoffs featured four teams (Knicks, Pacers, Thunder and Timberwolves) who had championship droughts spanning several decades or who had never won a championship. The Thunder would ultimately defeat the Pacers in seven games in the 2025 NBA Finals to win their second title in franchise history and their first in Oklahoma City.\nInternational influence.\nFollowing pioneers like Vlade Divac (Serbia) and Dra\u017een Petrovi\u0107 (Croatia), who joined the NBA in the late 1980s, an increasing number of international players have moved directly from playing elsewhere in the world to starring in the NBA. Since 2006, the NBA has faced EuroLeague teams in exhibition matches in the NBA Europe Live Tour, and since 2009, in the EuroLeague American Tour. On November 9, 2007, when the Houston Rockets with Yao Ming faced off against the Milwaukee Bucks with Yi Jianlian, over 200 million people in China watched on 19 different networks, making it the most-viewed game in NBA history.\nThe 2013\u201314 season opened with a record 92 international players on the opening night rosters, representing 39 countries and comprising over 20 percent of the league. The NBA defines \"international\" players as those born outside the 50 United States and Washington, D.C. This means that:\nThe beginning of the 2017\u201318 season saw a record 108 international players representing 42 countries marking 4 consecutive years of at least 100 international players and each team having at least one international player. In 2018, the Phoenix Suns hired Serbian coach Igor Koko\u0161kov as their new head coach, replacing Canadian interim coach Jay Triano, making Koko\u0161kov the first European coach to become a head coach for a team in the NBA.\nIn the 2023\u201324 season, the Mavericks and the Thunder each had eight international players on their roster. For seven consecutive seasons from 2018\u201319 to 2024\u201325, the league's MVP award has been given to an international player.\nOther developments.\nIn 2001, an affiliated minor league, the National Basketball Development League, now called the NBA G League, was created.\nA new official game ball was introduced on June 28, 2006, for the 2006\u201307 season, marking the first change to the ball in over 35 years and only the second ball in 60 seasons. Manufactured by Spalding, the new ball featured a new design and new synthetic material that Spalding claimed offered a better grip, feel, and consistency than the original ball. However, many players were vocal in their disdain for the new ball, saying that it was too sticky when dry, and too slippery when wet.\nCommissioner Stern announced on December 11, 2006, that beginning January 1, 2007, the NBA would return to the traditional leather basketball in use prior to the 2006\u201307 season. The change was influenced by frequent player complaints and confirmed hand injuries (cuts) caused by the microfiber ball. The Players' Association filed a suit on behalf of the players against the NBA over the new ball.\nThe Federal Bureau of Investigation (FBI) began an investigation on July 19, 2007, over allegations that veteran NBA referee Tim Donaghy bet on basketball games he officiated over the past two seasons and that he made calls affecting the point spread in those games. On August 15, 2007, Donaghy pleaded guilty to two federal charges related to the investigation. Donaghy claimed in 2008 that certain referees were friendly with players and \"company men\" for the NBA, and he alleged that referees influenced the outcome of certain playoff and finals games in 2002 and 2005. NBA commissioner David Stern denied the allegations and said Donaghy was a convicted felon and a \"singing, cooperating witness\". Donaghy served 15 months in prison and was released in November 2009. According to an independent study by Ronald Beech of Game 6 of the 2002 Western Conference Finals between the Los Angeles Lakers and Sacramento Kings, although the refs increased the Lakers' chances of winning through foul calls during the game, there was no collusion to fix the game. On alleged \"star treatment\" during Game 6 by the referees toward certain players, Beech claimed, \"there does seem to be issues with different standards and allowances for different players.\"\nThe first outdoor game in the modern era of the league was played at the Indian Wells Tennis Garden on October 11, 2008, between the Phoenix Suns and the Denver Nuggets.\nThe first official NBA league games on European ground took place in 2011. In two matchups, the New Jersey Nets faced the Toronto Raptors at the O2 Arena in London in front of over 20,000 fans.\nDonald Sterling, who was then-owner of the Los Angeles Clippers, received a lifetime ban from the NBA on April 29, 2014, after racist remarks he made became public. Sterling was also fined US$2.5\u00a0million, the maximum allowed under the NBA Constitution.\nBecky Hammon was hired by the San Antonio Spurs on August 5, 2014, as an assistant coach, becoming the second female coach in NBA history but the first full-time coach. This also makes her the first full-time female coach in any of the four major professional sports in North America.\nThe NBA announced on April 15, 2016, that it would allow all 30 of its teams to sell corporate sponsor advertisement patches on official game uniforms, beginning with the 2017\u201318 season. The sponsorship advertisement patches would appear on the left front of jerseys, opposite Nike's logo, marking the first time a manufacturer's logo would appear on NBA jerseys, and would measure approximately 2.5 by 2.5 inches. The NBA would become the first major North American professional sports league to allow corporate sponsorship logos on official team uniforms, and the last to have a uniform manufacturer logo appear on its team uniforms. The first team to announce a jersey sponsorship was the Philadelphia 76ers, who agreed to a deal with StubHub.\nOn July 6, 2017, the NBA unveiled an updated rendition of its logo; it was largely identical to the previous design, except with revised typography and a \"richer\" color scheme. The league began to phase in the updated logo across its properties during the 2017 NBA Summer League.\nThe NBA also officially released new Nike uniforms for all 30 teams beginning with the 2017\u201318 season, replacing the previous supplier, Adidas. All team jerseys included the Nike logo except for the Charlotte Hornets, whose jerseys instead had the Jumpman logo associated with longtime Nike endorser Michael Jordan, who owns the Hornets. In addition, the league eliminated \"home\" and \"away\" uniform designations. Instead, each team would have four or six uniforms: the \"Association\" edition, which is the team's white uniform, the \"Icon\" edition, which is the team's color uniform, and the \"Statement\" and \"City\" uniforms, which most teams use as an alternate uniform. In 2018, the NBA added the \"Earned\" uniform.\nIn 2018, Adam Silver showed support in the Supreme Court's decision to overturn a federal ban on sports betting. Silver thought it would bring greater transparency and integrity as well as business opportunities. Before naming DraftKings and FanDuel co-official sports betting partners of the NBA in 2021, the NBA first named MGM as the exclusive official gaming partner of the NBA and WNBA\u2014the first major American sports league to do so. With a deal between the 76ers and then-sportsbook FOX Bet as the first agreement between an NBA team and a sportsbook app, more teams partnered with operators thereafter. This early acceptance of sports betting translated to basketball being the most bet-on sport in the United States over football in 2023.\nAs a part of its November 2021 multi-year partnership deal with the United Arab Emirates (UAE), the NBA hosted two preseason games in Abu Dhabi on October 4 and 6, 2024, marking its third annual trip to the country. However, the Human Rights Watch (HRW) raised concerns, citing the UAE's pattern of using high-profile events to enhance its image. HRW accused the league of being complicit in \"sportswashing\" the UAE's poor human rights record, while the country seeks to display itself as open country, without addressing the abuses. On September 30, HRW wrote a letter to the NBA, urging it to implement a human rights risk mitigation strategy, and to ensure that the preseason games were not used as a distraction from the UAE's human rights abuses. The rights organization also pointed out that the UAE hosted the games amidst the reports of the country being directly involved in fuelling the Sudanese civil war. A coalition of human rights groups called upon the NBA to cancel the games in Abu Dhabi in solidarity with Sudanese.\nOn March 10, 2025, NBA and Australia's National Basketball League (NBL) announced that in October 2025, the New Orleans Pelicans would play two preseason games at Rod Laver Arena in Melbourne as part of the .\nTeams.\nCeltics \nNets \nKnicks \n76ers \nRaptors \nBulls \nCavaliers \nPistons \nPacers \nBucks \nHawks \nHornets \nHeat \nMagic \nWizards \nNuggets \nTimberwolves \nThunder \nTrail&lt;br&gt;Blazers \nJazz \nWarriors \nClippers \nLakers \nSuns \nKings \nMavericks \nRockets \nGrizzlies \nPelicans \nSpurs \n \nThe NBA originated in 1946 with 11 teams, and through a sequence of team expansions, reductions and relocations consists of 30 teams \u2013 29 in the United States and 1 in Canada.\nThe current league organization divides 30 teams into two 15-team conferences of three divisions with five teams each. The current divisional alignment was introduced in the 2004\u201305 season. Reflecting the population distribution of the United States and Canada as a whole, most teams are in the eastern half of the country: 13 teams are in the Eastern Time Zone, nine in the Central, three in the Mountain, and five in the Pacific.\nNotes:\nRegular season.\nFollowing the summer break, teams begin training camps in late September. Training camps allow the coaching staff to evaluate players (especially rookies), scout the team's strengths and weaknesses, prepare the players for the rigorous regular season and determine the 12-man active roster (and a 3-man inactive list) with which they will begin the regular season. Teams have the ability to assign players with less than two years of experience to the NBA G League. After training camp, a series of preseason exhibition games are held. Preseason matches are sometimes held in non-NBA cities, both in the United States and overseas. The NBA regular season begins in mid-October.\nDuring the regular season, each team plays 82 games, 41 each home and away. A team faces opponents in its own division four times a year (16 games). Each team plays six of the teams from the other two divisions in its conference four times (24 games), and the remaining four teams three times (12 games). Finally, each team plays all the teams in the other conference twice apiece (30 games). This asymmetrical structure means the strength of schedule will vary between teams (but not as significantly as the NFL or MLB). Over five seasons, each team will have played 80 games against their division (20 games against each opponent, 10 at home, 10 on the road), 180 games against the rest of their conference (18 games against each opponent, 9 at home, 9 on the road), and 150 games against the other conference (10 games against each team, 5 at home, 5 on the road).\nStarting with the 2023\u201324 season, the regular season includes an in-season tournament, in which all games in the tournament (except for the final) count towards the regular season.\nThe NBA is also the only league that regularly schedules games on Christmas Day. The league has been playing games regularly on the holiday since 1947, though the first Christmas Day games were not televised until . Games played on this day have featured some of the best teams and players. Christmas is also notable for NBA on television, as the holiday is when the first NBA games air on network television each season. Games played on this day have been some of the highest-rated games during a particular season.\nThe NBA has also played games on Martin Luther King Jr. Day (MLK Day) every year since the holiday was first observed in 1986.\nIn February, the regular season pauses to celebrate the annual NBA All-Star Game. Fans vote throughout the United States, Canada, and on the Internet, and the top vote-getters in each conference are named captains. Fan votes determine the rest of the All-Star starters. Coaches vote to choose the remaining 14 All-Stars. The player with the best performance during the game is rewarded with a Game MVP award. Other attractions of the All-Star break include the Rising Stars Challenge (originally Rookie Challenge), where the top rookies and second-year players in the NBA play in a 5-on-5 basketball game, with the current format pitting U.S. players against those from the rest of the world; the Skills Challenge, where players compete to finish an obstacle course consisting of shooting, passing, and dribbling in the fastest time; the Three Point Contest, where players compete to score the highest number of three-point field goals in a given time; and the NBA Slam Dunk Contest, where players compete to dunk the ball in the most entertaining way according to the judges. These other attractions have varying names which include the names of the various sponsors who have paid for naming rights.\nShortly after the All-Star break is the trade deadline, which is set to fall on the 16th Thursday of the season (usually in February) at 3\u00a0pm Eastern Time. After this date, teams are not allowed to exchange players with each other for the remainder of the season, although they may still sign and release players. Major trades are often completed right before the trading deadline, making that day a hectic time for general managers.\nAround the middle of April, the regular season ends. It is during this time that voting begins for individual awards, as well as the selection of the honorary, league-wide, postseason teams. The Sixth Man of the Year Award is given to the best player coming off the bench (must have more games coming off the bench than actual games started). The Rookie of the Year Award is awarded to the most outstanding first-year player. The Most Improved Player Award is awarded to the player who is deemed to have shown the most improvement from the previous season. The Defensive Player of the Year Award is awarded to the league's best defender. The Coach of the Year Award is awarded to the coach that has made the most positive difference to a team. The Most Valuable Player Award is given to the player deemed the most valuable for (his team) that season. Additionally, \"Sporting News\" awards an unofficial (but widely recognized) Executive of the Year Award to the general manager who is adjudged to have performed the best job for the benefit of his franchise.\nThe postseason teams are the All-NBA Team, the All-Defensive Team, and the All-Rookie Team; each consists of five players. There are three All-NBA teams, consisting of the top players at each position, with first-team status being the most desirable. There are two All-Defensive teams, consisting of the top defenders at each position. There are also two All-Rookie teams, consisting of the top first-year players regardless of position.\nPlayoffs.\nThe NBA playoffs begin in April after the conclusion of the regular season and play-in tournament with the top eight teams in each conference, regardless of divisional alignment, competing for the league's championship title, the Larry O'Brien Championship Trophy. Seeds are awarded in strict order of regular season record (with a tiebreaker system used as needed).\nHaving a higher seed offers several advantages. Since the first seed begins the playoffs playing against the eighth seed, the second seed plays the seventh seed, the third seed plays the sixth seed, and the fourth seed plays the fifth seed, having a higher seed typically means a team faces a weaker opponent in the first round. The team in each series with the better record has home-court advantage, including the First Round.\nThe league began using its current format, with the top eight teams in each conference advancing regardless of divisional alignment, in the 2015\u201316 season. Previously, the top three seeds went to the division winners.\nThe playoffs follow a tournament format. Each team plays an opponent in a best-of-seven series, with the first team to win four games advancing into the next round, while the other team is eliminated from the playoffs. In the next round, the successful team plays against another advancing team of the same conference. All but one team in each conference are eliminated from the playoffs. Since the NBA does not re-seed teams, the playoff bracket in each conference uses a traditional design, with the winner of the series matching the first- and eighth-seeded teams playing the winner of the series matching the fourth- and fifth-seeded teams, and the winner of the series matching the second- and seventh-seeded teams playing the winner of the series matching the third- and sixth-seeded teams. In every round, the best-of-7 series follows a 2\u20132\u20131\u20131\u20131 home-court pattern, meaning that one team will have home court in games 1, 2, 5, and 7, while the other plays at home in games 3, 4, and 6. From 1985 to 2013, the NBA Finals followed a 2\u20133\u20132 pattern, meaning that one team had home court in games 1, 2, 6, and 7, while the other played at home in games 3, 4, and 5.\nThe final playoff round, a best-of-seven series between the victors of both conferences, is known as the NBA Finals and is held annually in June (sometimes, the series will start in late May). The winner of the NBA Finals receives the Larry O'Brien Championship Trophy. Each player and major contributor\u2014including coaches and the general manager\u2014on the winning team receive a championship ring. In addition, the league awards the Bill Russell NBA Finals Most Valuable Player Award to the best performing player of the series.\nChampionships.\nThe Boston Celtics have the most championships, with 18 NBA Finals wins. The Los Angeles Lakers have the second-most with 17; the Golden State Warriors and Chicago Bulls have the third- and fourth-most, respectively, with seven and six titles.\nCurrent teams that have no NBA Finals appearances:\nMedia coverage.\nAs one of the major sports leagues in North America, the NBA has a long history of partnerships with television networks in the United States. The NBA signed a contract with DuMont Television Network in its eighth season, the 1953\u201354 season, marking the first year the NBA had a national television broadcaster. Similar to the National Football League, the lack of television stations led to NBC taking over the rights from the 1954\u201355 season until April 1962\u2013NBC's first tenure with the NBA. The 2025\u201326 season marks the first year of 11-year agreements with broadcast networks ABC and NBC, pay television network ESPN, and streaming services Peacock and Amazon Prime Video to nationally televise games in the United States. Games that are not broadcast nationally are usually aired over regional sports networks specific to the area where the teams are located.\nInternational competitions.\nThe NBA has sporadically participated in international club competitions. The first international competition involving the NBA was a 1978 exhibition game in Tel Aviv, Israel between the Washington Bullets and Israeli club Maccabi Tel Aviv. From 1987 to 1999 an NBA team played against championship club teams from Asia, Europe and South America in the McDonald's Championship. This tournament was won by the NBA invitee every year it was held.\nTicket prices and viewership demographics.\nIn 2022, an average ticket cost $77.75. Depending on the market and stage of the season\u2014preseason, regular season, postseason\u2014a ticket can range from $10 to $100,000.\nIn 2020, ticket prices for the NBA All Star Game became more expensive than ever before, averaging around $2,600, and even more on the secondary market.\nViewership demographics.\nAccording to Nielsen's survey, in 2013 the NBA had the youngest audience, with 45 percent of its viewers under 35. As of 2022[ [update]], the league remains the least likely to be watched by women, who make up only 30% of the viewership. As of 2014[ [update]], 45 percent of its viewers were black, while 40 percent of viewers were white, making it the only top North American sport that does not have a white majority audience.\nAs of 2017[ [update]], the NBA's popularity further declined among white Americans, who during the 2016\u201317 season, made up only 34% of the viewership. At the same time, the black viewership increased to 47 percent, while Hispanic (of any race) stood at 11% and Asian viewership stood at 8%. According to the same poll, the NBA was favored more strongly by Democrats than Republicans.\nOutside the U.S., the NBA's biggest international market is in China, where an estimated 800 million viewers watched the 2017\u201318 season. NBA China is worth approximately $4\u00a0billion.\nNotable people.\nForeign players.\nInternational influence.\nFollowing pioneers like Vlade Divac (Serbia) and Dra\u017een Petrovi\u0107 (Croatia), who joined the NBA in the late 1980s, an increasing number of international players have moved directly from playing elsewhere in the world to starring in the NBA. Below is a list of foreign players who have won NBA awards or have otherwise been recognized for their contributions to basketball, either currently or formerly active in the league:\nOn some occasions, young players, most but not all from the English-speaking world, have attended American colleges before playing in the NBA. Notable examples are:\nNBA Cares.\nThe league has a global social responsibility program, NBA Cares, that is responsible for the league's stated mission of addressing important social issues worldwide.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22094", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=22094", "title": "Nutation", "text": "Wobble of the axis of rotation\nNutation (from la\u00a0'nodding, swaying') is a rocking, swaying, or nodding motion in the axis of rotation of a largely axially symmetric object, such as a gyroscope, planet, or bullet in flight, or as an intended behaviour of a mechanism. In an appropriate reference frame it can be defined as a change in the second Euler angle. If it is not caused by forces external to the body, it is called free nutation or Euler nutation (after Leonhard Euler). A pure nutation is a movement of a rotational axis such that the first Euler angle is constant. Therefore it can be seen that the circular red arrow in the diagram indicates the combined effects of precession and nutation, while nutation in the absence of precession would only change the tilt from vertical (second Euler angle). However, in spacecraft dynamics, precession (a change in the first Euler angle) is sometimes referred to as nutation.\nIn a rigid body.\nIf a top is set at a tilt on a horizontal surface and spun rapidly, its rotational axis starts precessing about the vertical. After a short interval, the top settles into a motion in which each point on its rotation axis follows a circular path. The vertical force of gravity produces a horizontal torque \u03c4 about the point of contact with the surface; the top rotates in the direction of this torque with an angular velocity \u03a9 such that at any moment\nformula_1, (cross product)\nwhere L is the instantaneous angular momentum of the top.\nInitially, however, there is no precession, and the upper part of the top falls sideways and downward, thereby tilting. This gives rise to an imbalance in torques that starts the precession. In falling, the top overshoots the amount of tilt at which it would precess steadily and then oscillates about this level. This oscillation is called \"nutation\". If the motion is damped, the oscillations will die down until the motion is a steady precession.\nThe physics of nutation in tops and gyroscopes can be explored using the model of a \"heavy symmetrical top\" with its tip fixed. (A symmetrical top is one with rotational symmetry, or more generally one in which two of the three principal moments of inertia are equal.) Initially, the effect of friction is ignored. The motion of the top can be described by three Euler angles: the tilt angle \"\u03b8\" between the symmetry axis of the top and the vertical (second Euler angle); the azimuth \"\u03c6\" of the top about the vertical (first Euler angle); and the rotation angle \"\u03c8\" of the top about its own axis (third Euler angle). Thus, precession is the change in \"\u03c6\" and nutation is the change in \"\u03b8\".\nIf the top has mass \"M\" and its center of mass is at a distance \"l\" from the pivot point, its gravitational potential relative to the plane of the support is\nformula_2\nIn a coordinate system where the \"z\" axis is the axis of symmetry, the top has angular velocities \"\u03c9\"1,\u2009\"\u03c9\"2,\u2009\"\u03c9\"3 and moments of inertia \"I\"1,\u2009\"I\"2,\u2009\"I\"3 about the \"x\", \"y\", and \"z\" axes. Since we are taking a symmetric top, we have \"I\"1=\"I\"2. The kinetic energy is\nformula_3\nIn terms of the Euler angles, this is\nformula_4\nIf the Euler\u2013Lagrange equations are solved for this system, it is found that the motion depends on two constants \"a\" and \"b\" (each related to a constant of motion). The rate of precession is related to the tilt by\nformula_5\nThe tilt is determined by a differential equation for \"u\" \n cos(\"\u03b8\") of the form\nformula_6\nwhere \"f\" is a cubic polynomial that depends on parameters \"a\" and \"b\" as well as constants that are related to the energy and the gravitational torque. The roots of \"f\" are cosines of the angles at which the rate of change of \"\u03b8\" is zero. One of these is not related to a physical angle; the other two determine the upper and lower bounds on the tilt angle, between which the gyroscope oscillates.\nAstronomy.\nThe nutation of a planet occurs because the gravitational effects of other bodies cause the speed of its axial precession to vary over time, so that the speed is not constant. English astronomer James Bradley discovered the nutation of Earth's axis in 1728.\nEarth.\nNutation subtly changes the axial tilt of Earth with respect to the ecliptic plane, shifting the major circles of latitude that are defined by the Earth's tilt (the tropical circles and the polar circles).\nIn the case of Earth, the principal sources of tidal force are the Sun and Moon, which continuously change location relative to each other and thus cause nutation in Earth's axis. The largest component of Earth's nutation has a period of 18.6 years, the same as that of the precession of the Moon's orbital nodes. However, there are other significant periodic terms that must be accounted for depending upon the desired accuracy of the result. A mathematical description (set of equations) that represents nutation is called a \"theory of nutation\". In the theory, parameters are adjusted in a more or less \"ad hoc\" method to obtain the best fit to data. Simple rigid body dynamics do not give the best theory; one has to account for deformations of the Earth, including mantle inelasticity and changes in the core\u2013mantle boundary.\nThe principal term of nutation is due to the regression of the Moon's nodal line and has the same period of 6798 days (18.61 years). It reaches plus or minus 17\u2033 in longitude and 9.2\u2033 in obliquity. All other terms are much smaller; the next-largest, with a period of 183 days (0.5 year), has amplitudes 1.3\u2033 and 0.6\u2033 respectively. The periods of all terms larger than 0.0001\u2033 (about as accurately as available technology can measure) lie between 5.5 and 6798 days; for some reason (as with ocean tidal periods) they seem to avoid the range from 34.8 to 91 days, so it is customary to split the nutation into long-period and short-period terms. The long-period terms are calculated and mentioned in the almanacs, while the additional correction due to the short-period terms is usually taken from a table. They can also be calculated from the Julian day according to IAU 2000B methodology.\nIn popular culture.\nIn the 1961 disaster film \"The Day the Earth Caught Fire\", the near-simultaneous detonation of two super-hydrogen bombs near the poles causes a change in Earth's nutation, as well as an 11\u00b0 shift in the axial tilt and a change in Earth's orbit around the Sun.\nIn \"\", rapidly 'cycling' or 'changing' the 'shield nutation' is frequently mentioned as a means by which to delay the antagonist in their efforts to break through the defences and pillage the Enterprise or other spacecraft.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "22095", "revid": "14383484", "url": "https://en.wikipedia.org/wiki?curid=22095", "title": "National Institute for Standards and Technology", "text": ""}
{"id": "22096", "revid": "27335766", "url": "https://en.wikipedia.org/wiki?curid=22096", "title": "NASCO", "text": "NASCO or Nasco may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "22097", "revid": "50036606", "url": "https://en.wikipedia.org/wiki?curid=22097", "title": "North Atlantic Salmon Conservation Organization", "text": "International fisheries conservation organization\nThe North Atlantic Salmon Conservation Organization (NASCO) is an international organization established by the Convention for the Conservation of Salmon in the North Atlantic Ocean on October 1, 1983,\nAs a specialised regional fishery management organisation, NASCO's mission is to contribute through consultation and cooperation to the conservation, restoration, enhancement and rational management of salmon stocks with a 10-Year Plan to slow the decline of wild North Atlantic salmon.\nNASCO is headquartered in Edinburgh, United Kingdom, and was formed in response to the failure of independent states to effectively protect a global common such as the salmon population. It was recognized that international cooperation was essential to prevent unsustainable overfishing. NASCO has since established various regulations and guidelines to manage salmon fisheries, including restricting fishing to within 12 nautical miles of the coast with exceptions in Greenland and the Faroe Islands. Additionally, NASCO has recognized the increasing number of countries implementing catch-and-release practices and has brought light to the proper way to manage and catch-and-release scenario in order to reduce fishing mortality. NASO highlights the importance of keeping the fish in the water prior to release to avoid air exposure. There has been valuable evidence supporting increasing survival rates by following these guidelines.\nIn 2020, the NASCO operates with a budget of 636 630 GBP, with a little over 583 000 GBP coming from the member states.\nMembership.\nCurrent participants (since 1984):\nAfter withdrawing from NASCO in 2009, Iceland rejoined the fight to restore North Atlantic salmon in March 2023.\nFormer participants: \nFrance (in respect of St. Pierre &amp; Miquelon) attends NASCO's meetings as an observer.\nThe NASCO also has 34 NGOs from different member states that have observational status during the annual meetings.\nStructure.\nSource:\nCouncil: the governing body of NASCO \nInternational Atlantic Salmon Research Board: make scientific research recommendations to the Council and Commissions\nFinance and Administration Committee (FAC): deals with the administrative and financial matters of the organization. One member from each Party participates.\nSecretariat: headed by the Secretary, assist NASCO members on implementation\nThe primary tasks of the council include:\nThe Atlantic Salmon.\nAtlantic Salmon (\"Salmo salar)\", often referred to as \"King of Fish\" are anadromous fish. This means they spend a portion of their life cycle in both the fresh and salt water. Adult salmon lay their eggs in freshwater rivers, after the eggs hatch they mature for 1\u20133 years before migrating to the ocean.\nThreats to North Atlantic Salmon.\nNorth Atlantic salmon face many threats that have contributed to the significant population decline over the years and have garnered the need for restoration. Overfishing has historically affected numerous species across the globe, stemming from increasing pressure of both commercial and recreational fishing. Climate change has affected aquatic ecosystems due to an increase in ocean temperatures, ocean acidification, and ocean deoxygenation which has caused alterations in salmon migration patterns. Additionally, aquaculture has resulted from farmed salmon, posing a serious risk to wild salmon. Farmed salmon are producing toxic particles leading to the transmission of diseases and interbreeding.\nWild Salmon vs. Farmed.\nAs the international demand for salmon increase, salmon farming is growing rapidly in order to try and meet the needs of consumers. Salmon farming involves raising salmon in a wide net close to shore for the span of its life cycle. The average lifespan of salmon is typically three years. The salmon first begin in freshwater and are later transported to saltwater until they have matured enough to be sold. A study showed that 70% Atlantic salmon were produced through fish farming. Farmed salmon present a higher level of risk to contain toxins due to their controlled feed containing toxic particles. Some may argue that salmon farming is an eco-friendly form of protein production, however, the excess food waste produced from these farms disturbs aquatic life and can alter the biodiversity.\nThe Future of NASCO- A Ten-Year Plan.\nSource:\nNASCO's Council has adopted a Ten-Year Plan to address the threat to Atlantic salmon and to restore what was once a healthy, thriving population.\nNASCO's has set a goal to focus on and promote efforts aimed at protecting, conserving, and restoring wild Atlantic salmon across the species' range. In order to achieve this ten-year goal, they have outlined the following five objectives:\nAn Agenda for Action.\nA panel of four (4) distinguished men produced a Call-To-Action plan based on their expertise in NASCO affairs. The agenda contains the following guiding principals:\nCriticism of NASCO.\nThe ratification of NASCO has made excellent strides in the restoration of wild Atlantic salmon but has faced criticism for its lack of governmental support from member states when the agreements of NASCO interfere with the country's interests.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22098", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=22098", "title": "Nintendo Game Cube", "text": ""}
{"id": "22099", "revid": "69412", "url": "https://en.wikipedia.org/wiki?curid=22099", "title": "Narcissus (mythology)", "text": "Character in Greek mythology\nIn Greek mythology, Narcissus (; ) is a hunter from Thespiae in Boeotia (alternatively Mimas or modern-day Karaburun, \u0130zmir), known for his beauty which was noticed by all. According to the best-known version of the story in Ovid's \"Metamorphoses\", Narcissus rejected the advances of all women and men who approached him, instead falling in love with his own reflection in a pool of water. In some versions, he beat his breast purple in agony at being kept apart from this reflected love, and in his place sprouted a flower bearing his name.\nThe character of Narcissus is the origin of the term narcissism, a self-centered personality style. This quality in extreme contributes to the definition of narcissistic personality disorder, a psychiatric condition marked by grandiosity, excessive need for attention and admiration, and an impaired ability to empathize.\nEtymology.\nIn his \"Etymological Dictionary of Greek\", R. S. P. Beekes says that \"[t]he suffix [-\u03b9\u03c3\u03c3\u03bf\u03c2] clearly points to a Pre-Greek word.\"\nFamily.\nIn some versions, Narcissus was the son of the river god Cephissus and nymph Liriope, while Nonnus instead has him as the son of the lunar goddess Selene and her mortal lover Endymion.\nMythology.\nSeveral versions of the myth have survived from ancient sources, one from Pausanias, the Greek traveler and geographer of the second century AD, and a more popular one from Ovid, published before 8 AD, found in Book 3 of his \"Metamorphoses\". This is the story of Echo and Narcissus. In Ovid's narrative, the framing revolves around a test of the prophetic abilities of Tiresias, an individual who has experienced life as both a man and a woman. His sight was taken from him during a dispute between Juno and Jove; siding with Jove led to his blinding by an enraged Juno. In compensation for his lost sight, Jove granted him the gift of prophecy. The prophecy that solidified Tiresias's reputation is the tale of Echo and Narcissus.\nOvid.\nAfter being \"ravaged\" by the river god Cephissus, the nymph Liriope gave birth to Narcissus, who was \"beautiful even as a child.\" As was the custom, she consulted the seer Tiresias about the boy's future, who predicted that the boy would live a long life only if he never \"came to know himself\". During his 16th year, after getting lost while hunting with friends, Narcissus came to be followed by a nymph, Echo.\nEcho was an Oread (mountain nymph) and, like Tiresias, had a sensory ability altered after an argument between Juno and Jove. Echo had kept Juno occupied with gossip while Jove had an affair behind her back. In another similar version by Ovid, Echo kept the goddess Juno occupied with stories while Zeus's lovers escaped Mount Olympus. As a punishment, Juno took from Echo her agency in speech; Echo was thereafter never able to speak unless it was to repeat the last few words of those she heard. Echo had deceived using gossip; she would be condemned to be only that from then on.\nMeanwhile, Echo spied Narcissus, separated from his hunting friends, and she became immediately infatuated, following him, waiting for him to speak so her feelings might be heard. Narcissus sensed he was being followed and shouted \"Who's there?\" Echo repeated, \"Who's there?\" While this interaction continued, Echo came close enough so that she was revealed, and attempted to embrace him. Horrified, he stepped back and told her to \"keep her chains\". Heartbroken, Echo wasted away, losing her body amidst lonely glens, until nothing of her but her chaste verbal ability remained.\nNemesis, the goddess of revenge, heard the pleas of a young man, Ameinias, who had fallen for Narcissus but was ignored and cursed him; Nemesis listened, proclaiming that Narcissus would never be able to be loved by the one he fell in love with.\nAfter spurning Echo and the young man, Narcissus became thirsty. He found a pool of water which, in Ovid's account, no animal had ever approached. Leaning down to drink, Narcissus sees his reflection, which he finds as beautiful as a marble statue. Not realizing it was his own reflection, Narcissus fell deeply in love with it. Thus both Tiresias's prophecy and Nemesis' curse came true in the same instance.\nUnable to leave the allure of this image, Narcissus eventually realized that his love could not be reciprocated and he melted away from the fire of passion burning inside him, eventually turning into a gold and white flower.\nVersions without Echo.\nOvid was probably influenced by an earlier version ascribed to the captive Greek poet Parthenius of Nicaea, composed around 50 BC and rediscovered in 2004 by Dr Benjamin Henry among the Oxyrhynchus papyri at Oxford. This version is very concise and makes no mention of Echo.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;He had a cruel heart, and hated all of them, till he conceived a love for his own form: He wailed, seeing his face, delightful as a dream, within a spring; he wept for his beauty. Then the boy shed his blood and gave it to the earth... to bear.\nA version of the myth by Conon, a contemporary of Ovid, has an even bloodier ending (\"Narrations,\" 24), relating how a young man named Ameinias fell in love with Narcissus, who had already spurned his suitors, all of whom were male. Although Ameinias was very persistent, Narcissus spurned him too and gave him a sword, which Ameinias used to kill himself at Narcissus's doorstep after praying to the gods to teach Narcissus a lesson for all the pain he provoked. Narcissus walked by a pool of water and decided to drink some. He saw his reflection, became entranced by it, his first and only love, and killed himself because he could not have his object of desire. Because of this tragedy, the Thespians came to honor and reverence Eros especially among the gods.\nA century later the travel writer Pausanias recorded a novel variant of the story, in which Narcissus falls in love with his twin sister rather than himself.\nIn all versions, his body disappears and all that is left is a narcissus flower.\nInterpretation.\nComparative ancient interpretations.\nMiyawaki outlines several major ancient versions of the Narcissus myth, each emphasizing different themes. In Ovid\u2019s account, the myth centers on illusion, self-recognition, and the tragedy of unfulfilled desire. Conon\u2019s version includes the rejected suitor Ameinias and frames the story as a moralized tale about cruelty and punishment. Pausanias presents a more psychologically grounded narrative in which Narcissus mourns his deceased twin sister, interpreting the story as an expression of grief rather than self-love.\nPsychological interpretations.\nModern psychoanalytic scholarship has challenged Freud\u2019s reading of the myth. Javanbakht argues that Narcissus exhibits a conflicted pattern of withdrawal and longing more consistent with schizoid\u2013histrionic dynamics than narcissistic personality disorder. He also notes that Narcissus initially fails to recognize the reflection and that his fixation is a punishment imposed by Nemesis, not an inherent trait.\nInfluence on culture.\nThe myth of Narcissus has inspired artists for at least two thousand years, even before the Roman poet Ovid featured a version in book III of his \"Metamorphoses\". This was followed in more recent centuries by other poets (e.g. Keats and Alfred Edward Housman) and painters (Caravaggio, Poussin, Turner, Dal\u00ed (see \"Metamorphosis of Narcissus\"), and Waterhouse).\nLiterature.\nThe myth had a decided influence on English Victorian homoerotic culture, via Andr\u00e9 Gide's study of the myth, \"Le Trait\u00e9 du Narcisse\" ('The Treatise of the Narcissus', 1891). Oscar Wilde also used the myth within his works. One of his poems from 1894, \"The Disciple\",continues the story of Narcissus after his death,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200aThe Oreads and the pool Narcissus gazed in, in \nBefore this Wilde published \"The Picture of Dorian Gray\" in 1890, and used Narcissus as an example of beauty multiple times. In Chapter 1, Lord Henry used the myth to describe the beauty of the man Basil (the protagonist) had painted. Basil explained to Lord Henry he did not want to part with his work because he had put much of himself into it.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...and this young Adonis, who looks as if he was made out of ivory and rose-leaves. Why, my dear Basil, he is a Narcissus, and you\u2014well...\u2014\u200aLord Henry, in \nPaulo Coelho's \"The Alchemist\" also starts with a story about Narcissus, found (we are told) by the alchemist in a book brought by someone in the caravan. The alchemist's (and Coelho's) source was very probably Hesketh Pearson's \"The Life of Oscar Wilde\" (1946) in which this story is recorded (Penguin edition, p.\u00a0217) as one of Wilde's inspired inventions. This version of the Narcissus story is based on Wilde's \"The Disciple\" from his \"Poems in Prose (Wilde) \".\nSeamus Heaney references Narcissus in his poem \"Personal Helicon\" from his first collection \"Death of a Naturalist\":To stare, big-eyed Narcissus, into some spring\nIs beneath all adult dignity.\nPetrarchan poetry, often in the form of a Petrarchan sonnet, has been profoundly impacted by the myth of Narcissus. Most notably, Petrarch's Sonnet 45 contains themes and motifs inspired by the myth of Narcissus when the love interest, Laura, loves her reflection more than the narrator.\nVisual art.\nNarcissus has been a subject for many painters such as Caravaggio, Poussin, Turner, Dal\u00ed, Waterhouse, Carpioni, Lagren\u00e9e, and Roos.\nSculptors such as Paul Dubois, John Gibson, Henri-L\u00e9on Gr\u00e9ber, Benvenuto Cellini and Hubert Netzer have sculpted Narcissus.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22100", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=22100", "title": "Neo-Malthusian", "text": ""}
{"id": "22102", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=22102", "title": "Naval mine", "text": "Weapon for use in waters, triggered by the target's approach\nA naval mine is a self-contained explosive weapon placed in water to damage or destroy surface ships or submarines. Similar to anti-personnel and other land mines, and unlike purpose launched naval depth charges, they are deposited and left to wait until, depending on their fuzing, they are triggered by the approach of or contact with any vessel. \nNaval mines can be used offensively, to hamper enemy shipping movements or lock vessels into a harbour; or defensively, to create \"safe\" zones protecting friendly sea lanes, harbours, and naval assets. Mines allow the minelaying force commander to concentrate warships or defensive assets in mine-free areas giving the adversary three choices: undertake a resource-intensive and time-consuming minesweeping effort, accept the casualties of challenging the minefield, or use the unmined waters where the greatest concentration of enemy firepower will be encountered.\nAlthough international law requires signatory nations to declare mined areas, precise locations remain secret, and non-complying parties might not disclose minelaying. While mines threaten only those who choose to traverse waters that may be mined, the possibility of activating a mine is a powerful disincentive to shipping. In the absence of effective measures to limit each mine's lifespan, the hazard to shipping can remain long after the war in which the mines were laid is over. Unless detonated by a parallel time fuze at the end of their useful life, naval mines need to be found and dismantled after the end of hostilities; an often prolonged, costly, and hazardous task.\nModern mines containing high explosives detonated by complex electronic fuze mechanisms are much more effective than early gunpowder mines requiring physical ignition. Mines may be placed by aircraft, ships, submarines, or individual swimmers and boatmen. Minesweeping is the practice of the removal of explosive naval mines, usually by a specially designed ship called a minesweeper using various measures to either capture or detonate the mines, but sometimes also with an aircraft made for that purpose. There are also mines that release a homing torpedo rather than explode themselves.\nDescription.\nMines can be laid in many ways: by purpose-built minelayers, refitted ships, submarines, or aircraft\u2014and even by dropping them into a harbour by hand. They can be inexpensive: some variants can cost as little as US $2,000, though more sophisticated mines can cost millions of dollars, be equipped with several kinds of sensors, and deliver a warhead by rocket or torpedo.\nTheir flexibility and cost-effectiveness make mines attractive to the less powerful belligerent in asymmetric warfare. The cost of producing and laying a mine is usually between 0.5% and 10% of the cost of removing it, and it can take up to 200 times as long to clear a minefield as to lay it. Parts of some World War II naval minefields still exist because they are too extensive and expensive to clear. Some 1940s-era mines may remain dangerous for many years.\nMines have been employed as offensive or defensive weapons in rivers, lakes, estuaries, seas, and oceans, but they can also be used as tools of psychological warfare. Offensive mines are placed in enemy waters, outside harbours, and across important shipping routes to sink both merchant and military vessels. Defensive minefields safeguard key stretches of coast from enemy ships and submarines, forcing them into more easily defended areas, or keeping them away from sensitive ones.\nShipowners are reluctant to send their ships through known minefields. Port authorities may attempt to clear a mined area, but those without effective minesweeping equipment may cease using the area. Transit of a mined area will be attempted only when strategic interests outweigh potential losses. The decision-makers' perception of the minefield is a critical factor. Minefields designed for psychological effect are usually placed on trade routes to stop ships from reaching an enemy nation. They are often spread thinly, to create an impression of minefields existing across large areas. A single mine inserted strategically on a shipping route can stop maritime movements for days while the entire area is swept. A mine's capability to sink ships makes it a credible threat, but minefields work more on the mind than on ships.\nInternational law, specifically the Eighth Hague Convention of 1907, requires nations to declare when they mine an area, to make it easier for civil shipping to avoid the mines. The warnings do not have to be specific; for example, during World War II, Britain declared simply that it had mined the English Channel, North Sea and French coast.\nHistory.\nEarly use.\nNaval mines were first invented by Chinese innovators of Imperial China and were described in thorough detail by the early Ming dynasty artillery officer Jiao Yu, in his 14th-century military treatise known as the \"Huolongjing\". Chinese records tell of naval explosives in the 16th century, used to fight against Japanese pirates (\"wokou\"). This kind of naval mine was loaded in a wooden box, sealed with putty. General Qi Jiguang made several timed, drifting explosives, to harass Japanese pirate ships. The \"Tiangong Kaiwu\" (\"The Exploitation of the Works of Nature\") treatise, written by Song Yingxing in 1637, describes naval mines with a ripcord pulled by hidden ambushers located on the nearby shore who rotated a steel wheel flint mechanism to produce sparks and ignite the fuze of the naval mine. Although this is the rotating steel wheel's first use in naval mines, Jiao Yu described their use for land mines in the 14th century.\nThe first plan for a sea mine in the West was by Ralph Rabbards, who presented his design to Queen Elizabeth I of England in 1574. The Dutch inventor Cornelius Drebbel was employed in the Office of Ordnance by King Charles I of England to make weapons, including the failed \"floating petard\". Weapons of this type were apparently tried by the English at the Siege of La Rochelle in 1627.\nAmerican David Bushnell developed the first American naval mine, for use against the British in the American War of Independence. It was a watertight keg filled with gunpowder that was floated toward the enemy, detonated by a sparking mechanism if it struck a ship. It was used on the Delaware River as a drift mine, destroying a small boat near its intended target, a British warship.\nThe 19th century.\nThe 1804 Raid on Boulogne made extensive use of explosive devices designed by inventor Robert Fulton. The 'torpedo-catamaran' was a coffer-like device balanced on two wooden floats and steered by a man with a paddle. Weighted with lead so as to ride low in the water, the operator was further disguised by wearing dark clothes and a black cap. His task was to approach the French ship, hook the torpedo to the anchor cable and, having activated the device by removing a pin, remove the paddles and escape before the torpedo detonated. Also to be deployed were large numbers of casks filled with gunpowder, ballast and combustible balls. They would float in on the tide and on washing up against an enemy's hull, explode. Also included in the force were several fireships, carrying 40 barrels of gunpowder and rigged to explode by a clockwork mechanism.\nIn 1812, Russian engineer Pavel Shilling exploded an underwater mine using an electrical circuit. In 1842 Samuel Colt used an electric detonator to destroy a moving vessel to demonstrate an underwater mine of his own design to the United States Navy and President John Tyler. However, opposition from former president John Quincy Adams, scuttled the project as \"not fair and honest warfare\". In 1854, during the unsuccessful attempt of the Anglo-French (101 warships) fleet to seize the Kronstadt fortress, British steamships (9 June 1855, the first successful mining in Western history), and HMS \"Firefly\" suffered damage due to the underwater explosions of Russian naval mines. Russian naval specialists set more than 1,500 naval mines, or \"infernal machines\", designed by Moritz von Jacobi and by Immanuel Nobel, in the Gulf of Finland during the Crimean War of 1853\u20131856. The mining of \"Vulcan\" led to the world's first minesweeping operation. During the next 72 hours, 33 mines were swept.\nThe Jacobi mine was designed by German-born, Russian engineer Jacobi, in 1853. The mine was tied to the sea bottom by an anchor. A cable connected it to a galvanic cell which powered it from the shore, the power of its explosive charge was equal to of black powder. In the summer of 1853, the production of the mine was approved by the Committee for Mines of the Ministry of War of the Russian Empire. In 1854, 60 Jacobi mines were laid in the vicinity of the Forts Pavel and Alexander (Kronstadt), to deter the British Baltic Fleet from attacking them. It gradually phased out its direct competitor the Nobel mine on the insistence of Admiral Fyodor Litke. The Nobel mines were bought from Swedish industrialist Immanuel Nobel who had entered into collusion with the Russian head of navy Alexander Sergeyevich Menshikov. Despite their high cost (100 Russian rubles) the Nobel mines proved to be faulty, exploding while being laid, failing to explode or detaching from their wires, and drifting uncontrollably, at least 70 of them were subsequently disarmed by the British. In 1855, 301 more Jacobi mines were laid around Krostadt and Lisy Nos. British ships did not dare to approach them.\nIn the 19th century, mines were called torpedoes, a name probably conferred by Robert Fulton after the torpedo fish, which gives powerful electric shocks. A spar torpedo was a mine attached to a long pole and detonated when the ship carrying it rammed another one and withdrew a safe distance. The submarine used one to sink on 17 February 1864. A Harvey torpedo was a type of floating mine towed alongside a ship and was briefly in service in the Royal Navy in the 1870s. Other \"torpedoes\" were attached to ships or propelled themselves. One such weapon called the Whitehead torpedo after its inventor, caused the word \"torpedo\" to apply to self-propelled underwater missiles as well as to static devices. These mobile devices were also known as \"fish torpedoes\".\nThe American Civil War of 1861\u20131865 also saw the successful use of mines. The first ship sunk by a mine, , foundered in 1862 in the Yazoo River. Rear Admiral David Farragut's famous command during the Battle of Mobile Bay in 1864, \"Damn the torpedoes, full speed ahead!\" refers to a minefield laid at Mobile, Alabama.\nAfter 1865 the United States adopted the mine as its primary weapon for coastal defense. In the decade following 1868, Major Henry Larcom Abbot carried out a lengthy set of experiments to design and test moored mines that could be exploded on contact or be detonated at will as enemy shipping passed near them. This initial development of mines in the United States took place under the purview of the US Army Corps of Engineers, which trained officers and men in their use at the Engineer School of Application at Willets Point, New York (later named Fort Totten). In 1901 underwater minefields became the responsibility of the US Army's Artillery Corps, and in 1907 this was a founding responsibility of the United States Army Coast Artillery Corps.\nThe Imperial Russian Navy, a pioneer in mine warfare, successfully deployed mines against the Ottoman Navy during both the Crimean War and the Russo-Turkish War (1877-1878).\nDuring the War of the Pacific (1879-1883), the Peruvian Navy, at a time when the Chilean squadron was blockading the Peruvian ports, formed a brigade of torpedo boats under the command of the frigate captain Leopoldo S\u00e1nchez Calder\u00f3n and the Peruvian engineer , who perfected the naval torpedo or mine system to be electrically activated when the cargo weight was lifted. This system was employed on 3 July 1880, in front of the port of Callao, when the gunned transport ' was sunk while capturing a sloop mined by the Peruvians. A similar fate occurred to the gunboat schooner ' in front of the port of Chancay, on 13 September 1880 when a captured pleasure boat exploded while being hoisted on its side.\nDuring the Battle of Tamsui (1884), in the Keelung Campaign of the Sino-French War, Chinese forces in Taiwan under Liu Mingchuan took measures to reinforce Tamsui against the French; they planted nine torpedo mines in the river and blocked the entrance.\nEarly 20th century.\nDuring the Boxer Rebellion, Imperial Chinese forces deployed a command-detonated mine field at the mouth of the Hai River before the Dagu forts, to prevent the western Allied forces from sending ships to attack.\nThe next major use of mines was during the Russo-Japanese War of 1904\u20131905. Two mines blew up when the struck them near Port Arthur, sending the holed vessel to the bottom and killing the fleet commander, Admiral Stepan Makarov, and most of his crew in the process. The toll inflicted by mines was not confined to the Russians, however. The Japanese Navy lost two battleships, four cruisers, two destroyers and a torpedo-boat to offensively laid mines during the war. Most famously, on 15 May 1904, the Russian minelayer \"Amur\" planted a 50-mine minefield off Port Arthur and succeeded in sinking the Japanese battleships and .\nFollowing the end of the Russo-Japanese War, several nations attempted to have mines banned as weapons of war at the Hague Peace Conference (1907).\nMany early mines were fragile and dangerous to handle, as they contained glass containers filled with nitroglycerin or mechanical devices that activated a blast upon tipping. Several mine-laying ships were destroyed when their cargo exploded.\nBeginning around the start of the 20th century, submarine mines played a major role in the defense of US harbours against enemy attacks as part of the Endicott and Taft Programs. The mines employed were controlled mines, anchored to the bottoms of the harbours, and detonated under control from large mine casemates onshore.\nDuring World War I, mines were used extensively to defend coasts, coastal shipping, ports and naval bases around the globe. The Germans laid mines in shipping lanes to sink merchant and naval vessels serving Britain. The Allies targeted the German U-boats in the Strait of Dover and the Hebrides. In an attempt to seal up the northern exits of the North Sea, the Allies developed the North Sea Mine Barrage. During a period of five months from June 1918, almost 70,000 mines were laid spanning the North Sea's northern exits. The total number of mines laid in the North Sea, the British East Coast, Straits of Dover, and Heligoland Bight is estimated at 190,000 and the total number during the whole of WWI was 235,000 sea mines. Clearing the barrage after the war took 82 ships and five months, working around the clock. It was also during World War I, that the British hospital ship, , became the largest vessel ever sunk by a naval mine. The \"Britannic\" was the sister ship of the RMS \"Titanic\", and the .\nWorld War II.\nDuring World War II, the U-boat fleet, which dominated much of the battle of the Atlantic, was small at the beginning of the war and much of the early action by German forces involved mining convoy routes and ports around Britain. German submarines also operated in the Mediterranean Sea, in the Caribbean Sea, and along the US coast.\nInitially, contact mines (requiring a ship to physically strike a mine to detonate it) were employed, usually tethered at the end of a cable just below the surface of the water. Contact mines usually blew a hole in ships' hulls. By the beginning of World War II, most nations had developed mines that could be dropped from aircraft, some of which floated on the surface, making it possible to lay them in enemy harbours. The use of dredging and nets was effective against this type of mine, but this consumed valuable time and resources and required harbours to be closed.\nLater, some ships survived mine blasts, limping into port with buckled plates and broken backs. This appeared to be due to a new type of mine, detecting ships by their proximity to the mine (an influence mine) and detonating at a distance, causing damage with the shock wave of the explosion. Ships that had successfully run the gantlet of the Atlantic crossing were sometimes destroyed entering freshly cleared British harbours. More shipping was being lost than could be replaced, and Churchill ordered the intact recovery of one of these new mines to be of the highest priority.\nThe British experienced a stroke of luck in November 1939, when a German mine was dropped from an aircraft onto the mudflats off Shoeburyness during low tide. Additionally, the land belonged to the army and a base with men and workshops was at hand. Experts were dispatched from to investigate the mine. The Royal Navy knew that mines could use magnetic sensors, Britain having developed magnetic mines in World War I, so everyone removed all metal, including their buttons, and made tools of non-magnetic brass. They disarmed the mine and rushed it to the labs at HMS Vernon, where scientists discovered that the mine had a magnetic arming mechanism. A large ferrous object passing through the Earth's magnetic field will concentrate the field through it, due to its magnetic permeability; the mine's detector was designed to trigger as a ship passed over when the Earth's magnetic field was concentrated in the ship and away from the mine. The mine detected this loss of the magnetic field which caused it to detonate. The mechanism had an adjustable sensitivity, calibrated in milligauss.\nFrom this data, known methods were used to clear these mines. Early methods included the use of large electromagnets dragged behind ships or below low-flying aircraft (a number of older bombers like the Vickers Wellington were used for this). Both of these methods had the disadvantage of \"sweeping\" only a small strip. A better solution was found in the \"Double-L Sweep\" using electrical cables dragged behind ships that passed large pulses of current through the seawater. This created a large magnetic field and swept the entire area between the two ships. The older methods continued to be used in smaller areas. The Suez Canal continued to be swept by aircraft, for instance.\nWhile these methods were useful for clearing mines from local ports, they were of little or no use for enemy-controlled areas. These were typically visited by warships, and the majority of the fleet then underwent a massive degaussing process, where their hulls had a slight \"south\" bias induced into them which offset the concentration-effect almost to zero.\nInitially, major warships and large troopships had a copper \"degaussing coil\" fitted around the perimeter of the hull, energized by the ship's electrical system whenever in suspected magnetic-mined waters. Some of the first to be so fitted were the carrier and the liners and . It was a photo of one of these liners in New York harbour, showing the degaussing coil, which revealed to German Naval Intelligence the fact that the British were using degaussing methods to combat their magnetic mines. This was felt to be impractical for smaller warships and merchant vessels, mainly because the ships lacked the generating capacity to energise such a coil. It was found that \"wiping\" a current-carrying cable up and down a ship's hull temporarily canceled the ships' magnetic signature sufficiently to nullify the threat. This started in late 1939, and by 1940 merchant vessels and the smaller British warships were largely immune for a few months at a time until they once again built up a field.\nThe cruiser is just one example of a ship that was struck by a magnetic mine during this time. On 21 November 1939, a mine broke her keel, which damaged her engine and boiler rooms, as well as injuring 46 men, one later died from his injuries. She was towed to Rosyth for repairs. Incidents like this resulted in many of the boats that sailed to Dunkirk being degaussed in a marathon four-day effort by degaussing stations.\nThe Allies and Germany deployed acoustic mines in World War II, against which even wooden-hulled ships (in particular minesweepers) remained vulnerable. Japan developed sonic generators to sweep these; the gear was not ready by war's end. The primary method Japan used was small air-delivered bombs. This was profligate and ineffectual; used against acoustic mines at Penang, 200 bombs were needed to detonate just 13 mines.\nThe Germans developed a pressure-activated mine and planned to deploy it as well, but they saved it for later use when it became clear the British had defeated the magnetic system. The US also deployed these, adding \"counters\" which would allow a variable number of ships to pass unharmed before detonating. This made them a great deal harder to sweep.\nMining campaigns could have devastating consequences. The US effort against Japan, for instance, closed major ports, such as Hiroshima, for days, and by the end of the Pacific War had cut the amount of freight passing through Kobe\u2013Yokohama by 90%.\nWhen the war ended, more than 25,000 US-laid mines were still in place, and the Navy proved unable to sweep them all, limiting efforts to critical areas. After sweeping for almost a year, in May 1946, the Navy abandoned the effort with 13,000 mines still unswept. Over the next thirty years, more than 500 minesweepers (of a variety of types) were damaged or sunk clearing them.\nThe US began adding delay counters to their magnetic mines in June 1945.\nCold War era.\nSince World War II, mines have damaged 14 United States Navy ships, whereas air and missile attacks have damaged four. During the Korean War, mines laid by North Korean forces caused 70% of the casualties suffered by US naval vessels and caused 4 sinkings.\nDuring the Iran\u2013Iraq War from 1980 to 1988, the belligerents mined several areas of the Persian Gulf and nearby waters. On 24 July 1987, the supertanker \"SS\" Bridgeton was mined by Iran near Farsi Island. On 14 April 1988, struck an Iranian mine in the central Persian Gulf shipping lane, wounding 10 sailors.\nIn the summer of 1984, magnetic sea mines damaged at least 19 ships in the Red Sea. The US concluded Libya was probably responsible for the minelaying. In response the US, Britain, France, and three other nations launched \"Operation Intense Look\", a minesweeping operation in the Red Sea involving more than 46 ships.\nOn the orders of the Reagan administration, the CIA mined Nicaragua's Sandino port in 1984 in support of the Contras. A Soviet tanker was among the ships damaged by these mines. In 1986, in the case of \"Nicaragua v. United States\", the International Court of Justice ruled that this mining was a violation of international law.\nPost Cold War.\nDuring the Gulf War, Iraqi naval mines severely damaged and . When the war concluded, eight countries conducted clearance operations.\nHouthi forces in the Yemeni Civil War have made frequent use of naval mines, laying over 150 in the Red Sea throughout the conflict.\nIn the first month of the 2022 Russian invasion of Ukraine, Ukraine accused Russia of deliberately employing drifting mines in the Black Sea area. Around the same time, Turkish and Romanian military diving teams were involved in defusing operations, when stray mines were spotted near the coasts of these countries. London P&amp;I Club issued a warning to freight ships in the area, advising them to \"maintain lookouts for mines and pay careful attention to local navigation warnings\". Ukrainian forces have mined \"from the Sea of Azov to the Black Sea which banks the critical city of Odesa.\"\nTypes.\nNaval mines may be classified into three major groups; contact, remote and influence mines.\nContact mines.\nThe earliest mines were usually of this type. They are still used today, as they are extremely low cost compared to any other anti-ship weapon and are effective, both as a psychological weapon and as a method to sink enemy ships. Contact mines need to be touched by the target before they detonate, limiting the damage to the direct effects of the explosion and usually affecting only the vessel that triggers them.\nEarly mines had mechanical mechanisms to detonate them, but these were superseded in the 1870s by the \"Hertz horn\" (or \"chemical horn\"), which was found to work reliably even after the mine had been in the sea for several years. The mine's upper half is studded with hollow lead protuberances, each containing a glass vial filled with sulfuric acid. When a ship's hull crushes the metal horn, it cracks the vial inside it, allowing the acid to run down a tube and into a lead\u2013acid battery which until then contained no acid electrolyte. This energizes the battery, which detonates the explosive.\nEarlier forms of the detonator employed a vial of sulfuric acid surrounded by a mixture of potassium perchlorate and sugar. When the vial was crushed, the acid ignited the perchlorate-sugar mix, and the resulting flame ignited the gunpowder charge.\nDuring the initial period of World War I, the Royal Navy used contact mines in the English Channel and later in large areas of the North Sea to hinder patrols by German submarines. Later, the American antenna mine was widely used because submarines could be at any depth from the surface to the seabed. This type of mine had a copper wire attached to a buoy that floated above the explosive charge which was weighted to the seabed with a steel cable. If a submarine's steel hull touched the copper wire, the slight voltage change caused by contact between two dissimilar metals was amplified and detonated the explosives.\nLimpet mines.\nLimpet mines are a special form of contact mine that are manually attached to the target by magnets and remain in place. They are named because of the similarity to the limpet, a mollusk.\nMoored contact mines.\nGenerally, this type of mine is set to float just below the surface of the water or as deep as five meters. A steel cable connecting the mine to an anchor on the seabed prevents it from drifting away. The explosive and detonating mechanism is contained in a buoyant metal or plastic shell. The depth below the surface at which the mine floats can be set so that only deep draft vessels such as aircraft carriers, battleships or large cargo ships are at risk, saving the mine from being used on a less valuable target. In littoral waters it is important to ensure that the mine does not become visible when the sea level falls at low tide, so the cable length is adjusted to take account of tides. During WWII there were mines that could be moored in water.\nFloating mines typically have a mass of around , including of explosives e.g. TNT, minol or amatol.\nMoored contact mines with plummet.\nA special form of moored contact mines are those equipped with a plummet. When the mine is launched (1), the mine with the anchor floats first and the lead plummet sinks from it (2). In doing so, the plummet unwinds a wire, the deep line, which is used to set the depth of the mine below the water surface before it is launched (3). When the deep line has been unwound to a set length, the anchor is flooded and the mine is released from the anchor (4). The anchor begins to sink and the mooring cable unwinds until the plummet reaches the sea floor (5). Triggered by the decreasing tension on the deep line, the mooring cable is clamped. The anchor continues sinking down to the bottom of the sea, pulling the mine below the water surface to a depth equal to the length of the deep line (6). Thus, even without knowing the exact seafloor depth, an exact depth of the mine below the water surface can be set, limited only by the maximum length of the mooring cable.\nDrifting contact mines.\nDrifting mines were occasionally used during World War I and World War II. However, they were more feared than effective. Sometimes floating mines break from their moorings and become drifting mines; modern mines are designed to deactivate in this event. After several years at sea, the deactivation mechanism might not function as intended and the mines may remain live. Admiral Jellicoe's British fleet did not pursue and destroy the outnumbered German High Seas Fleet when it turned away at the Battle of Jutland because he thought they were leading him into a trap: he believed it possible that the Germans were either leaving floating mines in their wake, or were drawing him towards submarines, although neither of these was the case.\nAfter World War I the drifting contact mine was banned, but was occasionally used during World War II. The drifting mines were much harder to remove than tethered mines after the war, and they caused about the same damage to both sides.\nChurchill promoted \"Operation Royal Marine\" in 1940 and again in 1944 where floating mines were put into the Rhine in France to float down the river, becoming active after a time calculated to be long enough to reach German territory.\nRemotely controlled mines.\nFrequently used in combination with coastal artillery and hydrophones, controlled mines (or command detonation mines) can be in place in peacetime, which is a huge advantage in blocking important shipping routes. The mines can usually be turned into \"normal\" mines with a switch (which prevents the enemy from simply capturing the controlling station and deactivating the mines), detonated on a signal or be allowed to detonate on their own. The earliest ones were developed around 1812 by Robert Fulton. The first remotely controlled mines were moored mines used in the American Civil War, detonated electrically from shore. They were considered superior to contact mines because they did not put friendly shipping at risk. The extensive American fortifications program initiated by the Board of Fortifications in 1885 included remotely controlled mines, which were emplaced or in reserve from the 1890s until the end of World War II.\nModern examples usually weigh , including of explosives (TNT or torpex).\nInfluence mines.\nThese mines are triggered by the influence of a ship or submarine, rather than direct contact. Such mines incorporate sensors designed to detect the presence of a vessel and detonate when it comes within the blast range of the warhead. The fuzes on such mines may incorporate one or more of the following sensors: magnetic, passive acoustic or water pressure displacement caused by the proximity of a vessel.\nFirst used during WWI, their use became more general in WWII. The sophistication of influence mine fuzes has increased considerably over the years as first transistors and then microprocessors have been incorporated into designs. Simple magnetic sensors have been superseded by total-field magnetometers. Whereas early magnetic mine fuzes would respond only to changes in a single component of a target vessel's magnetic field, a total field magnetometer responds to changes in the magnitude of the total background field (thus enabling it to better detect even degaussed ships). Similarly, the original broadband hydrophones of 1940s acoustic mines (which operate on the integrated volume of all frequencies) have been replaced by narrow-band sensors which are much more sensitive and selective. Mines can now be programmed to listen for highly specific acoustic signatures (e.g. a gas turbine powerplant or cavitation sounds from a particular design of propeller) and ignore all others. The sophistication of modern electronic mine fuzes incorporating these digital signal processing capabilities makes it much more difficult to detonate the mine with electronic countermeasures because several sensors working together (e.g. magnetic, passive acoustic and water pressure) allow it to ignore signals which are not recognised as being the unique signature of an intended target vessel.\nModern influence mines such as the BAE Stonefish are computerised, with all the programmability this implies, such as the ability to quickly load new acoustic signatures into fuzes, or program them to detect a single, highly distinctive target signature. In this way, a mine with a passive acoustic fuze can be programmed to ignore all friendly vessels and small enemy vessels, only detonating when a very large enemy target passes over it. Alternatively, the mine can be programmed specifically to ignore all surface vessels regardless of size and exclusively target submarines.\nEven as far back as WWII it was possible to incorporate a \"ship counter\" function in mine fuzes. This might set the mine to ignore the first two ships passing over it (which could be minesweepers deliberately trying to trigger mines) but detonate when the third ship passes overhead, which could be a high-value target such as an aircraft carrier or oil tanker. Even though modern mines are generally powered by a long life lithium battery, it is important to conserve power because they may need to remain active for months or even years. For this reason, most influence mines are designed to remain in a semi-dormant state until an unpowered (e.g. deflection of a mu-metal needle) or low-powered sensor detects the possible presence of a vessel, at which point the mine fuze powers up fully and the passive acoustic sensors will begin to operate for some minutes. It is possible to program computerised mines to delay activation for days or weeks after being laid. Similarly, they can be programmed to self-destruct or render themselves safe after a preset period of time. Generally, the more sophisticated the mine design, the more likely it is to have some form of anti-handling device to hinder clearance by divers or remotely piloted submersibles.\nMoored mines.\nThe moored mine is the backbone of modern mine systems. They are deployed where water is too deep for bottom mines. They can use several kinds of instruments to detect an enemy, usually a combination of acoustic, magnetic and pressure sensors, or more sophisticated optical shadows or electro potential sensors. These cost many times more than contact mines. Moored mines are effective against most kinds of ships. As they are cheaper than other anti-ship weapons they can be deployed in large numbers, making them useful area denial or \"channelizing\" weapons.\nMoored mines usually have lifetimes of more than 10 years, and some almost unlimited. These mines usually weigh , including of explosives (RDX). In excess of of explosives the mine becomes inefficient, as it becomes too large to handle and the extra explosives add little to the mine's effectiveness.\nBottom mines.\nBottom mines (sometimes called ground mines) are used when the water is no more than deep or when mining for submarines down to around . They are much harder to detect and sweep, and can carry a much larger warhead than a moored mine. Bottom mines commonly use multiple types of sensors, which are less sensitive to sweeping.\nThese mines usually weigh between , including between of explosives.\nUnusual mines.\nSeveral specialized mines have been developed for other purposes than the common minefield.\nBouquet mine.\nThe bouquet mine is a single anchor attached to several floating mines. It is designed so that when one mine is swept or detonated, another takes its place. It is a very sensitive construction and lacks reliability.\nAnti-sweep mine.\nThe anti-sweep mine is a very small mine ( warhead) with as small a floating device as possible. When the wire of a mine sweep hits the anchor wire of the mine, it drags the anchor wire along with it, pulling the mine down into contact with the sweeping wire. That detonates the mine and cuts the sweeping wire. They are very cheap and usually used in combination with other mines in a minefield to make sweeping more difficult. One type is the Mark 23 used by the United States during World War II.\nOscillating mine.\nThe mine is hydrostatically controlled to maintain a pre-set depth below the water's surface independently of the rise and fall of the tide.\nAscending mine.\nThe ascending mine is a floating distance mine that may cut its mooring or in some other way float higher when it detects a target. It lets a single floating mine cover a much larger depth range.\nHoming mines.\nThese are mines containing a moving weapon as a warhead, either a torpedo or a rocket.\nRocket mine.\nA Russian invention, the rocket mine is a bottom distance mine that fires a homing high-speed rocket (not torpedo) upwards towards the target. It is intended to allow a bottom mine to attack surface ships as well as submarines from a greater depth. One type is the Te-1 rocket propelled mine.\nTorpedo mine.\nA torpedo mine is a self-propelled variety, able to lie in wait for a target and then pursue it e.g. the Mark 60 CAPTOR. Generally, torpedo mines incorporate computerised acoustic and magnetic fuzes. The US Mark 24 \"mine\", code-named Fido, was actually an ASW homing torpedo. The mine designation was disinformation to conceal its function.\nMobile mine.\nThe mine is propelled to its intended position by propulsion equipment such as a torpedo. After reaching its destination, it sinks to the seabed and operates like a standard mine. It differs from the homing mine in that its mobile stage is set before it lies in wait, rather than as part of the attacking phase.\nOne such design is the Mk 67 Submarine Launched Mobile Mine (which is based on a Mark 37 torpedo), capable of traveling as far as through or into a channel, harbour, shallow water area, and other zones which would normally be inaccessible to craft laying the device. After reaching the target area they sink to the sea bed and act like conventionally laid influence mines.\nNuclear mine.\nDuring the Cold War, a test was conducted with a naval mine fitted with tactical nuclear warheads for the \"Baker\" shot of Operation Crossroads. This weapon was experimental and never went into production. The Seabed Arms Control Treaty prohibits the placement of nuclear weapons on the seabed beyond a 12-mile coast zone.\nDaisy-chained mine.\nThis comprises two moored, floating contact mines which are tethered together by a length of steel cable or chain. Typically, each mine is situated approximately away from its neighbor, and each floats a few meters below the surface of the ocean. When the target ship hits the steel cable, the mines on either side are drawn down the side of the ship's hull, exploding on contact. In this manner it is almost impossible for target ships to pass safely between two individually moored mines. Daisy-chained mines are a very simple concept which was used during World War II. The first prototype of the Daisy-chained mine and the first combat use came in Finland, 1939.\nDummy mine.\nPlastic drums filled with sand or concrete are periodically rolled off the side of ships as real mines are laid in large mine-fields. These inexpensive false targets (designed to be of a similar shape and size as genuine mines) are intended to slow down the process of mine clearance: a mine-hunter is forced to investigate each suspicious sonar contact on the sea bed, whether it is real or not. Often a maker of naval mines will provide both training and dummy versions of their mines.\nMine laying.\nHistorically several methods were used to lay mines. During WWI and WWII, the Germans used U-boats to lay mines around the UK. In WWII, aircraft came into favour for mine laying with one of the largest examples being the mining of the Japanese sea routes in Operation Starvation.\nLaying a minefield is a relatively fast process with specialized ships, which is today the most common method. These minelayers can carry several thousand mines and manoeuvre with high precision. The mines are dropped at predefined intervals into the water behind the ship. Each mine is recorded for later clearing, but it is not unusual for these records to be lost together with the ships. Therefore, many countries demand that all mining operations be planned on land and records kept so that the mines can later be recovered more easily.\nOther methods to lay minefields include:\nIn some cases, mines are automatically activated upon contact with the water. In others, a safety lanyard is pulled (one end attached to the rail of a ship, aircraft or torpedo tube) which starts an automatic timer countdown before the arming process is complete. Typically, the automatic safety-arming process takes some minutes to complete. This allows the people laying the mines sufficient time to move out of its activation and blast zones.\nAerial mining in World War II.\nGermany.\nIn the 1930s, Germany had experimented with the laying of mines by aircraft. It became a crucial element in their overall mining strategy. Aircraft had the advantage of speed, and they would never get caught in their own minefields. German mines held a large explosive charge. From April to June 1940, the Luftwaffe laid 1,000 mines in British waters. Soviet ports were mined, as was the Arctic convoy route to Murmansk. The Heinkel He 115 could carry two medium or one large mine while the Heinkel He 59, Dornier Do 18, Junkers Ju 88 and Heinkel He 111 could carry more.\nSoviet Union.\nThe USSR was relatively ineffective in its use of naval mines in WWII in comparison with its record in previous wars. Small mines were developed for use in rivers and lakes, and special mines for shallow water. A very large chemical mine was designed to sink through ice with the aid of a melting compound. Special aerial mine designs finally arrived in 1943\u20131944, the AMD-500 and AMD-1000. Various Soviet Naval Aviation torpedo bombers were pressed into the role of aerial mining in the Baltic Sea and the Black Sea, including Ilyushin DB-3s, Il-4s and Lend-Lease Douglas Boston IIIs.\nUnited Kingdom.\nIn September 1939, the UK announced the placement of extensive defensive minefields in waters surrounding the Home Islands. Offensive aerial mining operations began in April 1940 when 38 mines were laid at each of these locations: the Elbe River, the port of L\u00fcbeck and the German naval base at Kiel. In the next 20 months, mines delivered by aircraft sank or damaged 164 Axis ships with the loss of 94 aircraft. By comparison, direct aerial attacks on Axis shipping had sunk or damaged 105 vessels at a cost of 373 aircraft lost. The advantage of aerial mining became clear, and the UK prepared for it. A total of 48,000 aerial mines were laid by the Royal Air Force (RAF) in the European Theatre during World War II.\nUnited States.\nAs early as 1942, American mining experts such as Naval Ordnance Laboratory scientist Dr. Ellis A. Johnson, CDR USNR, suggested massive aerial mining operations against Japan's \"outer zone\" (Korea and northern China) as well as the \"inner zone\", their home islands. First, aerial mines would have to be developed further and manufactured in large numbers. Second, laying the mines would require a sizable air group. The US Army Air Forces had the carrying capacity but considered mining to be the navy's job. The US Navy lacked suitable aircraft. Johnson set about convincing General Curtis LeMay of the efficacy of heavy bombers laying aerial mines.\nB-24 Liberators, PBY Catalinas and other bomber aircraft took part in localized mining operations in the Southwest Pacific and the China Burma India (CBI) theaters, beginning with a successful attack on the Yangon River in February 1943. Aerial minelaying operations involved a coalition of British, Australian and American aircrews, with the RAF and the Royal Australian Air Force (RAAF) carrying out 60% of the sorties and the USAAF and US Navy covering 40%. Both British and American mines were used. Japanese merchant shipping suffered tremendous losses, while Japanese mine sweeping forces were spread too thin attending to far-flung ports and extensive coastlines. Admiral Thomas C. Kinkaid, who directed nearly all RAAF mining operations in CBI, heartily endorsed aerial mining, writing in July 1944 that \"aerial mining operations were of the order of 100 times as destructive to the enemy as an equal number of bombing missions against land targets.\"\nA single B-24 dropped three mines into Haiphong harbour in October 1943. One of those mines sank a Japanese freighter. Another B-24 dropped three more mines into the harbour in November, and a second freighter was sunk by a mine. The threat of the remaining mines prevented a convoy of ten ships from entering Haiphong, and six of those ships were sunk by attacks before they reached a safe harbour. The Japanese closed Haiphong to all steel-hulled ships for the remainder of the war after another small ship was sunk by one of the remaining mines, although they may not have realized no more than three mines remained.\nUsing Grumman TBF Avenger torpedo bombers, the US Navy mounted a direct aerial mining attack on enemy shipping in Palau on 30 March 1944 in concert with simultaneous conventional bombing and strafing attacks. The dropping of 78 mines deterred 32 Japanese ships from escaping Koror harbour, and 23 of those immobilized ships were sunk in a subsequent bombing raid. The combined operation sank or damaged 36 ships. Two Avengers were lost, and their crews were recovered. The mines brought port usage to a halt for 20 days. Japanese mine sweeping was unsuccessful; and the Japanese abandoned Palau as a base when their first ship attempting to traverse the swept channel was damaged by a mine detonation.\nIn March 1945, Operation Starvation began in earnest, using 160 of LeMay's B-29 Superfortress bombers to attack Japan's inner zone. Almost half of the mines were the US-built Mark 25 model, carrying of explosives and weighing about . Other mines used included the smaller Mark 26. Fifteen B-29s were lost while 293 Japanese merchant ships were sunk or damaged. Twelve thousand aerial mines were laid, a significant barrier to Japan's access to outside resources. Prince Fumimaro Konoe said after the war that the aerial mining by B-29s had been \"equally as effective as the B-29 attacks on Japanese industry at the closing stages of the war when all food supplies and critical material were prevented from reaching the Japanese home islands.\" The United States Strategic Bombing Survey (Pacific War) concluded that it would have been more efficient to combine the United States's effective anti-shipping submarine effort with land- and carrier-based air power to strike harder against merchant shipping and begin a more extensive aerial mining campaign earlier in the war. Survey analysts projected that this would have starved Japan, forcing an earlier end to the war. After the war, Dr. Johnson looked at the Japan inner zone shipping results, comparing the total economic cost of submarine-delivered mines versus air-dropped mines and found that, though 1 in 12 submarine mines connected with the enemy as opposed to 1 in 21 for aircraft mines, the aerial mining operation was about ten times less expensive per enemy ton sunk.\nClearing WWII aerial mines.\nBetween 600,000 and 1,000,000 naval mines of all types were laid in WWII. Advancing military forces worked to clear mines from newly-taken areas, but extensive minefields remained in place after the war. Air-dropped mines had an additional problem for mine sweeping operations: they were not meticulously charted. In Japan, much of the B-29 mine-laying work had been performed at high altitude, with the drifting on the wind of mines carried by parachute adding a randomizing factor to their placement. Generalized danger areas were identified, with only the quantity of mines given in detail. Mines used in Operation Starvation were supposed to be self-sterilizing, but the circuit did not always work. Clearing the mines from Japanese waters took so many years that the task was eventually given to the Japan Maritime Self-Defense Force.\nFor the purpose of clearing all types of naval mines, the Royal Navy employed German crews and minesweepers from June 1945 to January 1948, organised in the German Mine Sweeping Administration (GMSA), which consisted of 27,000 members of the former \"Kriegsmarine\" and 300 vessels. Mine clearing was not always successful: a number of ships were damaged or sunk by mines after the war. Two such examples were the liberty ships \"Pierre Gibault\" which was scrapped after hitting a mine in a previously cleared area off the Greek island of Kythira in June 1945, and \"Nathaniel Bacon\" which hit a minefield off Civitavecchia, Italy in December 1945, caught fire, was beached, and broke in two.\nDamage.\nThe damage that may be caused by a mine depends on the \"shock factor value\", a combination of the initial strength of the explosion and of the distance between the target and the detonation. When taken in reference to ship hull plating, the term \"Hull Shock Factor\" (HSF) is used, while keel damage is termed \"Keel Shock Factor\" (KSF). If the explosion is directly underneath the keel, then HSF is equal to KSF, but explosions that are not directly underneath the ship will have a lower value of KSF.\nDirect damage.\nUsually only created by contact mines, direct damage is a hole blown in the ship. Among the crew, fragmentation wounds are the most common form of damage. Flooding typically occurs in one or two main watertight compartments, which can sink smaller ships or disable larger ones. Contact mine damage often occurs at or close to the waterline near the bow, but depending on circumstances a ship could be hit anywhere on its outer hull surface (the mine attack being a good example of a contact mine detonating amidships and underneath the ship).\nBubble jet effect.\nThe bubble jet effect occurs when a mine or torpedo detonates in the water a short distance away from the targeted ship. The explosion creates a bubble in the water, and due to the difference in pressure, the bubble will collapse from the bottom. The bubble is buoyant, and so it rises towards the surface. If the bubble reaches the surface as it collapses, it can create a pillar of water that can go over a hundred meters into the air (a \"columnar plume\"). If conditions are right and the bubble collapses onto the ship's hull, the damage to the ship can be extremely serious; the collapsing bubble forms a high-energy jet similar to a shaped charge that can break a metre-wide hole straight through the ship, flooding one or more compartments, and is capable of breaking smaller ships apart. The crew in the areas hit by the pillar are usually killed instantly. Other damage is usually limited.\nThe Baengnyeong incident, in which the ROKS \"Cheonan\" broke in half and sank off the coast South Korea in 2010, was caused by the bubble jet effect, according to an international investigation.\nShock effect.\nIf the mine detonates at a distance from the ship, the change in water pressure causes the ship to resonate. This is frequently the most deadly type of explosion, if it is strong enough. The whole ship is dangerously shaken and everything on board is tossed around. Engines rip from their beds, cables from their holders, etc. A badly shaken ship usually sinks quickly, with hundreds, or even thousands of small leaks all over the ship and no way to power the pumps. The crew fare no better, as the violent shaking tosses them around. This shaking is powerful enough to cause disabling injury to knees and other joints in the body, particularly if the affected person stands on surfaces connected directly to the hull (such as steel decks).\nThe resulting gas cavitation and shock-front-differential over the width of the human body is sufficient to stun or kill divers.\nCountermeasures.\nWeapons are frequently a few steps ahead of countermeasures, and mines are no exception. In this field the British, with their large seagoing navy, have had the bulk of world experience, and most anti-mine developments, such as degaussing and the double-L sweep, were British inventions. When on operational missions, such as the invasion of Iraq, the US still relies on British and Canadian minesweeping services. The US has worked on some innovative mine-hunting countermeasures, such as the use of military dolphins to detect and flag mines. Mines in nearshore environments remain a particular challenge. They are small and as technology has developed they can have anechoic coatings, be non-metallic, and oddly shaped to resist detection. Further, oceanic conditions and the sea bottoms of the area of operations can degrade sweeping and hunting efforts. Mining countermeasures are far more expensive and time-consuming than mining operations, and that gap is only growing with new technologies.\nPassive countermeasures.\nShips can be designed to be difficult for mines to detect, to avoid detonating them. This is especially true for minesweepers and mine hunters that work in minefields, where a minimal signature outweighs the need for armour and speed. These ships have hulls of glass fibre or wood instead of steel to avoid magnetic signatures. These ships may use special propulsion systems, with low magnetic electric motors, to reduce magnetic signature, and Voith-Schneider propellers, to limit the acoustic signature. They are built with hulls that produce a minimal pressure signature. These measures create other problems. They are expensive, slow, and vulnerable to enemy fire. Many modern ships have a mine-warning sonar\u2014a simple sonar looking forward and warning the crew if it detects possible mines ahead. It is only effective when the ship is moving slowly. \nA steel-hulled ship can be \"degaussed\" (more correctly, de-oerstedted or depermed) using a special degaussing station that contains many large coils and induces a magnetic field in the hull with alternating current to demagnetize the hull. This is a rather problematic solution, as magnetic compasses need recalibration and all metal objects must be kept in exactly the same place. Ships slowly regain their magnetic field as they travel through the Earth's magnetic field, so the process has to be repeated every six months.\nA simpler variation of this technique called \"wiping\", was developed by Charles F. Goodeve which saved time and resources.\nBetween 1941 and 1943 the US Naval Gun factory (a division of the Naval Ordnance Laboratory) in Washington, D.C., built physical models of all US naval ships. Three kinds of steel were used in shipbuilding: mild steel for bulkheads, a mixture of mild steel and high tensile steel for the hull, and special treatment steel for armor plate. The models were placed within coils which could simulate the Earth's magnetic field at any location. The magnetic signatures were measured with degaussing coils. The objective was to reduce the vertical component of the combination of the Earth's field and the ship's field at the usual depth of German mines. From the measurements, coils were placed and coil currents were determined to minimize the chance of detonation for any ship at any heading at any latitude.\nSome ships are built with magnetic inductors, large coils placed along the ship to counter the ship's magnetic field. Using magnetic probes in strategic parts of the ship, the strength of the current in the coils can be adjusted to minimize the total magnetic field. This is a heavy and clumsy solution, suited only to small-to-medium-sized ships. Boats typically lack the generators and space for the solution, while the amount of power needed to overcome the magnetic field of a large ship is impractical.\nActive countermeasures.\nActive countermeasures are ways to clear a path through a minefield or remove it completely. This is one of the most important tasks of any mine warfare flotilla.\nMine sweeping.\nA sweep is either a contact sweep, a wire dragged through the water by one or two ships to cut the mooring wire of floating mines, or a distance sweep that mimics a ship to detonate the mines. The sweeps are dragged by minesweepers, either purpose-built military ships or converted trawlers. Each run covers between , and the ships must move slowly in a straight line, making them vulnerable to enemy fire. This was exploited by the Turkish army in the Battle of Gallipoli in 1915, when mobile howitzer batteries prevented the British and French from clearing a way through minefields.\nIf a contact sweep hits a mine, the wire of the sweep rubs against the mooring wire until it is cut. Sometimes \"cutters\", explosive devices to cut the mine's wire, are used to lessen the strain on the sweeping wire. Mines cut free are recorded and collected for research or shot with a deck gun.\nMinesweepers protect themselves with an oropesa or paravane instead of a second minesweeper. These are torpedo-shaped towed bodies, similar in shape to a Harvey torpedo, that are streamed from the sweeping vessel thus keeping the sweep at a determined depth and position. Some large warships were routinely equipped with paravane sweeps near the bows in case they inadvertently sailed into minefields\u2014the mine would be deflected towards the paravane by the wire instead of towards the ship by its wake. More recently, heavy-lift helicopters have dragged minesweeping sleds, as in the 1991 Persian Gulf War.\nThe distance sweep mimics the sound and magnetism of a ship and is pulled behind the sweeper. It has floating coils and large underwater \"drums\". It is the only sweep effective against bottom mines.\nDuring WWII, RAF Coastal Command used Vickers Wellington bombers Wellington DW.Mk I fitted with degaussing coils to trigger magnetic mines. In a parallel development the Luftwaffe adapted some Junkers 52/3m aircraft to also carry a coil operated by electricity supplied from an onboard generator. The Luftwaffe called this adaption \"Minensuch(e)\" (lit. mine-search). In both cases pilots were required to fly at low altitude (up to about 200 feet above the sea) and at fairly low speeds to be effective.\nModern influence mines are designed to discriminate against false inputs and are, therefore, much harder to sweep. They often contain inherent anti-sweeping mechanisms. For example, they may be programmed to respond to the unique noise of a particular ship-type, its associated magnetic signature and the typical pressure displacement of such a vessel. As a result, a mine-sweeper must accurately mimic the required target signature to trigger detonation. The task is complicated by the fact that an influence mine may have one or more of a hundred different potential target signatures programmed into it.\nAnother anti-sweeping mechanism is a ship-counter in the mine fuze. When enabled, this allows detonation only after the mine fuze has been triggered a pre-set number of times. To further complicate matters, influence mines may be programmed to arm themselves (or disarm automatically\u2014known as \"self-sterilization\") after a pre-set time. During the pre-set arming delay (which could last days or even weeks) the mine would remain dormant and ignore any target stimulus, whether genuine or false.\nWhen influence mines are laid in an ocean minefield, they may have various combinations of fuze settings configured. For example, some mines (with the acoustic sensor enabled) may become active within three hours of being laid, others (with the acoustic and magnetic sensors enabled) may become active after two weeks but have the ship-counter mechanism set to ignore the first two trigger events, and still others in the same minefield (with the magnetic and pressure sensors enabled) may not become armed until three weeks have passed. Groups of mines within this mine-field may have different target signatures which may or may not overlap. The fuzes on influence mines allow many different permutations, which complicates the clearance process.\nMines with ship-counters, arming delays and highly specific target signatures in mine fuzes can falsely convince a belligerent that a particular area is clear of mines or has been swept effectively because a succession of vessels have already passed through safely.\nMinehunting.\nAs naval mines have become more sophisticated, and able to discriminate between targets, so they have become more difficult to deal with by conventional sweeping. This has given rise to the practice of minehunting. Minehunting is very different from sweeping, although some minehunters, known as mine countermeasures vessels (MCMVs) can do both tasks. Minehunters use specialized high-frequency sonars and high fidelity sidescaning sonar to locate mines, which are then inspected and destroyed either by divers or ROVs (remote controlled unmanned mini-submarines). It is slow, but also the most reliable way to remove mines, as it circumvents most anti-minesweeping countermeasures. Minehunting started during the Second World War, but it was only after the war that it became truly effective.\nSea mammals (mainly the bottlenose dolphin) have been trained to hunt and mark mines, most famously by the US Navy Marine Mammal Program. Mine-clearance dolphins were deployed in the Persian Gulf during the Iraq War in 2003. The US Navy claims that these dolphins were effective in helping to clear more than 100 antiship mines and underwater booby traps from Umm Qasr Port.\nFrench naval officer Jacques Yves Cousteau's Undersea Research Group was once involved in minehunting operations: They removed or detonated a variety of German mines, but one particularly defusion-resistant batch\u2014equipped with acutely sensitive pressure, magnetic, and acoustic sensors and wired together so that one explosion would trigger the rest\u2014was simply left undisturbed for years until corrosion would (hopefully) disable the mines.\nMine running.\nA more drastic method is simply to run a ship through the minefield, letting other ships safely follow the same path. An early example of this was Farragut's actions at Mobile Bay during the American Civil War. However, as mine warfare became more developed this method became uneconomical.\nThis method was revived by the German Imperial German Navy during World War I. Left with a surfeit of idle ships due to the Allied blockade, the Germans introduced a ship known as \"Sperrbrecher\" (\"block breaker\"). The type was also used during World War II. Typically an old cargo ship, loaded with cargo that made her less vulnerable to sinking (wood for example), the \"Sperrbrecher\" was run ahead of the ship to be protected, detonating any mines that might be in their path. The use of \"Sperrbrecher\" obviated the need to continuous and painstaking sweeping, but the cost was high. Over half the 100 or so ships used as \"Sperrbrecher\" in WWII were sunk during the war. Alternatively, a shallow draught vessel can be steamed through the minefield at high speed to generate a pressure wave sufficient to trigger mines, with the minesweeper moving fast enough to be sufficiently clear of the pressure wave so that triggered mines do not destroy the ship itself. These techniques are the only way to sweep pressure mines that is publicly known to be employed. The technique can be simply countered by use of a ship-counter, set to allow a certain number of passes before the mine is actually triggered. Modern doctrine calls for ground mines to be hunted rather than swept. A new system is being introduced for sweeping pressure mines, however counters are going to remain a problem.\nAn updated form of this method is the use of small unmanned ROVs (such as the \"Seehund\" drone) that simulate the acoustic and magnetic signatures of larger ships and are built to survive exploding mines. Repeated sweeps would be required in case one or more of the mines had its \"ship counter\" facility enabled i.e. were programmed to ignore the first 2, 3, or even 6 target activations.\nCounter-mining.\nAnother expedient for clearing mines, especially in a hurry, is counter-mining. By this method an explosive is detonated in the area of a known or suspected minefield and the blast either trips off the fuzes or the actual explosive contained within the mine or mines. This latter is known as a sympathetic detonation. Counter-mining is normally used as a last resort or if other equipment is not available. One example was at the entrance to Grand Harbour, Valletta, Malta in WW2 when the British dropped depth charges into the harbour entrance to detonate suspected mines prior to the arrival of an important convoy. It is especially useful against acoustic or pressure mines due to their activation by sound or increases in water pressure.\nNational arsenals.\nUS mines.\nThe United States Navy MK56 ASW mine (the oldest still in use by the United States) was developed in 1966. More advanced mines include the MK60 CAPTOR (short for \"encapsulated torpedo\"), the MK62 and MK63 Quickstrike and the MK67 SLMM (Submarine Launched Mobile Mine). Today, most US naval mines are delivered by aircraft.\nMK67 SLMM Submarine Launched Mobile Mine\nThe SLMM was developed by the United States as a submarine deployed mine for use in areas inaccessible for other mine deployment techniques or for covert mining of hostile environments. The SLMM is a shallow-water mine and is basically a modified Mark 37 torpedo.\nGeneral characteristics\nMK65 Quickstrike\nThe Quickstrike is a family of shallow-water aircraft-laid mines used by the United States, primarily against surface craft. The MK65 is a dedicated, purpose-built mine. However, other Quickstrike versions (MK62, MK63, and MK64) are converted general-purpose bombs. These latter three mines are actually a single type of electronic fuze fitted to Mk82, Mk83 and Mk84 air-dropped bombs. Because this latter type of Quickstrike fuze only takes up a small amount of storage space compared to a dedicated sea mine, the air-dropped bomb casings have dual purpose i.e. can be fitted with conventional contact fuzes and dropped on land targets, or have a Quickstrike fuze fitted which converts them into sea mines.\nGeneral characteristics\nMK56\nGeneral characteristics\nRoyal Navy.\nAccording to a statement made to the UK Parliament in 2002:\n...the Royal Navy does not have any mine stocks and has not had since 1992. Notwithstanding this, the United Kingdom retains the capability to lay mines and continues research into mine exploitation. Practice mines, used for exercises, continue to be laid in order to retain the necessary skills.\nHowever, a British company (BAE Systems) does manufacture the Stonefish influence mine for export to friendly countries such as Australia, which has both war stock and training versions of Stonefish, in addition to stocks of smaller Italian MN103 Manta mines. The computerised fuze on a Stonefish mine contains acoustic, magnetic and water pressure displacement target detection sensors. Stonefish can be deployed by fixed-wing aircraft, helicopters, surface vessels and submarines. An optional kit is available to allow Stonefish to be air-dropped, comprising an aerodynamic tail-fin section and parachute pack to retard the weapon's descent. The operating depth of Stonefish ranges between 30 and 200 metres. The mine weighs 990 kilograms and contains a 600 kilogram aluminised PBX explosive warhead.\nModern mine warfare.\nMine warfare remains the most cost-effective form of asymmetrical naval warfare. Mines are relatively cheap and being small allows them to be easily deployed. Indeed, with some kinds of mines, trucks and rafts will suffice. At present there are more than 300 different mines available. Some 50 countries currently have mining ability. The number of naval mine producing countries has increased by 75% since 1988. It is also noted that these mines are of an increasing sophistication while even the older type mines present a significant problem. It has been noted that mine warfare may become an issue with terrorist organizations. Mining busy shipping straits and mining shipping harbours remain some of the most serious threats.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "22103", "revid": "11952314", "url": "https://en.wikipedia.org/wiki?curid=22103", "title": "Naval Construction Battalions", "text": ""}
{"id": "22104", "revid": "196446", "url": "https://en.wikipedia.org/wiki?curid=22104", "title": "Nawal El Moutawakel", "text": "Moroccan 1984 Olympic champion and Minister of Sports"}
{"id": "22105", "revid": "410898", "url": "https://en.wikipedia.org/wiki?curid=22105", "title": "Public ownership", "text": ""}
{"id": "22106", "revid": "8120059", "url": "https://en.wikipedia.org/wiki?curid=22106", "title": "North Melbourne Football Club", "text": "Australian rules football club\nThe North Melbourne Football Club, nicknamed the Kangaroos or colloquially the Roos, is a professional Australian rules football club. The men's team competes in the Australian Football League (AFL), and the women's team in the AFL Women's (AFLW). The Kangaroos also field a reserves men's team in the Victorian Football League (VFL) and women's team in the VFLW.\nInformally founded in the suburb of North Melbourne in 1858 during the scratch matches era, it is the fourth-oldest club in the competition. The club has been based at Arden Street Oval since 1882. Arden Street serves as its headquarters, training facilities and home ground for its women's side. The club's senior men's team plays its home matches at Marvel Stadium in the Docklands area of Melbourne, as well as Bellerive Oval in Hobart, Tasmania which is also used by the women's team as a secondary home ground.\nThe club's mascot is a grey kangaroo wearing the club uniform, and its use dates from the mid-20th century. The club is also unofficially known as \"The Shinboners\", a term which dates to the 19th century. The club's motto is , Latin for \"victory demands dedication\".\nThe Kangaroos have won four VFL/AFL premierships; in 1975, 1977 (after a replay), 1996 and 1999. They have also won two AFL Women's premiership; in 2024 and 2025.\nHistory.\nFormative years.\nAccording to historian Gerard Dowling, the club was founded around 1869, although he and the club itself recognised a potential formation year as early as 1860. However, due to a lack of records, the club leaned towards the club\u2019s discontinuation around 1864; and decided to adopt 1869 as its year of establishment. \nThe borough was initially called North Melbourne, then Hotham from 1859, before the town reverted back to its original name on August 27 1887. The club primarily went by \"North Melbourne Football Club\" until 1876. As a foundation club of the Victorian Football Association (VFA) in 1877, the club was known as Hotham, reclaiming its original name, North Melbourne in 1888. James Henry Gardiner is cited as a significant figure during the formative period of the club and remains so.\nA match between North Melbourne and the South Yarra Football Club appears in a 1865 newspaper article. On 14 August 1869, North Melbourne played the employees of Messrs, Walker, May, and Co. at Princes Bridge in what is now central Melbourne. North also fielded a second-20 team that day. A few weeks later, on 2 September, North Melbourne played South Yarra for the Challenge Cup. North Melbourne defeated the Surrey Football Club at Royal Park on 18 September 1869. According to Dowling, Harry Fuhrhop was a pivotal figure among the generation of players being reported in the media from 1869. Fuhrop is listed regularly from 1869 representing the club as Captain and a player, and further in 1884 as a general committee member. Other early newspaper reports include playing Carlton United at Royal Park on 24 September 1870, and 1 October 1870 against East Brunswick.\nRegular premiership matches of Australian Football commenced in Victoria in 1870. Although North Melbourne was a part of this, it was classed as a \"junior club\". The words junior and senior at the time were not used to distinguish underage side but rather the playing quality and strength of the side. \"The Australasian\" noted them as being \"one of the best of many junior clubs\". The club graduated to senior ranks in 1874, finishing fourth. Along with the promotion, the club adopted its first uniform of blue and white horizontal stripes.\nIn 1876, twelve players from North Melbourne defected to join Albert Park. It was in 1939 that Brunswick resident Mr A.M. Alexander wrote in a letter to the editor of The Argus with numerous historical errors, that the dozen North Melbourne players which defected gave strong influence over their destination club, \"Albert Park-cum-North Melbourne.\" No mention however is ever made by the Albert Park Football Club of them merging with North Melbourne, including no mention in their 1877 Annual General Meeting (AGM) reported by The Argus on 21 April 1877.\nDespite the loss of twelve senior players in 1876, North Melbourne Football Club maintained its reserves team playing under the name Hotham United. The club's determination to continue football operations as Hotham United forced them to bolster their player stocks by recruiting youths who had recently completed their studies at St Mary's Anglican School. It was also in 1876 that the club played for the first time in their colours of blue and white. North Melbourne's ties to St Mary's Anglican School, established in 1853, began when students played football at the corner of Queens and Howard Streets. Impressed by the students' progress, the football committee recruited school leavers from St Mary's and increased recruitment from the school in 1876. This ultimately led the committee to adopt St Mary's blue and white colours in 1876, which continue to be reflected in the club's colours today. Recruits in 1876 included Sam Butt, who would later captain the club in the 1880s. For the clubs monumental efforts to keep North afloat, the rewards came in 1877 when the Victorian Football (VFA) accepted them as Hotham Football Club as a foundation member of the elite VFA competition.\nRoyal Park served as the club's home ground until 1882, when they moved to the Hotham Cricket Ground (now Arden Street Oval).\nAssociation years.\nFootball took a significant step forward in 1877, with the formation of the Victorian Football Association (VFA), the first properly constituted administrative body in the colony of Victoria. Hotham was one of five senior metropolitan clubs to compete in the inaugural season.\nIn 1882, Hotham football club once again became co-located with the Hotham Cricket Club when they moved into the North Melbourne Recreation Reserve (Arden Street Oval). The move was part of an effort to improve the ground improvements at the Hotham Cricket Ground, which was the name of the Reserve at the time, and a few years after the football club was given legal control of the cricket club in 1879 (citation to follow).\nIn 1886, the club adopted the traditional uniform of blue and white vertical stripes at the insistence of the VFA, who wanted a visible contrast between Geelong's and Hotham's uniforms. Additionally, the club returned to its original \"North Melbourne Football Club\" name on 30 March 1888 after the local government area reverted its name to North Melbourne.\nThe 1880s saw the club develop a penchant for inter-colonial travel with trips to Tasmania (1881 and 1887) and South Australia (1889). Hotham also found itself well represented at the first ever intercolonial representative game in 1879, with four players from the club gaining selection for Victoria.\nDisregarded by the VFL.\nThe VFA grew to 13 senior clubs in the 1890s. Led by Geelong and Essendon, the largest clubs of the VFA formed their own breakaway league, the Victorian Football League (VFL), in 1896. Despite finishing 6th in 1896, North Melbourne was not invited to the breakaway competition. The main reasons for being excluded were:\nNorth continued on in the depleted VFA, emerging as a powerhouse, finishing 2nd in 1897, 1898 and 1899. In 1903, after 34 years of competing, the club won its first premiership, defeating Richmond in the final. The club became back to back premiers in 1904 after Richmond forfeited the grand final due to the appointment of an umpire whose performance when the two teams met earlier in the year was severely criticised by Richmond players and officials.\nNorth merged with fellow VFA football club West Melbourne in 1907, which at the time had lost its home ground. The joint venture saw a chance of promotion, and the club applied for admission to the more prestigious VFL in 1908, but Richmond and University were admitted instead. North was kicked out of the VFA during the 1907/08 offseason as a result of applying to join the VFL, before the local community re-established the North Melbourne Football Club under a new committee, successfully enabling the club to play in the VFA in the 1908 season.\n\"The Invincibles\".\nThe reformation of the club necessitated a massive cleanout of the team, leaving only two players remaining from the previous season. The 1910 season was marked by one of the most sensational transfers in Victorian football history, when Andy Curran masterminded the clearance of Carlton's famed \"Big Four\" of 'Mallee' Johnson, Fred Jinks, Charlie Hammond and Frank 'Silver' Caine to North Melbourne. These signings secured the Northerners' third premiership in 1910.\nThe 1912 finals series was one of the most amazing ever, with the semi-final having to be played three times, after North and Brunswick drew twice. North was eventually victorious and moved on to the final, but lost the game by a mere four points with the last kick of the day.\nThe next few years were punctuated by \"The Invincibles\". In the Northerners' most illustrious period ever, the club went undefeated from 1914 to 1919, collecting premierships in 1914, 1915 and 1918 \u2013 the competition was in recess in 1916 and 1917 due to World War I. As well as this, the club won the championship in both 1915 and 1918 for finishing on top of the ladder, and accounted for VFL side St Kilda comfortably. During this period the club won 58 consecutive matches including 49 successive premiership matches, a record that has remained unmatched in Association or League history since.\nDespite being rejected from the VFL in both 1896 and 1907, North persisted in trying to gain admission into the League. On 30 June 1921, North told its players it would disband and try to gain entry to the VFL by the 'back-door'. Essendon League Football Club had lost its playing ground at East Melbourne and had decided to acquire the North Melbourne Recreation Reserve as a new playing ground. North accepted their proposal in the idea that the clubs would amalgamate. All of North's players were urged to join the Essendon League Club to help facilitate the amalgamation. The amalgamation was foiled when some members of the VFA launched a successful legal challenge. As a result, the Essendon League Club moved instead to the Essendon Oval, replacing the ground's original occupants, Essendon Association.\nNorth was now without a playing team and the Essendon Association Club was now without a ground, so as a matter of convenience the two clubs amalgamated so they could compete in the 1922 season. As it had after the merger with West Melbourne, North once again managed to avert its destruction. During this Period, North's main rivals were Footscray, meeting them in three Grand Finals.\nEntering the VFL.\nAfter three attempts, 29 years of waiting and numerous other applications to enter the VFL, finally North was rewarded for its persistence with admittance to the League in 1925, along with Footscray and Hawthorn. Even then, the opportunity was almost lost as the League delegates debated into the early hours of the morning on which clubs should be invited to join the intake. It was only after much deliberation that North Melbourne's name was eventually substituted for Prahran's making North \"the lucky side\" of the invitees that included Footscray and Hawthorn. North Melbourne was forced to change its uniform to avoid a clash when it joined the VFL.\nNorth Melbourne struggled for most of its first twenty-five years in the VFL, with one of few bright notes being Sel Murray winning the VFL Leading Goalkicker Medal in 1941 with 88 goals. By the late 1940s, North Melbourne had developed a strong list and significant supporter base. In 1949 North secured the VFL Minor Premiership, finishing top of the ladder at the end of the home-and-away season with 14 wins and 5 losses. They failed to make the Grand Final that year (eventually won by Essendon), but in 1950 they did reach the final, but were defeated by Essendon. It was in this year that the club adopted the \"Kangaroos\" mascot.\nIn February 1965, North Melbourne moved its playing and training base from the Arden Street Oval to Coburg Oval, signing a seven-year lease with the City of Coburg after initially negotiating long-term leases for up to 40 years. The club came to an arrangement to merge with the VFA's Coburg Football Club, whom it was displacing from the ground; fourteen Coburg committeemen joined the North Melbourne committee, but the merger was never completed after Coburg established a rival committee which remained loyal to the VFA. The lease at Coburg lasted only eight months; the Coburg council was hesitant to build a new grandstand without the security of a long-term lease, and neither party made the returns they expected, so it was terminated by mutual agreement in September 1965 and North Melbourne returned to the Arden Street Oval.\nOn field, the 1950s and 1960s were lean years for North Melbourne, though the club did secure two consecutive Night Premierships in 1965 and 1966. Allen Aylett was a brilliant player in the late 1950s and early 1960s (and captain between 1961 and 1964), as was Noel Teasdale, who lost the Brownlow Medal on a countback in 1965 (he was later awarded a retrospective medal when the counting system was amended).\nGolden era.\nIn the late 1960s, under the leadership of Allen Aylett, North Melbourne began its climb to supremacy. As part of a major recruitment drive North secured the services of several big-name stars, including Barry Davis from Essendon, Doug Wade from Geelong, John Rantall from South Melbourne, and Barry Cable from Perth. In a major coup, the great Ron Barassi was appointed coach in 1973. Barrassi reversed the club's playing fortunes, taking a struggling team that was once regarded as the traditional cellar dwellers of the competition through to a golden era of success that transformed North Melbourne into one of the powerhouses of the VFL. Barassi took North to a Grand Final (losing to Richmond by 41 points) in 1974 and brought success in his 1975 and 1977 seasons. North made five consecutive Grand Finals from 1974 to 1978 and defeated Norwood in the 1975 national championship and thus declared Champions of Australia.\nIn 1973 and 1974, North's wingman Keith Greig (recruited from Brunswick Football Club, Victoria) won consecutive Brownlow Medals; forward Malcolm Blight (recruited from Woodville Football Club, South Australia) then won the award in 1978. Doug Wade (recruited from Geelong Football Club, Geelong) won the Coleman Medal in 1974 with his 103 goals for the season.\nBarassi remained team coach until 1980, but only a Night Premiership in that year resulted in him leaving Arden Street. North then entered another period of decline, though Malcolm Blight kicked 103 goals to take out the Coleman medal in 1982, and another Brownlow win came through the talented Ross Glendinning in 1983. In that year, North Melbourne won a third Minor Premiership with 16 wins and 6 losses for the season, but they failed to make the Grand Final.\nTeam of the 1990s.\nDespite the tough, disciplined coaching of the legendary John Kennedy, the 1980s and early 1990s were mostly lean years for the Kangaroos. However, the rebuilding of the club was taking place. The Krakouer brothers (Jim and Phil) brought a spark into the side and lifted many hopes for North supporters and the excitement to the general football public. The innovative idea of night games was instigated by the club and meeting the challenges, the club survived. One major highlight was the recruitment of forward John Longmire in 1989, who topped the club goalkicking over five consecutive seasons (1990\u20131994) and won the Coleman medal in 1990 with 98 goals. At the beginning of the 1993 season, in a dramatic and controversial move, the board of the club sacked coach and long-time player Wayne Schimmelbusch, and appointed Denis Pagan in his place. Results were immediate, as North reached the finals for the first time in nearly a decade.\nPagan was instrumental in appointing young centre half-forward Wayne Carey as the club's youngest-ever captain. Carey had been recruited at the same time as Longmire, but had taken longer to develop as a player. Over the next nine seasons, Carey came to be regarded as the standout player in the league and was known as 'the King'.\nNorth Melbourne became a powerhouse through the 1990s under Pagan and Carey, and finished in the top four, making the preliminary finals or better, in every season from 1994 until 2000. After being eliminated in the preliminary finals in 1994 and 1995, North went on to defeat the Sydney Swans in the 1996 Grand Final to take out the club's third premiership, and the gold centenary AFL cup; Glenn Archer won the Norm Smith Medal. The club was again eliminated in the preliminary final in 1997. In 1998, as the club won both the pre-season Ansett Cup and topped the ladder with 16 wins and 6 losses, but went on to lose the 1998 Grand Final to Adelaide, not helped by an inaccurate goalkicking performance of 8.22 (70) to Adelaide's 15.15 (105). In 1999, the Kangaroos finished the regular season in second position on the ladder, and went on to defeat Carlton in the Grand Final, winning the club's fourth VFL/AFL premiership; former Sydney midfielder Shannon Grant taking out the Norm Smith Medal. The club was eliminated in the preliminary finals in 2000 against Melbourne.\nIn 1996, the club was in advanced merger talks with the financially depleted Fitzroy Football Club to create the North Fitzroy Kangaroos Football Club; however, Fitzroy ultimately merged with the Brisbane Bears instead.\nSeeking new markets and greater financial security in an increasingly corporatized AFL environment, the title \"North Melbourne\" was officially dropped from the logo in 1999, during which time the team played only as the \"Kangaroos\". During the successful 1999 season, North Melbourne played home games in Sydney with a view of becoming a second team in New South Wales; however, the experiment was not successful, with crowds averaging only 12,000.\n21st century.\nNorth's dominance of the league did not continue into the 21st century. Its decade-long on-field potency was in decline, and questions were raised about its financial position and long-term sustainability. Furthermore, three of the people most important to the club's success in the 1990s left the club under acrimonious circumstances: CEO Greg Miller left the club, captain Wayne Carey left prior to the 2002 season following an extramarital affair with the wife of teammate and vice captain Anthony Stevens, and coach Denis Pagan was lured to Carlton at the end of 2002. Pagan was replaced by 1996 premiership player Dani Laidley, who had previously been an Assistant Coach at Collingwood from 1999 until the end of season 2002.\nOn a post-season holiday, several players were caught in the 2002 Bali bombings terrorist attack, notably defender Jason McCartney, who suffered second-degree burns to over 50% of his body while carrying others to safety and nearly died during surgery after being flown back to Melbourne. In what is regarded as one of the most inspirational stories of Australian rules football and Australian sport in general, McCartney successfully returned to action on 6 June 2003 against Richmond at Docklands Stadium. Playing at full-forward, he took a mark in the final quarter, scored a goal from the resulting set shot, and set up Leigh Harding's winning goal with two minutes remaining. McCartney retired immediately after the game, citing that his recovery had left him spent, and he was chaired from the ground. McCartney wore the numbers \"88\" and \"202\" on the front of his long-sleeved guernsey for the match, signifying the Australian and total number of victims of the Bali bombings, while many in the crowd bore signs reading \"Bali 88/202\".\nOnfield, the club reached the elimination finals in 2002 and 2004.\nAfter a top-4 finish and a preliminary final berth in 2007, and a first-round elimination final exit in 2008, North Melbourne dropped to 13th in 2009, and coach Dani Laidley announced her resignation, with Darren Crocker acting as caretaker coach for the rest of the season, to eventually be replaced by ex-Brisbane Lions premiership player and Collingwood assistant coach Brad Scott. A$15\u00a0million redevelopment of the Arden Street, which had started in 2006, was completed in 2009, giving the club top-class training facilities.\nBrad Scott era.\nNorth Melbourne struggled in its first two years under Brad Scott, finishing 9th in both 2010 and 2011. In 2012, the club returned to the finals for the first time since 2008, finishing the season in 8th place, but would go down to the West Coast Eagles by 96 points in an elimination final. In 2012, the club began a three-year deal to play two games each year at Bellerive Oval in Hobart, Tasmania. The club finished 10th in 2013 in a season full of close losses. Nick Dal Santo signed with the club at the end of the 2013 season as a restricted free agent.\nIn 2014, North Melbourne finished 6th at the end of the home and away season and reached 40,000 members for the first time in the club's history.\nIn September, North Melbourne went on to defeat Essendon by 12 points in the 2nd Elimination Final, only taking the lead in the last quarter. The following week, North Melbourne beat Geelong in the 2nd Semi-final by 6 points advancing them through to their first preliminary final since 2007. Their finals campaign came to a disappointing end at Stadium Australia when they were beaten by Sydney by 71 points. In 2015 the club made history by becoming the first team to qualify for a preliminary final from 8th spot, losing to the West Coast Eagles by 25 points after leading at half time.\nIn 2016, North Melbourne won its first nine matches, which is the club's best start to a season in its VFL/AFL history. On 27 July 2016, the club announced it had surpassed 45,000 members for the first time in the club's history. In 2016, the Kangaroos fielded what was the oldest team in AFL history. Unfortunately after the midpoint of the season they fell away and struggled against some of the worst teams in competition. In the mid season of 2019 Brad Scott made the decision to leave NMFC after 10 years at the club taking them to the finals on multiple occasions.\nRhyce Shaw and David Noble.\nRhyce Shaw took over as caretaker coach in the interim in mid- to late 2019 and was later awarded the position as head coach for the following 2020 season. After a disappointing 2020 season where North won only 3 games and finished second-last, Rhyce Shaw left the club in late October 2020 due to personal issues, bringing his short tenure as head coach to an end.\nIn 2021, former Western Bulldogs and Adelaide assistant coach and long-time football administrator David Noble was appointed as the new senior coach on an open-ended staff contract. Noble led the club to the wooden spoon in 2021 despite the team producing some encouraging results towards the end of the season and ending with four wins and a draw from the season. Noble resigned from the position in mid-2022 after pressure resulting from North's poor start to the season.\nAlastair Clarkson era.\nOn 19 August 2022, North Melbourne signed Alastair Clarkson to coach the team for five seasons, starting with the 2023 season.\nClarkson stepped down as the coach of North Melbourne for part of the 2023 season due to him struggling with mental health problems from the racism accusations while he was at the Hawthorn Football Club, however returned toward the end of the season.\nClub symbols and identity.\nName and mascot.\nThe club was widely known as the \"Shinboners\" for much of its early history. The origins of the nickname is believed to come from the area's abattoirs, where a number of the players worked. It was Phonse Tobin, North president from 1953 to 1956, who oversaw the club adopting the kangaroo emblem in 1954; Tobin found the image of a shinbone unsavoury and wanted the club to have a mascot it could show with pride. In selecting a new name, he wanted something characteristically Australian and was inspired by a large kangaroo he saw on display outside a city store.\nThe official name of the club is North Melbourne, but the club has gone under several other aliases over the years. The club was founded as the \"North Melbourne Football Club\", but changed to \"North Melbourne cum Albert Park\" after merging with Albert Park in 1876. Following the reformation of the club in 1877, it was known as the \"Hotham Football Club\" but later took the name \"North Melbourne\" again in 1888. In 1998 the club proposed changing its name to the \"Northern Kangaroos\", but it was rejected by the AFL. From 1999 to 2007, the club traded without much success as \"The Kangaroos\" in a bid to increase its appeal nationally; this decision was reversed at the end of 2007 when the club again reverted to the name \"North Melbourne\".\nClub song.\n\"Join in the Chorus\" is the official anthem of the North Melbourne Football Club. It is sung to the tune of a Scottish folk song from around 1911, \"A Wee Deoch an Doris\".\nThe song is generally sung, in accordance to common football tradition, after a victory. It is also played before every match.\n\"Join in the Chorus\" is believed to be the oldest club anthem of any AFL club and has been associated with North from its early VFA days. The preamble of the song originates from a score of a theatre musical called \"Australia: Heart to Heart and Hand to Hand\", written by Toso Taylor in the 1890s in pre-federation Australia. The second verse is unknown in origin and was presumably added later by members of the club when the song was chosen. The chorus was appropriated from a song written and performed by Scottish musician Harry Lauder. The recording currently used by the club was performed by the Fable Singers in April 1972 and only includes the choruses.\nThe song has a strong Victorian heritage and has been traditionally sung by the Victorian State Football and Victorian Cricket teams respectively. The lyrics have occasionally been changed, including updating the year in the song (e.g. \"North Melbourne will be premiers in 1993\"), or to remove the words \"North Melbourne\" during the period when the club was competing only as the Kangaroos. Following 1993, the players would sing after a win, the last line as \"North Melbourne will be premiers just you wait and see.\" instead of \"..is the team that plays to win for you and me.\"\nFor the 2015 premiership season, You Am I's lead singer, Tim Rogers, a North Melbourne supporter, announced that he would assist in an updated version of the song including the two verses. This version is only played at North home games as the team runs onto the ground.\n\"Shinboner spirit\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;At clubs with bigger memberships, their supporters only touch their colours, but at North we have the Shinboner spirit. North people can touch that spirit \u2013 they are the real Shinboners, they are the club.\u2014\u200a\nNorth Melbourne has a proud history as a working-class, inner-city club. Reflecting the suburb of North Melbourne's lower socio-economic status in the 19th and early 20th century, the team has always been one of the smaller and less wealthy clubs, relying on the mateship and grit of its players and membership to succeed.\n'Shinboner spirit' refers to North's reputation of fighting against the odds and not asking for hand-outs. North's fans like to compare this to the (generally richer) clubs like Essendon and Carlton, which through their wealthier patronage and corresponding improved player catchments and ability to pay players more, were generally more successful in the pre\u2013salary cap era. The term persists to the modern day despite North Melbourne having switched its official nickname from the Shinboners to the Kangaroos in the 1950s.\nBecause it relates to the club's original nickname, Shinboner spirit is often associated with the complete history of the club. In 2005, to celebrate the club's 80th anniversary of senior competition in the VFL and the 30th anniversary of its first VFL premiership, the Kangaroos held a \"Shinboner Spirit\" gala event attended by almost the entire surviving players. In the awards ceremony, the key Shinboners of the past 80 years were acknowledged, and Glenn Archer was named the \"Shinboner of the Century\".\nGuernsey.\nThe North Melbourne Football Club has a long history of wearing various designs in the colours of royal blue and white.\nMost of the club's earliest jumpers were long-sleeved and not the sleeveless design common today. In their early years the club sported a hooped design when they took to the field. This changed at the behest of the VFA in 1884 who insisted that Hotham change their jumpers to vertical stripes to provide a visible contrast between Hotham and Geelong.\nAfter 1884 the vertical top was worn more often, usually in the lace-up design in the gallery below.\nAfter the merger with West Melbourne, North used a composite jumper that incorporated West Melbourne's red sash for the 1908 season. The merger was in reality, a takeover. The red sash was a token gesture and was removed the following season.\nIn the early 1920s North experimented with an NMFC monogram design, following League clubs like Carlton and South Melbourne.\nUpon promotion to the VFL in 1925, North Melbourne was forced to abandon its royal blue and white striped jumper as it was deemed the jumper design clashed with other clubs. During this period a jumper with a V design was used for several years, before the club returned to using its striped jumper combination of royal blue and white which has been used continuously since 1932.\nFor 86 seasons, until 2016, the blue stripes were centred, the guernsey had a blue collar and cuffs, and black numbers. Until the 1970s, the numbers were attached to a white panel, while since this point, the top half of the back of the guernsey has been made white to accommodate larger numbers.\nBetween 2011 and 2016, North Melbourne wore an inverted version of their guernsey, which was predominantly blue with white numbers, as an alternate uniform. In 2017, this was made the club's home jumper and the traditional version was reserved for clashes. However, this was reversed when the club signed a sponsorship deal with German sporting brand Puma, effective from the 2022 season. This saw a return of the traditional guernsey, as well as hooped socks, unused as part of the home uniform since the 1960s. The black player numbers would return in 2023.\nIn the 1990s, many AFL clubs began to produce alternate uniforms, known in Australian football as 'clash' guernseys. At Arden Street, this meant the introduction of the 'Bounding Roo'. Coinciding with a change in marketing by which the club sought to identify more with the \"Kangaroos\" image, this design included a blue chest with thin stripes extending downwards, onto a large kangaroo. The kangaroo was taken from the club's logo, in which it is represented bounding rightward. The guernsey is thus known as the 'Bounding Roo'. Given its association with the club's golden era in the late 1990s, the guernsey is popular among NMFC supporters today. It was used in 2016 to celebrate 20 years since the club's third premiership, and in 2019, North's 150th anniversary.\nUniform evolution.\nChanges in the North Melbourne uniform through the years:\nInitial years &amp; VFA:\nVFL/AFL:\nSignificant alternate uniforms:\nLogo.\nNorth Melbourne has experienced 7 logo changes since its introduction, with 5 of them featuring a bounding kangaroo behind a shield of blue and white stripes. In 2016, North Melbourne introduced a new logo that featured a much fiercer-looking kangaroo\u2014with its head only\u2014sitting on top of the words 'North Melbourne' inside a shield. The change was generally welcomed. The new kangaroo looks slightly to the right, indicating that it is looking into the future.\nHome ground.\nArden Street Oval was home to the Kangaroos between 1882 and 1985. The oval is currently owned by the City of Melbourne and leased by the North Melbourne Football Club for social, administration and training facilities, and is the site of the club's AFL Women's, VFL and VFL Women's home matches. The grandstands were removed following the conclusion of VFL/AFL matches.\nThe club has been a home tenant club at Docklands Stadium since the stadium's opening in 2000, and have also played several home games per season in non-Victorian stadiums. In 2012, the Kangaroos commenced playing a maximum of four home games per season at Bellerive Oval in Hobart. The arrangement, which was made in partnership with the Tasmanian Government and the AFL, concluded in 2025. From 2025 to at least 2028, the club will play two home games per season in Western Australia, splitting these games between Optus Stadium and Hands Oval in Bunbury.\nCorporate.\nOwnership.\n`The North Melbourne Football Club is a non-profit organisation limited by guarantee. Members of the club serve as the guarantees of capital and have full voting rights at AGMs to elect directors to the club's board.\nThe club's board of directors has nine members, with each director serving a three-year term before their position is put up for re-election at an AGM. Only one-third of the board is contested at each AGM due to the rolling structure of the terms of the directors. This structure safeguards the entire board from being ousted at a single AGM and has made North Melbourne immune to a lot of the in-house fighting witnessed at other AFL football clubs. The board governs the club as well as selecting a chairman to head the club through a majority vote of directors.\nNorth Melbourne is unique in its structure, because from 1986 to 2006 the club was privately owned and limited by shares. The club was floated in 1986 through a membership vote led by then chairman Bob Ansett. At the meeting, members were encouraged to buy into the club by purchasing shares. The float ended up raising over $3\u00a0million and helped to keep the club solvent through the next decade.\nIn 1991, the John Elliott-led Carlton Football Club attempted a hostile take over North Melbourne by purchasing a large parcel of shares formerly owned by Bob Ansett. The Blues acquired 20 per cent of the capital but that stake was eventually bought back in 2001 by John Magowan, the former head of Merrill Lynch Australia. The resulting melodrama saw the formation of B-Class shareholders who had the effective power of veto over any attempt to merge or relocate the club.\nFurther takeover attempts were made in the first decade of the 21st century by the Southport Sharks. Then chairman Allan Aylett knocked back a proposal from the Sharks that would have seen them gain a majority stake in the club in exchange for an injection of capital. In early 2006, another proposal from Sharks to underwrite the Kangaroos' games on the Gold Coast, in exchange for a slice of the shareholder structure at the club was knocked back after AFL intervention.\nDue to an Australian Taxation Office ruling in 2006, the club proposed a shareholder restructure that would have seen the B Class shareholders power reduced significantly and some voting rights returned to members. This was done to avoid extraordinary taxes being placed on the club, but the move was blocked in December by Bob Ansett and his proxies who feared that the restructure would make the club vulnerable to further takeover bids.\nOn 28 February 2007, another meeting was called to resolve the shareholder issue. A motion was passed that would return see some voting rights return to members and stop any future tax increments.\nIn April 2007 it was revealed the AFL was attempting to buy out the shareholders of the club in a bid to gain full ownership, and force a relocation of the club to the Gold Coast.\nDuring October 2007, a group called We Are North Melbourne (WANM) emerged and launched a public campaign, calling for ordinary members to be given the final say on the relocation issue. While the group became synonymous with the push to keep the club in Melbourne, its first priority was to see the club's shareholder structure wound-up and control returned to ordinary members.\nNorth Melbourne reverted to public company in November 2008. A moratorium was passed at an extraordinary general meeting that allowed James Brayshaw's board to serve unopposed until 2010, so as to allow his ticket the maximum time to enact their policies to make the North Melbourne Football Club financially viable.\nOn 20 November 2016, former Aussie Rules footballer and Football Federation Australia chairman Ben Buckley replaced James Brayshaw as the new chairman of the club.\nIn 2022, North Melbourne appointed Jen Watt as its CEO, joining president Sonja Hood in the first all-female AFL leadership team.\nPreviously a club with issues about financial sustainability, North became debt free in 2021 and through to 2023 has posted multiple consecutive surpluses. In 2022, North established the Arden Fund to boost the club's long-term financial sustainability.\nNight football.\nIn Round 1,1985, North Melbourne pioneered the concept of playing football on Friday nights. Since then, North Melbourne has played the most Friday night games of any AFL club.\nFriday night matches later became the most lucrative timeslot for televised games, and North Melbourne's relatively low supporter base resulted in fewer Friday night matches. Between 2010 and 2014, North Melbourne had hosted an annual Friday night match against Carlton in recognition of its pioneering role in the concept.\nGood Friday football.\nAfter years of campaigning to play on Good Friday, the AFL announced on 25 October 2016 that North Melbourne would play the Western Bulldogs on Good Friday in 2017. Good Friday in Australia is a day when people raise money for Melbourne's Royal Children's Hospital and North Melbourne announced that $5 from each ticket sold would go to the charity. The game is known as the Good Friday Superclash. North Melbourne played Essendon on Good Friday on 19 April 2019.\nIndigenous players.\nNorth Melbourne has a strong history of supporting and fostering Aboriginal footballers in the VFL and AFL. The first indigenous footballer to play for the club was Percy Johnson in the 1950s, and was followed by other fan favourites such as Bertie Johnson, Barry Cable and the Krakouer brothers in the following decades.\nThe following is a list of Indigenous footballers to have played senior football at the club:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nKilled in action.\nThe following footballers were killed in action during the World Wars and played senior football for North Melbourne.\nRivalries.\nEssendon.\nOne of the fiercest rivalries in the AFL can be traced back to 1896, when several clubs, including Essendon Football Club, broke away from the Victorian Football Association to form the Victorian Football League. North sought to join the breakaway competition, but some argue this desire was not realised due to Essendon feeling threatened by North's proximity and the fact their inclusion could drain Essendon of vital talent. More than 100 years later, some North supporters have not forgiven Essendon for the decision and have blamed the Bombers for their relatively small supporter base and gate revenue. North were finally admitted into the VFL in 1925 alongside Footscray and Hawthorn. In 1950, the two sides met in their first and only grand final meeting to date, which Essendon won by 38 points. The rivalry would flare up again in the 1980s. In 1982, the Krakouer brothers, Jim and Phil, led the Kangaroos to an Elimination Final win. Essendon had their revenge a year later, winning a Preliminary Final by 86 points. The rivalry was re-ignited in the late 1990s and early 2000s due to the on-field success of the two sides. In preparation for the 1998 finals series, and despite losing six of their last eight to the Kangaroos, legendary Essendon coach Kevin Sheedy publicly labelled North executives Greg Miller and Mark Dawson soft in response to comments from commentators that his Essendon team was soft. The Kangaroos beat Essendon in the much-hyped encounter that followed (a Qualifying Final), and North fans pelted Sheedy with marshmallows as he left the ground, although Sheedy was seemingly unfazed by the incident, encouraging a \"Marshmallow Game\" the next year and relishing in the fact that Sheedy's ulterior motive was to build up the game and draw a large crowd, which proved to be correct, drawing in 71,154 people to attend the game. In 2000, the Bombers thrashed North by 125 points. The biggest VFL/AFL comeback of all time occurred between the two teams when Essendon managed to come back from a 69-point deficit to win by 12 points in 2001. A meeting of the two rivals at the MCG in the 2014 AFL finals series in the 2nd Elimination Final resulted in North winning by 12 points, eliminating Essendon from the finals series and extending their drought of years without a finals win.\nThe rivalry has at times been described as one-sided; in 2020, Essendon player Devon Smith remarked \"It's a bit of a rivalry built up from them, but for us it's another game\" given Essendon Football club considers its main rivals to be Carlton, Collingwood and Hawthorn.\nHawthorn.\nNorth and Hawthorn have a rivalry that dates back to the 1950s when the two teams competed for the McCaskill Trophy in a series of tough and torrid encounters from 1952 to 1956, the trophy being named after Bob McCaskill who had coached both North and Hawthorn. The rivalry intensified in the 1970s when, after being generally unsuccessful in the first few decades since their entry into the VFL, both clubs became dominant and played against each other in three grand finals in four years. North Melbourne defeated Hawthorn in the 1975 VFL Grand Final by 55 points to win their maiden premiership. However, Hawthorn defeated North Melbourne in the 1976 grand final by 30 points and the 1978 grand final by 18 points. From 1974 to 1978 they played together in 10 finals and the 1976 NFL Night Series final in Adelaide. During the 1980s, Hawthorn dominated North but during the '90s the results were reversed, including a qualifying final which became the first ever AFL finals match to require extra time, after the scores were level with North Melbourne 12.19 (91) to Hawthorn 13.13 (91) at the end of regular time. North Melbourne dominated extra time, kicking 3.5 to Hawthorn's nil and won by 23 points. The rivalry reignited in the 21st century, firstly with an intense semi-final in 2007. Played in front of a crowd of nearly 75,000, the game was noted not only for its physical intensity, but also the flair and attacking ability of both teams' young playing groups, including a high-flying mark by North forward Aaron Edwards. In 2014 a choking incident involved Brian Lake and North Melbourne forward Drew Petrie, when Lake had Petrie in a choking hold during a match at Docklands Stadium. In 2015 there were several off the ball incidents and fights, including an all-in melee during the first term of their round 5 clash.\nClub honour board.\nNorth Melbourne Team of the Century.\nAt a special function in August 2001, the North Melbourne Team of the Century was announced. There was no minimum number of games set for selection. Wayne Carey was named as captain and Denis Pagan as coach. The selection panel was Geoff Poulter (journalist), Father Gerard Dowling (club historian), Keith McKenzie (former coach), Lloyd Holyoak (former president), Max Ritchie (former player and chairman of selectors) and Greg Miller (chief executive).\nShinboner of the Century.\nOn 18 March 2005, the North Melbourne football club held a special gala dinner entitled the \"North Story\" to celebrate the 80th anniversary of North's admission to the VFL, and the 30th anniversary of the club's first VFL premiership. Over 3500 people attended the historic event held at the Royal Exhibition Building, including almost all surviving North Melbourne players. Glenn Archer was voted the Shinboner of the Century by his peers as the player who most represents the 'Shinboner Spirit'. The following players were voted 'Shinboners' of their era:\n150th-year celebration.\nTo commemorate the 150th year of the founding of the North Melbourne Football Club, a 150th Year Celebration was organised for the first weekend of August 2019, which commenced with a Friday Night blockbuster against archrivals Hawthorn. Starting from 27 points down in the first quarter, the Kangaroos fought back against the Hawks to triumph as 22-point winners to get the weekend celebrations underway. The following day, the Kangaroos' VFL side took on Box Hill and won in a similar comeback performance, coming from 31 points down at three-quarter time to win by 2 points. To cap off the weekend, a 150th-Year Celebration Dinner was held at the Melbourne Convention &amp; Exhibition Centre, where the 150 greatest-ever North Melbourne players were announced, with the top-10 greatest North Melbourne players announced on the night from the results of an expert panel.\nTop 10 Greatest North Players\nClub achievements.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReserves team.\nThe North Melbourne reserves are the reserves team of the club, playing in the Victorian Football League (VFL).\nHistory.\nNorth Melbourne competed in the VFL/AFL reserves from 1925 until 1999. During that time, the team won seven premierships \u2212 1947, 1957, 1967, 1978, 1979, 1995 and 1996.\nFollowing the demise of the AFL reserves competition, the standalone reserves team was dissolved, and over the following eighteen years the club entered reserves affiliations with a range of VFL clubs.\nIn 2018, North Melbourne re-established its own reserves team. The side initially played its home games at Chirnside Park in Werribee until mid-2019, and then at the redeveloped Arden Street Oval since the second half of 2019.\nHonours.\nJim 'Frosty' Miller Medal: Nick Larkey (2018)\nWomen's teams.\nAFL Women's team.\nThe North Melbourne Women's are the women's team of the club, playing in the AFL Women's competition (AFLW).\nIn 2017, following the inaugural AFL Women's (AFLW) season, North Melbourne was among eight clubs that applied for licences to enter the competition from 2019 onwards. In September 2017, the club was announced as one of two clubs, along with Geelong, to receive a licence to join the competition in 2019. In April 2018, the club announced the signing of Western Bulldogs midfielder Emma Kearney, who had just won the AFL Women's best and fairest and a premiership and club best-and-fairest with the Bulldogs.\nThe club officially competes as the North Melbourne Tasmanian Kangaroos \u2013 often shortened simply to Kangaroos across league publications \u2013 due to its ground-sharing arrangement between venues in Victoria and Tasmania.\nThe team made the grand final in 2023, losing narrowly to Brisbane. In 2024 the club went on a 12-match unbeaten streak, a record for the AFL Women's competition (though this includes a draw against Geelong in round two), which culminated in a 30-point premiership victory against Brisbane. Star midfielder Jasmine Garner was awarded the best-on-ground medal for her 35-possession performance. The club again dominated in the 2025, winning all 12 home-and-away games and all three finals, to record back-to-back premierships and extend their winning run to 27 consecutive matches.\nVFL Women's team.\nNorth Melbourne began fielding a team in the second-tier VFL Women's league in 2021, following several years of affiliation with Melbourne University in the competition.\nUnder coach Brett Gourley, the club won the 2024 premiership, defeating the Western Bulldogs in the Grand Final played at Port Melbourne's ETU Stadium in July 2024. \n The team was renamed North Melbourne Werribee ahead of the 2025 season, as North Melbourne and Werribee Football Club entered into an affiliation arrangement and shared home games. The side claimed a second consecutive premiership, defeating Collingwood in the Grand Final by six points.\nActivism.\nSame-Sex Marriage.\nDuring the Australian Marriage Law Postal Survey, North Melbourne Football Club supported the Yes vote.\nVoice to Parliament.\nNorth Melbourne Football Club was a supporter of the Voice to Parliament.\nPoker machines.\nIn 2008, North became the first Victorian AFL club to \u2018exit\u2019 poker machine ownership, the club noting at the time that it didn\u2019t want to make money off the losses of others.\nSustainability.\nIn October 2025, North Melbourne became the first sporting club in Australia to receive a B Corp certification, for its \u2018remarkable impact on social and environmental performance, as well as its accountability and transparency.\u2019\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22107", "revid": "3798137", "url": "https://en.wikipedia.org/wiki?curid=22107", "title": "Treaty on the Non-Proliferation of Nuclear Weapons", "text": "International treaty\nThe Treaty on the Non-Proliferation of Nuclear Weapons, commonly known as the Non-Proliferation Treaty or NPT, is an international treaty, the objective of which is to prevent the spread of nuclear weapons and weapons technology, to promote cooperation in the peaceful uses of nuclear energy, and to further the goal of achieving nuclear disarmament and general and complete disarmament. Between 1965 and 1968, the treaty was negotiated by the Eighteen Nation Committee on Disarmament, a United Nations-sponsored organization based in Geneva, Switzerland.\nOpened for signature in 1968, the treaty entered into force in 1970. As required by the text, after twenty-five years, NPT parties met in May 1995 and agreed to extend the treaty indefinitely. The treaty defines nuclear-weapon states as those that have built and tested a nuclear explosive device before 1967; these are the United States (1945), Russia (1949), the United Kingdom (1952), France (1960), and China (1964).\nAs of August 2016, 191 states have become parties to the treaty. North Korea which acceded in 1985 but never came into compliance, announced its withdrawal from the NPT in 2003\u2014the only state to do so\u2014and carried out its first nuclear test in 2006. Four UN member states have never accepted the NPT, three of which possess or are thought to possess nuclear weapons: India, Israel, and Pakistan. In addition, South Sudan, founded in 2011, has not joined.\nAt the time the NPT was proposed, there were predictions of 25 to 30 nuclear weapon states within 20 years. Further non-proliferation initiatives include the export controls of the Nuclear Suppliers Group and the enhanced verification measures of the International Atomic Energy Agency (IAEA) Additional Protocol.\nCritics argue that the NPT cannot stop the proliferation of nuclear weapons or the motivation to acquire them. They express disappointment with the limited progress on nuclear disarmament, required under Article VI, where the five recognized nuclear-weapon states still have 13,400 warheads in their combined stockpile. UN officials have said that they can do little to stop states using nuclear reactors to produce nuclear weapons.\nDefinitions.\nThe treaty defines nuclear-weapon states as those that have built and tested a nuclear explosive device before 1 January 1967; these are the United States (1945), Russia (1949), the United Kingdom (1952), France (1960), and China (1964). Four other states are known or believed to possess nuclear weapons: India, Pakistan, and North Korea have openly tested and declared that they possess nuclear weapons, while Israel is deliberately ambiguous regarding its nuclear weapons status.\nThe NPT is often seen to be based on a central bargain:\nthe NPT non-nuclear-weapon states agree never to acquire nuclear weapons and the NPT nuclear-weapon states in exchange agree to share the benefits of peaceful nuclear technology and to pursue nuclear disarmament aimed at the ultimate elimination of their nuclear arsenals. \nThe treaty is reviewed every five years in meetings called Review Conferences. Even though the treaty was originally conceived with a limited duration of 25 years, the signing parties decided, by consensus, to unconditionally extend the treaty indefinitely during the Review Conference in New York City on 11 May 1995, in the culmination of U.S. government efforts led by Ambassador Thomas Graham Jr.\nAt the time the NPT was proposed, there were predictions of 25\u201330 nuclear weapon states within 20 years. Instead, more than forty years later, five states are not parties to the NPT, and they include the only four additional states believed to possess nuclear weapons. Several additional measures have been adopted to strengthen the NPT and the broader nuclear nonproliferation regime and make it difficult for states to acquire the capability to produce nuclear weapons, including the export controls of the Nuclear Suppliers Group and the enhanced verification measures of the International Atomic Energy Agency (IAEA) Additional Protocol.\nCritics argue that the NPT cannot stop the proliferation of nuclear weapons or the motivation to acquire them. They express disappointment with the limited progress on nuclear disarmament, where the five authorized nuclear weapons states still have 13,400 warheads in their combined stockpile. Several high-ranking officials within the United Nations have said that they can do little to stop states using nuclear reactors to produce nuclear weapons.\nTreaty structure.\nThe NPT consists of a preamble and eleven articles. Although the concept of \"pillars\" is not mentioned in the NPT, the treaty is often described as a \"three-pillar\" system, with an implicit balance among them:\nThese pillars are interrelated and mutually reinforcing. An effective nonproliferation regime, the members of which comply with their obligations, provides an essential foundation for progress on disarmament and makes possible greater cooperation on the peaceful use of nuclear energy. With the right to access the benefits of peaceful nuclear technology comes the responsibility of nonproliferation. Progress on disarmament reinforces efforts to strengthen the nonproliferation regime and to enforce compliance with obligations, thereby also facilitating peaceful nuclear cooperation.\nThe \"pillars\" concept has been questioned by some who believe that the NPT is, as its name suggests, principally about nonproliferation, and who worry that \"three pillars\" language misleadingly implies that the three elements have equivalent importance.\nFirst pillar: Non-proliferation.\nUnder Article I of the NPT, nuclear-weapon states pledge not to transfer nuclear weapons or other nuclear explosive devices to any recipient or in any way assist, encourage or induce any non-nuclear-weapon state in the manufacture or acquisition of a nuclear weapon.\nUnder Article II of the NPT, non-nuclear-weapon states pledge not to acquire or exercise control over nuclear weapons or other nuclear explosive devices and not to seek or receive assistance in the manufacture of such devices.\nUnder Article III of the Treaty, non-nuclear-weapon states pledge to accept IAEA safeguards to verify that their nuclear activities serve only peaceful purposes.\nFive states are recognized by the NPT as nuclear weapon states (NWS): China (signed 1992), France (1992), the Soviet Union (1968; obligations and rights now assumed by the Russian Federation), the United Kingdom (1968), and the United States (1968), which also happen to be the five permanent members of the United Nations Security Council.\nThese five NWS agree not to transfer \"nuclear weapons or other nuclear explosive devices\" and \"not in any way to assist, encourage, or induce\" a non-nuclear weapon state (NNWS) to acquire nuclear weapons (Article I). NNWS parties to the NPT agree not to \"receive\", \"manufacture\", or \"acquire\" nuclear weapons or to \"seek or receive any assistance in the manufacture of nuclear weapons\" (Article II). NNWS parties also agree to accept safeguards by the International Atomic Energy Agency (IAEA) to verify that they are not diverting nuclear energy from peaceful uses to nuclear weapons or other nuclear explosive devices (Article III).\nThe five NWS parties have made undertakings not to use their nuclear weapons against a non-NWS party except in response to a nuclear attack, or a conventional attack in alliance with a Nuclear Weapons State. However, these undertakings have not been incorporated formally into the treaty, and the exact details have varied over time. The U.S. also had nuclear warheads targeted at North Korea, a non-NWS, from 1959 until 1991. The previous United Kingdom Secretary of State for Defence, Geoff Hoon, has also explicitly invoked the possibility of the use of the country's nuclear weapons in response to a non-conventional attack by \"rogue states\". In January 2006, President Jacques Chirac of France indicated that an incident of state-sponsored terrorism on France could trigger a small-scale nuclear retaliation aimed at destroying the \"rogue state's\" power centers.\nSecurity provided by extended nuclear deterrence (also known as a nuclear umbrella) has been a factor limiting incentives for some NNWS to acquire nuclear weapons.\nSecond pillar: Disarmament.\nUnder Article VI of the NPT, all Parties undertake to pursue good-faith negotiations on effective measures relating to cessation of the nuclear arms race, to nuclear disarmament, and to general and complete disarmament.\nArticle VI of the NPT represents the only binding commitment in a multilateral treaty to the goal of disarmament by the nuclear-weapon states. The NPT's preamble contains language affirming the desire of treaty signatories to ease international tension and strengthen international trust so as to create someday the conditions for a halt to the production of nuclear weapons, and treaty on general and complete disarmament that liquidates, in particular, nuclear weapons and their delivery vehicles from national arsenals.\nThe wording of the NPT's Article VI arguably imposes only a vague obligation on all NPT signatories to move in the general direction of nuclear and total disarmament, saying, \"Each of the Parties to the Treaty undertakes to pursue negotiations in good faith on effective measures relating to cessation of the nuclear arms race at an early date and to nuclear disarmament, and on a treaty on general and complete disarmament.\" Under this interpretation, Article VI does not strictly require all signatories to actually conclude a disarmament treaty. Rather, it only requires them \"to negotiate in good faith\".\nHowever, some governments, especially non-nuclear-weapon states belonging to the Non-Aligned Movement, have interpreted Article VI's language as constituting a formal and specific obligation on the NPT-recognized nuclear-weapon states to disarm themselves of nuclear weapons, and argue that these states have failed to meet their obligation. The International Court of Justice (ICJ), in its advisory opinion on the Legality of the Threat or Use of Nuclear Weapons, issued 8 July 1996, unanimously interprets the text of Article VI as implying that\nThere exists an obligation to pursue in good faith and bring to a conclusion negotiations leading to nuclear disarmament in all its aspects under strict and effective international control.\nThe ICJ opinion notes that this obligation involves all NPT parties (not just the nuclear weapon states) and does not suggest a specific time frame for nuclear disarmament.\nCritics of the NPT-recognized nuclear-weapon states (the United States, Russia, China, France, and the United Kingdom) sometimes argue that what they view as the failure of the NPT-recognized nuclear weapon states to disarm themselves of nuclear weapons, especially in the post\u2013Cold War era, has angered some non-nuclear-weapon NPT signatories of the NPT. Such failure, these critics add, provides justification for the non-nuclear-weapon signatories to quit the NPT and develop their own nuclear arsenals.\nOther observers have suggested that the linkage between proliferation and disarmament may also work the other way, i.e., that the failure to resolve proliferation threats in Iran and North Korea, for instance, will cripple the prospects for disarmament. No current nuclear weapons state, the argument goes, would seriously consider eliminating its last nuclear weapons without high confidence that other countries would not acquire them. Some observers have even suggested that the very progress of disarmament by the superpowers\u2014which has led to the elimination of thousands of weapons and delivery systems\u2014could eventually make the possession of nuclear weapons more attractive by increasing the perceived strategic value of a small arsenal. As one U.S. official and NPT expert warned in 2007, \"logic suggests that as the number of nuclear weapons decreases, the 'marginal utility' of a nuclear weapon as an instrument of military power increases. At the extreme, which it is precisely disarmament's hope to create, the strategic utility of even one or two nuclear weapons would be huge.\"\nThird pillar: Peaceful use of nuclear energy.\nNPT Article IV acknowledges the right of all Parties to develop nuclear energy for peaceful purposes and to benefit from international cooperation in this area, in conformity with their nonproliferation obligations. Article IV also encourages such cooperation. This so-called third pillar provides for the transfer of nuclear technology and materials to NPT Parties for peaceful purposes in the development of civilian nuclear energy programs in those countries, subject to IAEA safeguards to demonstrate that their nuclear programs are not being used for the development of nuclear weapons.\nAs the commercially popular light water reactor nuclear power station uses enriched uranium fuel, it follows that states must be able either to enrich uranium or purchase it on an international market. Mohamed ElBaradei, then Director General of the International Atomic Energy Agency, has called the spread of enrichment and reprocessing capabilities the \"Achilles' heel\" of the nuclear nonproliferation regime. As of 2007, 13 states have an enrichment capability.\nDuring the 1960s and 1970s many states, almost 60, were supplied with research reactors fuelled by weapon grade highly enriched uranium (HEU) through the United States Atoms for Peace program and a similar Soviet Union program. In the 1980s a program to convert HEU research reactors to use low enriched fuel was started in the United States due to proliferation concerns. However 26 states possessed more than 1\u00a0kg of civilian HEU in 2015, and as of 2016 the stocks of HEU for civilian research were 60 tonnes, with 74 research reactors still using HEU.\nBecause the availability of fissile material has long been considered the principal obstacle to, and \"pacing element\" for, a country's nuclear weapons development effort, it was declared a major emphasis of U.S. policy in 2004 to prevent the further spread of uranium enrichment and plutonium reprocessing (a.k.a. \"ENR\") technology. Countries possessing ENR capabilities, it is feared, have what is in effect the option of using this capability to produce fissile material for weapons use on demand, thus giving them what has been termed a \"virtual\" nuclear weapons program. The degree to which NPT members have a \"right\" to ENR technology notwithstanding its potentially grave proliferation implications, therefore, is at the cutting edge of policy and legal debates surrounding the meaning of Article IV and its relation to Articles I, II, and III of the treaty.\nCountries that have become Parties to the NPT as non-nuclear-weapon States have a strong record of not building nuclear weapons, although some tried and one eventually left the NPT and acquired nuclear weapons. Iraq was found by the IAEA to have violated its safeguards obligations and subject to punitive sanctions by the UN Security Council. North Korea never came into compliance with its NPT safeguards agreement and was cited repeatedly for these violations, and later withdrew from the NPT and tested multiple nuclear devices. Iran was found in non-compliance with its NPT safeguards obligations in an unusual non-consensus decision because it \"failed in a number of instances over an extended period of time\" to report aspects of its enrichment program.&lt;ref name=\"IAEA-GOV/2003/75\"&gt;&lt;/ref&gt;&lt;ref name=\"IAEA-GOV/2005/77\"&gt;&lt;/ref&gt; In 1991, Romania reported previously undeclared nuclear activities by the former regime and the IAEA reported this non-compliance to the Security Council for information only. Libya pursued a clandestine nuclear weapons program before abandoning it in December 2003. The IAEA reported Syria's safeguards non-compliance to the UN Security Council, which did not take action.\nIn some regions, the fact that all neighbors are verifiably free of nuclear weapons reduces any pressure individual states might feel to build those weapons themselves, even if neighbors are known to have peaceful nuclear energy programs that might otherwise be suspicious. In this, the treaty works as designed.\nIn 2004, Mohamed ElBaradei said that by some estimates thirty-five to forty states could have the knowledge to develop nuclear weapons.\nKey articles.\n\"Article I\": Each nuclear-weapons state (NWS) undertakes not to transfer, to any recipient, nuclear weapons, or other nuclear explosive devices, and not to assist any non-nuclear weapon state to manufacture or acquire such weapons or devices.\n\"Article II\": Each non-NWS party undertakes not to receive, from any source, nuclear weapons, or other nuclear explosive devices; not to manufacture or acquire such weapons or devices; and not to receive any assistance in their manufacture.\n\"Article III\": Each non-NWS party undertakes to conclude an agreement with the IAEA for the application of its safeguards to all nuclear material in all of the state's peaceful nuclear activities and to prevent diversion of such material to nuclear weapons or other nuclear explosive devices.\n\"Article IV\": 1. Nothing in this Treaty shall be interpreted as affecting the inalienable right of all the Parties to the Treaty to develop research, production and use of nuclear energy for peaceful purposes without discrimination and in conformity with Articles I and II of this Treaty.\n2. All the Parties to the Treaty undertake to facilitate, and have the right to participate in, the fullest possible exchange of equipment, materials and scientific and technological information for the peaceful uses of nuclear energy. Parties to the Treaty in a position to do so shall also co-operate in contributing alone or together with other States or international organizations to the further development of the applications of nuclear energy for peaceful purposes, especially in the territories of non-nuclear-weapon States Party to the Treaty, with due consideration for the needs of the developing areas of the world.\n\"Article VI\": Each party \"undertakes to pursue negotiations in good faith on effective measures relating to cessation of the nuclear arms race at an early date and to nuclear disarmament, and on a Treaty on general and complete disarmament under strict and effective international control\".\n\"Article IX\": \"For the purposes of this Treaty, a nuclear-weapon State is one which has manufactured and exploded a nuclear weapon or other nuclear explosive device prior to 1 January 1967.\"\n\"Article X\": Establishes the right to withdraw from the Treaty giving 3 months' notice. It also establishes the duration of the Treaty (25 years before 1995 Extension Initiative).\nHistory.\nThe impetus behind the NPT was concern for the safety of a world with many nuclear weapon states. It was recognized that the Cold War deterrent relationship between just the United States and the Soviet Union was fragile. Having more nuclear-weapon states would reduce security for all, multiplying the risks of miscalculation, accidents, unauthorized use of weapons, escalation in tensions, and nuclear conflict. Moreover, since the use of nuclear weapons in Hiroshima and Nagasaki in 1945, it has been apparent that the development of nuclear capabilities by States could enable them to divert technology and materials for weapons purposes. Thus, the problem of preventing such diversions became a central issue in discussions on peaceful uses of nuclear energy.\nInitial efforts, which began in 1946, to create an international system enabling all States to have access to nuclear technology under appropriate safeguards, were terminated in 1949 without the achievement of this objective, due to serious political differences between the major Powers. By then, both the United States and the former Soviet Union had tested nuclear weapons, and were beginning to build their stockpiles.\nIn December 1953, US President Dwight D. Eisenhower, in his \"Atoms for Peace\" proposal, presented to the eighth session of the United Nations General Assembly, urged that an international organization be established to disseminate peaceful nuclear technology, while guarding against development of weapons capabilities in additional countries. His proposal resulted in 1957 in the establishment of the International Atomic Energy Agency (IAEA), which was charged with the dual responsibility for promotion and control of nuclear technology. IAEA technical activities began in 1958. An interim safeguards system for small nuclear reactors, put in place in 1961, was replaced in 1964 by a system covering larger installations and, over the following years, was expanded to include additional nuclear facilities. In recent years, efforts to strengthen the effectiveness and improve the efficiency of the IAEA safeguards system culminated in the approval of the Model Additional Protocol by the IAEA Board of Governors in May 1997.\nWithin the framework of the United Nations, the principle of nuclear non-proliferation was addressed in negotiations as early as 1957. The NPT process was launched by Frank Aiken, Irish Minister for External Affairs, in 1958. The NPT gained significant momentum in the early 1960s. The structure of a treaty to uphold nuclear non-proliferation as a norm of international behaviour had become clear by the mid-1960s, and by 1968 final agreement had been reached on a Treaty that would prevent the proliferation of nuclear weapons, enable cooperation for the peaceful use of nuclear energy, and further the goal of achieving nuclear disarmament. It was opened for signature in 1968, with Finland the first State to sign. Accession became nearly universal after the end of the Cold War and of South African apartheid. In 1992, The People's Republic of China and France acceded to the NPT, the last of the five nuclear powers recognized by the treaty to do so.\nThe treaty provided, in article X, for a conference to be convened 25 years after its entry into force to decide whether the treaty should continue in force indefinitely, or be extended for an additional fixed period or periods. Accordingly, at the NPT Review and Extension Conference in May 1995, state parties to the treaty agreed\u2014without a vote\u2014on the treaty's indefinite extension, and decided that review conferences should continue to be held every five years. After Brazil acceded to the NPT in 1998, the only remaining non-nuclear-weapon state which had not signed was Cuba, which joined the NPT (and the Treaty of Tlatelolco NWFZ) in 2002.\nSeveral NPT states parties have given up nuclear weapons or nuclear weapons programs. South Africa undertook a nuclear weapons program, but has since renounced it and acceded to the treaty in 1991 after destroying its small nuclear arsenal; after this, the remaining African countries signed the treaty.\nThe former Soviet Republics where nuclear weapons had been based, namely Ukraine, Belarus and Kazakhstan, transferred those weapons to Russia and joined the NPT by 1994 following the signature of the Budapest Memorandum on Security Assurances.\nSuccessor states from the Breakup of Yugoslavia and Dissolution of Czechoslovakia also joined the treaty soon after their independence. Montenegro and East Timor were the last countries to accede to the treaty on their independence in 2006 and 2003; the only other country to accede in the 21st century was Cuba in 2002. The three Micronesian countries in Compact of Free Association with the USA joined the NPT in 1995, alongside Vanuatu.\nMajor South American countries Argentina, Chile, and Brazil joined in 1995 and 1998. Arabian Peninsula countries included Saudi Arabia and Bahrain in 1988, Qatar and Kuwait in 1989, UAE in 1995, and Oman in 1997. The European states of Monaco and Andorra joined in 1995\u20136. Also acceding in the 1990s were Myanmar in 1992 and Guyana in 1993.\nUnited States\u2013NATO nuclear weapons sharing.\nAt the time the treaty was being negotiated, NATO had in place secret nuclear weapons sharing agreements whereby the United States provided nuclear weapons to be deployed by, and stored in, other NATO states. Some argue this is an act of proliferation violating Articles I and II of the treaty. A counter-argument is that the U.S. controlled the weapons in storage within the NATO states, and that no transfer of the weapons or control over them was intended \"unless and until a decision were made to go to war, at which the treaty would no longer be controlling\", so there is no breach of the NPT. These agreements were disclosed to a few of the states, including the Soviet Union, negotiating the treaty, but most of the states that signed the NPT in 1968 would not have known about these agreements and interpretations at that time.\nAs of 2005, it is estimated that the United States still provides about 180 tactical B61 nuclear bombs for use by Belgium, Germany, Italy, the Netherlands and Turkey under these NATO agreements. Many states, and the Non-Aligned Movement, now argue this violates Articles I and II of the treaty, and are applying diplomatic pressure to terminate these agreements. They point out that the pilots and other staff of the \"non-nuclear\" NATO states practice handling and delivering the U.S. nuclear bombs, and non-U.S. warplanes have been adapted to deliver U.S. nuclear bombs which must have involved the transfer of some technical nuclear weapons information. NATO believes its \"nuclear forces continue to play an essential role in war prevention, but their role is now more fundamentally political\".\nU.S. nuclear sharing policies were originally designed to help prevent the proliferation of nuclear weapons\u2014not least by persuading West Germany not to develop an independent nuclear capability by assuring it that West Germany would be able, in the event of war with the Warsaw Pact, to wield (U.S.) nuclear weapons in self-defense. (Until that point of all-out war, however, the weapons themselves would remain in U.S. hands.) The point was to limit the spread of countries having their own nuclear weapons programs, helping ensure that NATO allies would not choose to go down the proliferation route. (West Germany was discussed in U.S. intelligence estimates for a number of years as being a country with the potential to develop nuclear weapons capabilities of its own if officials in Bonn were not convinced that their defense against the Soviet Union and its allies could otherwise be met.)\nRussia's weapon deployment in Belarus.\nOn 27 February 2022, shortly after the 2022 Russian invasion of Ukraine, a referendum was staged in Belarus to remove a constitutional prohibition on basing nuclear weapons on its territory. On 25 June 2022, President of Belarus Lukashenko met Russian President Putin to discuss the deployment of Russian short-range nuclear-capable missiles on the territory of Belarus. The transfer of nuclear warheads would require a further decision, possibly after a number of years, and could be tied to future NATO decisions.\nIn Belarus, Russia plans to deploy nuclear-capable Iskander-M missile systems. Both conventional and nuclear versions of the missile would be provided under the plans. Additionally, Putin said that he would facilitate the modifications necessary for Belarusian Su-25 bombers to carry nuclear missiles.\nOn 14 June 2023, president Lukashenko said that Russia had started moving tactical nuclear weapons into Belarus's territory. The Russian president had said the weapons were moved \"as a deterrence measure\" against threats to Russian statehood, and would not be controlled by Belarus. NATO saw no evidence in a change in Russia's nuclear position, and in June 2023 Ukrainian intelligence said that not a single warhead had yet been transferred. \nHowever, by March 2024, reports seemed to confirm that Russian nuclear weapons are now hosted on Belarusian territory. Even so, contemporaneous reports remained reticent to draw the definite conclusion that deployment had already occurred. In any case, by the end of 2024, president Lukashenko requested the deployment of nuclear-capable, Russian Oreshnik intermediate range ballistic missile; Putin confirmed the possibility of the missiles' deployment by the end of 2025.\nNon-parties.\nFour states\u2014India, Israel, Pakistan, and South Sudan\u2014have never signed the treaty. India and Pakistan have publicly disclosed their nuclear weapon programs, and Israel has a long-standing policy of deliberate ambiguity with regards to its nuclear program (see List of states with nuclear weapons).\nIndia.\nIndia has detonated nuclear devices, first in 1974 and again in 1998. It is estimated to have enough fissile material for more than 150 warheads and was among the few countries to have a no first use policy, a pledge not to use nuclear weapons unless first attacked by an adversary using nuclear weapons, however India's former NSA Shivshankar Menon signaled a significant shift from \"no first use\" to \"no first use against non-nuclear weapon states\" in a speech on the occasion of Golden Jubilee celebrations of the National Defence College in New Delhi on 21 October 2010, a doctrine Menon said reflected India's \"strategic culture, with its emphasis on minimal deterrence\".\nIndia argues that the NPT creates a club of \"nuclear haves\" and a larger group of \"nuclear have-nots\" by restricting the legal possession of nuclear weapons to those states that tested them before 1967, but the treaty never explains on what ethical grounds such a distinction is valid. India's then External Affairs Minister Pranab Mukherjee said during a visit to Tokyo in 2007: \"If India did not sign the NPT, it is not because of its lack of commitment for non-proliferation, but because we consider NPT as a flawed treaty and it did not recognize the need for universal, non-discriminatory verification and treatment.\" Although there have been unofficial discussions on creating a South Asian nuclear weapons free zone, including India and Pakistan, this is considered to be highly unlikely for the foreseeable future.\nIn early March 2006, India and the United States finalized an agreement, in the face of criticism in both countries, to restart cooperation on civilian nuclear technology. Under the deal India has committed to classify 14 of its 22 nuclear power plants as being for civilian use and to place them under IAEA safeguards. Mohamed ElBaradei, then Director General of the IAEA, welcomed the deal by calling India \"an important partner in the non-proliferation regime.\"\nIn December 2006, United States Congress approved the United States-India Peaceful Atomic Energy Cooperation Act, endorsing a deal that was forged during Prime Minister Manmohan Singh's visit to the United States in July 2005 and cemented during President Bush's visit to India earlier in 2006. The legislation allows for the transfer of civilian nuclear material to India. Despite its status outside the Nuclear Non-Proliferation Treaty, nuclear cooperation with India was permitted on the basis of its clean non-proliferation record, and India's need for energy fueled by its rapid industrialization and a billion-plus population.\nOn 1 August 2008, the IAEA approved the India Safeguards Agreement and on 6 September 2008, India was granted the waiver at the Nuclear Suppliers Group (NSG) meeting held in Vienna, Austria. The consensus was arrived after overcoming misgivings expressed by Austria, Ireland and New Zealand and is an unprecedented step in giving exemption to a country, which has not signed the NPT and the Comprehensive Nuclear-Test-Ban Treaty (CTBT). While India could commence nuclear trade with other willing countries. The U.S. Congress approved this agreement and President Bush signed it on 8 October 2008.\nWhen China announced expanded nuclear cooperation with Pakistan in 2010, proponents of arms control denounced both the deals, claiming that they weakened the NPT by facilitating nuclear programmes in states which are not parties to the NPT.\nAs of January 2011[ [update]], Australia, a top three uranium producer and home to world's largest known reserves, had continued its refusal to export uranium to India despite diplomatic pressure from India.\nIn November 2011, Australian Prime Minister Julia Gillard announced a desire to allow exports to India, a policy change which was authorized by her party's national conference in December. The following month, Gillard overturned Australia's long-standing ban on exporting uranium to India. She further said, \"We should take a decision in the national interest, a decision about strengthening our strategic partnership with India in this the Asian century,\" and said that any agreement to sell uranium to India would include strict safeguards to ensure it would only be used for civilian purposes, and not end up in nuclear weapons.\nOn 5 September 2014 Tony Abbott, Gillard's successor as Australian Prime Minister, sealed a civil nuclear deal to sell uranium to India. \"We signed a nuclear cooperation agreement because Australia trusts India to do the right thing in this area, as it has been doing in other areas,\" Abbott told reporters after he and Indian Prime Minister Narendra Modi signed a pact to sell uranium for peaceful power generation.\nPakistan.\nIn May 1998, following India's nuclear tests earlier that month, Pakistan conducted two sets of nuclear tests, the Chagai-I and Chagai-II. Although there is little confirmed information in public, as of 2015, Pakistan was estimated to have as many as 120 warheads. According to analyses of the Carnegie Endowment for International Peace and the Stimson Center, Pakistan has enough fissile material for 350 warheads.\nPakistani officials argue that the NPT is discriminatory. When asked at a briefing in 2015 whether Islamabad would sign the NPT if Washington requested it, Foreign Secretary Aizaz Ahmad Chaudhry was quoted as responding \"It is a discriminatory treaty. Pakistan has the right to defend itself, so Pakistan will not sign the NPT. Why should we?\" Until 2010, Pakistan had always maintained the position that it would sign the NPT if India did so. In 2010, Pakistan abandoned this historic position and stated that it would join the NPT only as a recognized nuclear-weapon state.\nThe NSG Guidelines currently rule out nuclear exports by all major suppliers to Pakistan, with very narrow exceptions, since it does not have full-scope IAEA safeguards (i.e. safeguards on all its nuclear activities). Pakistan has sought to reach an agreement similar to that with India, but these efforts have been rebuffed by the United States and other NSG members, on the grounds that Pakistan's track record as a nuclear proliferator makes it impossible for it to have any sort of nuclear deal in the near future.\nBy 2010, China reportedly signed a civil nuclear agreement with Pakistan, using the justification that the deal was \"peaceful\". The British government criticized this, on the grounds that 'the time is not yet right for a civil nuclear deal with Pakistan'. China did not seek formal approval from the nuclear suppliers group, and claimed instead that its cooperation with Pakistan was \"grandfathered\" when China joined the NSG, a claim that was disputed by other NSG members. Pakistan applied for membership on 19 May 2016, supported by Turkey and China However, many NSG members opposed Pakistan's membership bid due to its track record, including the illicit procurement network of Pakistani scientist A.Q. Khan, which aided the nuclear programs of Iran, Libya and North Korea. Pakistani officials reiterated the request in August 2016.\nIsrael.\nIsrael has a long-standing policy of deliberate ambiguity with regards to its nuclear program (see List of countries with nuclear weapons). Israel has been developing nuclear technology at its Dimona site in the Negev since 1958, and some nonproliferation analysts estimate that Israel may have stockpiled between 100 and 200 warheads using reprocessed plutonium. The position on the NPT is explained in terms of \"Israeli exceptionality\", a term coined by Professor Gerald M. Steinberg, in reference to the perception that the country's small size, overall vulnerability, as well as the history of deep hostility and large-scale attacks by neighboring states, require a deterrent capability.\nThe Israeli government refuses to confirm or deny possession of nuclear weapons, although this is now regarded as an open secret after Israeli junior nuclear technician Mordechai Vanunu\u2014subsequently arrested and sentenced for treason by Israel\u2014published evidence about the program to the British \"Sunday Times\" in 1986.\nOn 18 September 2009, the General Conference of the International Atomic Energy Agency called on Israel to open its nuclear facilities to IAEA inspection and adhere to the non-proliferation treaty as part of a resolution on \"Israeli nuclear capabilities\", which passed by a narrow margin of 49\u201345 with 16 abstentions. The chief Israeli delegate stated that \"Israel will not co-operate in any matter with this resolution.\" However, similar resolutions were defeated in 2010, 2013, 2014, and 2015. As with Pakistan, the NSG Guidelines currently rule out nuclear exports by all major suppliers to Israel.\nOther states.\nNorth Korea.\nNorth Korea acceded to the treaty on 12 December 1985 in order to obtain assistance from the Soviet Union in the construction of four light-water reactors, but was found to be in noncompliance with its IAEA safeguards agreement after a series of inspections in 1992-93 which determined that North Korea had not fully declared its history of reprocessing spent fuel at the Yongbyon nuclear facility. North Korea responded by announcing its intent to withdraw from the treaty on 12 March 1993, and President Bill Clinton responded by announcing sanctions and considering military action. The crisis ended with the Agreed Framework negotiated by former US President Jimmy Carter in which North Korea agreed to an IAEA-monitored freeze of plutonium production facilities and construction of new reactors in exchange for two light-water reactors and heavy fuel oil shipments through the US-led Korean Peninsula Energy Development Organization consortium. North Korea also abandoned its withdrawal from the NPT.\nDuring the late 1990s and the early 2000s critics of the agreement, as well as Clinton's successor George W. Bush, expressed skepticism on North Korean compliance to the Agreed Framework. During 2002 negotiations US Assistant Secretary of State James A. Kelly accused North Korea of a secret highly enriched uranium program; North Korean First Vice Foreign Minister Kang Sok-ju and Vice Foreign Minister Kim Kye-gwan responded by denying the allegations but asserting that North Korea had a right to nuclear weapons. The U.S. subsequently halted fuel oil shipments to North Korea in December 2002 and the DPRK government again gave notice of withdrawal from NPT on 10 January 2003. The withdrawal became effective 10 April 2003 making North Korea the first state ever to withdraw from the treaty.\nIn April 2003, North Korea agreed to the multilateral six-party talks to find a diplomatic solution to the issue hosted by China and including the United States, South Korea, Russia, and Japan. North Korea initially demanded resumption of fuel shipments, while the United States demanded the \"complete, verifiable, and irreversible dismantlement\" of the North Korean nuclear program. On 10 February 2005, North Korea publicly declared that it possessed nuclear weapons and pulled out of the six-party talks. \"We had already taken the resolute action of pulling out of the Nuclear Non-Proliferation Treaty and have manufactured nuclear arms for self-defence to cope with the Bush administration's evermore undisguised policy to isolate and stifle the DPRK [Democratic People's Republic of Korea],\" a North Korean Foreign Ministry statement said regarding the issue. Six-party talks resumed in July 2005.\nOn 19 September 2005, North Korea announced that it would agree to a preliminary accord. Under the accord, North Korea would scrap all of its existing nuclear weapons and nuclear production facilities, rejoin the NPT, and readmit IAEA inspectors. The difficult issue of the supply of light water reactors to replace North Korea's indigenous nuclear power plant program, as per the 1994 Agreed Framework, was left to be resolved in future discussions. On the next day North Korea reiterated its known view that until it is supplied with a light water reactor it will not dismantle its nuclear arsenal or rejoin the NPT. The six-party talks eventually collapsed before a final agreement could be negotiated after the U.S. State Department sanctioned Banco Delta Asia under Section 311 of the Patriot Act for money-laundering involving North Korean accounts.\nOn 2 October 2006, the North Korean foreign minister announced that his country was planning to conduct a nuclear test \"in the future\", although it did not state when. On Monday, 9 October 2006 at 01:35:28 (UTC) the United States Geological Survey detected a magnitude 4.3 seismic event north of Kimchaek, North Korea indicating a nuclear test. The North Korean government announced shortly afterward that they had completed a successful underground test of a nuclear fission device. After United Nations Security Council Resolution 1718 imposed sanctions on North Korea, the six-party talks resumed. In February 2007 the parties agreed to the Initial Actions for the Implementation for the Joint Statement in which North Korea would dismantle its nuclear weapons programs, including the Yongbyon reactor, in exchange for the return of frozen funds at Banco Delta Asia and foreign energy assistance. However, the agreement failed due to verification problems and North Korea fully withdrew from the six-party talks in 2009 after the other members condemned the 2009 North Korean missile tests, expelling all US and IAEA inspectors from the country. The UN responded by adopting United Nations Security Council Resolution 1874 expanding the sanctions regime.\nIn 2007, reports from Washington suggested that the 2002 CIA reports stating that North Korea was developing an enriched uranium weapons program, which led to North Korea leaving the NPT, had overstated or misread the intelligence. However, even apart from these press allegations, there remains some information in the public record indicating the existence of a uranium effort. Quite apart from the fact that North Korean First Vice Minister Kang Sok-ju at one point admitted the existence of a uranium enrichment program, Pakistan's then-President Musharraf revealed that the A.Q. Khan proliferation network had provided North Korea with a number of gas centrifuges designed for uranium enrichment. Additionally, press reports have cited U.S. officials to the effect that evidence obtained in dismantling Libya's WMD programs points toward North Korea as the source for Libya's uranium hexafluoride (UF6)\u2014which, if true, would mean that North Korea has a uranium conversion facility for producing feedstock for centrifuge enrichment. North Korea formally announced the existence of a uranium enrichment program in September 2009.\nIn 2011, after rising tensions over the North Korean nuclear program, the ROKS \"Cheonan\" sinking, and the bombardment of Yeonpyeong, North Korea began to express interest in returning to the six-party talks. Bilateral negotiations between North Korea and the United States after the death of Kim Jong-il led to the 29 February 2012 \"Leap Day Agreement\" in which North Korea would agree to allow IAEA inspections and resume the six-party talks. However, these diplomatic gains were quickly undercut by launching the Unha-3 rocket, leading the United States to suspend food aid. North Korea conducted further nuclear tests in 2013, January 2016, September 2016, and 2017, and announced that it was developing miniaturized warheads and intercontinental ballistic missiles. It also claimed that it had successfully detonated thermonuclear weapons in the January 2016 and 2017 tests. The North Korean nuclear weapons development led to the 2017\u20132018 North Korea crisis which nearly led to war, with both North Korean Supreme Leader Kim Jong-un and US President Donald Trump threatening military action. The crisis was averted after a series of meetings between Kim Jong-un, US Secretary of State Mike Pompeo, and South Korean President Moon Jae-in finally culminating with the 2018 North Korea\u2013United States Singapore Summit between Trump and Kim, the first face-to-face meeting between the US and North Korean heads of state. The IAEA has called for North Korea to rejoin it and the NPT since 2013.\nIran.\nIran is a party to the NPT since 1970, but was found in non-compliance with its NPT safeguards agreement, and the status of its nuclear program remains in dispute. In November 2003 IAEA Director General Mohamed ElBaradei reported that Iran had repeatedly and over an extended period failed to meet its safeguards obligations under the NPT with respect to:\nAfter about two years of EU3-led diplomatic efforts and Iran temporarily suspending its enrichment program, the IAEA Board of Governors, acting under Article XII.C of the IAEA Statute, found in a rare non-consensus decision with 12 abstentions that these failures constituted non-compliance with the IAEA safeguards agreement. This was reported to the UN Security Council in 2006, after which the Security Council passed a resolution demanding that Iran suspend its enrichment.\nInstead, Iran resumed its enrichment program.\nThe IAEA has been able to verify the non-diversion of declared nuclear material in Iran, and is continuing its work on verifying the absence of undeclared activities. In February 2008, the IAEA also reported that it was working to address \"alleged studies\" of weaponization, based on documents provided by certain Member States, which those states claimed originated from Iran. Iran rejected the allegations as \"baseless\" and the documents as \"fabrications\". In June 2009, the IAEA reported that Iran had not \"cooperated with the Agency in connection with the remaining issues ... which need to be clarified to exclude the possibility of military dimensions to Iran's nuclear program.\"\nThe United States concluded that Iran violated its Article III NPT safeguards obligations, and further argued based on circumstantial evidence that Iran's enrichment program was for weapons purposes and therefore violated Iran's Article II nonproliferation obligations. The November 2007 US National Intelligence Estimate (NIE) later concluded with \"only moderate\" confidence, that Iran had halted a nuclear weapons program in the fall of 2003 \"primarily in response to increasing international scrutiny and pressure resulting from exposure of [its] previously undeclared nuclear work\", with \"moderate\" confidence that it \"probably would be technically capable of producing enough highly enriched uranium for a weapon sometime during the 2010-2015 time frame [with a lower level of confidence for weapon amounts of reprocessed plutonium in that time]\", and had not restarted those activities as of mid-2007, represented \"a halt to [its] entire nuclear weapons program.\"\nWhile describing the NIE's assessment of Iran's nuclear weapons program status as \"offer[ing] a ray of hope\", U.S. Special Representative for Nuclear Non-proliferation Christopher A. Ford was not convinced that Iran should be trusted to accumulate fissile material in the future, \"the principal obstacle that stands between it and nuclear weaponry.\" Ford emphasized the rapid growth of Iran's uranium enrichment program at Natanz, that it had \"remained committed to developing full-scale enrichment, and [was] pressing ahead with UNSC-proscribed activities\", and presumably, through his reference to plutonium reprocessing, its continued work on a heavy water reactor at Arak, which was begun covertly years before in conjunction with the very weaponization work that the NIE discussed. \"More international scrutiny and pressure [was] needed to ensure [Iran's] effort [could not] be restarted\". As The Bush Administration's Director of National Intelligence (DNI) Mike McConnell put it in 2008, the aspects of its work that Iran allegedly suspended were thus \"probably the least significant part of the program.\"\nIran stated it has a legal right to enrich uranium for peaceful purposes under the NPT, and further says that it had \"constantly complied with its obligations under the NPT and the Statute of the International Atomic Energy Agency\". Iran also stated that its enrichment program has been part of its civilian nuclear energy program, which is allowed under Article IV of the NPT. The Non-Aligned Movement has welcomed the continuing cooperation of Iran with the IAEA and reaffirmed Iran's right to the peaceful uses of nuclear technology.\nEarly during his tenure as United Nations Secretary General, between 2007 and 2016, Ban Ki-moon welcomed the continued dialogue between Iran and the IAEA. He urged a peaceful resolution of the issue.\nIn April 2010, during the signing of the U.S.-Russia New START Treaty, President Obama said that the United States, Russia, and other nations were demanding that Iran face consequences for failing to fulfill its obligations under the Nuclear Non-Proliferation Treaty, saying \"We will not tolerate actions that flout the NPT, risk an arms race in a vital region, and threaten the credibility of the international community and our collective security.\"\nIn 2010, Khamenei issued a fatwa declaring the use of nuclear weapons as forbidden by Islam and stated that Iran was not pursuing them.\nIn 2015, Iran negotiated a nuclear deal with the P5+1, a group of countries that consisted of the five permanent members of the UN Security Council (China, France, Russia, the United Kingdom, and the United States) plus Germany. On 14 July 2015, the P5+1 and Iran concluded the Joint Comprehensive Plan of Action (JCPOA), lifting sanctions on Iran in exchange for constraints and on Iran's nuclear activities and increased verification by the IAEA. \nOn 8 May 2018, President Donald Trump withdrew the United States from the JCPOA and reimposed sanctions on Iran.\nOn 16 June 2025, as a result of the ongoing 2025 Israel-Iran war, Iran announced that its parliament was drafting a bill to withdraw from the NPT.\nSouth Africa.\nSouth Africa is the only country that developed nuclear weapons by itself and later dismantled them\u2014unlike the former Soviet states Ukraine, Belarus and Kazakhstan, which inherited nuclear weapons from the former USSR and also acceded to the NPT as non-nuclear weapon states.\nDuring the days of apartheid, the South African government developed a deep fear of both a black uprising and the threat of communism. This led to the development of a secret nuclear weapons program as an ultimate deterrent. South Africa has a large supply of uranium, which is mined in the country's gold mines. The government built a nuclear research facility at Pelindaba near Pretoria where uranium was enriched to fuel grade for the Koeberg Nuclear Power Station as well as weapon grade for bomb production.\nIn 1991, after international pressure and when a change of government was imminent, South African Ambassador to the United States Harry Schwarz signed the Nuclear Non-Proliferation Treaty. In 1993, the then president Frederik Willem de Klerk openly admitted that the country had developed a limited nuclear weapon capability. These weapons were subsequently dismantled before South Africa acceded to the NPT and opened itself up to IAEA inspection. In 1994, the IAEA completed its work and declared that the country had fully dismantled its nuclear weapons program.\nLibya.\nLibya had signed (in 1968) and ratified (in 1975) the Nuclear Non-Proliferation Treaty and was subject to IAEA nuclear safeguards inspections, but undertook a secret nuclear weapons development program in violation of its NPT obligations, using material and technology provided by the A.Q. Khan proliferation network\u2014including actual nuclear weapons designs allegedly originating in China. Libya began secret negotiations with the United States and the United Kingdom in March 2003 over potentially eliminating its WMD programs. In October 2003, Libya was embarrassed by the interdiction of a shipment of Pakistani-designed centrifuge parts sent from Malaysia, also as part of A. Q. Khan's proliferation ring.\nIn December 2003, Libya announced that it had agreed to eliminate all its WMD programs, and permitted U.S. and British teams (as well as IAEA inspectors) into the country to assist this process and verify its completion. The nuclear weapons designs, gas centrifuges for uranium enrichment, and other equipment\u2014including prototypes for improved SCUD ballistic missiles\u2014were removed from Libya by the United States. (Libyan chemical weapons stocks and chemical bombs were also destroyed on site with international verification, with Libya joining the Chemical Weapons Convention.) Libya's non-compliance with its IAEA safeguards was reported to the U.N. Security Council, but with no action taken, as Libya's return to compliance with safeguards and Article II of the NPT was welcomed.\nIn 2011, the Libyan government of Muammar al-Gaddafi was overthrown in the Libyan Civil War with the assistance of a military intervention by NATO forces acting under the auspices of UN Security Council Resolution 1973. Gaddafi's downfall 8 years after the disarmament of Libya, in which Gaddafi agreed to eliminate Libya's nuclear weapons program, has been repeatedly cited by North Korea, which views Gaddafi's fate as a \"cautionary tale\" that influences North Korea's decision to maintain and intensify its nuclear weapons program and arsenal despite pressure to denuclearize.\nSyria.\nSyria is a state party to the NPT since 1969 and has a limited civil nuclear program. Before the advent of the Syrian Civil War it was known to operate only one small Chinese-built research reactor, SRR-1. Despite being a proponent of a Weapons of Mass Destruction Free Zone in the Middle East the country was accused of pursuing a military nuclear program with a reported nuclear facility in a desert Deir ez-Zor Governorate. The reactor's components had likely been designed and manufactured in North Korea, with the reactor's striking similarity in shape and size to the North Korean Yongbyon Nuclear Scientific Research Center. That information alarmed Israeli military and intelligence to such a degree that the idea of a targeted airstrike was conceived. It resulted in Operation Orchard, that took place on 6 September 2007 and saw as many as eight Israeli Air Force aircraft taking part. The Israeli government is said to have bounced the idea of the operation off of the US Bush administration, although the latter declined to participate. The nuclear reactor was destroyed in the attack, which also killed about ten North Korean workers. The attack did not cause an international outcry or any serious Syrian retaliatory moves as both parties tried to keep it secret: Despite a half-century state of war declared by surrounding states, Israel did not want publicity as regards its breach of the ceasefire, while Syria was not willing to acknowledge its clandestine nuclear program.\nUkraine.\nUkraine acceded to the NPT in 1994 as a non-nuclear-weapon state, and committed to remove all former Soviet nuclear weapons from its territory. In recognition of Ukraine's decision, the UK, the United States and Russia provided security assurances to Ukraine under the Budapest Memorandum of 1994.\nIn 1993, political scientist John Mearsheimer argued that the United States should encourage Ukraine to retain a nuclear deterrent against potential Russian expansion, and to reduce the danger of war. After the Russian invasion of 2014 Andreas Umland, an analyst from the Swedish Institute of International Affairs, argued that Ukraine had been unwise to give up its arsenal, as Russia breaking the treaty only had limited consequences, and demonstrated that only a nuclear arsenal guarantees a country's sovereignty in the face of aggression from a nuclear power. Mariana Budjeryn of Harvard Kennedy School's Belfer Center, argued that it was unclear whether Ukraine's nuclear arsenal would have kept it safe from Russian aggression. Establishing operative control and maintaining the missiles would have been challenging for Ukraine, which might have faced sanctions had it refused to give up its arsenal.\nLeaving the treaty.\nArticle X allows a state to leave the treaty if \"extraordinary events, related to the subject matter of this Treaty, have jeopardized the supreme interests of its country\", giving three months' (ninety days') notice. The state is required to give reasons for leaving the NPT in this notice.\nNorth Korea has also caused an uproar by its use of this provision of the treaty. Article X.1 only requires a state to give three months' notice in total, and does not provide for other states to question a state's interpretation of \"supreme interests of its country\". In 1993, North Korea gave notice to withdraw from the NPT. However, after 89 days, North Korea reached agreement with the United States to freeze its nuclear program under the Agreed Framework and \"suspended\" its withdrawal notice. In October 2002, the United States accused North Korea of violating the Agreed Framework by pursuing a secret uranium enrichment program, and suspended shipments of heavy fuel oil under that agreement. In response, North Korea expelled IAEA inspectors, disabled IAEA equipment, and, on 10 January 2003, announced that it was ending the suspension of its previous NPT withdrawal notification. North Korea said that only one more day's notice was sufficient for withdrawal from the NPT, as it had given 89 days before.\nThe IAEA Board of Governors rejected this interpretation. Most countries held that a new three-months withdrawal notice was required, and some questioned whether North Korea's notification met the \"extraordinary events\" and \"supreme interests\" requirements of the treaty. The Joint Statement of 19 September 2005 at the end of the Fourth Round of the Six-Party Talks called for North Korea to \"return\" to the NPT, implicitly acknowledging that it had withdrawn.\nRecent and coming events.\nThe main outcome of the 2000 Conference was the adoption by consensus of a comprehensive Final Document, which included among other things \"practical steps for the systematic and progressive efforts\" to implement the disarmament provisions of the NPT, commonly referred to as the Thirteen Steps.\nOn 18 July 2005, US President George W. Bush met Indian Prime Minister Manmohan Singh and declared that he would work to change US law and international rules to permit trade in US civilian nuclear technology with India. At the time, British columnist George Monbiot argued that the U.S.-India nuclear deal, in combination with US attempts to deny Iran (an NPT signatory) civilian nuclear fuel-making technology, might destroy the NPT regime.\nIn the first half of 2010, it was strongly believed that China had signed a civilian nuclear deal with Pakistan claiming that the deal was \"peaceful\".\nArms control advocates criticised the reported China-Pakistan deal as they did in case of U.S.-India deal claiming that both the deals violate the NPT by facilitating nuclear programmes in states which are not parties to the NPT. Some reports asserted that the deal was a strategic move by China to balance US influence in South-Asia.\nAccording to a report published by U.S. Department of Defense in 2001, China had provided Pakistan with nuclear materials and has given critical technological assistance in the construction of Pakistan's nuclear weapons development facilities, in violation of the Nuclear Non-Proliferation Treaty, of which China even then was a signatory.\nAt the Seventh Review Conference in May 2005, there were stark differences between the United States, which wanted the conference to focus on non-proliferation, especially on its allegations against Iran, and most other countries, who emphasized the lack of serious nuclear disarmament by the nuclear powers. The non-aligned countries reiterated their position emphasizing the need for nuclear disarmament.\nThe 2010 Review Conference was held in May 2010 in New York City, and adopted a final document that included a summary by the Review Conference President, Ambassador Libran Capactulan of the Philippines, and an Action Plan that was adopted by consensus. The 2010 conference was generally considered a success because it reached consensus where the previous Review Conference in 2005 ended in disarray. Many attributed the success of the 2010 conference to U.S. President Barack Obama's commitment to nuclear nonproliferation and disarmament. Some have warned that this success raised unrealistically high expectations that could lead to failure at the next Review Conference in 2015.\nThe \"Global Summit on Nuclear Security\" took place 12\u201313 April 2010. The summit was proposed by President Obama in Prague and was intended to strengthen the Nuclear Non-Proliferation Treaty in conjunction with the Proliferation Security Initiative and the Global Initiative to Combat Nuclear Terrorism. Forty seven states and three international organizations took part in the summit, which issued a communiqu\u00e9 and a work plan. For further information see 2010 Nuclear Security Summit.\nIn a major policy speech at the Brandenburg Gate in Berlin on 19 June 2013, Obama outlined plans to further reduce the number of warheads in the U.S. nuclear arsenal. According to \"Foreign Policy\", Obama proposed a \"one-third reduction in strategic nuclear warheads\u2014on top of the cuts already required by the New START treaty\u2014bringing the number of deployed warheads to about 1,000\". Obama is seeking to \"negotiate these reductions with Russia to continue to move beyond Cold War nuclear postures,\" according to briefing documents provided to \"Foreign Policy\". In the same speech, Obama emphasized his administration's efforts to isolate any nuclear weapons capabilities emanating from Iran and North Korea. He also called for a renewed bipartisan effort in the United States Congress to ratify the Comprehensive Nuclear-Test-Ban Treaty and called on countries to negotiate a new treaty to end the production of fissile material for nuclear weapons.\nOn 24 April 2014, it was announced that the nation of the Marshall Islands has brought suit in The Hague against the United States, the former Soviet Union, the United Kingdom, France, China, India, Pakistan, North Korea and Israel seeking to have the disarmament provisions of the NPT enforced.\nThe 2015 Review Conference of the Parties to the Treaty on the Non-Proliferation of Nuclear Weapons (NPT) was held at the United Nations in New York from 27 April to 22 May 2015 and presided over by Ambassador Taous Feroukhi of Algeria. The Treaty, particularly article VIII, paragraph 3, envisages a review of the operation of the Treaty every five years, a provision which was reaffirmed by the States parties at the 1995 NPT Review and Extension Conference and the 2000 NPT Review Conference. At the 2015 NPT Review Conference, States parties examined the implementation of the Treaty's provisions since 2010. Despite intensive consultations, the Conference was not able to reach agreement on the substantive part of the draft Final Document.\nThe Tenth Review Conference convened 1\u201326 August 2022, after a two-year postponement due to the COVID-19 pandemic, and concluded without adopting a final document. Contentious negotiations came close to consensus on a text, but ultimately Russia blocked consensus over issues related to its invasion of Ukraine, including references to the safety of the Zaporizhzhia Nuclear Power Plant in the draft text.\nOn June 23, 2023, The US Department of State issued a statement that the United States hosted the meeting on June 13\u201314 in Cairo among the five nuclear weapons states, describing it as \"an ongoing exchange in the context of the Nuclear Non-Proliferation Treaty (NPT).\"\nCriticism and responses.\nOver the years the NPT has come to be seen by many Third World states as \"a conspiracy of the nuclear 'haves' to keep the nuclear 'have-nots' in their place\". This argument has roots in Article VI of the treaty which \"obligates the nuclear weapons states to liquidate their nuclear stockpiles and pursue complete disarmament. The non-nuclear states see no signs of this happening\". Some argue that the NWS have not fully complied with their disarmament obligations under Article VI of the NPT. Some countries such as India have criticized the NPT, because it \"discriminated against states not possessing nuclear weapons on 1 January 1967,\" while Iran and numerous Arab states have criticized Israel for not signing the NPT. There has been disappointment with the limited progress on nuclear disarmament, where the five authorized nuclear weapons states still have 13,400 warheads (as of February 2021) among them.\nAs noted , the International Court of Justice, in its advisory opinion on the Legality of the Threat or Use of Nuclear Weapons, stated that \"there exists an obligation to pursue in good faith and bring to a conclusion negotiations leading to nuclear disarmament in all its aspects under strict and effective international control\". Some critics of the nuclear-weapons states contend that they have failed to comply with Article VI by failing to make disarmament the driving force in national planning and policy with respect to nuclear weapons, even while they ask other states to plan for their security without nuclear weapons.\nThe United States responds to criticism of its disarmament record by pointing out that, since the end of the Cold War, it has eliminated more than 13,000 nuclear weapons, and eliminated more than 80% of its deployed strategic warheads and 90% of non-strategic warheads deployed to NATO, in the process eliminating whole categories of warheads and delivery systems and reducing its reliance on nuclear weapons. U.S. officials have also pointed out the ongoing U.S. work to dismantle nuclear warheads. By the time accelerated dismantlement efforts ordered by President George W. Bush were completed, the U.S. arsenal was less than a quarter of its size at the end of the Cold War, and smaller than it had been at any point since the Eisenhower administration, well before the drafting of the NPT.\nThe United States has also purchased many thousands of weapons' worth of uranium formerly in Soviet nuclear weapons for conversion into reactor fuel. As a consequence of this latter effort, it has been estimated that the equivalent of one lightbulb in every ten in the United States is powered by nuclear fuel removed from warheads previously targeted at the United States and its allies during the Cold War.\nThe U.S. Special Representative for Nuclear Nonproliferation agreed that nonproliferation and disarmament are linked, noting that they can be mutually reinforcing but also that growing proliferation risks create an environment that makes disarmament more difficult. The United Kingdom, France and Russia likewise defend their nuclear disarmament records, and the five NPT NWS issued a joint statement in 2008 reaffirming their Article VI disarmament commitments.\nAccording to Thomas Reed and Danny Stillman, the \"NPT has one giant loophole\": Article IV gives each non-nuclear weapon state the \"inalienable right\" to pursue nuclear energy for the generation of power. A \"number of high-ranking officials, even within the United Nations, have argued that they can do little to stop states using nuclear reactors to produce nuclear weapons\". A 2009 United Nations report said that:\nThe revival of interest in nuclear power could result in the worldwide dissemination of uranium enrichment and spent fuel reprocessing technologies, which present obvious risks of proliferation as these technologies can produce fissile materials that are directly usable in nuclear weapons.\nAccording to critics, those states which possess nuclear weapons, but are not authorized to do so under the NPT, have not paid a significant price for their pursuit of weapons capabilities. Also, the NPT has been explicitly weakened by a number of bilateral deals made by NPT signatories, notably the United States.\nBased on concerns over the slow pace of nuclear disarmament and the continued reliance on nuclear weapons in military and security concepts, doctrines and policies, the Treaty on the Prohibition of Nuclear Weapons was adopted in July 2017 and was subsequently opened for signature on 20 September 2017. Entering into force on 22 January 2021, it prohibits each state party from the development, testing, production, stockpiling, stationing, transfer, use and threat of use of nuclear weapons, as well as assistance to those activities. It reaffirms in its preamble the vital role of the full and effective implementation of the NPT.\nIneffective enforcement of territorial integrity and rule of law in the 21st century could undermine the credibility of the security assurances that are part of the current global nuclear order.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22108", "revid": "33145", "url": "https://en.wikipedia.org/wiki?curid=22108", "title": "Nikolay Ivanovich Bukharin", "text": ""}
