{"id": "26833", "revid": "49998346", "url": "https://en.wikipedia.org/wiki?curid=26833", "title": "Scientific method", "text": "Interplay between observation, experiment, and theory in science\nThe scientific method is an empirical method for acquiring knowledge through careful observation, rigorous skepticism, hypothesis testing, and experimental validation. Developed from ancient and medieval practices, it acknowledges that cognitive assumptions can distort the interpretation of the observation. The scientific method has characterized science since at least the 17th century. Scientific inquiry includes creating a testable hypothesis through inductive reasoning, testing it through experiments and statistical analysis, and adjusting or discarding the hypothesis based on the results.\nAlthough procedures vary across fields, the underlying process is often similar. In more detail: the scientific method involves making conjectures (hypothetical explanations), predicting the logical consequences of hypothesis, then carrying out experiments or empirical observations based on those predictions. A hypothesis is a conjecture based on knowledge obtained while seeking answers to the question. Hypotheses can be very specific or broad but must be falsifiable, implying that it is possible to identify a possible outcome of an experiment or observation that conflicts with predictions deduced from the hypothesis; otherwise, the hypothesis cannot be meaningfully tested.\nWhile the scientific method is often presented as a fixed sequence of steps, it actually represents a set of general principles. Not all steps take place in every scientific inquiry (nor to the same degree), and they are not always in the same order. Numerous discoveries have not followed the textbook model of the scientific method, and, in some cases, chance has played a role.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\nThe history of the scientific method considers changes in the methodology of scientific inquiry, not the history of science itself. The development of rules for scientific reasoning has not been straightforward; the scientific method has been the subject of intense and recurring debate throughout the history of science, and eminent natural philosophers and scientists have argued for the primacy of various approaches to establishing scientific knowledge.\nDifferent early expressions of empiricism and the scientific method can be found throughout history, for instance with the ancient Stoics, Aristotle, Epicurus, Alhazen, Avicenna, Al-Biruni, Roger Bacon, and William of Ockham.\nIn the Scientific Revolution of the 16th and 17th centuries, some of the most important developments were the furthering of empiricism by Francis Bacon and Robert Hooke, the rationalist approach described by Ren\u00e9 Descartes, and inductivism, brought to particular prominence by Isaac Newton and those who followed him. Experiments were advocated by Francis Bacon and performed by Giambattista della Porta, Johannes Kepler, and Galileo Galilei. There was particular development aided by theoretical works by the skeptic Francisco Sanches, by idealists as well as empiricists John Locke, George Berkeley, and David Hume. C. S. Peirce formulated the hypothetico-deductive model in the 20th century, and the model has undergone significant revision since.\nThe term \"scientific method\" emerged in the 19th century, as a result of significant institutional development of science, and terminologies establishing clear boundaries between science and non-science, such as \"scientist\" and \"pseudoscience\". Throughout the 1830s and 1850s, when Baconianism was popular, naturalists like William Whewell, John Herschel, and John Stuart Mill engaged in debates over \"induction\" and \"facts,\" and were focused on how to generate knowledge. In the late 19th and early 20th centuries, a debate over realism vs. antirealism was conducted as powerful scientific theories extended beyond the realm of the observable.\nModern use and critical thought.\nThe term \"scientific method\" came into popular use in the twentieth century; Dewey's 1910 book, \"How We Think\", inspired popular guidelines. It appeared in dictionaries and science textbooks, although there was little consensus on its meaning. Although there was growth through the middle of the twentieth century, by the 1960s and 1970s numerous influential philosophers of science such as Thomas Kuhn and Paul Feyerabend had questioned the universality of the \"scientific method\", and largely replaced the notion of science as a homogeneous and universal method with that of it being a heterogeneous and local practice. In particular, Paul Feyerabend, in the 1975 first edition of his book \"Against Method\", argued against there being any universal rules of science; Karl Popper, and Gauch 2003, disagreed with Feyerabend's claim.\nLater stances include physicist Lee Smolin's 2013 essay \"There Is No Scientific Method\", in which he espouses two ethical principles, and historian of science Daniel Thurs' chapter in the 2015 book \"Newton's Apple and Other Myths about Science\", which concluded that the scientific method is a myth or, at best, an idealization. As myths are beliefs, they are subject to the narrative fallacy, as pointed out by Taleb. Philosophers Robert Nola and Howard Sankey, in their 2007 book \"Theories of Scientific Method\", said that debates over the scientific method continue, and argued that Feyerabend, despite the title of \"Against Method\", accepted certain rules of method and attempted to justify those rules with a meta methodology. \nStaddon (2017) argues it is a mistake to try following rules in the absence of an algorithmic scientific method; in that case, \"science is best understood through examples\". But algorithmic methods, such as \"disproof of existing theory by experiment\" have been used since Alhacen (1027) and his \"Book of Optics\", and Galileo (1638) and his \"Two New Sciences\", and \"The Assayer\", which still stand as scientific method.\nElements of inquiry.\nOverview.\nThe scientific method is the process by which science is carried out. As in other areas of inquiry, science (through the scientific method) can build on previous knowledge, and unify understanding of its studied topics over time. Historically, the development of the scientific method was critical to the Scientific Revolution.\nThe overall process involves making conjectures (hypotheses), predicting their logical consequences, then carrying out experiments based on those predictions to determine whether the original conjecture was correct. However, there are difficulties in a formulaic statement of method. The scientific method represents general principles rather than a fixed sequence, not all steps occur in every inquiry, nor always in the same order. It requires intelligence, imagination, and creativity rather than rigid adherence to procedure. \nFactors of scientific inquiry.\nThere are different ways of outlining the basic method used for scientific inquiry. The scientific community and philosophers of science generally agree on the following classification of method components. These methodological elements and organization of procedures tend to be more characteristic of experimental sciences than social sciences. Nonetheless, the cycle of formulating hypotheses, testing and analyzing the results, and formulating new hypotheses, will resemble the cycle described below.The scientific method is an iterative, cyclical process through which information is continually revised. It is generally recognized to develop advances in knowledge through the following elements, in varying combinations or contributions:\nEach element of the scientific method is subject to peer review for possible mistakes. These activities do not describe all that scientists do but apply mostly to experimental sciences (e.g., physics, chemistry, biology, and psychology). The elements above are often taught in the educational system as \"the scientific method\".\nThe scientific method is not a single recipe: it requires intelligence, imagination, and creativity. In this sense, it is not a mindless set of standards and procedures to follow but is rather an ongoing cycle, constantly developing more useful, accurate, and comprehensive models and methods. For example, when Einstein developed the Special and General Theories of Relativity, he did not in any way refute or discount Newton's \"Principia\". On the contrary, if the astronomically massive, the feather-light, and the extremely fast are removed from Einstein's theories \u2013 all phenomena Newton could not have observed \u2013 Newton's equations are what remain. Einstein's theories are expansions and refinements of Newton's theories and, thus, increase confidence in Newton's work.\nAn iterative, pragmatic scheme of the four points above is sometimes offered as a guideline for proceeding:\nThe iterative cycle inherent in this step-by-step method goes from point 3 to 6 and back to 3 again.\nWhile this schema outlines a typical hypothesis/testing method, many philosophers, historians, and sociologists of science, including Paul Feyerabend, claim that such descriptions of scientific method have little relation to the ways that science is actually practiced.\nCharacterizations.\nThe basic elements of the scientific method are illustrated by the following example (which occurred from 1944 to 1953) from the discovery of the structure of DNA (marked with and indented).\n In 1950, it was known that genetic inheritance had a mathematical description, starting with the studies of Gregor Mendel, and that DNA contained genetic information (Oswald Avery's \"transforming principle\"). But the mechanism of storing genetic information (i.e., genes) in DNA was unclear. Researchers in Bragg's laboratory at Cambridge University made X-ray diffraction pictures of various molecules, starting with crystals of salt, and proceeding to more complicated substances. Using clues painstakingly assembled over decades, beginning with its chemical composition, it was determined that it should be possible to characterize the physical structure of DNA, and the X-ray images would be the vehicle.\nThe scientific method depends upon increasingly sophisticated characterizations of the subjects of investigation. (The \"subjects\" can also be called or the \"unknowns\".) For example, Benjamin Franklin conjectured, correctly, that St. Elmo's fire was electrical in nature, but it has taken a long series of experiments and theoretical changes to establish this. While seeking the pertinent properties of the subjects, careful thought may also entail some definitions and observations; these observations often demand careful measurements and/or counting can take the form of expansive empirical research.\nA scientific question can refer to the explanation of a specific observation, as in \"Why is the sky blue?\" but can also be open-ended, as in \"How can I design a drug to cure this particular disease?\" This stage frequently involves finding and evaluating evidence from previous experiments, personal scientific observations or assertions, as well as the work of other scientists. If the answer is already known, a different question that builds on the evidence can be posed. When applying the scientific method to research, determining a good question can be very difficult and it will affect the outcome of the investigation.\nThe systematic, careful collection of measurements or counts of relevant quantities is often the critical difference between pseudo-sciences, such as alchemy, and science, such as chemistry or biology. Scientific measurements are usually tabulated, graphed, or mapped, and statistical manipulations, such as correlation and regression, performed on them. The measurements might be made in a controlled setting, such as a laboratory, or made on more or less inaccessible or unmanipulatable objects such as stars or human populations. The measurements often require specialized scientific instruments such as thermometers, spectroscopes, particle accelerators, or voltmeters, and the progress of a scientific field is usually intimately tied to their invention and improvement.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I am not accustomed to saying anything with certainty after only one or two observations.\u2014\u200a\nDefinition.\nThe scientific definition of a term sometimes differs substantially from its natural language usage. For example, mass and weight overlap in meaning in common discourse, but have distinct meanings in mechanics. Scientific quantities are often characterized by their units of measure which can later be described in terms of conventional physical units when communicating the work.\nNew theories are sometimes developed after realizing certain terms have not previously been sufficiently clearly defined. For example, Albert Einstein's first paper on relativity begins by defining simultaneity and the means for determining length. These ideas were skipped over by Isaac Newton with, \"I do not define , space, place and motion, as being well known to all.\" Einstein's paper then demonstrates that they (viz., absolute time and length independent of motion) were approximations. Francis Crick cautions us that when characterizing a subject, however, it can be premature to define something when it remains ill-understood. In Crick's study of consciousness, he actually found it easier to study awareness in the visual system, rather than to study free will, for example. His cautionary example was the gene; the gene was much more poorly understood before Watson and Crick's pioneering discovery of the structure of DNA; it would have been counterproductive to spend much time on the definition of the gene, before them.\nHypothesis development.\n Linus Pauling proposed that DNA might be a triple helix. This hypothesis was also considered by Francis Crick and James D. Watson but discarded. When Watson and Crick learned of Pauling's hypothesis, they understood from existing data that Pauling was wrong. and that Pauling would soon admit his difficulties with that structure.\nA hypothesis is a suggested explanation of a phenomenon, or alternately a reasoned proposal suggesting a possible correlation between or among a set of phenomena. Normally, hypotheses have the form of a mathematical model. Sometimes, but not always, they can also be formulated as existential statements, stating that some particular instance of the phenomenon being studied has some characteristic and causal explanations, which have the general form of universal statements, stating that every instance of the phenomenon has a particular characteristic.\nScientists are free to use whatever resources they have \u2013 their own creativity, ideas from other fields, inductive reasoning, Bayesian inference, and so on \u2013 to imagine possible explanations for a phenomenon under study. Albert Einstein once observed that \"there is no logical bridge between phenomena and their theoretical principles.\" Charles Sanders Peirce, borrowing a page from Aristotle (\"Prior Analytics\", 2.25) described the incipient stages of inquiry, instigated by the \"irritation of doubt\" to venture a plausible guess, as \"abductive reasoning\". The history of science is filled with stories of scientists claiming a \"flash of inspiration\", or a hunch, which then motivated them to look for evidence to support or refute their idea. Michael Polanyi made such creativity the centerpiece of his discussion of methodology.\nWilliam Glen observes that\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;the success of a hypothesis, or its service to science, lies not simply in its perceived \"truth\", or power to displace, subsume or reduce a predecessor idea, but perhaps more in its ability to stimulate the research that will illuminate\u00a0... bald suppositions and areas of vagueness.\u2014\u200a\nIn general, scientists tend to look for theories that are \"elegant\" or \"beautiful\". Scientists often use these terms to refer to a theory that is following the known facts but is nevertheless relatively simple and easy to handle. Occam's Razor serves as a rule of thumb for choosing the most desirable amongst a group of equally explanatory hypotheses.\nTo minimize the confirmation bias that results from entertaining a single hypothesis, strong inference emphasizes the need for entertaining multiple alternative hypotheses, and avoiding artifacts.\nPredictions from the hypothesis.\n James D. Watson, Francis Crick, and others hypothesized that DNA had a helical structure. This implied that DNA's X-ray diffraction pattern would be 'x shaped'. This prediction followed from the work of Cochran, Crick and Vand (and independently by Stokes). The Cochran-Crick-Vand-Stokes theorem provided a mathematical explanation for the empirical observation that diffraction from helical structures produces x-shaped patterns.\nIn their first paper, Watson and Crick also noted that the double helix structure they proposed provided a simple mechanism for DNA replication, writing, \"It has not escaped our notice that the specific pairing we have postulated immediately suggests a possible copying mechanism for the genetic material\".Any useful hypothesis will enable predictions, by reasoning including deductive reasoning. It might predict the outcome of an experiment in a laboratory setting or the observation of a phenomenon in nature. The prediction can also be statistical and deal only with probabilities.\nIt is essential that the outcome of testing such a prediction be currently unknown. Only in this case does a successful outcome increase the probability that the hypothesis is true. If the outcome is already known, it is called a consequence and should have already been considered while formulating the hypothesis.\nIf the predictions are not accessible by observation or experience, the hypothesis is not yet testable and so will remain to that extent unscientific in a strict sense. A new technology or theory might make the necessary experiments feasible. For example, while a hypothesis on the existence of other intelligent species may be convincing with scientifically based speculation, no known experiment can test this hypothesis. Therefore, science itself can have little to say about the possibility. In the future, a new technique may allow for an experimental test and the speculation would then become part of accepted science.\nFor example, Einstein's theory of general relativity makes several specific predictions about the observable structure of spacetime, such as that light bends in a gravitational field, and that the amount of bending depends in a precise way on the strength of that gravitational field. Arthur Eddington's observations made during a 1919 solar eclipse supported General Relativity rather than Newtonian gravitation.\nExperiments.\n Watson and Crick showed an initial (and incorrect) proposal for the structure of DNA to a team from King's College London \u2013 Rosalind Franklin, Maurice Wilkins, and Raymond Gosling. Franklin immediately spotted the flaws which concerned the water content. Later Watson saw Franklin's photo 51, a detailed X-ray diffraction image, which showed an X-shape and was able to confirm the structure was helical.\nOnce predictions are made, they can be sought by experiments. If the test results contradict the predictions, the hypotheses which entailed them are called into question and become less tenable. Sometimes the experiments are conducted incorrectly or are not very well designed when compared to a crucial experiment. If the experimental results confirm the predictions, then the hypotheses are considered more likely to be correct, but might still be wrong and continue to be subject to further testing. The experimental control is a technique for dealing with observational error. This technique uses the contrast between multiple samples, or observations, or populations, under differing conditions, to see what varies or what remains the same. We vary the conditions for the acts of measurement, to help isolate what has changed. Mill's canons can then help us figure out what the important factor is. Factor analysis is one technique for discovering the important factor in an effect.\nDepending on the predictions, the experiments can have different shapes. It could be a classical experiment in a laboratory setting, a double-blind study or an archaeological excavation. Even taking a plane from New York to Paris is an experiment that tests the aerodynamical hypotheses used for constructing the plane.\nThese institutions thereby reduce the research function to a cost/benefit, which is expressed as money, and the time and attention of the researchers to be expended, in exchange for a report to their constituents. Current large instruments, such as CERN's Large Hadron Collider (LHC), or LIGO, or the National Ignition Facility (NIF), or the International Space Station (ISS), or the James Webb Space Telescope (JWST), entail expected costs of billions of dollars, and timeframes extending over decades. These kinds of institutions affect public policy, on a national or even international basis, and the researchers would require shared access to such machines and their adjunct infrastructure.\nScientists assume an attitude of openness and accountability on the part of those experimenting. Detailed record-keeping is essential, to aid in recording and reporting on the experimental results, and supports the effectiveness and integrity of the procedure. They will also assist in reproducing the experimental results, likely by others. Traces of this approach can be seen in the work of Hipparchus (190\u2013120 BCE), when determining a value for the precession of the Earth, while controlled experiments can be seen in the works of al-Battani (853\u2013929 CE) and Alhazen (965\u20131039 CE).\nCommunication and iteration.\n Watson and Crick then produced their model, using this information along with the previously known information about DNA's composition, especially Chargaff's rules of base pairing. After considerable fruitless experimentation, being discouraged by their superior from continuing, and numerous false starts, Watson and Crick were able to infer the essential structure of DNA by concrete modeling of the physical shapes of the nucleotides which comprise it. They were guided by the bond lengths which had been deduced by Linus Pauling and by Rosalind Franklin's X-ray diffraction images.\nThe scientific method is iterative. At any stage, it is possible to refine its accuracy and precision, so that some consideration will lead the scientist to repeat an earlier part of the process. Failure to develop an interesting hypothesis may lead a scientist to re-define the subject under consideration. Failure of a hypothesis to produce interesting and testable predictions may lead to reconsideration of the hypothesis or of the definition of the subject. Failure of an experiment to produce interesting results may lead a scientist to reconsider the experimental method, the hypothesis, or the definition of the subject.\nThis manner of iteration can span decades and sometimes centuries. Published papers can be built upon. For example: By 1027, Alhazen, based on his measurements of the refraction of light, was able to deduce that outer space was less dense than air, that is: \"the body of the heavens is rarer than the body of air\". In 1079 Ibn Mu'adh's \"Treatise On Twilight\" was able to infer that Earth's atmosphere was 50 miles thick, based on atmospheric refraction of the sun's rays.\nThis is why the scientific method is often represented as circular \u2013 new information leads to new characterisations, and the cycle of science continues. Measurements collected can be archived, passed onwards and used by others. Other scientists may start their own research and enter the process at any stage. They might adopt the characterization and formulate their own hypothesis, or they might adopt the hypothesis and deduce their own predictions. Often the experiment is not done by the person who made the prediction, and the characterization is based on experiments done by someone else. Published results of experiments can also serve as a hypothesis predicting their own reproducibility.\nConfirmation.\nScience is a social enterprise, and scientific work tends to be accepted by the scientific community when it has been confirmed. Crucially, experimental and theoretical results must be reproduced by others within the scientific community. Researchers have given their lives for this vision; Georg Wilhelm Richmann was killed by ball lightning (1753) when attempting to replicate the 1752 kite-flying experiment of Benjamin Franklin.\nIf an experiment cannot be repeated to produce the same results, this implies that the original results might have been in error. As a result, it is common for a single experiment to be performed multiple times, especially when there are uncontrolled variables or other indications of experimental error. For significant or surprising results, other scientists may also attempt to replicate the results for themselves, especially if those results would be important to their own work. Replication has become a contentious issue in social and biomedical science where treatments are administered to groups of individuals. Typically an \"experimental group\" gets the treatment, such as a drug, and the \"control group\" gets a placebo. John Ioannidis in 2005 pointed out that the method being used has led to many findings that cannot be replicated.\nPeer review\u2014anonymous expert evaluation of research\u2014assesses experimental soundness rather than certifying correctness. Some journals request that the experimenter provide lists of possible peer reviewers, especially if the field is highly specialized. Specialists review methodology and design; if approved (sometimes requiring additional experiments), the prestige of the journal where the work is published indicates perceived quality.\nScientists typically are careful in recording their data, a requirement promoted by Ludwik Fleck (1896\u20131961) and others. Though not typically required, they might be requested to supply this data to other scientists who wish to replicate their original results (or parts of their original results), extending to the sharing of any experimental samples that may be difficult to obtain. To protect against bad science and fraudulent data, government research-granting agencies such as the National Science Foundation, and science journals, including \"Nature\" and \"Science\", have a policy that researchers must archive their data and methods so that other researchers can test the data and methods and build on the research that has gone before. Scientific data archiving can be done at several national archives in the U.S. or the World Data Center.\nFoundational principles.\nHonesty, openness, and falsifiability.\nThe unfettered principles of science are to strive for accuracy and the creed of honesty; openness already being a matter of degrees. Openness is restricted by the general rigour of scepticism. And of course the matter of non-science.\nSmolin, in 2013, espoused ethical principles rather than giving any potentially limited definition of the rules of inquiry. His ideas stand in the context of the scale of data\u2013driven and big science, which has seen increased importance of honesty and consequently reproducibility. His thought is that science is a community effort by those who have accreditation and are working within the community. He also warns against overzealous parsimony.\nPopper previously took ethical principles even further, going as far as to ascribe value to theories only if they were falsifiable. Popper used the falsifiability criterion to demarcate a scientific theory from a theory like astrology: both \"explain\" observations, but the scientific theory takes the risk of making predictions that decide whether it is right or wrong:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Those among us who are unwilling to expose their ideas to the hazard of refutation do not take part in the game of science.\"\u2014\u200a\nTheory's interactions with observation.\nScience has limits. Those limits are usually deemed to be answers to questions that aren't in science's domain, such as faith. Science has other limits as well, as it seeks to make true statements about reality. The nature of truth and the discussion on how scientific statements relate to reality is best left to the article on the philosophy of science here. More immediately topical limitations show themselves in the observation of reality.\nIt is the natural limitations of scientific inquiry that there is no pure observation as theory is required to interpret empirical data, and observation is therefore influenced by the observer's conceptual framework. As science is an unfinished project, this does lead to difficulties. Namely, that false conclusions are drawn, because of limited information.\nAn example here are the experiments of Kepler and Brahe, used by Hanson to illustrate the concept. Despite observing the same sunrise the two scientists came to different conclusions\u2014their intersubjectivity leading to differing conclusions. Johannes Kepler used Tycho Brahe's method of observation, which was to project the image of the Sun on a piece of paper through a pinhole aperture, instead of looking directly at the Sun. He disagreed with Brahe's conclusion that total eclipses of the Sun were impossible because, contrary to Brahe, he knew that there were historical accounts of total eclipses. Instead, he deduced that the images taken would become more accurate, the larger the aperture\u2014this fact is now fundamental for optical system design. Another historic example here is the discovery of Neptune, credited as being found via mathematics because previous observers didn't know what they were looking at.\nEmpiricism, rationalism, and more pragmatic views.\nScientific endeavour can be characterised as the pursuit of truths about the natural world or as the elimination of doubt about the same. The former is the direct construction of explanations from empirical data and logic, the latter the reduction of potential explanations. It was established above how the interpretation of empirical data is theory-laden, so neither approach is trivial.\nThe ubiquitous element in the scientific method is empiricism, which holds that knowledge is created by a process involving observation; scientific theories generalize observations. This is in opposition to stringent forms of rationalism, which holds that knowledge is created by the human intellect; later clarified by Popper to be built on prior theory. The scientific method embodies the position that reason alone cannot solve a particular scientific problem; it unequivocally refutes claims that revelation, political or religious dogma, appeals to tradition, commonly held beliefs, common sense, or currently held theories pose the only possible means of demonstrating truth.\nIn 1877, C. S. Peirce characterized inquiry in general not as the pursuit of truth \"per se\" but as the struggle to move from irritating, inhibitory doubts born of surprises, disagreements, and the like, and to reach a secure belief, the belief being that on which one is prepared to act. His pragmatic views framed scientific inquiry as part of a broader spectrum and as spurred, like inquiry generally, by actual doubt, not mere verbal or \"hyperbolic doubt\", which he held to be fruitless. This \"hyperbolic doubt\" Peirce argues against here is of course just another name for Cartesian doubt associated with Ren\u00e9 Descartes. It is a methodological route to certain knowledge by identifying what can't be doubted.\nA strong formulation of the scientific method is not always aligned with a form of empiricism in which the empirical data is put forward in the form of experience or other abstracted forms of knowledge as in current scientific practice the use of scientific modelling and reliance on abstract typologies and theories is normally accepted. In 2010, Hawking suggested that physics' models of reality should simply be accepted where they prove to make useful predictions. He calls the concept model-dependent realism.\nRationality.\nThe following section will first explore beliefs and biases, and then get to the rational reasoning most associated with the sciences.\nBeliefs and biases.\nScientific methodology often directs that hypotheses be tested in controlled conditions wherever possible. This is frequently possible in certain areas, such as in the biological sciences, and more difficult in other areas, such as in astronomy.\nThe practice of experimental control and reproducibility can have the effect of diminishing the potentially harmful effects of circumstance, and to a degree, personal bias. For example, pre-existing beliefs can alter the interpretation of results, as in confirmation bias; this is a heuristic that leads a person with a particular belief to see things as reinforcing their belief, even if another observer might disagree (in other words, people tend to observe what they expect to observe).\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[T]he action of thought is excited by the irritation of doubt, and ceases when belief is attained.\u2014\u200a\nA historical example is the belief that the legs of a galloping horse are splayed at the point when none of the horse's legs touch the ground, to the point of this image being included in paintings by its supporters. However, the first stop-action pictures of a horse's gallop by Eadweard Muybridge showed this to be false, and that the legs are instead gathered together.\nAnother important human bias that plays a role is a preference for new, surprising statements (see \"Appeal to novelty\"), which can result in a search for evidence that the new is true. Poorly attested beliefs can be believed and acted upon via a less rigorous heuristic.\nGoldhaber and Nieto published in 2010 the observation that if theoretical structures with \"many closely neighboring subjects are described by connecting theoretical concepts, then the theoretical structure acquires a robustness which makes it increasingly hard\u00a0\u2013 though certainly never impossible\u00a0\u2013 to overturn\". When a narrative is constructed its elements become easier to believe.\n notes \"Words and ideas are originally phonetic and mental equivalences of the experiences coinciding with them. ... Such proto-ideas are at first always too broad and insufficiently specialized. ... Once a structurally complete and closed system of opinions consisting of many details and relations has been formed, it offers enduring resistance to anything that contradicts it\". Sometimes, these relations have their elements assumed \"a priori\", or contain some other logical or methodological flaw in the process that ultimately produced them. Donald M. MacKay has analyzed these elements in terms of limits to the accuracy of measurement and has related them to instrumental elements in a category of measurement.\nDeductive and inductive reasoning.\nThe idea of there being two opposed justifications for truth has shown up throughout the history of scientific method as analysis versus synthesis, non-ampliative/ampliative, or even confirmation and verification. (And there are other kinds of reasoning.) One to use what is observed to build towards fundamental truths \u2013 and the other to derive from those fundamental truths more specific principles.\nDeductive reasoning derives specific conclusions from established general principles\u2014if the premises are true, the conclusion must be true. Inductive reasoning builds general principles from observations\u2014conclusions are probable but not guaranteed. Scientific inquiry employs both: induction generates hypotheses from observations; deduction predicts testable consequences. This process requires stringent scepticism regarding observed phenomena, because cognitive assumptions can distort the interpretation of initial perceptions.\nAn example for how inductive and deductive reasoning works can be found in the history of gravitational theory. It took thousands of years of measurements, from the Chaldean, Indian, Persian, Greek, Arabic, and European astronomers, to fully record the motion of planet Earth. Kepler(and others) were then able to build their early theories by generalizing the collected data inductively, and Newton was able to unify prior theory and measurements into the consequences of his laws of motion in 1727.\nAnother common example of inductive reasoning is the observation of a counterexample to current theory inducing the need for new ideas. Le Verrier in 1859 pointed out problems with the perihelion of Mercury that showed Newton's theory to be at least incomplete. The observed difference of Mercury's precession between Newtonian theory and observation was one of the things that occurred to Einstein as a possible early test of his theory of relativity. His relativistic calculations matched observation much more closely than Newtonian theory did. Though, today's Standard Model of physics suggests that we still do not know at least some of the concepts surrounding Einstein's theory, it holds to this day and is being built on deductively.\nA theory being assumed as true and subsequently built on is a common example of deductive reasoning. Theory building on Einstein's achievement can simply state that 'we have shown that this case fulfils the conditions under which general/special relativity applies, therefore its conclusions apply also'. If it was properly shown that 'this case' fulfils the conditions, the conclusion follows. An extension of this is the assumption of a solution to an open problem. This weaker kind of deductive reasoning will get used in current research, when multiple scientists or even teams of researchers are all gradually solving specific cases in working towards proving a larger theory. This often sees hypotheses being revised again and again as new proof emerges.\nThis way of presenting inductive and deductive reasoning shows part of why science is often presented as being a cycle of iteration. It is important to keep in mind that that cycle's foundations lie in reasoning, and not wholly in the following of procedure.\nCertainty, probabilities, and statistical inference.\nClaims of scientific truth can be opposed in three ways: by falsifying them, by questioning their certainty, or by asserting the claim itself to be incoherent. Incoherence, here, means internal errors in logic, like stating opposites to be true; falsification is what Popper would have called the honest work of conjecture and refutation \u2014 certainty, perhaps, is where difficulties in telling truths from non-truths arise most easily.\nScientific measurements include uncertainty estimates, calculated through repeated measurements, error propagation from underlying quantities, or sampling limitations. uncertainty. Counts of things may represent a sample of desired quantities, with an uncertainty that depends upon the sampling method used and the number of samples taken.\nIn the case of measurement imprecision, there will simply be a 'probable deviation' expressing itself in a study's conclusions. Statistics are different. Inductive statistical generalisation will take sample data and extrapolate more general conclusions, which has to be justified \u2014 and scrutinised. It can even be said that statistical models are only ever useful, but never a complete representation of circumstances.\nIn statistical analysis, expected and unexpected bias is a large factor. Research questions, the collection of data, or the interpretation of results, all are subject to larger amounts of scrutiny than in comfortably logical environments. Statistical models go through a process for validation, for which one could even say that awareness of potential biases is more important than the hard logic; errors in logic are easier to find in peer review, after all. More general, claims to rational knowledge, and especially statistics, have to be put into their appropriate context.&lt;ref name=\"Gauch Jr 2002 p30/ch4\"&gt;: Gauch gives two simplified statements on what he calls \"rational-knowledge claim\". It is either \"I hold belief X for reasons R with level of confidence C, where inquiry into X is within the domain of competence of method M that accesses the relevant aspects of reality\" (inductive reasoning) or \"I hold belief X because of presuppositions P.\" (deductive reasoning)&lt;/ref&gt; Simple statements such as '9 out of 10 doctors recommend' are therefore of unknown quality because they do not justify their methodology.\nLack of familiarity with statistical methodologies can result in erroneous conclusions. Foregoing the easy example, multiple probabilities interacting is where, for example medical professionals, have shown a lack of proper understanding. Bayes' theorem is the mathematical principle lining out how standing probabilities are adjusted given new information. The boy or girl paradox is a common example. In knowledge representation, Bayesian estimation of mutual information between random variables is a way to measure dependence, independence, or interdependence of the information under scrutiny.\nBeyond commonly associated survey methodology of field research, the concept together with probabilistic reasoning is used to advance fields of science where research objects have no definitive states of being. For example, in statistical mechanics.\nMethods of inquiry.\nHypothetico-deductive method.\nThe hypothetico-deductive model, or hypothesis-testing method, or \"traditional\" scientific method is, as the name implies, based on the formation of hypotheses and their testing via deductive reasoning. A hypothesis stating implications, often called predictions, that are falsifiable via experiment is of central importance here, as not the hypothesis but its implications are what is tested. Basically, scientists will look at the hypothetical consequences a (potential) theory holds and prove or disprove those instead of the theory itself. If an experimental test of those hypothetical consequences shows them to be false, it follows logically that the part of the theory that implied them was false also. If they show as true however, it does not prove the theory definitively.\nThe logic of this testing is what affords this method of inquiry to be reasoned deductively. The formulated hypothesis is assumed to be 'true', and from that 'true' statement implications are inferred. If the following tests show the implications to be false, it follows that the hypothesis was false also. If test show the implications to be true, new insights will be gained. It is important to be aware that a positive test here will at best strongly imply but not definitively prove the tested hypothesis, as deductive inference (A \u21d2 B) is not equivalent like that; only (\u00acB \u21d2 \u00acA) is valid logic. Their positive outcomes however, as Hempel put it, provide \"at least some support, some corroboration or confirmation for it\". This is why Popper insisted on fielded hypotheses to be falsifieable, as successful tests imply very little otherwise. As Gillies put it, \"successful theories are those that survive elimination through falsification\".\nDeductive reasoning in this mode of inquiry will sometimes be replaced by abductive reasoning\u2014the search for the most plausible explanation via logical inference. For example, in biology, where general laws are few, as valid deductions rely on solid presuppositions.\nInductive method.\nThe inductivist approach to deriving scientific truth first rose to prominence with Francis Bacon and particularly with Isaac Newton and those who followed him. After the establishment of the HD-method, it was often put aside as something of a \"fishing expedition\" though. It is still valid to some degree, but today's inductive method is often far removed from the historic approach\u2014the scale of the data collected lending new effectiveness to the method. It is most-associated with data-mining projects or large-scale observation projects. In both these cases, it is often not at all clear what the results of proposed experiments will be, and thus knowledge will arise after the collection of data through inductive reasoning.\nWhere the traditional method of inquiry does both, the inductive approach usually formulates only a research question, not a hypothesis. Following the initial question instead, a suitable \"high-throughput method\" of data-collection is determined, the resulting data processed and 'cleaned up', and conclusions drawn after. \"This shift in focus elevates the data to the supreme role of revealing novel insights by themselves\".\nThe advantage the inductive method has over methods formulating a hypothesis that it is essentially free of \"a researcher's preconceived notions\" regarding their subject. On the other hand, inductive reasoning is always attached to a measure of certainty, as all inductively reasoned conclusions are. This measure of certainty can reach quite high degrees, though. For example, in the determination of large primes, which are used in encryption software.\nMathematical modelling.\nMathematical modelling, or allochthonous reasoning, typically is the formulation of a hypothesis followed by building mathematical constructs that can be tested in place of conducting physical laboratory experiments. This approach has two main factors: simplification/abstraction and secondly a set of correspondence rules. The correspondence rules lay out how the constructed model will relate back to reality-how truth is derived; and the simplifying steps taken in the abstraction of the given system are to reduce factors that do not bear relevance and thereby reduce unexpected errors. These steps can also help the researcher in understanding the important factors of the system, how far parsimony can be taken until the system becomes more and more unchangeable and thereby stable. Parsimony and related principles are further explored below.\nOnce this translation into mathematics is complete, the resulting model, in place of the corresponding system, can be analysed through purely mathematical and computational means. The results of this analysis are of course also purely mathematical in nature and get translated back to the system as it exists in reality via the previously determined correspondence rules\u2014iteration following review and interpretation of the findings. The way such models are reasoned will often be mathematically deductive\u2014but they don't have to be. An example here are Monte-Carlo simulations. These generate empirical data \"arbitrarily\", and, while they may not be able to reveal universal principles, they can nevertheless be useful.\nScientific inquiry.\nScientific inquiry generally aims to obtain knowledge in the form of testable explanations that scientists can use to predict the results of future experiments. This allows scientists to gain a better understanding of the topic under study, and later to use that understanding to intervene in its causal mechanisms (such as to cure disease). The better an explanation is at making predictions, the more useful it frequently can be, and the more likely it will continue to explain a body of evidence better than its alternatives. The most successful explanations \u2013 those that explain and make accurate predictions in a wide range of circumstances \u2013 are often called scientific theories.\nMost experimental results do not produce large changes in human understanding; improvements in theoretical scientific understanding typically result from a gradual process of development over time, sometimes across different domains of science. Scientific models vary in the extent to which they have been experimentally tested and for how long, and in their acceptance in the scientific community. In general, explanations become accepted over time as evidence accumulates on a given topic, and the explanation in question proves more powerful than its alternatives at explaining the evidence. Often subsequent researchers re-formulate the explanations over time, or combined explanations to produce new explanations.\nProperties of scientific inquiry.\nScientific knowledge is closely tied to empirical findings and can remain subject to falsification if new experimental observations are incompatible with what is found. That is, no theory can ever be considered final since new problematic evidence might be discovered. If such evidence is found, a new theory may be proposed, or (more commonly) it is found that modifications to the previous theory are sufficient to explain the new evidence. The strength of a theory relates to how long it has persisted without major alteration to its core principles.\nTheories can also become subsumed by other theories. For example, Newton's laws explained thousands of years of scientific observations of the planets almost perfectly. However, these laws were then determined to be special cases of a more general theory (relativity), which explained both the (previously unexplained) exceptions to Newton's laws and predicted and explained other observations such as the deflection of light by gravity. Thus, in certain cases independent, unconnected, scientific observations can be connected, unified by principles of increasing explanatory power.\nSince new theories might be more comprehensive than what preceded them, and thus be able to explain more than previous ones, successor theories might be able to meet a higher standard by explaining a larger body of observations than their predecessors. For example, the theory of evolution explains the diversity of life on Earth, how species adapt to their environments, and many other patterns observed in the natural world; its most recent major modification was unification with genetics to form the modern evolutionary synthesis. In subsequent modifications, it has also subsumed aspects of many other fields such as biochemistry and molecular biology.\nHeuristics.\nConfirmation theory.\nDuring the course of history, one theory has succeeded another, and some have suggested further work while others have seemed content just to explain the phenomena. The reasons why one theory has replaced another are not always obvious or simple. The philosophy of science includes the question: \"What criteria are satisfied by a 'good' theory\". This question has a long history, and many scientists, as well as philosophers, have considered it. The objective is to be able to choose one theory as preferable to another without introducing cognitive bias. Though different thinkers emphasize different aspects, good theories are accurate, internally consistent, explanatory beyond required data, unifying of disparate phenomena, and fruitful for research. When empirical evidence is limited, scientists favor parsimony and invariant observations. Scientists will sometimes also list the very subjective criteria of \"formal elegance\" which can indicate multiple different things.\nThe goal here is to make the choice between theories less arbitrary. Nonetheless, these criteria contain subjective elements, and should be considered heuristics rather than a definitive. Also, criteria such as these do not necessarily decide between alternative theories. Quoting Bird:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"[Such criteria] cannot determine scientific choice. First, which features of a theory satisfy these criteria may be disputable (\"e.g.\" does simplicity concern the ontological commitments of a theory or its mathematical form?). Secondly, these criteria are imprecise, and so there is room for disagreement about the degree to which they hold. Thirdly, there can be disagreement about how they are to be weighted relative to one another, especially when they conflict.\"\nIt also is debatable whether existing scientific theories satisfy all these criteria, which may represent goals not yet achieved. For example, explanatory power over all existing observations is satisfied by no one theory at the moment.\nParsimony.\nThe desiderata of a \"good\" theory have been debated for centuries, going back perhaps even earlier than Occam's razor, which is often taken as an attribute of a good theory. Science tries to be simple. When gathered data supports multiple explanations, the most simple explanation for phenomena or the most simple formation of a theory is recommended by the principle of parsimony. Scientists go as far as to call simple proofs of complex statements \"beautiful\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We are to admit no more causes of natural things than such as are both true and sufficient to explain their appearances.\u2014\u200a\nThe concept of parsimony should not be held to imply complete frugality in the pursuit of scientific truth. The general process starts at the opposite end of there being a vast number of potential explanations and general disorder. An example can be seen in Paul Krugman's process, who makes explicit to \"dare to be silly\". He writes that in his work on new theories of international trade he reviewed prior work with an open frame of mind and broadened his initial viewpoint even in unlikely directions. Once he had a sufficient body of ideas, he would try to simplify and thus find what worked among what did not. Specific to Krugman here was to \"question the question\". He recognised that prior work had applied erroneous models to already present evidence, commenting that \"intelligent commentary was ignored\". Thus touching on the need to bridge the common bias against other circles of thought.\nElegance.\nOccam's razor might fall under the heading of \"simple elegance\", but it is arguable that \"parsimony\" and \"elegance\" pull in different directions. Introducing additional elements could simplify theory formulation, whereas simplifying a theory's ontology might lead to increased syntactical complexity.\nSometimes ad-hoc modifications of a failing idea may also be dismissed as lacking \"formal elegance\". This appeal to what may be called \"aesthetic\" is hard to characterise, but essentially about a sort of familiarity. Though, argument based on \"elegance\" is contentious and over-reliance on familiarity will breed stagnation.\nInvariance.\nPrinciples of invariance have been a theme in scientific writing, and especially physics, since at least the early 20th century. The basic idea here is that good structures to look for are those independent of perspective, an idea that has featured earlier of course for example in Mill's Methods of difference and agreement\u2014methods that would be referred back to in the context of contrast and invariance. But as tends to be the case, there is a difference between something being a basic consideration and something being given weight. Principles of invariance have only been given weight in the wake of Einstein's theories of relativity, which reduced everything to relations and were thereby fundamentally unchangeable, unable to be varied. As David Deutsch put it in 2009: \"the search for hard-to-vary explanations is the origin of all progress\".\nAn example here can be found in one of Einstein's thought experiments. The one of a lab suspended in empty space is an example of a useful invariant observation. He imagined the absence of gravity and an experimenter free floating in the lab. \u2014 If now an entity pulls the lab upwards, accelerating uniformly, the experimenter would perceive the resulting force as gravity. The entity however would feel the work needed to accelerate the lab continuously. Through this experiment Einstein was able to equate gravitational and inertial mass; something unexplained by Newton's laws, and an early but \"powerful argument for a generalised postulate of relativity\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The feature, which suggests reality, is always some kind of invariance of a structure independent of the aspect, the projection.\u2014\u200a\nThe discussion on invariance in physics is often had in the more specific context of symmetry. The Einstein example above, in the parlance of Mill would be an agreement between two values. In the context of invariance, it is a variable that remains unchanged through some kind of transformation or change in perspective. And discussion focused on symmetry would view the two perspectives as systems that share a relevant aspect and are therefore symmetrical.\nRelated principles here are falsifiability and testability. The opposite of something being \"hard-to-vary\" are theories that resist falsification\u2014a frustration that was expressed colourfully by Wolfgang Pauli as them being \"not even wrong\". The importance of scientific theories to be falsifiable finds especial emphasis in the philosophy of Karl Popper. The broader view here is testability, since it includes the former and allows for additional practical considerations.\nPhilosophy and discourse.\nPhilosophy of science looks at the underpinning logic of the scientific method, at what separates science from non-science, and the ethic that is implicit in science. There are basic assumptions, derived from philosophy by at least one prominent scientist, that form the base of the scientific method \u2013 namely, that reality is objective and consistent, that humans have the capacity to perceive reality accurately, and that rational explanations exist for elements of the real world. These assumptions from methodological naturalism form a basis on which science may be grounded. Logical positivist, empiricist, falsificationist, and other theories have criticized these assumptions and given alternative accounts of the logic of science, but each has also itself been criticized.\nThere are several kinds of modern philosophical conceptualizations and attempts at definitions of the method of science. The one attempted by the \"unificationists\", who argue for the existence of a unified definition that is useful (or at least 'works' in every context of science). The \"pluralists\", arguing degrees of science being too fractured for a universal definition of its method to by useful. And those, who argue that the very attempt at definition is already detrimental to the free flow of ideas.\nAdditionally, there have been views on the social framework in which science is done, and the impact of the sciences social environment on research. Also, there is 'scientific method' as popularised by Dewey in \"How We Think\" (1910) and Karl Pearson in \"Grammar of Science\" (1892), as used in fairly uncritical manner in education.\nPluralism.\nScientific pluralism is a position within the philosophy of science that rejects various proposed unities of scientific method and subject matter. Scientific pluralists hold that science is not unified in one or more of the following ways: the metaphysics of its subject matter, the epistemology of scientific knowledge, or the research methods and models that should be used. Some pluralists believe that pluralism is necessary due to the nature of science. Others say that since scientific disciplines already vary in practice, there is no reason to believe this variation is wrong until a specific unification is empirically proven. Finally, some hold that pluralism should be allowed for normative reasons, even if unity were possible in theory.\nUnificationism.\nUnificationism, in science, was a central tenet of logical positivism. Different logical positivists construed this doctrine in several different ways, e.g. as a reductionist thesis, that the objects investigated by the special sciences reduce to the objects of a common, putatively more basic domain of science, usually thought to be physics; as the thesis that all theories and results of the various sciences can or ought to be expressed in a common language or \"universal slang\"; or as the thesis that all the special sciences share a common scientific method.\nDevelopment of the idea has been troubled by accelerated advancement in technology that has opened up many new ways to look at the world.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The fact that the standards of scientific success shift with time does not only make the philosophy of science difficult; it also raises problems for the public understanding of science. We do not have a fixed scientific method to rally around and defend.\u2014\u200a\nEpistemological anarchism.\nPaul Feyerabend examined the history of science, and was led to deny that science is genuinely a methodological process. In his 1975 book \"Against Method\" he argued that no description of scientific method could possibly be broad enough to include all the approaches and methods used by scientists, and that there are no useful and exception-free methodological rules governing the progress of science. In essence, he said that for any specific method or norm of science, one can find a historic episode where violating it has contributed to the progress of science. He jokingly suggested that, if believers in the scientific method wish to express a single universally valid rule, it should be 'anything goes'. As has been argued before him however, this is uneconomic; problem solvers, and researchers are to be prudent with their resources during their inquiry.\nA more general inference against formalised method has been found through research involving interviews with scientists regarding their conception of method. This research indicated that scientists frequently encounter difficulty in determining whether the available evidence supports their hypotheses. This reveals that there are no straightforward mappings between overarching methodological concepts and precise strategies to direct the conduct of research.\nEducation.\nIn science education, the idea of a general and universal scientific method has been notably influential, and numerous studies (in the US) have shown that this framing of method often forms part of both students' and teachers' conception of science. This convention of traditional education has been argued against by scientists, as there is a consensus that educations' sequential elements and unified view of scientific method do not reflect how scientists actually work. Major organizations of scientists such as the American Association for the Advancement of Science (AAAS) consider the sciences to be a part of the liberal arts traditions of learning and proper understating of science includes understanding of philosophy and history, not just science in isolation.\nHow the sciences make knowledge has been taught in the context of \"the\" scientific method (singular) since the early 20th century. Various systems of education, including but not limited to the US, have taught the method of science as a process or procedure, structured as a definitive series of steps: observation, hypothesis, prediction, experiment.\nThis version of the method of science has been a long-established standard in primary and secondary education, as well as the biomedical sciences. It has long been held to be an inaccurate idealisation of how some scientific inquiries are structured.\nTraditional science education faced criticism for presenting an oversimplified, singular methodology that overemphasized experimentation, ignored social context, and suggested automatic knowledge generation through procedural steps.\nThe scientific method no longer features in the standards for US education of 2013 (NGSS) that replaced those of 1996 (NRC). They, too, influenced international science education, and the standards measured for have shifted since from the singular hypothesis-testing method to a broader conception of scientific methods. These scientific methods, which are rooted in scientific practices and not epistemology, are described as the 3 \"dimensions\" of scientific and engineering practices, crosscutting concepts (interdisciplinary ideas), and disciplinary core ideas.\nThe scientific method, as a result of simplified and universal explanations, is often held to have reached a kind of mythological status; as a tool for communication or, at best, an idealisation. Education's approach was heavily influenced by John Dewey's, \"How We Think (1910)\". Van der Ploeg (2016) indicated that Dewey's views on education had long been used to further an idea of citizen education removed from \"sound education\", claiming that references to Dewey in such arguments were undue interpretations (of Dewey).\nSociology of knowledge.\nThe sociology of knowledge is a concept in the discussion around scientific method, claiming the underlying method of science to be sociological. King explains that sociology distinguishes here between the system of ideas that govern the sciences through an inner logic, and the social system in which those ideas arise.\nThought collectives.\nA perhaps accessible lead into what is claimed is Fleck's thought, echoed in Kuhn's concept of normal science. According to Fleck, scientists' work is based on a thought-style, that cannot be rationally reconstructed. It gets instilled through the experience of learning, and science is then advanced based on a tradition of shared assumptions held by what he called \"thought collectives\". Fleck also claims this phenomenon to be largely invisible to members of the group.&lt;ref name=\"Fleck_comp_w/Kuhn\"&gt;&lt;/ref&gt;\nComparably, following the field research in an academic scientific laboratory by Latour and Woolgar, Karin Knorr Cetina has conducted a comparative study of two scientific fields (namely high energy physics and molecular biology) to conclude that the epistemic practices and reasonings within both scientific communities are different enough to introduce the concept of \"epistemic cultures\", in contradiction with the idea that a so-called \"scientific method\" is unique and a unifying concept.\nSituated cognition and relativism.\nOn the idea of Fleck's \"thought collectives\" sociologists built the concept of situated cognition: that the perspective of the researcher fundamentally affects their work; and, too, more radical views.\nNorwood Russell Hanson, alongside Thomas Kuhn and Paul Feyerabend, extensively explored the theory-laden nature of observation in science. Hanson introduced the concept in 1958, emphasizing that observation is influenced by the observer's conceptual framework. He used the concept of gestalt to show how preconceptions can affect both observation and description, and illustrated this with examples like the initial rejection of Golgi bodies as an artefact of staining technique, and the differing interpretations of the same sunrise by Tycho Brahe and Johannes Kepler. Intersubjectivity led to different conclusions.\nKuhn and Feyerabend acknowledged Hanson's pioneering work, although Feyerabend's views on methodological pluralism were more radical. Criticisms like those from Kuhn and Feyerabend prompted discussions leading to the development of the strong programme, a sociological approach that seeks to explain scientific knowledge without recourse to the truth or validity of scientific theories. It examines how scientific beliefs are shaped by social factors such as power, ideology, and interests.\nThe postmodernist critiques of science have themselves been the subject of intense controversy. This ongoing debate, known as the science wars, is the result of conflicting values and assumptions between postmodernist and realist perspectives. Postmodernists argue that scientific knowledge is merely a discourse, devoid of any claim to fundamental truth. In contrast, realists within the scientific community maintain that science uncovers real and fundamental truths about reality. Many books have been written by scientists which take on this problem and challenge the assertions of the postmodernists while defending science as a legitimate way of deriving truth.\nLimits of method.\nRole of chance in discovery.\nSomewhere between 33% and 50% of all scientific discoveries are estimated to have been \"stumbled upon\", rather than sought out. This may explain why scientists so often express that they were lucky. Scientists themselves in the 19th and 20th century acknowledged the role of fortunate luck or serendipity in discoveries. Louis Pasteur is credited with the famous saying that \"Luck favours the prepared mind\", but some psychologists have begun to study what it means to be 'prepared for luck' in the scientific context. Research is showing that scientists are taught various heuristics that tend to harness chance and the unexpected. This is what Nassim Nicholas Taleb calls \"Anti-fragility\"; while some systems of investigation are fragile in the face of human error, human bias, and randomness, the scientific method is more than resistant or tough \u2013 it actually benefits from such randomness in many ways (it is anti-fragile). Taleb believes that the more anti-fragile the system, the more it will flourish in the real world.\nPsychologist Kevin Dunbar says the process of discovery often starts with researchers finding bugs in their experiments. These unexpected results lead researchers to try to fix what they \"think\" is an error in their method. Eventually, the researcher decides the error is too persistent and systematic to be a coincidence. The highly controlled, cautious, and curious aspects of the scientific method are thus what make it well suited for identifying such persistent systematic errors. At this point, the researcher will begin to think of theoretical explanations for the error, often seeking the help of colleagues across different domains of expertise.\nRelationship with statistics.\nWhen the scientific method employs statistics as a key part of its arsenal, there are mathematical and practical issues that can have a deleterious effect on the reliability of the output of scientific methods. This is described in a popular 2005 scientific paper \"Why Most Published Research Findings Are False\" by John Ioannidis, which is considered foundational to the field of metascience. Much research in metascience seeks to identify poor use of statistics and improve its use, an example being the misuse of p-values.\nThe points raised are both statistical and economical. Statistically, research findings are less likely to be true when studies are small and when there is significant flexibility in study design, definitions, outcomes, and analytical approaches. Economically, the reliability of findings decreases in fields with greater financial interests, biases, and a high level of competition among research teams. As a result, most research findings are considered false across various designs and scientific fields, particularly in modern biomedical research, which often operates in areas with very low pre- and post-study probabilities of yielding true findings. Nevertheless, despite these challenges, most new discoveries will continue to arise from hypothesis-generating research that begins with low or very low pre-study odds. This suggests that expanding the frontiers of knowledge will depend on investigating areas outside the mainstream, where the chances of success may initially appear slim.\nScience of complex systems.\nScience applied to complex systems can involve elements such as transdisciplinarity, systems theory, control theory, and scientific modelling.\nIn general, the scientific method may be difficult to apply stringently to diverse, interconnected systems and large data sets. In particular, practices used within Big data, such as predictive analytics, may be considered to be at odds with the scientific method, as some of the data may have been stripped of the parameters which might be material in alternative hypotheses for an explanation; thus the stripped data would only serve to support the null hypothesis in the predictive analytics application. notes \"a scientific discovery remains incomplete without considerations of the social practices that condition it\".\nRelationship with mathematics.\nScience is the process of gathering, comparing, and evaluating proposed models against observables. A model can be a simulation, mathematical or chemical formula, or set of proposed steps. Science is like mathematics in that researchers in both disciplines try to distinguish what is \"known\" from what is \"unknown\" at each stage of discovery. Models, in both science and mathematics, need to be internally consistent and also ought to be \"falsifiable\" (capable of disproof). In mathematics, a statement need not yet be proved; at such a stage, that statement would be called a conjecture.\nMathematical work and scientific work can inspire each other. For example, the technical concept of time arose in science, and timelessness was a hallmark of a mathematical topic. But today, the Poincar\u00e9 conjecture has been proved using time as a mathematical concept in which objects can flow (see Ricci flow).\nNevertheless, the connection between mathematics and reality (and so science to the extent it describes reality) remains obscure. Eugene Wigner's paper, \"The Unreasonable Effectiveness of Mathematics in the Natural Sciences\", is a very well-known account of the issue from a Nobel Prize-winning physicist. In fact, some observers (including some well-known mathematicians such as Gregory Chaitin, and others such as Lakoff and N\u00fa\u00f1ez) have suggested that mathematics is the result of practitioner bias and human limitation (including cultural ones), somewhat like the post-modernist view of science.\nGeorge P\u00f3lya's work on problem solving, the construction of mathematical proofs, and heuristic show that the mathematical method and the scientific method differ in detail, while nevertheless resembling each other in using iterative or recursive steps.\nIn P\u00f3lya's view, \"understanding\" involves restating unfamiliar definitions in your own words, resorting to geometrical figures, and questioning what we know and do not know already; \"analysis\", which P\u00f3lya takes from Pappus, involves free and heuristic construction of plausible arguments, working backward from the goal, and devising a plan for constructing the proof; \"synthesis\" is the strict Euclidean exposition of step-by-step details of the proof; \"review\" involves reconsidering and re-examining the result and the path taken to it.\nBuilding on P\u00f3lya's work, Imre Lakatos argued that mathematicians actually use contradiction, criticism, and revision as principles for improving their work. In like manner to science, where truth is sought, but certainty is not found, in \"Proofs and Refutations\", what Lakatos tried to establish was that no theorem of informal mathematics is final or perfect. This means that, in non-axiomatic mathematics, we should not think that a theorem is ultimately true, only that no counterexample has yet been found. Once a counterexample, i.e. an entity contradicting/not explained by the theorem is found, we adjust the theorem, possibly extending the domain of its validity. This is a continuous way our knowledge accumulates, through the logic and process of proofs and refutations. (However, if axioms are given for a branch of mathematics, this creates a logical system \u2014Wittgenstein 1921 \"Tractatus Logico-Philosophicus\" 5.13; Lakatos claimed that proofs from such a system were tautological, i.e. internally logically true, by rewriting forms, as shown by Poincar\u00e9, who demonstrated the technique of transforming tautologically true forms (viz. the Euler characteristic) into or out of forms from homology, or more abstractly, from homological algebra.\nLakatos proposed an account of mathematical knowledge based on Polya's idea of heuristics. In \"Proofs and Refutations\", Lakatos gave several basic rules for finding proofs and counterexamples to conjectures. He thought that mathematical 'thought experiments' are a valid way to discover mathematical conjectures and proofs.\nGauss, when asked how he came about his theorems, once replied \"durch planm\u00e4ssiges Tattonieren\" (through systematic palpable experimentation).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes: Problem-solving via scientific method.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes: Philosophical expressions of method.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "26838", "revid": "4796325", "url": "https://en.wikipedia.org/wiki?curid=26838", "title": "Shotgun", "text": "Firearm loaded with a cartridge of pellets\nA shotgun (also known as a scattergun, peppergun, or historically as a fowling piece) is a long-barreled firearm designed to shoot a straight-walled cartridge known as a shotshell, which discharges numerous small spherical projectiles called shot, or a single solid projectile called a slug. Shotguns are most commonly used as smoothbore firearms, meaning that their gun barrels have no rifling on the inner wall, but rifled barrels for shooting sabot slugs (slug barrels) are also available.\nShotguns come in a wide variety of calibers and gauges ranging from 5.5\u00a0mm (.22\u00a0inch) to up to , though the 12-gauge (18.53\u00a0mm or 0.729\u00a0in) and 20-gauge (15.63\u00a0mm or 0.615\u00a0in) bores are by far the most common. Almost all are breechloading, and can be single barreled, double barreled, or in the form of a combination gun. Like rifles, shotguns also come in a range of different action types, both single-shot and repeating. For non-repeating designs, over-and-under and side-by-side break action shotguns are by far the most common variants. Although revolving shotguns do exist, most modern repeating shotguns are either pump action or semi-automatic, and also fully automatic, lever-action, or bolt-action to a lesser extent.\nPreceding smoothbore firearms (such as the musket) were widely used by European militaries from the 17th until the mid-19th century. The muzzleloading blunderbuss, the direct ancestor of the shotgun, was also used in similar roles from self-defense to riot control. Shotguns were often favored by cavalry troops in the early to mid-19th century because of its ease of use and generally good effectiveness on the move, as well as by coachmen for its substantial power. However, by the late 19th century, these weapons became largely replaced on the battlefield by breechloading rifled firearms shooting spin-stabilized cylindro-conoidal bullets, which were far more accurate with longer effective ranges. The military value of shotguns was rediscovered in the First World War, when American forces used the pump-action Winchester Model 1897 shotgun in trench fighting to great effect. Since then, shotguns have been used in a variety of close-quarters combat roles in civilian, law enforcement, and military applications.\nThe smoothbore shotgun barrel generates less resistance and thus allows greater propellant loads for heavier projectiles without as much risk of overpressure or a squib load, and are also easier to clean. The shot pellets from a shotshell are propelled indirectly through a wadding inside the shell and scatter upon leaving the barrel, which is usually choked at the muzzle end to control the projectile scatter. This means each shotgun discharge will produce a cluster of impact points instead of a single point of impact like other firearms. Having multiple projectiles also means the muzzle energy is divided among the pellets, leaving each individual projectile with less penetrative kinetic energy. The lack of spin stabilization and the generally suboptimal aerodynamic shape of the shot pellets also make them less accurate and decelerate quite quickly in flight due to drag, giving shotguns short effective ranges. In a hunting context, this makes shotguns useful primarily for hunting fast-flying birds and other agile small/medium-sized game without risking overpenetration and stray shots to distant bystanders and objects. However, in a military or law enforcement context, the high short-range blunt knockback force and large number of projectiles makes the shotgun useful as a door breaching tool, a crowd control or close-quarters defensive weapon. Militants or insurgents may use shotguns in asymmetric engagements, as shotguns are commonly owned civilian weapons in many countries. Shotguns are also used for target-shooting sports such as skeet, trap, and sporting clays, which involve flying clay disks, known as \"clay pigeons\", thrown in various ways by a dedicated launching device called a \"trap\".\nDesign factors.\nAction.\nThe action is the operating mechanism of a gun. There are many types of shotguns, typically categorized by the number of barrels or the way the gun is reloaded.\nBreak-action.\nFor most of the history of the shotgun, the breechloading break-action shotgun was the most common type, and double-barreled variants are by far the most commonly seen in modern days. These are typically divided into two subtypes: the traditional \"side-by-side\" shotgun features two barrels mounted horizontally beside each other (as the name suggests), whereas the \"over-and-under\" shotgun has the two barrels mounted vertically one on top of the other. Side-by-side shotguns were traditionally used for hunting and other sporting pursuits (early long-barreled side-by-side shotguns were known as \"fowling pieces\" for their use hunting ducks and other waterbirds as well as some landfowls), whereas over-and-under shotguns are more commonly associated with recreational use (such as clay pigeon shooting). Both types of double-barrel shotgun are used for hunting and sporting use, with the individual configuration largely being a matter of personal preference.\nAnother, less commonly encountered type of break-action shotgun is the combination gun, which is an over-and-under design with one smoothbore barrel and one rifle barrel (more often with a rifle barrel on top, but a rifle barrel on bottom was not uncommon). There is also a class of break-action guns called \"drillings\", which contain three barrels, usually two smoothbore barrels of the same gauge and a rifled barrel, though the only common theme is that at least one barrel be smoothbore. The most common arrangement was essentially a side-by-side shotgun with the rifled barrel below and centered. Usually a drilling containing more than one rifled barrel would have both rifled barrels in the same caliber, but examples do exist with different caliber barrels, usually a .22 long rifle and a centerfire cartridge. Although very rare, drillings with three and even four (a \"vierling\") shotgun barrels were made.\nPump-action.\nIn pump-action shotguns, a linearly sliding fore-end handguard (i.e. \"pump\") is manually moved back-and-forth like a hand pump to work the action, extracting the spent shell and inserting a new round, while cocking the hammer or striker. A pump-action shotgun is typically fed from a tubular magazine underneath the barrel, which also serves as a guide rail for the pump. The rounds are fed in one by one through a port in the receiver, where they are lifted by a lever called the \"elevator\" and pushed forward into the chamber by the bolt. A pair of latches at the rear of the magazine hold the rounds in place and facilitate feeding of one shell at a time. If it is desired to load the gun fully, a round may be loaded through the ejection port directly into the chamber, or cycled from the magazine, which is then topped off with another round. Well-known examples include the Winchester Model 1897, Remington 870, and Mossberg 500/590.\nPump-action shotguns are common hunting, fowling and sporting shotguns. Hunting models generally have a barrel between . Tube-fed models designed for hunting often come with a dowel rod or other stop that is inserted into the magazine and reduces the capacity of the gun to three shells (two in the magazine and one chambered) as is mandated by U.S. federal law when hunting migratory birds. They can also easily be used with an empty magazine as a single-shot weapon, by simply dropping the next round to be fired into the open ejection port after the spent round is ejected. For this reason, pump-actions are commonly used to teach novice shooters under supervision, as the trainer can load each round more quickly than with a break-action, while unlike a break-action, the student can maintain his grip on the gun and concentrate on proper handling and firing of the weapon.\nPump-action shotguns with shorter barrels and little or no barrel choke are highly popular for use in home defense, military and law enforcement, and are commonly known as riot guns. The minimum barrel length for shotguns in most of the U.S. is , and this barrel length (sometimes to increase magazine capacity and/or ensure the gun is legal regardless of measuring differences) is the primary choice for riot shotguns. The shorter barrel makes the weapon easier to maneuver around corners and in tight spaces, though slightly longer barrels are sometimes used outdoors for a tighter spread pattern or increased accuracy of slug projectiles. Home-defense and law enforcement shotguns are usually chambered for 12-gauge shells, providing maximum shot power and the use of a variety of projectiles such as buckshot, rubber, sandbag and slug shells, but 20-gauge (common in bird-hunting shotguns) or .410 (common in youth-size shotguns) are also available in defense-type shotgun models allowing easier use by novice shooters.\nA riot shotgun has many advantages over a handgun or rifle. Compared to \"defense-caliber\" handguns (chambered for 9mm Parabellum, .38 Special, .357 Magnum, .40 S&amp;W, .45 ACP and similar), a shotgun has far more power and damage potential (up to 10 times the muzzle energy of a .45 ACP cartridge), allowing a \"one-shot stop\" that is more difficult to achieve with typical handgun loads. Compared to a rifle, riot shotguns are easier to maneuver due to the shorter barrel, still provide better damage potential at indoor distances (generally 3\u20135 meters/yards), and reduce the risk of \"overpenetration\"; that is, the bullet or shot passing completely through the target and continuing beyond, which poses a risk to those behind the target through walls. The wide spread of the shot reduces the importance of shot placement compared to a single projectile, which increases the effectiveness of \"point shooting\" \u2013 rapidly aiming simply by pointing the weapon in the direction of the target. This allows easy, fast use by novices.\nLever-action.\nEarly attempts at repeating shotguns invariably centred around either bolt- or lever-action designs, drawing inspiration from contemporary repeating rifles, with the earliest successful repeating shotgun being the lever-action Winchester M1887, designed by John Browning at the behest of the Winchester Repeating Arms Company.\nLever shotguns, while less common, were popular in the late 19th century with the Winchester Model 1887 and Model 1901 being prime examples. Initially very popular, demand waned after the introduction of pump-action shotguns around the start of the 20th century, and production was eventually discontinued in 1920.\nOne major issue with lever-actions (and, to a lesser extent, pump-actions) was that early shotgun shells were often made of paper or similar fragile materials (modern hulls are plastic or metal). As a result, the loading of shells, or working of the action of the shotgun, could often result in cartridges getting crushed and becoming unusable, or even damaging the gun.\nLever shotguns have seen a return to the gun market in recent years, however, with Winchester producing the Model 9410 (chambering the .410-gauge shotgun shell and using the action of the Winchester Model 94 series lever-action rifle, hence the name), and a handful of other firearm manufacturers (primarily Norinco of China and ADI Ltd. of Australia) producing versions of the Winchester Model 1887/1901 designed for modern 12-gauge smokeless shotshells with more durable plastic casings. There has been a notable increase in lever-action shotgun sales in Australia since 1997, when pump-actions were effectively outlawed.\nBolt-action.\nBolt-action shotguns, while uncommon, do exist. One of the best-known examples is a 12-gauge manufactured by Mossberg featuring a 3-round magazine, marketed in Australia just after changes to the gun laws in 1997 heavily restricted the ownership and use of pump-action and semi-automatic shotguns. They were not a huge success, as they were somewhat slow and awkward to operate, and the rate of fire was noticeably slower (on average) than a double-barreled gun. The Rifle Factory Ishapore in India also manufactured a single-shot .410 bore shotgun based on the SMLE Mk III* rifle. The Russian Berdana shotgun was effectively a single-shot bolt-action rifle that became obsolete, and was subsequently modified to chamber 16-gauge shotgun shells for civilian sale. The U.S. military M26 is also a bolt-action weapon. Bolt-action shotguns have also been used in the \"goose gun\" application, intended to kill birds such as geese at greater range. Typically, goose guns have long barrels (up to 36\u00a0inches), and small bolt-fed magazines. Bolt-action shotguns are also used in conjunction with slug shells for the maximum possible accuracy from a shotgun.\nIn Australia, some straight-pull bolt-action shotguns, such as the Turkish-made Pardus BA12 and Dickinson T1000, the American C-More Competition M26, as well as the indigenous-designed SHS STP 12, have become increasingly popular alternatives to lever-action shotguns, largely due to the better ergonomics with less stress on the shooter's trigger hand and fingers when cycling the action.\nRevolver.\nColt briefly manufactured several revolving shotguns that were not particularly successful. The Colt Model 1839 Shotgun was manufactured between 1839 and 1841. Later, the Colt Model 1855 Shotgun, based on the Model 1855 revolving rifle, was manufactured between 1860 and 1863. Because of their low production numbers and age, they are among the rarest of all Colt firearms.\nThe Armsel Striker was a modern take on the revolving shotgun that held ten rounds of 12-gauge ammunition in its cylinder. It was copied by Cobray as the Streetsweeper.\nTaurus manufactures a carbine variant of the Taurus Judge revolver along with its Australian partner company Rossi, known as the \"Taurus/Rossi Circuit Judge\". It comes in the original combination chambering of .410 bore and .45 Long Colt, as well as the .44 Remington Magnum chambering. The rifle has small blast shields attached to the cylinder to protect the shooter from hot gases escaping between the cylinder and barrel.\nThe MTs255 () is a shotgun fed by a 5-round internal revolving cylinder. It is produced by the TsKIB SOO, Central Design and Research Bureau of Sporting and Hunting Arms. They are available in 12, 20, 28 and 32 gauges, and .410 bore.\nSemi-automatic.\nRecoil/inertia-driven or gas-operated actions are other popular methods of increasing the rate of fire of a shotgun; these self-loading shotguns are generally referred to as \"autoloaders\". Instead of having the action manually operated by a pump or lever, the action automatically cycles each time the shotgun is fired, ejecting the spent shell and reloading a fresh one into the chamber. The first successful semi-automatic shotgun was John Browning's Auto-5, first produced by Fabrique Nationale beginning in 1902. Other well-known examples include the Remington 1100, Benelli M1, and Saiga-12.\nSome, such as the Franchi SPAS-12 and Benelli M3, are capable of switching between semi-automatic and pump action. These are popular for two reasons; first, some jurisdictions forbid the use of semi-automatic actions for hunting, and second, lower-powered rounds, like \"reduced-recoil\" buckshot shells and many less-lethal cartridges, have insufficient power to reliably cycle a semi-automatic shotgun.\nAutomatic.\nFully automatic shotguns, such as the 1960s (appeared in 1967) Vietnam War-era Remington Model 7188 (designed for and used by U.S. Navy SEALs in Vietnam), the Auto Assault-12 (AA-12) or the USAS-12 also exist, but they are still rare.\nOther.\nIn addition to the commonly encountered shotgun actions already listed, there are also shotguns based on the Martini-Henry rifle design, originally designed by British arms maker W.W. Greener.\nSome of the more interesting advances in shotgun technology include the versatile NeoStead 2000 and fully automatics such as the Pancor Jackhammer or Auto-Assault 12.\nIn 1925, Rodolfo Cosmi produced the first working prototype hybrid semi-automatic shotgun, which had an 8-round magazine located in the stock. While it reloaded automatically after each shot like a semi-automatic, it had a break-action to load the first shell. This design has only been repeated once, by Beretta with their UGB25 automatic shotgun. The user loads the first shell by breaking the gun in the manner of a break-action shotgun, then closes it and inserts the second shell into a clip on the gun's right side. The spent hulls are ejected downwards. The guns combine the advantages of the break action (they can be proven to be safe by breaking open, there are no flying hulls) with those of the semi-automatic (low recoil, low barrel axis position hence low muzzle flip).\nThe Italian firearms manufacturer Benelli Armi SpA also makes the Benelli M3, a dual-mode hybrid shotgun that allows the user the choice of semi-automatic or pump-action operation. Pump-action operation is employed when shooting less energetic shells (such as baton rounds) that do not generate enough recoil to operate the semi-automatic mechanism. Conversely, the semi-automatic mode can be employed with more powerful shells, absorbing some of the recoil. Switching between the two modes is done by manipulating the ring located at the front of the foregrip.\nThe French firearm manufacturer Verney-Carron produces the V\u00e9loce shotgun, a \"lever-release blowback firearm\" using bolt catch mechanism like its similarly designed SpeedLine rifle. The V\u00e9loce is in essence a modified inertia-driven semi-automatic shotgun, but after blowback, the bolt is trapped by a bolt stop and cannot return to battery unless it is manually released by depressing a thumb lever near the tang of the grip. Because the gun will not chamber a new round without manual actuation, the design is technically not really a self-loading, and Verney-Carron described it as a \"manual repeating shotgun\". When Australian firearm dealers tried to import the V\u00e9loce shotgun in 2018, Greens' David Shoebridge and anti-gun groups such as Gun Control Australia caused a moral panic on the mainstream media, calling it \"semi-semi-automatic\" that needed to be prohibited as a \"rapid-fire weapon\".\nGauge.\nThe gauge number is determined by the weight, in fractions of a pound, of a solid sphere of lead with a diameter equal to the inside diameter of the barrel. So, a 10-gauge shotgun nominally should have an inside diameter equal to that of a sphere made from one-tenth of a pound of lead. Each gauge has a set caliber. By far the most common gauges are 12 (0.729 in, 18.5mm diameter) and 20 (0.614 in, 15.6mm), this includes other more or less common gauges, such as the 10, 16, 24, 28, 32, and 67 (.410 bore) gauge.\nDifferent gauges have different typical applications. 12-gauge shotguns are common for hunting geese, large ducks, or other big larger gamebirds; professional skeet and trap shooting; military applications; and home-defense applications. 16-gauge shotguns were once common for hunters who wanted to use only a single shotgun for gamebirds normally pursued with 12- or 20-gauge shotguns, but have become rarer in recent years. 20-gauge shotguns are often used for gamebirds such as doves, smaller ducks, and quail. 28-gauge shotguns are not as common but are classic quail-hunting guns. .410-gauge shotguns are typically used for squirrel hunting or for sportsmen seeking the challenge of killing game with a smaller load.\nOther, less common shotgun cartridges have their own unique uses. Ammunition manufacturer CCI produces 9mm Parabellum (.355 in.) and several other popular pistol calibers up to .45 ACP (11.43mm), as well as smaller calibers such as .22 Long Rifle (5.5mm) and .22 Magnum (5.5mm). These are commonly called snake shot cartridges. Larger gauges, up to 4 bore, too powerful to shoulder, have been built, but were generally affixed to small boats and referred to as punt guns. These were used for commercial waterfowl hunting, to kill large numbers of birds resting on the water.\nHandguns have also been produced that are capable of firing either .45 (Long) Colt or .410 shotgun shells from the same chamber; they are commonly known as \"snake guns\". Derringers such as the \"Snake Slayer and Cowboy Defender\" are popular among some outdoorsmen in the South and Southwest regions of the United States. There are also some revolvers, such as the Taurus Judge and Smith &amp; Wesson Governor, that are capable of shooting the .45LC/.410 rounds; but, as with derringers, they are not considered shotguns.\nThe .410 bore (10.4\u00a0mm) is unusual, being measured in inches, and would be approximately 67 \"real\" gauge, though its short hull versions are nominally called 36-gauge in Europe. It uses a relatively small charge of shot. It is used for hunting and for skeet. Because of its very light recoil (approx 10 N), it is often used as a beginner's gun. However, the small charge and typically tight choke make it more difficult to hit targets. It is also frequently used by expert shooters because of the difficulty, especially in expensive side-by-side and over-under models for hunting small bird game, such as quail and doves. Inexpensive bolt-action .410 shotguns are a very common first hunting shotgun among young preteen hunters, as they are used mostly for hunting squirrels, while additionally teaching bolt-action manipulation skills that will transfer easily later to adult-sized hunting rifles. Most of these young hunters move up to a 20-gauge within a few years, and to 12-gauge shotguns and full-size hunting rifles by their late teens. Still, many who are particularly recoil-averse choose to stay with 20-gauge shotguns all their adult life, as it is a suitable gauge for many popular hunting uses.\nA recent innovation is the back boring of barrels, in which the barrels are bored out slightly larger than their actual gauge. This reduces the compression forces on the shot when it transitions from the chamber to the barrel. This leads to a slight reduction in perceived recoil, and an improvement in shot pattern due to reduced deformation of the shot.\nShot.\nMost shotguns are used to fire \"a number of ball shot\", in addition to slugs and sabots. The ball shot or pellets is for the most part made of lead but this has been partially replaced by bismuth, steel, tungsten-iron, tungsten-nickel-iron and even tungsten polymer loads. Non-toxic loads are required by federal law for waterfowl hunting in the U.S., as the shot may be ingested by the waterfowl, which some authorities believe can lead to health problems due to the lead exposure. Shot is termed either birdshot or buckshot depending on the shot size. Informally, birdshot pellets have a diameter smaller than and buckshot are larger than that. Pellet size is indicated by a number; for birdshot, this ranges from the smallest 12 (1.2\u00a0mm, 0.05 in) to 2 (3.8\u00a0mm, 0.15 in) and then BB (4.6\u00a0mm, 0.18 in).\nFor buckshot, the numbers start and end with 4, 3, 2, 1, 0 (\"single-aught\"), 00 (\"double-aught\"), 000 (\"triple-aught\"), and 0000 (\"quadruple-aught\"). A different informal distinction is that \"birdshot\" pellets are small enough that they can be measured into the cartridge by weight, and simply poured in, whereas \"buckshot\" pellets are so large they must be stacked inside the cartridge in a fixed geometric arrangement to fit. The diameter in hundredths of an inch of bird shot sizes from No. 9 to No. 1 can be obtained by subtracting the shot size from 17. Thus, No. 4 bird shot is 17 \u2013 4 = 13 = in diameter. Different terminology is used outside the United States. In England and Australia, for example, 00 buckshot cartridges are commonly referred to as \"S.G.\" (Swanshot gauge) cartridges.\nPattern and choke.\nShot, small and round and delivered without spin, is ballistically inefficient. As the shot leaves the barrel, it begins to disperse in the air. The resulting cloud of pellets is known as the shot pattern, or shotgun shot spread. The ideal pattern would be a circle with an even distribution of shot throughout, with a density sufficient to ensure enough pellets will intersect the target to achieve the desired result, such as a kill when hunting or a break when shooting clay targets. In reality, the pattern is closer to a Gaussian, or normal distribution, with a higher density in the center that tapers off at the edges. Patterns are usually measured by firing at a diameter circle on a large sheet of paper placed at varying distances. The hits inside the circle are counted, and compared to the total number of pellets, and the density of the pattern inside the circle is examined. An \"ideal\" pattern would put nearly 100% of the pellets in the circle and would have no voids\u2014any region where a target silhouette will fit and not cover 3 or more holes is considered a potential problem.\nA constriction in the end of the barrel known as the choke is used to tailor the pattern for different purposes. Chokes may either be formed as part of the barrel at the time of manufacture, by squeezing the end of the bore down over a mandrel, or by threading the barrel and screwing in an interchangeable choke tube. The choke typically consists of a conical section that smoothly tapers from the bore diameter down to the choke diameter, followed by a cylindrical section of the choke diameter. Briley Manufacturing, a maker of interchangeable shotgun chokes, uses a conical portion about three times the bore diameter in length, so the shot is gradually squeezed down with minimal deformation. The cylindrical section is shorter, usually . The use of interchangeable chokes has made it easy to tune the performance of a given combination of shotgun and shotshell to achieve the desired performance.\nThe choke should be tailored to the range and size of the targets. A skeet shooter shooting at close targets might use 127 micrometres (0.005\u00a0inches) of constriction to produce a diameter pattern at a distance of . A trap shooter shooting at distant targets might use 762 micrometres (0.030\u00a0inches) of constriction to produce a diameter pattern at . Special chokes for turkey hunting, which requires long range shots at the small head and neck of the bird, can go as high as 1500 micrometres (0.060\u00a0inches). The use of too much choke and a small pattern increases the difficulty of hitting the target, whereas the use of too little choke produces large patterns with insufficient pellet density to reliably break targets or kill game. \"Cylinder barrels\" have no constriction.\nOther specialized choke tubes exist as well. Some turkey hunting tubes have constrictions greater than \"Super Full\", or additional features like porting to reduce recoil, or \"straight rifling\" that is designed to stop any spin that the shot column might acquire when traveling down the barrel. These tubes are often extended tubes, meaning they project beyond the end of the bore, giving more room for things like a longer conical section. Shot spreaders or diffusion chokes work opposite of normal chokes\u2014they are designed to spread the shot more than a cylinder bore, generating wider patterns for very short range use. A number of recent spreader chokes, such as the Briley \"Diffusion\" line, actually use rifling in the choke to spin the shot slightly, creating a wider spread. The Briley Diffusion uses a 1 in 36\u00a0cm twist, as does the FABARM Lion Paradox shotgun.\nOval chokes, which are designed to provide a shot pattern wider than it is tall, are sometimes found on combat shotguns, primarily those of the Vietnam War era. They were available for aftermarket addition in the 1970s from companies like A &amp; W Engineering. Military versions of the Ithaca 37 with \"duckbill\" choke were used in limited numbers during the Vietnam War by U.S. Navy Seals. It arguably increased effectiveness in close range engagements against multiple targets. Two major disadvantages plagued the system: One was erratic patterning; the second was that the shot would spread too quickly providing a limited effective zone.\nOffset chokes, where the pattern is intentionally slightly off of center, are used to change the point of impact. For instance, an offset choke can be used to make a double-barreled shotgun with poorly aligned barrels hit the same spot with both barrels.\nBarrel length.\nShotguns generally have longer barrels than modern rifles. Unlike rifles, however, the long shotgun barrel is not for ballistic purposes; shotgun shells use small powder charges in large diameter bores, and this leads to very low muzzle pressures (see internal ballistics) and very little velocity change with increasing barrel length. According to Remington, modern powder in a shotgun burns completely in barrels.\nSince shotguns are generally used for shooting at small, fast-moving targets, it is important to \"lead\" the target by firing slightly ahead of the target, so that when the shot reaches the range of the target, the target will have moved into the pattern.\nShotguns made for close ranges, where the angular speed of the targets is great (such as skeet or upland bird hunting), tend to have shorter barrels, around . Shotguns for longer range shooting, where angular speeds are small (trap shooting; quail, pheasant, and waterfowl hunting), tend to have longer barrels, 28 to . The longer barrels have more angular momentum, and will therefore swing more slowly but more steadily. The short, low angular momentum barrels swing faster, but are less steady. These lengths are for pump or semi-auto shotguns; break-open guns have shorter overall lengths for the same barrel length, and so will use longer barrels. The break-open design saves between in overall length, but in most cases pays for this by having two barrels, which adds weight at the muzzle. Barrels for shotguns have been getting longer as modern steels and production methods make the barrels stronger and lighter; a longer, lighter barrel gives the same inertia for less overall weight.\nShotguns for use against larger, slower targets generally have even shorter barrels. Small game shotguns, for hunting game like rabbits and squirrels, or shotguns for use with buckshot for deer, are often .\nShotguns intended for all-round hunting are a compromise, but a barrel pump-action 12-gauge shotgun with a modified choke can serve admirably for use as one gun intended for general all-round hunting of small-game such as quails, rabbits, pheasants, doves, and squirrels in semi-open wooded or farmland areas in many parts of the eastern U.S. (Kentucky, Indiana, Tennessee) where dense brush is less of a hindrance and the ability to have more reach is important. For hunting in dense brush, shorter barrel lengths are often preferred when hunting the same types of game.\nCaliber conversion sleeves.\nShotguns are well suited for the use of caliber conversion sleeves, allowing most single- and double-barrel shotguns to fire a wide range of ammunition. The X Caliber system consists of eight adapter sleeves that allow the 12-gauge models to fire: .380 ACP, 9mm Luger, .38 Special, .357 Magnum, .40 S&amp;W, .44 Special, .44 Magnum, .45 ACP, .45 Long Colt, .410 gauge and 20-gauge ammunition. They even make four adapter sleeves that allow the 20-gauge models to fire: 9mm Luger, .38 Special, .357 Magnum, .45 ACP, .45 Long Colt, and .410 gauge ammunition.\nAmmunition.\nThe extremely large caliber of shotgun shells has led to a wide variety of different ammunition.\nShotshells are the most commonly used round, filled with lead or lead substitute pellets.\nOf this general class, the most common subset is birdshot, which uses a large number (from dozens to hundreds) of small pellets, meant to create a wide \"kill spread\" to hunt birds in flight. Shotshells are described by the size and number of the pellets within, and numbered in reverse order (the smaller the number, the bigger the pellet size, similar to bore gauge). Size nine (#9) shot is the smallest size normally used for hunting and is used on small upland game birds such as dove and quail. Larger sizes are used for hunting larger upland game birds and waterfowl.\nBuckshot is similar to but larger than birdshot, and was originally designed for hunting larger game, such as deer (hence the name). While the advent of new, more accurate slug technologies is making buckshot less attractive for hunting, it is still the most common choice for police, military, and home defense uses. Like birdshot, buckshot is described by pellet size, with larger numbers indicating smaller shot. From the smallest to the largest, buckshot sizes are: #4, (called \"number four\"), #1, 0 (\"one-aught\"), 00 (\"double-aught\"), 000 (\"triple-aught\") and 0000 (\"four-aught\"). A typical round for defensive use would be a 12-gauge length 00 buck shell, which contains 9 pellets roughly in diameter, each comparable to a .38 Special bullet in damage potential. New \"tactical\" buckshot rounds, designed specifically for defensive use, use slightly fewer shot at lower velocity to reduce recoil and increase controllability of the shotgun. There are some shotgun rounds designed specifically for police use that shoot effectively from with a grouping of the balls.\nSlug rounds are rounds that fire a single solid slug. They are used for hunting large game and in certain military and law enforcement applications. Modern slugs are moderately accurate, especially when fired from special rifled slug barrels. They are often used in \"shotgun-only\" hunting zones near inhabited areas, where rifles are prohibited due to their greater range.\nSabots are a common type of slug round. While some slugs are exactly that\u2014a 12-gauge metal projectile in a cartridge\u2014a sabot is a smaller but more aerodynamic projectile surrounded by a \"shoe\" of some other material. This \"sabot\" jacket seals the barrel, increasing pressure and acceleration, while also inducing spin on the projectile in a rifled barrel. Once the projectile clears the barrel, the sabot material falls away, leaving an unmarked, aerodynamic bullet to continue toward the target. The advantages over a traditional slug are increased shot power, increased bullet velocity due to the lighter-mass bullet, and increased accuracy due to the velocity and the reduction in deformation of the slug itself. Disadvantages versus a traditional slug include lower muzzle momentum due to reduced mass, reduced damage due to smaller bullet diameter, and significantly higher per-unit cost.\nSpecialty ammunition.\nThe unique properties of the shotgun, such as large case capacity, large bore, and the lack of rifling, has led to the development of a large variety of specialty shells, ranging from novelties to high-tech military rounds.\nHunting, defensive, and military.\nBrenneke and Foster type slugs have the same basic configuration as normal slugs but have increased accuracy. The hollowed rear of the Foster slug improves accuracy by placing more mass in the front of the projectile, therefore inhibiting the \"tumble\" that normal slugs may generate. The Brenneke slug takes this concept a bit further, with the addition of a wad that stays connected to the projectile after discharge, increasing accuracy. Both slugs are commonly found with fins or ribs, which are meant to allow the projectile to safely squeeze down during passage through chokes, but they do not increase stability in flight.\nFlechette rounds contain aerodynamic darts, typically from 8 to 20 in number. The flechettes provide greatly extended range due to their aerodynamic shape and improved penetration of light armor. American troops during the Vietnam War packed their own flechette shotgun rounds, called \"beehive rounds\" after the similar artillery rounds. However, terminal performance was poor due to the very light weight of the flechettes, and their use was quickly dropped.\nGrenade rounds use exploding projectiles to increase long range lethality. These are currently experimental, but the British FRAG-12, which comes in High Explosive (HE), High Explosive Armor-piercing (HEAP) and High Explosive Fragmenting Antipersonnel (HEFA) forms, is under consideration by military forces.\nLess-lethal rounds, for riot and animal control.\nFlexible baton rounds, commonly called \"bean bags\", fire a fabric bag filled with birdshot or a similar loose, dense substance. The \"punch\" effect of the bag is useful for knocking down targets; the rounds are used by police to subdue violent suspects. The bean bag round is by far the most common less-lethal round used. Due to the large surface area of these rounds, they lose velocity rapidly, and must be used at fairly short ranges to be effective, though use at extremely short ranges, under , can result in broken bones or other serious or lethal injuries. The rounds can also fly in a frisbee-like fashion and cut the person or animal being fired at. For this reason, these types of rounds are referred to as less-lethal, as opposed to less-than-lethal.\nGas shells spray a cone of gas for several meters. These are primarily used by riot police. They normally contain pepper gas or tear gas. Other variations launch a gas-grenade-like projectile.\nRock salt shells are hand loaded with coarse rock salt crystals, replacing the standard lead or steel shot. Rock salt shells could be seen as the forerunners of modern less-lethal rounds. In the United States, rock salt shells were and are sometimes still used by rural civilians to defend their property. The brittle salt was unlikely to cause serious injury at long ranges, but would cause painful stinging injuries and served as a warning. British gamekeepers have used rock salt shells to deter poachers. Rather than get into a physical confrontation, they stalk the poachers, making themselves known by a loud shout of \"Run!\" just before firing, to avoid hitting the now fleeing subject in the eyes.\nRubber slugs or rubber buckshot are similar in principle to the bean bag rounds. Composed of flexible rubber or plastic and fired at low velocities, these rounds are probably the most common choice for riot control.\nTaser International announced in 2007 a new 12-gauge eXtended Range Electronic Projectile or XREP, which contains a small electroshock weapon unit in a carrier that can be fired from a standard 12-gauge shotgun. The XREP projectile is fin stabilized, and travels at an initial velocity of 100\u00a0m/s (300\u00a0ft/s). Barbs on the front attach the electroshock unit to the target, with a tassel deploying from the rear to widen the circuit. A twenty-second burst of electrical energy is delivered to the target. This product was expected to be released to market in 2008. They were used\u2014despite still being subject to testing, in breach of the supplier's license\u2014by Northumbria police in their standoff with Raoul Moat in 2010.\nBreaching rounds, often called frangible, Disintegrator, or Hatton rounds, are designed to destroy door locking mechanisms without risking lives. They are constructed of a very brittle substance that transfers most of the energy to the primary target but then fragment into much smaller pieces or dust so as not to injure unseen targets such as hostages or non-combatants that may be standing behind a breached door.\nBird bombs are low-powered rounds that fire a firecracker that is fused to explode a short time after firing. They are designed to scare animals, such as birds that congregate on airport runways.\nScreechers fire a pyrotechnic whistle that emits a loud whistling sound for the duration of its flight. These are also used to scare animals.\nBlank shells contain only a small amount of powder and no actual load. When fired, the blanks provide the sound and flash of a real load, but with no projectile. These may be used for simulation of gunfire, scaring wildlife, or as power for a launching device such as the Mossberg #50298 marine line launcher.\n&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Stinger is a type of shotgun shell which contains sixteen 00-buck balls made of Zytel, and is designed as a non-lethal ammunition ideally used in small spaces.\nNovelty and other.\nBolo rounds are made of two or more slugs molded onto steel wire. When fired, the slugs separate, pulling the wire taut creating a flying blade, which could theoretically decapitate people and animals or amputate limbs. However, many active shotgun users consider this to be overstated, and view bolo shells as being less effective than conventional ammunition. Bolo shell rounds are banned in many locations (including the U.S. states of Florida and Illinois) due to concerns about their potential lethality. The round is named in reference to bolas, which use two or more weighted balls on a rope to trap cattle or game.\nDragon's breath usually refers to a zirconium-based pyrotechnic shotgun round. When fired, a gout of flame erupts from the barrel of the gun (up to ). The visual effect it produces is impressive, similar to that of a short-ranged flamethrower. However, it has few tactical uses, mainly distraction/disorientation.\nFlare rounds are sometimes carried by hunters for safety and rescue purposes. They are available in low- and high-altitude versions. Some brands claim they can reach a height of up to .\nUses.\nThe typical use of a shotgun is against small and fast-moving targets, often while in the air. The spreading of the shot allows the user to point the shotgun close to the target, rather than having to aim precisely as in the case of a single projectile. The disadvantages of shot are limited range and limited penetration of the shot, which is why shotguns are used at short ranges, and typically against smaller targets. Larger shot sizes, up to the extreme case of the single projectile slug load, result in increased penetration, but at the expense of fewer projectiles and lower probability of hitting the target.\nAside from the most common use against small, fast-moving targets, the shotgun has several advantages when used against still targets. First, it has enormous stopping power at short range, more than nearly all handguns and many rifles. Though many believe the shotgun is a great firearm for inexperienced shooters, the truth is, at close range, the spread of shot is not very large at all, and competency in aiming is still required. A typical self-defense load of buckshot contains 8\u201327 large lead pellets, resulting in many wound tracks in the target. Also, unlike a fully jacketed rifle bullet, each pellet of shot is less likely to penetrate walls and hit bystanders (though in the case of traditional 00-Buck, overpenetration of soft and hard targets may be an issue). It is favored by law enforcement for its low penetration and high stopping power.\nOn the other hand, the hit potential of a defensive shotgun is often overstated. The typical defensive shot is taken at very close ranges, at which the shot charge expands no more than a few centimeters. This means the shotgun must still be aimed at the target with some care. Balancing this is the fact that shot spreads further upon entering the target, and the multiple wound channels are far more likely to produce a disabling wound than a rifle or handgun.\nSporting.\nSome of the most common uses of shotguns are the sports of skeet shooting, trap shooting, and sporting clays. These involve shooting clay discs, also known as clay pigeons, thrown in by hand and by machine. Both skeet and trap competitions are featured at the Olympic Games.\nHunting.\nThe shotgun is popular for bird hunting (called \"game-shooting\" in the United Kingdom, where \"hunting\" refers to hunting mammals with a pack of hounds), it is also used for more general forms of hunting especially in semi-populated areas where the range of rifle bullets may pose a hazard. Use of a smoothbore shotgun with a rifled slug or, alternatively, a rifled barrel shotgun with a sabot slug, improves accuracy to or more. This is well within the range of the majority of kill shots by experienced hunters using shotguns.\nHowever, given the relatively low muzzle velocity of slug ammunition, typically around 500\u00a0m/s (about 1600 feet per second), and the blunt, poorly streamlined shape of typical slugs (which cause them to lose velocity very rapidly, compared to rifle bullets), a hunter must pay close attention to the ballistics of the particular ammunition used to ensure an effective and humane kill shot.\nAt any reasonable range, shotgun slugs make effective lethal wounds due to their tremendous mass, reducing the length of time that an animal might suffer. For example, a typical 12-gauge shotgun slug is a blunt piece of metal that could be described as an 18\u00a0mm (.729\u00a0inch) caliber that weighs 28\u00a0grams (432 grains). For comparison, a common deer-hunting rifle round is a 7.62\u00a0mm (.308\u00a0inch) slug weighing 9.7\u00a0grams (150 grains), but the dynamics of the rifle cartridge allow for a different type of wound, and a much further reach.\nShotguns are often used with rifled barrels in locations where it is not lawful to hunt with a rifle. Typically, a sabot slug is used in these barrels for maximum accuracy and performance. Shotguns are often used to hunt whitetail deer in the thick brush and briers of the Southeastern and upper Midwestern United States, where, due to the dense cover, ranges tend to be close \u2013 25m or less.\nSabot slugs are essentially very large hollow point bullets, and are streamlined for maximum spin and accuracy when shot through a rifled barrel. They have greater ranges than older Foster and Brenneke-type slugs.\nPeople often use semiautomatic or pump-action shotguns for hunting waterfowl to small game.\nIndustrial.\nAnother use are industrial shotguns, used for buildup of slag in kilns. They are similar in usage but differ than powder-actuated tools. These are also used in the mining and cement industry for knocking down overhands and residue buildup, etc. A known example of an industrial shotgun is the 8-gauge Remington MasterBlaster.\nLaw enforcement.\nIn many countries, especially the United States and Canada, shotguns are widely used as a support weapon by police forces. One of the rationales for issuing shotguns is that, even without much training, an officer will probably be able to hit targets at close to intermediate range, due to the \"spreading\" effect of buckshot. This is largely a myth, as the spread of buckshot at 25 feet averages 8 inches, which is still very capable of missing a target. Some police forces are replacing shotguns in this role with carbine rifles such as AR-15s. Shotguns are also used in roadblock situations, where police are blocking a highway to search cars for suspects. In the U.S., law enforcement agencies often use riot shotguns, especially for crowd and riot control where they may be loaded with less-lethal rounds such as rubber bullets or bean bags. Shotguns are also often used as breaching devices to defeat locks.\nMilitary.\nShotguns are common weapons in military use, particularly for special purposes. Shotguns are found aboard naval vessels for shipboard security, because the weapon is very effective at close range as a way of repelling enemy boarding parties. In a naval setting, stainless steel shotguns are often used, because regular steel is more prone to corrosion in the marine environment. Shotguns are also used by military police units. U.S. Marines have used shotguns since their inception at the squad level, often in the hands of NCOs, while the U.S. Army often issued them to a squad's point man. Shotguns were modified for and used in the trench warfare of World War I, in the jungle combat of World War II and the Vietnam War. Shotguns were also used in the Iraq War, being popular with soldiers in urban combat environments. Some U.S. units in Iraq used shotguns with special frangible breaching rounds to blow the locks or hinges off doors when making a surprise entry into a dwelling.\nRecently, shotguns have proven to be one of the few effective means of repelling incoming drones in military conflicts \nHome and personal defense.\nShotguns are a popular means of home defense for many of the same reasons they are preferred for close-quarters tasks in law enforcement and the military.\nHistory.\nMost early firearms, such as the blunderbuss, arquebus, and musket had large diameter, smoothbore barrels, and could fire shot as well as solid balls. A firearm intended for use in wing shooting of birds was known as a fowling piece. The 1728 \"Cyclopaedia\" defines a \"fowling piece\" as:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nFor example, the Brown Bess musket, in service with the British army from 1722 to 1838, had a 19\u00a0mm (.75\u00a0inch) smoothbore barrel, roughly the same as a 10-gauge shotgun, and was long, just short of the above recommended 168\u00a0cm (5&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 feet). On the other hand, records from the Plymouth Colony show a maximum length of 137\u00a0cm (4&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 feet) for fowling pieces, shorter than the typical musket.\nShot was also used in warfare; the buck and ball loading, combining a musket ball with three or six buckshot, was used throughout the history of the smoothbore musket. The first recorded use of the term \"shotgun\" was in 1776 in Kentucky. It was noted as part of the \"frontier language of the West\" by James Fenimore Cooper.\nWith the adoption of smaller bores and rifled barrels, the shotgun began to emerge as a separate entity. Shotguns have long been the preferred method for sport hunting of birds, and the largest shotguns, the punt guns, were used for commercial hunting. The double-barreled shotgun has changed little since the development of the boxlock action in 1875. Modern innovations such as interchangeable chokes and subgauge inserts make the double-barreled shotgun the shotgun of choice in skeet, trap shooting, and sporting clays, as well as with many hunters.\nAs wing shooting has been a prestige sport, specialty gunsmiths such as Krieghoff or Perazzi have produced fancy double-barrel guns for wealthy European and American hunters. These weapons can cost US$5,000 or more; some elaborately decorated presentation guns have sold for up to US$100,000.\nDuring its long history, the shotgun has been favored by bird hunters, guards, and law enforcement officials. The shotgun has fallen in and out of favor with military forces several times in its long history. Shotguns and similar weapons are simpler than long-range rifles, and were developed earlier. The development of more accurate and deadlier long-range rifles minimized the usefulness of the shotgun on the open battlefields of European wars. But armies have \"rediscovered\" the shotgun for specialty uses many times.\n19th century.\nDuring the 19th century, shotguns were mainly employed by cavalry units. Both sides of the American Civil War employed shotguns. U.S. cavalry used the shotgun extensively during the Indian Wars in the latter half of the 19th century. Mounted units favored the shotgun for its moving target effectiveness, and devastating close-range firepower. The shotgun was also favored by citizen militias and similar groups.\nWith the exception of cavalry units, the shotgun saw less and less use throughout the 19th century on the battlefield. As a defense weapon, it remained popular with guards and lawmen, however, and the shotgun became one of many symbols of the American Old West. Lawman Cody Lyons killed two men with a shotgun; his friend Doc Holliday's only confirmed kill was with a shotgun. The weapon both these men used was the short-barreled version favored by private strongbox guards on stages and trains. These guards, called express messengers, became known as shotgun messengers, since they rode with the weapon (loaded with buckshot) for defense against bandits. Passenger carriages carrying a strongbox usually had at least one private guard armed with a shotgun riding in front of the coach, next to the driver. This practice has survived in American slang; the term \"riding shotgun\" is used for the passenger who sits in the front passenger seat. The shotgun was a popular weapon for personal protection in the American Old West, requiring less skill on the part of the user than a revolver.\nHammerless shotguns.\nThe origins of the hammerless shotgun are European but otherwise obscure. The earliest breechloading shotguns originated in France and Belgium in the early 19th century (see also the history of the Pinfire) and a number of them such as those by Robert and Chateauvillard from the 1830s and 1840s did not use hammers. In fact during these decades a wide variety of ingenious weapons, including rifles, adopted what is now often known as a \"needle-fire\" method of igniting the charge, where a firing pin or a longer sharper needle provided the necessary impact. The most widely used British hammerless needle-fire shotgun was the unusual hinged-chamber fixed-barrel breech-loader by Joseph Needham, produced from the 1850s. By the 1860s, hammerless guns were increasingly used in Europe both in war and sport, although hammer guns were still very much in the majority. The first significant encroachment on hammer guns was a hammerless patent which could be used with a conventional side-lock. This was British gunmaker T. Murcott's 1871 action nicknamed the \"mousetrap\" on account of its loud snap action. However, the most successful hammerless innovation of the 1870s was Anson and Deeley's boxlock patent of 1875. This simple but ingenious design only used four moving parts allowing the production of cheaper and reliable shotguns.\nDaniel Myron LeFever is credited with the invention of the American hammerless shotgun. Working for Barber &amp; LeFever in Syracuse, New York, he introduced his first hammerless shotgun in 1878. This gun was cocked with external cocking levers on the side of the breech. He went on to patent the first truly automatic hammerless shotgun in 1883. This gun automatically cocked itself when the breech was closed. He later developed the mechanism to automatically eject the shells when the breech was opened.\nJohn Moses Browning.\nOne of the men most responsible for the modern development of the shotgun was prolific gun designer John Browning. While working for Winchester Firearms, Browning revolutionized shotgun design. In 1887, Browning introduced the Model 1887 Lever Action Repeating Shotgun, which loaded a fresh cartridge from its internal magazine by the operation of the action lever. Before this time, most shotguns were the break-open type.\nThis development was greatly overshadowed by two further innovations he introduced at the end of the 19th century. In 1893, Browning produced the Model 1893 Pump Action Shotgun, introducing the now familiar pump action to the market. And in 1900, he patented the Browning Auto-5, America's first semi-automatic shotgun. The first semi-automatic shotgun in the world was patented in 1891\u20131893 by the Clair brothers of France. The Browning Auto-5 remained in production until 1998.\nWorld wars.\nThe decline in military use of shotguns reversed in World War I. American forces under General Pershing employed 12-gauge pump-action shotguns when they were deployed to the Western Front in 1917. These shotguns were fitted with bayonets and a heat shield so the barrel could be gripped while the bayonet was deployed. Shotguns fitted in this fashion became known as \"trench guns\" by the United States Army. Those without such modifications were known as \"riot guns\". After World War I, the United States military began referring to all shotguns as \"riot guns\".\nDue to the cramped conditions of trench warfare, the American shotguns were extremely effective. Germany even filed an official diplomatic protest against their use, alleging they violated the laws of warfare. The judge advocate general reviewed the protest, and it was rejected because the Germans protested use of lead shot (which would have been illegal) but military shot was plated. This is the only occasion the legality of the shotgun's use in warfare has been questioned.\nDuring World War II, the shotgun was not heavily used in the war in Europe by official military forces. However, the shotgun was a favorite weapon of Allied-supported partisans, such as the French Resistance. By contrast, in the Pacific theater, thick jungles and heavily fortified positions made the shotgun a favorite weapon of the United States Marines. Marines tended to use pump shotguns, since the pump action was less likely to jam in the humid and dirty conditions of the Pacific campaign. Similarly, the United States Navy used pump shotguns to guard ships when in port in Chinese harbors (e.g., Shanghai). The United States Army Air Forces also used pump shotguns to guard bombers and other aircraft against saboteurs when parked on airbases across the Pacific and on the West Coast of the United States. Pump and semi-automatic shotguns were used in marksmanship training, particularly for bomber gunners. The most common pump shotguns used for these duties were the 12-gauge Winchester Model 97 and Model 12. The break-open action, single-barrel shotgun was used by the British Home Guard and U.S. home security forces. Notably, industrial centers (such as the Gopher State Steel Works) were guarded by National Guard soldiers with Winchester Model 37 12-gauge shotguns.\nLate 20th century to present.\nSince the end of World War II, the shotgun has remained a specialty weapon for modern armies. It has been deployed for specialized tasks where its strengths were put to particularly good use. It was used to defend machine gun emplacements during the Korean War, American and French jungle patrols used shotguns during the Vietnam War, and shotguns saw extensive use as door breaching and close-quarter weapons in the early stages of the Iraq War, and saw limited use in tank crews. Many modern navies make extensive use of shotguns by personnel engaged in boarding hostile ships, as any shots fired will almost certainly be over a short range. Nonetheless, shotguns are far less common in military use than rifles, carbines, submachine guns, or pistols.\nOn the other hand, the shotgun has become a standard in law enforcement use. A variety of specialty less-lethal or non-lethal ammunitions, such as tear gas shells, bean bags, flares, explosive sonic stun rounds, and rubber projectiles, all packaged into 12-gauge shotgun shells, are produced specifically for the law enforcement market. Recently, Taser International introduced a self-contained electronic weapon which is fired from a standard 12-gauge shotgun.\nThe shotgun remains a standard firearm for hunting throughout the world for all sorts of game from birds and small game to large game such as deer. The versatility of the shotgun as a hunting weapon has steadily increased as slug rounds and more advanced rifled barrels have given shotguns longer range and higher killing power. The shotgun has become a ubiquitous firearm in the hunting community.\nLegal issues.\nGlobally, shotguns are generally not as heavily regulated as rifles or handguns, likely because they lack the range of rifles and are not easily concealable as handguns are; thus, they are perceived as a lesser threat by legislative authorities. The main exception is a sawed-off shotgun, especially a lupara, as it is more easily concealed than a normal shotgun.\nAustralia.\nWithin Australia, all shotguns manufactured after 1 January 1901 are considered firearms and are subject to registration and licensing. Most shotguns (including break-action, bolt-action and lever-action shotguns) are classed as \"Category A\" weapons and, as such, are comparatively easy to obtain a licence for, given a legally recognised \"legitimate reason\" (compare to the British requirement for \"good reason\" for a FAC), such as sport shooting or hunting. However, pump-action and semi-automatic shotguns are classed as \"Category C\" (magazine capacity no more than 5 rounds) or \"Category D\" (magazine capacity more than 5 rounds) weapons; a licence for this type of firearm is, practically speaking, unavailable to the average citizen due to the difficulty and red tape of acquiring one. For more information, see Gun politics in Australia.\nCanada.\nCanada has three classifications of firearms: non-restricted, restricted, and prohibited. Shotguns are found in all three classes.\nAll non-restricted shotguns must have an overall length of at least . Semi-automatic shotguns must also have a barrel length of no less than and with a capacity of 5 shells or less in the magazine to remain non-restricted. All other shotgun action types (pump/slide, break open, lever, bolt) do not have a magazine limit restriction or a minimum barrel length provided the overall length of the firearm remains more than and the barrel was produced by an approved manufacturer. Shotgun barrels may only be reduced in length to a minimum of . Non-restricted shotguns may be possessed with any Possession and Acquisition Licence (PAL) or Possession-Only License (POL) and may be transported throughout the country without special authorization and may be used for hunting certain species at certain times of the year.\nSemi-automatic shotguns with a barrel length of less than are considered restricted and any shotgun that has been altered so its barrel length is less than or if its overall length is less than is considered prohibited. Restricted and prohibited shotguns may be possessed with a PAL or POL that has been endorsed for restricted or prohibited grandfathered firearms. These shotguns require special Authorization to Transport (ATT).\nThe Canadian Firearms Registry was a government-run registry of all legally owned firearms in Canada. The government provided amnesty from prosecution to shotgun and rifle owners if they fail to register non-restricted shotguns and rifles. The long gun portion of the registry was scrapped in 2011.\nSee online for an official Canadian list of non-restricted and restricted and prohibited firearms.\nUnited Kingdom.\nIn the United Kingdom, a Shotgun Certificate (SGC) is required to possess a \"Section 2\" shotgun. These cost \u00a350 and can only be denied if the chief of police in the area believes and can prove that the applicant poses a real danger to the public, or if the applicant has been convicted of a crime punishable by imprisonment for a term of three years or more or if the applicant cannot securely store a shotgun (gun clamps, wire locks and locking gun cabinets are considered secure). The round number restrictions apply only to the magazine, not the chamber, so it is legal to have a single-barreled semi-auto or pump-action shotgun that holds more than 3 rounds in total, or a shotgun with separate chambers (which would need to also be multi-barrelled). For a shotgun to qualify as a section 2 shotgun, it must meet the following criteria:\nPrior to an SGC being issued, an interview is conducted with the local Firearms Officer. In the past, this was a duty undertaken by the local police, but more recently this function has been contracted out to civilian staff. The officer will check the location and suitability of the gun safe that is to be used for storage and conduct a general interview to establish the reasons behind the applicant requiring an SGC.\nAn SGC holder can own any number of shotguns meeting these requirements so long as he/she can store them securely. No certificate is required to own shotgun ammunition, but one is required to buy it. There is no restriction on the amount of shotgun ammunition that can be bought or owned. There are also no rules regarding the storage of ammunition.\nHowever, shotgun ammunition which contains fewer than 6 projectiles requires a section 1 Firearms Certificate (FAC). Shotguns with a magazine capacity greater than 2 rounds are also considered to be section 1 firearms and, as such, require an FAC to own. An FAC costs \u00a350 but is much more restrictive than an SGC. The applicant must nominate two referees who are known to the applicant to vouch for his or her character; a new 'variation' is required for each new caliber of gun to be owned; limits are set on how much ammunition a person can own at any one time; and an FAC can be denied if the applicant does not have sufficient 'good reason'. 'Good reason' generally means hunting, collecting, or target shooting \u2013 though other reasons may be acceptable. Personal defense is not an acceptable reason.\nAny pump-action or semi-automatic smoothbore gun (such as a shotgun) with a barrel length of less than 24 inches or total length of less than 40 inches is considered to be a section 5 firearm, that is, one that is subject to general prohibition, unless it is chambered for .22 caliber rimfire ammunition.\nUnited States.\nIn the U.S., federal law prohibits shotguns from being capable of holding more than three shells including the round in the chamber when used for hunting migratory gamebirds such as doves, ducks, and geese. For other uses, a capacity of any number of shells is generally permitted. Most magazine-fed shotguns come with a removable magazine plug to limit the capacity to 2, plus 1 in the chamber, for a total of 3 rounds, while hunting migratory gamebirds. Certain states have restrictions on magazine capacity or design features under hunting or assault weapon laws.\nShotguns intended for defensive use have barrels as short as for private use (the minimum shotgun barrel length allowed by law in the United States without federal registration). Barrel lengths of less than as measured from the breechface to the muzzle when the weapon is in battery, or have an overall length of less than are classified as short-barreled shotguns (SBS) under the 1934 National Firearms Act and are regulated. A similar short-barreled weapon having a pistol grip may be classified as an AOW or \"Any Other Weapon\" or \"Firearm\", depending on barrel length. A shotgun is defined as a weapon (with a buttstock) designed to be fired from the shoulder. The classification varies depending on how the weapon was originally manufactured.\nShotguns used by military, police, and other government agencies are regulated under the National Firearms Act of 1934; however, they are exempt from transfer taxes. These weapons commonly have barrels as short as so that they are easier to handle in confined spaces. Non-prohibited private citizens may own short-barreled shotguns by passing extensive background checks (state and local laws may be more restrictive) as well as paying a $200 federal tax and being issued a stamp. Defensive shotguns sometimes have no buttstock or will have a folding stock to reduce overall length even more when required. AOWs transfer with a $5 tax stamp from the BATFE.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26839", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=26839", "title": "Side-by-side shotgun", "text": ""}
{"id": "26840", "revid": "51063335", "url": "https://en.wikipedia.org/wiki?curid=26840", "title": "Saskatchewan", "text": "Province of Canada\nSaskatchewan is a province in Western Canada. It is bordered to the west by Alberta, to the north by the Northwest Territories, to the east by Manitoba, to the northeast by Nunavut, and to the south by the United States (Montana and North Dakota). Saskatchewan and neighbouring Alberta are the only landlocked provinces in Canada. In 2025, Saskatchewan's population was estimated at 1,253,569. Nearly 10% of Saskatchewan's total area of is fresh water, mostly rivers, reservoirs, and lakes.\nSaskatchewanians live primarily in the southern prairie half of the province, while the northern half is mostly forested and sparsely populated. Roughly half live in the two largest cities, Regina (the provincial capital) and Saskatoon (the largest city). Other notable cities include Prince Albert, Moose Jaw, Yorkton, Swift Current, North Battleford, Estevan, Weyburn, Melfort, and the border city of Lloydminster. English is the primary language of the province, with 82.4% of Saskatchewanians speaking English as their first language.\nSaskatchewan has been inhabited for thousands of years by indigenous peoples. Europeans first explored any part of the province in 1690 and first settled in the area in 1774. It became a province in 1905, carved out from the vast North-West Territories, which had until then included most of the Canadian Prairies. In the early 20th century, the province became known as a stronghold for Canadian social democracy, with the 1944 provincial election electing North America's first socialist government to office.\nSaskatchewan's economy is based on agriculture, mining, and energy. In 1992, the federal and provincial governments signed a historic land claim agreement with First Nations in Saskatchewan, granting these nations compensation which they could use to buy land on the open market for the bands. Presently, Saskatchewan is governed by the Saskatchewan Party, led by Premier Scott Moe, which has been in power since 2007.\nEtymology.\nThe name of the province is derived from the Saskatchewan River. The river is known as (\"swift flowing river\") in the Cree language. Anthony Henday's spelling was \"Keiskatchewan\", with the modern rendering, \"Saskatchewan\", being officially adopted in 1882, when a portion of the present-day province was designated a provisional district of the North-West Territories.\nGeography.\nSaskatchewan is the only province without a natural border. As its borders follow geographic lines of longitude and latitude, the province is roughly a quadrilateral, or a shape with four sides. However, the southern border on the 49th parallel and the northern border on the 60th parallel curve to the left as one proceeds east, as do all parallels in the Northern Hemisphere. Additionally, the eastern boundary of the province follows range lines and correction lines of the Dominion Land Survey, laid out by surveyors before the \"Dominion Lands Act\" homestead program (1880\u20131928).\nSaskatchewan is bounded on the west by Alberta, on the north by the Northwest Territories, on the north-east by Nunavut, on the east by Manitoba, and on the south by the U.S. states of Montana and North Dakota. Saskatchewan has the distinction of being the only Canadian province for which no borders correspond to physical geographic features (i.e., they are all parallels and meridians). Along with Alberta, Saskatchewan is one of only two land-locked provinces.\nThe overwhelming majority of Saskatchewan's population is in the southern third of the province, south of the 53rd parallel.\nSaskatchewan contains two major natural regions: the boreal forest in the north and the prairies in the south. They are separated by an aspen parkland transition zone near the North Saskatchewan River on the western side of the province, and near to south of the Saskatchewan River on the eastern side. Northern Saskatchewan is mostly covered by forest except for the Lake Athabasca Sand Dunes, the largest active sand dunes in the world north of 58\u00b0, and adjacent to the southern shore of Lake Athabasca. Southern Saskatchewan contains another area with sand dunes known as the \"Great Sand Hills\", covering over . The Cypress Hills, in the southwestern corner of Saskatchewan and Killdeer Badlands (Grasslands National Park), are areas of the province that were unglaciated during the last glaciation period, the Wisconsin glaciation.\nThe province's highest point, at , is in the Cypress Hills less than from the provincial boundary with Alberta. The lowest point is the shore of Lake Athabasca, at . The province has 14 major drainage basins made up of various rivers and watersheds draining into the Arctic Ocean, Hudson Bay, and the Gulf of Mexico.\nClimate.\nSaskatchewan receives more hours of sunshine than any other Canadian province. The province lies far from any significant body of water. This fact, combined with its northerly latitude, gives it a warm summer, corresponding to its humid continental climate (K\u00f6ppen type \"Dfb\") in the central and most of the eastern parts of the province, as well as the Cypress Hills; drying off to a semi-arid steppe climate (K\u00f6ppen type \"BSk\") in the southwestern part of the province. Drought can affect agricultural areas during long periods with little or no precipitation at all. The northern parts of Saskatchewan \u2013 from about La Ronge northward \u2013 have a subarctic climate (K\u00f6ppen \"Dfc\") with a shorter summer season. Summers can get very hot, sometimes above during the day, and with humidity decreasing from northeast to southwest. Warm southern winds blow from the plains and intermontane regions of the Western United States during much of July and August, and very cool or hot but changeable air masses often occur during spring and in September. Winters are usually bitterly cold, with frequent Arctic air descending from the north, and with high temperatures not breaking for weeks at a time. Warm chinook winds often blow from the west, bringing periods of mild weather. Annual precipitation averages 30 to 45 centimetres (12 to 18\u00a0inches) across the province, with the bulk of rain falling in June, July, and August.\nSaskatchewan is one of the most tornado-active parts of Canada, averaging roughly 12 to 18 tornadoes per year, some violent. In 2012, 33 tornadoes were reported in the province. The Regina Cyclone took place in June 1912 when 28 people died in an F4 Fujita scale tornado. Severe and non-severe thunderstorm events occur in Saskatchewan, usually from early spring to late summer. Hail, strong winds and isolated tornadoes are a common occurrence.\nThe hottest temperature ever recorded in Saskatchewan was in July 1937 when the temperature rose to in Midale and Yellow Grass. The coldest ever recorded in the province was in Prince Albert, north of Saskatoon, in February 1893.\nClimate change.\nThe effects of climate change in Saskatchewan are now being observed in parts of the province. Evidence of reduction of biomass in Saskatchewan's boreal forests (as with those of other Canadian prairie provinces) is linked by researchers to drought-related water stress, stemming from global warming, most likely caused by greenhouse gas emissions. While studies as early as 1988 (Williams, et al., 1988) have shown climate change will affect agriculture, whether the effects can be mitigated through adaptations of cultivars, or crops, is less clear. Resiliency of ecosystems may decline with large changes in temperature. The provincial government has responded to the threat of climate change by introducing a plan to reduce carbon emissions, \"The Saskatchewan Energy and Climate Change Plan\", in June 2007.\nHistory.\nSaskatchewan has been populated by various indigenous peoples of North America, including members of the Sarcee, Niitsitapi, Atsina, Cree, Saulteaux, Assiniboine (Nakoda), and Sioux.\nThe first known European to enter Saskatchewan was Henry Kelsey from England in 1690, who travelled up the Saskatchewan River in hopes of trading fur with the region's indigenous peoples. Fort La Jonqui\u00e8re and Fort de la Corne were first established in 1751 and 1753 by early French explorers and traders. The first permanent European settlement was a Hudson's Bay Company post at Cumberland House, founded in 1774 by Samuel Hearne. The southern part of the province was part of Spanish Louisiana from 1762 until 1802.\n19th century.\nIn 1803, the Louisiana Purchase transferred from France to the United States part of what is now Alberta and Saskatchewan. In 1818, the U.S. ceded the area to Britain. Most of what is now Saskatchewan was part of Rupert's Land and controlled by the Hudson's Bay Company, which claimed rights to all watersheds flowing into Hudson Bay, including the Saskatchewan River, Churchill, Assiniboine, Souris, and Qu'Appelle River systems.\nIn the late 1850s and early 1860s, scientific expeditions led by John Palliser and Henry Youle Hind explored the prairie region of the province.\nIn 1870, Canada acquired the Hudson's Bay Company's territories and formed the North-West Territories to administer the vast territory between British Columbia and Manitoba. The Crown also entered into a series of numbered treaties with the indigenous peoples of the area, which serve as the basis of the relationship between First Nations, as they are called today, and the Crown. Since the late twentieth century, land losses and inequities as a result of those treaties have been subject to negotiation for settlement between the First Nations in Saskatchewan and the federal government, in collaboration with provincial governments.\nIn 1876, following their defeat of United States Army forces at the Battle of the Little Bighorn in Montana Territory in the United States, the Lakota Chief Sitting Bull led several thousand of his people to Wood Mountain. Survivors and descendants founded Wood Mountain Reserve in 1914.\nThe North-West Mounted Police set up several posts and forts across Saskatchewan, including Fort Walsh in the Cypress Hills, and Wood Mountain Post in south-central Saskatchewan near the United States border.\nMany M\u00e9tis people, who had not been signatories to a treaty, had moved to the Southbranch Settlement and Prince Albert district north of present-day Saskatoon following the Red River Rebellion in Manitoba in 1870. In the early 1880s, the Canadian government refused to hear the M\u00e9tis' grievances, which stemmed from land-use issues. Finally, in 1885, the M\u00e9tis, led by Louis Riel, staged the North-West Rebellion and declared a provisional government. They were defeated by a Canadian militia brought to the Canadian prairies by the new Canadian Pacific Railway. Riel, who surrendered and was convicted of treason in a packed Regina courtroom, was hanged on November 16, 1885. Since then, the government has recognized the M\u00e9tis as an aboriginal people with status rights and provided them with various benefits.\nEuropean settlements.\nThe national policy set by the federal government, the Canadian Pacific Railway, the Hudson's Bay Company and associated land companies encouraged immigration. The \"Dominion Lands Act\" of 1872 permitted settlers to acquire one-quarter of a square mile of land to homestead and offered an additional quarter upon establishing a homestead. In 1874, the North-West Mounted Police began providing police services. In 1876, the \"North-West Territories Act\" provided for appointment, by Ottawa, of a Lieutenant Governor and a Council to assist him.\nHighly optimistic advertising campaigns promoted the benefits of prairie living. Potential immigrants read leaflets that described Canada as a favourable place to live and downplayed the need for agricultural expertise. Ads in \"The Nor'-West Farmer\" by the Commissioner of Immigration implied that western land held water, wood, gold, silver, iron, copper, and cheap coal for fuel, all of which were readily at hand. The reality was far harsher, especially for the first arrivals who lived in sod houses. However eastern money poured in and by 1913, long term mortgage loans to Saskatchewan farmers had reached $65 million.\nThe dominant groups comprised British settlers from eastern Canada and Britain, who comprised about half of the population during the late 19th and early 20th centuries. They played the leading role in establishing the basic institutions of plains society, economy and government.\n20th century.\nGender roles were sharply defined. Men were primarily responsible for breaking the land; planting and harvesting; building the house; buying, operating and repairing machinery; and handling finances. At first, there were many single men on the prairie, or husbands whose wives were still back east, but they had a hard time. They realized the need for a wife. In 1901, there were 19,200 families, but this surged to 150,300 families only 15 years later. Wives played a central role in settlement of the prairie region. Their labour, skills, and ability to adapt to the harsh environment proved decisive in meeting the challenges. They prepared bannock, beans and bacon, mended clothes, raised children, cleaned, tended the garden, helped at harvest time and nursed everyone back to health. While prevailing patriarchal attitudes, legislation, and economic principles obscured women's contributions, the flexibility exhibited by farm women in performing productive and nonproductive labour was critical to the survival of family farms, and thus to the success of the wheat economy.\nOn September 1, 1905, Saskatchewan became a province, with inauguration day held on September 4. Its political leaders at the time proclaimed its destiny was to become Canada's most powerful province. Saskatchewan embarked on an ambitious province-building program based on its Anglo-Canadian culture and wheat production for the export market. Population quintupled from 91,000 in 1901 to 492,000 in 1911, thanks to heavy immigration of farmers from Ukraine, U.S., Germany and Scandinavia. Efforts were made to assimilate the newcomers to British Canadian culture and values.\nIn the 1905 provincial elections, Liberals won 16 of 25 seats in Saskatchewan. The Saskatchewan government bought out Bell Telephone Company in 1909, with the government owning the long-distance lines and left local service to small companies organized at the municipal level. Premier Walter Scott preferred government assistance to outright ownership because he thought enterprises worked better if citizens had a stake in running them; he set up the Saskatchewan Cooperative Elevator Company in 1911. Despite pressure from farm groups for direct government involvement in the grain handling business, the Scott government opted to loan money to a farmer-owned elevator company. Saskatchewan in 1909 provided bond guarantees to railway companies for the construction of branch lines, alleviating the concerns of farmers who had trouble getting their wheat to market by waggon. The Saskatchewan Grain Growers Association, was the dominant political force in the province until the 1920s; it had close ties with the governing Liberal party. In 1913, the Saskatchewan Stock Growers Association was established with three goals: to watch over legislation; to forward the interests of the stock growers in every honourable and legitimate way; and to suggest to parliament legislation to meet changing conditions and requirements.\nImmigration peaked in 1910, and in spite of the initial difficulties of frontier life \u2013 distance from towns, sod homes, and backbreaking labour \u2013 new settlers established a European-Canadian style of prosperous agrarian society. The long-term prosperity of the province depended on the world price of grain, which headed steadily upward from the 1880s to 1920, then plunged down. Wheat output was increased by new strains, such as the \"Marquis wheat\" strain which matured 8 days sooner and yielded 7 more bushels per acre (0.72\u00a0m3/ha) than the previous standard, \"Red Fife\". The national output of wheat soared from in 1896, to in 1901, reaching by 1921.\nUrban reform movements in Regina were based on support from business and professional groups. City planning, reform of local government, and municipal ownership of utilities were more widely supported by these two groups, often through such organizations as the Board of Trade. Church-related and other altruistic organizations generally supported social welfare and housing reforms; these groups were generally less successful in getting their own reforms enacted.\nThe province responded to the First World War in 1914 with patriotic enthusiasm and enjoyed the resultant economic boom for farms and cities alike. Emotional and intellectual support for the war emerged from the politics of Canadian national identity, the rural myth, and social gospel progressivism The Church of England was especially supportive. However, there was strong hostility toward German-Canadian farmers. Recent Ukrainian immigrants were enemy aliens because of their citizenship in the Austro-Hungarian Empire. A small fraction were taken to internment camps. Most of the internees were unskilled unemployed labourers who were imprisoned \"because they were destitute, not because they were disloyal\".\nThe price of wheat tripled and acreage seeded doubled. The wartime spirit of sacrifice intensified social reform movements that had predated the war and now came to fruition. Saskatchewan gave women the right to vote in 1916 and at the end of 1916 passed a referendum to prohibit the sale of alcohol.\nIn the late 1920s, the Ku Klux Klan, imported from the United States and Ontario, gained brief popularity in nativist circles in Saskatchewan and Alberta. The Klan, briefly allied with the provincial Conservative party because of their mutual dislike for Premier James G. \"Jimmy\" Gardiner and his Liberals (who ferociously fought the Klan), enjoyed about two years of prominence. It declined and disappeared, subject to widespread political and media opposition, plus internal scandals involving the use of the organization's funds.\nPost\u2013Second World War.\nIn 1970, the first annual Canadian Western Agribition was held in Regina. This farm-industry trade show, with its strong emphasis on livestock, is rated as one of the five top livestock shows in North America, along with those in Houston, Denver, Louisville and Toronto.\nThe province celebrated the 75th anniversary of its establishment in 1980, with Princess Margaret, Countess of Snowdon, presiding over the official ceremonies. In 2005, 25 years later, her sister, Queen Elizabeth II, attended the events held to mark Saskatchewan's centennial.\nSince the late 20th century, First Nations have become more politically active in seeking justice for past inequities, especially related to the taking of indigenous lands by various governments. The federal and provincial governments have negotiated on numerous land claims, and developed a program of \"Treaty Land Entitlement\", enabling First Nations to buy land to be taken into reserves with money from settlements of claims.\n\"In 1992, the federal and provincial governments signed an historic land claim agreement with Saskatchewan First Nations. Under the Agreement, the First Nations received money to buy land on the open market. As a result, about 761,000 acres have been turned into reserve land and many First Nations continue to invest their settlement dollars in urban areas\", including Saskatoon. The money from such settlements has enabled First Nations to invest in businesses and other economic infrastructure.\n21st century.\nIn June 2021, a graveyard containing the remains of 751 unidentified people was found at the former Marieval Indian Residential School, part of the Canadian Indian residential school system.\nDemographics.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nEthnicity.\nAccording to the 2011 Canadian census, the largest ethnic group in Saskatchewan is German (28.6%), followed by English (24.9%), Scottish (18.9%), Canadian (18.8%), Irish (15.5%), Ukrainian (13.5%), French (Fransaskois) (12.2%), First Nations (12.1%), Norwegian (6.9%), and Polish (5.8%).\nLanguage.\nAs of the 2021 Canadian census, the ten most spoken languages in the province included English (1,094,785 or 99.24%), French (52,065 or 4.72%), Tagalog (36,125 or 3.27%), Cree (24,850 or 2.25%), Hindi (15,745 or 1.43%), Punjabi (13,310 or 1.21%), German (11,815 or 1.07%), Mandarin (11,590 or 1.05%), Spanish (11,185 or 1.01%), and Ukrainian (10,795 or 0.98%). The question on knowledge of languages allows for multiple responses.\nReligion.\nAccording to the 2021 census, religious groups in Saskatchewan included:\nEconomy.\nHistorically, Saskatchewan's economy was primarily associated with agriculture, with wheat being the precious symbol on the province's flag. Increasing diversification has resulted in agriculture, forestry, fishing, and hunting only making up 8.9% of the province's GDP in 2018. Saskatchewan grows a large portion of Canada's grain. In 2017, the production of canola surpassed the production of wheat, which is Saskatchewan's most familiar crop and the one most often associated with the province. The total net income from farming was $3.3 billion in 2017, which was $0.9 billion less than the income in 2016. Other grains such as flax, rye, oats, peas, lentils, canary seed, and barley are also produced in the province. Saskatchewan is the world's largest exporter of mustard seed. Beef cattle production by a Canadian province is only exceeded by Alberta. In the northern part of the province, forestry is also a significant industry.\nMining is a major industry in the province, with Saskatchewan being the world's largest exporter of potash and uranium. Oil and natural gas production is also a very important part of Saskatchewan's economy, although the oil industry is larger. Among Canadian provinces, only Alberta exceeds Saskatchewan in overall oil production. Heavy crude is extracted in the Lloydminster-Kerrobert-Kindersley areas. Light crude is found in the Kindersley-Swift Current areas as well as the Weyburn-Estevan fields. Natural gas is found almost entirely in the western part of Saskatchewan, from the Primrose Lake area through Lloydminster, Unity, Kindersley, Leader, and around Maple Creek areas.\nMajor companies based in Saskatchewan include Nutrien, Federated Cooperatives Ltd. and Cameco.\nMajor Saskatchewan-based Crown corporations are Saskatchewan Government Insurance (SGI), SaskTel, SaskEnergy (the province's main supplier of natural gas), SaskPower, and Saskatchewan Crop Insurance Corporation (SCIC). Bombardier runs the NATO Flying Training Centre at 15 Wing, near Moose Jaw. Bombardier was awarded a long-term contract in the late 1990s for $2.8 billion from the federal government for the purchase of military aircraft and the running of the training facility. SaskPower since 1929 has been the principal supplier of electricity in Saskatchewan, serving more than 451,000 customers and managing $4.5 billion in assets. SaskPower is a major employer in the province with almost 2,500 permanent full-time staff in 71 communities.\nEducation.\nPublicly funded elementary and secondary schools in the province are administered by twenty-seven school divisions. Public elementary and secondary schools either operate as secular or as a separate schools. Nearly all school divisions, except one operate as an English first language school board. The Division scolaire francophone No. 310 is the only school division that operates French first language schools. In addition to elementary and secondary schools, the province is also home to several post-secondary institutions.\nThe first education on the prairies took place within the family groups of the First Nations and early fur trading settlers. There were only a few missionary or trading post schools established in Rupert's Land \u2013 later known as the North West Territories. The first 76 North-West Territories school districts and the first Board of Education meeting formed in 1886. The pioneering boom formed ethnic bloc settlements. Communities were seeking education for their children similar to the schools of their homeland. Log cabins, and dwellings were constructed for the assembly of the community, school, church, dances and meetings.\nThe prosperity of the Roaring Twenties and the success of farmers in proving up on their homesteads helped provide funding to standardize education. Textbooks, normal schools for educating teachers, formal school curricula and state of the art school house architectural plans provided continuity throughout the province. English as the school language helped to provide economic stability because one community could communicate with another and goods could be traded and sold in a common language. The number of one-room schoolhouse districts across Saskatchewan totalled approximately 5,000 at the height of this system of education in the late 1940s.\nFollowing World War II, the transition from many one-room schoolhouses to fewer and larger consolidated modern technological town and city schools occurred as a means of ensuring technical education. School buses, highways, and family vehicles create ease and accessibility of a population shift to larger towns and cities. Combines and tractors mean the farmer could manage more than a quarter section of land, so there was a shift from family farms and subsistence crops to cash crops grown on many sections of land. School vouchers have been newly proposed as a means of allowing competition between rural schools and making the operation of cooperative schools practicable in rural areas.\nHealthcare.\nSaskatchewan's Ministry of Health is responsible for policy direction, sets and monitors standards, and provides funding for regional health authorities and provincial health services. Saskatchewan's health system is a single-payer system. Medical practitioners in Saskatchewan are independent contractors. They remit their accounts to the publicly funded Saskatchewan Medical Care Insurance Plan, which pays the accounts. Patients do not pay anything to their doctors or hospitals for medical care.\nIn 1944, the Co-operative Commonwealth Federation (CCF), a left-wing agrarian and labour party, won the provincial election in Saskatchewan and formed the first socialist government in North American history. Repeatedly re-elected, the CCF campaigned in the early 1960s on the theme of universal health coverage and, after winning the election again, implemented it, the first in Canada. However, it was fiercely opposed by the province's doctors' union, which went on a massive strike the day the new system came into effect. Supported by the Saskatchewan Chamber of Commerce, most newspapers and the right-wing Keep Our Doctors movement, the doctors' union ran an effective communications campaign portraying the universal health care system as a communist scheme that would spread disease. The strike, which had become very unpopular because of the outrageous rhetoric of some of its leaders (one of them had called for bloodshed), finally ended after a few weeks, and universal health coverage was adopted by the whole country five years later.\nGovernment and politics.\nSaskatchewan has the same form of government as the other Canadian provinces with a lieutenant-governor (who is the representative of the King in Right of Saskatchewan), premier, and a unicameral legislature.\nDuring the 20th century, Saskatchewan was one of Canada's more left-wing provinces, reflecting the slant of its many rural citizens which distrusted the distant capital government and which favoured a strong local government to attend to their issues. In 1944 Tommy Douglas became premier of the first avowedly socialist regional government in North America. Most of his Members of the Legislative Assembly (MLAs) represented rural and small-town ridings. Under his Cooperative Commonwealth Federation government, Saskatchewan became the first province to have Medicare. In 1961, Douglas left provincial politics to become the first leader of the federal New Democratic Party. In the 21st century, Saskatchewan began to drift to the right-wing, generally attributed to the province's economy shifting toward oil and gas production. In the 2015 federal election, the Conservative Party of Canada won ten of the province's fourteen seats, followed by the New Democratic Party with three and the Liberal Party of Canada with one; in the 2019 election, the Conservatives won in all of Saskatchewan's 14 seats, sweeping their competition, and retained them all in the 2021 election; in the 2025 Canadian federal election, the Liberal Party won a single seat in northern Saskatchewan .\nProvincial politics in Saskatchewan is dominated by the social-democratic Saskatchewan New Democratic Party and the centre-right Saskatchewan Party, with the latter holding the majority in the Legislative Assembly of Saskatchewan since 2007. The current Premier of Saskatchewan is Scott Moe, who took over the leadership of the Saskatchewan Party in 2018 following the resignation of Brad Wall. Numerous smaller political parties also run candidates in provincial elections, including the Green Party of Saskatchewan, Buffalo Party of Saskatchewan, Saskatchewan Progress Party, and the Progressive Conservative Party of Saskatchewan, but none is currently represented in the Legislative Assembly.\nNo Prime Minister of Canada has been born in Saskatchewan, but two (William Lyon Mackenzie King and John Diefenbaker) represented the province in the House of Commons of Canada during their tenures as head of government.\nAdministrative divisions.\nBelow the provincial level of government, Saskatchewan is divided into urban and rural municipalities. The Government of Saskatchewan's Ministry of Municipal Relations recognizes three general types of municipalities and seven sub-types \u2013 urban municipalities (cities, towns, villages and resort villages), rural municipalities and northern municipalities (northern towns, northern villages and northern hamlets). The vast majority of the land mass of Northern Saskatchewan is within the unorganized Northern Saskatchewan Administration District. Cities are formed under the provincial authority of \"The Cities Act\", which was enacted in 2002. Towns, villages, resort villages and rural municipalities are formed under the authority of \"The Municipalities Act\", enacted in 2005. The three sub-types of northern municipalities are formed under the authority of \"The Northern Municipalities Act\", enacted in 2010.\nIn 2016, Saskatchewan's 774 municipalities covered of the province's land mass and were home to of its population.\nThese 774 municipalities are local government \"creatures of provincial jurisdiction\" with legal personhood. One of the key purposes of Saskatchewan's municipalities are \"to provide services, facilities and other things that, in the opinion of council, are necessary or desirable for all or a part of the municipality\". Other purposes are to: \"provide good government\"; \"develop and maintain a safe and viable community\"; \"foster economic, social and environmental well-being\" and \"provide wise stewardship of public assets.\"\nTransportation.\nTransportation in Saskatchewan includes an infrastructure system of roads, highways, freeways, airports, ferries, pipelines, trails, waterways and railway systems serving a population of approximately 1,003,299 (according to 2007 estimates) inhabitants year-round. The Saskatchewan Department of Highways and Transportation estimates 80% of traffic is carried on the 5,031-kilometre principal system of highways.\nThe Ministry of Highways and Infrastructure operates over of highways and divided highways. There are also municipal roads which comprise different surfaces. Asphalt concrete pavements comprise almost , granular pavement almost , non structural or thin membrane surface TMS are close to and finally gravel highways make up over through the province. In the northern sector, ice roads which can only be navigated in the winter months comprise another approximately of travel. In 2024, the Government of Canada provided Saskatchewan with a $6.1-million grant for shuttle buses serving remote communities.\nSaskatchewan has over of roads and highways, the highest length of road surface of any Canadian province. The major highways in Saskatchewan are the Trans-Canada Highway, Yellowhead Highway northern Trans Canada route, Louis Riel Trail, CanAm Highway, Red Coat Trail, Northern Woods and Water route, and Saskota travel route.\nThe first Canadian transcontinental railway was constructed by the Canadian Pacific Railway (CPR) between 1881 and 1885. After the great east\u2013west transcontinental railway was built, north\u2013south connector branch lines were established. The 1920s saw the largest rise in rail line track as the CPR and Canadian National Railway (CNR) fell into competition to provide rail service within ten kilometres. In the 1960s there were applications for abandonment of branch lines. Today the only two passenger rail services in the province are \"The Canadian\" and Winnipeg\u2013Churchill train, both operated by Via Rail. \"The Canadian\" is a transcontinental service linking Toronto with Vancouver.\nThe main Saskatchewan waterways are the North Saskatchewan River or South Saskatchewan River routes. In total, there are 3,050 bridges maintained by the Department of Highways in Saskatchewan. There are currently twelve ferry services operating in the province, all under the jurisdiction of the Department of Highways.\nThe Saskatoon Airport was initially established as part of the Royal Canadian Air Force training program during World War II. It was renamed the John G. Diefenbaker Airport in 1993. \"Roland J. Groome Airfield\" is the official designation for the Regina International Airport as of 2005; the airport was established in 1930.\nAirlines offering service to Saskatchewan are Air Canada, WestJet, Delta Air Lines, Transwest Air, Sunwing Airlines, Norcanair Airlines, La Ronge Aviation Services Ltd, La Loche Airways, Osprey Wings Ltd, Buffalo Narrows Airways Ltd, \u00cele-\u00e0-la-Crosse Airways Ltd, Voyage Air, Pronto Airways, Venture Air Ltd, Pelican Narrows Air Service, Jackson Air Services Ltd, and Northern Dene Airways Ltd.\nThe Government of Canada agreed to contribute $20 million for two new interchanges in Saskatoon. One of them being at the Highway 219/Lorne Avenue intersection with Circle Drive, the other at the Senator Sid Buckwold Bridge (Idylwyld Freeway) and Circle Drive. This is part of the Asia-Pacific Gateway and Corridor Initiative to improve access to the CNR's intermodal freight terminal thereby increasing Asia-Pacific trade. Also, the Government of Canada will contribute $27 million to Regina to construct a CPR intermodal facility and improve infrastructure transportation to the facility from both national highway networks, Highway 1, the Trans-Canada Highway and Highway 11, Louis Riel Trail. This also is part of the Asia-Pacific Gateway and Corridor Initiative to improve access to the CPR terminal and increase Asia-Pacific trade.\nCulture.\nSaskatchewan is home to a number of museums. The Royal Saskatchewan Museum is the provincial museum of the province. Other museums include Diefenbaker House, Evolution of Education Museum, Museum of Antiquities, the RCMP Heritage Centre, Rotary Museum of Police and Corrections, Saskatchewan Science Centre, Saskatchewan Western Development Museum, and the T.rex Discovery Centre.\nArt.\nThe province is home to several art galleries, including MacKenzie Art Gallery, and Remai Modern. The province is also home to several performing arts centres including the Conexus Arts Centre in Regina, and TCU Place in Saskatoon. PAVED Arts, a new media artist-run space, is also in Saskatoon.\nMusic.\nThe province is presently home to several concert orchestras, the Regina Symphony Orchestra, the Saskatoon Symphony Orchestra, and the Saskatoon Youth Orchestra. The Regina Symphony Orchestra is at the Conexus Arts Centre, while the Saskatoon performs at TCU Place.\nLiterature.\nA leading writer from Saskatchewan is W. O. Mitchell (1914\u20131998), born in Weyburn. His best-loved novel is \"Who Has Seen the Wind\" (1947), which portrays life on the Canadian Prairies and sold almost a million copies in Canada. As a broadcaster, he is known for his radio series Jake and the Kid, which aired on CBC Radio between 1950 and 1956 and was also about life on the Prairies. Canadian author Farley Mowat's book Owls in the Family takes place in Saskatoon, Saskatchewan.\nSports.\nHockey is the most popular sport in Saskatchewan. More than 500 National Hockey League (NHL) players have been born in Saskatchewan, the highest per capita output of any Canadian province, U.S. state, or European country. This includes Gordie Howe, dubbed \"Mr. Hockey\" and widely regarded as one of the greatest hockey players of all time. Some other notable NHL figures born in Saskatchewan include Keith Allen, Bryan Trottier, Bernie Federko, Clark Gillies, Fernie Flaman, Fred Sasakamoose, Bert Olmstead, Harry Watson, Elmer Lach, Max Bentley, Sid Abel, Doug Bentley, Eddie Shore, Clint Smith, Bryan Hextall, Johnny Bower, Emile Francis, Glenn Hall, Chuck Rayner, Wendel Clark, Brad McCrimmon, Mike Babcock, Patrick Marleau, Theo Fleury, Terry Harper, Wade Redden, Brian Propp, Ryan Getzlaf, Chris Kunitz, Kelly Chase, and Jordan Eberle. A number of prominent women's hockey players and figures have come from the province as well, including Hayley Wickenheiser, Colleen Sostorics, Gina Kingsbury, Shannon Miller, and Emily Clark. Wickenheiser was the first female skater to play full-time professional hockey in a men's league and is regarded as one of the greatest hockey players of all time. Saskatchewan does not have a professional hockey franchise, but five teams in the junior Western Hockey League are based in the province: the Moose Jaw Warriors, Prince Albert Raiders, Regina Pats, Saskatoon Blades, and Swift Current Broncos.\nThe Saskatchewan Roughriders are the province's professional Canadian football team playing in the Canadian Football League, and are based in Regina but popular across Saskatchewan. The team's fans are also found to congregate on game days throughout Canada, and collectively they are known as \"Rider Nation\". The Roughriders are one of the oldest professional sports teams and community-owned franchises in North America and have won five Grey Cup championships. The province also boasts successful women's football teams. The Saskatoon Valkyries and the Regina Riot are the only two teams to win championships in the Western Women's Canadian Football League since it began play in 2011.\nThe province is home to two other professional sports franchises. The Saskatchewan Rush play in the National Lacrosse League. In 2016, their first year after relocating from Edmonton, Alberta, the Rush won both their Division Title and the League Championship. In 2018, the province received a Canadian Elite Basketball League franchise, the Saskatchewan Rattlers, which won the league's inaugural championship in 2019. The Saskatchewan Heat are a semi-professional team in the National Ringette League. The province boasts six teams in the Western Canadian Baseball League.\nCurling is the province's official sport and, historically, Saskatchewan has been one of the strongest curling provinces. Teams from Saskatchewan have won seven Canadian men's championships, five world men's championships, thirteen Canadian women's championships, and four world women's championships. Notable curlers from Saskatchewan include Ernie Richardson, Joyce McKee, Vera Pezer, Rick Folk, Sandra Schmirler, and Ben Hebert. In a 2019 poll conducted by The Sports Network (TSN), experts ranked Schmirler's Saskatchewan team, which won the gold medal at the 1998 Olympics, as the greatest women's team in Canada's history.\nSymbols.\nThe flag of Saskatchewan was officially adopted on September 22, 1969. The flag features the provincial shield in the upper quarter nearest the staff, with the floral emblem, the Prairie lily, in the fly. The upper green (in forest green) half of the flag represents the northern Saskatchewan forest lands, while the golden lower half of the flag symbolizes the southern wheat fields and prairies. A province-wide competition was held to design the flag, and drew over 4,000 entries. The winning design was by Anthony Drake, then living in Hodgeville.\nIn 2005, Saskatchewan Environment held a province-wide vote to recognize Saskatchewan's centennial year, receiving more than 10,000 online and mail-in votes from the public. The walleye was the overwhelming favourite of the six native fish species nominated for the designation, receiving more than half the votes cast. Other species in the running were the lake sturgeon, lake trout, lake whitefish, northern pike and yellow perch.\nSaskatchewan's other symbols include the tartan, the licence plate, and the provincial flower. Saskatchewan's official tartan was registered with the Court of Lord Lyon King of Arms in Scotland in 1961. It has seven colours: gold, brown, green, red, yellow, white and black. The provincial licence plates display the slogan \"Land of Living Skies\". The provincial flower of Saskatchewan is the western red lily.\nCentennial celebrations.\nIn 2005, Saskatchewan celebrated its centennial. To honour it, the Royal Canadian Mint issued a commemorative five-dollar coin depicting Canada's wheat fields as well as a circulation 25-cent coin of a similar design. Queen Elizabeth II and Prince Philip visited Regina, Saskatoon, and Lumsden, and the Saskatchewan-reared Joni Mitchell issued an album in Saskatchewan's honour.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; travel guide from Wikivoyage"}
{"id": "26841", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=26841", "title": "Summer solstice (disambiguation)", "text": "Summer solstice is the astronomical phenomenon that occurs on the longest day of the year.\nSummer solstice may also refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "26842", "revid": "43376670", "url": "https://en.wikipedia.org/wiki?curid=26842", "title": "Salting", "text": "Salting or Salted may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "26843", "revid": "38984", "url": "https://en.wikipedia.org/wiki?curid=26843", "title": "Saturday-night special", "text": ""}
{"id": "26845", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=26845", "title": "Subjectivism (disambiguation)", "text": ""}
{"id": "26847", "revid": "28979433", "url": "https://en.wikipedia.org/wiki?curid=26847", "title": "Socialism", "text": "Political philosophy emphasising social ownership of production\nSocialism is an economic and political philosophy encompassing diverse economic and social systems characterised by social ownership of the means of production, as opposed to private ownership. It describes the economic, political, and social theories and movements associated with the implementation of such systems. Social ownership can take various forms, including public, community, collective, cooperative, or employee. As one of the main ideologies on the political spectrum, socialism is the standard left-wing ideology in most countries. Types of socialism vary based on the role of markets and planning in resource allocation, and the structure of management in organizations.\nSocialist systems are divided into non-market and market forms. A non-market socialist system seeks to eliminate the perceived inefficiencies, irrationalities, unpredictability, and crises that socialists traditionally associate with capital accumulation and the profit system. Market socialism retains the use of monetary prices, factor markets and sometimes the profit motive. As a political force, socialist parties and ideas exercise varying degrees of power and influence, heading national governments in several countries. Socialist politics have been internationalist and nationalist; organised through political parties and opposed to party politics; at times overlapping with trade unions and other times independent and critical of them, and present in industrialised and developing nations. Social democracy originated within the socialist movement, supporting economic and social interventions to promote social justice. While retaining socialism as a long-term goal, in the post-war period social democracy embraced a mixed economy based on Keynesianism within a predominantly developed capitalist market economy and liberal democratic polity that expands state intervention to include income redistribution, regulation, and a welfare state.\nThe socialist political movement includes political philosophies that originated in the revolutionary movements of the mid-to-late 18th century and out of concern for the social problems that socialists associated with capitalism. By the late 19th century, after the work of Karl Marx and his collaborator Friedrich Engels, socialism had come to signify anti-capitalism and advocacy for a post-capitalist system based on some form of social ownership of the means of production. By the early 1920s, communism and social democracy had become the two dominant political tendencies within the international socialist movement, with socialism itself becoming the most influential secular movement of the 20th century. Many socialists also adopted the causes of other social movements, such as feminism, environmentalism, and progressivism.\nAlthough the emergence of the Soviet Union as the world's first nominally socialist state led to the widespread association of socialism with the Soviet economic model, it has since shifted in favour of democratic socialism. Academics sometimes recognised the mixed economies of several Western European and Nordic countries as \"democratic socialist\", although the system of these countries, with only limited social ownership (generally in the form of state ownership), is more usually described as social democracy. Following the revolutions of 1989, many of these countries moved away from socialism as a neoliberal consensus replaced the social democratic consensus in the advanced capitalist world. In parallel, many former socialist politicians and political parties embraced \"Third Way\" politics, remaining committed to equality and welfare while abandoning public ownership and class-based politics. Socialism experienced a resurgence in popularity in the 2010s.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nEtymology.\nAccording to Andrew Vincent, \"[t]he word 'socialism' finds its root in the Latin , which means to combine or to share. The related, more technical term in Roman and then medieval law was . This latter word could mean companionship and fellowship as well as the more legalistic idea of a consensual contract between freemen\".\nInitial use of \"socialism\" was claimed by Pierre Leroux, who alleged he first used the term in the Parisian journal in 1832. Leroux was a follower of Henri de Saint-Simon, one of the founders of what would later be labelled utopian socialism. Socialism contrasted with the liberal doctrine of individualism that emphasized the moral worth of the individual while stressing that people act or should act as if they are in isolation from one another. The original utopian socialists condemned this doctrine of individualism for failing to address social concerns during the Industrial Revolution, including poverty, oppression, and vast wealth inequality. They viewed their society as harming community life by basing society on competition. They presented socialism as an alternative to liberal individualism based on the shared ownership of resources. Saint-Simon proposed economic planning, scientific administration and the application of scientific understanding to the organisation of society. By contrast, Robert Owen proposed to organise production and ownership via cooperatives. \"Socialism\" is also attributed in France to Marie Roch Louis Reybaud while in Britain it is attributed to Owen, who became one of the fathers of the cooperative movement.\nThe definition and usage of \"socialism\" settled by the 1860s, with the term \"socialist\" replacing \"associationist\", \"co-operative\", \"mutualist\" and \"collectivist\", which had been used as synonyms, while the term \"communism\" fell out of use during this period. An early distinction between \"communism\" and \"socialism\" was that the latter aimed to only socialise production while the former aimed to socialise both production and consumption (in the form of free access to final goods). By 1888, Marxists employed \"socialism\" in place of \"communism\" as the latter had come to be considered an old-fashioned synonym for \"socialism\". It was not until after the Bolshevik Revolution that \"socialism\" was appropriated by Vladimir Lenin to mean a stage between capitalism and communism. He used it to defend the Bolshevik program from Marxist criticism that Russia's productive forces were not sufficiently developed for communism. The distinction between \"communism\" and \"socialism\" became salient in 1918 after the Russian Social Democratic Labour Party renamed itself to the All-Russian Communist Party, interpreting \"communism\" specifically to mean socialists who supported the politics and theories of Bolshevism, Leninism and later that of Marxism\u2013Leninism, although communist parties continued to describe themselves as socialists dedicated to socialism. According to \"The Oxford Handbook of Karl Marx\", \"Marx used many terms to refer to a post-capitalist society\u2014positive humanism, socialism, communism, realm of free individuality, free association of producers, etc. He used these terms completely interchangeably. The notion that 'socialism' and 'communism' are distinct historical stages is alien to his work and only entered the lexicon of Marxism after his death\".\nIn Christian Europe, communists were believed to have adopted atheism. In Protestant England, \"communism\" was too close to the Roman Catholic communion rite, hence \"socialist\" was the preferred term. Engels wrote that in 1848, when \"The Communist Manifesto\" was published, socialism was respectable in Europe while communism was not. The Owenites in England and the Fourierists in France were considered respectable socialists while working-class movements that \"proclaimed the necessity of total social change\" denoted themselves \"communists\". This branch of socialism produced the communist work of \u00c9tienne Cabet in France and Wilhelm Weitling in Germany. British moral philosopher John Stuart Mill discussed a form of economic socialism within free market. In later editions of his \"Principles of Political Economy\" (1848), Mill posited that \"as far as economic theory was concerned, there is nothing in principle in economic theory that precludes an economic order based on socialist policies\" and promoted substituting capitalist businesses with worker cooperatives. While democrats looked to the Revolutions of 1848 as a democratic revolution which in the long run ensured liberty, equality, and fraternity, Marxists denounced it as a betrayal of working-class ideals by a bourgeoisie indifferent to the proletariat.\nHistory.\nThe history of socialism has its origins in the Age of Enlightenment and the 1789 French Revolution, along with the changes that brought, although it has precedents in earlier movements and ideas. \"The Communist Manifesto\" was written by Karl Marx and Friedrich Engels in 1847\u201348 just before the Revolutions of 1848 swept Europe, expressing what they termed scientific socialism. In the last third of the 19th century parties dedicated to Democratic socialism arose in Europe, drawing mainly from Marxism. For a duration of one week in December 1899, the Australian Labor Party formed the first socialist government in the world when it was elected into power in the Colony of Queensland with Premier Anderson Dawson as its leader.\nIn the first half of the 20th century, the Soviet Union and the communist parties of the Third International around the world, came to represent socialism in terms of the Soviet model of economic development and the creation of centrally planned economies directed by a state that owns all the means of production, although other trends condemned what they saw as the lack of democracy. The establishment of the People's Republic of China in 1949, saw socialism introduced. China established a self-sufficient and self-reliant economy that was state-led and focused on rapid industrialization. Other policies included land redistribution and the Anti-Rightist Movement, followed by the disastrous Great Leap Forward. In the UK, Herbert Morrison said that \"socialism is what the Labour government does\" whereas Aneurin Bevan argued socialism requires that the \"main streams of economic activity are brought under public direction\", with an economic plan and workers' democracy. Some argued that capitalism had been abolished. Socialist governments established the mixed economy with partial nationalisations and social welfare.\nBy 1968, the prolonged Vietnam War gave rise to the New Left, socialists who tended to be critical of the Soviet Union and social democracy. Anarcho-syndicalists and some elements of the New Left and others favoured decentralised collective ownership in the form of cooperatives or workers' councils. In 1989, the Soviet Union saw the end of communism, marked by the Revolutions of 1989 across Eastern Europe, culminating in the dissolution of the Soviet Union in 1991. Socialists have adopted the causes of other social movements such as environmentalism, feminism and progressivism.\nEarly 21st century.\nIn 1990, the S\u00e3o Paulo Forum was launched by the Workers' Party (Brazil), linking left-wing socialist parties in Latin America. Its members were associated with the pink tide of left-wing governments on the continent in the early 21st century. Member parties ruling countries included the Front for Victory in Argentina, the PAIS Alliance in Ecuador, Farabundo Mart\u00ed National Liberation Front in El Salvador, Peru Wins in Peru, and the United Socialist Party of Venezuela, whose leader Hugo Ch\u00e1vez initiated what he called \"Socialism of the 21st century\".\nMany mainstream democratic socialist and social democratic parties continued to drift right-wards. On the right of the socialist movement, the Progressive Alliance was founded in 2013 by current or former members of the Socialist International. The organisation states the aim of becoming the global network of \"the progressive, democratic, social-democratic, socialist and labour movement\". Mainstream social democratic and socialist parties are also networked in Europe in the Party of European Socialists formed in 1992. Many of these parties lost large parts of their electoral base in the early 21st century. This phenomenon is known as Pasokification from the Greek party PASOK, which saw a declining share of the vote in national elections\u2014from 43.9% in 2009 to 13.2% in May 2012, to 12.3% in June 2012 and 4.7% in 2015\u2014due to its poor handling of the Greek government-debt crisis and implementation of harsh austerity measures.\nIn Europe, the share of votes for such socialist parties was at its 70-year lowest in 2015. For example, the Socialist Party, after winning the 2012 French presidential election, rapidly lost its vote share, the Social Democratic Party of Germany's fortunes declined rapidly from 2005 to 2019, and outside Europe the Israeli Labor Party fell from being the dominant force in Israeli politics to 4.43% of the vote in the April 2019 Israeli legislative election, and the Peruvian Aprista Party went from ruling party in 2011 to a minor party. The decline of these mainstream parties opened space for more radical and populist left parties in some countries, such as Spain's Podemos, Greece's Syriza (in government, 2015\u201319), Germany's Die Linke, and France's La France Insoumise. In other countries, left-wing revivals have taken place within mainstream democratic socialist and centrist parties, as with Jeremy Corbyn in the United Kingdom and Bernie Sanders in the United States. Few of these radical left parties have won national government in Europe, while some more mainstream socialist parties have managed to, such as Portugal's Socialist Party.\nBhaskar Sunkara, the founding editor of the American socialist magazine \"Jacobin\", argued that the appeal of socialism persists due to the inequality and \"tremendous suffering\" under current global capitalism, the use of wage labor \"which rests on the exploitation and domination of humans by other humans,\" and ecological crises, such as climate change. In contrast, Mark J. Perry of the conservative American Enterprise Institute (AEI) argued that despite socialism's resurgence, it is still \"a flawed system based on completely faulty principles that aren't consistent with human behavior and can't nurture the human spirit.\", adding that \"While it promised prosperity, equality, and security, it delivered poverty, misery, and tyranny.\" Some in the scientific community have suggested that a contemporary radical response to social and ecological problems could be seen in the emergence of movements associated with degrowth, eco-socialism and eco-anarchism.\nSocial and political theory.\nEarly socialist thought took influences from a diverse range of philosophies such as civic republicanism, Enlightenment rationalism, romanticism, forms of materialism, Christianity (both Catholic and Protestant), natural law and natural rights theory, utilitarianism and liberal political economy. Another philosophical basis for a great deal of early socialism was the emergence of positivism during the European Enlightenment. Positivism held that both the natural and social worlds could be understood through scientific knowledge and be analysed using scientific methods.\nThe fundamental objective of socialism is to attain an advanced level of material production and therefore greater productivity, efficiency and rationality as compared to capitalism and all previous systems, under the view that an expansion of human productive capability is the basis for the extension of freedom and equality in society. Many forms of socialist theory hold that human behaviour is largely shaped by the social environment. In particular, socialism holds that social mores, values, cultural traits and economic practices are social creations and not the result of an immutable natural law. The object of their critique is thus not human avarice or human consciousness, but the material conditions and man-made social systems (i.e. the economic structure of society) which give rise to observed social problems and inefficiencies. Bertrand Russell, often considered to be the father of analytic philosophy, identified as a socialist. Russell opposed the class struggle aspects of Marxism, viewing socialism solely as an adjustment of economic relations to accommodate modern machine production to benefit all of humanity through the progressive reduction of necessary work time.\nSocialists view creativity as an essential aspect of human nature and define freedom as a state of being where individuals are able to express their creativity unhindered by constraints of both material scarcity and coercive social institutions. The socialist concept of individuality is intertwined with the concept of individual creative expression. Karl Marx believed that expansion of the productive forces and technology was the basis for the expansion of human freedom and that socialism, being a system that is consistent with modern developments in technology, would enable the flourishing of \"free individualities\" through the progressive reduction of necessary labour time. The reduction of necessary labour time to a minimum would grant individuals the opportunity to pursue the development of their true individuality and creativity.\nCriticism of capitalism.\nSocialists argue that the accumulation of capital generates waste through externalities that require costly corrective regulatory measures. They also point out that this process generates wasteful industries and practices that exist only to generate sufficient demand for products such as high-pressure advertisement to be sold at a profit, thereby creating rather than satisfying economic demand. Socialists argue that capitalism consists of irrational activity, such as the purchasing of commodities only to sell at a later time when their price appreciates, rather than for consumption, even if the commodity cannot be sold at a profit to individuals in need and therefore a crucial criticism often made by socialists is that \"making money\", or accumulation of capital, does not correspond to the satisfaction of demand (the production of use-values). The fundamental criterion for economic activity in capitalism is the accumulation of capital for reinvestment in production, but this spurs the development of new, non-productive industries that do not produce use-value and only exist to keep the accumulation process afloat (otherwise the system goes into crisis), such as the spread of the financial industry, contributing to the formation of economic bubbles. Such accumulation and reinvestment, when it demands a constant rate of profit, causes problems if the earnings in the rest of society do not increase in proportion.\nSocialists view private property relations as limiting the potential of productive forces in the economy. According to socialists, private property becomes obsolete when it concentrates into centralised, socialised institutions not based on private appropriation of revenue\"\u2014\"but based on cooperative work and internal planning in allocation of inputs\u2014until the role of the capitalist becomes redundant. With no need for capital accumulation and a class of owners, private property in the means of production is perceived as being an outdated form of economic organisation that should be replaced by a free association of individuals based on public or common ownership of these socialised assets. Private ownership imposes constraints on planning, leading to uncoordinated economic decisions that result in business fluctuations, unemployment and a tremendous waste of material resources during crisis of overproduction.\nExcessive disparities in income distribution lead to social instability and require costly corrective measures in the form of redistributive taxation, which incurs heavy administrative costs while weakening the incentive to work, inviting dishonesty and increasing the likelihood of tax evasion while (the corrective measures) reduce the overall efficiency of the market economy. These corrective policies limit the incentive system of the market by providing things such as minimum wages, unemployment insurance, taxing profits and reducing the reserve army of labour, resulting in reduced incentives for capitalists to invest in more production. In essence, social welfare policies cripple capitalism and its incentive system and are thus unsustainable in the long run. Marxists argue that the establishment of a socialist mode of production is the only way to overcome these deficiencies. Socialists and specifically Marxian socialists argue that the inherent conflict of interests between the working class and capital prevent optimal use of available human resources and leads to contradictory interest groups (labour and business) striving to influence the state to intervene in the economy in their favour at the expense of overall economic efficiency. Early socialists (utopian socialists and Ricardian socialists) criticised capitalism for concentrating power and wealth within a small segment of society. In addition, they complained that capitalism does not use available technology and resources to their maximum potential in the interests of the public.\nMarxism.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nAt a certain stage of development, the material productive forces of society come into conflict with the existing relations of production or\u2014this merely expresses the same thing in legal terms\u2014with the property relations within the framework of which they have operated hitherto. Then begins an era of social revolution. The changes in the economic foundation lead sooner or later to the transformation of the whole immense superstructure.\n\u2014Karl Marx, \"Critique of the Gotha Program\"\nKarl Marx and Friedrich Engels argued that socialism would emerge from historical necessity as capitalism rendered itself obsolete and unsustainable from increasing internal contradictions emerging from the development of the productive forces and technology. It was these advances in the productive forces combined with the old social relations of production of capitalism that would generate contradictions, leading to working-class consciousness.\nMarx and Engels held the view that the consciousness of those who earn a wage or salary (the working class in the broadest Marxist sense) would be moulded by their conditions of wage slavery, leading to a tendency to seek their freedom or emancipation by overthrowing ownership of the means of production by capitalists and consequently, overthrowing the state that upheld this economic order. For Marx and Engels, conditions determine consciousness and ending the role of the capitalist class leads eventually to a classless society in which the state would wither away.\nMarx and Engels used the terms socialism and communism interchangeably, but many later Marxists defined socialism as a specific historical phase that would displace capitalism and precede communism.\nThe major characteristics of socialism (particularly as conceived by Marx and Engels after the Paris Commune of 1871) are that the proletariat would control the means of production through a workers' state erected by the workers in their interests.\nFor orthodox Marxists, socialism is the lower stage of communism based on the principle of \"from each according to his ability, to each according to his contribution\", while upper stage communism is based on the principle of \"from each according to his ability, to each according to his need\", the upper stage becoming possible only after the socialist stage further develops economic efficiency and the automation of production has led to a superabundance of goods and services. Marx argued that the material productive forces (in industry and commerce) brought into existence by capitalism predicated a cooperative society since production had become a mass social, collective activity of the working class to create commodities but with private ownership (the relations of production or property relations). This conflict between collective effort in large factories and private ownership would bring about a conscious desire in the working class to establish collective ownership commensurate with the collective efforts their daily experience.\nRole of the state.\nSocialists have taken different perspectives on the state and the role it should play in revolutionary struggles, in constructing socialism and within an established socialist economy.\nIn the 19th century, the philosophy of state socialism was first explicitly expounded by the German political philosopher Ferdinand Lassalle. In contrast to Karl Marx's perspective of the state, Lassalle rejected the concept of the state as a class-based power structure whose main function was to preserve existing class structures. Lassalle also rejected the Marxist view that the state was destined to \"wither away\". Lassalle considered the state to be an entity independent of class allegiances and an instrument of justice that would therefore be essential for achieving socialism.\nPreceding the Bolshevik-led revolution in Russia, many socialists including reformists, orthodox Marxist currents such as council communism, anarchists and libertarian socialists criticised the idea of using the state to conduct central planning and own the means of production as a way to establish socialism. Following the victory of Leninism in Russia, the idea of \"state socialism\" spread rapidly throughout the socialist movement and eventually state socialism came to be identified with the Soviet economic model.\nJoseph Schumpeter rejected the association of socialism and social ownership with state ownership over the means of production because the state as it exists in its current form is a product of capitalist society and cannot be transplanted to a different institutional framework. Schumpeter argued that there would be different institutions within socialism than those that exist within modern capitalism, just as feudalism had its own distinct and unique institutional forms. The state, along with concepts like property and taxation, were concepts exclusive to commercial society (capitalism) and attempting to place them within the context of a future socialist society would amount to a distortion of these concepts by using them out of context.\nUtopian versus scientific.\nUtopian socialism is a term used to define the first currents of modern socialist thought as exemplified by the work of Henri de Saint-Simon, Charles Fourier and Robert Owen which inspired Karl Marx and other early socialists. Visions of imaginary ideal societies, which competed with revolutionary social democratic movements, were viewed as not being grounded in the material conditions of society and as reactionary. Although it is technically possible for any set of ideas or any person living at any time in history to be a utopian socialist, the term is most often applied to those socialists who lived in the first quarter of the 19th century who were ascribed the label \"utopian\" by later socialists as a negative term to imply naivete and dismiss their ideas as fanciful or unrealistic.\nReligious sects whose members live communally such as the Hutterites are not usually called \"utopian socialists\", although their way of living is a prime example. They have been categorised as religious socialists by some. Similarly, modern intentional communities based on socialist ideas could also be categorised as \"utopian socialist\". For Marxists, the development of capitalism in Western Europe provided a material basis for the possibility of bringing about socialism because according to \"The Communist Manifesto\" \"[w]hat the bourgeoisie produces above all is its own grave diggers\", namely the working class, which must become conscious of the historical objectives set it by society.\nReform versus revolution.\nRevolutionary socialists believe that a social revolution is necessary to effect structural changes to the socioeconomic structure of society. Among revolutionary socialists there are differences in strategy, theory and the definition of \"revolution\". Orthodox Marxists and left communists take an impossibilist stance, believing that revolution should be spontaneous as a result of contradictions in society due to technological changes in the productive forces. Lenin theorised that under capitalism the workers cannot achieve class consciousness beyond organising into trade unions and making demands of the capitalists. Therefore, Leninists argue that it is historically necessary for a vanguard of class conscious revolutionaries to take a central role in coordinating the social revolution to overthrow the capitalist state and eventually the institution of the state altogether. \"Revolution\" is not necessarily defined by revolutionary socialists as violent insurrection, but as a complete dismantling and rapid transformation of all areas of class society led by the majority of the masses: the working class.\nReformism is generally associated with social democracy and gradualist democratic socialism. Reformism is the belief that socialists should stand in parliamentary elections within capitalist society and if elected use the machinery of government to pass political and social reforms for the purposes of ameliorating the instabilities and inequities of capitalism. Within socialism, \"reformism\" is used in two different ways. One has no intention of bringing about socialism or fundamental economic change to society and is used to oppose such structural changes. The other is based on the assumption that while reforms are not socialist in themselves, they can help rally supporters to the cause of revolution by popularizing the cause of socialism to the working class.\nThe debate on the ability for social democratic reformism to lead to a socialist transformation of society is over a century old. Reformism is criticized for being paradoxical as it seeks to overcome the existing economic system of capitalism while trying to improve the conditions of capitalism, thereby making it appear more tolerable to society. According to Rosa Luxemburg, capitalism is not overthrown, \"but is on the contrary strengthened by the development of social reforms\". In a similar vein, Stan Parker of the Socialist Party of Great Britain argues that reforms are a diversion of energy for socialists and are limited because they must adhere to the logic of capitalism. French social theorist Andr\u00e9 Gorz criticized reformism by advocating a third alternative to reformism and social revolution that he called \"non-reformist reforms\", specifically focused on structural changes to capitalism as opposed to reforms to improve living conditions within capitalism or to prop it up through economic interventions.\nCulture.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nUnder Socialism, solidarity will be the basis of society. Literature and art will be tuned to a different key.\n\u2014Trotsky, \"Literature and Revolution\", 1924\nIn the Leninist conception, the role of the vanguard party was to politically educate the workers and peasants to dispel the societal false consciousness of institutional religion and nationalism that constitute the cultural \"status quo\" taught by the bourgeoisie to the proletariat to facilitate their economic exploitation of peasants and workers. Influenced by Lenin, the Central Committee of the Bolshevik Party stated that the development of the socialist workers' culture should not be \"hamstrung from above\" and opposed the \"Proletkult\" (1917\u20131925) organisational control of the national culture. Similarly, Trotsky viewed the party as transmitters of culture to the masses for raising the standards of education, as well as entry into the cultural sphere, but that the process of artistic creation in terms of language and presentation should be the domain of the practitioner. According to political scientist Baruch Knei-Paz in his book \"The Social and Political Thought of Leon Trotsky\", this represented one of several distinctions between Trotsky's approach on cultural matters and Stalin's policy in the 1930s.\nIn \"Literature and Revolution\", Trotsky examined aesthetic issues in relation to class and the Russian revolution. Soviet scholar Robert Bird considered his work as the \"first systematic treatment of art by a Communist leader\" and a catalyst for later, Marxist cultural and critical theories.\nIn \"Problems of Everyday Life\", a contemporaneous book which further articulated his views on culture and science, Trotsky argued that cultural development was a prerequisite for socialist reconstruction. In particular, he argued that cultural development would accentuate industrial and technical progress. He viewed both elements to be interrelated components as part of dialectical interaction in which he viewed the low level of Russian technique and expertise to be a function of cultural backwardness. According to Trotsky, Western industrial techniques and products such as the radio should not be rejected due to their status as a product of a capitalist system but rather absorbed into the Soviet socialist framework to facilitate new forms of techniques and cultural production. In this interpretation, the transference of techniques brought new cultural changes in terms of rationalism, efficiency, exactitude and quality.\nTrotsky would later co-author the 1938 \"Manifesto for an Independent Revolutionary Art\" with the endorsement of prominent artists Andre Breton and Diego Rivera. Trotsky's writings on literature such as his 1923 survey which advocated tolerance, limited censorship and respect for literary tradition had strong appeal to the New York Intellectuals.\nPrior to Stalin's rule, literary, religious and national representatives had some level of autonomy in Soviet Russia throughout the 1920s but these groups were later rigorously repressed during the Stalinist era. Socialist realism was imposed under Stalin in artistic production and other creative industries such as music, film along with sports were subject to extreme levels of political control.\nThe counter-cultural phenomenon which emerged in the 1960s shaped the intellectual and radical outlook of the New Left; this movement placed a heavy emphasis on anti-racism, anti-imperialism and direct democracy in opposition to the dominant culture of advanced industrial capitalism.\nSocialist groups have also been closely involved with a number of counter-cultural movements such as Vietnam Solidarity Campaign, Stop the War Coalition, Love Music Hate Racism, Anti-Nazi League and Unite Against Fascism.\nEconomics.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThe economic anarchy of capitalist society as it exists today is, in my opinion, the real source of the evil. ... I am convinced there is only one way to eliminate these grave evils, namely through the establishment of a socialist economy, accompanied by an educational system which would be oriented toward social goals. In such an economy, the means of production are owned by society itself and are utilised in a planned fashion. A planned economy, which adjusts production to the needs of the community, would distribute the work to be done among all those able to work and would guarantee a livelihood to every man, woman, and child. The education of the individual, in addition to promoting his own innate abilities, would attempt to develop in him a sense of responsibility for his fellow men in place of the glorification of power and success in our present society.\n \u2014Albert Einstein, \"Why Socialism?\", 1949\nSocialist economics starts from the premise that \"individuals do not live or work in isolation but live in cooperation with one another. Furthermore, everything that people produce is in some sense a social product, and everyone who contributes to the production of a good is entitled to a share in it. Society as whole, therefore, should own or at least control property for the benefit of all its members\".\nThe original conception of socialism was an economic system whereby production was organised in a way to directly produce goods and services for their utility (or use-value in classical and Marxian economics), with the direct allocation of resources in terms of physical units as opposed to financial calculation and the economic laws of capitalism (see law of value), often entailing the end of capitalistic economic categories such as rent, interest, profit and money. In a fully developed socialist economy, production and balancing factor inputs with outputs becomes a technical process to be undertaken by engineers.\nMarket socialism refers to an array of different economic theories and systems that use the market mechanism to organise production and to allocate factor inputs among socially owned enterprises, with the economic surplus (profits) accruing to society in a social dividend as opposed to private capital owners. Variations of market socialism include libertarian proposals such as mutualism, based on classical economics, and neoclassical economic models such as the Lange model. Some economists, such as Joseph Stiglitz, Mancur Olson, and others not specifically advancing anti-socialists positions have shown that prevailing economic models upon which such democratic or market socialism models might be based have logical flaws or unworkable presuppositions. These criticisms have been incorporated into the models of market socialism developed by John Roemer and Nicholas Vrousalis.\nThe ownership of the means of production can be based on direct ownership by the users of the productive property through worker cooperative; or commonly owned by all of society with management and control delegated to those who operate/use the means of production; or public ownership by a state apparatus. Public ownership may refer to the creation of state-owned enterprises, nationalisation, municipalisation or autonomous collective institutions. Some socialists feel that in a socialist economy, at least the \"\" of the economy must be publicly owned. Economic liberals and right libertarians view private ownership of the means of production and the market exchange as natural entities or moral rights which are central to their conceptions of freedom and liberty and view the economic dynamics of capitalism as immutable and absolute, therefore they perceive public ownership of the means of production, cooperatives and economic planning as infringements upon liberty.\nManagement and control over the activities of enterprises are based on self-management and self-governance, with equal power-relations in the workplace to maximise occupational autonomy. A socialist form of organisation would eliminate controlling hierarchies so that only a hierarchy based on technical knowledge in the workplace remains. Every member would have decision-making power in the firm and would be able to participate in establishing its overall policy objectives. The policies/goals would be carried out by the technical specialists that form the coordinating hierarchy of the firm, who would establish plans or directives for the work community to accomplish these goals.\nThe role and use of money in a hypothetical socialist economy is a contested issue. Nineteenth century socialists including Karl Marx, Robert Owen, Pierre-Joseph Proudhon and John Stuart Mill advocated various forms of labour vouchers or labour credits, which like money would be used to acquire articles of consumption, but unlike money they are unable to become capital and would not be used to allocate resources within the production process. Bolshevik revolutionary Leon Trotsky argued that money could not be arbitrarily abolished following a socialist revolution. Money had to exhaust its \"historic mission\", meaning it would have to be used until its function became redundant, eventually being transformed into bookkeeping receipts for statisticians and only in the more distant future would money not be required for even that role.\nPlanned economy.\nA planned economy is a type of economy consisting of a mixture of public ownership of the means of production and the coordination of production and distribution through economic planning. A planned economy can be either decentralised or centralised. Enrico Barone provided a comprehensive theoretical framework for a planned socialist economy. In his model, assuming perfect computation techniques, simultaneous equations relating inputs and outputs to ratios of equivalence would provide appropriate valuations to balance supply and demand.\nThe most prominent example of a planned economy was the economic system of the Soviet Union and as such the centralised-planned economic model is usually associated with the communist states of the 20th century, where it was combined with a single-party political system. In a centrally planned economy, decisions regarding the quantity of goods and services to be produced are planned in advance by a planning agency (see also the analysis of Soviet-type economic planning). The economic systems of the Soviet Union and the Eastern Bloc are further classified as \"command economies\", which are defined as systems where economic coordination is undertaken by commands, directives and production targets. Studies by economists of various political persuasions on the actual functioning of the Soviet economy indicate that it was not actually a planned economy. Instead of conscious planning, the Soviet economy was based on a process whereby the plan was modified by localised agents and the original plans went largely unfulfilled. Planning agencies, ministries and enterprises all adapted and bargained with each other during the formulation of the plan as opposed to following a plan passed down from a higher authority, leading some economists to suggest that planning did not actually take place within the Soviet economy and that a better description would be an \"administered\" or \"managed\" economy.\nAlthough central planning was largely supported by Marxist\u2013Leninists, some factions within the Soviet Union before the rise of Stalinism held positions contrary to central planning. Leon Trotsky rejected central planning in favour of decentralised planning. He argued that central planners, regardless of their intellectual capacity, would be unable to coordinate effectively all economic activity within an economy because they operated without the input and tacit knowledge embodied by the participation of the millions of people in the economy. As a result, central planners would be unable to respond to local economic conditions.\nSelf-managed economy.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nSocialism, you see, is a bird with two wings. The definition is 'social ownership and democratic control of the instruments and means of production.'\n\u2014Upton Sinclair\nA self-managed, decentralised economy is based on autonomous self-regulating economic units and a decentralised mechanism of resource allocation and decision-making. This model has found support in notable classical and neoclassical economists including Alfred Marshall, John Stuart Mill and Jaroslav Vanek. There are numerous variations of self-management, including labour-managed firms and worker-managed firms. The goals of self-management are to eliminate exploitation and reduce alienation. Guild socialism is a political movement advocating workers' control of industry through the medium of trade-related guilds \"in an implied contractual relationship with the public\". It originated in the United Kingdom and was at its most influential in the first quarter of the 20th century. It was strongly associated with G. D. H. Cole and influenced by the ideas of William Morris.\nOne such system is the cooperative economy, a largely free market economy in which workers manage the firms and democratically determine remuneration levels and labour divisions. Productive resources would be legally owned by the cooperative and rented to the workers, who would enjoy usufruct rights. Another form of decentralised planning is the use of cybernetics, or the use of computers to manage the allocation of economic inputs. The socialist-run government of Salvador Allende in Chile experimented with Project Cybersyn, a real-time information bridge between the government, state enterprises and consumers. This had been preceded by similar efforts to introduce a form of cybernetic economic planning as seen with the proposed OGAS system in the Soviet Union. The OGAS project was conceived to oversee a nationwide information network but was never implemented due to conflicting, bureaucratic interests. Another, more recent variant is participatory economics, wherein the economy is planned by decentralised councils of workers and consumers. Workers would be remunerated solely according to effort and sacrifice, so that those engaged in dangerous, uncomfortable and strenuous work would receive the highest incomes and could thereby work less. A contemporary model for a self-managed, non-market socialism is Pat Devine's model of negotiated coordination. Negotiated coordination is based upon social ownership by those affected by the use of the assets involved, with decisions made by those at the most localised level of production.\nMichel Bauwens identifies the emergence of the open software movement and peer-to-peer production as a new alternative mode of production to the capitalist economy and centrally planned economy that is based on collaborative self-management, common ownership of resources and the production of use-values through the free cooperation of producers who have access to distributed capital.\nAnarcho-communism is a theory of anarchism which advocates the abolition of the state, private property and capitalism in favour of common ownership of the means of production. Anarcho-syndicalism was practised in Catalonia and other places in the Spanish Revolution during the Spanish Civil War. Sam Dolgoff estimated that about eight million people participated directly or at least indirectly in the Spanish Revolution.\nThe economy of the former Socialist Federal Republic of Yugoslavia established a system based on market-based allocation, social ownership of the means of production and self-management within firms. This system substituted Yugoslavia's Soviet-type central planning with a decentralised, self-managed system after reforms in 1953.\nThe Marxian economist Richard D. Wolff argues that \"re-organising production so that workers become collectively self-directed at their work-sites\" not only moves society beyond both capitalism and state socialism of the last century, but would also mark another milestone in human history, similar to earlier transitions out of slavery and feudalism. As an example, Wolff claims that Mondragon is \"a stunningly successful alternative to the capitalist organisation of production\".\nState-directed economy.\nState socialism can be used to classify any variety of socialist philosophies that advocates the ownership of the means of production by the state apparatus, either as a transitional stage between capitalism and socialism, or as an end-goal in itself. Typically, it refers to a form of technocratic management, whereby technical specialists administer or manage economic enterprises on behalf of society and the public interest instead of workers' councils or workplace democracy.\nA state-directed economy may refer to a type of mixed economy consisting of public ownership over large industries, as promoted by various Social democratic political parties during the 20th century. This ideology influenced the policies of the British Labour Party during Clement Attlee's administration. In the biography of the 1945 United Kingdom Labour Party Prime Minister Clement Attlee, Francis Beckett states: \"[T]he government ... wanted what would become known as a mixed economy.\"\nNationalisation in the United Kingdom was achieved through compulsory purchase of the industry (i.e. with compensation). British Aerospace was a combination of major aircraft companies British Aircraft Corporation, Hawker Siddeley and others. British Shipbuilders was a combination of the major shipbuilding companies including Cammell Laird, Govan Shipbuilders, Swan Hunter and Yarrow Shipbuilders, whereas the nationalisation of the coal mines in 1947 created a coal board charged with running the coal industry commercially so as to be able to meet the interest payable on the bonds which the former mine owners' shares had been converted into.\nMarket socialism.\nMarket socialism consists of publicly owned or cooperatively owned enterprises operating in a market economy. It is a system that uses the market and monetary prices for the allocation and accounting of the means of production, thereby retaining the process of capital accumulation. The profit generated would be used to directly remunerate employees, collectively sustain the enterprise or finance public institutions. In state-oriented forms of market socialism, in which state enterprises attempt to maximise profit, the profits can be used to fund government programs and services through a social dividend, eliminating or greatly diminishing the need for various forms of taxation that exist in capitalist systems. Neoclassical economist L\u00e9on Walras believed that a socialist economy based on state ownership of land and natural resources would provide a means of public finance to make income taxes unnecessary. Yugoslavia implemented a market socialist economy based on cooperatives and worker self-management. Some of the economic reforms introduced during the Prague Spring by Alexander Dub\u010dek, the leader of Czechoslovakia, included elements of market socialism.\nMutualism is an economic theory and anarchist school of thought that advocates a society where each person might possess a means of production, either individually or collectively, with trade representing equivalent amounts of labour in the free market. Integral to the scheme was the establishment of a mutual-credit bank that would lend to producers at a minimal interest rate, just high enough to cover administration. Mutualism is based on a labour theory of value that holds that when labour or its product is sold, in exchange it ought to receive goods or services embodying \"the amount of labour necessary to produce an article of exactly similar and equal utility\".\nThe current economic system in China is formally referred to as a socialist market economy with Chinese characteristics. It combines a large state sector that comprises the commanding heights of the economy, which are guaranteed their public ownership status by law, with a private sector mainly engaged in commodity production and light industry responsible from anywhere between 33% to over 70% of GDP generated in 2005. The current Chinese economy consists of 150 corporatised state-owned enterprises that report directly to China's central government. By 2008, these state-owned corporations had become increasingly dynamic and generated large increases in revenue for the state, resulting in a state-sector led recovery during the 2009 financial crises while accounting for most of China's economic growth. The Chinese economic model is widely cited as a contemporary form of state capitalism, the major difference between Western capitalism and the Chinese model being the degree of state-ownership of shares in publicly listed corporations. The Socialist Republic of Vietnam has adopted a similar model after the Doi Moi economic renovation but slightly differs from the Chinese model in that the Vietnamese government retains firm control over the state sector and strategic industries, but allows for private-sector activity in commodity production.\nPolitics.\nWhile major socialist political movements include anarchism, communism, the labour movement, Marxism, social democracy, and syndicalism, independent socialist theorists, utopian socialist authors, and academic supporters of socialism may not be represented in these movements. Some political groups have called themselves \"socialist\" while holding views that some consider antithetical to socialism. \"Socialist\" has been used by members of the political right as an epithet, including against individuals who do not consider themselves to be socialists and against policies that are not considered socialist by their proponents. While there are many variations of socialism, and there is no single definition encapsulating all of socialism, there have been common elements identified by scholars.\nIn his \"Dictionary of Socialism\" (1924), Angelo S. Rappoport analysed forty definitions of socialism to conclude that common elements of socialism include general criticism of the social effects of private ownership and control of capital\u2014as being the cause of poverty, low wages, unemployment, economic and social inequality and a lack of economic security; a general view that the solution to these problems is a form of collective control over the means of production, distribution and exchange (the degree and means of control vary among socialist movements); an agreement that the outcome of this collective control should be a society based upon social justice, including social equality, economic protection of people and should provide a more satisfying life for most people.\nIn \"The Concepts of Socialism\" (1975), Bhikhu Parekh identifies four core principles of socialism and particularly socialist society, namely sociality, social responsibility, cooperation and planning. In his study \"Ideologies and Political Theory\" (1996), Michael Freeden states that all socialists share five themes: the first is that socialism posits that society is more than a mere collection of individuals; second, that it considers human welfare a desirable objective; third, that it considers humans by nature to be active and productive; fourth, it holds the belief of human equality; and fifth, that history is progressive and will create positive change on the condition that humans work to achieve such change.\nAnarchism.\nAnarchism advocates stateless societies often defined as self-governed voluntary institutions, but that several authors have defined as more specific institutions based on non-hierarchical free associations. While anarchism holds the state to be undesirable, unnecessary or harmful, it is not the central aspect. Anarchism entails opposing authority or hierarchical organisation in the conduct of human relations, including the state system. Mutualists support market socialism, collectivist anarchists favour workers cooperatives and salaries based on the amount of time contributed to production, anarcho-communists advocate a direct transition from capitalism to libertarian communism and a gift economy and anarcho-syndicalists prefer workers' direct action and the general strike.\nThe authoritarian\u2013libertarian struggles and disputes within the socialist movement go back to the First International and the expulsion in 1872 of the anarchists, who went on to lead the Anti-authoritarian International and then founded their own libertarian international, the Anarchist St. Imier International. In 1888, the individualist anarchist Benjamin Tucker, who proclaimed himself to be an anarchistic socialist and libertarian socialist in opposition to the authoritarian state socialism and the compulsory communism, included the full text of a \"Socialistic Letter\" by Ernest Lesigne in his essay on \"State Socialism and Anarchism\". According to Lesigne, there are two types of socialism: \"One is dictatorial, the other libertarian\". Tucker's two socialisms were the authoritarian state socialism which he associated to the Marxist school and the libertarian anarchist socialism, or simply anarchism, that he advocated. Tucker noted that the fact that the authoritarian \"State Socialism has overshadowed other forms of Socialism gives it no right to a monopoly of the Socialistic idea\". According to Tucker, what those two schools of socialism had in common was the labor theory of value and the ends, by which anarchism pursued different means.\nAccording to anarchists such as the authors of \"An Anarchist FAQ\", anarchism is one of the many traditions of socialism. For anarchists and other anti-authoritarian socialists, socialism \"can only mean a classless and anti-authoritarian (i.e. libertarian) society in which people manage their own affairs, either as individuals or as part of a group (depending on the situation). In other words, it implies self-management in all aspects of life\", including at the workplace. Michael Newman includes anarchism as one of many socialist traditions. Peter Marshall argues that \"[i]n general anarchism is closer to socialism than liberalism. ... Anarchism finds itself largely in the socialist camp, but it also has outriders in liberalism. It cannot be reduced to socialism, and is best seen as a separate and distinctive doctrine.\"\nDemocratic socialism and social democracy.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n You can't talk about ending the slums without first saying profit must be taken out of slums. You're really tampering and getting on dangerous ground because you are messing with folk then. You are messing with captains of industry. Now this means that we are treading in difficult water, because it really means that we are saying that something is wrong with capitalism. There must be a better distribution of wealth, and maybe America must move toward a democratic socialism.\n \u2014Martin Luther King Jr., 1966\nDemocratic socialism represents any socialist movement that seeks to establish an economy based on economic democracy by and for the working class. Democratic socialism is difficult to define and groups of scholars have radically different definitions for the term. Some definitions simply refer to all forms of socialism that follow an electoral, reformist or evolutionary path to socialism rather than a revolutionary one. According to Christopher Pierson, \"[i]f the contrast which 1989 highlights is not that between socialism in the East and liberal democracy in the West, the latter must be recognised to have been shaped, reformed and compromised by a century of social democratic pressure\". Pierson further claims that \"social democratic and socialist parties within the constitutional arena in the West have almost always been involved in a politics of compromise with existing capitalist institutions (to whatever far distant prize its eyes might from time to time have been lifted)\". For Pierson, \"if advocates of the death of socialism accept that social democrats belong within the socialist camp, as I think they must, then the contrast between socialism (in all its variants) and liberal democracy must collapse. For \"actually existing\" liberal democracy is, in substantial part, a product of socialist (social democratic) forces\".\nSocial democracy is a socialist tradition of political thought. Many social democrats refer to themselves as socialists or democratic socialists and some such as Tony Blair employ these terms interchangeably. Others found \"clear differences\" between the three terms and prefer to describe their own political beliefs by using the term \"social democracy\". The two main directions were to establish democratic socialism or to build first a welfare state within the capitalist system. The first variant advances democratic socialism through reformist and gradualist methods. In the second variant, social democracy is a policy regime involving a welfare state, collective bargaining schemes, support for publicly financed public services and a mixed economy. It is often used in this manner to refer to Western and Northern Europe during the later half of the 20th century. It was described by Jerry Mander as \"hybrid economics\", an active collaboration of capitalist and socialist visions. Some studies and surveys indicate that people tend to live happier and healthier lives in social democratic societies rather than neoliberal ones.\nSocial democrats advocate a peaceful, evolutionary transition of the economy to socialism through progressive social reform. It asserts that the only acceptable constitutional form of government is representative democracy under the rule of law. It promotes extending democratic decision-making beyond political democracy to include economic democracy to guarantee employees and other economic stakeholders sufficient rights of co-determination. It supports a mixed economy that opposes inequality, poverty and oppression while rejecting both a totally unregulated market economy or a fully planned economy. Common social democratic policies include universal social rights and universally accessible public services such as education, health care, workers' compensation and other services, including child care and elder care. Socialist child care and elderly care systems allow citizens to take a more active role in building a socialist society, especially women. Social democracy supports the trade union labour movement and supports collective bargaining rights for workers. Most social democratic parties are affiliated with the Socialist International.\nModern democratic socialism is a broad political movement that seeks to promote the ideals of socialism within the context of a democratic system. Some democratic socialists support social democracy as a temporary measure to reform the current system while others reject reformism in favour of more revolutionary methods. Modern social democracy emphasises a program of gradual legislative modification of capitalism to make it more equitable and humane while the theoretical end goal of building a socialist society is relegated to the indefinite future. According to Sheri Berman, Marxism is loosely held to be valuable for its emphasis on changing the world for a more just, better future.\nThe two movements are widely similar both in terminology and in ideology, although there are a few key differences. The major difference between social democracy and democratic socialism is the object of their politics in that contemporary social democrats support a welfare state and unemployment insurance as well as other practical, progressive reforms of capitalism and are more concerned to administrate and humanise it. On the other hand, democratic socialists seek to replace capitalism with a socialist economic system, arguing that any attempt to humanise capitalism through regulations and welfare policies would distort the market and create economic contradictions.\nEthical and liberal socialism.\nEthical socialism appeals to socialism on ethical and moral grounds as opposed to economic, egoistic, and consumeristic grounds. It emphasizes the need for a morally conscious economy based upon the principles of altruism, cooperation, and social justice while opposing possessive individualism. Ethical socialism has been the official philosophy of mainstream socialist parties.\nLiberal socialism incorporates liberal principles to socialism. It has been compared to post-war social democracy for its support of a mixed economy that includes both public and private capital goods. While democratic socialism and social democracy are anti-capitalist positions insofar as criticism of capitalism is linked to the private ownership of the means of production, liberal socialism identifies artificial and legalistic monopolies to be the fault of capitalism and opposes an entirely unregulated market economy. It considers both liberty and social equality to be compatible and mutually dependent.\nPrinciples that can be described as ethical or liberal socialist have been based upon or developed by philosophers such as John Stuart Mill, Eduard Bernstein, John Dewey, Carlo Rosselli, Norberto Bobbio, and Chantal Mouffe. Other important liberal socialist figures include Guido Calogero, Piero Gobetti, Leonard Trelawny Hobhouse, John Maynard Keynes and R. H. Tawney. Liberal socialism has been particularly prominent in British and Italian politics.\nAuthoritarian socialism.\nLeninism.\nBlanquism is a conception of revolution named for Louis Auguste Blanqui. It holds that socialist revolution should be carried out by a relatively small group of highly organised and secretive conspirators. Upon seizing power, the revolutionaries introduce socialism. Rosa Luxemburg and Eduard Bernstein criticised Lenin, stating that his conception of revolution was elitist and Blanquist. Marxism\u2013Leninism combines Marx's scientific socialist concepts and Lenin's anti-imperialism, democratic centralism, vanguardism and the principle of \"He who does not work, neither shall he eat\".\nHal Draper defined socialism from above as the philosophy which employs an elite administration to run the socialist state. The other side of socialism is a more democratic socialism from below. The idea of socialism from above is much more frequently discussed in elite circles than socialism from below\u2014even if that is the Marxist ideal\u2014because it is more practical. Draper viewed socialism from below as being the purer, more Marxist version of socialism. According to Draper, Karl Marx and Friedrich Engels were devoutly opposed to any socialist institution that was \"conducive to superstitious authoritarianism\". Draper makes the argument that this division echoes the division between \"reformist or revolutionary, peaceful or violent, democratic or authoritarian, etc.\" and further identifies six major varieties of socialism from above, among them \"Philanthropism\", \"Elitism\", \"Pannism\", \"Communism\", \"Permeationism\" and \"Socialism-from-Outside\".\nAccording to Arthur Lipow, Marx and Engels were \"the founders of modern revolutionary democratic socialism\", described as a form of \"socialism from below\" that is \"based on a mass working-class movement, fighting from below for the extension of democracy and human freedom\". This type of socialism is contrasted to that of the \"authoritarian, anti-democratic creed\" and \"the various totalitarian collectivist ideologies which claim the title of socialism\" as well as \"the many varieties of 'socialism from above' which have led in the twentieth century to movements and state forms in which a despotic 'new class' rules over a stratified economy in the name of socialism\", a division that \"runs through the history of the socialist movement\". Lipow identifies Bellamyism and Stalinism as two prominent authoritarian socialist currents within the history of the socialist movement.\nTrotsky viewed himself to be an adherent of Leninism but opposed the bureaucratic and authoritarian methods of Stalin. A number of scholars and Western socialists have regarded Leon Trotsky as a democratic alternative rather than a forerunner to Stalin with particular emphasis drawn to his activities in the pre-Civil War period and as leader of the Left Opposition. More specifically, Trotsky advocated for a decentralised form of economic planning, mass soviet democratization, worker's control of production, elected representation of Soviet socialist parties, the tactic of a united front against far-right parties, cultural autonomy for artistic movements, voluntary collectivisation, a transitional program, and socialist internationalism.\nSeveral scholars state that in practice, the Soviet model functioned as a form of state capitalism.\nLibertarian socialism.\nLibertarian socialism, sometimes called left-libertarianism, social anarchism and socialist libertarianism, is an anti-authoritarian, anti-statist and libertarian tradition within socialism that rejects centralised state ownership and control including criticism of wage labour relationships (wage slavery) as well as the state itself. It emphasises workers' self-management and decentralised structures of political organisation. Libertarian socialism asserts that a society based on freedom and equality can be achieved through abolishing authoritarian institutions that control production. Libertarian socialists generally prefer direct democracy and federal or confederal associations such as libertarian municipalism, citizens' assemblies, trade unions and workers' councils.\nAnarcho-syndicalist Gaston Leval explained:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We therefore foresee a Society in which all activities will be coordinated, a structure that has, at the same time, sufficient flexibility to permit the greatest possible autonomy for social life, or for the life of each enterprise, and enough cohesiveness to prevent all disorder. ... In a well-organised society, all of these things must be systematically accomplished by means of parallel federations, vertically united at the highest levels, constituting one vast organism in which all economic functions will be performed in solidarity with all others and that will permanently preserve the necessary cohesion\".\nAll of this is typically done within a general call for libertarian and voluntary free associations through the identification, criticism and practical dismantling of illegitimate authority in all aspects of human life.\nAs part of the larger socialist movement, it seeks to distinguish itself from Bolshevism, Leninism and Marxism\u2013Leninism as well as social democracy. Past and present political philosophies and movements commonly described as libertarian socialist include anarchism (anarcho-communism, anarcho-syndicalism, collectivist anarchism, individualist anarchism and mutualism), autonomism, Communalism, participism, libertarian Marxism (council communism and Luxemburgism), revolutionary syndicalism and utopian socialism (Fourierism).\nReligious socialism.\nChristian socialism is a broad concept involving an intertwining of Christian religion with socialism.\nIslamic socialism is a more spiritual form of socialism. Muslim socialists believe that the teachings of the Quran and Muhammad are not only compatible with, but actively promoting the principles of equality and public ownership, drawing inspiration from the early Medina welfare state he established. Muslim socialists are more conservative than their Western contemporaries and find their roots in anti-imperialism, anti-colonialism and sometimes, if in an Arab speaking country, Arab nationalism. Islamic socialists believe in deriving legitimacy from political mandate as opposed to religious texts.\nSocial movements.\nSocialist feminism is a branch of feminism that argues that liberation can only be achieved by working to end both economic and cultural sources of women's oppression. Marxist feminism's foundation was laid by Engels in \"The Origin of the Family, Private Property, and the State\" (1884). August Bebel's \"Woman under Socialism\" (1879), is the \"single work dealing with sexuality most widely read by rank-and-file members of the Social Democratic Party of Germany (SPD)\". In the late 19th and early 20th centuries, both Clara Zetkin and Eleanor Marx were against the demonisation of men and supported a proletariat revolution that would overcome as many male-female inequalities as possible. As their movement already had the most radical demands in women's equality, most Marxist leaders, including Clara Zetkin and Alexandra Kollontai, counterposed Marxism against liberal feminism rather than trying to combine them. Anarcha-feminism began with late 19th- and early 20th-century authors and theorists such as anarchist feminists Goldman and Voltairine de Cleyre. In the Spanish Civil War, an anarcha-feminist group, (\"Free Women\") linked to the , organised to defend both anarchist and feminist ideas. In 1972, the Chicago Women's Liberation Union published \"Socialist Feminism: A Strategy for the Women's Movement\", which is believed to be the first published use of the term \"socialist feminism\".\nMany socialists were early advocates of LGBT rights. For early socialist Charles Fourier, true freedom could only occur without suppressing passions, as the suppression of passions is not only destructive to the individual, but to society as a whole. Writing before the advent of the term \"homosexuality\", Fourier recognised that both men and women have a wide range of sexual needs and preferences which may change throughout their lives, including same-sex sexuality and \"androg\u00e9nit\u00e9\". He argued that all sexual expressions should be enjoyed as long as people are not abused and that \"affirming one's difference\" can actually enhance social integration. In Oscar Wilde's \"The Soul of Man Under Socialism\", he advocates an egalitarian society where wealth is shared by all, while warning of the dangers of social systems that crush individuality. Edward Carpenter actively campaigned for homosexual rights. His work \"The Intermediate Sex: A Study of Some Transitional Types of Men and Women\" was a 1908 book arguing for gay liberation. who was an influential personality in the foundation of the Fabian Society and the Labour Party. After the Russian Revolution under the leadership of Lenin and Trotsky, the Soviet Union abolished previous laws against homosexuality. Harry Hay was an early leader in the American LGBT rights movement as well as a member of the Communist Party USA. He is known for his involvement in the founding of gay organisations, including the Mattachine Society, the first sustained gay rights group in the United States which in its early days reflected a strong Marxist influence. The \"Encyclopedia of Homosexuality\" reports that \"[a]s Marxists the founders of the group believed that the injustice and oppression which they suffered stemmed from relationships deeply embedded in the structure of American society\". Emerging from events such as the May 1968 insurrection in France, the anti-Vietnam war movement in the US and the Stonewall riots of 1969, militant gay liberation organisations began to spring up around the world. Many sprang from left radicalism more than established homophile groups, although the Gay Liberation Front took an anti-capitalist stance and attacked the nuclear family and traditional gender roles.\nEco-socialism is a political strain merging aspects of socialism, Marxism or libertarian socialism with green politics, ecology and alter-globalisation. Eco-socialists generally claim that the expansion of the capitalist system is the cause of social exclusion, poverty, war and environmental degradation through globalisation and imperialism under the supervision of repressive states and transnational structures. Contrary to the depiction of Karl Marx by some environmentalists, social ecologists and fellow socialists as a productivist who favoured the domination of nature, eco-socialists revisited Marx's writings and believe that he \"was a main originator of the ecological world-view\". Marx discussed a \"metabolic rift\" between man and nature, stating that \"private ownership of the globe by single individuals will appear quite absurd as private ownership of one man by another\" and his observation that a society must \"hand it [the planet] down to succeeding generations in an improved condition\". English socialist William Morris is credited with developing principles of what was later called eco-socialism. During the 1880s and 1890s, Morris promoted his ideas within the Social Democratic Federation and Socialist League. Green anarchism blends anarchism with environmental issues. An important early influence was Henry David Thoreau and his book \"Walden\" as well as \u00c9lis\u00e9e Reclus.\nIn the late 19th century, anarcho-naturism fused anarchism and naturist philosophies within individualist anarchist circles in France, Spain, Cuba and Portugal. Murray Bookchin's first book \"Our Synthetic Environment\" was followed by his essay \"Ecology and Revolutionary Thought\" which introduced ecology as a concept in radical politics. In the 1970s, Barry Commoner, claimed that capitalist technologies were chiefly responsible for environmental degradation as opposed to population pressures. In the 1990s socialist/feminists Mary Mellor and Ariel Salleh adopt an eco-socialist paradigm. An \"environmentalism of the poor\" combining ecological awareness and social justice has also become prominent. Pepper critiqued the current approach of many within green politics, particularly deep ecologists.\nSyndicalism.\nSyndicalism operates through industrial trade unions. It rejects state socialism and the use of establishment politics. Syndicalists reject state power in favour of strategies such as the general strike. Syndicalists advocate a socialist economy based on federated unions or syndicates of workers who own and manage the means of production. Some Marxist currents advocate syndicalism, such as De Leonism. Anarcho-syndicalism views syndicalism as a method for workers in capitalist society to gain control of an economy. The Spanish Revolution was largely orchestrated by the anarcho-syndicalist trade union CNT. The International Workers' Association is an international federation of anarcho-syndicalist labour unions and initiatives.\nPublic views.\nA multitude of polls have found significant levels of support for socialism among modern populations.\nA 2018 IPSOS poll found that 50% of the respondents globally strongly or somewhat agreed that present socialist values were of great value for societal progress. In China this was 84%, India 72%, Malaysia 62%, Turkey 62%, South Africa 57%, Brazil 57%, Russia 55%, Spain 54%, Argentina 52%, Mexico 51%, Saudi Arabia 51%, Sweden 49%, Canada 49%, Great Britain 49%, Australia 49%, Poland 48%, Chile 48%, South Korea 48%, Peru 48%, Italy 47%, Serbia 47%, Germany 45%, Belgium 44%, Romania 40%, United States 39%, France 31%, Hungary 28% and Japan 21%.\nA 2021 survey conducted by the Institute of Economic Affairs (IEA) found that 67% of young British (16\u201324) respondents wanted to live in a socialist economic system, 72% supported the re-nationalisation of various industries such as energy, water along with railways and 75% agreed with the view that climate change was a specifically capitalist problem.\nA 2023 IPSOS poll found that a majority of British public favoured public ownership of utilities including water, rail and electricity. Specifically, 68% of respondents favoured the nationalisation of water services, 65% supporting the nationalisation of the railways, 63% supporting the public ownership of power networks and 39% favouring broadband access which is operated by the government. The poll also found broad levels of support among traditional Labour and Conservative voters.\nThe results of a 2019 Axios poll found that 70% of US millennials were willing to vote for a socialist candidate and 50% of this same demographic had a somewhat or very unfavourable view of capitalism. Subsequently, another 2021 Axios poll found that 51% of 18\u201334 US adults had a positive view of socialism. Yet, 41% of Americans more generally had a positive view of socialism compared to 52% of those who viewing socialism more negatively.\nIn 2023, the Fraser Institute published findings which found that 42% of Canadians viewed socialism as the ideal system compared to 43% of British respondents, 40% Australian respondents and 31% American respondents. Overall support for socialism ranged from 50% of Canadians 18\u201324 year olds to 28% of Canadians over 55.\nIn 2025, a joint Rasmussen and Heartland Institute poll had found that 53% of young voters (18\u201339 age range) supported the prospect of a socialist candidate running in the upcoming 2028 presidential election and 76% of this same demographic favoured the nationalisation of key industries such as energy, healthcare and big tech sectors.\nCriticism.\nAccording to analytical Marxist sociologist Erik Olin Wright, \"The Right condemned socialism as violating individual rights to private property and unleashing monstrous forms of state oppression\", while \"the Left saw it as opening up new vistas of social equality, genuine freedom and the development of human potentials.\"\nBecause of socialism's many varieties, most critiques have focused on a specific approach. Proponents of one approach typically criticise others. Socialism has been criticised in terms of its models of economic organization as well as its political and social implications. Other critiques are directed at the socialist movement, parties, or existing states.\nSome forms of criticism occupy theoretical grounds, such as in the economic calculation problem presented by proponents of the Austrian School as part of the socialist calculation debate, while others support their criticism by examining historical attempts to establish socialist societies. The economic calculation problem concerns the feasibility and methods of resource allocation for a planned socialist system. Central planning is also criticized by elements of the radical left. Libertarian socialist economist Robin Hahnel notes that even if central planning overcame its inherent inhibitions of incentives and innovation, it would nevertheless be unable to maximize economic democracy and self-management, which he believes are concepts that are more intellectually coherent, consistent and just than mainstream notions of economic freedom.\nEconomic liberals and right-libertarians argue that private ownership of the means of production and market exchange are natural entities or moral rights which are central to freedom and liberty and argue that the economic dynamics of capitalism are immutable and absolute. As such, they also argue that public ownership of the means of production and economic planning are infringements upon liberty.\nCritics of socialism have argued that in any society where everyone holds equal wealth, there can be no material incentive to work because one does not receive rewards for a work well done. They further argue that incentives increase productivity for all people and that the loss of those effects would lead to stagnation. Some critics of socialism argue that income sharing reduces individual incentives to work and therefore incomes should be individualized as much as possible.\nPeter Self criticized the aims of socialism, arguing that equality erodes away at individual diversities and that the establishment of an equal society would have to entail strong coercion.\nMilton Friedman argued that the absence of private economic activity would enable political leaders to grant themselves coercive powers, powers that, under a capitalist system, would instead be granted by a capitalist class, which Friedman found preferable.\nMany commentators on the political right point to the mass killings under communist regimes, claiming them as an indictment of socialism. Opponents of this view, including supporters of socialism, state that these killings were aberrations caused by specific authoritarian regimes rather than socialism itself. They draw comparisons to killings, famines and excess deaths under capitalism, colonialism and anti-communist authoritarian governments.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "26849", "revid": "1398", "url": "https://en.wikipedia.org/wiki?curid=26849", "title": "Sabine River (Texas\u2013Louisiana)", "text": "River in the United States\nThe Sabine River () is a long river in the Southern U.S. states of Texas and Louisiana, From the 32nd parallel north and downstream, it serves as part of the boundary between the two states and empties into Sabine Lake, an estuary of the Gulf of Mexico.\nOver the first half of the 19th century, the river formed part of the Spanish\u2013American, Mexican\u2013American, and Texan\u2013American international boundaries. The upper reaches of the river flow through the prairie country of northeast Texas. Along much of its lower reaches, it flows through pine forests along the Texas\u2013Louisiana border, and eventually the bayou country near the Gulf Coast.\nThe river drains an area of , of which are in Texas and in Louisiana. It flows through an area of abundant rainfall and discharges the largest volume of any river in Texas. The name Sabine (es: \"R\u00edo de Sabinas\") comes from the Spanish word for cypress, in reference to the extensive growth of bald cypresses along the lower river. The river flows through an important petroleum-producing region, and the lower river near the Gulf is among the most industrialized areas of the southeastern United States. The river was often described as the dividing line between the Old South and the New Southwest.\nDescription.\nThe Sabine rises in northeast Texas by the union of three branches: the Cowleech Fork, Caddo Fork, and South Fork. The Cowleech Fork rises in northwestern Hunt County and flows southeast for . The Caddo Fork, shown as \"Caddo Creek\" on federal maps, rises in two tributary forks, the East Caddo Fork and the West Caddo Fork, in northwestern Hunt County. The South Fork rises in the southwestern corner of Hunt County and flows east for , joining the Caddo Fork and Cowleech Fork in southeastern Hunt County. The confluence of the forks is now submerged in the Lake Tawakoni reservoir. The combined river flows southeast across northeast Texas and is joined by a fourth branch, Lake Fork Creek, downstream from the reservoir.\nIn northeast Texas, the river flows past Kilgore, Mineola, Gladewater, Big Sandy, and Longview, the largest city on the river, to southwest of Shreveport at the 32nd parallel north, where it establishes the Texas-Louisiana boundary. It flows south, forming the state line for the remainder of its course. It is impounded west of Leesville, Louisiana, to form the Toledo Bend Reservoir, with the Sabine National Forest along its western bank. South of the reservoir, it passes through the bayou country, surrounded by wetlands, as well as widespread industrial areas near the Gulf Coast. Approximately south of Orange, it meets the Neches River from the west to form the and Sabine Lake, which drains through Sabine Pass to the Gulf of Mexico. The city of Port Arthur, Texas, sits along the western shore of Sabine Lake\nHistory.\nArcheological evidence indicates the valley of the river has been inhabited for as long as 12,000 years by indigenous peoples. Starting in the eighth century, the Caddo inhabited the area, building extensive earthwork mounds in complexes expressing their cosmology. The Caddo culture flourished until the late 13th century. Descendants of the Caddo were living along the river when the first European explorers arrived in the 16th century.\nThe river was named in 1716 by Spanish explorer Domingo Ram\u00f3n, and appeared as \"R\u00edo de Sabinas\" on a 1721 map. The river was used by French traders, and at various times, the river was claimed by both Spain and France. After the acquisition by Spain of the French territory of Louisiana in 1763, following France's defeat by Great Britain in the Seven Years' War, the capital of the Spanish province of Texas was established at Los Adaes on the east side of the river, near present-day Robeline, Louisiana.\nAfter acquiring the French territory west of the Mississippi River in 1803 Louisiana Purchase, the United States started to exert control in this area. It was at war with Native Americans in Louisiana along the Sabine River from 1836 to 1837, in the period when it was trying to remove the Indians to Indian Territory from the Southeast.\nRiver transportation.\nThe Sabine River was too deep to ford, and proved to be navigable. Early travelers and settlers would have to swim the river on horseback and cattle would have to be driven into the river to swim across. Ferries were later put into service. By the 1840s, steamboats were travelling from Logansport to Sabine Lake.\nFerries.\nRecorded ferry use began 1794, when Louis Chabinan (Sharben), his wife Margarite LaFleur, and their four children settled on the east bank of the Sabine River on land purchased from Vicinte Michele. Chabinan built a ferry landing on the river called \"Paso del Chaland.\" Louisiana State Highway 6 (La 6) and Texas State Highway 21 now meet near here, at the site of the present-day Pendleton Bridge. In 1796, Chabinan was drowned after being kicked by a horse and falling into the Sabine.\nMichel Crow married his widow and ran the ferry, until he sold it to James Gaines \"circa\" 1819; it was renamed Gaines Ferry. This ferry was in service until 1937, when it was replaced by the Pendleton Bridge, built during the Great Depression. Crow also operated a ferry he had started upriver, a 120-foot crossing started in 1796. It linked what became known as Carter's Ferry Road, now Texas FM 276. Carter's ferry was 25 miles from San Augustine and 15 miles from Many, Louisiana. Crow sold the ferry to Carter, who became the namesake. Farther north, and just above Bayou Lanan, was Williamson Ferry. \nOther ferries on the Sabine River:\nThe main Sabine River crossings were the El Camino Real (King's Highway) from Natchitoches, or \"Upper Route\" from Shreveport; and the \"Lower\" Route, from Opelousas called \"The Old Beef Trail\". It was used to drive thousands of cattle from Texas to Alexandria, Louisiana, for shipment to cities such as New Orleans. Hickman Ferry was a shipping point for areas as far west as Burkeville. Sabine River ports from Sabine Pass in river mileage were \"Belgrade\", 171 miles; \"Stark's Landing\" 191 miles; \"Loftin Ferry\", and \"Bayou Lanacoco\" 220 miles; \"Hickman's Ferry\" 252 miles; \"Burnham's Landing\" 261 miles; and \"Burr's Ferry\" 281 miles.\nBorder dispute.\nThe area's geography remained one of the least understood in the region. Various Spanish maps had errors in the naming of the Sabine and Neches and sometimes showed them flowing independently into the Gulf of Mexico. After the Louisiana Purchase by the United States in 1803, a dispute over the boundary between the U.S. and Spain led to a demilitarized zone agreement on November 6, 1806, negotiated by Gen. James Wilkinson and Lt. Col. Sim\u00f3n de Herrera, to establish a neutral territory on both sides of the river. Neither country would put military troops or civil police there.\nThe indefinite boundary was resolved by the Adams\u2013Onis Treaty of 1819, which established the Sabine River as the boundary from the Gulf to the 32nd parallel. The Spanish delay in the ratification of the treaty, and Mexico gaining independence in 1821, reignited the boundary dispute. The United States, at the insistence of Anthony Butler, claimed for a while that the names of the Sabine and Neches had been reversed, thus they claimed that the treaty established the boundary at the Neches. The first Anglo-American settlers began arriving in the region in the 1820s, soon outnumbering the Mexicans by ten to one. After the independence of the Republic of Texas from Mexico in 1836, the boundary between the U.S. and Texas was firmly established at the Sabine in accordance with the Adams-Onis Treaty. The river served as the western boundary of the United States until the Texas Annexation in 1845. In July 1848, the 30th United States Congress passed a public law endorsing the government of the United States to the Texas legislature to extend the Texas eastern boundary. The Act of Congress provisioned the State of Texas to geographical limits for incorporating one half of the Sabine Pass, Sabine Lake, and Sabine River, as far north as \u2015 International Boundary Marker \u2015 the thirty-second degree of north latitude.\nRiverboats.\nIn 1843, Capt. John Clemmons made the first trip up the Sabine in the steamboat \"Sabine.\" Steamboats carried passengers, as well as commodities such as cotton, from as far north as Logansport, Louisiana, down to Sabine Pass.\nThe pirate Jean Lafitte made many trips up the Sabine and reportedly started the colony of Shacklefoot on the Texas side of the Sabine River, south of Carter's ferry up Bayou Patroon.\nDuring the American Civil War, on September 8, 1863, a small Confederate force thwarted a Union invasion of Texas at the Second Battle of Sabine Pass, fought at the mouth of the river.\nIn the late 19th and early 20th centuries, the middle course of the river was an area of widespread logging. The discovery of petroleum at nearby Spindletop led to the river basin becoming the scene of widespread oil drilling. The lower river became heavily industrialized, and developed with many oil refineries and chemical plants. Such alteration to the wetlands resulted in a degradation of the water quality. Since the late 20th century, there have been federal, state, and local efforts to restore the quality of the river. In addition, draining of wetlands and dredging of bayous has caused decline in the acreage of wetlands, resulting in coastal erosion, and making the area much more vulnerable to hurricane damage.\nThe lower river, south of Orange to Sabine Lake, forms part of the Intracoastal Waterway, carrying barge traffic and some pleasure boats.\nAs a young man, Captain Bill McDonald of the Texas Rangers operated a small store at Brown's Bluff (modern-day Elderville) on the Sabine in Gregg County, Texas.\nToledo Bend reservoir.\nHadden's Ferry was the site of the ground-breaking ceremony held on October 5, 1961, for the 181,600-acre Toledo Bend Reservoir. Dedicated October 11, 1969, the reservoir is the largest human-made lake in the South. Flooding of lands along the Sabine River behind the dam inundated all the ferry sites within its boundary.\nSabine River Diversion Canal.\nThe 1970 Louisiana Legislature passed Acts 90 and 117, creating the Sabine River Diversion Canal, for the purpose of supplying fresh river water to businesses in Lake Charles, Sulphur, Westlake, and what was Mossville (now the Sasol complex), as well as to farmers along the canal, with a total capacity of a day. The canal was completed by the Louisiana Department of Public Works in 1981. The canal is long, with about of underground pipe, and begins on the Old Sabine River north of Niblett's Bluff. Pump station #1 is located two miles east of the river. The canal continues running east, piped under roadways such as Louisiana Highway 109 north of Vinton, the Edgerly Big Woods road, and Highway 388, which runs to Dequincy.\nJust east of Louisiana Highway 27, the canal forks to the south, running around southern Sulphur. The canal is piped under Louisiana Highway 108, at pumping station #4, providing river water to the business area known as City Service in Westlake, and companies such as Equistar, which has a daily contract for 734,400 gallons a day. Other customers and their gallons of use per day are the city of Westlake (8,640,000 gallons), Air Liquide (129,600), Air Products (1,728,000), CITGO (20,160,000), Phillips 66 (3,600,000), The Axiall subsidiary Eagle US 2 LLC (20,160,000), Entergy (21,600,000), Lake Charles Co-Gen (14,400,000), Louisiana Pigment (3,038,400) that produces Titanium White, another LyondellBasell company (720,000), and Matheson Tri-Gas (175,680).\nThe main canal continues east, crossing under Highway 27 and joined by the Houston River canal at pumping station #2, continuing to old Mossville. There it tees to the left, providing water to the Krause and Managan canal supplying the Nelson Industrial Steam Company (Nisco), which supplies steam and electricity to area businesses. The right tee of the canal terminates at pumping station #3 on what was 8th street in Mossville, now the Sasol complex, providing 46,080,000 gallons of river water for a total daily contract use of 141,166,000 gallons of river water a day.\nJanuary 2010 oil spill.\nUp to 450,000 gallons (about 11,000 bls) of crude oil spilled over the Sabine River when the tanker \"Eagle Otome\", which was carrying the shipment, struck two chemical-carrying barges due to loss of engine power on January 24, 2010, at 10\u00a0am local time.\n2016 flooding.\nSevere flooding during the first week of March 2016 was the result of record rainfalls in northern Louisiana and the Sabine River basin, of 18 to more than 24 inches. Toledo Bend Reservoir is considered at \"full pool\" at 172\u00a0ft; before the rains started, it was at 171.5\u00a0ft. On March 10, the level reached a record 174.36\u00a0ft, and 9 of the 11 gates were opened to 22\u00a0ft (two gates were out of commission for repairs). Lake Tawakoni, east of Dallas on the Sabine River, was 2 feet above full pool and Lake Fork Reservoir was 1 1/2 feet above full pool.\nWhen the reservoir level dropped to 173.69\u00a0ft, 9 gates were in operation at 20\u00a0ft. The previous record level of 173.93\u00a0ft was on May 18, 1989. At that time, the spillway gates were opened to 9\u00a0ft. The maximum height is 28\u00a0ft and with nine 9 gates open, the discharge rate is over 190,000\u00a0ft3 per second, which is equivalent to the flow over Niagara Falls.\nThe peak water flow from the dam was nearly 208,000\u00a0ft3 per second for 31 hours, equating to 1.5 million gallons per second. Catastrophic flooding was predicted to be from 2 to 5\u00a0ft above record floods of 1884 and 1889.\nAftermath.\nDuring peak flooding, Deweyville, Texas was surrounded by water, accessible only by air or boat. The flood stage is 24\u00a0ft, but reached 33.24\u00a0ft on March 10, 2016, which was 9.24\u00a0ft above flood stage.\nA group of Texas residents who suffered damage in the flooding met March 17, 2016, to discuss a class-action suit against the Sabine River Authority (SRA), based on their belief that it had mismanaged water release. The issue is under review by counsel.\nAccording to local ABC affiliate KBMT-TV, SRA spokesperson Ann Galassi stated that the SRA has guidelines it has to follow and those cannot be altered based on weather forecasts. She said that the guidelines are designed to protect the infrastructure of the dam. After the record flood event, the regulatory commission could possibly review the guidelines, and she said that the SRA would welcome that. The SRA of Texas states, \"The Authority was created as a conservation and reclamation district with responsibilities to control, store, preserve, and distribute the waters of the Sabine River and its tributary streams for useful purposes.\" The site also states, \"Toledo Bend Project-since its inception and original development over 50 years ago-has never been a flood-control facility. Rather, the project is regulated, as set forth in the project license, to accommodate a number of public benefits, including water supply, recreation, and hydropower production.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26854", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=26854", "title": "Seed beads", "text": ""}
{"id": "26858", "revid": "29615425", "url": "https://en.wikipedia.org/wiki?curid=26858", "title": "Super Nintendo", "text": ""}
{"id": "26859", "revid": "39008926", "url": "https://en.wikipedia.org/wiki?curid=26859", "title": "Synergy", "text": "Creation of a whole that is greater than the simple sum of its parts\nSynergy is the concept that a combined effect of two or more entities is greater than the sum of their individual effects. The term \"synergy\" comes from the Attic Greek word \u03c3\u03c5\u03bd\u03b5\u03c1\u03b3\u03af\u03b1 ' from ', , meaning \"working together\". Synergy is similar in concept to emergence.\nIn essence, synergy describes a situation where the whole is greater than the simple sum of its parts (i.e., a non-linear addition of force, energy, or effect). It is a fundamental principle observed in various fields, including physics, chemistry, biology, and social sciences. A common example is water, a compound whose properties are distinct and more complex than those of its constituent elements, hydrogen and oxygen.\nThe concept has a long history, with its roots in physiology and theology before being applied to social psychology and organizational behavior. In Christian theology, for instance, synergism is the idea that salvation involves cooperation between divine grace and human freedom. \nIn the biological sciences, synergy is seen as a key driver of evolution. The \"Synergism Hypothesis\", proposed by Peter Corning, suggests that the cooperative relationships at all levels of living systems, from genes to social groups, are favored by natural selection because they provide functional advantages for survival and reproduction. This principle also applies to toxicology and pharmacology, where the combined effect of multiple substances, such as drugs or toxins, can be significantly greater than their individual effects, a phenomenon known as drug synergy. This can be both beneficial, as in combination drug therapies, or harmful, as in the case of combined exposure to toxic chemicals.\nIn a business context, synergy suggests that a team can produce a superior result compared to what its members could achieve individually. This is often a goal in corporate mergers and acquisitions, where the combined entity is expected to be more valuable than the two separate companies. However, potential negative effects such as groupthink can arise in highly cohesive groups, leading to flawed decision-making. Furthermore, in the context of business, the word has been increasingly getting a pejorative connotation due to being used as corporate buzzword and the association with \"management-speak\". \nHistory.\nThe words \"synergy\" and \"synergetic\" have been used in the field of physiology since at least the middle of the 19th century:\nSYN'ERGY, \"Synergi'a\", \"Synenergi'a\", (F.) \"Synergie\"; from \"\u03c3\u03c5\u03bd\", 'with', and \"\u03b5\u03c1\u03b3\u03bf\u03bd\", 'work'. A correlation or concourse of action between different organs in health; and, according to some, in disease.\n\u2014Dunglison, Robley https:// Blanchard and Lea, 1853\nIn 1896, applied the term \"synergy\" to social psychology by writing \"La synergie sociale\", in which he argued that Darwinian theory failed to account of \"social synergy\" or \"social love\", a collective evolutionary drive. The highest civilizations were the work not only of the elite but of the masses too; those masses must be led, however, because the crowd, a feminine and unconscious force, cannot distinguish between good and evil.\nIn 1909, Lester Frank Ward defined synergy as the universal constructive principle of nature:\nI have characterized the social struggle as centrifugal and social solidarity as centripetal. Either alone is productive of evil consequences. Struggle is essentially destructive of the social order, while communism removes individual initiative. The one leads to disorder, the other to degeneracy. What is not seen\u2014the truth that has no expounders\u2014is that the wholesome, constructive movement consists in the properly ordered combination and interaction of both these principles. This is \"social synergy\", which is a form of cosmic synergy, the universal constructive principle of nature.\n\u2014Ward, Lester F. https:// G. P. Putnam's Sons, 1918, p. 358\nIn Christian theology, synergism is the idea that salvation involves some form of cooperation between divine grace and human freedom.\nA modern view of synergy in natural sciences derives from the relationship between energy and information. Synergy is manifested when the system makes the transition between the different information (i.e. order, complexity) embedded in both systems.\nAbraham Maslow and John Honigmann drew attention to an important development in the cultural anthropology field which arose in lectures by Ruth Benedict from 1941, for which the original manuscripts have been lost but the ideas preserved in \"Synergy: Some Notes of Ruth Benedict\" (1969).\nDescriptions and usages.\nIn the natural world, synergistic phenomena are ubiquitous, ranging from physics (for example, the different combinations of quarks that produce protons and neutrons) to chemistry (a popular example is water, a compound of hydrogen and oxygen), to the cooperative interactions among the genes in genomes, the division of labor in bacterial colonies, the synergies of scale in multicellular organisms, as well as the many different kinds of synergies produced by socially-organized groups, from honeybee colonies to wolf packs and human societies: compare stigmergy, a mechanism of indirect coordination between agents or actions that results in the self-assembly of complex systems. Even the tools and technologies that are widespread in the natural world represent important sources of synergistic effects. The tools that enabled early hominins to become systematic big-game hunters is a primordial human example.\nIn the context of organizational behavior, following the view that a cohesive group is more than the sum of its parts, synergy is the ability of a group to outperform even its best individual member. These conclusions are derived from the studies conducted by Jay Hall on a number of laboratory-based group ranking and prediction tasks. He found that effective groups actively looked for the points in which they disagreed and in consequence encouraged conflicts amongst the participants in the early stages of the discussion. In contrast, the ineffective groups felt a need to establish a common view quickly, used simple decision making methods such as averaging, and focused on completing the task rather than on finding solutions they could agree on.\nIn a technical context, its meaning is a construct or collection of different elements working together to produce results not obtainable by any of the elements alone. The elements, or parts, can include people, hardware, software, facilities, policies, documents: all things required to produce system-level results. The value added by the system as a whole, beyond that contributed independently by the parts, is created primarily by the relationship among the parts, that is, how they are interconnected. In essence, a system constitutes a set of interrelated components working together with a common objective: fulfilling some designated need.\nIf used in a business application, synergy means that teamwork will produce an overall better result than if each person within the group were working toward the same goal individually. However, the concept of group cohesion needs to be considered. Group cohesion is that property that is inferred from the number and strength of mutual positive attitudes among members of the group. As the group becomes more cohesive, its functioning is affected in a number of ways. First, the interactions and communication between members increase. Common goals, interests and small size all contribute to this. In addition, group member satisfaction increases as the group provides friendship and support against outside threats.\nThere are negative aspects of group cohesion that have an effect on group decision-making and hence on group effectiveness. There are two issues arising. The risky shift phenomenon is the tendency of a group to make decisions that are riskier than those that the group would have recommended individually. Group Polarisation is when individuals in a group begin by taking a moderate stance on an issue regarding a common value and, after having discussed it, end up taking a more extreme stance.\nA second, potential negative consequence of group cohesion is group think. Group think is a mode of thinking that people engage in when they are deeply involved in cohesive group, when the members' striving for unanimity overrides their motivation to appraise realistically the alternative courses of action. Studying the events of several American policy \"disasters\" such as the failure to anticipate the Japanese attack on Pearl Harbor (1941) and the Bay of Pigs Invasion fiasco (1961), Irving Janis argued that they were due to the cohesive nature of the committees that made the relevant decisions.\nThat decisions made by committees lead to failure in a simple system is noted by Dr. Chris Elliot. His case study looked at IEEE-488, an international standard set by the leading US standards body; it led to a failure of small automation systems using the IEEE-488 standard (which codified a proprietary communications standard HP-IB). But the external devices used for communication were made by two different companies, and the incompatibility between the external devices led to a financial loss for the company. He argues that systems will be safe only if they are designed, not if they emerge by chance.\nThe idea of a systemic approach is endorsed by the United Kingdom Health and Safety Executive. The successful performance of the health and safety management depends upon the analyzing the causes of incidents and accidents and learning correct lessons from them. The idea is that all events (not just those causing injuries) represent failures in control, and present an opportunity for learning and improvement. UK Health and Safety Executive, \"Successful health and safety management\" (1997): this book describes the principles and management practices, which provide the basis of effective health and safety management. It sets out the issues that need to be addressed, and can be used for developing improvement programs, self-audit, or self-assessment. Its message is that organizations must manage health and safety with the same degree of expertise and to the same standards as other core business activities, if they are to effectively control risks and prevent harm to people.\nThe term synergy was refined by R. Buckminster Fuller, who analyzed some of its implications more fully and coined the term synergetics.\nInformation theory.\nMathematical formalizations of synergy have been proposed using information theory to rigorously define the relationships between \"wholes\" and \"parts\". In this context, synergy is said to occur when there is information present in the joint state of multiple variables that cannot be extracted from the individual parts considered individually. For example, consider the logical XOR gate. If formula_1 for three binary variables, the mutual information between any individual source and the target is 0 bit. However, the joint mutual information formula_2 bit. There is information about the target that can only be extracted from the joint state of the inputs considered jointly, and not any others. \nThere is, thus far, no universal agreement on how synergy can best be quantified, with different approaches that decompose information into redundant, unique, and synergistic components appearing in the literature. Despite the lack of universal agreement, information-theoretic approaches to statistical synergy have been applied to diverse fields, including climatology, neuroscience sociology, and machine learning Synergy has also been proposed as a possible foundation on which to build a mathematically robust definition of emergence in complex systems and may be relevant to formal theories of consciousness.\nBiological sciences.\nSynergy of various kinds has been advanced by Peter Corning as a causal agency that can explain the progressive evolution of complexity in living systems over the course of time. According to the Synergism Hypothesis, synergistic effects have been the drivers of cooperative relationships of all kinds and at all levels in living systems. The thesis, in a nutshell, is that synergistic effects have often provided functional advantages (economic benefits) in relation to survival and reproduction that have been favored by natural selection. The cooperating parts, elements, or individuals become, in effect, functional \"units\" of selection in evolutionary change. Similarly, environmental systems may react in a non-linear way to perturbations, such as climate change, so that the outcome may be greater than the sum of the individual component alterations. Synergistic responses are a complicating factor in environmental modeling.\nPest synergy.\nPest synergy would occur in a biological host organism population, where, for example, the introduction of parasite A may cause 10% fatalities, and parasite B may also cause 10% loss. When both parasites are present, the losses would normally be expected to total less than 20%, yet, in some cases, losses are significantly greater. In such cases, it is said that the parasites in combination have a synergistic effect.\nDrug synergy.\nMechanisms that may be involved in the development of synergistic effects include:\nMore mechanisms are described in an exhaustive 2009 review.\nToxicological synergy.\nToxicological synergy is of concern to the public and regulatory agencies because chemicals individually considered safe might pose unacceptable health or ecological risk in combination. Articles in scientific and lay journals include many definitions of chemical or toxicological synergy, often vague or in conflict with each other. Because toxic interactions are defined relative to the expectation under \"no interaction\", a determination of synergy (or antagonism) depends on what is meant by \"no interaction\". The United States Environmental Protection Agency has one of the more detailed and precise definitions of toxic interaction, designed to facilitate risk assessment. In their guidance documents, the no-interaction default assumption is dose addition, so synergy means a mixture response that exceeds that predicted from dose addition. The EPA emphasizes that synergy does not always make a mixture dangerous, nor does antagonism always make the mixture safe; each depends on the predicted risk under dose addition.\nFor example, a consequence of pesticide use is the risk of health effects. During the registration of pesticides in the United States exhaustive tests are performed to discern health effects on humans at various exposure levels. A regulatory upper limit of presence in foods is then placed on this pesticide. As long as residues in the food stay below this regulatory level, health effects are deemed highly unlikely and the food is considered safe to consume.\nHowever, in normal agricultural practice, it is rare to use only a single pesticide. During the production of a crop, several different materials may be used. Each of them has had determined a regulatory level at which they would be considered individually safe. In many cases, a commercial pesticide is itself a combination of several chemical agents, and thus the safe levels actually represent levels of the mixture. In contrast, a combination created by the end user, such as a farmer, has rarely been tested in that combination. The potential for synergy is then unknown or estimated from data on similar combinations. This lack of information also applies to many of the chemical combinations to which humans are exposed, including residues in food, indoor air contaminants, and occupational exposures to chemicals. Some groups think that the rising rates of cancer, asthma, and other health problems may be caused by these combination exposures; others have alternative explanations. This question will likely be answered only after years of exposure by the population in general and research on chemical toxicity, usually performed on animals. Examples of pesticide synergists include Piperonyl butoxide and MGK 264.\nHuman synergy.\nSynergy exists in individual and social interactions among humans, with some arguing that social cooperation requires synergy to continue. One way of quantifying synergy in human social groups is via energy use, where larger groups of humans (i.e., cities) use energy more efficiently that smaller groups of humans. \nHuman synergy can also occur on a smaller scale, like when individuals huddle together for warmth or in workplaces where labor specialization increase efficiencies.\nWhen synergy occurs in the work place, the individuals involved get to work in a positive and supportive working environment. When individuals get to work in environments such as these, the company reaps the benefits. The authors of \"Creating the Best Workplace on Earth\" Rob Goffee and Gareth Jones, state that \"highly engaged employees are, on average, 50% more likely to exceed expectations that the least-engaged workers. And companies with highly engaged people outperform firms with the most disengaged folks- by 54% in employee retention, by 89% in customer satisfaction, and by fourfold in revenue growth. Also, those that are able to be open about their views on the company, and have confidence that they will be heard, are likely to be a more organized employee who helps his/ her fellow team members succeed.\nHuman interaction with technology can also increase synergy. Organismic computing is an approach to improving group efficacy by increasing synergy in human groups via technological means.\nTheological synergism.\nIn Christian theology, synergism is the belief that salvation involves a cooperation between divine grace and human freedom. Eastern Orthodox theology, in particular, uses the term \"synergy\" to describe this relationship, drawing on biblical language: \"in Paul's words, 'We are fellow-workers (\"synergoi\") with God' (1 Corinthians iii, 9)\".\nCorporate synergy.\nCorporate synergy occurs when corporations interact congruently. A corporate synergy refers to a financial benefit that a corporation expects to realize when it merges with or acquires another corporation. This type of synergy is a nearly ubiquitous feature of a corporate acquisition and is a negotiating point between the buyer and seller that impacts the final price both parties agree to. There are distinct types of corporate synergies, as follows.\nMarketing.\nA marketing synergy refers to the use of information campaigns, studies, and scientific discovery or experimentation for research and development. This promotes the sale of products for varied use or off-market sales as well as development of marketing tools and in several cases exaggeration of effects. It is also often a meaningless buzzword used by corporate leaders.\nRevenue.\nA revenue synergy refers to the opportunity of a combined corporate entity to generate more revenue than its two predecessor stand-alone companies would be able to generate. For example, if company A sells product X through its sales force, company B sells product Y, and company A decides to buy company B, then the new company could use each salesperson to sell products X and Y, thereby increasing the revenue that each salesperson generates for the company.\nPotential revenue synergies are generally taken less seriously than cost synergies by M&amp;A investment bankers due to the uncertainty introduced by markets. A McKinsey report found that around 70% of predicted revenue synergies from mergers failed to materialize.\nIn media revenue, synergy is the promotion and sale of a product throughout the various subsidiaries of a media conglomerate, e.g. films, soundtracks, or video games.\nFinancial.\nFinancial synergy gained by the combined firm is a result of number of benefits which flow to the entity as a consequence of acquisition and merger. These benefits may be:\nCash slack.\nThis is when a firm having a number of cash extensive projects acquires a firm which is cash-rich, thus enabling the new combined firm to enjoy the profits from investing the cash of one firm in the projects of the other.\nDebt capacity.\nIf two firms have no or little capacity to carry debt before individually, it is possible for them to join and gain the capacity to carry the debt through decreased gearing (leverage). This creates value for the firm, as debt is thought to be a cheaper source of finance.\nTax benefits.\nIt is possible for one firm to have unused tax benefits which might be offset against the profits of another after combination, thus resulting in less tax being paid. However this greatly depends on the tax law of the country.\nManagement.\nSynergy in management and in relation to teamwork refers to the combined effort of individuals as participants of the team. The condition that exists when the organization's parts interact to produce a joint effect that is greater than the sum of the parts acting alone. Positive or negative synergies can exist. In these cases, positive synergy has positive effects such as improved efficiency in operations, greater exploitation of opportunities, and improved utilization of resources. Negative synergy on the other hand has negative effects such as: reduced efficiency of operations, decrease in quality, underutilization of resources and disequilibrium with the external environment.\nCost.\nA cost synergy refers to the opportunity of a combined corporate entity to reduce or eliminate expenses associated with running a business. Cost synergies are realized by eliminating positions that are viewed as duplicate within the merged entity. Examples include the headquarters office of one of the predecessor companies, certain executives, the human resources department, or other employees of the predecessor companies. This is related to the economic concept of economies of scale.\nSynergistic action in economy.\nThe synergistic action of the economic players lies within the economic phenomenon's profundity. The synergistic action gives different dimensions to competitiveness, strategy and network identity becoming an unconventional \"weapon\" which belongs to those who exploit the economic systems' potential in depth.\nSynergistic determinants.\nThe synergistic gravity equation (SYNGEq), according to its complex \"title\", represents a synthesis of the endogenous and exogenous factors which determine the private and non-private economic decision makers to call to actions of synergistic exploitation of the economic network in which they operate. That is to say, SYNGEq constitutes a big picture of the factors/motivations which determine the entrepreneurs to contour an active synergistic network. SYNGEq includes both factors which character is changing over time (such as the competitive conditions), as well as classics factors, such as the imperative of the access to resources of the collaboration and the quick answers. The synergistic gravity equation (SINGEq) comes to be represented by the formula:\n\u03a3SYN.Act = \u03a3R-*I(CRed+COOP++AUnimit.)*V(Cust.+Info.)*cc\nwhere:\nSynergistic networks and systems.\nThe synergistic network represents an integrated part of the economic system which, through the coordination and control functions (of the undertaken economic actions), agrees synergies. The networks which promote synergistic actions can be divided in horizontal synergistic networks and vertical synergistic networks.\nSynergy effects.\nThe synergy effects are difficult (even impossible) to imitate by competitors and difficult to reproduce by their authors because these effects depend on the combination of factors with time-varying characteristics. The synergy effects are often called \"synergistic benefits\", representing the direct and implied result of the developed/adopted synergistic actions.\nComputers.\nSynergy can also be defined as the combination of human strengths and computer strengths, such as advanced chess. Computers can process data much more quickly than humans, but lack the ability to respond meaningfully to arbitrary stimuli.\nSynergy in literature.\nEtymologically, the \"synergy\" term was first used around 1600, deriving from the Greek word \"synergos\", which means \"to work together\" or \"to cooperate\". If during this period the synergy concept was mainly used in the theological field (describing \"the cooperation of human effort with divine will\"), in the 19th and 20th centuries, \"synergy\" was promoted in physics and biochemistry, being implemented in the study of the open economic systems only in the 1960 and 1970s.\nIn 1938, J. R. R. Tolkien wrote an essay titled \"On Fairy Stores\", delivered at an Andrew Lang Lecture, and reprinted in his book, \"The Tolkien Reader\", published in 1966. In it, he made two references to synergy, although he did not use that term. He wrote:\nFaerie cannot be caught in a net of words; for it is one of its qualities to be indescribable, though not imperceptible. It has many ingredients, but analysis will not necessarily discover the secret of the whole.\nAnd more succinctly, in a footnote, about the \"part of producing the web of an intricate story\", he wrote:\nIt is indeed easier to unravel a single \"thread\" \u2014 an incident, a name, a motive \u2014 than to trace the history of any \"picture\" defined by many threads. For with the picture in the tapestry a new element has come in: the picture is greater than, and not explained by, the sum of the component threads.\nSynergy in the media.\nThe informational synergies which can be applied also in media involve a compression of transmission, access and use of information's time, the flows, circuits and means of handling information being based on a complementary, integrated, transparent and coordinated use of knowledge.\nIn media economics, synergy is the promotion and sale of a product (and all its versions) throughout the various subsidiaries of a media conglomerate, e.g. films, soundtracks or video games. Walt Disney pioneered synergistic marketing techniques in the 1930s by granting dozens of firms the right to use his Mickey Mouse character in products and ads, and continued to market Disney media through licensing arrangements. These products can help advertise the film itself and thus help to increase the film's sales. For example, the Spider-Man films had toys of webshooters and figures of the characters made, as well as posters and games. The NBC sitcom 30 Rock often shows the power of synergy, while also poking fun at the use of the term in the corporate world. There are also different forms of synergy in popular card games like , Yu-Gi-Oh!, Cardfight!! Vanguard, and Future Card Buddyfight.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26860", "revid": "6046731", "url": "https://en.wikipedia.org/wiki?curid=26860", "title": "Syntax", "text": "System responsible for combining morphemes into complex structures\nIn linguistics, syntax ( ) is the study of how words and morphemes combine to form larger units such as phrases and sentences. Central concerns of syntax include word order, grammatical relations, hierarchical sentence structure (constituency), agreement, the nature of crosslinguistic variation, and the relationship between form and meaning (semantics). Diverse approaches, such as generative grammar and functional grammar, offer unique perspectives on syntax, reflecting its complexity and centrality to understanding human language.\nEtymology.\nThe word \"syntax\" comes from the ancient Greek word , meaning an orderly or systematic arrangement, which consists of (\"syn-\", \"together\" or \"alike\"), and (\"t\u00e1xis\", \"arrangement\"). In Hellenistic Greek, this also specifically developed a use referring to the grammatical order of words, with a slightly altered spelling: . The English term, which first appeared in 1548, is partly borrowed from Latin () and Greek, though the Latin term developed from Greek.\nTopics.\nThe field of syntax contains a number of various topics that a syntactic theory is often designed to handle. The relation between the topics is treated differently in different theories, and some of them may not be considered to be distinct but instead to be derived from one another (i.e. word order can be seen as the result of movement rules derived from grammatical relations).\nSequencing of subject, verb, and object.\nOne basic description of a language's syntax is the sequence in which the subject (S), verb (V), and object (O) usually appear in sentences. Over 85% of languages usually place the subject first, either in the sequence SVO or the sequence SOV. The other possible sequences are VSO, VOS, OVS, and OSV, the last three of which are rare. In most generative theories of syntax, the surface differences arise from a more complex clausal phrase structure, and each order may be compatible with multiple derivations. However, word order can also reflect the semantics or function of the ordered elements.\nGrammatical relations.\nAnother description of a language considers the set of possible grammatical relations in a language or in general and how they behave in relation to one another in the morphosyntactic alignment of the language. The description of grammatical relations can also reflect transitivity, passivization, and head-dependent-marking or other agreement. Languages have different criteria for grammatical relations. For example, subjecthood criteria may have implications for how the subject is referred to from a relative clause or coreferential with an element in an infinite clause.\nConstituency.\nConstituency is the feature of being a constituent and how words can work together to form a constituent (or \"phrase\"). Constituents are often moved as units, and the constituent can be the domain of agreement. Some languages allow discontinuous phrases in which words belonging to the same constituent are not immediately adjacent but are broken up by other constituents. Constituents may be recursive, as they may consist of other constituents, potentially of the same type.\nEarly history.\nThe \"A\u1e63\u1e6d\u0101dhy\u0101y\u012b\" of P\u0101\u1e47ini, from c.\u20094th century BC in Ancient India, is often cited as an example of a premodern work that approaches the sophistication of a modern syntactic theory since works on grammar had been written long before modern syntax came about. In the West, the school of thought that came to be known as \"traditional grammar\" began with the work of Dionysius Thrax.\nFor centuries, a framework known as , first expounded in 1660 by Antoine Arnauld and Claude Lancelot in a book of the same title, dominated work in syntax: as its basic premise the assumption that language is a direct reflection of thought processes and so there is a single most natural way to express a thought.\nHowever, in the 19th century, with the development of historical-comparative linguistics, linguists began to realize the sheer diversity of human language and to question fundamental assumptions about the relationship between language and logic. It became apparent that there was no such thing as the most natural way to express a thought and so logic could no longer be relied upon as a basis for studying the structure of language.\nThe Port-Royal grammar modeled the study of syntax upon that of logic. (Indeed, large parts of Port-Royal Logic were copied or adapted from the \"Grammaire g\u00e9n\u00e9rale\".) Syntactic categories were identified with logical ones, and all sentences were analyzed in terms of \"subject \u2013 copula \u2013 predicate\". Initially, that view was adopted even by the early comparative linguists such as Franz Bopp.\nThe central role of syntax within theoretical linguistics became clear only in the 20th century, which could reasonably be called the \"century of syntactic theory\" as far as linguistics is concerned. (For a detailed and critical survey of the history of syntax in the last two centuries, see the monumental work by Giorgio Graffi (2001).)\nTheories.\nThere are a number of theoretical approaches to the discipline of syntax. One school of thought, founded in the works of Derek Bickerton, sees syntax as a branch of biology, since it conceives of syntax as the study of linguistic knowledge as embodied in the human mind. Other linguists (e.g., Gerald Gazdar) take a more Platonistic view since they regard syntax to be the study of an abstract formal system. Yet others (e.g., Joseph Greenberg) consider syntax a taxonomical device to reach broad generalizations across languages.\nSyntacticians have attempted to explain the causes of word-order variation within individual languages and cross-linguistically. Much of such work has been done within the framework of generative grammar, which holds that syntax depends on a genetic endowment common to the human species. In that framework and in others, linguistic typology and universals have been primary explicanda.\nAlternative explanations, such as those by functional linguists, have been sought in language processing. It is suggested that the brain finds it easier to parse syntactic patterns that are either right- or left-branching but not mixed. The most-widely held approach is the performance\u2013grammar correspondence hypothesis by John A. Hawkins, who suggests that language is a non-innate adaptation to innate cognitive mechanisms. Cross-linguistic tendencies are considered as being based on language users' preference for grammars that are organized efficiently and on their avoidance of word orderings that cause processing difficulty. Some languages, however, exhibit regular inefficient patterning such as the VO languages Chinese, with the adpositional phrase before the verb, and Finnish, which has postpositions, but there are few other profoundly exceptional languages. More recently, it is suggested that the left- versus right-branching patterns are cross-linguistically related only to the place of role-marking connectives (adpositions and subordinators), which links the phenomena with the semantic mapping of sentences.\nTheoretical syntactic models.\nDependency grammar.\nDependency grammar is an approach to sentence structure in which syntactic units are arranged according to the dependency relation, as opposed to the constituency relation of phrase structure grammars. Dependencies are directed links between words. The (finite) verb is seen as the root of all clause structure and all the other words in the clause are either directly or indirectly dependent on this root (i.e. the verb). Some prominent dependency-based theories of syntax are the following:\nLucien Tesni\u00e8re (1893\u20131954) is widely seen as the father of modern dependency-based theories of syntax and grammar. He argued strongly against the binary division of the clause into subject and predicate that is associated with the grammars of his day (S \u2192 NP VP) and remains at the core of most phrase structure grammars. In place of that division, he positioned the verb as the root of all clause structure.\nCategorial grammar.\nCategorial grammar is an approach in which constituents combine as function and argument, according to combinatory possibilities specified in their syntactic categories. For example, other approaches might posit a rule that combines a noun phrase (NP) and a verb phrase (VP), but CG would posit a syntactic category \"NP\" and another \"NP\\S\", read as \"a category that searches to the left (indicated by \\) for an NP (the element on the left) and outputs a sentence (the element on the right).\" Thus, the syntactic category for an intransitive verb is a complex formula representing the fact that the verb acts as a function word requiring an NP as an input and produces a sentence level structure as an output. The complex category is notated as (NP\\S) instead of V. The category of transitive verb is defined as an element that requires two NPs (its subject and its direct object) to form a sentence. That is notated as (NP/(NP\\S)), which means, \"A category that searches to the right (indicated by /) for an NP (the object) and generates a function (equivalent to the VP) which is (NP\\S), which in turn represents a function that searches to the left for an NP and produces a sentence.\"\nTree-adjoining grammar is a categorial grammar that adds in partial tree structures to the categories.\nStochastic/probabilistic grammars/network theories.\nTheoretical approaches to syntax that are based upon probability theory are known as stochastic grammars. One common implementation of such an approach makes use of a neural network or connectionism.\nFunctional grammars.\nFunctionalist models of grammar study the form\u2013function interaction by performing a structural and a functional analysis.\nGenerative syntax.\nGenerative syntax is the study of syntax within the overarching framework of generative grammar. Generative theories of syntax typically propose analyses of grammatical patterns using formal tools such as phrase structure grammars augmented with additional operations such as syntactic movement. Their goal in analyzing a particular language is to specify rules which generate all and only the expressions which are well-formed in that language. In doing so, they seek to identify innate domain-specific principles of linguistic cognition, in line with the wider goals of the generative enterprise. Generative syntax is among the approaches that adopt the principle of the autonomy of syntax by assuming that meaning and communicative intent is determined by the syntax, rather than the other way around.\nGenerative syntax was proposed in the late 1950s by Noam Chomsky, building on earlier work by Zellig Harris, Louis Hjelmslev, and others. Since then, numerous theories have been proposed under its umbrella:\nOther theories that find their origin in the generative paradigm are:\nCognitive and usage-based grammars.\nThe Cognitive Linguistics framework stems from generative grammar but adheres to evolutionary, rather than Chomskyan, linguistics. Cognitive models often recognise the generative assumption that the object belongs to the verb phrase. Cognitive frameworks include the following:\nSee also.\nSyntactic terms.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "26861", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=26861", "title": "Shamanism", "text": "Religious practice\nShamanism is a spiritual practice that involves a practitioner (shaman) interacting with the spirit world through altered states of consciousness, such as trance. The goal of this is usually to direct spirits or spiritual energies into the physical world for the purpose of healing, divination, or to aid human beings in some other way.\nBeliefs and practices categorized as shamanic have attracted the interest of scholars from a variety of disciplines, including anthropologists, archeologists, historians, religious studies scholars, philosophers, and psychologists. Hundreds of books and academic papers on the subject have been produced, with a peer-reviewed academic journal being devoted to the study of shamanism.\nTerminology.\nEtymology.\nThe Modern English word \"shamanism\" derives from the Russian word , , which itself comes from the word from a Tungusic language \u2013 possibly from the southwestern dialect of the Evenki spoken by the Sym Evenki peoples, or from the Manchu language. The etymology of the word is sometimes connected to the Tungus root , meaning \"to know\". However, Finnish ethnolinguist Juha Janhunen questions this connection on linguistic grounds: \"The possibility cannot be completely rejected, but neither should it be accepted without reservation since the assumed derivational relationship is phonologically irregular (note especially the vowel quantities).\"\nMircea Eliade noted that the Sanskrit word , , designating a wandering monastic or holy figure, has spread to many Central Asian languages along with Buddhism and could be the ultimate origin of the word shaman. The word has been reported in Gandhari as , in Tocharian A as , in Tocharian B as and in Chinese as , .\nThe term was adopted by Russians interacting with the indigenous peoples in Siberia. It is found in the memoirs of the exiled Russian churchman Avvakum. It was brought to Western Europe twenty years later by the Dutch statesman Nicolaes Witsen, who reported his stay and journeys among the Tungusic- and Samoyedic-speaking Indigenous peoples of Siberia in his book \"Noord en Oost Tataryen\" (1692). Adam Brand, a merchant from L\u00fcbeck, published in 1698 his account of a Russian embassy to China; a translation of his book, published the same year, introduced the word \"shaman\" to English speakers.\nAnthropologist and archeologist Silvia Tom\u00e1\u0161kov\u00e1 argued that by the mid-1600s, many Europeans applied the Arabic term \"shaitan\" (meaning \"devil\") to the non-Christian practices and beliefs of Indigenous peoples beyond the Ural Mountains. She suggests that \"shaman\" may have entered the various Tungus dialects as a corruption of this term, and then been told to Christian missionaries, explorers, soldiers and colonial administrators with whom the people had increasing contact for centuries.\nA female shaman is sometimes called a \"&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;shamanka\", which is not an actual Tungus term but simply \"shaman\" plus the Russian suffix \"\" (for feminine nouns).\nDefinitions.\nThere is no single agreed-upon definition for the word \"shamanism\" among anthropologists. Anthropologist Manvir Singh argues that the most justifiable definition includes three basic features: entering non-ordinary states, engaging with unseen realities, and providing services like healing and divination.\nThe English historian Ronald Hutton noted that by the dawn of the 21st century, there were four separate definitions of the term which appeared to be in use:\nAccording to the \"Oxford English Dictionary\", a shaman ( , or ) is someone who is regarded as having access to, and influence in, the world of benevolent and malevolent spirits, who typically enters into a trance state during a ritual, and practices divination and healing. The word \"shaman\" probably originates from the Tungusic Evenki language of North Asia. According to Juha Janhunen, \"the word is attested in all of the Tungusic idioms\" such as Negidal, Lamut, Udehe/Orochi, Nanai, Ilcha, Orok, Manchu and Ulcha, and \"nothing seems to contradict the assumption that the meaning 'shaman' also derives from Proto-Tungusic\" and may have roots that extend back in time at least two millennia. The term was introduced to the west after Russian forces conquered the shamanistic Khanate of Kazan in 1552.\nThe term \"shamanism\" was first applied by Western anthropologists as outside observers of the ancient religion of the Turks and Mongols, as well as those of the neighbouring Tungusic- and Samoyedic-speaking peoples. Upon observing more religious traditions around the world, some Western anthropologists began to also use the term in a very broad sense. The term was used to describe unrelated magicoreligious practices found within the ethnic religions of other parts of Asia, Africa, Australasia and even completely unrelated parts of the Americas, as they believed these practices to be similar to one another. While the term has been incorrectly applied by cultural outsiders to many Indigenous spiritual practices, the words \"shaman\" and \"shamanism\" do not accurately describe the variety and complexity that is Indigenous spirituality. Each nation and tribe has its own way of life, and uses terms in their own languages.\nMircea Eliade writes, \"A first definition of this complex phenomenon, and perhaps the least hazardous, will be: shamanism = 'technique of religious ecstasy'.\" Shamanism encompasses the premise that shamans are intermediaries or messengers between the human world and the spirit worlds. Shamans are said to treat ailments and illnesses by mending the soul. Alleviating traumas affecting the soul or spirit are believed to restore the physical body of the individual to balance and wholeness. Shamans also say that they enter supernatural realms or dimensions to obtain solutions to problems afflicting the community, or visit other worlds or dimensions to bring guidance to misguided souls and to ameliorate illnesses of the human soul caused by foreign elements. Shamans operate primarily within the spiritual world, which, they believe, in turn affects the human world. The restoration of balance is said to result in the elimination of the ailment.\nCriticism of the term.\nThe anthropologist Alice Kehoe criticizes the term \"shaman\" in her book \"Shamans and Religion: An Anthropological Exploration in Critical Thinking\". Part of this criticism involves the notion of cultural appropriation. This includes criticism of New Age and modern Western forms of shamanism, which, according to Kehoe, misrepresent or dilute Indigenous practices. Kehoe also believes that the term reinforces racist ideas such as the noble savage.\nKehoe is highly critical of Mircea Eliade's work on shamanism as an invention synthesized from various sources unsupported by more direct research. To Kehoe, citing practices such as drumming, trance, chanting, entheogen and hallucinogen use, spirit communication, and healing as definitive of shamanism ignores the fact that they exist outside of what is defined as shamanism and even play similar roles in nonshamanic cultures, for example chanting in the Abrahamic religions. She argues that these expression are unique to each culture that uses them and that such practices cannot be generalized easily, accurately, or usefully into a global religion of shamanism. Because of this, Kehoe is also highly critical of the hypothesis that shamanism is an ancient, unchanged, and surviving religion from the Paleolithic period.\nThe term has been criticized for its perceived colonial roots, and as a tool to perpetuate perceived contemporary linguistic colonialism. By Western scholars, the term \"shamanism\" is used to refer to a variety of different cultures and practices around the world, which can vary dramatically and may not be accurately represented by a single concept. Billy-Ray Belcourt, an author and award-winning scholar from the Driftpile Cree Nation in Canada, argues that using language with the intention of simplifying culture that is diverse, such as Shamanism, as it is prevalent in communities around the world and is made up of many complex components, works to conceal the complexities of the social and political violence that Indigenous communities have experienced at the hands of settlers. Belcourt argues that language used to imply \"simplicity\" in regards to Indigenous culture, is a tool used to belittle Indigenous cultures, as it views Indigenous communities solely as a result of a history embroiled in violence, that leaves Indigenous communities only capable of simplicity and plainness.\nAnthropologist Mih\u00e1ly Hopp\u00e1l also discusses whether the term \"shamanism\" is appropriate. He notes that for many readers, \"-ism\" implies a particular dogma, like Buddhism, Catholicism or Judaism. He recommends using the term \"shamanhood\" or \"shamanship\" (a term used in old Russian and German ethnographic reports at the beginning of the 20th century) for stressing the diversity and the specific features of the discussed cultures. He believes that this places more stress on the local variations and emphasizes that shamanism is not a religion of sacred dogmas, but linked to the everyday life in a practical way. Following similar thoughts, he also conjectures a contemporary paradigm shift. Piers Vitebsky also mentions that, despite really astonishing similarities, there is no unity in shamanism. The various, fragmented shamanistic practices and beliefs coexist with other beliefs everywhere. There is no record of pure shamanistic societies (although their existence is not impossible). Norwegian social anthropologist Hakan Rydving has likewise argued for the abandonment of the terms \"shaman\" and \"shamanism\" as \"scientific illusions\".\nDulam Bumochir has affirmed the above critiques of \"shamanism\" as a Western construct created for comparative purposes and, in an extensive article, has documented the role of Mongols themselves, particularly \"the partnership of scholars and shamans in the reconstruction of shamanism\" in post-1990/post-communist Mongolia. This process has also been documented by Swiss anthropologist Judith Hangartner in her landmark study of Darhad shamans in Mongolia. Historian Karena Kollmar-Polenz argues that the social construction and reification of shamanism as a religious \"other\" actually began with the 18th-century writings of Tibetan Buddhist monks in Mongolia and later \"probably influenced the formation of European discourse on Shamanism\".\nHistory.\nShamanism is a system of religious practice. Historically, it is often associated with Indigenous and tribal societies, and involves belief that shamans, with a connection to the otherworld, have the power to heal the sick, communicate with spirits, and escort souls of the dead to the afterlife. The origins of Shamanism stem from Mongolia and indigenous peoples of far northern Europe and Siberia.\nDespite structural implications of colonialism and imperialism that have limited the ability of Indigenous peoples to practice traditional spiritualities, many communities are undergoing resurgence through self-determination and the reclamation of dynamic traditions. Other groups have been able to avoid some of these structural impediments by virtue of their isolation, such as the nomadic Tuvan (with an estimated population of 3000 people surviving from this tribe). Tuva is one of the most isolated Asiatic tribes in Russia where the art of shamanism has been preserved until today due to its isolated existence, allowing it to be free from the influences of other major religions.\nBeliefs.\nThere are many variations of shamanism throughout the world, but several common beliefs are shared by all forms of shamanism. Common beliefs identified by Eliade (1972) are the following:\nShamanism is based on the premise that the visible world is pervaded by invisible forces or spirits which affect the lives of the living. Although the causes of disease lie in the spiritual realm, inspired by malicious spirits, both spiritual and physical methods are used to heal. Commonly, a shaman \"enters the body\" of the patient to confront the spiritual infirmity and heals by banishing the infectious spirit.\nMany shamans have expert knowledge of medicinal plants native to their area, and an herbal treatment is often prescribed. In many places shamans learn directly from the plants, harnessing their effects and healing properties, after obtaining permission from the indwelling or patron spirits. In the Peruvian Amazon Basin, shamans and \"curanderos\" use medicine songs called \"icaros\" to evoke spirits. Before a spirit can be summoned it must teach the shaman its song. The use of totemic items such as rocks with special powers and an animating spirit is common.\nBelief in witchcraft and sorcery, known as \"brujer\u00eda\" in Latin America, exists in many societies. Other societies assert all shamans have the power to both cure and kill. Those with shamanic knowledge usually enjoy great power and prestige in the community, but they may also be regarded suspiciously or fearfully as potentially harmful to others.\nSoul can generally explain more, seemingly unassociated phenomena in shamanism:\nHealing may be based closely on the soul concepts of the belief system of the people served by the shaman. It may consist of the supposed retrieving the lost soul of the ill person.\nScarcity of hunted game can be solved by \"releasing\" the souls of the animals from their hidden abodes. Besides that, many taboos may prescribe the behavior of people towards game, so that the souls of the animals do not feel angry or hurt, or the pleased soul of the already killed prey can tell the other, still living animals, that they can allow themselves to be caught and killed.\nSpirits are invisible entities that only shamans can see. They are seen as persons that can assume a human or animal body. Some animals in their physical forms are also seen as spirits such as the case of the eagle, snake, jaguar, and rat. Beliefs related to spirits can explain many different phenomena. For example, the importance of storytelling, or acting as a singer, can be understood better if the whole belief system is examined. A person who can memorize long texts or songs, and play an instrument, may be regarded as the beneficiary of contact with the spirits (e.g. Khanty people).\nPractice.\nGenerally, shamans traverse the axis mundi and enter the \"spirit world\" by effecting a transition of consciousness, entering into an ecstatic trance, either autohypnotically or through the use of entheogens or ritual performances. The methods employed are diverse, and are often used together.\nMusic and songs.\nJust like shamanism itself, music and songs related to it in various cultures are diverse. In several instances, songs related to shamanism are intended to imitate natural sounds, via onomatopoeia.\nSound mimesis in various cultures may serve other functions not necessarily related to shamanism: practical goals such as luring game in the hunt; or entertainment (Inuit throat singing).\nInitiation and learning.\nShamans often say that they have been called through dreams or signs. However, some say their powers are inherited. In traditional societies shamanic training varies in length, but generally takes years.\nTurner and colleagues mention a phenomenon called \"shamanistic initiatory crisis\", a rite of passage for shamans-to-be, commonly involving physical illness or psychological crisis. The significant role of initiatory illnesses in the calling of a shaman can be found in the case history of Chuonnasuan, who was one of the last shamans among the Tungus peoples in Northeast China.\nThe wounded healer is an archetype for a shamanic trial and journey. This process is important to young shamans. They undergo a type of sickness that pushes them to the brink of death. This is said to happen for two reasons:\nItems used in spiritual practice.\nShamans may employ varying materials in spiritual practice in different cultures.\nThe drum is used by shamans of several peoples in Siberia. The beating of the drum allows the shaman to achieve an altered state of consciousness or to travel on a journey between the physical and spiritual worlds. Much fascination surrounds the role that the acoustics of the drum play to the shaman. Shaman drums are generally constructed of an animal-skin stretched over a bent wooden hoop, with a handle across the hoop.\nRoles.\nShamans have been conceptualized as those who are able to gain knowledge and power to heal in the spiritual world or dimension. Most shamans have dreams or visions that convey certain messages. Shamans may say that they have or have acquired many spirit guides, who they believe guide and direct them in their travels in the spirit world. These spirit guides are always thought to be present within the shaman, although others are said to encounter them only when the shaman is in a trance. The spirit guide energizes the shamans, enabling them to enter the spiritual dimension. Shamans say that they heal within the communities and the spiritual dimension by returning lost parts of the human soul from wherever they have gone. Shamans also say that they cleanse excess negative energies, which are said to confuse or pollute the soul. Shamans act as mediators in their cultures. Shamans say that they communicate with the spirits on behalf of the community, including the spirits of the deceased. Shamans believe they can communicate with both living and dead to alleviate unrest, unsettled issues, and to deliver gifts to the spirits.\nShamans perform a variety of functions depending upon their respective cultures; healing, leading a sacrifice, preserving traditions by storytelling and songs, fortune-telling, and acting as a psychopomp (\"guide of souls\"). A single shaman may fulfill several of these functions.\nThere are distinct types of shamans who perform more specialized functions. For example, among the Nanai people, a distinct kind of shaman acts as a psychopomp. Other specialized shamans may be distinguished according to the type of spirits, or realms of the spirit world, with which the shaman most commonly interacts. These roles vary among the Nenets, Enets, and Selkup shamans.\nThe assistant of an Oroqen shaman (called \"jardalanin\", or \"second spirit\") knows many things about the associated beliefs. He or she accompanies the rituals and interprets the behaviors of the shaman. Despite these functions, the \"jardalanin\" is not a shaman. For this interpretative assistant, it would be unwelcome to fall into a trance.\nEcological aspect.\nAs the primary teacher of tribal symbolism, the shaman may have a leading role in this ecological management, actively restricting hunting and fishing. Among the Tucano people, a sophisticated system exists for environmental resources management and for avoiding resource depletion through overhunting. This system is conceptualized mythologically and symbolically by the belief that breaking hunting restrictions may cause illness. The shaman is able to \"release\" game animals, or their souls, from their hidden abodes. The Piaroa people have ecological concerns related to shamanism. Among the Inuit the \"angakkuq\" (shamans) fetch the souls of game from remote places, or soul travel to ask for game from mythological beings like the Sea Woman.\nEconomics.\nThe way shamans get sustenance and take part in everyday life varies across cultures. In many Inuit groups, they provide services for the community and get a \"due payment\", and believe the payment is given to the helping spirits. An account states that the gifts and payments that a shaman receives are given by his partner spirit. Since it obliges the shaman to use his gift and to work regularly in this capacity, the spirit rewards him with the goods that it receives. These goods, however, are only \"welcome addenda\". They are not enough to enable a full-time shaman. Shamans live like any other member of the group, as a hunter or housewife. \nSince the early 2000s, the growth of ayahuasca tourism in South America has created an economic niche for practitioners, particularly in Iquitos, Peru, where retreat centers cater to foreign visitors. Media attention in international outlets further contributed to this trend, and many shamans and facilitators now sustain themselves by leading ceremonies for paying participants.\nFurthermore, due to the predominant number of female shamans over males, shamanism was and continues to be an integral part of women's economic liberation. Shamanism often serves as an economic resource due to the requirement of payment for service. This economic revenue was vital for female shamans, especially those living during the Chosun Dynasty in Korea (A.D. 1392\u20131910). In a culture that disapproved of female economic autonomy, the practice of shamanism allowed women to advance themselves financially and independently, in a way that had not been possible for them before.\nAcademic study.\nCognitive and evolutionary approaches.\nThere are two major frameworks among cognitive and evolutionary scientists for explaining shamanism. The first, proposed by anthropologist Michael Winkelman, is known as the \"neurotheological theory\". According to Winkelman, shamanism develops reliably in human societies because it provides valuable benefits to the practitioner, their group, and individual clients. In particular, the trance states induced by dancing, hallucinogens, and other triggers are hypothesized to have an \"integrative\" effect on cognition, allowing communication among mental systems that specialize in theory of mind, social intelligence, and natural history. With this cognitive integration, the shaman can better predict the movement of animals, resolve group conflicts, plan migrations, and provide other useful services.\nThe neurotheological theory contrasts with the \"by-product\" or \"subjective\" model of shamanism developed by anthropologist Manvir Singh. According to Singh, shamanism is a cultural technology that adapts to (or hacks) our psychological biases to convince us that a specialist can influence important but uncontrollable outcomes. Citing work on the psychology of magic and superstition, Singh argues that humans search for ways of influencing uncertain events, such as healing illness, controlling rain, or attracting animals. As specialists compete to help their clients control these outcomes, they drive the evolution of psychologically compelling magic, producing traditions adapted to people's cognitive biases. Shamanism, Singh argues, is the culmination of this cultural evolutionary process\u2014a psychologically appealing method for controlling uncertainty. For example, some shamanic practices exploit our intuitions about humanness: Practitioners use trance and dramatic initiations to seemingly become entities distinct from normal humans and thus more apparently capable of interacting with the invisible forces believed to oversee important outcomes. Influential cognitive and anthropological scientists, such as Pascal Boyer and Nicholas Humphrey, have endorsed Singh's approach, although other researchers have criticized Singh's dismissal of individual- and group-level benefits.\nEcological approaches and systems theory.\nGerardo Reichel-Dolmatoff relates these concepts to developments in the ways that modern science (systems theory, ecology, new approaches in anthropology and archeology) treats causality in a less linear fashion. He also suggests a cooperation of modern science and Indigenous lore.\nHistorical origins.\nShamanic practices may originate as early as the Paleolithic, predating all organized religions, and certainly as early as the Neolithic period. The earliest alleged burial of a shaman (and by extension the earliest supposed evidence of shamans and shamanic practices) dates back to the early Upper Paleolithic era (c. 30,000 BP) in what is now the Czech Republic.\nSanskrit scholar and comparative mythologist Michael Witzel proposes that all of the world's mythologies, and also the concepts and practices of shamans, can be traced to the migrations of two prehistoric populations: the \"Gondwana\" type (of circa 65,000 years ago) and the \"Laurasian\" type (of circa 40,000 years ago).\nIn November 2008, researchers from the Hebrew University of Jerusalem announced the discovery of a 12,000-year-old site in Israel that is perceived as one of the earliest-known shaman burials. The elderly woman had been arranged on her side, with her legs apart and folded inward at the knee. Ten large stones were placed on the head, pelvis, and arms. Among her unusual grave goods were 50 complete tortoise shells, a human foot, and certain body parts from animals such as a cow tail and eagle wings. Other animal remains came from a boar, leopard, and two martens. \"It seems that the woman \u2026 was perceived as being in a close relationship with these animal spirits\", researchers noted. The grave was one of at least 28 graves at the site, located in a cave in lower Galilee and belonging to the Natufian culture, but is said to be unlike any other among the Epipaleolithic Natufians or in the Paleolithic period.\nSemiotic and hermeneutic approaches.\nA debated etymology of the word \"shaman\" is \"one who knows\", implying, among other things, that the shaman is an expert in keeping together the multiple codes of the society, and that to be effective, shamans must maintain a comprehensive view in their mind which gives them certainty of knowledge. According to this view, the shaman uses (and the audience understands) multiple codes, expressing meanings in many ways: verbally, musically, artistically, and in dance. Meanings may be manifested in objects such as amulets. If the shaman knows the culture of their community well, and acts accordingly, their audience will know the used symbols and meanings and therefore trust the shamanic worker.\nThere are also semiotic, theoretical approaches to shamanism, and examples of \"mutually opposing symbols\" in academic studies of Siberian lore, distinguishing a \"white\" shaman who contacts sky spirits for good aims by day, from a \"black\" shaman who contacts evil spirits for bad aims by night. (Series of such opposing symbols referred to a world-view behind them. Analogously to the way grammar arranges words to express meanings and convey a world, also this formed a cognitive map). Shaman's lore is rooted in the folklore of the community, which provides a \"mythological mental map\". Juha Pentik\u00e4inen uses the concept \"grammar of mind\".\nArmin Geertz coined and introduced the hermeneutics, or \"ethnohermeneutics\", interpretation. Hopp\u00e1l extended the term to include not only the interpretation of oral and written texts, but that of \"visual texts as well (including motions, gestures and more complex rituals, and ceremonies performed, for instance, by shamans)\". Revealing the animistic views in shamanism, but also their relevance to the contemporary world, where ecological problems have validated paradigms of balance and protection.\nMedical anthropology approaches.\nIn many societies where shamanism is practiced, the understanding and treatment of illness are closely tied to social and cultural processes. Disease is often seen not just as a biological condition but as a disruption in the balance of spiritual and social relationships. The concept of the body in these contexts is multifaceted, encompassing physical, social, and cultural dimensions. Anthropologists Nancy Scheper-Hughes and Margaret Lock expand on this by introducing the idea of \"the three bodies\": the \"individual body\", relating to personal health experiences; the \"social body\", connecting health to social and cultural values; and the \"body politic\", reflecting the influence of power structures on health outcomes.\nAccording to anthropologist Donald Joralemon, the practice of medicine is inherently a social process, both in shamanistic societies and contemporary biomedicine. Joralemon argues that healing rituals, diagnoses, and treatments are deeply embedded in the cultural norms and social expectations of a community. This is particularly evident in shamanism, where the shaman addresses not only physical symptoms but also the spiritual and communal aspects of illness. The shaman's role is to restore harmony within the individual and the community, reinforcing the social bonds believed to influence health. Joralemon emphasizes that in both traditional and modern medical practices, disease is not merely a biological fact but a social phenomenon, shaped by the cultural and societal contexts in which it occurs .\nWhere a Shaman is present within a community - the group determines whether an individual is true Shaman or not. The group also determines whether an individual is sick and doomed by sorcery, this is where a Shaman is given the role to dispel an illness. The Shaman does not become a great Shaman because they cure a person, it is because they are known by the group as great Shamans. Community members known as dreamers also listen in on private conversations to convey an individual's known sickness.\nAccording to Vine DeLoria, the American Indian shaman who couldn't heal, weren't the great ones: a \"healer\" is a \"medicine\" person, &amp; that is a cut above a mere shaman.\nDecline and revitalization and tradition-preserving movements.\nTraditional, Indigenous shamanism is believed to be declining around the world. Whalers who frequently interacted with Inuit groups are one source of this decline in that region. In many areas, former shamans ceased to fulfill the functions in the community they used to, as they felt mocked by their own community, or regarded their own past as deprecated and were unwilling to talk about it to ethnographers. Vine DeLoria noted that in the Americas, the Whites wouldn't call shaman either shaman or medicine-men/people ( back then, the term was sexist ), they would call them, instead, the derogatory \"jugglers\", asserting that they were just fakers, even when they couldn't fathom how any of their work that they had just seen, could possibly have been faked.\nBesides personal communications of former shamans, folklore texts may narrate directly about a deterioration process. For example, a Buryat epic text details the wonderful deeds of the ancient \"first shaman\" Kara-G\u00fcrg\u00e4n: he could even compete with God, create life, steal back the soul of the sick from God without his consent. A subsequent text laments that shamans of older times were stronger, possessing capabilities like omnividence, fortune-telling even for decades in the future, moving as fast as a bullet.\nIn most affected areas, shamanic practices ceased to exist, with authentic shamans dying and their personal experiences dying with them. The loss of memories is not always lessened by the fact the shaman is not always the only person in a community who knows the beliefs and motives related to the local shaman-hood. Although the shaman is often believed and trusted precisely because they \"accommodate\" to the beliefs of the community, several parts of the knowledge related to the local shamanhood consist of personal experiences of the shaman, or root in their family life, thus, those are lost with their death. Besides that, in many cultures, the entire traditional belief system has become endangered (often together with a partial or total language shift), with the other people of the community remembering the associated beliefs and practices (or the language at all) grew old or died, many folklore memories, songs, and texts were forgotten\u2014which may threaten even such peoples who could preserve their isolation until the middle of the 20th century, like the Nganasan.\nSome areas could enjoy a prolonged resistance due to their remoteness.\nAfter exemplifying the general decline even in the most remote areas, there are revitalizations or tradition-preserving efforts as a response. Besides collecting the memories, there are also tradition-preserving and even revitalization efforts, led by authentic former shamans (for example among the Sakha people and Tuvans).\nNative Americans in the United States do not call their traditional spiritual ways \"shamanism\". However, according to Richard L. Allen, research and policy analyst for the Cherokee Nation, they are regularly overwhelmed with inquiries by and about fraudulent shamans, (aka \"plastic medicine people\"). He adds, \"One may assume that anyone claiming to be a Cherokee 'shaman, spiritual healer, or pipe-carrier', is equivalent to a modern day medicine show and snake-oil vendor.\"\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "26862", "revid": "4796325", "url": "https://en.wikipedia.org/wiki?curid=26862", "title": "Sexology", "text": "Scientific study of human sexuality\nSexology is the scientific study of human sexuality, including human sexual interests, behaviors, and functions. The term \"sexology\" does not generally refer to the non-scientific study of sexuality, such as social criticism.\nSexologists apply tools from several academic fields, such as anthropology, biology, medicine, psychology, epidemiology, sociology, and criminology. Topics of study include sexual development (puberty), sexual orientation, gender identity, sexual relationships, sexual activities, paraphilias, and atypical sexual interests. It also includes the study of sexuality across the lifespan, including child sexuality, puberty, adolescent sexuality, and sexuality among the elderly. Sexology also spans sexuality among those with mental or physical disabilities. The sexological study of sexual dysfunctions and disorders, including erectile dysfunction and anorgasmia, are also mainstays.\nHistory.\nEarly.\nSex manuals have existed for centuries, such as Ovid's , the \"Kama Sutra\" of Vatsyayana, the \"Ananga Ranga\", and \"The Perfumed Garden for the Soul's Recreation\". (\"Prostitution in the City of Paris\"), an early 1830s study on 3,558 registered prostitutes in Paris, written by Alexander Jean Baptiste Parent-Duchatelet (published in 1837, a year after he died), has been called the first work of modern sex research. In England, James Graham was an early sexologist who lectured on topics such as the process of sex and conception.\nThe scientific study of sexual behavior in human beings began in the 19th century with Heinrich Kaan, whose book \"Psychopathia Sexualis\" (1844) Michel Foucault describes as marking \"the date of birth, or in any case the date of the emergence of sexuality and sexual aberrations in the psychiatric field.\" The term \"sexology\" was coined for the first time in the United States by Elizabeth Osgood Goodrich Willard in 1867. Roughly simultaneously a group of homophile activists, not yet identifying themselves as sexologists, were responding to shifts in Europe's national borders, a crisis that brought into conflict laws that were sexually liberal and laws that criminalized behaviors such as homosexual activity.\nVictorian era to WWII.\nDespite the prevailing social attitude of sexual repression in the Victorian era, the movement towards sexual emancipation began towards the end of the nineteenth century in England and Germany. In 1886, Richard Freiherr von Krafft-Ebing published \"Psychopathia Sexualis.\" That work is considered as having established sexology as a scientific discipline.\nIn England, the founding father of sexology was the doctor and sexologist Havelock Ellis who challenged the sexual taboos of his era regarding masturbation and homosexuality and revolutionized the conception of sex in his time. His seminal work was the 1897 \"Sexual Inversion\", which describes the sexual relations of homosexual males, including men with boys. Ellis wrote the first objective study of homosexuality (the term was coined by Karl-Maria Kertbeny), as he did not characterize it as a disease, immoral, or a crime. The work assumes that same-sex love transcended age taboos as well as gender taboos. Seven of his twenty-one case studies are of inter-generational relationships. He also developed other important psychological concepts, such as autoerotism and narcissism, both of which were later developed further by Sigmund Freud.\nEllis pioneered transgender phenomena alongside the German Magnus Hirschfeld. He established it as new category that was separate and distinct from homosexuality. Aware of Hirschfeld's studies of transvestism, but disagreeing with his terminology, in 1913 Ellis proposed the term \"sexo-aesthetic inversion\" to describe the phenomenon.\nIn 1908, the first scholarly journal of the field, \"Journal of Sexology\" (\"Zeitschrift f\u00fcr Sexualwissenschaft\"), began publication and was published monthly for one year. Those issues contained articles by Freud, Alfred Adler, and Wilhelm Stekel. In 1913, the first academic association was founded: the \"Society for Sexology\".\nFreud developed a theory of sexuality. These stages of development include: Oral, Anal, Phallic, Latency and Genital. These stages run from infancy to puberty and onwards. based on his studies of his clients, between the late 19th and early 20th centuries. Wilhelm Reich and Otto Gross were disciples of Freud, but rejected his theories because of their emphasis on the role of sexuality in the revolutionary struggle for the emancipation of mankind.\nPre-Nazi Germany, under the sexually liberal Napoleonic Code, organized and resisted the anti-sexual, Victorian cultural influences. The momentum from those groups led them to coordinate sex research across traditional academic disciplines, bringing Germany to the leadership of sexology. Physician Magnus Hirschfeld was an outspoken advocate for sexual minorities, founding the Scientific Humanitarian Committee, the first advocacy for homosexual and transgender rights.\nHirschfeld also set up the first Institut f\u00fcr Sexualwissenschaft (Institute for Sexology) in Berlin in 1919. Its library housed over 20,000 volumes, 35,000 photographs, a large collection of art and other objects. People from around Europe visited the institute to gain a clearer understanding of their sexuality and to be treated for their sexual concerns and dysfunctions.\nHirschfeld developed a system which identified numerous actual or hypothetical types of sexual intermediary between heterosexual male and female to represent the potential diversity of human sexuality, and is credited with identifying a group of people that today are referred to as transsexual or transgender as separate from the categories of homosexuality, he referred to these people as \"transvestiten\" (transvestites). Germany's dominance in sexual behavior research ended with the Nazi regime. The Institute and its library were destroyed by the Nazis less than three months after they took power, May 8, 1933. The institute was shut down and Hirschfeld's books were burned.\nOther sexologists in the early gay rights movement included Ernst Burchard and Benedict Friedlaender. Ernst Gr\u00e4fenberg, after whom the G-spot is named, published the initial research developing the intrauterine device (IUD).\nPost WWII.\nAfter World War II, sexology experienced a renaissance, both in the United States and Europe. Large scale studies of sexual behavior, sexual function, and sexual dysfunction gave rise to the development of sex therapy. Post-WWII sexology in the U.S. was influenced by the influx of European refugees escaping the Nazi regime and the popularity of the Kinsey studies. Until that time, American sexology consisted primarily of groups working to end prostitution and to educate youth about sexually transmitted infections. Alfred Kinsey founded the Institute for Sex Research at Indiana University at Bloomington in 1947. This is now called the Kinsey Institute for Research in Sex, Gender and Reproduction. He wrote in his 1948 book that more was scientifically known about the sexual behavior of farm animals than of humans.\nPsychologist and sexologist John Money developed theories on sexual identity and gender identity in the 1950s. His work, notably on the David Reimer case has since been regarded as controversial, even while the case was key to the development of treatment protocols for intersex infants and children.\nKurt Freund developed the penile plethysmograph in Czechoslovakia in the 1950s. The device was designed to provide an objective measurement of sexual arousal in males and is currently used in the assessment of pedophilia and hebephilia. This tool has since been used with sex offenders.\nIn 1966 and 1970, Masters and Johnson released their works \"Human Sexual Response\" and \"Human Sexual Inadequacy,\" respectively. Those volumes sold well, and they were founders of what became known as the Masters &amp; Johnson Institute in 1978.\nVern Bullough was a historian of sexology during this era, as well as being a researcher in the field.\nThe emergence of HIV/AIDS in the 1980s caused a dramatic shift in sexological research efforts towards understanding and controlling the spread of the disease.\n21st century.\nTechnological advances have permitted sexological questions to be addressed with studies using behavioral genetics, neuroimaging, and large-scale Internet-based surveys.\nSexology is a regulated profession in some jurisdictions. In Quebec, sexologists must be members of the Ordre professionnel des sexologues du Qu\u00e9bec. They are one of the professions eligible to receive psychotherapy permits from the Ordre des psychologues du Qu\u00e9bec.\nNotable contributors.\nThis is a list of sexologists and notable contributors to the field of sexology, by year of birth:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26865", "revid": "829949", "url": "https://en.wikipedia.org/wiki?curid=26865", "title": "List of leaders of the Soviet Union", "text": "During its 69-year history, the Soviet Union usually had a \"de facto\" leader who would not always necessarily be head of state or even head of government but almost always held office as Communist Party General Secretary. The office of the chairman of the Council of Ministers was comparable to a prime minister in the First World whereas the office of the chairman of the Presidium was comparable to a president. According to Marxist-Leninist ideology, the head of the Soviet state was a collegiate body of the vanguard party (as described in Lenin's \"What Is to Be Done?\").\nFollowing Joseph Stalin's consolidation of power in the late 1920s, the post of the general secretary of the Central Committee of the Communist Party became synonymous with leader of the Soviet Union, because the post controlled both the Communist Party and (via party membership) the Soviet government. Often the general secretary also held high positions in the government. Since the post of general secretary lacked clear guidelines of succession, the office's successor needed the support of the Political Bureau (Politburo), the Central Committee, or another government or party apparatus to consolidate power. The President of the Soviet Union, an office created in March 1990, replaced the general secretary as the highest Soviet political office.\nContemporaneously to the establishment of the office of the president, representatives of the Congress of People's Deputies voted to remove Article 6 from the Soviet constitution which stated that the Soviet Union was a one-party state controlled by the Communist Party which in turn played the leading role in society. This vote weakened the party and its hegemony over the Soviet Union and its people. Upon the departure of an incumbent president from office, the Vice President of the Soviet Union would assume the office, though the Soviet Union dissolved before this was actually tested. After the failed coup in August 1991, the vice president was replaced by an elected member of the State Council of the Soviet Union.\nSummary.\nLenin was elected chairman of the Council of People's Commissars of the Soviet Union (Sovnarkom) on 30 December 1922 by the Congress of Soviets. At the age of 53, his health declined from the effects of two bullet wounds, later aggravated by three strokes which culminated with his death in 1924. Irrespective of his health status in his final days, Lenin was already losing much of his power to Joseph Stalin. Alexei Rykov succeeded Lenin as chairman of the Sovnarkom, and although he was \"de jure\" the most powerful person in the country, in fact, all power was concentrated in the hands of the \"troika\" \u2013 the union of three influential party figures: Grigory Zinoviev, Joseph Stalin, and Lev Kamenev. Stalin continued to increase his influence in the party, and by the end of the 1920s, he became the sole dictator of the USSR, defeating all his political opponents. The post of general secretary of the party, which was held by Stalin, became the most important post in the Soviet hierarchy.\nStalin's early policies pushed for rapid industrialisation, nationalisation of private industry and the collectivisation of private plots created under Lenin's New Economic Policy. As leader of the Politburo, Stalin consolidated near-absolute power by 1938 after the Great Purge, a series of campaigns of political murder, repression and persecution. On 22 June 1941 Nazi Germany invaded the Soviet Union, but by December the Soviet Army managed to stop the attack just shy of Moscow. On Stalin's orders, the Soviet Union launched a counter-attack on Nazi Germany, which finally succeeded in 1945. Stalin died in March 1953 and his death triggered a power struggle in which Nikita Khrushchev ultimately emerged victorious over Georgy Malenkov.\nKhrushchev denounced Stalin on two occasions, first in 1956 and then in 1962. His policy of de-Stalinisation earned him many enemies within the party, especially from old Stalinist appointees. Many saw this approach as destructive and destabilizing. A group known as Anti-Party Group tried to oust Khrushchev from office in 1957, but it failed. As Khrushchev grew older, his erratic behaviour became worse, usually making decisions without discussing or confirming them with the Politburo. Leonid Brezhnev, a close companion of Khrushchev, was elected the first secretary the same day of Khrushchev's removal from power. Alexei Kosygin became the new premier, and Anastas Mikoyan kept his office as chairman of the Presidium of the Supreme Soviet. On the orders of the Politburo, Mikoyan was forced to retire in 1965, and Nikolai Podgorny took over the office of chairman of the Presidium. The Soviet Union in the post-Khrushchev 1960s was governed by a collective leadership. Henry Kissinger, the American National Security Advisor, mistakenly believed that Kosygin was the leader of the Soviet Union and that he was at the helm of Soviet foreign policy because he represented the Soviet Union at the 1967 Glassboro Summit Conference. The \"Era of Stagnation\", a derogatory term coined by Mikhail Gorbachev, was a period marked by low socio-economic efficiency in the country and a gerontocracy ruling the country. Yuri Andropov (aged 68 at the time) succeeded Brezhnev in his post as general secretary in 1982. In 1983, Andropov was hospitalized and rarely met up at work to chair the politburo meetings due to his declining health. Nikolai Tikhonov usually chaired the meetings in his place. Following Andropov's death fifteen months after his appointment, an even older leader, 72-year-old Konstantin Chernenko, was elected to the general secretariat. His rule lasted for little more than a year until his death thirteen months later on 10 March 1985.\nAt the age of 54, Mikhail Gorbachev was elected to the general secretariat by Politburo on 11 March 1985. In May 1985, Gorbachev publicly admitted the slowing down of the economic development and inadequate living standards, being the first Soviet leader to do so while also beginning a series of fundamental reforms. From 1986 to around 1988, he dismantled central planning, allowed state enterprises to set their own outputs, enabled private investment in businesses not previously permitted to be privately owned, and allowed foreign investment, among other measures. He also opened up the management of and decision-making within the Soviet Union and allowed greater public discussion and criticism, along with the warming of relationships with the West. These twin policies were known as \"perestroika\" (literally meaning \"reconstruction\", though it varies) and \"glasnost\" (\"openness\" and \"transparency\"), respectively. The dismantling of the principal defining features of Soviet communism in 1988 and 1989 in the Soviet Union led to the unintended consequence of the Soviet Union breaking up after the failed August 1991 coup led by Gennady Yanayev.\nList of leaders.\nThe following list includes those who held the top leadership position of the Soviet Union from its founding in 1922 until its 1991 dissolution. \u2020 denotes leaders who died in office.\nList of troikas.\nOver the course of the Soviet Union's existence, there were four intervals where the country was ruled not by one figure but a troika (i.e.\"triumvirate\") comprising three leading figures within the Politburo. Such instances included: (1) the 2- to 3-year period between Lenin's incapacitation and the rise of Joseph Stalin; (2) the 3 months immediately following Stalin's death; (3) the years between Nikita Khrushchev's fall and Leonid Brezhnev's consolidation of power; and (4) the ailing Konstantin Chernenko's tenure as \"de jure\" leader of the Soviet Union.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "26866", "revid": "39457116", "url": "https://en.wikipedia.org/wiki?curid=26866", "title": "Seafood", "text": "Seafood is any form of sea life regarded as food by humans, prominently including fish and shellfish. Shellfish include various species of molluscs (e.g., bivalve molluscs such as clams, oysters, and mussels, and cephalopods such as octopus and squid), crustaceans (e.g. shrimp, crabs, and lobster), and echinoderms (e.g. sea cucumbers and sea urchins). Historically, marine mammals such as cetaceans (whales and dolphins) as well as seals have been eaten as food, though that happens to a lesser extent in modern times. Edible sea plants such as some seaweeds and microalgae are widely eaten as around the world, especially in Asia.\nSeafood is an important source of (animal) protein in many diets around the world, especially in coastal areas. Semi-vegetarians who consume seafood as the only source of meat are said to adhere to pescetarianism.\nThe harvesting of wild seafood is usually known as fishing or hunting, while the cultivation and farming of seafood is known as aquaculture and fish farming (in the case of fish). Most of the seafood harvest is consumed by humans, but a significant proportion is used as fish food to farm other fish or rear farm animals. Some seafoods (i.e. kelp) are used as food for other plants (a fertilizer). In these ways, seafoods are used to produce further food for human consumption. Also, products such as fish oil, spirulina tablets, fish collagen, and chitin are made from seafoods. Some seafood is fed to aquarium fish, or used to feed domestic pets such as cats. A small proportion is used in medicine or is used industrially for nonfood purposes (e.g. leather).\nHistory.\nThe harvesting, processing, and consuming of seafoods are ancient practices with archaeological evidence dating back well into the Paleolithic. Findings in a sea cave at Pinnacle Point in South Africa indicate \"Homo sapiens\" (modern humans) harvested marine life as early as 165,000 years ago, while the Neanderthals, an extinct human species contemporary with early \"Homo sapiens\", appear to have been eating seafood at sites along the Mediterranean coast beginning around the same time. Isotopic analysis of the skeletal remains of Tianyuan man, a 40,000-year-old anatomically modern human from eastern Asia, has shown that he regularly consumed freshwater fish. Archaeology features such as shell middens, discarded fish bones, and cave paintings show that sea foods were important for survival and consumed in significant quantities. During this period, most people lived a hunter-gatherer lifestyle and were, of necessity, constantly on the move. However, early examples of permanent settlements (though not necessarily permanently occupied), such as those at Lepenski Vir, were almost always associated with fishing as a major source of food.\nThe ancient river Nile was full of fish; fresh and dried fish were a staple food for much of the population. The Egyptians had implements and methods for fishing and these are illustrated in tomb scenes, drawings, and papyrus documents. Some representations hint at fishing being pursued as a pastime.\nFishing scenes are rarely represented in ancient Greek culture, a reflection of the low social status of fishing. However, Oppian of Corycus, a Greek author wrote a major treatise on sea fishing, the \"Halieulica\" or \"Halieutika\", composed between 177 and 180. This is the earliest such work to have survived to the modern day. The consumption of fish varied by the wealth and location of the household. In the Greek islands and on the coast, fresh fish and seafood (squid, octopus, and shellfish) were common. They were eaten locally but more often transported inland. Sardines and anchovies were regular fare for the citizens of Athens. They were sometimes sold fresh, but more frequently salted. A stele of the late 3rd century BCE from the small Boeotian city of Akraiphia, on Lake Copais, provides us with a list of fish prices. The cheapest was \"skaren\" (probably parrotfish) whereas Atlantic bluefin tuna was three times as expensive. Common salt water fish were yellowfin tuna, red mullet, ray, swordfish, or sturgeon, a delicacy that was eaten salted. Lake Copais itself was famous in all of Greece for its eels, celebrated by the hero of \"The Acharnians\". Other freshwater fish were pike fish, carp, and the less appreciated catfish.\nPictorial evidence of Roman fishing comes from mosaics. At a certain time, the goatfish was considered the epitome of luxury, above all because its scales exhibit a bright red colour when it dies out of water. For this reason, these fish were occasionally allowed to die slowly at the table. There even was a recipe where this would take place \"in Garo\", in the sauce. At the beginning of the Imperial era, however, this custom suddenly came to an end, which is why \"mullus\" in the feast of Trimalchio (see \"the Satyricon\") could be shown as a characteristic of the \"parvenu\", who bores his guests with an unfashionable display of dying fish.\nIn medieval times, seafood was less prestigious than other animal meats, and was often seen as merely an alternative to meat on fast days. Still, seafood was the mainstay of many coastal populations. Kippers made from herring caught in the North Sea could be found in markets as far away as Constantinople. While large quantities of fish were eaten fresh, a large proportion was salted, dried, and, to a lesser extent, smoked. Stockfish - cod that was split down the middle, fixed to a pole, and dried - was very common, though preparation could be time-consuming, and meant beating the dried fish with a mallet before soaking it in water. A wide range of mollusks (including oysters, mussels and scallops) were eaten by coastal and river-dwelling populations, and freshwater crayfish were seen as a desirable alternative to meat during fish days. Compared to meat, fish was much more expensive for inland populations, especially in Central Europe, and therefore not an option for most.\nModern knowledge of the reproductive cycles of aquatic species has led to the development of hatcheries and improved techniques of fish farming and aquaculture. A better understanding of the hazards of eating raw and undercooked fish and shellfish has led to improved preservation methods and processing.\nTypes of seafood.\nThe following table is based on the ISSCAAP classification (International Standard Statistical Classification of Aquatic Animals and Plants) used by the FAO to collect and compile fishery statistics. The production figures have been extracted from the FAO FishStat database, and include both capture from wild fisheries and aquaculture production.\nProcessing.\nFish is a highly perishable product: the \"fishy\" smell of dead fish is due to the breakdown of amino acids into biogenic amines and ammonia.\nLive food fish are often transported in tanks at high expense for an international market that prefers its seafood killed immediately before it is cooked. Delivery of live fish without water is also being explored. While some seafood restaurants keep live fish in aquaria for display purposes or cultural beliefs, the majority of live fish are kept for dining customers. The live food fish trade in Hong Kong, for example, is estimated to have driven imports of live food fish to more than 15,000 tonnes in 2000. Worldwide sales that year were estimated at US$400\u00a0million, according to the World Resources Institute.\nIf the cool chain has not been adhered to correctly, food products generally decay and become harmful before the validity date printed on the package. As the potential harm for a consumer when eating rotten fish is much larger than for example with dairy products, the U.S. Food and Drug Administration (FDA) has introduced regulation in the USA requiring the use of a time temperature indicator on certain fresh chilled seafood products.\nBecause fresh fish is highly perishable, it must be eaten promptly or discarded; it can be kept for only a short time. In many countries, fresh fish are filleted and displayed for sale on a bed of crushed ice or refrigerated. Fresh fish is most commonly found near bodies of water, but the advent of refrigerated train and truck transportation has made fresh fish more widely available inland.\nLong term preservation of fish is accomplished in a variety of ways. The oldest and still most widely used techniques are drying and salting. Desiccation (complete drying) is commonly used to preserve fish such as cod. Partial drying and salting are popular for the preservation of fish like herring and mackerel. Fish such as salmon, tuna, and herring are cooked and canned. Most fish are filleted before canning, but some small fish (e.g. sardines) are only decapitated and gutted before canning.\nConsumption.\nSeafood is consumed all over the world; it provides the world's prime source of high-quality protein: 14\u201316% of the animal protein consumed worldwide, with over one billion people reliant on seafood as their primary source of animal protein. Fish is among the most common food allergens.\nSince 1960, annual global seafood consumption has more than doubled to over 20\u00a0kg per capita. Among the top consumers are Korea (78.5\u00a0kg per head), Norway (66.6\u00a0kg) and Portugal (61.5\u00a0kg).\nThe UK Food Standards Agency recommends that at least two portions of seafood should be consumed each week, one of which should be oil-rich. There are over 100 different types of seafood available around the coast of the UK.\nOil-rich fish such as mackerel or herring are rich in long-chain omega-3 oils. These oils are found in every cell of the human body, and are required for human biological functions such as brain functionality.\nWhitefish such as haddock and cod are very low in fat and calories which, combined with oily fish rich in omega-3 such as mackerel, sardines, fresh tuna, salmon and trout, can help to protect against coronary heart disease, as well as helping to develop strong bones and teeth.\nShellfish are particularly rich in zinc, which is essential for healthy skin and muscles as well as fertility. Casanova reputedly ate 50 oysters a day.\nTexture and taste.\nOver 33,000 species of fish and many more marine invertebrate species have been identified. Bromophenols, which are produced by marine algae, give marine animals an odor and taste that is absent from freshwater fish and invertebrates. Also, a chemical substance called dimethylsulfoniopropionate (DMSP) that is found in red and green algae is transferred into animals in the marine food chain. When broken down, dimethyl sulfide (DMS) is produced, and is often released during food preparation when fresh fish and shellfish are heated. In small quantities it creates a specific smell one associates with the ocean, but in larger quantities gives the impression of rotten seaweed and old fish. Another molecule known as TMAO occurs in fishes and gives them a distinct smell. It also exists in freshwater species, but becomes more numerous in the cells of an animal the deeper it lives, so fish from the deeper parts of the ocean have a stronger taste than species that live in shallow water. Eggs from seaweed contain sex pheromones called dictyopterenes, which are meant to attract the sperm. These pheromones are also found in edible seaweeds, which contributes to their aroma.\nHealth benefits.\nThere is broad scientific consensus that docosahexaenoic acid (DHA) and eicosapentaenoic acid (EPA) found in seafood are beneficial to neurodevelopment and cognition, especially at young ages. The United Nations Food and Agriculture Organization has described fish as \"nature's super food.\" Seafood consumption is associated with improved neurologic development during pregnancy and early childhood and is more tenuously linked to reduced mortality from coronary heart disease.\nFish consumption has been associated with a decreased risk of dementia, lung cancer and stroke. A 2020 umbrella review concluded that fish consumption reduces all-cause mortality, cancer, cardiovascular disease, stroke and other outcomes. The review suggested that two to four servings per week is generally safe. However, two other recent umbrella reviews have found no statistically significant associations between fish consumption and cancer risks and have cautioned researchers when it comes to interpreting reported associations between fish consumption and cancer risks because the quality of evidence is very low.\nThe parts of fish containing essential fats and micronutrients, often cited as primary health benefits of eating seafood, are frequently discarded in the developed world. Micronutrients including calcium, potassium, selenium, zinc, and iodine are found in their highest concentrations in the head, intestines, bones, and scales.\nGovernment recommendations promote moderate consumption of fish. The US Food and Drug Administration recommends moderate (4 oz for children and 8\u201312 oz for adults, weekly) consumption of fish as part of a healthy and balanced diet. The UK National Health Service gives similar advice, recommending at least 2 portions (about 10 oz) of fish weekly. The Chinese National Health Commission recommends slightly more, advising 10\u201320 oz of fish weekly.\nHealth hazards.\nThere are numerous factors to consider when evaluating health hazards in seafood. These concerns include marine toxins, microbes, foodborne illness, radionuclide contamination, and man-made pollutants. Shellfish are among the more common food allergens. Most of these dangers can be mitigated or avoided with accurate knowledge of when and where seafood is caught. However, consumers have limited access to relevant and actionable information in this regard and the seafood industry's systemic problems with mislabelling make decisions about what is safe even more fraught.\nCiguatera fish poisoning (CFP) is an illness resulting from consuming toxins produced by dinoflagellates which bioaccumulate in the liver, roe, head, and intestines of reef fish. It is the most common disease associated with seafood consumption and poses the greatest risk to consumers. The population of plankton that produces these toxins varies significantly over time and location, as seen in red tides. Evaluating the risk of ciguatera in any given fish requires specific knowledge of its origin and life history, information that is often inaccurate or unavailable. While ciguatera is relatively widespread compared to other seafood-related health hazards (up to 50,000 people suffer from ciguatera every year), mortality is very low.\nScombroid food poisoning, is also a seafood illness. It is typically caused by eating fish high in histamine from being stored or processed improperly.\nFish and shellfish have a natural tendency to concentrate inorganic and organic toxins and pollutants in their bodies, including methylmercury, a highly toxic organic compound of mercury, polychlorinated biphenyls (PCBs), and microplastics. Species of fish that are high on the food chain, such as shark, swordfish, king mackerel, albacore tuna, and tilefish contain higher concentrations of these bioaccumulates. This is because bioaccumulates are stored in the muscle tissues of fish, and when a predatory fish eats another fish, it assumes the entire body burden of bioaccumulates in the consumed fish. Thus species that are high on the food chain amass body burdens of bioaccumulates that can be ten times higher than the species they consume. This process is called biomagnification.\nMan-made disasters can cause localized hazards in seafood which may spread widely via piscine food chains. The first occurrence of widespread mercury poisoning in humans occurred this way in the 1950s in Minamata, Japan. Wastewater from a nearby chemical factory released methylmercury that accumulated in fish which were consumed by humans. Severe mercury poisoning is now known as Minamata disease. The 2011 Fukushima Daiichi Nuclear Power Plant disaster and 1947\u20131991 Marshall Islands nuclear bomb testing led to dangerous radionuclide contamination of local sea life which, in the latter case, remained as of 2008.\nA widely cited study in JAMA which synthesized government and MEDLINE reports, and meta-analyses to evaluate risks from methylmercury, dioxins, and polychlorinated biphenyls to cardiovascular health and links between fish consumption and neurologic outcomes concluded that: \"The benefits of modest fish consumption (1-2 servings/wk) outweigh the risks among adults and, excepting a few selected fish species, among women of childbearing age. Avoidance of modest fish consumption due to confusion regarding risks and benefits could result in thousands of excess CHD [congenital heart disease] deaths annually and suboptimal neurodevelopment in children.\" \nMislabelling.\nDue to the wide array of options in the seafood marketplace, seafood is far more susceptible to mislabeling than terrestrial food. There are more than 1,700 species of seafood in the United States' consumer marketplace, 80 \u2013 90% of which are imported and less than 1% of which are tested for fraud. However, more recent research into seafood imports and consumption patterns among consumers in the United States suggests that 35%-38% of seafood products are of domestic origin. consumption suggests Estimates of mislabelled seafood in the United States range from 33% in general up to 86% for particular species.\nByzantine supply chains, frequent bycatch, brand naming, species substitution, and inaccurate ecolabels all contribute to confusion for the consumer. A 2013 study by Oceana found that one third of seafood sampled from the United States was incorrectly labeled. Snapper and tuna were particularly susceptible to mislabelling, and seafood substitution was the most common type of fraud. Another type of mislabelling is short-weighting, where practices such as overglasing or soaking can misleadingly increase the apparent weight of the fish. For supermarket shoppers, many seafood products are unrecognisable fillets. Without sophisticated DNA testing, there is no foolproof method to identify a fish species without their head, skin, and fins. This creates easy opportunities to substitute cheap products for expensive ones, a form of economic fraud.\nBeyond financial concerns, significant health risks arise from hidden pollutants and marine toxins in an already fraught marketplace. Seafood fraud has led to widespread keriorrhea due to mislabeled escolar, mercury poisoning from products marketed as safe for pregnant women, and hospitalisation and neurological damage due to mislabeled pufferfish. For example, a 2014 study published in PLOS One found that 15% of MSC certified Patagonian toothfish originated from uncertified and mercury polluted fisheries. These fishery-stock substitutions had 100% more mercury than their genuine counterparts, \"vastly exceeding\" limits in Canada, New Zealand, and Australia.\nSustainability.\nResearch into population trends of various species of seafood is pointing to a global collapse of seafood species by 2048. Such a collapse would occur due to pollution and overfishing, threatening oceanic ecosystems, according to some researchers.\nA major international scientific study released in November 2006 in the journal \"Science\" found that about one-third of all fishing stocks worldwide have collapsed (with a collapse being defined as a decline to less than 10% of their maximum observed abundance), and that if current trends continue all fish stocks worldwide will collapse within fifty years. In July 2009, Boris Worm of Dalhousie University, the author of the November 2006 study in \"Science\", co-authored an update on the state of the world's fisheries with one of the original study's critics, Ray Hilborn of the University of Washington at Seattle. The new study found that through good fisheries management techniques even depleted fish stocks can be revived and made commercially viable again. An analysis published in August 2020 indicates that seafood could theoretically increase sustainably by 36\u201374% by 2050 compared to current yields and that whether or not these production potentials are realised sustainably depends on several factors \"such as policy reforms, technological innovation, and the extent of future shifts in demand\".\nThe FAO State of World Fisheries and Aquaculture 2004 report estimates that in 2003, of the main fish stocks or groups of resources for which assessment information is available, \"approximately one-quarter were overexploited, depleted or recovering from depletion (16%, 7% and 1% respectively) and needed rebuilding.\"\nThe National Fisheries Institute, a trade advocacy group representing the United States seafood industry, disagree. They claim that currently observed declines in fish populations are due to natural fluctuations and that enhanced technologies will eventually alleviate whatever impact humanity is having on oceanic life.\nIn religion.\nFor the most part Islamic dietary laws allow the eating of seafood, though the Hanbali forbid eels, the Shafi forbid frogs and crocodiles, and the Hanafi forbid bottom feeders such as shellfish and carp. The Jewish laws of Kashrut forbid the eating of shellfish and eels. In the Old Testament, the Mosaic covenant allowed the Israelites to eat Finfish, but shellfish and eels were an abomination and not allowed.\nPescatarianism was widespread in the early Christian Church, among both the clergy and laity. In ancient and medieval times, the Catholic Church forbade the practice of eating meat, eggs and dairy products during Lent. Thomas Aquinas argued that these \"afford greater pleasure as food [than fish], and greater nourishment to the human body, so that from their consumption there results in a greater surplus available for seminal matter, which when abundant becomes a great incentive to lust\". In the United States, the Catholic practice of abstaining from meat on Fridays during Lent has popularised the Friday fish fry. In predominantly Roman Catholic areas, restaurants may adjust their menus during Lent by adding seafood items to the menu.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "26869", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=26869", "title": "Standards and Units", "text": ""}
{"id": "26870", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=26870", "title": "Soccer", "text": ""}
{"id": "26872", "revid": "12331483", "url": "https://en.wikipedia.org/wiki?curid=26872", "title": "SI base unit", "text": "One of the seven units of measurement that define the metric system\nThe SI base units are the standard units of measurement defined by the International System of Units (SI) for the seven base quantities of what is now known as the International System of Quantities: they are notably a basic set from which all other SI units can be derived. The units and their physical quantities are the second for time, the metre (sometimes spelled meter) for length or distance, the kilogram for mass, the ampere for electric current, the kelvin for thermodynamic temperature, the mole for amount of substance, and the candela for luminous intensity. The SI base units are a fundamental part of modern metrology, and thus part of the foundation of modern science and technology.\nThe SI base units form a set of mutually independent dimensions as required by dimensional analysis commonly employed in science and technology.\nThe names and symbols of SI base units are written in lowercase, except the symbols of those named after a person, which are written with an initial capital letter. For example, the \"metre\" has the symbol m, but the \"kelvin\" has symbol K, because it is named after Lord Kelvin and the \"ampere\" with symbol A is named after Andr\u00e9-Marie Amp\u00e8re.\nDefinitions.\nOn 20 May 2019, as the final act of the 2019 revision of the SI, the BIPM officially introduced the following new definitions, replacing the preceding definitions of the SI base units.\n2019 revision of the SI.\nNew base unit definitions were adopted on 16 November 2018, and they became effective on 20 May 2019. The definitions of the base units have been modified several times since the Metre Convention in 1875, and new additions of base units have occurred. Since the redefinition of the metre in 1960, the kilogram had been the only base unit still defined directly in terms of a physical artefact, rather than a property of nature. This led to a number of the other SI base units being defined indirectly in terms of the mass of the same artefact; the mole, the ampere, and the candela were linked through their definitions to the mass of the International Prototype of the Kilogram, a roughly golfball-sized platinum\u2013iridium cylinder stored in a vault near Paris.\nIt has long been an objective in metrology to define the kilogram in terms of a fundamental constant, in the same way that the metre is now defined in terms of the speed of light. The 21st General Conference on Weights and Measures (CGPM, 1999) placed these efforts on an official footing, and recommended \"that national laboratories continue their efforts to refine experiments that link the unit of mass to fundamental or atomic constants with a view to a future redefinition of the kilogram\". Two possibilities attracted particular attention: the Planck constant and the Avogadro constant.\nIn 2005, the International Committee for Weights and Measures (CIPM) approved preparation of new definitions for the kilogram, the ampere, and the kelvin and it noted the possibility of a new definition of the mole based on the Avogadro constant. The 23rd CGPM (2007) decided to postpone any formal change until the next General Conference in 2011.\nIn a note to the CIPM in October 2009, Ian Mills, the President of the CIPM \"Consultative Committee \u2013 Units\" (CCU) catalogued the uncertainties of the fundamental constants of physics according to the current definitions and their values under the proposed new definition. He urged the CIPM to accept the proposed changes in the definition of the \"kilogram\", \"ampere\", \"kelvin\", and \"mole\" so that they are referenced to the values of the fundamental constants, namely the Planck constant (\"h\"), the elementary charge (\"e\"), the Boltzmann constant (\"k\"), and the Avogadro constant (\"N\"A). This approach was approved in 2018, only after measurements of these constants were achieved with sufficient accuracy.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26873", "revid": "50717717", "url": "https://en.wikipedia.org/wiki?curid=26873", "title": "Second", "text": "SI unit of time\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nThe second (symbol: s) is a unit of time derived from the division of the day first into 24 hours, then to 60 minutes, and lastly to 60 seconds each, for a total of 24 \u00d7 60 \u00d7 60 = 86,400 seconds per day. The current and formal definition in the International System of Units (SI) is more precise: The second [...] is defined by taking the fixed numerical value of the caesium frequency, \u0394\"\u03bd\"Cs, the unperturbed ground-state hyperfine transition frequency of the caesium 133 atom, to be when expressed in the unit Hz, which is equal to s\u22121.\nThat is saying that a second is the duration of time it takes for 9 192 631 770 of these transitions to occur. Atomic clocks count these transitions, with an uncertainty of 1 second in 300 million years.\nThis current definition was adopted in 1967 when it became feasible to define the second based on fundamental properties of nature with caesium clocks. As the speed of Earth's rotation varies and is slowing ever so slightly, a leap second is added at irregular intervals to civil time to keep clocks in sync with Earth's rotation.\nThe definition that is based on &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204486400 of a rotation of the earth is still used by the Universal Time 1 (UT1) system.\nEtymology.\n\"Minute\" comes from the Latin , meaning \"first small part\" i.e. first division of the hour\u00a0\u2013 dividing into sixty, and \"second\" comes from the , \"second small part\", dividing again into sixty.\nUses.\nAnalog clocks and watches often have sixty tick marks on their faces, representing seconds (and minutes), and a \"second hand\" to mark the passage of time in seconds. Digital clocks and watches often have a two-digit seconds counter.\nSI prefixes are frequently combined with the word \"second\" to denote subdivisions of the second: milliseconds (thousandths), microseconds (millionths), nanoseconds (billionths), and sometimes smaller units of a second. Multiples of seconds are usually counted in hours and minutes. Though SI prefixes may also be used to form multiples of the second such as kiloseconds (thousands of seconds), such units are rarely used in practice. An everyday experience with small fractions of a second is a 1-gigahertz microprocessor that has a cycle time of 1 nanosecond. Camera shutter speeds are often expressed in fractions of a second, such as &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204430 second or &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20441000 second.\nSexagesimal divisions of the day from a calendar based on astronomical observation have existed since the third millennium BC, though they were not seconds as we know them today. Small divisions of time could not be measured back then, so such divisions were mathematically derived. The first timekeepers that could count seconds accurately were pendulum clocks invented in the 17th century. Starting in the 1950s, atomic clocks became better timekeepers than Earth's rotation, and they continue to set the standard today.\nClocks and solar time.\nA mechanical clock, which does not depend on measuring the relative rotational position of the Earth, keeps uniform time called \"mean time\", within whatever accuracy is intrinsic to it. That means that every second, minute and every other division of time counted by the clock has the same duration as any other identical division of time. A sundial, which measures the relative position of the Sun in the sky called \"apparent time\", does not keep uniform time. The time kept by a sundial varies by time of year, meaning that seconds, minutes and every other division of time is a different duration at different times of the year. The time of day measured with mean time versus apparent time may differ by as much as 15 minutes, but a single day differs from the next by only a small amount; 15 minutes is a cumulative difference over a part of the year. The effect is due chiefly to the obliqueness of Earth's axis with respect to its orbit around the Sun.\nThe difference between apparent solar time and mean time was recognized by astronomers since antiquity, but prior to the invention of accurate mechanical clocks in the mid-17th century, sundials were the only reliable timepieces, and apparent solar time was the only generally accepted standard.\nEvents and units of time in seconds.\nFractions of a second are usually denoted in decimal notation, for example 2.01 seconds, or two and one hundredth seconds. Multiples of seconds are usually expressed as minutes and seconds, or hours, minutes and seconds of clock time, separated by colons, such as 11:23:24, or 45:23 (the latter notation can give rise to ambiguity, because the same notation is used to denote hours and minutes). It rarely makes sense to express longer periods of time like hours or days in seconds, because they are awkwardly large numbers. For the metric unit of second, there are decimal prefixes representing 10\u221230 to 1030 seconds.\nSome common units of time in seconds are: a minute is 60 seconds; an hour is 3,600 seconds; a day is 86,400 seconds; a week is 604,800 seconds; a year (other than leap years) is 31,536,000 seconds; and a (Gregorian) century averages 3,155,695,200 seconds; with all of the above excluding any possible leap seconds. In astronomy, a Julian year is precisely 31,557,600 seconds.\nSome common events in seconds are: a stone falls about 4.9 meters from rest in one second; a pendulum of length about one meter has a swing of one second, so pendulum clocks have pendulums about a meter long; the fastest human sprinters run 10 meters in a second; an ocean wave in deep water travels about 23 meters in one second; sound travels about 343 meters in one second in air; light takes 1.3 seconds to reach Earth from the surface of the Moon, a distance of 384,400 kilometers.\nOther units incorporating seconds.\nA second is directly part of other units, such as frequency measured in hertz (inverse seconds or s\u22121), speed in meters per second, and acceleration in meters per second squared. The metric system unit becquerel, a measure of radioactive decay, is measured in inverse seconds and higher powers of second are involved in derivatives of acceleration such as jerk. Though many derivative units for everyday things are reported in terms of larger units of time, not seconds, they are ultimately defined in terms of the SI second; this includes time expressed in hours and minutes, velocity of a car in kilometers per hour or miles per hour, kilowatt hours of electricity usage, and speed of a turntable in rotations per minute.\nMoreover, most other SI base units are defined by their relationship to the second: the meter is defined by setting the speed of light (in vacuum) to be 299 792 458\u00a0m/s, exactly; definitions of the SI base units kilogram, ampere, kelvin, and candela also depend on the second. The only base unit whose definition does not depend on the second is the mole, and only two of the 22 named derived units, radian and steradian, do not depend on the second either.\nTimekeeping standards.\nA set of atomic clocks throughout the world keeps time by consensus: the clocks \"vote\" on the correct time, and all voting clocks are steered to agree with the consensus, which is called International Atomic Time (TAI). TAI \"ticks\" atomic seconds.\nCivil time is defined to agree with the rotation of the Earth. The international standard for timekeeping is Coordinated Universal Time (UTC). This time scale \"ticks\" the same atomic seconds as TAI, but inserts or omits leap seconds as necessary to correct for variations in the rate of rotation of the Earth.\nA time scale in which the seconds are not exactly equal to atomic seconds is UT1, a form of universal time. UT1 is defined by the rotation of the Earth with respect to the Sun, and does not contain any leap seconds. UT1 always differs from UTC by less than a second.\nOptical lattice clock.\nWhile they are not yet part of any timekeeping standard, optical lattice clocks with frequencies in the visible light spectrum now exist and are the most accurate timekeepers of all. A strontium clock with frequency 430\u00a0THz, in the red range of visible light, during the 2010s held the accuracy record: it gains or loses less than a second in 15 billion years, which is longer than the estimated age of the universe. Such a clock can measure a change in its elevation of as little as 2\u00a0cm by the change in its rate due to gravitational time dilation.\nHistory of definition.\nThere have only ever been three definitions of the second: as a fraction of the day, as a fraction of an extrapolated year, and as the microwave frequency of a caesium atomic clock, which have each realized a sexagesimal division of the day from ancient astronomical calendars.\nSexagesimal divisions of calendar time and day.\nCivilizations in the classic period and earlier created divisions of the calendar as well as arcs using a sexagesimal system of counting, so at that time the second was a sexagesimal subdivision of the day (ancient second=), not of the hour like the modern second (=). Sundials and water clocks were among the earliest timekeeping devices, and units of time were measured in degrees of arc. Conceptual units of time smaller than realisable on sundials were also used.\nThere are references to \"second\" as part of a lunar month in the writings of natural philosophers of the Middle Ages, which were mathematical subdivisions that could not be measured mechanically.\nFraction of solar day.\nThe earliest mechanical clocks, which appeared starting in the 14th century, had displays that divided the hour into halves, thirds, quarters and sometimes even 12 parts, but never by 60. In fact, the hour was not commonly divided in 60 minutes as it was not uniform in duration. It was not practical for timekeepers to consider minutes until the first mechanical clocks that displayed minutes appeared near the end of the 16th century. Mechanical clocks kept the \"mean time\", as opposed to the \"apparent time\" displayed by sundials. \nBy that time, sexagesimal divisions of time were well established in Europe.\nThe earliest clocks to display seconds appeared during the last half of the 16th century. The second became accurately measurable with the development of mechanical clocks. The earliest spring-driven timepiece with a second hand that marked seconds is an unsigned clock depicting Orpheus in the Fremersdorf collection, dated between 1560 and During the third quarter of the 16th century, Taqi al-Din built a clock with marks every &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20445 minute.\nIn 1579, Jost B\u00fcrgi built a clock for William of Hesse that marked seconds. In 1581, Tycho Brahe redesigned clocks that had displayed only minutes at his observatory so they also displayed seconds, even though those seconds were not accurate. In 1587, Tycho complained that his four clocks disagreed by plus or minus four seconds.\nIn 1656, Dutch scientist Christiaan Huygens invented the first pendulum clock. It had a pendulum length of just under a meter, giving it a swing of one second, and an escapement that ticked every second. It was the first clock that could accurately keep time in seconds. By the 1730s, 80 years later, John Harrison's maritime chronometers could keep time accurate to within one second in 100 days.\nIn 1832, Gauss proposed using the second as the base unit of time in his millimeter\u2013milligram\u2013second system of units. The British Association for the Advancement of Science (BAAS) in 1862 stated that \"All men of science are agreed to use the second of mean solar time as the unit of time.\" BAAS formally proposed the CGS system in 1874, although this system was gradually replaced over the next 70 years by MKS units. Both the CGS and MKS systems used the same second as their base unit of time. MKS was adopted internationally during the 1940s, defining the second as &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204486,400 of a mean solar day.\nFraction of an ephemeris year.\nSometime in the late 1940s, quartz crystal oscillator clocks with an operating frequency of ~100\u00a0kHz advanced to keep time with accuracy better than 1 part in 108 over an operating period of a day. It became apparent that a consensus of such clocks kept better time than the rotation of the Earth. Metrologists also knew that Earth's orbit around the Sun (a year) was much more stable than Earth's rotation. This led to proposals as early as 1950 to define the second as a fraction of a year.\nThe Earth's motion was described in Newcomb's \"Tables of the Sun\" (1895), which provided a formula for estimating the motion of the Sun relative to the epoch 1900 based on astronomical observations made between 1750 and 1892. This resulted in adoption of an ephemeris time scale expressed in units of the sidereal year at that epoch by the IAU in 1952. This extrapolated timescale brings the observed positions of the celestial bodies into accord with Newtonian dynamical theories of their motion. In 1955, the tropical year, considered more fundamental than the sidereal year, was chosen by the IAU as the unit of time. The tropical year in the definition was not measured but calculated from a formula describing a mean tropical year that decreased linearly over time.\nIn 1956, the second was redefined in terms of a year relative to that epoch. The second was thus defined as \"the fraction &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204431,556,925.9747 of the tropical year for 1900 January 0 at 12 hours ephemeris time\". This definition was adopted as part of the International System of Units in 1960.\nAtomic definition.\nEven the best mechanical, electric motorized and quartz crystal-based clocks develop discrepancies from environmental conditions; far better for timekeeping is the natural and exact \"vibration\" in an energized atom. The frequency of vibration (i.e., radiation) is very specific depending on the type of atom and how it is excited. Since 1967, the second has been defined as exactly \"the duration of 9,192,631,770 periods of the radiation corresponding to the transition between the two hyperfine levels of the ground state of the caesium-133 atom\". This length of a second was selected to correspond exactly to the length of the ephemeris second previously defined. Atomic clocks use such a frequency to measure seconds by counting cycles per second at that frequency. Radiation of this kind is one of the most stable and reproducible phenomena of nature. The current generation of atomic clocks is accurate to within one second in a few hundred million years. Since 1967, atomic clocks based on atoms other than caesium-133 have been developed with increased precision by a factor of 100. Therefore a new definition of the second is planned.\nAtomic clocks now set the length of a second and the time standard for the world.\nFuture redefinition.\nIn 2022, the best realisation of the second is done with caesium primary standard clocks such as IT-CsF2, NIST-F2, NPL-CsF2, PTB-CSF2, SU\u2013CsFO2 or SYRTE-FO2. These clocks work by laser-cooling a cloud of Cs atoms to a microkelvin in a magneto-optic trap. These cold atoms are then launched vertically by laser light. The atoms then undergo Ramsey excitation in a microwave cavity. The fraction of excited atoms is then detected by laser beams. These clocks have systematic uncertainty, which is equivalent to 50 picoseconds per day. A system of several fountains worldwide contribute to International Atomic Time. These caesium clocks also underpin optical frequency measurements.\nOptical clocks are based on forbidden optical transitions in ions or atoms. They have frequencies around , with a natural linewidth formula_1 of typically 1\u00a0Hz, so the Q-factor is about , or even higher. They have better stabilities than microwave clocks, which means that they can facilitate evaluation of lower uncertainties. They also have better time resolution, which means the clock \"ticks\" faster. Optical clocks use either a single ion, or an optical lattice with \u2013 atoms.\nRydberg constant.\nA definition based on the Rydberg constant would involve fixing the value to a certain value: formula_2. The Rydberg constant describes the energy levels in a hydrogen atom with the nonrelativistic approximation formula_3.\nThe only viable way to fix the Rydberg constant involves trapping and cooling hydrogen. This is difficult because it is very light and the atoms move very fast, causing Doppler shifts. The radiation needed to cool the hydrogen \u2013 \u2013 is also difficult. Another hurdle involves improving the uncertainty in QED calculations, specifically the Lamb shift in the 1s-2s transition of the hydrogen atom.\nRequirements.\nA redefinition must include improved optical clock reliability. TAI must be contributed to by optical clocks before the BIPM affirms a redefinition. A consistent method of sending signals must be developed before the second is redefined, such as fiber-optics.\nSI multiples.\nSI prefixes are commonly used for times shorter than one second, but rarely for multiples of a second. Instead, certain non-SI units are permitted for use with SI: minutes, hours, days, and in astronomy Julian years.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26874", "revid": "38516105", "url": "https://en.wikipedia.org/wiki?curid=26874", "title": "Metric prefix", "text": "Order of magnitude indicator\nA metric prefix is a unit prefix that precedes a basic unit of measure to indicate a multiple or submultiple of the unit. All metric prefixes used today are decimal. Each prefix has a unique symbol that is prepended to any unit symbol. The prefix \"kilo\", for example, may be added to \"gram\" to indicate multiplication by one thousand: one kilogram is equal to one thousand grams. The prefix \"milli\", likewise, may be added to \"metre\" to indicate division by one thousand, so one millimetre is equal to one thousandth of a metre.\nDecimal multiplicative prefixes have been a feature of all forms of the metric system, with six of these dating back to the system's introduction in the 1790s. Metric prefixes have also been used with some non-metric units. The SI prefixes are metric prefixes that were standardised for use in the International System of Units (SI) by the International Bureau of Weights and Measures (BIPM) in resolutions dating from 1960 to 2022. Since 2009, they have formed part of the ISO/IEC 80000 standard. They are also used in the Unified Code for Units of Measure (UCUM).\nList of SI prefixes.\nThe BIPM specifies twenty-four prefixes for the International System of Units (SI).\nThe first uses of prefixes in SI date back to the definition of kilogram after the French Revolution at the end of the 18th century. Several more prefixes came into use, and were recognised by the 1947 IUPAC 14th International Conference of Chemistry before being officially adopted for the first time in 1960.\nThe prefixes that were most recently adopted are \"ronna\", \"quetta\", \"ronto\", and \"quecto\". These prefixes were adopted in 2022, after a proposal from British metrologist Richard J. C. Brown. Before 2022, Q/q and R/r were the only Latin letters available for abbreviations, with all other Latin letters being already used for other prefixes (a, c, d, E, f, G, h, k, M, m, n, P, p, T, Y, y, Z, z), already used for SI units (including: SI base units, SI derived units, Non-SI units mentioned in the SI) (A, B, C, d, F, g, H, h, J, K, L, m, N, S, s, T, t, u, V, W), or easily confused with mathematical operators (I and l are easily confused with 1, O and o are easily confused with 0, X and x are easily confused with \u00d7). The large prefixes \"ronna\" and \"quetta\" were adopted in anticipation of needs for use in data science, and because unofficial prefixes that did not meet SI requirements were already circulating. The small prefixes were also added, even without such a driver, in order to maintain symmetry.\nThe prefixes from \"peta\" to \"quetta\" are based on the Ancient Greek or Ancient Latin numbers from 5 to 10, referring to the 5th through 10th powers of 103. The initial letter \"h\" has been removed from some of these stems and the initial letters \"z\", \"y\", \"r\", and \"q\" have been added, ascending in reverse alphabetical order, to avoid confusion with other metric prefixes.\nUsage.\nMicro symbol.\nWhen \"mega\" and \"micro\" were adopted in 1873, three prefixes existed starting with \"m\". It was necessary to use a symbol other than upper and lowercase 'm'. Eventually the Greek letter \"\u03bc\" was adopted.\nWith the lack of a \"\u03bc\" key on most typewriters, as well as computer keyboards, various other abbreviations remained common, including \"mc\", \"mic\", \"M\", and \"u\".\nFrom about 1960 onwards, \"u\" prevailed in type-written documents. Because ASCII, EBCDIC, and other common encodings lacked code-points for \"\u03bc\", this tradition remained even as computers replaced typewriters.\nWhen ISO 8859-1 was created, it included the \"\u03bc\" symbol for \"micro\" at codepoint ; later, the whole of ISO 8859-1 was incorporated into the initial version of Unicode. Many fonts that support both characters render them identically, but because the micro sign and the Greek lower-case letter have different applications (normally, a Greek letter would be used with other Greek letters, but the micro sign is never used like that), some fonts render them differently, e.g. Linux Libertine and Segoe UI.\nKeyboard entry.\nMost English-language keyboards do not have a \"\u03bc\" key, so it is necessary to use a key-code; this varies depending on the operating system, physical keyboard layout, and user's language.\n* On Microsoft Windows systems,\n** arbitrary Unicode codepoints can be entered in decimal with: sustained, , and releasing . A leading \"0\" is required (this registers as the corresponding Unicode hexadecimal code-point, 0xB5 = 181.), or\n** arbitrary Unicode codepoints can be entered in hexadecimal as: (up to 5\u00a0hexadecimal characters, not counting the leading '+', upper or lower case), or\n** in the tradition of MS-DOS, IBM code page 437 one can also enter old code-points in decimal: (the leading zero must be omitted);\n* On Linux systems,\n** under X11, when a Compose key has been enabled: \n** under X11, with \"ibus\" version 1.5.19 (or higher) active, and a non-composing input method selected: The default keybinding for starting codepoint input is . The key sequence then produces U+00B5, the micro sign.\n** on the VGA console's virtual terminals like tty1: arbitrary Unicode codepoints can be entered in decimal as: sustained, , and releasing . A leading \"0\" is not required.\n* On Linux systems,\n** code-point U+00b5 can be entered as (provided the right alt key is configured to act as ).\n* On MacOS systems, code-point U+00b5 can be entered as either or .\nTypesetting in LaTeX.\nThe LaTeX typesetting system features an \"SIunitx\" package in which the units of measurement are spelled out, for example,\n codice_1 formats as \"3\u00a0THz\".\nApplication to units of measurement.\nThe use of prefixes can be traced back to the introduction of the metric system in the 1790s, long before the 1960 introduction of the SI. The prefixes, including those introduced after 1960, are used with any metric unit, whether officially included in the SI or not (e.g., millidyne and milligauss). Metric prefixes may also be used with some non-metric units, but not, for example, with the non-SI units of time.\nMetric units.\nMass.\nThe units kilogram, gram, milligram, microgram, and smaller are commonly used for measurement of mass. However, megagram, gigagram, and larger are rarely used; tonnes (and kilotonnes, megatonnes, etc.) or scientific notation are used instead. The megagram does not share the risk of confusion that the tonne has with other units with the name \"ton\".\nThe kilogram is the only coherent unit of the International System of Units that includes a metric prefix.144\nVolume.\nThe litre (equal to a cubic decimetre), millilitre (equal to a cubic centimetre), microlitre, and smaller are common. In Europe, the centilitre is often used for liquids (e.g. bottles or servings of wine), and the decilitre is used less frequently. Bulk agricultural products, such as grain, beer and wine, often use the hectolitre (100 litres).\nLarger volumes are usually denoted in kilolitres, megalitres or gigalitres, or else in cubic metres (1 cubic metre = 1 kilolitre) or cubic kilometres (1 cubic kilometre = 1 teralitre). For scientific (other than medical) purposes, the SI unit of cubic metre is usually used, with scientific notation rather than prefixes.\nLength.\nThe kilometre, metre, centimetre, millimetre, and smaller units are common. The decimetre is rarely used. The micrometre is often referred to by the older non-SI name \"micron\", which is officially deprecated. In some fields, such as chemistry, the \u00e5ngstr\u00f6m (0.1\u00a0nm) has been used commonly instead of the nanometre. The femtometre, used mainly in particle physics, is sometimes called a fermi. For large scales, megametre, gigametre, and larger are rarely used. Instead, ad hoc non-metric units are used, such as the solar radius, astronomical units, light years, and parsecs, and less commonly large multiples (e.g. millions) of kilometres; the astronomical unit is mentioned in the SI standards as an accepted non-SI unit.\nTime.\nPrefixes for the SI standard unit second are most commonly encountered for quantities less than one second. For larger quantities, the system of minutes (60\u00a0seconds), hours (60\u00a0minutes) and days (24\u00a0hours) is accepted for use with the SI and more commonly used. When speaking of spans of time, the length of the day is usually standardised to \u00a0seconds so as not to create issues with the irregular leap second.\nLarger multiples of the second such as kiloseconds and megaseconds are occasionally encountered in scientific contexts, but are seldom used in common parlance. For long-scale scientific work, particularly in astronomy, the Julian year or \"annum\" (a) is a standardised variant of the year, equal to exactly \u00a0seconds (\u00a0days). The unit is so named because it was the average length of a year in the Julian calendar. Long time periods are then expressed by using metric prefixes with the annum, such as megaannum (Ma) or gigaannum (Ga).\nAngle.\nThe SI unit of angle is the radian, but degrees, as well as arc-minutes and arc-seconds, see some scientific use in fields such as astronomy.\nTemperature.\nCommon practice does not typically use the flexibility allowed by official policy in the case of the degree Celsius (\u00b0C). NIST states: \"Prefix symbols may be used with the unit symbol \u00b0C and prefix names may be used with the unit name \"degree Celsius\". For example, 12\u00a0m\u00b0C (12 millidegrees Celsius) is acceptable.\" In practice, it is more common for prefixes to be used with the kelvin when it is desirable to denote extremely large or small absolute temperatures or temperature differences. Thus, temperatures of star interiors may be given with the unit of MK (megakelvin), and molecular cooling may be given with the unit mK (millikelvin).\nEnergy.\nIn use the joule and kilojoule are common, with larger multiples seen in limited contexts. In addition, the kilowatt-hour, a composite unit formed from the kilowatt and hour, is often used for electrical energy; other multiples can be formed by modifying the prefix of watt (e.g. terawatt-hour).\nSeveral definitions exist for the non-SI unit calorie. Distinguished are gram calories and kilogram calories. One kilogram calorie, which equals one thousand gram calories, often appears capitalized and without a prefix (i.e. \"Cal\") when referring to \"dietary calories\" in food. It is common to apply metric prefixes to the gram calorie, but not to the kilogram calorie: thus, 1\u00a0kcal = 1000\u00a0cal = 1\u00a0Cal.\nNon-metric units.\nMetric prefixes are widely used outside the metric SI system. Common examples include the megabyte and the decibel. Metric prefixes rarely appear with imperial or US units except in some special cases (e.g., microinch, kilofoot, kilopound). They are also used with other specialised units used in particular fields (e.g., megaelectronvolt, gigaparsec, millibarn, kilodalton). In astronomy, geology, and palaeontology, the year, with symbol 'a' (from the Latin \"annus\"), is commonly used with metric prefixes: ka, Ma, and Ga.\nOfficial policies about the use of SI prefixes with non-SI units vary slightly between the International Bureau of Weights and Measures (BIPM) and the American National Institute of Standards and Technology (NIST). For instance, the NIST advises that \"to avoid confusion, prefix symbols (and prefix names) are not used with the time-related unit symbols (names) min (minute), h (hour), d (day); nor with the angle-related symbols (names) \u00b0\u00a0(degree), '\u00a0(minute), and \u2033\u00a0(second), whereas the BIPM adds information about the use of prefixes with the symbol \"as\" for arcsecond when they state: \"However astronomers use milliarcsecond, which they denote mas, and microarcsecond, \u03bcas, which they use as units for measuring very small angles.\"\nNon-standard prefixes.\nObsolete metric prefixes.\nSome of the prefixes formerly used in the metric system have fallen into disuse and were not adopted into the SI. The decimal prefix for ten thousand, \"myria-\" (sometimes spelt \"myrio-\"), and the early binary prefixes \"double-\" (2\u00d7) and \"demi-\" (\u00d7) were parts of the original metric system adopted by France in 1795,\nbut were not retained when the SI prefixes were internationally adopted by the 11th CGPM conference in 1960.\nOther metric prefixes used historically include hebdo- (107) and micri- (10\u221214).\nDouble prefixes.\nDouble prefixes have been used in the past, such as \"micromillimetres\" or \"millimicrons\" (now nanometres), \"micromicrofarads\" (\u03bc\u03bcF; now picofarads, pF), \"kilomegatonnes\" (now gigatonnes), \"hectokilometres\" (now 100\u00a0kilometres) and the derived adjective \"hectokilometric\" (typically used for qualifying the fuel consumption measures). These are not compatible with the SI.\nOther obsolete double prefixes included \"decimilli-\" (10\u22124), which was contracted to \"dimi-\" and standardised in France up to 1961.\nThere are no more letters of the Latin alphabet available for new prefixes (all the unused letters are already used for units). As such, Richard J. C. Brown (who proposed the prefixes adopted for 10\u00b127 and 10\u00b130) has proposed a reintroduction of compound prefixes (e.g. \"kiloquetta-\" for 1033) if a driver for prefixes at such scales ever materialises, with a restriction that the last prefix must always be \"quetta-\" or \"quecto-\". This usage has not been approved by the BIPM.\nSimilar symbols and abbreviations.\nIn written English, the symbol \"K\" is often used informally to indicate a multiple of thousand in many contexts. For example, one may talk of a \"40K salary\" (), or call the Year 2000 problem the \"Y2K problem\". In these cases, an uppercase K is often used with an implied unit (although it could then be confused with the symbol for the kelvin temperature unit if the context is unclear). This informal postfix is read or spoken as \"thousand\", \"grand\", or just \"k\".\nThe financial and general news media mostly use m or M, b or B, and t or T as abbreviations for million, billion (109) and trillion (1012), respectively, for large quantities, typically currency and population.\nThe medical and automotive fields in the United States use the abbreviations \"cc\" or \"ccm\" for cubic centimetres. One\u00a0cubic centimetre is equal to one\u00a0millilitre.\nFor nearly a century, engineers used the abbreviation \"MCM\" to designate a \"thousand circular mils\" in specifying the cross-sectional area of large electrical cables. Since the mid-1990s, \"kcmil\" has been adopted as the official designation of a thousand circular mils, but the designation \"MCM\" still remains in wide use. A similar system is used in natural gas sales in the United States: \"m\" (or \"M\") for thousands and \"mm\" (or \"MM\") for millions (thousand thousands) of British thermal units or therms, and in the oil industry, where \"MMbbl\" is the symbol for \"millions of barrels\". These usages of the capital letter \"M\" for \"thousand\" in MCM is from Roman numerals, in which \"M\" means 1000.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26875", "revid": "9021902", "url": "https://en.wikipedia.org/wiki?curid=26875", "title": "SI supplementary unit", "text": ""}
{"id": "26876", "revid": "1290051049", "url": "https://en.wikipedia.org/wiki?curid=26876", "title": "SI derived unit", "text": "Measurement unit derived from basic metric value\nSI derived units are units of measurement derived from the\nseven SI base units specified by the International System of Units (SI). They can be expressed as a product (or ratio) of one or more of the base units, possibly scaled by an appropriate power of exponentiation (see: Buckingham \u03c0 theorem). Some are dimensionless, as when the units cancel out in ratios of like quantities.\nSI coherent derived units involve only a trivial proportionality factor, not requiring conversion factors.\nThe SI has special names for 22 of these coherent derived units (for example, hertz, the SI unit of measurement of frequency), but the rest merely reflect their derivation: for example, the square metre (m2), the SI derived unit of area; and the kilogram per cubic metre (kg/m3 or kg\u22c5m\u22123), the SI derived unit of density.\nThe names of SI coherent derived units, when written in full, are always in lowercase. However, the symbols for units named after persons are written with an uppercase initial letter. For example, the symbol for hertz is \"Hz\", while the symbol for metre is \"m\".\nSpecial names.\nThe International System of Units assigns special names to 22 derived units, which includes two dimensionless derived units, the radian (rad) and the steradian (sr).\nOther units used with SI.\nSome other units such as the hour, litre, tonne, bar, and electronvolt are not SI units, but are widely used in conjunction with SI units.\nSupplementary units.\nUntil 1995, the SI classified the radian and the steradian as \"supplementary units\", but this designation was abandoned and the units were grouped as derived units.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26880", "revid": "37878", "url": "https://en.wikipedia.org/wiki?curid=26880", "title": "SI unit", "text": ""}
{"id": "26882", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=26882", "title": "Split (poker)", "text": ""}
{"id": "26883", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=26883", "title": "Skinheads", "text": ""}
{"id": "26884", "revid": "49592297", "url": "https://en.wikipedia.org/wiki?curid=26884", "title": "Superconductivity", "text": "Electrical conductivity with exactly zero resistance\nSuperconductivity is a set of physical properties observed in superconductors: materials where electrical resistance vanishes and magnetic fields are expelled from the material. Unlike an ordinary metallic conductor, whose resistance decreases gradually as its temperature is lowered, even down to near absolute zero, a superconductor has a characteristic critical temperature below which the resistance drops abruptly to zero. An electric current through a loop of superconducting wire can persist indefinitely with no power source.\nThe superconductivity phenomenon was discovered in 1911 by Dutch physicist Heike Kamerlingh Onnes. Like ferromagnetism and atomic spectral lines, superconductivity is a phenomenon which can only be explained by quantum mechanics. It is characterized by the Meissner effect, the complete cancellation of the magnetic field in the interior of the superconductor during its transitions into the superconducting state. The occurrence of the Meissner effect indicates that superconductivity cannot be understood simply as the idealization of \"perfect conductivity\" in classical physics.\nIn 1986, it was discovered that some cuprate-perovskite ceramic materials have a critical temperature above . It was shortly found (by Ching-Wu Chu) that replacing the lanthanum with yttrium, i.e. making YBCO, raised the critical temperature to , which was important because liquid nitrogen could then be used as a refrigerant. Such a high transition temperature is theoretically impossible for a conventional superconductor, leading the materials to be termed high-temperature superconductors. The cheaply available coolant liquid nitrogen boils at and thus the existence of superconductivity at higher temperatures than this facilitates many experiments and applications that are less practical at lower temperatures.\nHistory.\nSuperconductivity was discovered on April 8, 1911, by Heike Kamerlingh Onnes, who was studying the resistance of solid mercury at cryogenic temperatures using the recently produced liquid helium as a refrigerant. At the temperature of 4.2\u00a0K, he observed that the resistance abruptly disappeared. In the same experiment, he also observed the superfluid transition of helium at 2.2\u00a0K, without recognizing its significance. The precise date and circumstances of the discovery were only reconstructed a century later, when https:// was found. In subsequent decades, superconductivity was observed in several other materials. In 1913, lead was found to superconduct at 7\u00a0K, and in 1941 niobium nitride was found to superconduct at 16\u00a0K.\nGreat efforts have been devoted to finding out how and why superconductivity works; the important step occurred in 1933, when Meissner and Ochsenfeld discovered that superconductors expelled applied magnetic fields, a phenomenon which has come to be known as the Meissner effect. In 1935, Fritz and Heinz London showed that the Meissner effect was a consequence of the minimization of the electromagnetic free energy carried by superconducting current.\nLondon constitutive equations.\nThe theoretical model that was first conceived for superconductivity was completely classical: it is summarized by London constitutive equations. It was put forward by the brothers Fritz and Heinz London in 1935, shortly after the discovery that magnetic fields are expelled from superconductors. A major triumph of the equations of this theory is their ability to explain the Meissner effect, wherein a material exponentially expels all internal magnetic fields as it crosses the superconducting threshold. By using the London equation, one can obtain the dependence of the magnetic field inside the superconductor on the distance to the surface.\nThe two constitutive equations for a superconductor by London are:\nformula_1\nThe first equation follows from Newton's second law for superconducting electrons.\nConventional theories (1950s).\nDuring the 1950s, theoretical condensed matter physicists arrived at an understanding of \"conventional\" superconductivity, through a pair of remarkable and important theories: the phenomenological Ginzburg\u2013Landau theory (1950) and the microscopic BCS theory (1957).\nIn 1950, the phenomenological Ginzburg\u2013Landau theory of superconductivity was devised by Landau and Ginzburg. This theory, which combined Landau's theory of second-order phase transitions with a Schr\u00f6dinger-like wave equation, had great success in explaining the macroscopic properties of superconductors. In particular, Abrikosov showed that Ginzburg\u2013Landau theory predicts the division of superconductors into the two categories now referred to as Type\u00a0I and Type\u00a0II. Abrikosov and Ginzburg were awarded the 2003 Nobel Prize for their work (Landau had received the 1962 Nobel Prize for other work, and died in 1968). The four-dimensional extension of the Ginzburg\u2013Landau theory, the Coleman-Weinberg model, is important in quantum field theory and cosmology.\nAlso in 1950, Maxwell and Reynolds et al. found that the critical temperature of a superconductor depends on the isotopic mass of the constituent element. This important discovery pointed to the electron\u2013phonon interaction as the microscopic mechanism responsible for superconductivity.\nThe complete microscopic theory of superconductivity was finally proposed in 1957 by Bardeen, Cooper and Schrieffer. This BCS theory explained the superconducting current as a superfluid of Cooper pairs, pairs of electrons interacting through the exchange of phonons. For this work, the authors were awarded the Nobel Prize in 1972.\nThe BCS theory was set on a firmer footing in 1958, when N. N. Bogolyubov showed that the BCS wavefunction, which had originally been derived from a variational argument, could be obtained using a canonical transformation of the electronic Hamiltonian. In 1959, Lev Gor'kov showed that the BCS theory reduced to the Ginzburg\u2013Landau theory close to the critical temperature.\nGeneralizations of BCS theory for conventional superconductors form the basis for the understanding of the phenomenon of superfluidity, because they fall into the lambda transition universality class. The extent to which such generalizations can be applied to unconventional superconductors is still controversial.\nNiobium.\nThe first practical application of superconductivity was developed in 1954 with Dudley Allen Buck's invention of the cryotron. Two superconductors with greatly different values of the critical magnetic field are combined to produce a fast, simple switch for computer elements.\nSoon after discovering superconductivity in 1911, Kamerlingh Onnes attempted to make an electromagnet with superconducting windings but found that relatively low magnetic fields destroyed superconductivity in the materials he investigated. Much later, in 1955, G. B. Yntema succeeded in constructing a small 0.7-tesla iron-core electromagnet with superconducting niobium wire windings. Then, in 1961, J. E. Kunzler, E. Buehler, F. S. L. Hsu, and J. H. Wernick made the startling discovery that, at 4.2 kelvin, niobium\u2013tin, a compound consisting of three parts niobium and one part tin, was capable of supporting a current density of more than 100,000 amperes per square centimeter in a magnetic field of 8.8 tesla. The alloy was brittle and difficult to fabricate, but niobium\u2013tin proved useful for generating magnetic fields as high as 20 tesla.\nIn 1962, T. G. Berlincourt and R. R. Hake discovered that more ductile alloys of niobium and titanium are suitable for applications up to 10 tesla. Commercial production of niobium\u2013titanium supermagnet wire immediately commenced at Westinghouse Electric Corporation and at Wah Chang Corporation. Although niobium\u2013titanium boasts less-impressive superconducting properties than those of niobium\u2013tin, niobium\u2013titanium became the most widely used \"workhorse\" supermagnet material, in large measure a consequence of its very high ductility and ease of fabrication. However, both niobium\u2013tin and niobium\u2013titanium found wide application in MRI medical imagers, bending and focusing magnets for enormous high-energy-particle accelerators, and other applications. Conectus, a European superconductivity consortium, estimated that in 2014, global economic activity for which superconductivity was indispensable amounted to about five billion euros, with MRI systems accounting for about 80% of that total.\nJosephson effect.\nIn 1962, Josephson made the important theoretical prediction that a supercurrent can flow between two pieces of superconductor separated by a thin layer of insulator. This phenomenon, now called the Josephson effect, is exploited by superconducting devices such as SQUIDs. It is used in the most accurate available measurements of the magnetic flux quantum \"\u03a6\"0\u00a0=\u00a0\"h\"/(2\"e\"), where \"h\" is the Planck constant. Coupled with the quantum Hall resistivity, this leads to a precise measurement of the Planck constant. Josephson was awarded the Nobel Prize for this work in 1973.\nIn 2008, it was proposed that the same mechanism that produces superconductivity could produce a superinsulator state in some materials, with almost infinite electrical resistance. The first development and study of superconducting Bose\u2013Einstein condensate (BEC) in 2020 suggested a \"smooth transition between\" BEC and Bardeen-Cooper-Shrieffer regimes.\n2D materials.\nMultiple types of superconductivity are reported in devices made of single-layer materials. Some of these materials can switch between conducting, insulating, and other behaviors.\nTwisting materials imbues them with a \"moir\u00e9\" pattern involving tiled hexagonal cells that act like atoms and host electrons. In this environment, the electrons move slowly enough for their collective interactions to guide their behavior. When each cell has a single electron, the electrons take on an antiferromagnetic arrangement; each electron can have a preferred location and magnetic orientation. Their intrinsic magnetic fields tend to alternate between pointing up and down. Adding electrons allows superconductivity by causing Cooper pairs to form. Fu and Schrade argued that electron-on-electron action was allowing both antiferromagnetic and superconducting states.\nThe first success with 2D materials involved a twisted bilayer graphene sheet (2018, Tc ~1.7 K, 1.1\u00b0 twist). A twisted three-layer graphene device was later shown to superconduct (2021, Tc ~2.8 K). Then an untwisted trilayer graphene device was reported to superconduct (2022, Tc 1-2 K). The latter was later shown to be tunable, easily reproducing behavior found in millions of other configurations. Directly observing what happens when electrons are added to a material or slightly weakening its electric field enables quick testing of an unprecedented number of recipes to see which lead to superconductivity.\nIn four and five layer rhombohedral graphene, a form of superconductivity with spontaneously broken time reversal symmetry known as \"chiral superconductivity\" was recently observed. These systems were not observed to have any superlattice effects, and they can flip between two possible magnetic states without exiting the superconducting phase. This is in strong contrast to other observations of superconductivity and magnetic fields. \nThese devices have applications in quantum computing.\n2D materials other than graphene have also been made to superconduct. Transition metal dichalcogenide (TMD) sheets twisted at 5 degrees intermittently achieved superconduction by creating a Josephson junction. The device used used thin layers of palladium to connect to the sides of a tungsten telluride layer surrounded and protected by boron nitride. Another group demonstrated superconduction in molybdenum telluride (MoTe\u2082) in 2D van der Waals materials using ferroelectric domain walls. The Tc was implied to be higher than typical TMDs (~5\u201310 K).\nA Cornell group added a 3.5-degree twist to an insulator that allowed electrons to slow down and interact strongly, leaving one electron per cell, exhibiting superconduction. Existing theories do not explain this behavior.\nFu and collaborators proposed that electrons arrange to form a repeating crystal that allows the electron grid to float independently of the background atomic nuclei and the electron grid to relax. Its ripples pair electrons the way phonons do, although this is unconfirmed.\nClassification.\nSuperconductors are classified according to many criteria. The most common are:\nResponse to a magnetic field.\nA superconductor can be \"Type\u00a0I\", meaning it has a single critical field, above which superconductivity is lost and below which the magnetic field is completely expelled from the superconductor; or \"Type\u00a0II\", meaning it has two critical fields, between which it allows partial penetration of the magnetic field through isolated points called vortices. Furthermore, in multicomponent superconductors it is possible to combine the two behaviours. In that case the superconductor is of Type-1.5.\nTheory of operation.\nA superconductor is \"conventional\" if it is driven by electron\u2013phonon interaction and explained by the BCS theory or its extension, the Eliashberg theory. Otherwise, it is \"unconventional\". Alternatively, a superconductor is called unconventional if the superconducting order parameter transforms according to a non-trivial irreducible representation of the system's point group or space group.\nCritical temperature.\nA superconductor is generally considered \"high-temperature\" if it reaches a superconducting state above a temperature of 30\u00a0K (\u2212243.15\u00a0\u00b0C); as in the initial discovery by Georg Bednorz and K. Alex M\u00fcller. It may also reference materials that transition to superconductivity when cooled using liquid nitrogen \u2013 that is, at only \"T\"c\u00a0&gt;\u00a077\u00a0K, although this is generally used only to emphasize that liquid nitrogen coolant is sufficient. Low temperature superconductors refer to materials with a critical temperature below 30\u00a0K, and are cooled mainly by liquid helium (\"T\"c\u00a0&gt;\u00a04.2\u00a0K). One exception to this rule is the iron pnictide group of superconductors that display behaviour and properties typical of high-temperature superconductors, yet some of the group have critical temperatures below 30\u00a0K.\nMaterial.\nSuperconductor material classes include chemical elements (e.g. mercury or lead), alloys (such as niobium\u2013titanium, germanium\u2013niobium, and niobium nitride), ceramics (YBCO and magnesium diboride), superconducting pnictides (like fluorine-doped LaOFeAs), single-layer materials such as graphene and transition metal dichalcogenides, or organic superconductors (fullerenes and carbon nanotubes; though perhaps these examples should be included among the chemical elements, as they are composed entirely of carbon).\nElementary properties.\nSeveral physical properties of superconductors vary from material to material, such as the critical temperature, the value of the superconducting gap, the critical magnetic field, and the critical current density at which superconductivity is destroyed. On the other hand, there is a class of properties that are independent of the underlying material. The Meissner effect, the quantization of the magnetic flux or permanent currents, i.e. the state of zero resistance are the most important examples. The existence of these \"universal\" properties is rooted in the nature of the broken symmetry of the superconductor and the emergence of off-diagonal long range order. Superconductivity is a thermodynamic phase, and thus possesses certain distinguishing properties which are largely independent of microscopic details. Off diagonal long range order is closely connected to the formation of Cooper pairs.\nZero electrical DC resistance.\nThe simplest method to measure the electrical resistance of a sample of some material is to place it in an electrical circuit in series with a current source \"I\" and measure the resulting voltage \"V\" across the sample. The resistance of the sample is given by Ohm's law as \"R\u00a0=\u00a0V\u00a0/\u00a0I\". If the voltage is zero, this means that the resistance is zero.\nSuperconductors are also able to maintain a current with no applied voltage whatsoever, a property exploited in superconducting electromagnets such as those found in MRI machines. Experiments have demonstrated that currents in superconducting coils can persist for years without any measurable degradation. Experimental evidence points to a lifetime of at least 100,000 years. Theoretical estimates for the lifetime of a persistent current can exceed the estimated lifetime of the universe, depending on the wire geometry and the temperature. In practice, currents injected in superconducting coils persisted for 28 years, 7 months, 27 days in a superconducting gravimeter in Belgium, from August 4, 1995 until March 31, 2024. In such instruments, the measurement is based on the monitoring of the levitation of a superconducting niobium sphere with a mass of four grams.\nIn a normal conductor, an electric current may be visualized as a fluid of electrons moving across a heavy ionic lattice. The electrons are constantly colliding with the ions in the lattice, and during each collision some of the energy carried by the current is absorbed by the lattice and converted into heat, which is essentially the vibrational kinetic energy of the lattice ions. As a result, the energy carried by the current is constantly being dissipated. This is the phenomenon of electrical resistance and Joule heating.\nThe situation is different in a superconductor. In a conventional superconductor, the electronic fluid cannot be resolved into individual electrons. Instead, it consists of bound \"pairs\" of electrons known as Cooper pairs. This pairing is caused by an attractive force between electrons from the exchange of phonons. This pairing is very weak, and small thermal vibrations can fracture the bond. Due to quantum mechanics, the energy spectrum of this Cooper pair fluid possesses an \"energy gap\", meaning there is a minimum amount of energy \u0394\"E\" that must be supplied in order to excite the fluid. Therefore, if \u0394\"E\" is larger than the thermal energy of the lattice, given by \"kT\", where \"k\" is the Boltzmann constant and \"T\" is the temperature, the fluid will not be scattered by the lattice. The Cooper pair fluid is thus a superfluid, meaning it can flow without energy dissipation.\nIn the class of superconductors known as type II superconductors, including all known high-temperature superconductors, an extremely low but non-zero resistivity appears at temperatures not too far below the nominal superconducting transition when an electric current is applied in conjunction with a strong magnetic field, which may be caused by the electric current. This is due to the motion of magnetic vortices in the electronic superfluid, which dissipates some of the energy carried by the current. If the current is sufficiently small, the vortices are stationary, and the resistivity vanishes. The resistance due to this effect is minuscule compared with that of non-superconducting materials, but must be taken into account in sensitive experiments. However, as the temperature decreases far enough below the nominal superconducting transition, these vortices can become frozen into a disordered but stationary phase known as a \"vortex glass\". Below this vortex glass transition temperature, the resistance of the material becomes truly zero.\nPhase transition.\nIn superconducting materials, the characteristics of superconductivity appear when the temperature \"T\" is lowered below a critical temperature \"T\"c. The value of this critical temperature varies from material to material. Conventional superconductors usually have critical temperatures ranging from around 20\u00a0K to less than 1\u00a0K. Solid mercury, for example, has a critical temperature of 4.2\u00a0K. As of 2015, the highest critical temperature found for a conventional superconductor is 203 K for H2S, although high pressures of approximately 90 gigapascals were required. Cuprate superconductors can have much higher critical temperatures: YBa2Cu3O7, one of the first cuprate superconductors to be discovered, has a critical temperature above 90\u00a0K, and mercury-based cuprates have been found with critical temperatures in excess of 130\u00a0K. The basic physical mechanism responsible for the high critical temperature is not yet clear. However, it is clear that a two-electron pairing is involved, although the nature of the pairing (formula_2 wave vs. formula_3 wave) remains controversial.\nSimilarly, at a fixed temperature below the critical temperature, superconducting materials cease to superconduct when an external magnetic field is applied which is greater than the \"critical magnetic field\". This is because the Gibbs free energy of the superconducting phase increases quadratically with the magnetic field while the free energy of the normal phase is roughly independent of the magnetic field. If the material superconducts in the absence of a field, then the superconducting phase free energy is lower than that of the normal phase and so for some finite value of the magnetic field (proportional to the square root of the difference of the free energies at zero magnetic field) the two free energies will be equal and a phase transition to the normal phase will occur. More generally, a higher temperature and a stronger magnetic field lead to a smaller fraction of electrons that are superconducting and consequently to a longer London penetration depth of external magnetic fields and currents. The penetration depth becomes infinite at the phase transition.\nThe onset of superconductivity is accompanied by abrupt changes in various physical properties, which is the hallmark of a phase transition. For example, the electronic heat capacity is proportional to the temperature in the normal (non-superconducting) regime. At the superconducting transition, it suffers a discontinuous jump and thereafter ceases to be linear. At low temperatures, it varies instead as \"e\"\u2212\"\u03b1\"/\"T\" for some constant, \"\u03b1\". This exponential behavior is one of the pieces of evidence for the existence of the energy gap.\nThe order of the superconducting phase transition was long a matter of debate. Experiments indicate that the transition is second-order, meaning there is no latent heat. However, in the presence of an external magnetic field there is latent heat, because the superconducting phase has a lower entropy below the critical temperature than the normal phase. It has been experimentally demonstrated that, as a consequence, when the magnetic field is increased beyond the critical field, the resulting phase transition leads to a decrease in the temperature of the superconducting material.\nCalculations in the 1970s suggested that it may actually be weakly first-order due to the effect of long-range fluctuations in the electromagnetic field. In the 1980s it was shown theoretically with the help of a disorder field theory, in which the vortex lines of the superconductor play a major role, that the transition is of second order within the type II regime and of first order (i.e., latent heat) within the type I regime, and that the two regions are separated by a tricritical point. The results were strongly supported by Monte Carlo computer simulations.\nMeissner effect.\nWhen a superconductor is placed in a weak external magnetic field \"H\", and cooled below its transition temperature, the magnetic field is ejected. The Meissner effect does not cause the field to be completely ejected but instead, the field penetrates the superconductor but only to a very small distance, characterized by a parameter\u00a0\"\u03bb\", called the London penetration depth, decaying exponentially to zero within the bulk of the material. The Meissner effect is a defining characteristic of superconductivity. For most superconductors, the London penetration depth is on the order of 100\u00a0nm.\nThe Meissner effect is sometimes confused with the kind of diamagnetism one would expect in a perfect electrical conductor: according to Lenz's law, when a \"changing\" magnetic field is applied to a conductor, it will induce an electric current in the conductor that creates an opposing magnetic field. In a perfect conductor, an arbitrarily large current can be induced, and the resulting magnetic field exactly cancels the applied field.\nThe Meissner effect is distinct from this\u00a0\u2013 it is the spontaneous expulsion that occurs during transition to superconductivity. Suppose we have a material in its normal state, containing a constant internal magnetic field. When the material is cooled below the critical temperature, we would observe the abrupt expulsion of the internal magnetic field, which we would not expect based on Lenz's law.\nThe Meissner effect was given a phenomenological explanation by the brothers Fritz and Heinz London, who showed that the electromagnetic free energy in a superconductor is minimized provided formula_4 where \"H\" is the magnetic field and \"\u03bb\" is the London penetration depth.\nThis equation, which is known as the London equation, predicts that the magnetic field in a superconductor decays exponentially from whatever value it possesses at the surface.\nA superconductor with little or no magnetic field within it is said to be in the Meissner state. The Meissner state breaks down when the applied magnetic field is too large. Superconductors can be divided into two classes according to how this breakdown occurs. In Type I superconductors, superconductivity is abruptly destroyed when the strength of the applied field rises above a critical value \"H\"c. Depending on the geometry of the sample, one may obtain an intermediate state consisting of a baroque pattern of regions of normal material carrying a magnetic field mixed with regions of superconducting material containing no field. In Type II superconductors, raising the applied field past a critical value \"H\"c1 leads to a mixed state (also known as the vortex state) in which an increasing amount of magnetic flux penetrates the material, but there remains no resistance to the flow of electric current as long as the current is not too large. At a second critical field strength \"H\"c2, superconductivity is destroyed. The mixed state is actually caused by vortices in the electronic superfluid, sometimes called fluxons because the flux carried by these vortices is quantized. Most pure elemental superconductors, except niobium and carbon nanotubes, are Type I, while almost all impure and compound superconductors are Type\u00a0II.\nLondon moment.\nConversely, a spinning superconductor generates a magnetic field, precisely aligned with the spin axis. The effect, the London moment, was put to good use in Gravity Probe B. This experiment measured the magnetic fields of four superconducting gyroscopes to determine their spin axes. This was critical to the experiment since it is one of the few ways to accurately determine the spin axis of an otherwise featureless sphere.\nApplications.\nSuperconductors are promising candidate materials for devising fundamental circuit elements of electronic, spintronic, and quantum technologies. One such example is a superconducting diode, in which supercurrent flows along one direction only, that promise dissipationless superconducting and semiconducting-superconducting hybrid technologies.\nSuperconducting magnets are some of the most powerful electromagnets known. They are used in MRI/NMR machines, mass spectrometers, the beam-steering magnets used in particle accelerators and plasma confining magnets in some tokamaks. They can also be used for magnetic separation, where weakly magnetic particles are extracted from a background of less or non-magnetic particles, as in the pigment industries. They can also be used in large wind turbines to overcome the restrictions imposed by high electrical currents, with an industrial grade 3.6 megawatt superconducting windmill generator having been tested successfully in Denmark.\nIn the 1950s and 1960s, superconductors were used to build experimental digital computers using cryotron switches. More recently, superconductors have been used to make digital circuits based on rapid single flux quantum technology and RF and microwave filters for mobile phone base stations.\nSuperconductors are used to build Josephson junctions which are the building blocks of SQUIDs (superconducting quantum interference devices), the most sensitive magnetometers known. SQUIDs are used in scanning SQUID microscopes and magnetoencephalography. Series of Josephson devices are used to realize the SI volt. Superconducting photon detectors can be realised in a variety of device configurations. Depending on the particular mode of operation, a superconductor\u2013insulator\u2013superconductor Josephson junction can be used as a photon detector or as a mixer. The large resistance change at the transition from the normal to the superconducting state is used to build thermometers in cryogenic micro-calorimeter photon detectors. The same effect is used in ultrasensitive bolometers made from superconducting materials. Superconducting nanowire single-photon detectors offer high speed, low noise single-photon detection and have been employed widely in advanced photon-counting applications.\nOther early markets are arising where the relative efficiency, size and weight advantages of devices based on high-temperature superconductivity outweigh the additional costs involved. For example, in wind turbines the lower weight and volume of superconducting generators could lead to savings in construction and tower costs, offsetting the higher costs for the generator and lowering the total levelized cost of electricity (LCOE).\nPromising future applications include high-performance smart grid, electric power transmission, transformers, power storage devices, compact fusion power devices, electric motors (e.g. for vehicle propulsion, as in vactrains or maglev trains), magnetic levitation devices, fault current limiters, enhancing spintronic devices with superconducting materials, and superconducting magnetic refrigeration. However, superconductivity is sensitive to moving magnetic fields, so applications that use alternating current (e.g. transformers) will be more difficult to develop than those that rely upon direct current. Compared to traditional power lines, superconducting transmission lines are more efficient and require only a fraction of the space, which would not only lead to a better environmental performance but could also improve public acceptance for expansion of the electric grid. Another attractive industrial aspect is the ability for high power transmission at lower voltages. Advancements in the efficiency of cooling systems and use of cheap coolants such as liquid nitrogen have also significantly decreased cooling costs needed for superconductivity.\nNobel Prizes.\nAs of 2022, there have been five Nobel Prizes in Physics for superconductivity related subjects:"}
{"id": "26885", "revid": "4460044", "url": "https://en.wikipedia.org/wiki?curid=26885", "title": "Super fluids", "text": ""}
{"id": "26886", "revid": "1295697199", "url": "https://en.wikipedia.org/wiki?curid=26886", "title": "Siam (disambiguation)", "text": "Siam is the former name of Thailand, and is used to refer to the historical region of Central Thailand, usually including Southern Thailand.\nSiam or SIAM may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "26889", "revid": "43676253", "url": "https://en.wikipedia.org/wiki?curid=26889", "title": "Geography of Sweden", "text": " \nSweden is a country in Northern Europe on the Scandinavian Peninsula. It borders Norway to the west (which is one of Sweden\u2019s non-EU neighbours); Finland to the northeast; and the Baltic Sea and Gulf of Bothnia to the south and east. At , Sweden is the largest country in Northern Europe, the fifth largest in Europe, and the 55th largest country in the world.\nSweden has a long coastline on its east, and the Scandinavian mountain chain (Skanderna) on its western border, separating it from Norway. It has maritime borders with Denmark, Germany, Poland, Russia (another non-EU neighbour) Lithuania, Latvia and Estonia, and it is also linked to Denmark (southwest) by the \u00d6resund bridge. It has an Exclusive Economic Zone of .\nTerrain.\nMuch of Sweden is heavily forested, with 69% of the country being forest and woodland, while farmland constitutes only 8% of land use. Sweden consists of 39,960\u00a0km2 \nof water area, constituting around 95,700 lakes. The lakes are sometimes used for water power plants, especially the large northern rivers and lakes.\nMost of northern and western central Sweden consists of vast tracts of hilly and mountainous land called the Norrland terrain. From the south the transition to the Norrland terrain is not only seen in the relief but also in the wide and contiguous boreal forests that extend north of it with till and peat being the overwhelmingly most common soil types.\nSouth of the Norrland terrain lies the Central Swedish lowland which forms a broad east-west trending belt from Gothenburg to Stockholm. This is the traditional heartland of Sweden due to its large population and agricultural resources. The region forms a belt of fertile soils suitable for agriculture that interrupts the forested and till-coated lands to the north and south. Before the expansion of agriculture, these fertile soils were covered by a broad-leaved tree forest where maples, oaks, ashes, small-leaved lime and common hazel grew. The Central Swedish lowland does however also contain soils of poor quality, particularly in hills where Scots pine and Norway spruce grow on top of thin till soils. Agriculture aside, the region benefits also from the proximity of hydropower, forest and bergslagen's mineral resources. Sweden's four largest lakes, V\u00e4nern, V\u00e4ttern, M\u00e4laren and Hj\u00e4lmaren, lie within the lowlands.\nTo the south of the Central Swedish lowland lies the South Swedish highlands which except for a lack of deep valleys is similar to the Norrland terrain found further north in Sweden. The highest point of the highlands lies at 377 m. Poor soil conditions have posed significant difficulties for agriculture in the highlands, meaning that over time small industries became relatively important in local economies. \nSouthernmost Sweden contains a varied landscape with both plains and hilly terrain. A characteristic chain of elongated hills runs across Scania from northwest to southeast. These hills are horsts located along the Tornquist Zone. Some of the horsts are Hallands\u00e5sen, R\u00f6mel\u00e5sen and S\u00f6der\u00e5sen. The plains of Scania and Halland make up 10% of Sweden's cultivated lands and are the country's main agricultural landscape. Productivity is high relative to the rest of Sweden and more akin to that of more southern European countries. The natural vegetation is made up of broadleaf forest although conifer plantations are common. Southern Sweden has Sweden's greatest animal and plant diversity.\nThe two largest islands are Gotland and \u00d6land in the southeast. They differ from the rest of Sweden by being made up of limestone and marl with an alvar vegetation adapted to the island's calcareous soils. Gotland and \u00d6land have landforms that are rare or absent in mainland Sweden. These include active cliffs seen in segments of their western coasts, sea stacks called \"rauks\" and large cave systems.\nPolitical divisions.\nProvinces.\nSweden has 25 provinces or \"landskap\" (\"landscapes\"), based on culture, geography and history: Bohusl\u00e4n, Blekinge, Dalarna, Dalsland, Gotland, G\u00e4strikland, Halland, H\u00e4lsingland, H\u00e4rjedalen, J\u00e4mtland, Lapland, Medelpad, Norrbotten, N\u00e4rke, Sk\u00e5ne, Sm\u00e5land, S\u00f6dermanland, Uppland, V\u00e4rmland, V\u00e4stmanland, V\u00e4sterbotten, V\u00e4sterg\u00f6tland, \u00c5ngermanland, \u00d6land and \u00d6sterg\u00f6tland.\nWhile these provinces serve no political or administrative purpose, they play an important role for people's self-identification. The provinces are usually grouped together in three large lands (\"landsdelar\"): the northern Norrland, the central Svealand and southern G\u00f6taland. The sparsely populated Norrland encompasses almost 60% of the country.\nCounties.\nAdministratively, Sweden is divided into 21 counties, or \"l\u00e4n\". In each county there is a County Administrative Board, or \"l\u00e4nsstyrelse\", which is appointed by the national government.\nIn each county there is also a separate County Council, or \"region (before 1 januari 2020 called landsting)\", which is the municipal representation appointed by the county electorate.\nThe letters shown were on the vehicle registration plates until 1973.\nMunicipalities.\nEach county is further divided into municipalities or \"kommuner\", ranging from only one (in Gotland County) to forty-nine (in V\u00e4stra G\u00f6taland County). The total number of municipalities is 290.\nThe northern municipalities are often large in size, but have small populations \u2013 the largest municipality is Kiruna with an area as large as the three southern provinces in Sweden (Scania, Blekinge and Halland) combined, but it only has a population of 25,000, and its density is about 1 / km2.\nPopulation.\nSweden has a population of 10 million as of January 2017. The mountainous north is considerably less populated than the southern and central regions, partly because the summer period lasts longer in the south, and this is where the more successful agricultural industries were originally established. Another historical reason is said to be the desired proximity to key trade routes and partners in continental Europe, e.g. Germany. As a result, all seven urban areas in Sweden with a population of 100,000 or more, are located in the southern half of the country.\nCities.\nCities and towns in Sweden are neither political nor administrative entities, but rather localities or urban areas independent of municipal subdivisions. \nThe largest city by population, and the one most significant for culture and media, is the capital of Stockholm located in the east, with a population of 1,250,000. The second-largest city is Gothenburg, with a population of 510,500, located in the southwest. The third-largest is Malm\u00f6 in the south, with 258,000. The largest city in the north is Ume\u00e5 with 76,000 inhabitants.\nNatural resources.\nSweden's natural resources include copper, gold, hydropower, iron ore, lead, silver, timber, uranium, and zinc.\nEnvironment.\nAcid rain has become an issue, as it is damaging soils and lakes and polluting the North Sea and the Baltic Sea. The HBV hydrology transport model has been used to analyze nutrient discharge to the Baltic from tributary watersheds.\nClimate.\nMost of Sweden has a temperate climate, despite its northern latitude, with largely four distinct seasons and mild temperatures throughout the year. The winter in the far south is usually weak and is manifested only through some shorter periods with snow and sub-zero temperatures, autumn may well turn into spring there, without a distinct period of winter. The northern parts of the country have a subarctic climate while the central parts have a humid continental climate. The coastal south can be defined as having either a humid continental climate using the 0\u00a0\u00b0C isotherm, or an oceanic climate using the \u20133\u00a0\u00b0C isotherm.\nDue to the increased maritime moderation in the peninsular south, summer differences between the coastlines of the southernmost and northernmost regions are about in summer and in winter. This grows further when comparing areas in the northern interior where the winter difference in the far north is about throughout the country. The warmest summers usually happen in the M\u00e4laren Valley around Stockholm due to the vast landmass shielding the middle east coast from Atlantic low-pressure systems in July compared to the south and west. Daytime highs in Sweden's municipal seats vary from to in July and to in January. The colder temperatures are influenced by the higher elevation in the northern interior. At sea level instead, the coldest average highs range from to . As a result of the mild summers, the arctic region of Norrbotten has some of the northernmost agriculture in the world.\nSweden is much warmer and drier than other places at a similar latitude, and even somewhat farther south, mainly because of the combination of the Gulf Stream and the general west wind drift, caused by the direction of planet Earth's rotation. Continental west-coasts (to which all of Scandinavia belongs, as the westernmost part of the Eurasian continent), are notably warmer than continental east-coasts; this can also be seen by comparing e.g. the Canadian cities of Vancouver and Halifax, Nova Scotia with each other, the winter in west coast Vancouver is much milder; also, for example, central and southern Sweden has much milder winters than many parts of Russia, Canada, and the northern United States. Because of Sweden's high latitude, the length of daylight varies greatly. North of the Arctic Circle, the sun never sets for part of each summer, and it never rises for part of each winter. In the capital, Stockholm, daylight lasts for more than 18 hours in late June but only around 6 hours in late December. Sweden receives between 1,100 and 1,900 hours of sunshine annually.\nThe highest temperature ever recorded in Sweden was in M\u00e5lilla in June 1947, a record shared with Ultuna in Uppland. The coldest temperature ever recorded was in Vuoggatj\u00e5lme on 2 February 1966. Temperatures expected in Sweden are heavily influenced by the large Fennoscandian landmass, as well as continental Europe and western Russia, which allows hot or cool inland air to be easily transported to Sweden. That, in turn, renders most of Sweden's southern areas having warmer summers than almost everywhere in the nearby British Isles, even matching temperatures found along the continental Atlantic coast as far south as in northern Spain. In winter, however, the same high-pressure systems sometimes put the entire country far below freezing temperatures. There is some maritime moderation from the Atlantic which renders the Swedish continental climate less severe than that of nearby Russia. Even though temperature patterns differ between north and south, the summer climate is surprisingly similar all through the entire country in spite of the large latitudinal differences. This is due to the south's being surrounded by a greater mass of water, with the wider Baltic Sea and the Atlantic air passing over lowland areas from the south-west.\nApart from the ice-free Atlantic bringing marine air into Sweden tempering winters, the mildness is further explained by prevailing low-pressure systems postponing winter, with the long nights often staying above freezing in the south of the country due to the abundant cloud cover. By the time winter finally breaks through, daylight hours rise quickly, ensuring that daytime temperatures soar quickly in spring. With the greater number of clear nights, frosts remain commonplace quite far south as late as April. The cold winters occur when low-pressure systems are weaker. An example is that the coldest ever month (January 1987) in Stockholm was also the sunniest January month on record.\nThe relative strength of low and high-pressure systems of marine and continental air also define the highly variable summers. When hot continental air hits the country, the long days and short nights frequently bring temperatures up to or above even in coastal areas. Nights normally remain cool, especially in inland areas. Coastal areas can see so-called \"tropical nights\" above occur due to the moderating sea influence during warmer summers. Summers can be cool, especially in the north of the country. Transitional seasons are normally quite extensive and the four-season climate applies to most of Sweden's territory, except in Scania where some years do not record a meteorological winter (see table below) or in the high Lapland mountains where polar microclimates exist.\nOn average, most of Sweden receives between of precipitation each year, making it considerably drier than the global average. The south-western part of the country receives more precipitation, between , and some mountain areas in the north are estimated to receive up to . Despite northerly locations, southern and central Sweden may have almost no snow in some winters. Most of Sweden is located in the rain shadow of the Scandinavian Mountains through Norway and north-west Sweden. The blocking of cool and wet air in summer, as well as the greater landmass, leads to warm and dry summers far north in the country, with quite warm summers at the Bothnia Bay coast at 65 degrees latitude, which is unheard of elsewhere in the world at such northerly coastlines.\nIt is predicted that as the Barents Sea gets less frozen in the coming winters, becoming thus \"Atlantified\", additional evaporation will increase future snowfalls in Sweden and much of continental Europe.\nSwedish Meteorological Institute, SMHI's monthly average temperatures of some of their weather stations \u2013 for the latest scientific full prefixed thirty-year period 1961\u20131990\nNext will be presented in year 2020. The weather stations are sorted from south towards north by their numbers.\nExtreme points.\nThe extreme points of Sweden include the coordinates that are farthest north, south, east and west in Sweden, and the ones that are at the highest and the lowest elevations in the country. Unlike Norway and Denmark, Sweden has no external territories that can be considered either inside or outside the country depending on definition, meaning that the extreme points of Sweden are unambiguous.\nThe latitude and longitude are expressed in , in which a positive latitude value refers to the Northern Hemisphere, and a negative value refers to the Southern Hemisphere. Additionally, a negative elevation value refers to land below sea level. The coordinates used in this article are sourced from Google Earth, which makes use of the World Geodetic System (WGS)\u00a084, a geodetic reference system.\nLatitude and longitude.\nSweden's northernmost point is Treriksr\u00f6set, in the Lapland province, where the borders of Sweden, Norway, and Finland meet. The closest Swedish city to the area is Kiruna, which is Sweden's northernmost city. Sweden's southernmost point is in the harbour of the fishing village Smygehuk, near the city of Trelleborg, which borders the Baltic Sea. At the pier of the harbour, a signpost displays the exact position of the point, as well as the distance to Treriksr\u00f6set, Stockholm, Berlin, Paris, and Moscow.\nSweden's westernmost point is on Stora Drammen, an islet in Skagerrak outside the coast of Bohusl\u00e4n. Seabirds and harbor seals have colonies on the islet, but it is uninhabited by humans. Sweden's easternmost point is on Kataja, an islet south of Haparanda in the Bothnian Bay. The islet is divided between Sweden and Finland. The border was established in 1809, after the Finnish War, between what was previously two islets, a Swedish one called Kataja and a smaller Finnish one called Inakari. Since 1809, post-glacial rebound has caused the sea level in the region to drop relative to land level, joining the two islets. If counting the mainland only, Stensvik in Str\u00f6mstad is Sweden's westernmost point, and Sundholmen in Haparanda is the easternmost point.\nElevation.\nThe highest point in Sweden is the northern peak of Kebnekaise, which stands at . It is in the Scandinavian Mountains chain, in the province of Lapland. The mountain has two peaks, of which the glaciated southern one was until fairly recently the highest at above . The top glacier on the southern peak has shrunk fast; therefore the summit is not as high as earlier. It was in 2008.\nThe northern peak, which stands at , is free of ice. Other points of comparable height in the vicinity of Kebnekaise include Sarektj\u00e5kka at , and Kaskasatj\u00e5kka at .\nSweden's lowest point, which is below sea level, is in the Kristianstads Vattenrike Biosphere Reserve in the city of Kristianstad. The point is at the bottom of what was once Nosabyviken, a bay on the lake of Hammarsj\u00f6n. The bay was drained in the 1860s by John Nun Milner, an engineer, to get more arable land for Kristianstad.\nTransportation.\nOnly public transportation.\nHistorically.\nNorthernmost:\nSouthernmost: \nWesternmost:\nEasternmost:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26890", "revid": "49380818", "url": "https://en.wikipedia.org/wiki?curid=26890", "title": "Demographics of Sweden", "text": " \nThe demography of Sweden is monitored by the (Statistics Sweden). Sweden's population was 10,588,818 (1 April 2025), making it the 15th-most populous country in Europe after Czech Republic, the 10th-most populous member state of the European Union, and the 89th-most populous country in the world. The total fertility rate was rated at 1.43 in 2024, which is far below the replacement rate of 2.1.\nThe population exceeded 10 million for the first time on Friday, 20 January 2017. The three largest cities are Stockholm, Gothenburg and Malm\u00f6. Sweden's population has become much more ethnically, religiously and linguistically non-Swedish over the past 70 years as a result of immigration. Every fourth (24.9%) resident in the country has a foreign background and every third (32.3%) has at least one parent born abroad. The most common foreign ancestry is Finnish.\nStatistics Sweden projects a Swedish population of 12.6 million in 2070.\nPopulation.\nCities.\nSweden has 17 cities with a population of over 100,000 people. Most of Sweden's population lives in Svealand and G\u00f6taland.\nFertility.\nThe total fertility rate is the number of children born per woman. It is based on fairly good data for the entire period. Sources: Our World In Data and Gapminder Foundation.\nLife expectancy.\nSources: Our World In Data and the United Nations.\n1751\u20131949\n1950\u20132015\nSource: \"UN World Population Prospects\"&lt;templatestyles src=\"Template:Largest_cities/styles.css\" /&gt;\nStatistics.\nDemographic statistics according to the CIA World Factbook, unless otherwise indicated.\n&lt;includeonly&gt;&lt;templatestyles src=\"Chart/styles.css\"/&gt;&lt;/includeonly&gt;\n&lt;includeonly&gt;&lt;templatestyles src=\"Chart/styles.css\"/&gt;&lt;/includeonly&gt;\n&lt;includeonly&gt;&lt;templatestyles src=\"Chart/styles.css\"/&gt;&lt;/includeonly&gt;\nPopulation change.\nThe demography of Sweden is monitored by Statistics Sweden (SCB).\nThe 2005 Swedish census showed an increase of 1,488,322 compared to the 1990 census, an average increase of 88,680 annually. During the 1930s, birth rate increased by more than 88128.5 children per year while death rates fell and immigration surged. In the early 2000s, birth rate declined as immigration increased further, with the context of unrest in the Middle East, upholding steady population growth.\nPopulation projections.\nIn 1950 Sweden had fewer people aged 10\u201320 with more people ages 20\u201330 and 0\u201310. In 2017 the ratio of male to female remains steady at about 50\u201350. As a whole, the graph broadens with people appearing to live longer. In 2050 it is predicted that all ages will increase from below 300,000 males and females to above 300,000 males and females. With about 50,000 people living to the ages of 90\u2013100. In 2100 the graph is shaped as a rectangle with people of all ages and genders remaining steady. It narrows slightly at the top of the graph with about 250,000/300,000 males and females living to be 90\u2013100 years old.\nStatistics Sweden projects the following population development in Sweden:\nEurostat projects a population in Sweden reaching 11,994,364 people in 2040 and 14,388,478 in 2080.\nUrbanisation and population density.\nThe population density is just over 25 people per km2 (65 per square mile), with 1,437 persons per km2 in localities (continuous settlement with at least 200 inhabitants)., 87% of the population live in urban areas, which cover 1.5% of the entire land area. 63% of Swedes are in large urban areas. The population density is substantially higher in the south than in the north. The capital city Stockholm has a municipal population of about 950,000 (with 1.5 million in the urban area and 2.3 million in the metropolitan area). The second- and third-largest cities are Gothenburg and Malm\u00f6. Greater Gothenburg counts just over a million inhabitants and the same goes for the western part of Scania, along the \u00d6resund. The \u00d6resund Region, the Danish-Swedish cross-border region around the \u00d6resund that Malm\u00f6 is part of, has a population of 4 million. Outside of major cities, areas with notably higher population density include the agricultural part of \u00d6sterg\u00f6tland, the western coast, the area around Lake M\u00e4laren and the agricultural area around Uppsala.\nNorrland, which covers approximately 60% of the Swedish territory, has a very low population density (below 5 people per square kilometer). The mountains and most of the remote coastal areas are almost unpopulated. Low population density exists also in large parts of western Svealand, as well as southern and central Sm\u00e5land. An area known as \"Finnveden\", which is located in the south-west of Sm\u00e5land, and mainly below the 57th parallel, can also be considered as almost empty of people.\nOrigin.\nThe majority of the population are ethnic Swedes, or people who can trace most of their ethnicity to Sweden going back at least 12 generations. The Sweden Finns are a large ethnic minority comprising approximately 50,000 along the Swedish-Finnish border, and 450,000 first and second-generation immigrated ethnic Finns, mainly living in the M\u00e4laren Valley region. Me\u00e4nkieli Finnish has official status in parts of northern Sweden near the Finnish border.\nIn addition, Sweden's indigenous population groups include the S\u00e1mi people, who have a history of practicing hunting and gathering and gradually adopting a largely semi-nomadic reindeer herding lifestyle. The S\u00e1mi have lived in Fennoscandia from at earliest 3,500 years to at latest around 2,650 years ago, with evidence of a distinct ethnic identity linked to an early S\u00e1mi language diverging from early Finnish by the first millenium BC. S\u00e1mi presence in Scandinavia does not predate Norse/Scandinavian settlement of Scandinavia, as sometimes assumed \u2014 the migration of Germanic-speaking peoples to Southern Scandinavia happened independently and separate from the later S\u00e1mi migrations into the northern regions. However, S\u00e1mi presence in those northernmost regions, called S\u00e1pmi, does predate the Viking expansion, the establishment of Sweden as a country, and Sweden's colonization of S\u00e1pmi during the 1600s. It is this presence in the northernmost areas of Sweden, predating the Swedish colonization and presence in the S\u00e1pmi regions of Sweden, that is the basis for their classification as an indigenous people under ILO 169. Today, the S\u00e1mi language holds the status of official minority language in the Norrbotten, V\u00e4sterbotten and J\u00e4mtland counties.\nIn addition to the S\u00e1mi, Tornedalers, and Sweden Finns, Jewish and Roma people have national minority status in Sweden.\nThere are no official statistics on ethnicity, but according to Statistics Sweden, around two million (19.6%) inhabitants in Sweden are born in another country. Of those, more than half are Swedish citizens. The most common countries of origin were Syria (1.82%), Finland (1.45%), Iraq (1.41%), Poland (0.91%), Iran (0.76%) and Somalia (0.67%). The average age in Sweden is 41.1 years.\nThere are at least two studies that forecast future demographic changes in Sweden largely due to immigration and low birth rates. A 2006 study states that \"[based upon current data, extrapolated with relevant assumptions] Sweden and the Netherlands would have majority foreign-origin populations by the end of the [21st] century.\" A 2018 study concluded that in Sweden by \"2065, the share of the native population is [set] to decrease to 49%, the Western population is projected to fall to 63%, and the Muslim population increase to 25%.\" Thomas Lindh, at the time head researcher for the Swedish Institute for Futures Studies, claimed in an interview that by the year \"2050, more than half of Sweden's population will be immigrants or second-generation immigrants.\"\nVital statistics.\nData according to Statistics Sweden, which collects the official statistics for Sweden.\nNotable events in Swedish demographics:\n&lt;templatestyles src=\"template:sticky header/styles.css\"/&gt;&lt;templatestyles src=\"Template:Sort under/styles.css\" /&gt;&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;\nIn 2021 80,465 (70.4%) babies were born to Swedish-born mothers while 33,798 (29.6%) were born to foreign-born mothers. The total fertility rate for Swedish-born women was 1.62, for foreign-born ones 1.86.\nIn 2022 73,294 (70.0%) babies were born to Swedish-born mothers while 31,440 (30.0%) were born to foreign-born mothers. The total fertility rate for Swedish-born women was 1.47, for foreign-born ones 1.69.\nStructure of the population.\n&lt;templatestyles src=\"Template:Hidden begin/styles.css\"/&gt;Population Estimates by Sex and Age Group (01.I.2021) (Population statistics are compiled from registers. Data refer to registered resident population.): \nMigration.\nPrior to World War II, emigrants generally outnumbered immigrants. Since then, net migration has been positive with many immigrants coming to Sweden from the 1970s through today.\nEmigration.\nBetween 1820 and 1930, approximately 1.3 million Swedes, a third of the country's population at the time, emigrated to North America, and most of them to the United States. There are more than 4.4 million Swedish Americans according to a 2006 US Census Bureau estimate. In Canada, the community of Swedish ancestry is 330,000 strong.\nImmigration.\nThe demographic profile of Sweden has altered considerably due to immigration patterns since the 1970s. As of 2020, Statistics Sweden reported that around 2,686,040 or 25.9% of the inhabitants of Sweden were from a foreign background: that is, each such person either had been born abroad or had been born in Sweden to two parents who themselves had both been born abroad. Also taking into account people with only one parent born abroad, this number increases to one third (33.5%).\nAdditionally, the birth rate among immigrant women after arriving in Sweden is somewhat higher than among ethnic Swedes. Taking into account the fact that immigrant women have on average fewer children than Swedish women of comparable age, however, the difference in total birth rate is only 0.1 children more if the woman is foreign born \u2013 with the disclaimer that some women may have children not immigrating to and not reported in Sweden, who are thus not included in the statistics.\nHistorical immigration.\nImmigration increased markedly with World War II. Historically, the most numerous of foreign born nationalities are ethnic Germans from Germany and other Scandinavians from Denmark and Norway. In short order, 70,000 war children were evacuated from Finland, of which 15,000 remained in Sweden. Also, many of Denmark's nearly 7,000 Jews who were evacuated to Sweden decided to remain there.\nA sizeable community from the Baltic countries (Estonia, Latvia and Lithuania) arrived during the Second World War.\nDuring the 1950s and 1960s, the recruitment of immigrant labour was an important factor of immigration. The Nordic countries signed a trade agreement in 1952, establishing a common labour market and free movement across borders. This migration within the Nordic countries, especially from Finland, was essential to create the tax-base required for the expansion of the strong public sector now characteristic of Scandinavia. but the influx gave rise to an anti-Finnish sentiment within Sweden and Norway.\nThis continued until 1967, when the labour market became saturated, and Sweden introduced new immigration controls.\nOn a smaller scale, Sweden took in political refugees from Hungary and the former Czechoslovakia after their countries were invaded by the Soviet Union in 1956 and 1968, respectively.\nContemporary immigration.\nSince the early 1970s, immigration to Sweden has been mostly due to refugee migration and family reunification from countries in the Middle East and Latin America.\nAccording to Eurostat, in 2010, there were 1.33 million foreign-born residents in Sweden, corresponding to 14.3% of the total population. Of these, 859,000 (64.3%) were born outside the EU and 477,000 (35.7%) were born in another EU Member State. By comparison, the Swedish civil registry reports, for 2018, that nearly 1.96 million residents are foreign-born, a 47% increase from 2010. There are 8.27 million Swedish-born residents, giving a total population of 10.23 million, and a 19.1% foreign-born population. Malm\u00f6, the third largest city of Sweden and Sk\u00e5ne County as a whole have taken in highest numbers of refugees who reached Sweden, in particular during the Yugoslav Wars in the 1990s and the Syrian civil war in the 2010s.\nThe first group of Assyrians/Syriacs moved to Sweden from Lebanon in 1967. Many of them live in S\u00f6dert\u00e4lje (Stockholm). There are also around 40,000 Roma in Sweden. Some Roma people have long historical roots in Sweden, while others are more recent migrants from elsewhere in Europe.\nImmigrants from Western Asia have been a rapidly growing share of Sweden's population. According to the government agency Statistics Sweden, the number of immigrants born in all of Asia (including the Middle East) rose from just 1,000 in 1950 to 295,000 in 2003. Most of those immigrants came from Iraq, Iran, Lebanon and Syria, according to Statistics Sweden.\nImmigration of Iraqis increased dramatically during the Iraq War, beginning in 2003. A total of 8,951 Iraqis came to Sweden in 2006, accounting for 45% of the entire Iraqi migration to Europe. By 2007, the community of Iraqis in Sweden numbered above 70,000. In 2008, Sweden introduced tighter rules on asylum seekers.\nA significant number of Syrian Christians have also settled in Sweden. There have also been immigrants from South-Central Asia such as Afghanistan and India. Since the European migrant crisis, Syrians became the second-largest group of foreign-born persons in the Swedish civil registry in 2017 with 158,443 people (after former Yugoslavia).\nNote that the table below lists the citizenship the person had when arriving in Sweden, and therefore there are no registered Eritreans, Russians or Bosnians from 1990, they were recorded as Ethiopians, Soviets and Yugoslavs. The nationality of Yugoslavs below is therefore people who came to Sweden from the Socialist Federal Republic of Yugoslavia before 1991 and people who came from today's Montenegro and Serbia before 2003, then called the Federal Republic of Yugoslavia. Counting all people who came from Slovenia, Croatia, Bosnia and Herzegovina, Serbia, Montenegro, Kosovo, Macedonia, Serbia and Montenegro, the Federal Republic of Yugoslavia and the Socialist Federal Republic of Yugoslavia, there were 176,033 people from there in 2018.\n&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;\nLanguage.\nThe Swedish language is by far the dominating language in Sweden, and is used by the government administration. English is also widely spoken and is taught in public schools.\nSince 1999, Sweden has five officially recognised minority languages: S\u00e1mi, Me\u00e4nkieli, Finnish, Romani and Yiddish.\nThe S\u00e1mi languages, spoken by about 20,000\u201330,000 people worldwide, may be used in government agencies, courts, preschools and nursing homes in 26 municipalities: Arjeplog, Arvidsjaur, Berg, Dorotea, G\u00e4llivare, H\u00e4rjedalen, Jokkmokk, Kiruna, Krokom, Lule\u00e5, Lycksele, Mal\u00e5, Sorsele, Skellefte\u00e5, Stockholm, Storuman, Str\u00f6msund, Sundsvall, Ume\u00e5, Vilhelmina, Vindeln, \u00c5re, \u00c5sele, \u00c4lvdalen, \u00d6rnsk\u00f6ldsvik and \u00d6stersund.\nMe\u00e4nkieli-speakers have the same rights as above in the following nine municipalities: G\u00e4llivare, Haparanda, Kiruna, Pajala, \u00d6vertorne\u00e5, Kalix, Lule\u00e5, Stockholm and Ume\u00e5.\nFinnish-speakers have the same rights as above in 66 of Sweden's 290 municipalities.\nDuring the mid to late 20th and early 21st centuries, immigrant communities brought other languages, such as Persian, Serbo-Croatian, Arabic and Neo-Aramaic.\nReligion.\nThe majority (52.1%) of the population belongs to the Church of Sweden, the Lutheran church that was disestablished as a state church in 2000. Until 1996, those who had family members in the church automatically became members at birth. Other Christian denominations in Sweden include the Roman Catholic Church (see Catholic Church in Sweden), several Orthodox churches in diaspora, Baptist, Pentecostal, Neo-pietistic (\"nyevangeliska\") and other evangelical Christian churches (\"frikyrkor\" = 'free churches'). Shamanism persisted among the S\u00e1mi people up until the 18th century, but no longer exists in its traditional form as most S\u00e1mi today belong to the Lutheran church.\nJews were permitted to practice their religion in five Swedish cities in 1782, and have enjoyed full rights as citizens since 1870. The new Freedom of Religion Bill was passed in 1951, and former obstacles against Non-Lutherans working in schools and hospitals were removed. Further, that bill made it legal to leave any religious denomination, without entering another. There are also many Muslims, as well as a number of Buddhists and Bah\u00e1\u02bc\u00eds in Sweden, mainly as a result of 20th and 21st century immigration. There is also a small Zoroastrian community in Sweden.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26893", "revid": "41600801", "url": "https://en.wikipedia.org/wiki?curid=26893", "title": "Telecommunications in Sweden", "text": " \nThis article covers telecommunications in Sweden.\nTelecommunications.\nSweden liberalized its telecommunications industry starting in 1980s and being formally liberalized in 1993. This was three years ahead of USA and five years before the European common policy introduced in January 1998 allowed for an open and competitive telecommunication market. The Swedes, most of who are computer literate, enjoy a continuous growth in the Internet market and the availability of technologies such as Metro Ethernet, fiber, satellite, WAN access technologies and even the availability of 3G services. Statistically, 6.447 (2004) million telephone main lines are in use, 8.0436 (2005) million mobile cellular telephones are in use and 6.7 million Swedes are regular internet users.\nThis abundance of telecommunication technology is a result of promoting a competitive industry that was made possible by deregulation. Since Sweden was the first to take on this arduous task the government had to come up with \"a regulatory framework of its own\". The processes that went about resulting in the liberalization of the telecommunications' industry can be structured into three phases: \"Phase 1 of monopoly to Phase 2 with a mix of monopoly and competition to a \"mature\" Phase 3 with extensive competition\".\nDuring the period of 1993-2000 there is rise in competition with legislation of the regulatory body being changed several times. In the case of the POTS, Telia in 2000 still held monopoly in the fixed-line access market. Whereas, mobile phone and Internet penetration in the household market ended up being one of the highest in the world with more than 50 percent of the revenue coming from these two industries. There were three major organizations providing GSM services and 120 internet service providers. One of the major causes that lead competitions thrive in areas that did not have a history of monopoly was the light handed approach taken towards the interconnection issue by the regulatory body initially. Telia held very high interconnection charges, making it very difficult for new entrants to enter. But what it did do was push the new entrants to enter other markets. Tele2 did just that by taking out a massive marketing campaign to attract a huge number of customers to its internet access service. This campaign was successful enough to bring back Telia to the negotiation table over the interconnection issue . This process eventually lead to the abolition of the light handed regulatory approach towards interconnection and put more power in the hands of the regulatory body. The intensity of regulation kept increasing around 1999 in areas other than POTS, especially the mobile market.\nSignals intelligence.\nIn 2009, the Riksdag passed new legislation regulating the National Defence Radio Establishment (FRA), enabling them to collect information from both wireless and cable bound signals passing the Swedish border. Since most communications in Sweden pass through its borders at one point or another, this monitoring in practice affects most traffic within Sweden as well.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26894", "revid": "6032993", "url": "https://en.wikipedia.org/wiki?curid=26894", "title": "Transport in Sweden", "text": " \nTransport in Sweden is available for all four main modes of transport\u2014air, bus, ferry and rail\u2014assisting residents and visitors without their own vehicle to travel around much of Sweden's .\nRail.\nRail transport is operated by SJ, DSBFirst, Green Cargo, Vy T\u00e5g and more. Most counties have companies that provide ticketing, marketing and financing of local passenger rail, but the actual operation is undertaken by the aforementioned companies. There is 11,663\u00a0km of railway, of which 9,227 km is nationalised and 3,594 km is county-owned. As of 2008, over 11,000 km of rails are gauge, of which 7,531 km is electrified. There are 65 km of gauge.\nTrains generally keep to the left, as opposed to all neighbouring countries, a legacy of Sweden\u2019s driving direction prior to 1967.\nLight rail and metros.\nStockholm Metro (\"Stockholms tunnelbana\") is the only metro system in Sweden.\nCities with light rail (trams);\nStockholm previously had a large tram network, but this was discontinued in favour of bus and metro; a revival of the tram network was seen in the construction of Tv\u00e4rbanan in the late 1990s and early 2000s.\nRoad.\nSweden has right-hand traffic today, like all its neighbours.\nSweden had left-hand traffic (\"V\u00e4nstertrafik\" in Swedish) from approximately 1736 and continued to do so until 1967. Despite this virtually all cars in Sweden were actually left-hand drive and the neighbouring Nordic countries already drove on the right, leading to mistakes by visitors. The Swedish voters rejected a change to driving on the right in a referendum held in 1955.\nNevertheless, in 1963 the Riksdag passed legislation ordering the switch to right-hand traffic. The changeover took place on a Sunday morning at 5am on September 3, 1967, which was known in Swedish as \"Dagen H\" (H-Day), the 'H' standing for \"H\u00f6gertrafik\" or right-hand traffic.\nSince Swedish cars were left-hand drive, experts had suggested that changing to driving on the right would reduce accidents, because drivers would have a better view of the road ahead. Indeed, fatal car-to-car and car-to-pedestrian accidents did drop sharply as a result. This was likely due to drivers initially being more careful and because of the initially very low speed limits, since accident rates soon returned to nearly the same as earlier.\nTotal roadways: 572,900\u00a0km, as of 2009.\nMotorways.\nMotorways run through Sweden, Denmark and over the \u00d6resund Bridge to Stockholm, Gothenburg, Uppsala and Uddevalla. The system of motorways is still being extended. The longest continuous motorways are V\u00e4rnamo\u2013G\u00e4vle (E4; 585\u00a0km) and the Norwegian border\u2013Vellinge (E6; 482\u00a0km; as the motorway between Trelleborg and Oslo in Norway has been completed in 2015).\nPorts and harbours.\nThere are of waterways in Sweden.\nThere are 19 ports which are navigable to small steamers and barges.\nAir.\nIn 2012, there were 230 airports in Sweden. Of these, 149 have paved runways, with three (Stockholm Arlanda, G\u00f6teborg Landvetter and Lule\u00e5) being over long. There are over eighty airports with unpaved runways. A large number of war-time airfields exist in various lengths, usually built into roads, and are usually less than long. \nEvery hospital, airport and military base has a helipad.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "26895", "revid": "3828001", "url": "https://en.wikipedia.org/wiki?curid=26895", "title": "Swedish Armed Forces", "text": "National military force of Sweden\nThe Swedish Armed Forces (, literally The \"Defence Force\") are the armed forces of the Kingdom of Sweden. It consists of four separate military branches, the Swedish Army, the Swedish Navy, the Swedish Air Force and the Home Guard.\nSweden's military has undergone a significant transformation in recent years, driven by a rapidly evolving security environment in Europe and its historic decision to join NATO in March 2024.2 This shift has led to substantial increases in defence spending, ambitious personnel expansion plans, and a renewed focus on territorial defence alongside continued international engagement.\nThe Swedish Armed Forces have a long history, and reached their height in the seventeenth century, during the time of the Swedish Empire, when they participated in a variety of wars; these include the Scanian War, Northern War of 1655\u20131660, and Great Northern War, among others. Since the nineteenth century, they have also played an important role in the maintenance of Swedish neutrality, especially during the Cold War.\nThe Swedish Armed Forces consist of 25,600 active personnel, including 9,700 officers, 5,700 enlisted soldiers, and 10,200 civilian employees. Additionally, there are 7,100 reserve officers and 4,700 part-time enlisted soldiers, along with 22,200 soldiers in the Home Guard. As of 2023, 6,300 conscripts undergo military training annually, set to increase to 8,000 by 2025. In wartime, the total personnel is estimated to be 88,000, including all regularly employed personnel, reservists, and conscripts.\nUnits of the Swedish Armed Forces are currently on or have taken part in several international operations either actively or as military observers, including Afghanistan as part of the Resolute Support Mission and in Kosovo (as part of Kosovo Force). Moreover, the Swedish Armed Forces contribute as the leading state for a European Union Battlegroup approximately once every three years through the Nordic Battlegroup. Prior to 2024 Sweden had close relations with NATO and NATO members, and participates in training exercises like the Admiral Pitka Recon Challenge, and Exercise Trident Juncture 2018. In 2024, the country formally became a member of NATO. Sweden also has a strong cooperation with its closest allies of the Nordic countries, being part of the Nordic Defence Cooperation, Joint Expeditionary Force, and joint exercises such as Exercise Northern Wind.\nSweden has not participated in an officially declared war since the 1814 Swedish\u2013Norwegian War, although its forces, under the UN flag, have been involved in such conflicts as the Congo Crisis and the military intervention in Libya.\nEquipment.\nThe Swedish army has 121 tanks (Leopard 2/Strv 122), roughly 1,540 APCs (Patria XA-360/203/180, RG-32 Scout, Bv410, Bv308/309), 450 IFVs (CV9040), 11,300 utility vehicles (ex. Bv206/208, MB G-Class 6x6 and 4x4, MB sprinter), 84 towed and 40 self-propelled mortar (12 cm grk m/41, grkpbv90) and 26 self-propelled artillery guns (Archer). It also consists of several different specialized vehicles.\nThe Swedish Navy has a total of 387 ships, including 4 submarines (3 Gotland, 1 S\u00f6dermanland), 7 corvettes (5 Visby, 2 G\u00e4vle), 9 minesweepers (5 Koster, 4 Styrs\u00f6), 13 larger patrol boats (2 Stockholm and 11 Tapper) and 9 specialised ships with different support duties. The rest is made up of different smaller vessels such as the CB90.\nCurrently the Swedish Airforce has a total of 210 aircraft, 94 of those being JAS39C/D Gripen (60 JAS39E on order), 6 C130H Hercules (1 with aerial refueling capabilities), 4 SAAB 340 (2 AEW&amp;C and 2 VIP transport), 4 Gulfstream IV (2 SIGINT and 2 VIP transport) as well as 15 UH-60 Blackhawk, 18 NH90 and 20 AgustaWestland helicopters. The rest is made up of different transport and trainer aircraft.\nHistory.\nThe history of the Swedish Armed Forces dates back to the early sixteenth century, when they were founded by the newly crowned monarch Gustav I Vasa. Since then, they have played an important role in the history of Sweden; they have been engaged in numerous conflicts since their founding.\nIt was in the seventeenth century that the Swedish Armed Forces reached their height, during the time of the Swedish Empire. During this time, they were among the leaders in military innovation, and engaged in many wars; among the Swedish wars of the seventeenth century were the Thirty Years' War, Second Northern War, Scanian War and Great Northern War. The military of the Swedish Empire was one of the most important institutions in the empire.\nAfter a period of enhanced readiness during World War I, the Swedish Armed Forces were subject to severe downsizing during the interwar years. When World War II started, a large rearmament program was launched to once again guard Swedish neutrality, relying on mass male conscription as a source for personnel.\nAfter World War II, Sweden considered building nuclear weapons to deter a Soviet invasion. From 1945 to 1972 the Swedish government ran a clandestine nuclear weapons program under the guise of civilian defence research at the Swedish National Defence Research Institute. By the late 1950s, the work had reached the point where underground testing was feasible. However, at that time the Riksdag prohibited research and development of nuclear weapons, pledging that research should be done only for the purpose of defence against nuclear attack. The option to continue development was abandoned in 1966, and Sweden subsequently signed the Non-Proliferation Treaty in 1968; the program was finally concluded in 1972.\nDuring the Cold War, the wartime mass conscription system was kept in place to act as a deterrent to the Soviet Union, seen as the greatest military threat to Sweden. The end of the Cold War and the collapse of the Soviet Union meant that the perceived threat lessened and the armed forces were downsized, with conscription taking in fewer and fewer recruits until it was deactivated in 2010. This small size is often considered one of the major strategic weaknesses of the Swedish Armed Forces.\nThe Russo-Georgian War of 2008 and the events in Ukraine in 2014 gradually shifted Swedish debate back in favour of increased defence spending, as concerns grew over Russia's military buildup and intentions. Conscription was reintroduced in 2017 to supplement the insufficient number of volunteers signing up for service. Unlike in the past, the current conscription system applies to both men and women.\nFollowing the United Kingdom leaving the European Union in 2020, the EU's mutual defence clause (Lisbon Treaty Article 42.7) ceased to apply to the UK. In 2022, Sweden and the UK signed a mutual security deal, re-pledging support if either state is attacked.\nOn June 29, 2022, Finland and Sweden were formally invited to become members of NATO, and joined respectively in 2023 and 2024.\nDoctrine.\nThe Swedish Armed Forces have four main tasks:\nSweden aims to have the option of remaining neutral in case of proximate war. However, Sweden cooperates militarily with a number of foreign countries. As a member state of the European Union, Sweden is acting as the leading state for EU Battlegroups and also has a close cooperation, including joint exercises, with NATO through its membership in Partnership for Peace and Euro-Atlantic Partnership Council. In 2008 a partnership was initiated between the Nordic countries to, among other things, increase the capability of joint action, and this led to the creation of the Nordic Defence Cooperation (NORDEFCO). As a response to the expanded military cooperation the defence proposition of 2009 stated that Sweden will not remain passive if a Nordic country or a member state of the European Union were attacked.\nRecent political decisions have strongly emphasized the capability to participate in international operations, to the point where this has become the main short-term goal of training and equipment acquisition. However, after the 2008 South Ossetia war territorial defence was once again emphasized. Until then most units could not be mobilized within one year. In 2009 the Minister for Defence stated that in the future all of the armed forces must be capable of fully mobilizing within one week.\nIn 2013, after Russian air exercises in close proximity to the Swedish border were widely reported, only six percent of Swedes expressed confidence in the ability of the nation to defend itself.\nOrganisation.\nThe Chief of Defence, formerly the Supreme Commander of the Swedish Armed Forces (, \u00d6B), is a four-star general or flag officer who is the agency head of the Swedish Armed Forces and the highest ranking professional officer on active duty. The Chief of Defence reports, normally through the Minister of Defence, to the Government of Sweden, which in turn answers to the Riksdag. The current chief of defence is General Michael Claesson.\nBefore the enactment of the 1974 Instrument of Government, the King of Sweden was the de jure commander in chief (). Since then, King Carl XVI Gustaf is still considered to hold the honorary ranks of general and admiral \"\u00e0 la suite\", but the role is entirely ceremonial.\nThe Swedish Armed Forces consists of three service branches; the Army, the Air Force and the Navy, with addition of the military reserve force Home Guard. Since 1994, the first three service branches are organized within a single unified government agency, headed by the Chief of Defence, while the Home Guard reports directly to the chief. However, the services maintain their separate identities through the use of different uniforms, ranks, and other service specific traditions.\nArmed Forces Headquarters.\nThe Swedish Armed Forces Headquarters is the highest level of command in the Swedish Armed Forces. It is led by the Chief of Defence (formerly the Supreme Commander of the Swedish Armed Forces) with a civilian director-general as his deputy, with functional directorates having different responsibilities (e.g. the Military Intelligence and Security Service). Overall, the Armed Forces Headquarters has about 2,100 employees, including civilian personnel.\nSchools.\nSome of the schools listed below answer to other units, listed under the various branches of the Armed Forces:\nCentres.\nNordic Battlegroup.\nThe Nordic Battlegroup is a cooperative formation of the Swedish Armed Forces alongside mainly the other Nordic countries but also some of the Baltic countries as well as Ireland, tasked as one of the EU Battlegroups. The headquarter garrison for this group is currently situated in Enk\u00f6ping, Sweden.\nInternational deployments.\nSweden is part of the multinational Kosovo Force and has a naval force deployed to the gulf of Aden as a part of Operation Atalanta. Military observers from Sweden have been sent to a large number of countries, including Georgia, Lebanon, Israel and Sri Lanka and Sweden also participates with staff officers to missions in Sudan and Chad. Sweden has been one of the Peacekeeping nations of the Neutral Nations Supervisory Commission that is tasked with overseeing the truce in the Korean Demilitarized Zone since the Korean war ended in 1953. It was revealed in 2025 that Sweden was assisting the US in Somalia, primarily in regards to identification of killed and captured terrorists.\nPast deployments.\nSwedish air and ground forces saw combat during the Congo Crisis, as part of the United Nations Operation in the Congo force. Nine army battalions were sent in all, and their mission lasted from 1960 to 1964.\nA battalion and other units were deployed with the NATO-led peacekeeping SFOR in Bosnia and Herzegovina (1996\u20132000), following the Bosnian War. NORDBAT 2 has been studied as an example of mission command on a chaotic battlefield with conflicting national orders.\nSweden had military forces deployed in Afghanistan with the NATO-led International Security Assistance Force (2002\u20132014), and the subsequent Resolute Support Mission (2015\u20132021), which ended when all NATO troops were withdrawn after 20 years of action.\nPersonnel.\nFrom national service to an all-volunteer force.\nIn mid-1995, with the national service system based on universal military training, the Swedish Army consisted of 15 maneuver brigades and, in addition, 100 battalions of various sorts (artillery, engineers, rangers, air defence, amphibious, security, surveillance etc.) with a mobilisation-time of between one and two days. When national service was replaced by a selective service system, fewer and fewer young men were drafted due to the reduction in size of the armed forces. By 2010 the Swedish Army had two battalions that could be mobilized within 90 days. When the volunteer system had been fully implemented by 2019, the army consisted of 7 maneuver battalions and 14 battalions of various sorts with a readiness of one week. The Home Guard was reduced in size to 22,000 soldiers. In 2019 the Swedish Armed Forces, now with a restored national service system combined with volunteer forces, aimed to reach 3 brigades as maneuver units by 2025.\nRe-implementing conscription.\nAfter having ended the universal male conscription system in 2010, as well as deactivating conscription in peacetime, the conscription system was re-activated in 2017. Since 2018 both women and men are conscripted on equal terms. The motivation behind reactivating conscription was the need for personnel, as volunteer numbers proved to be insufficient to maintain the armed forces.\nThe Swedish defence forces are currently educating 5,000-6,000 conscripts per year. However, after the Russian invasion of Ukraine, the defence forces stated that there is a need for significantly more than the current. By December 2022, it was announced to increase the yearly conscripted to 10,000 by the end of 2035. In addition, figures from 2022 show that 79% of Swedes support in some form, an increase in the number of people who are conscripted. 47% of the respondents said that the majority of 19/20 year-olds should perform conscription.\nPersonnel structure.\nMilitary personnel of the Swedish Armed Forces consists of:\nK = Continuously\nT = Part-time\nP = Conscript, for personnel drafted under the Swedish law of comprehensive defence duty\nPlanned size of the Swedish Armed Forces 2011\u20132020.\nAnnual recruitment of GSS is assumed to be about 4,000 persons.\nCriticism and research.\nIn 2008, professor Mats Alvesson of the University of Lund and Karl Yd\u00e9n of the University of Gothenburg claimed in an op-ed, based on Yd\u00e9n's doctoral dissertation, that a large part of the officer corps of the Swedish Armed Forces was preoccupied with administrative tasks instead of training soldiers or partaking in international operations. They claimed that Swedish officers were mainly focused on climbing the ranks and thereby increasing their wages and that the main way of doing this is to take more training courses, which decreases the number of officers that are specialized in their field. Therefore, the authors claimed, the Swedish Armed Forces were poorly prepared for their mission. Major changes have been made to the officer system since then.\nThe transformation of the old invasion defence-oriented armed forces to the new smaller and more mobile force has also been criticized. According to the Supreme Commander of the Swedish Armed Forces the present defence budget will not be enough to implement the new defence structure by 2019. And that even when finished the armed forces will only be able to fight for a week at most.\nDuring 2013 several Russian Air Force exercises over the Baltic Sea aimed at Swedish military targets have made \nthe future of the Swedish Armed Forces a hot topic and several political parties now want to increase defence funding. In August 2019, the government announced a bank tax to fund the military spending.\nRanks.\nWhen an army based on national service (conscription) was introduced in 1901 all commissioned officers had ranks that were senior of the warrant officers (\"underofficerare\") and non-commissioned officers (\"underbef\u00e4l\"). In a reform 1926 the relative rank of the then senior warrant officer, fanjunkare, was increased to be equal with the junior officer rank \"underl\u00f6jtnant\" and above the most junior officer rank \"f\u00e4nrik\". In 1960 the relative rank of the warrant officers were elevated further so that\nIn 1972 the personnel structure changed, reflecting increased responsibilities of warrant and non-commissioned officers, renaming the \"underofficerare\" as \"kompaniofficerare\", giving them the same ranks as company grade officers (\"f\u00e4nrik\", \"l\u00f6jtnant\", \"kapten\"). \"Underbef\u00e4l\" was renamed \"plutonsofficerare\" and given the rank titles of sergeant and \"fanjunkare\", although their relative rank were now placed below \"f\u00e4nrik\". The commissioned officers were renamed \"regementsofficerare\", beginning with \"l\u00f6jtnant\". The three-track career system was maintained, as well as three separate messes.\nA major change in the personnel structure in 1983 (NBO 1983), merged the three professional corps of platoon officers, company officers, and regimental officers into a one-track career system within a single corps called professional officers (\"yrkesofficerare\"). The three messes were also merged to one.\nIn 2008 the Riksdag decided to create a two-track career system with a category called \"specialistofficerare\". When implementing the parliamentary resolution the Supreme Commander decided that some ranks in this category should, like the old \"underofficerare\" ranks in 1960\u20131972, have a relative rank higher than the most junior officers.\nPlanned expansion.\nBudget and personnel numbers.\nThe Swedish government has decided to increase the military budget to 2.6 percent of GDP by 2028. Furthermore, by 2030, they plan to increase the number of conscripts to 10,000 and to have a standing force of four brigades. In 2027, the budget for military research will increase by 50% to 1.6 billion SEK. By 2030, the number of employees is expected to increase to 115,000, and to 130,000 by 2035.\nPlanned military budget\nEquipment purchases.\nSweden has also put an order on 44 Leopard 2 tanks and will renovate 66 of the ones they have in their current arsenal (for 22 billion SEK). Alongside these renovations, they will also modernise their Combat Vehicle 90 vehicles (until 2030). Furthermore, the armed forces have placed an order for 575 trucks from Scania and Volvo. They will cost approximately 1.4 billion SEK and are expected to be delivered between 2025 and 2026. An effort to modernize the army's firearms was made in 2023 by purchasing a large quantity of weapons in collaboration with Finland from the Finnish manufacturer Sako. The weapons will be delivered during a 10 year period.\nThe Swedish Navy has placed an order for two new working ships from Astilleros Armon Vigo SA. They are expected to be delivered between 2027 and 2028 and are intended to replace HMS Pelikanen and HMS Furusund. The Swedish fleet of Stridsb\u00e5t 90s will also be strengthened, with 10 units ordered from Saab in 2024 for approximately 400 million SEK.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nManpower-numbers are taken from "}
{"id": "26896", "revid": "46505507", "url": "https://en.wikipedia.org/wiki?curid=26896", "title": "Foreign relations of Sweden", "text": "The foreign policy of Sweden was formerly based on the premise that national security is best served by staying free of alliances in peacetime in order to remain a neutral country in the event of war, with this policy lasting from 1814 in the context of the French Revolutionary and Napoleonic Wars until the 2022 Russian Invasion of Ukraine. In 2002, Sweden revised its security doctrine. The security doctrine at that point still stated that \"Sweden pursues a policy of non-participation in military alliances,\" but permitted cooperation in response to threats against peace and security. The government also seeks to maintain Sweden's high standard of living. These two objectives required heavy expenditures for social welfare, defence spending at rates considered low by Western European standards (around 1.2% of GNP prior to 2022), and close attention to foreign trade opportunities and world economic cooperation. In 2024, Sweden formally became part of a military alliance for the first time since the end of the War of the Sixth Coalition by joining NATO.\nForeign policy.\nThe foreign policy of Sweden encompasses a range of themes over the centuries. Some of the main issues include:\nUnited Nations.\nSweden has been a member of the United Nations since November 19, 1946, and participates actively in the activities of the organization, including as an elected member of the Security Council (1957\u20131958, 1975\u20131976, 1997\u20131998 and 2017\u20132018), providing Dag Hammarskj\u00f6ld as the second elected Secretary-General of the UN, etc. The strong interest of the Swedish Government and people in international cooperation and peacemaking has been supplemented in the early 1980s by renewed attention to Nordic and European security questions.\nSweden decided not to sign the Treaty on the Prohibition of Nuclear Weapons.\nEuropean Union.\nAfter the then Prime Minister Ingvar Carlsson had submitted Sweden's application in July 1991 the negotiations began in February 1993. Finally, on January 1, 1995, Sweden became a member of the European Union. While some argued that it went against Sweden's historic policy of neutrality, where Sweden had not joined during the Cold War because it was seen as incompatible with neutrality, others viewed the move as a natural extension of the economic cooperation that had been going on since 1972 with the EU. Sweden addressed this controversy by reserving the right not to participate in any future EU defence alliance. In membership negotiations in 1993\u20131994, Sweden also had reserved the right to make the final decision on whether to join the third stage of the EMU \"in light of continued developments.\" In a nationwide referendum in November 1994, 52.3 percent of participants voted in favour of EU membership. Voter turnout was high, 83.3 percent of the eligible voters voted. The main Swedish concerns included winning popular support for EU cooperation, EU enlargement, and strengthening the EU in areas such as economic growth, job promotion, and environmental issues.\nIn polls taken a few years after the referendum, many Swedes indicated that they were unhappy with Sweden's membership in the EU. However, after Sweden successfully hosted its first presidency of the EU in the first half of 2001, most Swedes today have a more positive attitude towards the EU. The government, with the support of the Center Party, decided in spring 1997 to remain outside of the EMU, at least until 2002. A referendum was held on September 14, 2003. The results were 55.9% for \"no\", 42.0% \"yes\" and 2.1% giving no answer (\"blank vote\").\nNordic Council.\nSwedish foreign policy has been the result of a wide consensus. Sweden cooperates closely with its Nordic neighbors, formally in economic and social matters through the Nordic Council of Ministers and informally in political matters through direct consultation.\nNonalignment.\nSwedish neutrality and nonalignment policy in peacetime may partly explain how the country could stay out of wars since 1814. Swedish governments have not defined nonalignment as precluding outspoken positions in international affairs. Government leaders have favored national liberation movements that enjoy broad support among developing world countries, with notable attention to Africa. During the Cold War, Sweden was suspicious of the superpowers, which it saw as making decisions affecting small countries without always consulting those countries. With the end of the Cold War, that suspicion has lessened somewhat, although Sweden still chooses to remain nonaligned. Sweden has devoted particular attention to issues of disarmament, arms control, and nuclear nonproliferation and has contributed importantly to UN and other international peacekeeping efforts, including the NATO-led peacekeeping forces in the Balkans. It sat as an observer in the Western European Union from 1995 to 2011, but it is not an active member of NATO's Partnership for Peace and the Euro-Atlantic Partnership Council.\nSweden's engagement with NATO was especially strengthened during the term of Anders Fogh Rasmussen.\nSweden's nonalignment policy has led it to serve as the protecting power for a number of nations who don't have formal diplomatic relations with each other for various reasons. It currently represents the United States, Canada, and several Western European nations in North Korea for consular matters. On several occasions when the United Kingdom broke off relations with Iran (including the 1979 Iranian Revolution, the Salman Rushdie affair, and the 2011 storming of the British embassy in Tehran), Sweden served as the protecting power for the UK.\nIn May 2022, Sweden formally applied to join the NATO alliance. The public opinion in the Nordic region had changed in favour of joining NATO since Russia's invasion of Ukraine on February 24 of the same year.\nRussian Foreign Ministry spokeswoman Maria Zakharova said in March 2022 that her government would have to respond if Sweden became a NATO member. However, in June 2022 President Vladimir Putin contradicted the statement, claiming that Sweden and Finland can \"join whatever they want\" on the condition that there will be no NATO military deployment in either country.\nIn March 2024, Sweden officially ended this period of nonalignment when it joined NATO.\nMilitary.\nSweden has employed its military on numerous occasions since the end of the Cold War, from Bosnia and Congo to Afghanistan and Libya. According to one study, \"this military activism is driven both by the Swedish internationalist tradition of \"doing good\" in the world, but also for instrumental purposes. These include a desire for political influence in international institutions, an interest in collective milieu shaping, and a concern to improve the interoperability and effectiveness of the Swedish military.\"\nParticipation in international organizations.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDiplomatic relations.\nList of countries which Sweden maintains diplomatic relations with:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26897", "revid": "32990417", "url": "https://en.wikipedia.org/wiki?curid=26897", "title": "Spice", "text": "Food flavoring\nIn the culinary arts, a spice is a seed, fruit, root, bark, or other plant substance primarily used for flavoring or coloring food. Spices are distinguished from herbs, which are the leaves, flowers, or stems of plants used for flavoring or as a garnish. Spices and herbs are both seasonings. \nSpices are sometimes used in medicine, religious rituals, cosmetics, or perfume production. They are usually classified into spices, spice seeds, and herbal categories. For example, vanilla is commonly used as an ingredient in fragrance manufacturing. Plant-based sweeteners such as sugar are not considered spices. \nSpices can be used in various forms, including fresh, whole, dried, grated, chopped, crushed, ground, or extracted into a tincture. These processes may occur before the spice is sold, during meal preparation in the kitchen, or even at the table when serving a dish, such as grinding peppercorns as a condiment. Certain spices, like turmeric, are rarely available fresh or whole and are typically purchased in ground form. Small seeds, such as fennel and mustard, can be used either in their whole form or as a powder. \nA whole dried spice has the longest shelf life, so it can be purchased and stored in larger amounts, making it cheaper on a per-serving basis. A fresh spice, such as ginger, is usually more flavorful than its dried form, but fresh spices are more expensive and have a much shorter shelf life. \nThere is no clinical evidence that spices affect health.\nIndia contributes to 75% of global spice production. This is reflected culturally through its cuisine. Historically, the spice trade developed throughout the Indian subcontinent as well as in East Asia and the Middle East. Europe's demand for spices was among the economic and cultural factors that encouraged exploration in the early modern period.\nDefinition.\nAlthough defining spice is difficult, varying definitions cover several common aspects. One such aspect is the biological source of spices: the \"Oxford English Dictionary\" (\"OED\") identifies the source as vegetables, while Redgrove (1933) is more specific as to the part of the plant, specifically the root, rhizome, flower, fruit, seed and bark when they are dried, in contrast with herbaceous parts which constitute herbs. \"The Oxford Companion to Food\" challenges spices as sourced from plants being a hard rule, pointing to ambergris being often identified as a spice despite its animal origin.\nAnother aspect is the geographical source: The \"OED\" specifies spices are sourced from the tropics, while \"The Oxford Companion to Food\" gives the example of caraway seeds as demonstrating that spices can come from temperate climes. The notion that spices have a tropical origin is historic: originally \"spice\" was understood as a type of merchandise from the Orient. As Europeans encountered the Americas, beginning the Columbian exchange, the meaning expanded to capture new aromatics, and the meaning later shifted again to refer to culinary use. This historic development has led to some ingredients indigenous to European cooking such as garlic and horseradish not being considered spices despite sharing many attributes.\nHistory.\nEarly history.\nArcheological study of early spice use is difficult, as spices were used in small quantities, leaving few preserved remains.\nThe spice trade developed throughout the Indian subcontinent and Middle East by 2000 BCE with cinnamon and black pepper, and in East Asia with herbs and pepper. The Egyptians used herbs for cuisine and mummification. Their demand for exotic spices and herbs helped stimulate world trade.\nCloves were used in Mesopotamia by 1700\u00a0BCE. The earliest written records of spices come from ancient Egyptian, Chinese, and Indian cultures. The Ebers Papyrus from early Egypt dating from 1550 BCE describes some eight hundred different herbal medicinal remedies and numerous medicinal procedures.\nBy 1000\u00a0BCE, medical systems based on herbs could be found in China, Korea, and India. Early uses were associated with magic, medicine, religion, tradition, and preservation.\nIndonesian merchants traveled around China, India, the Middle East, and the east coast of Africa. Arab merchants facilitated the routes through the Middle East and India. This resulted in the Egyptian port city of Alexandria being the main trading center for spices. The most important discovery prior to the European spice trade was the monsoon winds (40 CE). Sailing from Eastern spice cultivators to Western European consumers gradually replaced the land-locked spice routes once facilitated by the Middle East Arab caravans.\nSpices were prominent enough in the ancient world that they are mentioned in the Old Testament. In Genesis, Joseph was sold into slavery by his brothers to spice merchants. In Exodus, manna is described as being similar to coriander in appearance. In the Song of Solomon, the male narrator compares his beloved to many saffron, cinnamon, and other spices.\nHistorians believe that nutmeg, which originates from the Banda Islands in Southeast Asia, was introduced to Europe in the 6th century BCE. The Romans had cloves in the 1st century CE, as Pliny the Elder wrote about them.\nMiddle Ages.\nSpices were among the most demanded and expensive products available in Europe in the Middle Ages,[5] the most common being black pepper, cinnamon (and the cheaper alternative cassia), cumin, nutmeg, ginger, and cloves. Given medieval medicine's main theory of humorism, spices and herbs were indispensable to balance \"humors\" in food,[6] on a daily basis for good health at a time of recurrent pandemics. In addition to being desired by those using medieval medicine, the European elite also craved spices in the Middle Ages, believing spices to be from and a connection to \"paradise\". An example of the European aristocracy's demand for spice comes from the King of Aragon, who invested substantial resources into importing spices to Spain in the 12th century. He was specifically looking for spices to put in wine and was not alone among European monarchs at the time to have such a desire for spice.\nSpices were all imported from plantations in Asia and Africa, which made them expensive. From the 8th until the 15th century, the Republic of Venice held a monopoly on spice trade with the Middle East, using this position to dominate the neighboring Italian maritime republics and city-states. The trade made the region rich. It has been estimated that around 1,000 tons of pepper and 1,000\u00a0tons of other common spices were imported into Western Europe each year during the Late Middle Ages. The value of these goods was the equivalent of a yearly supply of grain for 1.5 million people. The most exclusive was saffron, used as much for its vivid yellow-red color as for its flavor. Spices that have now fallen into obscurity in European cuisine include grains of paradise, a relative of cardamom which mostly replaced pepper in late medieval north French cooking, along with long pepper, mace, spikenard, galangal, and cubeb.\nEarly modern period.\nVoyagers from Spain and Portugal were interested in seeking new routes to trade in spices and other valuable products from Asia. The control of trade routes and the spice-producing regions were the main reasons that Portuguese navigator Vasco da Gama sailed to India in 1499.[8] When da Gama discovered the pepper market in India, he was able to secure peppers for a much lower cost than demanded by Venice. At around the same time, Christopher Columbus returned from the New World. He described to investors the new spices available there.\nAnother source of competition in the spice trade during the 15th and 16th centuries was the Ragusans from the maritime republic of Dubrovnik in southern Croatia. The military prowess of Afonso de Albuquerque (1453\u20131515) allowed the Portuguese to take control of the sea routes to India. In 1506, he took the island of Socotra in the mouth of the Red Sea and, in 1507, Ormuz in the Persian Gulf. Since becoming the viceroy of the Indies, he took Goa in India in 1510, and Malacca on the Malay Peninsula in 1511. The Portuguese could now trade directly with Siam, China, and the Maluku Islands. \nWith the discovery of the New World came new spices, including allspice, chili peppers, vanilla, and chocolate. This development kept the spice trade, with the Americas as a latecomer with their new seasonings, profitable well into the 19th century.\nFunction.\nSpices are primarily used as food flavoring or to create variety. They are also used to perfume cosmetics and incense. At various periods, many spices were used in herbal medicine. Finally, since they can be expensive, rare and exotic commodities, their conspicuous consumption has often been a symbol of wealth and social class.\nPreservative claim.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nIt is often claimed that spices were used either as food preservatives or to mask the taste of spoiled meat, especially in the European Middle Ages. This is false. In fact, spices are rather ineffective as preservatives as compared to salting, smoking, pickling, or drying, and are ineffective in covering the taste of spoiled meat. Moreover, spices have always been comparatively expensive: in 15th century Oxford, a whole pig cost about the same as a pound of the cheapest spice, pepper. There is also no evidence of such use from contemporary cookbooks: \"Old cookbooks make it clear that spices weren't used as a preservative. They typically suggest adding spices toward the end of the cooking process, where they could have no preservative effect whatsoever.\" Indeed, Cristoforo di Messisbugo suggested in the 16th century that pepper may speed up spoilage.\nThough some spices have antimicrobial properties in vitro, pepper\u2014by far the most common spice\u2014is relatively ineffective, and in any case, salt, which is far cheaper, is also far more effective.\nClassification and types.\nBotanical basis.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCommon spice mixtures.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nHandling.\nA mortar and pestle is the classic set of tools for grinding a whole spice. Less labor-intensive tools are more common now: a microplane or fine grater can be used to grind small amounts; a coffee grinder is useful for larger amounts. A frequently used spice such as black pepper may merit storage in its own hand grinder or mill.\nThe flavor of a spice is derived in part from compounds (volatile oils) that oxidize or evaporate when exposed to air. Grinding a spice greatly increases its surface area and so increases the rates of oxidation and evaporation. Thus, the flavor is maximized by storing a spice whole and grinding when needed. The shelf life of a whole dry spice is roughly two years; of a ground spice roughly six months. The \"flavor life\" of a ground spice can be much shorter. Ground spices are better stored away from light.\nSome flavor elements in spices are soluble in water; many are soluble in oil or fat. As a general rule, the flavors from a spice take time to infuse into the food so spices are added early in preparation. This contrasts to herbs which are usually added late in preparation.\nSalmonella contamination.\nA study by the Food and Drug Administration of shipments of spices to the United States during fiscal years 2007\u20132009 showed about 7% of the shipments were contaminated by \"Salmonella\" bacteria, some of it antibiotic-resistant. As most spices are cooked before being served salmonella contamination often has no effect, but some spices, particularly pepper, are often eaten raw and are present at the table for convenient use. Shipments from Mexico and India, a major producer, were the most frequently contaminated. Food irradiation is said to minimize this risk.\nStandardization.\nThe International Organization for Standardization addresses spices and condiments, along with related food additives, as part of the International Classification for Standards 67.220 series.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26898", "revid": "15881234", "url": "https://en.wikipedia.org/wiki?curid=26898", "title": "Sect", "text": "Subgroup of a particular religious or ideological doctrine\nA sect is a subgroup of a religious, political, or philosophical belief system, typically emerging as an offshoot of a larger organization. Originally, the term referred specifically to religious groups that had separated from a main body, but it can now apply to any group that diverges from a larger organization to follow a distinct set of beliefs and practices. Sects often form when there is a perception of heresy either within the subgroup or from the larger group.\nIn an Indian context, sect refers to an organized tradition.\nEtymology.\nThe word \"sect\" originates from the Latin noun \"secta\" (a feminine form of a variant past participle of the verb \"\", to follow) which translates to \"a way, road\". Figuratively, it signifies a (prescribed) way, mode, or manner. Metonymously, sect refers to a discipline or school of thought as defined by a set of methods and doctrines. The various modern usages of the term stem largely from confusion with the homonymous (but etymologically unrelated) Latin word \"secta\" (the feminine form of the past participle of the verb \"\", to cut).\nSociological definitions and descriptions.\nSociologists have developed various definitions and descriptions for the term \"sect.\" Early scholars like Max Weber and Ernst Troeltsch (1912) were among the first to define sects within the church-sect typology, viewing them as voluntary associations of individuals who meet specific religious qualifications. Unlike churches, membership in a sect is not inherited at birth; rather, it arises from a person's voluntary acceptance of the sect's doctrines and disciplines, which requires ongoing validation from both the follower and the sect itself. Sects often attract individuals from marginalized or underprivileged social groups and typically form from schisms within established churches that align with the dominant social order.\nSects frequently critique liberal trends within mainstream denominations, advocating for a return to what they view as authentic religious practices. Their beliefs and practices are usually more radical and ethically strict than those of mainstream churches, acting as a form of protest against the prevailing societal values. The American sociologists Rodney Stark and William Sims Bainbridge argue that sects present themselves as authentic, reformed versions of the faith they have separated from, maintaining a high degree of tension with the surrounding society. They further assert that sects have, in contrast to churches, a high degree of tension with the surrounding society. Other sociologists, like Fred Kniss, suggest that sectarianism is best understood through the lens of what the sect opposes. Some religious groups may be in tension primarily with other co-religious groups of different ethnic backgrounds, while others may conflict with society at large rather than the church they originally separated from.\nSectarianism in the sociology of religion, is sometimes defined as a worldview that emphasizes the unique legitimacy of a sect's creed and practices, often heightening tension with broader society by maintaining strict boundaries.\nIn his book \"The Road to Total Freedom\", the English sociologist Roy Wallis describes that a sect is characterized by \"epistemological authoritarianism\": meaning it has an authoritative source for determining heresy. According to Wallis, sects claim to have unique and privileged access to truth or salvation, and their followers often view those outside the group as being in error. In contrast, Wallis describes cults as being marked by \"epistemological individualism,\" \nIn other languages.\nThe corresponding words for \"sect\" in European languages other than English \u2013 \"Sekte\" (German), \"secte\" (French), \"secta\" (Spanish, Catalan), \"sect\u0103\" (Romanian), \"setta\" (Italian), \"seita\" (Portuguese, Galician), \"sekta\" (Polish, Czech, Slovak, Bosnian, Croatian, Serbian, Slovenian, Latvian, Lithuanian), \"sekt\" (Danish, Estonian, Norwegian, Swedish), \"sekte\" (Dutch), \"sekti\" (Finnish), - \"szekda\" (Hungarian), \"\u0441\u0435\u043a\u0442\u0430\" (Russian, Serbian, Bulgarian, Ukrainian), \u03c3\u03ad\u03c7\u03c4\u03b1 (Greek) \u2013 refer to a harmful religious sect and translate into English as \"cult\".\nIn Buddhism.\nThe \"Macmillan Encyclopedia of Religion\" distinguishes three types of classification of Buddhism, separated into \"Movements\", \"Nik\u0101yas\" and \"Doctrinal schools\":\nIn Christianity.\nWhile the historical usage of the term \"sect\" in Christendom has had pejorative connotations, referring to a group or movement with heretical beliefs or practices that deviate from those of groups considered orthodox, its primary meaning is to indicate a community which has separated itself from the larger body from which its members came.\nIn Hinduism.\nThe Indologist Axel Michaels writes in his book about Hinduism that in an Indian context the word \"sect does not denote a split or excluded community, but rather an organized tradition, usually established by founder with ascetic practices.\" According to Michaels, \"Indian sects do not focus on heresy, since the lack of a center or a compulsory center makes this impossible \u2013 instead, the focus is on adherents and followers.\"\nIn Islam.\nIslam was classically divided into two major sects, known as Sunni Islam and Shia Islam. Kharijite and Murijite Islam were two early Islamic sects. Each sect developed several distinct jurisprudence systems reflecting their own understanding of the Islamic law during the course of the history of Islam.\nCurrent sects.\nSunnis are separated into five \"maddhabs\"; Hanafi, Maliki, Shafi'i, Hanbali and \u1e92\u0101hir\u012b. The Shia, on the other hand, first developed Kaysanism, which in turn divided into three major groupings known as Fivers, Seveners and Twelvers. The Zaydis separated first. The non-Zaydis were initially called \"Rafida\". The Rafidis later divided into two sub-groups known as Imamiyyah and Batiniyyah.\nAmman Message.\nAn Islamic convention held in Jordan in July 2005, which brought 200 Muslim scholars from over 50 countries together, announced the official recognition of eight schools of Islamic jurisprudence and the varying schools of Islamic theology. The eight recognized Islamic schools and branches are:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26899", "revid": "10981247", "url": "https://en.wikipedia.org/wiki?curid=26899", "title": "Spearmint", "text": "Plant species in the mint family\n&lt;templatestyles src=\"Template:Taxobox/core/styles.css\" /&gt;\nSpearmint (Mentha spicata), also known as garden mint, common mint, lamb mint and mackerel mint, is native to Europe and southern temperate Asia, extending from Ireland in the west to southern China in the east. It is naturalized in many other temperate parts of the world, including northern and southern Africa, North America, and South America. It is used as a flavouring in food and herbal teas. The aromatic oil, called \"oil of spearmint\", is also used as a flavoring and sometimes as a scent.\nThe species and its subspecies have many synonyms, including \"Mentha crispa\", \"Mentha crispata,\" and \"Mentha viridis\".\nDescription.\nSpearmint is a perennial herbaceous plant. It is tall, with variably hairless to hairy stems and foliage, and a wide-spreading fleshy underground rhizome from which it grows. The leaves are long and broad, with a serrated margin. The stem is square-shaped, a defining characteristic of the mint family of herbs. Spearmint produces flowers in slender spikes, each flower pink or white in colour, long and broad. Spearmint flowers in the summer (from July to September in the northern hemisphere), and has relatively large seeds, which measure . The name \"spear\" mint derives from the pointed leaf tips.\n\"Mentha spicata\" varies considerably in leaf blade dimensions, the prominence of leaf veins, and pubescence.\nTaxonomy.\n\"Mentha spicata\" was first described scientifically by Carl Linnaeus in 1753. The epithet \"spicata\" means 'bearing a spike'. The species has two accepted subspecies, each of which has acquired a large number of synonyms:\nOrigin.\nThe plant is an allopolyploid species (2\"n\"\u00a0=\u00a048), which could be a result of hybridization and chromosome doubling. \"Mentha longifolia\" and \"Mentha suaveolens\" (2\"n\"\u00a0=\u00a024) are likely to be the contributing diploid species.\nHybrids.\n\"Mentha spicata\" hybridizes with other \"Mentha\" species, forming hybrids such as:\nVarieties and cultivars.\nThere are several commonly available varieties and cultivars of \"Mentha spicata\":\nHistory and domestication.\nMention of spearmint dates back to at least the 1st century AD, with references from naturalist Pliny and mentions in the Bible. Further records show descriptions of mint in ancient mythology. Findings of early versions of toothpaste using mint in the 14th century suggest widespread domestication by this point. It was introduced into England by the Romans by the 5th century, and Turner mentions mint as being good for the stomach. John Gerard's \"Herbal\" (1597) states that: \"It is good against watering eyes and all manner of break outs on the head and sores. \"It is applied with salt to the biting of mad dogs,\" and that \"They lay it on the stinging of wasps and bees with good success.\" He also mentions that \"the smell rejoices the heart of man\", for which reason they used to strew it in chambers and places of recreation, pleasure, and repose, where feasts and banquets are made.\"\nSpearmint is documented as being an important cash crop in Connecticut during the period of the American Revolution, at which time mint tea was noted as being a popular drink due to it not being taxed.\nEcology.\nSpearmint can readily adapt to grow in various types of soil. Spearmint tends to thrive with plenty of organic material in full sun to part shade. The plant is also known to be found in moist habitats such as swamps or creeks, where the soil is sand or clay.\nSpearmint ideally thrives in soils that are deep, well-drained, moist, rich in nutrients and organic matter, and have a crumbly texture. The pH range should be between 6.0 and 7.5.\nDiseases and pests.\nFungal diseases.\nFungal diseases are common diseases in spearmint. Two main diseases are rust and leaf spot. \"Puccinia menthae\" is a fungus that causes the disease called \"rust\". Rust affects the leaves of spearmint by producing pustules inducing the leaves to fall off. Leaf spot is a fungal disease that occurs when \"Alternaria alernata\" is present on the spearmint leaves. The infection looks like circular dark spot on the top side of the leaf. Other fungi that cause disease in spearmint are \"Rhizoctonia solani\", \"Verticillium dahliae\", \"Phoma strasseri\", and \"Erysiphe cischoracearum\".\nNematode diseases.\nSome nematode diseases in spearmint include root knot and root lesions. Nematode species that cause root knots in this plant are various \"Meloidogyne\" species. The other nematode species are \"Pratylenchus\" which cause root lesions.\nViral and phytoplasmal diseases.\nSpearmint can be infected by tobacco ringspot virus. This virus can lead to stunted plant growth and deformation of the leaves in this plant. In China, spearmint have been seen with mosaic symptoms and deformed leaves. This is an indication that the plant can also be infected by the viruses, cucumber mosaic and tomato aspermy.\nCultivation and harvest.\nSpearmint grows well in nearly all temperate climates. Gardeners often grow it in pots or planters due to its invasive, spreading rhizomes.\nSpearmint leaves can be used fresh, dried, or frozen. The leaves lose their aromatic appeal after the plant flowers. It can be dried by cutting just before, or right (at peak) as the flowers open, about one-half to three-quarters the way down the stalk (leaving smaller shoots room to grow). Some dispute exists as to what drying method works best; some prefer different materials (such as plastic or cloth) and different lighting conditions (such as darkness or sunlight). The leaves can also be preserved in salt, sugar, sugar syrup, alcohol, or oil.\nOil uses.\nSpearmint is used for its aromatic oil, called oil of spearmint. The most abundant compound in spearmint oil is \"R\"-(\u2013)-carvone, which gives spearmint its distinctive smell. Spearmint oil also contains significant amounts of limonene, dihydrocarvone, and 1,8-cineol. Unlike oil of peppermint, oil of spearmint contains minimal amounts of menthol and menthone. It is used as a flavouring for toothpaste and confectionery, and is sometimes added to shampoos and soaps.\nTraditional medicine.\nSpearmint has been used in traditional medicine.\nInsecticide and pesticide.\nSpearmint essential oil has had success as a larvicide against mosquitoes. Using spearmint as a larvicide would be a greener alternative to synthetic insecticides due to their toxicity and negative effect to the environment.\nUsed as a fumigant, spearmint essential oil is an effective insecticide against adult moths.\nAntimicrobial research.\nSpearmint has been used for its supposed antimicrobial activity, which may be related to carvone. Its in vitro antibacterial activity has been compared to that of amoxicillin, penicillin, and streptomycin. Spearmint oil is found to have higher activity against gram-positive bacteria compared to gram-negative bacteria in vitro, which may be due to differing sensitivities to oils.\nBeverages.\nSpearmint leaves are infused in water to make spearmint tea. Spearmint is an ingredient of Maghrebi mint tea. Grown in the mountainous regions of Morocco, this variety of mint possesses a clear, pungent, but mild aroma. Spearmint is an ingredient in several cocktails, such as the mojito and mint julep. Sweet tea, iced and flavored with spearmint, is a summer tradition in the Southern United States. In Western Australia, green-coloured, spearmint-flavored milk is a local treat.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26902", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=26902", "title": "Satureja", "text": "Genus of flowering plants\nSatureja is a genus of aromatic plants of the family Lamiaceae, related to rosemary and thyme. It is native to southern and southeastern Europe, North Africa, the Middle East, and Central Asia. Historically, \"Satureja\" was defined broadly and many species of the subtribe Menthinae from throughout the world were included in it. In the modern cladistic era of botany, \"Satureja\" was redefined to a narrower monophyletic genus whose species are all native to Eurasia. Several species are cultivated as culinary herbs called savory, and they have become established in the wild in a few places.\nDescription.\n\"Satureja\" species may be annual or perennial. They are low-growing herbs and subshrubs, reaching heights of .\nThe leaves are long, with flowers forming in whorls on the stem, white to pale pink-violet.\nEcology and cultivation.\n\"Satureja\" species are food plants for the larva of some Lepidoptera (butterflies and moths). Caterpillars of the moth \"Coleophora bifrondella\" feed exclusively on winter savory (\"S. montana\").\nSavory may be grown purely for ornamental purposes; members of the genus need sun and well-drained soil.\nUses.\nBoth summer savory (\"Satureja hortensis\") and winter savory (\"Satureja montana\") are used to flavor food. The former is preferred by cooks but as an annual is only available in summer; winter savory is an evergreen perennial.\nSavory plays an important part in Persian, Armenian, Georgian, Bulgarian and Italian cuisine, particularly when cooking beans. It is also used to season the traditional Acadian stew known as \"\". The modern spice mixture Herbes de Provence has savory as one of the principal ingredients.\nIn Azerbaijan, savory is often incorporated as a flavoring in black tea.\nSpecies.\nSource:\nEtymology.\nThe etymology of the Latin word \"satureia\" is unclear. Speculation that it is related to \"saturare\", to \"satyr\", or to za'atar is not well supported. The ancient Hebrew name is Tzatrah \u05e6\u05ea\u05e8\u05d4.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26903", "revid": "234689", "url": "https://en.wikipedia.org/wiki?curid=26903", "title": "Solar System", "text": "The Sun and objects orbiting it\nThe Solar System consists of the Sun and the bodies that orbit it (most prominently Earth), being a system of masses bound together by gravity. The name comes from \"S\u014dl\", the Latin name for the Sun. It formed about 4.6\u00a0billion years ago when a dense region of a molecular cloud collapsed, creating the Sun and a protoplanetary disc from which the orbiting bodies assembled. The fusion of hydrogen into helium inside the Sun's core releases energy, which is primarily emitted through its outer photosphere. This creates a decreasing temperature gradient across the system. Over 99.86% of the Solar System's mass is located within the Sun.\nThe most massive objects that orbit the Sun are the eight planets. Closest to the Sun in order of increasing distance are the four terrestrial planets \u2013 Mercury, Venus, Earth and Mars. These are the planets of the inner Solar System. Earth and Mars are the only planets in the Solar System which orbit within the Sun's habitable zone, where liquid water can exist on the surface. Beyond the frost line at about five astronomical units (AU), are two gas giants \u2013 Jupiter and Saturn \u2013 and two ice giants \u2013 Uranus and Neptune. These are the planets of the outer Solar System. Jupiter and Saturn possess nearly 90% of the non-stellar mass of the Solar System.\nThere are a vast number of less massive objects. There is a strong consensus among astronomers that the Solar System has at least nine dwarf planets: Ceres, Orcus, Pluto, Haumea, Quaoar, Makemake, Gonggong, Eris, and Sedna. Six planets, seven dwarf planets, and other bodies have orbiting natural satellites, which are commonly called 'moons', and range from sizes of dwarf planets, like Earth's Moon, at their largest, to much less massive moonlets at their smallest. There are small Solar System bodies, such as asteroids, comets, centaurs, meteoroids, and interplanetary dust clouds. Some of these bodies are in the asteroid belt (between Mars's and Jupiter's orbit) and the Kuiper belt (just outside Neptune's orbit).\nBetween the bodies of the Solar System is an interplanetary medium of dust and particles. The Solar System is constantly flooded by outflowing charged particles from the solar wind, forming the heliosphere. At around from the Sun, the solar wind is halted by the interstellar medium, resulting in the heliopause. This is the boundary to interstellar space. Further out somewhere beyond from the Sun extends the outermost region of the Solar System, the theorized Oort cloud, the source for long-period comets, stretching to the edge of the Solar System, the edge of its Hill sphere, at , where its gravitational potential becomes equal to the galactic potential. The Solar System currently moves through a cloud of interstellar medium called the Local Cloud. The closest star to the Solar System, Proxima Centauri, is away. Both are within the Local Bubble, a relatively small 1,000 light-years (ly) wide region of the Milky Way.\nDefinition.\nThe Solar System includes the Sun and all objects that are bound to it by gravity and orbit it.\nThe International Astronomical Union describes the Solar System as all objects that are bound by the gravity of the Sun, the Sun itself, its eight planets, and the other celestial bodies which orbit it. NASA describes the Solar System as a planetary system, including the Sun and all objects that orbit it.\nWhen not used as a proper noun and written without capitalization, \"solar system\" may refer to either the Solar System itself or any system reminiscent of the Solar System.\nFormation and evolution.\nPast.\nThe Solar System formed at least 4.568\u00a0billion years ago from the gravitational collapse of a region within a large molecular cloud. This initial cloud was likely several light-years across and probably birthed several stars. As is typical of molecular clouds, this one consisted mostly of hydrogen, with some helium, and small amounts of heavier elements fused by previous generations of stars.\nAs the pre-solar nebula collapsed, conservation of angular momentum caused it to rotate faster. The center, where most of the mass collected, became increasingly hotter than the surroundings. As the contracting nebula spun faster, it began to flatten into a protoplanetary disc with a diameter of roughly and a hot, dense protostar at the center. The planets formed by accretion from this disc, in which dust and gas gravitationally attracted each other, coalescing to form ever larger bodies. Hundreds of protoplanets may have existed in the early Solar System, but they either merged or were destroyed or ejected, leaving the planets, dwarf planets, and leftover minor bodies.\nIn the warm inner Solar System close to the Sun, within the frost line and even further within the soot line, material other than metals and silicates, due to their higher boiling points, could not persist in solid form. Here planets formed that are mainly rocky, which are Mercury, Venus, Earth, and Mars. Because these refractory materials only comprised a small fraction of the solar nebula, the terrestrial planets could not grow very large.\nThe giant planets (Jupiter, Saturn, Uranus, and Neptune) formed further out, beyond the frost line, the point between the orbits of Mars and Jupiter where material is cool enough for volatile icy compounds to remain solid. The ices that formed these planets were more plentiful than the metals and silicates that formed the terrestrial inner planets, allowing them to grow massive enough to capture large atmospheres of hydrogen and helium, the lightest and most abundant elements. Leftover debris that never became planets congregated in regions such as the asteroid belt, Kuiper belt, and Oort cloud.\nWithin 50\u00a0million years, the pressure and density of hydrogen in the center of the protostar became great enough for it to begin thermonuclear fusion. As helium accumulates at its core, the Sun is growing brighter; early in its main-sequence life its brightness was 70% that of what it is today. The temperature, reaction rate, pressure, and density increased until hydrostatic equilibrium was achieved: the thermal pressure counterbalancing the force of gravity. At this point, the Sun became a main-sequence star. Solar wind from the Sun created the heliosphere and swept away the remaining gas and dust from the protoplanetary disc into interstellar space.\nFollowing the dissipation of the protoplanetary disk, the Nice model proposes that gravitational encounters between planetesimals and the gas giants caused each to migrate into different orbits. This led to dynamical instability of the entire system, which scattered the planetesimals and ultimately placed the gas giants in their current positions. During this period, the grand tack hypothesis suggests that a final inward migration of Jupiter dispersed much of the asteroid belt, leading to the Late Heavy Bombardment of the inner planets.\nPresent and future.\nThe Solar System remains in a relatively stable, slowly evolving state by following isolated, gravitationally bound orbits around the Sun. Although the Solar System has been fairly stable for billions of years, it is technically chaotic, and may eventually be disrupted. There is a small chance that another star will pass through the Solar System in the next few billion years. Although this could destabilize the system and eventually lead millions of years later to expulsion of planets, collisions of planets, or planets hitting the Sun, it would most likely leave the Solar System much as it is today.\nThe Sun's main-sequence phase, from beginning to end, will last about 10\u00a0billion years for the Sun compared to around two billion years for all other subsequent phases of the Sun's pre-remnant life combined. The Solar System will remain roughly as it is known today until the hydrogen in the core of the Sun has been entirely converted to helium, which will occur roughly 5\u00a0billion years from now. This will mark the end of the Sun's main-sequence life. At that time, the core of the Sun will contract with hydrogen fusion occurring along a shell surrounding the inert helium, and the energy output will be greater than at present. The outer layers of the Sun will expand to roughly 260 times its current diameter, and the Sun will become a red giant. Because of its increased surface area, the surface of the Sun will be cooler ( at its coolest) than it is on the main sequence.\nThe expanding Sun is expected to vaporize Mercury as well as Venus, and render Earth and Mars uninhabitable (possibly destroying Earth as well). Eventually, the core will be hot enough for helium fusion; the Sun will burn helium for a fraction of the time it burned hydrogen in the core. The Sun is not massive enough to commence the fusion of heavier elements, and nuclear reactions in the core will dwindle. Its outer layers will be ejected into space, leaving behind a dense white dwarf, half the original mass of the Sun but only the size of Earth. The ejected outer layers may form a planetary nebula, returning some of the material that formed the Sun\u00a0\u2013 but now enriched with heavier elements like carbon\u00a0\u2013 to the interstellar medium.\nGeneral characteristics.\nAstronomers sometimes divide the Solar System structure into separate regions. The inner Solar System includes Mercury, Venus, Earth, Mars, and the bodies in the asteroid belt. The outer Solar System includes Jupiter, Saturn, Uranus, Neptune, and the bodies in the Kuiper belt. Since the discovery of the Kuiper belt, the outermost parts of the Solar System are considered a distinct region consisting of the objects beyond Neptune.\nComposition.\nThe principal component of the Solar System is the Sun, a G-type main-sequence star that contains 99.86% of the system's known mass and dominates it gravitationally. The Sun's four largest orbiting bodies, the giant planets, account for 99% of the remaining mass, with Jupiter and Saturn together comprising more than 90%. The remaining objects of the Solar System (including the four terrestrial planets, the dwarf planets, moons, asteroids, and comets) together comprise less than 0.002% of the Solar System's total mass.\nThe Sun is composed of roughly 98% hydrogen and helium, as are Jupiter and Saturn. A composition gradient exists in the Solar System, created by heat and light pressure from the early Sun; those objects closer to the Sun, which are more affected by heat and light pressure, are composed of elements with high melting points. Objects farther from the Sun are composed largely of materials with lower melting points. The boundary in the Solar System beyond which those volatile substances could coalesce is known as the frost line, and it lies at roughly five times the Earth's distance from the Sun.\nOrbits.\nThe planets and other large objects in orbit around the Sun lie near the invariable plane of the Solar System, as does Earth's orbit, known as the ecliptic, and most closely the orbit of Jupiter, with an inclination to it of 0.3219\u00b0. Smaller icy objects such as comets frequently orbit at significantly greater angles to this plane. Most of the planets in the Solar System have secondary systems of their own, being orbited by natural satellites called moons. All of the largest natural satellites are in synchronous rotation, with one face permanently turned toward their parent. The four giant planets have planetary rings, thin discs of tiny particles that orbit them in unison.\nAs a result of the formation of the Solar System, planets and most other objects orbit the Sun in the same direction that the Sun is rotating. That is, counter-clockwise, as viewed from above Earth's north pole. There are exceptions, such as Halley's Comet. Most of the larger moons orbit their planets in prograde direction, matching the direction of planetary rotation; Neptune's moon Triton is the largest to orbit in the opposite, retrograde manner. Most larger objects rotate around their own axes in the prograde direction relative to their orbit, though the rotation of Venus is retrograde.\nTo a good first approximation, Kepler's laws of planetary motion describe the orbits of objects around the Sun. These laws stipulate that each object travels along an ellipse with the Sun at one focus, which causes the body's distance from the Sun to vary over the course of its year. A body's closest approach to the Sun is called its \"perihelion\", whereas its most distant point from the Sun is called its \"aphelion\".9-6 With the exception of Mercury, the orbits of the planets are nearly circular, but many comets, asteroids, and Kuiper belt objects follow highly elliptical orbits. Kepler's laws only account for the influence of the Sun's gravity upon an orbiting body, not the gravitational pulls of different bodies upon each other. On a human time scale, these perturbations can be accounted for using numerical models,9-6 but the planetary system can change chaotically over billions of years.\nThe angular momentum of the Solar System is a measure of the total amount of orbital and rotational momentum possessed by all its moving components. Although the Sun dominates the system by mass, it accounts for only about 2% of the angular momentum. The planets, dominated by Jupiter, account for most of the rest of the angular momentum due to the combination of their mass, orbit, and distance from the Sun, with a possibly significant contribution from comets.\nDistances and scales.\nThe radius of the Sun is . Thus, the Sun occupies 0.00001% (1 part in 107) of the volume of a sphere with a radius the size of Earth's orbit, whereas Earth's volume is roughly 1\u00a0millionth (10\u22126) that of the Sun. Jupiter, the largest planet, is from the Sun and has a radius of , whereas the most distant planet, Neptune, is from the Sun.\nWith a few exceptions, the farther a planet or belt is from the Sun, the larger the distance between its orbit and the orbit of the next nearest object to the Sun. For example, Venus is approximately 0.33\u00a0AU farther out from the Sun than Mercury, whereas Saturn is 4.3\u00a0AU out from Jupiter, and Neptune lies 10.5\u00a0AU out from Uranus. Attempts have been made to determine a relationship between these orbital distances, like the Titius\u2013Bode law and Johannes Kepler's model based on the Platonic solids, but ongoing discoveries have invalidated these hypotheses.\nSome Solar System models attempt to convey the relative scales involved in the Solar System in human terms. Some are small in scale (and may be mechanical\u00a0\u2013 called orreries)\u00a0\u2013 whereas others extend across cities or regional areas. The largest such scale model, the Sweden Solar System, uses the 110-meter (361-foot) Avicii Arena in Stockholm as its substitute Sun, and, following the scale, Jupiter is a 7.5-meter (25-foot) sphere at Stockholm Arlanda Airport, 40\u00a0km (25\u00a0mi) away, whereas the farthest current object, Sedna, is a 10\u00a0cm (4\u00a0in) sphere in Lule\u00e5, 912\u00a0km (567\u00a0mi) away. At that scale, the distance to Proxima Centauri would be roughly 8 times further than the Moon is from Earth.\nIf the Sun\u2013Neptune distance is scaled to , then the Sun would be about in diameter (roughly two-thirds the diameter of a golf ball), the giant planets would be all smaller than about , and Earth's diameter along with that of the other terrestrial planets would be smaller than a flea () at this scale.\nHabitability.\nThe zone of habitability of the Solar System is conventionally located in the inner Solar System around Earth, where atmospheric liquid water is enabled by the Sun. \nBesides solar energy, the primary characteristic of the Solar System enabling the presence of life is the heliosphere and planetary magnetic fields (for those planets that have them). These magnetic fields partially shield the Solar System from high-energy interstellar particles called cosmic rays. The density of cosmic rays in the interstellar medium and the strength of the Sun's magnetic field change on very long timescales, so the level of cosmic-ray penetration in the Solar System varies, though by how much is unknown.\nHabitability in the Solar System is though not solely dependent on surface conditions, and furthermore the Solar environment, since there might be habitablity in potential subsurface oceans of various Solar System bodies, or cloud layers of some planets, particularly Venus.\nComparison with extrasolar systems.\nAnalysis of \"Kepler\" data suggests that observed planetary systems in the Milky Way fall into three groups: \"similar\", which comprise planets of similar sizes similar distances apart and with highly circular orbits; \"ordered\", in which the masses of planets tend to increase with distance from their star, and \"mixed\", which show no pattern in masses whatsoever. The Solar System is an ordered system, as are 37% of observed systems. Similar systems however are the majority, comprising 59% of observed systems, while mixed systems comprise just 4%. \nCompared to many extrasolar systems, the Solar System stands out in lacking planets interior to the orbit of Mercury. The known Solar System lacks super-Earths, planets between one and ten times as massive as the Earth, although the hypothetical Planet Nine, if it does exist, could be a super-Earth orbiting in the edge of the Solar System.\nUncommonly, it has only small terrestrial and large gas giants; elsewhere planets of intermediate size are typical\u00a0\u2013 both rocky and gas\u00a0\u2013 so there is no \"gap\" as seen between the size of Earth and of Neptune (with a radius 3.8 times as large). As many of these super-Earths are closer to their respective stars than Mercury is to the Sun, a hypothesis has arisen that all planetary systems start with many close-in planets, and that typically a sequence of their collisions causes consolidation of mass into few larger planets, but in case of the Solar System the collisions caused their destruction and ejection.\nThe orbits of Solar System planets are nearly circular. Compared to many other systems, they have smaller orbital eccentricity. Although there are attempts to explain it partly with a bias in the radial-velocity detection method and partly with long interactions of a quite high number of planets, the exact causes remain undetermined.\nSun.\nThe Sun is the Solar System's star and by far its most massive component. Its large mass (332,900 Earth masses), which comprises 99.86% of all the mass in the Solar System, produces temperatures and densities in its core high enough to sustain nuclear fusion of hydrogen into helium. This releases an enormous amount of energy, mostly radiated into space as electromagnetic radiation peaking in visible light.\nBecause the Sun fuses hydrogen at its core, it is a main-sequence star. More specifically, it is a G2-type main-sequence star, where the type designation refers to its effective temperature. Hotter main-sequence stars are more luminous but shorter lived. The Sun's temperature is intermediate between that of the hottest stars and that of the coolest stars. Stars brighter and hotter than the Sun are rare, whereas substantially dimmer and cooler stars, known as red dwarfs, make up about 75% of the fusor stars in the Milky Way.\nThe Sun is a population I star, having formed in the spiral arms of the Milky Way galaxy. It has a higher abundance of elements heavier than hydrogen and helium (\"metals\" in astronomical parlance) than the older population II stars in the galactic bulge and halo. Elements heavier than hydrogen and helium were formed in the cores of ancient and exploding stars, so the first generation of stars had to die before the universe could be enriched with these atoms. The oldest stars contain few metals, whereas stars born later have more. This higher metallicity is thought to have been crucial to the Sun's development of a planetary system because the planets formed from the accretion of \"metals\".\nThe region of space dominated by the Solar magnetosphere is the heliosphere, which spans much of the Solar System. Along with light, the Sun radiates a continuous stream of charged particles (a plasma) called the solar wind. This stream spreads outwards at speeds from to , filling the vacuum between the bodies of the Solar System. The result is a thin, dusty atmosphere, called the interplanetary medium, which extends to at least .\nActivity on the Sun's surface, such as solar flares and coronal mass ejections, disturbs the heliosphere, creating space weather and causing geomagnetic storms. Coronal mass ejections and similar events blow a magnetic field and huge quantities of material from the surface of the Sun. The interaction of this magnetic field and material with Earth's magnetic field funnels charged particles into Earth's upper atmosphere, where its interactions create aurorae seen near the magnetic poles. The largest stable structure within the heliosphere is the heliospheric current sheet, a spiral form created by the actions of the Sun's rotating magnetic field on the interplanetary medium.\nInner Solar System.\nThe inner Solar System is the region comprising the terrestrial planets and the asteroids. Composed mainly of silicates and metals, the objects of the inner Solar System are relatively close to the Sun; the radius of this entire region is less than the distance between the orbits of Jupiter and Saturn. This region is within the frost line, which is a little less than from the Sun.\nInner planets.\nThe four terrestrial or inner planets have dense, rocky compositions, few or no moons, and no ring systems. They are composed largely of refractory minerals such as silicates\u2014which form their crusts and mantles\u2014and metals such as iron and nickel which form their cores. Three of the four inner planets (Venus, Earth, and Mars) have atmospheres substantial enough to generate weather; all have impact craters and tectonic surface features, such as rift valleys and volcanoes.\nAsteroids.\nAsteroids, except for the largest, Ceres, are classified as small Solar System bodies and are composed mainly of carbonaceous, refractory rocky and metallic minerals, with some ice. They range from a few meters to hundreds of kilometers in size. &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Many asteroids are divided into asteroid groups and families based on their orbital characteristics. Some asteroids have natural satellites that orbit them, that is, asteroids that orbit larger asteroids.\nAsteroid belt.\nThe asteroid belt occupies a torus-shaped region between 2.3 and from the Sun, which lies between the orbits of Mars and Jupiter. It is thought to be remnants from the Solar System's formation that failed to coalesce because of the gravitational interference of Jupiter. The asteroid belt contains tens of thousands, possibly millions, of objects over one kilometer in diameter. Despite this, the total mass of the asteroid belt is unlikely to be more than a thousandth of that of Earth. The asteroid belt is very sparsely populated; spacecraft routinely pass through without incident.\nBelow are the descriptions of the three largest bodies in the asteroid belt. They are all considered to be relatively intact protoplanets, a precursor stage before becoming a fully-formed planet (see List of exceptional asteroids):\nHilda asteroids are in a 3:2 resonance with Jupiter; that is, they go around the Sun three times for every two Jovian orbits. They lie in three linked clusters between Jupiter and the main asteroid belt.\nTrojans are bodies located within another body's gravitationally stable Lagrange points: L4, 60\u00b0 ahead in its orbit, or L5, 60\u00b0 behind in its orbit. Every planet except Mercury is known to possess at least one trojan. The Jupiter trojan population is roughly equal to that of the asteroid belt. After Jupiter, Neptune possesses the most confirmed trojans, at 28.\nOuter Solar System.\nThe outer region of the Solar System is home to the giant planets and their large moons. The centaurs and many short-period comets orbit in this region. Due to their greater distance from the Sun, the solid objects in the outer Solar System contain a higher proportion of volatiles such as water, ammonia, and methane, than planets of the inner Solar System because their lower temperatures allow these compounds to remain solid, without significant sublimation.\nOuter planets.\nThe four outer planets, called giant planets or Jovian planets, collectively make up 99% of the mass orbiting the Sun. All four giant planets have multiple moons and a ring system, although only Saturn's rings are easily observed from Earth. Jupiter and Saturn are composed mainly of gases with extremely low melting points, such as hydrogen, helium, and neon, hence their designation as gas giants. Uranus and Neptune are ice giants, meaning they are largely composed of 'ice' in the astronomical sense (chemical compounds with melting points of up to a few hundred kelvins such as water, methane, ammonia, hydrogen sulfide, and carbon dioxide.) Icy substances comprise the majority of the satellites of the giant planets and small objects that lie beyond Neptune's orbit.\nCentaurs.\nThe centaurs are icy, comet-like bodies whose semi-major axes are longer than Jupiter's and shorter than Neptune's (between 5.5 and 30\u00a0AU). These are former Kuiper belt and scattered disc objects (SDOs) that were gravitationally perturbed closer to the Sun by the outer planets, and are expected to become comets or be ejected out of the Solar System. While most centaurs are inactive and asteroid-like, some exhibit cometary activity, such as the first centaur discovered, 2060 Chiron, which has been classified as a comet (95P) because it develops a coma just as comets do when they approach the Sun. The largest known centaur, 10199 Chariklo, has a diameter of about and is one of the few minor planets possessing a ring system.\nTrans-Neptunian region.\nBeyond the orbit of Neptune lies the area of the \"trans-Neptunian region\", with the doughnut-shaped Kuiper belt, home of Pluto and several other dwarf planets, and an overlapping disc of scattered objects, which is tilted toward the plane of the Solar System and reaches much further out than the Kuiper belt. The entire region is still largely unexplored. It appears to consist overwhelmingly of many thousands of small worlds\u00a0\u2013 the largest having a diameter only a fifth that of Earth and a mass far smaller than that of the Moon\u00a0\u2013 composed mainly of rock and ice. This region is sometimes described as the \"third zone of the Solar System\", enclosing the inner and the outer Solar System.\nKuiper belt.\nThe Kuiper belt is a great ring of debris similar to the asteroid belt, but consisting mainly of objects composed primarily of ice. It extends between 30 and 50\u00a0AU from the Sun. It is composed mainly of small Solar System bodies, although the largest few are probably large enough to be dwarf planets. There are estimated to be over 100,000 Kuiper belt objects with a diameter greater than , but the total mass of the Kuiper belt is thought to be only a tenth or even a hundredth the mass of Earth. Many Kuiper belt objects have satellites, and most have orbits that are substantially inclined (~10\u00b0) to the plane of the ecliptic.\nThe Kuiper belt can be roughly divided into the \"classical\" belt and the resonant trans-Neptunian objects. The latter have orbits whose periods are in a simple ratio to that of Neptune: for example, going around the Sun twice for every three times that Neptune does, or once for every two. The classical belt consists of objects having no resonance with Neptune, and extends from roughly 39.4 to 47.7\u00a0AU. Members of the classical Kuiper belt are sometimes called \"cubewanos\", after the first of their kind to be discovered, originally designated 1992 \"QB1\", (and has since been named Albion); they are still in near primordial, low-eccentricity orbits.\nThere is strong consensus among astronomers that five members of the Kuiper belt are &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;dwarf planets. Many dwarf planet candidates are being considered, pending further data for verification.\nScattered disc.\nThe scattered disc, which overlaps the Kuiper belt but extends out to near 500\u00a0AU, is thought to be the source of short-period comets. Scattered-disc objects are believed to have been perturbed into erratic orbits by the gravitational influence of Neptune's early outward migration. Most scattered disc objects have perihelia within the Kuiper belt but aphelia far beyond it (some more than 150\u00a0AU from the Sun). SDOs' orbits can be inclined up to 46.8\u00b0 from the ecliptic plane. Some astronomers consider the scattered disc to be merely another region of the Kuiper belt and describe scattered-disc objects as \"scattered Kuiper belt objects\". Some astronomers classify centaurs as inward-scattered Kuiper belt objects along with the outward-scattered residents of the scattered disc.\nCurrently, there is strong consensus among astronomers that two of the bodies in the scattered disc are &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;dwarf planets:\nExtreme trans-Neptunian objects.\nSome objects in the Solar System have a very large orbit, and therefore are much less affected by the known giant planets than other minor planet populations. These bodies are called extreme trans-Neptunian objects, or ETNOs for short. Generally, ETNOs' semi-major axes are at least 150\u2013250\u00a0AU wide. For example, 541132 Lele\u0101k\u016bhonua orbits the Sun once every ~32,000\u00a0years, with a distance of 65\u20132000\u00a0AU from the Sun.\nThis population is divided into three subgroups by astronomers. The scattered ETNOs have perihelia around 38\u201345\u00a0AU and an exceptionally high eccentricity of more than 0.85. As with the regular scattered disc objects, they were likely formed as result of gravitational scattering by Neptune and still interact with the giant planets. The detached ETNOs, with perihelia approximately between 40\u201345 and 50\u201360\u00a0AU, are less affected by Neptune than the scattered ETNOs, but are still relatively close to Neptune. The sednoids or inner Oort cloud objects, with perihelia beyond 50\u201360\u00a0AU, are too far from Neptune to be strongly influenced by it.\nCurrently, there is one ETNO that is classified as a dwarf planet:\nStatistical variance has been observed in the orbits of some extreme trans-Neptunian objects, whose closest approaches to the Sun are mostly clustered around one sector and who display a similar orbital tilt to each other. Some astronomers have suggested that this may be the result of the influence of a large planet beyond Neptune; this hypothetical planet has been termed \"Planet Nine.\" Others credit this statistical variance to observational biases or sheer coincidence.\nOort cloud.\nThe Oort cloud is a theorized spherical shell of up to a trillion icy objects that is thought to be the source for all long-period comets, which were originally ejected from the planetary region by gravitational interactions with the gas giants. Oort cloud objects move very slowly, and can be perturbed by infrequent events, such as collisions, the gravitational effects of a passing star, or the galactic tide, the tidal force exerted by the Milky Way. No direct observation of the Oort cloud is possible with present imaging technology.\nThe Oort cloud is theorized to surround the Solar System from potentially ~2,000\u00a0AU from the Sun to up to ~200,000\u00a0AU. Lower estimates for the radius of the Oort cloud, by contrast, do not place it farther than . Most of the mass is orbiting in the region between 3,000 and . The furthest known objects, such as Comet West, have aphelia around from the Sun.\nGravitationally unstable populations.\nMeteoroids, meteors and dust.\nSolid objects smaller than one meter are usually called meteoroids and micrometeoroids (grain-sized), with the exact division between the two categories being debated over the years. By 2017, the IAU designated any solid object having a diameter between ~30\u00a0micrometers and 1\u00a0meter as meteoroids, and depreciated the micrometeoroid categorization, instead terms smaller particles simply as 'dust particles'.\nSome meteoroids formed via disintegration of comets and asteroids, while a few formed via impact debris ejected from planetary bodies. Most meteoroids are made of silicates and heavier metals like nickel and iron. When passing through the Solar System, comets produce a trail of meteoroids; it is hypothesized that this is caused either by vaporization of the comet's material or by simple breakup of dormant comets. When crossing an atmosphere, these meteoroids will produce bright streaks in the sky due to atmospheric entry, called meteors. If a stream of meteoroids enter the atmosphere on parallel trajectories, the meteors will seemingly 'radiate' from a point in the sky, hence the phenomenon's name: meteor shower.\nThe inner Solar System is home to the zodiacal dust cloud, which is visible as the hazy zodiacal light in dark, unpolluted skies. It may be generated by collisions within the asteroid belt brought on by gravitational interactions with the planets; a more recent proposed origin is materials from planet Mars. The outer Solar System hosts a cosmic dust cloud. It extends from about to about , and was probably created by collisions within the Kuiper belt.\nComets.\nComets are small Solar System bodies, typically only a few kilometers across, composed largely of volatile ices. They have highly eccentric orbits, generally a perihelion within the orbits of the inner planets and an aphelion far beyond Pluto. When a comet enters the inner Solar System, its proximity to the Sun causes its icy surface to sublimate and ionise, creating a coma: a long tail of gas and dust often visible to the naked eye.\nShort-period comets have orbits lasting less than two hundred years. Long-period comets have orbits lasting thousands of years. Short-period comets are thought to originate in the Kuiper belt, whereas long-period comets, such as Hale\u2013Bopp, are thought to originate in the Oort cloud. Many comet groups, such as the Kreutz sungrazers, formed from the breakup of a single parent. Some comets with hyperbolic orbits may originate outside the Solar System, but determining their precise orbits is difficult. Old comets whose volatiles have mostly been driven out by solar warming are often categorized as asteroids.\nBoundary region and uncertainties.\nMuch of the outer reaches of the Solar System is still unknown. The region beyond 100 AU away is virtually unexplored and learning about this region of space is difficult. Study of this region depends upon inferences from those few objects whose orbits happen to be perturbed such that they fall closer to the Sun, and even then, detecting these objects has often been possible only when they happened to become bright enough to register as comets. Many objects are yet to be discovered in the Solar System's outer region.\nThe Sun's gravitational sphere of influence is estimated to dominate over the gravitational forces of surrounding stars out to about two light-years (). The Sun's Hill sphere, its gravitational potential reaching the galactic potential, the potential of the galactic nucleus, the effective range of its gravitational influence, is thought to encompass the Oort cloud, and extend to up to 230,000\u00a0AU from the Sun.\nThe boundaries of the heliosphere and of the Hill sphere, the Sun's gravitational potential in respect to the interstellar medium and the galactic gravitational potential, at the edge of the Oort cloud, represent the boundaries of the Solar System with the galactic environment it is in.\nEdge of the heliosphere.\nThe Sun's stellar-wind bubble, the heliosphere, a region of space dominated by the Sun, has its boundary at the \"termination shock\". Based on the Sun's peculiar motion relative to the local standard of rest, this boundary is roughly 80\u2013100\u00a0AU from the Sun upwind of the interstellar medium and roughly 200\u00a0AU from the Sun downwind. Here the solar wind collides with the interstellar medium and dramatically slows, condenses and becomes more turbulent, forming a great oval structure known as the heliosheath.\nThe heliosheath has been theorized to look and behave very much like a comet's tail, extending outward for a further 40\u00a0AU on the upwind side but tailing many times that distance downwind to possibly several thousands of AU. Evidence from the \"Cassini\" and Interstellar Boundary Explorer spacecraft has suggested that it is forced into a bubble shape by the constraining action of the interstellar magnetic field, but the actual shape remains unknown.\nThe shape and form of the outer edge of the heliosphere is likely affected by the fluid dynamics of interactions with the interstellar medium as well as solar magnetic fields prevailing to the south, e.g. it is bluntly shaped with the northern hemisphere extending 9\u00a0AU farther than the southern hemisphere. The heliopause is considered the beginning of the interstellar medium. Beyond the heliopause, at around 230\u00a0AU, lies the bow shock: a plasma \"wake\" left by the Sun as it travels through the Milky Way. Large objects outside the heliopause remain gravitationally bound to the Sun, but the flow of matter in the interstellar medium homogenizes the distribution of micro-scale objects.\nCelestial neighborhood.\nWithin 10\u00a0light-years of the Sun there are relatively few stars, the closest being the triple star system Alpha Centauri, which is about 4.4\u00a0light-years away and may be in the Local Bubble's G-Cloud. Alpha Centauri A and B are a closely tied pair of Sun-like stars, whereas the closest star to the Sun, the small red dwarf Proxima Centauri, orbits the pair at a distance of 0.2\u00a0light-years. In 2016, a potentially habitable exoplanet was found to be orbiting Proxima Centauri, called Proxima Centauri b, the closest confirmed exoplanet to the Sun.\nThe Solar System is surrounded by the Local Interstellar Cloud, although it is not clear if it is embedded in the Local Interstellar Cloud or if it lies just outside the cloud's edge. Multiple other interstellar clouds exist in the region within 300\u00a0light-years of the Sun, known as the Local Bubble. The latter feature is an hourglass-shaped cavity or superbubble in the interstellar medium roughly 300\u00a0light-years across. The bubble is suffused with high-temperature plasma, suggesting that it may be the product of several recent supernovae.\nThe Local Bubble is a small superbubble compared to the neighboring wider Radcliffe Wave and \"Split\" linear structures (formerly Gould Belt), each of which are some thousands of light-years in length. All these structures are part of the Orion Arm, which contains most of the stars in the Milky Way that are visible to the unaided eye.\nGroups of stars form together in star clusters, before dissolving into co-moving associations. A prominent grouping that is visible to the naked eye is the Ursa Major moving group, which is around 80 light-years away within the Local Bubble. The nearest star cluster is Hyades, which lies at the edge of the Local Bubble. The closest star-forming regions are the Corona Australis Molecular Cloud, the Rho Ophiuchi cloud complex and the Taurus molecular cloud; the latter lies just beyond the Local Bubble and is part of the Radcliffe wave.\nStellar flybys that pass within of the Sun occur roughly once every 100,000\u00a0years. The closest well-measured approach was Scholz's Star, which approached to ~ of the Sun some ~70\u00a0thousands years ago, likely passing through the outer Oort cloud. There is a 1% chance every billion years that a star will pass within of the Sun, potentially disrupting the Solar System.\nGalactic position.\nThe Solar System is located in the Milky Way, a barred spiral galaxy with a diameter of about 100,000\u00a0light-years containing more than 100\u00a0billion stars. The Sun is part of one of the Milky Way's outer spiral arms, known as the Orion\u2013Cygnus Arm or Local Spur. It is a member of the thin disk population of stars orbiting close to the galactic plane.\nIts speed around the center of the Milky Way is about 220\u00a0km/s, so that it completes one revolution every 240\u00a0million years. This revolution is known as the Solar System's galactic year. The solar apex, the direction of the Sun's path through interstellar space, is near the constellation Hercules in the direction of the current location of the bright star Vega. The plane of the ecliptic lies at an angle of about 60\u00b0 to the galactic plane.\nThe Sun follows a nearly circular orbit around the Galactic Center (where the supermassive black hole Sagittarius A* resides) at a distance of 26,660\u00a0light-years, orbiting at roughly the same speed as that of the spiral arms. If it orbited close to the center, gravitational tugs from nearby stars could perturb bodies in the Oort cloud and send many comets into the inner Solar System, producing collisions with potentially catastrophic implications for life on Earth. In this scenario, the intense radiation of the Galactic Center could interfere with the development of complex life.\nThe Solar System's location in the Milky Way is a factor in the evolutionary history of life on Earth. Spiral arms are home to a far larger concentration of supernovae, gravitational instabilities, and radiation that could disrupt the Solar System, but since Earth stays in the Local Spur and therefore does not pass frequently through spiral arms, this has given Earth long periods of stability for life to evolve. However, according to the controversial Shiva hypothesis, the changing position of the Solar System relative to other parts of the Milky Way could explain periodic extinction events on Earth.\nDiscovery and exploration.\nHumanity's knowledge of the Solar System has grown incrementally over the centuries. Up to the Late Middle Ages\u2013Renaissance, astronomers from Europe to India believed Earth to be stationary at the center of the universe and categorically different from the divine or ethereal objects that moved through the sky. Although the Greek philosopher Aristarchus of Samos had speculated on a heliocentric reordering of the cosmos, Nicolaus Copernicus was the first person known to have developed a mathematically predictive heliocentric system.\nHeliocentrism did not triumph immediately over geocentrism, but the work of Copernicus had its champions, notably Johannes Kepler. Using a heliocentric model that improved upon Copernicus by allowing orbits to be elliptical, and the precise observational data of Tycho Brahe, Kepler produced the \"Rudolphine Tables\", which enabled accurate computations of the positions of the then-known planets. Pierre Gassendi used them to predict a transit of Mercury in 1631, and Jeremiah Horrocks did the same for a transit of Venus in 1639. This provided a strong vindication of heliocentrism and Kepler's elliptical orbits.\nIn the 17th century, Galileo publicized the use of the telescope in astronomy; he and Simon Marius independently discovered that Jupiter had four satellites in orbit around it. Christiaan Huygens followed on from these observations by discovering Saturn's moon Titan and the shape of the rings of Saturn. In 1677, Edmond Halley observed a transit of Mercury across the Sun, leading him to realize that observations of the solar parallax of a planet (more ideally using the transit of Venus) could be used to trigonometrically determine the distances between Earth, Venus, and the Sun. Halley's friend Isaac Newton, in his magisterial \"Principia Mathematica\" of 1687, demonstrated that celestial bodies are not quintessentially different from Earthly ones: the same laws of motion and of gravity apply on Earth and in the skies.142\nThe term \"Solar System\" entered the English language by 1704, when John Locke used it to refer to the Sun, planets, and comets. In 1705, Halley realized that repeated sightings of a comet were of the same object, returning regularly once every 75\u201376\u00a0years. This was the first evidence that anything other than the planets repeatedly orbited the Sun, though Seneca had theorized this about comets in the 1st century. Careful observations of the 1769 transit of Venus allowed astronomers to calculate the average Earth\u2013Sun distance as , only 0.8% greater than the modern value.\nUranus, having occasionally been observed since 1690 and possibly from antiquity, was recognized to be a planet orbiting beyond Saturn by 1783. In 1838, Friedrich Bessel successfully measured a stellar parallax, an apparent shift in the position of a star created by Earth's motion around the Sun, providing the first direct, experimental proof of heliocentrism. Neptune was identified as a planet some years later, in 1846, thanks to its gravitational pull causing a slight but detectable variation in the orbit of Uranus. Mercury's orbital anomaly observations led to searches for Vulcan, a planet interior of Mercury, but these attempts were quashed with Albert Einstein's theory of general relativity in 1915.\nIn the 20th century, humans began their space exploration around the Solar System, starting with placing telescopes in space since the 1960s. By 1989, all eight planets have been visited by space probes. Probes have returned samples from comets and asteroids, as well as flown through the Sun's corona and visited two dwarf planets (Pluto and Ceres). To save on fuel, some space missions make use of gravity assist maneuvers, such as the two \"Voyager\" probes accelerating when flying by planets in the outer Solar System and the Parker Solar Probe decelerating closer towards the Sun after its flyby of Venus.\nHumans have landed on the Moon during the Apollo program in the 1960s and 1970s and will return to the Moon in the 2020s with the Artemis program. Discoveries in the 20th and 21st century has prompted the redefinition of the term \"planet\" in 2006, hence the demotion of Pluto to a dwarf planet, and further interest in trans-Neptunian objects.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nData sources.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nOther sources.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26904", "revid": "46275428", "url": "https://en.wikipedia.org/wiki?curid=26904", "title": "Silurian", "text": "Third period of the Paleozoic Era\nThe Silurian ( ) is a geologic period and system spanning 23.5 million years from the end of the Ordovician Period, at Ma (million years ago) to the beginning of the Devonian Period, Ma. The Silurian is the third and shortest period of the Paleozoic Era, and the third of twelve periods of the Phanerozoic Eon. As with other geologic periods, the rock beds that define the period's start and end are well identified, but the exact dates are uncertain by a few million years. The base of the Silurian is set at a series of major Ordovician\u2013Silurian extinction events when up to 60% of marine genera were wiped out.\nOne important event in this period was the initial establishment of terrestrial life in what is known as the Silurian-Devonian Terrestrial Revolution: vascular plants emerged from more primitive land plants, dikaryan fungi started expanding and diversifying along with glomeromycotan fungi, and three groups of arthropods (myriapods, arachnids and hexapods) became fully terrestrialized.\nAnother significant evolutionary milestone during the Silurian was the diversification of jawed fish, which include placoderms, acanthodians (which gave rise to cartilaginous fish) and osteichthyan (bony fish, further divided into lobe-finned and ray-finned fishes), although this corresponded to sharp decline of jawless fish such as conodonts and ostracoderms.\nHistory of study.\nThe Silurian system was first identified by the Scottish geologist Roderick Murchison, who was examining fossil-bearing sedimentary rock strata in south Wales in the early 1830s. He named the sequences for a Celtic tribe of Wales, the Silures, inspired by his friend Adam Sedgwick, who had named the period of his study the Cambrian, from a Latin name for Wales. Whilst the British rocks now identified as belonging to the Silurian System and the lands now thought to have been inhabited in antiquity by the Silures show little correlation (cf. , ), Murchison conjectured that their territory included Caer Caradoc and Wenlock Edge exposures - and that if it did not there were plenty of Silurian rocks elsewhere 'to sanction the name proposed'. In 1835 the two men presented a joint paper, under the title \"On the Silurian and Cambrian Systems, Exhibiting the Order in which the Older Sedimentary Strata Succeed each other in England and Wales,\" which was the germ of the modern geological time scale. As it was first identified, the \"Silurian\" series when traced farther afield quickly came to overlap Sedgwick's \"Cambrian\" sequence, however, provoking furious disagreements that ended the friendship.\nThe English geologist Charles Lapworth resolved the conflict by defining a new Ordovician system including the contested beds. An alternative name for the Silurian was \"Gotlandian\" after the strata of the Baltic island of Gotland.\nThe French geologist Joachim Barrande, building on Murchison's work, used the term \"Silurian\" in a more comprehensive sense than was justified by subsequent knowledge. He divided the Silurian rocks of Bohemia into eight stages. His interpretation was questioned in 1854 by Edward Forbes, and the later stages of Barrande; F, G and H have since been shown to be Devonian. Despite these modifications in the original groupings of the strata, it is recognized that Barrande established Bohemia as a classic ground for the study of the earliest Silurian fossils.\nPaleogeography.\nWith the supercontinent Gondwana covering the equator and much of the southern hemisphere, a large ocean occupied most of the northern half of the globe. The high sea levels of the Silurian and the relatively flat land (with few significant mountain belts) resulted in a number of island chains, and thus a rich diversity of environmental settings.\nDuring the Silurian, Gondwana continued a slow southward drift to high southern latitudes, but there is evidence that the Silurian icecaps were less extensive than those of the late-Ordovician glaciation. The southern continents remained united during this period. The melting of icecaps and glaciers contributed to a rise in sea level, recognizable from the fact that Silurian sediments overlie eroded Ordovician sediments, forming an unconformity. The continents of Avalonia, Baltica, and Laurentia drifted together near the equator, starting the formation of a second supercontinent known as Euramerica.\nWhen the proto-Europe collided with North America, the collision folded coastal sediments that had been accumulating since the Cambrian off the east coast of North America and the west coast of Europe. This event is the Caledonian orogeny, a spate of mountain building that stretched from New York State through conjoined Europe and Greenland to Norway. At the end of the Silurian, sea levels dropped again, leaving telltale basins of evaporites extending from Michigan to West Virginia, and the new mountain ranges were rapidly eroded. The Teays River, flowing into the shallow mid-continental sea, eroded Ordovician Period strata, forming deposits of Silurian strata in northern Ohio and Indiana.\nThe vast ocean of Panthalassa covered most of the northern hemisphere. Other minor oceans include two phases of the Tethys, the Proto-Tethys and Paleo-Tethys, the Rheic Ocean, the Iapetus Ocean (a narrow seaway between Avalonia and Laurentia), and the newly formed Ural Ocean.\nClimate and sea level.\nThe Silurian period was once believed to have enjoyed relatively stable and warm temperatures, in contrast with the extreme glaciations of the Ordovician before it and the extreme heat of the ensuing Devonian; however, it is now known that the global climate underwent many drastic fluctuations throughout the Silurian, evidenced by numerous major carbon and oxygen isotope excursions during this geologic period. Sea levels rose from their Hirnantian low throughout the first half of the Silurian; they subsequently fell throughout the rest of the period, although smaller scale patterns are superimposed on this general trend; fifteen high-stands (periods when sea levels were above the edge of the continental shelf) can be identified, and the highest Silurian sea level was probably around higher than the lowest level reached.\nDuring this period, the Earth entered a warm greenhouse phase, supported by high CO2 levels of 4500 ppm, and warm shallow seas covered much of the equatorial land masses. Early in the Silurian, glaciers retreated back into the South Pole until they almost disappeared in the middle of Silurian. Layers of broken shells (called coquina) provide strong evidence of a climate dominated by violent storms generated then as now by warm sea surfaces.\nPerturbations.\nThe climate and carbon cycle appear to be rather unsettled during the Silurian, which had a higher frequency of isotopic excursions (indicative of climate fluctuations) than any other period. The Ireviken event, Mulde event, and Lau event each represent isotopic excursions following a minor mass extinction and associated with rapid sea-level change. Each one leaves a similar signature in the geological record, both geochemically and biologically; pelagic (free-swimming) organisms were particularly hard hit, as were brachiopods, corals, and trilobites, and extinctions rarely occur in a rapid series of fast bursts. The climate fluctuations are best explained by a sequence of glaciations, but the lack of tillites in the middle to late Silurian make this explanation problematic.\nFlora and fauna.\nThe Silurian period has been viewed by some palaeontologists as an extended recovery interval following the Late Ordovician mass extinction (LOME), which interrupted the cascading increase in biodiversity that had continuously gone on throughout the Cambrian and most of the Ordovician.\nThe Silurian was the first period to see megafossils of extensive terrestrial biota in the form of moss-like miniature forests along lakes and streams and networks of large, mycorrhizal nematophytes, heralding the beginning of the Silurian-Devonian Terrestrial Revolution. However, the land fauna did not have a major impact on the Earth until it diversified in the Devonian.\nThe first fossil records of vascular plants, that is, land plants with tissues that carry water and food, appeared in the second half of the Silurian Period. The earliest-known representatives of this group are \"Cooksonia\". Most of the sediments containing \"Cooksonia\" are marine in nature. Preferred habitats were likely along rivers and streams. \"Baragwanathia\" appears to be almost as old, dating to the early Ludlow (420 Ma) and has branching stems and needle-like leaves of . The plant shows a high degree of development in relation to the age of its fossil remains. Fossils of this plant have been recorded in Australia, Canada, and China. \"Eohostimella heathana\" is an early, probably terrestrial, \"plant\" known from compression fossils of Early Silurian (Llandovery) age. The chemistry of its fossils is similar to that of fossilised vascular plants, rather than algae.\nFossils that are considered as terrestrial animals are also known from the Silurian. The definitive oldest record of millipede ever known is \"Kampecaris obanensis\" and \"Archidesmus\" sp. from the late Silurian (425 Ma) of Kerrera. There are also other millipedes, centipedes, and trigonotarbid arachnoids known from Ludlow (420 Ma). Predatory invertebrates would indicate that simple food webs were in place that included non-predatory prey animals. Extrapolating back from Early Devonian biota, Andrew Jeram \"et al.\" in 1990 suggested a food web based on as-yet-undiscovered detritivores and grazers on micro-organisms. Millipedes from Cowie Formation such as \"Cowiedesmus\" and \"Pneumodesmus\" were considered as the oldest millipede from the middle Silurian at 428\u2013430 Ma, although the age of this formation is later reinterpreted to be from the early Devonian instead by some researchers. Regardless, \"Pneumodesmus\" is still an important fossil as the oldest definitive evidence of spiracles to breathe in the air.\nThe first bony fish, the Osteichthyes, appeared, represented by the Acanthodians covered with bony scales. Fish reached considerable diversity and developed movable jaws, adapted from the supports of the front two or three gill arches. A diverse fauna of eurypterids (sea scorpions)\u2014some of them a few meters in length\u2014prowled the shallow Silurian seas and lakes of North America; many of their fossils have been found in New York state. Brachiopods were abundant and diverse, with the taxonomic composition, ecology, and biodiversity of Silurian brachiopods mirroring Ordovician ones. Brachiopods that survived the LOME developed novel adaptations for environmental stress, and they tended to be endemic to a single palaeoplate in the mass extinction's aftermath, but expanded their range afterwards. The most abundant brachiopods were atrypids and pentamerides; atrypids were the first to recover and rediversify in the Rhuddanian after LOME, while pentameride recovery was delayed until the Aeronian. Bryozoans exhibited significant degrees of endemism to a particular shelf. They also developed symbiotic relationships with cnidarians and stromatolites. Many bivalve fossils have also been found in Silurian deposits, and the first deep-boring bivalves are known from this period. Chitons saw a peak in diversity during the middle of the Silurian. Hederelloids enjoyed significant success in the Silurian, with some developing symbioses with the colonial rugose coral \"Entelophyllum\". The Silurian was a heyday for tentaculitoids, which experienced an evolutionary radiation focused mainly in Baltoscandia, along with an expansion of their geographic range in the Llandovery and Wenlock. Trilobites started to recover in the Rhuddanian, and they continued to enjoy success in the Silurian as they had in the Ordovician despite their reduction in clade diversity as a result of LOME. The Early Silurian was a chaotic time of turnover for crinoids as they rediversified after LOME. Members of Flexibilia, which were minimally impacted by LOME, took on an increasing ecological prominence in Silurian seas. Monobathrid camerates, like flexibles, diversified in the Llandovery, whereas cyathocrinids and dendrocrinids diversified later in the Silurian. Scyphocrinoid loboliths suddenly appeared in the terminal Silurian, shortly before the Silurian-Devonian boundary, and disappeared as abruptly as they appeared very shortly after their first appearance. Endobiotic symbionts were common in the corals and stromatoporoids. Rugose corals especially were colonised and encrusted by a diverse range of epibionts, including certain hederelloids as aforementioned. Photosymbiotic scleractinians made their first appearance during the Middle Silurian. Reef abundance was patchy; sometimes, fossils are frequent, but at other points, are virtually absent from the rock record.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26905", "revid": "50826154", "url": "https://en.wikipedia.org/wiki?curid=26905", "title": "Siege", "text": "Military land blockade of a location\nA siege (from la\u00a0'to sit') is a military blockade of a city, or fortress, with the intent of conquering by attrition, or by well-prepared assault. Siege warfare (also called siegecraft or poliorcetics) is a form of constant, low-intensity conflict characterized by one party holding a strong, static, defensive position. The attacking party is said to be laying siege. Consequently, an opportunity for negotiation between combatants is common, as proximity and fluctuating advantage can encourage diplomacy.\nA siege occurs when an attacker encounters a city or fortress that cannot be easily taken by a quick assault, and which refuses to surrender. Sieges involve surrounding the target to block provision of supplies and reinforcement or escape of troops (a tactic known as \"investment\"). This is typically coupled with attempts to reduce the fortifications by means of siege engines, artillery bombardment, or mining (also known as sapping), or the use of deception or treachery to bypass defenses.\nFailing a military outcome, sieges can often be decided by starvation, thirst, or disease, which can afflict either the attacker or defender. This form of siege, though, can take many months or even years, depending upon the size of the stores of food the fortified position holds. The attacking force can circumvallate the besieged place, which is to build a line of earth-works, consisting of a rampart and trench, surrounding it. During the process of circumvallation, the attacking force can be set upon by another force, an ally of the besieged place, due to the lengthy amount of time required to force it to capitulate. A defensive ring of forts outside the ring of circumvallated forts, called contravallation, is also sometimes used to defend the attackers from outside.\nAncient cities in the Middle East show archaeological evidence of fortified city walls. During the Warring States period of ancient China, there is both textual and archaeological evidence of prolonged sieges and siege machinery used against the defenders of city walls. Siege machinery was also a tradition of the ancient Greco-Roman world. During the Renaissance and the early modern period, siege warfare dominated the conduct of war in Europe. Leonardo da Vinci gained some of his renown from design of fortifications. Medieval campaigns were generally designed around a succession of sieges. In the Napoleonic era, increasing use of ever more powerful cannons reduced the value of fortifications. In the 20th century, the significance of the classical siege declined. With the advent of mobile warfare, a single fortified stronghold is no longer as decisive as it once was. While traditional sieges do still occur, they are not as common as they once were due to changes in modes of battle, principally the ease by which huge volumes of destructive power can be directed onto a static target. Modern sieges are more commonly the result of smaller hostage, militant, or extreme resisting arrest situations.\nAncient period.\nThe necessity of city walls.\nCity walls and fortifications were essential for the defence of the first cities. The walls were built of mudbricks, stone, wood, or a combination of these materials, depending on local availability. They may also have served the dual purpose of showing potential enemies the might of the kingdom. The great walls surrounding the Sumerian city of Uruk in the ancient Near East gained a widespread reputation. The walls were in length, and up to in height.\nSome settlements in the Indus Valley civilization were also fortified. By about 3500\u00a0BC, hundreds of small farming villages dotted the Indus River floodplain. Many of these settlements had fortifications and planned streets.\nThe stone and mud brick houses of Kot Diji were clustered behind massive stone flood dikes and defensive walls, for neighbouring communities quarrelled constantly about the control of prime agricultural land. Mundigak (c. 2500\u00a0BC) in present-day south-east Afghanistan has defensive walls and square bastions of sun-dried bricks.\nThe Assyrians deployed large labour forces to build new palaces, temples, and defensive walls. Later, the walls of Babylon, reinforced by towers, moats, and ditches, gained a similar reputation. In Anatolia, the Hittites built massive stone walls around their cities atop hillsides, taking advantage of the terrain. In Shang dynasty China, at the site of Ao, large walls were erected in the 15th century BC that had dimensions of in width at the base and enclosed an area of some squared. The ancient Chinese capital for the State of Zhao, Handan, founded in 386 BC, also had walls that were wide at the base; they were tall, with two separate sides of its rectangular enclosure at a length of .\nThe cities of the Indus Valley Civilization showed less effort in constructing defences, as did the Minoan civilization on Crete. These civilizations probably relied more on the defence of their outer borders or sea shores. Unlike the ancient Minoan civilization, the Mycenaean Greeks emphasized the need for fortifications alongside natural defences of mountainous terrain, such as the massive Cyclopean walls built at Mycenae and other adjacent Late Bronze Age (c. 1600\u20131100 BC) centers of central and southern Greece.\nArchaeological evidence.\nAlthough there are depictions of sieges from the ancient Near East in historical sources and in art, there are very few examples of siege systems that have been found archaeologically. Of the few examples, several are noteworthy:\nDepictions.\nThe earliest representations of siege warfare have been dated to the Protodynastic Period of Egypt, c.\u20093000\u00a0BC. These show the symbolic destruction of city walls by divine animals using hoes.\nThe first siege equipment is known from Egyptian tomb reliefs of the 24th century BC, showing Egyptian soldiers storming Canaanite town walls on wheeled siege ladders. Later Egyptian temple reliefs of the 13th century BC portray the violent siege of Dapur, a Syrian city, with soldiers climbing scale ladders supported by archers.\nAssyrian palace reliefs of the 9th to 7th centuries BC display sieges of several Near Eastern cities. Though a simple battering ram had come into use in the previous millennium, the Assyrians improved siege warfare and used huge wooden tower-shaped battering rams with archers positioned on top.\nIn ancient China, sieges of city walls (along with naval battles) were portrayed on bronze 'hu' vessels, like those found in Chengdu, Sichuan in 1965, which have been dated to the Warring States period (5th to 3rd centuries BC).\nTactics.\nOffensive.\nAn attacker's first act in a siege might be a surprise attack, attempting to overwhelm the defenders before they were ready or were even aware there was a threat. This was how William de Forz captured Fotheringhay Castle in 1221.\nThe most common practice of siege warfare was to lay siege and just wait for the surrender of the enemies inside or, quite commonly, to coerce someone inside to betray the fortification. During the medieval period, negotiations would frequently take place during the early part of the siege. An attacker \u2013 aware of a prolonged siege's great cost in time, money, and lives \u2013 might offer generous terms to a defender who surrendered quickly. The defending troops would be allowed to march away unharmed, often retaining their weapons. However, a garrison commander who was thought to have surrendered too quickly might face execution by his own side for treason.\nAs a siege progressed, the surrounding army would build earthworks (a line of circumvallation) to completely encircle their target, preventing food, water, and other supplies from reaching the besieged city. If sufficiently desperate as the siege progressed, defenders and civilians might have been reduced to eating anything vaguely edible \u2013 horses, family pets, the leather from shoes, and even each other.\nThe Hittite siege of a rebellious Anatolian vassal in the 14th century BC ended when the queen mother came out of the city and begged for mercy on behalf of her people. The Hittite campaign against the kingdom of Mitanni in the 14th century BC bypassed the fortified city of Carchemish. If the main objective of a campaign was not the conquest of a particular city, it could simply be passed by. When the main objective of the campaign had been fulfilled, the Hittite army returned to Carchemish and the city fell after an eight-day siege.\nDisease was another effective siege weapon, although the attackers were often as vulnerable as the defenders. In some instances, catapults or similar weapons were used to fling diseased animals over city walls in an early example of biological warfare. If all else failed, a besieger could claim the booty of his conquest undamaged, and retain his men and equipment intact, for the price of a well-placed bribe to a disgruntled gatekeeper. The Assyrian siege of Jerusalem in the 8th century BC came to an end when the Israelites bought them off with gifts and tribute, according to the Assyrian account, or when the Assyrian camp was struck by mass death, according to the Biblical account. Due to logistics, long-lasting sieges involving a minor force could seldom be maintained. A besieging army, encamped in possibly squalid field conditions and dependent on the countryside and its own supply lines for food, could very well be threatened with the disease and starvation intended for the besieged.\nTo end a siege more rapidly, various methods were developed in ancient and medieval times to counter fortifications, and a large variety of siege engines was developed for use by besieging armies. Ladders could be used to escalade over the defenses. Battering rams and siege hooks could also be used to force through gates or walls, while catapults, ballistae, trebuchets, mangonels, and onagers could be used to launch projectiles to break down a city's fortifications and kill its defenders. A siege tower, a substantial structure built to equal or greater height than the fortification's walls, could allow the attackers to fire down upon the defenders and also advance troops to the wall with less danger than using ladders.\nIn addition to launching projectiles at the fortifications or defenders, it was also quite common to attempt to undermine the fortifications, causing them to collapse. This could be accomplished by digging a tunnel beneath the foundations of the walls, and then deliberately collapsing or exploding the tunnel. This process is known as mining. The defenders could dig counter-tunnels to cut into the attackers' works and collapse them prematurely.\nFire was often used as a weapon when dealing with wooden fortifications. The Roman Empire used Greek fire, which contained additives that made it hard to extinguish. Combined with a primitive flamethrower, it proved an effective offensive and defensive weapon. A sallying out might also occur with such weapons, or if the siege was of a location on a coastline, from ships launched from the harbor of the location.\nDefensive.\nThe universal method for defending against siege is the use of fortifications, principally walls and ditches, to supplement natural features. A sufficient supply of food and water was also important to defeat the simplest method of siege warfare: starvation. On occasion, the defenders would drive 'surplus' civilians out to reduce the demands on stored food and water.\nDuring the Warring States period in China (481\u2013221 BC), warfare lost its honorable, gentlemen's duty that was found in the previous era of the Spring and Autumn period, and became more practical, competitive, cut-throat, and efficient for gaining victory. The Chinese invention of the hand-held, trigger-mechanism crossbow during this period revolutionized warfare, giving greater emphasis to infantry and cavalry and less to traditional chariot warfare.\nThe philosophically pacifist Mohists (followers of the philosopher Mozi) of the 5th century BC believed in aiding the defensive warfare of smaller Chinese states against the hostile offensive warfare of larger domineering states. The Mohists were renowned in the smaller states (and the enemies of the larger states) for the inventions of siege machinery to scale or destroy walls. These included traction trebuchet catapults, high ballistas, a wheeled siege ramp with grappling hooks known as the Cloud Bridge (the protractible, folded ramp slinging forward by means of a counterweight with rope and pulley), and wheeled 'hook-carts' used to latch large iron hooks onto the tops of walls to pull them down.\nWhen enemies attempted to dig tunnels under walls for mining or entry into the city, the defenders used large bellows (the type the Chinese commonly used in heating up a blast furnace for smelting cast iron) to pump smoke into the tunnels in order to suffocate the intruders.\nAdvances in the prosecution of sieges in ancient and medieval times naturally encouraged the development of a variety of defensive countermeasures. In particular, medieval fortifications became progressively stronger\u2014for example, the advent of the concentric castle from the period of the Crusades\u2014and more dangerous to attackers\u2014witness the increasing use of machicolations and murder-holes, as well the preparation of hot or incendiary substances. Arrowslits (also called arrow loops or loopholes), sally ports (airlock-like doors) for sallies and deep water wells were also integral means of resisting siege at this time. Particular attention would be paid to defending entrances, with gates protected by drawbridges, portcullises, and barbicans. Moats and other water defenses, whether natural or augmented, were also vital to defenders.\nIn the European Middle Ages, virtually all large cities had city walls\u2014Dubrovnik in Dalmatia is a well-preserved example\u2014and more important cities had citadels, forts, or castles. Great effort was expended to ensure a good water supply inside the city in case of siege. In some cases, long tunnels were constructed to carry water into the city. Complex systems of tunnels were used for storage and communications in medieval cities like T\u00e1bor in Bohemia, similar to those used much later in Vietnam during the Vietnam War.\nUntil the invention of gunpowder-based weapons (and the resulting higher-velocity projectiles), the balance of power and logistics definitely favored the defender. With the invention of gunpowder, cannon and mortars and howitzers (in modern times), the traditional methods of defense became less effective against a determined siege.\nSiege accounts.\nAlthough there are numerous ancient accounts of cities being sacked, few contain any clues to how this was achieved. Some popular tales existed on how the cunning heroes succeeded in their sieges. The best-known is the Trojan Horse of the Trojan War, and a similar story tells how the Canaanite city of Joppa was conquered by the Egyptians in the 15th century BC. The Biblical Book of Joshua contains the story of the miraculous Battle of Jericho.\nA more detailed historical account from the 8th century BC, called the Piankhi stela, records how the Nubians laid siege to and conquered several Egyptian cities by using battering rams, archers, and slingers and building causeways across moats.\nClassical antiquity.\nDuring the Peloponnesian War, one hundred sieges were attempted and fifty-eight ended with the surrender of the besieged area.\nAlexander the Great's army successfully besieged many powerful cities during his conquests. Two of his most impressive achievements in siegecraft took place in the siege of Tyre and the siege of the Sogdian Rock. His engineers built a causeway that was originally wide and reached the range of his torsion-powered artillery, while his soldiers pushed siege towers housing stone throwers and light catapults to bombard the city walls.\nMost conquerors before him had found Tyre, a Phoenician island-city about from the mainland, impregnable. The Macedonians built a mole, a raised spit of earth across the water, by piling stones up on a natural land bridge that extended underwater to the island, and although the Tyrians rallied by sending a fire ship to destroy the towers, and captured the mole in a swarming frenzy, the city eventually fell to the Macedonians after a seven-month siege. In complete contrast to Tyre, Sogdian Rock was captured by stealthy attack. Alexander used commando-like tactics to scale the cliffs and capture the high ground, and the demoralized defenders surrendered.\nThe importance of siege warfare in the ancient period should not be underestimated. One of the contributing causes of Hannibal's inability to defeat Rome was his lack of siege engines, thus, while he was able to defeat Roman armies in the field, he was unable to capture Rome itself. The legionary armies of the Roman Republic and Empire are noted as being particularly skilled and determined in siege warfare. An astonishing number and variety of sieges, for example, formed the core of Julius Caesar's mid-1st-century BC conquest of Gaul (modern France).\nIn his \"Commentarii de Bello Gallico\" (\"Commentaries on the Gallic War\"), Caesar describes how, at the Battle of Alesia, the Roman legions created two huge fortified walls around the city. The inner circumvallation, , held in Vercingetorix's forces, while the outer contravallation kept relief from reaching them. The Romans held the ground in between the two walls. The besieged Gauls, facing starvation, eventually surrendered after their relief force met defeat against Caesar's auxiliary cavalry.\nThe Sicarii Zealots who defended Masada in AD 73 were defeated by the Roman legions, who built a ramp high up to the fortress's west wall.\nDuring the Roman\u2013Persian Wars, siege warfare was extensively used by both sides.\nMedieval period.\nMongols and Chinese.\nIn the Middle Ages, the Mongol Empire's campaign against China (then comprising the Western Xia dynasty, Jin dynasty, and Southern Song dynasty) by Genghis Khan until Kublai Khan, who eventually established the Yuan dynasty in 1271, was very effective, allowing the Mongols to sweep through large areas. Even if they could not enter some of the more well-fortified cities, they used innovative battle tactics to grab hold of the land and the people:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;By concentrating on the field armies, the strongholds had to wait. Of course, smaller fortresses, or ones easily surprised, were taken as they came along. This had two effects. First, it cut off the principal city from communicating with other cities where they might expect aid. Secondly, refugees from these smaller cities would flee to the last stronghold. The reports from these cities and the streaming hordes of refugees not only reduced the morale of the inhabitants and garrison of the principal city, it also strained their resources. Food and water reserves were taxed by the sudden influx of refugees. Soon, what was once a formidable undertaking became easy. The Mongols were then free to lay siege without interference of the field army, as it had been destroyed. At the siege of Aleppo, Hulagu used twenty catapults against the \"Bab al-Iraq\" (Gate of Iraq) alone. \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In J\u00fbzj\u00e2n\u00ee, there are several episodes in which the Mongols constructed hundreds of siege machines in order to surpass the number which the defending city possessed. While J\u00fbzj\u00e2n\u00ee surely exaggerated, the improbably high numbers which he used for both the Mongols and the defenders do give one a sense of the large numbers of machines used at a single siege.\nAnother Mongol tactic was to use catapults to launch corpses of plague victims into besieged cities. The disease-carrying fleas from the bodies would then infest the city, and the plague would spread, allowing the city to be easily captured, although this transmission mechanism was not known at the time. In 1346, the bodies of Mongol warriors of the Golden Horde who had died of plague were thrown over the walls of the Crimean city of Kaffa (now Feodosiya) during the siege of Caffa. It has been speculated that this operation may have been responsible for the advent of the Black Death in Europe. The Black Death is estimated to have killed 30%\u201360% of Europe's population.\nOn the first night while laying siege to a city, the leader of the Mongol forces would lead from a white tent: if the city surrendered, all would be spared. On the second day, he would use a red tent: if the city surrendered, the men would all be killed, but the rest would be spared. On the third day, he would use a black tent: no quarter would be given.\nHowever, the Chinese were not completely defenseless, and from AD 1234 until 1279, the Southern Song Chinese held out against the enormous barrage of Mongol attacks. Much of this success in defense lay in the world's first use of gunpowder (i.e. with early flamethrowers, grenades, firearms, cannons, and land mines) to fight back against the Khitans, the Tanguts, the Jurchens, and then the Mongols.\nThe Chinese of the Song period also discovered the explosive potential of packing hollowed cannonball shells with gunpowder. Written later c.\u20091350 in the \"Huo Long Jing\", this manuscript of Jiao Yu recorded an earlier Song-era cast-iron cannon known as the 'flying-cloud thunderclap eruptor' (fei yun pi-li pao). The manuscript stated that (Wade\u2013Giles spelling):\nThe shells (\"phao\") are made of cast iron, as large as a bowl and shaped like a ball. Inside they contain half a pound of 'magic' gunpowder (\"shen huo\"). They are sent flying towards the enemy camp from an eruptor (\"mu phao\"); and when they get there a sound like a thunder-clap is heard, and flashes of light appear. If ten of these shells are fired successfully into the enemy camp, the whole place will be set ablaze...\nDuring the Ming dynasty (AD 1368\u20131644), the Chinese were very concerned with city planning in regards to gunpowder warfare. The site for constructing the walls and the thickness of the walls in Beijing's Forbidden City were favoured by the Chinese Yongle Emperor (r. 1402\u20131424) because they were in pristine position to resist cannon volley and were built thick enough to withstand attacks from cannon fire.\n\"For more, see Technology of the Song dynasty.\"\nAge of gunpowder.\nThe introduction of gunpowder and the use of cannons brought about a new age in siege warfare. Cannons were first used in Song dynasty China during the early 13th century, but did not become significant weapons for another 150 years or so. In early decades, cannons could do little against strong castles and fortresses, providing little more than smoke and fire. By the 16th century, however, they were an essential and regularized part of any campaigning army, or castle's defences.\nThe greatest advantage of cannons over other siege weapons was the ability to fire a heavier projectile, farther, faster, and more often than previous weapons. They could also fire projectiles in a straight line, so that they could destroy the bases of high walls. Thus, 'old fashioned' walls \u2013 that is, high and, relatively, thin \u2013 were excellent targets, and, over time, easily demolished. In 1453, the Theodosian Walls of Constantinople, the capital of the Roman Empire, were broken through in just six weeks by the 62 cannons of Mehmed II's army, although in the end the conquest was a long and extremely difficult siege with heavy Ottoman casualties due to the repeated attempts at taking the city by assault.\nHowever, new fortifications, designed to withstand gunpowder weapons, were soon constructed throughout Europe. During the Renaissance and the early modern period, siege warfare continued to dominate the conduct of the European wars.\nOnce siege guns were developed, the techniques for assaulting a town or fortress became well known and ritualized. The attacking army would surround a town. Then the town would be asked to surrender. If they did not comply, the besieging army would surround the town with temporary fortifications to stop sallies from the stronghold or relief getting in. The attackers would next build a length of trenches parallel to the defenses (these are known as the \"first parallel\") and just out of range of the defending artillery. They would dig a trench (known as a forward) towards the town in a zigzag pattern so that it could not be enfiladed by defending fire. Once they were within artillery range, they would dig another parallel (the \"second parallel\") trench and fortify it with gun emplacements. This technique is commonly called entrenchment.\nIf necessary, using the first artillery fire for cover, the forces conducting the siege would repeat the process until they placed their guns close enough to be laid (aimed) accurately to make a breach in the fortifications. In order to allow the forlorn hope and support troops to get close enough to exploit the breach, more zigzag trenches could be dug even closer to the walls, with more parallel trenches to protect and conceal the attacking troops. After each step in the process, the besiegers would ask the besieged to surrender. If the forlorn hope stormed the breach successfully, the defenders could expect no mercy.\nEmerging theories.\nThe castles that in earlier years had been formidable obstacles were easily breached by the new weapons. For example, in Spain, the newly equipped army of Ferdinand and Isabella was able to conquer Moorish strongholds in Granada in 1482\u20131492 that had held out for centuries before the invention of cannons.\nIn the early 15th century, Italian architect Leon Battista Alberti wrote a treatise entitled \"De Re aedificatoria\", which theorized methods of building fortifications capable of withstanding the new guns. He proposed that walls be \"built in uneven lines, like the teeth of a saw\". He proposed star-shaped fortresses with low, thick walls.\nHowever, few rulers paid any attention to his theories. A few towns in Italy began building in the new style late in the 1480s, but it was only with the French invasion of the Italian peninsula in 1494\u20131495 that the new fortifications were built on a large scale. Charles VIII invaded Italy with an army of 18,000 men and a horse-drawn siege-train. As a result, he could defeat virtually any city or state, no matter how well defended. In a panic, military strategy was completely rethought throughout the Italian states of the time, with a strong emphasis on the new fortifications that could withstand a modern siege.\nNew fortresses.\nThe most effective way to protect walls against cannon fire proved to be depth (increasing the width of the defenses) and angles (ensuring that attackers could only fire on walls at an oblique angle, not square on). Initially, walls were lowered and backed, in front and behind, with earth. Towers were reformed into triangular bastions. This design matured into the \"trace italienne\". Star-shaped fortresses surrounding towns and even cities with outlying defenses proved very difficult to capture, even for a well-equipped army. Fortresses built in this style throughout the 16th century did not become fully obsolete until the 19th century, and were still in use throughout World War I (though modified for 20th-century warfare). During World War II, \"trace italienne\" fortresses could still present a formidable challenge, for example, in the last days of World War II, during the Battle in Berlin, that saw some of the heaviest urban fighting of the war, the Soviets did not attempt to storm the Spandau Citadel (built between 1559 and 1594), but chose to invest it and negotiate its surrender.\nHowever, the cost of building such vast modern fortifications was incredibly high, and was often too much for individual cities to undertake. Many were bankrupted in the process of building them; others, such as Siena, spent so much money on fortifications that they were unable to maintain their armies properly, and so lost their wars anyway. Nonetheless, innumerable large and impressive fortresses were built throughout northern Italy in the first decades of the 16th century to resist repeated French invasions that became known as the Italian Wars. Many stand to this day.\nIn the 1530s and 1540s, the new style of fortification began to spread out of Italy into the rest of Europe, particularly to France, the Netherlands, and Spain. Italian engineers were in enormous demand throughout Europe, especially in war-torn areas such as the Netherlands, which became dotted by towns encircled in modern fortifications. The densely populated areas of Northern Italy and the United Provinces (the Netherlands) were infamous for their high degree of fortification of cities. It made campaigns in these areas very hard to successfully conduct, considering even minor cities had to be captured by siege within the span of the campaigning season. In the Dutch case, the possibility of flooding large parts of the land provided an additional obstacle to besiegers, for example at the siege of Leiden. For many years, defensive and offensive tactics were well balanced, leading to protracted and costly wars such as Europe had never known, involving more and more planning and government involvement. The new fortresses ensured that war rarely extended beyond a series of sieges. Because the new fortresses could easily hold 10,000 men, an attacking army could not ignore a powerfully fortified position without serious risk of counterattack. As a result, virtually all towns had to be taken, and that was usually a long, drawn-out affair, potentially lasting from several months to years, while the members of the town were starved to death. Most battles in this period were between besieging armies and relief columns sent to rescue the besieged.\nMarshal Vauban and Van Coehoorn.\nAt the end of the 17th century, two influential military engineers, the French Marshal Vauban and the Dutch military engineer Menno van Coehoorn, developed modern fortification to its pinnacle, refining siege warfare without fundamentally altering it: ditches would be dug; walls would be protected by glacis; and bastions would enfilade an attacker. Both engineers developed their ideas independently, but came to similar general rules regarding defensive construction and offensive action against fortifications. Both were skilled in conducting sieges and defenses themselves. Before Vauban and Van Coehoorn, sieges had been somewhat slapdash operations. Vauban and Van Coehoorn refined besieging to a science with a methodical process that, if uninterrupted, would break even the strongest fortifications. Examples of their styles of fortifications are Arras (Vauban) and the no-longer-existent fortress of Bergen op Zoom (Van Coehoorn). The main differences between the two lay in the difference in terrain on which Vauban and Van Coehoorn constructed their defenses: Vauban in the sometimes more hilly and mountainous terrain of France, Van Coehoorn in the flat and floodable lowlands of the Netherlands.\nPlanning and maintaining a siege is just as difficult as fending one off. A besieging army must be prepared to repel both sorties from the besieged area and also any attack that may try to relieve the defenders. It was thus usual to construct lines of trenches and defenses facing in both directions. The outermost lines, known as the lines of contravallation, would surround the entire besieging army and protect it from attackers.\nThis would be the first construction effort of a besieging army, built soon after a fortress or city had been invested. A line of circumvallation would also be constructed, facing in towards the besieged area, to protect against sorties by the defenders and to prevent the besieged from escaping. The next line, which Vauban usually placed at about from the target, would contain the main batteries of heavy cannons so that they could hit the target without being vulnerable themselves. Once this line was established, work crews would move forward, creating another line at . This line contained smaller guns. The final line would be constructed only from the fortress. This line would contain the mortars and would act as a staging area for attack parties once the walls were breached. Van Coehoorn developed a small and easily movable mortar named the coehorn, variations of which were used in sieges until the 19th century. It would also be from this line that miners working to undermine the fortress would operate.\nThe trenches connecting the various lines of the besiegers could not be built perpendicular to the walls of the fortress, as the defenders would have a clear line of fire along the whole trench. Thus, these lines (known as saps) needed to be sharply jagged.\nAnother element of a fortress was the citadel. Usually, a citadel was a \"mini fortress\" within the larger fortress, sometimes designed as a reduit, but more often as a means of protecting the garrison from potential revolt in the city. The citadel was used in wartime and peacetime to keep the residents of the city in line.\nAs in ages past, most sieges were decided with very little fighting between the opposing armies. An attacker's army was poorly served, incurring the high casualties that a direct assault on a fortress would entail. Usually, they would wait until supplies inside the fortifications were exhausted or disease had weakened the defenders to the point that they were willing to surrender. At the same time, diseases, especially typhus, were a constant danger to the encamped armies outside the fortress, and often forced a premature retreat. Sieges were often won by the army that lasted the longest.\nAn important element of strategy for the besieging army was whether or not to allow the encamped city to surrender. Usually, it was preferable to graciously allow a surrender, both to save on casualties, and to set an example for future defending cities. A city that was allowed to surrender with minimal loss of life was much better off than a city that held out for a long time and was brutally butchered at the end. Moreover, if an attacking army had a reputation of killing and pillaging regardless of a surrender, then other cities' defensive efforts would be redoubled. Usually, a city would surrender (with no honour lost) when its inner lines of defense were reached by the attacker. In case of refusal, however, the inner lines would have to be stormed by the attacker and the attacking troops would be seen to be justified in sacking the city.\nSiege warfare.\nSiege warfare dominated in Western Europe for most of the 17th and 18th centuries. An entire campaign, or longer, could be used in a single siege (for example, Ostend in 1601\u20131604; La Rochelle in 1627\u20131628). This resulted in extremely prolonged conflicts. The balance was that, while siege warfare was extremely expensive and very slow, it was very successful\u2014or, at least, more so than encounters in the field. Battles arose through clashes between besiegers and relieving armies, but the principle was a slow, grinding victory by the greater economic power. The relatively rare attempts at forcing pitched battles (Gustavus Adolphus in 1630; the French against the Dutch in 1672 or 1688) were almost always expensive failures.\nThe exception to this rule were the English. During the English Civil War, anything which tended to prolong the struggle, or seemed like want of energy and avoidance of a decision, was bitterly resented by the men of both sides. In France and Germany, the prolongation of a war meant continued employment for the soldiers, but in England, both sides were looking to end the war quickly. Even when in the end the New Model Army\u2014a regular professional army\u2014developed the original decision-compelling spirit permeated the whole organisation, as was seen when pitched against regular professional continental troops the Battle of the Dunes during the Interregnum.\nExperienced commanders on both sides in the English Civil War recommended the abandonment of garrisoned fortifications for two primary reasons. The first, as for example proposed by the Royalist Sir Richard Willis to King Charles, was that by abandoning the garrisoning of all but the most strategic locations in one's own territory, far more troops would be available for the field armies, and it was the field armies which would decide the conflict. The other argument was that by slighting potential strong points in one's own territory, an enemy expeditionary force, or local enemy rising, would find it more difficult to consolidate territorial gains against an inevitable counterattack. Sir John Meldrum put forward just such an argument to the Parliamentary Committee of Both Kingdoms, to justify his slighting of Gainsborough in Lincolnshire.\nSixty years later, during the War of the Spanish Succession, the Duke of Marlborough preferred to engage the enemy in pitched battles, rather than engage in siege warfare, although he was very proficient in both types of warfare.\nOn 15 April 1746, the day before the Battle of Culloden, at Dunrobin Castle, a party of William Sutherland's militia conducted the last siege fought on the mainland of Great Britain against Jacobite members of Clan MacLeod.\nStrategic concepts.\nIn the French Revolutionary and Napoleonic Wars, new techniques stressed the division of armies into all-arms corps that would march separately and only come together on the battlefield. The less-concentrated army could now live off the country and move more rapidly over a larger number of roads.\nFortresses commanding lines of communication could be bypassed and would no longer stop an invasion. Since armies could not live off the land indefinitely, Napoleon Bonaparte always sought a quick end to any conflict by pitched battle. This military revolution was described and codified by Clausewitz.\nIndustrial advances.\nAdvances in artillery made previously impregnable defenses useless. For example, the walls of Vienna that had held off the Turks in the mid-17th century were no obstacle to Napoleon in the early 19th.\nWhere sieges occurred (such as the siege of Delhi and the siege of Cawnpore during the Indian Rebellion of 1857), the attackers were usually able to defeat the defenses within a matter of days or weeks, rather than weeks or months as previously. The great Swedish white-elephant fortress of Karlsborg was built in the tradition of Vauban and intended as a reserve capital for Sweden, but it was obsolete before it was completed in 1869.\nRailways, when they were introduced, made possible the movement and supply of larger armies than those that fought in the Napoleonic Wars. It also reintroduced siege warfare, as armies seeking to use railway lines in enemy territory were forced to capture fortresses which blocked these lines.\nDuring the Franco-Prussian War, the battlefield front lines moved rapidly through France. However, the Prussian and other German armies were delayed for months at the siege of Metz and the siege of Paris, due to the greatly increased firepower of the defending infantry, and the principle of detached or semi-detached forts with heavy-caliber artillery. This resulted in the later construction of fortress works across Europe, such as the massive fortifications at Verdun. It also led to the introduction of tactics which sought to induce surrender by bombarding the civilian population within a fortress, rather than the defending works themselves.\nThe siege of Sevastopol during the Crimean War and the siege of Petersburg (1864\u20131865) during the American Civil War showed that modern citadels, when improved by improvised defences, could still resist an enemy for many months. The siege of Plevna during the Russo-Turkish War (1877\u20131878) proved that hastily constructed field defenses could resist attacks prepared without proper resources, and were a portent of the trench warfare of World War I.\nAdvances in firearms technology without the necessary advances in battlefield communications gradually led to the defense again gaining the ascendancy. An example of siege during this time, prolonged during 337 days due to the isolation of the surrounded troops, was the siege of Baler, in which a reduced group of Spanish soldiers was besieged in a small church by the Philippine rebels in the course of the Philippine Revolution and the Spanish\u2013American War, until months after the Treaty of Paris, the end of the conflict.\nFurthermore, the development of steamships availed greater speed to blockade runners, ships with the purpose of bringing cargo, e.g. food, to cities under blockade, as with Charleston, South Carolina, during the American Civil War.\nModern warfare.\nWorld War I.\nMainly as a result of the increasing firepower (such as machine guns) available to defensive forces, First World War trench warfare briefly revived a form of siege warfare. Although siege warfare had moved out from an urban setting because city walls had become ineffective against modern weapons, trench warfare was nonetheless able to use many of the techniques of siege warfare in its prosecution (sapping, mining, barrage and, of course, attrition), but on a much larger scale and on a greatly extended front.\nMore traditional sieges of fortifications took place in addition to trench sieges. The siege of Tsingtao was one of the first major sieges of the war, but the inability for significant resupply of the German garrison made it a relatively one-sided battle. The Germans and the crew of an Austro-Hungarian protected cruiser put up a hopeless defense and, after holding out for more than a week, surrendered to the Japanese, forcing the German East Asia Squadron to steam towards South America for a new coal source.\nThe other major siege outside Europe during the First World War was in Mesopotamia, at the siege of Kut. After a failed attempt to move on Baghdad, stopped by the Ottomans at the bloody Battle of Ctesiphon, the British and their large contingent of Indian sepoy soldiers were forced to retreat to Kut, where the Ottomans under German General Baron Colmar von der Goltz laid siege. The British attempts to resupply the force via the Tigris river failed, and rationing was complicated by the refusal of many Indian troops to eat cattle products. By the time the garrison fell on 29 April 1916, starvation was rampant. Conditions did not improve greatly under Turkish imprisonment. Along with the battles of Tanga, Sandfontein, Gallipoli, and Namacurra, it would be one of Britain's numerous embarrassing colonial defeats of the war.\nThe largest sieges of the war, however, took place in Europe. The initial German advance into Belgium produced four major sieges: the Battle of Li\u00e8ge, the siege of Namur, the siege of Maubeuge, and the siege of Antwerp. All four would prove crushing German victories, at Li\u00e8ge and Namur against the Belgians, at Maubeuge against the French and at Antwerp against a combined Anglo-Belgian force. The weapon that made these victories possible were the German Big Berthas and the Skoda 305 mm Model 1911 siege mortars, one of the best siege mortars of the war, on loan from Austria-Hungary. These huge guns were the decisive weapon of siege warfare in the 20th century, taking part at Przemy\u015bl, the Belgian sieges, on the Italian Front and Serbian Front, and even being reused in World War II.\nAt the siege of Przemy\u015bl, during World War I, the Austro-Hungarian garrison showed excellent knowledge of siege warfare, not only waiting for relief, but sending sorties into Russian lines and employing an active defense that resulted in the capture of the Russian General Lavr Kornilov. Despite its excellent performance, the garrison's food supply had been requisitioned for earlier offensives, a relief expedition was stalled by the weather, ethnic rivalries flared up between the defending soldiers, and a breakout attempt failed. When the commander of the garrison Hermann Kusmanek finally surrendered, his troops were eating their horses and the first attempt of large-scale air supply had failed. It was one of the few great victories obtained by either side during the war; 110,000 Austro-Hungarian prisoners were marched back to Russia. Use of aircraft for siege running, bringing supplies to areas under siege, would nevertheless prove useful in many sieges to come.\nThe largest siege of the war, and arguably the roughest, most gruesome battle in history, was the Battle of Verdun. Whether the battle can be considered true siege warfare is debatable. Under the theories of Erich von Falkenhayn, it is more distinguishable as purely attrition with a coincidental presence of fortifications on the battlefield. When considering the plans of Crown Prince Wilhelm, purely concerned with taking the citadel and not with French casualty figures, it can be considered a true siege. The main fortifications were Fort Douaumont, Fort Vaux, and the fortified city of Verdun itself. The Germans, through the use of huge artillery bombardments, flamethrowers, and infiltration tactics, were able to capture both Vaux and Douaumont, but were never able to take the city, and eventually lost most of their gains. It was a battle that, despite the French ability to fend off the Germans, neither side won. The German losses were not worth the potential capture of the city, and the French casualties were not worth holding the symbol of her defense.\nThe development of the armored tank and improved infantry tactics at the end of World War I swung the pendulum back in favor of maneuver, and with the advent of Blitzkrieg in 1939, the end of traditional siege warfare was at hand. The Maginot Line would be the prime example of the failure of immobile, post\u2013World War I fortifications. Although sieges would continue, it would be in a totally different style and on a reduced scale.\nWorld War II.\nThe Blitzkrieg of the Second World War truly showed that fixed fortifications are easily defeated by manoeuvre instead of frontal assault or long sieges. The great Maginot Line was bypassed, and battles that would have taken weeks of siege could now be avoided with the careful application of air power (such as the German paratrooper capture of Fort Eben-Emael, Belgium, early in World War II).\nThe most important siege was the siege of Leningrad, which lasted over 29 months, about half of the duration of the entire Second World War. The siege of Leningrad resulted in the deaths of some one million of the city's inhabitants. Along with the Battle of Stalingrad, the siege of Leningrad on the Eastern Front was the deadliest siege of a city in history. In the west, apart from the Battle of the Atlantic, the sieges were not on the same scale as those on the European Eastern front; however, there were several notable or critical sieges: the island of Malta, for which the population won the George Cross and Tobruk. In the South-East Asian theatre, there was the siege of Singapore, and in the Burma campaign, sieges of Myitkyina, the Admin Box, Imphal, and Kohima, which was the high-water mark for the Japanese advance into India.\nThe siege of Sevastopol saw the use of the heaviest and most powerful individual siege engines ever to be used: the German 800\u00a0mm railway gun and the 600\u00a0mm siege mortar. Though a single shell could have disastrous local effect, the guns were susceptible to air attack in addition to being slow to move.\nAirbridge.\nThroughout the war both the Western Allies and the Germans tried to supply forces besieged behind enemy lines with ad-hoc airbridges. Sometimes these attempts failed, as happened to the besieged German Sixth Army the Battle of Stalingrad, and sometimes they succeeded as happened during the Battle of the Admin Box (5 \u2013 23 February 1944) and the short Siege of Bastogne (December 1944).\nThe logistics of strategic airbridge operations were developed by the Americans flying military transport aircraft from India to China over the Hump (1942\u20131945), to resupply the Chinese war effort of Chiang Kai-shek, and to the USAAF XX Bomber Command (during Operation Matterhorn).\nTactical airbridge methods were developed and, as planned, used extensively for supplying the Chindits during Operation Thursday (February \u2013 May 1944). The Chindits, a specially trained division of the British and Indian armies, were flown deep behind Japanese front lines in the South-East Asian theatre to jungle clearings in Burma where they set up fortified airheads from which they sailed out to attack Japanese lines of communications, while defending the bases from Japanese counterattacks. The bases were re-supplied by air with casualties flown out by returning aircraft. When the Japanese attacked in strength the Chindits abandoned the bases and either moved to new bases, or back to Allied lines.\nPost-World War II.\nSeveral times during the Cold War the western powers had to use their airbridge expertise.\nIn both Vietnamese cases, the Viet Minh and NLF were able to cut off the opposing army by capturing the surrounding rugged terrain. At Dien Bien Phu, the French were unable to use air power to overcome the siege and were defeated. However, at Khe Sanh, a mere 14 years later, advances in air power\u2014and a reduction in Vietnamese anti-aircraft capability\u2014allowed the United States to withstand the siege. The resistance of US forces was assisted by the PAVN and PLAF forces' decision to use the Khe Sanh siege as a strategic distraction to allow their mobile warfare offensive, the first Tet Offensive, to unfold securely.\nThe Battle of Khe Sanh displays typical features of modern sieges, as the defender has greater capacity to withstand the siege, the attacker's main aim is to bottle operational forces or create a strategic distraction, rather than take the siege to a conclusion.\nIn neighboring Cambodia, at that time known as the Khmer Republic, the Khmer Rouge used siege tactics to cut off supplies from Phnom Penh to other government-held enclaves in an attempt to break the will of the government to continue fighting.\nIn 1972, during the Easter offensive, the siege of An L\u1ed9c Vietnam occurred. ARVN troops and U.S. advisers and air power successfully defeated communist forces. The Battle of An L\u1ed9c pitted some 6,350 ARVN men against a force three times that size. During the peak of the battle, ARVN had access to only one 105\u00a0mm howitzer to provide close support, while the enemy attack was backed by an entire artillery division. ARVN had no tanks, the NVA communist forces had two armoured regiments. ARVN prevailed after over two months of continuous fighting. As General Paul Vanuxem, a French veteran of the Indochina War, wrote in 1972 after visiting the liberated city of An L\u1ed9c: \"An L\u1ed9c was the Verdun of Vietnam, where Vietnam received as in baptism the supreme consecration of her will.\"\nDuring the 1982 Lebanon War, the Israel Defence Forces besieged Beirut, the capital of Lebanon, to quickly realize their goals including the eviction of the Palestine Liberation Organization from the country.\nDuring the Yugoslav Wars in the 1990s, Republika Srpska forces besieged Sarajevo, the capital of Bosnia-Herzegovina. The siege lasted from April 1992 until February 1996.\nNumerous sieges haven taken place during the Syrian civil war, such as the siege of Homs, siege of Koban\u00ee, siege of Deir ez-Zor (2014\u20132017), siege of Nubl and al-Zahraa, and siege of al-Fu'ah and Kafriya.\nDuring various points in the Nagorno-Karabakh Conflict, Azerbaijan besieged the capital of Stepanakert (1991-1992), as well as the entire de facto Armenian-controlled republic during the Blockade of Nagorno-Karabakh (2022-2023).\nMultiple sieges took place in the Russo-Ukrainian war, notably the siege of Mariupol. Other sieges in the war include the Siege of Chernihiv and Siege of Sloviansk.\nThe Gaza war contained multiple sieges, including the siege of Gaza City and the siege of Khan Yunis.\nPolice sieges.\nSiege tactics continue to be employed in police contexts; such a siege is typically called a standoff or, in law enforcement jargon, a barricade situation. Standoffs may result from crimes and incidents such as robberies, raids, search and arrest warrants, prison riots, or terrorist attacks. Standoffs occur due to a variety of factors, most prominently the safety of police (against whom the besieged may have the upper hand), the besieged suspects (who police generally intend to arrest), bystanders (who may be in the crossfire), and hostages (who may be injured or killed by the suspects).\nThe optimal result of most standoffs is a peaceful resolution: the safe extraction of hostages and bystanders, and the peaceful surrender and arrest of the hostage-takers. To ensure this, police make use of trained negotiators and psychologists to learn the hostage-takers' demands (and meet said demands if feasible or permissible), gain the hostage-takers' trust, clarify that police do not intend to kill them or will even let them go (regardless of whether such claims are true), and coax the hostage-takers into surrendering or at least releasing hostages. In the event a peaceful resolution is impossible\u2014negotiations fail or do not proceed, hostages are released but the hostage-takers refuse to surrender, the hostage-takers resist violently, or hostages are killed\u2014police may respond in force, generally being able to rely on police tactical units or even military support if possible and required.\nMost standoffs are much shorter than military sieges, often lasting hours or days at most. Lengthy sieges may still occur, albeit rarely, such as the 51-day-long 1993 Waco siege. Most standoffs end in a peaceful resolution (i.e. 1973 Brooklyn hostage crisis, 1997 Roby standoff), though some may end in a police or military assault (i.e. 1994 Air France Flight 8969 hijacking, 1980 Iranian Embassy siege) or, in the worst-case scenarios, the deaths of authorities, hostage-takers, or hostages (i.e. 1985 MOVE bombing, 1985 EgyptAir Flight 648 hijacking, 2004 Beslan school siege, 2022 Robb Elementary School shooting). The aforementioned worst-case scenarios often result from poor planning, tactics, or negotiations on the part of the authorities (e.g. accidental killings of hostages by Unit 777 during the EgyptAir Flight 648 hijacking), or from violent acts committed by the hostage-takers (e.g. suicide bombings and executions during the Beslan school siege).\nIn some jurisdictions, depending on certain circumstances, standoffs that would usually be handled by police may be transferred to the military. For example, in the United Kingdom, standoffs with terrorists may be transferred to military responsibility for a military assault on the besieged. The threat of such an action ended the 1975 Balcombe Street siege, but the 1980 Iranian Embassy siege ended in a military assault and the deaths of all but one of the hostage-takers.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\nHistoriography"}
{"id": "26906", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=26906", "title": "Semantic dispute", "text": ""}
{"id": "26907", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=26907", "title": "Social engineering", "text": "Social engineering may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "26908", "revid": "27095161", "url": "https://en.wikipedia.org/wiki?curid=26908", "title": "St. Lawrence Seaway", "text": "System of waterways in Canada and the US\nThe St. Lawrence Seaway () is a system of rivers, locks, canals and channels in Eastern Canada and the Northern United States that permits oceangoing vessels to travel from the Atlantic Ocean to the Great Lakes of North America, as far inland as Duluth, Minnesota, at the western end of Lake Superior. The seaway is named for the St. Lawrence River, which flows straight from Lake Ontario to the Atlantic Gulf of St. Lawrence. Legally, the seaway extends from Montreal, Quebec, to Lake Erie, and includes the Welland Canal. Ships from the Atlantic Ocean are able to reach ports in all five of the Great Lakes via the Great Lakes Waterway.\nThe St. Lawrence River portion of the seaway is not a continuous waterway; rather, it consists of several stretches of navigable channels within the river, a number of locks, and canals along the banks of the St. Lawrence River to bypass several rapids and dams. A number of the locks are managed by the St. Lawrence Seaway Management Corporation in Canada, and others in the United States by the Great Lakes St. Lawrence Seaway Development Corporation; the two bodies together advertise the seaway as part of \"Highway H2O\". The section of the river from Montreal to the Atlantic Ocean is under Canadian jurisdiction, regulated by the offices of Transport Canada in the Port of Quebec.\nHistory.\nThe St. Lawrence Seaway was preceded by several other canals. In 1871, locks on the St. Lawrence allowed transit of vessels long, wide, and deep. The First Welland Canal, constructed between 1824 and 1829, had a minimum lock size of long, wide, and deep, but it was generally too small to allow passage of larger oceangoing ships. The Welland Canal's minimum lock size was increased to long, wide, and deep for the Second Welland Canal; to long, wide, and deep with the Third Welland Canal; and to long, wide, and deep for the current (Fourth) Welland Canal.\nThe first proposals for a binational comprehensive deep waterway along the St. Lawrence were made in the 1890s. In the following decades, developers proposed a hydropower project as inseparable from the seaway; the various governments and seaway supporters believed the deeper water to be created by the hydro project was necessary to make the seaway channels feasible for oceangoing ships. U.S. proposals for development up to and including the First World War met with little interest from the Canadian federal government. But the two national governments submitted St. Lawrence plans to a group for study. By the early 1920s, both the \"Wooten-Bowden Report\" and the International Joint Commission recommended the project.\nAlthough Canada's Liberal Prime Minister William Lyon Mackenzie King was reluctant to proceed, in part because of opposition to the project in Quebec, in 1932 he and the U.S. representative signed a treaty of intent. This treaty was submitted to the U.S. Senate in November 1932 and hearings continued until a vote was taken on March 14, 1934. The majority voted in favor of the treaty, but it failed to gain the necessary two-thirds vote for ratification. Later attempts between the governments in the 1930s to forge an agreement came to naught due to opposition by the Ontario government of Mitchell Hepburn and the government of Quebec. In 1936, John C. Beukema, head of the Great Lakes Harbors Association and a member of the Great Lakes Tidewater Commission, was among a delegation of eight from the Great Lakes states to meet at the White House with U.S. President Franklin D. Roosevelt to obtain his support for the seaway concept.\nBeukema and St. Lawrence Seaway proponents were convinced a nautical link would lead to the development of the communities and economies of the Great Lakes region by permitting the passage of oceangoing ships. In this period, exports of grain, along with other commodities, to Europe were an important part of the national economy. Negotiations on the treaty resumed in 1938, and by January 1940 substantial agreement was reached between Canada and the United States. By 1941, President Roosevelt and Prime Minister Mackenzie King made an executive agreement to build the joint hydro and navigation works, but this failed to receive the assent of the U.S. Congress. Proposals for the seaway were met with resistance; the primary opposition came from interests representing harbors on the Atlantic and Gulf Coasts and internal waterways and from the railroad associations. The railroads carried freight and goods between the coastal ports and the Great Lakes cities.\nAfter 1945, proposals to introduce tolls to the seaway were not sufficient to gain support for the project by the U.S. Congress. Growing impatient, and with Ontario desperate for the power to be generated by hydroelectricity, Canada began to consider developing the project alone. This seized the imagination of Canadians, engendering a groundswell of nationalism around the St. Lawrence. On September 28, 1951, Canadian Prime Minister Louis St. Laurent advised U.S. President Harry S. Truman that Canada was unwilling to wait for the United States and would build a seaway alone; the Canadian Parliament authorized the founding of the St. Lawrence Seaway Authority on December 21 of that year. Fueled by this support, Saint Laurent's administration decided during 1951 and 1952 to construct the waterway alone, combined with the Moses-Saunders Power Dam. (This became the joint responsibility of Ontario and New York: as a hydropower dam would change the water levels, it required bilateral cooperation.)\nThe International Joint Commission issued an order of approval for joint construction of the dam in October 1952. U.S. Senate debate on the bill began on January 12, 1953, and the bill emerged from the House of Representatives Committee of Public Works on February 22, 1954. It received approval from the Senate and the House by May 1954. The first positive action to enlarge the seaway was taken on May 13, 1954, when U.S. President Dwight D. Eisenhower signed the Wiley-Dondero Seaway Act to authorize joint construction and establish the St. Lawrence Seaway Development Corporation as the U.S. authority. The need for cheap haulage of Quebec-Labrador iron ore was one of the arguments that finally swung the balance in favor of the seaway. Groundbreaking ceremonies took place in Massena, New York, on August 10, 1954. That year Eisenhower appointed Beukema to the five-member St. Lawrence Seaway Advisory Board.\nIn May 1957, the Connecting Channels Project was begun by the United States Army Corps of Engineers. By 1959, Beukema was on board the U.S. Coast Guard cutter \"Maple\" for the first trip through the U.S. locks, which opened up the Great Lakes to oceangoing ships. On April 25, 1959, large, deep-draft ocean vessels began streaming to the heart of the North American continent through the seaway, a project supported by every administration from Woodrow Wilson through Eisenhower.\nIn the United States, N. R. Danelian, worked with the U.S. Secretary of State on Canadian-U.S. issues regarding the seaway, persevering through 15 years to gain passage by the U.S. Congress of the \"Seaway Act\". He later became president of the Great Lakes St. Lawrence Association to promote seaway development to benefit the American heartland. The seaway was heavily promoted by the Eisenhower administration, which had been concerned with a lack of US control.\nThe seaway opened in 1959 and cost C$470 million, $336.2 million of which was paid by the Canadian government. Elizabeth II, Queen of Canada Prime Minister John Diefenbaker, and President Eisenhower formally opened the seaway on June 26, 1959 with a short cruise aboard the royal yacht after addressing crowds in Saint-Lambert, Quebec. 22,000 workers were employed at one time or another on the project, a superhighway for ocean freighters. Port of Milwaukee director Harry C. Brockel forecast just before the Seaway opened in 1959 that \"The St. Lawrence Seaway will be the greatest single development of this century in its effects on Milwaukee's future growth and prosperity.\" Lester Olsen, president of the Milwaukee Association of Commerce, said, \"The magnitude and potential of the St. Lawrence Seaway and the power project stir the imagination of the world.\"\nThe seaway's opening is often credited with making the Erie Canal obsolete and causing the severe economic decline of several cities along the canal in Upstate New York. But by the turn of the 20th century, the Erie Canal had already been largely supplanted by the railroads, which had been constructed across New York and could carry freight more quickly and cheaply. Upstate New York's economic decline was precipitated by numerous factors, only some of which had to do with the St. Lawrence Seaway.\nUnder the Canada Marine Act (1998), the Canadian portions of the seaway were set up with a non-profit corporate structure; this legislation also introduced changes to federal ports.\nGreat Lakes and seaway shipping generates $3.4 billion in business revenue annually in the United States. In 2002, ships moved 222 million tonnes of cargo through the seaway. Overseas shipments, mostly of inbound steel and outbound grain, accounted for 15.4 million tonnes, or 6.9%, of the total cargo moved. In 2004, seaway grain exports accounted for about 3.6% of U.S. overseas grain shipments, according to the U.S. Grains Council. In a typical year, seaway steel imports account for around 6% of the U.S. annual total. The toll revenue obtained from ocean vessels is about 25\u201330% of cargo revenue. The Port of Duluth shipped just over 2.5 million tonnes of grain, which is less than the port typically moved in the decade before the seaway opened Lake Superior to deep-draft oceangoing vessels in 1959.\nInternational changes have affected shipping through the seaway. Europe is no longer a major grain importer; large U.S. export shipments are now going to South America, Asia, and Africa. These destinations make Gulf and West Coast ports more critical to 21st-century grain exports. Referring to the seaway project, a retired Iowa State University economics professor who specialized in transportation issues said, \"It probably did make sense, at about the time it (the Seaway) was constructed and conceived, but since then everything has changed.\"\nCertain seaway users have been concerned about the low water levels of the Great Lakes that had been recorded between 2010 and 2016.\nExpansion proposal.\nThe Panama Canal was completed in 1914 and also serves oceangoing traffic. In the 1950s, seaway designers chose not to build the locks to match the size of ships permitted by the 1914 locks at the Panama Canal (, known as the Panamax limit). Instead, the seaway locks were built to match the smaller locks of Welland Canal, which opened in 1932. The seaway locks permit passage of a ship long by wide (the Seawaymax limit).\nThe U.S. Army Corps of Engineers conducted a study to expand the St. Lawrence Seaway, but the plan was scrapped in 2011 because of budgetary issues.\nLocks in the St. Lawrence River.\nThere are seven locks in the St. Lawrence River portion of the seaway. From downstream to upstream they are:\nWater Level Elevations:\nLocks in the Welland Canal.\nThere are eight locks on the Welland Canal. From the north to the south, there is lock 1 at Port Weller, followed by Lock 2 and then Lock 3, a site with a visitors' information centre and museum in St. Catharines, Ontario. There are four locks in Thorold, Ontario, including twin-flight locks 4, 5 and 6, with Lock 7 leading up to the main channel. The Lake Erie level control lock sits in Port Colborne, Ontario. \nLock, channel dimensions, and additional statistical data.\nThe size of vessels that can traverse the seaway is limited by the size of the locks. Those on the St. Lawrence and the Welland Canal are long, wide, and deep. The maximum allowed vessel size is slightly smaller: long, wide, and deep. After the opening of the seaway, many vessels designed for use on the Great Lakes were built to the maximum size permissible by the locks, known informally as Seawaymax or Seaway-Max. Large vessels of the lake freighter fleet are built on the lakes and cannot travel downstream beyond the Welland Canal. On the remaining Great Lakes, these ships are constrained only by the largest lock on the Great Lakes Waterway, the Poe Lock at the Soo Locks (at Sault Ste. Marie), which is long, wide, and deep.\nA vessel's draft is another obstacle to its passage on the seaway, particularly in connecting waterways such as the St. Lawrence River. The depth in the seaway's channels is (Panamax depth) downstream of Quebec City, between Quebec City and Deschaillons, to Montreal, and upstream of Montreal. Channel depths and limited lock sizes mean that only 10% of current oceangoing ships, which have been built much larger than in the 1950s, can traverse the entire seaway. Proposals to expand the seaway, dating from as early as the 1960s, have been rejected since the late 20th century as too costly. In addition, researchers, policy makers, and the public are much more aware of the environmental issues that have accompanied seaway development and are reluctant to open the Great Lakes to more invasions of damaging species, as well as associated issues along the canals and river. Questions have been raised as to whether such infrastructure costs could ever be recovered. Lower water levels in the Great Lakes have also posed problems for some vessels in recent years, and pose greater issues to communities, industries, and agriculture in the region.\nWhile the seaway is (as of 2010) mostly used for shipping bulk cargo, the possibility of its use for large-scale container shipping is under consideration as well. If the expansion project were to go ahead, feeder ships would take containers from the port of Oswego on Lake Ontario in upstate New York to Melford International Terminal in Nova Scotia for transfer to larger oceangoing ships.\nA website hosts measurements of wind, water, levels and water temperatures. A real-time interactive map of seaway locks, vessels, and ports is available at. The United States' National Oceanic and Atmospheric Administration-funded Great Lakes Water Level Dashboard compiles statistics on water depth at various points along the seaway.\nEcology.\nTo create a navigable channel through the Long Sault rapids and to allow hydroelectric stations to be established immediately upriver from Cornwall, Ontario, and Massena, New York, Lake St. Lawrence was created behind a dam. This required the condemnation and acquisition by the government of all the properties of six villages and three hamlets in Ontario; these are now collectively known as The Lost Villages. The area was flooded beginning on July 1, 1958, creating the lake. There was also inundation on the New York side of the border, and the village of Louisville Landing was submerged.\nA notable adverse environmental effect of the operation of the seaway has been the introduction of numerous invasive species of aquatic animals into the Great Lakes Basin. The zebra mussel has been most damaging in the Great Lakes and through its invasion of related rivers, waterways, and city water facilities. Invasive species and artificial water level controls imposed by the seaway have had a negative impact on recreational fishing.\nThe seaway, along with the St. Lawrence River it passes through, also provides opportunities for outdoor recreation, such as boating, camping, fishing, and scuba diving. Of note, the Old Power House near Lock 23 (near Morrisburg, Ontario) became an attractive site for scuba divers. The submerged stone building has become covered with barnacles and is home to an abundance of underwater life. The seaway passes through the St. Lawrence River, which provides a number of diveable shipwrecks within recreational scuba limits (shallower than ). The region also offers technical diving, with some wrecks lying at . The water temperature can be as warm as during the mid- to late-summer months. The first of Lake Ontario is warmed and enters the St. Lawrence River, as the fast-moving water body has no thermocline circulation.\nOn July 12, 2010, \"Richelieu\" (owned by Canada Steamship Lines) ran aground after losing power near the C\u00f4te-Sainte-Catherine lock. The grounding punctured a fuel tank, spilling an estimated of diesel fuel, covering approximately . The seaway and lock were shut down to help contain the spill.\nInternational trade and tourism.\nThe seaway is important for American and Canadian international trade. It handles 40\u201350 million annual tonnes of cargo. About 50% of this cargo carried travels to and from international ports in Europe, the Middle East, and Africa. The rest comprises coastal trade, or short sea shipping, between various American and Canadian ports. Among international shippers are found:\nThe St. Lawrence Seaway (along with ports in Quebec) is the main route for Ontario grain exports to overseas markets. Its fees are publicly known, and were limited in 2013 to an increase of 3%. A trained pilot is required for any foreign trade vessel. A set of rules and regulations are available to help transit.\nCommercial vessel transit information is hosted on the Great Lakes St. Lawrence Seaway Development Corporation website.\nSince 1997, international cruise liners have been known to transit the seaway. The Hapag-Lloyd \"Christopher Columbus\" carried 400 passengers to Duluth, Minnesota, that year. Since then, the number of annual seaway cruising passengers has increased to 14,000.\nEvery year, more than 2,000 recreational boats, of more than 20\u00a0ft and one ton, transit the seaway. The tolls have been fixed for 2017 at $30 per lock. There is a $5 per lock discount for payment in advance. Lockages are scheduled 12 hours a day between the hours of 07:00 and 19:00 from June 15 to September 15.\nA list of organisations that serve the seaway in some fashion, such as chambers of commerce and municipal or port authorities, is available at the SLSDC website. A 56-page electronic \"Great Lakes St. Lawrence Seaway System\" Directory is published by Harbor House Publishers.\nMap.\n\"Map of the world Great Lakes and the St. Lawrence Seaway from 1959,\" depicting the entire length beginning at the Gulf of St. Lawrence in the east to the westernmost terminus at Lake Superior.\nSee also.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26909", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=26909", "title": "Silvio Berlusconi", "text": "Italian media tycoon and politician (1936\u20132023)\nSilvio Berlusconi ( ; ; 29 September 1936\u00a0\u2013 12 June 2023) was an Italian media tycoon and politician who served as the prime minister of Italy in three governments from 1994 to 1995, 2001 to 2006 and 2008 to 2011. He was a member of the Chamber of Deputies from 1994 to 2013; a member of the Senate of the Republic from 2022 until his death in 2023, and previously from March to November 2013; and a member of the European Parliament (MEP) from 2019 to 2022, and previously from 1999 to 2001. At the time of his death in 2023, he had a net worth of US$6.8\u00a0billion according to \"Forbes\", making him the 352nd-richest man in the world and the third-wealthiest person in Italy.\nBerlusconi rose into the financial elite of Italy in the late 1960s. He was the controlling shareholder of Mediaset and owned the Italian football club AC Milan from 1986 to 2017. He was nicknamed \"Il Cavaliere\" ('The Knight') for his Order of Merit for Labour; he voluntarily resigned from this order in March 2014. In 2009, \"Forbes\" ranked him 12th in the list of the World's Most Powerful People due to his domination of Italian politics throughout more than fifteen years at the head of the centre-right coalition.\nBerlusconi was prime minister for nine years in total, making him the longest serving post-war prime minister of Italy, and the third-longest-serving since Italian unification, after Benito Mussolini and Giovanni Giolitti. He was the leader of the centre-right party from 1994 to 2009, and its successor party The People of Freedom from 2009 to 2013. He led the revived Forza Italia from 2013 to 2023. Berlusconi was the senior G8 leader from 2009 until 2011, and he held the record for hosting G8 summits (having hosted three summits in Italy). After serving nearly 19 years as a member of the Chamber of Deputies, the country's lower house, he became a member of the Senate following the 2013 Italian general election.\nOn 1 August 2013, Berlusconi was convicted of tax fraud by the Supreme Court of Cassation. His four-year prison sentence was confirmed, and he was banned from holding public office for two years. Aged 76, he was exempted from direct imprisonment, and instead served his sentence by doing unpaid community service. Three years of his sentence were automatically pardoned under Italian law; because he had been sentenced to gross imprisonment for more than two years, he was banned from holding legislative office for six years and expelled from the Senate. Berlusconi pledged to stay leader of Forza Italia throughout his custodial sentence and public office ban. After his ban ended, Berlusconi ran for and was elected as an MEP at the 2019 European Parliament election. He returned to the Senate after winning a seat in the 2022 Italian general election, then died the following year from complications of chronic myelomonocytic leukemia, and was given a state funeral.\nBerlusconi was known for his populist political style and brash personality. In his long tenure, he was often accused of being an authoritarian leader and a strongman. At the height of his power, Berlusconi was the richest person in Italy, owned three of the main TV channels of the country, and indirectly controlled the national broadcasting company RAI through his own government. He was the owner of Italy's biggest publishing company, several newspapers and magazines, and one of the largest football clubs in Europe. At the time of his death, \"The Guardian\" wrote that Berlusconi \"gathered himself more power than was ever wielded by one individual in a Western democracy\". Berlusconi remained a controversial figure who divided public opinion and political analysts. Supporters emphasised his leadership skills and charismatic power, his fiscal policy based on tax reduction, and his ability to maintain strong and close foreign relations with both the United States and Russia. In general, critics address his performance as a politician and the ethics of his government practices in relation to his business holdings. Issues with the former include accusations of having mismanaged the state budget and of increasing the Italian government debt. The second criticism concerns his vigorous pursuit of his personal interests while in office, including benefitting from his own companies' growth due to policies promoted by his governments, having vast conflicts of interest due to ownership of a media empire, and being blackmailed as a leader because of his turbulent private life.\nEarly life and family.\nBerlusconi was born in 1936 in Milan, where he was raised in a middle-class family. His father, Luigi Berlusconi, was a bank employee, and his mother, Rosa Bossi, a housewife. He was the first of three children; he had a sister, Maria Francesca Antonietta, and a brother, Paolo.\nAfter completing his secondary school education at a Salesian college, Berlusconi studied law at the University of Milan, graduating with honours in 1961, with a thesis on the legal aspects of advertising. He was not required to serve the standard one-year stint in the Italian army which was compulsory at the time. During his university studies, he played upright bass in a group formed with the now Mediaset Chairman and amateur pianist Fedele Confalonieri and occasionally performed as a cruise ship crooner. In later life, he wrote AC Milan's anthem with the Italian music producer and pop singer Tony Renis and Forza Italia's anthem with the opera director Renato Serio. With the Neapolitan singer Mariano Apicella, he wrote two Neapolitan song albums: \"Meglio 'na canzone\" in 2003 and \"L'ultimo amore\" in 2006.\nIn 1965, Berlusconi married Carla Elvira Dall'Oglio, and they had two children: Maria Elvira, better known as Marina (born 1966), and Pier Silvio (born 1969). By 1980, Berlusconi had established a relationship with the actress Veronica Lario (born Miriam Bartolini), with whom he subsequently had three children: Barbara (born 1984), Eleonora (born 1986), and Luigi (born 1988). He was divorced from Dall'Oglio in 1985, and married Lario in 1990. By this time, Berlusconi was a well-known entrepreneur, and his wedding was a notable social event. One of his best men was Bettino Craxi, a former prime minister and leader of the Italian Socialist Party. In May 2009, Lario announced that she was to file for divorce. On 28 December 2012, Berlusconi was ordered to pay Lario $48\u00a0million a year in a divorce settlement, but could keep the $100\u00a0million house they lived in with their three children.\nBusiness career.\nMilano Due.\nBerlusconi's business career began in construction in the 1970s, when he built Milano Due, a development of 4,000 residential apartments east of Milan. The residential centre was built by Edilnord, a Berlusconi-owned company associated with the Fininvest group. Works began on the project in 1970 and was completed in 1979.\nThe profits from this venture provided the seed money for his advertising agency.\nTeleMilano.\nBerlusconi first entered the media world in the 1970s, buying from Giacomo Properzj and Alceo Moretti a small cable television company, TeleMilano, to service units built on his Segrate properties. It began transmitting in September of the following year. TeleMilano was one of the first Italian private television channels and later evolved into Canale 5, the first national private TV station.\nAfter buying two further channels, Berlusconi relocated the station to central Milan in 1977 and began broadcasting over the airwaves.\nFininvest.\nIn 1975, Berlusconi founded his first media group, Fininvest. In 1978 he joined the Propaganda Due masonic lodge. In the five years leading up to 1983, he earned some 113\u00a0billion Italian lire (\u20ac58.3\u00a0million). The funding sources are still unknown because of a complex system of holding companies, despite investigations conducted by various prosecutors.\nFininvest soon expanded into a country-wide network of local TV stations which had similar programming, forming, in effect, a single national network. At the time, laws permitted only the national broadcaster RAI to operate throughout the country, and this was seen as an effort to circumvent the state monopoly. Prior to 1974, Italian television was entirely under state ownership. Despite the landmark 1976 ruling by the Constitutional Court of Italy (decision no. 202/1976), which allowed private entities to operate local television stations, the state maintained prohibitions on live broadcasting and private news channels. Berlusconi was the first to successfully bypass these restrictions by distributing simultaneously pre-recorded broadcasts across multiple local stations, effectively creating the impression of a national live television network.\nIn 1980, Berlusconi founded Italy's first private national network, Canale 5, followed shortly thereafter by Italia 1, which was bought from the Rusconi family in 1982, and Rete 4, which was bought from Mondadori in 1984. He then launched three international sister networks: La Cinq (1986, France), Tele 5 (1988, West Germany), and Telecinco (1989, Spain). La Cinq and Tele 5 ceased operations in 1992 and were later replaced by La Cinqui\u00e8me and DSF, respectively.\nBerlusconi created the first and only Italian commercial TV empire. He was assisted by his connections to Bettino Craxi, secretary-general of the Italian Socialist Party and also the prime minister of Italy at that time, whose government passed, on 20 October 1984, an emergency decree legalising the nationwide transmissions made by Berlusconi's television stations. This was in response to judgements on 16 October 1984, in Turin, Pescara, and Rome, enforcing a law that previously restricted nationwide broadcasting to RAI, which had ordered these private networks to cease transmitting.\nAfter political turmoil in 1985, the decree was approved definitively; for some years, Berlusconi's three channels remained in legal limbo and were not allowed to broadcast news and political commentary. They were elevated to the status of full national TV channels in 1990 by the Mamm\u00ec law, named after Oscar Mamm\u00ec. In 1987, it bought out home video distributor Domovideo, in a seesaw contest with Vincenzo Romagnoli.\nIn 1995, Berlusconi sold a portion of his media holdings, first to the German media group Kirch Group (now bankrupt) and then by public offer. In 1999, Berlusconi expanded his media interests by forming a partnership with Kirch called the \"Epsilon MediaGroup\".\nOn 9 July 2011, a Milan court ordered Fininvest to pay 560\u00a0million euros in damages to Compagnie Industriali Riunite in a long-running legal dispute.\nOn 5 August 2016, Fininvest announced the signing of a preliminary agreement to sell all of their shares of AC Milan to Sino-Europe Sports Investment Management Changxing Co.Ltd. The deal was scheduled to be finalised by the end of 2016. On 13 April 2017, Berlusconi sold Milan to Rossoneri Sport Investment Lux for a total of \u20ac830\u00a0million after a 31-year reign.\nPolitical career.\nBerlusconi rapidly rose to the forefront of Italian politics in January 1994, forming a new party called . He was elected to the Chamber of Deputies for the first time and appointed as prime minister following the 1994 Italian general election, when Forza Italia gained a majority in the Chamber of Deputies less than three months after having been launched. His cabinet collapsed after nine months due to internal disagreements among the coalition parties, and he was succeeded as prime minister by Lamberto Dini. In the 1996 Italian general election, Berlusconi was defeated by the centre-left candidate Romano Prodi. In the 2001 Italian general election, he was again the centre-right candidate for prime minister and won against the centre-left candidate Francesco Rutelli. Berlusconi then formed his second and third cabinets, until 2006. Berlusconi was the leader of the centre-right coalition in the 2006 Italian general election, which he lost by a very narrow margin, his opponent again being Prodi. He was re-elected in the 2008 Italian general election following the collapse of the Second Prodi government and sworn in for the third time as prime minister on 8 May 2008.\nAfter losing his majority in parliament amid growing fiscal problems related to the European debt crisis, the resignation of Berlusconi as prime minister came on 16 November 2011. Berlusconi led the People of Freedom and its right-wing allies in the campaign for the 2013 Italian general election. Although he initially planned to run for a fifth term as prime minister, as part of the agreement with the Lega Nord, he would instead plan to lead the coalition without becoming prime minister. Berlusconi's centre-right coalition gained 29% of votes, ranking second, after the centre-left coalition Italy Common Good led by Pier Luigi Bersani. Subsequently, Berlusconi's allies supported the Letta Cabinet headed by Enrico Letta of the Democratic Party, together with the centrist Civic Choice of former prime minister Mario Monti.\nBerlusconi was criticised for his electoral coalitions with right-wing populist parties (Lega Nord and the National Alliance) and for apologetic remarks about Mussolini; he also officially apologised for Italy's actions in Libya during colonial rule. While in power, Berlusconi maintained ownership of Mediaset, the largest media company in Italy, and was criticised for his dominance of the Italian media. His leadership was also undermined by sex scandals.\nBeginnings.\nBerlusconi entered politics in 1994, reportedly admitting to Indro Montanelli and Enzo Biagi that he was forced to do so to avoid imprisonment. He served as prime minister of Italy from 1994 to 1995, 2001 to 2006, and 2008 to 2011. His career was racked with controversies and trials; among these was his failure to honour his promise to sell his personal assets in Mediaset, the largest television broadcaster in Italy, to dispel any perceived conflicts of interest.\nIn the early 1990s, the five governing parties known as the Pentapartito, including Christian Democracy (), the Italian Socialist Party, the Italian Social-Democratic Party, the Italian Republican Party and the Italian Liberal Party, lost much of their electoral strength almost overnight due to a large number of judicial investigations concerning the financial corruption of many of their foremost members in the Mani Pulite affair. This led to a general expectation that upcoming elections would be won by the Democratic Party of the Left, the heirs to the former Italian Communist Party, and their Alliance of Progressives coalition unless an alternative arose. On 26 January 1994, Berlusconi announced his decision to enter politics, in his own words to \"enter the field\", presenting his own political party, , on a platform focused on defeating \"communists\". His political aim was to convince the voters of the Pentapartito, who were shocked and confused by Mani Pulite scandals, that offered both a fresh uniqueness and the continuation of the pro-Western free-market policies followed by Italy since the end of World War II. Shortly after he decided to enter the political arena, investigators into the Mani Pulite affair were said to be close to issuing warrants for the arrest of Berlusconi and senior executives of his business group. During his political career, Berlusconi repeatedly stated that the Mani Pulite investigations were led by communist prosecutors who wanted to establish a Soviet-style government in Italy.\n1994 electoral victory.\nTo win the March 1994 general election, Berlusconi formed two separate electoral alliances: Pole of Freedoms (\"Polo delle Libert\u00e0\") with Lega Nord (Northern League) in northern Italian districts, and another, the Pole of Good Government (\"Polo del Buon Governo\"), with the National Alliance (\"Alleanza Nazionale\"), heir to the Italian Social Movement, in central and southern regions. In a pragmatic move, he did not ally with the latter in the North because Lega Nord disliked them. Consequently, was allied with two parties that were not allied with each other.\nBerlusconi launched a massive campaign of electoral advertisements on his three TV networks and prepared his top advertising salesmen with seminars and screen tests, of whom 50 were subsequently elected despite an absence of legislative experience. He subsequently won the elections, with Forza Italia garnering 21% of the popular vote, more than any other single party. One of the most significant promises that he made to secure victory was that his government would create \"one million more jobs\". He was appointed prime minister in 1994, but his term in office was short because of the inherent contradictions in his coalition: the League, a regional party with a strong electoral base in northern Italy, was at that time fluctuating between federalist and separatist positions and the National Alliance was a nationalist party that had yet to renounce neo-fascism at the time.\nFall of the Berlusconi I Cabinet.\nIn December 1994, following the leaking to the press of news of a fresh investigation by Milan magistrates, Umberto Bossi, leader of the Lega Nord, left the coalition claiming that the electoral pact had not been respected. This in turn forced Berlusconi to resign from office. Lega Nord also resented the fact that many of its MPs had switched to Forza Italia, allegedly lured by promises of more prestigious portfolios. In 1998, various articles attacking Berlusconi were published by Lega Nord's official newspaper \"La Padania\", with titles such as \"La Fininvest \u00e8 nata da Cosa Nostra\" ('Fininvest [Berlusconi's principal company] was founded by the Mafia').\nBerlusconi remained as caretaker prime minister for a little over a month until his replacement by a technocratic government headed by Lamberto Dini. Dini had been a key minister in the Berlusconi cabinet, and Berlusconi said the only way he would support a technocratic government would be if Dini headed it. In the end, Dini was supported by most of the opposition parties, but not by Forza Italia and Lega Nord. In 1996, Berlusconi and his coalition lost the elections and were replaced by a centre-left government led by Romano Prodi.\n2001 electoral victory.\nIn 2001, Berlusconi ran again, as leader of the right-wing coalition House of Freedoms (\"La Casa delle Libert\u00e0\"), which included the Union of Christian and Centre Democrats, Lega Nord, the National Alliance, and other parties. Berlusconi's success in the May 2001 general election led to him becoming prime minister once more, with the coalition receiving 49.6% of the vote for the Chamber of Deputies and 42.5% for the Senate of the Republic.\nOn the television interview programme \"Porta a Porta\", during the last days of the electoral campaign, Berlusconi created a powerful impression on the public by undertaking to sign the \"Contratto con gli Italiani\" (Contract with the Italians), an idea copied by his advisor Luigi Crespi from Newt Gingrich's Contract with America introduced six weeks before the 1994 US elections. This was considered to be a creative masterstroke in his 2001 bid for prime ministership. Berlusconi committed in this contract to improving several aspects of the Italian economy and life, and promised to not stand for re-election in 2006 if he failed to honour at least four of these five promises. Firstly, he undertook to simplify the complex Italian national tax system by introducing just two income tax rates (33% for those earning over 100,000 euros, and 23% for anyone earning less than that figure: anyone earning less than 11,000 euros a year would not be taxed). Secondly, he promised to halve the unemployment rate. Thirdly, he committed to financing and developing a massive new public works programme. Fourthly, he promised to raise the minimum monthly pension rate to 516 euros. Fifthly, he would reduce crime by introducing police officers to patrol all local zones and areas in Italy's major cities.\nBerlusconi II Cabinet.\nOpposition parties claim Berlusconi was not able to achieve the goals he promised in his \"Contratto con gli Italiani\". Some of his partners in government, especially the National Alliance and the Union of Christian and Centre Democrats, admitted the Government fell short of the promises made in the agreement, attributing the failure to an unforeseeable downturn in global economic conditions. Berlusconi himself consistently asserted that he achieved all the goals of the agreement, and said his Government provided \"un miracolo continuo\" (a continuous miracle) that made all 'earlier governments pale' (by comparison). He attributed the widespread failure to recognise these achievements to a campaign of mystification and vilification in the print media, asserting that 85% of newspapers were opposed to him. Luca Ricolfi, an independent analyst, held that Berlusconi had managed to deliver only one promise out of five, the one concerning minimum pension rates. According to Ricolfi, the other four promises were not honoured, in particular the undertakings on tax simplification and crime reduction.\nSubsequent elections.\nThe House of Freedoms did not do as well in the 2003 local elections as it did in the 2001 national elections. In common with many other European governing groups, in the 2004 elections to the European Parliament, gained 43.37% support. Forza Italia's support was also reduced from 29.5% to 21.0% (in the 1999 European elections Forza Italia had 25.2%). As an outcome of these results, the other coalition parties, whose electoral results were more satisfactory, asked Berlusconi and Forza Italia for greater influence on the government's political line.\nBerlusconi III Cabinet.\nIn the regional elections on 3\u20134 April 2005, centre-left candidates for regional presidencies won in 11 out of 13 regions where control of local governments and presidencies were at stake. Berlusconi's coalition held only two of the regions (Lombardy and Veneto) up for re-election. Three parties, Union of Christian and Centre Democrats, National Alliance and New Italian Socialist Party, threatened to withdraw from the Berlusconi government. Berlusconi after some hesitation, then presented to the president of Italy a request for the dissolution of his government on 20 April. On 23 April, he formed a new government with the same allies, reshuffling ministers and amending the government programme. A key point demanded by the Union of Christian and Centre Democrats and to a lesser extent by the National Alliance for their continued support was that the strong focus on tax reduction be reduced.\nAttempt to reform the Italian constitution.\nA key point in the Berlusconi government's programme was a planned reform of the Italian constitution, which Berlusconi considered to be inspired by the Soviet Union, an issue on which the coalition parties themselves initially had significantly different opinions. Lega Nord insisted on a federalist reform (devolution of more power to the regions) as a condition for remaining in the coalition. The National Alliance party pushed for a strong premiership (more powers to the prime minister).\nDifficulties in negotiating an agreement caused some internal unrest in the Berlusconi government in 2003, but they were mostly overcome and the law including devolution of powers to the regions, Federal Senate, and strong premiership, was passed by the Senate in April 2004; it was slightly modified by the Chamber of Deputies in October 2004, and again in October 2005, and finally approved by the Senate on 16 November 2005, with a narrow majority. Approval in a referendum is necessary to amend the Italian constitution without a qualified two-thirds parliamentary majority. The referendum was held on 25\u201326 June 2006 and resulted in the rejection of the constitutional reform, with 61.3% of voters casting ballots against it.\n2006 general election and opposition.\nOperating under a new electoral law written unilaterally by the governing parties with strong criticism from the parliamentary opposition, the April 2006 general election was held. The results of this election handed Romano Prodi's centre-left coalition, known as The Union (Berlusconi's opposition), a very thin majority: 49.8% against 49.7% for the centre-right coalition House of Freedoms in the Lower House, and a two-senator lead in the Senate (158 senators for The Union and 156 for the House of Freedoms). The Court of Cassation subsequently validated the voting procedures and determined that the election process was constitutional.\nAccording to the new electoral rules, The Union, nicknamed \"The Soviet Union\" by Berlusconi, with a margin of only 25,224 votes (out of over 38\u00a0million voters) won 348 seats (compared to 281 for the House of Freedoms) in the lower house given to whichever coalition of parties was awarded more votes as a result of the majority bonus system.\nThis electoral law, approved shortly before the election by Berlusconi's coalition in an attempt to improve their chances of winning the election, led to the coalition's defeat and gave Prodi the chance to form a new cabinet. Prodi's coalition government consisted of a large number of smaller parties. If only one of these nine parties that formed The Union withdrew its support to Prodi, his government would have collapsed. This situation was also the result of the new electoral system.\nCentrist parties such as the Union of Christian and Centre Democrats immediately conceded The Union's victory, while other parties, such as Berlusconi's Forza Italia and the Northern League, refused to accept its validity, right up until 2 May 2006, when Berlusconi submitted his resignation to then President of the Republic Carlo Azeglio Ciampi.\n2008 electoral victory.\nIn the run-up to the 2006 general election, there had been talk among some of the coalition members of the House of Freedoms about a possible merger into a \"united party of moderates and reformers\". Forza Italia, the National Alliance of Gianfranco Fini, and the Union of Christian and Centre Democrats of Pier Ferdinando Casini all seemed interested in the project. Soon after the election, Casini started to distance his party from its historical allies. On 2 December 2006, during a major demonstration of the centre-right in Rome against the Prodi II Cabinet, Berlusconi proposed the foundation of a Freedom Party, arguing that the people and voters of the different political movements aligned to the demonstration were all part of a people of freedom.\nOn 18 November 2007, after claiming the collection of more than 7\u00a0million signatures (including that of Umberto Bossi) demanding that then President of the Republic Giorgio Napolitano call a fresh election, Berlusconi announced from the running board of a car in a crowded Piazza San Babila in Milan that Forza Italia would soon merge or transform into The People of Freedom, also known as the PdL (\"Il Popolo della Libert\u00e0\"). Berlusconi also stated that this new political movement could include the participation of other parties. Both supporters and critics of the new party called Berlusconi's announcement \"the running board revolution\" (Italian: \"la rivoluzione del predellino\").\nAfter the sudden fall of the Prodi II Cabinet on 24 January, the break-up of The Union, and the subsequent political crisis, which paved the way for a fresh general election in April 2008, Berlusconi, Gianfranco Fini and other party leaders finally agreed on 8 February 2008 to form the PdL joint list, allied with Lega Nord of Bossi and the Movement for Autonomy of Raffaele Lombardo.\nIn the snap elections held on 13\u201314 April 2008, this coalition won against Walter Veltroni's centre-left coalition in both houses of the Italian Parliament. In the 315-member Senate of the Republic, Berlusconi's coalition won 174 seats to Veltroni's 134. In the lower house, Berlusconi's conservative bloc led by a margin of 9% of the vote: 46.5% (344 seats) to 37.5% (246 seats). Berlusconi capitalised on discontent over the nation's stagnating economy and the unpopularity of Prodi's government. His declared top priorities were to remove piles of rubbish from the streets of Naples and to improve the state of the Italian economy, which had under-performed the rest of the eurozone for years. He also said he was open to working with the opposition, and pledged to fight tax avoidance and tax evasion, reform the judicial system and reduce public debt. He intended to reduce the number of cabinet ministers to 12. Berlusconi and his ministers (Berlusconi IV Cabinet) were sworn in on 8 May 2008.\nOn 21 November 2008, the National Council of Forza Italia dissolved Forza Italia and established the PdL, whose inauguration took place on 27 March 2009, the 15th anniversary of Berlusconi's first electoral victory.\nWhile Forza Italia had never held a formal party congress to formulate its rules, procedures, and democratic balloting for candidates and issues, (since 1994 three party conventions of Forza Italia have been held, all of them resolving to support Berlusconi and reelecting him by acclamation) on 27 March 2009, at the foundation congress of the PdL political movement the statute of the new party was subject to a vote of approval. On 5,820 voting delegates, 5,811 voted in favour, 4 against and 5 abstained. During that political congress Berlusconi was elected as chairman of the PdL by a show of hands. According to the official minutes of the congress the result favoured Berlusconi, with 100 per cent of the delegates voting for him.\nThe People of Freedom split.\nBetween 2009 and 2010, Gianfranco Fini, former leader of the national conservative National Alliance (AN) and President of the Italian Chamber of Deputies, became a vocal critic of the leadership of Berlusconi. Fini departed from party's majority line on several issues but, most of all, he was a proponent of a more structured party organisation. His criticism was aimed at the leadership style of Berlusconi, who tends to rely on his personal charisma to lead the party from the centre and supports a less structured form of party, a movement-party that organises itself only at election times.\nOn 15 April 2010, an association named Generation Italy was launched to better represent Fini's views within the party and push for a different form of party organisation. On 22 April 2010 the National Committee of the PdL convened in Rome for the first time in a year. The conflict between Fini and Berlusconi was covered live on television. At the end of the day, a resolution proposed by Berlusconi's loyalists was put before the assembly and approved by a landslide margin. On 29 July 2010, the party executive released a document in which Fini was described as \"incompatible\" with the political line of the PdL and unable to perform his job of President of the Chamber of Deputies in a neutral way. Berlusconi asked Fini to step down, and the executive proposed the suspension from party membership of three MPs who had harshly criticised Berlusconi and accused some party members of criminal offences. As response, Fini and his followers formed their own groups in both chambers under the name of Future and Freedom (FLI). It was soon clear that FLI would leave the PdL and become an independent party. On 7 November, during a convention in Bastia Umbra, Fini asked Berlusconi to step down from his post of prime minister and proposed a new government including the Union of the Centre (UdC). A few days later, the four FLI members of the government resigned. On 14 December, FLI voted against Berlusconi in a vote of confidence in the Chamber of Deputies, a vote nonetheless won by Berlusconi by 314 to 311.\nIn May 2011, PdL suffered a big blow in local elections. Particularly painful was the loss of Milan, Berlusconi's hometown and party stronghold. In response to this and to conflicts within party ranks, Angelino Alfano, the Justice minister, was chosen as national secretary in charge of reorganising and renewing the party. The appointment of 40-year-old Alfano, a former Christian Democrat and later leader of Forza Italia in Sicily, was unanimously decided by the party executive. On 1 July, the National Council modified the party's constitution and Alfano was elected secretary almost unanimously. In his acceptance speech, Alfano proposed the introduction of primaries.\nResignation.\nOn 10 October 2011, the Chamber of Deputies rejected the law on the budget of the state proposed by the government. As a result of this event, Berlusconi moved for a confidence vote in the Chamber on 14 October, he won the vote with just 316 votes to 310, minimum required to retain a majority. An increasing number of Deputies continued to cross the floor and join the opposition and on 8 November the Chamber approved the law on the budget of the State previously rejected but with only 308 votes, while opposition parties did not participate in the vote to highlight that Berlusconi lost his majority. After the vote, Berlusconi announced his resignation after Parliament passed economic reforms. Among other things, his perceived failure to tackle Italy's debt crisis with an estimated debt sum of \u20ac1.9\u00a0trillion ($2.6\u00a0trillion) had urged Berlusconi to leave office. The popularity of this decision was reflected in the fact that while he was resigning crowds sang the Hallelujah Chorus of George Frideric Handel's \"Messiah\", complete with some vocal accompaniment; there was also dancing in the streets outside the Quirinal Palace, the official residence of the President of Italy, where Berlusconi went to tender his resignation.\nAusterity measures were passed, raising \u20ac59.8\u00a0billion from spending cuts and tax raises, including freezing public-sector salaries until 2014 and gradually increasing the retirement age for women in the private sector from 60 in 2014 to 65 in 2026. The resignation also came at a difficult time for Berlusconi, as he was involved in numerous trials for corruption, fraud and sex offences. He was often found guilty in lower courts, but used loopholes in Italy's legal system to evade incarceration.\nBerlusconi had also failed to meet some of his pre-election promises and had failed to prevent economic decline and introduce serious reforms. Many believed that the problems and doubts over Berlusconi's leadership and his coalition were one of the factors that contributed to market anxieties over an imminent Italian financial disaster, which could have a potentially catastrophic effect on the 17-nation eurozone and the world economy. Many critics of Berlusconi accused him of using his power primarily to protect his own business ventures. Umberto Bossi, leader of Lega Nord, a partner in Berlusconi's right-wing coalition, was quoted as informing reporters outside parliament, \"We asked the prime minister to step aside.\"\nOn 12 November 2011, after a final meeting with his cabinet, Berlusconi met President Giorgio Napolitano at the Palazzo del Quirinale to tend his resignation. As he arrived at the presidential residence, a hostile crowd gathered with banners insulting Berlusconi and throwing coins at the car. After his resignation, the booing and jeering continued as he left in his convoy, with the public shouting words such as \"buffoon\", \"dictator\" and \"mafioso\". Following Berlusconi's resignation, Mario Monti formed a new government that would remain in office until the next scheduled elections in 2013.\nIn the following years Berlusconi often expressed his point of view regarding his resignation in 2011. He accused Angela Merkel, Nicolas Sarkozy, Christine Lagarde and Giorgio Napolitano, along with other global economic and financial powers, of having plotted against him and forcing him to resign, because he had refused to accept a loan from the International Monetary Fund, which according to him, would have sold the country to the IMF.\n2013 general election.\nIn December 2012, Berlusconi announced on television that he would run again to become prime minister of Italy. Berlusconi said his party's platform would include opposition to Mario Monti's economic performance, which he said put Italy into a \"recessive spiral without end\".\nOn 7 January 2013, Berlusconi announced he had made a coalition agreement (centre-right coalition) with Lega Nord (LN); as part of it, PdL would support Roberto Maroni's bid for the presidency of Lombardy, and he would run as \"leader of the coalition\", but suggested he could accept a role as Minister of Economy under a cabinet headed by another People of Freedom (PdL) member, such as Angelino Alfano. Later that day, LN leader Maroni confirmed his party would not support Berlusconi being appointed as prime minister in the case of an electoral win. Berlusconi's coalition gained 29.1% of votes and 125 seats in the Chamber of Deputies, 30.7% of votes and 117 seats in the Senate.\nIn April 2013, Berlusconi's PdL announced his support of the Letta government, together with the Democratic Party and the centrist Civic Choice, of former prime minister Mario Monti.\nRefoundation of Forza Italia and public office ban.\nIn June 2013, Berlusconi announced the refoundation of his first party Forza Italia (FI). On 18 September the new party was launched and officially founded on 16 November. After the foundation of Forza Italia, Berlusconi announced that his new party would oppose the grand coalition government of Enrico Letta; the new political position taken by Berlusconi caused dissent in the movement, and the governmental wing of Forza Italia led by Angelino Alfano split from FI and founded a Christian democratic party called New Centre-Right, which supported the Letta Cabinet.\nOn 1 August 2013, Berlusconi was convicted of tax fraud by the court of final instance, the Supreme Court of Cassation, which confirmed his four-year prison sentence, of which three years are automatically pardoned, along with a public office ban for two years. As his age exceeded 70 years, he was exempted from direct imprisonment; he served his sentence by doing unpaid social community work. Because he was sentenced to a gross imprisonment of more than two years, a new Italian anti-corruption law (named after Paola Severino) resulted in the Senate expelling and barring him from serving in any legislative office for six years. Berlusconi pledged to stay leader of Forza Italia throughout his custodial sentence and public office ban. He was not able to freely campaign for his party.\nIn March 2017, Berlusconi expressed his intention to run once again as centre-right candidate for the premiership, even if he was banned from public office until 2019; the 2018 Italian general election was his seventh one as the centre-right frontunner. The general election resulted in Lega per Salvini Premier winning more seats than FI, and no electoral coalition winning an outright majority.\nPolitical comeback and election to European Parliament and Senate.\nIn January 2019, Berlusconi expressed his intention to run for candidacy in the 2019 European Parliament election in Italy. In the election, Forza Italia received only 8.8% of votes, the worst result in its history. Berlusconi was elected to the Parliament, becoming the oldest member of the assembly. He was a potential nominee in the 2022 Italian presidential election, which was ultimately won by Sergio Mattarella. From 2019 to 2022, Berlusconi had the lowest attendance rate among MEPs with 59%, largely because of months of dealing with symptoms after catching COVID-19 in September 2020.\nBerlusconi ran in the 2022 Italian election as the leader of Forza Italia, being elected to the Senate for the single-member constituency of Monza, returning to the Italian parliament after ten years.\nForeign policy.\nBerlusconi and his cabinets had a strong tendency to support American foreign policies, despite the policy divide between the US and many founding members of the European Union, such as Germany, France, and Belgium during the George W. Bush administration. Under Berlusconi's lead, the Italian Government also shifted its traditional position on foreign policy from being the most pro-Arab Western government, towards a greater friendship with Israel and Turkey than in the past. This resulted in a rebalancing of relations between all the Mediterranean countries, to reach \"equal closeness\" with them. Berlusconi was one of the strongest supporters of Turkey's application to accede to the European Union. To support Turkey's application Berlusconi invited Prime Minister Recep Tayyip Erdo\u011fan to take part in a meeting of the European leaders of Denmark, France, Germany, the Netherlands, Spain, Sweden, and the United Kingdom, gathered in L'Aquila for the 2009 G8 summit. Berlusconi described Saudi Arabia as an important force for stability in the region.\nItaly, with Berlusconi in office, became a solid ally of the United States due to his support for the war in Afghanistan and the Iraq War. On 30 January 2003, Berlusconi signed \"The letter of the eight\" supporting the US preparations for 2003 invasion of Iraq. Italy had some 3,200 troops deployed in Southern Iraq, the third largest contingent there after the American and British forces. When Romano Prodi became Prime Minister, Italian troops were gradually withdrawn.\nIn 2023, he warned of the danger posed to Europe and the Western world by China, saying that, \"China is the systemic competitor of the West in the 21st century. China is our real danger for the future.\"\nRelations with Russia.\nIn November 2007, Italy's state-owned energy company Eni signed an agreement with Russian state-owned Gazprom to build the South Stream pipeline. Investigating Italian parliament members discovered that Central Energy Italian Gas Holding (CEIGH), a part of the Centrex Group, was to play a major role in the lucrative agreement. Bruno Mentasti-Granelli, a close friend of Berlusconi, owned 33 per cent of CEIGH. The Italian parliament blocked the contract and accused Berlusconi of having a personal interest in the Eni-Gazprom agreement.\nBerlusconi was among the most vocal supporters of closer ties between Russia and the European Union. In an article published in Italian media on 26 May 2002, he said that the next step in Russia's growing integration with the West should be EU membership. Berlusconi had a warm relationship with Vladimir Putin. The two leaders often described their relationship as a close friendship, continuing to organise bilateral meetings even after Berlusconi's resignation in November 2011.\nIn 2015, Berlusconi visited Crimea, which had been illegally annexed by the Russian Federation one year prior: after landing in Yalta, he met with Putin in Sevastopol. Because of this, he was declared \"persona non grata\" by the Ukrainian government for three years.\nBerlusconi condemned the Russian invasion of Ukraine, saying he was deeply disappointed by the behaviour of Russian president Putin. On the eve of the 2022 Italian general election, he said that \"the troops were supposed to enter, reach Kyiv in a week, replace the Zelensky government with decent people and a week later come back\". In September 2022, Berlusconi made another statement at a Forza Italia convention in Venetia defending Putin: the statement was described by Italian media as confused and containing several factual errors, such as stating that Putin had been pressured to invade Ukraine \"by his colleagues in the Communist Party\". In October 2022, leaked audio recordings revealed Berlusconi expressing dismay at Italy's military support for Ukraine, and blaming Volodymyr Zelenskyy for the Russian invasion of Ukraine.\nRelations with Israel.\nUnder Berlusconi, Italy was an ally of Israel. Berlusconi was noted for his close and friendly relationship with Israeli prime minister Netanyahu. Netanyahu described Berlusconi as \"one of the greatest friends\". Berlusconi believed that Israel should be made an EU member. Berlusconi strongly defended Israel in the Israeli\u2013Palestinian conflict, continuing his support for Israel after leaving office. He defended Israel's actions during the Gaza\u2013Israel conflict and called for \"effective\" sanctions against Iran. However, he said that the construction of Israeli settlements in the occupied West Bank was a \"mistake\" and \"could be an obstacle to peace\".\nWhile Berlusconi was in office, Israel and Italy negotiated a $1\u00a0billion deal whereby Israel builds reconnaissance satellites for Italy, while Israel purchases the M-346 training plane for its air-force.\nRelations with Belarus.\nBerlusconi visited Alexander Lukashenko in Belarus in 2009. Berlusconi became the first Western leader to visit Lukashenko since Lukashenko came to power in 1994. At a press conference, Berlusconi paid compliments to Lukashenko and said, \"Good luck to you and your people, whom I know love you.\"\nCooperation with the Western Balkans.\nOn 5 April 2009, at the EU-US summit in Prague Berlusconi proposed an eight-point road map to accelerate the Euro-Atlantic integration of the western Balkans. During that summit the Italian Foreign Minister Franco Frattini urged his European colleagues to send \"visible and concrete\" signs to the countries concerned (Serbia, Kosovo, Bosnia, Montenegro, Croatia, Macedonia, and Albania).\nRelations with Libya.\nOn 30 August 2008, the Libyan leader Muammar Gaddafi and Berlusconi signed a historic cooperation treaty in Benghazi. Under its terms, Italy would pay $5\u00a0billion to Libya as compensation for its former military occupation. In exchange, Libya would take measures to combat illegal immigration coming from its shores and boost investment in Italian companies. The treaty was ratified by the Italian government on 6 February 2009, and by Libya on 2 March, during a visit to Tripoli by Berlusconi. Berlusconi apologised for Italy's actions during the Italian colonisation of Libya. In June Gaddafi made his first visit to Rome, where he met Berlusconi, President of the Italian Republic Giorgio Napolitano and Senate's Speaker Renato Schifani.\nWhen Gaddafi faced a civil war in 2011, Italy imposed a freeze on some Libyan assets linked to him and his family, pursuant to a United Nations-sponsored regime and then bombed the country with the violation of Libya of the No-Fly Zone. However, Berlusconi spoke out against NATO-led military intervention into Libya.\nBerlusconism.\n\"Berlusconismo\" ('Berlusconism') is a term used in Italian media and political analysts to describe the political positions of Berlusconi. The term arose in the 1980s, with a strongly positive meaning, as a synonym for entrepreneurial optimism. According to the definition given by the online vocabulary of the Italian Encyclopedia Institute, \"Berlusconismo\" has a wide range of meanings, all having their origins in the figure of Berlusconi, and the political movement inspired by him: the \"thought movement\", but also to \"social phenomenon\", and the phenomenon \"of custom\", which is bound to his entrepreneurial and political figure. The term is also used to refer to a certain \"laissez-faire\" vision supported by him, not in the economy and markets but in relation to politics. According to Berlusconi's political and entrepreneurial opponents, \"Berlusconismo\" is only a form of demagogy that is comparable to Italian fascism, in part because Berlusconi defended aspects of the regime of Benito Mussolini, although he criticised the Manifesto of Race, the Fascist Racial Laws, and the alliance with Nazi Germany. In 2013, he returned to calling Mussolini a good leader whose biggest mistake was signing up to the Holocaust in Italy and the extermination of the Jews. Contrastingly, his supporters compare \"Berlusconismo\" to French Gaullism and Argentinian Peronism.\nPolitical positions.\nBerlusconi defined himself as moderate, liberal, and a supporter of free trade; he was often also described as a populist or a conservative. After his resignation in 2011, Berlusconi became increasingly Eurosceptic, and he was often critical of the German chancellor Angela Merkel. One of Berlusconi's main leadership tactics was to use the party as an apparatus to reach power; it was defined as a light party because of a lack of a complex structure. This was decidedly comparable to the political tactics used by Charles De Gaulle in France. Another feature of great importance was the emphasis on a \"liberal revolution\", summarised by the \"Contract with the Italians\" of 2001.\nBerlusconi's proposed reforms were added to the pillars of his \"Contract with the Italians\", principally on the form of the Italian Constitution and the state, including the passage from a parliamentary system to a presidential republic, a higher election threshold, the abolition of the Italy's Senate of the Republic, a halving in the number of members of the country's Chamber of Deputies, the abolition of the provinces of Italy, and the reform of the judiciary, with separation of the careers between magistrates and magistrates's liability insurance, from Berlusconi considered impartial. Berlusconi declared himself to be persecuted by judges, having undergone 34 trials, accusing them of being manipulated by left-wingers and comparing himself to Enzo Tortora, who was a victim of a miscarriage of justice. In 2013, Berlusconi declared himself favourable to civil unions.\nBerlusconi was criticised for having legitimised and institutionalised radical-right parties, such as Brothers of Italy (FdI) and Lega Nord/Lega, and the post-fascists in Italy. He acknowledged this but said that, by legitimising them within the centre-right coalition, they would have become an extremist right that would not have won. For critics, including the historian David Broder, it was not FdI's Giorgia Meloni and Lega's Matteo Salvini, but Berlusconi himself who legitimised them and campaigned for them. Berlusconi's first cabinet in 1994 was the country's first right-wing coalition since World War II, and included neo-fascists for the first time in Europe since 1945; the post-fascists merged with his party in 2009. In his last years, Berlusconi's party and leadership were eclipsed by Salvini's Lega and Meloni's FdI.\nComparisons to other leaders.\nA number of writers and political commentators considered Berlusconi's political success a precedent for the 2016 United States presidential election of real estate tycoon Donald Trump as the 45th president of the United States, with most citing Berlusconi's panned prime ministerial tenure and therefore making the comparison in dismay. Roger Cohen of \"The New York Times\" wrote: \"Widely ridiculed, endlessly written about, long unscathed by his evident misogyny and diverse legal travails, Berlusconi proved a Teflon politician ... Nobody who knows Berlusconi and has watched the rise and rise of Donald Trump can fail to be struck by the parallels.\" In \"The Daily Beast\", Barbie Latza Nadeau wrote: \"If Americans are wondering just what a Trump presidency would look like, they only need to look at the traumatized remains of Italy after Berlusconi had his way.\" During the 2016 United States election, \"Politico\" described Berlusconi as the closest parallel to Trump in a historical world leader. In a piece written for \"Slate\" and published in April 2017, Lorenzo Newman noted the similarities in the career trajectories between the two.\nIn 2015, Andrej Babi\u0161, the then Finance Minister of the Czech Republic, was compared to Berlusconi due to his media ownership, business activities, political influence, and legal problems with a prison sentence hanging over him. \"Foreign Policy\" drew parallels between the two, labelling Babi\u0161 with the nickname \"Babisconi\". British historian Perry Anderson wrote that, despite Berlusconi's reputation as an of the European right, his actual policy record places him \"to the left of Bill Clinton, who built much of his career in America on policies\u2014delivering executions in Arkansas, scything welfare in Washington\u2014that would be unthinkable for any Prime Minister in Italy\".\nControversies.\nBerlusconi was involved in many controversies and over 20 court cases during his political career, including being sentenced to four years' imprisonment and a five-year ban from public office by the Court of Appeals for \u20ac7M tax evasion (and \u20ac280M slush fund) on 8 May 2013, confirmed by the Court of Cassation on 1 August 2013. Due to a general pardon, his imprisonment was reduced to one year, which due to his age could be served either as a house arrest or as community service.\nOn 24 June 2013, Berlusconi was found guilty of paying an underage prostitute for sex, and of abusing his powers in an ensuing cover up. He was sentenced to seven years in jail, and banned from public office for life. He was acquitted from the sex charges by the Italy appeals court on Friday, 18 July 2014.\nEconomic conflicts of interest.\nAccording to journalists Marco Travaglio and Enzo Biagi, Berlusconi entered politics to save his companies from bankruptcy and himself from convictions. Berlusconi's supporters hailed him as the \"novus homo\", an outsider who was going to bring a new efficiency to the public bureaucracy and reform the state from top to bottom.\nBerlusconi was investigated for forty different inquests in less than two years.\nBerlusconi's governments passed laws that shortened statutory terms for tax fraud. Romano Prodi, who defeated Berlusconi in 2006, claimed that these were \"ad personam laws\", meant to solve Berlusconi's problems and defend his interests.\nMedia control and conflict of interest.\nBerlusconi's extensive control over the media was widely criticised by some analysts, some press freedom organisations, and extensively by several Italian newspapers, national and private TV channels, by opposition leaders and in general members of opposition parties, who allege that Italy's media has limited freedom of expression. However such coverage of the complaint in practice put under discussion the point of the complaint itself. The \"Freedom of the Press 2004 Global Survey\", an annual study issued by the American organisation Freedom House, downgraded Italy's ranking from 'Free' to 'Partly Free' due to Berlusconi's influence over RAI, a ranking which, in \"Western Europe\" was shared only with Turkey (as of 2005[ [update]]). Reporters Without Borders states that in 2004, \"The conflict of interests involving Prime Minister Berlusconi and his vast media empire was still not resolved and continued to threaten news diversity.\" In April 2004, the International Federation of Journalists joined the criticism, objecting to the passage of a law vetoed by Carlo Azeglio Ciampi in 2003, which critics believe was designed to protect Berlusconi's reported 90% control of the Italian national media.\nBerlusconi's influence over RAI became evident when in Sofia, Bulgaria he expressed his views on journalists Enzo Biagi and Michele Santoro, and comedian Daniele Luttazzi. Berlusconi said that they \"use television as a criminal means of communication\". They lost their jobs as a result. This statement was called by critics \"Editto Bulgaro\".\nThe TV broadcasting of a satirical programme called \"RAIot\" was censored in November 2003 after the comedian Sabina Guzzanti made outspoken criticism of the Berlusconi media empire. Mediaset, one of Berlusconi's companies, sued RAI over Guzzanti's program, demanding 20\u00a0million euros for \"damages\"; in November 2003 the show was cancelled by the president of RAI, Lucia Annunziata. The details of the event were made into a Michael Moore-style documentary called \"Viva Zapatero!\", which was produced by Guzzanti.\nBerlusconi owned via Mediaset 3 of 7 national TV channels: (Canale 5, Italia 1, and Rete 4). Mediaset stated that it uses the same criteria as the public (state-owned) television RAI in assigning a proper visibility to all the most important political parties and movements (the so-called 'Par Condicio')\u2014which has been since often disproved. Enrico Mentana, the news anchor long seen as a guarantor of Canale 5's independence, walked out in April 2008, saying that he no longer felt \"at home in a group that seems like an electoral campaign committee\".\nOn 24 June 2009, Berlusconi during the Confindustria young members congress in Santa Margherita Ligure, Italy invited the advertisers to interrupt or boycott the advertising contracts with the magazines and newspapers published by , in particular and the newsmagazine \"L'espresso\", calling the publishing group \"shameless\", claiming that it was fuelling the economic crisis by discussing it extensively and accusing it of making a \"subversive attack\" against him. The publishing group announced it would begin legal proceedings against Berlusconi, given the \"criminal and civil relevance\" of his remarks.\nIn October 2009, Reporters Without Borders secretary-general Jean-Fran\u00e7ois Julliard declared that Berlusconi \"is on the verge of being added to our list of Predators of Press Freedom\", which would be a first for a European leader. He also added that Italy will probably be ranked last in the European Union in the upcoming edition of the RWB press freedom index.\nCriticism by \"The Economist\".\nOne of Berlusconi's strongest critics in the media outside Italy was the British weekly \"The Economist\" (nicknamed \"The Ecommunist\" by Berlusconi, despite the magazine's association with market liberalism), which in its issue of 26 April 2001 carried a title on its front cover, 'Why Silvio Berlusconi is unfit to lead Italy'. The war of words between Berlusconi and \"The Economist\" gained notoriety, with Berlusconi taking the publication to court in Rome and \"The Economist\" publishing letters against him. The magazine claimed that the documentation contained in its article proved that Berlusconi was 'unfit' for office because of his numerous conflicts of interest. Via Fininvest, Berlusconi claimed the article contained \"a series of old accusations\" that was an \"insult to truth and intelligence\".\nAccording to \"The Economist\"'s findings, Berlusconi, while prime minister, retained in effective control of 90% of all national television broadcasting. This figure included stations he owned directly as well as those over which he had indirect control by dint of his position as prime minister and his ability to influence the choice of the management bodies of these stations. \"The Economist\" also claimed that Berlusconi was corrupt and self-serving. A key journalist for \"The Economist\", David Lane, set out many of these charges in his book \"Berlusconi's Shadow\".\nLane points out that Berlusconi had not defended himself in court against the main charges, but had relied upon political and legal manipulations, most notably by changing the statute of limitation to prevent charges being completed in the first place. To publicly prove the truth of the documented accusations contained in their articles, the magazine publicly challenged Berlusconi to sue \"The Economist\" for libel. Berlusconi did so, losing versus \"The Economist\", and being charged for all the trial costs on 5 September 2008, when the Court in Milan issued a judgment rejecting all Berlusconi's claims and sentenced him to compensate for \"The Economist\"'s legal expenses.\nIn June 2011, \"The Economist\" published a strong article referring to Berlusconi as \"The man who screwed an entire country\".\nLegislative changes.\nOn some occasions, laws passed by the Berlusconi administration have effectively delayed ongoing trials involving him. For example, the law reducing punishment for all cases of false accounting and the law on \"legitimate suspicion\", which allowed defendants to request their cases to be moved to another court if they believe that the local judges are biased against them. Because of these legislative actions, political opponents accuse Berlusconi of passing these laws for the purpose of protecting himself from legal charges. \"La Repubblica\", for example, sustained that Berlusconi passed 17 different laws which have advantaged himself. Berlusconi and his allies, on the other hand, maintained that such laws were consistent with everyone's right to a rapid and just trial, and with the principle of \"presumption of innocence\" (\"garantismo\"); furthermore, they claimed that Berlusconi was being subjected to a political \"witch hunt\", orchestrated by certain (allegedly left-wing) judges.\nBerlusconi and his government quarrelled with the Italian judiciary often. His administration attempted to pass a judicial reform intended to limit the flexibility of judges and magistrates in their decision-making. Critics said it would instead limit the magistracy's independence by \"de facto\" subjecting the judiciary to the executive's control. The reform was met by almost unanimous dissent from the Italian judges, but was passed by the Italian parliament in December 2004. It was vetoed by the Italian President, Carlo Azeglio Ciampi.\nDuring the night hours between 5 and 6 March 2010, the Berlusconi-led Italian government passed a decree \"interpreting\" the electoral law to let the PDL candidate run for governor in Lazio after she had failed to properly register for the elections. The Italian Constitution states that electoral procedures can only be changed in Parliament, and must not be changed by governmental decree. Italy's president, whose endorsement of the decree was required by law, said that the measure taken by the government may not violate the Constitution.\nAccusations of links to the Mafia.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nBerlusconi, to solve his problems, has to solve ours.\nBerlusconi was never tried on charges relating to the Sicilian Mafia, although several Mafia turncoats have stated that Berlusconi had connections with the Sicilian criminal association. The claims arise mostly from the hiring of Vittorio Mangano, who was accused of being a \"mafioso\", as a gardener and stable-man at Berlusconi's Villa San Martino in Arcore, a small town near Milan. It was Berlusconi's friend Marcello Dell'Utri who introduced Mangano to Berlusconi in 1973. Berlusconi denied any ties to the Mafia. Marcello Dell'Utri even stated that the Mafia did not exist at all.\nIn 2004, Dell'Utri, co-founder of , was sentenced to nine years by a Palermo court on charge of \"external association to the Mafia\", a sentence describing Dell'Utri as a mediator between the economic interests of Berlusconi and members of the criminal organisation. Berlusconi refused to comment on the sentence. In 2010, Palermo's appeals court cut the sentence to seven years, but fully confirmed Dell'Utri's role as a link between Berlusconi and the Mafia until 1992.\nIn 1996, a Mafia informer, Salvatore Cancemi, declared that Berlusconi and Dell'Utri were in direct contact with Salvatore Riina, head of the Sicilian Mafia in the 1980s and 1990s. Cancemi disclosed that Fininvest, through Marcello Dell'Utri and mafioso Vittorio Mangano, had paid Cosa Nostra 200\u00a0million lire (between 100,000 and 200,000 of today's euro) annually. The alleged contacts, according to Cancemi, were to lead to legislation favourable to Cosa Nostra, in particular reforming the harsh 41-bis prison regime. The underlying premise was that Cosa Nostra would support Berlusconi's Forza Italia party in return for political favours. After a two-year investigation, magistrates closed the inquiry without charges. They did not find evidence to corroborate Cancemi's allegations. Similarly, a two-year investigation, also launched on evidence from Cancemi, into Berlusconi's alleged association with the Mafia was closed in 1996.\nAccording to yet another Mafia turncoat, Antonino Giuffr\u00e8\u2014arrested on 16 April 2002\u2014the Mafia turned to Berlusconi's party to look after the Mafia's interests, after the decline in the early 1990s of the ruling Christian Democratic party, whose leaders in Sicily looked after the Mafia's interests in Rome. Dell'Utri was the go-between on a range of legislative efforts to ease pressure on mafiosi in exchange for electoral support, according to Giuffr\u00e8. \"Dell'Utri was very close to Cosa Nostra and a very good contact point for Berlusconi\", he said. Giuffr\u00e8 also said that Berlusconi himself used to be in touch with Stefano Bontade, a top Mafia boss, in the mid-1970s. Berlusconi's lawyer dismissed Giuffr\u00e8's testimony as \"false\" and an attempt to discredit Berlusconi and his party. Giuffr\u00e8 said that other Mafia representatives who were in contact with Berlusconi included the Palermo Mafia bosses Filippo Graviano and Giuseppe Graviano. Dell'Utri's lawyer, Enrico Trantino, dismissed Giuffr\u00e8's allegations as an \"anthology of hearsay\".\nIn October 2009, Gaspare Spatuzza, a Mafioso turncoat, confirmed Giuffr\u00e8's statements. Spatuzza testified that his boss Giuseppe Graviano had told him in 1994, that Berlusconi was bargaining with the Mafia, concerning a political-electoral agreement between Cosa Nostra and Berlusconi's Forza Italia. Dell'Utri was the intermediary, according to Spatuzza. Dell'Utri has dismissed Spatuzza's allegations as \"nonsense\". Berlusconi's lawyer and MP for the PdL, Niccol\u00f2 Ghedini said that \"the statements given by Spatuzza about prime minister Berlusconi are baseless and can be in no way verified\".\nRemarks on Western civilisation and Islam.\nAfter the 11 September 2001 attacks in New York City, Berlusconi said: \"We must be aware of the superiority of our civilisation, a system that has guaranteed well-being, respect for human rights and\u2014in contrast with Islamic countries\u2014respect for religious and political rights, a system that has as its value understanding of diversity and tolerance.\" This declaration caused an uproar, not only in the Arab and Muslim world, but also all around Europe, including Italy. Subsequently, Berlusconi told the press: \"We are aware of the crucial role of moderate Arab countries... I am sorry that words that have been misunderstood have offended the sensitivity of my Arab and Muslim friends.\"\nRight-to-die case.\nAfter the family of Eluana Englaro (who had been comatose for 17 years) succeeded in having her right to die recognised by the judges and getting doctors to start the process of allowing her to die in the way established by the court, Berlusconi issued a decree to stop the doctor from letting her die. Stating that, \"This is murder. I would be failing to rescue her. I'm not a Pontius Pilate.\" Berlusconi went on to defend his decision by claiming that she was \"in the condition to have babies\", arguing that comatose women were still subject to menstruation.\nAnti-immigration laws.\nDuring his long career as Prime Minister, Berlusconi had to deal with massive immigration from the coast of North Africa. To limit illegal immigration, the Berlusconi's government promulgated the \"Bossi-Fini law\" in 2002. The law provides the expulsion, issued by the Prefect of the Province where an illegal foreign immigrant is found, and is immediately performed with the assistance at the border of the police. The standard allows the repatriation to the country of origin on the high seas, on the basis of bilateral agreements between Italy and neighbouring countries. If the illegal immigrant ships dock on Italian soil, the identification of those entitled to political asylum and the supply of medical treatment and care is undertaken by the marine police force. The law had been criticised by the centre-left opposition and the European Parliament.\nJokes, gestures, and blunders.\nBerlusconi developed a reputation for making insensitive remarks. On 2 July 2003, Berlusconi suggested that German Social democratic MEP Martin Schulz, who had criticised his domestic policies, should play a Nazi concentration camp guard in a film. Berlusconi insisted that he was joking, but accused Schulz and others of being \"bad-willing tourists of democracy\". This incident caused a brief cooling of Italy's relationship with Germany.\nAddressing traders at the New York Stock Exchange in September 2003, Berlusconi listed a series of reasons to invest in Italy, the first of which was that \"we have the most beautiful secretaries in the world\". This remark resulted in remonstration among female members of parliament, who took part in a one-day cross-party protest.\nIn 2003, during an interview with Nicholas Farrell, then editor of \"The Spectator\", Berlusconi claimed that Mussolini \"had been a benign dictator who did not murder opponents but sent them 'on holiday'\". In 2013, he returned to calling Mussolini a good leader whose biggest mistake was signing up to exterminate the Jews.\nBerlusconi had made disparaging remarks about Finnish cuisine during negotiations to decide on the location of the European Food Safety Authority in 2001. He caused further offence in 2005 when he claimed that during the negotiations he had had to \"dust off his playboy charms\" to persuade the Finnish president, Tarja Halonen, to concede that the EFSA should be based in Parma instead of Finland, and compared Finnish smoked reindeer unfavourably to culatello. One of Berlusconi's ministers later 'explained' the comment by saying that \"anyone who had seen a picture of Halonen must have been aware that he had been joking\". Halonen took the incident in good humour, retorting that Berlusconi had \"overestimated his persuasion skills\".\nIn March 2006, Berlusconi alleged that Chinese communists under Mao Zedong had \"boiled [children] to fertilise the fields\". His opponent Romano Prodi criticised Berlusconi for offending the Chinese people and called his comments 'unthinkable'.\nIn the run-up to the 2008 Italian general election, Berlusconi was accused of sexism for saying that female politicians from the right were \"more beautiful\" and that \"the left has no taste, even when it comes to women\". In 2008 Berlusconi criticised the composition of the Council of Ministers of the Spanish Government as being too 'pink' by virtue of the fact that it had (once the President of the Council, Jos\u00e9 Luis Rodr\u00edguez Zapatero, is counted) an equal number of men and women. He also stated that he doubted that such a composition would be possible in Italy given the \"prevalence of men\" in Italian politics.\nAlso in 2008, Berlusconi caused controversy at a joint press conference with Russian president Vladimir Putin. When a journalist from the Russian paper \"Nezavisimaya Gazeta\" asked a question about Putin's personal relationships, Berlusconi made a gesture towards the journalist imitating a gunman shooting.\nOn 6 November 2008, two days after Barack Obama was elected the first black US president, Berlusconi referred to Obama as \"young, handsome and even tanned\": On 26 March 2009 he said, \"I'm paler [than Mr Obama], because it's been so long since I went sunbathing. He's more handsome, younger and taller.\"\nOn 24 January 2009, Berlusconi announced his aim to increase the number of military patrolling the Italian cities from 3,000 to 30,000 to crack down on what he called an \"evil army\" of criminals. Responding to a female journalist who asked him if this tenfold increase in patrolling soldiers would be enough to secure Italian women from being raped, he said, \"We could not field a big enough force to avoid this risk [of rape]. We would need as many soldiers as beautiful women and I don't think that would be possible, because our women are so beautiful.\" Opposition leaders called the remarks insensitive and in bad taste. Berlusconi retorted that he had merely wanted to compliment Italian women. Other critics accused him of creating a police state.\nTwo days after the 2009 L'Aquila earthquake, Berlusconi suggested that people left homeless should view their experience as a camping weekend.\nIn October 2010, Berlusconi was chastised by the Vatican newspaper \"L'Osservatore Romano\" after he was filmed telling \"offensive and deplorable jokes\", including one whose punchline was similar to one of the gravest blasphemies in the Italian language. It was also revealed he had made another antisemitic joke a few days previously. Berlusconi responded to the allegations by saying the jokes were \"neither an offence nor a sin, but merely a laugh\".\nOn 1 November 2010, after once again being accused of involvement in juvenile prostitution, he suggested that an audience at the Milan trade fair should stop reading newspapers: \"Don't read newspapers any more because they deceive you. ... I am a man who works hard all day long and if sometimes I look at some good-looking girl, it's better to be fond of pretty girls than to be gay.\" The remarks were immediately condemned by Arcigay, Italy's main gay rights organisation.\nOn 13 July 2011, according to a leaked telephone surveillance transcript, Berlusconi told his presumed blackmailer Valter Lavitola: \"The only thing they can say about me is that I screw around ... Now they're spying on me, controlling my phone calls. I don't give a fuck. In a few months ... I'll be leaving this shit country that makes me sick.\"\nOn 27 January 2013, on the occasion of the Holocaust Remembrance Day, Berlusconi said the Italian fascist dictator Benito Mussolini, except for passing anti-Jewish laws in 1938, only had done \"good things\" for Italy; and also said Mussolini from a strategic point of view did the right thing in siding with Adolf Hitler during World War II, because Hitler at the point of time when the alliance was made had appeared to be winning the war.\nFriendship with Bettino Craxi.\nBerlusconi's career as an entrepreneur was also often questioned by his detractors. The allegations made against him generally included suspicions about the extremely rapid increase of his activity in the construction industry in the years 1961\u201363, hinting at the possibility that in those years he received money from unknown and possibly illegal sources. These accusations were regarded by Berlusconi and his supporters as empty slander, trying to undermine Berlusconi's reputation as a self-made man.\nAlso frequently cited by opponents are events dating to the 1980s, including supposed \"exchanges of favours\" between Berlusconi and Bettino Craxi, the former Socialist prime minister and leader of the Italian Socialist Party convicted in 1994, for various corruption charges. The Milan magistrates who indicted and successfully convicted Craxi in their \"Clean Hands\" investigation laid bare an entrenched system in which businessmen paid hundreds of millions of dollars to political parties or individual politicians in exchange for sweetheart deals with Italian state companies and the government itself. Berlusconi acknowledged a personal friendship with Craxi.\nFreedom Army.\nOn 28 May 2013, Berlusconi and his entourage launched an online initiative which consisted of the recruitment of volunteers, who are available to defend Berlusconi from the convictions of Milan's prosecutors, who were dealing with his trials, and whom Berlusconi often accused of being communists and anti-democratic.\nSimone Furlan, the creator of the Freedom Army, said in an interview: \"There comes a time in life, when you realize that fighting for an ideal is no longer a choice but an obligation. We civil society we were helpless spectators of the 'War of the Twenty Years' which saw Berlusconi fight and defend against slanderous accusations of all kinds, the result of a judicial persecution without precedent in history.\" This initiative, launched as Freedom Army, has been immediately nicknamed \"Silvio's Army\" by the media, and was condemned by the Democratic Party, the Five Star Movement and Left Ecology Freedom.\nWiretaps and accusations of corruption.\nIn December 2007, the audio recording of a phone call between Berlusconi, then leader of the opposition, and Agostino Sacc\u00e0 (general director of RAI) was published by the magazine \"L'Espresso\" and caused a scandal in the media. The wiretap was part of an investigation by the Public Prosecutor Office of Naples, where Berlusconi was investigated for corruption.\nIn the phone call, Sacc\u00e0 expresses words of impassioned political support to Berlusconi and criticises the behaviour of Berlusconi's allies. Berlusconi urges Sacc\u00e0 to broadcast a telefilm series which was strongly advocated by his ally Umberto Bossi. Sacc\u00e0 laments that many people have spread rumours about this agreement causing problems for him. Then Berlusconi asks Sacc\u00e0 to find a job in RAI for a young woman explicitly telling him that this woman would serve as an asset in a secret exchange with a senator of the majority who would help him to cause Prodi, with his administration, to fall. After the publication of these wiretaps, Berlusconi was accused by other politicians and by some journalists of political corruption through the exploitation of prostitution. In his own defence, Berlusconi said: \"In the entertainment world everybody knows that, in certain situations in RAI TV you work only if you prostitute yourself or if you are leftist. I have intervened on behalf of some personalities who are not leftists and have been completely set apart by RAI TV.\" In the State Department's 2011 Trafficking in Persons report authorised by US Secretary of State Hillary Clinton, Berlusconi was explicitly named as a person involved in the \"commercial sexual exploitation of a Moroccan child\".\nDivorce and allegations of sexual misconduct.\nAt the end of April 2009, Berlusconi's wife Veronica Lario, who would divorce him several years later, wrote an open letter expressing her anger at Berlusconi's choice of young, attractive female candidates\u2014some with little or no political experience\u2014to represent the party in the 2009 European Parliament elections. Berlusconi demanded a public apology, claiming that for the third time, his wife had \"done this to me in the middle of an election campaign\", and stated that there was little prospect of his marriage continuing. On 3 May, Lario announced she was filing for divorce. She claimed that Berlusconi had not attended his own sons' 18th birthday parties, and that she \"cannot remain with a man who consorts with minors\" and \"is not well\".\nNoemi Letizia, the girl in question, gave interviews to the Italian press, revealing that she calls Berlusconi \"papi\" ('daddy'), that they often spent time together in the past, and that Berlusconi would take care of her career as showgirl or politician, whichever she opted to pursue. Berlusconi claimed that he knew Letizia only through her father and that he never met her alone without her parents.\nOn 14 May, published an article alleging many inconsistencies in Berlusconi's story and asked him to answer ten questions to clarify the situation.\nTen days later, Letizia's ex-boyfriend, Luigi Flaminio, claimed that Berlusconi had contacted Letizia personally in October 2008 and said she had spent a week without her parents at Berlusconi's Sardinian villa around New Year's Eve 2009, a fact confirmed later by her mother. On 28 May 2009, Berlusconi said that he had never had \"spicy\" relations with Letizia, and said that if any such thing had occurred, he would have resigned immediately.\nOn 17 June 2009, Patrizia D'Addario, a 42-year-old escort and retired actress from Bari, Italy, claimed that she had been recruited twice to spend the evening with Berlusconi. Berlusconi denied any knowledge of D'Addario being a paid escort: \"I have never paid a woman... I have never understood what satisfaction there is if the pleasure of conquest is absent.\" He also accused an unspecified person of manoeuvring and bribing D'Addario.\nOn 26 June 2009, the \"ten questions\" to Berlusconi were reformulated by , and subsequently republished multiple times. On 28 August 2009, Berlusconi sued , the owner company of the newspaper, and classified the ten questions as \"defamatory\" and \"rhetorical\".\nBerlusconi's lifestyle raised eyebrows in Catholic circles, with vigorous criticism being expressed in particular by \"Avvenire\", owned by the Episcopal Conference of Italy. This was followed by the publication in the newspaper \"il Giornale\" (owned by the Berlusconi family) of details with regard to legal proceedings against the editor of \"Avvenire\", Dino Boffo, which seemed to implicate him for a harassment case against the wife of his ex-partner. Dino Boffo has always declared the details of the proceedings to be false, although he has not denied the basic premise.\nAfter a period of tense exchanges and polemics, Boffo resigned from his editorial position on 3 September 2009, and the assistant editor Marco Tarquinio became editor \"ad interim\".\nDuring a contested episode of \"AnnoZero\" on 1 October 2009, the journalist and presenter Michele Santoro interviewed Patrizia D'Addario. She stated she was contacted by Giampaolo Tarantini\u2014a businessman from Bari\u2014who already knew her and requested her presence at Palazzo Grazioli with \"the President\". D'Addario also stated that Berlusconi knew that she was a paid escort.\nShots of Porto Rotondo.\nThe attention of the newspapers was later attracted by photos that the photographer Antonello Zappadu had taken on several occasions; some document a vacation in May 2008 in Berlusconi's summer residence in Porto Rotondo, where Czech prime minister Mirek Topol\u00e1nek appears naked, and during the party young girls in bikinis or topless. On 5 June 2009, \"El Pa\u00eds\" published 5 of the 700 photos of the party. On recommendations from Berlusconi, the Rome Prosecutor's Office seized the photographic material for violation of privacy.\nRubygate.\nIn November 2010, 17-year-old Moroccan belly dancer and alleged prostitute Karima El Mahroug, better known as Ruby Rubacuori, claimed to have been given $10,000 by Berlusconi at parties at his private villas. The girl told prosecutors in Milan that these events were like orgies where Berlusconi and 20 young women performed an African-style ritual known as the \"bunga bunga\" in the nude.\nIt was also found out that, on 27 May 2010, El Mahroug had been arrested for theft by the Milan police but (being still a minor) she was directed to a shelter for juvenile offenders. After a couple of hours, while she was being questioned, Berlusconi, who was at the time in Paris, called the head of the police in Milan and pressured for her release, claiming the girl was related to Hosni Mubarak, then President of Egypt, and that to avoid a diplomatic crisis, she was to be brought to the custody of Nicole Minetti. Following repeated telephone calls by Berlusconi to the police authorities, El Mahroug was eventually released and entrusted to Minetti's care.\nThe investigation of Berlusconi for extortion (\"concussione\u200a\") and child prostitution regarding Karima El Mahroug has been referred to as \"Rubygate\".\nMP Gaetano Pecorella proposed to lower the age of majority in Italy to solve the case. Minetti was known for previous associations with Berlusconi, having danced for \"Colorado Cafe\", a show on one of Berlusconi's TV channels, and on \"Scorie\", an Italian version of \"Candid Camera\". In November 2009 she became a dental hygienist, and shortly afterward treated Berlusconi for two broken teeth and facial injuries after he was attacked with a marble statue at a political rally. In February 2010, she was selected as one of the candidates representing Berlusconi's The People of Freedom party, despite her lack of any political experience, and was seated on the Regional Council of Lombardy the following month.\n\"The Guardian\" reported that according to a series of media reports in October 2010, Berlusconi had met El Mahroug, then 17, through Nicole Minetti. Mahroug insisted that she had not slept with the then 74-year-old prime minister. She told Italian newspapers that she merely attended dinner at his mansion near Milan. El Mahroug said she sat next to Berlusconi, who later took her upstairs and gave her an envelope containing \u20ac7,000. She said he also gave her jewellery.\nBerlusconi came under fire for reportedly spending $1.8\u00a0million in state funds from Rai Cinema to further the career of a largely unknown Bulgarian actress, Michelle Bonev. The fact that this coincided with severe cuts being made to the country's arts budget provoked a strong reaction from the public.\nIn January 2011, Berlusconi was placed under criminal investigation relating to El Mahroug for allegedly having sex with an underage prostitute and for abuse of office relating to her release from detention. On 15 February 2011, a judge indicted Berlusconi to stand trial on charges carrying up to 15 years in prison. The fast-track trial opened on 6 April and was adjourned until 31 May. El Mahroug's lawyer said that Mahroug would not be attaching herself to the case as a civil complainant and denies that she ever made herself available for money. Another alleged victim, Giorgia Iafrate, also decided not to be a party to the case. In January 2013, judges rejected an application from Berlusconi's lawyers to have the trial adjourned so that it would not interfere with Italy's 2013 general election in which Berlusconi participated.\nOn 24 June 2013, Berlusconi was found guilty of paying for sex with an underage prostitute and of abusing his office. He was sentenced to seven years in prison, one more year than had been requested by the prosecution, and banned from public office for life. Berlusconi appealed the sentence and his conviction was quashed a year later, on 18 July 2014.\nIn 2020, Wondery released a podcast about Berlusconi's rise and fall entitled \"Bunga Bunga\" and hosted by comedienne Whitney Cummings.\nPanama Papers.\nIn April 2016, the Panama Papers scandal broke out; it was a leaked set of 11.5\u00a0million confidential documents that provide detailed information about more than 214,000 offshore companies listed by the Panamanian corporate service provider Mossack Fonseca, including the identities of shareholders and directors of the companies. The documents show how wealthy individuals, including public officials, hid their assets from public scrutiny. Berlusconi was cited in the list, along with his long-time partner at AC Milan, Adriano Galliani.\nHealth.\nOn 13 December 2009, Berlusconi was hit in the face with a statuette of Milan Cathedral after a rally in Milan's \"Piazza del Duomo\". The assailant was subsequently detained and identified as Massimo Tartaglia, a 42-year-old surveyor with a history of mental illness but no criminal record. Berlusconi suffered facial injuries, a broken nose and two broken teeth. He was subsequently hospitalised, and was discharged on 17 December.\nOn 7 June 2016, after the campaign for the 2016 Italian local elections, Berlusconi was hospitalised at the San Raffaele Hospital in Milan because of heart problems. After two days, on 9 June, his personal doctor Alberto Zangrillo announced that the stroke could have killed him, and that he had to have heart surgery to replace a defective aortic valve.\nOn 2 September 2020, amid the worldwide COVID-19 pandemic, Berlusconi tested positive for COVID-19. He had had contact with businessman Flavio Briatore, who had been hospitalised after contracting the virus, and with his daughter Barbara and his son Luigi, who had also tested positive. The following day, Berlusconi announced he was well and continuing to work; on the next day, 3 September, he was admitted to the San Raffaele Hospital in Milan with bilateral pneumonia. Alberto Zangrillo, head of intensive care at San Raffaele Hospital, said on 11 September 2020 that Berlusconi was admitted with a very high viral load, but that he was improving and his response to the disease had been \"optimal\". On 14 September, he was discharged. Berlusconi described COVID-19 as \"the most dangerous and frightening experience\" of his life. In May 2021, he was hospitalised due to COVID-19 long-term consequences.\nIn January 2022 Berlusconi was hospitalised for eight days to treat a severe urinary infection with strong antibiotic therapy. Due to hospitalisation, he was unable to participate in the presidential elections.\nOn 27 March 2023, Berlusconi was admitted to San Raffaele Hospital for three days after suffering pains. In April 2023, Berlusconi was hospitalised again at the San Raffaele Hospital in Milan, and was treated in intensive care after suffering breathing problems, due to severe pneumonia caused by chronic myelomonocytic leukemia. On 6 April, it was reported that Berlusconi had started chemotherapy. On 16 April, Berlusconi was transferred to a regular ward. In May 2023, a video of Berlusconi was played at the Forza Italia party reassuring his supporters at the party's convention in Milan. In the video, Berlusconi stated that he was ready to return to work after being hospitalised for a month, and that he had never stopped working even while in hospital. He was discharged from the hospital on 19 May, proclaiming \"the nightmare\" was over.\nDeath.\nHaving been hospitalised again on 9 June 2023, Berlusconi died on the morning of 12 June, at San Raffaele Hospital in Milan, aged 86.\nItaly's Council of Ministers declared a day of national mourning on the day of the funeral, also ordering that flags be flown half mast for three days; this was met with protests and polemics by some members of the centre-left coalition, as well as some jurists and political scientists.\nA few hours after his death, Berlusconi's body was brought to Villa San Martino, Berlusconi's mansion in Arcore, where he lay in state in the villa's private chapel. Due to security reasons, only relatives and close friends could access the chapelle ardente. The following day, a Private Mass in memory of the deceased was celebrated in the chapel by Father Giandomenico Colombo, a priest in charge of Arcore, at the presence of relatives and close friends.\nBerlusconi's state funeral was officiated in the Ambrosian Rite on 14 June in the Milan Cathedral by Mario Delpini, the Archbishop of Milan. Mons. Delpini delivered a homily on the meaning of life, mentioning some elements of Berlusconi's life (business, public life, politics), concluding that, \"That's what we can say about Silvio Berlusconi: he was a man and now he will meet God.\" The homily caused controversy and different interpretations: it was described as \"icy\" by \"Il Fatto Quotidiano\", while instead the \"Corriere della Sera\" described it as \"a perfect portrait, devoid of any hypocrisy\", noting that it was deeply appreciated by Berlusconi's family, while \"Il Foglio\" called it \"a great homily\". \"Il Messaggero\" remarked that the homily was inspired by the theology of Father Luigi Giussani, founder of Communion and Liberation.\nThe funeral was attended by 2,300 people in the Cathedral and 15,000 people in the square outside of it. Supporters of Berlusconi chanted \"C'\u00e8 solo un presidente!\" ('There is only one president!') and applauded while the coffin was entering and then leaving the Cathedral. Anti-communist chants were also reported.\nFollowing the religious function, Berlusconi's body was transferred back to Villa San Martino; then, he was transferred to the Tempio Crematorio Valenziano Panta Rei in Alessandria, where his body was cremated. His ashes were buried in the Chapel of Saint Martin in the mansion, next to the tomb of his parents Luigi and Rosa, and his sister Maria Antonietta.\nPersonal fortune.\nIn 2012, \"Forbes\" magazine reported that Berlusconi was Italy's sixth-richest man, with a net worth of $5.9\u00a0billion. He held significant assets in television, newspapers, publishing, cinema, finance, banking, insurance, and sports. However, in the summer of 2023, the Italian media estimated Berlusconi's legacy at only 4\u00a0billion euros.\nBerlusconi's main company, Mediaset, operates three national television channels, which in total cover half of the national television sector; and \"Publitalia\u200a\", the leading Italian advertising and publicity agency. Berlusconi also owned a controlling stake in Arnoldo Mondadori Editore, the largest Italian publishing house. His brother, Paolo Berlusconi, owns and operates \"il Giornale\", a centre-right newspaper that provides a pro-Berlusconi slant on Italian politics. \"Il Foglio\", one of the most influential Italian right-wing newspapers, is partially owned by his former wife, Veronica Lario. After Lario sold some of her ownership in 2010, Paolo Berlusconi acquired a majority interest in the newspaper. Silvio Berlusconi founded and was the major shareholder of Fininvest, which is among the largest private companies in Italy. With Ennio Doris he founded Mediolanum, one of the country's biggest banking and insurance groups. He had interests in cinema and home video distribution (Medusa Film and Penta Film). He also owned the football club AC Milan from 1986 to 2017, and owned AC Monza since 2018.\nAccording to his will, Berlusconi bequeathed controlling shares of Fininvest to his two sons and three daughters, a sum of 100 million euros from his personal wealth to his domestic partner, Marta Fascina, another 100 million euros to his brother Paolo Berlusconi and 30 million euros to his longstanding associate, Marcello Dell'Utri.\nElectoral history.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "26911", "revid": "1310024712", "url": "https://en.wikipedia.org/wiki?curid=26911", "title": "Sprung rhythm", "text": "Poetic rhythm mimicking natural speech\nSprung rhythm is a poetic rhythm designed to imitate the rhythm of natural speech. It is constructed from feet in which the first syllable is stressed and may be followed by a variable number of unstressed syllables. The British poet Gerard Manley Hopkins said he discovered this previously unnamed poetic rhythm in the natural patterns of English in folk songs, spoken poetry, Shakespeare, Milton, et al. He used diacritical marks on syllables to indicate which should be stressed in cases \"where the reader might be in doubt which syllable should have the stress\" (acute, e.g. sh\u00e9er) and which syllables should be pronounced but not stressed (grave, e.g., glean\u00e8d).\nSome critics believe he merely coined a name for poems with mixed, irregular feet, like free verse. However, while sprung rhythm allows for an indeterminate number of syllables to a foot, Hopkins was very careful to keep the number of feet per line consistent across each individual work, a trait that free verse does not share. Sprung rhythm may be classed as a form of accentual verse, as it is stress-timed, rather than syllable-timed, and while sprung rhythm did not become a popular literary form, Hopkins's advocacy did assist in a revival of accentual verse more generally.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "26912", "revid": "14770366", "url": "https://en.wikipedia.org/wiki?curid=26912", "title": "Sapindales", "text": "Order of flowering plants\nSapindales is an order of flowering plants. Well-known members of Sapindales include citrus; maples, horse-chestnuts, lychees and rambutans; mangos and cashews; frankincense and myrrh; mahogany and neem.\nThe APG III system of 2009 includes it in the clade malvids (in rosids, in eudicots) with the following nine families:\nThe APG II system of 2003 allowed the optional segregation of families now included in the Nitrariaceae.\nIn the classification system of Dahlgren the Rutaceae were placed in the order Rutales, in the superorder Rutiflorae (also called Rutanae). The Cronquist system of 1981 used a somewhat different circumscription, including the following families:\nThe difference from the APG III system is not as large as may appear, as the plants in the families Aceraceae and Hippocastanaceae stay in this order at APG III (both included in family Sapindaceae). The species now composing the family Nitrariaceae in APG III also belonged to this order in the Cronquist system as part of the family Zygophyllaceae, while those now in the family Kirkiaceae were present as part of the family Simaroubaceae.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26913", "revid": "51015731", "url": "https://en.wikipedia.org/wiki?curid=26913", "title": "Solanales", "text": "Order of dicot flowering plants\nThe Solanales are an order of flowering plants, included in the asterid group of the eudicots. Well-known members of Solanales include potatoes, sweet potatoes, eggplants, tomatoes, chili peppers, tobacco, petunias, nightshades, and morning glory. Some older sources used the name Polemoniales for this order.\nTaxonomy.\nThe following families are included here in newer systems such as that of the Angiosperm Phylogeny Group (APG):\nThe APG II classification treats the Solanales in the group Euasterids I.\nUnder the older Cronquist system, the latter three families were placed elsewhere, and a number of others were included:\nIn the classification system of Dahlgren the Solanales were in the superorder Solaniflorae (also called Solananae).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26914", "revid": "50741495", "url": "https://en.wikipedia.org/wiki?curid=26914", "title": "Sheepshead (card game)", "text": "American Card Game\nSheepshead is an American trick-taking card game derived from Bavaria's national card game, Schafkopf (lit. 'sheep's head'), hence it is sometimes called American Schafkopf. Sheepshead is most commonly played by five players, but variants exist to allow for two to eight players. There are also many other variants to the game rules, and many slang terms used with the game.\nSheepshead is most commonly played in Wisconsin, where it is sometimes called the \"unofficial\" state card game. In 1983, it was declared the official card game of the city of Milwaukee. It is also common among German counties in Southern Indiana, which has large German-American populations, and on the Internet. \nNumerous tournaments are held throughout Wisconsin during the year, with the largest tournament being the \"Nationals\", held annually in the Wisconsin Dells during a weekend in September, October or November, and mini-tournaments held hourly throughout German Fest in Milwaukee during the last weekend of each July. National 3-Hand Sheepshead Tournament has been held annually in Wisconsin since 1970 in the month of March. 48-hand sessions are held at locations around the state, offering players an opportunity to play in as many of the 100 plus sessions as they wish.\nEtymology.\nSchafkopf literally means \"sheep's head\" and may refer to the practice going back over a century of recording the score by drawing a stylised head of a sheep with nine lines. However, some sources argue that the term was probably derived and translated incorrectly from Middle High German and referred to playing cards on a barrel head (from \"kopf\", meaning head, and \"Schaff\", meaning a barrel).\nRules.\nPreparation.\nSheepshead is played with 7-8-9-10-J-Q-K-A in four suits, for a total of 32 cards. This is also known as a Piquet pack, as opposed to the 52 or 54 present in a full French deck (also known as a Poker deck, or a regular deck of playing cards). A sheepshead deck is made by removing all of the jokers, sixes, fives, fours, threes, and twos from a standard deck.\nCard strength.\nCard strength in sheepshead is different from in most other games. It is one of the most difficult things for some beginners to grasp.\nThere are 14 cards in the trump suit: all four queens, all four jacks, and all of \nthe diamonds. In order of strength from greatest to least:\nAlso, there are 3 \"fail\" suits, each containing 6 cards (18 total).\nIt's important to note that when a card is a member of the trump suit, it loses its membership as part of its \"\"standard\" suit. For instance, the queen of clubs is in the trump suit, and cannot follow suit if another club is led.\nClubs, spades, and hearts take no precedence over other fail suits, unlike trump, which always take fail. (Notice how both aces and tens outrank kings; arguably the most confusing aspect of card strength). The lead suit must be followed if possible; if not, then any card may be played such as trump (which will take the trick), or a fail card. Playing a fail of a different suit is called \"throwing off\"\" and can be a way to clear up another suit. Additionally, throwing off a point card is called \"schmearing.\"\nCard point values.\nEach card is given a separate point value as follows:\nThe strongest cards (queens and jacks) are not worth the most points, giving sheepshead some of its unusual character.\nThere are 120 points total in the deck. The goal of the game is to get half of these (60 or 61); in case of a tie, the player who picked up the blinds loses, and that player's opponents win. (There are variant rules for more peculiar situations, such as the Leaster.)\nScoring.\nScore is kept using game points (not to be confused with the point values of the cards) or using money. Points are given/taken on a zero-sum basis.\nThe following chart shows the game points for a five-person game (though other variations, with a different number of players, have different scoring). Game points are awarded based on the point value of cards taken during the hand. When playing for money, each game point generally represents a common money unit.\nThe deal.\nThe deck is shuffled and cut. The dealer then deals cards, starting with the player to the dealer's left, and typically two or three at a time to each person. In most standard five and six-handed games, two cards are also dealt to a separate pile called the \"blind.\" Usually this is dealt as a pair between rounds of dealing at any time so long as the last two cards are not dealt into the blind (because the dealer might inadvertently reveal the bottom card while dealing or shuffling).\nWhen done with a five-handed deal, each player should have six cards, with two in the blind.\nIn one variant, a player may require a redeal if the player's hand has no aces, no face cards, no trump, and no count/point cards. (\"No ace, no face, no trump, no count.\")\nPicking.\nThe player to the left of the dealer gets first choice to take the \"blind\" (the two face-down cards not dealt to any player). If they pass, the option is given to the next player (in clockwise order). There are several Variations for if the dealer does not wish to pick up the blind\u2014the dealer may be required to pick up the blind, or may have the option to call a Leaster, or may be able to call a Doubler.\nThe individual who takes the blind is called the \"picker\". The picker adds the two cards in the blind to their hand and then must choose two cards to lay down or \"bury\". The buried cards are added to the picker's score if the picker's side takes at least one trick.\nThe picker may also have a partner on their team who will then play against the remaining players. Depending on the variant or house-rule, the partner must automatically be the player with the jack of diamonds, or the picker may be able to call the ace of a fail suit and have that player be their partner. These are discussed in the variations section.\nOne of the more intriguing aspects of sheepshead is that the picker and partner change each hand, and a good deal of the game's strategy is in determining which player is the partner, as their identity is usually not revealed until after the game has begun.\nPlay.\nAfter the picker has buried their cards, the person to the left of the dealer plays the first card. Play continues clockwise until everyone has played. Every player must follow suit if possible. Trump is considered a suit, so if trump is led, and a player has trump in their hand, they must play trump. If a player cannot follow suit, then they can play any card from their hand. The person who played the card with the highest strength takes the trick (the highest trump, or if none, the highest card of the fail suit that was led). The player who took the previous trick then plays, or leads, a new card for the second trick. After all tricks have been taken, their point values are totaled and the winner declared, with all players adding or reducing their personal points accordingly (see the charts, above). The deal then shifts to the person to the left of the previous dealer.\nSheep Head variant.\nSheep Head is when there are four players and 24 cards are used instead of 32. Cards are shuffled by the dealer and cut (split it in two) by the player to the dealer's right. Two cards are dealt at a time. The most powerful trumps are as follows, Q of clubs, Q of spades, J of clubs, J of spades, J of hearts, J of diamonds, A of diamonds (fox), 10 of diamonds, K of diamonds, Q of diamonds, 9 of diamonds. The non-trump strengths are A, 10, K, Q, 9. The queen of hearts is no longer trump (it is actually a very weak card). Players have partners. The main objective is to get the ace of diamonds, also known as \"the fox\". The \"fox catchers\" are the top 6 most powerful trump. There is no picker, nor blind cards. When a card leads a trick, other players must follow suit, or trump if the trick is led with trump. The point system is based on the fox, 1 point, and however many \"counters\" a player has. The \"counter cards\" are always ace, 10, and king. If a player wins the last trick, they get 1 extra counter, with 13 counters in total. 7 to 9 counters is one point, and 10 to 12 counters is two points. The game is usually played to 21 or 42 points and whichever team reaches the number wins. If a player gets all the \"fox catchers\" in their hand, it is known as \"automatic bucking\", where the team automatically wins 14 points. If a player wins all the tricks, it is known as a \"buck\", where the team wins 7 points, it is like winning all 13 counters, but getting a higher reward from it.\nPlay variations.\nThere are a number of different play variations for sheepshead. Variants may change how partners are chosen, scoring, the suits considered fail, or what occurs when the blind is not picked. Variations in the number of players are discussed in the next section.\nPartners.\nThe following two variants apply only to five and six-player games, and possibly four-player games. Variants differ in whether the picker is permitted to choose to play alone, and in whether there are some situations where the picker may be \"required \"to play alone.\nCalled Ace.\nThe picker chooses a \"called ace suit\" after picking the blind. Whoever has this called ace will be their partner. There are a few further rules behind this.\nJack of diamonds.\nIn this variant, the partner is automatically the individual with the jack of diamonds. Unlike the Called Ace variant, the partner is not required to play the jack of diamonds with any required haste; thus the identity of the partner is usually secret for more of the game.\nThe normal rule is that if the picker has the jack of diamonds, whether as a result of the deal or picking up the jack in the blind, the picker must play alone. However, there are a number of variants within this method of play.\nSchiller\nIn this variant, the first person after the dealer has to pick. All other rules previously established in the game are still intact. \nIn most Sheepshead circles, 1 round of Schiller is played at the end of the night to end the game.\nScoring.\nCalling sheepshead.\nOne variant allows the picker to call \"sheepshead.\" This means that the picker believes they can take every trick. If they succeed they receive twice the number of points for a trickless game, but if they miss a single trick (even one lacking points), they must pay twice the value their opponents would have paid them for a trickless hand.\nDouble on the bump.\nIf the picker/partner do not win, they are \"bumped\". The standard method of playing sheepshead is that the picker/partner lose two times the points that opponents would lose in a similar loss. This may be called the \"Punish the picker\" rule. Some house rules do not enforce this \"Punish\" rule.\nSome house rules require the picker to take at least one trick. If the picker/partner do not take at least one trick and lose, then only the picker loses points. Picker -18, partner 0, opponents +6.\nCracking.\nIn this variant, when a player picks up the blind, any player who was not given the opportunity to pick up the blind and who is not the picker's partner may \"knock\" or \"crack\" by knocking the table with their fist. This automatically doubles the point values determining the score when the game ends. In the \"aces\" variant, the crack must take place after the ace has been called but before the first card is played.\nBlitzing or blitzers.\nThis variant allows players to double the point value of the game by revealing that they have the two black or red queens.\nTrump.\nDiamonds vs. clubs.\nTypically, diamonds are considered trump, but some groups use another suit (typically clubs around North Central Wisconsin). This would mean a nine of diamonds would be fail while a nine of clubs is trump instead.\nAlternatively, in some groups, the strengths of the various queens and jacks differ from standard rules.\nSpitz.\nA variant popular in some areas of Minnesota and Wisconsin is to change the order of strength of the trump cards. This is done by increasing the seven of diamond's strength to second in the list of trump:\nWhen playing this variant the seven of diamonds is referred to as \"the Spitz\". Another variation puts the seven of diamonds first in the list of trump.\nNo picker.\nSeveral different scenarios can occur if no one picks up the blind, including a forced pick, a Leaster, a Mittler, or a Doubler.\nForced pick.\nIn this variant, the person on the end is required to pick the blind. This is sometimes offset by a \"No Punish\" rule, and statistics; if no one desired the blind, then there's a better chance that the blind has decent cards, unless the trump is evenly spread out.\nLeasters.\nIn a leaster, the person with the fewest points wins the hand. There is no partner, and the winner simply receives one point from every opponent in the game. The blind is set aside and normally given to the player who takes the last trick. House rules may allow the dealer to declare which trick is given the blind (e.g. the first trick, or the second, etc.). Another house rule may be to set the blind aside so it is not given to anyone. The blind is not viewed until after the hand is over.\nMosters.\nA variant of the leaster is the moster, which is played the same as a leaster, but after the hand is scored, the player who took the most points pays out (as if for a simple loss) to all the rest of the players. Thus, in a five-player game, the affected player loses four points and the opponents get one each, unless the score is doubled by other means (cracking, etc.). The exception is taking all of the tricks, which is still scored as a win by the player doing so.\nMittlers (Middlers).\nAn alternative to playing leasters or Mosters, the player who wins this \u201cno picker\u201d game has the median number (middle value) of points among the five players after the hand is scored. Thus, the winner of the Mittler will have the third highest number of points. There will be two players with higher points and two players with lower points. If there is no clear middle value, no stakes are exchanged. This game is also known as \u201cMichigan Mediocre,\u201d named by the Ann Arbor Sheepshead Society (AASS) that created this variant.\nSchneidster.\nAnother leaster alternative, which follows most of the rules for a leaster but is won by the player who gets closest to 30 points (Schneider) without going over. In the event of a tie, the round is considered a wash. This is a newer variant originating in clubs in Madison, Wisconsin in the late 2010's, where the last person in picking order chooses which no pick rule they would like to use. The Schneidster provides an alternative for players who have low trump and high fail which would lose most tricks in a normal hand but take tricks in a leaster.\nDoublers.\nIn a doubler, the cards are reshuffled and a new hand is dealt and played as normal. However, at the end of this redeal, the point values lost and gained are doubled.\nThe pot.\nTypically occurring with a leaster (and during cash games), one point is placed into a pot for the next hand. Then, if the picker wins the hand, they split the pot with the partner (in a five handed game, the extra point goes to the picker such that they receive three and the partner receives a single point). However, if the picker loses the hand, the picker and partner must pay into the pot what they would have received.\nSchwanzers (Show Down).\nAll players reveal their cards after everyone has passed a dealt hand to discover the loser who pays the table 1 point each.\u00a0The blind is discarded.\nIn German, 'Schw\u00e4nzer' means a truant or a hooky player.\u00a0Truancy refers to a student being absent from school, and therefore uneducated. Thus, a Schwanzer occurs because at least one player is uneducated in how to pick in the game of sheepshead. \nThe purpose of a Schwanzer, also known as a showdown, is to catch maurers without playing a leaster or another variant of a \u201cno pick\u201d situation. The loser is determined by the highest number of points in a hand.\u00a0The Schwanzer points are scaled as follows: Queens = 3 points, Jacks = 2 points, Diamonds = 1 point.\nFor example, a hand with the Queen of spades (3 points), Jack of clubs (2 points), Ace of diamonds (1 point), 8 of diamonds (1 point), 10 of clubs (0 points), and 7 of spades (0 points) equals the Schwanzer point value of 7. (3+2+1+1)\nIf tied in points, the player with the most powerful trump loses.\u00a0For example, a hand with the Queen of clubs (3 points) and Queen of diamonds (3 points) loses to the hand with Queen of spades (3 points), Jack of clubs (2 points) and the Ace of diamonds (1 point).\nVariations in the number of players.\nThere are numerous variations in rules, so a discussion of house rules generally occurs before play begins. The following variations can be employed to accommodate different numbers of players.\nTwo-handed.\n1) Each player is dealt four cards in a row, face down. Then, four cards are dealt face up to each player and placed on top of the first four cards. The eight cards in front of each player are referred to as their 'battery' in the text below. Then, eight cards are dealt to each player's hand. \nEvery hand is played with no picking nor partner. Whichever player gets the higher number of points wins the hand.\nEach trick has four cards - one from each player's hand, and one from each player's battery (table cards). The highest card, per normal rules, takes the trick. At the end of the trick, any uncovered face down card is turned face up, and is in play for the next trick.\nFor the first trick, the non-dealer leads a card from their hand, then the dealer plays from their hand, then the non-dealer's battery, then the dealer's battery. Whichever hand or battery takes the trick must lead the next trick. Each trick is 'hand hand battery battery', or 'battery battery hand hand'.\n2) Sixteen cards are dealt face down in a four by four rectangle. Players are not allowed to look at the face-down cards. Then, a card is dealt face-up on top of these. The sixteen cards (eight stacks of two cards) closest to the dealer are the dealer's cards. A card must be face-up to be played. The opponent starts the first trick by playing one of their face-up cards, and the dealer responds by playing one of theirs. After each trick is played, any face-down cards uncovered are turned face-up. Play continues until all 32 cards have been played. Players are not allowed to look at their own face-down cards.\nThree-handed.\n1) Each player is dealt ten cards, with two going to the blind. The picker faces the other two players.\n2) The sevens of clubs and spades are removed, leaving thirty cards. Nine cards are then dealt to each player, with three going to the blind. The picker faces the others.\n3) The six non-trump sevens and eights are removed, dealing eight cards to each player, with two in the blind.\nFour-handed.\n1) Seven cards are dealt to each player with four in the blind. Given the large blind, this variation required the picker go \"cut-throat \"(without a partner).\n2) The seven of clubs and seven of spades are removed (\"or \"the six of clubs and six of spades are added). Seven (or eight) cards are dealt to each player, with two in the blind. Either the jack or ace partner rules may be used.\n3) Each player is dealt eight cards, with no blind. Either (A) the two players holding the black queens are partners, where the partners are secret until both cards are played, a player holding both black queens plays cut-throat against the three others; (B) the partners are the first two queens played; or (C) the partners are the first two played of any card agreed upon before the deal (7s, 8s, 9s, Ks, 10s, Js, Qs). In all these variations, the players with the agreed upon partner cards (black, red, or first two played) are considered the picker and partner for scoring purposes. In the latter variations, the timing of playing the agreed upon card is particularly important. For example, it may be worth it to waste the queen or play a card out of normal strategy to become partners with an individual who has already taken a good trick or two, or to avoid being stuck cut-throat or with a bad partner.\n4) In this variation popular in southern Indiana (typically known by as \"Sheephead\"), jacks are higher than queens (still clubs-spades-hearts-diamonds), and hearts (rather than diamonds) are trump. Queens are worth 2 points and jacks are worth 3 points. The schneider (which is typically known as \"frog\") is 31 points, even for opponents. In the event of a tie (the hicker/partner and opponents both scoring 60 points), the opponents are victorious. All four players are dealt eight cards. Starting with the player to the left of the dealer, the player has the option to \"hick\" or pass. Once every player has been given the opportunity to hick, the players will announce what they wish to play in order starting with the first player to the left of the dealer. The options are to declare \"call\" (call a fail-suit ace for a partner), \"The Best\" (play normally against the other three), \"side solo\" (declare another suit rather than hearts to be trump, and then play against the other three), or \"Billy\" (plays against the three others but attempts not to take a trick). The suit of the called ace need not be declared until it is the winning hick.\nThe hick that is played depends on which hicks are made. The ranking of the hicks in ascending order is: \"call\", \"Billy\", \"side-solo\", \"the Best\". No cards of the same suit as the fail-suit ace are required in the player's hand when calling a fail-suit ace. Additionally, more than one Billy may be made and played simultaneously. In the event that both a Billy and a side-solo are called, the player who announced the Billy has the option to \"lay it up\", that is declare their intention to place their cards face up on the table and allow their opponents to see their hand. This allows the Billy to be ranked higher than the side-solo. A player who announces a side-solo may also decide to lay down their cards, once again out-ranking the Billy and allowing the side-solo to take precedence. A Billy may not be laid on the table without a side-solo being called, and a side-solo may not be laid on the table without another player offering to lay their Billy on the table. The Best always takes precedence, and the cards are never laid face up on the table. As such, the Best may be declared instead of hicking.\nScoring: Players play to 24 on the given system:\nAn optional rule that some players employ is that, in the event that all players pass, \"wilky\" is played. In wilky, play begins with the player left of the dealer as normal with the goal to get as few points as possible. The player (or players if there is a tie) who scores the fewest points is awarded 2 points.\nThis variant may also be played with five players, in which case the dealer each round does not play or earn points.\nFive-handed.\nSix cards are dealt to each player, with two to the blind. A partner may be chosen by either the ace or jack rules. The partner is the player with the called ace.\nSix-handed.\n1) Five cards are dealt to each player, with two cards in the blind. The partner is automatically the jack of diamonds, and the game is played two against four. If the picker gets the jack of diamonds in the blind, they may call the next higher jack, not in their hand.\n2) Five cards are dealt to each player, with two cards in the blind. The partner is automatically the jack of diamonds \"and \"the ace of the called suit, with the game played three against three. If the picker gets the jack of diamonds in the blind or the jack of diamonds has the ace of the called suit, it is played two against four.\n3) Discard the sevens of clubs and spades. Five cards are dealt to each player, with no blind. Queen of clubs and queen of spades are partners, it is played two against four.\n4) Discard the sevens of clubs and spades. Five cards are dealt to each player, with no blind. Seven of Diamonds is the highest trump. Queen of clubs, queen of spades, and jack of diamonds are partners. A player having both black queens or a black queen and jack of diamonds has the option to pass one of the cards to the player to the left for one of their cards. Passing must be done before the lead player plays out. Double on the bump is applied to this variation.\nSeven-handed.\n1) Four cards are dealt to each player, with four to the blind. The picker takes all four cards from the blind, and buries four. The partner is automatically the jack of diamonds. If the picker has the jack, they may call up to the next highest jack, not in their hand.\n2) Four cards are dealt to each player, with four to the blind. The picker takes two cards from the blind, and the player immediately behind them takes the other two blind cards; they bury together and then play as partners against the other five. Also known as Shit-On-Your-Neighbor sheepshead.\n3) Four cards are dealt to each player, with four to the blind. The picker takes three cards from the blind, and the player immediately behind them takes the other card. The partner is automatically the jack of diamonds. The player behind the picker is not automatically the partner, so their bury may count towards the picker's opponents.\n4) Four cards are dealt to each player, with four to the blind. A die is rolled, and the partner is whatever number is on the die with 1 representing the player to the pickers left, and counting clockwise with six being the person to the picker's right. Each takes and buries two cards.\n5) Four cards are dealt to each player, with four to the blind. The picker takes 0, 1, or 2 cards, the person behind them is partner and takes 2, 1, or 0 card respectively. The two remaining cards are not revealed and are automatically buried for the other team. The Dealer may go \"nuclear\" giving all 4 of their cards to the other team's bury and taking the entire blind, the person behind them is still a partner.\n6) Four cards are dealt to each player, with four to the blind. The picker takes 2 or all 4 cards in the blinds. If the picker takes 2 they roll a die to determine their partner, who will take the other 2. The number rolled correlates to the partner by counting players clockwise of the picker. If the picker takes all 4 cards from the blinds, they play alone. For the picker to take all four cards in the blind, they must do so by taking them all at once. Players are not allowed to look at 2 and then decide if they want the remaining 2 cards in the blinds.\nEight-handed.\n1) Four cards are dealt to each player. The two black queens are partners.\n2) Four cards are dealt to each player. The queen of clubs, jack of diamonds, and 7 of diamonds are partners. If one partner has two of these cards, they can call the 8 of diamonds (if they have the 7 and the queen or jack) or jack of hearts (if they have the queen and the jack). If the other partner already has the 8 of diamonds or jack of hearts they can call again. It should always be 3 on 5 unless the partner chooses not to call another partner.\n3) Four cards dealt to each player. First two queens played are partners.\nGlossary / Slang.\nThe following phrases or slang can be used to describe certain behaviors or situations in the game. For more, see Glossary of card game terms.\nMauer.\nA player \"mauers\" when the player has enough power-cards to pick up the blind, and yet passes (whether for fear one's hand is not actually good enough, or worse, one hopes to set up another player to lose). Mauering is considered to be in very poor taste and in some cases players who do it often enough can be asked to leave a game. Of course, mauering can backfire if the hand results in a leaster, and the mauerer is stuck with what is then a poor hand.\nThere are different methods of deciding if a player has a strong hand. In a five-handed game, some players pick on any four trumps, while others decide based on the number of higher trump (queens and jacks). Others use a numbering system, giving each type of trump a point value and making the decision to pick based on a certain number of points. Statistically, players who have an opportunity to pick first need a stronger hand, while picking on the end usually means that since nobody else picked, the trump is fairly evenly spread out. Because of the complex nature of the game, in most cases, mauering is a matter of opinion.\nSchmear.\nA player \"schmears\" a trick by playing a high-point card (usually an ace or ten) into a trick that a player thinks will be (or has already been) taken by one of their partners, in order to increase the points earned on that trick. The term may also be a noun, referring to the high-point card played in this manner. An example of schmearing (by Opponents 2 and 3):\nThis trick was worth 34 points. That's schneider all by itself.\nOpponent 1 is guaranteed to win the trick as the queen of clubs is the highest card. As a result, opponents 2 and 3 both took advantage of the situation and put high-counting cards down. Also note that the picker played the 8\u2666, a no-counting card\u2014the opposite of schmearing.\nSchmearing is an important strategy. In this example, schmearing increased the value of the trick by 21 points to a total of 34 points\u2014schneider all by itself and over a quarter of the points available.\nRenege (Cheating).\nA player \"reneges\" means to fail to follow suit when able and required by the rules to do so. Reneging is a form of cheating. In most circles, this results in the guilty party forfeiting the hand.\nGranny hand.\nWhen a player holds all or most of the top trump there is no way for the opposition to win. This unusually powerful hand is often derided for its ease of play; \"My granny could win that hand.\" The hand still counts and is played out.\nIn some circles, the player simply lays down the granny hand and the opponents conceding by acclamation. Even if not completely a granny hand, some circles permit a player to state that they believe they will take all of the remaining tricks (possibly requiring an explanation, say, \"I have all of the remaining trump\"), giving opponents an opportunity to object (say, if the calling player miscounted trump) -- forestalling the players from needing to play out the remainder of the hand.\nBumping.\nWhen a teammate uses a higher powered card to take a trick that already is already going to their team\u2014usually when the trick is necessarily going to another teammate. Sometimes this is unavoidable especially in cases where there is only one card of a particular suit left in a player's hand. Sometimes this is strategic, such as to place an opponent on each side of the picker and/or the partner.\nCollusion (Cheating).\nAs with any partner game, code words or signs can be used to cheat. This involves 2 players creating a word or phrase which tells their partner in crime what to lead. For instance, Player A and Player B are colluding with each other in a game of 4 handed. Player A has the lead and Player B is behind the dealer without a fail Spade. Player B uses the phrase \"let's rock n' roll\" to signal Player A to lead spades. Player A leads spades, the picker trumps it, and Player B trumps over the Picker. This is very much frowned upon and if caught, the players are usually kicked out of the game. Also called \u201cTable Talk\u201d.\nThrowing Off / Slough.\nA player \"throws off\" or \"sloughs\" when, after a fail card is played and the player does not have any of that fail suit but does have trump, decides to play a fail card rather than trump. Sloughing well is a key to winning at sheepshead, especially as the picker. One popular situation to throw off is as follows and is known as \"The Throw Off\"; (1) a fail suit is led that the picker does not have, (2) the picker is 2nd in line, and (3) the picker throws off, usually because they have a poor hand, hoping their partner can take the trick.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26915", "revid": "146242", "url": "https://en.wikipedia.org/wiki?curid=26915", "title": "Linguistic relativity", "text": "Hypothesis of language influencing thought\nLinguistic relativity asserts that language influences worldview or cognition. One form of linguistic relativity, linguistic determinism, regards peoples' languages as determining and influencing the scope of cultural perceptions of their surrounding world.\nVarious colloquialisms refer to linguistic relativism: the Whorf hypothesis; the Sapir\u2013Whorf hypothesis ( ); the Whorf\u2013Sapir hypothesis; and Whorfianism.\nThe hypothesis is in dispute, with many different variations throughout its history. The \"strong hypothesis\" of linguistic relativity, now referred to as linguistic determinism, is that language \"determines\" thought and that linguistic categories limit and restrict cognitive categories. This was a claim by some earlier linguists pre-World War II; \nsince then it has fallen out of acceptance by contemporary linguists. Nevertheless, research has produced positive empirical evidence supporting a \"weaker\" version of linguistic relativity: that a language's structures influence a speaker's perceptions, without strictly limiting or obstructing them.\nAlthough common, the term \"Sapir\u2013Whorf hypothesis\" is sometimes considered a misnomer for several reasons. Edward Sapir (1884\u20131939) and Benjamin Lee Whorf (1897\u20131941) never co-authored any works and never stated their ideas in terms of a hypothesis. The distinction between a weak and a strong version of this hypothesis is also a later development; Sapir and Whorf never used such a dichotomy, although often their writings and their opinions of this relativity principle expressed it in stronger or weaker terms.\nThe principle of linguistic relativity and the relationship between language and thought has also received attention in varying academic fields, including philosophy, psychology and anthropology. It has also influenced works of fiction and the invention of constructed languages.\nHistory.\nThe idea was first expressed explicitly by 19th-century thinkers such as Wilhelm von Humboldt and Johann Gottfried Herder, who considered language as the expression of the spirit of a nation. Members of the early 20th-century school of American anthropology including Franz Boas and Edward Sapir also approved versions of the idea to a certain extent, including in a 1928 meeting of the Linguistic Society of America, but Sapir, in particular, wrote more often against than in favor of anything like linguistic determinism. Sapir's student, Benjamin Lee Whorf, came to be considered as the primary proponent as a result of his published observations of how he perceived linguistic differences to have consequences for human cognition and behavior. Harry Hoijer, another of Sapir's students, introduced the term \"Sapir\u2013Whorf hypothesis\", even though the two scholars never formally advanced any such hypothesis. A strong version of relativist theory was developed from the late 1920s by the German linguist Leo Weisgerber. Whorf's principle of linguistic relativity was reformulated as a testable hypothesis by Roger Brown and Eric Lenneberg who performed experiments designed to determine whether color perception varies between speakers of languages that classified colors differently.\nAs the emphasis of the universal nature of human language and cognition developed during the 1960s, the idea of linguistic relativity became disfavored among linguists. From the late 1980s, a new school of linguistic relativity scholars has examined the effects of differences in linguistic categorization on cognition, finding broad support for non-deterministic versions of the hypothesis in experimental contexts. Some effects of linguistic relativity have been shown in several semantic domains, although they are generally weak. Currently, a nuanced opinion of linguistic relativity is espoused by most linguists holding that language influences certain kinds of cognitive processes in non-trivial ways, but that other processes are better considered as developing from connectionist factors. Research emphasizes exploring the manners and extent to which language influences thought.\nAncient philosophy to the Enlightenment.\nThe idea that language and thought are intertwined is ancient. In his dialogue Cratylus, Plato explores the idea that conceptions of reality, such as Heraclitean flux, are embedded in language. But Plato has been read as arguing against sophist thinkers such as Gorgias of Leontini, who claimed that the physical world cannot be experienced except through language; this made the question of truth dependent on aesthetic preferences or functional consequences. Plato may have held instead that the world consisted of eternal ideas and that language should represent these ideas as accurately as possible. Nevertheless, Plato's Seventh Letter claims that ultimate truth is inexpressible in words.\nFollowing Plato, St. Augustine, for example, argued that language was merely like labels applied to concepts existing already. This opinion remained prevalent throughout the Middle Ages. Roger Bacon had the opinion that language was but a veil covering eternal truths, hiding them from human experience. For Immanuel Kant, language was but one of several methods used by humans to experience the world.\nGerman Romantic philosophers.\nDuring the late 18th and early 19th centuries, the idea of the existence of different national characters, or \"Volksgeister\", of different ethnic groups was a major motivator for the German romantics school and the beginning ideologies of ethnic nationalism.\nJohann Georg Hamann.\nJohann Georg Hamann is often suggested to be the first among the actual German Romantics to discuss the concept of the \"genius\" of a language. In his \"Essay Concerning an Academic Question\", Hamann suggests that a people's language affects their worldview:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The lineaments of their language will thus correspond to the direction of their mentality.\nWilhelm von Humboldt.\n In 1820, Wilhelm von Humboldt associated the study of language with the national romanticist program by proposing that language is the fabric of thought. Thoughts are produced as a kind of internal dialog using the same grammar as the thinker's native language. This opinion was part of a greater idea in which the assumptions of an ethnic nation, their \"Weltanschauung\", was considered as being represented by the grammar of their language. Von Humboldt argued that languages with an inflectional morphological type, such as German, English and the other Indo-European languages, were the most perfect languages and that accordingly this explained the dominance of their speakers with respect to the speakers of less perfect languages. Wilhelm von Humboldt declared in 1820:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In Humboldt's humanistic understanding of linguistics, each language creates the individual's worldview in its particular way through its lexical and grammatical categories, conceptual organization, and syntactic models.\nHerder worked alongside Hamann to establish the idea of whether or not language had a human/rational or a divine origin. Herder added the emotional component of the hypothesis and Humboldt then took this information and applied to various languages to expand on the hypothesis.\nBoas and Sapir.\nThe idea that some languages are superior to others and that lesser languages maintained their speakers in intellectual poverty was widespread during the early 20th century. American linguist William Dwight Whitney, for example, actively strove to eradicate Native American languages, arguing that their speakers were savages and would be better off learning English and adopting a \"civilized\" way of life. The first anthropologist and linguist to challenge this opinion was Franz Boas. While performing geographical research in northern Canada he became fascinated with the Inuit and decided to become an ethnographer. Boas stressed the equal worth of all cultures and languages, that there was no such thing as a primitive language and that all languages were capable of expressing the same content, albeit by widely differing means. Boas saw language as an inseparable part of culture and he was among the first to require of ethnographers to learn the native language of the culture to be studied and to document verbal culture such as myths and legends in the original language.\nBoas:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nBoas' student Edward Sapir referred to the Humboldtian idea that languages were a major factor for understanding the cultural assumptions of peoples. He espoused the opinion that because of the differences in the grammatical systems of languages no two languages were similar enough to allow for perfect cross-translation. Sapir also thought because language represented reality differently, it followed that the speakers of different languages would perceive reality differently.\nSapir:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;No two languages are ever sufficiently similar to be considered as representing the same social reality. The worlds in which different societies live are distinct worlds, not merely the same world with different labels attached.\nHowever, Sapir explicitly rejected strong linguistic determinism by stating, \"It would be na\u00efve to imagine that any analysis of experience is dependent on pattern expressed in language.\"\nSapir was explicit that the associations between language and culture were neither extensive nor particularly profound, if they existed at all:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It is easy to show that language and culture are not intrinsically associated. Totally unrelated languages share in one culture; closely related languages\u2014even a single language\u2014belong to distinct culture spheres. There are many excellent examples in Aboriginal America. The Athabaskan languages form as clearly unified, as structurally specialized, a group as any that I know of. The speakers of these languages belong to four distinct culture areas... The cultural adaptability of the Athabaskan-speaking peoples is in the strangest contrast to the inaccessibility to foreign influences of the languages themselves.\nSapir offered similar observations about speakers of so-called \"world\" or \"modern\" languages, noting, \"possession of a common language is still and will continue to be a smoother of the way to a mutual understanding between England and America, but it is very clear that other factors, some of them rapidly cumulative, are working powerfully to counteract this leveling influence. A common language cannot indefinitely set the seal on a common culture when the geographical, physical, and economics determinants of the culture are no longer the same throughout the area.\"\nWhile Sapir never made a practice of studying directly how languages affected thought, some notion of (probably \"weak\") linguistic relativity affected his basic understanding of language, and would be developed by Whorf.\nIndependent developments in Europe.\nDrawing on influences such as Humboldt and Friedrich Nietzsche, some European thinkers developed ideas similar to those of Sapir and Whorf, generally working in isolation from each other. Prominent in Germany from the late 1920s through the 1960s were the strongly relativist theories of Leo Weisgerber and his concept of a 'linguistic inter-world', mediating between external reality and the forms of a given language, in ways peculiar to that language. Russian psychologist Lev Vygotsky read Sapir's work and experimentally studied the ways in which the development of concepts in children was influenced by structures given in language. His 1934 work \"Thought and Language\" has been compared to Whorf's and taken as mutually supportive evidence of language's influence on cognition. Drawing on Nietzsche's ideas of perspectivism Alfred Korzybski developed the theory of general semantics that has been compared to Whorf's notions of linguistic relativity. Though influential in their own right, this work has not been influential in the debate on linguistic relativity, which has tended to be based on the American paradigm exemplified by Sapir and Whorf.\nBenjamin Lee Whorf.\nMore than any linguist, Benjamin Lee Whorf has become associated with what he termed the \"linguistic relativity principle\". Studying Native American languages, he attempted to account for the ways in which grammatical systems and language-use differences affected perception. Whorf's opinions regarding the nature of the relation between language and thought remain under contention. However, a version of theory holds some \"merit\", for example, \"different words mean different things in different languages; not every word in every language has a one-to-one exact translation in a different language\" Critics such as Lenneberg, Black, and Pinker attribute to Whorf a strong linguistic determinism, while Lucy, Silverstein and Levinson point to Whorf's explicit rejections of determinism, and where he contends that translation and commensuration are possible.\nDetractors such as Lenneberg, Chomsky and Pinker criticized him for insufficient clarity of his description of how language influences thought, and for not proving his conjectures. Most of his arguments were in the form of anecdotes and speculations that served as attempts to show how \"exotic\" grammatical traits were associated with what were apparently equally exotic worlds of thought. In Whorf's words:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We dissect nature along lines laid down by our native language. The categories and types that we isolate from the world of phenomena we do not find there because they stare every observer in the face; on the contrary, the world is presented in a kaleidoscope flux of impressions which has to be organized by our minds\u2014and this means largely by the linguistic systems of our minds. We cut nature up, organize it into concepts, and ascribe significances as we do, largely because we are parties to an agreement to organize it in this way\u2014an agreement that holds throughout our speech community and is codified in the patterns of our language [...] all observers are not led by the same physical evidence to the same picture of the universe, unless their linguistic backgrounds are similar, or can in some way be calibrated.\nSeveral terms for a single concept.\nAmong Whorf's best-known examples of linguistic relativity are instances where a non-European language has several terms for a concept that is only described with one word in European languages (Whorf used the acronym SAE \"Standard Average European\" to allude to the rather similar grammatical structures of the well-studied European languages in contrast to the greater diversity of less-studied languages).\nOne of Whorf's examples was the supposedly large number of words for 'snow' in the Inuit languages, an example that later was contested as a misrepresentation.\nAnother is the Hopi language's words for water, one indicating drinking water in a container and another indicating a natural body of water.\nThese examples of polysemy served the double purpose of showing that non-European languages sometimes made more specific semantic distinctions than European languages and that direct translation between two languages, even of seemingly basic concepts such as snow or water, is not always possible.\nAnother example is from Whorf's experience as a chemical engineer working for an insurance company as a fire inspector. While inspecting a chemical plant he observed that the plant had two storage rooms for gasoline barrels, one for the full barrels and one for the empty ones. He further noticed that while no employees smoked cigarettes in the room for full barrels, no-one minded smoking in the room with empty barrels, although this was potentially much more dangerous because of the flammable vapors still in the barrels. He concluded that the use of the word \"empty\" in association to the barrels had resulted in the workers unconsciously regarding them as harmless, although consciously they were probably aware of the risk of explosion. This example was later criticized by Lenneberg as not actually demonstrating causality between the use of the word \"empty\" and the action of smoking, but instead was an example of circular reasoning. Pinker in \"The Language Instinct\" ridiculed this example, claiming that this was a failing of human insight rather than language.\nTime in Hopi.\nWhorf's most elaborate argument for linguistic relativity regarded what he believed to be a fundamental difference in the understanding of time as a conceptual category among the Hopi. He argued that in contrast to English and other SAE languages, Hopi does not treat the flow of time as a sequence of distinct, countable instances, like \"three days\" or \"five years\", but rather as a single process and that consequently it has no nouns referring to units of time as SAE speakers understand them. He proposed that this view of time was fundamental to Hopi culture and explained certain Hopi behavioral patterns.\nEkkehart Malotki later claimed that he had found no evidence of Whorf's claims in 1980's era Hopi speakers, nor in historical documents dating back to the arrival of Europeans. Malotki used evidence from archaeological data, calendars, historical documents, and modern speech; he concluded that there was no evidence that Hopi conceptualize time in the way Whorf suggested. Many universalist scholars such as Pinker consider Malotki's study as a final refutation of Whorf's claim about Hopi, whereas relativist scholars such as John A Lucy and Penny Lee criticized Malotki's study for mischaracterizing Whorf's claims and for forcing Hopi grammar into a model of analysis that does not fit the data.\nStructure-centered approach.\nWhorf's argument about Hopi speakers' conceptualization of time is an example of the structure-centered method of research into linguistic relativity, which Lucy identified as one of three main types of research of the topic. The \"structure-centered\" method starts with a language's structural peculiarity and examines its possible ramifications for thought and behavior. The defining example is Whorf's observation of discrepancies between the grammar of time expressions in Hopi and English. More recent research in this vein is Lucy's research describing how usage of the categories of grammatical number and of numeral classifiers in the Mayan language Yucatec result in Mayan speakers classifying objects according to material rather than to shape as preferred by English speakers. However, philosophers including Donald Davidson and Jason Josephson Storm have argued that Whorf's Hopi examples are self-refuting, as Whorf had to translate Hopi terms into English in order to explain how they are untranslatable.\nWhorf dies.\nWhorf died in 1941 at age 44, leaving multiple unpublished papers. His ideas were continued by linguists and anthropologists such as Hoijer and Lee, who both continued investigating the effect of language on habitual thought, and Trager, who prepared a number of Whorf's papers for posthumous publishing. The most important event for the dissemination of Whorf's ideas to a larger public was the publication in 1956 of his major writings on the topic of linguistic relativity in a single volume titled \"Language, Thought and Reality\".\nBrown and Lenneberg.\nIn 1953, Eric Lenneberg criticized Whorf's examples from an objectivist philosophy of language, claiming that languages are principally meant to represent events in the real world, and that even though languages express these ideas in various ways, the meanings of such expressions and therefore the thoughts of the speaker are equivalent. He argued that Whorf's English descriptions of a Hopi speaker's idea of time were in fact translations of the Hopi concept into English, therefore disproving linguistic relativity. However Whorf was concerned with how the habitual \"use\" of language influences habitual behavior, rather than translatability. Whorf's point was that while English speakers may be able to \"understand\" how a Hopi speaker thinks, they do not \"think\" in that way.\nLenneberg's main criticism of Whorf's works was that he never showed the necessary association between a linguistic phenomenon and a mental phenomenon. With Brown, Lenneberg proposed that proving such an association required directly matching linguistic phenomena with behavior. They assessed linguistic relativity experimentally and published their findings in 1954. Since neither Sapir nor Whorf had ever stated a formal hypothesis, Brown and Lenneberg formulated their own. Their two tenets were (i) \"the world is differently experienced and conceived in different linguistic communities\" and (ii) \"language causes a particular cognitive structure\". Brown later developed them into the so-called \"weak\" and \"strong\" formulation:\nBrown's formulations became known widely and were retrospectively attributed to Whorf and Sapir although the second formulation, verging on linguistic determinism, was never advanced by either of them.\nJoshua Fishman's \"Whorfianism of the third kind\".\nJoshua Fishman argued that Whorf's true assertion was largely overlooked. In 1978, he suggested that Whorf was a \"neo-Herderian champion\" and in 1982, he proposed \"Whorfianism of the third kind\" in an attempt to reemphasize what he claimed was Whorf's real interest, namely the intrinsic value of \"little peoples\" and \"little languages\". Whorf had criticized Ogden's Basic English thus:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;But to restrict thinking to the patterns merely of English [...] is to lose a power of thought which, once lost, can never be regained. It is the 'plainest' English which contains the greatest number of unconscious assumptions about nature. [...] We handle even our plain English with much greater effect if we direct it from the vantage point of a multilingual awareness.\nWhere Brown's weak version of the linguistic relativity hypothesis proposes that language \"influences\" thought and the strong version that language \"determines\" thought, Fishman's \"Whorfianism of the third kind\" proposes that language \"is a key to culture\".\nLeiden school.\nThe Leiden school is a linguistic theory that models languages as parasites. Notable proponent Frederik Kortlandt, in a 1985 paper outlining Leiden school theory, advocates for a form of linguistic relativity: \"The observation that in all Yuman languages the word for 'work' is a loan from Spanish should be a major blow to any current economic theory.\" In the next paragraph, he quotes directly from Sapir: \"Even in the most primitive cultures the strategic word is likely to be more powerful than the direct blow.\"\n\"Rethinking Linguistic Relativity\".\nThe publication of the 1996 anthology \"Rethinking Linguistic Relativity\" edited by Gumperz and Levinson began a new period of linguistic relativity studies that emphasized cognitive and social aspects. The book included studies on linguistic relativity and universalist traditions. Levinson documented significant linguistic relativity effects in the different linguistic conceptualization of spatial categories in different languages. For example, men speaking the Guugu Yimithirr language in Queensland gave accurate navigation instructions using a compass-like system of north, south, east and west, along with a hand gesture pointing to the starting direction.\nLucy defines this method as \"domain-centered\" because researchers select a semantic domain and compare it across linguistic and cultural groups. Space is another semantic domain that has proven fruitful for linguistic relativity studies. Spatial categories vary greatly across languages. Speakers rely on the linguistic conceptualization of space in performing many ordinary tasks. Levinson and others reported three basic spatial categorizations. While many languages use combinations of them, some languages exhibit only one type and related behaviors. For example, Yimithirr only uses absolute directions when describing spatial relations\u2014the position of everything is described by using the cardinal directions. Speakers define a location as \"north of the house\", while an English speaker may use relative positions, saying \"in front of the house\" or \"to the left of the house\".\nSeparate studies by Bowerman and Slobin analyzed the role of language in cognitive processes. Bowerman showed that some basic cognitive functions, such as early spatial reasoning and object categorization in infants, develop largely independently of language. This suggests that not all aspects of cognition are shaped by linguistic structures, and therefore some cognitive processes may fall outside the scope of linguistic relativity. Slobin described another kind of cognitive process that he named \"thinking for speaking\"\u2014- the kind of process in which perceptional data and other kinds of prelinguistic cognition are translated into linguistic terms for communication. These, Slobin argues, are the kinds of cognitive process that are the basis of linguistic relativity.\nColour terminology.\nBrown and Lenneberg.\nSince Brown and Lenneberg believed that the objective reality denoted by language was the same for speakers of all languages, they decided to test how different languages codified the same message differently and whether differences in codification could be proven to affect behavior. Brown and Lenneberg designed experiments involving the codification of colors. In their first experiment, they investigated whether it was easier for speakers of English to remember color shades for which they had a specific name than to remember colors that were not as easily definable by words. This allowed them to compare the linguistic categorization directly to a non-linguistic task. In a later experiment, speakers of two languages that categorize colors differently (English and Zuni) were asked to recognize colors. In this manner, it could be determined whether the differing color categories of the two speakers would determine their ability to recognize nuances within color categories. Brown and Lenneberg found that Zuni speakers who classify orange and yellow together as a single color did have trouble recognizing and remembering nuances within the orange/yellow category. This method, which Lucy later classified as domain-centered, is acknowledged to be sub-optimal, because color perception, unlike other semantic domains, is hardwired into the neural system and as such is subject to more universal restrictions than other semantic domains.\nHugo Magnus.\nIn a similar study done by German ophthalmologist Hugo Magnus during the 1870s, he circulated a questionnaire to missionaries and traders with ten standardized color samples and instructions for using them. These instructions contained an explicit warning that failure of a language to distinguish lexically between two colors did not necessarily imply that speakers of that language did not distinguish the two colors perceptually. Magnus received completed questionnaires on twenty-five African, fifteen Asian, three Australian, and two European languages. He concluded in part, \"As regards the range of the color sense of the primitive peoples tested with our questionnaire, it appears in general to remain within the same bounds as the color sense of the civilized nations. At least, we could not establish a complete lack of the perception of the so-called main colors as a special racial characteristic of any one of the tribes investigated for us. We consider red, yellow, green, and blue as the main representatives of the colors of long and short wavelength; among the tribes we tested not a one lacks the knowledge of any of these four colors\" (Magnus 1880, p.\u00a06, as trans. in Berlin and Kay 1969, p.\u00a0141). Magnus did find widespread lexical neutralization of green and blue, that is, a single word covering both these colors, as have all subsequent comparative studies of color lexicons.\nResponse to Brown and Lenneberg's study.\nBrown and Lenneberg's study began a tradition of investigation of linguistic relativity through color terminology. The studies showed a correlation between color term numbers and ease of recall in both Zuni and English speakers. Researchers attributed this to focal colors having greater codability than less focal colors, and not to linguistic relativity effects. Berlin/Kay found universal typological color principles that are determined by biological rather than linguistic factors. This study sparked studies into typological universals of color terminology. Researchers such as Lucy, Saunders and Levinson argued that Berlin and Kay's study does not refute linguistic relativity in color naming, because of unsupported assumptions in their study (such as whether all cultures in fact have a clearly defined category of \"color\") and because of related data problems. Researchers such as Maclaury continued investigation into color naming. Like Berlin and Kay, Maclaury concluded that the domain is governed mostly by physical-biological universals.\nBerlin and Kay.\nStudies by Berlin and Kay continued Lenneberg's color research. They studied color terminology formation and showed clear universal trends in color naming. For example, they found that even though languages have different color terminologies, they generally recognize certain hues as more focal than others. They showed that in languages with few color terms, it is predictable from the number of terms which hues are chosen as focal colors: For example, languages with only three color terms always have the focal colors black, white, and red. The fact that what had been believed to be random differences between color naming in different languages could be shown to follow universal patterns was seen as a powerful argument against linguistic relativity. Berlin and Kay's research has since been criticized by relativists such as Lucy, who argued that Berlin and Kay's conclusions were skewed by their insistence that color terms encode only color information. This, Lucy argues, made them unaware of the instances in which color terms provided other information that might be considered examples of linguistic relativity.\nUniversalism.\nUniversalist scholars began a period of dissent from ideas about linguistic relativity. Lenneberg was one of the first cognitive scientists to begin development of the Universalist theory of language that was formulated by Chomsky as universal grammar, effectively arguing that all languages share the same underlying structure. The Chomskyan school also includes the belief that linguistic structures are largely innate and that what are perceived as differences between specific languages are surface phenomena that do not affect the brain's universal cognitive processes. This theory became the dominant paradigm of American linguistics from the 1960s through the 1980s, while linguistic relativity became the object of ridicule.\nEkkehart Malotki.\nOther universalist researchers dedicated themselves to dispelling other aspects of linguistic relativity, often attacking Whorf's specific examples. For example, Malotki's monumental study of time expressions in Hopi presented many examples that challenged Whorf's \"timeless\" interpretation of Hopi language and culture, but seemingly failed to address the linguistic relativist argument actually posed by Whorf (i.e. that the understanding of time by native Hopi speakers differed from that of speakers of European languages due to the differences in the organization and construction of their respective languages; Whorf never claimed that Hopi speakers lacked any concept of time). Malotki himself acknowledges that the conceptualizations are different, but because he ignores Whorf's use of quotes around the word \"time\" and the qualifier \"what we call\", takes Whorf to be arguing that the Hopi have no concept of time at all.\nSteven Pinker.\nCurrently many believers of the universalist school of thought still oppose linguistic relativity. For example, Pinker argues in \"The Language Instinct\" that thought is independent of language, that language is itself meaningless in any fundamental way to human thought, and that human beings do not even think in \"natural\" language, i.e. any language that we actually communicate in; rather, we think in a meta-language, preceding any natural language, termed \"mentalese\". Pinker attacks what he terms \"Whorf's radical position\", declaring, \"the more you examine Whorf's arguments, the less sense they make\".\nPinker and other universalists have been accused by relativists of misrepresenting Whorf's ideas and committing the strawman fallacy.\nCognitive linguistics.\nDuring the late 1980s and early 1990s, advances in cognitive psychology and cognitive linguistics renewed interest in the Sapir\u2013Whorf hypothesis. One of those who adopted a more Whorfian philosophy was George Lakoff. He argued that language is often used metaphorically and that languages use different cultural metaphors that reveal something about how speakers of that language think. For example, English employs conceptual metaphors likening time to money, so that time can be saved and spent and invested, whereas other languages do not talk about time in that manner. Other such metaphors are common to many languages because they are based on general human experience, for example, metaphors associating \"up\" with \"good\" and \"bad\" with \"down\". Lakoff also argued that metaphor plays an important part in political debates such as the \"right to life\" or the \"right to choose\"; or \"illegal aliens\" or \"undocumented workers\".\nAn unpublished study by Boroditsky et al. in 2003 reported finding empirical evidence favoring the hypothesis and demonstrating that differences in languages' systems of grammatical gender can affect the way speakers of those languages think about objects. Speakers of Spanish and German (which have different gender systems) were asked to use adjectives to describe various objects designated by words that were either masculine or feminine in their respective languages. Speakers tended to describe objects in ways that were consistent with the gender of the noun in their language, indicating that the gender system of a language can influence speakers' perceptions of objects. Despite numerous citations, the experiment was criticised after the reported effects could not be replicated by independent trials. Additionally, a large-scale data analysis using word embeddings of language models found no correlation between adjectives and inanimate noun genders, while another study using large text corpora found a slight correlation between the gender of animate and inanimate nouns and their adjectives as well as verbs by measuring their mutual information.\nColin Murray Turbayne also argued that the pervasive use of ancient \"dead metaphors\" by researchers within different linguistic traditions has contributed to needless confusion in the development of modern empirical theories over time. He points to several examples within the Romance and Germanic languages of the subtle manner in which mankind has become unknowingly victimized by such \"unmasked metaphors\". Cases include the incorporation of mechanistic metaphors first introduced by Rene Descartes and Isaac Newton during the 17th century into scientific theories which were subsequently developed by George Berkeley, David Hume and Immanuel Kant during the 18th century; and the influence exerted by Platonic metaphors in the dialogue \"Timaeus\" upon the development of contemporary theories of \"language\" in modern times. \nParameters.\nIn his 1987 book \"Women, Fire, and Dangerous Things: What Categories Reveal About the Mind\", Lakoff reappraised linguistic relativity and especially Whorf's ideas about how linguistic categorization represents and/or influences mental categories. He concluded that the debate had been confused. He identified four parameters on which researchers differed in their opinions about what constitutes linguistic relativity:\nLakoff concluded that many of Whorf's critics had criticized him using novel definitions of linguistic relativity, rendering their criticisms moot.\nRefinements.\nResearchers such as Boroditsky, Choi, Majid, Lucy and Levinson believe that language influences thought in more limited ways than the broadest early claims. Researchers examine the interface between thought (or cognition), language and culture and describe the relevant influences. They use experimental data to back up their conclusions. Kay ultimately concluded that \"[the] Whorf hypothesis is supported in the right visual field but not the left\". His findings show that accounting for brain lateralization offers another perspective.\nBehavior-centered research.\nRecent studies have also used a \"behavior-based\" method, which starts by comparing behavior across linguistic groups and then searches for causes for that behavior in the linguistic system. In an early example of this method, Whorf attributed the occurrence of fires at a chemical plant to the workers' use of the word 'empty' to describe barrels containing only explosive vapors.\nMore recently, Bloom noticed that speakers of Chinese had unexpected difficulties answering counterfactual questions posed to them in a questionnaire. He concluded that this was related to the way in which counter-factuality is marked grammatically in Chinese. Other researchers attributed this result to Bloom's flawed translations. Str\u00f8mnes examined why Finnish factories had a greater occurrence of work related accidents than similar Swedish ones. He concluded that cognitive differences between the grammatical usage of Swedish prepositions and Finnish cases could have caused Swedish factories to pay more attention to the work process while Finnish factory organizers paid more attention to the individual worker.\nNumbers and classifiers.\nEverett's work on the Pirah\u00e3 language of the Brazilian Amazon found several peculiarities that he interpreted as corresponding to linguistically rare features, such as a lack of numbers and color terms in the way those are otherwise defined and the absence of certain types of clauses. Everett's conclusions were met with skepticism from universalists who claimed that the linguistic deficit is explained by the lack of need for such concepts.\nRecent research with non-linguistic experiments in languages with different grammatical properties (e.g., languages with and without numeral classifiers or with different gender grammar systems) showed that language differences in human categorization are due to such differences. Experimental research suggests that this linguistic influence on thought diminishes over time, as when speakers of one language are exposed to another.\nTime perception.\nResearch on time-space congruency suggests that temporal perception is shaped by spatial metaphors embedded in language. Casasanto &amp; Boroditsky (2008) found that people often use spatial metaphors to conceptualize time, linking longer distances with longer durations. Research has shown that linguistic differences can influence the perception of time. Swedish, like English, tends to describe time in terms of spatial distance (e.g., \"a long meeting\"), whereas Spanish often uses quantity-based metaphors (e.g., \"a big meeting\"). These linguistic patterns correlate with differences in how speakers estimate temporal durations: Swedish speakers are more influenced by spatial length, while Spanish speakers are more sensitive to volume.\nExpanding on this, research on time-space congruency suggests that temporal perception is shaped by spatial metaphors embedded in language. In many languages, time is conceptualized along a horizontal axis (e.g., \"looking forward to the future\" in English). However, Mandarin speakers also employ vertical metaphors for time, referring to earlier events as \"up\" and later events as \"down\". Experiments have shown that Mandarin speakers are quicker to recognize temporal sequences when they are presented vertically, whereas English speakers exhibit no such bias.\nPronoun-dropping and intentionality.\nKashima &amp; Kashima observed a correlation between the perceived individualism or collectivism in the social norms of a given country, with the tendency to neglect the use of pronouns in the country's language. They argued that explicit reference to \"you\" and \"I\" reinforces a distinction between the self and the other in the speaker.\nResearch also suggests that this structural difference influences how speakers attribute intentionality in events. Fausey &amp; Boroditsky (2010) conducted experiments comparing how English and Spanish speakers describe accidental versus intentional actions. Their results showed that English speakers, who are accustomed to using explicit pronouns, were more likely to specify the agent responsible for an accidental event (e.g., \"John broke the vase\"). In contrast, Spanish speakers, who frequently omit pronouns, were more likely to use agent-neutral descriptions for accidental events (e.g., \"The vase broke\").\nFuture tense.\nA 2013 study found that those who speak \"futureless\" languages with no grammatical marking of the future tense save more, retire with more wealth, smoke less, practice safer sex, and are less obese than those who do not. This effect has come to be termed the linguistic-savings hypothesis and has been replicated in several cross-cultural and cross-country studies. However, a study of Chinese, which can be spoken both with and without the grammatical future marking \"will\", found that subjects do not behave more impatiently when \"will\" is used repetitively. This laboratory-based finding of elective variation within a single language does not refute the linguistic savings hypothesis but some have suggested that it shows the effect may be due to culture or other non-linguistic factors.\nPsycholinguistic research.\nPsycholinguistic studies explored motion perception, emotion perception, object representation and memory. The gold standard of psycholinguistic studies on linguistic relativity is now finding non-linguistic cognitive differences in speakers of different languages (thus rendering inapplicable Pinker's criticism that linguistic relativity is \"circular\").\nRecent work with bilingual speakers attempts to distinguish the effects of language from those of culture on bilingual cognition including perceptions of time, space, motion, colors and emotion. Researchers described differences between bilinguals and monolinguals in perception of color, representations of time and other elements of cognition.\nOther domains.\nLinguistic relativity inspired others to consider whether thought and emotion could be influenced by manipulating language.\nScience and philosophy.\nA major question is whether human psychological faculties are mostly innate or whether they are mostly a result of learning, and hence subject to cultural and social processes such as language. The innate opinion is that humans share the same set of basic faculties, variability due to cultural differences is less important, and the human mind is a mostly biological construction, so all humans who share the same neurological configuration can be expected to have similar cognitive patterns.\nMultiple alternatives have advocates. The contrary constructivist position holds that human faculties and concepts are largely influenced by socially constructed and learned categories, without many biological restrictions. Another variant is idealist, which holds that human mental capacities are generally unrestricted by biological-material structures. Another is the essentialist position, which holds that inherent biological or psychological differences between individuals or groups, such as genetic, neurological, or cognitive traits, may influence how they experience and conceptualize the world. Yet another is relativist (cultural relativism), which sees different cultural groups as employing different conceptual schemes that are not necessarily compatible or commensurable, nor more or less in accord with external reality.\nAnother debate considers whether thought is a type of internal speech or is independent of and prior to language.\nIn the philosophy of language, the question addresses the relations between language, knowledge and the external world, and the concept of truth. Philosophers such as Putnam, Fodor, Davidson, and Dennett see language as directly representing entities from the objective world, and categorization as reflecting that world. Other philosophers (e.g. Quine, Searle, and Foucault) argue that categorization and conceptualization is subjective and arbitrary. Another view, represented by Jason Storm, seeks a third way by emphasizing how language changes and imperfectly represents reality without being completely divorced from ontology.\nAnother question is whether language is a tool for representing and referring to objects in the world, or whether it is a system used to construct mental representations that can be communicated.\nTherapy and self-development.\nSapir/Whorf contemporary Alfred Korzybski was independently developing his theory of general semantics, which was intended to use language's influence of thinking to maximize human cognitive abilities. Korzybski's thinking was influenced by logical philosophy such as Russell and Whitehead's \"Principia Mathematica\" and Wittgenstein's \"Tractatus Logico-Philosophicus\". Although Korzybski was not aware of Sapir and Whorf's writings, the philosophy was adopted by Whorf-admirer Stuart Chase, who fused Whorf's interest in cultural-linguistic variation with Korzybski's programme in his popular work \"The Tyranny of Words\". S. I. Hayakawa was a follower and popularizer of Korzybski's work, writing \"Language in Thought and Action\". The general semantics philosophy influenced the development of neuro-linguistic programming (NLP), another therapeutic technique that seeks to use awareness of language use to influence cognitive patterns.\nKorzybski independently described a \"strong\" version of the hypothesis of linguistic relativity.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We do not realize what tremendous power the structure of an habitual language has. It is not an exaggeration to say that it enslaves us through the mechanism of s[emantic] r[eactions] and that the structure which a language exhibits, and impresses upon us unconsciously, is automatically projected upon the world around us.\nArtificial languages.\nIn their fiction, authors such as Ayn Rand and George Orwell explored how linguistic relativity might be exploited for political purposes. In Rand's \"Anthem\", a fictive communist society removed the possibility of individualism by removing the word \"I\" from the language. In Orwell's \"1984\" the authoritarian state created the language Newspeak to make it impossible for people to think critically about the government, or even to contemplate that they might be impoverished or oppressed, by reducing the number of words to reduce the thought of the locutor.\nOthers have been fascinated by the possibilities of creating new languages that could enable new, and perhaps better, ways of thinking. Examples of such languages designed to explore the human mind include Loglan, explicitly designed by James Cooke Brown to test the linguistic relativity hypothesis, by exploring whether it would make its speakers think more logically. Suzette Haden Elgin, who was involved with the early development of neuro-linguistic programming, invented the language L\u00e1adan to explore linguistic relativity by making it easier to express what Elgin considered the female worldview, as opposed to Standard Average European languages, which she considered to convey a \"male centered\" worldview. John Quijada's language Ithkuil was designed to explore the limits of the number of cognitive categories a language can keep its speakers aware of at once. Similarly, Sonja Lang's Toki Pona was developed according to a Taoist philosophy for exploring how (or if) such a language would direct human thought.\nProgramming languages.\nAPL programming language originator Kenneth E. Iverson believed that the Sapir\u2013Whorf hypothesis applied to computer languages (without actually mentioning it by name). His Turing Award lecture, \"Notation as a Tool of Thought\", was devoted to this theme, arguing that more powerful notations aided thinking about computer algorithms.\nThe essays of Paul Graham explore similar themes, such as a conceptual hierarchy of computer languages, with more expressive and succinct languages at the top. Thus, the so-called \"blub\" paradox (after a hypothetical programming language of average complexity called \"Blub\") says that anyone preferentially using some particular programming language will \"know\" that it is more powerful than some, but not that it is less powerful than others. The reason is that \"writing\" in some language means \"thinking\" in that language. Hence the paradox, because typically programmers are \"satisfied with whatever language they happen to use, because it dictates the way they think about programs\".\nIn a 2003 presentation at an open source convention, Yukihiro Matsumoto, creator of the programming language Ruby, said that one of his inspirations for developing the language was the science fiction novel \"Babel-17\", based on the Whorf Hypothesis.\nScience fiction.\nNumerous examples of linguistic relativity have appeared in science fiction.\nSociolinguistics and linguistic relativity.\nSociolinguistics affects some variables within language, including the manner in which words are pronounced, word selection in certain dialogue, context, and tone. It's suggested that these effects may have implications for linguistic relativity.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "26916", "revid": "44106950", "url": "https://en.wikipedia.org/wiki?curid=26916", "title": "Statutes of limitations", "text": ""}
{"id": "26917", "revid": "27577755", "url": "https://en.wikipedia.org/wiki?curid=26917", "title": "Statute of limitations", "text": "Time limit for starting legal proceedings\nA statute of limitations, known in civil law systems as a prescriptive period, is a law passed by a legislative body to set the maximum time after an event within which legal proceedings may be initiated. In most jurisdictions, such periods exist for both criminal law and civil law such as contract law and property law, though often under different names and with varying details.\nWhen the time which is specified in a statute of limitations runs out, a claim may no longer be filed, or if filed, it may be subject to dismissal if the defense against that claim is raised that the claim is time-barred as having been filed after the statutory limitations period.\nWhen a statute of limitations expires in a criminal case, the courts no longer have jurisdiction. In many jurisdictions with statutes of limitation there is no time limit for dealing with particularly serious crimes.\nIn civil law systems, such provisions are typically part of their civil and criminal codes. The cause of action dictates the statute of limitations, which can be reduced or extended in order to ensure a full and fair trial. The intention of these laws is to facilitate resolution within a \"reasonable\" period of time. What amount of time is considered \"reasonable\" varies from country to country. In some countries, as in the US, it may vary from jurisdiction to jurisdiction and state (or province, etc.) to state. Internationally, the statute of limitations may vary from one civil or criminal action to another. Some countries do not have a statute of limitations.\nAnalysis of a statute of limitations also requires the examination of any associated statute of repose, tolling provisions, and exclusions.\nApplications.\nCommon law legal systems can include a statute specifying the length of time within which a claimant or prosecutor must file a case. In some jurisdictions (e.g., California), a case cannot begin after the period specified, and courts have no jurisdiction over cases filed after the statute of limitations has expired. In some other jurisdictions (e.g., New South Wales, Australia), a claim can be filed which may prove to have been brought outside the limitations period, but the court will retain jurisdiction in order to determine that issue, and the onus is on the defendant to plead it as part of their defense, or else the claim will not be statute barred.\nOnce they are filed, cases do not need to be resolved within the period specified in the statute of limitations.\nPurpose.\nThe purpose and effect of statutes of limitations are to protect defendants. There are three reasons for their enactment:\nIn Classical Athens, a five-year statute of limitations was established for almost all cases, exceptions being such as the prosecution of non-constitutional laws (which had no limitation). Demosthenes wrote that these statutes of limitations were adopted to control \"sycophants\" (professional accusers).\nThe limitation period generally begins when the plaintiff's cause of action accrues, meaning the date upon which the plaintiff is first able to maintain the cause of action in court, or when the plaintiff first becomes aware of a previous injury (for example, occupational lung diseases such as asbestosis).\nStatute of repose.\nA statute of repose limits the time within which an action may be brought based upon when a particular event occurred (such as the completion of construction of a building or the date of purchase of manufactured goods), and does not permit extensions. A statute of limitations is similar to a statute of repose but may be extended for a variety of reasons (such as the minority of the victim).\nFor example, most U.S. jurisdictions have passed statutes of repose for construction defects. If a person receives an electric shock due to a wiring defect that resulted from the builder's negligence during construction of a building, the builder is potentially liable for damages if the suit is brought within the time period defined by the statute, normally starting with the date that construction is substantially completed. After the statutory time period has passed, without regard to the nature or degree of the builder's negligence or misconduct, the statute of repose presents an absolute defense to the claim.\nStatutes of repose are sometimes controversial; manufacturers contend that they are necessary to avoid unfair litigation and encourage consumers to maintain their property. Alternatively, consumer advocates argue that they reduce incentives to manufacture durable products and disproportionately affect the poor, because manufacturers will have less incentive to ensure low-cost or \"bargain\" products are manufactured to exacting safety standards.\nTolling and the discovery rule.\nMany jurisdictions toll or suspend the limitation period in exceptional circumstances such as if the aggrieved person (plaintiff, appellant or petitioner) was a minor, or has filed a bankruptcy proceeding. In those instances, the running of limitations is tolled or paused, until the condition ends. Equitable tolling may also be applied if an individual may intimidate a moving party into not reporting or has been promised a suspended period.\nThe statute of limitations may begin when the harmful event, such as fraud or injury, occurs or it may begin when the harmful event is discovered. The U.S. Supreme Court has described the \"standard rule\" of when the time begins as \"when the plaintiff has a complete and present cause of action.\" The rule has existed since the 1830s. A \"discovery rule\" applies in other cases (including medical malpractice), or a similar effect may be applied by tolling.\nAccording to U.S. district judge Sean J. McLaughlin, the discovery rule does not apply to mass media such as newspapers and the Internet; the statute of limitations begins to run at the date of publication. In 2013, the U.S. Supreme Court unanimously ruled in \"Gabelli v. SEC\" that the discovery rule does not apply to U.S. Securities and Exchange Commission's investment-advisor-fraud lawsuits since one of the purposes of the agency is to root out fraud.\nIn private civil matters, the limitation period may generally be shortened or lengthened by agreement of the parties. Under the Uniform Commercial Code, the parties to a contract for sale of goods may reduce the limitation period to one year but not extend it.\nLimitation periods that are known as laches may apply in situations of equity; a judge will not issue an injunction if the requesting party waited too long to ask for it. Such periods are subject to broad judicial discretion.\nFor US military cases, the Uniform Code of Military Justice (UCMJ) states that all charges except those facing court-martial on a capital charge have a five-year statute of limitations. If the charges are dropped in all UCMJ proceedings except those headed for general court-martial, they may be reinstated, once only, for six months.\nPrescription.\nIn civil law countries, almost all lawsuits must be brought within a legally-determined period at the end of which the right of action is extinguished. This is known as liberative or extinctive prescription. Under Italian and Romanian law, criminal trials must be ended within a time limit.\nIn criminal cases, the public prosecutor must lay charges within a time limit which varies by jurisdiction and varies based on the nature of the charge, whose directives vary from country to country. Over the last decade of the 20th century, many United States jurisdictions significantly lengthened the statute of limitations for sex offenses, particularly against children, as a response to research and popular belief that a variety of causes can delay the recognition and reporting of crimes of this nature.\nCommon triggers for suspending the prescription include a defendant's fugitive status or the commission of a new crime. In some jurisdictions, a criminal may be convicted \"in absentia\". Prescription should not be confused with the need to prosecute within \"a reasonable delay\" as obligated by the European Court of Human Rights.\nLaws by region.\nInternational crimes.\nUnder international law, genocide, crimes against humanity and war crimes are usually not subject to the statute of limitations as codified in a number of multilateral treaties. States ratifying the Convention on the Non-Applicability of Statutory Limitations to War Crimes and Crimes Against Humanity agree to disallow limitations claims for these crimes. According to Article 29 of the Rome Statute of the International Criminal Court, genocide, crimes against humanity and war crimes \"shall not be subject to any statute of limitations\".\nAustralia.\nIn Australia, there are no statutes of limitation in criminal proceedings if the maximum penalty that can be imposed for an offence committed by an individual includes imprisonment for more than 6 months. For civil matters, the statutes of limitation are prescribed by each state or territory jurisdiction.\nVictoria.\nThe \"Limitations Act 1958\" allows 12 years for victims of child abuse to make a claim, with age 37 the latest at which a claim can be made. The police submitted evidence to a commission, the Victorian Inquiry into Church and Institutional Child Abuse (in existence since 2012) indicating that it takes an average of 24 years for a victim of child sexual abuse to go to the police. According to Attorney General Robert Clark, the government will remove statutes of limitations on criminal child abuse; victims of violent crime should be given additional time, as adults, to deal with the legal system. Offenders of minors and the disabled have used the statute of limitations to avoid detection and prosecution, moving from state to state and country to country; an example which was presented to the Victorian Inquiry was the Christian Brothers.\nAn argument for abolishing statutes of limitations for civil claims by minors and people under guardianship is ensuring that abuse of vulnerable people would be acknowledged by lawyers, police, organizations and governments, with enforceable penalties for organisations which have turned a blind eye in the past. Support groups such as SNAP Australia, Care Leavers Australia Network and Broken Rites have submitted evidence to the Victoria inquiry, and the Law Institute of Victoria has advocated changes to the statute of limitations.\nWestern Australia.\nThe \"Criminal Procedure Act 2004\" outlines the statute of limitations, stating that a simple offence (an offence which can only be brought to a magistrate's court, and cannot include more than 12 months' imprisonment as the maximum penalty) shall have a statute of limitations of 12 months. However, all crimes (offences which can be brought to a district court or the supreme court) have no statute of limitations. Furthermore, a person may be charged with a simple offence after 12 months' if the person consents to such a charge being laid, or if that offence has a different statute of limitations as provided by law.\nCanada.\nCriminal.\nA criminal statute of limitations does exist in Canada, although for most crimes it is rather weak. Offences under the \"Criminal Code\" fall into one of two base categories: summary and indictable, with indictable being the more serious of the two. Additionally, most offences are hybrid offenses, where they may be tried as either summary or indictable depending on the severity of the crime; this is done at the prosecutor's discretion.\nSummary proceedings have a limitation period of 12 months unless waived (such as under a plea deal). Hybrid offences cannot be prosecuted as summary after the limitation period, but can still be upgraded to indictable.\nNon-hybrid summary offences (e.g. causing a disturbance, nudity, trespassing at night, falsifying employment records) cannot be prosecuted at all after the limitation period. Few offences fall under this category.\nIndictable offences (e.g. murder, kidnapping, sexual assault, perjury) do not have a limitation period; a defendant can be charged at any future date. In sexual assault cases in particular, men and women have been charged and convicted more than 40 years after the abuse had been committed. \nHybrid offences (e.g. theft, assault, harassment, mischief) can be charged as indictable if prosecutors deem it to be in the public interest and serious enough to be worth their resources, making the limitation period of 12 months somewhat weak or even irrelevant in many instances. Someone who has committed a hybrid offence in the past can never be truly immune from prosecution simply because their crime is \"out of statute\", unlike in other jurisdictions. Some hybrid offences may have aggravating factors which automatically make them indictable offences (e.g. mischief causing actual danger to life, assault which causes the victim to be wounded, maimed or disfigured), removing the limitation period entirely.\nCivil.\nLimitation periods for civil cases vary by province.\nClaims filed in Federal Court are generally subject to the limitation period of the province it arises from; in other cases the limitation period is 6 years.\nFinland.\nIn Finland, the authority of a prosecuting official to bring charges for a crime expires after a set period of time has passed since the act. This period is 20, 10, 5, or 2, years depending on the seriousness of the offence. Offences punishable with life imprisonment, such as murder and treason, do not expire. Sexual offences committed against minors do not expire before the victim reaches 23 or 28 years of age, depending on the nature of the offence.\nGermany.\nIn Germany, the statute of limitations on crimes varies by type of crime, with the highest statute of limitation being 30 years for voluntary manslaughter (). Murder, genocide, crimes against humanity, war crimes and the crime of aggression have no statute of limitations.\nIn Germany, the crime of murder used to have a 20-year statute of limitations. In 1969, the statute of limitations for murder was extended from 20 to 30 years. The limitations were abolished altogether in 1979, in order to prevent Nazi criminals from avoiding criminal liability.\nFor most other criminal offences, the statute of limitations is set by Section 78(3) of the Criminal Code () as follows:\nIn the civil code (), the regular statute of limitations is three years (plus the time until the end of the calendar year); however, different terms between two and thirty years may apply in specific situations. For example, the term is only two years for claims for alleged defects of purchased goods, but 30 years for claims resulting from a court judgement (such as awarded damages).\nIndia.\nThe statute of limitations in India is defined by the Limitations Act, 1963.\nThe statute of limitations for criminal offences is governed by Sec. 468 of the Criminal Procedure Code.\nIndonesia.\nThe statutes of limitations in Indonesia are defined by articles 136-139 of Law No. 1 of 2023 on Criminal Code, and varies by type of crimes and ages of the perpetrators. According to article 136 of the Criminal Code, as well as article 7 and article 46 of Law No. 26 of 2000 on Human Rights Courts, the limits are as follows:\nFor most crimes, the prescriptive period begins from the following day after the crime is committed. However, exceptions are made for crimes of forgery, currency destruction, abduction, and hostage-taking. For the first two, the period is calculated from the following day after the forged goods or damaged currency is used, while for crimes of abduction and hostage-taking, it is calculated from the following day after the victim is released or dies as a direct result of the crime.\nNew Zealand.\nThe statutes of limitations in New Zealand are defined by section 25 of the Criminal Procedure Act 2011. The limits are as follows:\nNorway.\nThe statute of limitations on murder was abolished by a change in law on 1 July 2014, causing any murders committed after 1 July 1989 to have no statute of limitations. This led to the national police force implementing a new investigation group for old cases called the \"Cold Case\" group. The law was also changed to let cases involving domestic violence, forced marriage, human trafficking and genital mutilation to count from the day the victim turns 18 years old. Cases where the statute of limitations have already passed can not be extended due to the constitution preventing it.\nPhilippines.\nIn the Philippines, the Revised Penal Code has different limitation periods, based on the penalty of the crime:\nOther special laws have their own limitation periods. For crimes punished under the Revised Penal Code, the limitation period won't run if the offender is outside the Philippines, while for those punished under other laws, it does. Municipal ordinances have a limitation period of 2 months.\nSouth Korea.\nIn July 2015, the National Assembly abolished a 25-year limit on first degree murder; it had previously been extended from 15 to 25 years in December 2007.\nTurkey.\nTurkish Code of Obligations sets the general limitation period to ten years, which applies where the law does not provide a specific limitation period.\nThere is no statute of limitations for sexual offenses committed against minors, however, under both the Turkish Penal Code (article 99) and Turkish Civil Code (Law No. 2827).\nUnited Kingdom.\nThe United Kingdom has no statute of limitations for criminal offences beyond minor summary offences (offences tried exclusively in the magistrates' courts); the Magistrates' Courts Act 1980 requires that criminal proceedings for summary offences be brought within six months. To obtain a conviction in \"some road traffic offences\" (e.g. speeding), the Road Traffic Offenders Act 1988 requires that the driver must be notified within 14 days of the offence of the intention to prosecute.\nFor civil claims, the period of validity varies depending on the type of claim. For example, a claim (debt) from a simple contract can no longer be pursued after six years.\nUnited States.\nIn the United States, statutes of limitations may apply in criminal procedures and civil lawsuits. Statutes of limitations vary significantly among U.S. jurisdictions.\nA government agency is permitted by the Congress to create under federal regulations its own statute of limitations.\nRetroactive extensions.\nThe U.S. Supreme Court held in 2003 in \"Stogner v. California\" by a 5\u20134 majority that California's retroactive extension of the criminal statute of limitations for sexual offenses committed against minors was an unconstitutional ex post facto law.\nCivil statutes.\nA civil statute of limitations applies to a non-criminal legal action, including a tort or contract case. If the statute of limitations expires before a lawsuit is filed, the defendant may raise the statute of limitations as an affirmative defense to seek dismissal of the claim. The exact time period depends on both the state and the type of claim (contract claim, personal injury, fraud etc.). Most fall in the range of one to ten years, with two to three years being most common.\nCriminal statutes.\nA criminal statute of limitations defines a time period during which charges must be initiated for a criminal offense. If a charge is filed after the statute of limitations expires, the defendant may obtain dismissal of the charge.\nInitiation of charges.\nThe statute of limitations in a criminal case only runs until a criminal charge is filed and a warrant issued, even if the defendant is a fugitive. When the identity of a defendant is not known, some jurisdictions provide mechanisms to initiate charges and thus stop the statute of limitations from running. For example, some states allow an indictment of a John Doe defendant based upon a DNA profile derived from evidence obtained through a criminal investigation. Although rare, a grand jury can issue an indictment in absentia for high-profile crimes to get around an upcoming statute of limitations deadline. One example is the skyjacking of Northwest Orient Airlines Flight 305 by D. B. Cooper in 1971. The identity of D. B. Cooper remains unknown, and he was indicted under the name \"John Doe, aka Dan Cooper.\"\nHeinous crimes.\nCrimes which are widely considered heinous have no statute of limitations. Although there is usually no statute of limitations for murder (particularly first-degree murder), judges have been known to dismiss murder charges in cold cases if they feel that the delay violates the defendant's right to a speedy trial. For example, waiting many years for an alibi witness to die before commencing a murder trial would be unconstitutional.\nMilitary law.\nUnder the U.S. Uniform Code of Military Justice (UCMJ), desertion has no statute of limitations.\nMaritime Injury Law\nUnder https://, \"Except as otherwise provided by law, a civil action for damages for personal injury or death arising out of a maritime tort must be brought within 3 years after the cause of action arose.\" There are some exceptions to this, primarily with regard to Jones Act cases filed against the government, in which case the statute of limitations can be less than 2 years.\nExceptions.\nPursuant to the legal doctrine of tolling, U.S. jurisdictions recognize exceptions to statutes of limitation that may allow for the prosecution of a crime or civil lawsuit even after the statute of limitations would otherwise have expired. Some states stop the clock for a suspect who is not residing within the state.\nThe right to speedy trial may potentially derail a felony prosecution after many years have passed, including in states that have no statute of limitations for the charged offense.\nFraud on the court.\nWhen an officer of the court is found to have fraudulently presented facts to impair the court's impartial performance of its legal task, the act (known as \"fraud upon the court\") is not subject to a statute of limitation: \"This concept that the inherent power of federal courts to vacate a fraudulently obtained judgment\u2014even years after the judgment was entered\u2014has long been recognized by the Supreme Court.\" Fraud on the court can be done many ways and in any court. One of which can be \"where the court or a member is corrupted or influenced or influence is attempted or where the judge has not performed his judicial function \u2014 thus where the impartial functions of the court have been directly corrupted.\" Officer of the court includes any judge, law clerk, court clerk, lawyer, investigator, probation officer, referee, legal guardian, parenting-time expeditor, mediator, evaluator, administrator, special appointee, and/or anyone else whose influence is part of the judicial mechanism.\nContinuing-violations doctrine.\nIn tort law, if any person or entity commits a series of illegal acts against another person or entity (or in criminal law if a defendant commits a continuing crime) the limitation period may begin to run from the last act in the series. The entire chain of events can be tolled if the violations were continuing. Courts have explained that the continuing-violations doctrine \"tolls the statute of limitations in situations where a continuing pattern forms due to discriminatory acts which have been occurring over a period of time, as long as at least one incident of discrimination occurred within the limitations period.\" Whether the continuing-violations doctrine applies to a particular violation is subject to judicial discretion; it was said to apply to copyright infringement in the jurisdiction of the Seventh Circuit, but not in the jurisdiction of the Second Circuit.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26918", "revid": "210028", "url": "https://en.wikipedia.org/wiki?curid=26918", "title": "Submarine sandwich", "text": "Type of sandwich originating from the United States\nA submarine sandwich, commonly known as a sub, is a type of American cold or hot sandwich made from a submarine roll (an elongated bread roll) that is split lengthwise and filled with meats, cheeses, vegetables, and condiments.\nAlthough \"submarine\" or just \"sub\" is the general term for both the bread roll and sandwiches made with it in both the US and other English speaking nations, there are many local nicknames, especially in the northeastern United States, such as hoagie (Philadelphia metropolitan area and Western Pennsylvania English), hero (New York City English), Maine Italian (Maine English), grinder (New England English, Fulton County, NY), wedge (Westchester, NY) or spuckie (Boston English).\nHistory.\nThis sandwich type originated in several different Italian-American communities in the northeastern United States from the late 19th to mid-20th centuries. The popularity of the Italian-American sandwich grew from its origins in Connecticut, Pennsylvania, Delaware, Maryland, New York, New Jersey, Massachusetts, and Rhode Island to other parts of the United States. This was often due to local pizzerias beginning to add the sub to their menus.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Pizzerias may have been among the first Italian-American eateries, but even at the turn of the [20th] century distinctions were clear-cut as to what constituted a true ristorante. To be merely a pizza-maker was to be at the bottom of the culinary and social scale; so many pizzeria owners began offering other dishes, including the hero sandwich (also, depending on the region of the United States, called a 'wedge,' a 'hoagie,' a 'sub,' or a 'grinder') made on an Italian loaf of bread with lots of salami, cheese, and peppers.\u2014\u200a\nAs the sandwich's popularity grew, small restaurants, called hoagie shops or sub shops, which specialized in offering the sandwich, began to open all over the United States. \nThere are now many chain restaurants that specialize in subs across the US.\nThe sandwich is also often available at supermarkets, local delis, and convenience stores. They include Wawa, which annually runs a sub promotional event during the summer called Hoagiefest, and Publix, whose sandwiches are often referred to as \"pub subs\".\nEtymology.\nIn a 1987 article in \"American Speech\", linguists Edwin Eames and Howard Robboy identified thirteen different terms for the submarine sandwich in the United States.\nSubmarine.\nThe use of the term \"submarine\" or \"sub\" (after the resemblance of the roll to the shape of a submarine) is widespread in the United States and Canada. Some accounts source the name as originating in New London, Connecticut (site of a United States Navy submarine base from 1915 onwards) in the World War II era. Written advertisements from 1940 in Wilmington, Delaware indicate the term originated prior to the United States entering World War II.\nOne theory says the submarine sandwich was brought to the U.S. by Dominic Conti (1874\u20131954), an Italian immigrant who came to New York in the late-19th century. He supposedly named it \"submarine roll\" after seeing the recovered 1901 submarine called \"Fenian Ram\" in the Paterson Museum of New Jersey in 1928. His granddaughter said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;My grandfather came to this country circa 1895 from Montella, Italy. Around 1910, he started his grocery store, called Dominic Conti's Grocery Store, on Mill Street in Paterson, New Jersey where he was selling the traditional Italian sandwiches. His sandwiches were made from a recipe he brought with him from Italy, which consisted of a long crust roll, filled with cold cuts, topped with lettuce, tomatoes, peppers, onions, oil, vinegar, Italian herbs and spices, salt, and pepper. The sandwich started with a layer of cheese and ended with a layer of cheese (this was so the bread wouldn't get soggy).\nHoagie.\nThe term \"hoagie\" originated in the Philadelphia area. There are a number of hypotheses about the origin of the term: \nShortly after World War II, there were numerous varieties of the term in use throughout Philadelphia. By the 1940s, the spelling \"hoagie\" dominated less-used variations like \"hoogie\" and \"hoggie\". By 1955, restaurants throughout the area were using the term \"hoagie\". Listings in Pittsburgh show hoagies arriving in 1961 and becoming widespread in that city by 1966.\nFormer Philadelphia mayor (and later Pennsylvania governor) Ed Rendell declared the hoagie to be the \"Official Sandwich of Philadelphia\". However, there are claims that the hoagie was actually a product of nearby Chester, Pennsylvania. DiCostanza's in Boothwyn, Pennsylvania claims that the mother of DiConstanza's owner originated the hoagie in 1925 in Chester. DiCostanza relates the story that a customer came into the family deli and through an exchange matching the customer's requests and the deli's offerings, the hoagie was created. Additional spellings include \"hoagy\".\nWoolworth's to-go sandwich was called a \"hoagie\" in all of its U.S. stores. B\u00e1nh m\u00ec sandwiches are sometimes referred to as \"Vietnamese hoagies\" in Philadelphia.\nHero.\nThe New York term \"hero\" is first attested in 1937. The name is sometimes credited to the \"New York Herald Tribune\" food writer Clementine Paddleford in the 1930s, but there is no good evidence for the claim. It is also sometimes said that it is related to the \"gyro;\" that is unlikely as the \"gyro\" was unknown in the United States until the 1960s. \"Hero\" (plural usually \"heros\" not \"heroes\") remains the prevailing New York City term for most sandwiches on an oblong roll with a generally Italian flavor, in addition to the original described above. Pizzeria menus often include eggplant parmigiana, chicken parmigiana, and meatball heros, each served with sauce.\nGrinder.\nA common term in New England, especially Connecticut, Massachusetts, and Rhode Island is \"grinder;\" its origin has several possibilities. One theory says it is derived from Italian-American slang for a dock worker, among whom the sandwich was popular. Others say that it was called a grinder because the bread's hard crust required much chewing, and that it would \"grind one's teeth\". In Pennsylvania, New York, and parts of New England, the term \"grinder\" usually refers to a \"hot\" submarine sandwich (meatball, sausage, etc.), whereas a cold sandwich (e.g., cold cuts) is usually called a \"sub\". In the Philadelphia area, the term \"grinder\" is also applied to any hoagie that is toasted in the oven after assembly, whether or not it is made with traditionally hot ingredients.\nItalian.\nThe term \"Maine Italian\" or simply \"Italian\" is used in Maine. Local folklore claims that a baker named Giovanni Amato invented the Italian in 1899.\nThe traditional Maine Italian sandwich is prepared using a long, soft bread roll or bun with ham and bologna along with American cheese, tomato, onion, green bell pepper, Greek olives, pickles, olive oil or salad oil, salt and cracked black pepper. Additional ingredients, such as pepperoni, banana pepper, or lettuce may be added to the sandwich. The sandwich is often cut in half to make it easier to handle.\nWedge.\nThe term \"wedge\" is used in the New York counties of Dutchess, Putnam, and Westchester, as well as the Connecticut county of Fairfield\u2013four counties directly north of New York City. Some base the name \"wedge\" on a diagonal cut in the middle of the sandwich, creating two halves or \"wedges\", or a \"wedge\" cut out of the top half of the bread with the fillings \"wedged\" in between, or a sandwich that is served between two \"wedges\" of bread. It has been said that \"wedge\" is short for \"sandwich\", with the name having originated from an Italian deli owner located in Yonkers, who got tired of saying the whole word.\n\"Wedge\" or \"wedgie\" can also refer to a northeastern deli meat sandwich cooked on pizza dough or a style of club sandwich.\nSpukie.\nThe term \"spukie\" (\"spukkie\" or \"spuckie\") is unique to the city of Boston and derives from the Italian word \"spuccadella\", meaning \"long roll\". The word \"spuccadella\" is not typically found in Italian dictionaries, which may suggest that it could be a regional Italian dialect, or possibly a Boston Italian-American innovation. Spukie is typically heard in parts of Dorchester and South Boston. Some bakeries in Boston's North End neighborhood have homemade spuccadellas for sale.\nParty sub.\nA party sub is a particularly long submarine sandwich, usually cut into pieces and served to guests at parties.\nInternational popularity.\nSubs or their national equivalents were already popular in many European, Asian, and Australasian countries when late 20th-century franchisee chain restaurants such as Subway and fast food outlets made them even more popular and increased the prevalence of the word \"sub\". Many outlets offer non-traditional ingredient combinations. Major international chains include Firehouse Subs, Quiznos, Mr. Sub, Jersey Mike's, Jimmy John's, Potbelly Sandwich Shop, and the largest restaurant chain in the world, Subway. \nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26919", "revid": "32308078", "url": "https://en.wikipedia.org/wiki?curid=26919", "title": "Semitic languages", "text": "Branch of the Afroasiatic languages\nThe Semitic languages are a branch of the Afroasiatic language family. They include Arabic, \nAmharic, Tigrinya, Aramaic, Hebrew, Maltese, Modern South Arabian languages and numerous other ancient and modern languages. They are spoken by more than 460 million people across much of West Asia, North Africa, the Horn of Africa, Malta, and in large immigrant and expatriate communities in North America, Europe, and Australasia. The terminology was first used in the 1780s by members of the G\u00f6ttingen school of history, who derived the name from Shem (\u05e9\u05dd), one of the three sons of Noah in the Book of Genesis.\nArabic is by far the most widely spoken of the Semitic languages with million native speakers of all varieties, and it is the most spoken native language in Africa and West Asia. Other Semitic languages include Amharic ( million native speakers), Tigrinya ( million speakers), Hebrew (5 million native speakers), Tigre ( million speakers), and Maltese ( speakers). Arabic, Amharic, Hebrew, Tigrinya, and Maltese are considered national languages with an official status. \nSemitic languages occur in written form from a very early historical date in West Asia, with East Semitic Akkadian (also known as Assyrian and Babylonian) and Eblaite texts (written in a script adapted from Sumerian cuneiform) appearing from c.\u20092600 BCE in Mesopotamia and the northeastern Levant respectively. The only earlier attested languages are Sumerian and Elamite (2800 BCE to 550 BCE), both language isolates, and Egyptian (c.\u20093000 BCE), a sister branch within the Afroasiatic family, related to the Semitic languages but not part of them. Amorite appeared in Mesopotamia and the northern Levant c.\u20092100 BC, followed by the mutually intelligible Canaanite languages (including Hebrew, Phoenician, Moabite, Edomite, and Ammonite, and perhaps Ekronite, Amalekite and Sutean), the still spoken Aramaic, and Ugaritic during the 2nd millennium BC.\nMost scripts used to write Semitic languages are abjads\u00a0\u2013 a type of alphabetic script that omits some or all of the vowels, which is feasible for these languages because the consonants are the primary carriers of meaning in the Semitic languages. These include the Ugaritic, Phoenician, Aramaic, Hebrew, Syriac, Arabic, and ancient South Arabian alphabets. The Ge\u02bdez script, used for writing the Semitic languages of Ethiopia and Eritrea, is technically an abugida\u00a0\u2013 a modified abjad in which vowels are notated using diacritic marks added to the consonants at all times, in contrast with other Semitic languages which indicate vowels based on need or for introductory purposes. Maltese is the only Semitic language written in the Latin script and the only Semitic language to be an official language of the European Union.\nThe Semitic languages are notable for their nonconcatenative morphology. That is, word roots are not themselves syllables or words, but instead are isolated sets of consonants (usually three, making a so-called \"triliteral root\"). Words are composed from roots not so much by adding prefixes or suffixes, but rather by filling in the vowels between the root consonants, although prefixes and suffixes are often added as well. For example, in Arabic, the root meaning \"write\" has the form \"k-t-b\". From this root, words are formed by filling in the vowels and sometimes adding consonants, e.g. \u0643\u0650\u062a\u0627\u0628 kit\u0101b \"book\", \u0643\u064f\u062a\u064f\u0628 kutub \"books\", \u0643\u0627\u062a\u0650\u0628 k\u0101tib \"writer\", \u0643\u064f\u062a\u0651\u0627\u0628 kutt\u0101b \"writers\", \u0643\u064e\u062a\u064e\u0628 \"kataba\" \"he wrote\", \u064a\u0643\u062a\u064f\u0628 \"yaktubu\" \"he writes\", etc or the Hebrew equivalent root K-T-B \u05db\u05ea\u05d1 forming words like \u05db\u05b7\u05ea\u05b8\u05d1 katav he wrote, \u05d9\u05b4\u05db\u05ea\u05d5\u05d1 yichtov he will write, \u05db\u05d5\u05ea\u05b5\u05d1 kotev he writes or a writer, \u05de\u05b4\u05db\u05ea\u05b8\u05d1 michtav a letter, \u05d4\u05b4\u05db\u05ea\u05b4\u05d9\u05d1 hichtiv he dictated. The Hebrew Kaf alternatively becomes Khaf (as in Scottish \"loch\") depending on the letter preceding it.\nName and identification.\nThe similarity of the Hebrew, Arabic and Aramaic languages has been accepted by all scholars since medieval times. The languages were familiar to Western European scholars due to historical contact with neighbouring Near Eastern countries and through Biblical studies, and a comparative analysis of Hebrew, Arabic, and Aramaic was published in Latin in 1538 by Guillaume Postel. Almost two centuries later, Hiob Ludolf described the similarities between these three languages and the Ethio-Semitic languages. However, neither scholar named this grouping as \"Semitic\".\nThe term \"Semitic\" was created by members of the G\u00f6ttingen school of history, initially by August Ludwig von Schl\u00f6zer (1781), to designate the languages closely related to Arabic, Aramaic, and Hebrew. The choice of name was derived from Shem, one of the three sons of Noah in the genealogical accounts of the biblical Book of Genesis, or more precisely from the Koine Greek rendering of the name, \u03a3\u03ae\u03bc (S\u0113m). Johann Gottfried Eichhorn is credited with popularising the term, particularly via a 1795 article \"Semitische Sprachen\" (\"Semitic languages\") in which he justified the terminology against criticism that Hebrew and Canaanite were the same language despite Canaan being \"Hamitic\" in the Table of Nations:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In the Mosaic Table of Nations, those names which are listed as Semites are purely names of tribes who speak the so-called Oriental languages and live in Southwest Asia. As far as we can trace the history of these very languages back in time, they have always been written with syllabograms or with alphabetic script (never with hieroglyphs or pictograms); and the legends about the invention of the syllabograms and alphabetic script go back to the Semites. In contrast, all so called Hamitic peoples originally used hieroglyphs, until they here and there, either through contact with the Semites, or through their settlement among them, became familiar with their syllabograms or alphabetic script, and partly adopted them. Viewed from this aspect too, with respect to the alphabet used, the name \"Semitic languages\" is completely appropriate.\nPreviously these languages had been commonly known as the \"Oriental languages\" in European literature. In the 19th century, \"Semitic\" became the conventional name; however, an alternative name, \"Syro-Arabian languages\", was later introduced by James Cowles Prichard and used by some writers.\nHistory.\nAncient Semitic-speaking peoples.\nSemitic languages were spoken and written across much of the Middle East and Asia Minor during the Bronze Age and Iron Age, the earliest attested being the East Semitic Akkadian of Mesopotamia (Akkad, Assyria, Isin, Larsa, and Babylonia) from the third millennium BC.\nThe origin of Semitic-speaking peoples is still under discussion. Several locations were proposed as possible sites of a prehistoric origin of Semitic-speaking peoples: Mesopotamia, the Levant, Ethiopia, the Eastern Mediterranean region, the Arabian Peninsula, and North Africa. According to a 2009 study, the Semitic languages originated in the Levant c.\u20093750 BC, and were introduced to the Horn of Africa c. 800 BC from the southern Arabian Peninsula. Others assign the arrival of Semitic speakers in the Horn of Africa to a much earlier date. According to another hypothesis, Semitic originated from an offshoot of a still earlier language in North Africa; desertification led to emigration in the fourth millennium BC to both what is now Ethiopia and northeast out of Africa into West Asia.\nThe various extremely closely related and mutually intelligible Canaanite languages, a branch of the Northwest Semitic languages included Edomite, Hebrew, Ammonite, Moabite, Phoenician (Punic/Carthaginian), Samaritan Hebrew, and Ekronite. They were spoken in what is today Israel and the Palestinian territories, Syria, Lebanon, Jordan, the northern Sinai Peninsula, some northern and eastern parts of the Arabian Peninsula, southwest fringes of Turkey, and in the case of Phoenician, coastal regions of Tunisia (Carthage), Libya, Algeria, and parts of Morocco, Spain, and possibly in Malta and other Mediterranean islands. Ugaritic, a Northwest Semitic language closely related to but distinct from the Canaanite group was spoken in the kingdom of Ugarit in north western Syria.\nA hybrid Canaano-Akkadian language also emerged in Canaan (Israel and the Palestinian territories, Jordan, Lebanon) during the 14th century BC, incorporating elements of the Mesopotamian East Semitic Akkadian language of Assyria and Babylonia with the West Semitic Canaanite languages.\nAramaic, a still living ancient Northwest Semitic language, first attested in the 12th century BC in the northern Levant, gradually replaced the East Semitic and Canaanite languages across much of the Near East, particularly after being adopted as the lingua franca of the vast Neo-Assyrian Empire (911\u2013605 BC) by Tiglath-Pileser III during the 8th century BC, and being retained by the succeeding Neo-Babylonian and Achaemenid Empires.\nThe \"Chaldean language\" (not to be confused with Aramaic or its Biblical variant, sometimes referred to as \"Chaldean\") was a Northwest Semitic language, possibly closely related to Aramaic, but no examples of the language remain, as after settling in south eastern Mesopotamia from the Levant during the 9th century BC, the Chaldeans appear to have rapidly adopted the Akkadian and Aramaic languages of the indigenous Mesopotamians.\nOld South Arabian languages (classified as South Semitic and therefore distinct from the Central-Semitic Arabic) were spoken in the kingdoms of Dilmun, Sheba, Ubar, Socotra, and Magan, which in modern terms encompassed part of the eastern coast of Saudi Arabia, and Bahrain, Qatar, Oman, and Yemen. South Semitic languages are thought to have spread to the Horn of Africa circa 8th century BC where the Ge\u02bdez language emerged (though the direction of influence remains uncertain).\nFirst century to twentieth century CE.\nClassical Syriac, a 200 CE Eastern Middle Aramaic dialect, used as a liturgical language in Mesopotamia, the Levant, and Kerala, India, rose to importance as a literary language of early Christianity in the third to fifth centuries and continued into the early Islamic era.\nThe Arabic language, although originating in the Arabian Peninsula, first emerged in written form in the 1st to 4th centuries CE in the southern regions of The Levant. With the advent of the early Arab conquests of the seventh and eighth centuries, Classical Arabic eventually replaced many (but not all) of the indigenous Semitic languages and cultures of the Near East. Both the Near East and North Africa saw an influx of Muslim Arabs from the Arabian Peninsula, followed later by non-Semitic Muslim Iranian and Turkic peoples. The previously dominant Aramaic dialects maintained by the Assyrians, Babylonians and Persians gradually began to be sidelined, however descendant dialects of Eastern Aramaic (including Suret (Assyrian and Chaldean varieties), Turoyo, and Mandaic) survive to this day among the Assyrians and Mandaeans of northern and southern Iraq, northwestern Iran, northeastern Syria and southeastern Turkey, with up to a million fluent speakers. Syriac is a recognized language in Iraq, furthermore, Mesopotamian Arabic is one of the most Syriac influenced dialects of Arabic, due to Syriac, the dialect of Edessa specifically, having originated in Mesopotamia. Meanwhile Western Aramaic is now only spoken by a few thousand Christian and Muslim Arameans (Syriacs) in western Syria. The Arabs spread their Central Semitic language to North Africa (Egypt, Libya, Tunisia, Algeria, Morocco, and northern Sudan and Mauritania), where it gradually replaced Egyptian Coptic and many Berber languages (although Berber is still largely extant in many areas), and for a time to the Iberian Peninsula (modern Spain, Portugal, and Gibraltar) and Malta.\nWith the patronage of the caliphs and the prestige of its liturgical status, Arabic rapidly became one of the world's main literary languages. Its spread among the masses took much longer, however, as many (although not all) of the native populations outside the Arabian Peninsula only gradually abandoned their languages in favour of Arabic. As Bedouin tribes settled in conquered areas, it became the main language of not only central Arabia, but also Yemen, the Fertile Crescent, and Egypt. Most of the Maghreb followed, specifically in the wake of the Banu Hilal's incursion in the 11th century, and Arabic became the native language of many inhabitants of al-Andalus. After the collapse of the Nubian kingdom of Dongola in the 14th century, Arabic began to spread south of Egypt into modern Sudan; soon after, the Beni \u1e24ass\u0101n brought Arabization to Mauritania. A number of Modern South Arabian languages distinct from Arabic still survive, such as Soqotri, Mehri and Shehri which are mainly spoken in Socotra, Yemen, and Oman.\nMeanwhile, the Semitic languages that had arrived from southern Arabia in the 8th century BC were diversifying in Ethiopia and Eritrea, where, under heavy Cushitic influence, they split into a number of languages, including Amharic and Tigrinya. With the expansion of Ethiopia under the Solomonic dynasty, Amharic, previously a minor local language, spread throughout much of the country, replacing both Semitic (such as Gafat) and non-Semitic (such as Weyto) languages, and replacing Ge\u02bdez as the principal literary language (though Ge\u02bdez remains the liturgical language for Christians and Jews of Ethiopean descent in the region); this spread continues to this day, with Qimant set to disappear in another generation.\nPresent distribution.\nArabic is currently the native language of majorities from Mauritania to Oman, and from Iraq to Sudan. Classical Arabic is the language of the Quran. It is also studied widely in the non-Arabic-speaking Muslim world. The Maltese language is a descendant of the extinct Siculo-Arabic, a variety of Maghrebi Arabic formerly spoken in Sicily. The modern Maltese alphabet is based on the Latin script with the addition of some letters with diacritic marks and digraphs. Maltese is the only Semitic official language within the European Union.\nSuccessful as second languages far beyond their numbers of contemporary first-language speakers, a few Semitic languages today are the base of the sacred literature of some of the world's major religions, including Islam (Arabic), Judaism (Hebrew and Aramaic (Biblical and Talmudic)), churches of Syriac Christianity (Classical Syriac) and Ethiopian and Eritrean Orthodox Christianity (Ge\u02bdez). Millions learn these as a second language (or an archaic version of their modern tongues): many Muslims learn to read and recite the Qur'an and Jews speak and study Biblical Hebrew, the language of the Torah, Midrash, and other Jewish scriptures. The followers of the Assyrian Church of the East, Chaldean Catholic Church, Ancient Church of the East, Assyrian Pentecostal Church, Assyrian Evangelical Church, and the Syriac Orthodox Church speak Eastern Aramaic languages and use Classical Syriac as their liturgical language. Classical Syriac is also used liturgically by the primarily Arabic-speaking followers of the Maronite Church, Syriac Catholic Church, and was originally the liturgical language of the Melkites in Antioch, and ancient Syria. Koine Greek and Classical Arabic are the main liturgical languages of Eastern Orthodox Christians in the Middle East, who compose the patriarchates of Antioch, Jerusalem, and Alexandria. Mandaic is both spoken and used as a liturgical language by the Mandaeans. Although the majority of Neo-Aramaic dialects spoken today are descended from Eastern varieties, Western Neo-Aramaic is still spoken in two villages in Syria. Despite the ascendancy of Arabic in the Middle East, other Semitic languages still exist. \nBiblical Hebrew, long extinct as a colloquial language and in use only as a Jewish literary, intellectual, and liturgical language, was revived in spoken form at the end of the 19th century. Modern Hebrew is the main language of Israel, with easily understandable Biblical Hebrew remaining as the language of the Bible, Jewish liturgy and religious scholarship of Jews worldwide. Modern Hebrew is the only example of an ancient tongue revived in modern times to become a vibrant, modern language used by Israel's 10 million citizens and many more in other countries. \nIn Arab-dominated Yemen and Oman, on the southern rim of the Arabian Peninsula, a few tribes continue to speak Modern South Arabian languages such as Mahri and Soqotri. These languages differ greatly from both the surrounding Arabic dialects and from the languages of the Old South Arabian inscriptions.\nHistorically linked to the peninsular homeland of Old South Arabian, of which only one language, Razihi, remains, Ethiopia and Eritrea contain a substantial number of Semitic languages; the most widely spoken are Amharic in Ethiopia, Tigre in Eritrea, and Tigrinya in both. Amharic is the official language of Ethiopia. Tigrinya is a working language in Eritrea. Tigre is spoken by over one million people in the northern and central Eritrean lowlands and parts of eastern Sudan. A number of Gurage languages are spoken by populations in the semi-mountainous region of central Ethiopia, while Harari is restricted to the city of Harar. Ge\u02bdez remains the liturgical language for certain groups of Christians in Ethiopia and in Eritrea and Ethiopean Jews.\nPhonology.\nThe phonologies of the attested Semitic languages are presented here from a comparative point of view (see Proto-Semitic language#Phonology for details on the phonological reconstruction of Proto-Semitic used in this article). The reconstruction of Proto-Semitic (PS) was originally based primarily on Arabic, whose phonology and morphology (particularly in Classical Arabic) is very conservative, and which preserves as contrastive 28 out of the evident 29 consonantal phonemes. with *s and *\u0161 merging into Arabic and *\u015b becoming Arabic .\nNote: the fricatives *s, *z, *\u1e63, *\u015b, *\u1e63\u0301, and *\u1e71 may also be interpreted as affricates (/t\u0361s/, /d\u0361z/, /t\u0361s\u02bc/, /t\u0361\u026c/, /t\u0361\u026c\u02bc/, and /t\u0361\u03b8\u02bc/), as discussed in .\nThis comparative approach is natural for the consonants, as sound correspondences among the consonants of the Semitic languages are very straightforward for a family of its time depth. Sound shifts affecting the vowels are more numerous and, at times, less regular.\nConsonants.\nEach Proto-Semitic phoneme was reconstructed to explain a certain regular sound correspondence between various Semitic languages. Note that Latin letter values (\"italicized\") for extinct languages are a question of transcription; the exact pronunciation is not recorded.\nMost of the attested languages have merged a number of the reconstructed original fricatives, though South Arabian retains all fourteen (and has added a fifteenth from *p &gt; f).\nIn Aramaic and Hebrew, all non-emphatic stops occurring singly after a vowel were softened to fricatives, leading to an alternation that was often later phonemicized as a result of the loss of gemination.\nIn languages exhibiting pharyngealization of emphatics, the original velar emphatic has rather developed to a uvular stop .\nNote: the fricatives *s, *z, *\u1e63, *\u015b, *\u1e63\u0301, and *\u1e71 may also be interpreted as affricates (/t\u0361s/, /d\u0361z/, /t\u0361s\u02bc/, /t\u0361\u026c/, /t\u0361\u026c\u02bc/, and /t\u0361\u03b8\u02bc/).\nNotes:\nPlain sibilants.\nSibilants have been one of the aspects of Semitic phonology that historical linguists have taken the most interest in, and Semiticists are nearly unanimous in the opinion that Proto-Semitic contained three plain sibilants, referred to by the shorthand S1, S2, and S3, or as \u0161, \u015b, and s. The realizations of these phonemes in earlier times is debated, with hypotheses ranging from a palatal for S1, and or for S3, to plain for S1 and for S3. \nInterestingly, the point of least controversy is the realization of S2, widely accepted to be lateral , In spite of the fact that this phoneme has completely merged with S1 or S3 in every other Semitic language outside of Modern South Arabian languages, such that the most widely-spoken Semitic languages (Arabic, Amharic, Hebrew and Tigrinya) have a two-way sibilant distinction rather than the original three-way distinction. This merger occurred at different times, and in different ways across Semitic which has led to the non-correspondence of, for example, Arabic, Hebrew and Shehri (Jibbali) words for \u2018ten\u2019 from Proto-Semitic (\u0295-s\u2082-r).\nNotes: s\u2081 (\u0161) is , and (in Soqotri) - and (for some speakers of Jibbali).\nThe following table shows the development of the various fricatives in Hebrew, Aramaic, Arabic and Maltese through cognate words:\nVowels.\nProto-Semitic vowels are, in general, harder to deduce due to the nonconcatenative morphology of Semitic languages. The history of vowel changes in the languages makes drawing up a complete table of correspondences impossible, so only the most common reflexes can be given:\nGrammar.\nThe Semitic languages share a number of grammatical features, although variation \u2014 both between separate languages, and within the languages themselves \u2014 has naturally occurred over time.\nWord order.\nThe reconstructed default word order in Proto-Semitic is verb\u2013subject\u2013object (VSO), possessed\u2013possessor (NG), and noun\u2013adjective (NA). This was still the case in Classical Arabic and Biblical Hebrew, e.g. Classical Arabic \u0631\u0623\u0649 \u0645\u062d\u0645\u062f \u0641\u0631\u064a\u062f\u0627 \"ra'\u0101 mu\u0127ammadun far\u012bdan\". (literally \"saw Muhammad Farid\", \"Muhammad saw Farid\"). In the modern Arabic vernaculars, however, as well as sometimes in Modern Standard Arabic (the modern literary language based on Classical Arabic) and Modern Hebrew, the classical VSO order has given way to SVO. Modern Ethiopian Semitic languages follow a different word order: SOV, possessor\u2013possessed, and adjective\u2013noun; however, the oldest attested Ethiopian Semitic language, Ge\u02bdez, was VSO, possessed\u2013possessor, and noun\u2013adjective. Akkadian was also predominantly SOV.\nCases in nouns and adjectives.\nThe proto-Semitic three-case system (nominative, accusative and genitive) with differing vowel endings (-u, -a -i), fully preserved in Qur'anic Arabic (see \u02beI\u02bfrab), Akkadian and Ugaritic, has disappeared everywhere in the many colloquial forms of Semitic languages. Modern Standard Arabic maintains such case distinctions, although they are typically lost in free speech due to colloquial influence. An accusative ending \"-n\" is preserved in Ethiopian Semitic. In the northwest, the scarcely attested Samalian reflects a case distinction in the plural between nominative \"-\u016b\" and oblique \"-\u012b\" (compare the same distinction in Classical Arabic). Additionally, Semitic nouns and adjectives had a category of state, the indefinite state being expressed by nunation.\nNumber in nouns.\nSemitic languages originally had three grammatical numbers: singular, dual, and plural. Classical Arabic still has a mandatory dual (i.e. it must be used in all circumstances when referring to two entities), marked on nouns, verbs, adjectives and pronouns. Many contemporary dialects of Arabic still have a dual, as in the name for the nation of Bahrain (\"ba\u0127r\" \"sea\" + \"-ayn\" \"two\"), although it is marked only on nouns. It also occurs in Hebrew in a few nouns (\"\u0161ana\" means \"one year\", \"\u0161natayim\" means \"two years\", and \"\u0161anim\" means \"years\"), but for those it is obligatory. The curious phenomenon of broken plurals\u00a0\u2013 e.g. in Arabic, \"sadd\" \"one dam\" vs. \"sud\u016bd\" \"dams\"\u00a0\u2013 found most profusely in the languages of Arabia and Ethiopia, may be partly of proto-Semitic origin, and partly elaborated from simpler origins.\nVerb aspect and tense.\nAll Semitic languages show two quite distinct styles of morphology used for conjugating verbs. \"Suffix conjugations\" take suffixes indicating the person, number and gender of the subject, which bear some resemblance to the pronominal suffixes used to indicate direct objects on verbs (\"I saw him\") and possession on nouns (\"his dog\"). So-called \"prefix conjugations\" actually takes both prefixes and suffixes, with the prefixes primarily indicating person (and sometimes number or gender), while the suffixes (which are completely different from those used in the suffix conjugation) indicate number and gender whenever the prefix does not mark this. The prefix conjugation is noted for a particular pattern of \"\" prefixes where (1) a \"t-\" prefix is used in the singular to mark the second person and third-person feminine, while a \"y-\" prefix marks the third-person masculine; and (2) identical words are used for second-person masculine and third-person feminine singular. The prefix conjugation is extremely old, with clear analogues in nearly all the families of Afroasiatic languages (i.e. at least 10,000 years old). The table on the right shows examples of the prefix and suffix conjugations in Classical Arabic, which has forms that are close to Proto-Semitic.\nIn Proto-Semitic, as still largely reflected in East Semitic, prefix conjugations are used both for the past and the non-past, with different vocalizations. Cf. Akkadian \"niprus\" \"we decided\" (preterite), \"niptaras\" \"we have decided\" (perfect), \"niparras\" \"we decide\" (non-past or imperfect), vs. suffix-conjugated \"pars\u0101nu\" \"we are/were/will be deciding\" (stative). Some of these features, e.g. gemination indicating the non-past/imperfect, are generally attributed to Afroasiatic. Proto-Semitic had an additional form, the jussive, which was distinguished from the preterite only by the position of stress: the jussive had final stress while the preterite had non-final (retracted) stress.\nThe West Semitic languages significantly reshaped the system. The most substantial changes occurred in the Central Semitic languages (the ancestors of modern Hebrew, Arabic and Aramaic). Essentially, the old prefix-conjugated jussive or preterite became a new non-past (or imperfect), while the stative became a new past (or perfect), and the old prefix-conjugated non-past (or imperfect) with gemination was discarded. New suffixes were used to mark different moods in the non-past, e.g. Classical Arabic \"-u\" (indicative), \"-a\" (subjunctive), vs no suffix (jussive). It is not generally agreed whether the systems of the various Semitic languages are better interpreted in terms of tense, i.e. past vs. non-past, or aspect, i.e. perfect vs. imperfect. A special feature in classical Hebrew is the waw-consecutive, prefixing a verb form with the letter waw in order to change its tense or aspect. The South Semitic languages show a system somewhere between the East and Central Semitic languages.\nLater languages show further developments. In the modern varieties of Arabic, for example, the old mood suffixes were dropped, and new mood prefixes developed (e.g. \"bi-\" for indicative vs. no prefix for subjunctive in many varieties). In the extreme case of Neo-Aramaic, the verb conjugations have been entirely reworked under Iranian influence.\nMorphology: triliteral roots.\nAll Semitic languages exhibit a unique pattern of stems called Semitic roots consisting typically of triliteral, or three-consonant consonantal roots (two- and four-consonant roots also exist), from which nouns, adjectives, and verbs are formed in various ways (e.g., by inserting vowels, doubling consonants, lengthening vowels or by adding prefixes, suffixes, or infixes).\nFor instance, the root \"k-t-b\" (dealing with \"writing\" generally) yields in Arabic:\n\"katabtu\" \u0643\u064e\u062a\u064e\u0628\u0652\u062a\u064f or \u0643\u062a\u0628\u062a \"I wrote\" (f and m)\n\"yuktab(u)\" \u064a\u064f\u0643\u0652\u062a\u064e\u0628 or \u064a\u0643\u062a\u0628 \"being written\" (masculine)\n\"tuktab(u)\" \u062a\u064f\u0643\u062a\u064e\u0628 or \u062a\u0643\u062a\u0628 \"being written\" (feminine)\n\"yatak\u0101tab\u016bn(a)\" \u064a\u064e\u062a\u064e\u0643\u064e\u0627\u062a\u064e\u0628\u064f\u0648\u0646\u064e or \u064a\u062a\u0643\u0627\u062a\u0628\u0648\u0646 \"they write to each other\" (masculine)\n\"istikt\u0101b\" \u0627\u0650\u0633\u062a\u0650\u0643\u062a\u0627\u0628 or \u0627\u0633\u062a\u0643\u062a\u0627\u0628 \"causing to write\"\nkit\u0101b \u0643\u0650\u062a\u064e\u0627\u0628 or \u0643\u062a\u0627\u0628 \"book\" (the hyphen shows end of stem before various case endings)\nkutayyib \u0643\u064f\u062a\u064e\u064a\u0650\u0651\u0628 or \u0643\u062a\u064a\u0628 \"booklet\" (diminutive)\n\"kit\u0101bat\" \u0643\u0650\u062a\u064e\u0627\u0628\u064e\u0629 or \u0643\u062a\u0627\u0628\u0629 \"writing\"\nkutt\u0101b \u0643\u064f\u062a\u0627\u0628 or \u0643\u062a\u0627\u0628 \"writers\" (broken plural)\n\"katabat\" \u0643\u064e\u062a\u064e\u0628\u064e\u0629 or \u0643\u062a\u0628\u0629 \"clerks\" (broken plural)\n\"maktab\" \u0645\u064e\u0643\u062a\u064e\u0628 or \u0645\u0643\u062a\u0628 \"desk\" or \"office\"\n\"maktabat\" \u0645\u064e\u0643\u062a\u064e\u0628\u0629 or \u0645\u0643\u062a\u0628\u0629 \"library\" or \"bookshop\"\n\"makt\u016bb\" \u0645\u064e\u0643\u062a\u0648\u0628 or \u0645\u0643\u062a\u0648\u0628 \"written\" (participle) or \"postal letter\" (noun)\n\"kat\u012bbat\" \u0643\u064e\u062a\u064a\u0628\u0629 or \u0643\u062a\u064a\u0628\u0629 \"squadron\" or \"document\"\n\"iktit\u0101b\" \u0627\u0650\u0643\u062a\u0650\u062a\u0627\u0628 or \u0627\u0643\u062a\u062a\u0627\u0628 \"registration\" or \"contribution of funds\"\n\"muktatib\" \u0645\u064f\u0643\u062a\u064e\u062a\u0650\u0628 or \u0645\u0643\u062a\u062a\u0628 \"subscription\"\nand the same root in Hebrew:\n\"k\u0101\u1e6fa\u1e07ti\" \u05db\u05ea\u05d1\u05ea\u05d9 or \u05db\u05b8\u05bc\u05ea\u05b7\u05d1\u05b0\u05ea\u05b4\u05bc\u05d9 \"I wrote\"\nkatt\u0101\u1e07 \u05db\u05ea\u05d1 or \u05db\u05b7\u05bc\u05ea\u05b8\u05bc\u05d1 \"reporter\" (\"m\")\n\"katte\u1e07e\u1e6f\" \u05db\u05ea\u05d1\u05ea or \u05db\u05b7\u05bc\u05ea\u05b8\u05bc\u05d1\u05b6\u05ea \"reporter\" (\"f\")\nkatt\u0101\u1e07\u0101\" \u05db\u05ea\u05d1\u05d4 or \u05db\u05b7\u05bc\u05ea\u05b8\u05bc\u05d1\u05b8\u05d4 \"article\" (plural katt\u0101\u1e07\u014d\u1e6f\" \u05db\u05ea\u05d1\u05d5\u05ea)\n\"mi\u1e35t\u0101\u1e07\" \u05de\u05db\u05ea\u05d1 or \u05de\u05b4\u05db\u05b0\u05ea\u05b8\u05bc\u05d1 \"postal letter\" (plural \"mi\u1e35t\u0101\u1e07\u012bm\" \u05de\u05db\u05ea\u05d1\u05d9\u05dd)\n\"mi\u1e35t\u0101\u1e07\u0101\" \u05de\u05db\u05ea\u05d1\u05d4 \"writing desk\" (plural \"mi\u1e35t\u0101\u1e07\u014d\u1e6f\" \u05de\u05db\u05ea\u05d1\u05d5\u05ea)\nk\u0259\u1e6f\u014d\u1e07e\u1e6f\" \u05db\u05ea\u05d5\u05d1\u05ea \"address\" (plural k\u0259\u1e6f\u014d\u1e07\u014d\u1e6f\" \u05db\u05ea\u05d5\u05d1\u05d5\u05ea)\nk\u0259\u1e6f\u0101\u1e07 \u05db\u05ea\u05d1 \"handwriting\"\nk\u0101\u1e6f\u016b\u1e07 \u05db\u05ea\u05d5\u05d1 \"written\" (\"f\" \"k\u0259\u1e6f\u016b\u1e07\u0101\" \u05db\u05ea\u05d5\u05d1\u05d4)\n\"hi\u1e35t\u012b\u1e07\" \u05d4\u05db\u05ea\u05d9\u05d1 \"he dictated\" (\"f\" \"hi\u1e35t\u012b\u1e07\u0101\" \u05d4\u05db\u05ea\u05d9\u05d1\u05d4)\n\"hi\u1e6fkatt\u0113\u1e07\" \u05d4\u05ea\u05db\u05ea\u05d1 \"he corresponded (\"f\" \"hi\u1e6fkatt\u0259\u1e07\u0101\" \u05d4\u05ea\u05db\u05ea\u05d1\u05d4)\n\"ni\u1e35ta\u1e07\" \u05e0\u05db\u05ea\u05d1 \"it was written\" (\"m\")\n\"ni\u1e35t\u0259\u1e07\u0101\" \u05e0\u05db\u05ea\u05d1\u05d4 \"it was written\" (\"f\")\nk\u0259\u1e6f\u012b\u1e07 \u05db\u05ea\u05d9\u05d1 \"spelling\" (\"m\")\n\"ta\u1e35t\u012b\u1e07\" \u05ea\u05db\u05ea\u05d9\u05d1 \"prescript\" (\"m\")\n\"m\u0259'\u1e35utt\u0101\u1e07 \u05de\u05db\u05d5\u05ea\u05d1 \"addressee\" (\"me\u1e35utte\u1e07\"'e\u1e6f\" \u05de\u05db\u05d5\u05ea\u05d1\u05ea \"f\")\n\"k\u0259\u1e6fubb\u0101\" \u05db\u05ea\u05d5\u05d1\u05d4 \"ketubah (a Jewish marriage contract)\" (\"f\")\nIn Tigrinya and Amharic, this root was used widely but is now seen as an archaic form. Ethiopic-derived languages use different roots for things that have to do with writing (and in some cases counting). The primitive root \"\u1e63-f\" and the trilateral root stems \"m-\u1e63-f\", \"\u1e63-h-f\", and \"\u1e63-f-r\" are used. This root also exists in other Semitic languages, such as Hebrew: \"sep\u0304er\" \"book\", \"s\u014dp\u0304er\" \"scribe\", \"misp\u0101r\" \"number\", and \"sipp\u016br\" \"story\". This root also exists in Arabic and is used to form words with a close meaning to \"writing\", such as \"\u1e63a\u1e25\u0101fa\" \"journalism\", and \"\u1e63a\u1e25\u012bfa\" \"newspaper\" or \"parchment\".\nVerbs in other non-Semitic Afroasiatic languages show similar radical patterns, but more usually with biconsonantal roots; e.g. Kabyle \"afeg\" means \"fly!\", while \"affug\" means \"flight\", and \"yufeg\" means \"he flew\" (compare with Hebrew, where \"hap\u0304l\u0113\u1e21\" means \"set sail!\", \"hap\u0304l\u0101\u1e21\u0101\" means \"a sailing trip\", and \"hip\u0304l\u012b\u1e21\" means \"he sailed\", while the unrelated \"\u0295\u016bp\u0304\", \"t\u0259\u0295\u016bp\u0304\u0101\", and \"\u0295\u0101p\u0304\" pertain to flight).\nCardinal numerals.\nThese are the basic numeral stems without feminine suffixes. In most older Semitic languages, the forms of the numerals from 3 to 10 exhibit polarity of gender (also called \"chiastic concord\" or \"reverse agreement\"), i.e. if the counted noun is masculine, the numeral would be feminine and vice versa.\nTypology.\nSome early Semitic languages are speculated to have had weak ergative features.\nCommon vocabulary.\nDue to the Semitic languages' common origin, they share some words and roots. Others differ. For example:\nTerms given in brackets are not derived from the respective Proto-Semitic roots, though they may also derive from Proto-Semitic (as does e.g. Arabic \"d\u0101r\", cf. Biblical Hebrew \"d\u014dr\" \"dwelling\").\nSometimes, certain roots differ in meaning from one Semitic language to another. For example, the root \"b-y-\u1e0d\" in Arabic has the meaning of \"white\" as well as \"egg\", whereas in Hebrew it only means \"egg\". The root \"l-b-n\" means \"milk\" in Arabic, but the color \"white\" in Hebrew. The root \"l-\u1e25-m\" means \"meat\" in Arabic, but \"bread\" in Hebrew and \"cow\" in Ethiopian Semitic; the original meaning was most probably \"food\". The word \"medina\" (root: \"d-y-n\"/\"d-w-n\") has the meaning of \"metropolis\" in Amharic, \"city\" in Arabic and Ancient Hebrew, and \"State\" in Modern Hebrew.\nThere is sometimes no relation between the roots. For example, \"knowledge\" is represented in Hebrew by the root \"y-d-\u02bf\", but in Arabic by the roots \"\u02bf-r-f\" and \"\u02bf-l-m\" and in Ethiosemitic by the roots \"\u02bf-w-q\" and \"f-l-\u1e6d\".\nFor more comparative vocabulary lists, see the Wiktionary appendix List of Proto-Semitic stems.\nClassification.\nThere are six fairly uncontroversial nodes within the Semitic languages: East Semitic, Northwest Semitic, North Arabian, Old South Arabian (also known as Sayhadic), Modern South Arabian, and Ethiopian Semitic. These are generally grouped further, but there is ongoing debate as to which belong together. The classification based on shared innovations given below, established by Robert Hetzron in 1976 and with later emendations by John Huehnergard and Rodgers as summarized in Hetzron 1997, is the most widely accepted today. In particular, several Semiticists still argue for the traditional (partially nonlinguistic) view of Arabic as part of South Semitic, and a few (e.g. Alexander Militarev or the German-Egyptian professor Arafa Hussein Mustafa) see Modern South Arabian as a third branch of Semitic alongside East and West Semitic, rather than as a subgroup of South Semitic. However, a new classification groups Old South Arabian as Central Semitic instead.\nRoger Blench notes that the Gurage languages are highly divergent and wonders whether they might not be a primary branch, reflecting an origin of Afroasiatic in or near Ethiopia. At a lower level, there is still no general agreement on where to draw the line between \"languages\" and \"dialects\"\u00a0\u2013 an issue particularly relevant in Arabic, Aramaic and Gurage\u00a0\u2013 and the strong mutual influences between Arabic dialects render a genetic subclassification of them particularly difficult.\nA computational phylogenetic analysis by Kitchen et al. (2009) considers the Semitic languages to have originated in the Levant c.\u20093750 BCE during the Early Bronze Age, with early Ethiosemitic originating from southern Arabia c.\u2009800 BCE. Evidence for gene movements consistent with this were found in Almarri et al. (2021).\nThe Himyaritic and Sutean languages appear to have been Semitic, but are unclassified due to insufficient data.\nDetailed list.\n&lt;templatestyles src=\"Tree list/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "26920", "revid": "46930796", "url": "https://en.wikipedia.org/wiki?curid=26920", "title": "Sammy Sosa", "text": "Dominican baseball player (born 1968)\nSamuel Peralta Sosa (; born November 12, 1968) is a Dominican former professional baseball right fielder. He played in Major League Baseball (MLB) for 18 seasons, primarily with the Chicago Cubs. After playing for the Texas Rangers and Chicago White Sox, Sosa joined the Cubs in 1992 and became regarded as one of the game's best hitters. Sosa hit his 400th home run in his 1,354th game and his 5,273rd at-bat, reaching this milestone quicker than any player in National League history. He is one of nine players in MLB history to hit 600 career home runs.\nIn 1998, Sosa, along with Mark McGwire, achieved international fame for his home run-hitting prowess in pursuit of Roger Maris' single-season home-run record. With the Cubs, Sosa became a 7-time All-Star while holding numerous team records. He finished his career with stints with the Baltimore Orioles and the Rangers for a second time. With the Rangers, Sosa hit his 600th career home run to become the fifth player in MLB history to reach the milestone.\nSosa is second all-time in home runs among foreign-born MLB players and is one of only three National League players since 1900 to reach 160 RBIs in one season (2001). He is also the only player to have hit 60 or more home runs in a single season three times, which he accomplished in 1998, 1999, and 2001. He did not lead the league in home runs in any of those seasons, although he did lead the league in 2000 with 50 home runs, and in 2002 with 49.\nIn a 2005 congressional hearing, Sosa\u2014through his attorney\u2014denied having used performance-enhancing drugs during his playing career, following multiple accusations. In a 2024 public statement, Sosa admitted to having made \"mistakes\" recovering from injuries during his career. \nEarly life.\nSosa was born in the Dominican Republic. Though born in a Batey community in Consuelo, his officially registered birthplace is San Pedro de Macor\u00eds, which was \"the largest town nearby\". Sosa is known to family and friends as \"Mikey\". His maternal grandmother suggested his birth name of Samuel, and also came up with his nickname: \"[She] heard the name on a soap opera she liked and decided from that moment on he would be Mikey.\"\nProfessional career.\nMinor Leagues (1989).\nPrior to making his major league debut, Sosa played for the Tulsa Drillers and Oklahoma City Comets.\nTexas Rangers (1989).\nSosa made his major league debut on June 16, 1989, with the Texas Rangers, wearing #17 and leading off as the starting left fielder. He hit his first career home run off Roger Clemens.\nChicago White Sox (1989\u20131991).\nOn July 29, 1989, the Rangers traded Sosa with Wilson \u00c1lvarez and Scott Fletcher to the Chicago White Sox for Harold Baines and Fred Manrique. In 1990, Sosa batted .233 with 15 home runs, 70 runs batted in, 10 triples, and 32 stolen bases. He also struck out 150 times, fourth most in the American League. Sosa started the 1991 season by hitting two home runs and driving in five runs. However, he slumped for the rest of the year and batted .203 with 10 home runs and 33 runs batted in.\nChicago Cubs (1992\u20132004).\nThe White Sox traded Sosa and Ken Patterson to the Chicago Cubs for outfielder George Bell before the 1992 season. Sosa batted .260 with eight home runs and 25 RBIs in his first season with the Cubs. In 1993, Sosa batted .261 with 33 home runs with 93 RBIs. He also showed his speed by stealing 38 bases and became the Cubs' first 30-30 player. Sosa continued to hit for power and speed in 1994 but he also improved his batting average. He ended up batting .300 with 25 home runs, 70 RBIs, and 22 stolen bases. Sosa was named to his first All-Star team in 1995. In 144 games, he batted .268 with 36 home runs and 119 RBIs. Sosa continued his success with the Cubs in 1996 as he batted .273 with 40 home runs and 100 RBIs. However, in 1997, Sosa batted just .251 with a .300 on-base percentage, and led the league in strikeouts with 174 despite hitting 36 home runs with 119 RBIs.\nAfter years as a respected power/speed threat with a rocket arm in right field, he emerged during the 1998 season as one of baseball's greatest. It was in this season that both Sosa and Mark McGwire were involved in the \"home run record chase\", when both players' prowess for hitting home runs drew national attention as they attempted to pass Roger Maris' single season home run mark of 61 home runs. In the early months of the year, Sosa trailed McGwire significantly, being as many as 16 homers behind at one point in May. But as the chase progressed, Sosa eventually tied McGwire with 46 home runs on August 10. However, McGwire pulled away slightly and reached 62 home runs to break the record first on September 8. Sosa tied McGwire once again at 62 on September 13. Eleven days later, with two games left to play in the season, the two were tied at 66 home runs each. Sosa ended the season with 66, finishing behind McGwire's 70. It was during that season that Cubs announcer Chip Caray nicknamed him \"Slammin' Sammy\", a nickname that quickly spread. Sammy produced then career-highs in batting average and slugging percentage, at .308 and .647 respectively. Sosa also led the league in RBIs and runs scored.\n Also in 1998, Sosa's 416 total bases were the most in a single season since Stan Musial's 429 in 1948. Sosa's performance in the month of June, during which Sosa belted 20 home runs, knocked in 47 runs, and posted an .842 slugging percentage, was one of the greatest offensive outbursts in major league history. Sosa won the National League Most Valuable Player Award for leading the Cubs into the playoffs in 1998, earning every first-place vote except for the two cast by St. Louis writers, who voted for McGwire. He and McGwire shared \"Sports Illustrated\" magazine's 1998 \"Sportsman of the Year\" award. Sosa was honored with a ticker-tape parade in his honor in New York City, and he was invited to be a guest at US President Bill Clinton's 1999 State of the Union Address. 1998 was also the first time the Cubs made the post-season since 1989. The Cubs qualified as the NL Wild Card team, but were swept by the Atlanta Braves in the NLDS. In the 1999 season, Sosa hit 63 home runs, again trailing Mark McGwire, who hit 65. In the 2000 season, Sosa led the league by hitting 50 home runs. He received the Babe Ruth Home Run Award for leading MLB in homers.\nIn 2001, he hit 64 home runs, becoming the first player to hit 60 or more home runs three times. However, he did not lead the league in any of those seasons; in 2001, he finished behind Barry Bonds, who hit 73 homers, breaking the single-season home run record set by McGwire in 1998 (70). In 2001, he also set personal records in runs scored (146), RBI (160), walks (116), on-base percentage (.437), slugging percentage (.737), and batting average (.328). He led the majors in runs and RBI, was second in home runs, second in slugging percentage, first in total bases, third in walks, fourth in on-base percentage, 12th in batting average, and 15th in hits. He also surpassed his 1998 number in total bases, racking up 425. Sosa once again led the league in home runs with 49 in 2002. In recognition of his accomplishments as a hitter, Sosa won the Silver Slugger Award (an award for offensive output, voted on by managers and coaches) in 1995 and in 1998 through 2002.\nIn 2003, the Cubs won the National League Central Division title. In May, he spent his first period on the disabled list since 1996 after having an injured toenail removed. On June 3, 2003, Sosa was ejected from a Chicago Cubs-Tampa Bay Devil Rays game in the first inning when umpires discovered he had been using a corked bat. Major League Baseball confiscated and tested 76 of Sosa's other bats after his ejection; all were found to be clean, with no cork. Five bats he had sent to the Hall of Fame in past years were also tested, and were all clean as well. Sosa stated that he had accidentally used the corked bat, which he claimed he only used during batting practice, and apologized for the incident. When Cubs manager Dusty Baker was interviewed later, he stated any use of corked bats on his team is strictly prohibited. On June 6, Sosa was suspended for eight games all without pay which was reduced to seven games (again without pay) on June 11 after appeal. Sosa finished the season with 40 home runs and hit two more in the 2003 NLCS against the Florida Marlins, falling to the team in seven games.\nIn May 2004, Sosa suffered an odd injury while sitting next to his locker chatting with reporters before a game in San Diego's Petco Park. He sneezed very violently, causing severe back pain. He was diagnosed with back spasms and placed on the disabled list. He finished with 35 homers, far below his numbers of his best years. Despite his declining production and release from the team at the end of the 2004 season, between 1995 and 2004 Sosa clubbed 479 home runs which is the most home runs by a player in history over a 10-year span. He also owns numerous team records for the Cubs and he holds the major-league record for the most home runs hit in a month (20, in June 1998). His tenure came to an end without fanfare, as he did not play in the final game of the regular season (played in Chicago) per his request, with Sosa reportedly leaving Wrigley Field before the game had ended. Sosa had stated he had permission from Baker to not play, while Baker stated that former assistant trainer Sandy Krum (serving as the go-between for the two) told Baker that Sosa had felt a bit injured and wanted out of the final game, but he expected Sosa to be on the bench with the rest of the players who weren't in the starting lineup.\nBaltimore Orioles (2005).\nOn January 28, 2005, the Cubs traded Sosa to the Baltimore Orioles in exchange for infielder-outfielder Jerry Hairston Jr., infielder Mike Fontenot, and RHP Dave Crouthers. To facilitate the deal, Sosa and his agent agreed to waive the clause that guaranteed his 2006 salary, and the players' union indicated it would not object to that agreement. Under the deal, Sosa earned $17.875\u00a0million for the 2005 season, with the Cubs paying $7\u00a0million of his salary. By playing for the 2005 Orioles alongside fellow 500-home-run batter Rafael Palmeiro, Sosa and Palmeiro became the first 500 home run club members in history to play together on the same team after reaching the 500 home run plateau. Sosa finished the 2005 season batting .221 with 14 home runs, his worst performance since 1992, and continuing his post-2001 trend of declines in batting average, homers, total bases, and RBI. On December 7, 2005, the Orioles decided not to offer him an arbitration contract, effectively ending his Baltimore Orioles tenure and making him a free agent.\nIn 2005, \"The Sporting News\" published an update of their 1999 book \"Baseball's 100 Greatest Players\". Sosa did not make the original edition, but for the 2005 update, with his career totals considerably higher, he was ranked at Number 95. During a stretch of nine consecutive years, Sosa hit 35 or more home runs and 100+ RBIs, all with the Chicago Cubs.\nYear off (2006).\nAt the end of January 2006, the Washington Nationals offered Sosa two different minor-league offers, both of which he turned down. On February 15, 2006, Sosa's agent Adam Katz stated: \"We're not going to put him on the retirement list. We decided that [not putting him on that list] was the best thing to do. But I can say, with reasonable certainty, that we've seen Sammy in a baseball uniform for the last time.\" During that year, Sosa accompanied President Leonel Fern\u00e1ndez of the Dominican Republic on several diplomatic trips including to the United States, Japan, and Taiwan.\nTexas Rangers (2007).\nThe Texas Rangers, Sosa's original team, signed him to a minor league deal worth $500,000 on January 30, 2007. This was the same contract that Sosa turned down the previous year from the Nationals. The contract included an invitation to spring training, where Sosa competed for a spot in the lineup with Nelson Cruz, Jason Botts, and other rookies/prospects. Sosa was successful during spring training and was added to the team's 25-man roster. He started the 2007 season as the Rangers' designated hitter and occasional right fielder.\nAt the same time, the Chicago Cubs awarded Sosa's number 21 to new pitcher Jason Marquis, who coincidentally served up Sosa's 600th career home run. This caused some concern, due to Sosa's accomplishments with the Cubs, including his status as the Cubs' all-time home run leader.\nOn April 26, 2007, Sosa made history by hitting a home run in his 45th major league ballpark. He has also homered in The Ballpark at Disney's Wide World of Sports, near Orlando, Florida, a usually minor-league and Spring training park that hosted a regular season series between the Rangers and the Tampa Bay Devil Rays in May 2007, although he did not hit a homer at the two regular season games the Cubs played at the Tokyo Dome in 2000 vs. the Mets. On June 20, 2007, Sosa hit a home run off of Jason Marquis during an inter-league game against the Chicago Cubs. Sosa became only the fifth man in history, following Babe Ruth, Willie Mays, Hank Aaron, and Barry Bonds, to hit 600 regular season home runs. The home run was the first one that Sosa had recorded against the Cubs, and as a result he has hit a home run against every active MLB team. Sosa is the Cubs' all-time home run leader, having hit 545 with that team.\nEnd of career (2008\u20132009).\nOn May 28, 2008, Sosa announced that he instructed his agent not to offer his services to any MLB team for the 2008 season, and planned on filing for retirement, but never did. On December 25, 2008, Sosa announced he intended to unretire and play in the World Baseball Classic and once again test the free agent market in hopes of signing with a Major League ballclub in 2009. Sosa said that he had been keeping in shape at his home, and was hoping that after a strong World Baseball Classic he would prove to major-league teams that he was still capable of playing in MLB. However, he was not selected as part of the Dominican Republic's roster. He remained a free agent and did not actively look for a team.\nOn June 3, 2009, Sosa announced his intention to retire from baseball. He made the announcement in the Dominican Republic and said that he was calmly looking forward to his induction into the Baseball Hall of Fame since his statistics were up to par.\nDrug test controversy.\nOn June 16, 2009, \"The New York Times\" reported that Sosa was on a list of players who had tested positive for performance-enhancing drugs in 2003, in baseball's steroids scandal. The paper stated that this information had been obtained from unnamed attorneys with knowledge of Major League Baseball drug test results from 2003.\nPreviously, Sosa sat alongside Rafael Palmeiro, Jose Canseco, and Mark McGwire at a hearing before the United States Congress. His attorney testified on his behalf, stating, \"To be clear, I have never taken illegal performance-enhancing drugs. I have never injected myself or had anyone inject me with anything. I have not broken the laws of the United States or the laws of the Dominican Republic. I have been tested as recently as 2004, and I am clean.\"\nOn December 19, 2024, Sosa released a somewhat ambiguous public statement through his PR firm, stating, \"There were times I did whatever I could to recover from injuries in an effort to keep my strength up to perform over 162 games. I never broke any laws, but in hindsight, I made mistakes and I apologize.\" Almost immediately, Cubs chairman Thomas S. Ricketts responded with a statement of his own, inviting Sosa to the 2025 Cubs Convention: \"We appreciate Sammy releasing his statement and for reaching out. No one played harder or wanted to win more\u2026We plan on inviting him to the 2025 Cubs Convention and, while it is short notice, we hope that he can attend. We are all ready to move forward together.\"\nNational Baseball Hall of Fame consideration.\nIn an interview with ESPN Deportes, Sosa said he would \"calmly wait\" for his induction into the National Baseball Hall of Fame, for which he became eligible in 2013. In results announced on January 9, 2013, Sosa was not elected by the Baseball Writers' Association of America (BBWAA) into baseball's Hall of Fame in Cooperstown, New York, receiving 12.5% in his first year on the ballot\u2014the requirement for election is 75%. In the following years, his voting percentage dropped as low as 6.6% in 2015 to a high of 17% in 2021. A candidate remains eligible for inclusion on subsequent ballots as long as he receives a minimum of 5.0% of the vote in a given year, and is removed from consideration by the BBWAA after 10 years of not being elected; thus, Sosa's final appearance was on the 2022 ballot, where he received 18.5% of votes.\nSosa may still be inducted into the Hall of Fame if recommended by the Hall of Fame's Contemporary Baseball Era Veterans Committee, which may elect players outside of the 10-year BBWAA eligibility window. However, the steroid ties and suspicions that prevented Sosa from previously being voted into the Hall of Fame, along with players like Barry Bonds and Roger Clemens, have made that seem unlikely.\nPersonal life.\nSosa married Sonia Rodr\u00edguez, a former Dominican TV dancer, in 1991. They have four children. He was formerly married to Karen Lee Bright for eight months beginning in 1990.\nIn 2009, Sosa appeared at a music awards show looking much lighter in complexion than he had just months earlier. The buzz around this drastic change prompted him to go on a Spanish-language television station to deny that he was ill, or that he hated being dark-skinned, or that his new skin tone was the result of steroid use. Sosa explained that he uses a bleaching cream before going to bed which softens and lightens his skin. \nSosa is Catholic.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26926", "revid": "1301488368", "url": "https://en.wikipedia.org/wiki?curid=26926", "title": "Spenser (character)", "text": "American literary detective\nSpenser is a fictional private investigator created by the American mystery writer Robert B. Parker. He acts as the protagonist of a series of detective novels written by Parker and later continued by Ace Atkins and Mike Lupica. His first appearance was in the 1973 novel \"The Godwulf Manuscript\". He is also featured in the 1980s television series \"\" and a related series of TV movies based on the novels. In March 2020, he was featured in the Netflix thriller film \"Spenser Confidential\".\nSpenser is only referred to by his surname in the novels, but the television series has him introduce himself as \"David Spenser\" to a cop sitting at the diner in the fifteenth episode of season 2. Also, Spenser is addressed as \"Jim\" at the end of Chapter 9 of \"The Godwulf Manuscript\" though this was probably a casual address by a stranger, akin to \"Mac\" or \"Buddy.\"\nFictional biography.\nSpenser was born and grew up in Laramie, Wyoming and is a Boston private eye in the mold of Raymond Chandler's Philip Marlowe, a smart-mouthed tough guy with a heart of gold. Unlike Marlowe, Spenser maintains a committed relationship with one woman (Susan Silverman, a psychologist). He is an ex-boxer who likes to remind readers that he once fought the former heavyweight champ Jersey Joe Walcott, and he lifts weights to stay in shape. He is quite well educated, cooks, and lives by a code of honor he and Susan discuss occasionally\u2014though as infrequently as he can manage.\nLike his creator, Robert B. Parker, Spenser is a Bostonian, and spent time in Korea with the U.S. Army. Spenser served as an infantryman in the 1st Infantry Division during the Korean War.\nSpenser is a former State trooper investigator assigned to the Suffolk County District Attorney's (DA) Office (although some novels state that he also worked out of the Middlesex County DA's Office; \"Walking Shadow\" and the pilot episode of \"\" say he was a Boston Police detective), and regularly seeks help from (or sometimes butts heads with) Martin Quirk. Quirk is originally a police lieutenant, later a captain, and he rises to an assistant superintendent (according to \"Little White Lies\") of the Boston Police Department. Among his other police contacts are Sergeant Frank Belson and Detective Lee Farrell, both homicide investigators under Quirk's command; Healy, a captain of the Massachusetts State Police; and Mark Samuelson, an LAPD lieutenant (later promoted to captain, as mentioned in \"Back Story\"). In Massachusetts, each county District Attorney's office has a squad of State Police Detectives assigned to their office to conduct investigations of major crimes committed in their jurisdictions.\nScotch is Spenser's drink of celebration. This is mostly having to do with an encounter with a bear while bird hunting in his teens. Spenser seems to agree with William Faulkner's assessment of Scotch \u2014 \"that brown liquor which not women, not boys and children, but only hunters drank.\" He also frequently drinks Irish Whiskey, sometimes just as a nod to his ethnic heritage, saying \u201cThe thing I like about Irish whiskey is that the more you drink the smoother it goes down. Of course that's probably true of antifreeze as well, but illusion is nearly all we have.\u201d\nOne of the inconsistencies or possible cases of retroactive continuity within the Spenser series surrounds his mother. In some of the early books he refers to his mother and, in 1981's \"A Savage Place\", for example, he quotes advice his mother gave him. By \"A Catskill Eagle\", Spenser states that his mother died during labor and he was delivered via Caesarean section, i.e. \"not of woman born\" as Parker has Spenser put it; he was raised by his father and his two maternal uncles, all of them carpenters, who do not appear in the series. Spenser received a football scholarship to Holy Cross, where he played strong safety. Spenser injured his knee and dropped out because he did not have the funds to complete his schooling. He took up boxing, and met Hawk, a tough man skilled with firearms, and Henry Cimoli, the owner of a gym where Spenser and Hawk still work out. His family unit beyond his near-fraternal relationship with Hawk is essentially Susan Silverman, an unofficial foster son named Paul Giacomin, and a series of dogs all named Pearl after Spenser's childhood dog of the same breed, a German Shorthaired Pointer. Silverman, originally a high school guidance counselor, continues to assist Spenser in his cases after becoming a Harvard-trained Ph.D. psychologist. Giacomin, initially an awkward, unsocialized teenager, becomes a professional actor and dancer.\nHawk.\nThe other major character in the Spenser novels is his close friend Hawk, originally introduced in the fourth novel \"Promised Land\". A black man, Hawk is an equally tough but somewhat shady echo of Spenser himself. Hawk served in the French Foreign Legion and in combat operations overseas. Hawk is a \"Gun for Hire\" who lives by his own personal code. Spenser and Hawk met as boxing opponents during a preliminary bout in the Boston Arena (now known as Matthews Arena). Each man believes he was the victor. Spenser and Hawk respect each other and are friends who each understand the other's philosophy of how to conduct themselves in life. Hawk received his own television series, \"A Man Called Hawk\", in 1989.\nYoung Spenser.\nReleased in 2009, a young adult novel, \"Chasing the Bear\", discusses some of Spenser's childhood, and further complicates the continuity issue with his family. At the end of the novel, Spenser leaves his father and uncles behind in Wyoming to attend college in Boston. No information was released as to whether this would commence a fourth regular series for Parker before his death in January 2010.\nSpenser's firearms.\nIn the 1970s and 1980s, Spenser usually carried a Smith &amp; Wesson Model 36 in .38 Special caliber, \"Chief's Special\" revolver. He would sometimes carry a .357 Magnum revolver that he usually kept in the top drawer of his office desk, for \"just in case\" situations. Spenser also had a small .32 caliber revolver that he carried as a \"backup\" weapon in the 1970s and early 1980s. In the novel \"The Widening Gyre\", Spenser carried a .25 caliber semiautomatic as a backup, and had it in his hand when confronted by two assassins - killing both. In 1992, Spenser started regularly carrying a Browning Hi-Power 9mm semi-automatic pistol. In 2010, Spenser replaces the Browning with a Smith &amp; Wesson .40 caliber semi-automatic pistol. In 2012, he starts carrying the Chief's Special again while working, but also carries the .357 Magnum or the .40 caliber Smith &amp; Wesson, in addition to the .38 Special, when anticipating a possible gunfight. On rare occasions, Spenser would use a rifle or shotgun when the situation required them. Spenser of the TV show carried a Beretta 92 9mm semi-automatic pistol. He also used a revolver, mostly in the first season.\nNovels.\nBy Robert B. Parker:\nBy Ace Atkins:\nBy Mike Lupica:\nAdaptations.\nThe universe depicted in the TV episodes and movies diverges from that in the novels, though many of the filmed presentations are based on, and named after, novels in the series.\nSpenser TV series.\nThe Spenser books were the inspiration for the 1985-1988 ABC TV series \"\" starring Robert Urich as Spenser, Barbara Stock as Susan, and Avery Brooks as Hawk. All three seasons of the series have been released on DVD by the Warner Archive Collection.\nAvery Brooks starred in a spin-off series entitled \"A Man Called Hawk\".\nFirst Spenser film series.\nFour made-for-TV movies based upon the series were produced by the Lifetime cable network between 1993 and 1995, again starring Robert Urich and Avery Brooks. The movies were based on four of Parker's novels: \"Ceremony\", \"Pale Kings and Princes\", \"The Judas Goat\" and \"A Savage Place\". Parker and his wife Joan co-wrote the first two screenplays. Barbara Stock was replaced as Susan Silverman in the first two movies by Barbara Williams and in the last two by veteran actress Wendy Crewson (\"Air Force One\"). Frank Belson was played by J. Winston Carroll. Parker's son Daniel appears in all four movies as a waiter in Spenser's favorite restaurant. Unlike the series, which was filmed in Boston, the new movies were filmed in Toronto (to take advantage of lower production costs). The first two movies retained the novels' Boston setting (parts of Toronto passed for Boston), while the second two were re-written to take place in Toronto.\nSecond Spenser film series.\nBeginning in 1999, Joe Mantegna played Spenser in three TV movies on the A&amp;E cable network: \"Small Vices\" (1999), \"Thin Air\" (2000), \"Walking Shadow\" (2001). Marcia Gay Harden played Susan, while Shiek Mahmud-Bey and, later, Ernie Hudson played Hawk. Robert B. Parker had a significant role in the development of the TV movies (all three films were adapted by Parker, with his wife co-authoring \"Walking Shadow\").\nSpenser Netflix movie.\n\"Spenser Confidential\" (formerly called \"Wonderland\") is a mystery film directed by Peter Berg and written by Sean O'Keefe. The film is very loosely based on the 2013 novel by Ace Atkins, an authorized continuation of the Spenser series. It uses the names of characters from the series of novels and a Boston setting, but otherwise departs substantially from the Parker/Atkins novels. The film stars Mark Wahlberg as Spenser, Winston Duke as Hawk and Alan Arkin as Henry Cimoli. Post Malone, Iliza Shlesinger, Bokeem Woodbine and Donald Cerrone also appear. \"Spenser Confidential\" was released by Netflix in March 2020. The movie received generally negative reviews, with Atkins taking negative swipes at both Wahlberg and the movie itself in the pages of the two Spenser novels released after the movie.\nShared universe.\nSpenser and Hawk live in the same Boston literary universe as Parker's other, later series characters: private investigator Sunny Randall and small town police chief Jesse Stone, the former of whom was possibly mentioned in passing as a blonde jogging with an English bull terrier, while the latter had a much larger role in \"Back Story\". Susan Silverman is Sunny Randall's psychologist in \"Melancholy Baby\".\nThe fictional Taft University, where Susan teaches, was also a primary setting for the Spenser novel \"Playmates\" and the non-Spenser novel \"Love and Glory\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26928", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=26928", "title": "Seven-card stud2", "text": ""}
{"id": "26929", "revid": "46051904", "url": "https://en.wikipedia.org/wiki?curid=26929", "title": "Spanish", "text": "Spanish might refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "26930", "revid": "30394555", "url": "https://en.wikipedia.org/wiki?curid=26930", "title": "Sideshow", "text": "Theatrical genre\nIn North America, a sideshow is an extra, secondary production associated with a circus, carnival, fair, or other such attraction. They historically featured human oddity exhibits (so-called \u201cfreak shows\u201d), preserved specimens (real or fabricated, such as the Fiji Mermaid), live animal acts, burlesque or strip shows, actually or ostensibly dangerous stunts, or stunts that appear painful like human blockhead.\nMost modern sideshows feature fewer to no animal acts, and have a greater focus on trainable feats or consensual body modification rather than exhibiting people with congenital disabilities, either due to changing public opinion or local laws prohibiting the exhibition of disabled people or animals.\nTrainable acts associated with sideshows include sword swallowing, fire breathing and manipulation, magic and visual illusions, human blockhead, knife throwing, lying on a bed of nails, contortion, and may also include an overlap with circus acts such as juggling, aerial hoop/silk/chains acrobatics, and motorcycle stunts like the Globe of Death. Whether such an act is considered \u201csideshow\u201d or \u201ccircus\u201d depends on how the show itself is billed, or advertised, to potential viewers.\nIn popular culture.\n\u201cSideshow\u201d as a theme is associated with the strange, grotesque, provocative, and taboo. Some movies, TV shows, Halloween decoration manufacturers, and live performers have adopted these aesthetics, which may include dramatic costumes, dangerous stunts, deformed humans or animals, sexual themes, horror elements, and other provocative or disturbing imagery.\nThe horror anthology \"\" involved sideshow themes throughout its story and promotional materials. It features dramatized versions of real sideshow performers from history, such as the ectrodactyl character Jimmy Darling, portrayed by Evan Peters in prosthetic makeup, based on the real \u201cLobster Boy\u201d, Grady Stiles Jr. The show also featured actors with real congenital abnormalities, such as Mat Fraser, born with phocomelia, and Jyoti Amge, the world\u2019s smallest living woman.\nTypes.\nThere are four main types of classic sideshow attractions:\nLegality.\nModern sideshows in North America have significantly fewer or no human oddities, and few to no traveling girl shows, due to both a changing public opinion and local laws prohibiting the exhibition of disabled people or animals, as well as stricter regulation of nude performance and designated locations they can legally occur.\nIn Michigan, since 1931 it has been a misdemeanor to display deformed or disabled humans as part of an exhibit, whether for free or by charging for tickets, except as part of medical education.\nIn Florida, as of 2024 it is a misdemeanor offense to display deformed animals in any place where a fee is charged. There is currently no law in Florida prohibiting human oddity exhibition.\nMost traveling burlesque dancers now work in dedicated legal venues such as cabarets or strip clubs, rather than as part of a carnival midway as was typical in the 20th century.\nRacism and Exploitation.\nParticularly in the United States, sideshows historically included practices such as the purchase of human beings, the display of human zoos, exploitation of the mentally disabled who could not consent to perform, segregation of performers and customers, especially in girl shows (nearly or fully nude performances), and minstrel shows.\nIn 1835, African-American woman Joice Heth was enslaved and sold to John S. Bowling and later P.T. Barnum, and was exhibited in sideshows under the false claim that she was the \u201c161-year-old nursing mammy of George Washington.\u201d After her death she was publicly autopsied, for which Barnum charged admission.\nUp until the mid 20th century, revues (girl shows) in the United States were racially segregated. Additionally, Black customers were prohibited from viewing white women performers, while anyone was permitted to see Black women.\nIn the 1999 book \"Girl Show: Into the Canvas World of Bump and Grind\", a former \u201cgirl show\u201d owner is quoted as saying:\n\u201cWhen we played in Texas we couldn\u2019t let black airmen into our show because the girls were white. These guys weren\u2019t allowed to see white strippers but they could go overseas and be killed for their country. That was OK? We didn\u2019t like it but the fair board and local police made the rules. This was up into the late 1950s and possibly the early 1960s.\u201d\nEarly history and acts.\nBy the 1830s, \"outside shows\" began to be established alongside travelling circuses. Initially, the circuses distanced themselves from the sideshows, but in 1850, a relationship was established between them.\n\"Working acts\" often exhibited a number of stunts that could be counted on to draw crowds. These stunts used little-known methods and offered the elements of danger and excitement. Such acts included fire eating, sword swallowing, knife throwing, body piercing, lying on a bed of nails, walking up a ladder of sharp swords, and more. \nDecline.\nInterest in sideshows declined as television made it easy (and free) to see the world's most exotic attractions. Moreover, viewing \"human oddities\" became distasteful as the public conscience changed, and many localities passed laws forbidding the exhibition of freaks. The performers often protested (to no avail) that they had no objection to the sideshow, especially since it provided not only a good income for them, but in many cases it provided their only possible job. \nEmmitt Bejano, a man with lamellar ichthyosis who performed as \u201cThe Alligator Boy\u201d, said: \u201c[Sideshow work] keeps me off the relief line.\u201d\nRevival.\nWith legal restrictions on human oddity exhibitions, most modern sideshows feature performances of trainable stunts and body modifications, which can but do not necessarily require congenital abnormalities.\nIn 2013, Gary Turner, born with Ehlers-Dalnos syndrome, performed as Gary Stretch with The Circus of Horrors, alongside other performers such as Jesus Aceves, a man born with hypertrichosis billed as \u201cWolfboy\u201d, who walked on swords as part of his act.\nJohn Haze, owner of the show, said of their sword swallower with body modifications Hannibal Helmurto:\n\"He wore a normal suit and had no tattoos. Ten years later he turned up at the Hackney Empire and he had completely changed his body.\"\nIn modern times, sideshow performers are often individual professionals or groups. A greater number of \"Single O\" attractions still tour carnivals.\nIn the 1940s, Ward Hall began the World of Wonders Amazement Show, which is still running today. It is the oldest carnival sideshow organization in America and is currently owned and run by Thomas Breen. \nIn 1970, John Strong Jr (son of John Strong of The John Strong 3 Ring Tented Circus) began a 47-year continuous run of traveling sideshow, The Strong Sideshow. Several acts and artifacts toured over the years such as the 5-legged dog, Chupacabra, a 2-headed cow, and a mummy. John Jr. performed all the live acts himself for several years including sword swallowing, fire eating, bed of nails blade box and electric chair. After living the lifestyle for a lifetime, The Strong Sideshow is now in residency at \"The Sideshow Museum\", in Uranus, Missouri.\nIn the early 1990s, Jim Rose developed a modern sideshow called \"the Jim Rose Circus\", reinventing the sideshow with two types of acts that would attract modern audiences and stay within legal bounds. The show featured acts reviving traditional sideshow stunts and carrying some of them to extremes, and \"fringe\" artists (often exhibiting extreme body modification) performing bizarre or masochistic acts like eating insects, lifting weights by means of hooks inserted in their body piercings, or stapling currency to their forehead. The show drew audiences at venues unknown to old-time sideshows, like rock clubs and the 1992 Lollapalooza festival. The Jim Rose Circus held its last known performance in 2013 at The London Burlesque Festival. The impact of the Jim Rose Circus on pop culture inspired a new wave of performers. There are now more sideshow performers than at any other time in the genre's history. At the same time in Canada, Scott McClelland, grandson of itinerant showman N.P. Lewchuk, formed Carnival Diablo, a show that performs frequently to this day. The success of these shows sparked a growing number of performers to revive the traditional sideshow arts, taught by sideshow veterans, and many now perform in spot engagements from rock clubs and comedy clubs to corporate events.\n\"Sideshows by the Seashore\", sponsored by Coney Island USA in Brooklyn, New York City, has performed since 1983, and tours under the name \"Coney Island Circus Sideshow\". Circus historian and collector Ken Harck ran the Brothers Grim Sideshow, which toured with the OzzFest music festival in the summer of 2006 and 2007. Sideshow celebrity and multiple world record breaker Chayne Hultgren 'The Space Cowboy' owns Australia's largest traveling oddity museum 'The Mutant Barnyard' and along with his partner Zoe Ellis 'AKA: Zoe L'amore' they run 'Sideshow Wonderland'.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26931", "revid": "49144025", "url": "https://en.wikipedia.org/wiki?curid=26931", "title": "Scorpio", "text": "Scorpio is the Latin word for scorpion. It most often refers to:\nThe term Scorpio may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "26932", "revid": "50878164", "url": "https://en.wikipedia.org/wiki?curid=26932", "title": "Sagittarius (constellation)", "text": "Zodiac constellation in the southern celestial hemisphere\nSagittarius is one of the constellations of the zodiac and is located in the Southern celestial hemisphere. It is one of the 48 constellations listed by the 2nd-century astronomer Ptolemy and remains one of the 88 modern constellations. Its old astronomical symbol is (\u2650\ufe0e). Its name is Latin for \"archer\". Sagittarius is commonly represented as a centaur drawing a bow. It lies between Scorpius and Ophiuchus to the west and Capricornus and Microscopium to the east.\nThe center of the Milky Way lies in the westernmost part of Sagittarius (see Sagittarius A).\nVisualizations.\nAs seen from the northern hemisphere, the constellation's brighter stars form an easily recognizable asterism known as \"the Teapot\". The stars \u03b4 Sgr (Kaus Media), \u03b5 Sgr (Kaus Australis), \u03b6 Sgr (Ascella), and \u03c6 Sgr form the body of the pot; \u03bb Sgr (Kaus Borealis) is the point of the lid; \u03b32 Sgr (Alnasl) is the tip of the spout; and \u03c3 Sgr (Nunki) and \u03c4 Sgr the handle. These same stars originally formed the bow and arrow of Sagittarius.\nMarking the bottom of the teapot's \"handle\" (or the shoulder area of the archer), is the bright star (2.59 magnitude) Zeta Sagittarii (\u03b6 Sgr), named Ascella, and the fainter Tau Sagittarii (\u03c4 Sgr).\nTo complete the teapot metaphor, under dark skies a particularly dense area of the Milky Way (the Large Sagittarius Star Cloud) can be seen rising in a north-westerly arc above the spout, like a puff of steam rising from a boiling kettle.\nThe constellation as a whole is often depicted as having the rough appearance of a stick-figure archer drawing its bow, with the fainter stars providing the outline of the horse's body. Sagittarius famously points its arrow at the heart of Scorpius, represented by the reddish star Antares, as the two constellations race around the sky. Following the direct line formed by Delta Sagittarii (\u03b4 Sgr) and Gamma2 Sagittarii (\u03b32 Sgr) leads nearly directly to Antares. Fittingly, Gamma2 Sagittarii is Alnasl, the Arabic word for \"arrowhead\", and Delta Sagittarii is called Kaus Media, the \"center of the bow,\" from which the arrow protrudes. Kaus Media bisects Lambda Sagittarii (\u03bb Sgr) and Epsilon Sagittarii (\u03b5 Sgr), whose names Kaus Borealis and Kaus Australis refer to the northern and southern portions of the bow, respectively.\nDue to its astronomical interest and its status as a Zodiac constellation, Sagittarius is one of the best-known constellations and is considered a prominent feature of the summer skies in the northern hemisphere. However, at locations north of 43\u00b0N the constellation either drags along the southern horizon, or it does not rise at all. By contrast, in most of the southern hemisphere Sagittarius can appear overhead or nearly so. It is hidden behind the Sun's glare from mid-November to mid-January and is the location of the Sun at the December solstice. By March, Sagittarius is rising at midnight. In June, it achieves opposition and can be seen all night. The June full moon appears in Sagittarius.\nIn classical antiquity, Capricorn was the location of the Sun at the December solstice, but due to the precession of the equinoxes, this had shifted to Sagittarius by the time of the Roman Empire. By approximately 2700 AD, the Sun will be in Scorpius at the December solstice.\nNotable features.\nStars.\n\u03b1 Sgr (Rukbat, meaning \"the archer's knee\") despite having the \"alpha\" designation, is not the brightest star of the constellation, having a magnitude of only 3.96. It is towards the bottom center of the map as shown. Instead, the brightest star is Epsilon Sagittarii (\u03b5 Sgr) (\"Kaus Australis,\" or \"southern part of the bow\"), at magnitude 1.85, or about seven times as bright as \u03b1 Sgr.\nSigma Sagittarii (\u03c3 Sgr) (\"Nunki\") is the constellation's second-brightest star at magnitude 2.08. Nunki is a B2V star approximately 260 light-years away. \"Nunki\" is a Babylonian name of uncertain origin, but thought to represent the sacred Babylonian city of Eridu on the Euphrates, which would make Nunki the oldest star name currently in use.\nZeta Sagittarii (\u03b6 Sgr) (\"Ascella\"), with apparent magnitude 2.61 of A2 spectra, is actually a double star whose two components have magnitudes 3.3 and 3.5.\nDelta Sagittarii (\u03b4 Sgr) (\"Kaus Meridionalis\"), is a K2 spectra star with magnitude 2.71 about 350 light years from Earth.\nEta Sagittarii (\u03b7 Sgr) is a double star with component magnitudes of 3.18 and 10, while Pi Sagittarii (\u03c0 Sgr) (\"Albaldah\") is actually a triple system whose components have magnitudes 3.7, 3.8, and 6.0.\nThe Bayer designation Beta Sagittarii (Beta Sgr, \u03b2 Sagittarii, \u03b2 Sgr) is shared by two star systems, \u03b2\u00b9 Sagittarii, with apparent magnitude 3.96, and \u03b2\u00b2 Sagittarii, magnitude 7.4. The two stars are separated by 0.36\u00b0 in the sky and are 378 light-years from earth. Beta Sagittarii, located at a position associated with the forelegs of the centaur, has the traditional name \"Arkab\", meaning \"Achilles tendon\".\nNova Sagittarii 2015 No. 2 was discovered on 15 March 2015, by John Seach of Chatsworth Island, NSW, Australia. It lies near the center of the constellation. It reached a peak magnitude of 4.3 before steadily fading.\nDeep-sky objects.\nThe Milky Way is at its densest near Sagittarius, as this is where the Galactic Center lies. As a result, Sagittarius contains many star clusters and nebulae.\nStar clouds.\nSagittarius contains two well-known star clouds, both considered fine binocular objects.\nNebulae.\nSagittarius contains several well-known nebulae, including the Lagoon Nebula (Messier 8), near \u03bb Sagittarii; the Omega Nebula (Messier 17), near the border with Scutum; and the Trifid Nebula (Messier 20), a large nebula containing some very young, hot stars.\nIn addition, several other nebulae have been located within Sagittarius and are of interest to astronomy.\nOther deep sky objects.\nIn 1999 a violent outburst at V4641 Sgr was thought to have revealed the location of the closest known black hole to Earth, but later investigation increased its estimated distance by a factor of 15. The complex radio source Sagittarius A is also in Sagittarius, near its western boundary with Ophiuchus. Astronomers believe that one of its components, known as Sagittarius A*, is associated with a supermassive black hole at the center of the galaxy, with a mass of 2.6 million solar masses. Although not visible to the naked eye, Sagittarius A* is located off the top of the spout of the Teapot asterism. The Sagittarius Dwarf Elliptical Galaxy is located just outside the Milky Way.\nBaade's Window is an area with very little obscuring dust that shows objects closer to the Milky Way's center than would normally be visible. NGC 6522, magnitude 8.6, and NGC 6528, magnitude 9.5, are both globular clusters visible through Baade's Window. 20,000 and 24,000 light-years from Earth, with Shapley classes of VI and V respectively, both are moderately concentrated at their cores. NGC 6528 is closer to the galactic core at an approximate distance of 2,000 light-years.\n2MASS-GC02, also known as Hurt 2, is a globular cluster at a distance of about 16 thousand light-years from Earth. It was discovered in 2000 by Joselino Vasquez, and confirmed by a team of astronomers under the leadership of R. J. Hurt at 2MASS.\nExploration.\nThe space probe New Horizons is moving on a trajectory out of the Solar System as of 2016 that places the probe in front of Sagittarius as seen from the Earth. New Horizons will exhaust its radioisotope thermoelectric generator long before it reaches any other stars.\nThe Wow! signal was a strong narrowband radio signal that appeared to have come from the direction of Sagittarius.\nMythology.\nThe Babylonians identified Sagittarius as the god Nergal, a centaur-like creature firing an arrow from a bow. It is generally depicted with wings, with two heads, one panther head and one human head, as well as a scorpion's stinger raised above its more conventional horse's tail. The Sumerian name Pabilsag is composed of two elements\u00a0\u2013 Pabil, meaning 'elder paternal kinsman' and Sag, meaning 'chief, head'. The name may thus be translated as the 'Forefather' or 'Chief Ancestor'. The figure is reminiscent of modern depictions of Sagittarius.\nGreek mythology.\nIn Greek mythology, Sagittarius is usually identified as a centaur: half human, half horse. However, perhaps due to the Greeks' adoption of the Sumerian constellation, some confusion surrounds the identity of the archer. Some identify Sagittarius as the centaur Chiron, the son of Philyra and Cronus, who was said to have changed himself into a horse to escape his jealous wife, Rhea, and tutor to Jason. As there are two centaurs in the sky, some identify Chiron with the other constellation, known as Centaurus. Or, as an alternative tradition holds, that Chiron devised the constellations Sagittarius and Centaurus to help guide the Argonauts in their quest for the Golden Fleece.\nA competing mythological tradition, as espoused by Eratosthenes, identified the Archer not as a centaur but as the satyr Crotus, son of Pan, who Greeks credited with the invention of archery. According to myth, Crotus often went hunting on horseback and lived among the Muses, who requested that Zeus place him in the sky, where he is seen demonstrating archery.\nThe arrow of this constellation points towards the star Antares, the \"heart of the scorpion\", and Sagittarius stands poised to attack should Scorpius ever attack the nearby Hercules, or to avenge Scorpius's slaying of Orion.\nTerebellum.\nOn the west side of the constellation, Ptolemy also described the asterism Terebellum consisting of four 4th magnitude stars, including the closest and fastest moving member, Omega Sagittarii.\nAstrology.\nAs of 2002[ [update]], the Sun appears in the constellation Sagittarius from 18 December to 18 January. In tropical astrology, the Sun is considered to be in the sign Sagittarius from 22 November to 21 December, and in sidereal astrology, from 16 December to 14 January.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "26933", "revid": "40126538", "url": "https://en.wikipedia.org/wiki?curid=26933", "title": "Scorpius", "text": "Zodiac constellation in the southern celestial hemisphere\nScorpius is a zodiac constellation located in the Southern celestial hemisphere, where it sits near the center of the Milky Way, between Libra to the west and Sagittarius to the east. Scorpius is an ancient constellation whose recognition predates Greek culture; it is one of the 48 constellations identified by the Greek astronomer Ptolemy in the second century.\nNotable features.\nStars.\nScorpius contains many bright stars, including Antares (\u03b1 Sco), \"rival of Mars,\" so named because of its distinct reddish hue; \u03b21 Sco (Graffias or Acrab), a triple star; \u03b4 Sco (Dschubba, \"the forehead\"); \u03b8 Sco (Sargas, of Sumerian origin); \u03bd Sco (Jabbah); \u03be Sco; \u03c0 Sco (Fang); \u03c3 Sco (Alniyat); and \u03c4 Sco (Paikauhale).\nMarking the tip of the scorpion's curved tail are \u03bb Sco (Shaula) and \u03c5 Sco (Lesath), whose names both mean \"sting.\" Given their proximity to one another, \u03bb Sco and \u03c5 Sco are sometimes referred to as the Cat's Eyes.\nThe constellation's bright stars form a pattern like a longshoreman's hook. Most of them are massive members of the nearest OB association: Scorpius\u2013Centaurus.\nThe star \u03b4 Sco, after having been a stable 2.3 magnitude star, flared in July 2000 to 1.9 in a matter of weeks. It has since become a variable star fluctuating between 2.0 and 1.6. This means that at its brightest it is the second brightest star in Scorpius.\nU Scorpii is the fastest known nova, with a period of about 10 years.\nAH Scorpii is a red supergiant star and one of the largest known stars, being 1,400 times larger than the Sun. It is also a luminous star, 340,000 times brighter than the Sun, although it is too faint to be seen by the naked eye, with a brightness varying from 6.5 to 9.6.\nThe close pair of stars \u03c91 Scorpii and \u03c9\u00b2 Scorpii are an optical double, which can be resolved by the unaided eye. One is a yellow giant, while the other is a blue B-type star in the Scorpius-Centaurus Association.\nThe star once designated \u03b3 Sco (despite being well within the boundaries of Libra) is today known as \u03c3 Lib. Moreover, the entire constellation of Libra was considered to be claws of Scorpius (\"Chelae Scorpionis\") in Ancient Greek times, with a set of scales held aloft by Astraea (represented by adjacent Virgo) being formed from these westernmost stars during later Greek times. The division into Libra was formalised during Ancient Greek or Roman times.\nDeep-sky objects.\nDue to its location straddling the Milky Way, this constellation contains many deep-sky objects such as the open clusters Messier 6 (the Butterfly Cluster) and Messier 7 (the Ptolemy Cluster), NGC 6231 (by \u03b6\u00b2 Sco), and the globular clusters Messier 4 and Messier 80.\nMessier 80 (NGC 6093) is a globular cluster of magnitude 7.3, 33,000 light-years from Earth. It is a compact Shapley class II cluster; the classification indicates that it is highly concentrated and dense at its nucleus. M80 was discovered in 1781 by Charles Messier. It was the site of a rare discovery in 1860 when Arthur von Auwers discovered the nova T Scorpii.\nNGC 6302, also called the Bug Nebula, is a bipolar planetary nebula. NGC 6334, also known as the Cat's Paw Nebula, is an emission nebula and star-forming region.\nMythology.\nIn Greek mythology, several myths associated with Scorpius attribute it to Orion. According to one version, Orion boasted to the goddess Artemis and her mother, Leto, that he would kill every animal on Earth. Artemis and Leto sent a scorpion to kill Orion. Their battle caught the attention of Zeus, who raised both combatants to the sky to serve as a reminder for mortals to curb their excessive pride. In another version of the myth, Artemis' twin brother, Apollo, was the one who sent the scorpion to kill Orion after the hunter earned the goddess' favor by admitting she was better than him. After Zeus raised Orion and the scorpion to the sky, the former hunts every winter but flees every summer when the scorpion comes. In both versions, Artemis asked Zeus to raise Orion.\nIn a Greek myth without Orion, the celestial scorpion encountered Phaethon while he was driving his father Helios' Sun Chariot.\nOrigins.\nThe Babylonians called this constellation MUL.GIR.TAB - the 'Scorpion'; the signs can be literally read as 'the (creature with) a burning sting'.\nIn some old descriptions the constellation of Libra is treated as the Scorpion's claws. Libra was known as the Claws of the Scorpion in Babylonian (\"zib\u0101n\u012btu\" (compare Arabic \"zub\u0101n\u0101\")) and in Greek (\u03c7\u03b7\u03bb\u03b1\u03b9).\nAstrology.\nThe Western astrological sign Scorpio differs from the astronomical constellation. Astronomically, the Sun is in Scorpius's IAU boundaries for just six days, from November 23 to November 28. Much of the difference is due to the constellation Ophiuchus, which is used by few astrologers. Scorpius corresponds to the Hindu nakshatras Anuradha, Jyeshtha, and Mula.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "26934", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=26934", "title": "Scheme", "text": "Scheme or schemer may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "26938", "revid": "21678789", "url": "https://en.wikipedia.org/wiki?curid=26938", "title": "SF", "text": "SF may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
